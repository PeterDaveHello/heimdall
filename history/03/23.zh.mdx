---
localized_date: 2023年3月23日
top_news: De-cloud and de-k8s - bringing our apps back home
---



## 2023 年 3 月 23 日

### [De-cloud and de-k8s - bringing our apps back home](https://dev.37signals.com/bringing-our-apps-back-home/?ref=hackernewsgpt.com)

- 由于技术债务和云服务的复杂性，37signals 的运营团队正在将他们的应用从云端移回自己的硬件上。
- 他们创建了一个名为 "mrsk "的工具，以简化他们现有的容器化应用程序的操作。
- 他们对配置管理进行了现代化和简化，将配置虚拟机的时间从每个客户约 20 分钟缩短到不到 1 分钟。
- 37signals 将他们的 CDN 和 DNS 需求切换到 Cloudflare，以取代 CloudFront 和 Route53。
- Tatalist、Writeboard 和 Backpack 在不到六周的时间内完成了迁移，最后一次迁移只用了 16 分钟。
- 他们的大多数应用程序只需要一个标准的 Rails 应用程序部署作为基础设施要求。

### [2 月房价下跌，为 11 年来首次](https://www.wsj.com/articles/home-prices-fell-in-february-for-first-time-in-11-years-73df0107?ref=hackernewsgpt.com)

- 2019 年 2 月，美国以前拥有的房屋销售量比上个月增长了 14.5%，但比去年同期下降了 22.6%。
- 美国 2 月份的房屋价格 11 年来首次下降，显示了美联储加息运动的影响。
- 全国房地产经纪人协会报告说，美国经历了十多年来房价的首次同比下降和抵押贷款利率的下调。

### [OpenAI 的政策阻碍了语言模型的可重复研究](https://aisnakeoil.substack.com/p/openais-policies-hinder-reproducible?ref=hackernewsgpt.com)

- OpenAI 的政策阻碍了对语言模型的可重复研究，语言模型已经成为私人控制的研究基础设施。
- OpenAI 的模型废弃令人担忧，因为语言模型(LLMs)正在成为基础设施的关键部分，研究人员和开发人员依靠 LLMs 作为基础层，然后针对特定的应用或回答研究问题进行微调。
- OpenAI 和其他公司一样，定期更新较新的模型，如 GPT-3.5 和 GPT-4，这意味着使用这些模型会成为可重复性的障碍。
- OpenAI 对 Codex 的匆忙废除迫使研究人员和开发人员转而使用 GPT 3.5 模型，而这些模型是没有可比性的，导致旧有工作的不可复制性。
- OpenAI 允许研究人员访问 Codex，但申请过程不透明，而且不清楚该模型可以使用多长时间。
- 将 LLMs 开源可能是确保重现性的关键一步。

### [反恐精英 2 - CS:GO 特定玩家的有限测试](https://counter-strike.net/cs2?ref=hackernewsgpt.com)

- 反恐精英 2》正在开发中，目前正在对 CS:GO 中的部分玩家进行有限测试。
- 这次测试是为了评估新的游戏机制、武器和其他功能。
- 开发商还没有宣布《反恐精英 2》的发布日期。

### [Coinbase 被 SEC 发出威尔斯通知](https://www.reuters.com/legal/coinbase-issued-wells-notice-by-sec-2023-03-22/?ref=hackernewsgpt.com)

- 美国证监会向 Coinbase 发出威尔斯通知，称其可能就其部分加密货币产品起诉该公司。
- 据说 Coinbase 的现货市场和 Earn、Prime 和 Wallet 产品受到了审查。
- 像 Coinbase 的 Earn 这样的盯盘服务被指控没有在美国证券交易委员会注册。
- 公告发布后，Coinbase 的股票下跌了近 13%。
- Coinbase 表示，通知发出后，其服务照常运营。

### [Mozilla.ai: Investing in Trustworthy AI](https://blog.mozilla.org/en/mozilla/introducing-mozilla-ai-investing-in-trustworthy-ai/?ref=hackernewsgpt.com)

- Mozilla 宣布创建 Mozilla.ai，它将建立一个值得信赖的独立开源人工智能生态系统。
- 这家初创公司将使开发值得信赖的人工智能产品变得容易，其核心是机构、问责制、透明度和开放性。
- Mozilla 正在为这一举措投入 3000 万美元，并将由 Moez Draief 领导。
- 最初的重点将是使生成性人工智能更安全、更透明的工具，以及以人为本的推荐系统，不误导或破坏福祉。

### [美国证券交易委员会指控加密货币企业家贾斯汀-孙和他的公司涉嫌欺诈](https://www.sec.gov/news/press-release/2023-59?ref=hackernewsgpt.com)

- 美国证券交易委员会(SEC)已经指控加密资产企业家贾斯汀-孙和他的三家公司未经注册提供和销售加密资产证券 Tronix(TRX)和 BitTorrent(BTT)。
- 美国证券交易委员会称，孙正义和他的公司通过多个未注册的 "赏金计划 "提供和销售 TRX 和 BTT 作为投资。
- 孙正义还违反了联邦证券法的反欺诈和市场操纵条款，策划了一个计划，人为地夸大 TRX 在二级市场的表面交易量。
- 美国证券交易委员会还指控八位名人非法兜售 TRX 和/或 BTT 而不披露报酬：Lindsay Lohan、Jake Paul、DeAndre Cortez Way(Soulja Boy)、Austin Mahone、Michele Mason(Kendra Lust)、Miles Parks McCollum(Lil Yachty)、Shaffer Smith(Ne-Yo)和 Aliaune Thiam(Akon)。
- 除两位名人外，被指控的个人同意支付总额超过 40 万美元的罚金、利息和罚款以解决指控，但不承认或否认美国证券交易委员会的调查结果。

### [不受欢迎的观点：不要用树莓派做这个](https://set-inform.com/2021/08/24/unpopular-opinion-dont-use-a-raspberry-pi-for-that/?ref=hackernewsgpt.com)

- 一篇博文反对将 Raspberry Pi 作为不显眼且价格低廉的 Linux 主机的默认选择。
- 作者建议，只有当 Raspberry Pi 在 GPIO 接口、极低的功率要求或狭小的空间限制等特定需求方面表现出色时，才应该使用它。
- 作者举例说明其他选择，如 AMD GX-415GA 或 HP Prodesk 600 G4 微型台式机，可以以类似甚至更低的成本提供更多的计算能力、更快和更可靠的存储，以及更好的社区支持。
- 作者的结论是，从长远来看，使用一个能够涵盖广泛用途的更强大的系统，比积累一堆有限用途的树莓派要好。

### [开发人员的就业市场是疯狂的](https://old.reddit.com/r/ExperiencedDevs/comments/11xq5cz/the_developer_job_market_is_insane_right_now/?ref=hackernewsgpt.com)

- 开发者就业市场目前竞争激烈，使候选人很难找到合适的角色。
- 一些公司正在使用过于冗长的招聘程序，包括多次面试、性格测验和技术测试，这使潜在的可雇用的候选人感到失望。
- 有关招聘实践的负面经验可以通过在线评论报告，作为提高对招聘方法问题的认识的一种方式。
- 候选人认为工作面试是一个通过/失败的事件，而雇主则认为这是一场竞争。
- 由于公司有避免可能的歧视诉讼的政策，所以很少有反馈。
- 候选人不应该浪费时间去申请不合适的工作，LinkedIn 在帮助候选人跟踪申请和与招聘人员沟通方面发挥了关键作用。
- 有些公司对简单的工作有过于复杂的面试过程。
- 现在软件工程师的就业市场很严峻，市场上有很多高质量的工程师，但公司在招聘时却很谨慎，很挑剔。
- 公司在招聘过程中更加挑剔，导致面试过程更长，角色竞争更激烈。
- 网络仍然是寻找工作的最佳途径，特别是在一个艰难的市场中。

### [研究表明，我们只能在 50%左右的时间里准确识别人工智能作家](https://hai.stanford.edu/news/was-written-human-or-ai-tsu?ref=hackernewsgpt.com)

- 斯坦福大学研究人员的一项研究显示，人们在大约 50%的时间内只能准确识别人工智能生成的文本。
- 该研究的参与者在 OKCupid、AirBNB 和 Guru.com 的社交媒体平台上看到了文本样本。
- 研究发现，高语法正确性和第一人称代词的使用经常被错误地归因于人类生成的文本，而提及家庭生活和使用非正式的对话性语言也是如此。
- 该研究的影响表明，更便宜和更容易的人工智能生成的内容可能会在未来导致更多的错误信息。
- 研究小组提出了一些解决方案，如给人工智能一个可识别的口音，或在高风险的情况下自我披露机器，以提高我们区分人类和人工智能生成的内容的能力。


