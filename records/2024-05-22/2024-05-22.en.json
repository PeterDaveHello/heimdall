[
  {
    "id": 40432688,
    "title": "Pioneering Computer Engineer Gordon Bell Passes Away at 89",
    "originLink": "https://arstechnica.com/gadgets/2024/05/gordon-bell-an-architect-of-our-digital-age-dies-at-age-89/",
    "originBody": "the great memory register in the sky — Gordon Bell, an architect of our digital age, dies at age 89 Bell architected DEC's VAX minicomputers, championed computer history, mentored at Microsoft. Benj Edwards - 5/21/2024, 6:53 PM Enlarge / A photo of Gordon Bell speaking at the annual PC Forum in Palm Springs, California, March 1989. Ann E. Yow-Dyson/Getty Images reader comments 37 Computer pioneer Gordon Bell, who as an early employee of Digital Equipment Corporation (DEC) played a key role in the development of several influential minicomputer systems and also co-founded the first major computer museum, passed away on Friday, according to Bell Labs veteran John Mashey. Mashey announced Bell's passing in a social media post on Tuesday morning. Further Reading Long gone, DEC is still powering the world of computing \"I am very sad to report [the] death May 17 at age 89 of Gordon Bell, famous computer pioneer, a founder of Computer Museum in Boston, and a force behind the @ComputerHistory here in Silicon Valley, and good friend since the 1980s,\" wrote Mashey in his announcement. \"He succumbed to aspiration pneumonia in Coronado, CA.\" Bell was a pivotal figure in the history of computing and a notable champion of tech history, having founded Boston's Computer Museum in 1979, which later became the heart of the Computer History Museum in Mountain View, with his wife Gwen Bell. He was also the namesake of the ACM's prestigious Gordon Bell Prize, created to spur innovations in parallel processing. Born in 1934 in Kirksville, Missouri, Gordon Bell earned degrees in electrical engineering from MIT before being recruited in 1960 by DEC founders Ken Olsen and Harlan Anderson. As the second computer engineer hired at DEC, Bell worked on various components for the PDP-1 system, including floating-point subroutines, tape controllers, and a drum controller. Bell also invented the first UART (Universal Asynchronous Receiver-Transmitter) for serial communication during his time at DEC. He went on to architect several influential DEC systems, including the PDP-4 and PDP-6. In the 1970s, he played a key role in overseeing the aforementioned VAX minicomputer line as the engineering manager, with Bill Strecker serving as the primary architect for the VAX architecture. Advertisement After retiring from DEC in 1983, Bell remained active as an entrepreneur, policy adviser, and researcher. He co-founded Encore Computer and helped establish the NSF's Computing and Information Science and Engineering Directorate. In 1995, Bell joined Microsoft Research where he studied telepresence technologies and served as the subject of the MyLifeBits life-logging project. The initiative aimed to realize Vannevar Bush's vision of a system that could store all the documents, photos, and audio a person experienced in their lifetime. Bell was elected to the National Academy of Engineering, National Academy of Sciences, and American Academy of Arts and Sciences. He received the National Medal of Technology from President George H.W. Bush in 1991 and the IEEE's John von Neumann medal in 1992. “He was immeasurably helpful” As news of Bell's passing spread on social media Tuesday, industry veterans began sharing their memories and condolences. Former Microsoft CTO Ray Ozzie wrote, \"I can't adequately describe how much I loved Gordon and respected what he did for the industry. As a kid I first ran into him at Digital (I was then at DG) when he and Dave were working on VAX. So brilliant, so calm, so very upbeat and optimistic about what the future might hold.\" Further Reading A brief tour of the PDP-11, the most influential minicomputer of all time Ozzie also recalled Bell's role as a helpful mentor. \"The number of times Gordon and I met while at Microsoft—acting as a sounding board, helping me through challenges I was facing—is uncountable,\" he wrote. Former Windows VP Steven Sinofsky also paid tribute to Bell on X, writing, \"He was immeasurably helpful at Microsoft where he was a founding advisor and later full time leader in Microsoft Research. He advised and supported countless researchers, projects, and product teams. He was always supportive and insightful beyond words. He never hesitated to provide insights and a few sparks at so many of the offsites that were so important to the evolution of Microsoft.\" \"His memory is a blessing to so many,\" wrote Sinofsky in his tweet memorializing Bell. \"His impact on all of us in technology will be felt for generations. May he rest in peace.\" reader comments 37 Benj Edwards Benj Edwards is an AI and Machine Learning Reporter for Ars Technica. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC. Advertisement Promoted Comments Unclebugs There are going to be a lot more of these obituaries because the generation to gave rise to and engineered the digital revolution is/was the Baby Boomer generation and those born just before WWII. As a boomer, I lived through the punchcard era of programming et cetera. What makes this so interesting to me is that the technology which we take for granted today was not available to previous generations, so who knows how many people in how many countries actually made so much scientific progress possible. In today's world we nearly instantly know who published what, when, and where, because of pioneers like Gordon Bell. We will also see them passing on and others picking up the mantle to move us forward. I do wonder at times what kind of world my grandsons will be inheriting, but all the Gordon Bells out there are working to make it a better one. May 21, 2024 at 7:22 pm holmes4 I worked for DEC from 1978 through its end, and Gordon was revered among nearly all of us engineers. His memo suggesting a \"No-Output Division\" for employees who are just wasting other peoples' time is legendary. May 21, 2024 at 7:35 pm Channel Ars Technica ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=40432688",
    "commentBody": "Gordon Bell has died (arstechnica.com)1184 points by dcminter 23 hours agohidepastfavorite67 comments ChrisArchitect 22 hours agoNYT obit https://www.nytimes.com/2024/05/21/technology/c-gordon-bell-... jpgvm 23 hours agoprevGordon was the first investor in my first startup, the first guy that believed in us. Even though I only met him later in his life he was still sharp as a tack, never lost the mind of the engineer. Sometimes it's best not to meet your heroes but Gordon lived up to the hype and then some. Super gentle, generous with his time, the consummate gentleman. One of my fondest memories from my startup years was enjoying dinner with Gordon and his wife in Sydney, she made the most amazing cookies. To this day I don't think I have had a better cookie haha. Visited the computer history museum with him once for a bit of a VIP tour I guess. So many stories about PDPs and all the friends he made along the way. Thanks for all the stories and memories old man, you have earned your rest. RIP. reply pfdietz 21 hours agoparentI wonder if that cookie recipe is written down somewhere. Gordon Bell practiced \"lifelogging\", so maybe! reply avagate 18 hours agorootparentHis lifelogging was a project called MyLifeBits. He wore a camera that took a picture every 20 seconds. Even called the book about his work Total Recall (and MSFT's new product that does something similar on the desktop is called Recall). Someone who worked with him at MSR wrote about it: https://www.linkedin.com/pulse/gordon-bell-standing-shoulder... reply drew870mitchell 3 hours agorootparentThe book is wonderful, as biz-tech-optimist quick reads go, and some of its ideas have stuck with me over a decade after reading it. I'm almost entirely off MSFT products now but i was heartened to see the Recall announcement the other day. Bell was a rare visionary. RIP reply skottenborg 8 hours agorootparentprevInteresting. Stephen Wolfram also wears a camera that snaps pictures every 20 seconds for special events. This is quite a read: https://writings.stephenwolfram.com/2019/02/seeking-the-prod... reply Roritharr 6 hours agorootparentI wish I could set my Meta Glasses to do this for special occasions where it's socially acceptable. reply ChuckMcM 13 hours agoprevI was really sad to hear he had passed. Since the first computer I ever programmed was a PDP-8/e I thought the guy who designed it must be a genius. When the Computer History Museum was being formed I gave them \"1K\" ($1024) and the person who collected that at the reception I was attending was Gwen Bell. I told her I admired Gordon's work and she called him over to say \"Hi\". We talked for about an hour about the PDP 8 and how the /E differed from the first 8 and the 8/I. Later, at a Vintage Computer Festival event Gordon was being honored and I worked with my Dad to gold plate an XR2242 front panel key which we then attached to a medal ribbon and presented to Gordon in a flip up Medal Presentation box. He got a great kick out of that. Definitely one of my heroes. reply workergnome 23 hours agoprevMy father worked with him at CMU and the story he always told (while possibly apocryphal) was that the reason that the ASCII bell character sequence was CRTL-G was because of Gordon. reply kragen 20 hours agoparentit seems somewhat unlikely. let's follow the trail the existence of bell characters, of course, predates gordon bell's existence itself (they're in the ita2 baudot-murray code from 01932, two years before his birth) so what we're discussing is specifically the assignment of the ascii bell character to the control character corresponding to bell's middle initial it was already ^g in 01963 according to tom jennings's excellent history https://web.archive.org/web/20100414012008/http://wps.com/pr... https://landley.net/history/mirror/ascii.html#ASCII-1963 and at that point bell had just started working at dec three years before. however, he was working on serial communications at dec, and had just been doing research at mit, so it wouldn't be terribly surprising if he, or friends of his from mit or dec, were to sit on the ansi (then asa) committee mackenzie's 'coded character sets' from 01980 has a chapter 13 about ascii https://textfiles.meulie.net/bitsaved/Books/Mackenzie_CodedC... but unfortunately it doesn't go into any detail on the composition of the asa committee. note that mackenzie was the ibm thug who invented ebcdic and spent the 60s and 70s trying to kill ascii, so he devotes most of the book to glorifying that catastrophic error; the book is from 01980, the year before ibm shipped its first ascii-supporting equipment, the ibm pc. it's reasonable to see jennings's account as a violent reaction against mackenzie's book, writing the malignant influence of the punched-card codes out of history entirely, though, as we'll see, the original draft of ascii was designed by a punched-card man bell's oral history interviews https://www.computerhistory.org/collections/catalog/10270203... don't mention ascii or asa or ansi, so he probably wasn't on the committee, but if it was a connivance by a friend of his, it would be easy to imagine him deliberately not mentioning it https://dl.acm.org/doi/pdf/10.1145/363831.363839 is an early (01965) publication of what eventually became ascii-1967, but it doesn't list the subcommittee members; the subcommittee seems to have been x3.2 at that point, though the 01963 document was called x3.4-1963 http://edition.cnn.com/TECH/computing/9907/06/1963.idg/ says the original proposal was submitted to ansi (though other sources say ansi didn't exist yet) by bob bemer of ibm in 01961. i thought it would be interesting to see if it already had ^g for bel, because bemer would be unlikely to know bell at that point in 02002 bemer wrote a 52-page history of ascii himself called 'a story of ascii' https://archive.org/details/ascii-bemer which includes a survey of coded character sets from 01960, including the character set used on the 'lincolnwriter' at mit, where bell had been working, and the pdp-1 for which bell designed the uart, as well as another 40 or so. so it wasn't like there was no contact. as it happens, neither of those two character sets includes a bell character the bell character appears in the first version of the ascii proposal in the leftmost column of table 3 on page 17 — but at position 10, from which it was moved to its current position of 7 (^g) after four revisions (iso/tc97 wg b, 01962 may 4, following x3.2/1, which was 01961 september 18). his only comment on why they moved all the control characters around was, 'the controls were regularized and grouped to 7 transmission controls, 6 format effectors, and 5 device controls; the improvement from the haphazardness of the previous proposals is quite apparent.' this was shortly before ibm sent him to the penalty box for promoting ascii, leading to him quitting to go to univac at that point there was still disagreement about whether to start the alphabet at the beginning of a 16-codepoint 'column' or, as is done today, one character later, so that a corresponds to 1, b corresponds to 2, etc. so assigning bel to 7 could have ended up with it being ^h. (i'm not clear on whether the ctrl key existed yet, but i'm pretty sure bit-paired keyboards did, on the teletype.) unfortunately bemer is also largely silent on the membership of the committee, though he does mention particular members from time to time. unless i've overlooked it, he doesn't mention anyone from mit or dec. the iso meeting was an international thing, with delegations from the us and various european countries, and thus seems particularly unlikely to have redesigned the character set to honor a dec engineer, who the committee members would think of as an american engineer so it's probably just a coincidence, but the evidence i've been able to turn up is not very conclusive reply gojomo 17 hours agorootparentI like that your deep dive into whether this story might be true is the polar opposite of the \"too good to check\" impulse in journalism & social media, which instead tries to squeeze some attention & entertainment out of a pleasing story before doing any checks that might ruin the illusion. reply mauricioc 9 hours agorootparentThe grandparent thought this was implausible, researched it as an outsider (with a slight bias towards thinking the claim is false, which is not a problem per se) and still didn't find any refutation. While I applaud the impetus behind the research, I'm more inclined to believe the apocryphal story after reading the attempt to refute it; not every piece of gossip will be supported by a written statement. reply darkwater 7 hours agorootparentprevOff-topic but, why are you using a leading zero to number years? reply aGHz 7 hours agorootparentNever too early to prepare for Y10K compliance: https://longnow.org/ideas/long-now-years-five-digit-dates-an... reply mgarciaisaia 13 hours agorootparentprevDon't you ever let reality get in the way of a good story reply panosfilianos 11 hours agorootparentprevreplies like these are the only reason to be at HN reply chris_wot 13 hours agorootparentprevSir, that is an amazing answer and a real gem of info on HN - thank you! reply AnimalMuppet 22 hours agoparentprevI have no data, but I wish that to be true. What an amazing tribute. reply inopinatus 21 hours agoparentprevcode 007, it's a secret reply kevindamm 19 hours agorootparentAh, hidden in plain sight, the seventh letter of the alphabet being G. reply readthenotes1 21 hours agoparentprevhttps://www.sensitiveresearch.com/Archive/CharCodeHist/X3.4-... ASCII was developed in 1963 by a guy from IBM while Bell was at DEC. However since Bell has worked in the PDP's UART, it's possible... reply ChrisArchitect 22 hours agoprevFrom the Computer History Museum homepage: > REMEMBERING CHM COFOUNDER GORDON BELL > CHM is saddened to share the news that Museum cofounder and Fellow Gordon Bell passed away on May 17, 2024. Bell was a prominent American electrical engineer and computer scientist who made a tremendous impact on the world of computing—from handheld devices to supercomputers. Bell is in the pantheon of brilliant computer designers that includes Seymour Cray and Gene Amdahl. > Beyond his groundbreaking engineering contributions, Bell has been a major force in preserving and presenting the history of computing to millions of visitors and explaining its impact on the world around us. With his then-wife, Gwen, and DEC cofounder Ken Olsen, he started The Computer Museum in Boston, which later became the Computer History Museum. Bell was a generous longtime donor and active member of the Board of Trustees. He will be missed by all. reply davidmurphy 19 hours agoparentI work at CHM, and we had a staff lunch today coincidentally. I raised a (non-alcoholic) toast in tribute to Gordon Bell with colleagues as we dined at my lunch table. Grateful for his legacy! Here he is speaking at a CHM event last year on Ethernet's 50th: https://youtu.be/T9On2L0-ObU?t=2267 reply ericd 19 hours agoparentprevMy wife jokes that we’ve never made it to the end of that museum, because the museum has always closed before we get to the end, and we’ve been at least a dozen times. I had no idea he cofounded it, among his other accomplishments. reply jhbadger 21 hours agoparentprevIt was unfortunate (at least for East Coasters) that the Computer Museum moved to the West Coast in 1999 -- I used to enjoy visiting it in Boston in the 1980s and 1990s. But I suppose with the decline of DEC and the rise of Microsoft and Apple in the 1980s that the center of the computer industry moved West too. reply pmcjones 18 hours agoparentprevHere's a tech report Gordon wrote: Out of a Closet: The Early Years of Years of The Computer [X] Museums https://research.microsoft.com/apps/pubs/default.aspx?id=147... And here's a website he created to capture the history of the original Computer Museum(s) at DEC and then Boston: https://tcm.computerhistory.org reply benreesman 13 hours agoprev\"The cheapest, fastest, and most reliable components are those that are not there.\" - Gordon Bell Rest in Peace Legend. I'm sure I join the entire community in wishing the best to his loved ones. He will be missed by all of us. reply Doctor-R 21 hours agoprevSome of his books are available in pdf on his website: https://gordonbell.azurewebsites.net/gbvita.htm I used Computer Structures:Readings and Examples in an architecture class, and High Tech Ventures in an entrepreneurial class at Stanford. I feel that Digital Equipment Corp entered a death spiral when he left. As a volunteer, I was fortunate that I was able to work with him on some projects at the Computer History Museum. I wish that I had taped him discussing many of the artifacts in the exhibit, especially machines he worked on. I created some training notebooks for CHM docents using chapters from Computer Structures, and the 1982 revised version. reply sctb 22 hours agoprevI remember watching a Channel 9 video about a decade or so ago where they visited Bell and co at the MSR office in San Francisco. That's where Gordon wanted to be and so Microsoft opened an office for him. In the video he was wearing a video camera around his neck and speaking a bit about the MyLifeBits project, IIRC. Now that I'm middle-aged and my relationship to technology has been changing, I'm struck by the passion, curiosity, and engagement he continued to exhibit. Remarkable lifelong attitude. reply walterbell 21 hours agoprevhttps://en.wikipedia.org/wiki/MyLifeBits > MyLifeBits is a life-logging experiment begun in 2001. It is a Microsoft Research project inspired by Vannevar Bush's hypothetical Memex computer system. The project includes full-text search, text and audio annotations, and hyperlinks. The \"experimental subject\" of the project is computer scientist Gordon Bell, and the project will try to collect a lifetime of storage on and about Bell.. For this, Bell has digitized all documents he has read or produced, CDs, emails, and so on. He continues to do so, gathering web pages browsed, phone and instant messaging conversations and the like more or less automatically. The book Total Recall describes the vision and implications for a personal, lifetime e-memory for recall, work, health, education, and immortality. In 2010, Total Recall was published in paperback. As of 2016, Bell was no longer using the wearable camera associated with the project. He described the rise of the smartphone as largely fulfilling Bush's vision of the Memex. \"Total Recall\" (2009) by Gordon Bell, https://www.amazon.com/Total-Recall-Memory-Revolution-Everyt... reply TiredOfLife 20 hours agoparentAnd obligatory related HN thread https://news.ycombinator.com/item?id=40425306 reply dboreham 21 hours agoprevSad news. If readers haven't come across it already, recommend his book \"Computer Engineering\". Available still in print and also on the kindle platform. https://www.amazon.com/Computer-Engineering-Hardware-Systems... reply whereistimbo 21 hours agoparentThe Gordon Bell's webpage has the free pdf version as @DoctorR posted https://news.ycombinator.com/item?id=40434375 reply dcminter 21 hours agoparentprevAlso on bitsavers: http://www.bitsavers.org/pdf/dec/_Books/Bell-ComputerEnginee... reply toomuchtodo 23 hours agoprevhttps://en.wikipedia.org/wiki/Gordon_Bell reply fredsmith219 18 hours agoprevThe same day he dies, Microsoft announces version control in Windows Explorer, which he originally bought to the file system in VMS. I know he worked on NT, I wonder why they didn’t introduce version control before now. reply kreddor 2 hours agoparentI think NTFS already supports it? The recent announcement seems to be for native git support. reply amirhirsch 23 hours agoprevRIP. I had the pleasure of messaging with him while developing a PDP-11/70 hardware replacement 17 years ago. reply KerrAvon 22 hours agoparentJust curious, did you write that up anywhere? Sounds potentially interesting to this audience. reply amirhirsch 21 hours agorootparenthttps://fpgacomputing.blogspot.com/2009/02/emulation-is-sinc... reply aap_ 22 hours agoprevOne of the most influential people in computer history. I'm glad I got to exchange a few mails with him a few years ago. RIP, GB. reply pjmorris 3 hours agoprevI've always loved 'The cheapest, fastest and most reliable components of a computer system are those that aren't there.' -- Gordon Bell, as quoted in Jon Bentley's 'Programming Pearls.' reply leoc 21 hours agoprevHe was great on camera, for example as the presenter of the Computer History Museum's old Computer Pioneers: Pioneer Computers video: https://www.youtube.com/watch?v=qundvme1Tik&list=PL14396C953... reply billylo 19 hours agoparentIt's so humbling to understand the history and the ingenuity required to create these foundations. Amazing stuff. reply dang 22 hours agoprevI liked this one: https://archive.computerhistory.org/resources/text/DEC/dec.b... via Gordon Bell – The No Output Division (1982) [pdf] - https://news.ycombinator.com/item?id=38490320 - Dec 2023 (1 comment) reply dcminter 22 hours agoparentAs someone who attends a lot of meetings at the moment I smarted a bit reading that. I don't think any of them are \"sewing circles\" but still... reply petesoper 19 hours agoprevGordon was one of the founders of Encore Computer and my first encounter was in Mass at the point Hydra, Resolution, Foundation and the other component company acquisitions were melding together. I remember being gob smacked by Gordon having a little Vax as his PC and only later came the \"well of course he does\" realization. He was keen for us to get on to Arpanet and that happened before the end of 1984. reply redbell 10 hours agoprevAs a side note, his personal page at https://gordonbell.azurewebsites.net/ doesn't seem to have been updated in more than ten years now. I believe it would make more sense to read \"Gordon Bell (1934-2024)\" instead of just \"Gordon Bell\". reply awestley 19 hours agoprevRIP. I loved the Computer Museum as a kid. It’s probably one of those thing that had a much bigger impact on me than I realize. reply hnthrowaway0328 23 hours agoprevI knew him through reading \"Showstopper\". What a loss! reply smarks 23 hours agoprevHere’s a link to Mashey’s post on mstdn: https://mstdn.social/@JohnMashey/112477330642538953 It’s short enough that I’ll quote it here. “I am very sad to report death May 17 at age 89 of Gordon Bell, famous computer pioneer, a founder of Computer Museum in Boston, and a force behind the @ComputerHistory her in Silicon Valley, and good friend since the 1980s. He succumbed to aspiration pneumonia in Coronado, CA. I'm told there will be a \"Celebration of Life\" service in August in Silicon Valley. (Another fallen giant, we attended a similar service in April for another, Nobelist Arno Penzias.)” HN should post the black bar. reply smarks 21 hours agoparentIn the thread below his preview post, Mashey added the following (edited for typos): \"When I lead tours of Computer History Museum, I usually say there were 3 giants in the early decades of computer architecture: Gene Amdhal - mainframes Gordon Bell - minicomputers Seymour Cray - supercomputers and I was lucky to know the first two well, never met Cray.\" https://mstdn.social/@JohnMashey/112477430691339073 reply 082349872349872 45 minutes agorootparent> never met Cray We lost Cray* to an untimely automobile accident. It'd be possible to have many fewer of those in the future, but that policy seems to be a much harder sell than I'd think it would be. * when the Mac team bragged they'd used a Cray to design their latest version (heat flow simulation IIRC), Cray humblebragged back that he'd used a Mac to design his latest version. reply timoteostewart 12 hours agoprevNot to be confused with Adam Gordon Bell, who is still very much alive. https://news.ycombinator.com/user?id=adamgordonbell https://adamgordonbell.com/ reply Sontho 11 hours agoprevA legend gone. reply swozey 20 hours agoprevI went to Mountain View/SV/California for the first time maybe 5 years ago and the CHM was so much cooler than I expected. It made me incredibly envious to have grown up on the east coast in the 90s where none of my friends had a computer until the early-mid 2000s instead of CA. Everyone I knew online was from California for a LONG time. I feel like I missed out on so much cool stuff because I learned most things out of Barnes and Noble books that I couldn't afford instead of being enmeshed in the culture. Rest in peace reply panick21_ 18 hours agoprevI was just recently on a youtube trip listening to all his talks and interviews. Also read some stuff, But I need to get the 'Computer Engineering' book. And I love history, and he did so much both as a participant, analyst and historian. Defiantly want to learn even more. Condolences to all who knew him. reply mproud 13 hours agoprevTIL that’s why the black bar is at the top of the page. reply dumpHero2 23 hours agoprevTop obituary posts on hn: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... reply f_allwein 22 hours agoparentJust thought how nice it is to read so many warm and heartfelt memories in all those obituaries. Wonder if it’ll be the same for current tech leaders/ maybe something for them to consider… reply II2II 21 hours agorootparentThere will be some, either due to their current contributions or decisions they make later in life. It is just hard to see that in the present since news tends to (and has always tended to) focus upon controversy. reply brian_herman 23 hours agoprevnext [2 more] Black bar for Bell please? reply brian_herman 22 hours agoparentThanks Dang! reply hwbunny 22 hours agoprevnext [3 more] If we could've preserved his brain for the future. reply pfdietz 21 hours agoparentIn a bell jar? reply hwbunny 21 hours agorootparentIn a digital rom. reply faeyanpiraat 20 hours agoprev [–] Breathing difficulties should never be the cause of death. I hope we are going to conquer these \"simple\" causes in the next couple of years. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gordon Bell, a pioneering computer engineer and key figure in the development of Digital Equipment Corporation's (DEC) influential minicomputers, passed away at age 89.",
      "Bell was instrumental in creating the VAX minicomputer line and co-founded the first major computer museum, which evolved into the Computer History Museum in Silicon Valley.",
      "He contributed to Microsoft Research, was the subject of the MyLifeBits life-logging project, and received numerous accolades, including the National Medal of Technology and the IEEE's John von Neumann medal."
    ],
    "commentSummary": [
      "Gordon Bell, a pioneering computer engineer and investor, has passed away, leaving a significant impact on the tech industry and those he mentored.",
      "Bell was known for his \"lifelogging\" project, MyLifeBits, and his contributions to computing, including work on the PDP-8 and founding the Computer History Museum.",
      "Despite his connections at DEC and MIT, the ASCII bell character (CTRL-G) predates Bell and was not named after him; Bob Bemer of IBM played a key role in developing ASCII."
    ],
    "points": 1184,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1716319439
  },
  {
    "id": 40434800,
    "title": "Sam Altman Faces Scrutiny Over OpenAI's Unauthorized Use of Scarlett Johansson's Voice",
    "originLink": "https://slate.com/technology/2024/05/scarlett-johansson-ai-voice-sam-altman-openai.html",
    "originBody": "THE INDUSTRY Sam Altman Is Showing Us Who He Really Is We should believe him. BY NITISH PAHWA MAY 21, 20245:20 PM Photo illustration by Slate. Photos by Mike Coppola/Getty Images for Time and Andreas Rentz/Getty Images. TWEET SHARE COMMENT OpenAI, the research firm whose 2022 launch of ChatGPT single-handedly pushed “artificial intelligence” into the mainstream, isn’t often inclined to back down from the knotty disputes—over copyright, safety concerns, appropriate regulations—that its innovative tech has raised. Yet this month, it antagonized someone much more powerful, and is already retreating just a touch. On Monday evening, Scarlett Johansson issued a statement to NPR’s Bobby Allyn about OpenAI’s GPT-4o announcement, which the company showcased in a live demonstration just last week. Specifically, the multimodal computer interaction model centered around a voice assistant named Sky, whose timbre really, really resembled ScarJo’s. “Last September, I received an offer from Sam Altman, who wanted to hire me to voice the current ChatGPT 4.0 system,” Johansson wrote. “After much consideration and for personal reasons, I declined the offer. Nine months later, my friends, family and the general public all noted how much the newest system named ‘Sky’ sounded like me. When I heard the released demo, I was shocked, angered and in disbelief that Mr. Altman would pursue a voice that sounded so eerily similar to mine that my closest friends and news outlets could not tell the difference.” Statement from Scarlett Johansson on the OpenAI situation. Wow: pic.twitter.com/8ibMeLfqP8 — Bobby Allyn (@BobbyAllyn) May 20, 2024 Johansson likewise mentioned that she was “forced” to hire lawyers who wrote letters to Altman and his company, after which “OpenAI reluctantly agreed” to switch out the voice. Indeed, earlier that morning, OpenAI tweeted that it was “working to pause the use of Sky” after hearing “questions about how we chose the voices in ChatGPT, especially Sky.” ADVERTISEMENT “We believe that AI voices should not deliberately mimic a celebrity’s distinctive voice—Sky’s voice is not an imitation of Scarlett Johansson but belongs to a different professional actress using her own natural speaking voice,” the company insisted in an accompanying blog post. Altman also spoke to Johansson’s explicit objection after NPR’s reporting, telling the public broadcaster: “We cast the voice actor behind Sky’s voice before any outreach to Ms. Johansson. Out of respect for Ms. Johansson, we have paused using Sky’s voice in our products. We are sorry to Ms. Johansson that we didn’t communicate better.” It was a strange apology and dubious explanation, not least because Altman himself invited comparisons of Sky’s voice to Johansson’s during the GTP-4o rollout. As was noted amply last week, he tweeted the word “her,” in obvious reference to what he’s previously called his favorite movie: Her, the 2013 Oscar-winning drama in which Johansson voices a Siri-like voice assistant with whom the film’s protagonist falls in love. (Altman, in a subsequent personal blog post: “It feels like AI from the movies.”) What’s more, as Johansson mentioned in her statement: “Two days before the ChatGPT 4.0 demo was released, Mr. Altman contacted my agent, asking me to reconsider. Before we could connect, the system was out there.” And, as the Washington Post’s Nitasha Tiku tweeted, she noticed during a live demo in September—the very same month that OpenAI reportedly offered ScarJo its hire-for-training offer—that the Sky voice even then sounded like Johansson, and that executives denied this was “intentional.” the ScarJo episode gives me an excuse to revisit one of the most memorable OpenAI demos I've had the pleasure of attending. back in ***September*** when the company first played the \"Sky\" voice, I told the exec in charge it sounded like ScarJo and asked him if it was intentional — Nitasha Tiku (@nitashatiku) May 21, 2024 Naturally, this hullabaloo has invited quite a bit of attention: The world’s most influential A.I. company is squaring off against a brand-name and litigation-happy celebrity, over a rather bizarre interpretation of one of her most acclaimed movies, in a reference that was employed in large part to launch one of OpenAI’s most esteemed upgrades to date—and one that has already fueled a surge in its mobile-app revenue (as well as controversy over the spam used to train its Chinese-language capabilities). The timing is a bit eyebrow-raising as well, considering that Johansson and her fellow actors only reached a post-strike union deal months ago—one fueled in large part over concerns regarding A.I.’s impacts on the movie industry. It makes sense that SAG-AFTRA publicly praised Johansson’s stance here against OpenAI. ADVERTISEMENT It’s also unusual to see Altman and his executives assume a preemptively defensive crouch on this, especially since they’ve offered little in the way of apology or transparency when it comes to the heaping amounts of data used to train and power apps like ChatGPT and DALL-E 3—other than admitting it would be “impossible” to train these models without sucking up vast amounts of copyright work, whether books or artworks or articles, sans permission or disclosure. The company is already fending off lawsuits from authors and news publishers over this very practice—and ironically, as 404 Media reported this month, it also sent a “copyright complaint” to the moderators of the OpenAI subreddit over their use of … OpenAI’s logo. Yet OpenAI’s reportedly aggressive actions in courting ScarJo’s voice and then pressing ahead without her consent have invited a new level of public opprobrium against the otherwise popular app-maker. The resulting damage control may arise from the fact that this incident, plus other developments from inside OpenAI’s offices over the past few months, may be exposing something else about the notoriously closed-lid firm: what kind of person Sam Altman really is. ADVERTISEMENT The last time OpenAI drama made national news occurred when the majority of the company’s board gave a no-confidence vote in Altman and suddenly fired him in November. They claimed that “he was not consistently candid in his communications with the board, hindering its ability to exercise its responsibilities.” The vague statement and rapid action led to public speculation that coalesced into an all-out war between two staunch sides: one consisting of Altman and his unfailingly loyal lieutenants, the other consisting of underlings and overseers worried over how quickly Altman wanted to develop and deploy new products, with little consideration to their potential for misuse, as well as his “psychologically abusive” treatment of employees (as the Post’s Tiku had reported). The aftereffects of that dust-up lingered for months after Altman was restored and the OpenAI board was (mostly) purged of his opponents. Ilya Sutskever, a main character in the November saga who’d reportedly questioned Altman’s honesty but stayed on at OpenAI, apparently “never returned to work” in the months following the fight, according to the New York Times. Last week, the company announced his departure. Just hours after that news, the head of Sutskever’s team announced his resignation, tweeting that he’d “been disagreeing with OpenAI leadership about the company’s core priorities for quite some time, until we finally reached a breaking point.” Reporters at Vox revealed that “at least five more of the company’s most safety-conscious employees have either quit or been pushed out” since November, with one of those quitters telling the website that he’d “gradually lost trust in OpenAI leadership.” ADVERTISEMENT There are likely still others who can’t talk, as Vox found out, because of an “extremely restrictive off-boarding agreement” that OpenAI employees are forced to sign if they want to retain any vested equity with the company—and that “forbids them, for the rest of their lives, from criticizing their former employer” or “even acknowledging that the NDA exists.” These revelations made waves in the tech world even prior to the ScarJo incident; Altman claimed on X that he was unaware of the equity provision, that it was being rewritten, and that “if any former employee who signed one of those old agreements is worried about it, they can contact me and we’ll fix that too.” But in light of Altman’s reputation within Silicon Valley, this comes across as a bit fishy. Related From Slate NITISH PAHWA Google Is About to Change Everything—and Hopes You Won’t Find Out READ MORE Past reporting from the MIT Technology Review has indicated that OpenAI “is obsessed with maintaining secrecy, protecting its image, and retaining the loyalty of its employees.” This appeared to play out in April, when the Information reported that two OpenAI staffers, one of them an ally of Sutskever’s, were fired for “allegedly leaking information.” As Bloomberg has noted, Altman is quietly thought of among his industry as “ambitious, cunning, even Machiavellian.” Other details from OpenAI’s ongoing copyright battles appear to bolster this. As part of its suit with the Authors Guild, documents were released showing how OpenAI deleted two massive datasets, consisting of “more than 100,000 published books,” that had been used to train an early iteration of its GPT model. Furthermore, the employees tasked with scrubbing that data were no longer with OpenAI, which had refused to disclose anything about its training-data history to the Authors Guild prior to this lawsuit. POPULAR IN TECHNOLOGY Sam Altman Is Showing Us Who He Really Is When I Tell People What I’m Doing to Make Ends Meet as a Grad Student, Their Reactions Are Something Else DeviantArt’s Downfall Is Devastating, Depressing, and Dumb Google Is About to Change Everything—and Hopes You Won’t Find Out On Monday, the lead counsel for the New York Times’ own suit against OpenAI sent a letter to the presiding judge, accusing the company of delaying a similar discovery process by “taking weeks to respond, dragging out negotiations over a protective order, and refusing to quickly produce basic information.” Oh yeah, and the Securities and Exchange Commission is investigating Altman’s comms in a probe over whether he and other senior OpenAI leaders misled the company’s investors. Yet Altman clearly hopes all this will wash away: OpenAI’s first post in the aftermath of the ScarJo squabble was a “safety update” for the AI Seoul Summit, which mentions that “we prioritize protecting our customers, intellectual property, and data.” ADVERTISEMENT For all Altman talks about the importance of “transparency,” for all the generosity he’s professed toward OpenAI’s dissenters, and for all the governmental glad-handing he’s done to paint himself as a responsible steward of A.I., it seems pretty clear he’s unafraid of playing a completely different game under wraps. If the underlying record of how he appears to treat his own employees, run his company, and keep his secrets clashes so much with his public statements, why should anyone—least of all Scarlett Johansson herself—trust that he actually went about Sky’s voice-training process in good faith? TWEET SHARE COMMENT Artificial Intelligence Celebrities",
    "commentLink": "https://news.ycombinator.com/item?id=40434800",
    "commentBody": "Sam Altman is showing us who he really is (slate.com)331 points by panarky 20 hours agohidepastfavorite397 comments panarky 20 hours agoAltman would have us believe it's all just an innocent misunderstanding but without actually saying so: \"We cast the voice actor behind Sky’s voice before any outreach to Ms. Johansson.\" Is he trying to suggest the company did not try to make the voice sound like her without her permission? The statement sounds like it's written by a lawyer to be technically true while implying something that is actually false. These are weasel words. He sounds sneaky, evasive and intentionally deceptive. We should not give a sneaky, deceptive and manipulative person this much power over our future. reply orthecreedence 20 hours agoparent> We should not give a sneaky and deceptive man this much power over our future. We should not give anybody this much power over our future. reply ryandrake 4 hours agorootparentJust to state the obvious, \"we\" are not doing anything here. \"We,\" as in \"the general public 'we'\" don't have much of a choice when someone has lots of money and lawyers and wants to use those resources to sneakily and deceptively make more money. Unless \"we\" elect better representatives who are willing to write and enforce laws governing the wealthy's ability to effectively do whatever they want, then \"we\" don't have much of a say. reply a_wild_dandan 19 hours agorootparentprevThis is why open source must win. I mean, it won't, but it's the only path to avoiding a silicon aristocracy. reply mensetmanusman 18 hours agorootparentThe code for these systems is around 1000 lines. It just takes $100,000,000 in electricity costs to execute the program. Open source might not matter. reply nradov 16 hours agorootparentI guess what we really need is super cheap fusion power or something? Or perhaps a way to easily share the cost by spreading the training load and electricity bill across millions of home computers? reply mikhailfranco 1 hour agorootparentYou are 2.5 years and $375m behind Sam :) Nuclear fusion start-up Helion scores $375 million investment from Open AI CEO Sam Altman https://www.cnbc.com/2021/11/05/sam-altman-puts-375-million-... reply vineyardmike 15 hours agorootparentprevIt's not literally the electricity that's the problem. It's also the billions in GPUs, and the teams of people fine tuning with reinforcement learning. Unlike most software projects that came before, Big AI Projects require a level of funding and coordination that can't be overcome with \"more volunteers\". It requires coordination and deep pockets - not for writing the code but for training it. reply dopidopHN 14 hours agorootparentprevOnce again, marx and the mean of production strike reply dbuder 19 hours agorootparentprevYes, an Open AI reply miohtama 20 hours agoparentprevThere are hundreds of people with similar voices. If any voice actor can pull the same accent than Ms. Johansson, it should be fair game, as long it was the original training material? Voices cannot be copyrighted or be exclusive, although I am sure Hollywood will try to copyright them in some point. reply afavour 20 hours agorootparentHe kind of ruined that argument when he tweeted “Her” alongside the video. Pretty clearly drawing a line between the voice and Johansson’s portrayal in the movie. Incredible, really. It would have been so easy to just… not do that. reply SrslyJosh 19 hours agorootparentGiven: 1. The plot of \"Her\" (guy falls in love with synthesized voice, played by Johansson) 2. Altman's affinity for the film (the article says he's called it his \"favorite movie\") Reaching out to Johansson about cloning her voice, then doing so without permission feels like Altman is creeping on her. The sooner this bubble pops, the better. reply couchdb_ouchdb 16 hours agorootparentWhat bubble? This isn't crypto. Have you used these tools? They aren't going anywhere. reply hnfong 15 hours agorootparentThere could be a bubble in terms of stock valuation, but the tools are definitely going to stay. This could be kinda like the dot com bubble -- the Internet went on to become BIG, but the companies just went bust... (and the ones that strive are probably not well known) reply ryandrake 4 hours agorootparentIt's an exuberance bubble. Every tech company on earth is racing to \"do something with AI\" because all of their competitors are trying to \"do something with AI\" and they don't want to be left out of the excitement. The excitement and exuberance will inevitably cool, and then a new thing will emerge and they'll all race to \"do something with that new thing.\" reply sshine 11 hours agorootparentprevI finally caved and started using GPTs daily a couple of days ago. I went to ask the Internet \"best AI tools\", and there's no clear consensus: Various Redditors go on to suggest \"here's 100 you might like to try\". So there's clearly a bubble, thousands of startups all trying for similar things. I am personally looking forward to try Wolfram GPT: https://www.wolfram.com/wolfram-plugin-chatgpt/ reply glenstein 4 hours agorootparentI understand there's way too much out there, but I think there is at least some clarity about the landscape at present. ChatGPT is currently king of the mountain. That could change, but right now that's how it is. Google's Gemini and Facebook's Llama 3 are clearly in a tier below. The 100s of tools you are seeing are various mixed and matched technologies that also belong in this tier. Claude (massive context) and Mistral/Mixtral (decent with no censoring/guard rails) are interesting for special cases. And if you're determined and want to put in the effort, you can experiment or self-host and perhaps come up with some capabilities that do something special that suits a use case or something you want to optimize for (although not everyone has time for that). So I wouldn't say it's just all this one big swirl of confusion and therefore a bubble and due to come crashing down. There's wheat, there's chaff, there's rhyme and reason. reply caeril 1 hour agorootparent> ChatGPT is currently king of the mountain. This is completely false. Claude Opus is significantly better than GPT 4. > Mistral/Mixtral (decent with no censoring/guard rails) These models have been heavily censored, I'm not sure what you're talking about. Community efforts like Dolphin to fine-tune Mixtral have some success, but no, Karen is definitely still hard at work in France, ensuring that Mistral AI's models don't offend anyone's precious fee-fees. reply px43 19 hours agorootparentprevHer was a movie with an AI assistant who talked like a normal human rather than an intentionally clunky \"bleep blorp\" dialect that lots of other movies go with. They even make fun of this in the movie when he asks her to read an email using a classic voice prompt, and she responds pretending to be a classic AI assistant. The new voice2voice from OpenAI allows for a conversational dialect, most prominently demonstrated in pop culture by the movie Her. Sam's tweet makes perfect sense in that context. Sky's voice has been the default voice in voice2voice for almost a year now, and no one has made a connection to the Her voice until it started acting more conversational. It seems pretty obvious that OpenAI was looking for a more conversational assistant, likely inspired by the movie Her, and it would have been cool if the actress had helped make that happen, but she didn't, and here we are. Also Juniper has always been the superior voice model. I just now realized that one of my custom GPTs kept having this annoying bug where the voice kept switching from Juniper to Sky, and that seems to be resolved now that Sky got removed. reply pseudalopex 18 hours agorootparent> Sky's voice has been the default voice in voice2voice for almost a year now, and no one has made a connection to the Her voice until it started acting more conversational. No.[1] [1] https://www.reddit.com/r/ChatGPT/comments/177v8wz/i_have_a_r... reply btilly 19 hours agorootparentprevLet's take a parallel situation from around 20 years ago, and see how you feel about it. I'm going back that far as a reminder of what was long considered OK, before AI. In the movie The Seed of Chucky, Britney Spears gets killed. You can watch the clip at https://www.youtube.com/watch?v=x3kCg5o0cHA. It is very clearly Britney Spears. Except Britney Spears was not hired for the role. They hired a Britney Spears impersonator for the scene. They did everything that they could to make it look like Britney, and think it was Britney. But it really wasn't. Do you think that Britney should have sued the Chucky franchise for that? If so, should Elvis Presly's estate also sue all of the Elvis Presly impersonators out there? Where do you draw the line? And if not, where do you draw the line between what happened in Chucky, and what happened here? I really don't see a line between now having someone who sounded like the actress, and then tweeting the name of one of her movies, and what happened 20 years ago with Chucky killing someone who looked like Britney, then showing a license plate saying \"BRITNEY1\", and THEN saying, \"Whoops I did it again.\" (The title of her most famous song at the time.) If anything, the movie was more egregious. reply kcplate 6 hours agorootparentThere is a distinction between the image of a celebrity and their voice. The image of a celebrity is usually pretty cut and dried, it’s them, or obviously intended to be them. If the use of their image isn’t meant to be satirical, it’s problematic. The Crispin Glover/Back to the Future 2 case is a good example of non-satirical use that was problematic. Zemeckis used previous footage of Glover, plus used facial molds of Glover to craft prosthetics for another actor. Voices…are usually not so distinctive. However, certain voices are very distinct—Tom Waits, Miley Cyrus, James Earl Jones, Matt Berry. Those voices are pretty distinctively those people and simulating their voices it would be obvious who you are simulating. Other celebrity voices are much more generic. Scarlett fits into this with a pretty generic female voice with a faint NY/NJ accent. Open AI screwed up by taking a generic voice and making it specific to the celebrity by reference and by actually pursuing the actor for the use of their voice. reply afavour 18 hours agorootparentprev> Seed of Chucky, the off-the-wall fifth installment of Don Mancini's Child's Play franchise, was forced to include a special disclaimer about pop superstar Britney Spears > This scene was included in promotional spots for the film, most specifically Seed of Chucky's trailer, but the distributing company associated with the film, Focus Features, made the decision to significantly cut the scene down and add a disclaimer. The disclaimer that ran with the promotional spot, which was altered to only show a brief glimpse of Ariqat as Spears, stated: \"Britney Spears does not appear in this film.\" https://screenrant.com/seed-of-chucky-movie-promos-britney-s... reply simonsarris 18 hours agorootparentprev> If so, should Elvis Presly's estate also sue all of the Elvis Presly impersonators out there? Generally the \"Right to Publicity\" laws are clear about expiring at death. It's not like copyright. reply SrslyJosh 19 hours agorootparentprevI don't think this is an apples-to-apples comparison. The movie producers didn't produce a simulation of Britney's voice and attempt to sell access to it. However you feel about an probably-unapproved celebrity cameo in a movie, it's not the same thing as selling the ability to impersonate that celebrity's voice to anyone willing to pay, in perpetuity. reply btilly 19 hours agorootparentIf you go to Vegas, you can go to a wedding officiated by someone who looks like, sounds like, and acts like Elvis Presly. This is available to anyone. You can get the same actor to do the same simulation for another purpose if you're willing to pay for it. The biggest difference that I see is that technology has made the simulation cheaper and easier. reply camel_Snake 18 hours agorootparentAnd these people are known as \"Elvis Presley impersonators.\" They don't pretend to be some obscure person you've never heard of, for very obvious reasons. The biggest difference here is obviously one of scale. I don't think ScarJo would be threatening to sue you, the individual, if you did a voice impression of her for a talent show or a friends wedding. reply stefan_ 19 hours agorootparentprevThis kind of de minimis artistic use is what fair use was invented for, and god knows they licensed her likeness regardless. reply andrewflnr 20 hours agorootparentprevThat makes it weird, but it doesn't (itself) mean they literally used her voice. It just means they were inspired by the movie. It's not illegal to be weird. reply llamaimperative 19 hours agorootparentLegally they don’t need to have literally used her voice to have broken the law, never mind violating many people’s basic sense of what’s right and wrong. reply andrewflnr 17 hours agorootparentThey don't? Because if it's true that they used a sound-alike voice actress for the actual model, I don't see how any reasonable complaint about that could stand. You can't ban people from voice-acting who have similar voices to other celebrities. There needs to be something more to it. reply CaptainZapp 10 hours agorootparent> You can't ban people from voice-acting who have similar voices to other celebrities Actually, you probably can.[0] [0] https://casetext.com/case/waits-v-frito-lay-inc Edit: Added the context for the reply reply andrewflnr 5 hours agorootparentWell that's... concerning? I'm not sure I disagree with the decision there but to apply it any more widely would be a problem. reply llamaimperative 4 hours agorootparentIt's such a huge problem that it's only brought up in the context of someone (probably) doing exactly what it's designed to prevent... By some miracle, this actually isn't used to outlaw satire or put Elvis impersonators out of work. It's used to prevent people from implying endorsement where none exists. reply pseudalopex 15 hours agorootparentprevThe something more is intent.[1] [1] https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply hluska 19 hours agorootparentprevI think it’s less the voice and more about how they went about it. They were apparently in negotiations with her and they fell apart. Then they tried to resume negotiations with her two days before the new model launched. If it was just an actor, it might be a case of inspiration gone awry. But this particular actor sued Disney in 2021 after making a lot of movies and a lot of money making movies for them. Deliberately poking a fight with a litigation happy actor is weird. Most weird is really benign. But this is the kind of weird that forces out of court settlements. It’s reckless. Edit - mistyped the date as 2001. Changed to 2021. reply andrewflnr 19 hours agorootparentOh, sure. There's plenty of other ways OpenAI have been boneheaded. I'm just saying the mere fact of referencing \"Her\" implies very little. reply jprd 19 hours agorootparentThat's a fair statement if you take the \"Her\" post out-of-context and without the corroborating retort from ScarJo and his history. Which, of course, is not possible and also pretty boneheaded itself. This isn't some college kid with an idea and too much passion. reply lwansbrough 20 hours agorootparentprevThe founding principle of Silicon Valley. reply throwaway42668 20 hours agorootparentprevPerpetual benefit of the doubt given for every implication as though it’s happening in a vacuum is how humanity keeps putting megalomaniacs and sociopaths into positions of power and influence. It’s really a shame. reply andrewflnr 19 hours agorootparentIf we're going to pillory Sam Altman, it's important to do it for the right reasons. That was not a good reason. I really should not need to defend this principle. reply jrflowers 19 hours agorootparentWhat reason do you suggest is more appropriate to “pillory Sam Altman” reply andrewflnr 17 hours agorootparentMost of the other ones in this thread? reply czl 19 hours agorootparentprevHad the film Her used someone else as the AI voice that sounded like Johansson would there be complaints about the film using a voice that sounded like Johansson? Does it matter if producers try to hire her first? Because only Johansson has that voice? Johansson does not visually show up the film Her and if not for the film credits could the voice in that film be used to use identity her from hundreds millions of other possible women? ( I had no idea who did the voice acting and would never had known if not for this news.) Now if the owners of the film Her were to request OpenAI licence a character from their film (like licencing say C3P0 character from Disney) maybe there would be a case but an actor claiming they own a natural human \"voice\" I think is a stretch when there are thousands of people with similar voices. And she is visually never in the film that made that AI voice famous so it could be anyone in that film with a similar voice. reply nradov 15 hours agorootparentI don't know about complaints but Ms. Johansson might be able to win a civil suit in that hypothetical situation. It would depend on the facts of the particular case, particularly any evidence that the defendants acted in bad faith. I think a lot of technologists don't understand how burden of proof works in civil trials, or that there is no presumption of \"innocence\". reply czl 2 hours agorootparentCivil trails are based on a preponderance of evidence (aka 50%) burden of proof standard (vs beyond reasonable doubt standard in criminal trails). I can see a civil judge or jury being given evidence showing very few listeners think the voices match in _blind voice tests_. Here for example you can listen to the voices side by side: https://www.reddit.com/r/ChatGPT/comments/1cwy6wz/comment/l4... And here is voice of another actress ( Rashida Jones ): https://www.youtube.com/watch?v=385414AVZcA This test is not blind but YOU tell me which you think is similar to the openAI sky voice? And what does that tell you about likely court result for Johansson? And having reached this conclusion yourself would you now think the other actress Rashida Jones is entitled to compensation based on this similarly test? Because there are no other women with similar voices? reply yreg 20 hours agorootparentprev> He kind of ruined that argument when he tweeted \"Her\" Why? The grandparent is not saying it's coincidence. Why is it not okay to hire someone who has a voice similar to celebrity X who you intentionally want to immitate? I mean if you don't actually mislead people to believe that your immitation is actually X - which would be obviously problematic? reply TylerE 20 hours agorootparentHe strongly implied that it wasn’t an imitation. reply yreg 19 hours agorootparentWe are talking about miohtama's argument, not Sam Altman. I don't believe Sam Altman, but I am interested in the general “is it legal/ethical to immitate something uncopyrightable” argument. reply TylerE 17 hours agorootparentAltman tweeted the name of a film Johansson stared in in association with this launch. reply FireBeyond 17 hours agorootparentprevAlright then, the solution is simple. All he has to do is name the actress that OpenAI -did- hire for the voice work, right? That would put any doubt to rest. reply throwaway5959 19 hours agorootparentprevHe knew there would be blowback, he just didn’t care. Look at how many people are talking about it. reply dclowd9901 19 hours agorootparentprevI imagine he feels invincible at this point and gets off on displaying power. reply meimo 20 hours agorootparentprevMore likely he was drawing a line between the fictional AI assistant, and their real, actualised assistant. reply HenryBemis 20 hours agorootparentprevHe said/X-ed the quiet part loud. reply stefan_ 19 hours agorootparentprevThis is one of those “accuse a diver of being a paedophile” moments. Who knew Sam is a creep with a Scarlet Johansson obsession cooking up a voice model just like her on compute daddy Satya paid for (but books as revenue, 2000 dotcom style). reply nomel 19 hours agorootparentprevHere’s a side by side. I’m not hearing the similarity that everyone else is: https://www.reddit.com/r/ChatGPT/comments/1cx9t8b/vocal_comp... Oops, that sounds like a match with Rashida Jones. Here’s one one of Scarlett J.: https://www.reddit.com/r/singularity/comments/1cx24sy/vocal_... I have a suspicion that most people with strong opinions on this haven’t actually compared Sky and Scarlett Johansson directly. reply xela79 7 hours agorootparent^^^this Rashida Jones is indeed a closer match, and might well be the person they went to once Scarlett declined and showed no interest. reply LeonB 20 hours agorootparentprevIn back to the future II, Crispin Glover didn’t sign up to be George McFly so they used facial prosthetics and impersonation to continue the George McFly character. He sued Universal, and reportedly settled for $760,000. Example article on the topic - https://www.hollywoodreporter.com/business/business-news/bac... reply frankacter 20 hours agorootparentWhile not defending OpenAI or Altman, the caveat here is that this was a voice actor using their natural voice, not an actor impersonating scarlett johansson. Setting a precedent that if your natural voice sounds similar to a more famous actor precludes you from work would be a terrible precedent to set. reply dragonwriter 19 hours agorootparent> Setting a precedent that if your natural voice sounds similar to a more famous actor precludes you from work would be a terrible precedent to set. Yes, but literally no one anywhere is suggesting that the voice actress used would be banned from work because of any similarity between her voice and Johansson's; that’s an irrelevant strawman. Some people are arguing that there is considerable reason to believe that the totality of the circumstances of OpenAI’s particular use of her voice would make OpenAI liable under existing right of personality precedent, which, again, does not create liability for mere similarity of voice. reply frankacter 18 hours agorootparent>Yes, but literally no one anywhere is suggesting that the voice actress used would be banned from work because of any similarity between her voice and Johansson's; that’s an irrelevant strawman It's not. The original comment in this chain was drawing parallel to a lawsuit in which someone intentionally took steps to impersonate an actor. This situation is a voice actor using their \"natural voice\" as a source of work. If a lawsuit barring OpenAI from using this voice actor is successful, due to similarities to a more famous actor, that puts this voice actor's future potential at risk for companies actively wanting to avoid potential for litigation. Suggesting a calming female persona as a real time always present life assistant draws parallel to a movie about a calming female persona that is a real time always present life assistant is not a smoking gun of impropriety. Pursuing a more famous name to attach to marketing is certainly worth paying a premium over a lesser known voice actor and again is not a smoking gun. Sky voice has been around for a very long time in the OpenAI app dating back to early 2023. No one was drawing similarities or crying foul and decrying how it \"sounds just like Scarlett\" .. reply pseudalopex 17 hours agorootparent> This situation is a voice actor using their natural voice as a source of work. https://news.ycombinator.com/item?id=40435388 > Sky voice has been around for a very long time in the OpenAI app dating back to early 2023. No one was drawing similarities or crying foul and decrying how it \"sounds just like Scarlett\" .. No.[1] [1] https://www.reddit.com/r/ChatGPT/comments/177v8wz/i_have_a_r... reply frankacter 17 hours agorootparentWhile you're right I should have chosen my words more carefully, a random reddit post with 68 upvotes doesn't really dispute the substance of my comment. OpenAI has been plastered across the news cycles for the last year, most of that time with Sky as the default voice. There was no discernable upheaval or ire in the public space suggesting the similarities of the voice in any meaningful public manner until this complaint was made. reply pseudalopex 15 hours agorootparentThe Reddit post had a link to a Washington Post article. And what you think the substance of your comment was is unclear. Most people don't use ChatGPT. Many people who use ChatGPT don't use voice generation. OpenAI's September update didn't have a demo watched by millions unless I missed something. Altman hyped the May update with references to Her. Some people thought the recent voice generation changes made the Sky voice sound more like Johansson. Some people gave OpenAI the benefit of the doubt before Johansson revealed they asked her twice. And what do you believe it would prove otherwise? reply frankacter 14 hours agorootparent>Washington Post article. And what you think the substance of your comment was is unclear. You mean this? \"Each of the personas has a different tone and accent. “Sky” sounds somewhat similar to Scarlett Johansson, the actor who voiced the AI that Joaquin Phoenix’s character falls in love with in the movie “Her.” Deng, the OpenAI executive, said the voice personas were not meant to sound like any specific person.\" As I stated prior, and thank you for making my point, despite being publicly available for near a year, there was minor mention of similarities with no general public sentiment. >Altman hyped the May update with references to Her If by \"hype\" you mean throwaway comments on social media that general population was unaware. Drawing a parallel to a calming persona of an always on life assistant from pop culture in a few throwaway social media posts from personal accounts such as \"Hope Everyone's Ready\" isn't hyping it as Her any more than Anthropic is selling their offerings as a Star Trek communicator despite a few comments they've made on social media. Ambiguous \"some people\" overstates any perceived concern and \"most people don't use ChatGPT\" understates how present they've been on the news. Mobile app, which heavily emphasized voice and has \"Sky\" as it's default voice The ChatGPT mobile application had over 110+ million downloads across iOS and Android platforms before the May announcement. In regards to the November announcement, yes, voice was very prominent in it with Sky as the default language. (https://youtu.be/pq34V_V5j18?si=66lEWxgteBbtKifl) reply pseudalopex 19 hours agorootparentprev> While not defending OpenAI or Altman, the caveat here is that this was a voice actor using their natural voice, not an actor impersonating scarlett johansson. How do you know? reply frankacter 18 hours agorootparent\"Sky's voice is not an imitation of Scarlett Johansson but belongs to a different professional actress using her own natural speaking voice\" https://www.npr.org/2024/05/20/1252495087/openai-pulls-ai-vo... reply FireBeyond 17 hours agorootparentAhh, because Sam \"Insufficiently Candid\" Altman has never lied before? reply hluska 19 hours agorootparentprevIf we assume that Scarlett Johansson is telling the truth, why would they try to resume negotiations with her two days before they launched the model? If they found a good actor whose voice sounds like Scarlett Johansson, that’s a great argument. But if they found a good actor whose voice sounds like Scarlett Johansson because the real Scarlett Johansson said no, that gets more questionable. When they did all that and still promoted the launch by directly referring to a Scarlett Johansson role, it got even more questionable. I’m not pulling out my pitchforks but this is reckless. reply czl 19 hours agorootparent> why would they try to resume negotiations Could they be trying to avert possible negative public perception even if they believe all they did was 100% legal? If you have ample funds and are willing to pay someone to make X easier for you does your offer to pay them imply that X is against the law? If your voice sounds like someone famous now you are prevented from getting any voice acting work? Because that famous person owns the rights to your voice? Tell me which law says this? reply hluska 16 hours agorootparentI don’t know why you’re asking me those last three questions. First, I’m not a lawyer. Second, I didn’t make any claims that could make those questions relevant. Instead, I’ll repeat my earlier claim - this was reckless. If they were trying to avoid a strong negative perception, they failed. And they failed with an actor who sued Disney shortly after they paid her $20 million to make a movie. reply czl 1 hour agorootparentYou asked the good question about why they may have acted as they did and I attempted to answer it. In hindsight based on results it may look reckless but decisions need to be judged based on that is known at the time they are made and the public reaction was not a foregone outcome. The openAI sky voice has been available since last September why was there no outrage about it back then? You can listen to the voices side by side: https://www.reddit.com/r/ChatGPT/comments/1cwy6wz/comment/l4... And here is voice of another actress ( Rashida Jones ): https://www.youtube.com/watch?v=385414AVZcA This test is not blind but YOU tell me which you think is similar to the openAI sky voice? > And they failed with an actor who sued Disney shortly after they paid her $20 million to make a movie. OpenAI did not fail. They suspended the sky voice and backed down not to further anger a segment of the public who views much of what OpenAI does in a negative light. Given the voice test above do you seriously think OpenAI would lose in court? Would that matter to the segment of population that is already outraged by AI? How are journalists and news companies affected by AI? How might their reporting be biased? reply CaptainZapp 10 hours agorootparentprevThere is precedent. Frito Lay wanted to use a Tom Waits song for an ad. Since Waits is violently opposed to the use of his music in ads he declined. So they hired an impersinator for the soundtrack. Waits sued Frito Lay for voice misappropriation and false endorsement and they had to cough up to the tune of 2.6 million for violating his rights. This was upheld on appeal[0]. So, you absolutely have precedent and in my opinion it's galling that the tech bro'ship just doesn't give a shit about the rights of others. [0] reply wk_end 19 hours agorootparentprevI think it would be more like \"precludes you from work (arguably) deceptively impersonating the more famous actor.\" reply frankacter 18 hours agorootparentSpeaking with your natural voice is not impersonating. reply wk_end 16 hours agorootparentYou should tell that to OpenAI, who are the ones selling it as \"her\". reply frankacter 16 hours agorootparentDrawing a parallel to a calming persona of an always on life assistant from pop culture in a few throwaway social media posts from personal accounts such as \"Hope Everyone's Ready\" isn't \"selling it as Her\" any more than Anthropic is selling their offerings as a Star Trek communicator despite a few comments they've made on social media. reply pseudalopex 18 hours agorootparentprevhttps://news.ycombinator.com/item?id=40435388 reply dotnet00 20 hours agorootparentprevI think the issue is intent. It's fine if two voices happen to be similar. But it becomes a problem if you're explicitly trying to mimic someone's likeness in a way that is not obviously fair use (eg parody). If they reached out to Johansson first and then explicitly attempted to mimic her despite her refusal, it might be a problem. If the other voice was chosen first, and had nothing to do with sounding the same as Johansson, they should be fine. reply saalweachter 19 hours agorootparentIsn't there also something about an actor's voice versus an actor's performance? Eg, James Earl Jones performing Darth Vader vs Mufasa vs Terence Mann are three different things. reply michaelmrose 20 hours agorootparentprevYou don't need fair use for something that isn't copyrightable. reply bobthepanda 19 hours agorootparentNo, it is. Waits v. Frito Lay was a successful lawsuit where Tom Waits sued Frito Lay for using an impression of his voice in a radio commercial. https://casetext.com/case/waits-v-frito-lay-inc See also Midler v. Ford Motor Co. https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply michaelmrose 19 hours agorootparentCorrect me if I'm wrong that had nothing to do with copyright and fair use is moot reply bobthepanda 18 hours agorootparentIn California, personality rights have the same protections. https://en.wikipedia.org/wiki/California_Celebrities_Rights_... reply rswerve 15 hours agorootparentprevThis is not the case. “ A voice, or other distinctive uncopyrightable features, is deemed as part of someone's identity who is famous for that feature and is thus controllable against unauthorized use. Impersonation of a voice, or similarly distinctive feature, must be granted permission by the original artist for a public impersonation, even for copyrighted materials.” https://en.m.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply Cheer2171 19 hours agorootparentprev> There are hundreds of people with similar voices. Voice *actors* act. It is in the name. The voice they perform in is not their usual voice. A good voice actor can do dozens of different characters. If you hire a voice actor to impersonate someone else's voice, that is infringement. Bette Midler vs Ford, Tom Waits vs Frito Lay are the two big examples of court cases where a company hired voice actors to impersonate a celebrity for an ad, and lost big in court. reply czl 18 hours agorootparentSo when a cartoon show hires a sound alike replacement voice actor so that the switch is hard to tell the former actor has a case against the show? Perhaps instead the show has a case against the former voice actor using that same character voice elsewhere such as in radio advertising to impersonate cartoon characters that are not licenced? reply gamblor956 18 hours agorootparentTheoretically yes. Which is why they disclaim that right in their work contract for a voice acting gig. Believe it or not, these issues have been around for decades, and have been well settled for nearly as long. reply czl 18 hours agorootparentSo the voice of the AI in the film \"Her\" who do you think has more rights to it being reused elsewhere in association with AI? The voice actor? The film owners? Why then the current news? reply tangentstar 19 hours agorootparentprevNo, voices can be exclusive. One good example is Bette Midler, who sued Ford in tort for misappropriation of voice and won on appeal to CA9. 849 F.2d 460. reply __loam 20 hours agorootparentprevIt's not that simple. Actors have a right to protect the use of their likeness in commercial projects like ads, and using a \"soundalike\" is not sufficient to say that isn't what you were trying to do. The relevant case law is Waits vs. Frito Lay. The fact that OpenAI approached her about using her voice twice and that Sam Altman tweeted about a movie she starred in makes her case much stronger than if they had just used a similar voice actor. reply WheatMillington 19 hours agorootparentprevLooking like a celebrity is obviously not an issue. A lookalike being passed off as a celebrity is an issue. reply czl 18 hours agorootparentWas OpenAI was passing off their AI model as Johansson? Obviously not. If anything OpenAI tried to mimic the AI from the film Her and owners of that film may try to seek compensation. I hope that fails but they can try. reply robofanatic 20 hours agorootparentprevI believe professional singer's voices will be copyrighted in future if not getting already. reply ozim 20 hours agorootparentTry to sing or play a cover just like original of a song - yt will take it down in no time. the same with white noise videos, they strike copyright infringement easy or at least they were. Did not check but I assume so it still is the case. reply bobthepanda 19 hours agorootparentprevthey have been since 1988. https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply williamcotton 19 hours agorootparentprevTrademarked more likely. reply m463 14 hours agorootparentprevI think the law doesn't allow impersonation. reply FireBeyond 17 hours agorootparentprevThe whole \"Her\" thing, and the fact that even Johansson's family and friends couldn't tell it apart are somewhat telling. Or Altman could reveal the identity of the voice actress OpenAI did use. I'm sure that will happen, and remove all doubt... reply czl 2 hours agorootparent> even Johansson's family and friends couldn't tell it apart are somewhat telling. You can listen to the voices side by side: https://www.reddit.com/r/ChatGPT/comments/1cwy6wz/comment/l4... And here is voice of another actress ( Rashida Jones ): https://www.youtube.com/watch?v=385414AVZcA This test is not blind but YOU tell me which you think is similar to the openAI sky voice? And what does that tell you about likely court result for Johansson? And having reached this conclusion yourself would you now think the other actress Rashida Jones is entitled to compensation based on this similarly test? Because there are no other women with similar voices? What might support from friends and family of Rashida Jones be an indication of? reply riku_iki 20 hours agorootparentprevWith generative AI training may not be needed, it can be part of prompt: imitate voice like in this file: her.mp3. reply BobbyJo 20 hours agorootparentthat's..... that's training. reply px43 20 hours agorootparentIt's only training if it remembers it after the conversation is over. reply Cheer2171 19 hours agorootparentAbsolutely false. reply rockemsockem 20 hours agorootparentprevIt's, not though. reply rasz 14 hours agorootparentprevSo you really buy this bluff about using another similar sounding voice actor? reply dustfinger 3 hours agoparentprev> We should not give a sneaky, deceptive and manipulative person this much power over our future. I think this should be applied to our government. In my opinion, it is a failing in the structure of our government that those running the country control the police and appear to rarely be investigated unless by the request of a political opponent. They are seemingly outside of the law. It would be better if they were under perpetual investigation; forever kept in check. We should have assurance that those leading our country are not villainous traitors. reply lenerdenator 20 hours agoparentprevIf the voice actor was cast... why bother reaching out to ScarJo? Like, do you want to pay her fee, Sam? Because the general idea is to not pay the fee. Which is why you probably cast the voice actor before reaching out to Johansson. reply avarun 19 hours agorootparentBecause it’s still great marketing to have Scarjo on board? That immediately returns positive ROI on the cost to hire her. reply llamaimperative 19 hours agorootparentWhich is also why it’s unethical to use a voice clearly designed to be mistaken for her. reply avarun 18 hours agorootparentI agree that it’s a bit of a sketchy thing to do, and potentially even illegal based on similar case law, but the commenter I responded to created an entire fake sequence of events that seems incredibly unlikely, when there’s a far simpler explanation. reply lenerdenator 17 hours agorootparentprevI mean, I guess? I don't know how many people base their choice in AI model or application on the voice, but maybe I'm just not privy to that. reply Lerc 19 hours agorootparentprevA potential answer to that is liability protection even when you feel like you are legally in the clear. It is still worth paying a sum to avoid a lawsuit you think you will win. An example of this is Weird Al pays for the rights to things that are probably ok under fair use parody protection. Paying for the rights removes the possibily of a challenge. reply hluska 19 hours agorootparentDoes Weird Al pay rights? I know he asks for permission to maintain his relationships with artists and to make sure he gets his share of songwriting credits (and the fees). But does he pay for rights? I’ve never seen that before and I’d love to read more. reply klyrs 18 hours agorootparentActually, yes, he does. https://www.weirdal.com/archives/faq/ reply hluska 16 hours agorootparentThat says he asks for permission. His new song would generate songwriter credits and they’re paid out totally differently from regular royalties. Is that what you mean by him paying for rights? reply klyrs 13 hours agorootparentRereading your comment, I see that my answer rather falls short of your question. I don't claim to know anything about Weird Al beyond what he wrote on that page. reply hluska 4 hours agorootparentHonestly pal, I really appreciate you trying! I’m one of very few people strange enough to care about the minutiae of this. I’m grateful that you jumped into my weird rabbit hole with me for awhile. It was kind of you to try to help me. reply Lerc 18 hours agorootparentprevNow you've got me doubting myself. It was covered in a Tom Scott video. I'll have a look for it. https://www.youtube.com/watch?v=1Jwo5qc78QU&t=485s reply jprd 19 hours agorootparentprevIANAL - but I think there is some sort of carve-out for parody? @sama and OpenAI are clearly not parodying \"Her\" - especially with that paper trail. This is a great question and I hope someone here with requisite knowledge can help. reply hluska 16 hours agorootparentMy understanding is he doesn’t have to ask permission but does for two purposes. It’s important to him to keep good relationships with artists, and he wants to make sure that he gets songwriting credits because those are paid differently (and are often more lucrative) than royalties from recordings. I’d love to find out if he directly pays artists for rights. That would be really interesting and would add a whole dimension to his problems with Prince. reply Teever 19 hours agorootparentprevIs there any way to confirm that they actually did hire a voice actor prior to reaching out to ScarJo? reply rrrrrrrrrrrryan 18 hours agorootparentScarJo claims they reached out to her just 2 days prior to demoing the voice that sounded like her, and (I believe) OpenAI outright claimed that they hired a different voice actor, though they didn't admit that they instructed her to try to sound like Scarlett's character in Her, which could make or break Scarlett's case. reply Blackthorn 18 hours agorootparentThey claimed they hired someone and they can't tell you who it is but pretty please trust them that they hired someone. reply Teever 17 hours agorootparentprevHow can we tell if the model was trained exclusively on data from the voice actor and not ScarJo. The hiring of the voice actor could be complete misdirection for all we know. reply chx 20 hours agoparentprev> He sounds sneaky, evasive and intentionally deceptive. Well, here's Yishan Wong describing how Altman and the Reddit founders have conned Conde Nast: https://reddit.com/r/AskReddit/comments/3cs78i/whats_the_bes... he answers at https://reddit.com/r/AskReddit/comments/3cs78i/whats_the_bes... Cool story bro. Except I could never have predicted the part where you resigned on the spot :) Other than that, child's play for me. Thanks for the help. I mean, thanks for your service as CEO. reply Repulsion9513 19 hours agoparentprev> The statement sounds like it's written by a lawyer to be technically true while implying something that is actually false. That describes nearly every statement to ever come out of a CEO's mouth. (Or anyone else who's primary job is marketing) reply caeril 1 hour agoparentprevI agree that he should have been honest, but from the opposite perspective. Altman should have said, \"Yes, we made the voice similar to this washed-up actress, but her voice is not much different from anyone else with similar regional upbringing, year of birth, habits, and ethnic background, so we invite anyone else born in the mid-eighties, raised in Greenwich, and with Danish heritage, to sue us too. We'll see how well you do in court. Otherwise, get fucked.\" This whole thing with anybody giving a shit about your voice, which isn't even yours, as it's a product of your environment and genes, and will be strikingly similar to anyone with similarities thereof, is insane. Altman shouldn't have used weasel words, I agree. He should have owned it, because it's a total non-issue, and the people upset about it need to be shamed as the Luddite assholes that they are. reply barfingclouds 4 hours agoparentprevIt doesn’t sound like her reply Reubachi 4 hours agorootparentI listened to a comedy podcast early last week that was using Chatgpt4 with this voice to make some funny bits/jokes. Without having any context about who the voice was, or the \"Drama\" between OpenAI and actress in question, or even really being aware of Scarlett Johansson's body of work, I immediately went \"Oh that's Scarlett Johansson or whatever, cool\" To read all of this after the fact is almost comical. It's as if the powers that be realized the issues with the \"one-man-in-charge-of-ai\" platform and created this almost unbelievable story to decredit him. reply NautilusWave 18 hours agoparentprevNon-sequitur statements like this drive me nuts. Somehow, politicians and executive types learn how to use just enough of them to make the audience forget what they're not saying. reply piva00 11 hours agorootparentIt's quite funny (not sure if ironic) in the context of OpenAI, ChatGPT can do exactly the same thing: generate a string of sentences that from cursory skimming might sound about right but when reading with attention you find all the cracks and incongruences in the generated text. reply quantified 18 hours agoparentprevRecall the adage that power corrupts and absolute power corrupts absolutely. It certainly changes your perspective. reply SpicyLemonZest 20 hours agoparentprevIt's not a vague suggestion - in the full statement that's been reported elsewhere, he explicitly says it. > The voice of Sky is not Scarlett Johansson's, and it was never intended to resemble hers. We cast the voice actor behind Sky’s voice before any outreach to Ms. Johansson. Out of respect for Ms. Johansson, we have paused using Sky’s voice in our products. We are sorry to Ms. Johansson that we didn’t communicate better. I'm skeptical whether this is true, but it's a pretty unambiguous and non-sneaky denial. reply Reubachi 4 hours agorootparentscenario -the creator of a new widget takes tha widget to another widget manufacturer and says \"Would you like to put your stamp on this? It's similar to yours, yet derivative enough and we would both benefit.\" - other widget manufacturer says \"no\" -Creator of widget then puts the badge on the widget anyway, gets called out/faces legal action -Creator of widget says \"Well, we planned to put the badge on there anyway before even considering the other widget manufacturer. It's just coincidence. This shouldn't even go to court. Laughable that the face of modern tech is cheesing this much. reply carabiner 19 hours agoparentprevI'm surprised no one's pointing out the similarity between initial consonants in Sky and Scarlett. It seems deliberate. reply xyst 20 hours agoparentprev> We should not give a sneaky, deceptive and manipulative person this much power over our future. sneaky, deceptive, and manipulative is a tag line for many billionaires. you don't get that rich without stepping on many people. reply pmarreck 20 hours agoparentprevIt doesn't matter because Sky's voice is materially and objectively different from ScarJo's. Anyone who heard them both side by side would immediately realize this. reply flumpcakes 20 hours agorootparentThe clips that I have seen sound very similar to Scarlett Johansson to me, to the point that I thought it was her likeness on purpose. Is this Sky? https://www.tiktok.com/@kylephilippi/video/73185169285097751... reply nomel 19 hours agorootparentprevComparison: https://news.ycombinator.com/item?id=40435695 reply kalupa 20 hours agorootparentprevlol reply WalterBright 20 hours agoparentprevJim Carrey made his career by impersonating celebrity voices. So did Rich Little. reply limitedfrom 19 hours agorootparentWhen Jim Carrey is impersonating, it's clear that it's Jim Carrey impersonating someone for comedy-sake, not providing a service in lieu of someone else. In other words, Jim Carrey isn't getting paid to stand in for Jack Nicholson for example. Otherwise, it looks more like the Midler vs Ford Motor Co. case[1] [1] https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply qzw 19 hours agorootparentprevAre you referring to doing impressions where the act lasts for a few minutes, or are you saying that Jim Carrey actually impersonated other celebrity voice for like a whole movie or interview? There is a difference, I think. One feels like “fair use” while the other would seem more like “plagiarism”. reply rawrawrawrr 20 hours agorootparentprevParody is covered under fair use. reply sneak 20 hours agorootparentAs pointed out upthread, fair use is an exemption for copyright. You don’t need fair use for something that isn’t copyrighted (and, indeed, isn’t even copyrightable). reply okanat 19 hours agorootparentThe voice and expression is copyrightable, that's just how audio books are under copyright protection. reply ugh123 20 hours agorootparentprevDid Jim Carrey provide a service for anyone to impersonate a voice? reply WalterBright 19 hours agorootparentSure. How do you think he made money at it? reply akaru 20 hours agorootparentprevPop goes the weasel. reply orthecreedence 20 hours agorootparentprev\"I think it's fine for a profit-driven corporation to impersonate people on a large scale without their permission. Jim Carrey did it...\" reply xt00 20 hours agoprevThis is a typical \"move fast and break things\" mentality.. except that mentality betrays Sam's statements about doing a bunch of this stuff \"carefully\" etc.. its all a smokescreen.. nobody is going to realistically stop working on AGI in order to be careful.. basically AGI is being pursued like the race to get the atom bomb.. so yea history tells us its full speed ahead with no brakes. Scarjo is just the latest person getting stomped on along the way.. eventually it will be a whole ton of people getting stomped on.. whoops! reply somethoughts 19 hours agoparent\"This is a typical \"move fast and break things\" mentality.. \" with a big dash of “there’s no such thing as bad publicity” thinking thrown in for good measure. Staying relevant is all that matters these days. reply smilebot 18 hours agoparentprevI would put this in the \"better to ask for forgiveness than ask than permission\" bucket. Which is also a typical mentality in SV. reply dorkwood 18 hours agorootparentBut they did ask permission, and were denied. reply popalchemist 20 hours agoparentprevnext [6 more] [flagged] bigstrat2003 20 hours agorootparent> \"Move fast and break things\" is explicitly, exactly the wrong attitude for the person/team in charge of a world-changing superpower. Thankfully, they aren't in charge of anything like that. reply runeofdoom 19 hours agorootparentArguably, allowing anyone to create very believable lies is a world-changing superpower. reply metadat 19 hours agorootparentprevHow do you know what the effects and importance of current gen AI will be? reply bozhark 20 hours agorootparentprevMove Smooth & Fix Things (tm) reply threatofrain 19 hours agorootparentprevIf Nazis had the nuclear bomb then they'd would've been backed into a corner and quite possibly dropped the bomb. reply kaiwen1 20 hours agoprevThere are many people with voices similar to Scarlett Johansson's. If SJ is unwilling to be a voice actor for OpenAi, then why should OpenAI not find a similar voice and use that instead? SJ certainly does not have a monopoly on all voices similar to hers. Anyone in possession of such a voice has the same right as SJ to monetize it. And someone did in fact exercise that right. If you compare the Sky voice to SJ's, they're not the same. OpenAI's mistake was caving to SJ. They should have kept Sky and told SJ to get lost. If SJ sued, they could simply prove another voice actor was used and make the legitimate argument that SJ doesn't have a monopoly on voices similar to hers. reply sillysaurusx 19 hours agoparentI too am mystified. I think what’s going on here is that Scarlett is famous, and so media outlets will widely cover this. In other words, this latest incident hasn’t riled up people any more than usual — if you scan the comments, they’re not much different from how people already felt about OpenAI. But now there’s an excuse for everybody to voice their opinions simultaneously. They’re acting like the company literally stole something. It also didn’t help that OpenAI removed the Sky voice. Why would they do that unless they have something to hide? The answer of course is that Scarlett is famously rich, and a famously rich person can wage a famously expensive lawsuit against OpenAI, even if there’s no basis. But OpenAI should’ve paid the cost. Now it just looks like their hand was caught in some kind of cookie jar, even though no one can say precisely what kind of cookies were being stolen. reply campbel 19 hours agoparentprevIANAL, but I think the mistake they made was constantly referencing the movie 'Her' when talking about Sky. reply nomel 19 hours agorootparentRegardless of the exactly voice spectrum, the plot would apply with any flirty female voice. It was not a movie about Scarlett Johansson. It was a movie about AI eliciting a relationship. For the “her” reference(s?), was there anything beyond the single tweet? reply danielmarkbruce 19 hours agorootparentprev100%. This whole thing is more stupidity than anything else. There is nothing wrong with using a voice that sounds like her. There is everything wrong with referencing the movie and sort of implying it is the voice from the movie. They could have easily let others make the connection. So dumb. reply sillysaurusx 19 hours agorootparentWhy is it wrong to explicitly mimic a part played in a movie? Are we saying that the actor owns their portrayal of the role? OpenAI should’ve owned their actions. \"Yes, we wanted to get a voice that sounded like the one from Her.\" There’s nothing wrong with that. reply pseudalopex 18 hours agorootparent> OpenAI should’ve owned their actions. \"Yes, we wanted to get a voice that sounded like the one from Her.\" There’s nothing wrong with that. https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply danielmarkbruce 3 hours agorootparentprevNot an IP lawyer, but I think the company that produced the movie owns the relevant IP, and Johansson might also own IP around it. You can have an opinion on it, but they are going to get sued. Just like I can't take Moana and throw her in an ad where it says \"I like [insert cereal here]\", they can't take a character and use it without expecting Disney/whoever to come sue them. reply pests 19 hours agorootparentprevActors get a lot of rights to their likeness. So, yes maybe? reply sillysaurusx 19 hours agorootparentHmm. Being able to say \"thou shalt not make a character similar to Her\" is a lot like saying \"thou shalt not make a video game character similar to any other.\" It’s not an explicit copy, and their name for Sky was different. That’s the bar for the videogame industry; why should it be different for actors? Especially one that didn’t show her face. This whole thing is reminiscent of Valve threatening to sue S2 for allegedly making a similar character. Unsurprisingly, the threats went nowhere. reply lelandfe 18 hours agorootparentYou've really contorted the facts here. This isn't a character, it's a voice. The voice sounds remarkably like Scarlett Johansson's. reply sillysaurusx 18 hours agorootparentIt’s the other way around. The contortionists are on the other side of the issue. We’re talking about OpenAI hiring someone to use their natural speaking voice. As movies say, any similarity to existing people is completely coincidental from a legal perspective. From a moral perspective, I can’t believe that people are trying to argue that someone’s voice should be protected under law. But that’s a personal opinion. reply pseudalopex 18 hours agorootparent> We’re talking about OpenAI hiring someone to use their natural speaking voice. How do you know? reply sillysaurusx 18 hours agorootparentThey said so, and it’s what I would have done. I have no reason not to believe them. Unfortunately a commenter pointed out that there’s legal precedent for protecting people’s voices from commercial usage specifically (thanks to a court case from four decades ago), so I probably wouldn’t have tried this. The cost of battling it out in the legal system is outweighed by the coolness factor of replicating Her. I personally feel it’s a battle worth winning, since it’s bogus that they have to worry about some annoyed celebrity, and your personal freedoms aren’t being trodden on in this case. But I can see why OpenAI would back down. Now, if some company was e.g. trying to commercialize everybody’s voices at scale, this would be a different conversation. That should obviously not be allowed. But replicating a culturally significant voice is one of the coolest aspects of AI (have you seen those recreations of historical voices from other languages translated into English? If not, you’re missing out) but that’s not what OpenAI did here. reply pests 14 hours agorootparentDo you always believe everything a corporation tells you? If so, I have a bridge you might be interested in buying reply sillysaurusx 14 hours agorootparentNo. But in this particular case, there are two factors that make that irrelevant for me. One, I would have made their same mistake. (If I was Sam, I too would have found it a really cool idea to make GPT have the voice of Her, and I too would not have realized there was one dumb court case from the 80s standing in the way of that.) Two, it’s bogus that conceptually this isn’t allowed. I’m already anti-IP — I think that IP is a tool that corporations wield to prevent us from using \"their\" ideas, not to protect us from being exploited as workers. And now this is yet another thing we’re Not Allowed To Do. Great, that sounds like a wonderful world, just peachy. Next time maybe we’ll stop people from monetizing the act of having fun at all, and then the circle of restrictions will be complete. Or, another way of putting it: poor Scarlett, whatever will she do? Her voice is being actively exploited by a corporation. Oh no. In reality, she’s rich, powerful, and will be absolutely fine. She’d get over it. The sole reason that she’s being allowed to act like a bully is because the law allows her to (just barely, in this case, but there is one legal precedent) and everyone happens to hate or fear OpenAI, so people love rooting for their downfall and calling Sam an evil sociopath. Someone, please, make me a moral, ethical argument why what they did here was wrong. I’m happy to change my mind on this. Name one good reason that they shouldn’t be allowed to replicate Her. It would’ve been cool as fuck, and sometimes it feels like I’m the only one who thinks so, other than OpenAI. reply lelandfe 6 hours agorootparent\"This is perfectly legal!\" Actually, there's a similar court case from 1988 that creates legal precedent for her to sue. \"That's just one case! And it's from 1988! That's 36 years ago: rounded up, that's 4 decades!\" Actually, there's a court case from 1992 that built on that judgement and expanded it to define a specific kind of tort. \"That's bad law! Forget the law! I demand a moral justification.\" Anyway, asking a person if you can make money off their identity, them saying no, and you going ahead and doing that anyway seems challenging to justify on moral grounds. I don't think you're willing to change your mind, your claim notwithstanding. reply sillysaurusx 4 hours agorootparentIf you approach a debate from a bad faith standpoint, don’t be surprised when the other person doesn’t change their mind. \"I think you’re a liar\" is a great way to make them nope out. Which is a shame, since you had a decent argument. Except it isn’t. Again, you’re acting like OpenAI tried to profit off of Scarlett. They tried to profit off of the portrayal she did in the movie Her. These are not the same thing, and treating them as interchangeable is some next level moral rationalization. One is taking advantage of someone. The other is what the movie industry is for. Now, where’s this case from 1992 that expended and defined the scope of this? reply qarl 37 minutes agorootparent> Except it isn’t. Again, you’re acting like OpenAI tried to profit off of Scarlett. They tried to profit off of the portrayal she did in the movie Her. Ahhh... so you admit OpenAI has been shady, but you argue they're actually ripping of Spike Jones not Scarlett Johansson? HEH. The people who say Sam is shady aren't really interested in this distinction. (And you're wrong, both ScarJo and the film own aspects of the character they created together.) breadwinner 19 hours agoparentprevAgree. And what about people who look similar to SJ? Are they precluded from acting jobs, simply because SJ became an actor first? reply limitedfrom 19 hours agoparentprevI encourage you to look through this case: https://en.wikipedia.org/wiki/Midler_v._Ford_Motor_Co. reply sillysaurusx 19 hours agorootparent1. The case is from 1988. That’s the year I was born. Societal norms are in a constant state of flux, and this one case from 36 years ago isn’t really an indication of the current state of how case law will play out. 2. Ford explicitly hired an impersonator. OpenAI hired someone that sounded like her, and it’s her natural voice. Should movies be held to the same standard when casting their actors? This is about as absurd as saying that you’re not allowed to hire an actor to play a role. reply lelandfe 18 hours agorootparentMidler is actually quite similar. Midler didn't want to do a commercial, and refused an offer, so they hired a lookalike that fooled her friends. The appellate court held that Ford and its advertising agency had \"misappropriated\" Midler's voice. Waits v. Frito Lay, Inc was '92, and cited it. They used a Tom Waits-sounding voice on an original song, and Waits successfully sued: > Discussing the right of publicity, the Ninth Circuit affirmed the jury’s verdict that the defendants had committed the “Midler tort” by misappropriating Tom Waits’ voice for commercial purposes. The Midler tort is a species of violation of the right of publicity that protects against the unauthorized imitation of a celibrity’s voice which is distinctive and widely known, for commercial purposes. https://tiplj.org/wp-content/uploads/Volumes/v1/v1p109.pdf Of course, who knows what a court will find at the end of this. There is precedent, however. reply sillysaurusx 18 hours agorootparentThank you. I didn’t know it was similar specifically for voices in commercial use. That’s annoying, but we live in a country with lots of annoying laws that we nonetheless abide by. In this case I guess OpenAI just didn’t want to risk losing a court battle. I still think legal = moral is mistaken in general, and from a moral standpoint it’s bogus that OpenAI couldn’t replicate the movie Her. It would’ve been cool. But, people can feel however they want to feel about it, and my personal opinion is worth about two milkshakes. But it’s still strange to me that anyone has a problem with what they did. reply calf 7 hours agorootparentI was born in 1983 and it is wrong to make profit off of someone else's art without their permission. It isn't strange at all. This includes using an impersonator. This excludes parody intentions. So the overall argument isn't strange, you just disagree without having articulated exactly what biases you to disagree. It is moral disagreement ultimately. reply djur 12 hours agorootparentprev> OpenAI hired someone that sounded like her, and it’s her natural voice. They say so, yes. Seems like they didn't want to go through discovery in order to prove it. reply dragonwriter 12 hours agorootparentprev> The case is from 1988. That’s the year I was born. Societal norms are in a constant state of flux, and this one case from 36 years ago isn’t really an indication of the current state of how case law will play out. Correct, while Midler presents a similar fact pattern and is a frequently taught and cited foundational case in this area, the case law has evolved since Midler, to an even stronger protection of celebrity publicity rights, that is even more explicitly not concerned with with the mechanism by which the identity is appropriated. Waits v. Frito Lay (!992), another case where voice sound-alike was a specific issue, has been mentioned in the thread, but White v. Samsung Electronics America (1993) [0], while its fact pattern wasn't centered on sound-alike voice appropriation, may be more important in that it underlines that the mechanism of appropriation is immaterial so long as the appropriation can be shown: —quote— In Midler, this court held that, even though the defendants had not used Midler's name or likeness, Midler had stated a claim for violation of her California common law right of publicity because \"the defendants … for their own profit in selling their product did appropriate part of her identity\" by using a Midler sound-alike. Id. at 463-64. In Carson v. Here's Johnny Portable Toilets, Inc., 698 F.2d 831 (6th Cir. 1983), the defendant had marketed portable toilets under the brand name \"Here's Johnny\"--Johnny Carson's signature \"Tonight Show\" introduction–without Carson's permission. The district court had dismissed Carson's Michigan common law right of publicity claim because the defendants had not used Carson's \"name or likeness.\" Id. at 835. In reversing the district court, the sixth circuit found \"the district court's conception of the right of publicity … too narrow\" and held that the right was implicated because the defendant had appropriated Carson's identity by using, inter alia, the phrase \"Here's Johnny.\" Id. at 835-37. These cases teach not only that the common law right of publicity reaches means of appropriation other than name or likeness, but that the specific means of appropriation are relevant only for determining whether the defendant has in fact appropriated the plaintiff's identity. The right of publicity does not require that appropriations of identity be accomplished through particular means to be actionable. It is noteworthy that the Midler and Carson defendants not only avoided using the plaintiff's name or likeness, but they also avoided appropriating the celebrity's voice, signature, and photograph. The photograph in Motschenbacher did include the plaintiff, but because the plaintiff was not visible the driver could have been an actor or dummy and the analysis in the case would have been the same. Although the defendants in these cases avoided the most obvious means of appropriating the plaintiffs' identities, each of their actions directly implicated the commercial interests which the right of publicity is designed to protect. –end quote– > Ford explicitly hired an impersonator. OpenAI hired someone that sounded like her, and it’s her natural voice. Hiring a natural sound-alike voice vs. an impersonator as a mechanism is not the legal issue, the issue is the intent of the defendant in so doing (Ford in the Midler case, OpenAI in a hypothetical Johansson lawsuit) and the commercial effect of them doing so. [0] https://law.justia.com/cases/federal/appellate-courts/F2/971... reply lelandfe 5 hours agorootparentNice write up, thanks. Unrelated, but as someone who came along into this world after Carson's Tonight Show, I had no idea that that moment from The Shining was a play on that. Today's lucky 10,000. reply Blackthorn 18 hours agoparentprev> then why should OpenAI not find a similar voice and use that instead? That's assuming they did, right now they're asking us to pretty please trust them that their girlfriend from Canada is really real! She's real, you guys! No I can't show her to you. reply hnburnsy 18 hours agoparentprev>OpenAI's mistake was caving to SJ. They should have kept Sky and told SJ to get lost. If SJ sued, they could simply prove another voice actor was used and make the legitimate argument that SJ doesn't have a monopoly on voices similar to hers. Yes, they should have not reached out again, but now they are screwed. In no way will they want a trial and associated discovery. SJ can write her own ticket here. reply rrrrrrrrrrrryan 18 hours agoparentprevIf they told the voice actor to try to impersonate SJ, then Scarlett does have a case. That may not be how it should work, but it is very much how the law currently works. reply gxyt6gfy5t 17 hours agoparentprevCan they make that claim if SJ voice exists in the training data before fine tuning? We don’t know what they train on reply FireBeyond 14 hours agoparentprev> OpenAI's mistake was caving to SJ. ... If SJ sued, they could simply prove another voice actor was used and make the legitimate argument that SJ doesn't have a monopoly on voices similar to hers. Or... hear me out... maybe they couldn't prove that, which is why they caved. Caved within a day or so of her lawyers asking \"So if it's not SJ's voice, whose is it?\" reply gamblor956 18 hours agoparentprevOpenAI caved immediately because they knew they would lose a lawsuit and be looking at a minimum of an 8 figure payout. Voice impersonation has been a settled matter for decades. It doesn't matter that they used another actress. What matters is that they tried to pass the voice off as SJ's voice several times. reply FMecha 19 hours agoparentprevSee Waits vs. Frito Lay. reply kaiwen1 19 hours agorootparentIn that case, as I understand it, the voice actor intentionally mimicked Waits, purposefully using his intonations, style of speech, and phrasing, all of which were not natural to the voice actor. He was intentionally mimicking Waits. I doubt the same claim can be made of the Sky voice actor. reply djur 12 hours agorootparentOpenAI had the opportunity to prove as much in court and chose not to. reply game_the0ry 20 hours agoprevI wonder how long this thread will last on HN... How much influence does @sama have around here nowadays? For the record, I was never impressed with him - I am not aware of single consequential thing he has done or built other than take the credit for the fine work of the AI scientist + engineers at OpenAI. It feels like the company is just a vehicle for how own ambition and legacy, not much else. reply minimaxir 20 hours agoparentHacker News is famously editorially independent from YC-affiliated people, and dang has said that specifically avoids killing threads involving YC people/companies (not that Sam Altman is YC-affiliated anymore). reply sillysaurusx 19 hours agoparentprevThe thread is rightly being knocked off by the mods because there’s zero substance here. It’s a follow-on thread (knock one) to a public uproar (knock two) about something that isn’t representative of a new phenomenon (knock three). This isn’t what HN is for. reply minimaxir 18 hours agorootparentIt's likely getting flagged organically (and due to the ratio of comments to upvotes, getting penalized by the flame war detector), but not due to a vast YC conspiracy. reply sillysaurusx 18 hours agorootparentHm? You and I agree. There’s no conspiracy here. This is \"bog standard moderation\", as Dan would say. Look at it this way: if the community didn’t flag it, it would be the mods’ duty to get this one off the front page. So whether it was the community or the mods is incidental. reply throw10920 15 hours agoparentprevI flagged the submission because it's flamebait. It's not intellectually rewarding. It's not suitable for HN. HN is not an advocacy platform. reply dang 15 hours agoparentprev> I wonder how long this thread will last on HN Users flagged it and it also set off the flamewar detector. I don't think we'd turn the penalties off on this one because because this article is derivative of the threads HN has already had on the recent things - threads like these: Statement from Scarlett Johansson on the OpenAI \"Sky\" voice - https://news.ycombinator.com/item?id=40421225 - May 2024 (970 comments) Jan Leike Resigns from OpenAI - https://news.ycombinator.com/item?id=40363273 - May 2024 (391 comments) Ilya Sutskever to leave OpenAI - https://news.ycombinator.com/item?id=40361128 - May 2024 (780 comments) Those were huge threads! Sometimes media articles are driven by the topic getting discussed on Hacker News in the first place. That is: major HN thread -> journalist takes notice -> article about topic -> HN user submits article -> another HN thread—but now it's a repetitive one. We don't need that feedback loop, especially because the mind tends to resort to indignation to make up for the lack of amusement in repetitive content (https://hn.algolia.com/?dateRange=all&page=0&prefix=true&sor...), and the earlier threads have been indignant (and repetitive) enough already. > How much influence does @sama have around here nowadays? Zero. He never asked for any change about anything HN-related even while he was running YC, and certainly not since then. Btw Sam was the person who posted https://www.ycombinator.com/blog/two-hn-announcements/. > For the record, I was never impressed with him (I'll add a personal bit even though that's usually a bad idea... I remember hearing this kind of comment about Sam going back to the Loopt days. My theory is that it had to do with pg praising him so publicly—I think it evoked a \"why him and not me?\" feeling in readers. The weird-ironic thing is that the complaint has only grown as Sam has achieved more. Running OpenAI through the biggest tech boom since the iPhone is...rather obviously massive. I think if Sam unifies gravity into quantum theory, brokers peace in the middle east, and cures cancer, we'll still be hearing these complaints—because they're not really grounded either in objective achievement or lack of it. It's some kind of second-order phenomenon, and actually rather interesting. At least if you aren't Sam!) reply p_j_w 2 hours agorootparent>My theory is that it had to do with pg praising him so publicly—I think it evoked a \"why him and not me?\" feeling in readers. The weird-ironic thing is that the complaint has only grown as Sam has achieved more...running OpenAI through the biggest tech boom since the iPhone is...rather obviously massive. I think if Sam unifies gravity into quantum theory, brokers peace in the middle east, and cures cancer, we'll still be hearing these complaints—because they're not really grounded either in objective achievement or lack of it. It's some kind of second-order phenomenon, and actually rather interesting. At least if you aren't Sam! You're right, posting this was a bad idea. It reads like a \"neener neener you're just jealous\" defense of someone you happen to like. reply dang 2 hours agorootparentRead it that way if you like! I think the phenomenon is a curious one. It is, however, drowned out by a far more dominant rule, which is never to contradict an angry mob—it only produces more of the same. I break that rule sometimes but not often. reply wsatb 19 hours agoparentprevCouldn't this be said for most CEOs? They're never really the ones doing the dirty work. reply game_the0ry 19 hours agorootparentNot all CEOs are terrible. reply s1k3s 20 hours agoprevI love how we went from questioning copyright & licensing to \"GPT vs Google, which one is better\". To every artist or engineer out there who contributed to the general knowledge: you lost, everything you've ever done to help other people is now part of the models and there's nothing you can do to take it back. What even happened to the copyright strikes artists were supposed to bring up against these AI companies? That seems like 100 years ago :) reply WalterBright 20 hours agoparentI'm happy to contribute to the general knowledge. It's better than being forgotten and having no impact. reply malfist 20 hours agorootparentOh you will be forgotten. All your knowledge will come from some trademarked AI bot and you won't even get a linkback reply hu3 19 hours agorootparent> Oh you will be forgotten. Not your parent comenter but please allow me to enlighten you. https://en.wikipedia.org/wiki/Walter_Bright https://en.wikipedia.org/wiki/D_(programming_language) When in doubt, always double-check who you're replying to in HN. We are lucky to have many great minds around. reply dclowd9901 19 hours agorootparentThe point is still salient. People who don’t have Wikipedia links will be forgotten. Though I guess maybe that’s always been true. reply tasuki 13 hours agorootparentYour legacy can continue as part of the AI trained on your output. What would you prefer? Would you want people to remember your name? Your face? Your voice? Which people? How often should they have to remember you? For how many thousands of years? reply simianparrot 7 hours agorootparent> Your legacy can continue as part of the AI trained on your output. That is one incredibly dense dystopian sentence right there. Damn. reply malfist 3 hours agorootparentprevThat's like saying that your happy someone person who plagiarized your work got famous because you live on in their \"trained output\" reply 8372049 19 hours agorootparentprevIn this specific case I asked ChatGPT, which said \"Walter Bright is the creator of the D programming language. He's a talented programmer!\", so maybe he specifically won't be forgotten. Most of the rest of us probably will, though. reply WalterBright 19 hours agorootparentI have no idea if I am talented or not. I do know that I've spend a lot of time programming, and it's inevitable one would get better at it over time. I also learned from being around people who were really good, and were kind enough to help me. reply Lerc 19 hours agorootparentprevI think your answer belies an an assumption that is important in this context. You are assuming that who came up with knowledge is important. I think Walter was saying that he would rather the knowledge not be forgotten, not that he was the one who provided it. reply codezero 20 hours agorootparentprevunless you find a way to poison the AI so that it remembers you :) reply actuallyalys 19 hours agoparentprev> I love how we went from questioning copyright & licensing to \"GPT vs Google, which one is better\". Have we? Certainly the people litigating haven't. And as this article notes, actors' newest contract does have protections against AI. SAG-AFTRA's press release states [0] they are pursuing legislation. That could be bluster or could go nowhere, but certainly people haven't given up. [0]: https://www.sagaftra.org/sag-aftra-statement-regarding-scarl... reply lannisterstark 4 hours agoparentprev>there's nothing you can do to take it back Given the fact that many, many people make their software MIT licensed (or rather, do whatever, I don't care license), I think most of us will be ok with that :) reply sublinear 19 hours agoparentprevI think that's a naive take. Derivative works are nothing new. What's new is that the price of this work is much lower with a tradeoff in quality. Even human copycats are still better than generative AI by miles. The artist is not defined by their past work or other miscellaneous artifacts, but their perspective and creativity. This too is not a revelation. AI has nothing to do with this. It's just a means to an end. The real problem is the legal stuff. Everything else is hype. reply __loam 19 hours agoparentprevThere's currently like 10 lawsuits against generative AI companies that are working through the courts including the one from Sarah Andersen, Kelly McKernan, and Karla Ortiz, one from Getty Images, one from the Author's Guild, and one from the New York Times. It should be shocking to nobody that lawsuits take time to litigate, and until the court settles the questions at hand, Open AI and its ilk are operating in a legal gray area. reply czl 18 hours agorootparent> and until the court settles the questions at hand, Open AI and its ilk are operating in a legal gray area. My understanding of western law is that things are ok unless law forbids it. So they are operating in an area that under _current_ laws is ok but because of what may be at stake many wish the current laws were different and are willing to use litigation and lobby efforts to that end. This is NOT IN REPLY TO YOU but a general observation: Imagine the litigation that will happen when brain implants enable brain to brain sharing sensations and thoughts. Imagine the horrible copyright abuse! How will the publishing industry and sports industry and Hollywood control the rampart piracy?!? reply __loam 15 hours agorootparentWhy are we imagining a hypothetical situation in the context of talking about things that are currently happening? It's an interesting thought experiment but it's kind of irrelevant because brain implants are nowhere near that level and as far as I know, freedom of thought is already part of western law. I am not a lawyer though, I just think we can think about the actual damages to real people rather than make shit up. reply czl 13 hours agorootparentI put the \"NOT IN REPLY TO YOU\" since I meant that as a thought experiment of a possible future that where a similar situation may arise. Notice it is not freedom of thought that is in question. What is in question is freedom to share your sensations with others. You are watching a live football game and you share the sensations (what you see / hear / smell) with friends and family who are not there, etc. add to this technology that enables perfect memory of you sensations and instantly sharing them. In that possible future many will litigate and complain that their copyright and broadcast rights are being violated and they must be compensated much like what is happening with generative AI today. Sure this is scifi today. So were \"flying machines\" and \"moon visits\" and magic of our global communication pocket devices, etc. Gpt4o is a bunch of matrix math being done on high purity ore and refined sand powered by the sun / wind / splitting atoms / ... A century back few would believe it. Even a decade back, any predictions about a real AI like gpt4o working in just a decade, would you believe such predictions? reply couchdb_ouchdb 18 hours agoprevDoes anyone else think this whole affair is wildly overblown? I'm absolutely perplexed by the blow back from the tech industry on this issue. Sam Altman tried something. ScarJo filed a lawsuit. ChatGPT took down the voice. That's it guys. The system worked like it should. But to suggest that he's a terrible person because of it is just beyond me. This is hardly a #MeToo type situation. She's a rich and famous Hollywood actor. She's OK. reply mikepalmer 15 hours agoprevWhat if we take AI out of the equation. Should the voice actress who voiced Sky (call her A) be unable to do any voice work because she sounds too much like SJ? How about if the production company that made \"Her\" wants to make \"Her 2\". SJ declines the voice work. Are they not allowed to hire A to do the voice work? They ask SJ again but she still declines. They make the movie with A. Was it bad form? Just trying to figure out where people would draw the line. reply Gud 14 hours agoparentWhy would we take A.I. out of the equation? Presumably, the production company and Scarlet Johansson would have it in their contract what to do in case she doesn’t want to act in a sequel. No contract exists between OpenAI and Scarlet Johansson. reply djur 12 hours agoparentprevThe relevant case law concerns defendants who \"use an imitation to convey the impression\" that it's the actual person. Just having a voice that sounds like SJ is not a problem, but the \"Her\" tweet and the fact that they tried to get her on board complicates the issue, and if there's any paper trail that they intentionally chose a soundalike that might be trouble. Actors don't work in films without detailed contracts, so the normal rules don't necessarily apply in that situation. The producers of Her might have the right to use SJ's likeness in related material. In any case, if they made another movie with a soundalike, the soundalike would be credited and not just called \"A\", so there would be no confusion about whose voice it was. reply redox99 20 hours agoprevThey hired a voice actor for Sky's voice. If OpenAI loses, does this mean this voice actor cannot do their job any longer, because it happens some other actor has a similar voice? Could Sky's voice actor sue a movie Johansson works in, because Johannson is copying her voice? reply dragonwriter 20 hours agoparent> If OpenAI loses, does this mean this voice actor cannot do their job any longer, because it happens some other actor has a similar voice? No. Just as if they hired a writer to do something that made them liable for copyright violation, or an engineer for something that made them liable for patent violation, those workers would not be banned from work. The violation of right of personality isn't mere similarity of voice. reply a_wild_dandan 19 hours agorootparentThe Sky voice actress could legitimately lose clients who fear \"likeness\" litigation, for all Her potential contracts, regardless of context. Your analogy needs work. reply bluefirebrand 20 hours agoparentprevNo, the voice actor didn't do anything wrong OpenAi might have done something wrong by hiring her with the intention of making a voice model they can leverage Scarlett's fame to market reply czl 18 hours agorootparentOpenAI wanted to imitate the AI from the film Her. When you show that film to 100 random people how many will know who did the voice for the AI in the film? I myself had no idea. Moreover there are people now running blind voice similarly tests of similar voices of various other possible female actors. Guess what these blind voice tests show? reply rasz 14 hours agoparentprev>They hired a voice actor for Sky's voice. Are you sure about that? Want to bet it wont ever reach discovery? reply Texasian 20 hours agoparentprevThat’s a blatant misunderstanding of how voice acting works. A good voice actor is a vocal chameleon, and can really change their voice for each role. reply nomel 19 hours agorootparentThis is simply not true. A voice actor doesn’t have to be skilled at changing their voice, especially in this context. Many are hired for their natural voice, like narration. When most film actors do voice acting, they’re just using their voice. They’re not hired for being chameleons. reply Texasian 18 hours agorootparentThat’s because film actors are hired to voice act for their fame, not for their skills as voice actors. reply nomel 17 hours agorootparentYes, and another example is that sometimes the “skill” of a voice actor is having pleasing vocal cords. Again, this is why most narrators are hired: they sound good. Not all voice actors are chameleons. It is not a requirement for all voice acting jobs. If you listen to many audio books, you’ll see the voice actors usually have very very poor ability to modulate their voice. Laughably so. reply austinwade 19 hours agoprevThis may come off as defamatory, however does anyone else feel like Sam Altman has slowly been heading towards an impending reputation disaster hilariously adjacent to that of Sam Bankman-Fried? I've seen this perspective expressed on twitter/X several times as well. reply istjohn 18 hours agoparentNever trust a \"Sam.\" reply varjag 20 hours agoprevAn eerie feeling that the \"I do not consent\" scene from Ghost in the Shell plays out irl. https://getyarn.io/yarn-clip/e913bd02-2582-4258-819f-2d5a00b... reply stickfigure 20 hours agoprevIf you get 10 random people in a room and blindly played a clip of Scarlett Johansson speaking normally (ie not lines from a movie), I'd put money that exactly zero out of 10 people could identify the speaker. It's one thing to copyright a performance or own a likeness. Owning the sound of a voice is scary territory we do not want to get into, or the estate of every singer will be suing the estate of every other singer who will be suing the remaining actual living singers. Thinking about replying to this comment? Don't make your writing style sound too much like mine, I have lawyers standing by. And all you trendy kids that type without caps and punctuation can expect a visit from the estate of e.e. comings. reply WheatMillington 19 hours agoparentIf you had picked someone with a less disctinct voice you may have a point, but ScarJo's voice is very distinct. I'd bet on 10/10 people who are engaged in pop culture and 5/10 general people guessing correctly. reply wvenable 19 hours agorootparentScarJo's voice is very distinct but it's clear from this thread that people can't recognize that. As soon as you play both clips right after each other it's obvious that Sky isn't an imitation of ScarJo's voice because it doesn't have those distinctive features of her voice. I think though that Sky's performance is similar to ScarJo's performance in Her. They're both playing AI voices. reply lenerdenator 20 hours agoprevThis feels like someone trying to do something they thought Steve Jobs would do. reply yieldcrv 20 hours agoparentspend a little bit of time in SF or the peninsula and you’ll see that’s a common thing there unless you’re running a company into the ground and getting a bailout from your rival who is trying to delay an antitrust suit, then you’re not doing Steve Jobs correctly reply lenerdenator 20 hours agorootparentIt's usually people who never worked for Steve or ever got to meet him who seem to take this approach. Their company isn't just a business, it's a cult, and they're the Founder (notice the capital \"F\") and part of being in charge of this cult is asserting dominance over others. Steve knew to rarely pull this outside of tech executive circles; the new generation doesn't seem to keep it in SV. Musk is the go-to example but Altman's turning that way too. reply k1t 20 hours agorootparentprevDoes this mean Mitchell Baker is doing Steve Jobs correctly? reply staunch 20 hours agoparentprevSteve Jobs was a superficial asshole but was fundamentally a good and ethical person. There's only one major ethical mistake documented in his entire life (being an absentee father while his first daughter was young), which he spent decades making amends for. The people that emulate Steve Jobs poorly are usually real assholes with a long list of ethical mistakes. reply jedberg 20 hours agorootparent> There's only one major ethical mistake documented in his entire life (being an absentee father while his first daughter was young) Jobs lied to Steve Wozniak. Atari gave Jobs $5000 to make Breakout for Atari. He told Wozniak he got $700 so Wozniak took home $350. reply rqtwteye 19 hours agorootparentThere is also the story where early Apple employees didn’t get any stock and Wozniak gave some of his. reply staunch 19 hours agorootparentThings are always more complicated than this... As a rule, Apple gave stock to employees prior to the IPO, many of whom got rich. But some employees weren't eligible according to the criteria Steve (really, the board) came up with, and so they did not receive stock. Their criteria were typical for the time. Woz and a few others felt bad about this and shared some of their stock. Whether those ineligible people \"deserved\" stock is a matter of judgement... reply lenerdenator 20 hours agorootparentprevIIRC Jobs also later blamed Wozniak's head injury from a plane crash for him not remembering several good things Jobs did for him, as a cover for those things never happening. reply staunch 19 hours agorootparentprevSteve Jobs gave Woz half of the base amount, which is what Woz agreed to. Jobs withheld the fact that he was going to receive a bonus on top of the base amount, and did not share any of that money. Was it an ethical mistake? Sure. He should have at least disclosed that he was receiving the bonus money, even if he didn't want to share it. But claiming it was a \"major ethical mistake\" seems fairly out of touch with reality. And of course, taken in the context of all of the good things they did together, it was completely insignificant and Woz has said as much. reply varjag 10 hours agorootparentWhen you decide to hide money from your partner it's not called a \"mistake\". reply n2d4 20 hours agorootparentprevCan you be a \"good\" and \"ethical\" person if, throughout your entire professional life, you bully and berate nearly anyone around you? reply P_I_Staker 1 hour agorootparentNo. OP is a dangerous fool. These standards are important. reply hot_gril 19 hours agorootparentprevTensions run high in these situations, and in the end they were just building personal computers. So yes, I can understand a boss who's always yelling that the product is shit and demanding that people fix it, but is also an ok person. If there's a comic book villain tech leader out there, it's a CEO of some lifeless conglomerate that mainly buys out the competition and fires everyone aboard, or it's someone in charge of society-altering tech who is choosing to misuse it. And I'm not going to name names. reply hot_gril 20 hours agorootparentprevI agree, that and the \"no cold call\" agreement (which equally involved other CEOs). If I were that famous, someone would probably pick out all my missteps and make me out to look like a horrible person too. The most iconic superficial Steve Jobs impersonation was the Theranos founder Elizabeth Holmes. reply CamperBob2 20 hours agorootparentWell, those, and that one time when he ripped off Woz, but yeah, great guy, except for all those incidents. reply vunderba 18 hours agorootparentprevBy all accounts, he was an incredible bully not just to his employees but also to his family as well. He refused to recognize his daughter even after a paternity test, and despite being a multi millionaire 1000 times over only paid child support when forced to by the courts. Does that sound like the behavior of a good and ethical person? reply disqard 12 hours agorootparentShhhhh, he's the patron saint of the tech world, and you're on HN -- do you really expect a large percentage of folks here to share your views? FWIW, I think he did understand some very fundamental truths about how to sell technology to the masses, but he definitely diverged from Alan Kay's philosophy outlined in \"Dynabook\". IMO, he's less of a \"savior\" and more of a \"god-tier salesperson\". Edit: I mentioned the \"Dynabook\", because Jobs often used the \"bicycle for the mind\" line, in interviews and newspaper ads. reply P_I_Staker 1 hour agorootparentprevHe has a whole laundry list of sleezy actions and abusive behaviors. reply 129 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI, led by Sam Altman, is under scrutiny after Scarlett Johansson accused the company of using a voice in its GPT-4o model that closely mimicked hers without her consent.",
      "Johansson had declined an offer to voice the system and has since hired lawyers, leading OpenAI to pause the use of the voice.",
      "This incident, coupled with internal turmoil and legal challenges over data usage, raises questions about Altman's transparency and leadership, contrasting with his public stance on responsible AI development."
    ],
    "commentSummary": [
      "The article critiques Sam Altman for allegedly using a voice actor resembling Scarlett Johansson without consent, raising ethical and legal concerns about power concentration among the wealthy and the need for better regulations.",
      "The discussion delves into the ethical implications of voice cloning, referencing legal cases like Midler v. Ford and Waits v. Frito Lay, and debates the legality and morality of using celebrity likenesses without permission.",
      "It also touches on AI's rapid expansion, the impact on voice acting jobs, and the broader implications of AI technologies, highlighting the tension between legal constraints and ethical considerations."
    ],
    "points": 331,
    "commentCount": 397,
    "retryCount": 0,
    "time": 1716330356
  },
  {
    "id": 40432834,
    "title": "Revolutionizing Data Storage: Single Plain Text File Method by Breck Yunits",
    "originLink": "https://breckyunits.com/scrollsets.html",
    "originBody": "A New Way to Store Knowledge HTMLTXTPDF by Breck Yunits May 21, 2024 All tabular knowledge can be stored in a single long plain text file. The only syntax characters needed are spaces and newlines. This has many advantages over existing binary storage formats. Using the method below, a very long scroll could be made containing all tabular scientific knowledge in a computable form. * There are four concepts to understand: measures concepts measurements comments Measures First we create measures by writing parsers. The parser contains information about the measure. The only required information for a measure is an id, such as temperature. An example measure: temperatureParser Concepts and Measurements Next we create concepts by writing measurements. The only required measurement for a concept is an id. A line that starts with an id measurement is the start of a new concept. A measurement is a single line of text with the measure id, a space, and then the measurement value. Multiple sequential lines of measurements form a concept. An example concept: id Earth temperature 14 Comments Unlimited comments can be attached under any measurement using the indentation trick. An example comment: temperature 14 > The global mean surface air temperature for that period was 14°C (57°F), with an uncertainty of several tenths of a degree. - NASA https://earthobservatory.nasa.gov/world-of-change/global-temperatures * The Complete Example Putting this all together, all tabular knowledge can be stored in a single plain text file using this pattern: idParser temperatureParser id Earth temperature 14 > The global mean surface air temperature for that period was 14°C (57°F), with an uncertainty of several tenths of a degree. - NASA https://earthobservatory.nasa.gov/world-of-change/global-temperatures * Once your knowledge is stored in this format, it is ready to be read—and written—by humans, traditional software, and artificial neural networks, to power understanding and decision making. Edit history can be tracked by git. * A Visualization Blue dots are measure ids. The first blue dot is a measure definition (aka a parser). The red dot is a measurement value. The blue-red pair is a measurement, as well as a concept. The cyan dot is a comment. View Source * Prior Art Modern databases[1] were designed before git[2], fast filesystems[3], and the Tree Notation stack[4], all requirements of this system. GNU Recutils[5] deserves credit as the closest precursor to our system. If Recutils were to adopt some designs from our system it would be capable of supporting larger databases. * Initial Implementation and Experimental Evidence ScrollSets is the name of the first implementation of the system above. It is open source and dedicated to the public domain. ScrollSets are used to power the open source website PLDB.io. PLDB currently has over 300 measures, over 4,000 concepts and over 150,000 measurements, contributed by over 100 people, dozens of software crawlers, and a couple of artificial neural networks. If printed on a single scroll, the PLDB ScrollSet would be over one kilometer long. * Enhancements For pragmatic reasons, it is best to split your data into 1 file per concept and combine concept files at runtime. The utility and joy of this system improves as your parser language improves. The parser language powering ScrollSets is currently called Grammar, and is largely influenced by ANTLR[6] and Racket[7]. It is very helpful to have a sortIndex attribute on your measures to automatically prioritize[8] the measurements in your source and output files. The impact of this simple enhancement hints at interesting signs of dense information packing achieved by this method, which may have implications for the weights and training of artificial neural networks. Computed measures are measurements not stored statically, but derived at runtime from other measurements. They are very useful and easy to add with a few lines of parser code. You generally always want to add a type attribute to your measures, which gives you error checking, among other things. Measures can be nested. This means it is best to be restrictive in what characters are allowed in measure ids to integrate with a broad set of software tools. For example, you can nest a minParser under temperatureParser to generate a temperature_min column name in a generated TSV. It is useful to have measures whose values are foreign keys, such as a list of ids. * Conclusion Measurements loosely map to nucleotides; concepts to genes; parsers to ribosomes. This system might also have broad use. You can read more about ScrollSets on the Scroll blog, see small demos at sets.scroll.pub, and see the large implementation at PLDB.io. * Citations [1] SQL: Donald D. Chamberlin and Raymond F. Boyce [2] Git: Linus Torvalds, Junio Hamano, et al [3] M1: Apple The M1 laptop was the first consumer machine where the performance of this system wasn't abysmal. [4] Tree Notation: Breck Yunits et al [5] GNU Recutils: Jose E. Marchesi Recutils and our system have debatable syntactic differences, but our system solves a few clear problems described in the Recutils docs: \"difficult to manage hierarchies\". Hierarchies are painless in our system through nested parsers, parser inheritance, parser mixins, and nested measurements. \"tedious to manually encode...several lines\". No encoding is needed in our system thanks to the indentation trick. In Recutils comments are \"completely ignored by processing tools and can only be seen by looking at the recfile itself\". Our system supports first class comments which are bound to measurements using the indentation trick. \"It is difficult to manually maintain the integrity of data stored in the data base.\" In our system advances parsers provides unlimited capabilities for maintaining data integrity. [6] ANTLR: Terence Parr et al [7] Racket: Matthias Felleisen, Matthew Flatt, Robert Bruce Findler, Shriram Krishnamurthi, et al. [8] Prettier: James Long et al * Thanks Thank you to everyone who helped me evolve this idea into its simplest form, including but not limited to, A, Alex, Andy, Ben, Brian, C, Culi, Dan, G, Greg, Jack, Jeff, John, L, Liam, Hari, Hassam, Jose, Matthieu, Ned, Nick, Nikolai, Pavel, Steph, Tom, Zach, Zohaib. ⁂ View source Built with Scroll v93.0.0",
    "commentLink": "https://news.ycombinator.com/item?id=40432834",
    "commentBody": "Storing knowledge in a single long plain text file (breckyunits.com)286 points by breck 23 hours agohidepastfavorite109 comments boomlinde 8 hours agoIt feels like you left a chapter or two out. You mention in the citations that \"Hierarchies are painless in our system through nested parsers, parser inheritance, parser mixins, and nested measurements.\" Nothing else in the article gives any hint as to what those things are or how your system implements them except nested measurements. It's unclear at all what a parser is in your system. It is however clear that what you call \"parsers\" aren't parsers. Is the list of \"parsers\" a schema definition? Overall it seems like your ideas would make more sense if you used more widely adopted language to describe it. \"Concepts\" are records, \"measurements\" are fields. reply breck 7 hours agoparent> It feels like you left a chapter or two out. I agree with you. More details will come out over time but I wanted to keep yesterday's paper a single page. > You mention in the citations that \"Hierarchies are painless in our system through nested parsers, parser inheritance, parser mixins, and nested measurements.\" Nothing else in the article gives any hint as to what those things are or how your system implements them except nested measurements. It's unclear at all what a parser is in your system. Below is a link to a web IDE we built. You can see parsers (on the left), and concepts (on the right). Nested parsers and parser inheritance are demonstrated. Mixins is not currently in that branch yet. Ignore the \"cells\" stuff at top (that turned out to be an unneeded division between lines parsers and word parsers). https://jtree.treenotation.org/designer#url%20https%3A%2F%2F... > Overall it seems like your ideas would make more sense if you used more widely adopted language to describe it. \"Concepts\" are records, \"measurements\" are fields. Yes, concepts often map to records or rows. Measures to fields or columns. Measurements to the cells in a spreadsheet. There are reasons for my terminology, that should become clearer over time. reply the_duke 5 hours agorootparentFrom a quick scan, it sounds like you re-invented a lot of the concepts of semantic data, just with different terminology and a different text format. (RDF, triples, ...) reply 0x445442 5 hours agorootparentI wish there was a defacto/canonical site that housed free papers that people could go search before embarking on these types of efforts. Perhaps there is but when I attempt these types of searches I get directed to pay walled ACM type links or Github \"Papers We Love\" type links. reply breck 5 hours agorootparentYou might enjoy https://pldb.io/, which is a paywall free, open source, public domain, database you can browse completely locally, with information on all of these kinds of prior languages. :) reply breck 5 hours agorootparentprevIt would certainly be fair to add RDF/triples/semantic web, to prior work. I spent many years exploring that stuff. We are aiming at roughly the same problem. Our implementation has solved some important details. reply FabHK 3 hours agorootparentMight be worth highlighting some of the problems solved (particularly those that earlier ideas haven't). reply kjksf 22 hours agoprevI've built a web-based tool for myself that has similar philosophy: https://edna.arslexis.io/ It does support multiple pages but you can use just one. It has a nifty feature in that you can divide the single file into virtual parts. They just have alternate backgrounds to tell them apart. And each virtual part can have a type for syntax highlighting (plain text, markdown or a programming language). I've been using it for a few months now and it's my primary note taking / knowledge recording thing. Even though it's web based, on Chrome you can save notes on disk so it works like a desktop app. Each note is a plain text file so you can edit them in any text editor. If you put notes on a shared drive (Dropbox, OneDrive, Google Drive etc.) you can work on notes on multiple computers. It's also open-source: https://github.com/kjk/edna reply gitinit 19 hours agoparentEDIT: Originally I just looked at the website. Looking at the GitHub repo, I see it's a fork, which makes sense (I also didn't notice the other replies!) Either way, it's cool. I'll probably end up using this myself. I was unable to find a way to store notes in a folder or in encrypted Gists though. This seems nearly identical to Heynote[0], which was also on HN[1]. Even the example blocks share some content with that used as an example in the screenshot on the Heynote homepage (and I think in the app too) [0]: https://heynote.com/[1]: https://news.ycombinator.com/item?id=38733968 reply kjksf 17 hours agorootparentTo save on disk you must use Chrome or Edge because only they support necessary APIs. Initial note storage is in localStorage. To switch to disk: right-click for context menu, `Notes storage` / `Move notes from browser to directory`. Then choose a directory on disk and we will do one time migration from localStorage => disk. You can then switch to another directory (some apps call it a \"workspace\"). Because why not. Encryption is probably the next feature I'll add because I want to store secrets in my notes and I'll feel better if those notes are encrypted. More docs: https://edna.arslexis.io/help Multiple notes is pretty big addition. I loved the concept and implementation of blocks in Heynote but a single note was a deal breaker for me. I've also added some UI like right-click context menu for discoverability, ability to enable spell checking. And I'm really trying to optimize for speed of use, including speed of switching between notes. For example you can assign Alt + 0 .. Alt + 9 as note quick access shortcuts. By default I create 3 notes: scratchpad, daily journal and inbox and they get Alt + 1, Alt + 2, Alt + 3 quick access shortcuts but you can assign them to any page you want. reply Brajeshwar 16 hours agorootparentprevJonatan Heyman produces some pretty awesome and useful apps/tools. One should check out his work - https://heyman.info reply zcw100 8 hours agoparentprevLooks like a CLI version of a tiddlywiki reply desio 11 hours agoparentprevLooks like that's on codemirror framework? Any good resources you could share on wiring up custom language and view? I've managed to kinda get something working with lezer but the docs aren't great and I want to setup some pretty specific behaviour in the view with folding and validation etc. reply kjksf 8 hours agorootparentYes, Codemirror. What I know about Codemirror I mostly learned by reading other people's code so I suggest that. Specifically code of silverbullet: https://github.com/silverbulletmd/silverbullet/tree/main/web... (and a few other directories there). It implements very advanced Markdown mode, lots of code to learn from. reply porridgeraisin 21 hours agoparentprevJust found out this is a fork of heynote! Was looking for one of these with web support reply jonatanheyman 11 hours agorootparentHeynote exists as a web app as well :) https://app.heynote.com/ reply kjksf 21 hours agorootparentprevYeah, I loved the simplicity and speed of Heynote and math mode. I wanted multiple notes and I didn't get why it was made as a desktop app first given that all functionality to implement it is available in a browser (well, Chrome). So I forked it and added those features. Been using it daily so it was worth it. reply smusamashah 21 hours agoparentprevThis is great. Any plans to add images support? (for screenshots in my case) I use OneNote extensively because it's free form like a white board and allows pasting images (which i often do while debugging). reply ralgozino 3 hours agorootparentsounds like Obsidian's canvas: https://obsidian.md/canvas reply kjksf 20 hours agorootparentprevProbably not to Edna. It's focused on being fast and lightweight. I've been thinking about more featureful markdown note taker that would support images and more. I've started on such a thing but stalled. It's way more work. The good thing about Edna is that I spent less than a month adding the features I wanted to Heynote fork. The current version is at https://notedapp.dev/ but don't use it for actual notes. reply pcblues 8 hours agorootparentprevA thing I used OneNote for was easy OCR. reply FredPret 22 hours agoparentprevVery cool! I love the math block. Is there a way to reference a variable elsewhere, or fetch data online? Then you could build a little personal dashboard with it. reply kjksf 21 hours agorootparentNot at the moment. I was thinking about making math more like a mode i.e. make it available in every block type, as opposed to it's own block type. Then it would be active in plain text, markdown and even code blocks. As to data fetching - falls a bit outside of scope. reply porridgeraisin 21 hours agoparentprevHeynote is similar reply kjksf 21 hours agorootparentEdna is a fork of Heynote with a bunch of changes. Mostly it supports multiple notes and it's a web app, not a desktop app. I could build a desktop app but it would not offer almost any advantages given that Edna can also save notes on disk (that's how I use it). You can use Chrome's \"Install\" feature to make it look act like a native app (it opens in it's own window and acts independently of the browser). reply jonatanheyman 11 hours agorootparentHeynote also exists as a web app: https://app.heynote.com/ reply BOOSTERHIDROGEN 8 hours agorootparentCan I self hosted this ? reply sphars 6 hours agorootparentLooking at the GitHub repo[0], I don't see why you wouldn't be able to host it yourself (extra configuration may be required). In the package.json, there is a script for running the web app `npm run webapp:build`, so I'd assume you could do that and then host the built web app in ./webapp/dist however you'd like. [0]: https://github.com/heyman/heynote reply canadiantim 21 hours agoparentprevHow does the saving notes on disk work? You mean just downloading it? Or is the content synced? If so how does that work? reply kjksf 21 hours agorootparentChrome implements APIs that allow accessing files on the disk. So Edna either stores notes in localStorage or in a directory of your choosing on disk. In Edna you can right-click for context menu to switch between localStorage and disk. If you ask: \"how do the browser APIs work\", you can look at https://github.com/kjk/edna/blob/main/src/fileutil.js Basically, there's `window.showDirectoryPicker()` to ask user for permission to access directory (either read only or read write). And then using that directory handle you can read list of files, read / write files or create new files. reply wernsey 11 hours agorootparentOh, man, many years ago I used Tiddlywiki (and later Wiki-On-A-Stick) as a browser-based note taking app, but stopped using it because the API they used to save the file to disk got deprecated and removed. History not repeating but rhyming, I suppose... Anyway, thanks for this. I've just added it to my bookmarks. reply wodenokoto 12 hours agoprevI don’t get it. How do I now that something is a data definition and not just more data? Is “>” a special character together with space and new lines? He calls it a trick, why? How do I add data with spaces and new lines? Is “Parser” a keyword that you postfix to names of values? He writes “idParser” and then has a value in each observation that is named “id” reply breck 7 hours agoparent> I don’t get it. How do I now that something is a data definition and not just more data? In our ScrollSet implementation, a measure definition (what you call a \"data definition\") is a subset of a parser. You will know something is a measure definition when you see a line starting with a word with a \"Parser\" postfix, and nested inside that definition is a line like \"extends abstractMeasureParser\". Below is a link to a web IDE we built. You can see all of the measure definitions currently powering PLDB on the left. On the right, you can see a concept (\"more data\", in your terms). https://jtree.treenotation.org/designer#url%20https%3A%2F%2F... > He calls it a trick, why? The current term of art is \"Offi-side rule\" (https://en.wikipedia.org/wiki/Off-side_rule). I never liked that term. I call it the indentation trick. But I am referring to the Offside_rule. reply csomar 1 hour agoprevI understand the author point, but I think this is over-complicating a database table while losing most of the features a database can give you. This is not some new concept, however. I stumbled upon this concept two years ago with some dude promoting a \"Vault\" architecture, where you use a single \"notion.so\" table to store all your data. You create views from this data to separate topics. You'll then be able to \"centralize\" all you notion stuff in a single file; all while being able to link any two topics or more together. What hit me is that I can export the notion table to CSV and then this can be fed into an AI pipeline that might be able to predict my tasks better (like code). Only problem was, a couple of months into this and the notion interface became completely unusable. This can be done with a regular database. Though the views/interfaces to interact are not that easy to create. I didn't find an alternative (I tried airtable too) reply TZubiri 13 hours agoprevXml is too bulky, let's do csv Csv is too limited too strongly typed, let's do json. Json is too heavily punctuated let's do yaml. Yaml is too yamly, let's do this instead. reply wruza 11 hours agoparentLet’s just do json5 after json. https://json5.org/ reply corn13read2 9 hours agorootparentI'll wait for version 6 reply Quothling 3 hours agoparentprevEventually everything becomes toml. All jokes aside, I think the equivalent for this would be markdown not xml/csv/json/yaml. reply benatkin 12 hours agoprevNested Markdown with code fences is plain text. Alas, vscode will choke on it. I have a project where a thin wrapper loads from a giant markdown file into a sandboxed iframe. That way you could paste code from an unknown source into it and play with the output and paste private data into it and it wouldn’t be encoded into a URL sent to a server, as making network requests and following links are blocked. https://codeberg.org/ristretto/pages notebook.md is huge, output in the project website, link to source in the README. reply zitterbewegung 2 hours agoprevThis reminds me of Org Mode[1] https://orgmode.org reply a_c 12 hours agoprevIf we forego human read-write-ability to gain some interactivity, we got https://tiddlywiki.com/ , a single long html file reply dflock 22 hours agoprevThis is _so much more_ than the title suggests - this is not about making notes in text files. reply breck 18 hours agoparentYou get it ;). reply jhoechtl 3 hours agoprevGlad recutils got a mention. I find it superior to the proposed concept. Sadly recutils never cought on. reply samatman 2 hours agoprevIn case you would like to be less (or more) confused, this is an application of Tree Notation, by the same author https://treenotation.org/ I suffer from the same flaw as the author, a tendency towards grandiosity and fervor in describing my good ideas. So I'm in a good position to advise that he knock it off: people don't like that, and it will keep them from using your stuff even if it's good. Which it might be, actually. The extreme simplicity of the foundation is laudable. reply breck 2 hours agoparentThe brevity and grandiosity is not for marketing the idea, it is so the idea can be attacked. I don't want to waste my working hours building a factory out of the wrong materials. If I've made a mistake, I want to know. If the idea is truly good, the products built on the idea should do just fine. reply samatman 1 hour agorootparentIt's your project to run as you please, of course. My guess is that the attacks you draw will skip any basis in technical merit and land directly on the tone, proceeding on an emotional basis. We have an n=1 here with plenty of that behavior on display. You'd like to believe that someone proposing Tree Notation for a project wouldn't be dismissed with \"isn't that, like, the YAML for TimeCube guy?\". But this is, in large part, how the world actually functions. reply breck 38 minutes agorootparentIt's been a slog, but I'm very happy with how the ideas in Scroll (which for all intents and purposes Tree Notation and Grammar are Scroll--99% of usage is Scroll) and PLDB have evolved. I don't mind the pushback. If it wasn't for the pushback against Tree Notation, I never would have started PLDB. (\"Learn to research properly\", one commenter once said. And he was right. I think PLDB is the proper way to do research). It's much nicer to get pushback than crickets. That means people are generously giving their time to consider the ideas. Crickets is the worst. I should know, I mostly get crickets. reply runjake 22 hours agoprevCaveat from article: > For pragmatic reasons, it is best to split your data into 1 file per concept and combine concept files at runtime. reply pizzafeelsright 20 hours agoparentAll separate things should be in different files. And files are just key/values anyway. reply egeozcan 10 hours agorootparentI wouldn't say \"should\" but I agree. A file is a very abstracted concept and it technically can mean a lot of different things depending on the file system. However, it is a very good abstraction that's nearly universal and practically there is little to no reason not to use them to organize things. reply kriro 4 hours agoprevIt is surprisingly common for very good bug bounty hunters to rely on stuff.txt as their major \"knowledge base\". At least I've heard this from a couple of high earning guys in interviews. They usually just grep through it or roughly remember where things are. I was quite surprised to hear that. reply zaik 8 hours agoprevToo many people don't know about Wikidata. reply breck 7 hours agoparentCan you elaborate? reply fellowniusmonk 23 hours agoprevI'm so excited for this kind of work. I think there is an alternate history where EMACS or an EMACS equivalent became the dominant OS but the onboarding process was too onerous, and the community has been focused on technical integrations instead of integrating a larger less technical community of people into a sane but simpler default. With AI I think interfaces will further bifurcate between \"users\" and \"creators\" and pretty much all of our \"desktop\" ui paradigms will be consigned to history in favor of structured collaborative text interfaces. reply pama 13 hours agoparentI thought I wasnt alone but perhaps I live in a sparsely populated alternative history where Emacs gets simpler over time. Once you know the basics they dont change. Some more advanced tools gradually simplify or improve but it takes years. Various ideas are explored by users around the globe and the simplest and best ones survive: we now have magit and eglot and treesitter support. And org, but also markup. The shells are true shells with unlimited context and full access to the OS. Similarily for the REPLs. The only thing I miss is changing tools all the time and losing history, which felt like a refreshing excuse to start over when I was younger —- these days I dont have the patience and time. reply akasakahakada 11 hours agoprevEducate me if this is not reinventing the wheel of ymal, toml, xml, etc. reply enriquto 8 hours agoparentOne would rather say that ymal, toml, xml, etc. are wheel reinventions of plain text files. reply TZubiri 13 hours agoprevWhen you still haven't emerged from the covid pandemic and your shutdown project started to take roots deep in your mind. It reminds me of that scene from The Shining where the character writes the same sentence over and over again. reply breck 7 hours agoparentAll text and no syntax makes Breck a dull boy. All text and no syntax makes Breck a dull boy. All text and no syntax makes Breck a dull boy. reply h2odragon 23 hours agoprevplain text has so many advantages. then you need some syntax for the strictures of your use case. and /etc is reborn. reply Terr_ 11 hours agoparentThen you want to be able to access old copies, and RCS [0] is reborn... [0] https://en.wikipedia.org/wiki/Revision_Control_System reply fwip 20 hours agoprevNot sure why the \"fast filesystem\" links to the M1 processor. reply breck 18 hours agoparentYou are right, that is not clear. I've added a note and link (https://github.com/breck7/breckyunits.com/commit/61792237c0b...) \"The M1 laptop was the first consumer machine I tried where the performance of this system wasn't abysmal.\" - https://breckyunits.com/building-a-treebase-with-6.5-million... Thank you! reply fwip 3 hours agorootparentThanks for the explanation. :) reply 082349872349872 8 hours agoprevtangent: http://www-formal.stanford.edu/jmc/elephant/elephant.html reply breck 7 hours agoparentI know what my rabbit hole of the day will be now. Thanks! (https://github.com/breck7/pldb/commit/83ba14454ed80fa682c85d...) reply thorncorona 20 hours agoprevthis is solved better by obsidian reply Sarky 13 hours agoparentIndeed. Markdown files seperated into folders. I organize them into topics. Easy to search with a lot of possible customizations. And even setup without customizations is optically pleasing and functional reply breck 19 hours agoparentprevCan you explain why? reply atrus 17 hours agorootparentObsidian is a bit closer to an unstructured TreeBase than this single file TreeBase imo. reply igtztorrero 4 hours agoprevI like the blog site, it's using scroll language, cool ! reply cpr 22 hours agoprevI did this for decades (using Emacs) but finally gave up and am using Notes. reply breck 2 hours agoparentAny useful tricks or techniques you picked up along the way? reply ukuina 15 hours agoparentprevInterestingly, I am moving more towards plain text notes because they are easier to ingest for LLMs. reply pimlottc 4 hours agoprevI have no idea what the visualization means. reply EGreg 4 hours agoprevWhat I want to know is, what is the maximum size of a PHP file that can be loaded? I guess I can TIAS but is it documented anywhere ?? reply AtlasBarfed 21 hours agoprevThere's two hard problems in computer science: name spacing and caching. This ... Is namespace hell, and if you squint at the caching problem, it's actually an indexing problem, which is also related to this. reply adtac 21 hours agoparentThe aphorism typically says cache invalidation is hard. Not because you don't know what index to invalidate but because it's hard to invalidate the thing at the right time. Caching itself is quite easy, just ask the designers of speculative execution at Intel :) reply samatman 3 hours agorootparentIf a cache doesn't have cache invalidation, it isn't a cache, it's a database. reply racional 6 hours agoprevSee also - How do you store your knowledge? - https://news.ycombinator.com/item?id=40131689 reply rakoo 20 hours agoprevIs this a serious article ? The state of the art of knowledge ? There are at least two (2) existing prior art implementation that have done this for years, only better (as in, with better tools): - recutils: https://www.gnu.org/software/recutils/ - ndb: https://9fans.github.io/plan9port/man/man7/ndb.html Please, developers of everywhere, I beg you: please learn what came before you before reinventing the wheel, only triangular this time. Please take the time to appreciate that if it's so obvious maybe it's because of your ignorance and not your genius. reply stavros 19 hours agoparentMaybe the author just independently came up with this, thought it was cool, and wanted to share? I don't know if \"please do a thorough literature review before showing me things\" is the right sentiment here. reply vineyardmike 19 hours agorootparentConsidering the article has a “prior art” section, I assume a literature review would be appropriate. My confidence is shaken considering the sparse “prior art” section links to Apple M1 as an example of “fast file systems”. reply tambourine_man 18 hours agorootparentYeah, this is really weird. reply breck 18 hours agorootparentprevIt wasn't clear why I mentioned M1. I updated that. Thank you. https://github.com/breck7/breckyunits.com/commit/61792237c0b... A number of things have to best fast for this system to be enjoyable to use (at scale) and before the M1 no personal machine I ever tried came close. reply chipdart 13 hours agorootparentprev> Maybe the author just independently came up with this, thought it was cool, and wanted to share? That's perfectly fine, but that's besides the whole point. The point is that between coming up with something and implementing it, there should be a step to check if anyone already did something similar. The whole point of researching prior work is to a) don't waste time reinventing the wheel, b) leverage prior work to improve your own ideas, c) make better use of your time by doing meaningful contributions instead of taking a risk on whether you're ripping off someone else's work. That's the absolute basic standard on scientific publishing, for example. If you pick up any paper at all, you'll notice that right after the introduction and summary you get a bibliographical review listing any relevant work that your peers already contributed. When anyone submits a paper, the reviewers can and outright do reject your submission if it fails to adequately contextualize the paper with regards to prior art and related work. One of the points is to ensure the author is not wasting everyone's time with a novel approach to the wheel. More importantly, if an author fails to know what's already there, how can they tell their idea is any good? reply rkangel 6 hours agorootparentprev> Maybe the author just independently came up with this, thought it was cool, and wanted to share? Except that the title (\"A New Way to Store Knowledge\") is leaning heavily on NEW. reply rakoo 19 hours agorootparentprevI'm not sure the paper-like presentation of the article shows that the author was in pure discovery mode, eager to share something new and interesting. My message is an echo to earlier comments of earlier posts that talked about a similar point: nothing is ever new, everything has already been done before. If we tell ourselves we're engineers, we should be studying what came before in order to prove that the new thing is indeed better. That being said, recutils is the standard method of recording data in GNU, and ndb is the standard method of configuring stuff in Plan 9, a system that any proponent of UNIX mindset should know about. I'm not exactly talking about obscure stuff here. reply chipdart 13 hours agorootparent> I'm not sure the paper-like presentation of the article shows that the author was in pure discovery mode, eager to share something new and interesting. If the author was following a paper-like presentation, the author somehow skipped the section listing relevant prior work. This is something every single journal enforces, as researching prior work is the very first step any author does when they come up with something. reply breck 19 hours agoparentprevThank you for bringing up recutils and ndb. I had seen them years ago but didn't make the connection when writing this paper. But there are some great connections, and I will definitely be updating the post with a section and links to them. I am reading through the source and will have more to say soon. If anyone has any links to massive plain text datasets based on these (or other similar tools), I would appreciate more pointers. I can tell you now (subject to change), based on my preliminary read through the source is that the two systems you mentioned missed some highly important details that I have presented in my paper, with order of magnitude impacts. Not to discredit them at all, rather I think my work gives them credit, in that they were on the right track, and we just have the benefit of some recent innovations, and get to stand on their shoulders (and the shoulders of others). Edit: I have updated the paper with a reference to Recutils. Thanks rakoo! https://github.com/breck7/breckyunits.com/commit/71b706d296e... The added text: GNU Recutils^recutils deserves credit as the closest precursor to our system. If Recutils were to adopt some designs from our system it would be capable of supporting larger databases. https://www.gnu.org/software/recutils/ ^recutils: GNU Recutils: Jose E. Marchesi https://www.gnu.org/software/recutils/ - Recutils and our system have debatable syntactic differences, but our system solves a few clear problems described in the Recutils docs: - \"difficult to manage hierarchies\". Hierarchies are painless in our system through nested parsers, parser inheritance, parser mixins, and nested measurements. - \"tedious to manually encode...several lines\". No encoding is needed in our system thanks to the indentation trick. - In Recutils comments are \"completely ignored by processing tools and can only be seen by looking at the recfile itself\". Our system supports first class comments which are bound to measurements using the indentation trick. - \"It is difficult to manually maintain the integrity of data stored in the data base.\" In our system advances parsers provides unlimited capabilities for maintaining data integrity. reply rakoo 19 hours agorootparentIf your research has added value over the existing state of the art I would love to read more about it ! reply breck 17 hours agorootparentThanks to your pointer, I was able to explain a bit more about the advances over the SOTA. Thank you! This is the speed at which peer review should happen. If I'm lucky, I'll wake up tomorrow to someone else pointing out another precursor I overlooked. reply rakoo 7 hours agorootparentThanks for the comparison ! I see there are some advances compared to recutils, those would benefit being put to the front ! reply mushufasa 23 hours agoprevThe title, \"A New Way to Store Knowledge\", indicates this is a joke. reply knighthack 19 hours agoparentThe moment I read the text I knew the title was satirical. You know it is when it starts like this: \"...All tabular knowledge can be stored in a single long plain text file. The only syntax characters needed are spaces and newlines.\" That's fundamentally the simplest way of storing text. And it's nothing new, yet people have long ignored that simplicity for much more complicated ways of storing text. reply m463 22 hours agoparentprevI suspect it refers to Wolfram's \"A New Kind of Science\". I don't see it as a this-is-all-a-joke thing though, more tongue in cheek. also I think one-big-text-file has a certain simplicity, like everything-is-a-file on unix (or more properly plan9) reply happytoexplain 22 hours agoparentprevIs there some context you're leaving unsaid? reply mushufasa 22 hours agorootparenta plain text file is the oldest idea for storing knowledge. see unix philosophy: \"Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface.\" reply sprobertson 21 hours agorootparentDid you read past the title? The main point of the article is a syntax for knowledge bases - plain text is just an implementation detail. reply chipdart 13 hours agorootparentIf you take out plain text from this presentation, what's left? The tree structure? The log aspect? In order to claim any of this is remotely novel, you have to first ignore the whole body of work built around information systems. reply breck 7 hours agorootparentMaybe you missed the link in the \"Evidence\" section to a 7 year open source project containing 172,162 lines of code, and a compiler compiler. ;) reply chipdart 7 hours agorootparentThat doesn't answer my question. reply breck 5 hours agorootparent> If you take out plain text from this presentation, what's left? The tree structure? The log aspect? In order to claim any of this is remotely novel, you have to first ignore the whole body of work built around information systems. Thank you for the feedback. I've updated the paper with some more links. The language in which the measures are written in (currently called Grammar. I will like rename it to something like Parssers) is quite advanced. The improvements over Recutils, the closest precursor I am aware of, have now been added. The PLDB ScrollSet is now about 500,000 cells of information. Each cell is strongly typed and fully auditable by git. There is a high amount of signal in that dataset. It is an intelligent set of weights, and continually getting more intelligent. And it is read at runtime as a single plain text file and compiled to a single CSV (or tsv, json, etc). All from using the system documented in the paper (and the advanced language for Parsers). If you can point me to a similar database or similar scale anywhere in the world (plain text base, >10e5 size, git backed, strongly typed, hierarchical and graphical), I would be grateful as I might learn something. reply robertclaus 14 hours agoparentprevI hope so... reply andrepd 21 hours agoparentprevIt must be, right?? The whole thing reads like a satire of the exact kind of thing HN would fawn over. Just look at the current comments! reply SrslyJosh 17 hours agorootparentI'm not sure myself. I didn't want this to be the second comment on the submission so I'll say it now: I got TimeCube vibes from this. reply Biganon 19 hours agoprevThis gives off a TimeCube vibe. reply throwthrowuknow 21 hours agoprev [–] Facts reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Breck Yunits introduces a method to store tabular knowledge in a single plain text file using spaces and newlines, offering advantages over binary formats.",
      "The system, called ScrollSets, is human-readable, editable with git, and compatible with traditional software and AI, and powers the open-source website PLDB.io.",
      "Key features include measures, concepts, measurements, and comments, with enhancements like splitting data into multiple files, using a parser language called Grammar, and adding attributes such as sortIndex and types."
    ],
    "commentSummary": [
      "The article by Breck discusses storing knowledge in a single long plain text file, with critiques on concepts like nested parsers and the reinvention of semantic data concepts.",
      "Tools such as Edna and Heynote are mentioned for note-taking, highlighting features like quick access shortcuts, local storage, and potential enhancements like image support and OCR (Optical Character Recognition).",
      "The discussion emphasizes the importance of referencing prior work to avoid redundancy, the practicality of organizing data in files, and reflections on the simplicity of plain text files for data storage, especially during the COVID-19 pandemic."
    ],
    "points": 286,
    "commentCount": 109,
    "retryCount": 0,
    "time": 1716320196
  },
  {
    "id": 40440283,
    "title": "Right to Roam Movement Seeks to Reclaim Public Access to England's Lands",
    "originLink": "https://news.mongabay.com/2024/05/right-to-roam-movement-fights-to-give-the-commons-back-to-the-commoners/",
    "originBody": "The “right to roam” movement in England seeks to reclaim common rights to access, use and enjoy both private and public land, since citizens only have access to 8% of their nation’s land currently. Campaigner and activist Jon Moses joins the Mongabay podcast to discuss the history of land ownership change in England with co-host Rachel Donald, and why reestablishing a common “freedom to roam” — a right observed in places like the Czech Republic and Norway — is necessary to reestablishing human connection with nature and repairing damaged landscapes. At least 2,500 landscapes are cut off from public access in England, requiring one to trespass to reach them. “There needs to be a kind of rethinking really of [what] people’s place is in the landscape and how that intersects with a kind of [new] relationship between people and nature as well,” Moses says on this episode. Like most nations, England doesn’t have legally recognized rights for citizens to cross non-public lands. This means that the nearly 56 million people who live there are only legally allowed to access 8% of the country. One particularly picturesque example of this problem was recently noted by the BBC, which discussed a large piece of public land that’s actually inaccessible due to being surrounded by private land, forcing people to trespass in order to reach it. Right to Roam campaigner Jon Moses speaks with Rachel Donald on the latest Mongabay Newscast about a growing movement in England that stages creative events like group walks on private land to point out the benefits of public access for repairing degraded landscapes and improving the lives of everyday citizens, which are outlined in a new book, Wild Service: Why Nature Needs You, that he’s co-edited with Nick Hayes. Listen here: Freedom-to-roam laws aren’t widely recognized outside of Scandinavia and Europe, but Moses says these rights are fundamental to repairing the damage caused by centuries of private land ownership. “I think that there needs to be a kind of rethinking really of [what] people’s place is in the landscape and how that intersects with a kind of new … vision of farming and a new relationship between people and nature as well.” Among the reasons Moses says is given for the increase in private land ownership over the past few centuries is industrial agriculture, which he says isn’t benefiting the farmers all that much either. Moses says the reasons for decreases in the rights of “commoners,” as they’re referred to, to access and use common land in England were in part to suppress wage growth and quash locals’ autonomy. “They’re really kind of explicit about this in the documentation, that we need to break common rights in order to create a kind of more dependent class of agricultural laborers that are reliant on a wage,” Moses says. Subscribe to or follow the Mongabay Newscast wherever you listen to podcasts, from Apple to Spotify, and you can also listen to all episodes here on the Mongabay website, or download our free app for Apple and Android devices to gain instant access to our latest episodes and all of our previous ones. Banner image: Thousands gather for a protest against the attempt to ban wild camping on Dartmoor. Campaigners gathered to raise ‘Old Crockern’ – a mythical spirit of the moor – on Stall Moor, owned by the landowner leading the ban. Image courtesy of Jon Moses. Rachel Donald is a climate corruption reporter and the creator of Planet: Critical, the podcast and newsletter for a world in crisis. Her latest thoughts can be found at 𝕏 via @CrisisReports and at Bluesky via @racheldonald.bsky.social. Mike DiGirolamo is a host & associate producer for Mongabay based in Sydney. He co-hosts and edits the Mongabay Newscast. Find him on LinkedIn, Bluesky and Instagram. Related Reading: Article published by Erik Hoffner Activism, Environment, Environmental Activism, environmental justice, Environmental Philosophy, Environmental Policy, Featured, Human Rights, Interviews, Land Rights, Land Use Change, Landscape Restoration, Nature And Health, Podcast, Public Health, public lands England, Scotland, United Kingdom PRINT",
    "commentLink": "https://news.ycombinator.com/item?id=40440283",
    "commentBody": "'Right to roam' movement fights to give the commons back to the public (mongabay.com)279 points by Breadmaker 6 hours agohidepastfavorite323 comments SoftTalker 4 hours agoI think the main reason people get nervous about \"the public\" roaming their land is the liability and the personal injury lawsuit industry in the USA. If I let someone cross my land and he trips on a tree root and breaks his leg, now I'm possibly facing a lawsuit. Also, what are they allowed to do? Simply crossing the land is one thing. Around here many private landowners are dealing with homeless encampments that are not only a liability but a sanitary issue, as they tend to be full of litter, needles, food waste, and human waste and end up attracting vermin. reply NeoTar 4 hours agoparent> Also, what are they allowed to do? If the law in England were to be similar to the one in Scotland (https://en.wikipedia.org/wiki/Scottish_Outdoor_Access_Code), then \"access rights can be exercised for recreational purposes, some educational activities and certain commercial purposes, and for crossing over land and water.\" \"Access rights do not extend to motorised activities... Access rights do not include the right to hunt, shoot or fish... Gathering items such as mushrooms or berries for commercial gain is not covered by access rights; but the customary picking of wild fungi and berries for personal consumption is not prohibited under the code.\" \"Wild camping, defined as lightweight camping by small numbers of people staying no more than two or three nights in any one place, is permitted under the code. ... The code requires that campers leave no trace, and must take away all litter, remove all traces of the tent pitch and of any open fire, and not cause any pollution\" So, homeless encampments are not permitted since these would not fall under this code. reply Nextgrid 2 hours agorootparent> are not permitted since these would not fall under this code The thing is, the law/code only matters if it is enforced. I have little faith this will be enforced enough to be a deterrent when much more important things like shoplifting, bike or phone theft have effectively been decriminalized by lack of enforcement. Edit: to be clear I am just playing devil's advocate here. I am in favor of \"right to roam\" laws, just pointing out that restrictions in the law by themselves don't mean anything unless they're followed up by adequate enforcement to deter the prohibited behavior and systemic changes to make said behavior unnecessary in the first place (in case of homelessness for example). reply readyman 2 hours agorootparentScotland doesn't have the extreme levels of inequality that result in extreme levels of shoplifting, and therefore the shoplifting comparison doesn't hold up. reply UberFly 2 hours agorootparentInequality isn't the correct term. It's poverty, drug abuse and mental illness. Poverty still isn't a green light to commit crimes though. There are plenty of places to seek help legally. Crime is as much a cultural problem as anything else. reply Schnitz 1 hour agorootparentThe problem is the large amount of people with nothing to loose and no realistic path to a better future. If your day to day reality is as bad as jail, you might as well shoplift or camp illegally or whatever. What are they going to do? House and feed you? reply chaostheory 39 minutes agorootparentThere are plenty of government programs and nonprofits that help the needy. They work for 80% of the homeless. The issue with the chronically homeless who make up the other 20% is that they refuse the help because they don't want to follow rules such as curfews and no drugs & alcohol. The main reason for this is that most of them suffer from mental illness. This is a medical issue. reply readyman 17 minutes agorootparentYou're forgetting the tremendous number of homeless who simply die. Also, the US is incapable of even reproducing itself, which falls far short of my definition of \"works.\" reply OJFord 2 hours agorootparentprev> Inequality isn't the correct term. It's poverty, drug abuse and mental illness. ...relative to others with less of that; hence an inequality. reply antisthenes 1 hour agorootparentprev> Inequality isn't the correct term. It's poverty, drug abuse and mental illness. Just curious where you think those last 3 things stem from. Drug abuse and mental illness are much more prevalent in those worst off economically. Poverty (in developed countries) is almost always a result of inequality due to bad policies (lack of social safety nets). > Crime is as much a cultural problem as anything else. Right, part of crime is cultural, and part is economic. But culture is also determined by lack of access to economic opportunities. reply gottorf 1 hour agorootparent> Drug abuse and mental illness are much more prevalent in those worst off economically. Poverty (in developed countries) is almost always a result of inequality If the first half of your statement is true, then why do the billions of people subsisting on a few dollars a day around the world do not have society-wide problems with drug abuse and mental illness? Or are you implying that this causation only happens in developed countries? What can you do to refute the idea that instead of drug abuse and mental illness being caused poverty, the same factors that predispose one to drug abuse and mental illness also predispose one to poverty? > culture is also determined by lack of access to economic opportunities Similarly, it's rather the other way around; lack of access to economic opportunities is caused by a culture that values human capital less. Of course, the two compound over time; but history is empirically full of examples of minority cultural groups that were discriminated against (whether legally, socially, or otherwise) but nevertheless succeeded economically due to the culture placing a high value on human capital[0]. [0]: Sowell, T. Discrimination and Disparities. reply readyman 27 minutes agorootparent>If the first half of your statement is true, then why do the billions of people subsisting on a few dollars a day around the world do not have society-wide problems with drug abuse and mental illness? They don't live in societies with extreme inequality and precarity. Under capitalism, inequality is the problem, not merely poverty. reply thaumasiotes 1 hour agorootparentprev> then why do the billions of people subsisting on a few dollars a day around the world do not have society-wide problems with drug abuse and mental illness? Or are you implying that this causation only happens in developed countries? As stupid as the idea that inequality in itself causes these problems is, it doesn't have trouble explaining why this would only happen in developed countries. Historic levels of inequality, including urban \"anyone can easily see that their downstairs neighbor is a hundred times richer than they are\" inequality, were much greater than modern ones and involved a lot less social pathology; maybe look in that direction. > What can you do to refute the idea that instead of drug abuse and mental illness being caused poverty, the same factors that predispose one to drug abuse and mental illness also predispose one to poverty? Looking for a root cause seems unnecessary for this question; mental illness can easily just cause poverty directly. reply s1artibartfast 31 minutes agorootparentI think the direction of causality does bring into question what the expectations are for an egalitarian society is. Is a society just if people with drug abuse, mental illness, and general dysfunction have equality of outcomes? Of course, this simplistic debate belies the fact that all of these attributes have multifactorial causes, and most are in cyclical feedback with each other. Dysfunction begets poverty begets dysfunction. No single intervention is socially curative outside of storybook logic. Getting on my podium, I think that these factors are worse in developed societies than poor one (which often have greater inequality) for numerous reasons: First would be the visibility of inequality. Next would be culture of material consumption. Next would be breakdown of social community (and the efficacy of social norms). I think this explains why this types of behaviors are seen more in places like the US, which has a longstanding culture of materialism and individualism. I think it also explains why the behavior is more pronounced for outgroups and fractured broken communities. This further explains why some groups within the US with strong social community have relatively low crime rates despite very poor economic conditions reply marcosdumay 45 minutes agorootparentprev> Historic levels of inequality, including urban \"anyone can easily see that their downstairs neighbor is a hundred times richer than they are\" inequality, were much greater than modern ones and involved a lot less social pathology; maybe look in that direction. That one is absolutely not true. reply gottorf 25 minutes agorootparentWhich part's not true, that inequality was lesser in the past, or that social pathology is more today? reply thaumasiotes 40 minutes agorootparentprevWhy do you think we no longer have servants? reply __loam 34 minutes agorootparentprevPoverty can also cause mental illness. reply thaumasiotes 29 minutes agorootparentThis is pretty unlikely from a Darwinian perspective. reply readyman 1 hour agorootparentprev>Inequality isn't the correct term. It's poverty, drug abuse and mental illness. Inequality is absolutely the correct term. The rich wield their means to exploit the poor. Without the rich, the poor are not exploited and poverty, drug abuse, and mental illness all decline. Every. Single. Time. reply __loam 1 hour agorootparentprevThis is a stupid take, frankly. Lots of crime in major American cities would go away if much more affordable housing was available. High cost of living causes poverty and stress, which can lead to drug use and mental illness. It's very obvious that these things are related. reply Nextgrid 2 hours agorootparentprevI'm not even sure inequality/poverty is the main driver. If there is no penalty for shoplifting then it just makes sense to shoplift no matter your financial situation. It's just that for a long while, enforcement or the illusion of there being enforcement mostly kept everyone in order, but nowadays the illusions are breaking down. More and more people are pushing the boundaries and realizing that no actual enforcement is happening, so why should they stop? We see the same in white-collar crime where companies constantly push the boundaries in blatant bad faith and this keeps happening because the illusions that kept everyone in order have broken down and actual enforcement isn't sufficient to deter the bad behavior. Keep in mind that shoplifting isn't merely a survival issue, there are \"professionals\" who steal for resale. reply vlovich123 2 hours agorootparent> If there is no penalty for shoplifting then it just makes sense to shoplift no matter your financial situation. And yet enforcement isn’t as strong of a predictor of shoplifting as poverty/inequality. It’s like the joke - I murder as much as I want and it’s not the fear of enforcement that keeps the number at 0. It may be why you aren’t shoplifting but please don’t extrapolate to the rest of us. > We see the same in white-collar crime where companies constantly push the boundaries in blatant bad faith and this keeps happening because the illusions that kept everyone in order have broken down and actual enforcement isn't sufficient to deter the bad behavior. White collar and petty theft are very different. The simplest proof is that white collar crime as a concept didn’t even exist until the 20th century whereas petty theft has existed forever. reply Nextgrid 1 hour agorootparent> enforcement isn’t as strong of a predictor of shoplifting as poverty/inequality. I agree because there's still some morality left. But morality itself can change, and if deviance is normalized by lack of enforcement we might very well end up in a situation where nobody thinks twice about shoplifting, just like when it comes to white-collar crime which is already normalized and keeps being rewarded by the market again and again, so it's not really surprising that more and more \"blue-collar\" crime is happening. > White collar and petty theft are very different Why? Are you saying stealing a 3£ chocolate bar is bad, but doing the same in software via a hidden fee or some arcane clause in the ToS that nobody read (and thus did not agree to) is acceptable? In both cases someone is out 3£. reply vlovich123 1 hour agorootparent> I agree because there's still some morality left. But morality itself can change, and if deviance is normalized by lack of enforcement we might very well end up in a situation where nobody thinks twice about shoplifting That’s a strong claim, but is there any scientific basis for claiming that enforcement creates morality? Anecdotally I see morality police in super religious communities and all it seems to enforce is the appearance of morality but actually people are chafing against it and subverting it all the time - if anything the repression seems to create higher incidence of violent and sexual crimes. As for police, I haven’t checked recently but the number of police officers and the amount of crime that occurs seems to be fairly uncorrelated which is not supporting the hypothesis that more enforcement = better morality and less crime. One place I saw this play is out is in the Bahamas where you and super rich white people putting up huge fences claiming that the locals had a culture of theft - if it’s accessible steal it - when the simpler, but more uncomfortable truth, seemed to be that poverty and inequality creates resentment and the amount of inequality was quite extreme. > Why? Are you saying stealing a 3£ chocolate bar is bad, but doing the same in software via a hidden fee or some arcane clause in the ToS that nobody read (and thus did not agree to) is acceptable? In both cases someone is out 3£. I agree both are unacceptable but legally one form is an acceptable way to do business. White collar crime is something totally different by the way - it’s about individual actions like embezzlement or corruption. Corporate behavior is a whole other category. A major difference of corporate misbehavior is that companies generally exhibit a very sociopathic behavior so they engage in that pure calculus you talk about and moral hazards are extremely real (largely because the market is allowed to reward sociopaths). People at the individual level however don’t operate that way though - aside from where the brain is broken and there’s a compulsive act formed for theft or crime (often due to formative experiences during childhood), most people just don’t want to hurt each other but that desire is weak vs self preservation and preservation of your family. And what starts out as preservation can spiral downward into trying to give yourself the life you think you want (that nice jacket or nice tv). reply Nextgrid 1 hour agorootparent> is there any scientific basis for claiming that enforcement creates morality Not sure (and doubt it) but my argument is that if enforcement was adequate then you wouldn't need morality - morality would be a \"bonus\" but even if it were to go away, adequate enforcement would still deter the undesirable behavior by making it unprofitable. > which is not supporting the hypothesis that more enforcement = better morality and less crime. \"Law enforcement\" in general is too broad to be able to draw this conclusion. Which crimes actually trigger enforcement (and what is the penalty)? If police is too busy busting kids smoking pot (or other victimless crimes that are easy to prosecute) to attend shoplifting incidents/property crime then shoplifting will remain regardless of how much \"enforcement\" there is (and of course the second-order effects from punishing pot smokers will set them up for a life of crime where they'll then \"upgrade\" to other crime with actual victims). > both are unacceptable but legally one form is an acceptable way to do business But law != morality. From a moral point of view I'm not sure there's a difference - in both cases someone is unjustly enriching themselves at the expense of the victim. When talking about morals and how they prevent people from acting antisocially, those morals may evolve over time if the bad behavior has been normalized by financial reward & lack of consequences. > People at the individual level however don’t operate that way though That is true but the economic incentives that are there (and lack of deterrence) means that people may start operating that way and I'd argue more and more people do, whether by choice or by lack of other options. reply vlovich123 1 hour agorootparentAnd I’m saying that enforcement and morality are swamped by poverty and inequality. I’d recommend trying to find any grounding in evidence of your claims because the poverty and inequality links to crime are pretty well established in the data. reply nathan_compton 2 hours agorootparentprev\"If there is no penalty for shoplifting then it just makes sense to shoplift no matter your financial situation.\" True sociopath logic, my man. Most people do not base their actions on some kind of spreadsheet where they are optimizing for economic success. Many people, I hazard to guess most, base their behavior on some sort of pile of moral ideas and/or general bonhomie. Most people are pretty chill and don't want to screw around with other people's livelihoods regardless of legal consequences. reply Nextgrid 2 hours agorootparent> Many people, I hazard to guess most, base their behavior on some sort of pile of moral ideas and/or general bonhomie How do you then explain every company out there being hostile to their customers and constantly pushing the boundaries of what's acceptable, or even things like wage theft which is surprisingly common? Or is there a double-standard here, where individuals are supposed to act in good faith but companies are not just allowed to be assholes, but rewarded for doing so by the market and lack of adequate law enforcement actions? It's true that morality and good-faith behavior has mostly kept things working well, but it's clear that morals and good faith alone isn't good enough since there are entities that abuse the system so laws and enforcement should be there. If it's not, then I'm not going to be particularly angry about the little guys acting antisocially when the entire economic system is encouraging & rewarding it. Look at it from an IT security perspective: it's great that most users are acting in good faith and are not trying to exploit your system, but you still need to plan for the worst and make sure your system can survive hostile encounters. The same should apply to our legal system. reply nathan_compton 1 hour agorootparentThe design of companies (especially limited liability companies, but many other aspects as well) diffuses the moral/aesthetic implications of decision making while concentrating the fiduciary implications, thus leading to behavioral patterns which are pretty inhuman. I'm not arguing that there are not some bad actors - this is clearly and obviously true. I think the legal system should act in whatever way optimizes its goals (presumably, the flourishing of living things or something) and I tend to think the punitive impulse typically doesn't do that. It's main appeal is that it feels good to imagine someone getting punished. reply Nextgrid 1 hour agorootparent> I tend to think the punitive impulse typically doesn't do that Well when it comes to companies the punishment and deterrent should be monetary damages that will effectively make the undesirable behavior unprofitable and thus discourage it in the future. But we're not doing that, setting the standard that antisocial behavior is acceptable (and rewarded by the market by being more profitable than acting honestly), thus it is no surprise that the little guys have a go at it (and guess what, since we're not punishing that either, there is no downside to doing it repeatedly). reply TeMPOraL 59 minutes agorootparentprev> Look at it from an IT security perspective: it's great that most users are acting in good faith and are not trying to exploit your system, but you still need to plan for the worst and make sure your system can survive hostile encounters. I think this is exactly the opposite of the right perspective for law and ethics. Society runs on trust, the more trust the better. ITSec runs best on zero trust. Applying the latter to the former lead to absurdities like \"code is law\" \"smart\" contracts. reply Dylan16807 1 hour agorootparentprev> How do you then explain Companies are sociopathic and we haven't figured out a good way to deal with this. > you still need to plan for the worst and make sure your system can survive hostile encounters Sure, but that's pretty different from saying it \"just makes sense\" to be a hostile actor. reply Nextgrid 1 hour agorootparent> sociopathic and we haven't figured out a good way to deal with this Great, so let's start dealing with this rather than continuing the double-standard where the big guys are allowed & encouraged to behave antisocially while the little guys are shamed for it. Until this is addressed, I'm not particularly surprised to see the little guys start acting anti-socially too; it makes perfect sense in the system of incentives we currently live in. Some people are lucky enough to survive while acting morally, but I don't think it's fair to be angry at those who don't instead of addressing the systemic problem that encourages antisocial behavior, both individual & corporate. reply Dylan16807 31 minutes agorootparentThere have always been sociopaths, and it hasn't caused everyone to act like sociopaths. So that right there breaks the \"perfect sense\" claim. reply madeofpalk 2 hours agorootparentprevIn the countries that have this, such as Scotland or Sweden or Switzerland, how much of this is actually a problem? reply soco 2 hours agorootparentSwitzerland here: depends what kind of property. A large garden? The owner will likely call the cops on you for trespassing as soon as you show up (and they will come). A meadow some place up in the mountains? The rule is you camp after sunset and decamp at sunrise, but as with every remote place, if nobody sees you... Picking berries the same: it's stealing (Mundraub, yes in CH is still illegal) so in the smaller garden you'll be seen and probably reported but otherwise you'll be luckier. reply __loam 1 hour agorootparentprevIt seems to have been working in the UK for centuries. reply posterman 2 hours agorootparentprevTell me you don't know what decriminalization means without telling me you don't know what decriminalization means. reply UberFly 2 hours agorootparentprevThe law would definitely be abused like renter's laws are abused now. reply arethuza 4 hours agorootparentprevSome areas in Scotland also have bye-laws stopping camping during the summer months to reduce potential environment impact: e.g. https://www.lochlomond-trossachs.org/things-to-do/camping/ca... These are relatively small areas though. reply Pet_Ant 3 hours agorootparentprev> \"Access rights do not extend to motorised activities... This seems problematic as there are remote properties that are only accessible through long trails. Stuff like ice fishing spots where you might need to snowmobile a few kilometers. Same with ATVs for deep woods camping. Personally, I have a registered trail through land I own and have no problem with it. I hope people get it to enjoy since I don't get enough chances to. I can't even get to it myself without passing through a dozen different lots. reply baobun 3 hours agorootparentI guess just like Scottish law is adapted to Scottish environment, similar adjustments can be made were applicable. No one suggested porting Scottish code verbatim to Alaska. Also, it's not like long hikes with camping along the way are unheard of. reply BanazirGalbasi 3 hours agorootparentprevMaybe explicitly registered trails (like the one on your land) could grant more access than the default Scottish ones mentioned above. That way the people who are okay with motorized vehicle access can allow it while not affecting the majority who probably don't want vehicles running through their land. A decade ago several teenagers wore a track through the back of my parents' yard with snowmobiles during winter. I'm not familiar enough with snowmobiles to know how much snow should be on the ground, but they kept going after it was reduced to muddy slush that had been churned up by the treads in the back. reply ghaff 2 hours agorootparentMy neighbor doesn’t really care about people walking on her property down by the river. But periodically some ATVer rips down the no trespassing signs and makes a complete mess of the trail during muddy conditions. reply skrebbel 1 hour agorootparentAnd this is why a law like this wouldn’t work in low-trust societies like the US. reply ghaff 1 hour agorootparentPeople need to give terms like low trust , especially as applied to large and diverse countries, a rest rather than spouting them because they think it makes them sound smart. In this case it’s what used to be a very rural town—founded 1653–which over the last few decades has become much more exurban and people who have lived there for a long time find the increased housing density, which in spite of still being pretty low, means people can’t just hunt and ride ATVs everywhere like they could 40 years ago. reply jononor 58 minutes agorootparentprevA few kilometers of snow is easily crossed by skis or snowshoes. Every cabin in Norway used to be accessed like that (changing now the last 2 years, where people now mostly expect to drive to the door). But still skiing a few kilometers is a basic life skill to me, especially if one is going to be going into the woods in the wintertime... At least from 10-12 years of age. reply groby_b 3 hours agorootparentprevIf you want to camp in the deep woods, and there is no trail, hike. Seriously. I appreciate land owners who do make trails available. Seriously. I like offroading, I'm grateful for people who give that opportunity. But I don't think we're entitled to reach everything in a motorized way. And I certainly understand if land owners don't want a permanent stream of ATVs across their land. This is ultimately a balance of rights, and I think \"no motor vehicles unless the land owners allows it\" is a fairly decent balance. reply micromacrofoot 3 hours agorootparentprevThis might be an unpopular opinion. But if you need motorized conveyance to camp remotely... then you should probably not camp remotely. It's ok if some wild areas are less accessible. reply rrix2 3 hours agorootparentYep, if people want to do that there are hundreds of miles of forest service roads they can use to drive in to our national forests. reply Workaccount2 3 hours agorootparent*cries in east coast* Seriously, we have nothing over here. All the land was bought up, often before there even was a united states. And the forests we do have tend to be very heavily regulated. You want to do anything it's all pay for permit and be clustered with a bunch of other permit buyers. I am not aware of single forest in the Northeast where you can just drive in, camp, and leave without breaking the law. reply doctoboggan 3 hours agorootparentI've done exactly what you describe (drive in, camp, leave without breaking the law) in the White Mountains in NH[0]. In general, dispersed camping[1] is legal in almost all national forest and BLM land. I think many people don't realize this but you can camp for free almost anywhere in a national forest (keeping certain distances from trails, roads and bodies of water) [0]: https://en.wikipedia.org/wiki/White_Mountains_(New_England) [1]: https://en.wikipedia.org/wiki/Dispersed_camping reply Workaccount2 55 minutes agorootparentIf you hike in you can camp on the east coast, generally you must be at least 1/4 mile from where you park. On the west coats you can just pull in with your car and set up camp right there. reply prometheus76 1 hour agorootparentprevIsn't there a 14-day limit in National Parks? reply ghaff 1 hour agorootparentIn general there are far more restrictions in National Parks than in national forests than on BLM land. There are some restrictions but really very few in the latter two categories. reply throw7 58 minutes agorootparentprevIn NY, the state parks will be heavily regulated having designated pay for/reserved camp spots along with amenities. However, the forest preserves (Adirondacks/Catskills) and state forests do allow backcountry/primitive camping. Just look for a nearby state forest and look up the dec regulations for that site. More than likely you can can primitive camp there. reply Workaccount2 52 minutes agorootparentYou can primitive/dispersed camp at most forests in the NE. However they all require being far from a road. The best you can do is park and hike in. reply ghaff 32 minutes agorootparent1/4 mile is not far from a road. Of course, terrain may otherwise make it difficult to camp if the trail heads right up. reply volkl48 3 hours agorootparentprevThere's lots of state + national forest land in the Northeast where that's legal. I've done it many times in PA/NY/VT/NH/ME. There are probably some options in the other more developed states too, but I don't usually visit them as much for outdoor recreation. Outside of the most popular locations for tourists that's pretty much the default. ------- If you've had trouble finding this, have you been limiting your search to parks? Parks are usually more heavily restricted in terms of camping. reply dhagberg 2 hours agorootparentprevHistorically, Maine had excellent recreation policies in cooperation with the private paper companies that owned the majority of land in the northern part of the state: areas not actively being logged were available for recreation access, as were vehicles on logging roads (though you best yield to the logging trucks that drive down the middle of the roads, even if it means you need to dive into the ditch). State recreation fees for snowmobiles, fishing, etc. would cover things like insuring the private landowners against liability. However, starting in the mid/late 90's, much of the paper company land was divested and sold to private equity land holders (yay modern finance!) and those previous open access policies have been very much curtailed. It's a big loss to the community, but it sure must be making some money for shareholders somewhere... reply ghaff 3 hours agorootparentprevWhite Mountain National Forest for one. There are restriction regarding how close to a trail or hut you can camp and the topography can be challenging but you certainly can. But yes there are orders of magnitude more national forest land out west. Probably more than the size of the entire or maybe UK. reply mazugrin2 3 hours agorootparentprevCheck out the White Mountain National Forest in New Hampshire or the Green Mountain National Forest in Vermont. I've heard it's also legal in CT State Forests but haven't actually seen this written down anywhere. reply rowdyelectron 3 hours agorootparentprevGreene mountains in VT is one example. You can even shoot there without being bothered. Lmk if you need a list of places in MA NH and VT. reply zhynn 2 hours agorootparentprevI'll just leave this here: https://fpr.vermont.gov/recreation/activities/camping/primit... There are many, and nobody goes there. reply burningChrome 2 hours agorootparentprevWhich can also make camping and hiking in those areas far more dangerous. If a rescue team have hike in 20 miles to get you without any motorized vehicles and can't get a chopper into those remote areas? They shouldn't be remote, they should just be left completely inaccessible. The problem then is people these days, IMHO are far more reckless and stupid and will try and prove Mother Nature wrong by attempting to go into these areas to get internet cred from Tik Tok and other platforms. Perfect example is the people who go to Longs Peak and attempt the Keyhole Route thinking its a well traveled hike and easy. reply ghaff 1 hour agorootparentIf people are reckless and stupid that seems a self-correcting problem. There are a ton of places in the Western US that are more than 20 miles from a road with very few restrictions on camping. reply tekla 1 hour agorootparentprevIf you don't want to do it, don't do it. reply carlosjobim 1 hour agorootparentprev> Stuff like ice fishing spots where you might need to snowmobile a few kilometers. You generally have the right to travel any river or lake. I haven't heard of any country or place that limits this. reply dahfizz 3 hours agorootparentprevI mean, are homeless encampments ever permitted? Yet they show up and are very hard to get rid of. Its not a can of worms I would want opened if I owned property on the west coast, that is for sure. reply hanniabu 3 hours agorootparentprevHow do you prevent people from getting to close to your house and invading your privacy? Someone can come on your property with the intention to rob you, stalk you, etc and if they get caught they can just they were passing through. And unless you have cameras it would make it pretty difficult to prove otherwise. When you're out in the woods all alone that makes you pretty vulnerable and this isn't a situation I would want to be in. reply NeoTar 2 hours agorootparent\"Access rights do not extend to the land surrounding a house or other dwelling (e.g. a static caravan) to the extent needed to provide residents with a reasonable measures of privacy. This is usually defined as the garden around or adjacent to the house that is intensively managed for the enjoyment of residents. \" - https://en.wikipedia.org/wiki/Scottish_Outdoor_Access_Code The article goes on to give examples where this has been legally determined to be a significant area - over 5 hectares (12 acres) around a property ... for people like me who don't fully understand areas in this context, that would be a square of 220m (720 feet) to a side. You are allowed to fence this area off, or take other security measures. And ultimately - its not hugely different to the current situation. If I intend to commit a crime against you, is adding a trespass going to dissuade me? reply BobaFloutist 3 hours agorootparentprevIt sounds like you're not a good candidate for an owner of a large parcel of wilderness. And that's ok! Not everyone has to own acres of undeveloped land! I think it's appropriate that some kinds of ownership are as much a responsibility as a privilege, similar to how not everyone is prepared to be responsible for river or stream running through their property. For a somewhat tortured metaphor, there are seats on planes that give extra leg room, as long as you're willing and able to help others in the case of an emergency. You get the benefit of the extra leg room, but you get the responsibility of helping others in an emergency. And that seems like a fair balance! reply doctor_phil 3 hours agorootparentprevPreventing accidental privacy intrusion is easy. If you have a fence around your property (or even something as simple as a mowed lawn) then it is quite obvious where your plot starts and where the forest ends. Someone malicious doesn't care about laws anyway. If they get caught today, couldn't they could just deny that they were there? I don't understand what would change in that case. reply balderdash 4 hours agoparentprevI’d also add litter, trampling of grass/shrubbery, illegal structures (e.g. deer stands/blinds), theft (picking flowers, berries, apples, vegetables), and idiots trying to pet or take pictures with livestock that weigh 20x what they do. These are all things my family deals with despite our farm being posted no trespassing the entire perimeter. I literally can not imagine how bad it would be if people felt legally entitled to be there + how hard it would be to get law enforcement involved (“I’m not poaching, I was just taking the scenic route…”) reply maxerickson 4 hours agorootparentIn Michigan, agricultural land is treated as if it is posted, so you are trespassing if you go on it, no notice required. I would think that is not uncommon. reply Loughla 4 hours agorootparentIn Illinois, Iowa, and Missouri, it has to be explicitly signed via actual signs, or purple paint (relatively recent laws allow this in rural areas). Alaska requires signs. Indiana requires signs. Those are the states I am familiar with. I believe the states that do not require notice are in the minority, but I'm not sure how to prove that. reply mauvehaus 2 hours agorootparentprevCounterpoint: the people who are observing your boundaries currently are precisely the ones who wouldn't make a mess of it and do stupid stuff. And there's probably a set of people using it who aren't being dipshits who you don't know about. The idiots are already doing the things you don't want them to do and allowing them to roam isn't going to change that. The problematic behaviors are the ones the laws should target (and perhaps already do, e.g. having a blind up without landowner permission is illegal where I live). Merely being on another's property shouldn't be cause to involve law enforcement. I have supported the right to roam (and generally treated posted property as \"open to respectful and responsible use\") for years, and that has not changed since becoming a home and landowner. Our land is wooded, not agricultural, and I have no issue with kindly use by all. reply lambdaxyzw 4 hours agorootparentprev>litter, trampling of grass/shrubbery Obviously illegal, in public places too, do no relation to the topic discussed. >theft Come on. Theft is obviously illegal everywhere. >idiots trying to pet or take pictures with livestock that weigh 20x what they do Good thing is that it anyone is hurt in this scenario it's the idiot. Why worry about it? >I literally can not imagine how bad it would be if people felt legally entitled to be there + how hard it would be to get law enforcement involved I used to do a lot of hiking (in Spain, France, and some other European mountain ranges). Many remote routes go nearby or through someone's fields or even properties (like through someone's backyard). There are many farm animals on the trails or just next to them. Fortunately nobody here cares and we are all more happy because of it reply joenot443 2 hours agorootparentWe’ve got horses and alpacas on our farm in Ontario, it’s super common for tourists with their hiking poles and huge cameras to venture off the Bruce Trail and onto our land to take photos with our animals. Obviously they don’t mean any harm, but horses can be super dangerous and a kick to the head is fatal for humans. What separates places like Canada or USA from Western Europe is that here there’s an entire industry of litigators chomping at the bit for a case like that, regardless of how much of an idiot you think that person is. I’m not happy with the system either, but it’s a reality here. reply s1artibartfast 3 hours agorootparentprevThese were provided as reasons why people dont want strangers on their land. Im not sure how actions being illegal is a dismissal of the concerns. People doing illegal things is one of the main drivers for not wanting anyone on the land. reply forgetfreeman 2 hours agorootparentThese activities are the post-facto justifications folks typically toss up when objecting to people on their land, but I find their lack of imagination dull beyond belief. If we're constructing hypotheticals around potential bad behavior by unknown actors, spice it up a bit! Why not claim you don't want folks on your land because you're worried someone will construct an unlicensed breeder reactor or idk, perform rituals designed to summon the Elder Ones? Full Disclosure: I've gotten belligerent with folks crossing my yard to get to the municipal bus stop on my property and spent significant time and effort trying to get it moved off my block. I've intentionally planted invasives along property boundaries to block neighbors views into my property, put up posted signs in a residential neighborhood, and once gleefully ignored a hedgerow full of poison ivy to the point the actual Department of Transportation contacted me to complain about it making the corner of my property unnavigable to foot traffic and a hazard to road traffic. I offer no excuses for any of that, I don't want randos on my property because by and large I despise human beings. All of that is to say I think the entire conversation around ownership rights vs public rights could use a bit more honesty from the landowners who are either afraid of strangers or hate people in general. reply s1artibartfast 1 hour agorootparentThe examples are obscure because people are providing examples from a very broad and diverse class. The category \"things you dont want done to or with your property\" has millions of things in it, so if you pick 5 randomly they will be odd and dissimilar. That doesn't mean they arent real or legitimate concerns. I dont think attitudes against trespassing is just fear or misanthropy. Enforcing a permitter is a completely logical method to reduce the number of people doing undesirable things within the perimeter. It is used all the time all over the world as a pre-emptive control. reply forgetfreeman 1 hour agorootparentUnderstand I don't disagree with you in any meaningful sense, and it may be more of a regional issue (I live in the South), but quite frequently these kinds of excuses are trundled out when what was actually meant is some combination of \"the poors disgust me\" or \"I'm terrified of brown people\". :/ reply s1artibartfast 1 hour agorootparentPerhaps it is regional. I grew up in a rural area that was very white. We had issues with people riding dirtbikes and tearing up our land leading to sand traps. We had vehicles and tools stolen, and one case of home burglary. Most common was hunters trespassing to hunt game we cultivated, and sometimes shooting towards our house. Im sure some of these people were poor, but my distaste for trespassers doesnt come from that. property rights and no trespassing sings provide a practical tool to for protecting your property. You might not see someone snooping around your garage, but you are more likely to detect them if being within a mile of your house. reply yjftsjthsd-h 1 hour agorootparentprev> If we're constructing hypotheticals around potential bad behavior by unknown actors, spice it up a bit! > I've gotten belligerent with folks crossing my yard to get to the municipal bus stop on my property So you want people to come up with unlikely reasons, then immediately turn around and deliver your own \"dull beyond belief\" example? Have you considered that other people's \"hypotheticals\" are also \"boring\" because those are the things they're actually worried about? reply lcnPylGDnU4H9OF 3 hours agorootparentprev> illegal I'd imagine it's not about being illegal; probably more about the actual trouble of getting appropriate compensation on top of the fact that you have to catch the person who did it in the first place. > Good thing is that it anyone is hurt in this scenario it's the idiot. Why worry about it? American culture is very litigious. It's linked elsewhere in the thread but maybe also useful here: https://en.wikipedia.org/wiki/Attractive_nuisance_doctrine. Not exactly idiots but perhaps people who are a little naive. Although, I also wouldn't be particularly surprised to learn of a case involving adults. reply toss1 3 hours agorootparentprev>>Good thing is that [if] anyone is hurt in this scenario it's the idiot. Why worry about it? Because then the idiot or his/her family will sue YOU for the consequences of their stupidity. It happens ALL the time. And even if you win the lawsuit, you lose, because you must defend yourself and your property at the cost of insane amounts of time and tens- to hundreds-of-thousands of dollars. So, even, if you win, you lose. Just because some trespasser was an idiot. Things would change a lot if liability laws were changed so that if you are on someone else's property, the default is that it is at your risk (absent actual intentional man-traps which are already illegal). But this is not the case. >>Fortunately nobody here cares and we are all more happy because of it Yes, that is nice. The laws are different there, and they should be here. But a famous hiking trail in iirc Colorado was recently closed due to liability concerns crossing private property, and someone got sued. When the law was changed, it was again opened up. Just because we want things to be a certain way, does not mean they are that way. Until the REALITY is changed to the better way, do not ridicule people for recognizing and acting on the actual reality. (When it changes, they'll likely change too, and of they don't, then you can ridicule them.) reply JKCalhoun 4 hours agoparentprev> I think the main reason people get nervous about \"the public\" roaming their land is the liability and the personal injury lawsuit industry in the USA. I would be surprised if that were really the case. I'm sure people would say that is the reason but I rather doubt that is the real reason. People want their own kingdoms. (And private land ownership likely self-selects those people.) reply Loughla 4 hours agorootparentI live in the US, and I have a \"large\" amount of property that is clearly marked for no-trespassing. The reason for this is the prior landowner was forced to sell when a trespasser drowned in the pond on the property and the landowner was sued, successfully, by their family. If there were clear laws regarding trespassers and liability, I would gladly take the no trespassing signs down. I don't care if someone wants to go swim or fish on the very nice pond we have, but I absolutely will not lose my house for someone I don't know. reply ohples 1 hour agorootparentIINAL BUT, This depends on the state you live in, New Hampshire for example I believe your liability is much more limited. reply cratermoon 4 hours agorootparentprevIn the US, at least for most states I'm aware of, the attractive nuisance doctrine applies. And almost anything can be considered an attractive nuisance. It just sucks for everyone because it means the public and property owners lose out. reply arethuza 4 hours agorootparentFrom my reading, the attractive nuisance doctrine applies to children - who I would have thought would be the people least likely to pay attention to \"No Trespassing\" signs? https://en.wikipedia.org/wiki/Attractive_nuisance_doctrine reply s1artibartfast 3 hours agorootparentThat doesn't negate the parent point, and it's not just about attractive nuisance, although childproofing 100 acres is a ridiculous task. There's also been successful suits from people who get injured after breaking and entering locked buildings reply fwip 1 hour agorootparentAll of the suits of this type that I'm aware of have been pretty well misrepresented by the media or person telling the story. Generally they fall into a couple of categories: 1) The person injured was a child (usually omitted from the story). 2) The owner of the building knowingly set a dangerous trap for intruders (e.g: a shotgun pointed at the front door). 3) Ended in settlement with no admission of wrongdoing by any party. 4) Totally made up. E.g: the popular \"A burglar fell through a skylight and broke his ankle\" story was actually a teenager, who climbed on the roof of his school to try to point a floodlight at the basketball court, and fell through a skylight, becoming permanently disabled. They settled out of court. reply s1artibartfast 1 hour agorootparentfor what it is worth, I think the breaking and entering case is distinct from attractive nuisance, which is much more common. reply IncreasePosts 4 hours agorootparentprevThis was a recent issue here with regards to privately owned mountain peaks, with the owners shutting down due to liability concerns. https://kdvr.com/news/colorado/a-simple-sign-will-allow-acce... After they were indemnified from liability the peaks opened back up. reply Aurornis 2 hours agorootparentprev> I would be surprised if that were really the case. I'm sure people would say that is the reason but I rather doubt that is the real reason. It's a real reason, even if it's not as likely to happen as people think it is. The example of someone tripping on a root and suing for damages would get tossed out of court. However, getting to that point could require you to hire a lawyer, deal with a lot of hassle, spend money, and other things you'd rather avoid. However, there are many examples of land owners being sued for various things that happen on their property. Ironically, one of the arguments for holding the landowner responsible in these cases is to demonstrate that they didn't actively stop people from entering the land and doing whatever got them hurt or killed. If it can be shown that the area was a popular or well-known destination for local kids, for example, you have a different set of legal responsibilities. Likewise, if you know something is dangerous and you don't make an effort to keep people out, you could bring legal liability upon yourself. It's a real thing. The near limitless legal interpretations makes it logical to lock down a property rather than risk it. reply dghlsakjg 2 hours agorootparentThe obvious counterpoint is to create strong exclusions in the law, and to allow victims of frivolous suits to pursue costs of defending. The \"right to roam\" generally applies to unimproved or undeveloped land, so an exemption for injuries caused by natural features and activities compatible with legal land use should go some way to alleviating concerns. If you are 'right to roaming' across my land and I have a legal quarry pit that you fall into, I should be immune, and you should be paying my lawyer's bill. reply mminer237 1 hour agorootparentWhile I generally agree, that doesn't really solve the problem as you can't collect payment from an indigent litigant. reply dghlsakjg 1 hour agorootparentThat's a completely separate legal issue. What you will find, is that indigent claimants have a hard time finding a lawyer for frivolous cases when the law is written clearly. Lawyers don't take contingency cases that they know they are going to lose, and people that can afford to shove a frivolous case through the system by paying a lawyer hourly have enough money to pay a second lawyer. reply nsagent 3 hours agorootparentprevSearch online for beware of dog lawsuits in the US as an example of liability. The problem is that these laws vary by jurisdiction, so for example in California those signs do not protect the homeowner if someone is bitten on their land [1]. Michigan State University has a comprehensive overview of dog bite laws in the US indicating where \"beware of dog\" signs legally protect the owner from lawsuits [2] when someone trespasses. [1]: https://www.enjuris.com/california/premises-liability/beware... [2]: https://www.animallaw.info/topic/table-dog-bite-strict-liabi... reply ryandrake 3 hours agorootparentprevThis is a good example of the difference between an excuse and a reason. The excuse people use to oppose roaming is \"risk of lawsuits\" but the actual reason is the \"what's mine is mine and you can't use it\" mentality. reply vitaflo 2 hours agorootparentIf you own the land I don’t see any why it’s a bad thing to not want others trespassing on it. No diff than I don’t want people randomly deciding to sit in my car for whatever reason while I’m at work. reply dghlsakjg 2 hours agorootparentKeep in mind that 'right to roam' applies to unimproved and (some) agricultural land, and roamers can't disturb the right of enjoyment of the owner. This isn't your normal urban backyard. Its more like someone walked through the parking spot that you paid to park in on their way to somewhere else. reply forgetfreeman 2 hours agorootparentprevSome folks absolutely want their own private fiefdoms. I've got a \"neighbor\" right now that's archetypical. In less than a year of moving in he's already made ham-handed attempts to scam me out of control of my right of way, been an apocalyptic pain in the ass to the young couple that just cleared a couple acres and built a house next to his property, and made several attempts to discuss creating an HOA on our road. Then there are folks like me that are exhausted by having to navigate other people's agendas and just want to be left the fuck alone. Anyway, you're spot on. All of the pearl clutching about liability is just the socially acceptable excuse folks offer for their behavior. reply eurleif 3 hours agoparentprevIn Vermont, where activities like hunting and hiking are allowed on any land not explicitly posted to prohibit it, there is also a liability shield for property owners in the statutes: https://legislature.vermont.gov/statutes/section/12/203/0579... reply amarant 3 hours agoparentprevHere in Sweden you're allowed to cross any land that is not directly connected to a house(read someone's lawn) you may pick wild mushrooms and berries growing there, and you may raise a tent and spend 1 night. The rule for camping as I understand it is that after you've stayed your 1 night in one place, you have to move \"out of sight\" from that location before you strike camp again. You may not damage trees, cross fields where food is grown(as this would damage the crops) and you may not pick any planted fruits or berries. Landowners are not liable for any injuries you may incur while on their land. Unless(I think?) you're on their lawn, which you're only allowed to enter if you have permission from the home owner. There are probably a bunch of cornercases I'm unaware of, but that's the gist of it at least reply gspencley 3 hours agoparentprevI approach this from a matter of principle. I don't recognize anyone's \"right\" to enjoy someone else's privately owned property or, stated more honestly, to infringe upon the property rights of others. My wife and I currently live in a medium sized city but we are not the type to enjoy city life at all and thus dream of buying a sizeable chunk of land for the both of us to enjoy and retire to. The biggest factor motivating us to want to make that \"investment\" is our ability to enjoy peace, quiet and solitude on our own property, knowing that there is not another human being within several acres of us. Our lives and property do not exist for the enjoyment of others. We are not your tools. Find somewhere else to loiter, wander, roam or whatever. Our property is private for a reason. We have no desire to encounter anyone else on it regardless of what they are up to. reply ipsento606 1 hour agorootparent> I approach this from a matter of principle. I don't recognize anyone's \"right\" to enjoy someone else's privately owned property or, stated more honestly, to infringe upon the property rights of others. I also approach it from a matter of principle - I don't recognize anyone's right to truly \"own\" land. They didn't create it. It existed before they were born and it will exist after they die. Allowing a market in land doesn't, beyond any fringe degree, encourage the creation of new land. Disallowing a market in land does not decrease the supply of land. So by what right can a person \"own\" a piece of land they didn't create? On a base level, land is what a country is. Your citizenship of a country entitles you to exist upon the land of that country. Imagine if a child were born into a country where every scrap of land was privately owned, and every land owner refused that child the right to exist upon \"their\" land. What is the child supposed to do? I recognize that there are social and economic advantages to allowing people some exclusive rights of access to some land. I recognize that there are advantages to allowing some people some limited rights of monopoly when they make improvements to land. But I do not recognize that a private entity can truly \"own\" land, completely and in perpetuity, as if they had created it from whole cloth. reply klabb3 56 minutes agorootparent100% true. The cult of land ownership is one of the most absurd norms in almost the entire world modulo the few nomadic peoples still around. It’s not just unjust and unsustainable but simply not pragmatic, judging by all exceptions: air space, pollution, zoning, rivers, damming, emergency access etc etc. From a human development perspective, what makes sense is to define usage rights. If you’re using the land for X I can use it for Y. This originates in the principles of refining nature: for instance if I build a boat out of a log, then it reasonably becomes my property because of the human labor that went into it. Where to draw the lines between when, where and how nature gets refined enough to get usage rights can’t easily be deduced from principles, and will vary across regions and cultures. For instance in sparse regions you can afford a larger buffer zone around dwellings. Even within a country (like the US) human lifestyle varies so much that it’s reasonable to have different rules in different places. Perhaps people are married to the concept of owning land so much that the wording cannot be changed. But it’s already obvious that nobody owns the land, the rivers, the lakes, the air. It’s absurd that it’s illegal to walk in the wilderness because of an imaginary line in the sand. I’m from a country with freedom to roam, so I have my bias. That said, to its credit the US has despite its strong private land ownership laws, an amazing and vast set of national-, state parks and BLM land. So from an access-to-nature POV, it’s an incredible country overall. reply gottorf 1 hour agorootparentprev> I recognize that there are social and economic advantages to allowing people some exclusive rights of access to some land. I recognize that there are advantages to allowing some people some limited rights of monopoly when they make improvements to land. But I do not recognize that a private entity can truly \"own\" land, completely and in perpetuity, as if they had created it from whole cloth. What's the difference? Of course nobody truly \"owns\" land in the cosmic sense, for the reasons you stated; and of course most societies nevertheless permit the legal fiction of \"land ownership\", also for the reasons you stated (that generally it results in more favorable outcomes for society as a whole). So you're back to square one. A Georgist land-value tax is the fairest solution to this problem, I think. Let society as a whole enjoy the fruits of that which no landowner caused to happen (the value of the land without any improvements), and let the landowner enjoy the fruits of his own improvements upon the land. reply wbazant 3 hours agorootparentprevA property claim is a bundle of rights, and people democratically decide what is in the bundles. What something being (your) property means is up to all your neighbours to decide. Fortunately someone with more exclusionary view can move to a place where lots of people think like them - a community of solitude is what you need! reply s1artibartfast 2 hours agorootparentIt is is inversely up to each individual decide if they will abide with their neighbors democratic decision. There is always a push and push back to the individual/social dynamic. reply forgetfreeman 1 hour agorootparentprevUh, no? My neighbors have literally no say whatsoever regarding what is or isn't a legally permissible use of or activity on my property, and no governing body exists to permit them any kind of referendum on the subject. reply kcb 1 hour agorootparentYou write this as if your land is a sovereign nation... Regardless of where you are in the US you are under many layers of government(by the people/your neighbors) that absolutely regulate what you can do on your property. Heck the people can even legally forcibly aquire your property if the will was there. reply dghlsakjg 1 hour agorootparentprev> I don't recognize anyone's \"right\" to enjoy someone else's privately owned property or, stated more honestly, to infringe upon the property rights of others. There are those that do not recognize your \"right\" to exclude them from passing peacefully over land. Notably, in the real world, the FAA doesn't care one bit if you think you own your land. They will use the force of the federal government to let anyone fly a plane over your house (including at low altitude). As a more extreme example, many indigenous people do not recognize your right to own land that was never sold. Your principle doesn't really stand up well in the real world. There are all sorts of exceptions to private property rights. People can legally come onto your land without your permission for all sorts of reasons (utility workers, aircraft overflying, government agents, police, private citizens who haven't been told not to, etc..) The 'right to roam' is just an extension of that, that says that if an undeveloped piece of land lies between where you are and where you need to go, you can pass over that land in a way that does not interfere with the landowner just like all the other exceptions to a landowners \"exclusive\" right to the land. reply 9dev 2 hours agorootparentprevThis is so hard to understand as a European. Why does it need to be your very own land to be enjoyable? I regularly go hiking in the alps. Sometimes I walk for hours without meeting a single other soul, but if I do, it's always a friendly greeting as we pass another. Why can't we share these places? reply gspencley 2 hours agorootparentYou're not asking anyone to share, though. You're asking for the government to grant you a legally enforceable entitlement to use property that someone else worked to acquire and maintain. So your question becomes \"why should property rights exist in the first place?\" The answer is that our existence, by nature of being a human being, has material requirements. Humans have non-material requirements as well (friendships, hobbies, art etc.), but you can't dismiss the material requirements of the human experience. The same reason that it needs to be your food, your bed, your clothing is the reason that land ownership needs to be a protected right as well. If you weaken respect and protection for land ownership then, rationally, you weaken the recognition of all property rights from food to clothing to musical instruments to your tech devices. Each material \"property\" may serve different purposes for the owner, but that doesn't negate the necessity of owning property. And a claim to property is the ability to control its use. reply vitalredundancy 1 hour agorootparent> If you weaken respect and protection for land ownership then, rationally, you weaken the recognition of all property rights from food to clothing to musical instruments to your tech devices. there's a fallacy of scale here, in the same way a handgun isn't the same as a nuclear weapon, and so should probably have different provisions applied to it. land is vastly more useful, and usable, than someone's shirt or ipad. multiple people can enjoy a stream, or a forest, or even a singular tree on a piece of land at the same time, and in a multitude of ways. that's not true of an ipad or shirt. this diversity and simultaneity of use puts land in a different class. severing tight coupling of personal property(like shirts and ipads) with private property(land, generally structures on land, though the latter is admittedly more contestable), is pretty useful and seems totally rational to me. it seems less rational to think weakening one would weaken the other. If anything, the distinction between personal and private property opens up new ways of thinking about property that can lead to agreeable outcomes. more generally, see also the benefits of the commons - https://www.nature.com/articles/340091a0 that said i'm with you in certain respects, i generally like solitude personally, but though i dream of having ten or so acres myself, i don't want to deprive anyone else of thoughtfully, carefully, and temporarily enjoying it either. reply dghlsakjg 1 hour agorootparentprevPrivate property has never really been exclusive. This isn't a new line that is being crossed. \"Owning\" land gives you some rights over it, but not exclusive ones. It doesn't even give you exclusive right to access the land. People can temporarily access the land for a variety of legal and valid reasons like utility work, police investigations, sales, surveys, etc. They can even permanently access the land through easements. Right to Roam isn't saying that you don't have property rights, it is just providing another limited exception to an already long list. It is saying that people have the right to enter your unimproved land for the purpose of crossing it in a way that does not interfere with the property owner's other rights. In some places it also includes the right to temporarily sleep on the land. There is no 'material requirement' to being a human that requires that if you own a large piece of unimproved land, people cannot peacefully walk across the parts you aren't using. reply mrmanner 1 hour agorootparentprevTo use an analogy: In the US there are fair use exemptions to intellectual property rights. That doesn't mean there's no such thing as intellectual property, or that it's meaningless. The right to roam in some other countries is a fair use exemption to land ownership rights. That doesn't mean there's no such thing as land ownership, or that it's meaningless. reply mrmanner 1 hour agorootparentprevIt's actually quite funny that the freedom to roam in large parts of Europe predates the USA by several hundred years and is universally accepted by landowners, yet it's talked about as if it's some sort of unprincipled anomaly. reply fifilura 3 hours agorootparentprevAs a matter of principle, what gives you the right to own a part of the Earth? Who did you buy it from and who did they buy it from? reply Nagyman 1 hour agorootparentHear, hear. Go back far enough and it's stolen land, insofar as any land can be owned. Entitled folks ranting about \"their\" property is kinda gross. You were granted that right by society, through ancestral collective agreements and cooperation wrt currency, labour, etc - not some divine right, privilege, or \"hard work\". Many times, killing or threatening people was how it was acquired not too long ago - and it's not too late for that to happen again (see Ukraine). There are other ways to organize land-property rights. i.e. leased for some lifetime period, to be returned to the commons thereafter. There is only so much on this planet, and the richest individuals/corporations will gobble it up before too long; then what? reply prepend 3 hours agorootparentprevSociety is just a set of mutually agreed to rules. There’s no natural law for language, currency, culture, etc. So saying property rights are bogus, but body autonomy rights are ok seems like an arbitrary line to draw that makes society worse. We need some civil method of organizing and managing scarce resources, I think. reply fifilura 50 minutes agorootparentI am not saying property rights are bogus, but they are also not a god-given principle. This is why I reacted. There are lots of ways to draw the line. Allowing people to walk in a forest you \"own\" is one of them. reply digging 1 hour agorootparentprev> So saying property rights are bogus, but body autonomy rights are ok seems like an arbitrary line to draw that makes society worse. That seems obviously wrong to me. I can imagine a world without private land ownership that still grants people rights to privacy and autonomy in their home, even grants the privilege of open space around some of their homes (but since this is my imaginary world, ugly monocultured lawns aren't allowed). The benefits of such a world are that wealth is less arbitrarily concentrated, that municipalities can own the land they govern, that cities and states have the ability to adapt to changing populations without running into private land barriers at every turn. Like in all things, it would be a balance, just as today we have a balance (albeit an extremely lopsided one) between individual rights and governments rights. Eminent domain exists, so the right of an individual person to permanently own a slice of the Earth and keep or grow or ruin it for future generations is already not absolute. reply gottorf 39 minutes agorootparent> I can imagine a world without private land ownership that still grants people rights to privacy and autonomy in their home I dare say that you don't have to imagine, and there are past and current examples of societies that are closer to your vision than what modern developed nations allow for in terms of private land ownership. I think the median person is better off in systems that allow for private land ownership than not. Look at China: they don't have to deal with private property rights, so they're able to build tons of infrastructure to benefit the people (good!). But the same powers that let government do that are also used to horribly oppress minority groups like the Uyghurs (bad!). Of course, things owned by the people can be run for the benefit of the people if the people are composed of angels in perpetuity; but that, I'm afraid, will have to remain in the realm of imagination. ;-) reply sakjur 2 hours agorootparentprevProperty rights doesn’t have to be bogus for the right to roam to exist. Can you develop random land under the right to roam? No, that remain the exclusive right of the owner. Same goes for logging, farming, and depending on legislature a whole heap of other benefits to owning land. That doesn’t mean your country has to acknowledge a right to roam, it’s ultimately up to all legislatures to decide where to draw its lines. None of those lines are self-evident, though it doesn’t matter which rights the land owner cares to acknowledge, as that is the prerogative of the legislator. reply harimau777 2 hours agorootparentprevMany people view private property, and in particular land, as theft. The reasoning is that at one point private property was owned collectively by society so the only way that it could now have a single owner is if it was stolen at some point. Note that in this case, private property is separate from personal property like someone's house, car, clothing, etc. reply gspencley 2 hours agorootparentWhat do you mean by \"society\"? I could demonstrate that it is a word that is so vague as to be meaningless, but I will humour you and assume that you mean \"all individuals coexisting within an arbitrarily defined geographical boundary\" and I will shorten that to \"all of us\" for brevity, because I think (hope) that abides by the spirit in which you meant it. Theft, by definition, is the forceful transfer of property from the owner to a non-owner, therefore infringing upon the owner's rights. If \"society\" is \"all of us\" and \"all of us\" owns \"all property\" then the idea that recognizing and protecting an individual's rights to claim property is a contradiction. When I say \"right\" I mean a moral principle defining and sanctioning an individual’s freedom of action in a social context. So if \"society\" is sanctioning the freedom to acquire and maintain property, the \"society\" cannot have been \"stolen from\" as a result of \"society\" itself recognizing that right. reply hgomersall 12 minutes agorootparentThere's no ambiguity here and it's clear what is meant. At some point in the past, someone powerful enclosed a chunk of land and enforced that enclosure with violence. Hundreds of years of systematic enclosure of the commons in the UK denied many people the vital resources they needed to live and Right to Roam is the attempt to reverse some of that elitist legacy. reply hgomersall 42 minutes agorootparentprevHow did you get that land? Presumably you acquired it from someone legitimately. But how did they get it? At some point, it was enclosed and almost certainly enclosed to exclude others without their consent. It is the notion of private property that is the problem here, not problems you get by denying people their birthright. reply nathan_compton 1 hour agorootparentprevI'm curious where you think property rights come from. reply forgetfreeman 2 hours agorootparentprevYou are not alone. My wife and I managed to attain that dream in the last year. 20 heavily wooded acres, each of the \"neighbors\" lots range in size from 10 to 40 acres. Being able to go entire days without seeing a rando is every bit of what you think it might be like and I strongly encourage you to make the move as early in life as you possibly can. large acreage frequently takes significant investments in time and labor to get into a configuration that suits you, don't wait until you're so old that that work pushes the limits of your physical abilities. Best of luck to you! reply codexb 3 hours agoparentprevI think the problem is that there doesn't appear to be any plan to manage the land usage. In the US, there is tons of public land, but there are giant federal and state departments that manage it, and there are entire books of rules for how that land can be used. The public land is a collectively owned asset that is managed for public benefit. Areas can be closed off, or require permits, or limited to a specific usage. The \"right to roam\" seems almost completely unregulated with no power to manager or limit this public asset. It's a right without any responsibility. reply mauvehaus 2 hours agorootparentThere's certainly a responsibility to follow other applicable laws. You aren't allowed to litter or murder your hiking buddy on private property even if you're allowed to be on it. reply aramova 2 hours agorootparentprev> It's a right without any responsibility. How can you say something so controversial yet so brave? reply duped 4 hours agoparentprevSeveral states have spiritually similar laws, like how all beaches in California are public and it's illegal for private land owners to cut off access to them. I don't think anyone has won a personal injury lawsuit against a land owner for tripping over a root, but land owners have been sued for breaking that law and trying to create effectively private beaches. reply SkyBelow 3 hours agorootparentWould this be because the beach is deemed public, not private with a right to access it? To allow someone to sue a landowner on the beach would be confirming it is privately owned by the landowner, no? reply estebank 3 hours agorootparentThey are sued for blocking pre-existing access. Everyone, including those doing the blocking, acknowledge that the beach is public, but by blocking access they are trying to avoid people actually using it so they can enjoy it as if it were private. reply duped 3 hours agorootparentprevI'm not sure the specific details of ownership, but the gist is that in California, everyone has a right to access the beach. Private land owners aren't entitled to blocking access to the beaches, even across their property. This court case has been going on for years over this (1) and the only reason it hasn't been tossed out is the billionaire who owns the land keeps paying lawyers to appeal. (1) https://www.sfchronicle.com/bayarea/article/martins-beach-la... reply everforward 3 hours agorootparentprevThey mean on a person's way to the beach as they're crossing the private property. I.e. you park on the street and have to walk across a private yard to access the public beach, because there is no public walkway to get to the beach. If someone were to be injured while crossing that private yard to the beach, the owner of the yard could be liable. What happens on the beach is not the yard owners problem, because it's not their property and they have no duties related to it (other than not impeding other people crossing their property). reply codemac 3 hours agorootparentprevmartin's beach :( reply ledauphin 4 hours agoparentprevI'm interested to read more about the \"personal property liability\" thing in the US. I have never heard anyone explain why your example would expose you to liability. There are other things I can imagine, like unfenced swimming pools or open sinkholes that you knew about, but tree roots and general features of the land? Maybe there's a long history of case law about this. reply crazygringo 4 hours agorootparentBasically just think of it as a continuum from things you're obviously responsible for (a child drowns in your pool because you didn't put up a fence), to things you're obviously not (somebody fell and broke a bone because they tripped over a tree root in your acres of backyard forest). That there's a big gray area in the middle, and that somebody can sue you if they're injured in that gray area, and even if they lose it's still expense and stress and a time suck for you. reply bigstrat2003 3 hours agorootparentI would say that a child falling in your pool is something you're obviously not responsible for. The fact that case law in the US says otherwise is a shameful commentary on how broken the US legal system is. reply nness 3 hours agorootparentIf you are required by law to put a fence around your pool and include a child-safe door, and you fail to do so, and a child drowns — why shouldn't you be liable? (Although I think many from the US may interpret a \"fence around a pool\" to be an overreach of government regulation. But in Australia, \"barrier laws\" exist in every state/territory to avoid accidental drownings.) reply madeofpalk 3 hours agorootparentprevAustralia solved this differently - it's illegal to have an unfenced pool precisely because young children wander and fall into pools and drown. We understand that kids shouldn't die. If your fence is neglected or the kid was otherwise somehow able to get in, you're liable. Have a fence up to code, and you're not liable. reply arethuza 3 hours agorootparentDid a lot of kids die in pools before that law was introduced? NB I'm in Scotland so outside pools aren't a big risk but I also grew up in a small fishing village on a very wild and rocky coast with high cliffs and the idea of anyone trying to \"protect\" kids in that kind of environment seems very odd to me. reply madeofpalk 2 hours agorootparentThere's considerably less unsupervised kids running around rocky coasts with high cliffs than around neighbourhoods and backyards. Note that Australia also has plenty of coasts and does not mandate a fence around them all. reply crazygringo 2 hours agorootparentprevOf course. These laws don't just come out of nowhere. Kids drowning in pools is a real thing. reply gottorf 36 minutes agorootparentOf course, it's also a real thing that the home builders' and contractors' association lobbies to make every pool be legally required to be enclosed by a fence, which naturally needs to be built by a licensed professional. reply lambdaxyzw 4 hours agorootparentprev>obviously responsible for (a child drowns in your pool because you didn't put up a fence) Does this also count if you didn't invite the child and the terrain was clearly marked as your property? If yes, this is pretty surprising and non-obvious to me. Do i misunderstand something? For me, the obvious example is bobby trapping your property and hurting a fireman who came to put out a fire. reply crazygringo 4 hours agorootparentYes, it absolutely does count. You might indeed consider it non-obvious and surprising -- I certainly did when I first learned of it growing up here. Another classic example is that a thief can sue you if they fall through rotting floorboards on your porch and break their legs. But we've collectively decided, as a society, that property owners are not just prohibited from booby trapping their properties, but are required to actively maintain them in a safe condition according to reasonable standards. If there's something a reasonable person would know was a safety risk on their property, they'll be held liable if they didn't fix it and somebody injured themselves because of it. The thinking is basically -- kids will run around onto other people's property, people get lost, etc. We know kids go where they're not supposed to. Nobody should be risking injury or death just because of that, if and when reasonable safety precautions by the property owner could have prevented that. In other words, we live in a society, and we have a certain minimal level of active duty of care towards others. Owning a piece of property comes with rights but also responsibilities. reply stragies 3 hours agorootparentDon't at least the parents of the kid that drowned in your pool while trespassing on your land get at least a charge of \"criminal negligence\" against them? IANAL, but aren't kid'saren't kid'sAttempts to completely eliminate risk leads to miserable lives and societies. Covid response in certain jurisdictions was a great example of this. \"If it saves even one more life, it's worth it!\" reply gampleman 2 hours agorootparentprev> IANAL, but aren't kid'sbut aren't kid'sAnd 14+ years old that drowns in a pool for inability to swim is also something that should be blamable on the parents, not the pool owner. There's no law stating you need to teach your kids to swim. reply chrisBob 2 hours agorootparentprevBeing a parent is hard. I would say that half of the US thinks parents are the problem with kids these days and that a good kid should \"spend time outside in the neighborhood like we used to\", and then the other half will call the police if your child is out of sight because \"aren't kid'sBut apparently there's no duty of care towards oneself to not trespass into unknown conditions, to watch where you're going, or to supervise one's kids? No, there absolutely is. The key word is \"reasonable\", which I used intentionally and multiple times in my comment. Every time you dig a deep hole that might be hard to see, yes you're supposed to put up some kind of cones or warning tape or something. You're rightly not allowed to turn your yard into a booby trap, even if it's part of a construction process. (Of course you don't need to put something up while you're working and supervising -- but you sure do overnight while you're away from it.) We're supposed to watch where we're going, but we also expect to be able to walk across a yard without breaking our ankle because of a hard-to-see hole. Just like there's a big difference between a hole filled with water where a child could drown (that requires an actual physical barrier), versus a hole where they might fall in but break an ankle at best (cones are fine). And I don't know why you think a pile of wood is unsafe, that's fine. Why would you need a fence? Unless it's stacked so high you can easily push it over to topple it, but you shouldn't be doing that in the first place. You're trying to push examples to unreasonable extremes, when the whole point is the concept of reasonable safety. (FWIW, I happen to agree with you in thinking that tort law is not always the best way to implement this, that there should often be legal enforcement regardless of whether someone suffers an injury, and that injuries should often be compensated out of a general fund. It's tricky though because this would require a level of constant, regular government safety inspections of private property that not everyone is OK with. However, I think the general standard of reasonable safety is nevertheless absolutely correct.) reply mindslight 1 hour agorootparent\"Reasonable\" is a courts / legal industry weasel word that allows them to kick the can down the road not defining explicit requirements, which is what creates so much of the unknowable liability. This might be fine if we were talking matters of a few thousand dollars, but when we're talking about hundreds of thousands or more, creating a game of life-altering hot potato. And ambiguity would be understandable if we were talking about equitably judging personal action vs another personal action, but what we're talking about here is personal action vs an existing situation that was entered voluntarily. I do not think that it is \"reasonable\" that I'm responsible for any random uninformed person lackadaisically traversing my property as if it's some maintained event space they were invited into with a corresponding warranty of fitness. Yet the courts disagree, and so we're off to the races about what's \"reasonable\". Do I need cones for a drainage ditch/brook that has been around for decades? Do I need cones for the 6-8\" ruts due to driving through a part of my yard when it was waterlogged? Do I need cones or a fence for a tree that has half fallen down, resting on a neighboring tree, that I've yet to take down the rest of the way? Do I need cones for stumps of cut down trees? Do I need cones for items kept on the ground? Do I need warning signs about possible bees' nests in parts of structures? Do I need warning signs about the high number of ticks due to my letting the grass get halfway to a meadow? Beware of bear because it can hide in my overgrown bushes? These aren't unreasonable extremes, but actual concrete examples. The world is an inherently unsafe place. We create structure that makes tiny slices of it \"safe\". Creating a general requirement that the nominal owner of a chunk of land is ambiguously responsible for making it completely safe, even for those who were uninvited, just devolves into putting up one big fence and \"no trespassing\" signs while hoping for the best. This is precisely what this thread is lamenting. Also compensating out of a general fund would in no way require government inspections of private property. We're talking about extremely rare situations here, meaning this could be covered as-is in a statistical manner. In fact it already mostly is by private insurance, except when/until it isn't, with that reverse-lottery dynamic rearing its ugly head again. (The wood pile example is because climbing on them is unsafe, yet looks fun. It's essentially the same type of attractive nuisance as a swimming pool) reply cratermoon 4 hours agorootparentprevIn most of the US, the attractive nuisance doctrine applies, unfortunately. And nearly anything can be considered an attractive nuisance, or at least there's probably a lawyer out there willing to take the case and cost the landowner money. reply bbarnett 4 hours agorootparentQuite so. I get doubly annoyed when people have heated pools by lakes, the lake is clearly not fenced, but that fence had better be on your pool. And many pools have a shallow end, and many homeowners have long docks, which are in deep water. Yet docks aren't required to be fenced here. reply RRWagner 3 hours agorootparentprev\"can sue you\" is a very very important detail here. As I understand it, in the UK, the losing party in a suit pays legal expenses on both sides, which discourages \"let's just shake them down\" lawsuits. in the U.S. it's way too easy to get a contingency lawyer who knows anyone can sue someone else for anything and they'll have to settle for $$ just because it's cheaper than going to court to \"win\" against a weak complaint. I did some financial modeling on this years ago that gave a good prediction of when cases will settle in the U.S. tl;dr when the money given to the defense lawyer approaches the probable expectation of the loss you're trying to avoid. reply bluGill 3 hours agorootparentThe downside of loser pays is coorts will sometimes find against you in an obvious case and so only the rich can dare risk court. reply bigstrat2003 2 hours agorootparentIn the \"you pay your own cost\" system of the US, only the rich can afford to bring a case as well. And we have the added downside that only the rich can afford to defend themselves. I would much rather have the loser pays system, even though it isn't perfect. reply bluGill 2 hours agorootparentIn the us a lawyer will go to court on a you pay only if you win. reply arethuza 3 hours agorootparentprevThe other major downside of loser pays is that it makes litigation very difficult to stop once it starts - and lawyers, funnily enough, will always say that you have an excellent case encouraging people to start litigation.... reply SoftTalker 2 hours agorootparentA good lawyer will not take a case that you are very likely to lose, and he will advise you that you have no case. I believe a judge can also admonish or censure a lawyer who brings a frivilous claim into court? Not sure how often that happens. reply LorenPechtel 27 minutes agorootparentprevOpen holes that you know about are one of the issues with the Colorado peaks. There are old mineshafts up there. The owners put up signs, they get torn down. There's an interesting (slot canyon) local hike that's a good example. The whole situation is a mess, it's an old non-operating mine grandfathered inside what's now a national recreation area. Seems some years ago somebody's car was damaged (not exactly astounding, you need a 4x4 HCV and know how to drive it to get there.) Since it happened on private property their insurance tried to go after the landowner. For years it was posted as no trespassing although some groups still did sneak in. Then there was a period of a few years where it wasn't posted and we (local hiking community) believed it was accessible (nope--flash flood took out the signs and gate.) I went with one such group. There were a couple of mineshafts in the side of the canyon, imperfectly blocked by chain link fencing. Once glance inside was plenty to make me NOPE! it but some of the group squirmed in anyway. After seeing that I completely understand why the owner denies access. While I in general support a right to roam it needs to come with extremely strong liability protections. There are too many idiots out there who do not respect that nobody's combing the land for hazards, nor is it even possible as they may change. (There was a case a while back, trespassing IIRC biker got hurt because a flash flood had taken out the paved road he was on. Owner liable.) reply devmor 4 hours agorootparentprevI am not a legal scholar, but anecdotally a common theme in US law is that if you don't make obvious attempts to stop someone from doing something with your property (be it land, objects or intellectual property) then you are tacitly approving it. The most well known example is probably Trademark Erosion. Given this theme, it's not hard to see how a judge could rule that if you allow a lot of people to traverse your land, you are inherently maintaining a passageway and are thus responsible for ensuring its safety. reply bbarnett 4 hours agorootparentIn Toronto Canada, the Eaton's center, which people walk through to get to other streets, closes once per year for this very reason. reply dboreham 4 hours agorootparentprevFUD reply ben_w 3 hours agoparentprev> I think the main reason people get nervous about \"the public\" roaming their land is the liability and the personal injury lawsuit industry in the USA. If I let someone cross my land and he trips on a tree root and breaks his leg, now I'm possibly facing a lawsuit. I rather got the impression that it was rich people wanting privacy. As for lawsuits… I'm not sure how effective they are, but here in Berlin half the woods say \"Privatgelände / Benutzung auf eigene Gefahr!\" which means what you might guess without a translation. reply danaris 2 hours agorootparentIt's entirely possible that the reason this type of lawsuit is still a real thing is because of rich people recognizing that it also gets them extra privacy. (At least in part.) reply INTPenis 2 hours agoparentprevYou're right, I don't think the US overall system is ready for a right to roam. I come to this conclusion sometimes, one simple example is that most US suburbs are not ready for public transport because of the distances between each home. reply chasd00 1 hour agorootparentI have some land in SE Oklahoma the going rule that I’ve been told is if you cross an open gate leave it open and if you cross a closed gate close it behind you. However, I still make it a point to meet and shake hands with the owners of the land I cross. I live in Texas and, especially near the border with Mexico, you’re putting your life in danger trespassing on land, no matter how remote, without permission. reply techjamie 1 hour agoparentprevNot a lawyer, but an important part of why those lawsuits can happen is under the idea that you invited someone onto your property, therefore, you have a duty to ensure they're safe when they accept that invitation. Places open to anyone, like a restaurant or grocery store, have an implied invitation because they want everyone to come inside and spend money. So if someone jumps your fence and breaks their leg walking through your property, you didn't invite them there, you aren't intending your land to be open to the public, so the onus would theoretically be on the traveler to cover their own bills. They could sue anyway, sure. But they can do that right now without any legal changes anyway, it would just be under well established law and they likely wouldn't win. reply _DeadFred_ 37 minutes agoparentprevPersonally I like to let my children roam on my land unattended. I would not be willing to do this if random strangers were allowed onto my land. reply oooyay 2 hours agoparentprev> I think the main reason people get nervous about \"the public\" roaming their land is the liability and the personal injury lawsuit industry in the USA This is somewhat a solved problem in the US, what you're describing is actually nefarious behavior by cities and counties. I'll give an anecdote and I'm sure someone will come tell me if I'm wrong :) In Texas we called these \"public easements\". Back then in order for the city or county to establish a public easement they had to establish that there was a reason, they had to indemnify the area and some buffer around it, and they were obligated to maintain the land that they created the easement on. Sounds simple, right? Not so much. Cities and counties would often short change the indemnification, leaving the land owner on the hook for things they shouldn't be on the hook for. Sometimes the city would also have vaguely phrased policies like, \"all public easements must have sidewalks\" and those sidewalks would often incur some amount of damage to the landscape. Think about, for instance, a sidewalk going from a road, through someones property, to what is a dirt trail through the woods. Doesn't really make sense - but the city has a policy it's obligated to abide by! I think in general cities and counties could benefit from some non-court oversight to these processes with the public that don't need to involve expensive things like lawyers and are frameworked to understand the perspective of both the public and people giving access. There should also be a zero tolerance policy for underindemnifying the easement. Since you mentioned homlessness - I now live in Portland. Here's the way I deal with it: If you camp on public land around my neighborhood I expect you to be a good neighbor. Clean up your trash, no feces or urination in public, no leering/jeering/being creepy etc... I've generally provided water, heating devices, medical aid, etc to people that need it - the same way a good neighbor would. Some amount of people don't care about those boundaries though and will violate every single basic human expectation you can have. City code enforcement is generally not setup to handle disputes like this and neither are the police so it puts the public in really weird spots. I don't know how to solve that, but those folks aren't using easement rights. They're using public camping rights, which are entirely different and have more to do with camping on BLM and forestry land. reply kyleblarson 2 hours agoparentprevI live on a large property in a very rural mountain area in the US. My property abuts state land on 2 sides but we've never really had any issues with trespassers, likely because of the first sentence of SoftTalker's comment. Our area is one of the most popular mule deer hunting spots in the Northwest which seems like it could be problematic, but in my experience the hunters are extremely respectful of private property. It's also nice to be able to hunt mulies on my own property and not worry about errant bullets. It is a but unsettling in the last 2 weeks of October (regular rifle deer season) when the local grocery store literally fills the aisles with pallets of Busch Light and Fireball. reply DoreenMichele 3 hours agoparentprev1. Right to roam (in the US) might might actually reduce homeless encampments. In my firsthand experience, people are generally more sympathetic and supportive if you are just passing through as a homeless person. They may give you a ride and/or a small amount of cash without you asking, but the US is actively hostile to pedestrians in most places and you have zero right to pitch a tent overnight anywhere. 2. If homelessness is something you dislike, the primary root cause of homelessness is lack of affordable housing. This is a nationwide problem, not peculiar to the West Coast. So if you don't like homeless encampments, try to find ways to foster the existence of more affordable housing generally. It's a win/win solution that helps the homeless without rewarding or encouraging bad behavior and gets \"the homeless\" out of \"your\" face (not intended as a personal attack). And has zero relationship whatsoever to this issue. None. reply 5040 2 hours agorootparentSpeaking for myself, I'm actively hostile because of all their littering. Hard to be sympathetic when they toss all their garbage on the ground. reply justin66 2 hours agorootparent\"Actively hostile\" meaning what? reply 5040 1 hour agorootparentThink of it as an inner disposition. reply mauvehaus 2 hours agoparentprevI know if at least several states that have a recreational use law, the gist of which is generally along the lines of \"if you aren't being charged money to access the property, you can't sue the landowner for anything that happens to you while you're lawfully recreating.\" Kentucky has a law of this type on the books, and it helps a lot with access to climbing at the Red River Gorge. reply nick7376182 1 hour agoparentprevThe law could easily include a liability disclaimer. People just don't like other people, want their privacy, and want their \"I got mine\" land locked public lands. reply bpodgursky 4 hours agoparentprevIn the west it's more often that the public \"roaming\" their land is hunting for big game and trying to edge onto private land to find it. Hikers are inconvenienced but they aren't the norm. reply chaostheory 45 minutes agoparentprev> Also, what are they allowed to do? In Vermont, where they have something similar to free roam laws, a lot of people are having issues with hunters roaming their property. reply groby_b 3 hours agoparentprev> If I let someone cross my land and he trips on a tree root and breaks his leg, now I'm possibly facing a lawsuit. Don't worry, you're impacted by laws anyways. (My fave example is outdoor pools in LA, which by now require a fence. Never mind if there are never any children on the property, there might be at some point) > Simply crossing the land is one thing Yup. And it isn't just homeless encampments (which we could address, if we wanted to ever provide housing), it's also that a good chunk of people are, well, asocial assholes. See e.g. folks defacing public parks, destroying natural monuments fo",
    "originSummary": [
      "The \"right to roam\" movement in England seeks to reclaim public access to both private and public lands, as currently only 8% of the land is accessible to citizens.",
      "Activist Jon Moses highlights the history of land ownership in England and the need to reestablish the \"freedom to roam\" to reconnect people with nature and repair landscapes.",
      "The movement organizes events like group walks on private land to demonstrate the benefits of public access and addresses the historical suppression of common rights."
    ],
    "commentSummary": [
      "The \"right to roam\" movement seeks public access to private lands for recreation and education, inspired by Scotland's model, which limits motorized activities, hunting, and long-term camping.",
      "Critics in the USA worry about liability, lawsuits, and homeless encampments, while supporters believe these issues can be managed with proper enforcement and systemic changes.",
      "The debate highlights economic inequality, mental illness, drug abuse, and crime, discussing the role of social communities, property rights, and the need for legal reforms to balance public access and private property rights."
    ],
    "points": 279,
    "commentCount": 323,
    "retryCount": 0,
    "time": 1716382095
  },
  {
    "id": 40436651,
    "title": "Scandal Erupts at Regeneron ISEF 2024 Over Cheating Allegations",
    "originLink": "https://www.karlstack.com/p/exclusive-scandal-at-americas-top",
    "originBody": "Share this post Exclusive: Scandal at America's Top Science Fair www.karlstack.com Copy link Facebook Email Note Other Discover more from Karlstack Opinionated investigative journalism. Over 10,000 subscribers Subscribe Continue reading Sign in Karlstack Academia Exclusive: Scandal at America's Top Science Fair ''Honestly ISEF is probably going to sweep this under the rug unless it comes in the news. Someone needs to send it to CNN or something.'' Christopher Brunet May 21, 2024 87 Share this post Exclusive: Scandal at America's Top Science Fair www.karlstack.com Copy link Facebook Email Note Other 56 Share The Regeneron International Science and Engineering Fair (ISEF) is the world’s largest and most prestigious science fair. ISEF 2024 took place last week (May 11-17) at the Los Angeles Convention Center. https://www.societyforscience.org/isef/ Krish Pai won first place in the environmental engineering division, which came with a prize of $55,000 and the Regeneron Young Scientist Award. Pai cheated. Krish Pai, 17, of Del Mar, California, received the second Regeneron Young Scientist Award of $50,000 for his machine-learning research to identify microbial genetic sequences that can be modified to biodegrade plastic. His new software, called Microby, scans databases of microorganisms and determines which ones can be changed genetically to biodegrade plastics. In tests, he identified two microorganisms that can be genetically modified to degrade plastic at a cost he believes would be ten times less than traditional recycling. Subscribe Thank you for reading Karlstack. This post is public so feel free to share it. Share Pai is an intern at the University of Southern California. I had reservations about writing on a 17-year-old, so I consulted with a few more senior journalists to discuss the ethical considerations. Of course it's worth covering, major media outlets, like CNN cover science fairs all the time. 17 is old enough to get charged as an adult in every jurisdiction. Egregious conduct by 17 year olds is not excusable. Important to bust this for several reasons, one of which is that he's clearly on the fast track to a high level gig in neuroscience. Can we investigate this? If you won't, we will. — Anonymous journalist It's completely fine to publish on this. It's a big award, a prestigious organization—but you might angle it against the org, which allowed this to pass its process. — Anonymous journalist Think of all the other kids who got fucked over. — Anonymous journalist Plus, he is already outed extensively on Reddit, Twitter, and via a Google Doc currently circulating that thousands of people have seen. This anonymous Google Docs dossier is the source of my article and is signed by, ‘‘ISEF 2024 and future competitors, ISEF & Society for Science alums, Concerned researchers.’’ You can download the dossier here: Open Letter To Regeneron Isef 13.9MB ∙ PDF file Download Download As per the dossier: The ISEF winner student uses the following image as a key claim of the 100% plastic degraded in their presentation and more: However, the image boxed in red above is a falsified image taken from online, and has had mirroring performed in the hopes that no one would notice. The original image can be found here: https://www.mci.edu/en/news-filter-en/228-researchnews/4728-microorganisms-can-degrade-plastics and is from a European University Ulysseus lab testing Ideonella sakaiensis, a completely different organism than the one the Regeneron ISEF finalist used. The ISEF finalist very clearly labels the figure as: ‘‘Plastic degraded by discovered microbes’’, which is clearly false - a clear cut case of fraud. The ISEF Finalist is taking other people’s data for completely different research projects, and claiming it as their own. Original image from European University Ulysseus lab: The ISEF finalist flipped the image to generate the below image shown on their poster, presentation, etc: If you compare the shapes of the plastics as seen above, you will quickly notice the Regeneron ISEF Finalist’s figure is a mirror image of the past published image! This is blatant data fabrication and research fraud. The image was not only altered by mirroring it, but was combined with another image by the finalist. This goes to show this is not an accident — the Regeneron ISEF finalist intentionally manipulated the image to play it off as their own creation and result. They also placed an image of themself right next to this result, making it seem like it was their own data. In the spotting-academic-fraud business, we call this a slam dunk. But there’s more. The researcher also steals the wavelength vs reflectivity plot as shown (top right), making it seem like it came from their data: From the ISEF finalist’s ProjectBoard, the figure in question is in the top right. This figure is right next to a picture of themself to make it seem like it was their own collection and creation. Original source by Zhu et al., 2019: (PDF) Plastic Solid Waste identification system based on Near Infrared Spectroscopy in combination with support vector machine And much more. The dossier thoroughly documents numerous additional instances of theft of figures, exaggerated claims of novelty, misappropriation of a previous researcher's device, plagiarism, citation fraud, similarities to past winning ISEF projects, and potential scientific inaccuracies. It’s a brutal takedown. I find this evidence highly compelling; however, I am not including it all in my article to save space. I strongly encourage you to read the dossier yourself: Open Letter To Regeneron Isef 13.9MB ∙ PDF file Download Download Here's another example of a stolen image. This appeared in Pai’s slide and research paper; he claimed to have built a near infrared spectrometer: This image was taken from a Rasberry Pi article from 2021: [Pai] does not give any credit to the original creator of the device, or its images and acts like they “built a custom sensor” and “developed [the] tool.” This is very clearly an attempt to conceal the original creator … it is clear that the finalist did not actually build the device, and faked this part completely. Conclusion These actions, while serious, should not define Pai’s entire life. Everyone makes mistakes — Lord knows I did plenty of stupid, immoral things when I was 17 — and there is always the opportunity for growth and redemption. I sincerely hope that Pai repents and strives to become a more ethical person. In my view, he should still have the opportunity to attend a good university and build a long, accomplished career. However, his award should be revoked. The current situation is unfair to the other participants. The fraud is clear. The $55,000 prize should be given to the runner-up. This case highlights a significant oversight failure by the world's most prestigious science fair. The responsibility now lies with The International Science and Engineering Fair to take action and issue a statement. I anticipate that the mainstream media will cover this story later this week. Expect to see this story on CNN soon. Leave a comment Share Subscribe 87 Share this post Exclusive: Scandal at America's Top Science Fair www.karlstack.com Copy link Facebook Email Note Other 56 Share",
    "commentLink": "https://news.ycombinator.com/item?id=40436651",
    "commentBody": "Scandal at America's top science fair (karlstack.com)266 points by potench 16 hours agohidepastfavorite184 comments uneekname 15 hours agoI was a finalist at the 2017 ISEF and it was quite an experience. A lot of super smart kids there and we all had fun living it up in Los Angeles. There was a stark contrast between those of us who had designed our projects completely ourselves, and those who had significant mentors/lab affiliations. No hate to high schoolers getting valuable STEM experience at local universities, but Regeneron should do more to differentiate between these different projects. reply levi-turner 5 hours agoparent> There was a stark contrast between those of us who had designed our projects completely ourselves, and those who had significant mentors/lab affiliations. Love to see someone confirming my cynicism. In high school, a science teacher asked me if I were interested in doing something for the (then) Intel Talend Search. I looked up the previous finalists / winners and noticed that an overwhelming majority of the kids were in cities with top tier research universities (or did math stuff, those kids' locations varied a bit more). At that point, my spider sense told me that it wasn't worth the effort to try to compete without the backing / mentoring of a credentialed adult. reply georgeburdell 11 hours agoparentprevI never judged ISEF, but it was highly predictable that the kids with university mentorship made it from my circuit to there. Felt really unfair to the smart self-motivated kids who didn’t have connections. IMO the fairs should take a much harder stance on this, as it defeats the spirit of such competitions. reply isef_researcher 2 hours agorootparentPeople with connections have a leg up, but it's really not that hard to do it yourself. My parents were not researchers, we did not have connections, but I literally could emailed prof after prof showing my enthusiasm & knowledge I had gained already from my research until one decided to take a chance on me. I ended up publishing research with that connection I built which probably made a big difference for my college & grad school admissions. Most people just don't try this or give up too early or just didn't do the work to research on their own. reply teekert 11 hours agoparentprevHonestly, in my country (the Netherlands) this whole attitude changed within 1 generation. My parents left met largely alone with my school stuff. Now I hear all my friends complaining that their kid's school \"is so much work\" for them. Crazy right? When I ask them: Why help them at all (my kids are younger btw), they tell me that \"sure we can just not help them, they won't make it into university (but something \"lower\"), whereas other kids that get help/coaching will.\" It's a super bad trend because the parent won't be around after school (during their adult life I mean) and in a way these parents are also taking something away from their kids, namely the feeling that they made it on their own merit. My generation is also known as \"helicopter parents\" and this is just another expression of it. Maybe because we have less kids later and those we have (often after fertility treatments) are our princesses and princes? Maybe because we have more time? reply fransje26 10 hours agorootparentUnless something drastically changed in the education system the last ten years, I wonder where all that perceived workload is coming from. Because 10 years back, the homework load, as expressed by the post high-school students I was hanging around with, was significantly lower than in some other European countries. reply teekert 10 hours agorootparentDutch youth is spending an average (!) of 5 hours and 45 minutes per day on digital media. That's some serious amount of time, putting pressure on everything else. I was always told: 8 hours of work, 8 hours of sleep, 8 hours of leisure. Sure, you have eating and commuting etc. But people nowadays have to take those 5+ hours attention they're giving away from somewhere. reply fransje26 9 hours agorootparent> Dutch youth is spending an average (!) of 5 hours and 45 minutes per day on digital media. I was wondering if something like that was at play. Well, here are some hard statistics. Thank you for that. > That's some serious amount of time It's a worrying and disturbing amount of time. Now, the question is: is more time wasted on digital media than was wasted on TV in the past? And secondly: does the current TV time come on top of that, or has TV simply been displaced to other media, and is therefore fully included in the 5 hours and 45 minutes? reply rerdavies 9 hours agorootparentAnd thirdly: would anyone complain if children were spending 5 hours and 45 minutes a day reading books? Watching television was much more toxic than digital media. Network television spoon fed content targeted at a lowest common denominator to everyone, that content was consumed passively. It was horrible. Digital media allows active selection of content, and provides access to much higher quality information, if you want it. Back in the day, you were lucky if your public library had even one book on a subject you were interested in, and if it did, it was probably mediocre at best. And highschool libaries? Pfft. Brittanica? Pathetic compared to Wikipedia. Today, kids have instant access to all of human knowledge as digital media. It's a false equivalency to compare TV time to digital media time. reply teekert 8 hours agorootparentSure, my son enjoys high quality content like \"Life on our planet\", but he also has a Smartphone, which is much more addictive than a TV with, indeed, mediocre content. Moreover, all my friends were outside, on the streets, in the forest. Not so much right now. reply Cheer2171 6 hours agorootparentprevCome off it. These kids aren't spending that time reading Wikipedia, they're on social media platforms that optimize for engagement and gambling apps disguised as video games. reply notachatbot1234 5 hours agorootparentprevHave you seen what children are doing on their phones? It's not sophisticated discourse on all human knowledge or reading informative articles. It's digital heroin, ads and rage content. reply sickofparadox 1 hour agorootparentprevThere has to be a name for this absolutely divorced from reality whataboutism. At best, kids may spend one of those ~6 hours watching edutainment, but it is far more likely to be entirely spent scrolling on Twitter, Tiktok, or Instagram for microdoses of engagement dopamine. reply TeMPOraL 8 hours agorootparentprev> Unless something drastically changed in the education system the last ten years, I wonder where all that perceived workload is coming from. In Europe? At least around here, in post-Soviet states, 10 years ago is about the time the first generation of people, who experienced the \"good school -> good university -> good job\" phenomenon on themselves, had kids reaching school age. The rat race is barely picking up steam over here; we're lagging a couple decades of social \"progress\" compared to our Western counterparts. reply throwawaysleep 10 hours agorootparentprev> It's a super bad trend because the parent won't be around after school (during their adult life I mean) At least in North America, this has massively changed within a generation. By a lot. Virtually all of my social circle got help at a young age to buy big houses from their parents. Parents support kids for much longer. Kids live with their parents much longer. So yeah, the parents are now always there for people my age (mid 20s). reply wholinator2 8 hours agorootparentDamn, none of my friends can even afford a house now, and there's definitely no parental help with _purchasing a home_. That's such an insanely large amount of money. Parents might help with kids from time to time but monetary assistance ended the moment we first graduated. reply Karrot_Kream 10 hours agoparentprevHeh now wait until you realize what it's like for kids coming from areas near the poverty line. I entered ISEF at a local level on a whim, my science teacher knew I was his brightest but didn't know what to do with me, I borrowed a rundown pair of shirt/slacks my dad retired from job interviews. The experience left such a deep mark on me that even now in the middle of a very successful tech career I remember it. I did a project on perceptrons which I learned about at the local community college library (from a copy of Mitchell's Machine Learning!) because my parents knew it kept weird 'ol me busy and off the streets. Fun times! reply isef_researcher 2 hours agoparentprevNot saying this phenomenon of having connections isn't true, but also, kinda unrelated to the issue here, no? This kid plagiarized & had serious research misconduct. The fact that he has connections via his sister & dad is not the problem imo. reply cbanek 12 hours agoparentprevI remember when I did science fair a long time ago and this was still true. I managed to get a few levels to the state science fair, but that was as far as I ever got. It was all about the best humidity conditions for popping popcorn with the fewest un-popped kernels and maximum volume. Some of the other projects that I saw were just amazing. Even if the parents didn't help many of the top projects involved thousands of dollars of equipment that most students had no access to. And no, other than maybe $100 from my parents, they didn't help at all. reply puzzledobserver 11 hours agorootparentUnderstanding the effect of humidity on popcorn making sounds like a fascinating research project. Also one that I can honestly imagine a high school student undertaking. I would like to know how you controlled humidity, what your popcorn making apparatus was, what conclusions you drew, can it really make my popcorn better, so many questions. It seems so sad that we're taking projects that would be real fun---like yours---and comparing them to projects that clearly required massive amounts of infrastructure and external expertise. Now, again, both kinds of projects have their place: one to let students do genuine science, and the other for students to get an exposure to university research labs. Why again are we turning science fairs into competitions and handing out awards and using them to filter college admissions? How many science fair entries report on failed experiments or admit that they didn't obtain statistically significant results? The whole thing reeks of misplaced incentives. reply cbanek 11 hours agorootparentAww shucks, thank you for the kind words. I'd count out little dixie cups of 100 popcorn kernels each. Then I would weigh them and put them all in the laundry room, where the humidity was pretty constant for different time periods over a few months. I took another set of batches and heated them up in the oven for different periods of time. Then re-weigh to see how much moisture was lost from the kernels. Seeing that the amount of unpopped kernels and volume was pretty consistent between the fast drying and slow drying allowed me to predict what it might be like for years old popcorn by really drying out the kernels. I also did some batches in a high humidity environment using a box with a humidifier and seeing the weight gain from the moisture. Everything was popped in an air popper to give everything that was going to pop the time to pop. Then count the unpopped kernels! The overall conclusion is popcorn is probably good for up to a year, and you can do a lot better than the microwave bags if you buy loose popcorn. Generally more moisture helped, but there was a sweet spot range where there's enough moisture to have the steam make it pop big and open, but too much humidity made the casing soft and it would have just a kernel that was cracked but didn't pop. The hardest part was coming up with a precision scale that could do two digits of precision. Basically everyone that used them then were either drug dealers or people who bought actual lab equipment. Thank you for coming to my popcorn ted talk. Oh and I forgot, this was when I was in 5th grade. Good times. reply throwawaysleep 11 hours agorootparentprevNobody would enter the science fair if it didn’t provide a benefit to winning. reply Terr_ 11 hours agorootparentprev> Understanding the effect of humidity on popcorn making sounds like a fascinating research project. It may also manifest in microwaves which \"Popcorn\" settings (well, when it's not a fraudulent feature) where monitoring moisture changes can help detect when a bad is done. (The fall-off in popping noises being another metric.) reply throwawaysleep 15 hours agoparentprevI imagine this would just lead to it being more closely concealed. reply tomcam 13 hours agoparentprev> There was a stark contrast between those of us who had designed our projects completely ourselves, and those who had significant mentors/lab affiliations. Said with kindness and discretion. Parental \"help\", e.g. doing most or all of the work for a science fair entry, is an open secret among Asian communities. It has been for decades. I know firsthand that many Chinese-born parents don't even view it as at all wrong. reply WillPostForFood 13 hours agorootparentWe are family friends with a Chinese national who did pretty well in this year's ISEF. They spent last summer back in mainland China at a private science fair camp where they prepped and prebuilt most of their project for the year. They are very bright, did a ton of real work, but had a large paid team behind them supporting and helping. They almost could have professional and amateur divisions at this point. reply vsnf 12 hours agorootparentprev> Parental \"help\", e.g. doing most or all of the work for a science fair entry, is an open secret among Asian communities. This has been a meme/running gag in countless sitcoms and Sunday morning newspaper comic strips for as long as I can remember. Not the Asian community part, just the 'parents actually doing the work' part. The joke is typically about overly competitive middle class suburban fathers juxtaposed against their children who have better things to do than care about dorky school projects. reply neilv 12 hours agorootparentThe Cub Scout Pinewood Derby that I saw -- in which the kid is to carve a model car out of a block of wood at home, to race at an event -- they had wisely issued extra kits ahead of time, for those parents who would get a little too enthusiastic about helping Junior, and had separate races among the parents' cars. Of course, the stakes were much smaller than an award or school admission that potentially makes/breaks your child's brilliant future career. reply tromp 10 hours agorootparentAs featured in South Park episode \"Pinewood Derby\" [1] [2]. [1] https://en.wikipedia.org/wiki/Pinewood_Derby_(South_Park) [2] https://www.southparkstudios.com/episodes/oki0th/south-park-... reply esdf 9 hours agorootparentAlso a (not south park) movie! https://en.wikipedia.org/wiki/Down_and_Derby reply ToucanLoucan 5 hours agorootparentprevDo you need to have a child to get in on the parents segment of your cub scout's pinewood derby race? Asking for a friend. reply neilv 1 hour agorootparentI had the same thought. :) I don't know what they're doing now. (I saw it when my mom led a Cub Scout pack, decades ago.) If you wanted to organize some competitions in your city, the track I saw would be easy to build. You might want to design it to break down for storage in someone's garage, and to fit in the back of a couple SUVs. Maybe get city approval to host events as a block party or at a park. Or pre-arrange to donate it to a parish that hosts Scouts and has room to store it and occasionally set it up in their school gym or coffee&donuts hall. Today, you also have more RC vehicle competitions, and (over-media-ified) generations of battling homebrew robots. reply jszymborski 11 hours agorootparentprevThat's frankly an amazing way to stem the number of enthusiastic parents doing their kid's projects. I wouldn't have thought of it. reply alfalfasprout 12 hours agorootparentprevYep and this is a big problem. Because while the fraud in this article was clear cut… in many other cases there can be significant misrepresentation about the student’s actual novel contributions. reply strikelaserclaw 5 hours agorootparentprevdue to growing up in cut throat dog eat dog culture, a lot of people from asia don't really teach their kids about ethics and morality even whilst living in western societies, many times they encourage the opposite. reply UncleMeat 7 hours agorootparentprevMany many years ago I participated in a national history competition and went to nationals. The participants were almost entirely white, and there was absolutely this \"well its obvious the parents didi this\" thing there too. reply anal_reactor 12 hours agorootparentprevUnfortunately, many cultures don't see honesty as a value on its own. In Polish there's a word \"frajer\" which is an offensive term for someone who got cheated or didn't take advantage of a situation. The logic is that, if the society as a whole is dishonest, then it doesn't make sense to be a martyr recognized by no-one, and it's better to make sure you take care of yourself first. reply nsajko 12 hours agorootparentFun fact: that's actually a Yiddish word: https://en.wiktionary.org/wiki/frajer English translation: dope, sucker. As in there's a sucker born every minute: https://en.wikipedia.org/wiki/There%27s_a_sucker_born_every_... reply eigenket 12 hours agorootparentFun fact: according to the etymology I could find online it's actually originally a German word (meaning client of a prostitute) that was borrowed by Yiddish, then borrowed in turn by Polish from Yiddish and also ended up in a couple of other European languages. reply tokai 11 hours agorootparentYiddish is a German language. reply eigenket 10 hours agorootparentNot exclusively. It has elements from Hebrew and Aramaic (of course) as well as from various Slavic languages. A big chunk of it derives from High German but not all. reply gumby 5 hours agorootparentWhat tokai said was OK: English is also classified as a Germanic language even though it includes a lot of French words, not to mention Hindi etc. For that matter, a German word like „Dolmetsch“ doesn’t make German a Turkic language. reply eigenket 4 hours agorootparentI think calling something a Germanic language is a bit different to calling it a German language. I completely agree with your point about a \"Germanic language\" but I disagree about \"a German language\". reply phreeza 12 hours agorootparentprevSimilar word also exists in standard German, where it originally meant \"f*cker\" but now just means a man who buys services from a prostitute. reply rurban 11 hours agorootparentFreier is not F*cker, just someone who needs to pay for sex, and is more independent then reply phreeza 11 hours agorootparentNo it more likely comes from archaic \"freien\", which still is used for \"to marry\" but used to mean something slightly different ;) reply fransje26 10 hours agorootparentThey still use a variant of that word in Dutch: vrijen. With the old meaning.. ;) reply actionfromafar 5 hours agorootparentThe even older meaning is \"courter\". reply verisimi 12 hours agorootparentprevAlso, 'chutzpah' which has a sense of being proud of trying to get away with it, unashamed. reply azherebtsov 11 hours agorootparentprevReminds me about covid time math competition. It had to be taken online. Usually maximum score can be reached by less than a dozen of students, but when competition was online there were over 3000 math geniuses https://wiadomosci.onet.pl/kraj/koronawirus-gigantyczne-rozb... reply ggambetta 12 hours agorootparentprevUnfortunately very similar to Uruguay, where I grew up. One of the many reasons I haven't lived there for a while now :( reply piva00 9 hours agorootparentTo pile on top: also pretty similar to Brazilian culture where following the rules will be looked down as being stupid (since everyone else isn't abiding by them, you doing it is considered as self-handicapping). One of my least favourite features of Brazil and definitely in the top 3 reasons why I left the country more than a decade ago. reply fransje26 11 hours agorootparentprevIn Czech Republic, under communism, they used to say: \"If you are not stealing from the state, you are stealing from your own family.\" reply snickerbockers 14 hours agoprev>Everyone makes mistakes — Lord knows I did plenty of stupid, immoral things when I was 17 — and there is always the opportunity for growth and redemption. when did the definition of 'mistake' change to encompass actions done on purpose? a mistake is when your data is invalid because you did the math wrong, not when all your data is simultaneously false and plagiarized. i don't mean to disagree with the notion that his entire life shouldn't be ruined over one incident at a science fair when he's a teenager, but let's not make it sound like this is a careless blunder that could happen to anybody. reply physicles 14 hours agoparentThose stupid, immoral things that the author did at 17 were also done on purpose. The mistake is in the reasoning that led to the decision to do the action. Pai's mistake was _deciding_ to commit research fraud, and then doing it. reply halayli 14 hours agoparentprevA mistake is not exclusive to actions, it encompass judgement as well. Misguided actions start from a misguided judgement. reply smogcutter 14 hours agoparentprevMost mistakes aren’t accidents, plenty of accidents aren’t mistakes. reply hn_throwaway_99 12 hours agoparentprevThe definition of mistake has always included actions done on purpose. Consider the sentences: Getting on that Boeing jet was a huge mistake. The worst mistake I ever made was voting for Trump. Having an intern give him a blowjob was the biggest mistake of Clinton's career. In all of those cases the action was done on purpose. You are confusing the definition of mistake with the phrase \"by mistake\", i.e. \"I ran rm -rf by mistake\", which means unintentionally. reply throwaway48476 7 hours agorootparentYou are confusing mens rea and actus rea. reply edanm 10 hours agoparentprev> when did the definition of 'mistake' change to encompass actions done on purpose? It didn't change, it's always been that way. From Google search: > an action or judgment that is misguided or wrong. > Example: \"coming here was a mistake\" reply bimguy 12 hours agoparentprevI believe you're confusing \"mistake\" with \"accident\". reply throwawaysleep 14 hours agoparentprevWe generally consider anyone under 18 now to basically not have capacity to make decisions. Therefore anything they do that is bad is a mistake. reply bee_rider 13 hours agoparentprevI think it features in the song “we are the champions,” so before 1977. I think “I’ve made mistakes/people make mistakes” has been used to euphemistically describe a lapse of judgement for a really long time. reply ggambetta 12 hours agorootparentOr even better, the passive form, \"mistakes have been made\" :) reply relwin 14 hours agoprevMy kids attended the same high school district that this student's school, Canyon Crest Academy (CCA), is part of. My youngest has friends that attended CCA and I asked him once why he didn't want to attend (it's an open school district) -- his reply is \"all they do is study for AP tests.\" So I'm thinking there might be other pressures (i.e. parental) to perform, and this student may have responded in a desperate fashion. reply JKCalhoun 5 hours agoparentRaising my kids in the Bay Area, I certainly am aware of what I call unhealthy competitiveness in even the public schools. If you think this is an unfortunate way to raise a child — in that kind of overly competitive environment – then there is a lot of blame to go around. The difficulty of getting into a UC school being an obvious place to start. reply acheong08 15 hours agoprevOne of the details that strike me is that the cheater comes from a fairly wealthy background and has no need for that prize money at all. They have much more to lose than gain and this doesn’t seem rational at all. reply onetimeusename 14 hours agoparentIt's for university admissions. It's not that surprising. There's a lot of fraud in admissions. I've met students who have given TED talks on subjects they have no idea about, written science books with fake reviews on Amazon, etc. all for admissions. reply oefrha 14 hours agorootparentThere are a lot of firms specializing in designing bullshit extracurricular activities for rich snobs. As long as you’re willing to pay it’s not hard to have UN photo ops, TED talks like you said, philanthropy in Africa, etc. under your belt, all low risk activities that are usually good enough for Ivy League. It’s interesting this guy chose to fake one of the few things people might actually bother to scrutinize. He’s probably looking further than college, though. reply ChrisMarshallNY 5 hours agorootparentprevWasn't there a recent scandal, about celebrities gaming the system to get their kids admitted to top-tier colleges? I seem to remember folks getting jailed/fired/fined for that. reply saagarjha 15 hours agoparentprevThey don’t need the money. They want to win so they can get into college. reply armchairhacker 14 hours agorootparentGoogling his name brings up this article as the third result. Someone in whatever college he has been accepted to will surely discover and spread rumors, which he can’t really defend against because all the evidence supports that he did it. If he tries to publish anything, people will see his name and immediately question its legitimacy. If he gets an offer and the employer finds out they may rescind it because they can’t trust him. Maybe he won’t outright get his admission rescinded, but I can’t see how a prestigious college is worth more than an intact reputation (I’m sure that without this award he still would’ve been accepted to a great community college at worst, and with his research internship assuming good AP scores, he may have even got into his top choice). reply krisoft 10 hours agorootparentSure. The gist of what you write is true. Being caught cheating harms his future prospects. You are thinking that now because he was already caught. But when he decided to cheat he didn’t know he will be caught. Probably he either estimated the chanches of him it wrong. Thinking perhaps that he will do a better job with the cheating, or that nobody looks that hard. Or he assumed lower consequences. Perhaps assuming if they catch him they just won’t give him the award, as opposed to making a big deal out of it. reply throwaway48476 7 hours agorootparentIf the chance of getting caught is low enough the expected value of cheating is positive. reply acheong08 14 hours agorootparentprevIs college that important when you’re already rich af? There are other channels to get in without risking reputational ruin. reply navigate8310 13 hours agorootparentThe boy cones from an Indian background which is highly competitive and looks down on it's own people if they are not \"successful\" career wise reply Reubachi 3 hours agorootparentHe comes from a rich caste family, which is on the opposite side in regards to \"introspection and external perception\". Indian society is unlike any other and cannot be simplified, even within the individual castes. Of course I do not know this individual and their mindset concerning \"motivations\", but I find it very unlikely that these \"mistakes\" are due to entrenched group morays shared among poor/dalit castes. reply dagw 11 hours agorootparentprevIs college that important when you’re already rich af? A lot of people care about prestige and reputation at least as much as they care about money, especially people who have money. For many people being rich isn't enough, they also have to be seen as smart and successful. reply JKCalhoun 5 hours agorootparentprev> without risking reputational ruin Feels a bit like, \"Hope this impresses the judges ... but not too much.\" Like I imagine the way card counters in Vegas must feel. I want to win, but not so much I attract the attention of the pit bosses. reply WillPostForFood 13 hours agorootparentprevMore important than ever. Rich and your kids didn't get into the Ivy you were graduated from? Shameful. reply notjoemama 14 hours agoprevIn reading this, I am reminded of a YouTube video by CGP Grey about how anger is more viral than any other emotional reaction online, including love. But then I think, isn't this one of those times where at least some level of annoyance is justified? Except, there's nothing I can do about it. Does making more people aware, that can't do anything about it, improve the situation? Or is awareness pointless because of how transient it is? And, what if the next great filter isn't great, but a series of smaller exponential filters pulled into a tight timeframe by the advancement of technology? I probably just need more sleep. reply isef_researcher 1 hour agoparentThere is a reason to increase awareness - to put pressure on Society for Science to take action. So far they still have not made a public statement, have disabled their YouTube comments etc, and seem to just be waiting for this all to blow over. reply JKCalhoun 5 hours agoparentprevNot anger, justice. Most of us crave justice porn, and only when I am feeling in my most generous, zen-like mood can I find fault in that. reply tonymet 14 hours agoparentprevAnger is an appropriate reaction to dishonest behavior reply kadoban 14 hours agorootparentThe anger is appropriate for the circumstance, maybe. Seeking out things to make you angry (aka social media in general) is not healthy. reply rblatz 13 hours agorootparentprevIf you or someone you know was in the science fair, or you were involved with it somehow. Maybe if you users just really invested in science fairs, those are all reasons to be angry. But if you are like most, this has no impact whatsoever on you or your life. At most this should provoke a shrug, a head shake, and a “that’s not right, I hope they do something.” From the vast majority of people. reply npinsker 13 hours agorootparentI think it’s fine to be angry at the world when frauds are rewarded and celebrated. It’s not a victimless crime, and if you wish for the world to be a meritocracy, it feels like a slap in the face. reply dataflow 11 hours agorootparentprev> But if you are like most, this has no impact whatsoever on you or your life. Uh, how do you so confidently say this? Do you have a crystal ball that can see into the future? You have no idea what the honest researchers might've gone on to accomplish in the future as a result of winning these competitions. One of them might literally change the world (including your life) for the better if they don't get discouraged along the way through witnessing fraudsters win like this. That's literally the point of these competitions -- to increase the chances of someone making a world-changing discovery or invention down the road. You should absolutely be angry if some of the brightest minds that could solve your current problems are actively being turned away from doing so. reply dataflow 15 hours agoprev> The image boxed in red above is a falsified image taken from online, and has had mirroring performed in the hopes that no one would notice. This probably won't happen in the future... because future competitors will learn from this mistake and know to run their image generation through AI so that their images are \"novel\"... > Don't mentors have to sign off along the way? That part I don't get... Can someone explain this? Is it plausible the mentors genuinely had no idea? reply pstrateman 15 hours agoprevThat's not only scientific fraud, it's real felony fraud. Maybe community service equivalent to 50,000.00 at federal minimum wage would sort him out. reply thriftwy 12 hours agoparentThe child is nothing to be blamed for, it is a 100% problem of the organizers. For a 17 years old, even throwing together such work is already an worthwhile result. Teens is a golden age of compilation and remixing. reply CaliforniaKarl 12 hours agorootparent> The child is nothing to be blamed for, it is a 100% problem of the organizers. I am surprised that the organizers did not catch this, though I don't know enough to know how much time the organizers had. > For a 17 years old, even throwing together such work is already an worthwhile result. Teens is a golden age of compilation and remixing. For kids, in general, if one kid makes a claim (\"I made this,\" or \"This game cartridge is mine\") that turns out to be false, there is generally some sort of comeuppance. That could be as simple as the kid losing respect within their peer group, or it could be as serious as parents being informed about the kid commiting a petty crime. This is important, because it instills society's values (such as they are) in the child. For example, what if kid A steals a game cartridge from kid B, and then kid B retaliates by shooting and killing kid A? That response is generally frowned upon, in most parts of the world. In my opinion, it would be fine if \"the child\" was presenting a poster showing the current state of research in microbial recycling of plastics. That's a cool thing for a high school senior or college freshman to do. But to take existing research (stealing), manipulate images (lying), and cast it as their own work (stealing and lying), on a national stage, that requires an appropriate comeuppance. reply thriftwy 11 hours agorootparentMy point, if you can't get adult professionals with wages admit they fk'd up, there's zero and even negative expectations of unpaid teenager contestants. And that's what I am seeing happening right now. You have unacceptable amount of leniency towards organizers, in \"don't know how much time did they have\". They should've had enough to scrutinize their short list. Perhaps it all looks like the winning submission. reply Xelbair 5 hours agorootparentprev>The child is nothing to be blamed for, it is a 100% problem of the organizers. If I,as a child, stole 50k USD, surely i would get thrown into the jail, or juvie. >For a 17 years old, even throwing together such work is already an worthwhile result. Teens is a golden age of compilation and remixing. There's difference between remixing and outright stealing with intent to deceive, for monetary gain. Even more so when one's under university tutelage, and comes from well off family - where 50k USD matters way less. reply thriftwy 4 hours agorootparentThis case only became severe because they chose to award these money to compilated work with no attribution. If they didn't reward this specific work it would be a non-issue. So by induction blame lies on the offering part. Doing subpar work is not stealing. Come on, we've been through \"intellectual property\" already and now this. reply isef_researcher 1 hour agorootparentprevIf his project was just shoddy scientifically, that wouldn't be an issue. I'm sure 90% of the projects are like that. He committed deliberate fraud, stealing other people's work (including past kid winners!), and won 50k for it. That's not \"throwing something together\" it's deliberate cheating. reply distances 11 hours agorootparentprev17 year olds are of course fully responsible for their own academic claims and creations. You would get expelled from many high schools for much smaller cases of plagiarism. reply thriftwy 10 hours agorootparentDo you really get expelled from high school in the USA? Isn't that basically mandatory education? And for plagiarism? I'd see some evidence. reply dagw 10 hours agorootparentBig difference between public and private schools. Getting expelled from a public school is pretty hard, you basically have to do something seriously illegal involving guns and/or drugs. Getting expelled from a private school is an entirely different thing. They can expel you for a lot of things, and basically anything that makes the school look bad in the eyes of prospective future 'customers' is high on that list. Especially among more prestigious schools. reply distances 9 hours agorootparentprevI don't know, my anecdotes would be from a private school in Europe where a family member is a teacher. They take plagiarism seriously, but also can expel students a lot easier than public schools can. reply thriftwy 9 hours agorootparentThe point being is that plagiarism at a known private school that you pay good money for and hope to rely on, is something you will give much more consideration than sending work to a science fair to see if it will stick to a wall or not. Neither are particularly good behaviors, but as a \"computer guy\" I think your public-facing API (science fair admissions) should validate its inputs. There are people out there who send know malicious requests to endpoints, you know. Instead of blaming an underage student I'd reevaluate all of their prior nominations. Chances of dragons being there. reply distances 8 hours agorootparentI totally agree that the fair failed badly at validating the submissions. > The child is nothing to be blamed for, it is a 100% problem of the organizers. This is what I disagree with. A 17 year old is not an innocent child that mustn't be blamed. At this age (and already earlier too) there has to be real consequences for plagiarism, proportionate to the case. Plagiarize coursework? Fail the course. Cheat in final exams? Fail the exams and retake the year. And so on. reply thriftwy 8 hours agorootparentSo let him fail the science fair and probably be banned from entering this science fair and probably other ones if they're federated. If that's not his first participation then the previous ones should also be reevaluated. But that doesn't have much point since he's growing out of them already. And I don't think it's fair to pursue him further (other than existing bad publicity) since people do stupid things all the time and the idea of limited liability exists for a reason. reply JKCalhoun 5 hours agorootparentprev> Teens is a golden age of compilation and remixing. Yeah, in the arts maybe, but not in the sciences. reply thriftwy 4 hours agorootparentYou have enough life experience to know the difference. Do teens? Are you confident in that? Are you a child psychologist? Do you have any? How many papers did you publish? reply JKCalhoun 4 hours agorootparentI'm only saying you don't excuse it because they are teens. reply sgerenser 15 hours agoprevSounds like someone is a member of the Dan Ariely school of science. There might be a professorship at Duke in his future. reply throwawaymaths 15 hours agoparentHome hellinga also at duke! reply liendolucas 10 hours agoprevIsn't this equally embarrassing for the people that decided to award him? I mean just looking at those images or even imagining the sort of research and equipment that would take to achieve something like this, shouldn't have raised red flags easily? reply mike_hearn 9 hours agoparentSure, but it happens all the time with \"professional\" science too. This guy did nothing that isn't seen every day in the literature. The reason these people didn't check the claims is because they have an extremely strong culture of never checking any claims. If they did they might discover the claims were false, and then they might feel obliged to attack a colleague who realistically will be protected by their institution, and who might be a peer reviewer or even colleague in future. So, ignorance is bliss. reply jerf 5 hours agoparentprevConsider the distribution of the entered projects. Due to the selection process (think evolution-style selection rather than \"human judging\" selection), all the projects, whether purely-student-driven, student-driven with just a dash of parental help, half-and-half, and the student basically along for the ride as the parent runs a project, are in one big pile. Is there going to be a bright, sharp dividing line? Especially in light of the fact that quality is only going to be loosely correlated with external help? Perhaps this is an unpopular call but my personal opinion is that the whole idea of a \"national scale\" science project contest is irredeemably flawed and the correct answer is simply to discard it. It is a common flaw in thinking, often expressed by many commenters zealous to \"correct\" other people, that if you can't draw a bright sharp unarguable line between the various elements of a group of some sort that you can't claim the group \"exists\". This is nonsense; almost every practical grouping scheme will always have borderline cases or exceptions. But there does need to be some sort of actual grouping, or some sort of relatively objective way to sort and categorize the elements, that is accessible to the sorter. In this case, while from the objective divine perspective maybe we could create an objective standard for who got \"too much help\" to be qualified, there is no conceivable world in which the contest judges could ever get sufficiently accurate information to be presented with anything other than a very smooth gradation that they simply will have no handle to make a correct decision with. So the incentives will always be to get as much help as possible and then have human-intelligent agents doing their best to fool the human-intelligent judges, and that's just a hopeless situation. Of course, the contest will not be shut down. But what can happen and what may well happen is that it will get more and more embroiled in controversy each year as the game-theoretic local optimum approach for the contestants each year becomes more and more to accuse their competition of being \"too helped\" and thus take out the competition until it is simply a farce. This is the worst game-theory case for cooperation; very limited repetition of plays by any given participant, most likely one, so no reason to care about the integrity of the contest for next year when they won't even be participating most likely. reply nsajko 13 hours agoprevSource, \"Open Letter to Regeneron ISEF\": https://docs.google.com/document/d/1e4vjzp6JgClCFXkbNOweXZno... reply refurb 11 hours agoparentWow, the entire project was basically copy pasted from other work. What gets me, is there are clear scientific errors (talking about RNA fragments but should have been protein fragments). This would have been immediately caught by someone with a basic knowledge of the field. How do they judge the projects if not having subject matter experts closely review them and the results? reply thaumaturgy 13 hours agoprevThis is pretty similar to some fraud in professional science that's more common than it should be. A few people have started to make it a hobby to detect copy-and-pasted and altered images in published research: Fabrication discovered in prominent Alzheimer's research: https://www.science.org/content/article/potential-fabricatio... \"Sleuths\" uncovering fraud and getting retractions for thousands of papers: https://apnews.com/article/danafarber-cancer-scandal-harvard... and https://www.newyorker.com/science/elements/how-a-sharp-eyed-... and https://retractionwatch.com/2022/07/22/papers-in-croce-case-... So I'm dismayed but not surprised that the incentives driving fraud in research science are trickling down into pre-college science fairs. A cynical person might conclude that we're just training the next generation of scientists to be better at fraud. reply mihaaly 11 hours agoprev> These actions, while serious, should not define Pai’s entire life Too late for that. Very late. Unluckily his mind is set on pretending too much. Which is ubiquitous and actually encouraged in life to a great degree (not like this should be an excuse for adapting). What is not late is to seek a different career in life. Be an influencer, praised youtuber or a political adviser perhaps, but the science world needs much different mindset. His reputation is annihilated by himself beyond repair anyway. The useful side of the story: be it a learning experience for the others. reply ipython 13 hours agoprevMany, many years ago I participated in ISEF, so this is personally disappointing to me. I'll echo some of the sibling comments about the difference between kids who did the project alone versus parents/lab mentors who ... ahem ... contributed significantly to the project. In contrast, my project was entirely self-made and therefore not very impressive, but it had some gimmicks in how I presented it which managed to impress judges at the school and regional levels, enough to send me to ISEF. ISEF was an amazing experience, especially as a kid from a school that was nothing special. Our school was so excited that they hired a public speaking specialist to work with me to prepare. Looking back, that training in public speaking directly contributed to many successes in my career decades down the line. Plus the experience of going to ISEF still brings back positive memories. I never felt like I belonged - there were some amazingly smart kids there - but the social camaraderie and the ability to meet kids that thought it was cool to be smart was eye opening. As far as \"making mistakes when you're 17\" - yeah, I made mistakes then too, but I certainly paid the price for them. Especially when you make conscious decisions to defraud and falsify, if these allegations can be proven. There should be serious consequences for this. reply fransje26 9 hours agoparent> Especially when you make conscious decisions to defraud and falsify To earn $55,000... reply poulpy123 8 hours agoprevI'm baffled by the idea of making science competition with so much prize money for teenagers. For me it's antithetic with the goal of scientific research and can only fail in the long term. As a side note, the real responsible here is not the tennagers, but the organizers that didn't manage to catch a fraud so obvious reply strikelaserclaw 5 hours agoparentmost of these teenagers already come from upper middle class (professional parents) backgrounds, they don't need the money, they know that winning it is a guaranteed admission to MIT or Harvard. Getting admitted to top schools today is an order of magnitude tougher than it was even 10 years ago. reply xnorswap 5 hours agoparentprevThe amount of prize money shocked me too, I put it down to a culture I don't understand. See also $50,000 prize money for what's called a \"Spelling Bee\": Asking children to spell words correctly. I feel so far removed from understanding that culture that I feel like I can't criticize it. reply throwawaysleep 15 hours agoprevI wrote an earlier reply to someone about how all I learned from the several mandatory ethics courses is that the people who cheat tend to be winners even after their punishment, if any. I bet that even after all this, that kid will still be better off having cheated than not. reply capybara_2020 15 hours agoparentI am curious, what is the definition of winners here? Do they make more money or do they invent more successful products/ideas or is it something else? reply throwawaysleep 14 hours agorootparentMoney, social acceptance, access to desirable partners, positions of prestige, etc. All the nice things we wrestle over in life. Anything you compete for except the “he was a good man” phrasing in obituaries, the cheaters usually get to have. Even if caught. Not cheating outside of a few really heinous crimes such as murder (killing your science fair opponent wouldn’t be a winning strategy if caught) is an altruistic action. reply JKCalhoun 5 hours agorootparent> Not cheating outside of a few really heinous crimes such as murder (killing your science fair opponent wouldn’t be a winning strategy if caught) is an altruistic action. I can only imagine someone trying to justify cheating would say that. Cheating on your spouse is okay? Not cheating on your spouse altruistic? That concept is alien to me. I don't understand someone having no self-respect or being completely numb to how others feel. I know some exist, but I can't comprehend. If there's \"winning\" in life it's through living a good and happy life. Some time past our teenage years I think all but the most self-adsorbed people realize that being kind and respectful to others also contributes to our own happiness. reply rendall 14 hours agorootparentprev> Not cheating... is an altruistic action. Wow that's dark. reply fattegourmet 13 hours agoparentprevI had an ethics (philosophy) course in uni and I don't think _ethos_ is about winning. https://en.wikipedia.org/wiki/Ethos reply throwawaysleep 10 hours agorootparentIt isn't. But that is what makes it irrelevant to the target audience. reply hilux 14 hours agoparentprevIndeed - last I checked, Kaavya Viswanathan was doing just fine. Even had a stint at white-shoe law firm. reply paulcole 15 hours agoprevWhen I was 16 I did a project on whether plants could be used to remove heavy metals from soil. I don’t know why I did this but I did a nitrate test on the plants (because I had been putting lead nitrate into the soil) and drew the conclusion that it must’ve worked. About 2 weeks before the city science fair I realized my error (none of my teachers had said anything). So in an attempt to lose, I made my backboard as bad as possible. I didn’t use scissors or glue, I just tore the paper and used masking tape. Long story short, I have no idea how, but despite my best efforts, I won the city science fair including an HP-48 graphing calculator and a trip to the state science fair. At the state science fair my backboard (you had to use the same one as the city contest) was mocked by much more studious 8-year olds. I found out that teachers weren’t allowed in the exhibition hall so I just abandoned my space and went to the beach. I did not win the state science fair. reply jmercouris 15 hours agoparentwhy would you try to lose instead of just writing about the null hypothesis? why even make a submission? reply rileymat2 15 hours agorootparentI am not sure it shows the null hypothesis either, unless I am missing something because it was not chance or sampling error. reply paulcole 6 hours agorootparentprevI was 16 and didn’t want to do any more work. My school was making me submit my project. In hindsight, obviously there was a lot I could’ve done differently. Also, I didn’t know what a null hypothesis was then. TBH I still don’t! reply tocs3 15 hours agoparentprevDid you tell the judge or could you get a sense of what they thought? reply paulcole 6 hours agorootparentI probably talked to 3 or 4 judges and explained to all of them exactly what I did and never lied. But I also wasn’t forthcoming about the error. I just explained the experiment and the result. None of them asked any questions that I couldn’t answer. I remember I was sitting next to a girl who had an amazing project. At the end of the day they called her name for 2nd place and I remember thinking, “Wow, who beat her?!” And then they call my name… I thought it was either all a mistake or that maybe the judges thought I was mentally challenged on account of my backboard and it was a pity situation? In hindsight, perhaps an emperor has no clothes situation where everybody sees the error but nobody wants to be the first one to call it out? reply blackeyeblitzar 15 hours agoprevScience fairs always have hints of fraud around them. Many of the children putting out incredibly advanced research, beyond their capacity, are benefiting from their parents’ expertise, or friends of family, or access to labs, and such. It’s not talked about much but has been an issue for decades. As a side note, the criticism around this incident seems to have some racial tones. It’s weird to see tweets referring to participants as the “Indian guy” and “Chinese guy”. Or is that just me? reply acheong08 15 hours agoparent> As a side note, the criticism around this incident seems to have some racial tones. Noticed that as well. I feel like it has unfortunately become somewhat socially acceptable to be slightly racist against Indians and Chinese people due to a mix of politics and demographics in tech. reply shrubble 14 hours agoparentprevIt probably does. For every solid guy from Indian background who was living in the USA that I worked with, there were always at least 5 horror stories involving e.g. some back office tasks that involved one of 3000+ people working in India (at a previous company of > 30k total employees). It's not fair to the guys in the USA for sure. reply luyu_wu 15 hours agoparentprevAgree with the last bit. This is the perfect way to start racially stereotyping. For the first bit, unfortunately that's hard to control and is actually talked about quite a bit (speaking as a HS student). I would be interested in alternative suggestions to limit these advantages, but I don't think it's realistically possible. reply deely3 12 hours agoparentprev> Many of the children putting out incredibly advanced research, beyond their capacity, are benefiting from their parents’ expertise, or friends of family, or access to labs, and such. Do we have a solution for this, and do we need a solution? Lets go nuts, lets go hyperbolic: should we ban kids from learning from their parents? reply jjeaff 11 hours agorootparentthey aren't necessarily learning anything from their parents. their parents are doing most of the work. reply tbyehl 5 hours agoparentprev> Or is that just me? Click around on Karlstack some more. reply nullc 14 hours agoparentprevI don't know if it's still the case, but decades ago when I was at ISEF (and somewhat fewer years ago when I judged...) the judges would get to talk to the students. reply geomark 11 hours agorootparentI judged at some robotics competitions where we interviewed the students. It was usually immediately apparent if the student had not done the work, and as a result they would not receive an award. I think that's the only way to do it. The student must be able to describe the work they did. A fraudster might still get through with sufficient coaching. reply throwawaysleep 15 hours agoparentprevDefinitely racial tones. Asian countries are frequently accused of copying, cheating, and stealing intellectual property from others, so it matches what people assume about members of those races. reply miningape 10 hours agorootparentI think this comes down to \"face culture\" where its \"better\" to lie and be caught than be forthright from the beginning. The people used to / raised in face cultures think this is normal and acceptable behavior (because: hey everyone else is doing this I should too - If I don't I will fall behind), whereas those from more \"honest\" cultures tend to despise the behaviour as it makes work less trustworthy and tends to give an unfair advantage. Notice how the reason for and against doing this is the same: unfairness. Face cultures tend to embrace systemic unfairness as \"fair\" whereas non face cultures tend to call it as it is. What's interesting is that countries \"with a face culture\" tend to have higher levels of corruption and unfair business practices but also much higher levels of societal cohesion and trust. In other words, the more likely you are to save face the less likely you are to live in a democracy. And the less likely you are to trust institutions/organisations the more likely that they are trustworthy. reply throwaway48476 7 hours agorootparentThere are plenty of examples in the recent past of high social trust countries without a face culture. reply zachlatta 15 hours agoprevIt's frustrating that we encourage fraudulent behavior for the college application process. I blame the judges, and college admissions departments. It orients the entire USA public education system around training sociopathic behavior into teenagers. We tell young people the best way to get ahead in life is through exaggerating. Then we train them to do it in their college essays and extracurriculars. Gross. reply WillPostForFood 13 hours agoparentWe need lottery based admissions. Let schools set a minimum test score, and anyone over that goes into lottery for admissions. Kill off essays, extra curriculars, club sports, summer programs, AP tests, Legacy admits, early applications, and let kids have some life again. reply blululu 13 hours agorootparentThis feels fair. I would personally be totally in favor of nationalizing college admissions along such lines. Every school is given a fixed number of admits/waitlists and these are then allocated by lottery based upon such rudimentary qualifications. The federal government could easily force the issue by tying federal funds to a unified national admission scheme (They did this back in the 60's to eliminate men's colleges). reply ZeroGravitas 9 hours agorootparentprevAnd the cool second order effect of this, is that all the energy currently invested in this zero sum competition will be redirected into a plan B for kids that don't make the cut. Which prompts all sorts of interesting ideas like, why don't we have more prestigious universities? Did we decide that there was only so much science that needed done? Or were we trying to put a protective moat round the children of the elites so they didn't need to compete? And then put all our energies into ensuring our kid scraped into the bottom rung of that protected elite and didn't end up on the scrap heap? reply dagw 8 hours agorootparentwhy don't we have more prestigious universities? Depends what you mean by \"prestigious universities\". If you mean \"one of the N best schools in the country\" then per definition you cannot create more prestigious universities. If you mean universities capable of offering really high quality education to undergrads, then there are already very many 'unprestigious' universities that are every bit as good as the prestigious ones and in many cases probably a lot better. I guess what is needed is some sort signal that, while this university doesn't have as many Nobel laureates as Stanford, it is every bit as good at teaching undergraduate physics. I wish there was a university ranking that only focused on the quality of the undergraduate teaching and education, but I have no idea how that would be done. reply WitCanStain 8 hours agorootparentprev>why don't we have more prestigious universities? Legacy families need prestigious universities to be rare and exclusive so that them having gone there increases in value. They already know that their kids will get in so making top universities more exclusive only has benefits for them. reply MerManMaid 12 hours agorootparentprevLove where your head is at, but assuming we're talking about the united states, we literally just have enough money and resources to subsidize every kid who wants to attend college if we really wanted to. There are so many measurable long-term benefits to higher education both for the individual as well as the state that it's truly insane (to me any at least) with how unaccessible we've let it become. reply anon291 12 hours agorootparentWe do have many good schools but unlike most places we also have extremely great schools. So while it's pretty easy to fund a good education for everyone, there's always going to be competition for the best. reply MerManMaid 11 hours agorootparent>there's always going to be competition for the best. Agreed but surely we could come up with a form of competition more fair than something which heavily favors the wealthy and/or familial alumni. reply Ekaros 13 hours agorootparentprevI recommend some type of testing. Even subject specific. And for most desirable institutions just outright auction for certain amount of spots. Let the rich bid for spot and the money spend to subsidise others. reply anon291 12 hours agorootparent> \"Let the rich bid for spot and the money spend to subsidise others.\" this is called international students reply EvgeniyZh 12 hours agorootparentprevJust make tests hard enough so that you wouldn't need lottery reply UncleMeat 6 hours agorootparentAt some point a test stops becoming a general aptitude test and starts becoming a \"how good are you at taking this test\" situation. You get specific prep courses designed just around that one specific test and strategies optimized for that specific test. You start selecting for \"elite\" rather than \"smart.\" A merit lottery also keeps everybody from having to waste shitloads of time studying for this one test. reply EvgeniyZh 1 hour agorootparentAny test checks how good are you at taking this test. I've not seen evidence that at some complexity level it stops correlating with success in university, have you? reply BeFlatXIII 5 hours agorootparentprevThe lottery sortition above the minimum standard (which can still be set quite high) is the solution to preventing a competitive monoculture that a strict \"top N scores admitted\" policy would make. reply jjeaff 11 hours agorootparentprevany tests will always be gamed by those with the resources to game them. either ethically (through special tutors and private programs) or unethically (cheating). reply EvgeniyZh 10 hours agorootparentAny system can and will be cheated, that wasn't the point of neither OP's or mine proposals. Standardized testing is a good predictor. In my country people are admitted based on standardized testing only (country wide subject exams and sat-like test) or results of university-adjacent \"preparation courses\" and it works fairly well. The affirmative action is realized directly as a bonus points to your scores based on the background, which reduces the effect of ethical gaming. reply watwut 11 hours agorootparentprevPaying tutors is not gaming the system. It is trying to learn effectively. I get that one wants to avoid creating a system where students are forced to spend too much time to learn purely for competition sake with no real practical need, but still. The core issue is the pyramid shaped system where not being at one of these super places means that you are out of the competition for best work in general. reply saberience 10 hours agorootparentHaving to pay for tutors to have a chance of getting into the best colleges biases the whole system in favour of the wealthy. Do you want only rich kids going to college? reply dagw 9 hours agorootparentIf you are genuinely smart you will do well enough on qualify for top schools just by studying at school and on your own and relying on your own ability. And even the best and most expensive tutors cannot do that much to improve your scores if you just don't have the aptitude and discipline. The system now is far more geared towards sending only rich kids to college than any national testing and admissions system would be. reply throwaway48476 7 hours agorootparentThere's a diminishing return on the value invested in tutoring where innate ability plays a bigger part. reply dagw 6 hours agorootparentI've witnessed this first hand via a friend of the family. Their kid didn't have the grades or entrance exam test scores to study what they wanted at university. So the kid got to take a year off after high school and focus entirely on studying for the entrance exams with regular tutoring from various private tutors. And while their test scores absolutely did improve quite a bit by doing this, they didn't improve enough, and they still ended up having to study at a secondary choice anyway. reply BeFlatXIII 5 hours agoparentprevThat's why admissions should be tests-only. No interviews, no personality scores, no intentional shaping of the leadership class. reply fattegourmet 13 hours agoprevHope he ends up in Tarkington College. 'What's the hurry, son?' reply jgalt212 5 hours agoprevReading this article and comments it seems that cheating is just as common in the Tour de France as the Regeneron. reply thriftwy 12 hours agoprevThe elephant in the room is that 17 years old should not be writing long scientific articles witha lot of supporting material. They are not paid for that and they are expected to study first. We should definitely expect to see short, brilliant discoveries from teenagers when they notice a gem in a heap of data adults discarded. But not that kind of bureaqucratic nightmare style scientific papers where the result is attained mostly through prespiration, not inspiration. 100% great for already learned and paid adults, being fraud or exploitation of adolescents. reply readthenotes1 15 hours agoprevThere's a good book, Punished By Rewards. reply hilux 14 hours agoparentBorrowed - thanks! reply readthenotes1 1 hour agorootparentThere's more to it, but I found the advice \"Praise effort, not results\" to incredibly useful. reply zimnmley 15 hours agoprevnext [2 more] [flagged] mathattack 15 hours agoparentThis version is much better, and captures the juvinality of it all. reply userbinator 15 hours agoprevnext [6 more] [flagged] defrost 15 hours agoparentWhat are you attempting to say with \"scare quotes\" and conspiratorial nods to The Consensus? reply jgord 14 hours agorootparentSlightly offtopic : there seems to be a lack of articles loosely related to climate change / green-tech on HN... given the amount of new tech and the size and urgency of warming, Id expect to see more discussion/argument. It seems to be a self-censored topic on HN, for reasons I genuinely cant guess. reply fnordian_slip 10 hours agorootparentThere are a lot of climate change deniers on hn, though they have mostly moved on to denying the human impact on climate instead, after outright denial became harder and harder to argue for. Some have even already moved on to the third phase, \"it's too late now, so we might as well not do anything\", but these are still few. It's sad, but education and intelligence do not guarantee understanding or wisdom. reply userbinator 14 hours agorootparentprev\"urgency\"? That's what they want you to think... and yes there are lots of articles but they get quickly flagged by those who don't believe in that religion. reply jgord 11 hours agorootparentCan you define \"that religion\" .. I'm guessing you mean \"people who believe that climate change / global warming is caused by humans burning carbon fuels and emitting CO2\" .. ie. Im assuming, but want to check, that you are one of the many people who believe climate warming is happening, but is caused by natural processes, rather than human burning of carbon fuels ? Im aware of polls that show around half of people think that. If say 3/4 of HN users agree with you, it explains pretty well why articles on climate change are flagged as \"political\" or such - which is my assumption, after reading your comment. reply fergie 12 hours agoprevWe shouldn't internationally name and shame 17 year olds on HN. reply imiric 11 hours agoparentTheir name is already widespread online. A niche forum linking to an article that mentions it will hardly make an impact. Besides, this behavior deserves shaming, revoking of their prize, and maybe even legal repercussions. A 17 year old is practically an adult in many jurisdictions, and if they're doing this at that age, they will only continue to commit fraud later. Ethics should be learned early on in life, and a 17 year old should know better. Let this be a lesson. reply up2isomorphism 9 hours agoprev [–] Sadly he actually has a big chance to survive and strive in today's science community, as https://en.wikipedia.org/wiki/Replication_crisis. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A scandal has surfaced at the Regeneron International Science and Engineering Fair (ISEF) 2024, involving Krish Pai, a 17-year-old winner in the environmental engineering division.",
      "Pai is accused of cheating by using falsified images and plagiarized data in his project on microorganisms that biodegrade plastic, with an anonymous dossier providing detailed evidence.",
      "The incident underscores significant oversight failures by ISEF, and there are calls for revoking Pai's award to maintain fairness, with anticipated mainstream media coverage."
    ],
    "commentSummary": [
      "The discussion critiques the fairness of the Intel International Science and Engineering Fair (ISEF), noting disparities between independently designed projects and those with significant mentorship or lab affiliations, often favoring students with university connections.",
      "Broader societal trends, such as increased parental involvement and excessive digital media use among youth, are discussed, highlighting their impact on children's independence, self-esteem, and time management.",
      "Concerns about the competitive nature of science fairs, prevalence of plagiarism, and research misconduct are raised, along with the ethics of cheating and the role of organizers in preventing fraud."
    ],
    "points": 266,
    "commentCount": 184,
    "retryCount": 0,
    "time": 1716343766
  },
  {
    "id": 40435771,
    "title": "Mastering Common Lisp: A Comprehensive Guide to Tools, Libraries, and Best Practices",
    "originLink": "https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/",
    "originBody": "A Road to Common Lisp Posted on August 27th, 2018. I've gotten a bunch of emails asking for advice on how to learn Common Lisp in the present day. I decided to write down all the advice I've been giving through email and social media posts in the hopes that someone might find it useful. One disclaimer up front: this is a road to Common Lisp, not the road to Common Lisp. It's what I followed (without some of the dead ends) and has a lot of my personal opinions baked in, but it is by no means the only way to learn the language. This post has been translated into Japanese. I can't vouch for the accuracy of any translations. Context History Consequences Escaping the Hamster Wheel of Backwards Incompatibility Practicality Begets Purity Extensibility Power Ugliness A Road to Learning Common Lisp Get a Lisp Pick an Editor Hello, Lisp A Gentle Introduction Getting Practical Make Something Lisp as a System Learning Paradigms Switch Things Up Recipes for Success Final Patterns Where to Go From Here Macros Object-Oriented Programming with CLOS Low-Level Programming Web Development Game Development Window Management Unit Testing More Implementations Modern Common Lisp Structure Packages Systems Projects Recap Common Libraries Alexandria Bordeaux Threads CFFI CL-PPCRE Drakma Iterate local-time lparallel Named Readtables Roswell SERIES st-json usocket Good Luck! Context I think it's important to have a sense of where Common Lisp came from and what kind of a language it is before you start learning it. There are some things that will seem very strange if you're coming straight from modern languages, but will make more sense if you've got a bit of background context. History Common Lisp has a long, deep history. I'm not going to try to cover it all here — if you're interested you should check out some of the following (in roughly increasing order of detail): Wikipedia's History of Lisp and History of Common Lisp. The Where it Began section in Practical Common Lisp. The History: Where did Lisp come from? section of the comp.lang.lisp FAQ. Common Lisp: the Untold Story by Kent Pitman. The Evolution of Lisp by Guy Steele and Richard Gabriel. I realize you probably won't want to read all of the links above immediately, so here's a whirlwind tour of sixty years of Lisp. Lisp began in the late 1950's. It was invented by John McCarthy at MIT. Over the next twenty or so years various versions and dialects of Lisp grew and flourished. Some of the more notable dialects were Maclisp, BBN Lisp/Interlisp, Franz Lisp, Spice Lisp, and Lisp Machine Lisp. There were others too. The point is that there were a lot of different implementations, all growing, changing, and trying out different things. (Scheme also originated in this time frame, but took a very different route and diverged from the path we're looking at. I won't cover Scheme in this post.) In the early 1980s people decided that having a whole slew of mutually-incompatible dialects of Lisp might be not be ideal. An effort was made to take these different languages that had grown organically and produce one common language that would satisfy the needs of everyone (or at least a reasonable subset of \"everyone\"). In 1984 the first edition of Guy Steele's Common Lisp: the Language was published. If you do some math you'll see that at the time the book was published Lisp had around twenty-five years of real-world use, experimentation, experience, and history to draw upon. Even so, the book alone didn't quite satisfy everyone and in 1986 a committee (X3J13) was formed to produce an ANSI specification for Common Lisp. While the committee worked on the standardization process, in 1990 the second edition of Common Lisp: the Language was published. This was more comprehensive and contained some of the things the committee was working on (see the comp.lang.lisp FAQ linked above for more on this). At this point the Lisp family of languages had over thirty years of experience and history to draw upon. For comparison: Python (a \"modern\" language many people think of as also being \"kind of old\") was released for the first time the following year. In 1992 the X3J13 committee published the first draft of the new Common Lisp ANSI standard for public review (see Pitman's paper). The draft was approved in 1994 and the approved specification was finally published in 1995. At this point Lisp was over thirty-five years old. The first version of Ruby was released in December of that year. That's the end of the history lesson. There has not been another revision of the ANSI specification of Common Lisp. The version published in 1995 is the one that is still used today — if you see something calling itself \"an implementation of Common Lisp\" today, that is the specification it's referring to. Consequences I wanted to give you a quick overview of the history of Common Lisp because I want you to know what you're getting yourself into. I want you to realize that Common Lisp is a stable, large, practical, extensible, ugly language. Understanding these characteristics will make a lot of things make more sense as you learn the language, and I want to talk a little bit more about each of them before I start offering recommendations. Escaping the Hamster Wheel of Backwards Incompatibility If you're coming from other languages, you're probably used to things breaking when you \"upgrade\" your language implementation and/or libraries. If you want to run Ruby code you wrote ten years ago on the latest version of Ruby, it's probably going to take some effort to update it. My current day job is in Scala, and if a library's last activity is more than 2 or 3 years old on Github I just assume it won't work without a significant amount of screwing around on my part. The Hamster Wheel of Backwards Incompatibility we deal with every day is a fact of life in most modern languages, though some are certainly better than others. If you learn Common Lisp, this is usually not the case. In the next section of this post I'll be recommending a book written in 1990. You can run its code, unchanged, in a Common Lisp implementation released last month. After years of jogging on the Hamster Wheel of Backwards Incompatibility I cannot tell you how much of a relief it is to be able to write code and reasonably expect it to still work in twenty years. Of course, this is only the case for the language itself — if you depend on any libraries there's always the chance they might break when you update them. But I've found the stability of the core language is contagious, and overall the Common Lisp community seems fairly good about maintaining backwards compatibility. I'll be honest though: there are exceptions. As you learn the language and start using libraries you'll start noticing some library authors who don't bother to document and preserve stable APIs for their libraries, and if staying off the Hamster Wheel is important to you you'll learn to avoid relying on code written by those people as much as possible. Practicality Begets Purity Another thing to understand about Common Lisp is that it's a large, practical language. The second edition of Common Lisp: the Language (usually abbreviated as \"CLtL2\" by Common Lisp programmers) is 971 pages long, not including the preface, references, or index. You can get a surprising amount done by writing pure Common Lisp without much extra support. When programming applications in Common Lisp people will often depend on a small(ish) number of stable libraries, and library writers often try to minimize dependencies by utilizing as much of the core language as possible. I try to stick to fewer than ten or so dependencies for my applications and no more than two or three for my libraries (preferably zero, if possible), but I'm probably a bit more conservative than most folks. I really don't like the Hamster Wheel. It's also worth noting that since Common Lisp has been around and stable for so long, it has libraries older and more stable than many programming languages. For example: Bordeaux Threads (the de-facto threading library for Common Lisp) was first proposed in 2004 and released soon after (2006 at the latest but possibly earlier, it's hard to tell because so many links are dead now), which makes it about fourteen years old. So yes, threading is handled by a library, but I'm not worried about it breaking my code in the next decade or two. My advice is this: as you learn Common Lisp and look for libraries, try to suppress the voice in the back of your head that says \"This project was last updated six years ago? That's probably abandoned and broken.\" The stability of Common Lisp means that sometimes libraries can just be done, not abandoned, so don't dismiss them out of hand. Extensibility Part of Common Lisp's practicality comes from its extensibility. No one has been clamoring for a new version of the specification that adds features because Common Lisp's extensibility allows users to add new features to the language as plain old libraries, without having to alter the core language. Macros are what might come to mind when you hear \"Lisp extensibility\", and of course that's part of it. Macros allow users to write libraries that would need to be core language features in other languages. Common Lisp doesn't include string interpolation. You want it? No problem, you don't have to wait for Scala 2.10 or Python 3.6, just use a library. Want to try some nondeterministic programming without any boilerplate? Grab a library. Pattern matching syntax can make for some really beautiful, readable code. Common Lisp doesn't include it, but of course there's a library. Enjoying algebraic data types in Haskell or Scala? Here's your library. All of these libraries rely on macros to make using them feel seamless. Of course you could do all of that without macros, but you've have to add a layer of boilerplate to manage evaluation. This: (match foo '(list x y z) (lambda (x y z) (+ x y z)) '(vector x y) (lambda (x y) (- x y))) just doesn't flow off the fingers like: (match foo ((list x y z) (+ x y z)) ((vector x y) (- x y))) No one's up in arms trying to get a new revision of the Common Lisp standard to add pattern matching because you can write it as a library and get 90% or more of what you've get if it were built in. The language gives you enough power to extend it in a way that feels like the extension was there from the beginning. Having things that are core features in other languages be provided by libraries might seem at odds with the previous section about minimizing dependencies, and to some extent that's true. But I think there's a happy medium where you can write stable libraries in the core language and then depend on a small number of those libraries in your applications to add exactly the features you need for any particular problem. Power Macros are one of the things that make Lisp so extensible, because they let you transform arbitrary code into other arbitrary code. This is true for macros in languages like C too, but Common Lisp macros are different because they're part of the language. In C you have a layer of macros on top, written in a preprocessor macro language. The macro layer and the language layer are separate from each other, with the macro layer providing one one extra level of abstractive power (which, don't get me wrong, is certainly useful). In Common Lisp, you write macros in Common Lisp itself. You can then use those macros to write functions, and use those functions to write more macros. Instead of two stratified layers it's a feedback loop of abstractive power. But macros aren't the only thing about Common Lisp that make it so practical and extensible. Something people often don't realize is that while Common Lisp is an extremely high-level language thanks to macros, it also has plenty of low-level facilities as part of the language. It's never going to be as low-level as something like C, Rust, or Forth, but you might be surprised at some of the things that the ANSI spec includes. Want to see the assembly code a particular function compiles down to? DISASSEMBLE it! Want to stack-allocate something to avoid some garbage collection? X3J13 thought of that. Need arrays of unboxed floats to ship to a graphics card? The standard allows for that. Think GOTO should be considered helpful, not harmful? Well, okay, we're all adults here. Good luck, try not to shoot your foot off. Need to do unsigned 8-bit arithmetic in your Game Boy emulator, but would prefer it to compile down to just a machine instruction or two? It's possible. Not all Common Lisp implementations actually perform all these optimizations, but the designers of Common Lisp had the foresight to include the language features needed to support them. You can write vanilla Common Lisp as defined by the standard and trust that it will run everywhere, and implementations that do support these kinds of things will take advantage of the optimization opportunities. This combination of supporting extremely high-level programming with macros and a reasonable amount of low-level optimization mean that even though the specification is over twenty years old, it's still a good solid base to build on today. The thirty years of experience and history the designers were drawing from allowed them to create a very practical language that has survived for decades. Ugliness It's also important to realize that while Common Lisp might be very practical, the need to accommodate existing users and dialects means that there are plenty of ugly parts. If you buy a paper copy of the second edition of Common Lisp: the Language and look up \"kludges\" in the index you'll find this: Common Lisp is not a beautiful crystal of programming language design. It's a scruffy workshop with a big pegboard wall of tools, a thin layer of sawdust on the floor, a filing cabinet in the office with a couple of drawers that open perpendicular to the rest, and there's a weird looking saw with RPLACD written on the side sitting off in a corner where no one's touched it for twenty years. This historical baggage is a price paid to ensure Common Lisp had a future. It made it practical for people using the old dialects to actually adopt Common Lisp with a reasonable amount of effort. If the designers had tried to make it perfect and beautiful this could have made it too different to port implementations and code to and might have resulted in the language being ignored, instead of being adopted and embraced. A Road to Learning Common Lisp If all of this hasn't scared you away from the language, let's talk about how you can learn it in 2018. If you search around on the internet for Common Lisp tutorials and guides, you're not going to find as much as you might expect. This is because a lot of Common Lisp reference material was created before or during the infancy of the internet. There are a lot of books about Common Lisp out there. Some are better than others. I'll recommend the ones I think are the best, but don't hesitate to browse around and find others. Get a Lisp To get started with Common Lisp you'll need to install a Common Lisp implementation. Common Lisp is an ANSI specification, so there are multiple implementations of it, which gives you choices. There are a bunch of options, but I'll make it simple for you: If you're using MacOS and want a single GUI app you can download from the App Store, choose ClozureCL (often abbreviated \"CCL\"). Otherwise, choose SBCL. That's Clozure with a Z. Clojure is something entirely different that just happens to have a confusingly similar name. You might also hear of something called CLISP, which sounds like it might be what you want. It's not. CLISP is just another implementation, but it hasn't had a release in eight years (even though development is still ongoing in its source repos!) and it's not as commonly used as CCL or SBCL, so it'll be harder to find help if you have questions about the installation, etc. You might also hear about something called Roswell. Don't use Roswell, you don't need it (yet (or at all)). Just install SBCL or CCL for now, you can explore the other options once you've got your bearings a bit better. Pick an Editor You might hear people tell you that you must learn Emacs before learning Common Lisp. They're wrong. You can get started learning the language just fine in whatever text editor you're comfortable in. If you don't have a preference, CCL itself comes bundled with a text editor on MacOS. That one will work just fine to start. Emacs, Vim, Sublime Text, Atom, whatever, for now it doesn't matter. As long as it can balance parentheses, highlight comments and strings, and autoindent Lisp code that's all you need to start. Worry about shaving the editor yak once you're more comfortable in the language. Hello, Lisp To check that you've got everything set up properly, make a hello.lisp file with the following contents: (defun hello () (write-line \"What is your name?\") (let ((name (read-line))) (format t \"Hello, ~A.~%\" name))) Don't worry about what this means yet, it's just a check that everything's working properly. Open an SBCL or CCL REPL (Read/Eval/Print Loop) and load the file by entering (load \"hello.lisp\"), then call the function and make sure it works. It should look something like this if you picked SBCL: $ sbcl * (load \"hello.lisp\") T * (hello) What is your name? Steve Hello, Steve. NIL * Or if you chose CCL but still want to use the command line, rather than the MacOS app (the command line program might be annoyingly named ccl64 if you're on a 64-bit system): $ ccl64 Clozure Common Lisp Version ... ? (load \"hello.lisp\") #P\"/home/sjl/Desktop/hello.lisp\" ? (hello) What is your name? Steve Hello, Steve. NIL ? If your arrow keys and backspace don't work in the REPL, use rlwrap to fix that. rlwrap sbcl will give you a non-miserable REPL. rlwrap is a handy tool to have in your toolbox anyway. A Gentle Introduction The best book I've found for getting started in Common Lisp is Common Lisp: A Gentle Introduction to Symbolic Computation. This book really does strive to be gentle. Even if you've programmed before I'd still recommend starting here because it eases you into the language. The 1990 edition is available free from the site, and there's a 2013 reprint which fixes some minor errors in the 1990 version. If you can afford it I'd recommend buying the 2013 edition, but the 1990 version will also do fine. Go through the book and do all the exercises. This will take a while, and is mainly meant to get you started overcoming some of the main obstacles to being comfortable in Common Lisp, such as: How am I ever going to remember all these weird function names? Why do people use strings so rarely? When do I need the god damn quotation mark? If you find the book is moving too slow, just skim forward a bit. Skimming is a very useful skill to practice as a programmer. I think it's better for authors to err on the side of explaining too much when writing books and documentation — expert readers should be comfortable skimming if you explain too much, but new users will be stuck wallowing in confusion if you're too terse. Creating hours of newbie misery and confusion to save a few flicks of an expert's scroll wheel is a poor tradeoff to make. You should also join the #clschool channel on the Freenode IRC network so you can ask questions if you get stuck. For the most part people there are friendly and helpful, though I'll warn you in advance that there's at least one person who can sometimes be abrasive. There's also a #clnoobs channel, but that was mostly abandoned during the latest wave of Freenode spam because no one had ops to help combat the spam. If IRC isn't your thing there's also a Discord server that some of us hang out in. Join the #common-lisp channel there and we'll be happy to help you. Getting Practical Once you've finished that book the next one you should attack is Practical Common Lisp. You can get a paper copy if you want, but the full book is available on the site for free. You can skip the editor/programming environment part because the environment it recommends (Lisp in a Box) is abandoned and no longer works. Just keep using the programming environment you're comfortable with for now. Unfortunately the book doesn't include exercises. If you really want to get the most out of it you can type in all the code as you're reading it and poke at it, but if you've already done the exercises in the previous book it's probably safe to just sit down and read the book carefully. Don't read more than a chapter or two a day. It will take a while for your brain to digest all the information. Make sure you understand everything as you go through the book. Don't be afraid to ask questions on IRC or Discord (or email me if you want, I don't mind) if something's not clear. You should also begin to get comfortable looking up things in the Common Lisp language specification itself. It's the ultimate manual for Common Lisp. It can be pretty dense at points, but can answer many questions you might have if you read it slowly and carefully. You can either use the index page to find what you're looking for or just search on Google for \"clhs whatever\" (CLHS stands for \"Common Lisp HyperSpec\", which is the hyperlinked, HTML version of the spec). If you already use the Dash app for MacOS, it has the Common Lisp spec available. (Some people will tell you to learn the language by just reading the spec. That's ridiculous — it's like trying to learn French by reading a dictionary. It's a useful tool to have, but not the only one you'll need.) Make Something Once you've got those two books under your belt and some practice using the spec, it's time to make something without someone holding your hand. It doesn't have to be anything big or special, the goal is to just write some Lisp without having the answer on the next page. If you need some ideas: Do some Project Euler problems. Do some Advent of Code exercises. Make a stupid Twitter bot. Make a personal calendar program that records your appointments, checks the weather forecast the day of, etc. Use Sketch to implement the stuff in some Coding Math videos. It doesn't really matter what you make, just make something on your own. Lisp as a System At this point it's time to take your Common Lisp skills up a notch. Up until now I've told you to just use any text editor because it's more important to get you some experience with the language, but now it's time to dive into the deep end. In most languages the development process looks something like this: Edit some code in the project with an editor. Compile the project (some languages skip this step). Run the project (or the tests). Observe the output (in the console, a browser, etc). Go to 1. This is not how most Common Lisp users interact with the language. In Common Lisp, the development cycle looks more like this: Start a Lisp process. Load the project. Edit some code with your editor. Tell the running process to compile only the code you edited. Interact with the changed code in the process via the REPL, an HTTP request, etc. Observe the output (in the console, a browser, etc). Go to 3. When you embrace the Lisp way of working you'll rarely recompile and reload an entire project. Usually you'll write a function (or a macro, or parameter, or whatever), compile just that function, maybe poke at it in the REPL a bit, and then move on to the next function. This has some advantages over the traditional compile-everything-then-run approach. First: compiling a small chunk of code is fast. I just timed compiling a few of the larger functions in one of my projects and they took around 50-80 microseconds. You don't have to wait for the compiler, so your concentration/thought process never has time to wander. Another advantage is that when you get back the results of your compilation (and running), any errors or warnings you receive are almost certainly related to the few lines of code you just compiled. If you compile a ten-line function, run it, and get a division by zero error you can immediately focus in on the ten lines you just compiled and think about what changed. Because the Lisp process is always running, as soon as you compile a function it's ready to be used in the REPL. You can throw some arbitrary data at it and inspect the results to see how it behaves in isolation before you build more things on top of it. This cycle of making a function, compiling it, poking at it to make sure it's working as expected, and moving on happens constantly. In contrast, when working in languages like Scala or Python I almost never find myself writing one single function and compiling or running the project immediately. Spinning up the compiler or running the unit tests takes at least a second or two (or sometimes minutes in Scala, unfortunately) so to avoid having a constant stream of gaps in my thought I end up writing a bunch of functions at once, and then I run the project or tests once I know they have a chance of working. But then when I get back an error I have much more surface area to check, because I've added a lot of new code! So now I have to track down a problem that might be in something I wrote four minutes ago, whereas in Lisp I would only have to ever look at the code I wrote in the last few seconds. I've started using IntelliJ with Scala to help make this a bit less painful. It does help with the compile times because it recompiles things on the fly, but it doesn't solve the rest of the problem. I can write a Scala function in IntelliJ and it will be compiled immediately, but I can't interact with it immediately like I can in Common Lisp. When you work in this style with Common Lisp I think you'll really grow to love it. Writing in other languages will begin to feel like shipping your code off to the DMV and getting it back a week later with a page full of red ink somewhere in the hundred forms you filled out. Writing in Common Lisp feels like interacting with a living, breathing organism, or like teaching things to an eager assistant. This philosophy of Lisp being not just a programming language but a living, breathing programming system goes beyond just the short feedback loop and interactive REPL, too. As an example: imagine you're making a video game and have a bug somewhere in your damage calculation that will occasionally cause a division by zero. Now let's say you're working on the code for a particular quest. You'll start the game, load a save file at the beginning of the quest, and start going through the steps. All of a sudden, in the middle of killing the final monster for the quest, you hit the damage bug! In traditional languages, one of two things might happen: The game crashes, and you get a stack trace and maybe a core dump. You've wrapped a try block around the main game loop that logs a stack trace and ignores errors and allows the game to continue. Case 1 is pretty bad. You've got to try to track down the bug from a snapshot of what things looked like at the time (the stack trace and core dump). And even if you manage to fix it, now you've got to redo all that playing to get back to testing your quest code that you were originally working on. Case 2 is bad, in a different way. If you just ignore errors all the time, the game might now be in a weird state. You also might lose some critical context that's necessary to debug the problem, unless you're also saving a core dump (but I don't know of many people who save a core dump on every exception). In Common Lisp you can certainly choose to panic on or ignore errors, but there's a better way to work. When an error is signaled in Common Lisp, it doesn't unwind the stack. The Lisp process will pause execution at that point and open a window in your editor showing you the stack trace. Your warrior's sword is hovering over the monster, waiting for you. At this point you can communicate with the running process at the REPL to see what's going on. You can examine variables in the stack, or even run any arbitrary code you want. Once you figure out the problem (\"Oh, I see, the calculate-armor-percentage function returns 0 if a shielding spell ran out during the same frame\") you can fix the code, recompile the problematic function, and restart the execution of that function (or any other one!) in the call stack! Your warrior's sword lands, and you move back to what you were doing before. You don't have to track down the bug from just a stack trace, like a detective trying to piece together what happened by the blood stains on the wall. You can examine the crime as it's happening and intervene to save the victim. It's like if you could run your code in a debugger with a breakpoint at every single line that only activates if something goes wrong! Maybe you don't make video games, sure, but this process can be useful in all kinds of contexts. Maybe you're writing a web app that talks to an API somewhere, and are debugging a request that fails between two calls to the API, e.g. between \"create widget foo\" and \"add foo to widget list bar\". Instead of just aborting the request, logging a stack trace, and now leaving things in a possibly weird state (foo having been created without being in the expected bar list), you can fix the problem and allow the request to finish properly. Of course this won't always work. If you've got a big function that does some side effects and then crashes, restarting execution of the function would make the side effects happen again. But if you divide up your functions well (one function to a function!) this case is pretty rare. And even when it does happen, it just means you're back in the same situation you're in by default with other languages! Support for this style of interactive development doesn't just come from some fancy editor plugins — it's baked into the bones of the language. For example: the standard specifies a method named update-instance-for-redefined-class that lets you customize what happens to objects when their class is redefined! This isn't something you'll use all the time, but something like Sketch (a Common Lisp equivalent of Java's Processing library) uses it to automatically update the running sketch when you redefine its class. Dynamically updating running code in a safe, consistent way doesn't require any dark magic in Common Lisp because it's the expected, usual way to work. So how do you actually get this wonderful interactive experience? The bad news is that you're going to need to shave the editor yak. You really only have two choices here: Emacs with SLIME or Sly. Vim (or Neovim) with Vlime or Slimv. I wish this weren't the case, but those are really only the realistic options today (aside from the editing environments for the (expensive) commercial Lisps). If you're like me and already have Vim burned too deeply into your fingers to ever get it out, I'd recommend Vim with Vlime. It will give you 80% of the experience you'll get with Emacs. Otherwise go with Emacs. You might want to look into Portacle, which bundles Emacs and SLIME and a bunch of other things together, or you might want to have a go at setting up Emacs and SLIME or Sly yourself. I can't really give you much advice on the Emacs side of things because I haven't had much experience with it, so you'll need to do a bit of research here. Whatever you choose, spend some time setting up your editor and environment of choice. This will be a lot of fiddly metawork, but will pay off handsomely as you continue working in Lisp. On a side note: if anyone is interested in making a Common Lisp LSP language server, I think it would be a hugely useful contribution to the community. Having an LSP server would mean you could get a much nicer programming experience in many editors out of the box, which would help new people quite a lot. I think you could piggyback on top of Swank to do a lot of the language-side stuff, and it would mostly be a matter of implementing the LSP interface. If this sounds interesting to you, please let me know — I'd be willing to help. I've done some work at my day job making a Scala LSP language server that uses IntelliJ as a backend, so I have at least some idea of how that sausage gets made. I just don't have the time or motivation to do an entire LSP server for Common Lisp all by myself. Learning Paradigms At this point you should have a pretty good handle on the basics of Common Lisp, and have set up one of the more powerful development environments. Your next goals should be to learn how to write idiomatic Common Lisp and to get some practice using your fancy new environment. I think the perfect book for both of these is Paradigms of Artificial Intelligence Programming, often abbreviated as PAIP. The book was recently made available for free as a PDF, or you can buy a used paper copy if you prefer. This book was written in 1992 so it's not about the hyped up AI fields you've been hearing about in the news like machine learning — instead it's a tour of Good Old-Fashioned AI. Even if you're not particularly interested in this kind of AI, the book is a great example of how to write Common Lisp code. One thing I really love about this book is that almost all the functions in it have docstrings. If you look at most other programming books they omit the documentation strings, presumably for space reasons and because they feel the surrounding text is documentation enough. But writing helpful docstrings is an art in and of itself, and I think books that omit them train readers that \"good code omits docstrings\", which is a bad habit to get into. The book contains plenty of exercises, conveniently categorized by how difficult or involved they are: S for \"seconds\". M for \"minutes\". H for \"hours\". D for \"days\". This is a very good idea which more books should steal. Do all of the S and M exercises, and try your hand at at least a few of the H ones. If a D sounds particularly interesting don't be afraid to spend some time on it — really digging into a problem is exactly what you need at this point in your Lisp journey. Switch Things Up Now that you're comfortable in Common Lisp and your programming environment, it's time to push yourself out of your comfort zone again. At the beginning I had you choose either SBCL or CCL. Now I want you to install whichever one you didn't originally choose and make sure all the code you've written so far runs in it. This may seem a bit like running in place, but making sure your code runs in more than one implementation will keep you honest. It will force you to write portable code that doesn't rely on anything implementation-specific that might change in the next decade or two. And you might even discover that you like this other implementation better than the original — maybe CCL's super-fast compile times make you smile, or SBCL's strong type inference catches more of your bugs. Go through all the code you've written so far and make sure it all runs in the new implementation. You might also want to take this opportunity to refactor or rewrite some of it — you've learned a lot since you first started, so your earliest Common Lisp code will probably look pretty rough to you now. Recipes for Success The final technical book I'll recommend to every aspiring Lisp programmer is Common Lisp Recipes, sometimes abbreviated as CLR. Unlike most of the other books I've recommended so far this one is relatively recent: it was published in 2015. It's not free, but I think it's well worth the money it costs. The book is written by the author of several very heavily used Common Lisp libraries. It's a bit of a grab bag of topics (which is why I think you need a decent amount of Lisp under your belt before you tackle it) but it's a very well-written grab bag that will teach you a lot of things you won't find in other books. Final Patterns If you've gotten this far you're pretty invested in Common Lisp, and I want to recommend one not-strictly-technical book that I think you'll really enjoy: Patterns of Software by Richard Gabriel. It's available as a PDF on the author's site, and you can still find used print copies online if you prefer. This is not the \"Gang of Four\"/\"Design Patterns\" book that you might have already read or heard about, but is a set of essays on a variety of loosely-related topics. It's the best book I've read so far this year. I don't want to spoil anything in it for you, so I'll just say that I think you'll find it well worth your time. Where to Go From Here If you made it through all the books and activities in the previous section: congratulations, you're off to a great start! Now that you've got a decent handle on the core language you can explore in many different directions, depending on your interests. Macros If you want to learn the secrets of macros, you'll probably want to read and work through On Lisp and Let Over Lambda (in that order). I'll say that you should take both books (especially the latter) with a large grain of salt. A lot of Common Lisp users don't agree with all of the arguments and style in these books, but I think they can still provide plenty of value if you read them with a critical mind. Object-Oriented Programming with CLOS Common Lisp has some very sophisticated support for Object-Oriented Programming through CLOS. If you're like me and have bad memories of OOP from working in a Java cube farm, I'd urge you to give CLOS a fair chance to change your mind. Start with Object-Oriented Programming in COMMON LISP: A Programmer's Guide to CLOS. It's a wonderfully-written, short and to-the-point book that will give you a good overview of how CLOS is intended to be used. If you really want to bend your mind, try The Art of the Metaobject Protocol (usually abbreviated as AMOP). This book will probably take you a couple of tries to get through. Read it until you hit a mental wall, go work on other things for a couple of months, and come back and try again. Repeat that process as many times as necessary. Low-Level Programming Low-level programming can mean a lot of different things, so I'll just mention one possibility here. If you're interested in writing emulators for old computers, I wrote a series of posts on making a CHIP-8 emulator in Common Lisp. cl-6502 is an emulator for the processor used in the NES (and lots of other things) and has a really nice literate programming version that's wonderful to read through. Web Development Unfortunately I don't have too many suggestions for web development in Common Lisp. I've made a conscious effort to avoid web development in the past five or so years, because it seems like the Hamster Wheel of Backwards Incompatibility has become more of a Hamster Centrifuge in that field. There is a #lispweb channel on Freenode and a #webdev channel in the Lisp Discord, so if you have questions you could start by asking there. Those channels are a bit less populated than the other Lisp channels, so don't expect an answer immediately. Game Development Common Lisp has a small but enthusiastic community of people who like making games. There's a #lispgames channel on Freenode and a #gamedev channel on the Lisp Discord that you should join if you're interested. Land of Lisp is a fun book to go through. The coding style in the book has some... \"eccentricities\", which is why I don't recommend it as a first book on Lisp (e.g. using ash instead of truncate or floor for integer division), but if you know the language and just want to get started making some simple games I think you'll enjoy working through it. If you want an excuse to make a game in Lisp in a week, the Lisp Game Jam is something you can join. It's usually held once or twice each year, so you'll have to search around (or ask in #lispgames) to find out when the next one is. Lisp doesn't have any engine as full-featured as Unity, but several people are currently working on making 3D game engines. Ask around to see what people are using these days. Unfortunately a 3D game engine will generally need to interface with the OS to render images and produce audio, and so can't be written in pure Common Lisp. This means that some running on the Hamster Wheel of Backwards Incompatibility will be necessary to keep up with OS changes (e.g. Apple deprecating OpenGL). If you're interested in old-school ASCII/tile-based games, I've personally done some work with using ncurses and bearlibterminal in Common Lisp. There's something really fun about making a game people can play over telnet! Feel free to get in touch with me if you're interested in that kind of stuff and want to know more. Window Management If you're running Linux and like tinkering with your desktop environment, StumpWM is an X window manager written in Common Lisp. I've just recently switched back to Linux so I've only been using it for about two months, but it's really pleasant to be able to customize my working environment with Common Lisp. StumpWM has a small but friendly community — if you're looking for a non-trivial open source Common Lisp project to contribute to, StumpWM would be a great choice. Unit Testing If you're coming from a modern language, especially one with a lot of test-driven development advocates, you might be surprised at the lack of an emphasis on unit testing in Common Lisp. I think one reason for this is that in some languages a unit test is the simplest way to actually run a function, but Lisp's interactive style of development gives you an even easier alternative: just run the function in the REPL! Despite the lack of heavy unit testing in the community, there are almost as many unit testing frameworks as there are Common Lisp programmers! This is probably because making a unit testing framework is so easy with a few macros. I love 1am, but there are plenty more to choose from. Whichever one you choose, please make sure to be a good citizen and create a separate ASDF system for your unit tests, so people can use your library without having to load Yet Another Testing Framework. More Implementations I had you use SBCL and CCL because those are the most popular free Common Lisp implementations today, but they aren't the only actively-developed ones out there. There's plenty of others you might want to explore: ABCL runs on the JVM. ECL can be embedded in a C program, and can translate Common Lisp code to C code. CLASP is still under development, but is an implementation designed to be easy to interoperate with C++. Lispworks and Allegro CL are commercial implementations with a lot of extra features and support, but are not free. (I omitted CLISP because I'm mad at them for choosing a name that confuses the heck out of new people. Hey, I warned you this post would contain Opinions™.) I tend to use SBCL for my own projects, but I make sure the units tests for all my libraries run in SBCL, CCL, ABCL, and ECL. This keeps me honest and gives me a reasonable degree of confidence that I'm writing portable code. Modern Common Lisp Common Lisp is old and stable, but that doesn't mean it's stagnant. The language gives you plenty of power to build on, and before I wrap this up I want go over a couple of recent developments in the Common Lisp world that the older books you've been learning from don't talk about. I also want to clarify some things that often trip up new people. Structure Common Lisp's terminology for various parts of projects is often confusing to new people because it's old and uses a lot of words that we use now (like “package”) to mean subtly different things than people mean today. Things get easier once you internalize what Common Lisp means by the terms. (Side note: I posted a quick-and-dirty version of this section as a comment on Lobste.rs while I was waiting for a plane — this section of the post is an expanded version of that comment.) Packages We often see questions in IRC and Discord that look something like: \"How do I export a class from a package\"? Questions worded like this are a sign of a very common misunderstanding about what packages in Common Lisp actually are. A package in Common Lisp is a container for symbols. That's it. They're a way to group related names (symbols) together so you don't have to do the miserable prefixing of every name with mylibrary-... like you need to do in Emacs Lisp or C to avoid name clashes. You don't export a class from a package, you export a symbol. You don't import a function, you import the symbol it's attached to. This sounds pedantic, but is important to keep clear in your head as you start using the package system. If you're not clear on what exactly a symbol is, I wrote a separate post just about symbols which you might find helpful. Another major tripping point for new people is the relationship between packages and files. Or, rather: the completely lack of any relationship in Common Lisp. In many languages like Python, Java, or Clojure, a file's package and its location on the hard drive are tied together. For example: when you say import foo.bar.baz in Python, Python will look for a baz.py file inside the foo/bar/ directory (it's a little more complicated than this, but that doesn't matter for this example). In Common Lisp, this is not the case. Files and packages are completely unrelated in Common Lisp. You can have many files that all work in the same package, or one file that switches between many packages, or even create or modify packages at runtime. This gives you the flexibility to work however you want. For example: in my procedural art library Flax most of the packages are each used in one specific file, much like you would do in modern languages. But the flax.drawing package contains not only a drawing protocol but also several implementations of that protocol (PNG, SVG, etc), and so I split the code into a series of separate files, each one dealing with how to draw a single format (plus one for the protocol itself). I could have created separate packages for each implementation and set up the imports/exports between them, but I didn't feel like the extra boilerplate was worth it. Common Lisp is flexible enough to let you make such choices. So if files and packages aren't related, the next question is: how does Common Lisp know where to find anything on disk when it comes time to load the code? Systems A system in Common Lisp is a collection of serveral things: Some code. A description of how to load that code. A list of other systems this system depends on, which need to be loaded prior to loading this one. Some metadata like author, license, version, homepage, etc. The Common Lisp language itself has no knowledge of systems. If you look at section 11.9 of CLtL2 you'll see that it was imagined that each author would write their own custom file to load their code. But since Common Lisp gives you the power to abstract almost anything, people eventually abstracted the process of loading Common Lisp code. ASDF is a Common Lisp library bundled with most modern implementations which handles defining and loading systems. The name ASDF stands for \"Another System Definition Facility\", so as you might guess there have been several other such libraries. ASDF is the one everyone uses today. ASDF standardizes the process of defining a system into something like this: The system definition(s) for a project called foo would be in a file named foo.asd. Each system is defined with a (defsystem ...) form inside this file. We'll talk more about what a \"project\" is shortly. Note the extension of the file is asd, not asdf, which is a little confusing, but was probably chosen to work in environments with three-letter-extension limits. The ASDF manual is the definitive resource for the syntax and semantics of defsystem, but can be a little heavy to read if you're just getting started. Another way to get started is to read some .asd files of some small-to-medium sized open source projects and see how they handle things. Systems and packages are orthogonal in Common Lisp. Some systems (like small libraries) will define exactly one package. Some systems will define multiple packages. Rarely a system might not define any new packages, but will use or add to an existing one. For example: My directed graph library cl-digraph contains a system called cl-digraph. That system has a description of how to load the code, which lives in the cl-digraph.asd file. One of the files specified for loading is package.lisp, which creates a package called digraph. Even though ASDF standardizes some aspects of system definition, it still gives you plenty of flexibility. As you read projects by different authors you'll encounter different ways of organizing systems — this can be a little overwhelming at first, but it means you can organize a system in the way that works best for that system, which is really nice once you've got some experience under your belt. One example of this is how people define packages for their systems. There are a couple of common ways to do this you'll see in the wild: A single package.lisp file which contains all the definitions for all the packages in the project, and gets loaded before all other files. This is the strategy I usually prefer. Each file defines its package at the top of the file, much like you would in Clojure or other modern languages. Care is taken in the system definition to load the files in the correct order so that each package is defined before it is ever used. To review: a system is a collection of code and a description of how to load it, a list of its dependencies, and some metadata. Now let's move up one level higher to the final layer of structure you need to know about. Projects A project in Common Lisp is not an official term defined anywhere that I know of, but is a word that's generally used to mean something like a library, a framework, an application, etc. A project will usually define at least one system, because systems are where you describe how to load the code, and if a project didn't define a system how would you know how to load its code? My string-wrapping library Bobbin is a project that defines two systems: The bobbin system contains the actual data structure and API. It has no dependencies. The bobbin/test system contains the unit tests. It depends on the bobbin system (because that's the code it's going to test) and the 1am system (a unit test framework). I made this a separate system because it allows users to load the main code without also having to load the unit testing framework if they're not going to be running the tests. Both of these systems are defined in the bobbin.asd file. ASDF treats systems with a forward slash in their name specially and knows to look for them in the asd file named with the text before the slash. We saw how Common Lisp has no concept of a system — that concept comes from ASDF. Similarly, ASDF has no concept of the internet or of reaching out to somewhere to download things. ASDF assumes you have somehow acquired the systems you want to load and stored them on your hard drive, perhaps by sending a check to an address and receiving a copy of the code on floppy disk, as many of my old Lisp books offer in their final pages. Quicklisp is another library that works on top of ASDF to provide the \"download projects from the internet automatically if necessary\" functionality that people expect in the modern world. So when you say (ql:quickload :bobbin) you’re asking Quicklisp to download Bobbin (and any dependencies) if necessary, and then hand it off to ASDF to actually load the code of the bobbin system. Unlike ASDF, Quicklisp is relatively new in the Common Lisp world (it's only about eight years old) and so is not bundled with any modern Lisp implementations that I know of, which is why you need to install it separately. Recap Here's a quick recap of the different layers of project structure you'll encounter in Common Lisp. Jot these down on a post it note you can refer to as you're learning. Files are files on your hard drive. Packages are containers of symbols. They are orthogonal to files. Systems are collections of code, instructions on how to load that code, dependency lists, and metadata. They are orthogonal to packages. Projects are high-level collections of... \"stuff\" such as code, documentation, maybe some image assets, etc. They are (mostly) orthogonal to systems (are you seeing a trend here?). Common Lisp itself knows about files and packages. ASDF adds systems. Quicklisp adds the internet. Common Libraries Common Lisp doesn't have as large of a community as some newer languages, but it still has a lot of libraries because it's had a community for a longer time. The stability of the core language means that many libraries written in portable Common Lisp ten or fifteen years ago can still run just fine today. In this final section I'll give you a quick overview of some of the more popular libraries you might run into as you learn the language. You don't have to use all of them, but it's helpful to have some idea of what's available. Alexandria Alexandria is one of the most popular Common Lisp libraries (the name is a pun on the Library of Alexandria), and it's a collection of all kinds of useful little utility functions like read-file-into-byte-vector and map-permutations. There are a lot of utility libraries for Common Lisp around — one rite of passage is building up your own personal utility library over time — but Alexandria is the most popular one. Most projects with any dependencies at all will eventually end up with Alexandria in the dependency graph somewhere. Bordeaux Threads Bordeaux Threads was mentioned earlier. Threads aren't part of the Common Lisp standard, but most implementations provide their own custom interface for working with them. Bordeaux Threads wraps all these implementation-specific interfaces and provides an API so you can write threaded code that will work portably. If you're looking for something like Java's new Thread(() -> foo()).start(), this is what you want. CFFI CFFI is a foreign-function interface library that lets you load C libraries (e.g. foo.dylib or foo.so) and call the functions in them. It works by wrapping implementation-specific interfaces, because this isn't part of the Common Lisp standard. Unfortunately it has the same name as Python's FFI library, so if you're searching for documentation make sure you're looking at the right version. CL-PPCRE CL-PPCRE is an implementation of Perl-compatible regular expressions. If you're looking to use regular expressions in Common Lisp, this is what you want. Drakma Drakma is an HTTP client. If you need to make an HTTP request, this is what you want. There are other HTTP clients around, but Drakma is commonly used and is fine for almost anything you might need. Iterate Iterate is a replacement for the loop macro. It works similarly, but has a more Lispy syntax and a well-defined API for extending it with new iteration constructs. I really like it myself, but beware: if you get used to iterate going back to vanilla loop will feel painful. local-time local-time is a library for working with time and dates in Common Lisp. The standard has some basic support for times built in, but if you want to do much calculation with times (including timezones) this is probably what you want. If you're looking for something like Joda Time in Common Lisp, this is as close as you're going to get. lparallel lparallel is a library that builds on top of Bordeaux Threads to make common parallel processing operations much easier. Think of it as GNU Parallel for Lisp, with a few extra features (e.g. channels and tasks). For example: if you've got a big vector you're mapping over with (map 'vector #'work some-vector) you can split it into chunks and run in multiple threads by changing it to (lparallel:pmap 'vector #'work some-vector). Named Readtables Named readtables is a library that adds namespaces for readtables. One painful part of the standard is that reader macros are added and removed to the global readtable on the fly, so if you load multiple systems that define the same reader macros things can get messy. Named readtables adds some much-needed hygiene to that process. If you're working with reader macros at all you absolutely want to use this. Roswell Roswell is a couple of things rolled into one. It's a C program that handles installing and running multiple different Common Lisp implementations (kind of like NVM or rvm), and it also provides a unified way to write small shell scripts in Common Lisp and compile them into binaries. I used Roswell for a little over a year, but I eventually stopped and now I don't think it's worth the trouble, for a couple of reasons. First: if you write portable code you generally don't need to worry running a particular version of an implementation, because Common Lisp is so stable. I usually just install the latest version of each implementation I use with a package manager or by building from source. Second: after using it for a while I found that Roswell was always very brittle to upgrade, and whenever things broke it would spew an almost JVM-sized stack trace without a decent error message. For me, the negatives outweighed the positives. I'd recommend simply using the latest version of the implementations you care about and writing portable code. For the compiling-into-binaries functionality I'd recommend using your implementation's built-in support for this, or using UIOP's wrapper around that, or using a separate library like Deploy. Of course your mileage might vary. If you find yourself really needing to run specific versions of specific Common Lisp implementations in rapid succession, you should look into Roswell. SERIES SERIES was almost included in Common Lisp (it's in Appendix A of CLtL2), but didn't quite make it. It's a library for writing functional code that looks like the traditional map and filter and reduce operations but which compiles down to efficient loops. If you're looking for Clojure's transducers in Common Lisp, this is what you want. st-json JSON support in Common Lisp is a god damn mess. There are an absurd number of JSON libraries and I don't really like any of them. For me, the most important quality I need in a JSON library is an unambiguous, one-to-one mapping of types. For example: some libraries will deserialize JSON arrays as Lisp lists, and JSON true/false as t/nil. But this means [] and false both deserialize to nil, so you can't reliably round trip anything! I've settled on using st-json and wrapping it up to be a little more ergonomic with some glue code. It's not the fastest solution out there, but it works for my needs. There are plenty of other options out there, so if you have different needs than me you should look into them. usocket usocket is a library for networking sockets. Sockets and networking aren't part of the Common Lisp standard, but most implementations provide a custom interface for working with them. usocket wraps the implementation-specific interfaces and provides an API so you can write networking code portably. If you want to make Lisp listen on a port and read streams of bytes from clients, or want to connect to a port and send raw bytes to it, this is what you want. Good Luck! I hope this whirlwind tour was useful. Common Lisp is an old, deep language. It's not something you can learn in a month, but if you're willing to spend the time it will reward careful study. Feel free to email me or pop into IRC or Discord if you have questions. Good luck!",
    "commentLink": "https://news.ycombinator.com/item?id=40435771",
    "commentBody": "A Road to Common Lisp (2018) (stevelosh.com)207 points by fuzztester 19 hours agohidepastfavorite115 comments b3lm0nt 16 hours agoI wanted to love Common Lisp, but as a Vim user every day was a struggle. One typically uses plugins (Slimv, Vlime) that contort buffers in bizarre ways in order to simulate the SLIME EMacs REPL — if not, they will lose out on the interactive development experience that is so central to CL. Being tied to either EMacs or an enterprise solution like LispWorks to get the full language experience was ultimately a non-starter. I’d love for someone to build an alternative CL development experience that could work in a wider range of text editors and IDEs. There is a lot to learn from CL, but I think it can be hard to access for most developers. reply nomilk 15 hours agoparentA flavour of emacs called 'doom emacs' is basically emacs for vim users (same keybindings and many similar features): https://github.com/doomemacs/doomemacs?tab=readme-ov-file#do... Great set of instructions for how to set it up here: https://www.youtube.com/watch?v=xyXDE5gP2QI (and if you're on macOS, this video is flawless for installation specifics: https://www.youtube.com/watch?v=A6SxH9lUWV0) reply kaeland 14 hours agorootparentAs a vim user, I’ve been using doom emacs for the past 3.5 years and haven’t looked back yet. I really enjoy the Common Lisp experience while using doom as well. reply kaeland 3 hours agorootparentI should also note that I’m looking forward to CLOG being ready as an in-browser IDE for Common Lisp soon. It’s a really neat open source tool for developers if you haven’t heard of it yet: https://github.com/rabbibotton/clog reply Zambyte 14 hours agorootparentprevI appreciate the message you're conveying (I also switched from using vim for years to emacs for years, probably for good) but man, we have to stop attaching tools to our identities. You're not only more than a vim user, you don't even use vim! reply kqr 9 hours agorootparentI would argue Evil mode (which Doom Emacs includes) is an implementation on Vim. Only instead of being an implementation in C, it's an implementation in Elisp. I equate Vim not with the weird configuration language or source code of the original Vim project, but with the interaction language it uses – and Evil uses the same one. Evil is more than \"a vim compatibility layer\" -- it is a reimplementation of Vim closer in spirit to nvim than anything else. reply bmacho 14 hours agorootparentprevStop being vim-purist! There are so many ways that one can be a vim user, and yes, using vim is not necessary reply tasuki 7 hours agorootparentWhat is necessary to be a vim user? reply necrotic_comp 4 hours agorootparentIt's about modal editing and the editing commands/paradigm inherent in that. reply fuzztester 2 hours agorootparentThis is a classic explanation: Your problem with Vim is that you don't grok vi https://stackoverflow.com/questions/72498282/your-problem-wi... reply stragies 1 hour agorootparentDirect link to original SE posting: https://stackoverflow.com/questions/1218390/what-is-your-mos... reply samatman 1 hour agorootparentprevSome tools are closer to being identities than others. Being a 'vim user' is more like being a Dvorak user, it lives in muscle memory. 'vim user' is overloaded here, it colloquially means \"user of the vim text editing language\" rather than (just) \"user of the text editor, vim\". I'm about intermediate at wielding vim, and the VSCode plugin implements enough of the language for me. But I'm fluent enough that being deprived of it is unpleasant, and I won't willingly edit text using a program which doesn't implement a decent vim mode. It's not like computer languages or applications: the right number of text editing command-languages to be good at, like the right number of keyboard layouts, is one. Typing on a keyboard, and editing text, is my job. I don't want to waste time and productivity on learning several ways to do it, these are means to an end. This being HN, someone might come up with some valid reasons to master more than one keyboard layout, particularly a \"weird\" one while retaining fluency in a standard one. Granted, call it a concession to an imperfect world. reply medo-bear 12 hours agorootparentprevCommon Lisp in Doom uses Sly. If you want to stick to Slime and prefer vim ergonomics to those of Emacs there is also Spacemacs, which I just learned even has its own Wikipedia page: https://en.m.wikipedia.org/wiki/Spacemacs reply sandbach 10 hours agorootparentThat sort of thing is all configurable. It's easy to tell Doom Emacs to use Slime instead. reply actuallyalys 19 minutes agoparentprevIf you use Neovim, you could try Conjure. I really like it for other lisps, but I haven’t used it for Common Lisp. I wouldn’t say it “contorts buffers in a bizarre way,” although in my experience, different Vim users have their own take on that. reply vindarel 8 hours agoparentprevMore editor plugins have been developed in the recent years: https://lispcookbook.github.io/cl-cookbook/editor-support.ht... Atom/Pulsar (very good support), VSCode (good, in development), Sublime, Jetbrains suite, Jupyter notebooks… And that's not all. Lem, a general-purpose editor tailored for CL (see other comments below), and even more recent, the CLOG builder (CL Omnificient GUI) which ships an editor in the browser: https://github.com/rabbibotton/clog-linux-ez/releases/ && https://github.com/rabbibotton/clog-win64-ez/releases Rustaceans could help on this project: https://github.com/fonol/parrot/ (Rust, Tauri) reply massysett 9 hours agoparentprevThe author of “Let Over Lambda” dislikes Emacs and does not use it. What’s more, he didn’t use Slimv or anything like it or even Vim at all. He used a more basic vi, maybe nvi. So perhaps the interactive experience is not essential. You can just edit and compile like you would in C. That’s not what I do—-I use Slime—but it is possible. Also, a lot of the interactivity is required by the standard to be built in to your Lisp’s REPL, so you can do quite a bit if your REPL isn’t primitive. SBCL doesn’t even have readline but you can use rlwrap. https://letoverlambda.com/ reply djha-skin 6 hours agoparentprevI just do it in vim and tmux (it used to be screen): https://blog.djhaskin.com/blog/developing-common-lisp-using-... This works real well. I honestly don't see the point of slime, it feels like it was written so that people didn't have to use the terminal, but the terminal works just fine for me. I even wrote a :make plugin for it, which works well enough: https://git.sr.ht/~skin/roswell-sbcl.vim reply reikonomusha 14 hours agoparentprev\"Lem is the editor/IDE well-tuned for Common Lisp. [...] If you come from Emacs or Vim, you will feel right at home.\" https://lem-project.github.io/ reply medo-bear 12 hours agorootparentI'm curious, how does Lem compare to Emacs as a common lisp ide? reply vindarel 9 hours agorootparentIt compares pretty well: it has all the essential features, and some more. It only lacks a couple keybindings in my eyes (shortcut to call the function at point in the REPL, shortcut to \"change-package\" from a lisp file). It has: - the interactive debugger - the Lisp REPL - so we can have a full-featured Lisp REPL on the terminal with: alias ilem='lem --eval \"(lem-lisp-mode:start-lisp-repl t)\"' - the same compilation, evaluation, code navigation keybindings and error reporting some more: - when we evaluate an expression, it will show a loading spinner during that time and then the result in an overlay. - a \"watch\" command that shows results in the overlay too https://lem-project.github.io/usage/common_lisp/#watch Overall, Lem has: - a built-in LSP client that is known to work with other languages (and syntax highlighting for many languages) - some tools, still more rudimentary than Emacs: directory mode, find file in project, project tree side view, Git tool (shows status, does interactive rebase)… - it is in the process of having co-editing in Lem itself. The developer(s) are beta-testing a collaborative web-based version of Lem: https://github.com/sponsors/cxxxr Lem has ncurses and SDL2 interfaces. https://lem-project.github.io/usage/usage/ reply alt0_ 11 hours agorootparentprevIt's pretty raw and buggy still, but if you're already a cl hacker, you'll certainly enjoy it. It is missing most useful Emacs features but also seems to have some of it's own, particularly for CL. reply kentrado 5 hours agoparentprevI don't understand. Why not just use Emacs with evil-mode? reply Kehvarl 3 hours agoparentprevI had similar issues trying to get used to EMACS when I was playing the CL. Add to that the fact that I tend to use Windows at least half of the time, and I wanted an alternative. I ended up setting up Atom with SLIMA and some other plugins to do CL development on Windows and Ubuntu. I even wrote up some very sparse instructions https://github.com/Kehvarl/roguelike-tutorial-cl/blob/main/d... While Atom is gone, Pulsar now has a SLIMA plugin to allow Lisp interaction. reply orthecreedence 15 hours agoparentprevBack in my CL days I loved Slimv. It had its warts, but was miles beyond having a shell with a REPL open. I imagine it has only gotten better since (I haven't touched lisp in almost 10 years now). That said, I never gave Emacs a serious shake so I was probably missing out quite a lot on what a good interactive experience could be. reply jimbokun 15 hours agoparentprevUnderstandable, but it also seems like there is a disconnect between the philosophy of vi and the philosophy of Lisp. Vi is designed to be purely a text editor, and not an environment for building text based applications. Common Lisp being so inherently interactive, seems to require a dynamic, interactive text editing environment. Like Emacs. reply kunley 7 hours agorootparentHmm, IIRC Paul Graham also used vi most of his coding years. So yes, great things can be accomplished with vi in the Lisp galaxy. reply ngcc_hk 13 hours agorootparentprevBut that is old. Vim can easily interact with lisp real time. It would and probably never will be the same as emacs which is a lisp env. Still it is good enough. reply p_l 12 hours agorootparentGNU Emacs nor XEmacs also can not behave like ZMACS on lisp machines - there's just as much disconnect as between (n)ViM and lisp image. It's always a remote, RPC-like relation. In fact, I'd say that a certain ancient Erlang mode for Emacs resulted in closer relationship between Emacs and Erlang, as it made Emacs into a process in OTP cluster. reply mbrock 7 hours agorootparentThere's also an interesting SWI-Prolog mode that embeds the language runtime with dynamic linking and integrates quite deeply. reply sitzkrieg 14 hours agoparentprevi agree and went through the same struggles before totally giving up, i discovered racket along way tho so it was a net win reply medo-bear 12 hours agorootparentYou should give common lisp another chance and see what you have been missing in racket. reply bigstrat2003 3 hours agoparentprevYeah, I read this article with interest up until I got to the part where he admits you're gonna have to use either vim or emacs. I have no desire to subject myself to the pain of either of those editors, so I guess CL isn't for me. reply barrenko 34 minutes agoprevLisps are great to challenge your thinking, but (with Clojure) I got stuck at making sense of macros — way out of my depth at that moment in time. reply nomilk 16 hours agoprevGreat read. Highly fond of long single-pagers. Curious why lisp's REPL is frequently touted as an incredible language feature e.g.: > Support for this style of interactive development doesn't just come from some fancy editor plugins — it's baked into the bones of the language. > So how do you actually get this wonderful interactive experience? I've only ever programmed in interpreted languages (R, ruby), so I can't really understand how or why a REPL is so great since to me a (console|REPL|interpreter) is a standard feature (nothing extraordinary). Perhaps because I haven't had to work in a language without the convenient and immediate ability to execute arbitrary user inputs (as a REPL or interpreter can), for example a compiled language. reply julianeon 2 hours agoparentI can think of a REPL use case I don't know how to do easily in another language. Doable yes, but easily and conveniently, no. I want to build a little tool for the command line: meaning it should be runnable at any time I pull down my terminal, easily started and stopped. In it, I want to listen to a Telegram room. Basically the idea is, in this Telegram room, things are announced, and I want to look up some of them. It could be anything: sneakers, toys, concert tickets. But let's say crypto projects, as there is a running stream of them all day. (Doesn't have to be if you don't like crypto but let's go with it for now). So I'm printing this list of crypto projects to the screen. Every so often I want to hover over one and get more information about it. For example, pretend there's a project called PGPalooza, one of many that's being printed in this list that's spilling out in real time on my terminal screen. I scroll up to PGPalooza and run a command on it, and then it runs some commands and opens up a few browser windows that I can look at to learn more about it. This is easy to do in Lisp, in an intuitive natural way, that I don't think I could do with the same ease in other languages. You could think of this as demonstrating the benefits of interactivity in action. I can scroll up and modify the PGPalooza text to read lookup(\"PGPalooza\") and then press Ctrl-E at the end to return one type of data, and financials(\"PGPalooza\") to see another. It's also very easy to modularly add commands to it too, to expand on this. reply lgrapenthin 2 hours agoparentprevWhat most answers here are missing is pointing out the unique difference between a LISP REPL and an interpreter console/shell kind of thing, which is that it fits seamlessly into the languages design. I often see Javascript devs quite unimpressed by a REPL - \"I have a console, too\". And while Javascript admittedly comes close, its just not the same. What makes LISP REPLS special is precisely that there is nothing special about them. There are no extra ceremonies, caveats, or layers that turn a LISP into a REPL. Its conceptually a fourliner, merely replacing the compilers input of parsing text files with reading user input, while providing access to a modified environment after each step. This is possible not because of the REPL, but because of how LISP is designed. It understands going into packages, importing stuff, inspecting values all naturally, not via some \"interactive\" mode / layer. You are speaking to the compiler directly and it understands your language. For this reason it is much more reliable and natural to embed a REPL in your development process in LISP, than in other languages. reply ggm 15 hours agoparentprevHad you worked in Fortran, Pascal or Algol or C, and been forced to think linearly to a deck of cards, and a job queue, and do all the marshalling of the IO into that job queue through some horrendous syntax of JCL of some kind, then the experience of being in a REPL might be more momentus. Instead you're a fish swimming in clear water not understanding why water is so unbelievably amazing if you haven't been in it before. Of course LISPians want to make their REPL very meta, compared to any REPL, and it is: its degree of self-introspection, and the potential to modify the REPL is a REPL on steroids experience. But just being a REPL, is pretty damn amazing if you had to uplift from write-compile-assemble-marshall-coordinate-queue-run-cleanup \"before\" (I did learn on punched cards in the 70s. Bugs hurt at a 20 min production-to-run cycle, some people were a drive away from the batch queue, and a 1 day turnaround was good.) reply lispm 12 hours agoparentprev> compiled language more like \"batch compiled language\". In many Lisps one would incrementally compile code. Common Lisp has already three functions built-in: LOAD, COMPILE and COMPILE-FILE. How they work is depending on the implementation, but LOAD typically can load source and compiled files, COMPILE compiles a single function in memory, and COMPILE-FILE compiles a source file to a compiled file (native machine code or some byte-code). SBCL for example compiles with these functions every thing to machine code, which it does anyway, by default. One of the things which make this useable for incremental work is the symbol table, which holds all symbols and its values&functions. One can change the function of a symbol at runtime and global function calls go through this symbol table (-> late binding). So an update to a function has effect on its next call. reply nanomonkey 15 hours agoparentprevThe REPL can be much more than a prompt where you execute code. In fact with many editors you can evaluate blocks of lisp code directly. Networked REPL's are amazing, specially when you're fixing code on machines that are difficult to physically access, like in space. The ability to query the current value of a symbol (function, macro, variable, record) and replace it at runtime without clobbering the runtime state is a great boon to the development process. Also Common Lisp and a few Schemes allow you to interpret and compile a symbol's value (to speed up execution). reply ColonelPhantom 16 hours agoparentprevWhen using Python, the REPL does not feel remotely integral to the experience. For example, my Django project, when an exception occurs in debug mode, has a nice page with a backtrace et cetera. However, I cannot resume, or poke around using a REPL, or even view details of local variables. I feel like if Django was implemented in Common Lisp this would not be a problem at all, if not for technical reasons then for cultural reasons. reply matthewn 15 hours agorootparentIf you install the django-extensions package and use runserver_plus instead of runserver, when you hit an exception you get a live REPL in your browser where you can poke around and inspect at will. It's not CL-level power, but it's mighty useful. reply struanr 11 hours agorootparentFor non Django code, the IPython REPL with the %pdb magic enabled drops you in a ipdb debugger on an exception. Doesn't allow resuming but still very useful. reply wrs 16 hours agorootparentprevOver on the Ruby side, there is a library [0] that gives your web application error pages with a live REPL in them. [0] https://github.com/BetterErrors/better_errors reply troad 16 hours agoparentprevThe difference, as I understand it, is that the REPL is the running Lisp, and all of its code. You can inspect or redefine any function inside of Lisp itself, live, no matter how integral, in the same way you input any of your own code. The interactive mode of interpreted languages is more of a sandbox, from that perspective. reply lispm 12 hours agorootparentThe REPL often is also the default debugger. On error one gets a debug REPL at the point of the error (no unwinding), one debug level deeper. The debug REPL is basically a normal REPL, but with some debug features (stack movement, ...) and the ability to call predefined restarts in the code. reply reikonomusha 14 hours agorootparentprevThis is a pretty reasonable approximation. The REPL is also the library-fetcher, program loader, compiler, debugger, disassembler, and profiler. reply skydhash 13 hours agoparentprev> Curious why lisp's REPL is frequently touted as an incredible language feature e.g. Another language that’s great in that regard is Smalltalk/Pharo. It’s the Minecraft of programming languages. Your program start as an IDE and you morph it to what you want. Feels like building a car while it’s running. reply KingMob 8 hours agorootparentYes, touting the REPL of Lisps is a bit misleading. It's better to say that Lisps and Smalltalk(s) are deeply interactive programming experiences, in ways that most languages aren't yet. reply lispm 5 hours agorootparentIt's not that misleading, though, true, both provide various interactive development environments, with Smalltalk versions very much GUI tool based (with tools like the System Browser). Typically when one starts a Lisp development system, it will always start some kind of visible REPL. Either it runs it in a Terminal (most UNIX Lisps have a terminal REPL), runs it as a tool in its own GUI-based IDE (MCL, CCL, Allegro CL, LispWorks, Corman Lisp, ..., Symbolics Genera, CL + McCLIM) or runs the REPL frontend in a connected IDE (-> SLIME + GNU Emacs is a prominent IDE for CL, earlier this was done using subprocesses called \"inferior Lisps\" like in ILISP+GNU Emacs). The conversational REPL interface (typing expressions, evaluating the expression and getting a response) is widely used. Smalltalk has the \"Workspace\" or a Playground (-> Pharo) as similar tools. reply Qem 1 hour agorootparentSpeaking of Pharo, for those interested, enrollment is opening for the advanced MOOC scheduled to start next month: https://www.fun-mooc.fr/en/courses/advanced-object-oriented-... reply KingMob 1 hour agorootparentprevUhh, yes, I'm familiar. I write Clojure for a living. What's misleading is touting the acronym \"REPL\", instead of touting why that's important. Everyone who's used to the weaker \"REPLs\" of other languages don't understand what the big deal is, because they think they already know, so it's important to move past the acronym when explaining its value. reply spit2wind 14 hours agoparentprevHere's a great demo of the REPL: https://www.youtube.com/watch?v=_B_4vhsmRRI reply sourcepluck 9 hours agoparentprevI think this relatively short blogpost does an excellent job of answering your question: https://mikelevins.github.io/posts/2020-12-18-repl-driven/ reply killerstorm 15 hours agoparentprevJupiter works good as long as all your code is in one file. You can't really modify code outside of cells you made. In Common Lisp you can develop a project with multiple files interactively, you can even modify library code, maybe even the runtime reply nomilk 15 hours agorootparent> you can even modify library code, maybe even the runtime this would be difficult (and not recommended) but not strictly impossible in languages other than lisp (e.g. read library files, edit them, re-write them, re-load the library). But to play devil's advocate, isn't the language feature that makes this easy in lisp its homoiconicity, as opposed to its REPL? reply killerstorm 5 hours agorootparentNo. It is easy because: * The environment for top-level definitions in the file is almost identical to REPL. I.e. there's not much special about a file, thus you don't need a context of a file to submit a new definition. * Symbols provide an indirection mechanism which isn't tied to a specific location. * CLOS actually put a lot of effort into doing something reasonable on redefinition. Python module system is based on dicts. While it would seem like it would be easy to manipulate in runtime, module 's dicts are constructed by module-level import statements, and re-constructing the right state of all modules after an update might be tricky. OTOH if you update symbol's function in CL, every user of that symbol will pick up the new definition. It's also more performant than dicts: caller has a pointer to a symbol and needs to do just one indirection, there's no lookup at runtime. reply whartung 12 hours agorootparentprevAnother feature of CL, specifically CLOS, is that it actually has a formal protocol for changing classes. A formal protocol you can tap into. While hardly omniscient, I don’t know of another language that does offer this. I don’t even think Smalltalk has this. (Smalltalk has a fundamental primitive related to this called “become:”, which can be used for this purpose, but that’s less formal than what CLOS provides.) What does this mean? It means that you can change the structure of classes, AND their instances, in a live, running system. Not just their structure, but how the system transmutes from the old structure to the new structure. How the conversion is done. What does this have to do with the REPL? It’s part and parcel of the kind of environment and functionality of the system that is exposed by the REPL. The REPL is not just a console that you can type into, and use backspace, and what not. It’s the door to the very rich world underlying the system. And this is the key point. In CL, the REPL is not an afterthought. It’s not an add-on. It’s a core competency. Much of this no doubt came from the Lisp Machine experience, where all you had was a running image that, like a surgeon, you had your arms elbow deep into. A system where you could not trivially just stop and restart for every little change. A system where you had to have the ability to change the tires on a running vehicle. The vast majority of modern REPL environments don’t have that burden, so when things get tough, they can punt. “Eh, just restart and do over.” It’s absolutely fair to consider whether that quality is actually still germane in the modern era. Hard to imagine a scenario where you might do something like a change like this on a running server, especially in our age of “cattle, not pets”. But the legacy is still there from that past time. A time when not only were they pets, they were coddled and spoiled. So the folks back then had to think this stuff through. reply pjmlp 6 hours agorootparentThat is why I always give Lisp enviroments and Smalltalk as example, when someone comes up with the common excuse that Python cannot have good JITs, as it is too dynamic. Finally it is starting to change. reply pfdietz 5 hours agorootparentprevThe REPL is not an add-on in the sense that it comes with the implementation, but it is in the sense that if it were not provided, it could be implemented using only things available standardly in a Common Lisp implementation. reply baq 12 hours agorootparentprevIf AWS had an R&D Labs division with zero expectation of profit I think you could sell them an idea of Elastic Lisp Machine where a deployment is not a restart but whatever you need to do in the lisp world. (Patch an image…? No idea but sounds cool!) reply lispm 12 hours agorootparentprevThe language features that make this possible are a) late-binding and b) resident development tools (compiler, debugger, interpreter, inspector, trace, ... are all included in the runtime). reply killerstorm 5 hours agorootparentNot all kinds of late-binding is good. Python uses dicts which has more runtime overhead than symbols, but make it hard to develop code interactively. Consider foo.py def foo1(x): return x+1 bar.py from foo import foo1 def bar1(x): return foo1(x)\\*2 I can modify foo.foo1 in REPL: foo.foo1 = lambda x: x+3 but bar.bar1 will still use the old definition! bar1 lookups foo1 via a dict which is constructed when bar is imported, so it won't be updated unless I reload all files. So dicts are just wrong for this, there are too many of them. Symbols are basically perfect for this as they provide an easily manageable point of indirection and also much more performant. reply skydhash 14 hours agorootparentprevNot really. The runtime, plus your code is a virtual machine. It’s similar to docker container in that regard. The REPL is your shell. And you can poke around everything. Another language that has that is Smalltalk/pharo. In comparison, the Python REPL feel like the os part was burned on ROM. reply p_l 14 hours agoparentprevAn important thing to remember is that both R and Ruby have directly, wholly, imported the REPL approach (not just having an interpreter you can type at, like Python) from Lisp/Common Lisp - with R arguably fitting as Lisp-family language if with different syntax (Ruby's other inspirations were Smalltalk obviously, and less known was being Perl replacement) reply hayley-patton 13 hours agoparentprevThere's a lot of language semantics which make the REPL convenient to write interesting amounts of code in, Gilad Bracha details some in(with the message reflected in the medium, embedding the Newspeak IDE in the document for examples). It's unrelated to compiling or interpreting; many Common Lisp implementations will compile code from the REPL too. reply dang 16 hours agoprevRelated: A Road to Common Lisp (2018) - https://news.ycombinator.com/item?id=31645558 - June 2022 (48 comments) A Road to Common Lisp - https://news.ycombinator.com/item?id=17852194 - Aug 2018 (92 comments) reply nesarkvechnep 9 hours agoprevI really like Common Lisp! Unfortunately, I can’t really find a use case for it. I usually develop web services and there Elixir and Erlang are winners in my book. For command line tools I use Rust or C. Can someone recommend types of applications where Common Lisp shines? I guess one can always write the business logic in CL and expose it via Unix socket. reply citizen_friend 5 hours agoparentThis is an odd question. Web services are great with CL. But you already have languages you prefer. So yes, you must be interested in CL to want to replace one of those. reply vindarel 8 hours agoparentprevCL is very general purpose. Where it shines IMO is: the development experience (interactive, good compile-time type warnings with SBCL), the stability, the delivery of applications (compile to a self-contained binary), the overall feature set. I use it for web back-ends and little scripts. Everything's stable, my Sentry dashboard is empty. [edit: sorry, just had a stupid production error in my Python app] Some friends love Elixir and do great things with it, but I'm in your reverse situation: I don't have enough incentives to switch. Elixir's REPL is good but it's only a REPL, not an image-based experience. Its Emacs modes are rudimentary. Phoenix looks great, but it's very opinionated (and very much code-generator oriented, strange). I can't copy-paste a binary to my servers (or other users). The Torch admin dashboard looks cool, but I just made my own in a week-end (and again, I'm afraid by code generation). LiveView looks awesome but it's its own little world and I might approach it with HTMX and HTMX websockets. TLDR; I can do both web apps and CLI tools with CL and switching must be worth it too. reply nick__m 7 hours agorootparentand again, I'm afraid by code generation Do you use macro and higher order function? If you do, you already use code generation, so why are you afraid ? reply vindarel 7 hours agorootparentI mean code generation that writes code to files. I'm afraid they bit rot fast and make upgrading harder. Macros generate code on the fly, not in my source files. reply medo-bear 7 hours agorootparentprevBecause macros in common lisp are very easy to grok, which is not to say that common lisp programmers promote willy-nilly use of macros reply nick__m 7 hours agorootparentUnlike Scheme, CL macro are glorified template based code generator. If your not careful to use facilities like gensym and packages it easy to accidentally capture already binded terms at call site. reply lispm 6 hours agorootparentIf we look at macros in Scheme R7RS they are mostly transformers on patterns. -> https://standards.scheme.org/corrected-r7rs/r7rs-Z-H-6.html#... > If your not careful to use facilities like gensym and packages it easy to accidentally capture already binded terms at call site. Luckily CL programmers have heard about that and are usually careful about that. reply nesarkvechnep 7 hours agorootparentprevThank you! I read some time ago that compilation to binaries is not really a solved problem. Also the ecosystem was very lean. At the same time you need to include a dependency for everything because the standard library is also lean. You’re mostly right about Elixir but Phoenix is not opinionated, at all. It’s code-generation oriented only if you want to use the generators. I don’t use them. reply vindarel 7 hours agorootparentack, thanks. I still want to see what I'm missing, so I'll keep trying. Compilation to binaries works fine. A SBCL binary will weight ±35MB (compressed, 120MB uncompressed). This includes everything (compiler, debugger etc). A bigger app with dozens of deps doesn't grow too fast, like ±40MB for a web app. I think that's in the ballparks of a growing Go app. LispWorks allows to shrink the binary size to ±4MB (but then you can't connect to it remotely and live reload the running image). Start-up times are very fast. A SBCL binary relies on GLIBC. There was a patch for truly static binaries, needs more care (https://www.timmons.dev/posts/static-executables-with-sbcl-v...) It's true you need to choose and include a dependency for common tasks: HTTP client, JSON and CSV… As for \"lean\", well, it depends. See awesome-cl. CL's ecosystem is richer for some tasks than other emerging and trendy languages, poorer in some areas. Interfacing with Java or Python is possible (ABCL and LispWorks, py4cl2). reply citizen_friend 5 hours agorootparentprevANSI Common Lisp was criticized when it came out for having a bloated standard library and feature set. It’s not extensive like python, but it’s not C. reply whobre 8 hours agoparentprevEven the author of the article says he uses Scala professionally. reply medo-bear 7 hours agoparentprevAs far as use cases are concerned, I think of Common Lisp as a higher level C with much better ergonomics. My particular use case is prototyping low level computations for performance tuning. Common Lisp excels at prototyping. I guess if you need to implement something for which there already exist 20 other libraries there is not much point, which is also the reason I'm not a huge fan of Rewrite in Rust movement. reply surfingdino 7 hours agoparentprev> (...) types of applications where Common Lisp shines? An application to Y Combinator? /s reply huygens6363 5 hours agoprevI love the concept of the REPL and live editing and such, but my everyday work experience using a debugger sounds like it’s about 80% of the way there? I can break, inspect, run expressions and generally figure out what’s going on by experimenting. Maybe not edit code directly, but I honestly never feel the need. Looking and poking around is in the vast majority of cases all I need. Am I missing something incredible? reply vindarel 2 hours agoparentI suggest: do you find yourself often quitting the debugger and re-running the same test, the same task from the start? You can avoid that in CL. Just leave the debugger open, go to the buggy line (\"v\" on a stacktrace in Slime), fix the function, re-compile it on the fly (C-c C-c in Slime), come back to the debugger, resume the program from the stackframe you want, now it passes. If the first steps were taking 10 minutes, you just saved yourself some time. You don't need special needs for that, it's a fast workflow I use everyday. demo: https://www.youtube.com/watch?v=jBBS4FeY7XM debugging a complex stacktrace: Python VS CL: https://lisp-journey.gitlab.io/images/debugging-python-VS-li... Another important point: we debug everything while keeping the current state in memory (in the image). We don't have to re-create our test data. All the program state is kept live, until we restart the image. reply 7thaccount 5 hours agoparentprevIn a lot of cases... probably not in my experience. I think it can make a big difference in some cases though. What REPL were you using though? Something to think about is that the Lisp and Smalltalk REPLs are a lot more powerful than Python in that I think when an expression fails, the program itself can be edited and it will start where it left off. You can't do that with Python. Edit: the article does a good job of explaining this as \"It's like if you could run your code in a debugger with a breakpoint at every single line that only activates if something goes wrong!\" reply huygens6363 1 hour agorootparentModern (proprietary) tooling comes really close to that experience, but I can see how it is liberating compared to editing text files, waiting for compilation and preying it works. I guess modern tools learned from the best. reply vindarel 8 hours agoprevIt's a great article. Since 2018 though, we have more tools and resources so we can enhance it. (I copy/edit a comment of mine from last thread) ## Pick and Editor The article is right that you can start with anything. Just `load` your .lisp file in the REPL. But even in Vim, Sublime Text, Atom/Pulsar, VSCode, the Jetbrains suite or Jupyter notebooks, you can get pretty good to very good support. See https://lispcookbook.github.io/cl-cookbook/editor-support.ht... > if anyone is interested in making a Common Lisp LSP language server, I think it would be a hugely useful contribution to the community. Here's a new project used for VSCode: https://github.com/nobody-famous/alive-lsp There's also https://github.com/cxxxr/cl-lsp ## Libraries He doesn't mention this list, what a shame: https://github.com/CodyReichert/awesome-cl => the CL ecosystem is probably bigger than you thought. Sincerely, only recently, great packages appeared: CLOG, sento (actors concurrency), 40ants-doc, official CL support on OVH through Platform.sh, great editor add-ons (Slite test runner, Slime-star modules…), Coalton 1.0 (Haskell-like ML on top of CL), April v1.0 (APL in CL), a Qt 5 \"library\" (still hard to install), many more… (Clingon CLI args parser, Lish, a Lisp Shell in the making, the Consfigurator deployment service, generic-cl)… His list is OK, I'd pick another HTTP client (Dexador instead of Drakma) and another JSON library (jzon or shasht), new ones since 2018 too, but that's a detail. BTW, see also a list of companies: https://github.com/azzamsa/awesome-lisp-companies/ (nothing official, we add when we find one) ## Other resources The Cookbook (to which I contribute) is a useful reference to see code and get things done, quickly. https://lispcookbook.github.io/cl-cookbook/ While I'm at it, my last shameless plug: after my tutorials written for the Cookbook and my blog, I wanted to do more. Explain, structure, demo real-world Common Lisp. I'm creating this course (there are some free videos): https://www.udemy.com/course/common-lisp-programming/?coupon... You'll learn CL efficiently and support an active Lisper. ## Web Development See the Cookbook, and the awesome list. We have many libraries, you still have to code for things taken for granted in other big frameworks. I have some articles on my blog. I have a working Django-like DB admin dashboard, I have to finish the remaining 20%… We have new very cool kids in town, especially CLOG, that is like a GUI for the browser. Check it out: https://github.com/rabbibotton/clog ## Game Development See again the awesome-cl list. And the Kandria game, published on Steam, all done in CL: https://kandria.com/ ## Unit Testing We have even more test frameworks since 2018! And some are actually good O_o ## Projects To create a full-featured CL project in one command, look no further, here's my (shameless plug) project skeleton: https://github.com/vindarel/cl-cookieproject you'll find the equivalent for a web project, lighter alternatives in the README, and a demo video: https://www.youtube.com/watch?v=XFc513MJjos&feature=youtu.be ## Community We are also on Discord: https://discord.gg/hhk46CE and on Libera Chat. ## Implementations CLASP (CL for C++ on LLVM) reached its v1.0, congrats. https://github.com/clasp-developers/clasp/releases/tag/1.0.0 More are in the making… We got dynamic library delivery tool for SBCL (sbcl-librarian). There's a rumor from the European Lisp Symposium that a feature beginning in \"co\" and lasting in \"routine\" is coming to SBCL. Allegro CL (proprietary) got a new version running in the browser… Crazy Lisp worldJSON support in Common Lisp is a god damn mess Is the JSON situation any better now in 2024? reply ludston 9 hours agoparentYes. The trend is towards standardizing on an library called jzon. It's pretty decent. reply varjag 10 hours agoparentprevThis piece is enthusiastic but a bit subjective. I personally had zero troubles with JSON in CL, just chose one library and use it. Would also disagree with some his recommendations, e.g. Drakma has a lacking interface for error handling and Dexador is nicer for use in prod. reply cess11 10 hours agoparentprevJSON is a messy format, you'll always have to know your requirements well to be able to pick a fitting parser for it. Are you going to parse a simple, small key-value-structure? Pretty much any library will solve it for you or you could invent your own simple parser. If you need to stream gigabytes of complicated JSON and do sophisticated transformations back into JSON or something like that, then you'll have to evaluate several libraries and have a look at how they translate into CL datatypes. Some might reduce a combination of false, null, the empty list to NIL, which could lead to information loss and surprises. reply e12e 17 hours agoprev(2018) reply next_xibalba 4 hours agoprevThis comment could read as provocative but it is not intended to be. It’s a genuine question: Lisp seems to get outsized attention on HN. If Lisp is so good, why isn’t its use more widespread? *Maybe it’s disproportionate attention on HN is just a pg remnant? reply vindarel 2 hours agoparentThe other way around: its use might be more widespread than one thinks, because it is still used in the industry, it is still chosen by new companies. https://github.com/azzamsa/awesome-lisp-companies/ (nothing official here) For instance, CL seems a corner stone for quantum computing these days. Not saying it is widespread, of course. reply tmtvl 4 hours agoparentprevI think it's a combination of reasons: people aren't used to the syntax, so it turns some of them off from giving Lisp a try, Lisp machines didn't take off and their competition didn't have great Lisp support, when computers became more powerful and better suited for Lisp it was seen as older and not as hot as the new things like Perl and Java, and there's still the perception that because Emacs offers a truly first-class Lisp experience that other editors won't work so well for it. And of course because of those various reasons the Lisp community is rather small so it creates the vicious cycle of 'the community is too small and there are no libraries so I won't use it' into 'there are too few people using it so there's a small community and less manpower to make various libraries'. reply intelVISA 1 hour agoparentprevRumor has it that HN accs are ranked by mentions of Lisp, if you fall too low you risk 'problems' from The Powers That Be. reply BeetleB 4 hours agoparentprevAnd this comment is asked every time a Common Lisp submission comes up. Perhaps go and read prior answers? > If Lisp is so good, why isn’t its use more widespread? What does \"good\" and \"widespread\" have to do with each other? Mildly orthogonal concerns. As a tech junkie, one experience that has been consistent all my life is \"the best stuff is almost never widespread\". When I was in to digital cameras, the \"best\" camera was rarely the widespread one - both pre-DSLR and after. The best file management utility is not the widespread one. The best radio is not the widespread one. The best TV is not the widespread one. The best SW for a task is often not the most widespread one. I know I'm not answering the question. Instead, I want you to ponder the faulty premise in your question. Instead of tying your question to \"widespread\", why not simply ask why people like Common Lisp so much? It's like asking \"If that job is so awesome, why doesn't it pay well?\" reply next_xibalba 2 hours agorootparent> Perhaps go and read prior answers HN is not a knowledge base or docs. It’s a forum. Perhaps you should go and read the HN guidelines? reply samatman 6 minutes agorootparentprevYou're giving me absolutely terrible comp.lang.lisp flashbacks here. reply TerrifiedMouse 3 hours agoparentprev> If Lisp is so good, why isn’t its use more widespread? The Lisp Curse: http://winestockwebdesign.com/Essays/Lisp_Curse.html reply sapling-ginger 17 hours agoprevThe author first says that CL people usually avoid dependency hell: >When programming applications in Common Lisp people will often depend on a small(ish) number of stable libraries, and library writers often try to minimize dependencies by utilizing as much of the core language as possible. But then try to expound on CL's extensibility using libraries: > No one has been clamoring for a new version of the specification that adds features because Common Lisp's extensibility allows users to add new features to the language as plain old libraries Very contradictory, and these two paragraphs are in two adjacent sections. reply iLemming 16 hours agoparentAs other pointed out, there's no contradiction. I would like to add that CL often avoids dependency hell with: - Standardized Specification: Common Lisp has a stable and comprehensive standard that reduces the need for external libraries. - Load Time Flexibility: Its dynamic nature allows loading and reloading of code at runtime, facilitating easier management of dependencies. - Isolation through Packages: The Lisp package system provides a way to encapsulate code and manage namespaces effectively, reducing conflicts. - Backward Compatibility: Common Lisp places a strong emphasis on backward compatibility, which helps in maintaining stability across versions. - Mature Ecosystem: Many Common Lisp projects are long-lived and stable, leading to a mature ecosystem with less frequent breaking changes. I can't claim to be a very experienced CL coder, but I wrote enough Clojure, and similarly, rarely ever see dependency problems, even though Clojure heavily relies on the JVM ecosystem, inheriting both its strengths and complexities. Clojure emphasizes interoperability with Java and uses many Java libraries, which can introduce complex dependency trees and conflicts common in the Java ecosystem, yet at the same time, Clojure emphasizes small, composable libraries (often referred to as the \"small libraries\" philosophy), reducing the likelihood of large, monolithic dependencies causing issues. The community prioritizes modularity and ease of composition, leading to the prevalence of smaller, more focused libraries. Common Lisp in contrast tends to favor more extensive libraries or systems that provide a broad set of features within a single package. reply skydhash 14 hours agorootparentThe thing is that’s once you’ve casted most external inputs to lisp data structures, you don’t really need anything else other than utility algorithms (crypto,…). And with metaprogramming, it’s easier to do stuff without special classes and decorator. You can visualize the code as data being transformed, as a chain of transformers, or when you do metaprogramming as data generating code and code generating data. It’s all organic and you can do a lot without external code, because very soon you’re coding with a language adapted to your problem domain. To GP: Think about how simple the HTTP protocol is (the core), so if you want a web framework, you want something that will map the headers and the body to cl data structures and then you can go to solve smaller problems like routing, auth, response generation,… Then you notice boilerplate and you macro them out. Same for most client libraries. It really easy to add an ad-hoc library that solve your problems. So you do that instead of reaching to others’ code. reply kloop 15 hours agoparentprevThe lisp world has a rather different idea of extensibility via library than you are used to. For example, the Common Lisp Object System (CLOS, object oriented programming in lisp) originated as a library. Lisp's main looping mechanism (loop) also originated as a macro (although long before CL standardization). You just don't do js levels of dependencies when they're adding big features like that. You don't need 100,000 programming paradigms in your code base. reply mepian 17 hours agoparentprevHow is this contradictory? The point is that you can extend the language when you really need it. reply fuzztester 17 hours agoparentprevI don't see any contradiction in those two points. Both of them can simultaneously be true. reply julianeon 3 hours agoprevThere's some serious cognitive dissonance going on in this section: As an open-source project, Racket is posi­tioned at a happy medium. The core devel­op­ment team has been working together for years, and the commits remain fast & furious. But they’re friendly scien­tists, not Shire-dwelling egotists, and remain recep­tive to improve­ments across the whole system. If you have a better idea, they’ll listen; if you code it up to their stan­dards and make a pull request, they’ll take it. [2021 update: I no longer contribute to Racket due to abuse & bullying by the project lead­er­ship. Everyone in the broader Racket commu­nity, however, has always been helpful and kind.] reply Jtsummers 2 hours agoparentThat's not cognitive dissonance, that's \"I wrote a thing when I held one view. Instead of changing it entirely here is an additional comment that revises my previous one. I'm not going to edit the original.\" The order of things matters. \"I hold this view which contradicts my earlier, no longer held, view.\" is not cognitive dissonance. \"I hold this view despite it contradicting my other view.\" is cognitive dissonance. reply vindarel 2 hours agoparentprevWrong thread? There is no mention of Racket here. reply Jtsummers 2 hours agorootparentMy guess is they meant to respond to this comment: https://news.ycombinator.com/item?id=40442347 But somehow didn't hit reply and just made it a top level comment instead. reply ativzzz 3 hours agoprev [–] This article fails to explain why lisp. People talk about it on HN sometimes. This article says \"here's how to learn it\". Why should I learn it? There's a million languages out now that I can learn instead. The author gives a few ways I can use lisp. Why would I choose lisp over any of the other languages that have stronger ecosystems that solve those same problems and are built specifically for them? The syntax looks arcane and it seems that the most prevalent modern use for lisp is emacs, so if I don't use emacs, why lisp? reply pjlegato 2 hours agoparentIn brief, Lisp's S-expressions (the parentheses) are a straightforward instantiation of the abstract syntax trees to which all other languages parse. You can manipulate that tree easily and directly in Lisp, whereas other languages (that are not variations of Lisp) hide parts of it, to varying degrees. All other languages are either equivalent to Lisp, perhaps with a different superficial syntax (there are very few of these; one is Mathematica) or expose only a strict subset of this capability (most other non-Lisp languages.) In particular, Lisp makes it trivial to do (real) metaprogramming -- programs that write other programs, including the introduction of entirely novel syntactic constructs -- via macros. Lisp macros can create new language syntax that controls when and how code is evaluated, perhaps rewriting it. Non-Lisp languages can't do that fully, only subsets of it. Ruby metaprogramming, for example, is clever syntactic sugar. You can give methods clever names and use clever calling conventions so that they read more similarly to English, which is called \"metaprogramming\" in Ruby; but you don't have universal control of the parsers from the level of ordinary Ruby code, and you can't completely control when and how code evaluation happens. Now, how practical or useful is all that? Opinions vary, from hardcore \"you should invent a full DSL with unique syntax for each particular application\" Lispers, all the way to those who say macros are a fun but dangerous toy with limited practical value. reply lgrapenthin 3 hours agoparentprevThe article is not trying to sell you on Lisp, in its first sentence it clarifies, that it is written for people who were \"asking for advice on how to learn Common Lisp\"... reply uncleshelby 3 hours agoparentprevMatthew Butterick wrote a book about Racket (a dialect of Lisp) which has a great appendix that tries to explain why Lisp is worth learning: https://beautifulracket.com/appendix/why-racket-why-lisp.htm... There are lots of evangelist explanations for why Lisp is The Best out there, but this is one of the better and more concrete ones. reply nomilk 3 hours agoparentprev [–] Not sure how much other languages developed in 22 years since this essay, but PG makes the case for lisp here: https://paulgraham.com/icad.html Computerphile riffs on the importance of homoiconicity and the ability for a language to programatically alter itself: https://www.youtube.com/watch?v=dw-y3vNDRWk Uncle bob had tried many languages and settled on lisp: https://www.youtube.com/watch?v=UBXXw2JSloo&t=2m40s > for 30 years I thought I don't want to learn lisp, it's a dumb language, and I read (Structure and Interpretation of Computer Programs) and it changed my mind... I thought I'm going to get (clojure) and dither around with it.. and I just fell in love with the language and I've been using it ever since reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post \"A Road to Common Lisp\" offers a comprehensive guide on learning Common Lisp, covering its historical context, practical steps, and recommended tools and libraries.",
      "It emphasizes Common Lisp's stability, backwards compatibility, and extensibility, contrasting it with modern languages that often require significant maintenance for outdated libraries.",
      "The post provides practical advice on minimizing dependencies, using stable libraries, setting up a development environment, and engaging with the community, along with advanced learning resources and debugging practices."
    ],
    "commentSummary": [
      "The discussion highlights the challenges of using text editors for Common Lisp (CL) development, noting the superior plugin support in Emacs with SLIME compared to Vim.",
      "Alternatives like Doom Emacs, Spacemacs, Conjure for Neovim, Atom, VSCode, and Jupyter notebooks are suggested for better CL development experiences.",
      "The conversation emphasizes Lisp's REPL (Read-Eval-Print Loop) for real-time interaction, its dynamic coding capabilities, and the complexities of CL macros, while also addressing the limited adoption of Lisp due to its unfamiliar syntax and historical context."
    ],
    "points": 208,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1716335979
  },
  {
    "id": 40433511,
    "title": "Wikimedia Enterprise Unveils APIs for Enhanced AI Training and Search Engine Integration",
    "originLink": "https://enterprise.wikimedia.com/",
    "originBody": "Enterprise-grade APIs for Search Engines, LLMs, Deep Learning & more Enrich user experience by improving answers to user questions and augmenting search results no matter your platform size. Get Started Now → Real-time access to Knowledge Retrieve or Stream data from Wikimedia projects in any language, access metadata packaged exclusively for Wikimedia Enterprise. Detect vandalism and important updates at the article level. Built for Search & Knowledge Graphs Unleash the potential within your own organization. Use Wikimedia Enterprise to populate and refine knowledge graphs, LLMs, voice assistants, training models, AI and so much more. Latest Blog Article More Data with every Article Revision and Probability of Revert Our APIs have been updated with new metadata about every article edit along with a Probability of Revert helping you make more informed decisions. The Version object has some impressive updates we’re excited to show you. Jump to the article → API Solutions Data Delivery You Can Trust Frequent Access the most current and accurate information, and ensure that your content is up-to-date and relevant. Daily and hourly snapshots and available real-time service make out-of-date exports a thing of the past. Reliable Written agreements, no additional content restrictions, SLAs, 24/7 support, and contractual guarantees against surprise breaking changes make working with Wikimedia Enterprise safe and reliable at scale. Usable Wikimedia Enterprise APIs are well-documented and supported by a dedicated team of engineers, making it easier for your team to get started and implement. Reliable & Consistent Wikimedia Content Content With Integrity Reduce risk by improving the accuracy and reliability of content served to your users. Wikimedia Enterprise has multiple tools and processes designed to help detect the introduction of inaccurate or biased information in project content. Machine Readable Parse and extract specific information from well-structured, well-documented services. Access multiple machine-readable data formats with globally consistent identifiers and API responses, whether you’re requesting a single article, an entire project’s snapshot, or the real-time stream. Learn about our APIs Read the API Docs What Data is included in the APIs? Wikimedia Enterprise API Project Data Wikipedia alone has grown into the world’s largest reference website. Wikimedia Enterprise APIs make it easy to access the knowledge contained across Wikipedia, in over 330 language editions, along with other Wikimedia Projects. Explore Included Project Data → 850+ unique datasets 100M+ unique project pages 20M+ monthly edits",
    "commentLink": "https://news.ycombinator.com/item?id=40433511",
    "commentBody": "Wikimedia Enterprise – APIs for LLMs, AI Training, and More (wikimedia.com)207 points by ks2048 22 hours agohidepastfavorite137 comments bawolff 21 hours agoWhile i am sympathetic to wmf finding alternative funding streams, I do get nervous about these sort of things due to the inherent conflict of interest and incentives to canabalize the free offerings. I'm not saying that is happening now, but will it happen eventually? Additionally, originally it was promised this would all be open source, and officially they are sticking with that, but it seems like they are going with the model of throwing code over the fence like once a year, which does not really meet my expectations. reply tw04 15 hours agoparent> While i am sympathetic to wmf finding alternative funding streams Why are you sympathetic to it? Their fund, at this point, can make enough off interest on a basic CD to not just pay for every possible cost they could have until the end of time, but make the maintainer(s) obscenely wealthy without breaking a sweat. https://upload.wikimedia.org/wikipedia/foundation/3/3e/Wikim... $250m - they’re doing this out of greed, not need. reply ff317 15 hours agorootparentOver the long term of many years you're /lucky/ if a stable very-low-risk investment can net ~3% when accounting for inflation. Thus $250M could maybe net you roughly $7.5M/year. Exactly how many network links, servers, and engineering staff do you think that buys? It's way under what it operates on today, which is way under what it ideally should be for site like Wikipedia. And that's /just/ the operational engineering of the sites on a technical level. You also need HR, you need Finance, you need a lot of Lawyers, you need software developers, you need a travel department, a fundraising team, PR people, community relations people, grant-making for the extended open ecosystem around the Wikimedia movement, conference planning, and the list goes on. You're off by enough to seem troll-ish at best. reply flipbrad 9 hours agorootparentIt would be nice if we had a \"lot of lawyers\", given how frequently we're sued to try and get content censored, or having to fight orders to hand over user data - and more generally, how massive these new laws we need to comply with are (see, e.g., the EU Digital Services Act, which even creates an entirely new annual independent audit process). We even intervene in other court cases to try and prevent bad laws being created/interpreted in ways that would hurt the open internet (see, e.g., our amicus in the French Constitutional Court two weeks ago, our lawsuit against the US NSA, and our amicus briefs in the two US \"Netchoice\" US Supreme Court cases). We also operate the https://foundation.wikimedia.org/wiki/Legal:Legal_Fees_Assis... Sadly, we're a very tight team. The downsides of being a nonprofit... Anyhow, I'm going to assume people are just ignorant as to how much WMF does, not deliberately trying to undermine it. https://meta.wikimedia.org/wiki/Assume_good_faith , as they say. (disclosure: lawyer for WMF) reply bhickey 8 hours agorootparentIt isn't a question of the good work you do. People care about Wikipedia, not the Wikimedia Foundation. The criticism arises from misleading advertising. WMF fundraising conflates the two, implying that _Wikipedia_ needs money or it'll die. Meanwhile the 2023 budget shows $3.1m in hosting expenses versus $24.4m in awards and grants. reply flipbrad 1 hour agorootparentFirstly, there's less conflation these days - go see recent banner wording for yourself. Secondly, if you're still just acknowledging Wikipedia hosting costs - and thus pretending there's (for example) no legal work necessary for it - I don't think people are getting through to you as they should. (And no, I'm not saying all legal work we do is a strict necessity for Wikipedia. Some is a strict necessity, and some is strategic e.g. an amicus, or the NSA lawsuit - but the latter does help secure a healthy environment for it and future projects that might want to take its place.) reply mrweasel 4 hours agorootparentprevThat is an issue. There is a number of projects that the Wikimedia Foundation want to do or be involved in, because they align with the mission. These all costs money, but are frequently of little interest to anyone not involved directly. There is absolutely no way to fund these, which leads to the foundation pushing for donations via Wikipedia, because that's the only thing enough people actually care about. For the most part Wikimedia could kill off everything but English, Germany, French, Russian and a handful of other wikis and most people would be just as happy. Wikimedia absolutely suck at telling people why they need the money. Technically the budget is completely transparent, it's just communicated extremely poorly. reply tw04 15 hours agorootparentprevWhat are you talking about? The AVERAGE CD right now is 5%. My local CU is almost 6%. US bonds are currently ~4.5% - if you consider those unstable, I guess the US economy isn't stable - and if the US economy crashes, wikipedia will be the least of their or our worries. Wikimedia's expenses are almost ENTIRELY going to staff. Their balance sheet for 2023 included $101m in expenses for salaries and benefits out of a total expense of $160m. Their hosting was $3m. So yes, I'm confident their network links and servers cost almost nothing, and they don't need anywhere near $101m in compensation to keep the lights on when the VAST majority of their content is contributed for free. https://wikimediafoundation.org/wp-content/uploads/2023/11/W... reply bawolff 14 hours agorootparent> Their hosting was $3m Its kind of unclear what this includes. Computer equipment is a separate line, and wikimedia owns its own servers, so presumably that is separate from server costs. You don't have to buy new servers every year so some servers might simply have been purchased in other years, although maybe that gets ammortized, i dont know. Additionally when you host your own servers you need staff to operate them. When using something like AWS, this would be part of your AWS fees, but if you operate your own servers then you have to pay that part separately. Its probably cheaper overall in the end when you are wikipedia scale, but the costs break down differently. reply kemayo 14 hours agorootparentprevYou may have missed them saying \"when accounting for inflation\". In the US at the moment that's around 3%. Thus your local credit union's savings account, a nice and stable investment, is effectively giving you around 3% appreciation in real-money each year right now. (I have no idea whether their broader point about the rate over-time is correct, admittedly.) reply remus 13 hours agorootparentprev> What are you talking about? The AVERAGE CD right now is 5%. My local CU is almost 6%. US bonds are currently ~4.5% - if you consider those unstable, I guess the US economy isn't stable - and if the US economy crashes, wikipedia will be the least of their or our worries. If you want to live off the interest you have to worry about inflation which essentially devalues your pot by x% per year, so if you really need y% for running costs you really need about x*y% to do it long term. reply yareal 13 hours agorootparentprevAn engineer costs $500k a year. Salary, benefits, office space, equipment, hr, legal, and other overhead. The engineer will only see a fraction of that, of course. If you told me it took a hundred engineers to run Wikipedia I'd say, that's not totally unreasonable. Features, design, api, scaling, moderation, there's a ton for engineers to be doing. reply JimDabell 4 hours agorootparentAn engineer doesn’t cost $500k/yr. An engineer who lives in one of the highest cost-of-living places on earth costs $500k/yr. There’s absolutely no reason Wikimedia needs to pay that much. reply sciurus 7 hours agorootparentprevYour overall point still stands, but FWIW Wikimedia pays less than its peers. To compare two active listings Senior Security Engineer at Mozilla (https://boards.greenhouse.io/mozilla/jobs/5803609): $124,000 to $199,000 plus bonus Senior Security Engineer at Wikimedia (https://boards.greenhouse.io/wikimedia/jobs/5890112): $105,000 to $164,000 reply yareal 5 hours agorootparentThe rule of thumb is that employees cost the company double what they pay the employee. So, still hundreds of thousands per employee. reply ryan_lane 13 hours agorootparentprevHosting means nothing without the staff. Hardware, networking, datacenters, etc are the cheap part because the staff are good at their jobs. You and the other set of trolls that think that Wikimedia can run itself need to appreciate that just because you work for a non-profit doesn't mean you should work for slave wages, or that you should be forced to work with the bare minimum amount of staff to keep things running without being able to make improvements to the infrastructure, reader experience, editor experience, or data consumer experience. In comparison to similar services, Wikimedia has a relatively small overall budget that's well spent. reply bawolff 14 hours agorootparentprevThis is a rediculous thing to say. You think the interest off 250 million would be enough to run the wikipedia website? Do you have any experience operating web properties at scale to come to this conclusion? Did you base this on anything at all? reply Brybry 13 hours agorootparentI don't agree that it's pure greed but hosting costs for the Wikimedia Foundation in the FY2022-2023 were $3.1 million. [1][2] [1] https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2... [2] https://wikimediafoundation.org/wp-content/uploads/2023/11/W... (page 4, pdf page 6 for expenses) reply bawolff 11 hours agorootparentSure, but hosting costs are a very small part of the costs of running a website (and tbh, its super unclear what hosting costs do and do not include. Do they include the cost of servers? Is it just peering costs and renting rackspace? At the very least they do not include staff. Servers are pretty useless if you don't have anyone to hook them up and manage them) reply Shrezzing 8 hours agorootparentprevHosting costs are £3m, but total expenditure is $160m - which obviously isn't covered by the interest on $250m. reply Contax 7 hours agorootparentprevI don't know what it takes at the scale of something like Wikipedia, but at my own scale, a single/self-employed developer, yes, hosting costs are a small part, but then I have to eat, a place to live, replace hardware, pay bills and taxes and much much more, things none of my sites could exist without. Hosting is nothing without coders and maintainers, regardless of if the main content is contributed free, and decent coders and maintainers, software and hardware engineers, aren't cheap and don't count as hosting costs. reply olalonde 10 hours agorootparentprev1M$/year used to be enough. Source: https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2... reply bawolff 8 hours agorootparentWhy stop there, the site cost $0/year back in 1999. reply lakomen 12 hours agorootparentprevHosting 80GB of data? Absolutely. Even if it was 800GB. reply bawolff 11 hours agorootparentUmm, its roughly 500 terabytes if you include uploaded files, but that is besides the point. Hosting a bunch of static data is really easy but only a small part of running a site like wikipedia. reply chillydawg 12 hours agorootparentprevthe expensive bit of serving big websites is the ads, the tracking, the analytics, the vast internal teams focused on endless avb testing etc. if you boil Wikipedia down it's mostly static pages with a crud editor. it's cached to the moon and back, most pages don't change. the pages are tiny. they're not paying aws for bandwidth. reply bawolff 11 hours agorootparent> most pages don't change Generally the pages that are viewed a lot change a lot. Sure, there is a long tail of mostly static pages, but that is not super relavent. reply choppaface 15 hours agorootparentprevHarvard is also exceptionally greedy to charge tuition, but also it wouldn’t be fair for legacy admits to get the brand and network without paying what is peanuts to most of those families. LLM trainers need to pay for Wikipedia to help balance the information economy. If Google had to pay something substantial versus just lifting the content into their own “smart” results, then other sites would follow and wouldn’t have to rely on crappy SEO tricks. Another perspective is that LLM trainers have largely been so disrespectful of IP / copyrights from their own greed that the content creators need to fight back with greed of their own. If the WM approach to media loses out to corporate and/or state control, it could e.g. make the Western internet much more like state-owned China. Not entirely convincing arguments but it’s probably going too far to call WMF too greedy. reply yareal 13 hours agorootparentprevYour own link shows investment income as about $3-4m. Nowhere near enough to pay for infrastructure and engineers, let alone all the other things you need to operate Wikipedia. If you want to argue against finding Wikipedia you are going to have to do so in something approximating reality. Because the idea that they could somehow operate on one percent of their first budget is completely off base. reply toomuchtodo 20 hours agoparentprevI’d rather Wikipedia offer it versus a for profit enterprise using their dataset. Cut out the middleman and vertically integrate. reply kemayo 19 hours agoparentprevThere's a whole statement-of-principles thing that at least implies that the intention isn't to cannibalize the existing offerings: https://meta.wikimedia.org/wiki/Wikimedia_Enterprise/Princip... Though I imagine that only works so far as you feel you can trust the Foundation to stick to those principles, so that's complicated. :D There's also a bunch of FAQs here that sort of get at how the funding streams are supposed to integrate into the existing structures and how it's supposed to avoid pushing out the free services: https://meta.wikimedia.org/wiki/Wikimedia_Enterprise/FAQ (As I said elsewhere, I work for the WMF but I don't work on anything related to this so I'm just commenting as someone who has more experience searching through our public info than most HN commenters would...) reply bawolff 11 hours agorootparent> Though I imagine that only works so far as you feel you can trust the Foundation to stick to those principles, so that's complicated. :D At the end of the day, WMF is made up of people, and people follow incentives. I'm not saying they are bad people, but they aren't saints either. They are just people like anyone else. It might not happen today, but 5 or 10 years from now, i'm not so sure. Eventually there will be some situation where people involved will have to chose between something for the public good vs something that sells enterprise APIs better. If WMF becomes dependent on the enterprise money, it will be hard to chose the public good. When that day comes, the enshitification begins. After all, google once claimed not to be evil. The motto didn't last. reply riedel 13 hours agoparentprevI think commercial offerings are good to offer as an alternative to donations for institutions that want to support something and cannot easily make a donations. reply admissionsguy 5 hours agoparentprevWMF goes the way of bureaucracies. It finds multiple ways to enlarge itself over the years and just cannot ever get any smaller. I suppose at some point it will overextend itself and harm Wikipedia, the only[1] thing of value, in the process. [1] Yeah there are Wikidata and some other projects. But it's like saying Google is not an ad company. reply causal 56 minutes agoprevWhat's up with HN's general tone of hostility toward Wikimedia foundation? It's weird how the more free a service is the more entitled our attitudes seem to become. reply ThrowawayTestr 50 minutes agoparentI think the hostility comes from Wikipedia constantly asking for money when most of the money goes to things that aren't Wikipedia. reply paulette449 6 minutes agorootparentHiding behind a throwaway account allows you to make false statements, unless you can substantiate the \"most of the money\" comment. Wikimedia Foundation breaks down its expenditure here: https://wikimediafoundation.org/support/where-your-money-goe... I'm sure what poster is referring to was \"discussed\" previously in the link below. I use parentheses because it descended into flames pretty quickly: https://news.ycombinator.com/item?id=33170710 reply mushufasa 22 hours agoprevYet this also exists: https://en.wikipedia.org/wiki/Wikipedia:Database_download reply paxys 21 hours agoparentWhich is a good thing. The entire corpus is CC-licensed and anyone can download it for free. If you want a real-time API, performance SLAs, machine parsable formats, support etc. then pay for it. reply btown 20 hours agorootparentIt also seems Wikimedia isn't trying to relicense the content in any way that strips its e.g. CC-SA status, but rather providing the licenses as context alongside each API call. https://helpcenter.enterprise.wikimedia.com/hc/en-us/article... It's worth noting that https://creativecommons.org/faq/#artificial-intelligence-and... itself takes the general stance that \"as a general matter text and data mining in the United States is considered a fair use and does not require permission under copyright.\" But as a practical matter, I wouldn't be surprised if some Wikipedia editors balk at their volunteer work being actively marketed and reformatted for ease of LLM training by the very platform that solicited their volunteer services, regardless of their works' legal status and Wikimedia's technical respect of that legal status. reply emw 19 hours agorootparent> I wouldn't be surprised if some Wikipedia editors balk at their volunteer work being actively marketed and reformatted for ease of LLM training As someone who avidly edited Wikipedia for 6-8 years, I am happy to see my volunteer work used for LLM training. I also agree some other editors likely aren't. reply lambdaone 10 hours agorootparentGiven that all Wikipedia editors have explicitly consented to their content being released under the Creative Commons Attribution-ShareAlike 4.0 License, they don't get a choice about their content being used for any purpose. Redistribution of content is an entirely different matter, and the legal status of copyrighted material in relation to LLM training is an open issue that is currently the subject of litigation. reply emw 6 hours agorootparentWikimedia Foundation’s perspective on this [1]: > \"it is important to note that Creative Commons licenses allow for free reproduction and reuse, so AI programs like ChatGPT might copy text from a Wikipedia article or an image from Wikimedia Commons. However, it is not clear yet whether massively copying content from these sources may result in a violation of the Creative Commons license if attribution is not granted. Overall, it is more likely than not if current precedent holds that training systems on copyrighted data will be covered by fair use in the United States, but there is significant uncertainty at time of writing.\" The new Wikimedia Enterprise APIs facilitate attribution. For example, the \"api.enterprise.wikimedia.com/v2/structured-contents/{name}\" response [2] includes an \"editor\" object in a \"version\" object. So the Wikipedia editor who most recently edited the article seems quite feasible to attribute. ML apps could incorporate such attribution in their offering, and help satisfy the \"BY\" clause in the underlying CC-BY-SA 4.0 license for Wikipedia content. --- 1. https://meta.wikimedia.org/wiki/Wikilegal/Copyright_Analysis... 2. https://enterprise.wikimedia.com/docs/on-demand/#article-str... reply ZunarJ5 5 hours agorootparentprevAs another editor, I think they might be a vocal minority. :) reply lenerdenator 13 hours agorootparentprev> But as a practical matter, I wouldn't be surprised if some Wikipedia editors balk at their volunteer work being actively marketed and reformatted for ease of LLM training by the very platform that solicited their volunteer services, I think that will heavily depend on just what the money goes to. A better user experience, tightening up the code behind things, fewer nag screens for donations? Justifiable. Jimmy Wales going from decently-compensated to a bad case of Founder Syndrome? Not so justifiable. Founder Syndrome: a psychological condition wherein a person who starts a venture believes the venture should earn them a net worth on the order of billions of dollars, regardless of its actual economic value, and is willing to seriously enshittify the venture's product or service in order to make this delusion come true, especially in preparation for an IPO. See also: /u/spez, SPAC, Facebook, Unity Engine reply bawolff 11 hours agorootparent> Jimmy Wales going from decently-compensated to a bad case of Founder Syndrome? Not so justifiable. Jimmy wales is not paid at all (he has a board seat, but that doesn't come with any money) He of course has leveraged his fame from being \"founder\" quite extensively. I think most of his money comes from fandom which he is also one of the founders of. reply ks2048 21 hours agorootparentprevI don't have a problem with having paid special services, but the \"machine parsable formats\" is a bit troubling since I think that should be a core part of the open wikipedia project. I submit this link after coming across this site while Googling for info on parsing wikipedia \"infoboxes\". I plan to check out their \"Article Structured Contents (BETA)\" API. Improving infoboxes to be machine-readable seems important. And it would be bad if didn't do this because it's a revenue stream for them. reply kemayo 18 hours agorootparentMachine-readable infoboxes are surprisingly painful because an \"infobox\" isn't a top-level thing in mediawiki. Rather, it's something that emerged from community practice -- a template that's slightly-standardized, and has a sprawling network of subtemplates for specific categories of article. Then the assorted other language wikipedias have their own variants of these templates with their own names, etc. Pulling it into a mediawiki extension (or core) and making it part of the page-level metadata gets suggested pretty frequently, but it's a bit contentious amongst the hardcore editors who'd need to actually adopt such things. The template-based nature of the current infoboxes mean that they're very accessible to the community, and it's easy to spin off new variants or make changes without getting programmers to help you. There's slow movement towards getting the sort of data that winds up in infoboxes into wikidata, but it's still somewhat spotty. (If you've never done it, it can be quite edifying to install mediawiki for yourself and seeing how much of the surrounding infrastructure of wikipedia is absent because it's all templates.) reply PokestarFan 16 hours agorootparentI once tried to export a simple infobox template with dependencies and it exported 30-40 different template/module pages. reply codetrotter 21 hours agorootparentprevThere’s also Wikidata which has machine readable data for everyone https://m.wikidata.org/wiki/Wikidata:Main_Page > Wikidata is a free and open knowledge base that can be read and edited by both humans and machines. > Wikidata acts as central storage for the structured data of its Wikimedia sister projects including Wikipedia, Wikivoyage, Wiktionary, Wikisource, and others. reply riku_iki 20 hours agorootparentYes, but it is different dataset, many(majority?) infoboxes are not in wikidata reply zozbot234 18 hours agorootparentprevDBPedia has been providing machine-readable info drawn from Wikipedia infoboxes for a long time, and that's absolutely an open project. But there are drawbacks to that approach, nowadays Wikipedia users are broadly expected to input that info into Wikidata (a language-independent project, providing its data under the CC0 license) and the Wikipedias are gradually moving towards fetching the information from there as well. The English Wikipedia is somewhat behind on that, so DBPedia might still be useful for parsing info from it. reply bawolff 21 hours agorootparentprevJust fyi, i think the plan for machine readable infoboxes is stick the data in wikidata, which has its own dumps in machine readable format as well as a publicly accessible SPARQL query endpoint. Its actually quite cool. If you have never played with it i encourage checking out some of the example queries (there is a button labelled examples) on https://query.wikidata.org/ reply elric 21 hours agorootparentprevCC-BY-SA to be specific. How does attribution of derivative works work in LLMs (etc)? When is the content they produce required to be CC-BY-SA as well (by virtue of the -SA part of the license)? reply schlauerfox 20 hours agorootparentLLM output can't be copywritten as it's not the work of a human. The company would presumably have to include attribution to every piece of data the system is trained on for every query? Seems absurd, but then how would attribution work? Not really considered when the license was written. reply elric 12 hours agorootparentLicenses go beyond copyright though, they tell you what you can and can't do with something someone else made. They're contracts. I'm sure we'll be seeing more lawsuits (and likely new regulation and licenses) around this. Are you saying LLMs are not derivatives of their source material? Why not? reply grape_surgeon 11 hours agorootparentI agree on lawsuits being likely and needed to establish precedent. CC-BY-SA specifies \"other rights such as publicity, privacy, or moral rights may limit how you use the material\". At some point, maybe poorly-trained chatbots that consistently produce what's seen as avoidably/negligantly poor results may become regulated. Like how if a company poorly trains its employees, it is on the hook for their employees' behavior. reply nextaccountic 13 hours agorootparentprev> machine parsable formats, Isn't the point of wikidata to offer machine-parseable formats? Also: how can those formats be locked into a paywall? reply itishappy 21 hours agoparentprevWikimedia is Wikipedia's parent entity, but it's also the parent of: MediaWiki Wikibooks Wikidata Wikifunctions Wikimedia Commons Wikinews Wikiquote Wikisource Wikispecies Wikiversity Wikivoyage Wiktionary https://en.wikipedia.org/wiki/Wikimedia_Foundation reply violet13 20 hours agorootparentIt sounds like an impressive list, but many of these are ghost towns and are of little value to machine learning. Wikiversity is a mess... Wikipedia is the crown jewel and probably the only thing of unique commercial value for ML. reply grape_surgeon 11 hours agorootparentDisagree, this is too dismissive. Commons, Wikidata, and Wiktionary are all useful. Especially Wiktionary; probably one of the best online dictionaries imo. Often has a lot of unique info that's hard to find even in dictionaries, very good etymologies. All useful in ML. reply emw 19 hours agorootparentprevWikipedia indeed seems the most valuable for ML, by far. Wikidata, Wikimedia Commons, and Wiktionary also seem useful there. reply resolutebat 18 hours agorootparentWikivoyage is underrated and that was not helped by the acrimonious split with Wikitravel (which was acquired a predatory marketing company), but it finally seems to be pulling ahead. reply hehdhdjehehegwv 17 hours agorootparentprevOne of my favorite LLM applications is getting them to write wikidata queries. The data is amazing, but the query language is nothing but pure hell. reply StableAlkyne 5 hours agoparentprevIt does exist, it is just incredibly painful to use -- it's a raw SQL dump of each individual page, which is missing some of the dynamically generated parts of the page you might care about (like categories, unless you separately download that table too). You also have to then run it through wiki software locally if you want the rendered page instead of markup. Don't get me wrong, it is wonderful that the Wikipedia team offers this, and I am grateful they give anything at all for offline usage. It just feels like it's intended more as a side product of their backup process, rather than something you're really supposed to use. reply mtmail 20 hours agoparentprevI'm using those dumps for a monthly data process. It breaks regularly, mirrors disappear, there's only very few mirrors with the full data and little history. (I'm running a mirror for OpenStreetMap but don't have the disk capacity or bandwith for wikipedia's mirror requirements). reply boramalper 13 hours agorootparent> I'm running a mirror for OpenStreetMap Curious why you're running a mirror for OSM, is it public or for your private use? If you don't mind, I'd love to learn more about it; sounds super interesting to me. reply w10-1 19 hours agorootparentprevRight, the incentives are adverse: if they lower quality of service for free offerings, they'll be rewarded with more paying customers for reliable service. But quality does take money. reply madeofpalk 7 hours agorootparentWhat are the incentives for more paying customers? Wikimedia Foundation, being a non-profit, has a lot less incentives to chase money at the expense of product quality. reply dangoodmanUT 8 hours agoparentprevsee you in a year when that finishes reply ImaCake 18 hours agoparentprevHaving the data available for download and a paywalled API is pretty standard practice for a lot of this kind of data. Copernicus weather/satellite data is often setup like this. There's a free download option, a free (limited) API, and then if you wanna get fancy you can use a more feature rich paid API. Many other weather services do similar. It seems to work pretty well with the usual caveats. reply riku_iki 21 hours agoparentprevfor now reply miffy900 7 hours agoprevI'm reading the API docs https://enterprise.wikimedia.com/docs/ And they don't have an OpenAPI spec available to download? So they seriously expect developers to just manually write their own client code by reading and translating those example CURL commands by hand??! Seriously it's 2024! Not having a spec to download and insepct for any API is a sign of incompetence. When tools like Postman or https://github.com/OpenAPITools/openapi-generator-cli exist and save hours of time, you can't seriously expect devs to write all this connecting code by hand anymore. reply schoenobates 4 hours agoparentBottom of the page ... https://api.enterprise.wikimedia.com/spec/spec.yaml reply chuckreynolds 4 hours agoparentprevlink at bottom of https://enterprise.wikimedia.com/docs/ page reply krainboltgreene 1 hour agoparentprev> And they don't have an OpenAPI spec available to download? So they seriously expect developers to just manually write their own client code by reading and translating those example CURL commands by hand??! This is baby work to literally every programmer I know. reply causal 59 minutes agorootparentNot to mention that if it's really needed, the LLMs this is made for also excel at converting CURL commands to whatever spec pretty trivially. I've used them this way on a few occasions. reply croes 5 hours agoparentprevThen create one, share it and save us some time. reply trustno2 5 hours agorootparentso enterprise very wow reply michaelt 7 hours agoparentprevIf only there was some code generation technology that could take in human-readable specifications, not just machine-readable ones.... reply low_tech_punk 20 hours agoprevNitpick, the purple blue gradient is overused, especially as the background of source code examples. It hinders readability and feels off-brand for a Wikimedia project. This might be foreshadowing a descent into chasing trends. I just hope Wikimedia does not follow Mozilla's track in spending budget on fluff work. reply s1k3s 21 hours agoprev> Real-time access to Knowledge Wikipedia knowledge is basically \"democracy\" knowledge, i.e. the more people decided to support an idea, the \"truer\" it gets. That's not knowledge at all! reply tux3 21 hours agoparentThat's exactly what almost all knowledge is. When was it that you last verified something by yourself, with an experiment? You didn't test the things you know. You know things because you could see they were the consensus, and so you had no reason to challenge them. If an idea is disputed, then you trust it less. If it comes from a small number of reputable sources, then you trust it more than a large numbers of unreliable people. So with the Wiki. Human knowledge isn't from the platonic realm. Human knowledge isn't checked by a theorem prover. You get almost all of your knowledge from other people, and you have no choice but to trust them for almost all of it. reply southernplaces7 16 hours agorootparent>That's exactly what almost all knowledge is. That's what almost all human assumption and belief system is, also ideology and religion, but knowledge is indeed something different, and not of a type that should rely on democratic consensus. It instead needs to be held up by material evidence that's always subject to retesting no matter how unpopular a new idea is. This is obvious. The rest of what you say could just as easily be applied to the foolish social dogmas of nearly any past age in human history, dogmas that so often turned out to be wrong. A small number of reputable sources (for their time) upheld doctrines such as geocentrism, religious extremism, hatred for certain racial groups and numerous fervent beliefs in the right of certain people to dominate others. These are just a few examples. A more material one would be the certainty among reputable sources that plate tectonics were nonsense, until of course they were shown not to be by what started as an argument by only a few people who were deemed very unreliable. None of this is to give weight to every crackpot idea put forth, or claim that all opinions are equally valid until stated otherwise, but what makes the difference is evidence, not consensus. reply grape_surgeon 11 hours agorootparentIf I'm interpreting your comment correctly, I don't think your presentation of the role of popular consensus on Wikipedia is accurate. Read this page: https://en.wikipedia.org/wiki/Wikipedia:Consensus. Wikipedia doesn't establish consensus by pure numbers or voting, although it is a contributing factor. In disputes, it has moderated discussions with verdicts given by elevated users, including admins. Things like statistics and even (perhaps especially) precedent all weigh in. Popularity of a side can be weighted, but ruling purely based on popularity is actively discouraged. This can lead to scenarios where 90% of users want something, but the moderater rules along with the 10%. Often, this happens when the discussion was initially among a bunch of relatively new users who aren't aware of some policy, and a more experienced editor points that a dispute is clearly not in line with some policy. This happens very regularly and is often a source of drama with long discussions. This process actually arguably works better on popular and contentious pages; you get eyes and discussions of substance on those. Most boring pages are virtually ghost towns and are counterintuitively more susceptable to popularity-based consensus. Whatever you put up will likely stick, so it's just a matter of how many people and who will protect the page for the longest. Also read this page: https://en.wikipedia.org/wiki/Wikipedia:Neutral_point_of_vie.... The second page addresses your concern about not giving too much weight to fringe theories. It's not enforced as well as it could be in many places though; it can be hard to judge what's due or undue weight. reply rkagerer 20 hours agorootparentprevWhen was it that you last verified something by yourself, with an experiment? Just a few weeks ago. I did a simple experiment to check whether the Super-94 at my local Chevron is indeed ethanol-free. It wasn't. reply dools 19 hours agorootparentNow imagine you were able to go and edit the sign that says it is ethanol free to add the details of your test and dispute the claim, that would improve the knowledge. reply LeoPanthera 16 hours agorootparentThis is nice analogy, but a wrong analogy. Wikipedia specifically does not allow original research. https://en.wikipedia.org/wiki/Wikipedia:No_original_research reply croemer 17 hours agorootparentprevFor that to make it into Wikipedia you'd have to first write an article in a reputable source. reply tux3 9 hours agorootparentOr rather, have a reputable source write an article about your work. If you write the news article about your own work and they publish it, the article is still a primary source (despite not being self-published)! reply molticrystal 18 hours agorootparentprevI thought knowledge, at least the best type comes from primary sources and from repeatable experiments with explicit premises as much as possible. This makes it sound like all knowledge is hearsay. If it is, what is the point of a place like Wikipedia or even an encyclopedia? reply denton-scratch 9 hours agorootparentIndeed, the best type of knowledge comes from primary sources and original research. But those also produce an awful lot of not-knowledge. Wikipedia's approach to sifting the knowledge from the not-knowledge is to prefer reliable secondary sources, i.e. sources deemed capable of telling the difference, mainly because they have a reputation for good editorial control. It's far from an ideal touchstone; but relying on \"experts\" is worse, because who's an expert? You need experts to identify experts, which is circular. \"Reliable secondary sources\" doesn't amount to hearsay. reply nickpsecurity 21 hours agorootparentprev“That's exactly what almost all knowledge is.” It’s worse than that. Much knowledge comes from authorities or peers. The sources could be unpopular or barely reviewed. Yet, people are likely to believe specific types of sources. It seems to be hardwired for some purpose. reply Tao3300 20 hours agorootparentprevWe trust the consensus of published, peer-reviewed experts. That's different than the kind of Demos that does things like declare war on Persia, kill Jesus and Socrates, or edit Wikipedia. > If an idea is disputed, then you trust it less. If it comes from a small number of reputable sources, then you trust it more than a large numbers of unreliable people. So with the Wiki. Right. That makes Wiki kind of unreliable. Not completely. And not to the point of uselessness, but you should trust it about as far as you can throw it. > Human knowledge isn't from the platonic realm. Citation needed ;) reply tux3 20 hours agorootparent>We trust the consensus of published, peer-reviewed experts. That's different than the kind of Demos that does things like declare war on Persia, kill Jesus and Socrates, or edit Wikipedia. Ye of little faith! The Demos, after much bickering, have also decided to largely trust the consensus of published, peer-reviewed experts. But what you really have to ask when you say you trust the consensus, is who forms the consensus of peer-reviewed experts? It's rare to get an explicit consensus from an actual organization. When Cochrane does a large meta-analysis, and whisper \"moderate evidence\", I stop reading and immediately trust them with my life. Unfortunately, they very rarely have confidence in anything. Most of the time, the consensus of published, peer-reviewed expert is also not something people form on their own. When has your neighbor last read and synthesized the literature to determine what the consensus is on hydroxyapatite in toothpaste, before going to the store? Individual experts, I also trust only as far as I can throw them. The consensus of experts I'm happy to rely on. But that, very often, also comes from trusting the Demos, I'm afraid. reply TheGlav 20 hours agorootparentprevWe humans also trust the consensus of non-peer reviewed truth all the time. Tell that group of children that the opposite sex doesn't have cooties, and there's a good chance they'll laugh at you. Look at any online community, and it's the same. We humans are great at it and do it all the time. reply simonw 21 hours agoparentprevRead up on Wikipedia's \"reliable source\" policies. Information on Wikipedia is meant to be backed up by a verifiable source, partly to prevent a situation where knowledge only makes it onto Wikipedia if enough of the editors agree that it should be true. Molly White made a great video and write-up explaining this a few months ago: https://blog.mollywhite.net/become-a-wikipedian-transcript/#... reply s1k3s 21 hours agorootparentI know about that, but it's basically the same thing since reliable sources in the wikipedia terms are a set of sources that we collectively decide to trust. What's interesting about wikipedia sources is that it won't allow you to directly quote a person even though they are a well known trustworthy information source. Instead you must back up your statements through a 3rd party (usually media-related) entity. This is both good and bad, considering that journalists may not be the best at evaluating certain information, especially in the science or politics field. reply tux3 20 hours agorootparent>it won't allow you to directly quote a person even though they are a well known trustworthy information source Little known fact: That is actually allowed in some limited situations, but only reluctantly, and with a lot of care. For instance if someone is recognized as an established researcher in their field with publications in top academic journals and then they make a statement on their website about something they have expertise in, you can actually cite that if you have no better source! Even though it's a direct self-published quote. reply afh1 19 hours agorootparentprev... and Wikipedia does not consider itself a reliable source. Rightfully so. Open any politics-related article and you'll see why. reply verdverm 21 hours agoparentprevThat politicians get to scrub their pages shows there are cracks in places, but overall it's generally pretty ok reply Tao3300 21 hours agorootparent> overall it's generally pretty ok That's the kind of glowing praise I'd get from my 8th grade Geometry teacher when I got a C on a test. reply verdverm 21 hours agorootparentlol, I find wikipedia to be a bit all over the place or lack structure. It also is largely a giant block of text, though I do think the new LHS menu has improved things reply kristianpaul 20 hours agoprevInteresting, the current DB dump is not for everyone, but if they also offer an LLM trained on Wikipedia data that answers and provide actual valida citation , please do. (not sure if duckduckgo stop offering that) reply flipbrad 9 hours agoparentNot quite what you're looking for, but something to play around and give feedback on in this area is https://meta.m.wikimedia.org/wiki/Future_Audiences/Experimen... reply yreg 20 hours agoparentprevAFAIK a good way to provide better answers and avoid hallucinations would be to compute embeddings for all sections of text in Wikipedia and then when a user asks a question create an embedding from that question. Use it to find the X closest embeddings to the question being posed, lookup their original articles, feed them all into context of an LLM and then ask it to answer the question based on that context (alone). Contexts are becomming quite large so it's possible to put a lot of stuff in there. LLMs answering questions based on a giben text seem to be more reliable than those that are simply trained/fine tuned on some library of texts. p reply jahewson 20 hours agorootparentUnfortunately this still results in plenty of hallucinations. reply falcor84 19 hours agorootparentWhat do you mean? Have you or someone else already followed this exact approach? reply yreg 10 hours agorootparentSupabase did: https://supabase.com/blog/chatgpt-supabase-docs I've attempted it as well a year ago (mostly for fun) for our project. Yes, it can still hallucinate. But I would say it's much much much better in this regard than fine-tuning. When I did it, the main issue was that our documentation wasn't exhaustive enough. There are plenty of things that are clear to our users (other teams in the company), but not at all clear to the LLM from the few text excerpts it receives. Also, our context was quite limited back then to just a few paragraphs of text. reply nestorD 18 hours agorootparentprevThe approach described above is what is commonly referred to as RAG[0]. I am not aware of someone having used it on Wikipedia but, from experience and while it helps, it does not eliminate all hallucinations. [0]: https://en.wikipedia.org/wiki/Large_language_model#:~:text=t... reply ImaCake 17 hours agoparentprevYou can do this with the copilot chat feature in MS Edge. I just tried to ask it to use only wikipedia and it gave me four references, two of which were wiki. So at least you can get it to spit out references with a bias reply mort96 10 hours agoprevI give it at most a year before they start using this LLM to generate content for Wikipedia reply thih9 20 hours agoprevIs it’s ok to train AIs on CC-licensed data? What about attribution, should the AI be distributed with a note about the dataset’s origin? I could imagine a poorly trained model that returns content nearly identical to original; who would enforce CC rules then? reply yreg 20 hours agoparentIt shouldn't be much of a problem to ship the LLM along with attributions. (List of all sources used in the dataset - not a problem, unless they are secret, shady or illegal.) Wikipedia is one of the easy ones, since you need to attribute just 'Wikipedia' for the entire corpus instead of many individual users. The bigger issue is when a user uses the model to generate some text. Should they attribute it when using it somewhere? That doesn't seem very practical, since it seems that soon most of the text will be edited by LLMs and those seem to be trained on most of the web -> so pretty much everything would need to be attributed to everything. Unless someone puts a stop to this, which I find improbable. reply sp332 17 hours agorootparentIncluding a list of every Wikipedia author is possible but very inconvenient. https://en.m.wikipedia.org/wiki/Wikipedia:Reusing_Wikipedia_... reply killingtime74 15 hours agorootparentI wonder if it can be like those California proposition notices, just include it everywhere just in case reply pwarner 18 hours agoparentprevhttps://creativecommons.org/2023/08/18/understanding-cc-lice... reply dangoodmanUT 8 hours agoprevGood so they can stop shilling for donations on wikipedia reply nickpsecurity 22 hours agoprevI was hoping more groups did stuff like this. The free sites doing it could handle some copyright issues if their EULA had a built-in license for distribution. In my previous analysis, (IIRC) I found that Wikipedia articles were under a copyleft license with attribution requirements. Does how Wikipedia Enterprise delivers this bypass that where neither use nor derivatives have those requirements? Or are they ignoring the licensing requirements which still legally apply to enterprise customers? Or are they not even claiming to address it? reply kemayo 21 hours agoparentMy understanding is that Enterprise is mostly about smoother delivery of content. E.g. Google has those informational summaries in search results, and it's easier for it to keep those current if there's a stream of updates it can subscribe to, rather than having to constantly download the full Wikipedia database dumps and parse them out. It also puts it all into conveniently formatted responses, and tries to do some signaling of content reliability. The API responses do include information about the content license, which differs a bit between different wikimedia properties: https://helpcenter.enterprise.wikimedia.com/hc/en-us/article... (I work for the WMF. I don't work on the Enterprise stuff, or have any insider knowledge of it. E.g. I used Google as an illustrative example, but I have no idea whether they're actually using this service. :D) reply bawolff 21 hours agorootparent> to keep those current if there's a stream of updates it can subscribe to, rather than having to constantly download the full Wikipedia database dumps and parse them out. I mean presumably prior to this they were using the [free] parsoid rest api along with the [free] event stream api. I highly doubt they were parsing the dumps. Its not even clear to me what the core value proposition of the new api is over the old api from the perspective of google. Maybe SLAs? A way to justify donating money without it looking like a donation? reply kemayo 20 hours agorootparentNo idea whether it's any quicker than the event stream APIs, but it sounds like the machine-readable aspect does a lot of processing that just using parsoid wouldn't get you. Parsoid is only a wikitext-to-HTML service, so you'd still need to do significant work on it to get meaning out of that HTML. The data dictionary page[1] suggests that it's exposing things like \"how many citation-needed templates are in this?\" (presumably localized, since those template names change across wikis), which I could see being handy for services like that. That said, I suspect that the real value is just the \"reliable\" bit on that summary page. > Written agreements, no additional content restrictions, SLAs, 24/7 support, and contractual guarantees against surprise breaking changes make working with Wikimedia Enterprise safe and reliable at scale. i.e. If I was building a big enterprise thing using wikipedia data, getting a SLA and a promise that us rando open source devs won't completely change the APIs on a whim would be nice. [1]: https://enterprise.wikimedia.com/docs/data-dictionary/ reply flipbrad 9 hours agorootparentprevThere's also r&d going into additional, inferred data layers, e.g.: https://m.mediawiki.org/wiki/Wikimedia_Enterprise/Breaking_n... reply bawolff 21 hours agoparentprevAll licensing requirements still apply. However keep in mind that different wikimedia content is under different licenses (e.g. wikidata is public domain). Additionally in the united states, if you take just the factual content (removed from any creative context) the facts are not copyrightable so the license does not apply. reply adultSwim 13 hours agoprevI support this and think it should be a model for other organizations. They already publish the data for free. It's already being used to train models. Companies are already using those models to profit. I'm not sure I understand the concern. I hope to see their APIs expand in future work, successfully tying together machine learning with their prior work on publishing a knowledge graph enriched with high quality structured metadata. reply deegles 21 hours agoprev [–] Looking forward to seeing the details on how they will handle revenue sharing with all of the people who contribute to them. reply gurchik 21 hours agoparentFunding that goes to editors (for example, stipends to travel to Wikipedia conferences) has been decreasing steadily each year. It's not due to a lack of money - Wikimedia consistently brings in millions of surplus revenue each year, see WP:CANCER[1] - so it's not clear that an additional revenue source will change anything. ^1: https://en.wikipedia.org/wiki/User:Guy_Macon/Wikipedia_has_C... reply paxys 21 hours agoparentprevIf you want monetary compensation you should not be contributing to Wikipedia. Otherwise apply to work there as an employee. reply tux3 21 hours agorootparentAfter seeing this comment, onlookers report that the Wikimedia Foundation appears to have just vanished in a puff of volunteerism reply philipwhiuk 19 hours agorootparentThe Wikimedia Foundation are paid employees. reply tux3 17 hours agorootparentThey sure are! I think the parent comment to mine was edited, and now my reply looks weird. This is what I remember replying to: \"If you want monetary compensation you should not be contributing to Wikipedia\" reply kmeisthax 21 hours agoparentprevThe details are: none. There is no revenue sharing. That's literally the point of the Creative Commons license that Wikipedia uses. There's some things on the margins about attribution strings and share-alike requirements, but none of it would render AI training on Wikipedia illegal or compel AI companies to seek a separate, royalty-bearing license. Creative Commons is a \"do what you wish\" license, not a \"free until I want money, then I rugpull you\" license. If you wanted revenue sharing, you were at the wrong party. You wanted the Microsoft-sponsored \"Open Source is Communism\" party down the block. reply carlosjobim 21 hours agoparentprevProbably the same ways as billion dollar businesses share revenue with open source developers... reply riku_iki 21 hours agoparentprev [–] are they obligated?.. reply cdme 19 hours agorootparent [–] No, but nobody is obligated to contribute to or support them either. reply riku_iki 19 hours agorootparent [–] that's not really true. Because of network capture, those who wants to contribute into some public free human knowledge, obligated to do it through wikimedia and contribute to wikimedia revenue streams. reply cdme 52 minutes agorootparent [–] Or this simply discourages contributions for folks not wanting to volunteer effort to the gaping maw of yet another monolithic content vacuum/LLM. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Wikimedia Enterprise offers enterprise-grade APIs designed to enhance search engines, large language models (LLMs), and deep learning applications by improving search results and answers.",
      "The APIs provide real-time access to data from Wikimedia projects in any language, with tools to detect vandalism and updates, supporting applications like voice assistants and AI training models.",
      "The service includes over 850 datasets, 100M+ project pages, and 20M+ monthly edits, delivering frequent, reliable, and well-documented data, including metadata on article edits and a Probability of Revert feature."
    ],
    "commentSummary": [
      "Wikimedia Enterprise is exploring new funding streams, such as APIs for large language models (LLMs) and AI training, sparking debate over potential conflicts of interest and risks to free offerings.",
      "Critics argue existing funds should suffice, while supporters cite high operational costs and legal challenges, highlighting the tension between open-source commitments and financial sustainability.",
      "The debate includes whether Wikipedia should charge LLM trainers to address information economy and IP issues, with opinions varying on the legitimacy of Wikimedia's funding needs and the impact on free services."
    ],
    "points": 207,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1716323550
  },
  {
    "id": 40438960,
    "title": "Why You Should Add a /Now Page to Your Website and How to Do It",
    "originLink": "https://sive.rs/now2",
    "originBody": "Tech blog: How and why to make a /now page on your site 2024-05-18 Background I used to wonder what my friend Benny Lewis was doing. He has a website and social media accounts, but neither gave an overview of what he’s doing now. Then I realized some people might wonder the same about me. So in 2015, I made a /now page on my website, saying what I’d tell a friend I hadn’t seen in a year. It has a nice side-effect of being a public declaration of priorities. It’s a good link to give people when saying no to invitations and distractions. Word spread, and soon hundreds of people had a /now page on their personal website. So I made a site to showcase them all: nownownow.com — (a static site generated by PostgreSQL functions.) It currently has over 2300 people worldwide. This week I added browse by location and search. Got a personal website? Add a /now page The three main ingredients are: a page, usually at URL /now, linked from your main menu, usually alongside /about an overview of what’s going on with you — what you’d tell a friend you hadn’t seen in a year the date it was last updated WordPress instructions: In the left menu, under “Pages”, click “Add New Page”. Then, where it says “Add title”, replace that with just three letters: now. That will ensure the URL is /now, and after it’s posted, you can change the title to “What I’m doing now” or whatever. Wix instructions: On the left, under “Site Menu”, click “+ Add Page”. Call it Now, next to your “About” page. Click the (…) to its right, then to “SEO basics”, to edit “URL slug” and make sure it’s just the three letters: now No website yet? Use Bear If you don’t have a personal website yet, I highly recommend Bear at BearBlog.dev. It’s so simple, clean, and free. The owner and creator, Herman in South Africa, runs it himself with great love. And no investors so no enshittification. He plans to keep it alive forever. I believe in it so much that I told Herman I would be its godfather. If he ever can’t (or doesn’t want to) run it anymore, I will help run it, or fund a foundation to keep it alive. To create a /now page on Bear, click “Pages”, then “New page”. Then, after it says “title:”, type just three letters: now. That will ensure the URL is /now, and after it’s posted, you can change the title to “What I’m doing now” or whatever. Got a /now page? I’ll add you to nownownow.com Once it’s live, just email me your URL, and I add it (by hand) to nownownow.com. (This is also a good time to say hello, if you haven’t yet. I read and reply to every email.) © 2024 Derek Sivers. Copy & share: sive.rs/now2",
    "commentLink": "https://news.ycombinator.com/item?id=40438960",
    "commentBody": "How and why to make a /now page on your site (sive.rs)200 points by sarimkx 9 hours agohidepastfavorite71 comments oefrha 7 hours agoJust use good old /about or equivalent. For most people who aren’t thinking about their website every day, /now will inevitably end up as “what I was doing when I last remembered I have a /now page” instead of what they’re actually doing now. Idea for the future: in a few years, check how many /now pages were last updated in May 2024. reply darreninthenet 6 hours agoparentI host mine on (the rather very good) omg.lol and they send me a weekly reminder via email... I can even update it by replying to the email using markdown https://darreninthe.net/now reply karaterobot 5 hours agoparentprevBingo. I made a /now page a couple years ago, and removed it a couple months ago, rather than pretend I was ever going to update it. It was just the original text I wrote when I made the page. I assume that's the normal case for these pages. reply mwidell 6 hours agoparentprevFor every Derek Sivers there are 9999 people who don't even care to update their website on a yearly basis. reply sneak 6 hours agorootparentI use a jekyll/CI/static hosting workflow, and even though I make a zillion git commits a day, somehow branching, editing, PRing, and merging one to my website seems like friction. I have a 4-5 posts in my head I want to make that have been languishing for weeks/months because it feels like too much of a hassle. I'm thinking of moving to a wordpress-backed CMS (that gets ingested by the static page build system) just to remove it, so I can simply type into a box and smash a button. reply alias_neo 5 hours agorootparentFunny, I'm in the same situation; I'm endlessly tinkering, and I feel like I could benefit from documenting some of it on my \"blog\" if nobody else does, but the friction of cloning to whichever machine I'm on, probably need to update my SSH key in Github because I've moved to another distro, then writing up and trying to keep the high-standard I've tried to for my blog, with quality images, and step-by-step instructions beginners should be able to follow, means I haven't updated it in months, possibly not even this year. reply coldpie 5 hours agorootparentprevWordpress (or some other well-supported CMS) is nice too, because you can edit from anywhere if you're not at your main development PC. I've written & published blog posts in 30 minutes on my phone in the kitchen, including taking and uploading the photos, while waiting for dinner to finish cooking. As with everything we're not getting paid to do, removing friction is key. reply kalleboo 5 hours agorootparentprevWhat I ended up doing was writing a PHP script that would scrape threads off my Mastodon account that were posted with a specific hashtag, and turn them into threadreader-style static HTML blog posts (with some minor automated massaging to remove hashtags etc). For my scatterbrain, composing and posting a Mastodon thread is a lot lower-stakes than writing a blog post. reply LVB 5 hours agorootparentprevSimilar state, ended up with Netlify CMS (now the weirdly-named https://decapcms.org). Still just my repo and static page build process, but I get a basic GUI to make and edit pages. reply batch12 4 hours agorootparentprevI went through the same loop. For now, I've settled on Ghost, but always have an eye out for something easy to maintain and write on. reply oneeyedpigeon 5 hours agorootparentprevSurely if you can get that workflow up and running, it wouldn't be beyond you to automate the process and slap an html form in front of it? reply mplanchard 6 hours agorootparentprevWhy not develop on and push directly to your main branch? reply pixelmonkey 6 hours agoprevThis is a cool idea. I also really like simonw’s TIL feed: https://til.simonwillison.net/ Like a microblog of little learnings in day-to-day development. One interesting thing that occurred to me recently is that my personal site (https://amontalenti.com) is more an essay archive and identity verification tool, than it is a “blog” or “microblog.” That is, the timestamps of the content on there are the least interesting thing about it. The most valuable page, for me, is https://amontalenti.com/archive. As for something like /now, the most fascinating implementation of this is an old friend of mine from college. He and I were both early 2000s bloggers, but he came up with the idea, in 2001 or so, to keep a nearly-daily one sentence personal diary on his blog. He kept that up for the last 20+ years (he is nowadays a CS researcher and inventor in HCI). Very impressive near-daily microblogging habit over a lifetime! https://www.chrisharrison.net/index.php/Home/Log reply jalict 6 hours agoparentGreat examples, thanks for sharing all of them! Love Chris’ real life commits messages. Find them very nice just to get general overview of what was going on in your life at the time. reply hennell 8 hours agoprevThis is an interesting idea, but like most things it's just going to age. checking nownownow.com for people in the UK with one, the first 2 I picked were updated in 2021 the next 2023. Then I had two that were this month and last. TBH linking to a twitter or equivalent social media might be better. Or make now now now a more automatic system. reply oneeyedpigeon 8 hours agoparentI don't think that's necessarily a bad thing, unless the content of the page was something like \"eating a sandwich\" which, afaict, is not the purpose. The article author wrote: > So in 2015, I made a /now page on my website, saying what I’d tell a friend I hadn’t seen in a year. So the 2021 pages are probably a little out of date, but I think the 2023 and more recent ones should be fine. I think /now is less a Twitter clone and more like an 'About Me' with only the most recent interesting thing you want to say. reply paxys 8 hours agoparentprevYup. The majority of people on the planet already have a \"now\" page, and that is their social media profile. reply imadj 7 hours agorootparent> The majority of people on the planet already have a \"now\" page, and that is their social media profile. You might be right but the people who have personal websites/blogs with enough passion to add a now page are likely to be in the opposite camp, the minority who dislike social media reply roger_ 7 hours agoparentprevI think it’s a question of timescale. Twitter, etc.: hours - days Now page: months - years About page: decades reply zimpenfish 8 hours agoparentprevI think I looked at about 6 from the UK and 4 of them had huge headshots at the top which pushed all the information below the fold. Think maybe only two of them were actually had \"now\" kind of information as well. reply drcongo 7 hours agoparentprevTo be fair, pretty much nothing has changed in my life in the last 3 years either. reply DeathArrow 8 hours agoparentprev>This is an interesting idea, but like most things it's just going to age. You can use an LLM to extract and summarize data from your social media. reply seanhunter 6 hours agorootparentThis is like a second law of thermodynamics for communication. You take something that's already pretty low signal and then extract whatever from it and republish some slop you generate from that using a model. Models are then trained on published media and thus the circle continues, with everything trending to sludge over time. reply xnorswap 6 hours agoprevI miss the days when we had enough trust, and even more naivety, to have the finger protocol. For those who didn't know or don't remember what the finger protocol was: > The program would supply information such as whether a user is currently logged-on, e-mail address, full name etc. As well as standard user information, finger displays the contents of the .project and .plan files in the user's home directory. The idea of showing a real name, email address and logged in status, without the explicit consent of that person, is completely incompatible with a modern understanding of trust. But a small protocol to find out what someone is up to, available on demand, well that would be nice. The key difference between this and something like twitter, is that firstly it's a first class protocol, there isn't a twitter protocol and you can't implement a twitter server and twitter client independently, but more importantly, it's pull not push. You're not being pushed notifications when someone updates their .project or .plan. You're not being pushed a feed of \"recommended users\". You simply ask for someone's .plan and get served it. Can you recreate that functionality with nothing more than HTTP and an index page? Yes, of course, and this is one such attempt, but until we have a simple client, shipped on most machines, where I could simply type the equivalent of \"finger jcarmac@id.net\", and get back a short burst of a dozen or so lines, then it won't feel the same. Of course money ruins everything too, it wouldn't be enough to provide such a thing, because people would far too quickly start having space reserved to advertising. There's too many eyeballs leading to too much money chasing those eyeballs. A handful of academics have a chance to push back and shun someone who tries to advertise on their usenet newsgroup. There's zero chance of that happening to anyone on any new platform now. Any platform that gets popular enough to \"take off\" will all too quickly be taken over by people who optimise for eyeballs, monetise those eyeballs and reinvest money into chasing more eyeballs. And that's a core \"problem\" with this project and projects like it. It's a social problem, not a technological one. The technology was solved in the 1970s. reply bongodongobob 6 hours agoparentIf there were 6 billion people on the internet back then it would have been abused. Times weren't better, people weren't better, it's just a numbers game. reply xnorswap 6 hours agorootparentYes, that's what I meant by \"A handful of academics had a chance\". I'd disagree about \"Times weren't better\". The internet of even just 25 years ago was vastly better for many use cases, if your interests aligned with the relatively smaller pool of people on it back then. Does that make it overall better? Well not really, and I'm not the sort of person who tries desperately to recreate that time through things like neocities, because time marches on and things change. But it is still worth appreciating what was good about that time, and asking ourselves if there are lessons we can learn about what's changed over time. reply seanhunter 6 hours agorootparentprevFinger literally was the first protocol to be abused on the early internet. https://en.wikipedia.org/wiki/Morris_worm reply astrodust 5 hours agorootparentprevDynamics of a small town versus a large metropolis. It's just that the small town back then had John Carmack diligently updating his finger profile as he was working on major projects. reply pablo1 8 hours agoprevI've been thinking about something like this for a while, wondering if it could be a decentralized alternative to social media timelines. I really like the idea of having a /now page with a short public status that you could share with friends and which can be less work to update than writing an entire blog post. That being said, the \"standard\" you defined could have been bit more specific in my opinion. If I have multiple friends with /now pages, I would like to read them all in one place. For this RSS would work nicely, maybe with a separate feed from your blog. If you don't want RSS, maybe making the /now page a uniform text-based format would have been better? Just an opinion on this. reply MattJ100 7 hours agoparentThis is not a new idea, there is some prior work: - https://en.wikipedia.org/wiki/Finger_(protocol) (one of the earliest implementations of the idea) - https://en.wikipedia.org/wiki/Microblogging (the general concept) - https://spec.indieweb.org/ (existing standards for this kind of thing) Before Mastodon there was Identica/Status.Net, before that generation of tools there were bots that would let you update a page on your website by sending a short message from your chat client. Even Twitter had SMS and XMPP interfaces for this, in the early days. reply rpastuszak 8 hours agoparentprevHehe, I'm actually playing with a similar idea. I'm still trying to figure out how to reduce friction for less tech-savvy users, so have both the ability to plug in your own feed or use the UI on the site. I wrote about now pages here https://untested.sonnet.io/My+Now+Page I also made a version of \"my life in weeks\" https://days.sonnet.io as an excuse for reflection, an excuse to get the bird's eye view of my life, then to encourage others to do something similar. And, some people, even here on HN, have! reply OnACoffeeBreak 7 hours agorootparentYour \"my life in weeks\" page is just lovely. I teared up from the tenderness of it. That is such a great idea. I have been toying with the idea of writing a memoir, but I haven't started because it seems so daunting of a task. This, on the other hand, is constrained, but still leaves a lot of room for creativity. reply rpastuszak 7 hours agorootparentThanks! You might like this then https://untested.sonnet.io/Stream+of+Consciousness+Morning+N... I've been doing this since the late 2019 and it's become a huge part of my life, my relationship with myself and others. reply zimpenfish 8 hours agoparentprevSounds like you're after something like TWTXT[1] [1] https://indieweb.org/twtxt reply yaky 7 hours agoparentprevI believe this can be implemented via XMPP's presence protocol [0]. IIRC this is what WhatsApp did, and sharing your current status was the original purpose of WhatsApp. Messaging and calls were added later. 0: https://xmpp.org/rfcs/rfc6121.html#presence reply amszmidt 9 hours agoprevAh! The .plan file that finger(1) used reinvented for the Web world. reply readingnews 8 hours agoparentPerhaps we can just: ln -s .plan ~/public_html/now/index.html Sure, we can run it through some template or use awk, but what the heck. reply Shorel 7 hours agoprevAwesome concept that needs to come back, it reminds me of John Carmack’s .plan file. https://fabiensanglard.net/fd_proxy/doom3/pdfs/johnc-plan_19... reply yreg 8 hours agoprevIs this a blog for people who want to blog, but don't want to call it a blog? reply azangru 8 hours agoparentLooks more like a status page. Where blogs are historical lists of articles, this page gets updated regularly, with new content overwriting the old. reply hk__2 8 hours agorootparent> Where blogs are historical lists of articles, this page gets updated regularly, with new content overwriting the old. Looks like the same to me. The page gets updated \"regularly\" (like a blog) and older content serves as a history of what the person was doing at that moment. reply hyperpape 7 hours agorootparentA blog is (by default) additive. You append by adding a new post, the items are ordered by date of creation, and you rarely remove old content. If you look at the author's /now page, it's very clearly not that: https://sive.rs/now. reply john___matrix 8 hours agoparentprevI think so, I feel I'm missing the point of this one reply mikae1 6 hours agoprevFrom experience... /now pages are usually /then pages. Whatever you do, add an update date so we know if you lost interest in updating or if the information is recent. reply jl6 9 hours agoprevPerhaps a new entry in the web's most horrible standard: /.well-known/now ? reply petecooper 7 hours agoparentFor anyone curious: https://datatracker.ietf.org/doc/html/rfc5785 reply trelane 5 hours agoprevThis sounds a lot like what an RSS feed is supposed to achieve. \"What I'm doing now\" is a lot of the original point of a blog (web log). The way one keeps up to date is having a \"current\" link to the most recent item, forward/backward navigation, and an RSS/Atom feed to automate the process. reply karaterobot 5 hours agoparent> \"What I'm doing now\" is a lot of the original point of a blog (web log). Or, Twitter! Giving short status reports was the original point of that application, maybe the only one it ever had. reply trelane 5 hours agorootparentYes, twitter et al. are types of \"microblogging,\" which is itself a type of blogging. reply Vox_Leone 5 hours agoprevIt is a very nice and important initiative. Blogs and personal pages are the essence of the Internet and anything that aims to honor them should be encouraged. Many people worry about the imminent collapse of original and clean sources, essential for the functioning of LLMs, but blogs can be the salvation. They are the main source of diverse and original material, given their sheer number and update frequency. For this reason alone, they should receive more attention and care from search engines [especially Google, which aims to be a player in the AI sector]. Your idea also has an interesting social flare. Congrats and thank you for your work. I hope to add my blog as soon as I have my /now. reply sarimkx 9 hours agoprevFor reference: https://nownownow.com/ reply castalian 8 hours agoparentMore in the same spirit: https://aboutideasnow.com/ reply pixelmonkey 7 hours agorootparentIs this site still working? I get no response when doing a search and can’t add my site either. reply yau8edq12i 9 hours agoparentprevWhat do you mean by \"for reference\"? That URL is feature prominently in the linked blog post. reply 1970-01-01 5 hours agoprevI think 99% of your viewers will care a lot more about /how and /why. But its your website, do whatever you want. reply ChrisMarshallNY 7 hours agoprevI just look at folks' GitHub Activity Graph. There's not a whole ton of folks that I'm particularly interested in knowing what they are doing, away from the technical interactions that we're having. It's not because I'm a misanthrope, but because I already have a circle of friends and acquaintances that I get that information, verbally, from, each day. But I'm not saying it's a bad idea; just that I'm probably not one to use it. reply sumanthvepa 6 hours agoprevSounds like the .plan file in a Unix home directory, updated for today's web sensibilities.It would be nice to hook up my .plan to my website. There's a nice weekend project. reply dako2117 6 hours agoprevVery cool idea, but maybe it should be called /was :D I wonder how many of these /now pages will be updated? reply carbonatom 7 hours agoprevDoes it have to /now exactly? Can it be /now.html? I don't have any fancy tools or frameworks to create extension-less URLs. I just dump my HTMLs into a folder. So can /now.html work for this? Edit: Wow! Why downvote me for an honest question? What's so revolting about this question that you feel the need to downvote this? reply denzil 7 hours agoparentUsually having index.html in /now would behave as if the /now was the page. Other index.extension files (like index.php) might also work depending on the server configuration. reply carbonatom 6 hours agorootparentYou mean like /now/index.html. Yeah, that could work! Thanks! But \"/now.html\" feels \"cleaner\" to me. I know others might disagree. If this now thing could support just \"/now.html\" or even \"/now\" redirecting to \"/now.html\", that would be swell! Maybe they already do support it? Hoping to learn from the community if these alternative paths are supported. reply quesera 6 hours agorootparent/now is cleaner in practice, because it's shorter, matches a (nascent, proposed) \"standard\", and hides the implementation details. File path /now/index.html is a fine way to expose your content at /now ... Most webservers will default to config that allows this. You could replace it in the future with a gigantic web app that is wired into your brain implant to retrieve realtime status. If you use /now.html, you would have to fight the framework to lie about the implementation details, instead of just not specifying them in the first place. You could also configure your webserver to serve /home/carbonatom/webstuff/dereks-idea/now/new-version-2025.html as /now, if you like. These are the kind of implementation details that a good URL will hide (even if the specific example is a terrible case, the equivalent does happen sometimes!). reply Zambyte 6 hours agorootparentprevWhat do you want out of support? Listings on the nownownow.com site seem to be done manually, so it shouldn't matter what you make the path if that's what you're going for. reply anentropic 5 hours agoparentprevYou don't have to do any tricks with index.html or \"fancy tools or frameworks to create extension-less URLs\" there's no reason your HTML files have to be named with .html at the end of the filename reply koromak 5 hours agoprevWorking at company B Working at company B Working at company B Working at company A Working at company A reply est 6 hours agoprevLooks like we also need an aggregation standard for this. Maybe bsky or something? reply apples_oranges 7 hours agoprevGiven the tech we have now, it should probably be auto updating.. ;) reply hlubac 8 hours agoprevits all about friction. I hade numerous blogs where the manual operations ruined the relevancy. If updating your \"now\" page would be as simple as tweeting or posting on facebook, people would do it. Heck, ill make a stupid simple ssg with web administration for this stuff reply devdaim 7 hours agoprev [–] can anybody educate me on this ? i have no idea whats going on reply bertman 7 hours agoparent [–] The author encourages people to create a /now path for their personal domain (e.g. https://devdaim.me/now) and write about what they're currently doing or working on. The author also built nownownow.com where he aggregates people's /now pages. See https://nownownow.com/about for more info. reply sivers 7 hours agorootparent [–] Great summary. Thank you. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In 2015, Derek Sivers introduced the concept of a /now page on his website to share his current activities, inspired by the absence of such information on a friend's site.",
      "The idea gained traction, leading Sivers to establish nownownow.com, a directory featuring over 2300 /now pages globally.",
      "Sivers encourages others to create their own /now pages and provides instructions for various platforms, offering to add them to the directory upon request."
    ],
    "commentSummary": [
      "The concept of \"/now\" pages, popularized by Derek Sivers, involves individuals sharing their current activities on personal websites.",
      "While some find \"/now\" pages useful, others note they can become outdated quickly, suggesting alternatives like /about pages, reminders, and easier content management systems (CMS).",
      "The discussion highlights the potential of \"/now\" pages to revive personal web pages and blogs, contributing to diverse and original content on the internet."
    ],
    "points": 200,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1716369133
  },
  {
    "id": 40437379,
    "title": "Fluent Bit Vulnerability Sparks Urgent Patching Amid Memory Safety Concerns in C",
    "originLink": "https://xeiaso.net/shitposts/no-way-to-prevent-this/CVE-2024-4323/",
    "originBody": "\"No way to prevent this\" say users of only language where this regularly happens Published on 05/21/2024, 232 words, 1 minutes to read A forlorn business man resting his head on a brown wall next to a window. - Photo by Andrea Piacquadio, source: Pexels In the hours following the release of CVE-2024-4323 for the project Fluent Bit, site reliability workers and systems administrators scrambled to desperately rebuild and patch all their systems to fix a vulnerability in HTTP parsing code that allows for heap corruption and arbitrary code execution by making a HTTP GET request with a megabyte of the letter 'A' in its body. This is due to the affected components being written in C, the only programming language where these vulnerabilities regularly happen. \"This was a terrible tragedy, but sometimes these things just happen and there's nothing anyone can do to stop them,\" said programmer Prince Marcel O'Keefe, echoing statements expressed by hundreds of thousands of programmers who use the only language where 90% of the world's memory safety vulnerabilities have occurred in the last 50 years, and whose projects are 20 times more likely to have security vulnerabilities. \"It's a shame, but what can we do? There really isn't anything we can do to prevent memory safety vulnerabilities from happening if the programmer doesn't want to write their code in a robust manner.\" At press time, users of the only programming language in the world where these vulnerabilities regularly happen once or twice per quarter for the last eight years were referring to themselves and their situation as \"helpless.\" Share Facts and circumstances may have changed since publication. Please contact me before jumping to conclusions if something seems wrong or unclear. Tags:",
    "commentLink": "https://news.ycombinator.com/item?id=40437379",
    "commentBody": "\"No way to prevent this\" say users of only language where this regularly happens (xeiaso.net)193 points by tbillington 14 hours agohidepastfavorite273 comments fnordian_slip 11 hours agoJust in case someone needs the reference, the onion uses '\"no way to prevent this\" says only nation where this regularly happens' as a reoccurring article at every major school shooting[0], to highlight the frequency of such events and the fact that nothing has really changed since the last one. [0] https://www.theonion.com/no-way-to-prevent-this-says-only-na... reply kevincox 5 hours agoparentI find the Wikipedia article also a good summary of the \"joke\" and is quite chilling to read. https://en.wikipedia.org/wiki/%27No_Way_to_Prevent_This,%27_... reply voidUpdate 11 hours agoparentprevThis is also an ongoing series on that blog, if you look at previous entries there's lots with the same title, also about C having buffer overflows reply xena 11 hours agorootparenthttps://xeiaso.net/shitposts/no-way-to-prevent-this/ Generated by exactly 69 lines of Go every time: https://github.com/Xe/site/blob/main/cmd/no-way-to-prevent-t... reply TeMPOraL 10 hours agorootparentKudos for faithfully reproducing the joke then. reply xena 2 hours agorootparentThanks, I've had thoughts about making it a bit more elaborate (possibly involving large language models somehow to help synthesize what's going on into the right format, and so that it's not literally the same thing every time), but there's a charm in making it literally the same thing every time with the details swapped out. It points out the repetition to the level that all you need to do is swap out the details next time. This is all so preventable, but sometimes these things just happen and there's not anything anyone can do about them. reply fnordian_slip 10 hours agorootparentprevDidn't catch that, thanks! reply Supermancho 9 hours agoparentprevThe oversimplification is part of the joke. reply nailer 8 hours agorootparentnext [21 more] [flagged] tim333 3 hours agorootparentIt's not even really benefits of guns are outweighed by people doing murders. All countries pretty much have some gun availability. In the UK where I am you can get a shotgun without huge problems for example. Also all countries have restrictions - even in the US I don't think you are allowed to stock up on M777 howitzers and ammo (British gun by the way). It's about having sane regulation. reply sickofparadox 3 hours agorootparentThe last comprehensive study on gun usage in the United States estimated that there are up to 2.5 million defensive uses of guns in the US yearly, most of which never involve firing a shot. They also found a correlation between gun ownership and lack of injury from violent crimes. Also you can own howitzers in the US, they just require special paperwork and a $200 tax stamp. https://nap.nationalacademies.org/catalog/18319/priorities-f... reply tim333 3 hours agorootparentI don't really understand US politics very well but looking at Wikipedia there's stuff like >poll in ...October 2015 found that 92% of Americans supported \"universal background checks for all gun sales\" But you can't do it because the NRA owns your politicians? That's the kind of thing that could be fixed I would have thought. reply sickofparadox 3 hours agorootparentWe have universal (depending on what that means) background checks for everything except private sales currently, you cannot go to a store and buy a gun without submitting one. Private sales are person to person and represent a rounding error in gun sales. Guns are a hot button topic and most people are uninformed so stats like \"want universal background checks\" doesn't actually amount to anything actionable legislatively because according to most gun owners, we have that, but many that don't own think its the wild west. reply ThunderSizzle 8 hours agorootparentprevWell, I'm glad that you volunteered to go live in Soviet Russia or Fascist Germany, or a disarmed Native American tribe. Disarming population leads to tyranny without consequences. reply Sammi 7 hours agorootparentMost of the free democratic western world does not have a lax gun culture like the US has and yet there's no tyranny. Weird. reply j-krieger 7 hours agorootparentThis isn't as clear cut of a case as you make it out to be. Britain's recently been on a path of overregulation bordering tyranny and limiting free speech. Canada is on a similar path. German green and red party politicians recently caught flack for trying to criminalize unpleasant critique. Press freedom and press independence are actively getting worse and Europe is setting course on a path of nationalism and conservative hardliners and there's an active war being fought on its borders. Islamic nationalism is on the rise and the issue concerning unregulated migration has a real chance to cause uprisings in the continent. I do not like powerful guns in the hands of the population and I love the idea of a peaceful civilization without the need for violence, but you're living in a relatively short peaceful historic phase, which is just now starting to take a turn for worse again. reply cwillu 6 hours agorootparentAnd the US police routinely rob travellers of their cash and goods at gunpoint. So again, what good are the lax gun laws providing the populatnon against tyranny? reply krapp 3 hours agorootparentAs we've learned recently, American gun owners don't give a shit about tyranny so long as the tyrants don't come for their guns. In fact, depending on whose head the boot comes down on, they'll even cheer it on. reply tim333 4 hours agorootparentprevI don't think you can call the British thing tyranny, speaking as a Brit. Ok there have been some hate speech laws, but we have elections and can vote the pols out, no armed uprising required. reply 1attice 3 hours agorootparentprevAmerican take: - UK sociopolitical problems caused by lack of guns - Canada sociopolitical problems caused by lack of guns - German sociopolitical problems caused by lack of guns I think I can complete the rest of the thinkpiece on my own, with the help of ChatGPT. My prompt starts with, \"You are a gun\" reply Rodeoclash 6 hours agorootparentprevAnd you're going to stop them with your guns? Good luck. reply ghnws 7 hours agorootparentprevTIL almost every european country is in a state of tyrnanny. Also Yemen which is one of the only countries with somewhat similar gun ownership compared to usa (bit less than half as many guns per capita) must be the epitome of freedom and safety. reply Gud 5 hours agorootparentWhat about Switzerland? They have extremely liberal gun laws, on par with the USA. Perhaps it’s not the guns that are the problem? Perhaps it’s the overall dysfunction of the US as a country? reply rspoerri 5 hours agorootparentEvery swiss that is issued the military gun (which is most) get a gun. They are trained by military professionals how to use the gun and hoe to store the weapon at home. It is for example forbidden and punishable by law, if something happens with your weapon, if you stored your weapons ready to shoot. You must remove the bolt and store it in a save, secured location. Using ammunition provided by the goverment must not be used, if it is used you will be punished. If you dont handle your weapon responsibly during trainig you may go to military prison. So probably it probably not really compareable to how most people learn to handle a weapon in the usa. reply TheCoelacanth 5 hours agorootparentprevSwitzerland has very high rates of fun ownership, but their laws are far from lax. They are much stricter than the US. You need a permit to buy anything other than a hunting rifle. You can't buy a gun if you have been convicted of a crime, have an alcohol or drug addiction or express a dangerous attitude. You generally can't carry a gun except when going to and from hunting or a shooting range and you can't have the gun loaded in transit. It's also compulsory for most male citizens to learn to handle a gun safely, something which the US doesn't require even if you buy a gun. reply yjftsjthsd-h 4 hours agorootparent> You need a permit to buy anything other than a hunting rifle. You can't buy a gun if you have been convicted of a crime, have an alcohol or drug addiction or express a dangerous attitude. ...as opposed to the US? Do you think you can just buy a machine gun over the counter without any checks in the states? reply tialaramex 4 hours agorootparentNot an actual machine gun (a weapon specifically designed for automatic high rate of fire), no. The US Supreme Court has repeatedly struck down reasonable restrictions for hand guns and rifles though, and seems likely to conclude that modifying a weapon to in effect become fully automatic is somehow OK. This creates a convenient gap which I don't think a reasonable person can believe is a mistake. reply tialaramex 5 hours agorootparentprevAlthough Switzerland does indeed have (by comparison to the rest of civilised countries) \"Extremely liberal gun laws\" and the higher deaths and injuries to match, it doesn't really compare to the US. reply tecleandor 7 hours agorootparentprevOr most of the EU countries as of today? ¯\\_(ツ)_/¯ reply pdimitar 10 hours agoprevI've been doing programming for ~31 years in total and ~22 years professionally and at this point I have lost all hope that programmers at large will ever gain these mythic qualities called \"self-reflection\" and \"introspection\". Truth is, these people are simply afraid for their cozy jobs, that's all there is to it. Derivative states of mind like Stockholm Syndrome and Sunk Cost Fallacy are quite normal to appear in these conditions. On OP: I could not agree more. People always downplay their fuck-ups, that's sadly part of being a Homo Sapiens, but the lack of awareness is still both despairing and hilarious to watch. And finally, C/C++'s niches have decreased but these people will not adapt, of course. Almost anything I've done with those languages 15-20 years can today be done with Rust. Or if you are on a tight time budget -- Golang, and you still won't lose too much speed. But sure, \"nothing can be done, these things sometimes happen\". Sigh. reply jokteur 10 hours agoparentI would love to be able to use Rust in my professional project. Unfortunately, I am doing high performance scientific computing. Rust doesn't even come close to offer any good alternative to cross-plateform, cross-device (CPU/GPU) libraries such as OpenMP Target, Kokkos, SYCL, ... I believe we need Nvidia/AMD to take Rust seriously (I'm not sure it is even possible without unsafe everywhere) to be able to offer good libraries. In my world, using C++ is the modern language, because most project are stuck with Fortran. reply pdimitar 9 hours agorootparentThat's completely valid and that's why I said \"almost anything\" -- other things include kernel development and embedded. My broader point was that C/C++ are still kings in some areas but people insist on using them where a bunch of languages do better today. reply miki123211 9 hours agorootparentAlso cross-platform libraries, if you want to be everywhere, from computers and phones to set top boxes to weird Japanese rtoses you haven't even heard of, Rust just won't cut it. reply p_l 9 hours agorootparentFortunately there are other languages that are more available cross-platform than Rust with its tiny Tier 1 list. Unless ofc you're contractually obligated to use vendors half-arsed kludget together patchy version of GCC of unknown provenance that they compiled with barely half C support, let alone other GCC languages. reply pjmlp 9 hours agorootparentprevAt least C++ provides the tools to avoid this kind of problems, if one choses to do so, instead of insisting into C idioms. reply anon-3988 9 hours agoparentprevNo, more people should be using memory managed languages like Java and Golang. Then educate and expose people to sum types and pattern matching. It is actually insane how people is still unconvinced about sum types. Imagine how insane it is to program without product types? That's exactly what it felt like. reply pdimitar 9 hours agorootparent> It is actually insane how people is still unconvinced about sum types. Oh don't even get me started on this but I agree sooooo much. > No, more people should be using memory managed languages like Java and Golang. Well, I use both Golang and Rust depending on the need. We can have both, it's not an either-or. reply amarant 9 hours agorootparentI'm feeling my lack of academic training here, but I needed to make sure. When you say sum types, are you referring to enums, or is it a broader concept than that? The Wikipedia article was quite archaic but seemed to support my initial understanding that you're talking about enums. Are you talking about enums? reply tialaramex 8 hours agorootparentRust's enum is a sum type. The enum in C is just integers (again) wearing a hat for some reason. This may not be obvious, but if my enum in C seemingly has three possible values it... doesn't, it actually has at least hundreds of possible values, but only three have names - it's just an integer in a hat. A sum type is an idea from type arithmetic. Suppose we have two types A and B, and we want to produce a new type from those, the most common provision in languages is to let you make a product type, it has all the values of A multiplied by all the values of B, this may be available to you as a named tuple, perhaps named a \"struct\" or \"class\" in your preferred language. But what if instead we added these types instead of multiplying them? The new type has the values of A plus the values of B ? That's a sum type. Suppose I have three types which resemble booleans: mood (it's either happy or sad), size (huge or tiny) and activity (either sleeping or eating) A sum type of these three would allow me to make a \"brief\" of a cat as one of the six values, either as its mood, its size or its activity. The cat brief can be sad, or sleeping, or tiny, but it cannot be sleeping and sad [in this model] any more than a cat's size could be both huge and tiny. There are 2 + 2 + 2 = six values of the brief type. In contrast a product type, maybe lets call that \"state\" of the cat consists of separate values of each of the three constituents, so the state of a cat might be (sad, tiny, sleeping) or (happy, huge, eating) or any other combination. There are 2 * 2 * 2 = eight values of this state type. Just as an arithmetic is kinda crap if it only has multiply but not add, a type system is kinda crap if it can't make sum types. Where complicated hard-to-get-right hacks are used (e.g. C++ std::variant) these are often unsatisfying both ergonomically and in terms of delivered functionality, so hence the desire to have actual sum types in the language. reply flohofwoe 7 hours agorootparentprevIn Rust they are called \"enum\", elsewhere \"tagged union\", \"discriminated union\" or \"variant\" (under the hood, all of those are just a C-style union bundled with a tag field which identifies the active content of the union). The rest is language specific syntax sugar which makes their usage more or less convenient and typesafe (and sometimes more memory efficient, for instance a pointer|null type doesn't need the tag since the set of valid pointers doesn't overlap with null) reply tialaramex 3 hours agorootparent> (under the hood, all of those are just a C-style union bundled with a tag field which identifies the active content of the union) Crucially that's not necessarily what's going on in Rust and (assuming it lands) won't be the actual implementation of C++ std::optional specialisation. Instead the language can decide from the value which type it has. This is where Rust's Guaranteed Niche Optimisation kicks in. If we've promised the compiler that type T's values don't occupy the space needed fully, the GNO promises that sum types consisting of T plus one other value are the same size as T was. There is no \"tag field\". In practice, the compiler can provide optimisations beyond the Guarantee. For example the compiler can see that OwnedFd (a file descriptor) has a niche so Option is the same size as OwnedFd (ie the same size as a C integer, typically 4 bytes), but it can also see that char has a huge niche. Many of the 32 bits aren't needed to store a 21-bit Unicode scalar value, so (although the guarantee doesn't apply) a sum type of a char and six hundred other named possibilities is the same size as just the char was. Ah, I see you mention this at the end, I think it's worth highlighting much earlier, that the \"tag\" isn't actually a mechanically necessary part of such a type. reply pdimitar 9 hours agorootparentprevYes, I am talking Rust enums and OCaml's enumerated data types. reply williamcotton 8 hours agorootparentOr what F# calls a Discriminated Union. reply flohofwoe 7 hours agorootparentprevJust call them \"tagged union\" or \"variant\" and suddenly \"sum types\" are not so rare anymore ;) ...same with \"struct\", \"record\" or \"tuple\" vs \"product type\". Nobody calls them that except functional programmers and mathematicians, both quite rare specimen in the wider programming world, but nevertheless they are ancient and widely known concepts even among us \"peasant coders\" ;) reply anon-3988 2 hours agorootparent> Just call them \"tagged union\" or \"variant\" and suddenly \"sum types\" are not so rare anymore ;) Nah, this is a false dichotomy. If a language doesn't have product types but instead resort to declaring variables separately, you don't call that \"structs\". Similarly, calling tagged unions a sum type is kind of misleading. They are both programming languages, I am sure I can do whatever I can do in A using B. Why is a \"struct\" such a powerful concept? Because it is correct by construction. When I declare struct A, I have everything that A should contain. It is impossible to say, oops, I forgot about A::b. Similarly, a sum type as a concept is only useful when the abstraction is very, very solid. Tagged unions or variants (in C and C++ respectively) is nothing like that. I have a variant A, I checked that that it is B, but oops, I casted it as C. Its your typical TOCTOU (or LOCLOU for line of check, line of use, I guess). std::optional is also like, same with pointers. Proper sum types, like Rust, it is literally impossible for me to get C by mistake. Obviously, all of this minus some underlying implementation details, unsafe code yadda yadda. Sorry if I sound aggressive, but I am just tired of \"we have A at home, A at home (the most cursed shit)\". Does go have enums? Yea... just declare some global constants like so bro. SomeEnum_A = 0 SomeEnum_B = 1 SomeEnum_C = 2 Yea...\"enums\".. Edit: Oh how can I forget, we had this kind of issue just TODAY in production. No wonder I am so pissed off. reply yau8edq12i 10 hours agoparentprevI program MCUs as a hobby. I wish I could use something better than C. Even C++ with RAII would be better. But somehow, even C++ support is spotty, with unsupported features, broken debugging, etc. for seemingly no reason. And all device-specific libraries are written in C, so I'd have to write C++ wrappers for every little thing. Send help... reply pdimitar 10 hours agorootparentThat's why I said \"almost anything\". I am aware that f.ex. kernel development and embedded work is still firmly in the C domain. I am not evangelizing for Rust, Golang or anything in particular. I am evangelizing for periodically asking yourself \"Am I still using the best tool for the job?\" which most people never do. reply nottorp 10 hours agorootparentActually, maybe Rust would get more people interested if it didn't sound like a religion... reply devjab 8 hours agorootparentIt’s a cult, but you don’t have to join the cult. I use Rust both privately and more and more frequently professionally and I don’t really notice the cult community outside of smiling at it once in a while when it blows up on HN. We’re mostly adopting rust to replace our C, to protect us from ourselves. It’s just so much easier to hand off these sort of projects to developers who mainly work with things like Java or C#. Partly because of the memory “safety” but also because things like enums work the way they expect them to being sum types, and so on. It’s also very clear when something is intended not to be mutable. The borrow checker is probably the biggest struggle, where with C, everything is a struggle. Rust still has a long way to come though, and maybe it’ll never get there. I do think we’ll see an uptake as performance increasingly matters due to cloud costs and ESG. Right now though, I’d argue that unless you know why you “want” to use Rust then maybe you shouldn’t. reply pdimitar 7 hours agorootparentMostly agreed with your comment though I still have to remark that every community has zealots and it's mystifying to me why are people so annoyed by Rust's. So it's hard to agree that \"Rust is a cult\". As you said, it's a pragmatic but also kinda niche language. I don't reach for it unless I can't do the job with others, easier and quicker to work with languages. reply AnimalMuppet 5 hours agorootparent> ... every community has zealots and it's mystifying to me why are people so annoyed by Rust's. Because they're the ones that we keep hearing from right now. When it was the Haskell zealots showing up every few days, they were annoying. When it was the Lisp zealots, they were annoying. reply flohofwoe 7 hours agorootparentprevThe C sphere is actually refreshingly free of zealotry (mainly I guess because there isn't such a thing as a \"C community\" and even despite C being the main attack target of language zealots - funny enough nobody complains about those pesky assembly coders and their hippie attitude towards memory safety lol). The \"religious zeal\" was also an important reason why I switched back to C from C++ and why I don't have much interest in Rust. I can't quite stand the \"holier than thou\" attitude in.parts of those communities. reply pjmlp 6 hours agorootparentAre you sure? The C sphere overlaps with the UNIX one, for obvious reasons. reply flohofwoe 5 hours agorootparentI can't remember Linux zealots raving irrationally about C though (although when googling I'm sure something will come up). Topics like Wayland or systemd on the other hand, oh my... reply pjmlp 5 hours agorootparentI said UNIX culture, not Linux. Diving into the ruins of Usenet, or UNIX/C literature, will provide enough examples. reply pdimitar 6 hours agorootparentprev> This was an important reason why I switched back to C from C++ and why I don't have much interest in Rust. I can't quite stand the the \"holier than thou\" attitude in.parts of those communities. This is 100% baffling to me. Let me explain. 1. Every single area has zealots. Yours included. And we're not talking only work. Every hobby area as well. 2. What the attitude of the most toxic 0.1% of the users of a thing is has exactly ZERO correlation with whether the thing is good and worth using. 3. By resisting only those 0.1% toxic zealots you are only demonstrating meaningless rebelliousness. As a supposed adult you should be immune to what are people hyping up and form your own opinion. INFORMED opinion. Not one based on the \"many people praise it hence I, the intellectual, will stay far away from that obvious nonsense\" stance. 4. Have you considered that maybe, just maybe, Rust is praised because it's actually good? Have you considered that the Rust community is not trying to cheat its way into your heart, and that the love Rust gets is justified by the people who need its features? Seems like you did not, and that's disappointing. In other words, I have zero clue of your thought process here, maybe you can help me understand? Back in my home town the VW Golf had an ardent fan base, yet one of my friends still bought one after he graduated. He didn't call the people who loved VW Golf zealots. He did his research and concluded that with his budget and mechanic skills the VW Golf is the ideal option. Food for thought? reply flohofwoe 6 hours agorootparentI spent 20 years with C++ as my main language, and the endless and heated \"style discussions\" where personal.opinions are thrown around like facts were just tiring and a massive waste of time. And it's such endless circular discussion where the extremists show up (I guess the equivalent in Rust is shaming projects that use unsafe, IIRC there have been quite a few dramas in the past). Shit like this is simply mentally exhausting, and in now 7 years of C as my main language I did not encounter this even once). In general C coders seems to be a quite relaxed, happy and tolerant bunch. reply pdimitar 6 hours agorootparentRestating your anecdotal evidence is just stubborn and does not advance any discussion but you do you. You also addressed almost zero of what I said and asked you. reply flohofwoe 6 hours agorootparentIn the end I did seriously look into Rust for a time and decided that's not my thing and instead watch progress from the sidelines in case anything interesting happens in the language to give it another try. What's quite obvious when watching from the outside is that it's almost always people with a crab emoji in their profile who are more likely to talk shit about C programmers (myself included in a couple of cases via subtweeting). I usually just shrug it off and move on, because what else is there to do? reply pdimitar 6 hours agorootparent> In the end I did seriously look into Rust for a time and decided that's not my thing and instead watch progress from the sidelines in case anything interesting happens in the language to give it another try. FYI I did the same because the kind of work that I do does not desperately need Rust's benefits. But I'll always call out biased and prejudiced people and I don't care about what the HN group-think believes. > I usually just shrug it off and move on, because what else is there to do? 1. Stop thinking that the zealots are representative of... anything at all, really. (I don't include myself in that group of zealots. I get ticked off by bias and firmly held preconceived notions. That's why I commented as much in the entire sub-thread started by me.) 2. Do your own research like you did. 3. Refuse to think about trolls and zealots. Which is what all of us as healthy adults in this attention-predatory age of the internet should do. reply nottorp 6 hours agorootparentprevIn Europe (esp Eastern), if you take resale price into account you have to get a german car because everything else loses value faster :) The VWs you can just dump on the fans. I know, I live in a similar country. reply pdimitar 6 hours agorootparentThe point is that the guy who was bombarded by feedback that VW Golf is good did not go out of his way to avoid buying it. He did his own research, formed his own informed opinion, and didn't go against the grain due to misguided notions. Wink wink. reply pdimitar 10 hours agorootparentprevMaybe it's you and some other curmudgeons projecting -- worth to consider if that's the case. Maybe it's normal for people to praise something that legitimately solved their problems. I know that happened with me. reply glass-z13 10 hours agorootparentThere is a difference between praising and preaching, the latter happens more often with rust reply pdimitar 10 hours agorootparentIf you say so. ¯\\_(ツ)_/¯ But even if it was true (I'd contest it's not) can't you ignore it and judge the language on its merits? We are not teenagers for a long, long time now, we should be making up our own mind about things. reply nottorp 9 hours agorootparent> we should be making up our own mind about things But you denied my right to make up my own mind about Rust based on what its proponents say. I believe you even attempted to insult me, too bad I don't know what curmudgeon means :) reply pdimitar 9 hours agorootparentI have not done either. \"Curmudgeon\" is a \"get off my lawn, kids!\" grandpa btw. :) I have not denied you anything, I implored you to ignore the zealots that exist IN EVERY ECOSYSTEM and judge the thing based on what it can actually do. Please don't misrepresent what I said, that's not arguing in good faith. reply nottorp 9 hours agorootparentHeh, this grandpa has written like 3x more python than C this year. And the C part was no choice - that was all I had on these devices. Edit: from what I hear from my peers (translation: other programmers that I have coffee or drinks with), if I started a new server application today and I needed the performance of a compiled language, I should use Go not Rust. I believe servers are where the propensity of C like languages to allow you to shoot yourself in the foot is the problem, isn't it? reply pdimitar 9 hours agorootparentServers and many CLI tools, yes. Buffer overflows and memory unsafety are really easy to allow there for everyone but absolutely Godlike C/C++ devs. Golang, Rust, Nim, Zig, and a few others are a much better fit nowadays. reply nottorp 9 hours agorootparentprevBefore the current \"AI\" hysteria, HN was full of \"I've rewritten this thing that was working just fine in Rust\". No mention of how it's better, has more features - or even has all the original's features - or anything about why you should use the rewrite instead of the original. Am I supposed to use a tool just because of what it's made of, or because it solves a problem for me? reply pdimitar 9 hours agorootparent> No mention of how it's better No embarrassing buffer overflow CVEs is a very good start. To me that's an actual selling point and I've migrated from almost all UNIX coreutils to Rust alternatives for that reason alone. > Am I supposed to use a tool just because of what it's made of, or because it solves a problem for me? No, as an adult you are supposed to not frame the discussion unfairly and ask the right questions. reply nottorp 8 hours agorootparentThe right questions according to who? Are your coreutils replacements 100% drop-in? reply pdimitar 8 hours agorootparentI don't need a 100% drop-in. Barely anyone does. I've observed at least 80% of all of the coreutils features are not used by 90% - 99% of programmers and sysadmins. Ask people if they used all flags of `sort` and report back results as a test of my hypothesis. > The right questions according to who? This is tiring. I told you twice that I'd prefer you engaging in technical merits. You keep drawing attention to what is annoying you but you'll have to talk to your friends and family about that because I am not interested. Bye. reply nottorp 6 hours agorootparentBut the only \"technical merit\" seems to be \"omg it's more secure\". I've literally never seen any other argument in favor of Rust. reply AnimalMuppet 5 hours agorootparentprevI don't see many CVEs in coreutils. Maybe one or two, in several decades? I do on occasion use obscure flags (or at least ones that are obscure to me). > This is tiring. Hey, you're the one keeping the argument going... reply pdimitar 5 hours agorootparentOne more person misinterpreting? Cool. I am getting tired of being misinterpreted, not of the argument itself because the argument ended several comments ago and the person focused on being a little rebel (\"who gets the determine the right questions\" is his favorite pet peeve apparently). There is no argument currently, just people trying really hard to miss the point that was stated very clearly. reply AnimalMuppet 5 hours agorootparentYeah... I'll just leave the other readers (if anyone else is still reading) to judge whether we missed your point, or you missed ours... (Or, I suppose, whether we're just talking past each other.) reply pdimitar 5 hours agorootparentBy all means, name your exact point then. Mine was that some people needlessly -- and very immaturely -- rebel against using Rust because of something they saw on HN 5 years ago. There's no Rust zealotry here for a long time. I chased after a few people asking them if they really tried it or they simply resist something because it's gaining popularity. How dare I? :D reply pjmlp 9 hours agorootparentprevMikroe is still in business selling Pascal and Basic compilers for all kinds of tiny CPU and MCUs since 1997, so some people do value their products. reply MrBuddyCasino 8 hours agorootparentprevRust only works for a few popular targets, but if it is just a hobby then Zig might be an option. C interop is pretty seamless, so you don't face the problem of having to reinvent the universe. reply GoblinSlayer 7 hours agorootparentIn my experience interop is rarely a language problem, lion share of time is consumed by reading the docs, testing if you understood the docs correctly, testing what's implied but not written in the docs and figuring out how to cope with idiosyncratic interface. reply GoblinSlayer 9 hours agoparentprevIt's possible to write systematically safe code in C, no need to change language. People really just don't want to do it. reply from-nibly 6 hours agorootparentIt's possible to write systematically safe code in assembly, no need to use any language. People really just don't want to do it. reply GoblinSlayer 5 hours agorootparentWhen the language has builtin safety, it has better ergonomics, so there's merit in switching language. reply pjmlp 9 hours agorootparentprevIn theory, in 50 years of practice, not really. reply GoblinSlayer 7 hours agorootparentIf you mean those two godlike C programmers, that's not what I mean. reply pdimitar 9 hours agorootparentprevMaybe it is but the last several years of periodic (and quite embarrassing) CVEs suggest otherwise. reply GoblinSlayer 7 hours agorootparentWhat they suggest? What I and the discussed article claim is that safe code isn't written because programmers don't want it. CVEs aren't caused by desires, they are caused by unsafe code. reply pdimitar 7 hours agorootparentMany people suggest to start gradually migrating to either Rust or start investing much more seriously in formally proving C/C++ code (which is IMO a huge endeavor). As I said in multiple other comments, I know there are valid cases for C/C++ where various factors prevent migration. I am not playing a little rebel revolutionary here, I am addressing the people who can migrate away but refuse to do so based on hand-wavy philosophy clashes (or my favorite petty rebellious take: \"people praise Rust, I must resist using it!\"). Petty stuff and I am pretty disappointed that people who bill themselves as \"engineers\" refuse to see objective evidence and hold on to only what they know. Those are the people I address with my comment. Not the people who will be never allowed to migrate away a 2 million lines worth of C codebase. They have my deepest sympathies. reply GoblinSlayer 4 hours agorootparentI didn't propose to migrate to rust. reply pdimitar 4 hours agorootparentYou asked me a question, I replied. reply bell-cot 9 hours agorootparentprevTHIS, sadly. Though it'd be more accurate to re-phrase: 's/just don't want to do it/have other priorities, or are stuck in organizations with other priorities/' reply pdimitar 9 hours agorootparentI get that we can't always do what we want in our jobs (and in some places quite rarely even). I get it fully and I sympathize. But that still doesn't do C/C++ any favors. None of my Rust contracting work ever resulted in a buffer overflow. reply pjmlp 6 hours agorootparentAnd it doesn't need to be Rust, as the anti-seat belt folks always are quick to complain about, plenty of systems languages since PL/I and NEWP days have bounds checks by default. Back in the days we were arguing for Ada, Modula-2, Object Pascal on Usenet, we were straitjacket programming advocates apparently. reply pdimitar 6 hours agorootparentHaha, nice analogy, thank you. :) And yeah I am gradually giving up on arguing with people who are extremely biased but point at me and blame me for being biased. Seems there's no win. I actually regret engaging so thoroughly in this thread but once started I figured I'll not budge and will hold my ground. I am anti-group-think that way. I haven't engaged in such threads in a while and I think the next time around is going to be months in the future. We'll see. reply _rm 9 hours agoparentprevThis is one possibility. Have you considered the other, that you're the old-man-yells-at-cloud variety of narcissist? Hence why you choose to interpret things as everyone (except you) is defective. Everyone (except you) is laughable, completely lacking in self-awareness, refusing to adapt and be and do as they should (according to you of course). Because they're all lesser than you! That's why. You write Rust. So obviously, you're so far above them. Like a God looking down at monkeys. Couldn't be reasons like inertia, or lacking the time, or not having the budget to change, or being too tired to learn, or any other such thing that'd let them be equal to you but just with differing priorities. No, because then you wouldn't get your narcissistic supply, allowing your delusion you're better than others, rather than a man distracting himself from his own failings? Just an alternative theory. What do you think? reply odiroot 1 hour agorootparentDon't worry, HN went through this many times before. It was Go a few years ago, Node.JS before that. Rust too shall pass. reply pdimitar 9 hours agorootparentprev> Couldn't be reasons like inertia, or lacking the time, or not having the budget to change, or being too tired to learn, or any other such thing that'd let them be equal to you but just with differing priorities. This is already included in the \"almost anything\" expression and you are the 4th person deliberately (or accidentally?) not noticing it. There are valid cases for C/C++ both on technical merits and business specifics. I have not denied that. --- The rest of your comment is just projection borne out of your faulty assumptions about my comment and it's thus not interesting at all. reply FdbkHb 7 hours agorootparent> This is already included in the \"almost anything\" expression and you are the 4th person deliberately (or accidentally?) not noticing it. I genuinely think that : 1/ this field is dominated by a disproportionate amount of people with autistic traits 2/ their ability to reason only functions in the narrowest sense and their grasp of language (takes everything in the most literal sense, thinks in extremes, prone to putting things in boxes, have a very, very strong attachment to their routine and are unable to ever leave the comfort zone they constructed) makes any attempt at communication beyond painful. I have come to not even bother replying to people who are unable to understand human words such as when they interpret \"most\" as meaning \"all\" or \"rarely\" as \"never\" as it's one of the telltale signs that it is going to be extremely unproductive. This phenomenon is the cause of most pains and drama. Once you start to see how this pattern develops you understand the true cause of the endless bikeshedding, of why even the idea of having a code of conduct can raise endless anger and storms and so on. You're touching a comfort zone so the temper tantrums are thrown. The routine has been built and it must continue until the end of times. If there's any field in this world that is in need of more neurotypical, emotionally stable adults, this is it. reply Xeamek 10 hours agoparentprevEh, Rust would be fine if not for the fact that it's too opinionated. Unfortunately you can't just have Rust's safety checks, without opting into restrictions that Rust designers force onto You that aren't inherent to safety checks, but more because 'that's a better practice (according to us)'. And also, easy and fast iteration just isn't there, both because of borrow checker restrictions and compile times reply pdimitar 10 hours agorootparentC/C++ being non-opinionated is the main source of the security vulnerabilities. Let's face it, it felt good to be a lone cowboy carrying a lot of responsibility and knowing what you are doing. I was there myself and I'll admit the ego trip was awesome. These times are long past and naturally, people refuse to adapt. > Unfortunately you can't just have Rust's safety checks, without opting into restrictions that Rust designers force onto You that aren't inherent to safety checks, but more because 'that's a better practice (according to us)'. Show me something that does better and I'll switch tomorrow. But don't tell me C/C++ are better -- they are not. Too much freedom leads to CVEs literally every month somewhere and that's only because we don't have better vetting and checking tools, otherwise I'm sure we'd be getting one every day for a while. > And also, easy and fast iteration just isn't there, both because of borrow checker restrictions and compile times I agree on that, that's why I mentioned Golang. Most of the C/C++ systems I worked on around 15-20 years ago didn't need the close-to-the-metal speed because at least 90% of their time was spent on I/O... frak, even Python would have done well there. And Golang is times faster. It's a very nice compromise if you want to be productive and don't care super much about CPU speed efficiency. reply pjc50 10 hours agorootparent> C/C++ being non-opinionated is the main source of the security vulnerabilities This. \"Undefined behavior\" is such a terrible way of thinking. As is the \"we can assume in the optimizer that UB does not happen and then eliminate code on that basis\", which allows the compiler to introduce bugs that only appear at certain -O levels. It took decades to get them to define arithmetic as twos-complement. reply aw1621107 9 hours agorootparent> It took decades to get them to define arithmetic as twos-complement. I'm not sure this is right? IIRC C++20/C23 require two's complement representation for signed integers but generally leave other behaviors (including signed overflow) the same. [0]: https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p09... reply ngrilly 9 hours agorootparentprevI’d say the biggest problem of interpreted, JIT compiled, and GCed languages is not the speed; it’s the RAM use. I agree that quite often we don’t need the speed of close-to-the-metal. But there is something wrong with most programs eating tens or hundreds of megabytes, without doing much. reply pdimitar 9 hours agorootparentAnd I agree on that. My favorite Elixir's runtime (Erlang's BEAM VM) still has some subtle problems with holding on to big(ger) binaries (strings) that requires very specific code be written at the green thread boundaries and it can get pretty maddening if you don't get it right -- which is not easy. Golang I hear is doing much better btw. But you still have to be wary of its footguns i.e. leaking goroutines. reply GoblinSlayer 4 hours agorootparentprev>Show me something that does better and I'll switch tomorrow. There's no limit to perfection, but if you merely don't write C of opportunistic kind, logical errors quickly start to outweigh other types of errors. reply pdimitar 4 hours agorootparentAre you willing to die on this hill? I remember an HN post a while ago where both Microsoft and Google said something like 65% of the bugs in C code were related to memory (un)safety. reply Xeamek 10 hours agorootparentprevThere are restrictions out on You by the borrow checker to ensure safety, and then there are restrictions put on You by rust design team 'just because'. Again, the former are fine, it's the latter I have a problem with. reply pdimitar 10 hours agorootparentIn order for me to agree on the \"just because\" part you'll have to give some examples. What made you think they are arbitrary? And how did they prevent you from doing your job? reply Xeamek 9 hours agorootparentComment above, mentioned borrowing while structs instead of borrowing memory. I believe this was once discussed under term 'partial borrows', but the \"idiomatic\" aproach is to 'just split your structs'. Which isn't really a good aproach to structuring codebase, it's just to appeal to borrow checker inflexibility. Lack of global scope. Lack of function overloading. reply Measter 5 hours agorootparent> Comment above, mentioned borrowing while structs instead of borrowing memory. I believe this was once discussed under term 'partial borrows', but the \"idiomatic\" aproach is to 'just split your structs'. You're mistaking \"idomatic because it's the only way\" with \"idomatic because we say say so\". There is currently no way in Rust to specify the granularity of a borrow, so we're stuck with splitting your structs to get around it. Part of the problem is that it's a hard problem to design around. It can not be done automatically by the compiler, because it would result in changes in the implementation being changes in the type signature. For example, say we have this function: pub fn foo(&self) -> i32 { self.a + 5 } The granularity is borrowing `a`. If we then change it to this: pub fn foo(&self) -> i32 { self.a + self.b } The granularity of the borrow has changed in a backwards incompatible way (it now includes `b`), but that change is not reflected in the signature. It's the same reason why the compiler refuses to infer signature lifetimes from function bodies now. You could, of course, say that we can allow the programmer to specify it manually: pub fn foo(&'borrow self) -> i32 where 'borrow: 'self.a + 'self.b { self.a + self.b } But this is now leaking implementation details if `a` or `b` are private fields. reply Xeamek 4 hours agorootparentThat's truism, ofcourse there is no way to do something that is not impemented. The question is whether or not the fact of it not being implemented comes from problem difficulty, or designers explicit refusal to do so reply aw1621107 9 hours agorootparentprev> Lack of function overloading. Isn't there at least some technical basis for this (less-than-ideal interactions with type inference IIRC)? reply pjmlp 9 hours agorootparentprevI would say until C++98, C++ used to be more opinated, one of the reasons many of us went with C++ when given the choice, wasn't OOP features, rather the security improvements over bare bones C, with compiler provider frameworks. Then eventually C++ got invaded by C expatriates, and writing C with C++ compiler idioms increased instead of going away. It is like giving Typescript to groups of folks that insist on using any all over the place. reply pdimitar 9 hours agorootparentActually I have good-ish memories of the early `boost` (we're talking 2003 - 2006) and some of the `std::` libraries in C++. They got the job done fine and were not in the way. So yeah, agreed. reply eterevsky 10 hours agorootparentprevUnfortunately you have to pick 2 out of: - Lack of restrictions - Safety - Performance If you choose safety and no restriction, you pay the price in performance (for GC etc.) reply flohofwoe 10 hours agorootparentThere's a massive Terra Incognita to explore between Rust on one side and Python on the other side (just to pick two extremes). It's not \"2 out of 3\", it's a triangle where a language can pick a sweet spot anywhere within the triangle (and ideally, it's not a \"sweet spot\" either, but more like a \"sweet area\" where the programmer can pick an actual spot within that area defined by the language). reply pdimitar 10 hours agorootparentThat sort of extreme flexibility simply does not exist. I mean it does but then you are firmly in the dynamic languages territory and you are forgoing any hope for close-to-the-metal performance. reply flohofwoe 9 hours agorootparentIMHO it does and its not restricted to dynamic languages (like JS or Python), look at this Zig function signature for instance (just an example from my current dabbling): fn setData(comptime pins: anytype, bus: anytype, data: u8) @TypeOf(bus) In practice this looks and feels like dynamic typing, yet when looking at the compiler output it still resolves to optimal code (since it's \"compile-time dynamic typing\" not \"run-time dynamic typing\", but the difference in practice is surprisingly small). reply pdimitar 9 hours agorootparentWell you can make OCaml and Rust look like dynamic typing as well by omitting type signatures and squeezing the type inference engine as much as you can but I was under the impression that you have more asked about something that is very relaxed in terms of upfront requirements and be able to tighten it up later? That's why I claimed that no such language exists. reply flohofwoe 8 hours agorootparentI was thinking more in terms of \"language surface\" but it didn't come across, C and Zig have a fairly small language surface (Zig a bit bigger than C), simple language primitives that can be combined quite freely and without much restrictions, but at the same time not carrying a lot of semantics the compiler could use to ensure safety (ignoring the \"sloppiness\" design warts of C though, like implicit type conversions, allowing accidential uninitialized data, or inverted defaults (mutable vs immutable) - these things are obvious problems but cannot be easily fixed in C or C++ because of backward compatibility requirements - they have been fixed in Zig though). Rust is quite the opposite, more primitives that carry semantics (most of those in the stdlib though), a stronger but also more rigid type system, but those are pretty much needed for the compiler to guarantee safety. The million dollar question is of course, can there be a more relaxed Rust with the same safety and performance guarantees, maybe by \"squeezing the type inference engine\" even more (and letting Rust look or somehow extract information across crate boundaries)? And do Rust programmers even see this as desirable, or are they mostly comfortable in their current sweet spot of the triangle? reply pdimitar 7 hours agorootparentI agree that your million dollar question is very good and relevant. Rust can definitely be improved -- async is sticking out as a sore thumb still and it requires a lot of ad-hoc knowledge that's not at all intuitive -- but I'd still venture to say it does pretty well in many areas. Rust absolutely is not the end state of programming languages but I feel in many ways it's quite ahead than most of everything else. But yes, we still need something a tad better than it. reply SpaceNugget 9 hours agorootparentprevI'm not super familiar with Zig, but that appears to be the same as the rust function signature fn setData(pins: P, bus: B, data: u8) -> B; in rust, the P and B are resolved at compile time, not at runtime. If you wanted dynamic dispatch the types would be Box reply flohofwoe 8 hours agorootparentYes, it's essentially the same, the comptime attribute on the pins arg is quite important though (in the function body that's not shown). reply Xeamek 10 hours agorootparentprevAgain, restrictions that are forced you for a price of safety are one thing. But what I'm complaining about are restrictions that don't have to be there to get borrowchecker working, but rather are there because designers arbitrary decided \"it's better this way\". reply komali2 10 hours agorootparentAs someone just starting to finally learn Rust, I'm curious what some examples of this might be. reply flohofwoe 10 hours agorootparentAll AFAIK, since I only dabble occasionally in Rust: The borrow checker works on \"struct granularity\", but it would be much more flexible and convenient if borrowing would work on memory location granularity (for instance passing a struct reference into a function \"taints\" the entire struct as borrowed, even if that function only accesses a single item in the borrowed struct - this 'coarse borrowing' restriction then may lead to all sorts of workarounds to appease the compiler, from 'restructuring' your structs into smaller pieces (which then however may fit one borrowing situation, but not another), or using 'semantic crutches' like Rc, Cell or Box. There are also related restrictions about function call barriers. AFAIK the Rust compiler cannot \"peek into\" called function bodies to figure out what's actually going on inside those functions (and that information would be very valuable for fine-grained borrow checking), it can only work with the information in the function signature. Again, disclaimer: take this with a grain of salt since I'm not a daily Rust user, but this is how I understood why Rust feels so restrictive. reply pdimitar 9 hours agorootparent> The borrow checker works on \"struct granularity\", but it would be much more flexible and convenient if borrowing would work on memory location granularity (for instance passing a struct reference into a function \"taints\" the entire struct as borrowed, even if that function only accesses a single item in the borrowed struct - this 'coarse borrowing' restriction then may lead to all sorts of workarounds to appease the compiler, from 'restructuring' your structs into smaller pieces (which then however may fit one borrowing situation, but not another), or using 'semantic crutches' like Rc, Cell or Box. That's valid, thanks for pointing it out. I seem to recall the team lately mentioning they are starting to consider fixing that. And yes that's a real productivity killer, happened to me as well in the past. reply Measter 5 hours agorootparentprev> There are also related restrictions about function call barriers. AFAIK the Rust compiler cannot \"peek into\" called function bodies to figure out what's actually going on inside those functions (and that information would be very valuable for fine-grained borrow checking), it can only work with the information in the function signature. I don't think it's so much \"can not\" as it is \"will not\". Allowing the function signature to be determined by the body can lead to accidentally breaking callers by changing the body. That, at least, is consistent with other parts of the signature: the input/output types and how the lifetimes of input/output references are related. reply eterevsky 9 hours agorootparentprevThey made a lot of progress with borrow checker granularity between 1.0 and now. It's much more granular now than before. reply hdjksndhsi 10 hours agorootparentprevSo a few things .. Rust is a very good safe language. It also has an unsafe keyword to make the compiler ignore borrows etc. If you want fast iteration, use python and then hand transpile your code into rust. Not every tool has to be used at once ... but Python for the idea and rust for the implementation can be the best of both worlds ... :) reply Xeamek 9 hours agorootparentExcept Rust's unsafe is even worse then any other 'unsafe' languages. And while you can technically prototype in a other language, speed of iteration is always a bottleneck. The only way to escape it is if You are an about master of language, the project you are working on and even the feature you are adding. But that's a verry rare case scenario reply pdimitar 9 hours agorootparentI don't disagree btw. As a contractor I have found myself very often in a situation where Rust's slower iteration simply didn't work for me so I got back to Elixir and also relearned and started getting proficient in Golang. Rust's slower iteration only disappears when you become a pro as you said and that's my main problem with it. I simply can't invest as much time and effort for free. reply self_awareness 10 hours agorootparentprevMost programmers don't have any opinions, so if they use an unopinionated language, they end up using patterns that opinionated people use. So it's better to have one source of truth for opinions, so that we don't end up using the \"wrong\" opinions of people who talk more than they think. reply flohofwoe 9 hours agorootparentCompiler/language people are also just \"opinionated people\" though. Some have good opinions, some have bad opinions. In the worst case you have opinions which are the result of a 'design by committee/community' process. reply self_awareness 9 hours agorootparentSingle source of truth of opinions can be challenged and changed if one's arguments are good enough. The benefit is that it's easier to see the advantages and disadvantages for those opinions, because they're all in the same place. This is in contrast to C++, where one organization creates a set of guidelines, another organization creates another set of guidelines. Valid arguments of critique in one organization are not seen in the other. Single source of truth is also beneficial to compiler authors as well, because they get more feedback how the language is used and why. reply scotty79 10 hours agorootparentprevRust is just a different language. It's not C-like or Java-like plus checks or anything like that. It's a value oriented language. Variables mean something completely different than in any other common language. Everything is about the values and where they are kept at the moment. reply nomilk 11 hours agoprevMore broadly: > \"No way to prevent $THIS\" say users of only language where $THIS regularly happens A weird psychological quirk I've noticed (of myself, and others) is we'll often exhibit a sort of 'programming language xenophobia', where we apathetically accept (or don't even notice) unpleasantries of our language of choice, yet be quite averse to the unpleasantries of other languages. Maybe it's due to sunk cost; time/effort has already been spent finding work arounds for or adapting to the warts of our native tongue, whereas doing so for unfamiliar languages would require additional effort. reply jstimpfle 10 hours agoparentNo way to prevent \"this\", says C++ programmer. reply from-nibly 6 hours agorootparentJust use Python it uses 'self' reply jstimpfle 4 hours agorootparentIn Python, you can easily just not type \"self\" (or whatever you named the 1st arg). In C++, you can not not type \"this\", at least if you don't, \"this\" will be looked up anyway. reply bsza 10 hours agoparentprevI would rather have unpleasantries that make the language safer vs unpleasantries that make it more vulnerable. Especially when the unpleasantries in question don’t even make the language easier to use. reply quectophoton 6 hours agorootparentC standard: \"Undefined behavior means such a situation can't happen.\" Me: \"If it can't happen then it would be fine to just crash on those situations, right? Because such a crash would never be reached. Can we get that?\" C compilers: \"No. Would you want to crash on signed integer overflow, for example?\" Me: \"Yes? Would be safer than the current situation at least.\" C compilers: \"What, no, that would make your programs imperceptibly slower. Would you even like that?\" Me: \"Yes, I'll be able to live with that.\" C compilers: \"Well, the answer is still no.\" reply GoblinSlayer 5 hours agorootparentC is more likely to define wrapping arithmetic. Wrapping is defined as undefined for compatibility with MIPS processors that support checked arithmetic. reply nullc 6 hours agorootparentprevIt would have taken you less time to look up -fwrapv / -ftrapv / -fsanitize=signed-integer-overflow + -fsanitize-undefined-trap-on-error than write out that misleading dialog. :) reply quectophoton 6 hours agorootparentFair. Last time I checked ubsan was a few years ago for a small program, and I've read stuff about it not being suitable for anything outside development (more like a valgrind complement than a release option) because of how it messed with environment variables and linked libraries or something, so I might not have the full picture. reply JimDabell 10 hours agoparentprevThere’s probably a large selection bias at work as well – people who care about those specific unpleasantries will avoid that language in the first place. reply BoxOfRain 10 hours agoparentprevThis is definitely a thing I recognise in myself, a year and a half of writing Scala daily has made me much more prejudiced against Java than I was before. reply immibis 10 hours agoparentprevsee also https://wiki.c2.com/?BlubParadox reply isoprophlex 11 hours agoprevMaybe C programmers need some more thoughts and prayers at deployment time? reply devjab 10 hours agoparentYou obviously need to perform the correct rites and pay your homage to the blessed machine spirit or the Omnissiah will not permit your code to compile. reply ramon156 10 hours agorootparentWe can learn a lot from terry davis reply Beretta_Vexee 9 hours agoparentprevNo, the only way to stop a bad dev with a strcpy() is a good dev with a strcpy(). reply isoprophlex 8 hours agorootparentC doesn't overflow and spill your memory contents, your RAM modules do! reply snovv_crash 9 hours agorootparentprevBasically fuzzing then? reply bigiain 10 hours agoparentprevBut the 2nd amendment guarantees their right to insecure code! reply mikewarot 2 hours agoprevFree Pascal and Lazarus which is a GUI built on it support strings that don't require manual allocation and are counted and reference counted. A huge amount of grief would go away if that library could be supported in the Linux kernel somehow, and all of the string parameters in system calls ported. reply cookiengineer 11 hours agoprevAlternative headline should be \"But I have been taught that using C++ makes me the better programmer\" because the stereotypes of echo chambers on the internet raised a lot of unreflected programmers to be this way. There is a place for C, where there's no alternative. But that place is where 99% of programmers never work, because they are not doing kernel nor firmware development (which, in the meantime, also has a lot of support by and for memory safe VMs and languages). The issue I have with this narcisstic fatigue (similar to the author's point I assume) is that there is no reflection when they fuck up a codebase. The best code is the code that is safe and easy to read, and doesn't need to use \"clever tricks\" that beginners cannot understand. If you are using some tricks for type casting to implement your ideas into code, you probably should not write code. Code should be dumb and easily maintainable. If it is not, you made the wrong choice for the programming language. reply pjmlp 10 hours agoparentKernels have been developed in safer languages already before C became widespread outside Bell Labs, it is a myth that C is even required for that, other than historical baggage. reply p_l 10 hours agorootparentEspecially when one adds how many \"low level programming\" idioms for C are, as far as I understand, undefined behaviour in C. Like assigning an address to then use as pointer to physical memory... Which is extra visible when one looks at original UNIX sources and its many short assembly bits in separate files to handle bits of direct hw manipulation. reply lpribis 9 hours agorootparent> Like assigning an address to then use as pointer to physical memory... What do you mean by this? Like writing to a specific integer address? *((volatile unsigned *)(0x20001000)) = 0x12345678; That's not UB and is also the only way to write to memmapped registers. reply p_l 9 hours agorootparentIt's not UB. It's also not covered by standard - it's implementation-specified. What will happen is dependant on decision of compiler writers. It is, however, not the only way to write to memmapped registers. The original C way of doing so was to use an assembly function wrapping the actual act of reading/writing (honestly, better than doing the above, as it helps making it very explicit how the write will happen as well as abstracting any details like needing to add a barrier or whatsoever), the other way was to specify the symbol with address of the memmapped register in assembly, and link resulting object with C code. A C implementation is, AFAIK, free to refuse the literal addresses used as pointers and pass as ISO C. reply rfoo 6 hours agorootparentBoth of the alternative do not generate same code though. At least they don't without LTO. reply p_l 6 hours agorootparentThe point of \"implementation defined\" is that the actual code generated is up to implementation, or in fact whether it even accepts such code. reply pjc50 9 hours agorootparentprev> That's not UB Please cite chapter and verse of the C standard which defines this behavior. Any edition. reply foldr 8 hours agorootparentI don't know if this particular example is UB or not, but the dichotomy here between 'defined' and 'not defined' is a false one, as C also specifies some constructs as having 'implementation defined' behavior. The behavior of such constructs is not defined in the standard, but is also not 'undefined' in the special sense of 'undefined behavior'. Edit: Looks like the result in this case is implementation defined: https://stackoverflow.com/a/24212940 reply phoe-krk 10 hours agoparentprev> There is a place for C, where there's no alternative. Alternatives to C have started appearing for a long while, and they are quite mature now. > because they are not doing kernel development FluentBit, where this error occurred, is a userspace application. > there is no reflection when they fuck up a codebase C does not support runtime reflection, that is correct. It's one of the reasons why it's a programming and debugging nightmare. > If you are using some tricks for type casting to implement your ideas into code There seem to be no casting issues involved in https://www.tenable.com/security/research/tra-2024-17. > The best code is the code that is safe and easy to read, and doesn't need to use \"clever tricks\" that beginners cannot understand. It's just a pile of truisms. Is your whole post even related to this article? reply darkwater 10 hours agorootparent> Is your whole post even related to this article? I think they were just reiterating TFA message in another way: Don't expose yourself to the pitfalls of C when the actual power of C is not really needed. reply cookiengineer 10 hours agorootparentprev> There seem to be no casting issues involved in ... Maybe go to http://osv.dev/list and search for OOB or Out of Boundary errors instead to make a study on whether this regularly happens or not? Especially when parsing arbitrary strings into a struct? I'm not sure whether or not you got my message to prefer any programming language over C/C++ or whether you're trying to ignore that on purpose? reply yetihehe 11 hours agoparentprev> Code should be dumb and easily maintainable. We now have enough resources to do this. When C was created, we had to do those tricks to have good performance. Currently C is best used for constrained devices, where sometimes you need those tricks. > If it is not, you, yes ... you, made the wrong choice for the programming language. Or your project manager or CTO, or some other stakeholder. reply consp 10 hours agoparentprev> Code should be dumb and easily maintainable. Well ... that rules out everyone's pet favourite here to replace c. reply baq 10 hours agorootparentwhich is C, because nothing can replace C. C is portable assembly. Don't use it unless you really must. Yes I know people want to replace C with Rust, no it won't work because Rust is not assembly, yes it can be used to replace anywhere between 90% to 99% of C and it shouldn't even be too hard. (Unless your embedded device manufacturer doesn't care, which of course they don't.) reply pjc50 10 hours agorootparent> C is portable assembly. Unfortunately, it isn't quite this, and many of the instances which people use it for this are actually undefined behavior; there's a hinterland of \"things C compilers do\" which are used as portable asm but are not part of C because they are UB. I sometimes wonder if it would be feasible to define an actually portable typesafe macro assembler. reply pjmlp 6 hours agorootparentprevOnly if you mean K&R C, where C was mostly a portable macro assembler, calling into Assembly code, written and compiled via an external assembler like in the first iteractions of the UNIX rewrite from Assembly into C. The Lions book is a good example of what that C used to be like. reply foldr 10 hours agoparentprev>But that place is where 99% of programmers never work, because they are not doing kernel development Certain embedded targets are also legitimate use cases for C. For example, I am currently working on a project using an 8051 microcontroller. Aside from using assembly – which obviously isn't safe either – there is no practical alternative to using C. Rust may be making inroads for 32-bit targets, but will likely never be able to target an 8051. reply flohofwoe 10 hours agoparentprev> The issue I have with this narcisstic fatigue (similar to the author's point I assume) is that there is no reflection when they fuck up a codebase. Forgive my bluntness, but do you even know any C programmers? The ones I know are not at all a homogenous group (there isn't even anything resembling a \"C community\" - and IMHO that's a good thing btw). > The best code is the code that is safe and easy to read. These two things are not really related. - Rust code is safe, but typically not easy to read - C code is unsafe, but typically easy to read ...as a counter example though, C++ code is unsafe, and typically not easy to read. Of course \"readability\" is entirely subjective too. Seasoned programmers are typically blind to the problems of their language of choice (and that includes C's sloppiness, and Rust's readability). Language beginners typically stumble over problems that experienced users of that language wouldn't even think of. > Code should be dumb and easily maintainable. Well, obviously, but see above, one programmers 'dumb and maintainable' is another programmers 'unmaintainable complicated mess'. IME it's harder to write code that's 'dumb and maintenable' in languages that nudge the programmers towards sugarcoating the program logic in high level abstractions than in \"simple\" languages like C, Go or Zig, because you don't just need to know the language, but also understand the high level abstractions the original author came up with (and which might have been a good fit at the start of the project, but not 3 years later when requirements have changed and the original programmers have long left for greener pastures). IME it's not 'narcissism' that makes programmers pick C, but the incredible flexibility of the language, combined with being quite predictable what code will be generated (yes, optimizer passes do complex things, but after a while you'll develop an intuition for what the compiler will do, verifiable via godbolt). Also for instance, look at the hoops other languages are willing to jump through just to get close - but never fully match - what's possible with simple text replacement in the C preprocessor (an incredible hot take, I know). reply xigoi 10 hours agorootparent> C code is unsafe, but typically easy to read Are you joking? reply flohofwoe 7 hours agorootparentAbsolutely not, modern C code (eg C99 or later) looks a lot different than C89. One problem is that the C stdlib is stuck in the C89 era, but at the same time most of the stdlib isn't all that important for writing C code). reply akoboldfrying 9 hours agoprevSome of the HN discussion about whether \"new projects in C should be allowed\" is moot: Fluent Bit was imported into git in 2015 [0] (a few months before Rust's first public release), and may be considerably older than that for all I know. I suppose incidents like this actually do give a reason to \"rewrite it in Rust\", when \"it\" is \"widely deployed infrastructure written in C\". OTOH, I'm sure there were plenty of non-memory-safety bugs introduced and later fixed over the years, and rewriting in Rust will recapitulate that subset of bugs. [0] https://github.com/fluent/fluent-bit/commit/49269c5ec3c74411... reply nullc 6 hours agoparentPeople slipping backdoors into stuff are no doubt super enthusiastic about Rust both for the opportunity for new anonymous nobodies to rewrite long stable and proven tools as well as the dependency ecosystem that tends to blindly pull in multiple different entire HTTPS/TLS stacks into anything but the most trivial software. reply tialaramex 3 hours agorootparentI don't buy it. Rust has a really good track record on attracting more people to read and modify the code, which isn't what you want if you're hiding backdoors in the code. In decades of writing C (sometimes as a hobby, often for a lot of money) I'd guess I thought \"These errors when I wrote bugs in my program are crap, somebody should fix it\" maybe once per month on average. But a C compiler is very intimidating code, subtle and hard to even build from scratch let alone contribute to, so I never attempted to make such changes. In only a few years of writing Rust (none of that paid) exactly twice I've thought \"Man this compiler error diagnostic isn't very good, somebody should fix it\". The first time I asked on Reddit, and I was informed that I wasn't the first to notice, the fixed diagnostic was in nightly Rust already. The second time I found the diagnostic and I just fixed it, compiled first time, wrote a new unit test, checked that passed, wrote a pull request. Landed it. Then I wrote a HN comment, a reader found a bug in my diagnostic, so I fixed the original code, and wrote a new PR which also landed. If Rust has told you that instead of 'X' when you needed a byte, you should write b'X' because just 'X' is a char not a byte - that's me, that's my small fix. [Before the fix 'X' wasn't legal here, of course, but the diagnostic wouldn't suggest what to write instead] reply nullc 1 hour agorootparentI'm not sure how modifying the compiler is relevant to the point. I think it's the general trend that early in languages lives its much easier to contribute to the tools, after decades of amassing improvements (such as yours!) they tend to become less accessible. But regardless, the \"rewrite in rust\" advocacy has created a significant opportunity for projects created by single people, without outside review and often without significant domain expertise (at least where they are slavish re-implementations of existing code), to be proposed as replacements for longstanding stable tools. Whatever the merits of that chance it's also dream for someone looking to introduce new vulnerabilities. Even where the replacement itself is reviewed it will usually come with a massively expanded dependency footprint which isn't. reply diego_sandoval 10 hours agoprevI thought it was going to be about JS and npm, given some of their fiascos [1][2][3] [1] https://qz.com/646467/how-one-programmer-broke-the-internet-... [2] https://www.bleepingcomputer.com/news/security/dev-corrupts-... [3] https://www.sonatype.com/blog/everything-matters-why-the-npm... reply minikomi 10 hours agoparent`this` was mostly prevented in JS with the introduction of arrow function expressions reply alternatex 10 hours agorootparentI had someone on Reddit r/webdev try to convince me that 'this' was not a mistake but a powerful language feature. A small glimpse into the mind of JS fans. reply orf 10 hours agorootparentIt kinda is a powerful language feature But with great power comes great responsibility, and that doesn’t mean it was a good idea in hindsight. reply _old_dude_ 9 hours agorootparentYes, it's functions vs methods. You can make this explicit like in Python, you can make it implicit but have two kinds of methods, instance methods and static methods like in C++/C#/Java. And you have JavaScript were all functions have an implicit this ... reply pjc50 9 hours agorootparentprevIf it didn't exist, people would come up with weird hacks to implement the few cases where you do need it. But those are rare. reply consp 10 hours agoprevOh no ... a bug in a C program. This easy bashing on existing C programs is getting boring and annoying. Write a new userspace program? Use anything else, all language shave flaws so pick one which supports the features you need. Want to quickly write something because you are not allowed to rewrite the entire ecosystem you need into a new language since the project will go massively over budged: Use what you can and what's available and accept the risks, which is the 99th percentile of software. reply nubinetwork 9 hours agoprev> a vulnerability in HTTP parsing code that allows for heap corruption and arbitrary code execution by making a HTTP GET request with a megabyte of the letter 'A' in its body You mean a buffer overflow? Why write so technical then dumb down something that's pretty obvious. reply SSLy 9 hours agoparentbuffers are stored on heap. reply davedx 11 hours agoprevThoughts and prayers reply subjectsigma 6 hours agoprevI bet this person felt really smart posting about this problem that surely nobody has ever thought of before reply web007 22 minutes agoparentA) \"surely nobody has ever thought of [this] before]\" says person who hasn't read https://xeiaso.net/shitposts/no-way-to-prevent-this/ B) It's a spin on The Onion headline about school shootings. reply subjectsigma 10 minutes agorootparentA) I know, it still sounds smug and condescending B) I know, it still sounds smug and condescending reply Simon_O_Rourke 10 hours agoprevPrince Marcel O'Keefe must be C royalty! reply KaiserPro 11 hours agoprevNeeds more furries. reply blueflow 11 hours agoparentYeah, was about to note that the link is unexpectedly SFW. reply darkwater 10 hours agorootparentWhy? Furries are NSFW because they look cartoonish and \"unprofessional\"? I don't like them but what a boring workplace would that be. reply xena 10 hours agorootparentThey're being satirical. People usually berate my posts because I have cartoon characters for Socratic exchanges to teach people things like Kubernetes, claiming that is \"unprofessional\" or something. These people are sarcastically berating my post for NOT using that Socratic system. reply darkwater 10 hours agorootparentIMO GGP wasn't being sarcastic, but GP maybe was. Anyway I keep my thought: if a workplace, especially if in Tech or Tech-adjacent, sees furries as NSFW, it's a very boring workplace and I would run away from it at the first possibility. reply blueflow 10 hours agorootparentprevNo I'm not. I expected that there is some furry or anime girl visible when i click on that link. This is the stuff i do not want to have on my screen when there are coworkers nearby. reply xena 10 hours agorootparentHave this: https://xeiaso.net/notes/2024/ai-hype/ reply j-krieger 7 hours agorootparentI also used to think I had this issue when reading your blogs at work. Turns out, nobody really cares and if they do, a quick explanation suffices entirely. I no longer care as well. Your imagery is part of who you are as a writer, and it's part of your work. People need to take it or leave it. reply blueflow 10 hours agorootparentprevBismuth crystals are less edgy. reply llm_trw 10 hours agorootparentprevIt's gross because I don't want to think about your sex life when at work, but I guess this type of exhibitionism is fine. reply Zecc 9 hours agorootparentWhy did you jump from 'cartoon characters having Socratic conversations' to 'sex life'? Good grief. reply llm_trw 9 hours agorootparentBecause those cartoon characters always look like the fursuits of the person writing the article. reply subjectsigma 6 hours agorootparentprevBeing a furry is and always has been a sex thing for the majority of the fandom. Some furries will vehemently deny this but we have receipts going all the way back to the 1970’s: https://en.wikifur.com/wiki/Vootie Anime is not inherently sexual as a medium but has a well-deserved reputation for being associated with creeps and perverts. Don’t talk about either in professional settings. reply mjevans 12 hours agoprev [–] The headline is misleadingly focusing on a soundbite out of the full quote. \"It's a shame, but what can we do? There really isn't anything we can do to prevent memory safety vulnerabilities from happening if the programmer doesn't want to write their code in a robust manner.\" -- Some (uncredited?) C programmer. Does C have more footguns as a low level language? Of course. That's part of the freedom of bringing only the baggage a project needs. Sadly, like many dangerous or sharp tools, incorrect use will lead to harms. If someone has a choice, a safer more modern language can accommodate less skilled practitioners. reply tialaramex 11 hours agoparentIt's a deliberate echo of the famous Onion headline about America's absolutely disgraceful pretence that it couldn't do anything about all the shootings. https://en.wikipedia.org/wiki/%27No_Way_to_Prevent_This,%27_... > If someone has a choice, a safer more modern language can accommodate less skilled practitioners. This is the usual mistake. It's not a \"skill issue\". Footguns are a design mistake, they're much more dangerous than necessary hence the name. As a result the practitioners accomodated by a better language are all those capable of mistake ie all humans. reply pjc50 10 hours agorootparentRather like the school shooting issue, the C issue is bound up with people at the identity level; they insist on the danger because they cannot stand the possibility of the danger being taken away from them. Their ability to use guns or C safely must not be questioned. They percieve it as an insult to take that choice away from them. They are the safe C programmer that never ships a CVE. They know that they themselves would never shoot up a school, so what the problem? Oh it's bad people. Well, that's happening somewhere else to other people, so it's fine and they can carry on. (edit: someone was helpful to provide an example in this thread; https://news.ycombinator.com/item?id=40438716 ) reply jimwhite42 10 hours agorootparentHere's an attempt to explaining the irrational part of programmers deciding which programming language to use. Part of it goes into more detail on ideas like C programmers insisting 'on the danger because they cannot stand the possibility of the danger being taken away from them'. \"The Pervert's Guide to Computer Programming Languages\" https://www.youtube.com/watch?v=mZyvIHYn2zk It's pretty out there, but I thought also interesting. reply pdimitar 8 hours agorootparentprevCongratulations, you just landed in my very small number of favorite comments. reply highcountess 10 hours agorootparentprevOne can in fact not do anything about something for which one refuse to even consider the root causes of. In the case of shootings, one must talk about what may have caused shootings to start noticeably increasing in around the 1970s, to the point where a single year started having as many shootings as all the shootings prior to the 20th century combined. Fun fact; the first documented school shooting was perpetrated by some Lenape indigenous people, in Pennsylvania in 1764, during which attack they also beat to death all of the students and scalped everyone. reply pjc50 9 hours agorootparent> Fun fact; the first documented school shooting was perpetrated by some Lenape indigenous people, in Pennsylvania in 1764, during which attack they also beat to death all of the students and scalped everyone That would probably count under modern definitions of \"terrorism\". I would also say that most school shootings should also be counted as \"terrorism\", except there's a very strong ideological push to not look at them this way. Don't look at the radicalisation. Don't read the (suspiciously similar) manifestoes. Don't look at who they cite for inspiration. reply ben_w 10 hours agorootparentprevIf you're going to go back there far, before it was independent, I bet there was something documented in medieval Oxford or Cambridge involving a longbow and/or an anelas. reply tialaramex 10 hours agorootparentprev[Also writing \"skill issue\" caused me to immediately think of Gill Issue, the Grand Poo World 3 course with a name that's a pun on skill issue, so for anybody else whose brain works the same way, here's somebody competent beating Gill Issue: https://www.youtube.com/shorts/I6PdLgUGHaw ] reply l33t7332273 10 hours agoparentprev>If someone has a choice, a safer more modern language can accommodate less skilled practitioners The implication here is thoroughly debunked. We’ve seen over and over again that memory safety bugs will happen in every C codebase(ignoring toy or small codebases). Even for the mythical and infallible “skilled practitioner” spending time re-solving the solved issues inherent to C just isn’t a good use of developer time. reply voidUpdate 11 hours agoparentprevhttps://en.wikipedia.org/wiki/%27No_Way_to_Prevent_This,%27_... reply ChrisMarshallNY 9 hours agoparentprev> a safer more modern language can accommodate less skilled practitioners. That’s really what it’s all about. SV is absolutely obsessed with hiring bad programmers, treating them like crap, so they don’t stick around, and somehow, magically, forcing them to write good code. We have this belief that if we just use the “right” tool (in this case, a particular programming language), all of our products will be good. Couple that, with the belief that we should be able to build our stuff on someone else’s code, for free, and you have a recipe for disaster. People like Linus Torvalds are living proof that it is quite possible to write amazing stuff, in old languages (he is a C guy), but people like that, are rare as hen’s teeth, and may be difficult for today’s tech managers to handle. There really is no substitute for running a good shop, hiring good people, training them well, treating them well, paying them well, and keeping them around for significant lengths of time. Also, we need to be able to hold ourselves accountable for the Quality of our own work -regardless of the tools we use. Torvalds is notorious for being a tough taskmaster, because he’s serious about the Quality of his work, and casts that onto others. “Treating people well” does not mean using kid gloves. It can mean expecting people to act like grown-ups, produce grown-up work, and not accepting less. I worked in an environment like that for decades. It was often quite stressful, but was also personally rewarding. It isn’t the tools that are broken; it’s the management culture, and no one wants to fix that. reply xena 11 hours agoparentprevI have a longer nuanced post to write out at some point about my feelings here, but here's the cliff's notes: We should not be developing new projects in C, and we should make it politically hard to make new projects written in C in distribution repositories. C is going to stay around for a long time and that's okay, but there are so many inherent problems of its design and implementation that make it unsuited for unsupervised use. I wish that we didn't have to make such hard-line stances about this, but people have continuously proven that this tool is unsuitable for modern development and it's only going to get worse as time goes on. reply maeln 10 hours agorootparent> We should not be developing new projects in C I would give at least embedded development a pass, since you rarely do have a choice there reply pjc50 10 hours agorootparentIt's difficult, because \"embedded not networked\" is an environment where security risks are low, but \"embedded networked\" is a really nasty environment of haunted routers and abandoned IoT devices. Is it acceptable to risk buffer overruns on the HTTP server running on an insulin pump? reply p_l 10 hours agorootparentprevMostly because you often get shipped half-broken pile of C-based SDK as your blessed environment. Not because there's no other options (and long before Rust had its name coined) reply xena 10 hours agorootparentprevWell, yes. I'm more focusing on user space applications here. This is why that nuance post would have to be so long. People here would probably misconstrue it to be that I want to \"kill C\" though. That's part of the reason why I haven't written it yet lol reply j-krieger 7 hours agorootparentprevI agree. I regularly use Rust on embedded devices and what many advocates like to leave out is that you're just using regular old C under the hood anyway. It's bindings all the way down. reply immibis 10 hours agorootparentprevIf your distribution refuses to package useful free software, I'll use another distribution. I think this is true for most people. reply WesolyKubeczek 10 hours agorootparentprevnext [6 more] [flagged] pjc50 10 hours agorootparentFine, but there's no reason you should be allowed to ship C in devices which have safety critical consequences to the public, including unnecessary risk of data security breaches through allowing buffer overruns. You can write in a nice safe sandbox over there. (maybe this will eventually be part of the UL/CE requirements, \"contains no C code\") reply WesolyKubeczek 8 hours agorootparentC and C++ have another brand of safety \"safe\" languages du jour don't have: it's an ISO standard. Granted, it's not a very good standard, but the upside is that everyone and their dog has a C compiler for every new architecture, and I bet C++ too. You are not, strictly speaking, beholden to any single compiler implementation out there, they all have their idiosyncrasies, but C won't disappear overnight. It's more even than having a single foundation oversee it. C and C++ are largely immune to, say, a foundation dissolving because one day it turns out its members cannot comport themselves as responsible adults and a big enough drama ensues. The fact that C and C++ have no singular \"community\" to speak of is a very strong side. So when there are at least two (or better three) fully independent implementations of your C alternative, we'll talk about gatekeeping C. Now, if you are a vendor and capital owner, nothing forbids you from forbidding C within your company and devices you produce. That has been your prerogative since forever, predicated on your ability to afford it. I'm more wound up about activists and evangelists trying to impose their hobby horse upon others. You do you. Show, don't tell. reply Xeamek 10 hours agorootparentprevThat's not how society progress. At some point you just disallow horses to go onto the high-speed road, and aren't waiting for literally every last farmer to sell their horse over a car. reply WesolyKubeczek 8 hours agorootparentHigh-speed roads are a low percentage of all roads. reply xena 10 hours agorootparentprevThank you for demonstrating why I haven't written that longer post yet. I'd just be torn apart and berated for bothering to express nuance. reply benjaminl 11 hours agoparentprevThe story is satire. But the satire is illustrating true problems and attitudes. reply croes 11 hours agoparentprevA safer language accommodates every programmer. Nobody writes flawless code. reply danuker 11 hours agoparentprev> only the baggage a project needs What projects need manual memory management? Those where the hardware costs are comparable to development/maintenance costs. That is much rarer than people think. RAM is cheap, and few applications really need bespoke allocation. And it's not just a question of skill; even the most disciplined make mistakes. It's one of how much brainpower you want to allocate to... memory allocation. reply Xeamek 10 hours agorootparent>What projects need manual memory management Games. Big/specialiased games to be precise, as for smaller projects managed language offer good enough performance. reply p_l 9 hours agorootparentIn practice I found C/C++ \"manual memory management\" fans to know surprisingly little about memory management, or even how much manual memory management costs them in performance. High end games programming sometimes knocks the love of malloc()/free() (and naive RAII) out of them. reply superb_dev 11 hours agoparentprevWhat’s missing from Rust? I don’t care if you use C, but don’t pretend like there isn’t another option reply JonChesterfield 11 hours agorootparentSimplicity. reply marcyb5st 10 hours agorootparentWith all the language features I agree. However, if you reduce the language surface it is possible to have something safe and simple enough (IMHO). For instance, you can say no async, no custom traits and only {Debug, Display, Eq, PartialEq, ...} are allowed for your structs and generics. From limited personal experience that takes away more than half of the complexity of navigating rust code. reply jstimpfle 10 hours agorootparentThe more you take away, the closer you are to a simple but unsafe language. If you remove the \"unsafe\" keyword, many things you can't solve easily nor optimally. You might be able to outsource some complexity to external libraries, but integrating libraries is itself a major headache, and it can lead to security issues too. reply superb_dev 57 minutes agorootparentUnsafe is a daunting language feature, but ultimately it’s a feature. You’re meant to use it if you need it. You don’t need to outsource complexity anywhere. Rust is fully capable. reply marcyb5st 9 hours agorootparentprevFair enough. But unsafe for kernel code I guess it's a necessary evil (that's why I didn't mention it). However, I believe the being \"opt-in\" by explicitly marking sections unsafe is the way to go instead of having unsafe by default (which is the only way using C). reply relistan 11 hours agorootparentprevThis. Learning Rust is like a long series of jousting matches with the compiler. reply cornholio 10 hours agorootparentIt's more than that. Even after you learn it, you will struggle a lot with productivity, especially fast iteration and incremental changes and fixes, as Rust forces you to redesign and refactor your code. reply jiggawatts 10 hours agorootparentprevThe alternative is jousting with attackers. In production. When you're not aware of it. You're not even on the field, let alone mounted on your horse and wearing armour. reply yetihehe 11 hours agorootparentprevSimpleFastSafe. Choose two. reply jamesdhutton 9 hours agorootparentExactly this. It's all about trade-offs. You need to pick the right tool for the job. Sometimes the right tool is dangerous. Knives are dangerous tools, but you need them if you want to cook a meal. reply yetihehe 9 hours agorootparentI love one comparison to hole hawg[0] (used for unix vs windows&mac), which is usable here. Memory safe languages are like a fancy electric drill from target. They get the job done, but if you want some more serious drilling they die on you instead of doing something dangerous. C is like one of those drills which are comprised of engine and a handle (cheap, changeable piece of steel pipe). They are designed to do one thing: they rotate a drill. When drill blocks, they rotate you. But when you take appropriate precautions, boy do it drills... This is from my favourite book: In the beginning was the command line. [0] https://web.stanford.edu/class/cs81n/command.txt , search \"HOLE HAWG\". reply superb_dev 59 minutes agorootparentSo what are you able to do with C that you can’t do in Rust? Somethings are more difficult to pull off, but everything possible in C is possible in Rust. Worst comes to worst you can always drop into unsafe Rust This “sometimes you need a knife argument just doesn’t make sense. You can have the power and the safety. Stop cutting off your fingers. reply izacus 10 hours agorootparentprevPeople overwhelmingly chose Simple and Fast. Still. reply superb_dev 11 hours agorootparentprevWell computing has gotten a lot more complex since c’s inception. It’s model has held up well but the cracks are there reply JonChesterfield 10 hours agorootparentPrograms are a lot more complex. The computers aren't. They were far less homogenous in the early years. Today you have a octet addressed little endian integer machine, with ieee float hardware and a small vector unit. Maybe you have two different instances of that on the same address space, but probably just one. I think reasonable argument could be made that the complexity in modern computing is primarily self inflicted by software engineers. reply superb_dev 1 hour agorootparentComputers have gotten much more complex. Maybe your OS provides that nice little bubble for you, but it’s an illusion reply tialaramex 10 hours agorootparentprevThis isn't a crazy thought to have about K&R C. They're trying to fit a high level language onto a 1970s computer and so sacrifices must be made. Some of the trades they make are... questionable and others I'd say clearly wrong (they just don't need Tony's billion dollar mistake, nor to be so cavalier with types in general), but it's not as though they're targeting a machine with gigabytes of RAM and a multi-core CPU. But, people aren't writing K&R C. These days most of them are writing something closer to C99 or C11 and some may be using something newer (e.g. C17) or proprietary (GNU's C dialect) either deliberately or just because it compiled and nobody told them not to. At that point you've actually given away much of the simplicity, and yet what you get for your trouble is largely more footguns. Trade up for a sound type system and fewer footguns instead. reply JonChesterfield 9 hours agorootparentISO C comes with a list of constructs that the language is entitled to silently miscompile. Varying from \"those bytes can't be an integer, I'll delete that function for you\" through \"signed integers can't overflow, so that overflow check you wrote must return false, so I'll delete it for you\". This makes simple application code slightly faster. That's kind of a reasonable domain for C++ but on dubious ground for C. Where C is superb is talking to hardware and language implementation, exactly the areas the ISO group has chosen to cripple the language for. Thankfully compilers know about this and provide fno-strict-aliasing et al. Maybe there should be a std= style flag to change to the language subset that doesn't actively try to miscompile your program chasing benchmark numbers. reply jstimpfle 10 hours agorootparentprevWhat things simplicity do you lose? I think there isn't much of a difference between these dialects. Most important one might be possibility to define variables on the spot instead of at top of block. Then, some people like C99 compound literals. I don't think any of these break simplicity, they are quality-of-life improvements with no interactions with the rest of the language semantics. Next one is what, the C11 memory model? Doesn't take away any simplicity, just defines things better. reply tialaramex 6 hours agorootparentHere's my thinking. It's fair to say C99 isn't that much more complicated than C89, which formalizes various things that are a bad idea such as \"volatile\", as well as numerous good ideas like hey we should let you define a variable where you use the variable - however C99 adds more of the bad like \"restrict\". In both those cases the K&R C model was very simple. You could decide you love how simple this model is, and when smarter compilers optimise it into a pretzel or other languages are faster that's OK. This code used to drive the serial port, now it does nothing, OK, don't use C to write such drivers. This code used to go real fast, now everybody else is faster, OK, don't use C if you need the best performance. C89 and C99 choose different, making the language more complicated to keep addressing performance and compatibility. In C99 I can write the fast serial port driver, but it's significantly more complicated as a result. The beginner will definitely get it wrong and explaining why is pretty subtle. Then C11 says actually you're not writing sequential programs, which was a crucial simplification in K&R C - the programs you can write do one thing at a time, in order, and then maybe stop. The memory model in C11 is needed because it says actually your programs might do more or different things at once. Now, in reality by 2011 lots of people were writing C that's not actually sequential - after all SMP Linux long pre-dates C11. But those weren't legal C programs, they're GNU's dialect and so all bets are off. Nobody is claiming Linux is simple. So C11 definitely isn't the simple language fo",
    "originSummary": [
      "A vulnerability (CVE-2024-4323) in the Fluent Bit project has led to urgent patching efforts by site reliability engineers and systems administrators.",
      "The flaw, originating from HTTP parsing code in C, permits heap corruption and arbitrary code execution through a specific HTTP GET request.",
      "This incident underscores the persistent issue of memory safety vulnerabilities in C, which has been responsible for 90% of such problems over the past 50 years, despite the importance of robust coding practices."
    ],
    "commentSummary": [
      "The discussion critiques U.S. school shootings and ineffective responses, using a satirical format to address buffer overflows in C programming, and compares U.S. gun regulation with other countries, highlighting NRA influence and public support for universal background checks.",
      "It contrasts U.S. and Swiss gun laws, critiques C/C++ in favor of modern languages like Rust and Golang, and discusses programming paradigms, emphasizing Rust's memory safety and community dynamics.",
      "The conversation critiques the tech industry's focus on tools over skilled developers and good management, emphasizing the need for clear, maintainable code and the challenges of transitioning from C to safer languages like Rust."
    ],
    "points": 193,
    "commentCount": 273,
    "retryCount": 0,
    "time": 1716352571
  },
  {
    "id": 40440854,
    "title": "Bill Gates Endorses Sal Khan's Vision of AI-Driven Education in \"Brave New Words\"",
    "originLink": "https://www.gatesnotes.com/Brave-New-Words",
    "originBody": "Sal Khan is pioneering innovation in education…again LOG IN SIGN UP LOG IN SIGN UP AHEAD OF THE CURVE Sal Khan is pioneering innovation in education…again Brave New Words paints an inspiring picture of AI in the classroom. By Bill Gates| May 21, 2024 0 When GPT-4o launched last week, people across the internet (and the world) were blown away. Talking to AI has always felt a bit surreal—but OpenAI’s latest model feels like talking to a real person. You can actually speak to it, and have it talk back to you, without lags. It’s as lifelike as any AI we’ve seen so far, and the use cases are limitless. One of the first that came to my mind was how big a game-changer it will be in the classroom. Imagine every student having a personal tutor powered by this technology. I recently read a terrific book on this topic called Brave New Words. It’s written by my friend (and podcast guest) Sal Khan, a longtime pioneer of innovation in education. Back in 2006, Sal founded Khan Academy to share the tutoring content he’d created for younger family members with a wider audience. Since then, his online educational platform has helped teach over 150 million people worldwide—including me and my kids. Well before this recent AI boom, I considered him a visionary. When I learned he was writing this book, I couldn’t wait to read it. Like I expected, Brave New Words is a masterclass. Chapter by chapter, Sal takes readers through his predictions—some have already come true since the book was written—for AI’s many applications in education. His main argument: AI will radically improve both student outcomes and teacher experiences, and help usher in a future where everyone has access to a world-class education. You might be skeptical, especially if you—like me—have been following the EdTech movement for a while. For decades, exciting technologies and innovations have made headlines, accompanied by similarly bold promises to revolutionize learning and teaching as we know it—only to make a marginal impact in the classroom. But drawing on his experience creating Khanmigo, an AI-powered tutor, Sal makes a compelling case that AI-powered technologies will be different. That’s because we finally have a way to give every student the kind of personalized learning, support, and guidance that’s historically been out of reach for most kids in most classrooms. As Sal puts it, “Getting every student a dedicated on-call human tutor is cost prohibitive.” AI tutors, on the other hand, aren’t. Picture this: You're a seventh-grade student who struggles to keep up in math. But now, you have an AI tutor like the one Sal describes by your side. As you work through a challenging set of fraction problems, it won’t just give you the answer—it breaks each problem down into digestible steps. When you get stuck, it gives you easy-to-understand explanations and a gentle nudge in the right direction. When you finally get the answer, it generates targeted practice questions that help build your understanding and confidence. And with the help of an AI tutor, the past comes to life in remarkable ways. While learning about Abraham Lincoln’s leadership during the Civil War, you can have a “conversation” with the 16th president himself. (As Sal demonstrates in the book, conversations with one of my favorite literary figures, Jay Gatsby, are also an option.) When the time comes to write your essay, don’t worry about the dreaded blank page. Instead, your AI tutor asks you thought-starters to help brainstorm. You get feedback on your outline in seconds, with tips to improve the logic or areas where you need more research. As you draft, the tutor evaluates your writing in real-time—almost impossible without this technology—and shows where you might clarify your ideas, provide more evidence, or address a counterargument. Before you submit, it gives detailed suggestions to refine your language and sharpen your points. Is this cheating? It’s a complicated question, and there’s no one-size-fits-all answer. Sal notes that bouncing ideas off friends, asking family members to critique work, and using spellcheckers and tools like Grammarly—which can rephrase entire sentences—aren’t considered cheating today by most measures. Similarly, when used right, AI doesn’t work for students but with them to move something forward that they might otherwise get stuck on. That’s why, according to Sal, a lot of educators who first banned AI from class are now encouraging students to use it. After all, mastery of AI won’t just be nice to have in a few years—for many professions, it’ll be necessary. Employees who can use AI effectively will be far more valuable than those who can’t. By incorporating this technology into education, we're both improving students’ experiences and outcomes and preparing them for the jobs of the future—which will become more enjoyable and fulfilling with AI in the mix. That includes teaching. With every transformative innovation, there are fears of machines taking jobs. But when it comes to education, I agree with Sal: AI tools and tutors never can and never should replace teachers. What AI can do, though, is support and empower them. Until now, most EdTech solutions, as great as they may be, haven’t meaningfully made teachers’ lives easier. But with AI, they can have a superhuman teaching assistant to handle routine tasks like lesson planning and grading—which take up almost half of a typical teacher's day. In seconds, an AI assistant can grade spelling tests or create a lesson plan connecting the Industrial Revolution to current events. It can even monitor each student's progress and give teachers instant feedback, allowing for a new era of personalized learning. With AI assistants handling the mundane stuff, teachers can focus on what they do best: inspiring students, building relationships, and making sure everyone feels seen and supported—especially kids who need a little extra help. Of course, there are challenges involved in bringing AI into schools at scale, and Sal is candid about them. We need systems that protect student privacy and mitigate biases. And there’s still a lot to do so that every kid has access to the devices and connectivity they need to use AI in the first place. No technology is a silver bullet for education. But I believe AI can be a game-changer and great equalizer in the classroom, the workforce, and beyond. I recently visited First Avenue School in Newark, New Jersey, where Khanmigo is currently being piloted. We’re still in the early days, but it was amazing to see firsthand how AI can be used in the classroom—and to speak with students and teachers who are already reaping the benefits. It felt like catching a glimpse of the future. No one understands where education is headed better than Sal Khan, and I can't recommend Brave New Words enough. READ THIS NEXT 5 great things to read or watch this summer I found an unintentional theme connecting them all. The head of TED has his own ideas worth spreading Infectious Generosity is a timely, inspiring read about philanthropy in the digital age. The Women gave me a new perspective on the Vietnam War Kristin Hannah’s wildly popular novel about an army nurse is eye-opening and inspiring. Discussion Thank you for being part of the Gates Notes Insider community. Not seeing your comment? You can read our policy on moderating comments here and learn about our Gates Notes badges here. Add comment Please log in or sign up to comment 0 responses Sort by all Comments loading... More comments About Bill Search Personal Podcast Photo essays Books Education Videos Saving lives Climate and energy Pandemic prevention Inequality, gender, and race Subscribe to emails from Bill Sign up © 2024 The Gates Notes LLC Privacy Policy Terms of Use Contact",
    "commentLink": "https://news.ycombinator.com/item?id=40440854",
    "commentBody": "Sal Khan is pioneering innovation in education again (gatesnotes.com)190 points by Brajeshwar 5 hours agohidepastfavorite224 comments 7thpower 4 hours agoI am a high school dropout and who learned math using Khan Academy after never having completed more than pre-algebra in middle school. Sal Khan’s work changed my life and allowed me to build a foundation in not only math, but also finance and economics, that allowed me to feel confident enough to go to college. I did not have a support system or people in my life who could teach me these things, but I had the internet and patience, which meant I had opportunities that did not exist even a few years before (this was in 2014). Now I work in AI and generally have a life I could not have dreamed of. Every time I go to the grocery store to buy something and don’t have to worry about my card being declined, it feels like magic. Even years later. If I had been in that situation a few years earlier, my life would be very different. I’m excited to live in a world where my daughters and countless others will have a tutor that can help them maximize their potential throughout their lives. I’m excited not only for them, but for society. What a time to be alive. reply siamese_puff 3 minutes agoparentThat’s pretty impressive. Any chance you can shed light on the feasibility of this for a standard high school dropout? Did you have certain luxuries from family or otherwise that made this possible? I’m mostly asking to learn how the US system (assuming you’re in the US) supports folks taking this path. reply piker 4 hours agoparentprev> Every time I go to the grocery store to buy something and don’t have to worry about my card being declined, it feels like magic. Even years later. So this is universal! reply tptacek 2 hours agorootparentI'm almost 30 years from anything resembling precarity and I still subtly cross myself almost every time I swipe a card at the grocery store. reply fragmede 21 minutes agorootparentthe real question is how many backups do your carry in case the first one doesn't work, and I'm not asking about credit card point games reply barrenko 33 minutes agorootparentprevJust did this a minute ago! reply jjice 2 hours agoparentprevKhan Academy is a treasure of a service. Probably my favorite non-profit out there. High quality information with low barrier to entry. It got me through Calculus, Calc 2, and Linear Algebra. reply meetingthrower 2 hours agoparentprevLove to see this - a miracle! We used it to partially homeschool a kid in math, then he graduated to SAT prep for himself, etc. Totally free. What a gift to the world. reply doctoboggan 3 hours agoparentprevImpressive! You should give yourself more credit as it takes more than just internet and patience to teach yourself enough to get into college. I am also excited for society. However I am worried as well. While an AI tutor who is able to understand the child's current knowledge and gear the lessons toward what will make the most sense will be very powerful, it could also be used for brainwashing, propaganda, misinformation, etc. While we've invented a better way to transfer knowledge, we haven't removed the human desire to control information. reply diddypiddy 3 hours agorootparentWe live in a world where wealth is increasingly being concentrated at the top, social mobility for the average person is trending downwards, suicide rates in the US are at all-time highs, drug abuse rising, general deaths of despair rising, mental illness rising, climate and ecological catastrophes mounting by unchecked greed and all of this AI crap is mostly in the hands of the powerful who will use it to solidify the trends of the things I've mentioned above. Which begs the question, what kind of society is this to be excited about? Great if you live in a bubble unaffected by the above, but for the rest of us, the society sucks. reply megaman821 3 hours agorootparentThe average person has a higher standard of living and more wealth than ever before. Suicide rates are not at all-time highs, they were much higher during the World Wars and Great Depression. Drug abuse is down too, but newer drugs are more potent. Mental illness is a hard stat to compare over time since it is very sensitive to the collection mechanisms. The growth of carbon-free technologies has been exponential over the last few decades. Open(source?) AI models trail the leading closed models by 6-12 months, it's hard to say they are only in the hands of the most powerful. The world is better than ever before, but it could be even better. The internet is filled with too many doomerist takes. reply delfinom 2 hours agorootparent> Suicide rates are not at all-time highs, they were much higher during the World Wars and Great Depression. Nah we already exceeded WW2. https://www.nbcnews.com/health/mental-health/cdc-data-finds-... > but available data suggests suicides are more common in the U.S. than at any time since the dawn of World War II. >U.S. suicides steadily rose from the early 2000s until 2018, when the national rate hit its highest level since 1941. I guess we still haven't exceeded the Great Depression rates but it's really not that hard of a target reply lolinder 1 hour agorootparentSuicide rates during WW1 were hovering around 20 per 100k. During the Great Depression it peaked at 22 per 100k [0]. That's around 50% higher than the 2022 number you cite (14.3 per 100k), which is hard to describe as \"really not that far off\". EDIT: The comment I replied to has been edited in multiple ways since I replied, so the text in quotes above is no longer present. The comment previously indicated that we had already exceeded \"the world wars\" (not just WW2) and that we were \"really not that far off\" from the rates of the Great Depression. Slight meta tangent: OP, in general it's considered good form to reply to people who reply to you rather than just modifying your comment. Calling out edits explicitly (like I've done here) after you've received replies is also considered good form. [0] https://www.usatoday.com/story/graphics/2023/11/29/2022-suic... reply balls187 2 hours agorootparentprevThat might be true outside the US; I believe that the standard of living has gone down in the US, due in large part to the pandemic, followed by rampant inflation. The shift away from manufacturing jobs to service jobs also played a role, along with the population boom in major cities. The cities/countries with the highest standards of living all seemingly exist in Europe. EDIT To Add: look at the revolting against McDonald's to see my point. Taking your family to mcdonalds used to be something you didn't really need to think about. Not anymore. reply lolinder 1 hour agorootparentThis kind of comparison always neglects to consider the fact that any given European country is much smaller and much more homogeneous than the US. Which US state are you comparing to? Using the Human Development Index (HDI) as a passable proxy for standard of living: Mississippi has an HDI of 0.866, about the same as Portugal and somewhat higher than Bulgaria (the lowest HDI in the EU) at 0.799. Massachusetts has an HDI of 0.949, which is about the same as Germany and only a tiny bit lower than #1 Switzerland's 0.967. In other words: both Europe and the US span a wide range of HDI scores, but the European Union has a wider range in both directions. Europe is both better and worse than the US, depending on where in Europe and where in the US you're talking about. https://en.wikipedia.org/wiki/List_of_countries_by_Human_Dev... https://en.wikipedia.org/wiki/List_of_U.S._states_and_territ... reply balls187 1 hour agorootparent> This kind of comparison always neglects to consider the fact that any given European country is much smaller and much more homogeneous than the US. Which US state are you comparing to? I'm aware of the criticism of Apples to Oranges. I assume given such a basic level of criticism on any comparison between the US and Europe that it's no longer remotely relevant because to any study ranking would clearly account for that. Oxford Economics just released their 1000 cities index, https://www.bloomberg.com/news/articles/2024-05-21/new-york-... The US dominated in the economic advantage, and europe dominated in the quality of life index. reply megaman821 1 hour agorootparentprevEurope also experienced a pandemic, has even worse inflation and worse unemployment. It could just be cultural attitudes make European cities a more pleasant place to live. reply balls187 1 hour agorootparent> It could just be cultural attitudes make European cities a more pleasant place to live. Cultural attitudes certainly, particularly around work vs leisure. Also mass transit systems, and social supports for people working in the service industry. The criticisms for europe are that it takes a lot of tax revenue to support those things, bureaucracy, strikes, etc. Im not saying one system is better than the other--just that in the US, despite our massive economic might, our standard of living sucks. reply kiba 51 minutes agorootparentMass transits and more pleasant places to live are probably correlated with more tax efficient policies. It's just that the USA has accumulated a number of unfair advantages. reply skrtskrt 2 hours agorootparentprevwhen you visit or live among people or parts of society that that essentially never \"modernized\" in any meaningful way, the only thing they really need is better healthcare. the rest is a load of crap that is just solving problems created by industrialization and modernization reply megaman821 2 hours agorootparentAre you talking about lost Amazon tribes? Most places I have visited people have seen real quality of life improvements by having clean water, refrigeration, sewage systems and access to the internet. reply szundi 1 hour agorootparentYeah yeah, but it’s so romantic that they use bamboo sticks for hunting and killing each other with poisoned arrows while dying of worm infections and shit reply kiba 53 minutes agorootparentprevA lot of that is just land use policies. When you look at the average American household budget, it makes sense. The #1 and #2 are housing and transportation followed by taxes. Climate change and ecological catastrophes, mental illness are really land use policies in disguise or at least can be explained partly. reply fullofideas 3 hours agorootparentprevI am not discounting what you said about wealth concentration and upward mobility, but the top post that started this thread is surely a counter example for what you are saying? Yes, the makers of openai/gemini/whatever could power such ai tutors, and make more money, but there are legit cases where this will be an enormous boost that was unthinkable just a few years ago. reply szundi 1 hour agorootparentprevWhat’s this? DC comics? Open source models will give a lot of people lots of chances. Period. Other things we’ll see, doomers were never quite right - so far reply renewiltord 1 hour agorootparentprevNah, we live in a great world where most people recognize that absolute life quality matters more than relative life quality. Online commenters all go to therapy and are miserable, and their bosses are idiots, and everyone is spying on them, and so on and so on. But most people are better off than their parents and knowing this, they’re generally happy. reply fragmede 18 minutes agorootparentprevthis is already an objection, that most of the LLMs are aligned to a certain kind of California thinking; Open AI, Anthropic, xAI, and Facebook, among others, being from there. reply insane_dreamer 1 hour agorootparentprev> While we've invented a better way to transfer knowledge, we haven't removed the human desire to control information. that is a huge problem; but it's not one solved by technology reply keybored 1 hour agoparentprev> Now I work in AI So it goes. reply sonabinu 4 hours agoparentprevA very powerful story! thanks for sharing reply tomjen3 1 hour agoparentprevHave you written that story to Khan academy? reply 7thpower 1 hour agorootparentI started to, but then never completed it. Typical dropout behavior ;) reply Pulcinella 4 hours agoprevBackground: I taught high school science for half a decade and now I am in tech. This will never take off. One, there is no money in Ed.Tech. There is no money in Ed.Tech. There is no money in Ed.Tech. What little money there is goes to the obvious stuff like student records databases. Anything that requires an ongoing subscription fee is dead in the water. The only reason those stupid smartboards took off is because they make school boards look cool, they are a one time cost, and can be paid for with bonds (because they are a one time cost). Teachers don't want them (projectors and document cameras are good, though). Ed.Tech is a wasteland of failed startups. Part of the problem is also that classic \"the people with the purchasing power are not the people who will be using the product\" problem. Two, everyone outside of education thinks \"well has anyone just tried sitting down with the kids and talking to them/explaining it to them?\" Yes, obviously. The problem isn't that they are lazy, snot-nosed kids (that's a problem well within an experienced teacher's skill set to solve). The problem is what is the AI going to do with the kid says \"fuck you\" to the AI because they haven't eaten since lunch the previous day (school is the only place they get regular meals), or they don't even know what to ask because they are basically 4 grades behind in math, or the wifi is dead for the 8th time that month because the school board will never pay for infrastructure. Three, what if the AI is just wrong and starts confusing the student? Even GPT-4 fabricates things all the time. Sure it can generally put words in grammatically correct order and is passible for writing no one is going to read anyway (like marketing emails). But the moment it requires actual domain knowledge all these AI models completely fall down because, again, they don't actually understand anything, they just are really good at guessing what word comes next. reply seidleroni 3 hours agoparentI understand the skepticism around AI in ed tech, and I think people have the right to be skeptical of this being portrayed as a \"cure all\". Saying that it is of no value because nobody will pay for it and the kids wont learn from it because they're hungry does not capture the whole picture. I was never a great student because I had trouble focusing in class, but if I had this to guide me through my homework, I believe I would have been a much better student. Looking at math homework and having no idea how to even start and no resources to help is very different than looking at the problem and working with AI to help you understand how to attack the problem. Sure, you can't turn every single kid into a math wiz, but I think there is a real possibility that this will help almost every kid become better at math than they would have. Assuming this is low cost, I think many parents would be very willing to pay for it. reply peppertree 25 minutes agorootparentIf you have ever worked with children you will realize vast majority of them lack the willpower to learn new things and seek out answers. A good teacher can provide the social accountability and guide them, but it's not something you can put on auto pilot with AI. reply babl-yc 3 hours agoparentprevThere may be \"no money in EdTech\" but that doesn't mean there can't be impactful products for it. Students don't want to pay for Google but every student still uses it. Some students will want to waste time if given access to more tools like AI agents, but the motivated ones will use it to their advantage. Even if it's wrong sometimes, it's right a lot, perfect for rubber ducking, and almost always gives answers that are at least interesting or point you in a useful direction. As for \"GPT-4\" fabricating things, I remember in school how I wrote essays and was given A's despite citing NYT and Wikipedia. Fabrications exist all over the place. If anything, hallucinations might give more examples as to how to be skeptical of any source and look for direct sources as much as possible. In college I went to office hours and there was 30 minute line to talk to the TAs. AI agents respond instantly. These things are going to overall transform education for the better. reply Pulcinella 3 hours agorootparentAs for \"GPT-4\" fabricating things, I remember in school how I wrote essays and was given A's despite citing NYT and Wikipedia. Fabrications exist all over the place. If anything, hallucinations might give more examples as to how to be skeptical of any source and look for direct sources as much as possible. \"Actually it's good that AI sucks because it will teach people to be more skeptical\" is not a very compelling argument. reply neuralnetes-COO 3 hours agorootparentThis is the purpose of LLMOps. To provide guardrails for precise output to prevent hallucination. reply nicce 3 hours agorootparentprev> As for \"GPT-4\" fabricating things, I remember in school how I wrote essays and was given A's despite citing NYT and Wikipedia. Fabrications exist all over the place. If anything, hallucinations might give more examples as to how to be skeptical of any source and look for direct sources as much as possible. At least you wrote it by yourself? Copy-paste from GPT-4 removes the whole thinking process and need for basic skills. It is extremely difficult to prove that someone just copied the text without doing any own work. If it is difficult to detect and punish, then certainly almost everyone will do that, if they get an advantage. What is the future of proving that I know something myself? reply friend_and_foe 1 hour agorootparentYou ask a very interesting question, that to me speaks to the future of education gets to the bottom of education entirely. Right now, education focuses on getting people through the system so they can attain a credential. It teaches us, primarily, how to get one over on the system, how to look for loopholes and shortcuts. It creates a culture of corruption, of looking for approval from institutions in order to move up in life. What does a world where anyone can learn anything they like for free very easily look like? Well undoubtedly it looks like a place where a lot of people don't learn much, because they have no interest in learning. But it also looks like a place where people who are interested in learning can and do learn endlessly if they like, the opportunity for anyone to get educated to a degree reserved for elites that most of us could only dream of even two decades ago is upon us. Writing the paper won't be about proving you wrote the paper to some authority figure, because it's no longer proof that you wrote it. Writing the paper will become about helping yourself understand something you want to understand. So to your question, what is the future of proving that I know something, the future is you can't prove you know something, there's nobody to prove it to and you know things because you want to know things, because you recognize the value on knowing them beyond \"this piece of paper qualifies me for a job.\" The future is the truth that we have been pretending isn't true for a century: that no matter what you try to do, those that want to learn will learn and those that don't won't, and their lives will be what they are on their own merit and of their own volition. If you want to call yourself educated, the only person you need to be proving that to is yourself. We have entered a world of information post scarcity, which necessarily comes with post scarcity of noise, distraction and disinformation. The competition to understand things and the benefit that comes with understanding things will get stiffer, but access to that competition will become egalitarian. There will be a great divide among people: those that follow the noise of the day and those that continue to learn freely of their own volition. reply insane_dreamer 1 hour agoparentprevI agree it's not a silver bullet doesn't begin to address the issue where students aren't learning because of issues they're dealing with outside of school. I see this as Khan Academy x10. It'll be a great tool for those for whom Khan Academy itself was a good tool. If it's free (or for a nominal free), then parents will use it at home with their kids as a supplement to school. Teachers might use it on a case by case basis with students who want to accelerate or who are behind. It will highly accelerate learning for those who want to and are able to learn. The problems you describe, which are very real and important, are social problems, not educational problems per se or problems solved with technology. reply raisedbyninjas 3 hours agoparentprevMaybe no school board buys and puts it into every class. Parents will still buy it and it can supplement learning gaps when doing homework. $20/month is a rounding error compared to pre-school, clothes, extra-curricular activies, private school, private tutors, etc. reply aeyes 3 hours agorootparentThe kids of people who can afford all you mentioned usually don't have problems with education. It's those who don't have $20. My parents spent almost nothing on my education, just a couple of $ per year to buy a notebook or two. I used the same pens for almost ten years. I participated in zero sports, had zero tutors... I did ok but I had peers with even less resources and not all of them did good. reply Kye 2 hours agorootparentFond memories of being mocked for wearing the same clothes I wore the previous year or two. Wait no, not fond. The clothes were fine: good condition, clean, etc. Just old from the perspective of kids who didn't understand they came from money or that their parents were bad with money and headed toward disaster. /u/raisedbyninjas was hopefully kinder than those kids even though it sounds like they were in the same cohort by how small $20/month sounds to them. reply danielmarkbruce 53 minutes agorootparentprevThe very people you are talking about that \"don't have problems\" are spending money and effort to get their kids to do even better, get into better schools etc. It's not some binary fine/not fine thing. They view it extremely differently to how you appear to be viewing it. reply Kye 21 minutes agorootparentPoint of view wont add $20/month to the budget that doesn't instantly go to other priorities like having enough food or replacing some clothes that are about to fall apart. reply insane_dreamer 59 minutes agorootparentprevGiven that Sal has never turned Khan Academy into a commercial product -- despite its resounding success and popularity, and the large amount of $$$ he could have made -- has proven he's not in this for the money. So I expect the AI version to also be free or at least have a free version for parents (and schools who can't afford it). reply ThinkingGuy 2 hours agorootparentprevMost likely scenario: school boards buy it, then use it to justify cutting the number of teachers. reply gnicholas 32 minutes agorootparentThey won’t actively cut teachers, they just won’t hire as many specialists. We have a couple math specialists who just do remedial math. Kids who are at grade level or above get zero attention during math time. This will be a cheap way to provide attention to those kids, at a fraction of the cost of hiring more math specialists or classroom teachers. reply mceoin 12 minutes agoparentprevhttps://news.ycombinator.com/item?id=8863 reply Kye 2 hours agoparentprev>> \"Three, what if the AI is just wrong and starts confusing the student? Even GPT-4 fabricates things all the time.\" It was bad enough when the text was wrong because of shoddy editing. reply neuralnetes-COO 2 hours agorootparentThis is the purpose of LLMOps. To provide guardrails for precise output to prevent hallucination. reply dotinvoke 1 hour agorootparentThis is the first I'm hearing of LLMOps, please elaborate a bit on what it entails. How does it provide guardrails? reply jasondigitized 47 minutes agoparentprevThere are obscene amounts of money in EdTedh. It lives in rich parents wallets. reply selykg 3 hours agoparentprevAs an IT and data analytics manager in ed tech, I agree, there is no money in ed tech. I make a customer support rep salary. It's ridiculous. reply danielmarkbruce 56 minutes agoparentprevThere is a small fortune spent on private education. After school classes, tutoring etc etc. The money is spent by the upper middle class and above. If this solution works better for some subset of those people, it will take off in that market. reply jasondigitized 45 minutes agorootparentThis. Well to do people do not blink when it comes to funding academic and athletic growth for their children. reply MR4D 2 hours agoparentprevA couple thoughts... First, clearly you had a crappy experience. And that sucks. There are probably many others with bad stories as well. I'm deeply involved with my kids education and can only imagine how much that sucked. Second, we can't solve everything at once. Hungry kids, bad parenting, all that will take time, and may never be resolved. I wish it could be, but honestly, it will take time - probably a long, long time. Third, he's building for the future. Richer schools (both private and public) will get this first, typical schools will get it next, and poor schools (both administratively poor and monetarily poor) will get it eventually. This is where that great quote applies - \"The future is here, it's just not evenly distributed\" - and boy will it apply to education. So much so that some parents will feel like they are left in the stone age by comparison. Fourth, an anecdote. I do volunteer work for an education-related non profit. I learned during covid that HISD (Houston school district) couldn't easily move to online learning because 30% of their students did not have internet access at home. Thirty percent!!! I was blown away. Still am. But it's gotten much better, and we've evolved. Does it still suck? Yes, undoubtedly (HISD was taken over by the state, if that tells you how big their problems are). So I know this will not be evenly distributed because of this experience. reply Myrmornis 3 hours agoparentprev> Sure it can generally put words in grammatically correct order and is passible for writing no one is going to read anyway (like marketing emails). But the moment it requires actual domain knowledge all these AI models completely fall down because, again, they don't actually understand anything, they just are really good at guessing what word comes next. Many of us are frequently using it to obtain answers requiring domain knowledge; the evidence that this works is that the answers it gives are often found to be correct, and yet things we did not know. So your description is simply contradicting the experience of many people. Perhaps you're using it in a different domain, or not writing clear prompts, but it's well worth experiencing what people are talking about. reply MajimasEyepatch 3 hours agorootparentI can ask ChatGPT to write code and assess myself whether it's correct or not. (It's frequently not, but it can still be useful for certain tasks.) I can ask it to explain something about the industry I work in or adjacent fields and have a pretty good sense of whether it's leading me in the right direction. But if I asked it to teach me about, say, Chinese history, I would have very little ability to assess whether it's telling me the truth or sprinkling little falsehoods into things. I would only be able to catch the most blatant mistakes; the rest would require more detailed independent research. Now imagine you're a kid who's still learning reading comprehension and hasn't yet developed a functional BS detector. You're not going to have much of an ability to separate truth from fiction, but you're likely going to trust this thing that sounds authoritative. reply welshwelsh 3 hours agorootparentWhile these are all valid concerns, they also apply to human teachers. Humans spew bullshit all the time. But that's OK. A teacher's knowledge doesn't need to be perfect, it just needs to be better than the student's. If ChatGPT explains Chinese history in a way that is 80% accurate, to a student whose understanding of Chinese history is 10% accurate, the student will walk away with a better understanding of Chinese history. reply camdenreslink 2 hours agorootparentThis seems very incorrect to me. Human teachers make mistakes, or understand details of something incorrectly sometimes, but it doesn't come up in every lesson. It only happens occasionally, and sometimes a student will correct them/challenge them on it. ChatGPT makes mistakes literally every time I use it (in a domain that I'm knowledgable in). How is that the same thing? Being given incorrect information is worse than not having the knowledge at all IMO. reply nopinsight 1 hour agorootparentDo you mean GPT-3.5 (free) or GPT-4 (paid)? Their performance and hallucination rates are very different. GPT-4o (the best current model) is now becoming available to free, registered users now. What do you think of it? Unless your domain is very specialized, I think GPT-4T, GPT-4o, and Claude 3 Opus for example are quite good. reply camdenreslink 47 minutes agorootparentI use GPT 4, and it still constantly invents things and presents them to me with authority. I haven’t tried GPT-4o yet. reply wrs 3 hours agorootparentprev“Fall down” doesn’t mean they’re always wrong. It means they’re right just often enough to make you believe them when they’re making stuff up, which is a terrible characteristic for a teacher. At this point, ChatGPT is good enough that I can tell what authoritative source I should go look at for the answer, which is great, but I’m not going to believe any statements it makes without checking. I think people suffer a bit of Gell-Mann amnesia when dealing with ChatGPT. I actually do get a lot of value from ChatGPT as a self-motivated learner with a specific goal in mind, but that’s not the scenario we’re talking about. reply tangjurine 3 hours agoparentprevIdk... My company is doing pretty well (ixl learning) reply hinkley 3 hours agorootparentI suspect there’s a difference between selling to school boards and selling to individual learners. I know college kids are using edtech, but they don’t like it much. And there was one-time purchasing during the quarantine. And obviously Khan academy must be doing okay. reply kody 3 hours agorootparentprevMy students LOVED IXL. I couldn't believe when I found out the kids kept using IXL after school and on weekends to compete with each other. reply tehalex 3 hours agoparentprevThere's some money but there's really two markets: small medium (eg a lot of work for a relatively small sale) and mega districts (and those generally just goes to the big established players because of connections) Most school wifi isn't that bad anymore - the bigger problem for us is web filters that break things in interesting ways. reply tripdout 3 hours agoparentprevYet Khan Academy is free. reply Jtsummers 3 hours agorootparentBut Khanmigo isn't, it's $4/month. reply pritambarhate 52 minutes agorootparentI think over the time GPUs will become cheap or some other break through will make running LLMs cheaper. Then this fee won't be required. reply bryanlarsen 3 hours agorootparentprevI'm willing to bet that it will be in the future. Maybe a free version that can run locally on Copilot+ level NPU's or GPU's, perhaps taking advantage of software & hardware cost reductions to get it down to a level that they can talk Gates into paying for it. reply lcnPylGDnU4H9OF 1 hour agorootparent> I'm willing to bet that [Khanmigo] will be [free] in the future. If anyone doubts this, just take a look at what Khan Academy currently offers for a fresh perspective. Make an account and click around (https://www.khanacademy.org/signup); it should be easy to see that a ton of effort went into making this and, as far as I can tell, they run purely on donations. I wouldn't be surprised if the current cost of operating Khanmigo is just being passed along by Khan Academy at no markup, or even a slight loss. reply nextworddev 3 hours agorootparentprevKhanmigo is free for teachers I believe reply Jtsummers 3 hours agorootparentWho are not the learner which is the context of this particular writeup. Gates is talking about using LLMs to assist students as tutors, and that is not offered for free ($4/month, $44/year). reply insane_dreamer 55 minutes agorootparentThe idea is that teachers can use it with students. For parents who want to use it with their children, $4/month (for your entire family!) is very small compared to anything out there that you want to use to supplement your kids education (other than Khan Academy itself, which is free). Is it affordable to poor families in Bangladesh? No, but the barrier to sponsorship is low: \"for $50K a year you could sponsor it for 1000 families in Bangladesh\" is not a difficult sell. Also, I expect Sal to raise funding to give it for free to those who can't afford it (just as he did with Khan Academy). At least it's not some VC-backed venture that we know is going to be look for a 10~100x return, so we can be thankful for that. reply Jtsummers 46 minutes agorootparent> The idea is that teachers can use it with students. https://www.khanmigo.ai/pricing Yes, teachers can use it with students if they pay for it. One day it might be free for students, but it presently is not. Which is what I was pointing out to the person I originally replied to. This discussion is about Khanmigo, a subset of what Khan Academy provides, and it is not free for students (though, yes, that cost is not exorbitant). But it does make it difficult to claim that Khan Academy is free when the specific feature being discussed is not. reply nextworddev 2 hours agorootparentprevthe bet is probably that the teachers will vouch for Khanmigo at schools but I’m sure Microsoft doesn’t mind giving away Khanmigo for students too reply qaq 3 hours agoparentprevnext [5 more] [flagged] tbihl 3 hours agorootparentTextbooks do a better job than 90% of teachers, and that's not a dig at teachers. I spend more time, by far, figuring out how to keep student attention than thinking about the material itself. I'd be way more excited about getting 6 of my students to start reading and understanding textbooks than getting all 60 to pass. OTOH, my bosses would be pretty pissed... reply bryanlarsen 3 hours agorootparentIIRC studies show one-on-one attention is worth 2 standard deviations in test scores and a good teacher is worth 1 standard deviation. (Not coincidentally home schoolers have about one standard deviation of advantage). Khanmigo doesn't have to be as good as a teacher to provide an advantage to the student. reply bsder 2 hours agorootparent> (Not coincidentally home schoolers have about one standard deviation of advantage). Citation required as this is heavily dependent upon the purpose of the home schooling and the resources of the parents. Anecdata: My cousin was not doing well in 4th grade. So, they pulled her out and her grandmother taught her for 8 hours a day, 5 days a week, every single day. By the time she came back to school in 5th grade she was doing extremely well and hyper motivated to never go through that experience again. :) She was, however, the exception, not the rule. So much so that a lot of teachers complimented her and her family on the outcome. Her family had no agenda other than \"fix her education\". Most homeschoolers do not bring to bear that amount of resource and attention, and they have quite a bit poorer results. reply bsder 2 hours agorootparentprev> AI does a better job than prob 90% of the teachers. AI is better funded than probably 99.9% of teachers, so ... Ahem. Go sit in a class sometime before spouting that kind of unsubstantiated claptrap. Like anything with a distribution, some teachers are subpar. However, 90+% of teachers are trying very hard. They have too many students. They have too few resources. Many of them are fight against bad home lives of the students. And, through it all, they have a bunch of bureaucrats promulgating the latest and greatest bullshit that never works. We know what works. Small classes ( Anything that requires an ongoing subscription fee is dead in the water. The only reason those stupid smartboards took off is because they make school boards look cool, they are a one time cost, and can be paid for with bonds (because they are a one time cost). Bonds take a one-time cost and turn it into a recurring cost (like a subscription) that is paid in installments over time. It's baffling that that it's easier to do that than just having a subscription in the first place. reply wisty 4 hours agoprev> But drawing on his experience creating Khanmigo, an AI-powered tutor, Sal makes a compelling case that AI-powered technologies will be different. That’s because we finally have a way to give every student the kind of personalized learning, support, and guidance that’s historically been out of reach for most kids in most classrooms. As Sal puts it, “Getting every student a dedicated on-call human tutor is cost prohibitive.” AI tutors, on the other hand, aren’t. Personalisation fails for a simple reason - people don't really want to learn. Classes work because the teacher can inspire (or at least push), and there's peer pressure to learn (or at least keep up with the herd). I'm sure there's a dozen or so self-taught Python or Rust programmers here who will loudly refute what I'm saying, and point out that they were perfectly capable of learning something they were very interested in, but I bet a lot of them would also like to learn a foreign language or quantum physics and haven't gotten that done. AI will fail for the same reason Youtube, DVDs, video cassettes, radio lessons, and phonographs all failed to be a revolution. If you want to learn something, and have the motivation, then reading the textbook is easily good enough (for theoretical subjects) and for less theoretical subjects you barely need a textbook, just lots of practice. Yes, you can probably learn a little tiny bit faster with AI, if you (or someone staring over your shoulder) have the motivation to play some AI learning game rather than a more fun-optimised game that's purely about having fun, but it's a small optimisation. reply beryilma 2 hours agoparent> Personalisation fails for a simple reason - people don't really want to learn. Students/people who are interested in learning a particular subject are doing just fine learning it from already available material, be it books, videos, MOOCs, etc. They may or may not use AI, but AI won't make a huge difference for these type of people. For people who are not interested in learning, AI won't do sh*t. Because the problem is not that they don't have a tutor available to them; the problem is that they don't have motivation to learn. I am not being judgemental here: it is perfectly understandable, for example, why a poor kid may not have motivation to learn. A few years ago, MOOCs were touted as the next best thing to democratize education and make it available to underserved populations around the world. This did not happen. Some research shows that MOOCs are mostly used by an already-educated group of people who are interested in further learning. I think learning with the help of an AI tutor would be no different: its users will not be the intended ones. reply jobs_throwaway 3 hours agoparentprev> If you want to learn something, and have the motivation, then reading the textbook is easily good enough Anecdotally, I found it dramatically easier to learn math through Khan academy than from textbooks. For one, I have terrible handwriting which makes the pen and paper part messy and hard to read, and for two, Khan's lessons were broken down into much smaller, more digestible steps. I took discrete math at Uni and had to learn it from the same Rosen textbook that many on this thread probably did themselves. If I had the same thing in an online version analogous to Khan Academy, I think I would've had a much better time. Now obviously, some of the harder problems and proofs in that book are much harder to grade automatically the way Khan does for grade school math, but that seems like something LLMs are trending towards being able to do reply aio2 1 hour agoparentprevI'm going to be straight forward with you: You're wrong. Not everybody can sit their butts down and go through every word in a textbook. Watching videos on Youtube helps a lot, along with other methods. Don't believe me? Look at those school tutorials on Youtube. Look at all the math videos, science videos and other topics. And I'm not talking about people who build cool DIY stuff and explain it at the surface level. I'm talking about people going through a school curriculum. There are kids who actually watch this, believe it or not, and it's wonderful. This counters your statement which is \"people don't want to learn\". That's simply untrue. Everyday we are learning something new. You may not want to learn whatever they're teaching in school, but you will want to learn other things. And I think a personal tutor, especially a cheaper one, like Khan's AI tutor, will help a lot. reply djeastm 1 hour agoparentprevYep. When I first saw how great AI was at answering my questions, I imagined myself talking to it every day to learn everything I'd ever wanted to know. Turns out, what I actually want to know is just that small subset of things I need to know to get by, plus maybe a little extra for variety. And I consider myself intellectually curious. I have multiple college degrees, one of which I got purely for the fun of it. So if I can't bring myself to get AI to teach me things, I can't believe that those less intrinsically motivated will be able to either. reply lolinder 1 hour agoparentprev> If you want to learn something, and have the motivation, then reading the textbook is easily good enough (for theoretical subjects) and for less theoretical subjects you barely need a textbook, just lots of practice. This may be true for the average student, but I don't absorb content from written text very well at all. The single biggest reason why I got A's through college was being able to listen to video lectures (YouTube, Khan Academy, and occasionally the professors themselves) at 2x speed. I absorb and retain information that way extremely easily, but put me in front of a textbook and I can't focus on it. YouTube may not have been an education revolution for you, but it's definitely changed my life. reply keybored 1 hour agoparentprev> , but I bet a lot of them would also like to learn a foreign language or quantum physics and haven't gotten that done. Learn a foreign language from school? How much do I know of the German/French/Spanish (it was one of them, one of the options) that I studied for years in school? None. For some subjects, something being taught in school seems like a magnet for making a topic or subject boring and uninteresting. Like if it wasn’t taught at all people would at least not be actively biased against it and might pick it up by happenstance. Which makes me doubt all of those “no one knows X; therefore we should teach it in school”. I don’t think that follows. > Personalisation fails for a simple reason - people don't really want to learn. What does (do? Lack of school English) everyone have in common? Schooling. reply danielmarkbruce 50 minutes agoparentprevThis is absolutely not true for kids in the range of maybe 9-13 or something. I have kids. I learn via text books. They just can't do it yet, and they are a good way ahead of most of the kids in their grade. reply red_admiral 4 hours agoparentprevThis. The people for whom personalized learning works well, can do it with any technology, even books. I recently learnt a new programming language from an O'Reilly book just fine, then did some exercises in a (non-AI) online REPL/tutorial tool, then went off to code a project of my own. reply lolinder 51 minutes agorootparentOn the flip side, I've absolutely never been able to pick up a new programming language from a book. Most of the languages I've learned I started with YouTube video tutorials, but most recently when I wanted to learn Rust do you know what worked really well for me? GitHub Copilot. I started a new project, and when I didn't know what syntax to use I made a comment and examined the output. By the time the project was done I'd learned how Rust worked and could write code without help. Before making sweeping pronouncements about what does or doesn't work for learning, it would be worth considering that people vary widely in which learning strategies work well for them. You might just be projecting your own preferred learning style out on the world. reply gwern 2 hours agoprevNote that when Bill Gates praises GPT-4o, he is at least partially \"talking his book\": he retains large amounts of equity in Microsoft, and has been intimately involved in MS's big bet on OA - in 2019, when Kevin Scott was lobbying a big investment in OA (https://gwern.net/doc/reinforcement-learning/openai/2019-sco...), Bill Gates was CCed, Gates invested in Inflection (recently rolled up into MS), and Sam Altman & Greg Brockman personally demoed GPT-4 to Gates at his mansion (https://www.nytimes.com/2023/12/03/technology/ai-openai-musk...) to show that GPT-4 could solve the AP Biology test that Gates had said would convince him LLMs were real. And I'm sure his involvement now goes well beyond just those few instances I've happened to note. reply w10-1 2 hours agoprevGenerative AI works by selecting the most likely next words. But students misunderstand in many different ways. How would it be tailored instead of another way of delivering lesson plans? Even assuming you already had the topology of the problem space, you'd have to interrogate the student with all possible ways for each question to determine what's missing for them. But part of the problem is impedance matching: failing students get little positive feedback because they have to correct many mistakes before they start getting things right. Interrogation makes the impedance-matching problem much, much worse (no matter how sweet and enticing the voice). Sure, I believe in success patterns and strong leaders. But I'd need to see a sketch of how Khan understands and addresses the problems before I'd invest or rely on this as anything other than a stop-gap that continues the under-funding of mass education. reply educaysean 42 minutes agoparentHow would an excellent human teacher work with such a failing student? Can that technique be something that the AI could model? reply olooney 4 hours agoprevThere has always been a split between students who are there to learn and those who are there to get a diploma. AI will simply make this divide wider. Students who actually want to acquire knowledge and skills will benefit enormously, while students who are trying to skate through with minimal effort will find themselves hitting the job market with literally no skills or knowledge beyond copying-and-pasting in and out of chat windows. reply jasondigitized 39 minutes agoparentThat’s a feature of a job market, not a bug. reply cmcconomy 2 hours agoprevReally depressing that Bill Gates is impressed by the idea of \"chatting with lincoln\". Is this what we were missing in school? Our teachers dressing up with a tophat and bullshitting that they're lincoln and making stuff up? reply djeastm 1 hour agoparentRight? In twenty years, people are going to be comparing their imaginary conversations with Lincoln as if they're historical fact. reply stevarino 16 minutes agorootparentThat's an interesting \"what-if\" though... How would a future generation be affected if they have a parasocial relationship with Lincoln? Or any historical figure? Or a currently running politician? I feel sci-fi authors have their work cut out for them... reply Apocryphon 41 minutes agorootparentprevThis clip was making the rounds in response to some AI hustler startup making an Alan Turing AI chatbot their CTO: https://www.youtube.com/watch?v=mEMbLt4B4iA reply jamilton 41 minutes agoparentprevI'd probably find that kinda entertaining as a kid, and being entertained is useful for teaching/learning to a degree. reply rahimnathwani 4 hours agoprevI'm as excited about the potential as anyone. I would love to give my child an AI tutor like The Primer. But nothing like that exists today, as far as I know. I was disappointed with Khanmigo when I tried it back in August. Although I have a year's subscription to it, I've not asked my child to try it. It seemed too boring and told me my answer (to a problem it had given me) was wrong, even though I was right. I'm optimistic, but I think there's work to do. I've not seen an AI system that can apply the pedagogy of George Polya: give the student a small hint by asking a question that could have occured to the student themselves. reply nicetryguy 34 minutes agoprevIf 3 delicious cans of Pepsi: The Taste of a Generation cost six dollars, how much does each thirst quencing soda can cost individually? We solve this by... reply from-nibly 2 hours agoprevDisclaimer I'm talking about the US, but I believe it applies at least somewhat to most of the modern education system everywhere. The problem of education isn't the lack of resources it's the lack of purpose. The internet is all the resources you will ever need. Sure AI could augment this a little. Maybe it could re-explain something you can't quite wrap your head around. The problem is that kids know that the education system isn't even kind of preparing them for what's to come. Knowledge work and trades couldn't be further from what public school prepares you for. Having a teacher for every kid wouldn't change this. The problem is so fundamental, and the solution is so destructive that we can't just tack on one more thing to \"fix\" education. Learning comes from doing, augmented with reflection. Public Schools don't ever do either of those things. The closest you ever get to doing anything that another human could want is building something in shop class. The closest thing you get to reflection is a grade that can only be negative feedback or the lack of feedback, plus there's no time for building on that reflection, just move onto the next thing. reply balls187 1 hour agoparentIs your comment based on recent experience? I have two young school age kids, and my experience with them does not align with your assessment. Their schooling is vastly different from the \"Sit still, do what you're told\" model that was used to train the an upcoming generation of factory workers. reply n4r9 3 hours agoprevCalling this \"Brave New Words\" reminds me of a recent submission: \"For tech CEOs, the dystopia is the point\" - https://news.ycombinator.com/item?id=40371835 > a time-honored internet tradition: pointing out that the science fictional reference point a tech founder put forward was not an aspirational one, but, in fact, a dystopia containing a warning meant to be heeded, not emulated. reply Jtsummers 3 hours agoprev> As you work through a challenging set of fraction problems, it won’t just give you the answer—it breaks each problem down into digestible steps. When you get stuck, it gives you easy-to-understand explanations and a gentle nudge in the right direction. When you finally get the answer, it generates targeted practice questions that help build your understanding and confidence. You don't need an LLM for this. Since the topic is specifically math, consider what that actually entails, especially for K-12 math education. The example is fractions. The rules for fraction problems are well-defined, we don't need an LLM to guess at the steps, we can literally write a simple program that encodes all the individual steps and prompts the student when they make a mistake to step back and walk through each small step (instead of taking big steps, like going from 1/2+1/4 to an answer have the student fill out each step like how to make the denominators the same and then adding the numerators and then, if applicable, simplifying). Generating problems is also not something an LLM needs to be involved in. Such a strange and wasteful use of these tools. reply w10-1 2 hours agoparentSo then what if the generative LLM is simply the \"UI\", tailored to the student, but working from a topological map of the subject matter in the form of quizzes? And if it were able to present questions targeted at student gaps, broken down to be challenging but achievable, i.e., to build success patterns? Wouldn't that work for any subject matter - not just math? reply emacsen 4 hours agoprevThis has seemed like the next logical step in education for a while now. I recently used ChatGPT to help me understand some Kubernetes and Terraform configuration. It was able to talk to me about the configuration and also help me understand some of the larger context- how information flows between the systems, what the terms mean, etc. It provided direct explanations, and metaphors when I needed it, and let me ask clarifying questions. This kind of learning system would be especially useful for people like myself who have Learning Disabilities, where once I understand a topic, I can speed ahead, but sometimes I'll just get \"stuck\", sometimes for days/weeks. Having a tutor can help, but there's a lot of embarrassment and that can lead to anxiety, which can in turn make it harder to learn. Obviously such a system will need some safeguards around it, but having a system like this be able to both explain and point to primary sources could be a complete game changer for students. reply bn-l 4 hours agoprevI never found the Kahn academy videos good. His teaching style was just totally off. I found some videos by a company called The Teaching Company. Really old school, very early 2000s or late 90s. Incredibly high quality truly gifted teachers—-just less well known online. reply rramadass 3 hours agoparentI am glad somebody mentioned \"The Teaching Company\" and their offerings - https://en.wikipedia.org/wiki/The_Teaching_Company I used to checkout their \"The Great Courses\" dvds from the local library (in the USA) long time ago. They were a set of presentations each a full lecture length and delivered by respected professors in their fields. No flashy animations/music/narrative distractions but sedate multimedia in support of the lecture. I am not sure how it has changed nowadays but people should definitely check it out; there is a lot of good content there. reply nothrowaways 3 hours agoparentprevCan agree. Did a pretty good PR and first comer advantage. reply maccard 1 hour agoprevI studied engineering in university, and as part of that I took enough calculus, numerical methods, statistics, and logic courses to earn a math degree along side my engineering one. I spent hundreds of hours poring over 1500 page textbooks and being given the driest lectures imaginable by people who were delivering them on autopilot. I would estimate that one hour of khan academy was roughly equivalent to a weeks coursework, which was 3 lectures and probably an extra 2 hours of self study per lecture. It was undoubtedly the only reason I succeeded in the way I did. reply balls187 1 hour agoprevMy son is a second grader who is behind on his english reading and writing. He's smart, able to understand and convey complex ideas, and can solve math problems beyond his grade level. He is classified as learning disabled, and has IEP through the school district which gives him accommodations including access to assistive technologies--such as an OCR reader that will read the words on a page to him to allow him to answer questions. At the very least, AI for ed-tech is the next evolution of those technologies, which may even be allowed without the need of a 504 or IEP (e.g. each student in his class has a school issued laptop). I'm also curious what subjects would be made obsolete because of the power of AI assistants. I certainly was not taught Latin, and my kids will never need to learn cursive writing. reply jimmar 1 hour agoprevI work in academia and look forward to embracing AI tools. Students motivated to learn will do great with it. Others will need AI to really push them to learn, and it's not clear to me how that will work. Many students just want to know what they have to submit to get a grade. Spending 20 minutes chatting with AI about a topic might be a good learning activity, but incentivizing that with grading will be tricky. I've sometimes wondered when I'll get called to the Dean's office because a student died in class because breathing wasn't specifically listed as a grading requirement on the syllabus. reply the__alchemist 2 hours agoprevI began a Journey in my mid-20s that I'm still on. (38) I took math classes, starting at middle-school grade. Did most of the Khan material. Moved on to MitX classes in further math, and sciences. Now I am working on an ab-initio atom/molecule simulating for funsies. Khan academy is an invaluable resource. When I have kids, it will be a core part of their curriculum! reply IncreasePosts 2 hours agoprevI'll admit I haven't read the book mentioned in the article. But I can't help but feel this is just dreaming about \"AI\" as a magical intelligence that we can perfectly instruct and trust, instead of having an actual plan for how current SotA AI could deliver that experience. I personally wouldn't trust any current LLM to train my child, without having to go over all of its content and see if it was actually trustworthy or not. reply insane_dreamer 1 hour agoprevThis is perhaps one of the best use cases for AI. (Khan Academy is excellent. Over a decade ago, my home-schooled daughter [we were not living in the US at the time] used Khan Academy throughout high school, scoring 2300 on the SAT and getting a full scholarship to a prestigious US college to study engineering.) reply mihaic 4 hours agoprevAll the articles I've read about AI improving education make the same assumption: AI will help students learn that same things as we teach them now easier. If AI will be so revolutionary to me that first mean a complete overhaul of what students should learn? We haven't even properly done this reevaluation of the curriculum even for being constantly connected to the internet. Students really need to learn a lot fewer things on average, but the fundamentals matter even more now. Honestly, 90% of the population doesn't need more than elementary math, but they really need to understand how percentages or pro-rata work. In the end, looks like a puff piece by Bill Gates is still a puff piece. reply smugglerFlynn 2 hours agoprev> Chapter by chapter, Sal takes readers through his predictions—some have already come true since the book was written—for AI’s many applications in education. His main argument: AI will radically improve both student outcomes and teacher experiences, and help usher in a future where everyone has access to a world-class education. I'd argue that the very thing that made Khan Academy successful in the first place was not \"accessible education\" or \"cost prohibitive\" practices, but Sal's human attention to the students needs and all the amazing content he created. Thousands of people will pick up from this article that AI is the solution to the education, while in reality it is people like Sal who are the actual solution, with YouTube, AI and other tech just being the tools to help scaling human talent. reply markles 3 hours agoprevStudents are not lacking access to information, they're lacking motivation. reply w10-1 2 hours agoparent> lacking motivation Isn't this for lack of tutors, which AI solves? With teaching now (even via videos), there's no way to present material for 30 students when they vary widely in background understanding and attention span, so only the high middle gets targeted. This creates a vicious cycle where the spread only gets larger as students age. If slow kids can be tutored to catch up, they'll be much more motivated as part of the class, instead of the losers. If fast kids are given a taste of how ignorant they remain, they might have more sympathy for others, and might try to help instead of compete. reply djeastm 1 hour agorootparent>Isn't this for lack of tutors, which AI solves? I would argue there's a very human element to tutoring that AI does not provide. Having been a tutor and also having been tutored myself, the personal relationship is very important. To know some other human is taking their very human time to help you is a powerful motivating factor that an AI can't simulate. To see another human performing some task that you can't activates some kind of primal desire to emulate them. AI can't simulate that. reply fhe 2 hours agoprevthe article makes it as if the solution to education is \"a dedicated tutor to every student\". I do not think that's the case. The problem is that not every student has the motivation, and having a tutor on call 24-7 doesn't change it. the article goes on to describe how such an AI tutor might work: \"As you work through a challenging set of fraction problems, it won’t just give you the answer—it breaks each problem down into digestible steps. When you get stuck, it gives you easy-to-understand explanations and a gentle nudge in the right direction. When you finally get the answer, it generates targeted practice questions that help build your understanding and confidence.\" reading it, and watching the demo of gpt-4o tutoring math (https://www.youtube.com/watch?v=dBrdd7xg-dg), I felt the opposite -- that if I had such a tutor, whatever motivation I had would have been stripped away by such a tutor. I really needed the quiet struggle with a problem, and feeling that I conquered it on my own, instead of being guided through a paint-by-number kit. I acknowledge that I might have an unusual learning style, or that I simply belonged to a generation that grew up without such tools, hence the aversion, much like my parents grew up without digital calculators (although they don't harbor any aversion to the use of calculators). reply from-nibly 2 hours agoparentYeah that's not an unusual learning style. No one can learn without struggle. There has to be some reason for your brain to remember something. If the AI is right there ready to do it for you, then why would you remember anything? reply d_burfoot 3 hours agoprevThere's always been an economic contradiction in a common education. The skills that a typical high school education will teach you are not very valuable, because they are oversupplied. No one is going to pay you to solve AP calculus problems or write an essay about the French Revolution; not because these are easy tasks, but because the world is full of people who can perform them. AI education will continue this trend. AI can certainly teach you all kinds of remarkable skills. But the value of those skills will now plummet, because these are exactly the kinds of jobs that will be automated by AI! reply bertil 3 hours agoprevThis is a lot of words for not saying that students keep sending essays entirely written by ChatGPT and never proof-read by their “author.” Never having to do homework is affecting students dramatically, according to many teachers. What Gates and Kahn describe is interesting, but it’s a little bit like talking about color theory and how the fact that a baseball bat is purple affected you after you just got whacked in the head with it. reply jerome-jh 1 hour agoprevThe article made me smile by how much disconnected to reality it is: - kids give their assignments to AI so that it solves it for them, not for getting a hint. - it has long been demonstrated human interaction is required to learn difficult things (such as reading/writing), otherwise kids would learn those skills on video. - learning is about practicing difficult stuff. AI is about having the computer doing difficult stuff for you. \"Employees who can use AI effectively will be far more valuable than those who can’t.\" The point of AI is that there is absolutely nothing to do for it to digest your problem. Show me someone who can't use AI? Must be illiterate? \"jobs of the future—which will become more enjoyable and fulfilling\" ... finding and fixing the errors the AI made. My parents are much better at counting with no calculator than my kids. Mental calculation is no more seen as a valuable skill now that everybody effectively has a calculator in his pocket (smartphone). AI will make some skills once valuable obsolete. The question is not how are we going to teach with AI but WHAT are we going to teach? reply dorkwood 3 hours agoprevSal jumped on the NFT wagon, now he's jumping on the AI one. Not surprising, but hopefully something good comes from this play at least. reply toomuchtodo 4 hours agoprevhttps://www.youtube.com/watch?v=LI7UOuX9Qjs (\"Sal Khan on why Khan Academy is a non-profit\") reply moomoo11 4 hours agoprevAI is like the promise of back when consumer internet was just popping off. You can have all the knowledge at your fingertips! What actually happened: ads shoved down our throats and way more distractions (porn, games, etc.) Meanwhile math and reading levels continue to plummet. So I don’t have high hopes. Those of us who use tools to succeed will continue to do so. Others who can’t control themselves will keep complaining. Nothing new. AI will give us an answer with ads shoved into it with companies bidding to show their ad with the answer. People will do degenerate shit with AI, and gaming addiction will continue. People will still keep blaming the system and wondering why they can’t get ahead while spending most of their free time wasting it on gambling, porn, and games instead of learning. The world will be split unevenly into people who research to contribute to AI knowledge base, and people who simply consume AI content. The question is. How will we (the enlightened ones lol) make money off it? reply AlexandrB 4 hours agoparentHaving been through a few technology cycles now, I am also skeptical. We're in the honeymoon phase where anything seems possible and everything is cheap or free (VC/company subsidized). What will AI look like when it comes time to pay the piper? More ads? Perpetual subscriptions? reply 2OEH8eoCRo0 4 hours agoparentprevThe consumer internet is a blessing and a curse. Without consumers the internet doesn't have much economic benefit. To use the internet to sell things you need the normies- so you pull all the non-technical people onto the internet where they are scammed, hacked, and manipulated at scale. reply moomoo11 4 hours agorootparentThat's my point. Same with AI. reply ebr4him 4 hours agoprevYour country isn’t eligible right now. At this time, only people who live in the United States are eligible to use Khanmigo. reply red_admiral 4 hours agoprevBoth Bill Gates and Sal Khan (and, for good measure, Mark Zuckerberg too) have tried revolutionizing education with technology before. If we look at exactly how and where past attempts went wrong, we might find some challenges for this one too. I remember when MOOCs were the future of education, as students across the world would have free access to the best lectures from the best teachers and could watch them over and over again at their own pace. That ... didn't result in the second coming of Christ, to put it politely. reply olooney 3 hours agoparent\"We try things. Occasionally they even work.\" —Rob Balder reply nbzso 4 hours agoprevIf you have some form of financial independence in your life, some form of the grid backup, you know what is all this about. Did you think the richest of the elite will give their kids this form of education? Seriously? My kids learn in a classical way. No aid, no electronic devices, no \"modern\" bullshit. Critical thinking is a must in a world of corporations greed and digital dystopia. The school mandatory program is just a form of training ground. They learn how to see the real problems around and how to adapt to ever-changing hypocrisy. Never trusted a word coming from the corporate monster Microsoft. Never looked at Bill Gates as more than a greedy manipulator and sociopath. Downvotes don't change the reality:) reply IncreasePosts 3 hours agoparentThe elite will give their kids this education when it is better than what a team of dedicated humans can provide. We are no where near that stage though. reply add-sub-mul-div 4 hours agoparentprevI agree the endgame is turning all education (and other areas of society) into McDonald's type crap because it's cheapest to offer. But it's weird to make this about Microsoft when AI is being shoved down our throats from all directions. Like you said, it's a \"world of\" greed. reply nbzso 3 hours agorootparentGreed is contagious. But looking at Closed AI and seeing Azure all over it is not easy to ignore. Looking at hostile takeover of FOSS at GitHub to train commercial product Copilot is another thing. We all knew the strategy when they bought it, and we all complied with the move. They have power because we refuse to challenge the lack of intervention from authorities. It is all a big scam. reply croes 4 hours agoprev>Picture this: You're a seventh-grade student who struggles to keep up in math. But now, you have an AI tutor like the one Sal describes by your side. Picture this: You're a seventh-grade student who struggles to solve the equations in math. But now you have an AI that solves it for you. I bet that there will be more students of the later type than the former. reply tombert 4 hours agoparentI dunno, I've found ChatGPT (and its clones) have been immensely useful as a learning tool for me. Having it summarize stuff in different ways and being able to immediately ask clarifying questions has been sort of a game-changing learning tool, at least for me. I don't think they should allow use of AI during tests because yeah, it'd just do all the work for them and they wouldn't learn anything, but I absolutely think there's value in being able to use it as a 24/7 instant tutor, particularly since ChatGPT can be coerced into explaining things in basically any style that you'd like. Something I've found fun and bizarrely useful is having ChatGPT explain stuff in terms of scripts from King of the Hill. It's fun to hear Hank Hill compare ZF Set Theory to something as reliable and efficient as propane while Dale goes into tirades about how the government imposed the axiom of choice to distract away from System F. reply nicklecompte 4 hours agorootparentIncredibly depressing to read this comment when I have tested GPT-4 extensively on simple finite group theory, and it could not reliably distinguish associativity from commutativity, either in prose or in computations, even for very small groups where I gave the multiplication table. The only simple abstract algebra problems it could solve were cliches it almost certainly memorized. I would never use an LLM for learning undergraduate mathematics. It is overwhelmingly likely that you are learning incorrect facts about mathematics from ChatGPT, especially with the distracting gimmick of using cartoon characters. reply pnathan 3 hours agorootparentAt this point, I am surprised that LLMs _can_ do code, given the volume of incorrect information they give on specific topics. reply nicklecompte 2 hours agorootparentI think most LLM codegen successes is due to their translation abilities, which is what transformers were designed to do in the first place. Software developers usually solve problems in human language (or maybe a sketch) with general “white collar reasoning abilities” that most of us honed in college, regardless of our major. The translation to Python or whatever is often quite routine. A human developer’s software-specific problem-solving skills are needed for questions involving state, unfamiliar algorithms, “simple” quantitative reasoning, newer programming languages, etc... all of which LLM codegen is pretty bad at. reply tombert 4 hours agorootparentprevFirst, just because there's issues with some misinformation with ChatGPT right now doesn't imply that it will always be there. Second, I know what fuck I'm doing, and I'm sorry to \"depress\" you, but having a high level summary of something in terms of a cartoon is generally reasonably accurate, and generally any information I learn is also mechanically checked with Isabelle. I agree that it shouldn't be the be-all-end all of everything but if you're a student who's already frustrated with math, having a high-level description of stuff in terms of something you understand can be valuable. reply xhkkffbf 3 hours agorootparentAnother way to look at it is to recognize that all teachers have limitations. Humans often convey misinformation too. reply tombert 3 hours agorootparentYeah, and I actually think that there can be some value in students being challenged to find some misinformation. I maintain that one of the very best teachers I ever had was my 9th grade biology teacher, purely because she understood absolutely nothing about biology and appeared to just be making shit up. You could argue that in a vacuum this might be benign, but part of the issue is that she would use tests provided by the textbook, written by competent biologists. As a result of this, I had to learn to ignore most of what my teacher said, and sometimes argue back with her, and I feel like ironically I learned biology better than most people in that class; if nothing else I did get an A on all the \"real\" tests from the textbooks. I think that arguing is actually a really underrated tool in education. Looking for and correcting bullshit is something that extraordinarily enlightening, at least for me, and I think AIs even in their current state can be useful for that. reply nicce 3 hours agorootparent> Yeah, and I actually think that there can be some value in students being challenged to find some misinformation. The future generations do not have the same background as we do. For them it is very difficult to teach what is \"misinformation\", or have a thinking model like that, unless we make them read proper books and compare the content for the output of the AI. But if the AI is soon correct enough, they don't get it, and they don't feel it important, and they just take the output from AI as fact. reply tombert 3 hours agorootparentI agree with all that, and that's why I think we should still keep using traditional books for the foreseeable future. I think that AI can be a terrific supplement, particularly if the students are told to challenge it a bit. I think that just like human teachers, it'll be impossible to completely solve the misinformation problem, but I do think it'll get asymptotically close to being solved. reply cmcconomy 3 hours agorootparentprevfinding misinformation is a critical skill, but you need a basis to suss out bullshit. diving into the LLM plausibility deepend is not the best way for most people to distinguish the two. reply RandomLensman 3 hours agorootparentprevDoes ChatGPT give you good exercises in set theory to work through as well on that or is that back to other material? reply tombert 3 hours agorootparentI've never really had it do exercises in set theory, so tough to say. Usually the thing I like about it most is getting it summarize stuff at a high level, and then giving me keywords than I can independently search for and play around with in Isabelle. Like, for me I think part of the value to ChatGPT is simply figuring out some of what I don't know that I don't know. When I was a lecturer I would use ChatGPT to generate Java homework assignment. It would do \"ok\" with that, but it usually required three or four iterations to get something that actually made sense, and usually it would require a bit of editing on my end to get results I was happy with. It still saved me a boatload of time though, particularly since it was even able to give me the assignment in pandoc-compatible markdown. reply RandomLensman 3 hours agorootparentI always thought it tough to really learn math without doing exercise to really understand how things work. reply tombert 3 hours agorootparentIt is! In my case, that's why I usually try and figure out something to do in Isabelle. Trying to prove some kind of property based on something I learned from ChatGPT. I also will occasionally grab exercises from \"real\" textbooks once I know the keywords to search in Kagi. reply RandomLensman 2 hours agorootparentNot sure self-selecting on exercises is really sufficient (at least for me I doubt it). reply tombert 1 hour agorootparentYou're not wrong, but such is the way with nearly anything autodidactic. Learning how to find exercises that are challenging enough to actually learn something is a skill that I'm not going to pretend that I've mastered, but I would like to think I've gotten reasonably good with. I was a college dropout for quite awhile but was still working as a software engineer, and while that's definitely not something I would recommend to anyone (it makes stuff way harder), it did have the advantage of making me pretty decent at teaching myself stuff, simply because my career depended on me being able to play with the \"big boys\" on an intellectual level. For software it's comparatively easier though, because you can just have a project to do X, and if it's complicated enough you'll likely touch on a lot of CS concepts, even some you didn't directly self-select. Math (particularly more abstract math) is harder simply because it's much harder to practice; there aren't a ton of tangible \"math projects\" that you can hack on. The closest way I've been able to practice it is by using Isabelle. I didn't use ChatGPT to learn that initially, since I learned how to use it before ChatGPT was released; I read through the \"Concrete Semantics\" free book and did those examples, so I guess that of proves your point more than mine. reply ben_w 4 hours agorootparentprev> I don't think they should allow use of AI during tests because yeah, it'd just do all the work for them and they wouldn't learn anything, but I absolutely think there's value in being able to use it as a 24/7 instant tutor, particularly since ChatGPT can be coerced into explaining things in basically any style that you'd like. For any test where there's an AI good enough to cheat with and cheap enough students can afford it, the test itself is no longer important — it is as pointless as testing how well students can use fountain pens when everyone uses a keyboard for actual work. Or how well they can play chess. I'm not sure the exact shape of what each model can and can't do, but I am confident that this means they're never be an important \"cheating\" risk, not even when they're technically capable of it. reply miki123211 3 hours agorootparentI used to agree with this point, but I actually changed my stance. Once you hit a problem that an AI cannot solve, it's good to be at least aware of what's going on in the field. You don't necessarily have to remember every formula and every fact off the top of your head, but having an intuition on what facts and formulas there are and where they can be used is immensely helpful. Imagine you're writing a program in an esoteric scripting language that Copilot doesn't understand, and you need to put a large array of events in order from oldest to newest. If you had to learn this sort of think before, you'll immediately have an intuition that this is called sorting, there are slow (n^2) sorting algorithms and faster (n log n) sorting algorithms and you want the latter, and that quicksort is probably a good candidate to start with. You don't necessarily have to be able to write quicksort by hand, you can look up an implementation online and port it to your weird proprietary language, but the intuition is important. reply ben_w 3 hours agorootparentHmm. That sounds like a different thing than I'm saying, and I agree with what I think you're saying. So, if an AI can answer \"what's a fast sort function\" with \"quicksort, here's some pseudocode: …\", that's a related but different question to \"write quicksort in [this brand new language you've never encountered before]\". Is like how AI won't take our jobs, but it will take over for each individual task that our jobs are made from. reply tombert 4 hours agorootparentprevWell, no, I absolutely and fundamentally disagree with that. We didn't just stop teaching children how to read the second that text-to-speech stuff came about, and we didn't stop teaching basic arithmetic the second that calculators were invented, and we didn't stop teaching algebra the second that Wolfram Alpha was released. There is value in learning the fundamentals of things. If you never actually learn algebra, then it becomes effectively impossible to do the more advanced stuff. reply ben_w 3 hours agorootparent> We didn't just stop teaching children how to read the second that text-to-speech stuff came about TTS from visual input isn't good enough to be an example of that yet. It's good, but not that good. > we didn't stop teaching basic arithmetic the second that calculators were invented and we didn't stop teaching algebra the second that Wolfram Alpha was released. And yet, my A-level exams 22 years ago required me to have a graphic calculator. reply tombert 3 hours agorootparent> TTS from visual input isn't good enough to be an example of that yet. It's good, but not that good. Even if TTS were absolutely perfect, then I'd still maintain my point. > And yet, my A-level exams 22 years ago required me to have a graphic calculator. Doesn't that sort of prove my point? Calculators existed and were obviously useful, but they didn't just stop teaching you algebra, despite knowing you had a calculator. reply ben_w 3 hours agorootparent> Doesn't that sort of prove my point? Only if you missed mine about how it is no longer cheating to use one. reply tombert 3 hours agorootparentI see, so you're claiming that if AI can be utilized to solve the problem, and it's determined to be useful, then it should be allowed to be on a test as a result, in the same way that a graphing calculator is no longer considered cheating? I think the disagreement I have is that I think part of the reason calculators are allowed on calculus tests is because they're actually not that useful for a lot of what they teach you in calculus. I had a graphing calculator in my math and physics classes in high school, but most of my work was still done with a pen and paper. The calculator was of course useful for the arithmetic stuff, and it could be useful to sanity-check your work (e.g. to see if the roots you calculated were correct), but I still had to do most of the actual calculus by hand. Even when I got a calculator with a CAS built in (HP 50G), I would still have to do most of the algebra by hand, and honestly if my teachers had known that my calculator had a CAS I suspect they wouldn't have allowed me to use it to begin with. reply llm_trw 4 hours agorootparentprevFountain pens are easier to use than most ball point pens. If you need to think deeply about a problem there are few better things than a binder of a3 paper and a fountain pen to think. That said the uselessness of education is the point. It's a signal that you're willing to do pointless work for future rewards. We may as well replace it with counting beans and it would be just as effective. reply ben_w 3 hours agorootparentAs a southpaw, the last thing I want to do is touch a fountain pen. Well, unless I have another go at learning Arabic… reply chii 4 hours agoparentprev> But now you have an AI that solves it for you. and then the AI explains how it was solved, step by step. You can repeatedly ask it to clarify, and it has endless patience and won't get bored or sick of you. Eventually, you understand how the equation is solved. No human teacher would be able to achieve this. reply koolba 4 hours agorootparent> No human teacher would be able to achieve this. This immediately reminds me of the scene in Terminator 2 where Sarah Connor is reflecting on how the terminator, reprogrammed to aid John Connor, is the best father figure he’s ever had. https://www.youtube.com/watch?v=tksN5Jaan9E “It would never leave him, and it would never hurt him. Never shout at him or get drunk and hit him or say he was too busy to spend time with him. It would always be there, and it would die to protect him.” reply jononor 1 hour agorootparentIt some areas superhuman performance is sadly not that high of a bar... reply atonse 4 hours agorootparentprevWow this video is making me want to go and re-watch Terminator 2. Amazing. what a beautiful scene, words, everything. And it's objectively true. reply anon7725 3 hours agorootparentprevPlus it has detailed files. reply mminer237 4 hours agorootparentprevThat requires a young student who is really self-motivated to keep asking it to clarify things. Plenty of teachers, parents, and tutors are willing to keep trying new ways of explaining things to kids until they understand it. The kid giving up is way more common than the adult without someone pushing him to keep trying or coming back to it regularly. Obviously, not every child has someone in his life that cares enough to do that, but I can't see AI as anything other than a subpar substitute. reply anon7725 3 hours agorootparentI guess the difference is that there is a social dynamic at play between a student and an instructor. The student may tire of some aspect of the relationship before they tire of learning the material. For example, unless the instructor has some kind of Jedi master level self control they may begin to show frustration at being asked the same question repeatedly or with minor variations. reply theyinwhy 4 hours agorootparentprevFor many the alternative would be no substitute at all. reply jsbg 4 hours agorootparentprevExactly. In school I couldn't understand the Heine-Borel theorem and a professor actually got annoyed at me asking about it even though it was just one time. When ChatGPT was first released one of the first things I did was ask it to explain it to me. Even the 3.0 model was pretty good at it! reply CamelCaseName 4 hours agorootparentI must admit, I am quite envious of students with these tools. I wish I had this during my studies. Certainly as my parent's generation must have been with the internet and computers for me. I'm not sure what to do with this envy. Though, it has made me want to have a child even more, just to see first hand how they could develop so much faster and smarter than me. reply atonse 4 hours agorootparentprevWhat I also love is that you can ask it to explain with varying degrees of simplicity. You can say, ELI5 (like the Explain Like I'm 5 years old Subreddit), or explain it like a child, or explain it in very simple English (which is like Simple English wikipedia). It is actually going to be the greatest learning tool, but only for people that genuinely want to learn. reply llm_trw 4 hours agorootparentprev>Eventually, you understand how the equation is solved. No human teacher would be able to achieve this. One of the things I have hugely enjoyed about LLMs is asking the same question again and again until I finally get why it is the way it is. No human could deal with \"I don't get it, try explaining it another way...\" after the 10th time. reply Ghexor 4 hours agorootparentprevA human teacher can see the problem from the students perspective and understand the error they make and why they make it. No current ai would be able to achieve this. But alas, few human teachers can or will take the time to do this per student. Infinite time and patience really are the ai's superpower here IMO. reply GolfPopper 4 hours agorootparentprevBut sometimes it makes up answers that are wrong but sound plausible to you. You have no way to tell when it does this, and neither does it. reply falcor84 4 hours agorootparentNeither can you easily notice that when a human teacher/tutor does that. At least with math, you're able to try it yourself and see if it works. I've had many cases where following through on a misleading explanation by a teacher/book actually ended up leading to me better retaining the topic. reply bn-l 4 hours agorootparentprevOr when you tell it you think the answer is something else it agrees with you and apologies that yes, now it can see, 2+2 does equal 5. reply xscott 4 hours agorootparentprevThat's absolutely a bug that needs to be fixed, but I think it's possible. Maybe have the network which generates the answer be moderated by another network that assesses the truthiness of it. It's just a matter of priorities for the company designing the models. reply ben_w 3 hours agorootparentIt might be possible, but nobody knows for sure, because these models are rather more mysterious than their architecture suggests. > Maybe have the network which generates the answer be moderated by another network that assesses the truthiness of it. Like a GAN? Sometimes you can do that, but it seems not always. If this was simple and obvious, they'd have done it as soon as the first one was interesting-but-wrong. reply jobs_throwaway 3 hours agorootparentprevEspecially in a limited domain like grade school math, it seems entirely plausible that we can have models in very short order that ~never hallucinate. There's no external dependencies and the problem space is extremely well-defined and constrained. Much, much, much easier than making something like Chat-GPT never hallucinate reply neuralnetes-COO 4 hours agorootparentprevThat is the entire purpose of LLMOps. Provide guardrails to prevent hallucination and ensure precise control of GenAI output. reply tayo42 4 hours agorootparentHow can you tell what's true or not? reply neuralnetes-COO 4 hours agorootparentYou have to develop your own QA methods to ensure output is exactly what you want. reply miki123211 3 hours agorootparentprev> no human teacher would be able to achieve this. They would, but only if you were rich enough to afford a personal tutor. There's plenty of scientific evidence that students who have one learn a lot faster than those stuck in a classroom. With AI, you can probably get most of the benefits of a personal tutor for a fraction of the price. reply itronitron 3 hours agorootparentprevThere are already multiple websites that will solve math problems that the user submits and then walk through the individual steps one by one. I'm pretty sure the solutions are based on mathematics and not a trained AI. reply jgalt212 4 hours agorootparentprev> Eventually, you understand how the equation is solved. No human teacher would be able to achieve this. Not true, but only available at great expense. reply theptip 3 hours agoparentprevThere is an important point here; the curriculum needs to change, a lot. There is little point in writing essays any more. We’ll need to find other ways of testing knowledge acquisition. But also, we’ll need other menus of skills/knowledge to acquire. It seems to me that rote memorization of facts is even less useful than it was 5 years ago. However being able to synthesize facts and ideas, this is where the human edge will be concentrated. With AI to do the grunt work, maybe we can have our kids actually building meaningful things much earlier than they would otherwise be capable of. reply radicaldreamer 2 hours agoparentprevPeople who find the tool to do the work for them will be fine. I remember “learning” to use Mathematica so I could easily complete copious calculus assignments and homework in high school. It didn’t keep me from learning the material - a lot of those assignments and problem sets were simply busy work — but did improve ho much free time I had to read and surf the net and learn new tech things. reply Phiwise_ 4 hours agoparentprevWhy would you assume this? Wouldn't Sal Kan want to design his version of a teacher AI to avoid that behavior? reply red_admiral 4 hours agoparentprevWe've had phone apps that you can point at an equation in a textbook and it solves it for you, for several years now: https://apps.apple.com/us/app/fastmath-take-photo-solve/id14... I don't think we need Generative AI for 7th grade. College, perhaps, but how much advanced math is there in 7th grade these days? reply dmvdoug 3 hours agorootparentCame here to point this out, as a history teacher who is often told by students they use phone apps for math. reply asabla 4 hours agoparentprevFor sure! But idea behind these AI tutors are to help and guide you through the process of asking questions until you understands. Will it be perfect? hell no! Just another tool for teachers to either enhance and/or give extra help with almost no extra resources. Hopefully this will pan out for the better then the worse reply nicce 4 hours agorootparentWhere is the opportunity, there is a crime. The most of the students will not use it for improving their own text or iteration process, unless the penalties for cheating are very high. They instead copy-paste the instructions, add some adjustments, and then copy-paste the output. This will give them results in the shortest amount of time, if there are assignments where something needs to be returned. But how to detect cheaters? Too many students do tasks as in \"completion\" oriented way, not in learning oriented way. I am mostly talking from college/university perspective. reply PheonixPharts 4 hours agorootparentprev> pan out for the better then the worse While I'm sure this is a typo, I also expect this is exactly how it will play out. For the better initially, then, for the worse a short time later. reply nicklecompte 4 hours agoparentprevPicture this: you're a high school junior struggling to understand simple free-body diagrams. You ask the AI tutor for help and it gives you a pile of bullshit. Unfortunately the bullshit is written in the exact same authoritative tone as your (correct) textbook, and the AI temporarily gaslights the actual human teacher into accepting a wrong answer, even though the teacher has a B.S. in physics. (Source: a very smart science teacher I know and won't name. Keep in mind most high school science teachers have weak scientific backgrounds. This technology is poison.) reply LegitShady 4 hours agoparentprevI have coworkers who already stop to type things into a GPT before using any part of their mind to think about things. At this point I assume its inevitable that for large segments of people, who are not actively trying to maintain the independence of their mind, will allow these computers to do their thinking and decision making for them. reply lannisterstark 4 hours agorootparentNot everything needs to be analyzed ad-nauseum. Sometimes I just want an answer so I can move on and use that for something productive in my life. reply nicce 4 hours agorootparent> I just want an answer The issue is that AI is not at least yet accurate enough for that. You need think on your own and be expert to spot all the inaccuracies. But then again, we are talking about how students can learn based on that... reply add-sub-mul-div 4 hours agorootparentprevCalculators keep us from having to practice a certain skill and we accept whatever consequences of that, we've survived it. But yeah, imagine if the skill we no longer had to practice was critical thinking period. reply photochemsyn 4 hours agoparentprevSolve one problem with the help of a LLM, then solve three problems of the same type without the help of a LLM. Might need a human teacher to explain to the student why this approach is necessary, though. reply falcor84 4 hours agoparentprevBut does a typical teenager actually need to \"keep up in math\"? I would hazard a guess that only maybe 5% of people would need to ever utilize any math beyond basic algebra. Wouldn't it make more sense to leave these kids to do something else with their time, while offering personalized (possibly AI supported) math programs to those who actually intend to do something with it? reply tombert 4 hours agorootparentI think that number might be a bit higher if students had access to near-constant tutoring to answer any kind of questions that come up; I think a lot of kids get frustrated because they don't immediately get something and there isn't someone around to answer questions. Sample size of one, and obviously there's a million confounding variables here, but I think that my love of math stems from the fact that both my parents, and especially my dad, really loved math (and physics), and so whenever I had any questions about any aspect of math (at least up to calculus and differential equations), I could ask one of them for help pretty much whenever I wanted, and they would enthusiastically help me immediately, and eventually I grew to love it myself. Eventually I did well enough in math to where they gave me a test in school and I was able to skip two grades in it (going from 7th grade to 9th grade level). I ended up getting much more into discrete math and surpassed my parents in the more \"pure\" math. Even if my genetics were completely unaltered, I am quite convinced that if my parents weren't there to provide constant help then that wouldn't have happened. I think AI has the possibility of providing a comparable experience to what I had. It can patiently explain every aspect of math that any middle or high school student is likely to come across, and I think it has power to \"de-frustrate\" them as a result. reply empyrrhicist 4 hours agorootparentprevI teach people who thought this way, and later decided to enter a career that requires basic data analysis literacy. They struggle with things like order of operations, which is incredibly frustrating. Teaching math up to the high school/introductory college level is about building foundational skills that can be applied in different directions. Will they need to apply trig identities? Probably not, but the process of getting there in high school is good for their minds and foundational abilities. So yes, I'd personally say we should expect people to \"keep up in math\". reply Phiwise_ 4 hours agorootparentprevThose 5% go on to make an upper-class salary sitting in an air-conditioned office instead of a lower-class salary turning wrenches and stacking boxes. What makes more sense than enabling everyone who can to attain that life? (Plus every one of them who gets out makes life better for the rest at least by reducing downward pressure on wages, and hopefully also by creating new business opportunities that raise wages further by increasing supply. Rigorous education is almost always a win-win: https://matiane.wordpress.com/2021/09/15/democratic-educatio... ) reply falcor84 4 hours agorootparentSpeaking of AI, I wouldn't be surprised if, in the next decade, jobs that involve turning wrenches would pay significantly more than most jobs that can be done fully on a computer. reply Phiwise_ 3 hours agorootparentPerhaps, but only because most jobs done on computers today are by people who also have little if any math or programming ability. Change that and it's a different world to make those predictions in. reply viking123 2 hours agorootparentprevI mean wouldn't those blue collar jobs get more and more saturated then if office jobs get less and less pay so people start moving to those? Personally I very much respect people who do those jobs, but I could never do them because of my disability so my only good choice is pretty much computer related jobs or then it's back to some sort of government benefits. reply nicce 4 hours agorootparentp",
    "originSummary": [
      "Bill Gates commends Sal Khan's new book, \"Brave New Words,\" for its exploration of AI's transformative potential in education.",
      "Gates emphasizes the capabilities of OpenAI's GPT-4o, noting its lifelike interactions and potential as a personal tutor for students.",
      "Sal Khan argues that AI can enhance student outcomes and teacher experiences through personalized learning, with Gates recommending the book for its insightful predictions and practical applications in the classroom."
    ],
    "commentSummary": [
      "Khan Academy, founded by Sal Khan, offers free educational resources that have significantly impacted lives, including a high school dropout who pursued a career in AI.",
      "The discussion covers AI's potential and risks in education, highlighting concerns about misinformation, societal impacts, and the balance between AI benefits and drawbacks.",
      "AI tools like Khanmigo are examined for their cost and accessibility, with debates on AI's effectiveness versus traditional teaching, emphasizing the importance of motivation and human interaction in education."
    ],
    "points": 190,
    "commentCount": 224,
    "retryCount": 0,
    "time": 1716385193
  },
  {
    "id": 40434290,
    "title": "MIT vs. Stanford Startups: Tech Innovation vs. Market Strategy",
    "originLink": "http://fpgacomputing.blogspot.com/2013/11/the-stanford-startup-and-mit-startup.html",
    "originBody": "Reconfigurable Computing This blog is a notebook of my thoughts on parallel programming and accelerated computing. The instruction stream is deprecated: parallel programming is a spreadsheet. Tuesday, November 05, 2013 The Stanford Startup and the MIT Startup Message from a Jedi to a Young Padawan When I graduated and was considering pursuing startups, an alum from my fraternity gave me some advice. He was a successful entrepreneur and sent me a message about pursuing technology-oriented startups. He presented a maxim about an MIT company and a Stanford company building products for the same market. The Stanford company gets a product out quickly, they make money, iterate and then raise money. They use network effects to lock-in customers or viral growth tactics to get super-linear returns on marketing investment. The MIT company seeks to develop an unassailable technical advantage, optimizing their product or process in terms of kilojoules, units per second, and dollars. They either find a market-fit or sell their technology to the Stanford company. The dichotomy is between a focus on technology development and a focus on market development. Let me present an instance of this: two startups are selling environmentally-friendly ammonia (a real and big problem). The Pitch The MIT company: \"Our unique chemical process allows us to produce ammonia with no environmental impact for 10 percent less cost than competitors. We can modify our catalytic nanoparticle process for the production of perchlorates and sulfates, and dominate the industrial chemical supply industry.\" The Stanford company: \"We sell premium household cleaning supplies and fertilizer that are produced sustainably and good for the environment. We sell in stores and offer a monthly subscription model; receiving a package will remind you to clean up your house and water your flowers.\" Sales and Marketing The MIT startup has no sales to customers, but possibly a DARPA grant to develop their technology. The team has 9 PhDs and just hired an MBA to start finding customers. They believe their technical advantage using solar-powered nano-crystalline catalysts will enable them to lower the cost of production of commodity chemicals and therefore dominate the market. Their customers will be the major fertilizer, pharmaceutical and consumer product companies. Google for the company name and you will find a landing page. They are still \"in stealth mode\" while they finish up some R&D and production optimizations for their nano-particle production. Team MIT needs funding to develop a manufacturing facility (and to survive as a company). Their vision for sales and distribution involves hundreds of payments for tens of millions of dollars each year for shipment sizes that look like something out of The Wire or Breaking Bad. The Stanford startup has developed no new technology but has already validated its customer model selling sustainable branded cleaners and fertilizers at a local Whole Foods and Home Depot. Costs for sustainably produced chemicals are higher, but the founders maxed out their credit card buying a wholesale shipment and were able to sell a premium retail product at a small profit. They setup stands at farmers' markets to sign people up for monthly packages of cleaning supplies and plant food. After testing their market hypothesis, they decided to focus on cleaning products and limit marketing for the fertilizer product because that strategy generated more recurring revenue for less cost. Attrition rate for the cleaning product shipments is lower than growth and there are customers posting on the internet about how much they \"appreciate the hand-signed note thanking them for supporting their mission to spread sustainable production.\" They have thousands of monthly customers, they know their cost per customer acquisition and they know their average revenue per customer. Team Stanford think they could get millions of customers to pay them $9 a month for their product; which includes rags in addition to ammonia and bleach. They are still tracking a growing market niche for sustainable home food growing systems including plant food and seeds. They think viral marketing strategies will help them reduce their customer acquisition costs so they want funding to expand logistics and distribution in other regions and try some other growth strategies like advertisements, and letting people choose scents in-stores before placing an order. Investor Response The outcome for either of these companies is non-obvious. The MIT company claims to have the successor to the Haber-Bosch process, a chemical process technology that won its inventors Nobel prizes and was the foundation for what was once the world's largest chemical supplier. However, they want to enter an established commodity market and need to prove that they can scale sales from zero. Investors will need to vet the technology before they can fund the company. Investors look for \"order of magnitude better\" when vetting technology companies to determine if the technology is defensible. Very few investors will have an understanding of the chemical supply market and fewer still will understand the founders' PhD work optimizing production of ammonia using nano-particle colloids. They will also need a lot of funding before they can serve this market. On the other hand, the Stanford startup has traction in a market and will likely have a much easier time raising funding. Investors will understand their consumer market and they won't require technical vetting. It is unclear if their market position is defensible. Someone else can replicate what they do especially since there are no network effects where the total value of the product increases with more users thus creating market lock-in. However, they don't need much funding to grow their sales and they are looking to scale from a solid profitable foundation, which decreases the perceived risk to investors. The MIT startup could potentially be a $100B company in the chemical supply market. However, the Stanford startup can be reasonably valued at $10M today based on traction and will get term sheets from many investors. The MIT startup is much more speculative today and needs to find a wealthy individual to bankroll their first factory or take strategic investment from large potential customers. Conclusions There are many companies that fit both of these patterns and end up successful. The successful technology startups eventually develop a market approach. A lot of founders pivot from developing hi-tech to do entirely different market-focused ventures. Some founders have taken both approaches in separate companies and been successful at both. Conventional wisdom suggests the best startups develop technology and a market simultaneously. Many startups can operate with just a telephone and a spreadsheet on day one and then use technology to automate their operations. Technology is not a prerequisite for business success, but marketing is. Posted by Amir at 9:38 AM 25 COMMENTS: John Melonakos said... Great post and congrats on getting noticed by Hacker News for this one. I have a blog about accelerated computing too (http://notonlyluck.com) and you might be interested in following ArrayFire :) Good to be connected to you :) 10:11 PM Anonymous said... A really great post. thank you. 1:28 AM Anonymous said... Lame, idiotic stereotypes 12:42 PM Anonymous said... It's a bit of a ridiculous dichotomy, but I see your point. I like your post but would've liked it far better if it wasn't so superficial - as an MIT grad I would have expected some numbers and not just unproven claims. Moreover, calling yourself a \"jedi\" on the basis of founding one company that didn't raise seed is a bit of a stress. 1:33 PM Anonymous said... The MIT / Stanford dichotomy is interesting. Beyond that, an important point is that those heavy tech companies should invest earlier and heavier in market development. This investment will pay dividends in market acceptance and fund raising. And, they need to pay attention to the business model. Innovation in the business model, especially in the commodity space, is critical for new entrant. -Andrew 3:59 PM Unknown said... this hilarious youtube starring Nicola Tesla, pretty much sums up the state of affairs in Silicon Valley. http://www.youtube.com/watch?v=zngK13FMgXM 5:46 PM John said... I cannot attest to the MIT vs Stanford aspect (and it would be good to see some date to test this hypothesis), but we have observed this in the start-ups we try to move out of academic labs and incubators. The start-ups out of the lab are tech-heavy, can be hard to pitch but probably offer higher chance to make a fundamental change in a market - and a bigger impact. The accelerator-based, usually business model focused start-up, is easier to grasp, cheaper to fund and faster to market (or fail). For most investors the choice is simple - go the faster route. It also drives home the point that if you go have a heavily tech-based start-up, you need to find investors who know your space, have invested in it and understand the time and steps necessary to grow the business. You cannot convert investors over to your space. 7:31 AM myegyware said... a great hard work god bless you man 2:14 PM gwencon said... Good read! Oh, btw, for entrepreneurs who have great startup ideas but lacks funding, I suggest visiting iSeed.. It's an angel group who focuses to very early stage startup. 10:47 PM Franco said... Your last sentence was a great summary for what I needed to take away from your article. The two different approaches to market just happened to use two schools as examples ... that could have been replaced with GM and Ford, Oracle and IBM...Great read! 8:21 AM Unknown said... It’s my fortune to go to at this blog and realize out my required stuff that is also in the quality.cloud4computers 3:57 AM Anonymous said... Awesome work! That is quite appreciated. I hope you’ll get more success.Mr. Hugh 10:52 PM Anonymous said... I think FPGA is definitely the way to go but the competition there is pretty high so don't know about a startup there. Been reading The Design Warrior's Guide to FPGAs and FPGA is pretty good technology 9:44 PM Lea Paige Matteo said... How Lemeridian funding service grant me a loan!!! Hello everyone, I'm Lea Paige Matteo from Zurich Switzerland and want to use this medium to express gratitude to lemeridian funding service for fulfilling his promise by granting me a loan, I was stuck in a financial situation and needed to refinance and pay my bills as well as start up a Business. I tried seeking for loans from various loan firms both private and corporate organisations but never succeeded and most banks declined my credit request. But as God would have it, I was introduced by a friend named Lisa Rice to Le_meridian funding service and undergone the due process of obtaining a loan from the company, to my greatest surprise within 48hrs just like my friend Lisa, I was also granted a loan of $216,000.00 So my advise to everyone who desires a loan, \"if you must contact any firm with reference to securing a loan online with low interest rate of 1.9% and better repayment plans/schedule, please contact Le_meridian funding service. Besides, he doesn't know that am doing this but due to the joy in me, I'm so happy and wish to let people know more about this great company whom truly give out loans, it is my prayer that GOD should bless them more as they put smiles on peoples faces. You can contact them via email on {lfdsloans@lemeridianfds.com Or lfdsloans@outlook.com} or Text through Whatsapp +1-989 394 3740. 6:36 PM AIB FUNDING. said... I am very grateful to Elegant loan firm for helping me get a $ 600,000 loan with the helping of loan officer Russ Harry, and I will always be grateful. My life has changed, my money has been paid, I now own a business that I used to support my family. I am grateful to you, Mr. Russ, and God bless you. You can contact them for your financial assistance by e-mail: Elegantloanfirm@hotmail.com for your financial assistance. 9:20 PM Unknown said... Hello everyone, I'm Patricia Sherman in Oklahoma USA right now. I would like to share with you my experience of borrowing USD $185,000.00 to clear my bank draft and start a new business. It all started when I lost my house and I took my stuff because of the bank policy and I met some bills and some personal needs. So I became very desperate and started looking for funds in every way. Fortunately for me, a friend of mine, Linda told me about a credit company firm, I was intrigued by the fraud, but I was intrigued by my situation and had no choice but to get advice from my friend about this company. contacting them really doubted me because of my past experience with online lenders, did you know that little? '' Elegantloanfirm@hotmail.com This company has been very helpful to me and my colleague and today, thanks to this credit company, the proud owner of well-organized work and responsibilities, they smiled back at me. So if you really need to grow or start your own business, or if you really need to borrow money in any financial hardship, we recommend you find a financial development opportunity in your business today. {E-mail:} Elegantloanfirm@hotmail.com / whats-app number +393511617486.... online for credit not a victim of scam Thank you. 7:45 PM KITS Technologies said... Thanks for the blog article.Much thanks again. Fantastic. Cognos training Core Java online training Core Java training Django online training Django training Go Language online training Go Language training Hibernate online training Hibernate training Hyperion ESS Base online training 7:51 PM Rebecca Michaelson said... HELLO, I am Rebecca Michaelson by name living in Europe. Here is a good news for those interested. There is away you can earn money without stress contact (THOMAS FREDDIE) for a blank [ATM CARD] today and be among the lucky once who are benefiting from this cards. This PROGRAMMED blank ATM card is capable of hacking into any ATM machine anywhere in the world. I got my master card from a good Hacker on the internet, with this ATM Card I am able to collect $5000 dollars every day via contacts: +1 (985)-465-8370 {thomasunlimitedhackers@gmail.com} I was very poor but this card have made me rich and happy, If you want to get this opportunity to become rich and establish your business then apply for this Master card, I am so happy about this because i got mine last week and I have used it to get $240,000.00 dollars from THOMAS FREDDIE UNLIMITED Hackers is giving out the card just to help the poor and needy and they ALSO OFFER FINANCIAL ASSISTANCE. get yours from THOMAS FREDDIE UNLIMITED HACKERS today. Kindly contact them by Email thomasunlimitedhackers@gmail.com Thank You and God bless 5:51 AM scot frank said... GOOD CARD WITH COOL CASH...Get THE 2022 BLANK ATM Programmed Card and cash money directly in any ATM Machine around you. There is no risk of being caught, because the card has been programmed in such a way that it´s not traceable, it also has a technique that makes it impossible for the CCTV to detect you and you can withdraw a total sum of $5,000.00 USD daily,try and get yours today from (MR OSCAR WHITE ) of oscarwhitehackersworld@gmail.com And be among the lucky ones who are benefiting from it. Now email the hacker : oscarwhitehackersworld@gmail.com or Text/WhatsApp +1(330)-732-5665 4:06 AM Startup Bazzar said... Nice blog! Do you have an idea and want to start your own startup? Visit our website to know about Top 10 Valued Startups In India. This will help you decide which industry you want to start your business in and which city you want to base it in. For more details kindly visit our website. 4:27 AM Sruthi Karan said... Lovely post..! I got well knowledge of this blog. Thank you! Best Family Lawyer for Dads Child Support Virginia 5:21 AM Anonymous said... Yar she blows 5:14 PM Anonymous said... Fartfucker 5:14 PM Anonymous said... The Jedi is obviously the fraternity brother that gave him the advice. 5:25 PM Anonymous said... Yes, he seems like a Stanford grad 2:36 AM Post a Comment Older Post Home Subscribe to: Post Comments (Atom) RSS feed for this blog Blog Archive ▼ 2013 (1) ▼ November (1) The Stanford Startup and the MIT Startup ► 2012 (4) ► October (2) ► March (1) ► January (1) ► 2011 (7) ► October (1) ► August (1) ► March (2) ► January (3) ► 2010 (8) ► December (1) ► November (3) ► October (1) ► July (1) ► March (1) ► February (1) ► 2009 (5) ► November (1) ► August (2) ► July (1) ► March (1) ► 2008 (29) ► December (2) ► November (2) ► October (1) ► September (3) ► August (3) ► July (4) ► June (4) ► May (2) ► April (1) ► March (5) ► February (1) ► January (1) ► 2007 (7) ► October (1) ► September (3) ► August (1) ► April (1) ► January (1) ► 2006 (46) ► December (3) ► November (2) ► October (6) ► September (9) ► August (6) ► July (7) ► June (1) ► May (12) About Me Amir \"I have a blog about FPGAs\" is a terrible pick-up line. email: amir at zigfu View my complete profile External Links All About Electronics Scalable Atomicity Scalability Blog harry the ASIC guy Nadav's Tech Adventures FPGA and DSP from scratch Reconfigurable, Reconshmigurable Cloud N Multicore Blog at Cilk Arts The Techdoer Times business|bytes|genes|molecules ASIC-SOC-VLSI Design Blog Lead, Follow. or... Accelerated Times FPGA Central Thinking Parallel My non-RC Blog debits source trac Digital Electronics Blog Catalyst Accelerated Computing Source Trac Accelerated Computing Company Links Accelerated Computing Solutions Acceleware Acceloigc Achronix Altera Ambric AMD Celoxica Cilk Arts ClearSpeed Codetronix Convey Computer CriticalBlue DRC Exegy ImpulseC Intel Interactive Supercomputing Mitrionics mu-vision Nallatech Netezza nggrid NVidia Pico Computing Progeniq RapidMind Rapport SRC Computers Starbridge Systems Stream Processors Tilera Xilinx XtremeData",
    "commentLink": "https://news.ycombinator.com/item?id=40434290",
    "commentBody": "The Stanford Startup and the MIT Startup (2013) (fpgacomputing.blogspot.com)166 points by momofuku 21 hours agohidepastfavorite66 comments ben7799 4 hours agoThe article strikes me as somewhat OK but overly critical of the MIT startup and overly forgiving of the Stanford startup. Also prior to the mid 1990s it seems like the Stanford startup thing really hadn't begun yet. You look at the old guard of SV companies and they operated much more like east coast culture. To me it seems like the modern \"Stanford startup\" culture arose from VC money from the investors who made tons of money in the first .com boom. As someone who has spent my entire career in the Boston area (but have worked for SFBA HQed companies too) my perception has been that the MIT influence and the general cultural difference has some of the following elements: - East coast is much more conservative in business approach - Fake it till you make it is far less common here - For a long time it was unheard of for a Boston area company to try and go public or seek an exit without showing a sustainable, profitable business model - Companies here are basically never founded on breaking the law and hoping you become too big to fail and the law has to be changed - Way less focus on consumer tech here - Way less adtech influence (but that has grown) - Way less tech businesses based on trying to ruin traditional jobs and way less focus on trying to convert people to gig jobs. Some of the sports betting tech is here which is a black eye on the area IMO. There is some stuff in the Theranos vein that just seems like it would be very hard for it to have happened on the east coast. But over time now the east coast is being influenced by the Stanford culture and things are getting a little less conservative and a little more likely to be get-rich-quick and/or shady. reply alephnerd 4 hours agoparentI went to school out East and work out west, and consumer tech is way more of a NYC thing than a Bay Area thing because the personas and professional networks are out there. West Coast is also enterprise or business tech driven, but those founders aren't as media friendly or sexy despite being the majority (hence the Musks and increasingly Altmans hogging the limelight). Boston has potential, but it honestly isn't leveraging it. The elitism is rife to a level unlike in California. A NU, BU, or UMass Amherst founder isn't going to be in the same circles as the Harvard and MIT founders who can leverage the I-Lab or Engine and HBS+Sloan resources, but in the Bay Area, a UCB, UCSC, SJSU, and Stanford kid will all be in the same professional circles. CIC tried, but they are trash. At one point, most startups in Greater Boston were basically Israeli companies using it as a US HQ because of the El Al direct and the large Israeli diaspora (throw a rock and you'll hit a Cafe Landwer). Everything is tied up to elitism and old structure institutions out East (where did you study) while out West it's much more output driven (where do you work). Works well for it's biotech innovation space though, which Boston is known for. (ironically, I liked DC except the humidity - way less stick up their butt, but they also have a bohemian streak) reply neilv 2 hours agorootparent> The elitism is rife to a level unlike in California. Awhile ago, to students at MIT, I mentioned suspiciously \"MIT shop\" companies, and said that, if you don't think there's people at Northeastern who could hold their own, then recalibrate worldview. There's absolutely a lot of elitism around certain NE schools known around the world, agreed. Those schools actively promote it, and it's evident in some post-graduation things, including companies. But I also see variations on that elitism around Stanford, Google, and some other Bay Area icons. One difference between the elitism I notice most commonly around MIT, and around Bay Area, is that MIT's version is often about having survived a trial by fire, and being uniquely stronger due to that (not that I fully agree). Bay Area versions more often come across as less-secure reaching for and clinging to symbols of status, and nurturing artificial frat-like exclusivity. (Clinging to Leetcode hazing rituals is just one example.) Of course, on an individual person level, you'll find a lot of smart and thoughtful people who don't subscribe to the elitism -- maybe the majority of people who could claim the same exclusive club as the elitists. And some of the smartest people are the most humble in thought and manner. But elitism does seep into a lot of things. I suppose that club elitism might also be involved in some of the more arrogant actions you see affecting large swaths of society, separate from money/power motivations. The Bay Area sure does have a lot of that arrogance, sometimes labeling it \"disrupt\". (But maybe most often \"disrupt\" is more about grabbing money/power, than a genuine but arrogant belief that one can and should make decisions for society. Maybe all that matters to some is that they can, and anything else, like \"changing the world [for better/worse, who cares]\" is rationalization that's been blessed as virtuous.) reply alephnerd 1 hour agorootparent> But I also see variations on that elitism around Stanford, Google, and some other Bay Area icons. Absolutely! And no place is without it's elitism. It's just annoying that Boston's is based on a specific identity that cannot be absolved (where you went to school for elementary, high, then college) versus something that adults have some autonomy to define (Cambridge and Somerville was much more refreshing, but the same issues persisted underneath). That said, everyone should cut people to size whenever any form of elitism arises. It's all bullshit, we make good money - what's the point about clinging to a specific identity. reply 3dworldrunner 3 hours agorootparentprevHaving gone to university in Boston at a few different institutions, this is completely true. It's in the water. I think a lot of people never get out of the mindset, either. reply gottorf 3 hours agorootparentprev> throw a rock and you'll hit a Cafe Landwer Are those new to the area? I don't live there anymore, but I spent a decade in Greater Boston and have never heard of this. reply alephnerd 3 hours agorootparentThey aren't that common (only 3 I think), but they're a very Israeli brand and the only other North American city with a similar number is Toronto (not even New York). New York is fairly Jewish but not really Israeli, but in Boston the Jewish community is very Israeli. reply tpetr 2 hours agorootparentprevhonest question, what's wrong with the CIC? reply alephnerd 1 hour agorootparentIt's been sometime since I was there, but it felt like it tried to be a South Park Commons style salon, but promising founders in the Software and Hardware space had plenty of better options like Engine or I-Labs, or moving out West to join YC or SPC. I've noticed UAV/Autonomous/SpaceTech (UAE and Saudi are on a buying streak rn) and Biotech (unsurprising) startups do fairly well in the Boston scene. reply neltnerb 1 hour agoparentprevI would say that MIT has jumped on the entrepreneurship train (for better and worse) much more wholeheartedly in the decade since this account of an even older (!) anecdote. That's not to say that the startups aren't doing hard tech and they're still different than west coast startups. However, scientists are perfectly fine at using the scientific method for business development once you explain it to them and are much smarter about getting initial revenue and market validation and know perfectly well it's important -- if you mentor them even a little bit. MIT started working much harder to explain this in the mid '00s when it truly was much more like what this story says. reply alephnerd 1 hour agorootparent> I would say that MIT has jumped on the entrepreneurship train (for better and worse) much more wholeheartedly in the decade since this account of an even older (!) anecdote. Also, a lot more west coasters (like me and my peers) started coming out to Cambridge for school this past 10-15 years after Stanford, USC, UCLA CS/Anderson, and Berkeley EECS/Haas became increasingly difficult to get admission into. I have plenty of Harvard and MIT friends who were rejected by those 4 programs despite being Californians. > if you mentor them even a little bit. MIT started working much harder to explain this in the mid '00s when it truly was much more like what this story says. Yep! Programs like Engine helped, and I-Labs across town at Harvard as well, and YC ofc had its origins in Cambridge. reply hberg 20 minutes agoprevThere are major cultural differences between these schools that the article doesn't touch upon. Having presented business/product ideas to classmates & colleagues at both schools, here's a gross simplification of responses I've experienced: Me: I have an idea for \"foo\" MIT reply: \"Here's a list of 10 reasons why that won't work\" Stanford reply: \"That's neat, and here's 10 reasons you should work on it\" One might see the Stanford response as unrealistic or patronizing, but one of these creates a culture of positive ideation (and hustle-culture startups) while the other leads to a lot of discouraged entrepreneurs. reply zinodaur 3 hours agoprevThe MIT startup is like a breath of fresh air - a company that is actually doing something! Stanford style startups are a way better way to make money - but I wish people would just stop making them. Filling the economy with parasitic middle men hasn't worked out too well for us. reply jobs_throwaway 2 hours agoparentWhat about the tech economy hasn't worked out well? Americans and tech workers in particular have never been better off reply sterlind 1 hour agorootparentThe enshittification of the Internet? Search results overrun with SEO, internet-connected dishwashers, toxic social media full of dark patterns, discarded Juuls littering the streets, ads on paid streaming services that cut half their content because of mergers, meanwhile the planet is burning. Yes, there's a burgeoning middle class of engineers who design those Juul pods and build those ad networks, but imagine if all those people were hard at work engineering desalination plants and better batteries. Imagine if that paid better. reply jobs_throwaway 1 hour agorootparentThat all sounds dramatically preferable to an economy that follows what you suggested and companies like Google, Facebook, Netflix, Salesforce, etc etc don't exist because we haven't solved desalination yet reply zackmorris 22 minutes agorootparentprevI almost can't tell if you're trolling. If we look at quality of life metrics like the percentage of work hours required to rent or buy housing, then it takes about 1.5 times more hours worked to live today than it did in the 1990s when I was a young adult: https://www.motherjones.com/kevin-drum/2018/05/raw-data-rent... https://www.manausa.com/blog/wage-inflation-home-affordabili... see \"Wage-Adjusted Monthly Mortgage Payments\" section Because housing costs keep going up while median wages have been stagnant since the turn of the millennium: https://www.cbpp.org/blog/census-income-rent-gap-grew-in-201... The last affordable years were around 1994 before the internet arrived, 2012 during the middle of Obama's terms and maybe 2020 during the pandemic. But we've had so much corporate greed inflation to save the rich from losing any money for the 2 years that workers took off during covid-19 that any income gains by labor have been completely wiped out. $15 hourly wage? What a joke. Sure, we have fancier video games, smart phones and even passable AI. But I can tell you straight up that in 1994 we had no concept for the level of anxiety that people live under today. I feel awful for young people born after that who think that whatever all this is is how it always was. Had wages kept up with inflation and trickle-down economics not happened, so that the wealthy paid their fair share of taxes and we had the government services we're due like free public education and healthcare, the inflation-adjusted median US income would be twice what it was in 1994 and 3-4 times what it was in the 1970s. Well over the $70,000 mark where happiness peaks and more money provides diminishing returns. In other words, we could work for 3 months of the year and more than afford everything we have now, including savings and retirements. But the wealthy keep us down and divided because the highest profits come from struggle and war. The financialization of tech under the Stanford model widens wealth inequality. I can't even imagine how many things would be fully automated and approaching free by now had the MIT model kept the pace of true innovation at 1960s and 1980s levels in areas like pharmaceuticals, genetics, miniaturization and other pure research. Instead we have 2 day shipping and privatized space travel, which are cool and everything, but people are homeless and dying of starvation all around the world and on our watch in proxy wars. Words like travesty don't even begin to capture how far astray we've gone. reply danjl 2 hours agoprevThe Stanford startup looks AMAZING for five years, and then, after getting hundreds of millions in investment, they realize they are only making tens of thousands in revenue, everyone starts fighting, friendships and money are lost. Meanwhile, the slow growing MIT company discovers a tangential product while developing their technology. They release the pivot product which slowly grows revenue. They build under revenue, never take investment money, and share revenues. Everyone gets rich and stays friends, and the VCs get nothing. reply ijidak 49 minutes agoparentI'd love to see the cumulative collective market cap of MIT founded companies vs Stanford companies. My guess is that Stanford founded companies would win. I'm an MIT grad myself. But I've noticed the incredible productivity of startups coming out of the Bay Area. Though, not sure how much of that is Stanford grads specifically as opposed to other schools in the area (as well as graduates from schools around the country who flocked to the Bay Area). reply amirhirsch 39 minutes agorootparentMIT companies in aggregate don't add up to a Google. ChatGPT did a pretty good job with these prompts and renders a pie chart with outdated valuations. Chat sharing doesn't work with the embedded pie charts, here are the prompts: \"Can you produce a pie chart of the top 10 most valuable MIT companies?\"\"Can you produce a pie chart of the top 10 most valuable Stanford companies?\" (Elon Musk went to Stanford for two days so it counted Tesla.) reply neilv 14 hours agoprevThe article names its archetypes not entirely fairly, based on my experience at three MIT startups. Two were novel-tech academic spinoffs, and the third was alumni applying/integrating COTS tech driven by customer problem domain. Of those three, two were business-thinking much like the article's \"Stanford\" archetype. The other had, like the article's \"MIT\" archetype, a period to develop tech from the lab, and a challenging changing of gears to be cutting-edge product-driven. Also, a fourth MIT startup, which I recently almost co-founded, even before I joined the nascent team, the inventor-CEO had already done impressive customer-oriented legwork, and found Bay Area advisors, more like \"Stanford\" in the article. > The team has 9 PhDs and just hired an MBA to start finding customers. This is a problem, if none of the PhDs happen to have non-academic strong experience in product, nor in industry team engineering. An academic environment will tend to make people think they know more than they do, about things academia doesn't know. Also, academic degree and career paths in some ways reward the opposite of how I think people in a startup, or other effective company, should be thinking. (Unless the startup is more the VC growth investment scheme kind, which can be mostly about appearances.) One MBA (even if very experienced) probably can't, by themself, counterbalance all those experience gaps, nor those lessons to unlearn. > The MIT startup has no sales to customers, but possibly a DARPA grant to develop their technology. I don't know about the more involved DARPA grant-writing, but SBIRs do seem to be popular seed-ish funding: https://www.sbir.gov/ reply sybercecurity 5 hours agoparentSBIRs can be a good first set of funding. Some agencies go with $100k for six months, so win a couple of grants and you are doing pretty good. The problem is that some agenices have different criteria, forms, etc. so just because you jumped through the hoops for one funding source, it doesn't automatically translate (government does love their paperwork/processes). Some programs are specifically designed for commercialization and want to see a product available at the end. There was a big shift to that post 9/11 (sometimes called \"little 'r', big 'D'\": less research, more development. reply Symmetry 2 hours agoparentprevSBIRs can be useful, but they can also be a trap where a company just keeps going after SBIRs and never takes the technology to market. reply choppaface 13 hours agoparentprevAnd Google is a pretty good counter-example to “The Stanford startup has developed no new technology” reply Nevermark 2 hours agorootparent(Google is huge, and does real tech, i.e. advances in deep learning. The following only applies to their search startup phase.) PageRank was innovative, and had great \"market fit\" (or \"user fit\", prior to ad revenue), but wasn't very deep as technology goes. Google's (original) business success came from leveraging that into a three-way network-effect as the middleman connecting web content users, web content providers, and web advertisers. Even today, PageRank's successor algorithms appear to be aimed more at ad revenue optimization than improving search as a technology. Likewise. Netflix, Facebook, Expedia, Spotify, Uber, Airbnb, ... use tech as operations, it is not the product. Their primary defenses are not unique technology, but network effects, customer information lock-in, and other market-side moats. They have great technical people doing great work. But a high proportion of their innovation is aimed at their own operations, customer engagement, etc., not creating and offering new technology. -- Technology first companies typically end up as part of a supply chain. nVidia is a good example They have become huge, but are still a parts maker in a lot of ways. They have created a sticky ecosystems, but their primary work and moat remains keeping up a relentless technological cadence. Another example was Amazon. They started by adapting others' tech to create an online store. But instead of simply optimizing that, they fully developed distributed computing as a service, and spun that out as its own business. Now they are a provider in other companies' supply/resource chains. reply beowulfey 6 hours agorootparentprevI don't think these archetypes apply to the mid-90s Stanford/MIT scenes reply jjssmith 6 hours agorootparentprevAFAIK, the Markov chain page ranker existed before Google (Jon Kleinberg's papers, e.g.), what Google paper added were some smaller bells and whistles, like using the text description of the hrefs. reply gregshap 5 hours agoprevI remember this article was extremely eye opening for me as a recent grad in 2013 Boston. I think it's hard for people to understand today how much less the ideas like lean startups, Paul Graham essays, customer validation, etc had penetrated software engineering mindset in early 2010's, at least outside of SFBA. reply CuriouslyC 4 hours agoparentAnd here we are 11 years later with people cargo-culting all those things. I once overheard someone seriously suggest building a MVP for a game in an established genre. reply humansareok1 4 hours agorootparentThis actually works though. Pre-Alpha games get limited releases on Steam and can raise millions that can be used to finish and polish the game. reply CuriouslyC 3 hours agorootparentAs an avid gamer, I can tell you that early access games that are too early don't do well unless they're made by someone famous. Early access works well with games that are released in a semi-polished state - Hades is probably the poster child for a well executed early access. reply bsaul 17 minutes agoprevFunny how MIT sounds like europe in this example.. reply PaulHoule 5 hours agoprevI remember going to a conference at Stanford and I overheard more than one group of students talking about Sam Altman. Around Cornell I hear a lot of conversations of students who, on the other hand. think getting ahead is getting ahead in academia. I definitely find grad students are interested in hearing about adventures in startup land but they aren’t steeped in that the way Stanford students are. reply anamax 16 hours agoprevThat comparison ignored the part where MIT (the University) screwed the deal. Things are changing, but startup in MA are playing hard-mode and don't get any extra points for doing so. reply zachthewf 16 hours agoparentDon't get it twisted—the MIT Startup is still based in SFBA reply dang 18 hours agoprevDiscussed at the time: The Stanford Startup and the MIT Startup - https://news.ycombinator.com/item?id=6715864 - Nov 2013 (85 comments) reply divtiwari 13 hours agoprevI don't know why, but as a non-American, this seems to be more of a Nerd vs Jock kinda thing. Am I correct in my interpretation? reply dfedbeef 13 hours agoparentYes. reply Animats 13 hours agoprevA 10% projected improvement in a bulk chemical process isn't that useful unless you're already in the industry. It's not enough to justify entering the industry. 2x, though... reply amirhirsch 12 hours agoparentThe real company that this was based on probably projected beating the cost of the equivalent Haber-Bosch industrial setup but ultimately couldn’t reduce the nanoparticle production costs and pivoted to selling nanoparticles. I think the best “carbon free” ammonia is still 50% more expensive than the cheapest ammonia, but there seems to be continuous research into promising methods. I’m not a chemical engineer though, and do not know how to qualify research, but this recent article from a Stanford group was intriguing: https://news.stanford.edu/stories/2023/04/ecofriendly-ammoni... A similar area with a ton of interesting research is sustainable production of silicon where current smelting uses carbothermic reduction of silica in an arc furnace reply Animats 11 hours agorootparentTotal world silicon production for ICs isn't that big. It's about 9 million metric tons / year. Steel production is around 2 billion metric tons / year. reply selimthegrim 8 hours agorootparentprevThere has been some recent work from KAUST calling the Stanford work into question. reply yencabulator 2 hours agoparentprevIt was also \"no environmental impact\", though. reply jeffreyrogers 3 hours agoprevThere's another type: the Stanford Startup that can't find product-market fit so it markets itself as an MIT Startup. reply lenerdenator 5 hours agoprevMy insomniac brain automatically filled in \"prison experiment\" after Stanford, and then I started to think, what if startup-VC-founder-unicorn culture is all an elaborate psychology experiment? reply dirtybirdnj 2 hours agoparentshhhh don't say the quiet part out loud reply lenerdenator 1 hour agorootparentSorry, Dr. Zimbardo. reply ijidak 46 minutes agoprevHas anyone seen stats on the cumulative collective market cap of MIT founded companies vs Stanford companies? I'd love a database of companies and their public valuations, tagged by the schools of the founders. My guess is that the market cap of the Stanford founded companies would beat those of the MIT founded companies. I'm an MIT grad myself. But I feel, given MIT's prominence as a tech institution, the cumulative market cap of MIT founded companies would be surprisingly small. reply chillingeffect 6 hours agoprevAs an east coaster the MIT startup hypothesis tracks very well. It's not just MIT but most startups out here i've been involved with. They're generally moonshots of tech, \"guaranteed\" to sell bc you have to buy bc the tech is superior. :) Since following HN years back i've been trying to speak up at these companies with ideas like building a brand, market test-fit, etc and been given the cold stare. Thanks to this article I now see it's cultural. Typically these founders have relevant experience in their field, so they \"know\" there's a fit without testing and prefer to remain in stealth mode until the big reveal. reply jprete 5 hours agoparentMarketing, sales, market testing, and doing what customers want are inherently messy processes. I think people who spend too much time immersed in purely technical work start to think that messy processes are inherently wrong, because there are no definitive right answers. Probably the best thing to do would be, at the university level, to give engineers more business experience and marketing/sales types more concrete-problem experience. But that would be vocational, and I think universities systematically dislike seeing their work as vocational training. reply banish-m4 13 hours agoprevAvoid being a cliche by hustling and bring something awesome with tech too. The two aren't mutex. reply light_hue_1 16 hours agoprevAs true today as it was back then. At MIT the atmosphere is around hard tech startups. That's even what the MIT accelerator specializes in https://engine.xyz/ reply amirhirsch 16 hours agoparentAuthor. Anantha Chandrakasan mentioned this essay at a launch event for The Engine. He was my boss when I was a TA :) reply choppaface 13 hours agorootparentDoes the article draw on “worse is better” ? https://www.jwz.org/doc/worse-is-better.html reply DonHopkins 3 hours agorootparentThere's also the corollary East Coast Lisp / West Coast Lisp dichotomy. https://news.ycombinator.com/item?id=39583305 [...] Leaning hard into the IDE (or ChatGPT these days) because your language design is flawed is a hella/totally stereotypical \"West Coast\" thing to do, as described in \"Evolution of Lisp\", \"Worse is Better\", and \"History of T\", and exemplified by Interlisp and Warren Teitelman's \"pervasive philosophy of user interface design\" and implementation of \"DWIM\". https://en.wikipedia.org/wiki/DWIM https://www.techfak.uni-bielefeld.de/~joern/jargon/DWIM.HTML https://escholarship.org/uc/item/6492j904 If your language isn't terribly designed, then your IDE doesn't have to be such a complex non-deterministic Rube Goldberg machine, papering over the languages flaws, haphazardly guessing about your intent, \"yelling at you\" all the time about potential foot-guns and misunderstandings. As you might guess, I'm firmly in the \"East Coast\" MacLisp / Emacs camp, because that's what I learned to program in the 80's. I can't stand most IDEs (except for the original Lisp Machines, and Emacs of course), especially when they keep popping up hyperactive completion menus that steal the keyboard input focus and spew paragraphs of unexpected boilerplate diarrhea into my buffer whenever I dare to type ahead quickly and hit return. But my point is that you can have and should demand the best of both coasts, unless you start off with a Shitty West Coast Programming Language or a Shitty East Coast IDE. [...] reply thefaux 3 hours agorootparentThe problem is that west coast programming languages/ides are easier to sell. It genuinely pains me how accurate the original worse is better essay is. reply scherlock 18 hours agoprevMight as well called Stanford B2C and MIT B2B. Yeah, B2B needs more capital since they are building a plant while B2C is really about sourcing materials, packaging and marketing. Completely different businesses, different CapEx and OpEx models, different risks and different investors. reply byyoung3 18 hours agoparentI thinks it’s more hard tech vs traditional startup. reply hehdhdjehehegwv 17 hours agoparentprevYes, it’s apples to oranges, I don’t really see much value in the analysis. reply alphazard 18 hours agoprevWhat is (maybe better left) unspoken are the kinds of errors attributable to both strategies. The really great tech that never makes it to consumers and is lost, only to be rediscovered years later--MIT. Garbage software that consumers are tricked or forced into using--Stanford. reply photochemsyn 17 hours agoprevIntellectual property generated at universities that accept any taxpayer funding whatsoever should belong to the taxpayer, meaning any US citizen should automatically have access to that IP under a free non-exclusive license. If you don't like this, tell the billionaires to go back to funding private research centers (e.g. Bell Labs) and they can own all the IP generated there outright. Otherwise, it's just a ripoff of the taxpayer by state-subsidized 'entrepreneurs' which makes a mockery of the whole free-market capitalist competition system they claim to support. Ultimately, we end up with a system of aristocrats gambling at casinos who are given government bailouts every time they make a stupid bet - which is not sustainable over the long run. reply vineyardmike 14 hours agoparent> Intellectual property generated at universities that accept any taxpayer funding whatsoever should belong to the taxpayer Not everything generated at a university that takes tax money is government owned, but everything the government funds is available to the government. > private research centers (e.g. Bell Labs) Companies like Google or Apple have been funding tons of research. I worked for a government research lab doing medical research. The research being done for the Apple Watch was miles better than ours, because it had way more funding. Further reading: https://en.wikipedia.org/wiki/Bayh–Dole_Act reply triyambakam 18 hours agoprevI find this kind of rhetorical device tiring to read when it goes on and on like this. Once I read the conclusion I felt like I'd be cheated and it could have just said that in the beginning. reply dfedbeef 13 hours agoprev [–] Wow so finance school startups and engineering school startups are different? reply alephnerd 4 hours agoparentStanford isn't a finance school. CS and Human Bio/Pre-Med have been the 2 biggest undergrad majors on campus for a decade+ now. Finance is an East Coast and Chicago thing placement wise, because West Coast High Finance collapsed in 2008. reply dfedbeef 13 hours agoparentprev [–] Don't @ me I went to a SUNY reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post contrasts two hypothetical startups from MIT and Stanford, focusing on their differing strategies: MIT's emphasis on technical superiority and Stanford's focus on rapid market entry and customer acquisition.",
      "Investors tend to prefer the Stanford model due to its market traction and understandable consumer model, highlighting the importance of balancing technology development with market strategies for startup success.",
      "The discussion underscores the dichotomy between technology development and market development in startup strategies, with mixed reactions from readers."
    ],
    "commentSummary": [
      "The article contrasts the startup cultures of Stanford and MIT, highlighting Stanford's aggressive, VC-funded growth model versus MIT's conservative, sustainability-focused approach.",
      "Stanford's influence is shifting East Coast practices towards more aggressive business models, impacting professional dynamics and entrepreneurial morale.",
      "The tech economy's growth has led to wealth but also societal issues like environmental degradation and economic inequality, prompting a critique of profit-focused models and advocating for integrated business and technical training in universities."
    ],
    "points": 166,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1716327335
  },
  {
    "id": 40434766,
    "title": "Why Clear, Readable Code Outshines Clever, Complex Code",
    "originLink": "https://read.engineerscodex.com/p/clever-code-is-probably-the-worst",
    "originBody": "Share this post Clever code is probably the worst code you could write read.engineerscodex.com Copy link Facebook Email Note Other Discover more from Engineer’s Codex Explaining tools and technologies used and created by big tech companies. Become a smarter software engineer in just 7 minutes a week. Over 25,000 subscribers Subscribe Continue reading Sign in Clever code is probably the worst code you could write And clear, readable code is probably the hardest code to write Nov 20, 2023 60 Share this post Clever code is probably the worst code you could write read.engineerscodex.com Copy link Facebook Email Note Other 9 Share Engineer’s Codex is a free publication about real-world software engineering. I write about real-world technical case studies, outages, and interesting stories from the industry. Subscribe When I was an undergrad, Leetcode broke my brain. I would see top solutions of esoteric one-liners and wrongly think “how do I ever get this good?” What does this even do? This is commonly called “code golfing”. It’s a fun hobby, but very far from “good code.” Everybody (including those on Leetcode) knows this isn’t good code. In the industry, it’s the worst code one could write. However, on the other end of the spectrum, I realized eventually that the clearest code was actually the hardest to write. It made sense retrospectively. Reviewing the code of a senior staff software engineer was much easier to follow and review compared to the code of an entry-level L3 engineer. Subscribe Clear code: the good and the bad The “power” of clear code, for better or for worse, was made fully clear to me after a certain incident at work. I once wrote a data enrichment module in C++, a language that is generally harder to read compared to other languages simply due to its verbosity. I started with just two files (.h/.cpp) and all the implementation code went into just these two files. The result was this giant, disgusting piece of spaghetti on the inside, but a perfectly working program on the outside. This would never get past code review. xkcd 1513 I split the implementation into 30+ diffs. At the time I was working at a company that used stacked diffs. (This also happened to be my personal record for length of chained diffs, so I was pretty proud of the following outcome 🙂). Each diff was a neat, containerized piece of code, with convenient placeholders for dependencies that would arrive in a later diff. It had code neatly split out into helper functions and helper files when necessary. Each diff had reasonable unit test coverage - the basics and some obvious edge cases were covered, but I didn’t go wastefully overboard with it. Each diff also took me quite a few iterations of “code cleaning,” refactoring, and more. It took a lot more effort than I expected to achieve “clear code,” especially for such a large program. The result? A beautiful landing of the data enrichment module, with easy to read, clear code. While I was proud of it, there was suddenly a problem when I talked to my manager about it. “While I understand how complex this was, when it comes to performance reviews, this code looks trivial. It looks too easy, too simple. I would recommend writing an implementation doc of this module just so we can demonstrate that this was actually quite complex.” I was shocked - this wasn’t some startup. This was one of the biggest companies in the world, known for their engineering culture. I now understood why Big Tech seemingly had so many docs — half of the docs I wrote didn’t need to be written, except they did… because I wanted to get raises and be promoted. While promotion culture in Big Tech is a story for another article (subscribe to see it in your inbox soon 🙂), the main point here is that great code is very clear and readable. Subscribe There’s a popular saying that debugging code is twice as hard as writing it. It’s the reason why when ChatGPT outputs some hogwash, it’s easier just to re-prompt it or write it from scratch yourself instead of trying to figure out the errors in its buggy code. Clever code is harder to read and looks esoteric. Clear code is harder to write and looks easy. Some other thoughts about clear code Work Chronicles! I love their comics. (Source) The only way I got better at writing clear, readable code was just writing a lot of code while strictly following a clear style guide. Also, having more experienced devs review my code with a magnifying glass. It was agony to get tons of comments and “nits” about seemingly pointless style in the beginning, but it paid off in the end. Coding style is more important than I expected in the beginning. My start to software engineering started from being on the product-minded end of the spectrum and moved towards the “technical-minded” side of the spectrum. I had started coding solely to start a business, so I initially only cared about code as a tool, resulting in crappy, unmaintainable code. It’s only through more experience with writing code and working within teams that the importance of clear, readable code became more obvious. It’s not just me. This is an obvious revelation to anybody who has been writing code in the industry for more than a year. John Carmack once wrote a long email about coding style in 2007, which is an interesting read. Google probably has the most public style guide. Vercel also recently released their style guide, and pretty much every company uses some sort of linter and prettifier. One last note My friend Jordan Cutler, who writes the popular High Growth Engineer , is holding a course: Mid-level to Senior for high-growth engineers. I’m a huge advocate for Jordan - he’s an extremely kind, driven, and encouraging friend. If you’re interested in growing as a software engineer, I would highly recommend his course. Engineer’s Codex is a free publication about real-world software engineering. I write about real-world technical case studies, outages, and interesting stories from the industry. Subscribe 60 Share this post Clever code is probably the worst code you could write read.engineerscodex.com Copy link Facebook Email Note Other 9 Share PreviousNext",
    "commentLink": "https://news.ycombinator.com/item?id=40434766",
    "commentBody": "Clever code is probably the worst code you could write (2023) (engineerscodex.com)158 points by rbanffy 20 hours agohidepastfavorite175 comments jbandela1 19 hours agoI think “clever” is more related to unfamiliarity. There is actually a lot of cleverness going on that people just become familiar with. Structured programming is actually very clever if you think about it. Function calls are, when you look at it closely, very clever. It encapsulates how to jump to a function entry point, how to pass on values in registers or in memory, how to adjust stack pointers, and all other sorts of cleverness. For loops are clever with different parts of the statement controlling and executing different parts of the loop. Compare that with BASIC A six year old child can understand: 10 PRINT “Hello” 20 GOTO 10 Going on to object oriented programming, dynamic dispatch and v-tables are clever. What you call and where you go to in your program are determined by the dynamic type of an object. This is very far from the simple BASIC GOTO What difference does looking at it like this make. First we don’t reject automatically reject new concepts just because they aren’t simple. While function calls are complex, they bring many benefits. In addition, this approach emphasizes the role of education to in taking useful concepts and making them familiar to a broader group of people. reply HarHarVeryFunny 19 hours agoparentI think there's a difference between \"clever\" and complex. You can express a complex algorithm or pattern with simple easy to understand code - complexity doesn't have to manifest itself as unreadable or incomprehensible code. To me \"clever\" code is more about they way you are doing something than the complexity of what you are trying to do. Clever is the opposite of straightforward and easy to comprehend without a detailed explanation. For example you might be \"forced\" to write clever code as an optimization to calculate something in a non-obvious way, maybe also based on some non-obvious pre-conditions that have been assumed and make this a valid approach. You don't normally want to write \"clever\" code - you want to write easy to understand straightforward code, and on the occasion when you feel compelled to a clever implementation, for the sake of future you or your teammates, you better precede it with a block comment prefixed with \"here be dragons\" and a detailed explanation of what it is doing and why it is doing it in this non-obvious way. reply dotnet00 19 hours agorootparentI also prefer this perspective. I had an epiphany about this sort of code when I was trying to describe what my code did for a research paper, and in trying to express why I was proud of it, I called it complex, only for my research advisor to point out that complexity was not the point of the work, so calling it complex did not convey what about it made the research interesting. Although it wasn't his intention, it changed my perspective on the \"clever\" tricks I liked using, since it made me realize that being clever was not the kind of complexity that mattered. So, nowadays I try to write simple, easy to understand code, leaving the cleverness and complexity to the way the problem is tackled. reply SOLAR_FIELDS 3 hours agorootparentJust to codify this with some examples: Here’s some recent examples of what I consider “clever” that I’ve had to work with from previous people and that I’ve written myself: Someone who loved Lisp wrote a bunch of the unit test suites where I work using Python in a very clever metaprogramming way. They would dynamically generate and attach functions to a test object for testing REST requests. This is both 1. Difficult to read and understand 2. Much more difficult to test the behavior of All to save probably maybe 100 lines of code. This is an example where I feel like code is too clever for its own good without having a good reason to be like that. It also flies in the face of what you would conventionally expect when it comes to Python unit test suites. One example where sometimes it’s necessary to be clever: I did a db migration in about 100 lines of Python/SQL that worked fine at small scale using Alembic/Python/SQL and was a straightforward update with CTE. When tested on large production grade dataset however it completely fell apart. Some clever hacks with batching and temp table later and I have something runnable, but now it’s all in sql and while well commented is much harder to grok what’s going on at first glance. reply dkarl 16 hours agorootparentprev> You don't normally want to write \"clever\" code - you want to write easy to understand straightforward code I think what the parent comment is getting at is the relative nature of \"clever\" and \"straightforward.\" At certain times and in certain programming communities, use of deep inheritance hierarchies was \"straightforward,\" and passing a function as a method parameter was so \"exotic\" and \"clever\" that languages didn't directly support it. reply _heimdall 17 hours agorootparentprevI've always considered code to be \"clever\" when its using something in a way it is rarely used, and usually specifically with something very common like an arithmetic operator. I've seen some really clever code using arithmetic operators to flip variables in ways that look like magic at first. I've also seen, and used myself, a few similar kinds of tricks in JavaScript especially when working with booleans. I never really considered code \"clever\" when its just unreadable or incomprehensible. IMO that's just bad code. reply bexsella 17 hours agorootparentprevI work with embedded DSPs, and there are certainly points where the maths gets incredibly dense and hard to intuitively parse. Your last point has proven true for me many times. Luckily, with the exception one block of code, the maths is detailed plainly above the implementation. So, while there might be an occasion where I might not fully understand what's going on, I can see where the original author of the code was coming from, and can follow the following code accordingly. Indeed, I believe one of the comment blocks does start with \"Here be dragons\". reply jiggawatts 17 hours agorootparentprevWe've built modern computing on top of encapsulated cleverness. I don't mind clever code, as long as it's a polished gem set into a nice abstraction hiding away the details. Databases have clever code in them. Network stacks have clever code. Heap allocators have clever code. We've built our simple code on top of these. If you need some clever code, write it in the same style: a self-contained library with clean abstractions and thorough documentation. Whatever you do, never \"weave\" clever code through simple business logic! reply rightbyte 12 hours agorootparent> Whatever you do, never \"weave\" clever code through simple business logic! Oh I love that blog series. reply intelVISA 16 hours agorootparentprevClever is simple, complexity is The Enemy. reply ekzy 19 hours agoparentprevYes. A relevant quote from Alan Kay in his talk “the power of simplicity”: > one of the things that's worked the best the last three, or four hundred years, is you get simplicity by finding a slightly more sophisticated building block to build your theories out of. its when you go for a simple building block that anybody understand through common sense, that is when you start screwing yourself right and left, because it just might not be able to ramify through the degrees of freedom and scaling you have to go through, and it's this inability to fix the building blocks that is one of the largest problems that computing has today in large organizations. people just won't do it https://youtu.be/NdSD07U5uBs reply P_I_Staker 1 hour agoparentprevYes, but people are widely familiar with certain concepts. Hating \"clever code\" doesn't mean hating any abstraction or good elegant ideas (like function calls). The thing is that this stuff has already been in circulation for so long, and many of the good ideas have been found. If you tried to come up with new solutions for function calls, people would understandably be skeptical. reply mianos 18 hours agoparentprevIt's not this and there is a test: Judging something assumes at least a minimal level of expertise in both the domain and language. I don't know Ruby, a lot looks obtuse, that's not a sign of clever code. If I see examples like the article in languages I know, it's 'clever code'. reply MrJohz 14 hours agorootparentBut even then, there's degrees of knowledge and familiarity within that. For example, in Python, is using the `else` block of a for-loop clever? It's a part of the language that I'm familiar with - in principle it's just domain knowledge. But I've worked with plenty of Python devs who've never seen or used that construct before. For them, it's often black magic, and a classic example of \"clever\" code. The point is that everyone judges cleverness based on what they know and are familiar with. If I need to think too hard to understand it, then it's clever code. But everyone has different levels of familiarity and experience, which means that cleverness is always an individual metric. reply MattPalmer1086 7 hours agorootparentYep. A long time ago I remember using C# delegates to pass methods into a standard error handling wrapper. It's part of the language, but this was before functional programming was part of most OO Devs toolkit. Everyone was completely confused by it. reply psychoslave 19 hours agoparentprevCleverness is like connecting dots. It might be an instance that reveal a smooth curve that seems so obviously clear afterward but was unfathomed so far. Or it can cast a baffling intricated sequence of discrete points each generated at coordinates using the previous one in a well specified but completely ungrabbable way, the whole drawing a scary screaming face that any sane mind will flea away from. reply jawns 20 hours agoprevHere's an old joke about the progression from junior to mid-level to senior developer: Junior dev: My code is simple, straightforward, and easy to understand. Mid-level dev: My code is clever, innovative, expressive, hyper-optimized, and ingenious. Senior dev: My code is simple, straightforward, and easy to understand. In software development, \"clever\" solutions are like poems. In the best poems, there are usually multiple layers of meaning, nuances and subtleties, some harder to tease out than others. Sometimes you have to sit with a poem for a while before you are able to truly drink it all in. To mid-level engineers, writing this sort of poetic code has an intoxicating appeal. It allows them to flaunt their talents, demonstrate their mastery of the language, and impress their colleagues with their ingenuity. But more often than not, what is really needed is the code version of ordinary prose: straightforward, with a preference for clarity over succinctness, easy for others to understand, easy to edit, and with fewer surprises and deviations from convention than a poem. With prose, particular the sort of no-nonsense style found in wire news reports and explanatory journalism, the best work is easy for the reader to comprehend and lends itself to being edited. For instance, a skilled copy editor can condense it to fit, if need be. reply TheCoelacanth 19 hours agoparentI don't think it's accurate, though. Junior devs often write overly complicated code because they don't really understand the problem they're trying to solve. Junior devs write unintentionally complex code, mid-level devs write intentionally complex code, senior devs write simple code. reply bluGill 18 hours agorootparentSometimes seniour devs write complex code but hide the complexity behind a simple interface. reply _heimdall 14 hours agorootparentI'd include this as table stakes for a senior dev. You don't always need to work on complex code, but I'd expect they work to go to a senior dev and I'd expect complexity to be hidden behind a simple interface. reply drewcoo 8 hours agorootparentprevHiding complexity behind a simple interface is not clever. It's smart. It's also the facade design pattern. https://en.wikipedia.org/wiki/Facade_pattern reply aidos 19 hours agoparentprevWith a slight difference that junior dev tends be proud of the code they’re added while a senior will be proud of the code they’ve removed… reply latentsea 17 hours agorootparentSo much this. reply m463 14 hours agoparentprevI've seen junior devs write code carefully, putting time and effort into it. The code was ornate and almost too over-commented. mid-level devs become more pragmatic, but can skimp on both elegance and simplicity vs complication. What's interesting is that decent senior dev code sometimes almost looks careless, but really works well in the end. For example, immediately exiting with an error instead of complex error recovery. (the latter would just move the problem around and make finding and fixing the root cause more troublesome) Another thing would be duplicating code instead of doing some complex re-use with complicated conditionals. reply JohnBooty 4 hours agorootparentWhat's interesting is that decent senior dev code sometimes almost looks careless, but really works well in the end. I absolutely love this description. In a lot of ways, YAGNI is what really sets senior code apart. When I was a more junior dev, I thought senior code often looked under-engineered, but in hindsight I realized I was over-engineering things at the time. Another thing would be duplicating code instead of doing some complex re-use with complicated conditionals. God, I wish I could go back in time and burn this into my brain. reply yieldcrv 20 hours agoparentprevI just say, bell curve meme reply RangerScience 18 hours agoparentprevMostly, yeah - although Good poems give you clear meaning now, and deep meaning later. I think probably great code is like that, too. It’s clear in how it addresses the immediate needs, but it’s deep in how it sets up addressing later, subtler, or less proximal needs. Git itself comes to mind. At the basic level, it’s super straightforward: you have diffs, you put them in a row, that’s a branch. Easy. Clear. Then you want to do something weird, and lo and behold, you can. The “cleverness” - maybe call it the “clever simplicity” - that it’s built out of makes it possible, and “easy”. The deep part of the poem, that you didn’t need to understand in the beginning, starts becoming apparent and meaningful. reply Tao3300 18 hours agoparentprevBest summarized in meme format: https://x.com/nice_byte/status/1466940940229046273 reply dheera 19 hours agoparentprevReality: This is mostly because mid-level dev needs to justify their existence in order to not get laid off or PIP and is worried about losing their H1B and having to uproot their entire family in 60 days notice. Hyper-optimized, hard-to-read code that only they understand is one way to increase reliance on them while giving a reason that can be put into a promotion doc. Mid-level jobs are worried about maintaining their job. Junior dev doesn't care because they can go wherever, they aren't worried about the uprooting, and well-written code is a ticket to a multiple new jobs. Senior dev doesn't care because they have saved enough money, have permanent status, and if the company doesn't want them they aren't worried about there being better opportunities. They have enough online evidence of their competence and don't need to prove themselves. reply strken 17 hours agorootparentWhen I was a mid-level dev, the overly complicated code I wrote came about because I read an article on e.g. Ruby metaprogramming, got excited, wondered why we didn't use reflection more, and found a place where I could apply it. Perhaps you thought about job security, but that seems like part of your personal journey and isn't tied to seniority. I was just inexperienced and a touch arrogant, as mid-level engineers must be. At higher levels, the reason I don't write code like that is because I've been burnt too many times by the new hotness. It is slightly about job security, but only because I fully expect that any crazy shit I fling out today will eventually hit the fan and come back to me, probably at 3am during on-call. reply ern 19 hours agorootparentprevThis is mostly because mid-level dev needs to justify their existence in order to not get laid off or PIP and is worried about losing their H1B and having to uproot their entire family in 60 days notice. Hyper-optimized, hard-to-read code that only they understand is one way to increase reliance on them while giving a reason that can be put into a promotion doc. Mid-level jobs are worried about maintaining their job. That seems to be a matter of survival overriding ethics and professional pride. I know I came up with some really cringeworthy and complex solutions as a mid-level dev, but I would never have done it deliberately. If people are put into a situation where they need to purposefully write substandard code to not get deported, it's something that needs to be fixed. reply fr4nkr 19 hours agoprevI would argue that what constitutes clever code varies a lot by language. There's always a \"cleverness\" threshold where being able to read or refactor the code becomes harder, but this threshold isn't universal. Python in particular makes it very easy to be too clever, since its extremely rigid syntax was designed specifically to discourage it, but it ended up giving the user the necessary tools to be clever anyway, and the end result is usually... not pretty. reply morkalork 19 hours agoparentWhat would qualify as clever Python? These kind of broad and vague statements make me wonder if I am guilty.. reply sgarland 18 hours agorootparentFor a simple example, I think the walrus operator (:=) could be considered clever. I like it, and use it, but the fact that you can declare a variable, store a value in it, and then perform actions depending on its value, all in one line, gives me pause. if (foo := bar()) is not None: baz(foo) Whereas the traditionally accepted Python method of dealing with this would be EAFP: try: foo = bar() baz(foo) except AttributeError: # handle exception reply anitil 15 hours agorootparentIn your first example I think most people would skip the 'is not None' as None is already falsy and drop the extra braces. I find it visually clearer than the second example where the cause and effect are slightly separated, but I do agree there's an element of cleverness to it. reply sgarland 7 hours agorootparentIn this imaginary example, yes, a False is likely to cause the same issues that None would. But as a sibling comment mentions, it’s not always desirable to drop the explicitness for syntactic sugar. reply globular-toast 11 hours agorootparentprevBut that would be a mistake if you need the branch to run for other falsely values like 0 or the empty string. reply knome 17 hours agorootparentprevWhat? Those aren't equivalent at all. Where are you expecting an AttributeError to come from? Why are you comfortable catching them from anything inside of the baz(...) invocation? The traditional method would be to just bind it and check for a null outside the expression. foo = bar() if foo is not None: baz(foo) I don't know why people insisted on pretending binding variables before using them was such a difficulty that it was worth altering the language. Lazy and bad programmers aren't going to stop being lazy and bad when you hand them the ability to name things willy nilly. They'll just use that badly as well. reply sgarland 17 hours agorootparentThe assumption in the example is that baz() required foo to not be None; attempting to use None where you expect a string will probably in an AttributeError. As to your example, both LBYL and EAFP are accepted Python standards. reply lolive 17 hours agorootparentprevI currently have a dilemma regarding a XML generation code. Should I write it in pure Python with endless nested loops and DOM manipulations. Or should I use a templating engine that is exactly the DSL [:domain specific language] to express declaratively how to generate the output. Solution 2 is superbly consise and straight to the point, but I am pretty sure noone will ever climb the learning curve that this additional DSL imposes to any newcomer. I really wonder which final choice I will make for my production code. [truth is that refactoring solution 2 is painless, but at the same time debugging solution 2 is tricky] reply MrJohz 14 hours agorootparentCan you write functions and classes in Python that roughly mimic the DSL you're aiming for? This is often called an embedded DSL, and it's a great technique for allowing developers to work with domain objects inside a language that they're still familiar with. There's a handful of templating languages that do this sort of thing using functions, so in Python you might write form( {\"method\": \"POST\"}, label( \"Name\", input({\"type\": \"text\"}), ), ) The learning curve becomes significantly lighter because you're just using Python constructs in the Python language, which means your IDE can suggest functions to you like it would with any other library. reply dijksterhuis 18 hours agorootparentprevTL;DR - OOP obsession is a common python developer phase. it's a dangerous phase. - maintainable code is not minified code. minified code is minified code. - stoopid code is often stoopid enough when it satisfies real world / human concerns, not technical concerns. ---- I've done all of these, and I see other people repeating them. 1. hyper optimised and utterly fragile class based inheritance / abstractions. Not optimised in performance. Optimised in terms of minimisation of code. avoid ABCs like the plague. YAGNI so save yourself some heartache and keep it stoopid. 2. especially when ^ includes many static methods that could be standalone functions. a good sign the code can probably refactor to functional + objects/dataclasses (and probably be easier to test as a result). You didn't need it, go back to keeping it stoopid. 3. methods that call another method, that calls another method, that eventually calls one of the static methods. often when I see this, none of these child methods are called by anything else. someone wrote multiple separate methods because apparently we shouldn't write methods with more than 10 LoC. because that's how to write clean code apparently. just put it all in a single method so I don't have open multiple different browser tabs while sitting in the doctor's office responding to an incident on my phone. stop optimising for LoC and make it obviously stoopid. 4. hiding how the code will run away from main entrypoint by adding a `className.run()` method. yeah, cool, your main function has been minified. kudos. But now I have no idea what steps your script will run. I have to go and read something else. make it obviously stoopid to someone reading this for the first time. 5. using names of concepts from other languages. don't call classes an \"Interface\" or a \"Controller\" because it sounds better. This isn't Java nor is it Kubernetes. It's python. keep names so stoopid that I can understand when my phone has woken me up at 3 am. 6. functional is usually simpler, until you start turning in a mathematician. you are not a mathematician. and neither is the junior sitting next to you. don't overuse recursion or currying etc. keep it stoopid enough that the junior sitting next to you has a chance of taking over responsibility for it one day without going through a PhD in mathematics. 7. avoid using functionality from the last 3x minor versions of python [0]. slow down and let others catch up first so we can all be stoopid together. ---- caveat: experience will vary wildly between different hoomans regarding what is considered stoopid enough. [0]: a good exception here is something like case matching. this was pretty big so I would have allowed that, so long as everyone was aware it was a new thing now (I'd have done a post on slack saying -- Oi, go look at this, it's big) reply porphyra 20 hours agoprevI also find that, in C++, int sum = 0; for (int i = 0; i the `accumulate` example can be made simpler with `std::plus` Accumulate, surprisingly enough, accumulates by default: return accumulate(x.begin(), x.end(), 0); reply MathMonkeyMan 18 hours agorootparentJust make sure you're accumulating integers and not doubles! reply a_t48 14 hours agorootparentObviously, you have to use std::accumulate(v.cbegin(), v.cend(), decltype(*v.cbegin()){}); :) :) :) reply vlovich123 18 hours agorootparentprev> and is even faster (compiler is free to do the additions in any order) Is that actually true? I'm not even sure how hypothetically removing ordering requirements would help you extract performance, let alone any compilers that could do anything with that today. Unless the standard library were to auto-parallelize the reduction, but I doubt they'd do that because the overhead of starting threads would be quite costly for anything but the absolute largest ranges since C++ doesn't have a thread pool sitting idly for you (not to mention that the docs for the function don't mention any thread safety requirements for the BinaryOp and Init which would be required for any such optimization). reply a_t48 16 hours agorootparentThe linked page has benchmarks - I'd have to go dig into godbolt to see why it's faster. The standard library can actually auto-parallelize, but you have to opt in (see the ExecutionPolicy argument). Edit: I don't know how to dig into the actual implementation of std::reduce on godbolt - it's not inlined. I think the sibling comment has it right though - one can do adds of four at a time with whatever SIMD extensions are available. reply im3w1l 18 hours agorootparentprevI think relaxing the ordering requirement let's you use simd something like this (semi-pseudo code) (a, b, c, d) = (0, 0, 0, 0); for(int i = 0; iThe main operation, addition, is completely hidden magic the main operation is reduction which is fairly basic computer science and taught in any non-BS curriculum - https://en.wikipedia.org/wiki/Reduction_operator (or https://en.wikipedia.org/wiki/Fold_(higher-order_function) which is the standard way to introduce this concept ; check in particular the table showcasing all the implementations in various languages). The standard reduction for a set of numbers to a number that is likely going to be the very first example in your textbook is addition. reply Dylan16807 17 hours agorootparentThe reduction is explicit. That's not what the complaint is about. And it's more about implementation than the actual result. The actual operation is addition. I don't care if it's the first example, that doesn't mean you should hide it. Imagine if print did hello world by default. reply o11c 18 hours agorootparentprevstd::ranges::fold_left (since C++23) can take a range directly instead of a separated pair of iterators, and requires the explicit add. reply j1elo 19 hours agorootparentprevLook at that link: 2,4,6) ... These overloads participate in overload resolution only if std::is_execution_policy_v> is true. std::is_execution_policy_v> is true. std::is_execution_policy_v? std::decay_t? std::remove_cvref_t? Really, this madness with C++ needs to stop. People who work on newer versions of the language might be very conservative with the language syntax itself, but they clearly decided having carte blanche to adding an infinite amount of stuff to the standard library. Could someone please force them to stop, somehow? The whole rest of the industry would be thankful. reply nine_k 19 hours agoparentprevIt's mostly the problem of the language, and not of the approach. In a more expressive language you can omit the explicit slicing (x.begin(), x.end()) and have the compiler derive the lambda's signature for you, so you'd write something like reduce(x, (a, b) => a + b), or even fold (+) x, with all the same static analysis and efficient compilation guarantees. reply knome 17 hours agorootparentI think it's mostly a fad issue. Normal loops and if statements are just as possible to hit with a static analyzer. But the very fact that they look easy makes a certain kind of programmer see them as beneath them. They want the complex looking code, even if it's functionally equivalent and semantically no more sound. They like the visual noise and complexity of it. It rubs their egos the right way. reply nine_k 16 hours agorootparentLoops are more complex. They expose more implementation details, worse, they \"expose\" irrelevant details. Unless your CPU is very simple, like a Cortex M0, the C compiler will likely rewrite your loop using vector instructions (think MMX / SSE / Neon), leaving an unrecognizable mess where a neat loop with an index used to be. C was invented to match PDP-9 and PDP-11, and it matches them beautifully. Constructs like *a++ = *b++ directly compile to instructions like MOV (R1)+, (R2)+, etc. But however much I may like the beauty and simplicity of the PDP-11 architecture, it belongs to the past, or maybe to simplest MCUs. C no longer matches hardware all that well, and especially the idioms of C from classic books written 30-40 years ago don't match modern hardware woefully, if you care about the last bit of performance. (If you don't, take C#, Java, Go, even V8; they are plenty fast with JIT compilers.) reply knome 2 hours agorootparent00106 template 00107 _Tp 00108 accumulate(_InputIterator __first, _InputIterator __last, _Tp __init, 00109 _BinaryOperation __binary_op) 00110 { 00111 // concept requirements 00112 __glibcxx_function_requires(_InputIteratorConcept) 00113 __glibcxx_requires_valid_range(__first, __last); 00114 00115 for (; __first != __last; ++__first) 00116 __init = __binary_op(__init, *__first); 00117 return __init; 00118 } https://gcc.gnu.org/onlinedocs/libstdc++/libstdc++-html-USERS-4.0/stl__numeric_8h-source.html#l00108 It's just a loop. The compiler is doing all of the same transformations regardless of whether you use the higher order function or just write a loop yourself. -------------- _STD_BEGIN _EXPORT_STD template_NODISCARD _CONSTEXPR20 _Ty accumulate(const _InIt _First, const _InIt _Last, _Ty _Val, _Fn _Reduce_op) { // return noncommutative and nonassociative reduction of _Val and all in [_First, _Last), using _Reduce_op _STD _Adl_verify_range(_First, _Last); auto _UFirst = _STD _Get_unwrapped(_First); const auto _ULast = _STD _Get_unwrapped(_Last); for (; _UFirst != _ULast; ++_UFirst) { #if _HAS_CXX20 _Val = _Reduce_op(_STD move(_Val), *_UFirst); #else // ^^^ _HAS_CXX20 / !_HAS_CXX20 vvv _Val = _Reduce_op(_Val, *_UFirst); #endif // ^^^ !_HAS_CXX20 ^^^ } return _Val; } https://github.com/microsoft/STL/blob/63354c3fa9c1fb2ab1fccb58c47d23c6af1c290f/stl/inc/numeric#L24 Also just a loop in MS' standard lib. reply sgarland 20 hours agoparentprevThat is somewhat annoying, yes. I'm a huge fan of Python's list comprehension, but it's generally accepted to be a normal part of the language, and IMO, more readable: print([x for x in range(10) if not x % 2]) [0, 2, 4, 6, 8] vs. l = [] for x in range(10): if not x % 2: l.append(x) print(l) [0, 2, 4, 6, 8] reply okanat 19 hours agorootparentCall me crazy, but I find the second example more readable. The first example is long line and you have to go back and forth to understand it. The second example is a single top down pass. reply sgarland 19 hours agorootparentI’m sure I’m biased, since I code mainly in Python. List/dict comprehensions read the same to me as the longer form, just more concisely. This can be taken too far, and you can wind up with horribly obtuse one-liners that are just awful. reply okanat 18 hours agorootparentI write and maintain code in a bunch of languages. Rust has risen to the first place, C is the close second followed by C++ and Python. All of the languages except C have similar iterator-based stuff that let you write one liners and often with lambdas. I dislike them all. They give way too much leeway and encourage many developers to try to prove how clever they are. Once you have to debug the code containing them, all of the complexity of the syntactic sugar comes crashing down on you. The debugger starts jumping to weird places, sometimes even optimized out parts of the standard libraries while for loops usually stay debugable. reply crazygringo 19 hours agorootparentprevAgreed, me as well. The second example reflects how my brain thinks and the intuitive order of what has to happen. In the first example, it's all out of order. reply psychoslave 3 hours agorootparentprevWith ruby 3.4 (prior to that `_1` should be used instead of `it`): (0..10).select{it.even?} reply psychoslave 3 hours agorootparentAlso not that the result is `[0, 2, 4, 6, 8, 10]`, unlike the behavior of Python which exclude the value explicitely passed in parameter from the represented range. reply f33d5173 18 hours agorootparentprevI've seen people complain about wrapping a comprehension over multiple lines, but I can't imagine packing them all in one. In your example, I would spread it out over five lines, so it would be at as long as the imperative case. While I like python, I think the unusual order that components of a comprehension are written is to its detriment. It would make more sense if they were in the same order in both examples. The python ternary has a similar issue. reply glandium 17 hours agorootparentprevYou chose the one example that doesn't need a list comprehension. print(list(range(0, 10, 2))) reply sgarland 17 hours agorootparentGood call. reply floxy 18 hours agorootparentprevx = np.arange(0,10,1) print(x[x%2==0]) reply Xeoncross 20 hours agoparentprevint sum = 0; for (int i = 0; iPretty much looks the same in all C-like languages Because it’s ancient; that doesn’t necessarily make it better or clearer. Look at it like you’ve never seen it before. It has an entire line of boilerplate smack bang in the middle. Sure, your brain filters it out because you’re used to it, but it’s still fugly. And it’s prone to typos/copypaste errors like all boilerplate. reply Xeoncross 17 hours agorootparentYes, but it's also not going anywhere. I don't consider replacing a common loop convention with what amounts to a randomly-generated sentence or two of syntax and letters in each language to be an improvement. reply theshrike79 13 hours agorootparentprevJust the '++i' instead of 'i++' brought my reading that code to a halt and I had to start deciphering if it actually changes the operation of the loop. reply constantcrying 3 hours agoparentprevThat is just a question of what you are used to. The \"functional style\" example is very obvious to a person who is familiar with that style. In fact if the rest of the code base is in a similar style it is the easier one to understand. There is nothing inherent which makes either better or cleverer than the other. (Also the first one is incomplete, as \"n\" is not defined, making the later more self contained) reply haolez 20 hours agoparentprevI like C++, but I don't understand this tradition of keeping these annoying namespaces prefixed to everything. Just get rid of those std::, foo::bar::whatever::, etc from your code and make it more readable. Use the \"use\" clause. It's very rare for such names to be ambiguous in the same file, unless I'm missing some bigger picture here. reply porphyra 20 hours agorootparentusing namespace std; is considered kinda bad since you don't want your namespace to be polluted with a bunch of std stuff. For example if you have `int count` lying around somewhere you'd want to be able to call `std::count` without fear of it being shadowed. reply haolez 19 hours agorootparentBut ambiguity gives you readability. And if a \"count\" variable clashes with the function name, it's trivial for the compiler to catch this and warn you. It's a matter of preference, but I'd still risk ambiguity and name collision, especially when you go beyond std:: (like boost stuff). reply tialaramex 19 hours agorootparentBecause of bad design decisions, a whole pile of unrelated stuff lives in the std namespace, and the disambiguation probably isn't what you wanted, so this can silently cause surprises. reply devnullbrain 19 hours agorootparentprevIt gives you readability. It's not what I'm used to, so it feels like reading French to me. Generally, if I see something without a namespace, it has a local scope. reply kalkr 19 hours agoparentprevTraditional C style for is terrible compared to what you can do with iterators in my opinion, but idk if C++ has those. list.iter().sum() ezpz reply leetcrew 16 hours agoparentprevthe readability issue here is in part that function arguments are purely positional in c++. a little over the top for this simple example, but you can always create local variables to document intention. auto initVal = 0; auto accumulateOp = [](int a, b) {return a + b;}; return std::accumulate(x.begin(), x.end(), initVal, accumulateOp); I'd prefer to see a for each loop over algorithms functions in such simple cases, but I'd prefer almost anything over direct indexing when it isn't necessary. when I see that in new code, my first thought is always \"what am I missing here?\". reply phailhaus 19 hours agoparentprevThe other thing nice about the second style is that it's much easier to skim when part of a larger function, since it's a single type-checked statement. Keeps you from doing too much in it too. reply GrantMoyer 17 hours agoparentprevIf you use C++23's ranges and Boost Lambda and sacrifice your better judgement, you can get it down to: fold_left(x, 0, _1 + _2) reply sesuximo 19 hours agoparentprevImo it doesn’t matter at all. Both are fine. Surely there are more pressing things out there to think about! reply williamcotton 19 hours agoparentprevI haven’t written any C++ since the 90s. That is unrecognizable. Is that an anonymous function? reply nine_k 19 hours agorootparentC++98 should be forgotten as a bad dream. C++17 is almost a sane and convenient language (as long as you remember about the boiling depths into which you can fall if you're careless). C++ will live for very long, like Fortran. And also like Fortran, there now must be a serious and uncommon reason to start a new project in it. reply pklausler 18 hours agorootparentWhy does one need an uncommon reason to begin development in Fortran? reply nine_k 17 hours agorootparentFor instance, the much narrower circle of experts. Usually if you do need Fortran, it means you're going to run numerical code on a huge cluster with RAM in terabytes and cores in the thousands, so the developers you're looking for should understand parallelization very well (and how modern Fortran does it), know words like MPI and Slurm, etc. Beside that, knowledge of the common numerical methods and libraries is expected. This is a relatively unusual setup. Few job listings mention it. If you just want some highly parallel numerical code, but a GPU with several tens of gigs of RAM would suffice, you just take Numpy, or PyTorch, or other such library, wrapped into Python. You suddenly have a wide circle of developers, plethora of references, and no lower chances to publish in a prestigious journal than if you'd taken Fortran :) reply floxy 19 hours agorootparentprevYes. https://learn.microsoft.com/en-us/cpp/cpp/lambda-expressions... reply lupire 19 hours agoparentprevWhy would you not use std::sum(x) ? reply neonsunset 20 hours agoparentprevC++ makes this (and many other things!) needlessly painful. In C# it is just return numbers.Sum(); reply vlovich123 18 hours agorootparentSame for Rust. reply the__alchemist 16 hours agorootparentI tend to use for loops in Rust for this reason; simple, and understandable by anyone who's programmed in an imperative language. The one-liner approach tends to include an explicit type declaration (Or turbofish), `iter()`, and `collect()`, at minimum. reply tialaramex 19 hours agorootparentprevWhere did \"numbers\" come from, and why are you so sure you can Sum() it? The original C code offered has some data structure (perhaps an array?) called x. Do C# arrays have a Sum method? I don't think so. In Rust you would probably just write: x.iter().sum() reply nyssos 19 hours agorootparent> Do C# arrays have a Sum method? I don't think so. It's not literally a method (it's not, for instance, in the vtable of some array class), but as far as their API is concerned, yeah, they do: https://github.com/dotnet/runtime/blob/main/src/libraries/Sy... reply neonsunset 19 hours agorootparentprevC# arrays don't. However, C# arrays are IEnumerable, which does. reply lupire 19 hours agorootparentIEnunerable of course does not have Sum. Only collections of numeric types (including arrays) have Sum. https://learn.microsoft.com/en-us/dotnet/api/system.linq.enu... reply masfuerte 19 hours agorootparentSo you can't use IEnumerable.Sum if T is a custom type implementing operator+ ? reply neonsunset 19 hours agorootparentYou could, but .Sum is a little more specific than that - it is non-overflowing sum. Historically, constraining generic arguments on addition was problematic - the full feature set of numeric types was \"lifted\" to be fully representable through generics only recently[0]. With that said, there is an open proposal[1] to introduce additional generic math overloads to IEnumerable methods, but it hasn't seen much activity as the existing overloads cover most commonly used numeric types already. [0]: https://learn.microsoft.com/en-us/dotnet/standard/generics/m... [1]: https://github.com/dotnet/runtime/issues/64031 reply lupire 19 hours agorootparentprevThis comment makes no sense. You dismissed the C# code, and then wrote the same thing in Rust, but with an extra non-conceptually-meaningful boilerplate step. May as well ask, \"where did x come from, and why are you so sure you can iter().sum() it?\" C# has generic types, so yes, C# arrays of numbers have a Sum method. https://stackoverflow.com/questions/2419343/how-to-sum-up-an... Don't make bold dismissive comments about things you are ignorant of. It makes you look Blubby. reply tialaramex 19 hours agorootparentThe C# code ends up relying on LINQ, it's interesting how many C# programmers don't even think about that, either anything they work on already uses LINQ or they just reflexively bring it in everywhere they write C# You'll see that a few of those SO comments actually say they're relying on LINQ to make that work. The array type doesn't have such a method itself. So, in reality although many C# programmers will think of this as \"correct\" it just won't even compile... except if there's already LINQ. reply wvenable 17 hours agorootparentLINQ is just part of .NET standard library along with the very collections we are talking about. I'm not sure why one would care about the distinction. reply latentsea 17 hours agorootparentprevUsage of LINQ is usually taken for granted. reply neonsunset 18 hours agorootparentprevThere is nothing wrong with System.Linq just like there's nothing wrong with Rust's std::iter::Iterator. If anything, this makes writing Rust use the existing muscle memory if you have C# experience and vice versa. The performance profile of LINQ, while much maligned, has been steadily improving over the years and, in the example of Sum itself, you actually do want to use it because it will sum faster than open-coded loop[0]. I do have grievances regarding LINQ still - my (non-negotiable) standpoint is that Roslyn (C# compiler) must lower non-escaping LINQ operations to open-coded loops, inline lambdas at IL level and similar, making it zero-cost - .NET (IL compiler/runtime) provides all the tools necessary to match what Rust's zero-cost-ish iterator expressions offer and there just needs to be more political will in the Roslyn teams to do so. Because of this, I'm holding my breath waiting for DistIL[1] to be production-ready which does just that. [0]: https://github.com/dotnet/runtime/blob/main/src/libraries/Sy... [1]: https://github.com/dubiousconst282/DistIL (I don't understand what you mean by \"it won't compile\", because it will, in most cases System.Linq namespace is already referenced anyway, either through global usings or at the top of the file) reply tialaramex 7 hours agorootparent> (I don't understand what you mean by \"it won't compile\", because it will, in most cases System.Linq namespace is already referenced anyway, either through global usings or at the top of the file) The \"in most cases\" is doing all the lifting here. Rust's Iterator is in the prelude. Even if you #![no_std] you get the core prelude which has core::iter::Iterator. You would need to explicitly write code to tell Rust \"No, I don't want the prelude\" to get rid of it, I'm sure people do that, otherwise it wouldn't be possible, but few enough that I've never seen it. But in C# there is no such promise. In most (but not all) real world C# projects somebody already brought in LINQ. If you're using a technology that gives you a \"ready to go\" standard C# project template it undoubtedly folds in LINQ too. But it's not actually provided by the language and that's a meaningful gap. Notably in several of the playground type tools, since LINQ is not there by default this won't work - like I said it won't compile and it doesn't suggest \"Oh you need LINQ\" because the C# compiler doesn't provide such suggestions. reply neonsunset 6 hours agorootparentIt's difficult to talk to someone committed to misreading the replies. LINQ aka IEnumerable/Iterator methods are usually imported by default, something like with prelude. As others said, they are part of standard library. I'm not sure what you are arguing against either but whatever your criticism is - it is misplaced as C# and Rust roughly belong to the same Venn diagram of features against commonly held beliefs. You can test it yourself: sudo apt install dotnet-sdk-8.0 mkdir TestConsole && cd TestConsole dotnet new console And then just paste/echo the following to Program.cs: var numbers = Enumerable.Range(0, 10).ToArray(); var sum = numbers.Sum(); Console.WriteLine(sum); This will compile. If that's not enough, then it's likely Rust the language is not for you either and you may want to use something like Go for the time being. reply quotemstr 20 hours agoparentprevOne pet peeve of mine is people using std::for_each instead of a simple loop reply jraph 19 hours agorootparentSame in JS. I once worked with someone who would use [].forEach and didn't like for loops because functional good, iterative loops bad. It was essentially in the coding style of the project and the for version would be rejected in MRs. I don't miss this. IMHO [].forEach just essentially expresses the same thing as a regular for loop, although in a more verbose and convoluted way that is also likely very inefficient because a JS compiler probably can't optimize away the function call per iteration, because of the very dynamic nature of JS. forEach probably has its use when you specifically need to call an existing function on each element, but I don't otherwise see the appeal. reply lupire 19 hours agorootparentYou are making a strong evidence-free claim about what JS compilers don't do. https://stackoverflow.com/questions/9981607/array-foreach-ru... reply jraph 13 hours agorootparentYou call \"strong claim\" something I prefixed with \"probably\"? It seems for loops in your link can be slower because .length (a function in disguise) is repeatedly called. I do save .length when writing JS. .length calls has been hard to optimize and it can't hurt too much to cache it at the start of the loop. Now it's good news if today's engines are able to optimize most of .forEach. The amount of optimization JS engines can do never ceases to amaze me and yes, any performance claim in JS needs to be constantly reviewed and checked at the time it is discussed. You can't take a \"probably\" as gospel. Still, it was a bit lazy of me to not re-check, I guess being called out was warranted. reply Teckla 18 hours agorootparentprevAt $WORK we use Mozilla Rhino for some JavaScript processing. We tested the normal loop vs. the clever loop. Performance-wise, the normal loop blew the doors off the clever loop. reply MrJohz 14 hours agorootparentRhino is a very uncommon engine though. It has its niche, but if you're developing for simpler engines like that, then you typically know that in advance and know what considerations you're going to need to make for that. When it comes to performance, lessons that apply to Rhino are unlikely to apply to more mainstream engines. EDIT: That's not to say that everyone should use map and forEach all the time, just that your benchmarks are unlikely to be relevant to most JS devs outside of your specific use-case. reply globular-toast 11 hours agoparentprevsum(x) is easiest to read. If your language doesn't provide that as standard just define it yourself. In general you should always be idiomatic, though. If every C++ developer understands the accumulate version then use that. reply jasonpeacock 19 hours agoprevKernighan's Law: Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it. reply vlovich123 18 hours agoparentUnless you got dumber between writing and debugging, it more likely means that it takes twice as long (or even more if you haven't touched it in a bit). It's unlikely that Kernighan meant it takes someone twice as smart to figure out what you were doing as that would be a nonsensical interpretation (someone twice as smart may not be able to figure out what the stupid person is trying to do in the first place if the code written was nonsensical). reply fargle 17 hours agorootparent> It's unlikely that Kernighan meant it takes someone twice as smart to figure out what you were doing no, that is exactly what he meant. clever code means you are just barely able to understand it enough to write it yourself [in any amount of time]. therefore, you aren't going to be able to debug it at all, by a factor of nearly two. and if you are the \"smartest\" person in the org (which he often was), then you are really in big trouble. now obviously things in the real world like \"smart\" and \"clever\" are not one-dimensional quantities in neat categories, but he was making a memorable and funny quote, with quite a bit of truth to it, not a precise scientific hypothesis. see also: \"too smart for one's own good\" > nonsensical interpretation how so? > someone twice as smart may not be able to figure out what the stupid person is trying to do in the first place if the code written was nonsensical. true, but irrelevant, this is about clever code from a smart person, not nonsense code from a stupid one. reply bluGill 6 hours agorootparentprevMost of the problems I've had to debug the place to look is not clear. Sure I've had to fix \"The is not spelled Teh\", but most problems are it breaks in some weird situation - step one is figuring out where to even start looking. Once I narrow down the exact place to look it might be easy, but I have to hold a lot of different areas of code in my head while narrowing things down. Even when I narrow it down, sometimes the answer is make the code more complex, and if the code is already on the edge of how complex I can handle I won't know how to make it more complex. reply matrix87 17 hours agoparentprevnot smart enough to debug it in the same amount of time it took to write it reply photochemsyn 16 hours agoparentprevI'm finding LLMs invaluable in deciphering this kind of thing, with suitable prompting: System: Always provide clear instructions from the perspective of an expert in the field. Double-check answers for logical coherence and factual correctness, using a consistent step-by-step methodology. Explain the benefits and disadvantages of different approaches in a compare-and-contrast style, and value security, readability, and organization over clever tricks. User: Consider the following code function in Python: \"def minimumTotal(self, t): return reduce (lambda a,b:[f + min (d,e) for d,e,f in zip(a, a[[1:],b)], t[::-1])[0]\" . The goal is to rewrite this using only simple python bulitins like for loops. Use a step-by-step approach to dissassemble this code into a simpler format, and include plenty of comments. User: Clarify what is meant, mathematically, by \"the minimum path sum from top to bottom in a triangle\" Okay now I understand it... This is much easier if the original code has a set of robust tests you can run your LLM-generated code against, to make sure it works as advertised, but you can get the LLM to generate tests too if needed. Now I want to go see how it does when faced with C obfuscation competitions. reply nine_k 19 hours agoprevI keep to a simple rule: smart code is an asset, clever code is a liability. Smart code is usually simple and clear, while also being short and efficient. Achieving this is not easy, but reading, understanding, and using smart code is easy. (Otherwise it's not smart, but, well, ordinary.) An example of smart code for me would be the merge sort algorithm, or the Lisp interpretation loop. Clever code is usually some kind of last-resort hack, a trick, applied in dire straits, or to achieve a unique effect. An example would be the inverse square root hack, or the Duff device. Beside the actual writing time, code review time is good for making code smarter and less clever. reply dpc_01234 19 hours agoprev\"Clever code\" here means \"code-golf-like code\". \"Clever\" is too subjective to be used like this. One person's clever, is another person's mundane, and it varies across languages, ecosystems, teams. Also I'd like to point out that in this example, had that function had a comment and a couple of tests, then it wouldn't really matter much what the implementation is. If you don't like it, you can rewrite it your preferred way. Though as a dev I'd be too lazy to try to optimize code for code-golf-like properties in the first place. reply tehnub 20 hours agoprevThis is true, but in code reviews and such, it often boils down to familiarity above anything else, like someone preferring names = [] for record in records: names.append(record[\"name\"]) to names = [record[\"name\"] for record in records] Now, I might say something if I saw this: import operator names = list(map(operator.itemgetter(\"name\"), records)) Seems a bit unidiomatic given that list comprehensions are in the language... but probably many disagree. reply hleszek 19 hours agoparentA simple list comprehension is quite readable and better IMHO. It is very common and most people will understand directly what it does. Of course, when you have multiple levels or complex lambdas inside, then I agree that the for loop might be preferable. reply amanzi 19 hours agoparentprevGreat example. My personal preference is the first one, but I put that down to me being inexperienced and not working in a professional development environment. I've been using Ruff with most of the rules enabled, and they have a page for this scenario here: https://docs.astral.sh/ruff/rules/manual-list-comprehension/ Another one that trips me up is the ternary operator: https://docs.astral.sh/ruff/rules/if-else-block-instead-of-i... I prefer the longer, more verbose version, even though the suggestion looks more clever. reply aidos 19 hours agorootparentLet me see if I can sway you. The nice thing about both the ternary and the list compression is that they become statements of the form derived_thing = some_computation. The code flows better when you’re skimming it at a high level and thinking “then we get this”, “then pluck this”. You can think more about your reformed data and less about how it was reformed. The alternative is that the branching obscures what you’re trying to create at each step. Sometimes I’ll even use 2 list comprehensions instead of a loop (even though it’s slower) because it’s clearer to read something like: odds = […] evens = […] That’s my experience, anyway. reply sgarland 18 hours agoparentprevI’m convinced that the only reason the operator library exists is to provide inputs for functools, which itself is mostly there to pretend that you’re a functional programmer. …but I do kinda like map(). reply VTimofeenko 19 hours agoparentprevI'd say it also heavily depends on the code style that's internal to the project. Case in point, for heavy toolz users: list(toolz.pluck(\"name\", records)) reply haolez 20 hours agoprevThat's what I like about Go. It's easy to read and understand Go code from open source projects written in it (although Kubernetes is a notable exception, with a very convoluted Go code). reply bloaf 19 hours agoprevSo I’m going to play the devil’s advocate and say that concise code has a readability advantage in that you don’t need to keep track of intermediate variables or other state across hundreds of lines of code or multiple files. This was/is the promise of languages like APL; those willing to invest in learning arcane and terse symbols can move mountains in a few keystrokes. I know that for my part, when reading a language I’m familiar with, it’s usually much faster to puzzle out a concise solution than a verbose-in-the-name-of-simplicity one. reply Jagerbizzle 20 hours agoprevI’ve been a C++ dev for a couple of decades and know my fair share of unreadable code. I’ve recently started learning Python and holy shit, it’s like you get accolades in this language for doing as much as possible in as few characters as possible. Guess I’m getting too old for these young whippersnappers. reply JohnBooty 4 hours agoparentAfter spending six months with Python so far, the problem with the Python ecosystem is that you have a lot of really smart people (scientists, mathematicians) who are not software engineers by trade writing a lot of these libraries. I guess it's a good problem to have, in a lot of ways, because it's also why Python has that huge science/datascience/etc ecosystem. reply lopatin 19 hours agoparentprevIf you think Python is like that, I advise you to never look at Ruby codebase. But seriously, of course you can write Python one-liners or nested comprehensions, but I get the idea that it's not really Pythonic. They still want clear, iterative code. It's just more concise, but the idea is the same, but with less scrolling. reply JohnBooty 4 hours agorootparentIf you think Python is like that, I advise you to never look at Ruby codebase. The codebase for Ruby itself, or the codebase of your typical Ruby app or library? I spent about a decade with Ruby and my general impression is that the community really moved away from overly-clever metaprogramming. The codebase for the Ruby language itself is definitely a challenging read. reply mostlysimilar 19 hours agorootparentprev> If you think Python is like that, I advise you to never look at Ruby codebase. Like any other language you can write perfectly expressive and intelligible code in Ruby, and in fact it is quite common to do so. The first layer of a Ruby codebase tends to be approachable, it's only when you get into some of the bigger libraries that you get some tricky metaprogramming. Even then I don't often see Rubyists write tricky/clever code for the sake of it. The metaprogramming usually has utility and is often the \"right\" way to do something, especially in say the Rails codebase. Ruby is all about developer happiness. It's the founding principle and the guiding ethos of the community. reply drewcoo 8 hours agorootparentI don't think they're talking about Ruby code golf. Another way of stating the GP's comment is that a Rubyist looking at a Python codebase will be shocked at all of the verbose boilerplate. Ditto for a Pythonista looking at C++ code. reply fl0ki 19 hours agoprevEveryone thinks they're writing good code. Even many experienced seniors write code that they think is good code but others loathe. Best case, they can at least solve problems without introducing new ones; though more often than not, they're still making many junior mistakes while couching them in senior terminology. Aside: Do we really need to keep rewording this exact same essay every month since the first computer program was ever written? reply 000ooo000 14 hours agoparentHey if no one is writing blogspam and posting it to HN, when am I gonna get to drop my hot take on what differentiates junior, mid, and senior developers? And what about my thesis that there is actually a huge difference between programmers, developers, and engineers? My identity is really wound up in all of this so it's important that I get an opportunity to put other developers down. reply boxed 19 hours agoparentprevThis one was a bit different. It also featured an extremely dangerous and incompetent manager. reply beryilma 3 hours agoprevI would extend this to clever languages: \"Clever languages are the worst languages you could write in\". And I would put most functional programming languages in this category. reply 127 20 hours agoprevSometimes clever code creates a good abstraction. Clever code that doesn't create a suitable trade-off with complexity isn't actually clever at all. Of course, never code golf outside actual code golfing puzzles. reply slushy-chivalry 19 hours agoprevA bit of a clickbaity title, but I'll bite I think \"cleverness\" is a function of your (and your team's) experience in a particular language / domain space I worked with teams where verbose Java is considered \"simple, straightforward, and easy to understand\" I also worked with teams where terse Haskell is considered \"simple, straightforward, and easy to understand\" and of course these codebases look nothing alike reply boxed 19 hours agoprevIt's like no one in the comments here read the piece. Honestly, it's a bit like the author himself didn't. The big thing in this article is the dangerous and incompetent manager. People like that in a company could destroy the entire thing, and yet it's sort of just mentioned in passing like \"oh that's funny\". It's not funny, it's absolutely terrifying! reply hackable_sand 12 hours agoprevCleverness is found in grokking a system. A system of simple code is more easily understood. It's easier to move and impress the system at high-level user interfaces. At what rational scale does the system become clever? How long is a system considered clever and how often? Can you use diff trees to infer high-level logical migration and evolution patterns within the source files themselves? reply schwarzrules 20 hours agoprevAnytime I find myself being clever, I'm reminded of this deadpan exchange. Tyler Durden: How’s that working out for you? Narrator: What? Tyler Durden: Being clever. Narrator: … Great. Tyler Durden: Keep it up, then. reply gregjor 18 hours agoprevI suppose every generation of programmers has to rediscover this and it can’t hurt to keep writing articles and books about it. From The Elements Of Programming Style , 1978, by Kernighan and Plauger, rule one: “Write clearly – don't be too clever.” The whole book, a short read, spells out principles and wisdom from experience that all programmers would benefit from. reply mybrid 18 hours agoprevI follow Einstein's metric, \"make something a simple as possible, but no simpler.\" reply quantum_state 16 hours agoprevIn the spirit that Programming is Theory Building, one would want to keep it simple, consistent, and easy to understand with basic constructs defined in a somewhat irreducible (single responsibility) manner. reply stephc_int13 19 hours agoprevThere is always some part of subjectivity when evaluating complexity and clarity. But all things being equal, this point still stands and should be not being brushed off as \"skill issue\". Clarity is a difficult skill to acquire, but it pays off. reply dustypotato 11 hours agoprevNARUTO - Never follow Absolute Rules as Ultimate Truth Over practicality reply matrix87 17 hours agoprevI don't think the python example is \"too clever\" though, the expanded version seems more convoluted reply doubloon 16 hours agoprevYou learn about this a lot in writing and humanities classes not so much in CS classes reply Aeolun 17 hours agoprevI like how there is a constant stream of people realizing and writing blog posts about this. reply myspeed 16 hours agoprevIn reality, writing a code that is easily understandable for everyone is good code. Clever code is intricate and difficult to follow by many. Coding is done for a team of people and not to show individual preceptive of a business problem/solution. reply GuB-42 16 hours agoprev> Clever code is probably the worst code you could write But you should write it anyways. Preferably in a situation of little consequence (school, personal projects, prototyping, etc...) Otherwise, how do you make the difference between code that is simple and code that is just dumb? \"not clever\" code typically has: copy-pasting, no abstractions, hardcoded values, global variables, cascading \"if\"s... And sometimes, it is the right thing to do, but good, readable code is usually a bit more clever than that. But how do you know the right kind of cleverness? For me, the best way is to experiment. Sometimes, trying to be clever fails, sometimes, it really makes your code better, but if you don't try, your code will never get better. reply jraph 20 hours agoprevYep. I now find it enjoyable to refactor my code to the point of making it feel obvious and straightforward. Not always easy. For me, it helps imagining some colleague read my code and judge me. And fortunately, I work at a place where I trust people to recognize when something that looks obvious is not actually dumb. Not that I'm so great at dumb but I try at least. Tooling that allows you to move classes, methods, rename stuff, inline or extract functions efficiently helps a lot. It pains me a bit to write this, as someone whose favorite code editor is a text editor, not an IDE. I find there's comparable joy in writing. Rephrasing and simplifying a text to find the most efficient / obvious phrasing. I suspect writing software might affect writing in such ways, though I don't think I would be able to tell a developer's writing apart. reply mcv 19 hours agoprevI've noticed I love the clever, elegant abstractions I invent, because I understand how they work and they give me a really neat and readable way to organise my code. And I hate the clever elegant abstractions others create, because I the code is so abstract I can't tell by looking at it what it does, and I don't have their mental model of the abstraction in my head. Cleverness is fine if you can make sure the reader gets the right mental model in their head, but not if not. And because nobody cares about your documentation, your options are to either explain it to everybody (sounds stupid but can actually work -- for a while), or to make your code explain it for you. And that limits how clever and abstract it can be. reply alphazard 18 hours agoprevThe knockdown test for too clever is that the original author can't maintain or extend the code later on. You can use this phenomenon to prove to people that they were being too clever. \"See? not so easy, and this is all your doing\" Beyond that there is a a tradeoff to be had between utilizing powerful and expressive language features, and alienating less proficient programmers. In industry, redundancy and parallelism (of humans) matters a lot, and so the code has to be dumbed down quite a bit. If you're working solo or with a few highly competent peers, you can afford more cleverness. reply jongjong 19 hours agoprevThis is true. That's why the software engineering recruitment process is completely broken... They select for people who revel in unnecessary complexity. What kind of person enjoys spending their time practicing many variations of pointless complicated coding puzzles instead of working on useful side projects or learning new concepts and technologies? The big tech recruitment process is all about puzzle solving under time constraints though. Pragmatic engineers have no chance of competing against the puzzle solvers. reply readthenotes1 20 hours agoprevI wonder how old this advice is. I know that it predates the century but I'm not sure how far back. (A favorite quote of mine that I believe is from the 1970s says \"It's easier to make working code fast then to make fast code work.\" Since the fundamental problems of programming have not changed over the centuries, I wouldn't at all be surprised if there's an anti-clever saying from the dawn of computing) reply tialaramex 19 hours agoparent> the fundamental problems of programming have not changed over the centuries It hasn't been a whole century yet. Grace Hopper's career started in 1944, eighty years ago. reply readthenotes1 2 hours agorootparentAda Lovelace predates her reply zb3 19 hours agoprevThe actual example'd make the post better, but I understand the author is not allowed to give more details on that one :( reply mvdtnz 19 hours agoprevThis is why I don't like working with Ruby teams. Of course you can write straight-forward Ruby code and I encourage it, but Ruby does seem to attract developers who like to write \"dynamic\" code and use \"meta-programming\" (what we would call \"reflection\" in other languages, where it's made intentionally difficult). I think it's mostly the influence of the Rails framework that leads developers towards \"magic\", although it doesn't help that Ruby makes this kind of programming especially easy. reply CodeWriter23 20 hours agoprevMostly true. reply spullara 19 hours agoprev [–] Some developers like to solve problems and some like to solve puzzles. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article from Engineer’s Codex argues that \"clever\" code, known for its complexity, is the worst type of code to write, advocating instead for clear and readable code.",
      "The author shares personal experiences, highlighting that achieving clear code often requires extensive refactoring and documentation, despite it being undervalued in performance reviews.",
      "Emphasizing the importance of coding style and continuous learning, the article recommends resources and courses for software engineers to enhance their skills."
    ],
    "commentSummary": [
      "The discussion stresses the importance of clarity and simplicity in coding, advising against overly \"clever\" code that complicates maintenance.",
      "It highlights how perceptions of code complexity evolve with experience, noting that junior developers often write complex code due to inexperience, while senior developers prioritize simplicity and maintainability.",
      "The conversation also explores motivations behind writing complex code, such as job security and experimentation, and debates the balance between readability and conciseness."
    ],
    "points": 158,
    "commentCount": 175,
    "retryCount": 0,
    "time": 1716330095
  },
  {
    "id": 40437535,
    "title": "Alacritty: High-Performance, Cross-Platform Terminal Emulator Using OpenGL",
    "originLink": "https://github.com/alacritty/alacritty",
    "originBody": "Alacritty - A fast, cross-platform, OpenGL terminal emulator About Alacritty is a modern terminal emulator that comes with sensible defaults, but allows for extensive configuration. By integrating with other applications, rather than reimplementing their functionality, it manages to provide a flexible set of features with high performance. The supported platforms currently consist of BSD, Linux, macOS and Windows. The software is considered to be at a beta level of readiness; there are a few missing features and bugs to be fixed, but it is already used by many as a daily driver. Precompiled binaries are available from the GitHub releases page. Join #alacritty on libera.chat if you have questions or looking for a quick help. Features You can find an overview over the features available in Alacritty here. Further information Announcing Alacritty, a GPU-Accelerated Terminal Emulator January 6, 2017 A talk about Alacritty at the Rust Meetup January 2017 January 19, 2017 Alacritty Lands Scrollback, Publishes Benchmarks September 17, 2018 Installation Alacritty can be installed by using various package managers on Linux, BSD, macOS and Windows. Prebuilt binaries for macOS and Windows can also be downloaded from the GitHub releases page. For everyone else, the detailed instructions to install Alacritty can be found here. Requirements At least OpenGL ES 2.0 [Windows] ConPTY support (Windows 10 version 1809 or higher) Configuration You can find the documentation for Alacritty's configuration in man 5 alacritty, or by looking at the website if you do not have the manpages installed. Alacritty doesn't create the config file for you, but it looks for one in the following locations: $XDG_CONFIG_HOME/alacritty/alacritty.toml $XDG_CONFIG_HOME/alacritty.toml $HOME/.config/alacritty/alacritty.toml $HOME/.alacritty.toml On Windows, the config file will be looked for in: %APPDATA%\\alacritty\\alacritty.toml Contributing A guideline about contributing to Alacritty can be found in the CONTRIBUTING.md file. FAQ Is it really the fastest terminal emulator? Benchmarking terminal emulators is complicated. Alacritty uses vtebench to quantify terminal emulator throughput and manages to consistently score better than the competition using it. If you have found an example where this is not the case, please report a bug. Other aspects like latency or framerate and frame consistency are more difficult to quantify. Some terminal emulators also intentionally slow down to save resources, which might be preferred by some users. If you have doubts about Alacritty's performance or usability, the best way to quantify terminal emulators is always to test them with your specific usecases. Why isn't feature X implemented? Alacritty has many great features, but not every feature from every other terminal. This could be for a number of reasons, but sometimes it's just not a good fit for Alacritty. This means you won't find things like tabs or splits (which are best left to a window manager or terminal multiplexer) nor niceties like a GUI config editor. License Alacritty is released under the Apache License, Version 2.0.",
    "commentLink": "https://news.ycombinator.com/item?id=40437535",
    "commentBody": "Alacritty – A fast, cross-platform, OpenGL terminal emulator (github.com/alacritty)145 points by alexzeitler 13 hours agohidepastfavorite157 comments Rogach 6 hours agoI moved to alacritty from gnome-terminal. Wasn't for latency or throughput - I didn't notice any difference in latency, and difference in throughput is only visible when cat'ing 3MB of text. However, for me the selling point was a text config file, which I can edit, backup, or store in git (unlike gnome-terminal, where customization was done either in GUI or in gconf, and while it's also text files somewhere they are difficult to work with). reply plandis 1 hour agoparentVersion controlled config was why I started using it too! reply Piraty 6 hours agoparentprevI prefer xfce4-terminal for exactly this reason. https://github.com/Piraty/dotfiles/blob/3203d78/.config/xfce... reply zokier 12 hours agoprevAlacritty, foot, wezterm, kitty form this block of \"nextgen\" terminal emulators. I do find them difficult to differentiate. I personally use foot as my daily driver, but that is just because alacritty happened to have some issues with nvidia drivers (bleh). But I chalk that up to nvidia, not alacritty. reply padthai 11 hours agoparentFoot is Linux only and lightweight, take it as a Wayland version of Xterm with good defaults and almost no emulation options. The rest works in all major OS. Alacrity is all about GPU rendering speed at the cost of everything else (at some point it did not have scrollbars/history). Kitty and Wezterm are packed with features and more difficult to differentiate. They are all good though. reply Sammi 7 hours agorootparentThere still are no scrollbars in Alacritty: https://github.com/alacritty/alacritty/issues/775 Use Wezterm is you want a modern rust based terminal with basic nice stuff like scrollbars. reply alwillis 1 hour agorootparent+1 for WezTerm. Excellent documentation, fast and pretty much all the bells and whistles you could want in a modern terminal. reply reyqn 9 hours agorootparentprevNot sure if you don't consider Windows a major OS, but Kitty doesn't work there. reply padthai 8 hours agorootparentI actually use it in Windows (WSL2) but good point it does not work natively (so no Powershell/CMD). reply d0mine 2 hours agoparentprevI haven't stumbled upon any issues with alacritty + nvidia (lucky, perhaps). Though, mostly, I use vterm in emacs (unmatched customization & integration) reply eviks 6 hours agoparentprevwezterm is the most flexible with its lua config, big differentiator Then being x-platform is also an easy differentiator of the 2 reply imbnwa 6 hours agorootparentCan't live without Lua config reply ploum 11 hours agoparentprevAss I use Offpunk to surf the web and Chafa to display picture, my main concern is displaying images using the sixel protocol (or, in the case of kitty, its own protocol). Last time I tried, Alacritty didn’t support sixel (while even xterm supports it) reply la_oveja 12 hours agoprevi do prefer kitty[0] if i want a modern terminal emulator [0] https://github.com/kovidgoyal/kitty reply ivolimmen 11 hours agoparentMe too. Nothing beats the \"CTRL + SHIFT + G\" option (open last output in less); no other terminal has it. reply klibertp 5 hours agorootparentI wrote something similar on top of TMUX and zsh. I use zsh hooks to dump the current TMUX pane to a file (/tmp/lastcmd) just before a new prompt is displayed; I also set variables $O1, $O2, ... to respective output lines. It never occurred to me to bind `less /tmp/lastcmd` to a key, though - good idea :) (BTW: the problematic part was to make it fast enough not to be noticeable. The code that dumps the pane contents and searches for the start of the last output is written in Nim, in effect.) It was possible in TMUX because it gives you programmatic access to the pane's content. It's probably possible to do the same with some terminals - urxvt uses Perl as an extension language, for example - but TMUX provides a compatibility layer, which means I don't need to rewrite the whole setup if I change the terminal emulator. reply akx 8 hours agorootparentpreviTerm2: cmd+shift+a = select output of last command. I can then cmd+c, open whatever editor I want (or `pbpasteless` if I want `less`). reply Tyr42 7 hours agorootparentTIL, thanks. reply jemmyw 11 hours agorootparentprevI didn't even know about that and I've been using kitty for years reply ossusermivami 8 hours agorootparenttry kitty-scrollback as well https://github.com/mikesmithgh/kitty-scrollback.nvim for scrolling back via neovim... reply skywal_l 11 hours agoparentprevMy understanding is that kitty has an automatic (opt-out) update feature [0][1]. I don't really like the idea of a terminal doing that. However I like the fact that kitty developer(s) actively improved the state of the terminal emulation with their new keyboard and graphic protocols [2]. [0] https://github.com/kovidgoyal/kitty/issues/2481 [1] https://github.com/kovidgoyal/kitty/pull/3544 [2] https://news.ycombinator.com/item?id=40378357 reply aumerle 11 hours agorootparentNope, that's an update notification not an update. And its opt-in if you use kitty via a distribution package and opt-out if you use the standalone kitty binaries distributed by the developer. See https://sw.kovidgoyal.net/kitty/conf/#opt-kitty.update_check... reply skywal_l 11 hours agorootparentFunny, I always use the binaries distributed by the developers whenever I can thinking that the less intermediaries the better. Maybe I need to revise that position. reply sudo_chmod777 10 hours agorootparentThat's... quite a Windows mindset. reply lupusreal 10 hours agorootparentprevMalicious distro packagers are virtually unheard of, and another set of eyes on the software is generally better. For instance, if the developer sells out the packager can save your bacon. This is especially true on Android where selling out is more common (see: the Simple Apps situation and F-Droid) but also a valid consideration on desktop Linux. reply viraptor 9 hours agorootparentI wouldn't assume anything about distro packages really. It's a higher bar in some systems (like Debian), lower in some (like nixpkgs), but the time investment to be in a position to sabotage something is quite low overall and requires little skill. Then there are not-distro packages that they easily abused over time. For example sourceforge was a respected distributor of software for a long time and they moved to adware installers. reply lupusreal 5 hours agorootparentI stick to official distro packages from distros I like, mainly Debian and OpenSUSE. Community packages are too sketchy for me, and I consider downloading packages from sourceforge/etc to be a Windowism. And while it's possible for a malicious entity to infiltrate the ranks of distro packagers, I think the threat of the developer selling out has proven to be more likely. reply bozey07 10 hours agorootparentprevI certainly see Kitty is as a little crufty (\"feature-packed\" to some), but from my limited research it appears to be one of the fastest, so I can't really complain :-) reply crizzlenizzle 10 hours agoparentprevNice, I like lightweight and modern terminal emulators. Just installed kitty and compared it in a sloppy way to foot [0] (by running `xxd /dev/urandom` side-by-side) and foot appears to be faster. [0] https://codeberg.org/dnkl/foot reply Ferret7446 8 hours agorootparentkitty is written in Python, which instantly lowers the ceiling for performance by an order of magnitude. I discarded it as an option in the past: the most important requirement for me is the terminal cannot crash, and I can't trust a Python program to do that. reply lima 7 hours agorootparentMuch of kitty is written in C, particularly the (very fast) rendering pipeline. reply FireInsight 8 hours agorootparentprevI like Kitty graphics protocol, but never used it. Didn't know Kitty was python, always assumed it was compiled due to the reported speed benefits. Maybe I'd benefit from switch to foot since my setup is mostly wayland nowadays, extra startup speed would be great. Foot seems to also have working terminal clipboard integration with `micro` too. reply majoe 8 hours agorootparentprevFoot is really great. I often open terminals for executing single commands, so I appreciate its short startup time reply anticodon 8 hours agoparentprevkitty is nice, but it has a problem with garbled unicode sequences (e.g. if you accidentally cat a binary file to standard output). It sometimes hangs up for a minute or two on seeing invalid unicode sequence. At least that was the case for several years, and so I switched to alacritty because it doesn't have this problem. reply entuno 11 hours agoparentprevNot to be confused with KiTTY, the (seemingly abandoned) Windows SSH client based on PuTTY. reply ctenb 12 hours agoprevI tried to use alacritty in the past, but moved to wezterm eventually, because of it's superior customizability and features. reply Sammi 7 hours agoparentWezterm gives you basic stuff like scrollbars that Alacritty refuses to do: https://github.com/alacritty/alacritty/issues/775 reply yoyohello13 1 hour agorootparentI'm glad Alacritty is so conservative with adding features. There are plenty of options for \"feature packed\" terminals. I use tmux for scrollback, panes, tabs, etc. So I'm happy there is an option for a barebones GPU terminal. reply TheSmoke 9 hours agoparentprevsame here. it's been around 2 years since I moved to wezterm. pretty happy with it. reply karolist 12 hours agoprevI tried it for a few years a while back on macOS but it somehow felt off, I don't remember why, something to do with mouse selection. I went back to iTerm2 and that's that, you couldn't view images with feh and similar tools in macOS terminals for some reason so I had no reason to stay. Out of interest, why would I want anything faster than iTerm2 anyway? Never felt that my terminal is slow. reply jwells89 3 hours agoparentOn Mac, I have yet to find anything that can top the combo of Apple Terminal with the now-defunct Visor/TotalTerminal[0] haxie. Apple Terminal meets my needs well enough and TotalTerminal’s implementation of quake-style dropdown was the smoothest I’ve encountered on any platform. iTerm2 has a dropdown window that can be enabled, but it’s surprisingly much more janky than TotalTerminal’s was despite being a first-party feature instead of a hack. [0]: https://totalterminal.binaryage.com/ reply Myrmornis 11 hours agoparentprevThe main problem with iTerm2 is that the configuration is not via plain text and so it's impossible to keep track of your config in git. (I did try the dynamic profiles feature for a couples of years, but it's not the same). I use alacritty now, but I'm sure wezterm etc are also great. reply theonething 11 hours agorootparentin Settings -> General -> Preferences is a checkbox labeled \"Load preferences from a custom folder or URL. I have that checked and the configs are saved in a text file of plist format. reply ngcazz 11 hours agoparentprevInput and rendering latency are much better in Alacritty than iTerm. If you spend a lot of time editing large files in Vim it's certainly noticeable. reply jr-14 11 hours agorootparentI've had the same issue with iTerm using neovim, rendering latency was just too much iTerm. However instead of Alacrity I've opted to use wezterm as it's nice to use Lua for both neovim and my terminal config. reply platzhirsch 12 hours agoprevSince it's the year of Wayland desktop I prefer foot https://codeberg.org/dnkl/foot Renders faster than Alacritty or kitty. reply SushiHippie 9 hours agoparentSame and it also opens faster, which is important for me, as I use a tiling window manager and open/close terminals fairly often instead of using something like tmux. reply Maledictus 9 hours agoparentprevbut it is also the year of Rust, that's why I, in 2024, prefer Alacritty. ;) reply jrgirvan 10 hours agoprevAs I broke away from windows a few years ago, I used the default terminal in popos, then got a Mac as my work machine. Then broke away from vscode to neovim and didn't like the default Mac terminal or iterm2, looked for a cross platform terminal, found alacritty and haven't looked back. Are there other non-gpu accelerated terminals that would work just as well? Probably, but alacritty is installed, configured and works well for me reply pasc1878 9 hours agoparentWhat reasons do you have for not liking iTerm and Terminal.app and what does alacrity do better? reply lionkor 12 hours agoprevUsed it, its everything you need most likely. And it somehow managed to become popular and advertise itself without the \"written in Rust\" tagline. I like that. Ofc its written in Rust. reply eviks 12 hours agoparentOfc there was a tagline. Check the announcement post in the repo's readme, it's your typical \"blazing fast Rust\" > Alacritty is a blazing fast, GPU accelerated terminal emulator. It’s written in Rust and uses OpenGL https://jwilm.io/blog/announcing-alacritty/ reply bjoli 11 hours agoprevIt says to use a multiplexer for tabs and splits, but doesn't that negate some of the performance claims? Tmux and screen are pretty notorious for slowing things down. reply grawp 11 hours agoparentI use window manager for tabs as it should be. No need for some stinky multiplexer. reply Lio 8 hours agorootparentI think it's unfair to label tmux \"stinky\". It is slower, that's true, but so many times I've had to restart my terminal or I've quit it accidentally and tmux has saved my bacon. Performance is adequate (for me), it's cross platform and gives me multiple cut/copy buffers. reply gorgoiler 10 hours agoparentprevOh that’s very interesting to hear about tmux increasing latency. I’ve not heard this before but now you mention it, it seems obvious. Could you elaborate? reply soraminazuki 8 hours agorootparentTerminals emulators aren't aware of tmux panes, so it'd likely needs to redraw the whole thing if even a single pane changes. reply weinzierl 12 hours agoprevAlacritty is cool and deserves the attention but I think wezterm totally underrated and does not get enough. reply CowOfKrakatoa 11 hours agoparentWhy? Did you try both and what did you think? reply ikornaselur 11 hours agorootparentI used Alacritty for couple of years, before switching to WezTerm almost a year ago. There were two reasons for my change, the Alacritty devs are really obsessed with speed, which is good, but.. means less features, even _optional_ features like ligatures. I like ligatures, and because they slow down the rendering slightly the alacritty devs do not want to include it[0] The other reason is that I wanted a way to have my terminal have two different colorschemes, light for the day and dark for the night. It seems that it might be supported now with alacritty[1]? But it does also seem like you need an external script still to do it.. I went with WezTerm because it supports both natively, everything else feels the same TBH, but the fact that WezTerm has more features that are optional, is what I liked. [0] https://github.com/alacritty/alacritty/issues/50 [1] https://github.com/alacritty/alacritty/issues/6578 reply weinzierl 43 minutes agorootparentprevYes, I did, but it's been a while and I don't remember off the top of my head the details why I settled with wezterm. What I can say is, that I find wezterm configuration quite pleasant. Overall I think they are in the same league but Alacrity gets a lot more attention and that's why I like to remind people that there is wezterm too. reply botanical 12 hours agoprevDevelopment of features are a bit hindered in Alacritty; kitty and wezterm on the other hand, have useful features and have been really good. Personally, I'm using kitty for the past month. reply absoluteunit1 2 hours agoprevMoved to Alacritty from iTerm2 recently. The biggest plus was the simple text config. I actively make a lot of changes to my config (always experimenting with different shortcuts and other things) and updating configs on multiple machines (work and personal) became a headache. This solved that for me; can just commit any changes to the text file and pull on other machine. reply izoow 11 hours agoprevI've been using Konsole and I only relatively recently found out how powerful its tab/split management is. You can drag and drop tabs between different windows, and you can drag and drop panes between different tabs to create splits, which also works even between tabs in different windows. reply dsincl12 12 hours agoprevMy shoutout to Ghostty (by Mitchell Hashimoto & community). Although still in beta, hands down the best terminal I've used on both Mac and Linux. reply monsieurbanana 12 hours agoparentIt seems to be a private project that might one day be public, a bit of a non-starter if you can't get access to it. reply deadbolt 5 hours agoparentprevDo you know the dev, or is there a waitlist somewhere where I could possibly get access to try it out? I couldn't locate one on their site. reply wonger_ 4 hours agorootparentThe closest thing is a Discord server linked in this post: https://mitchellh.com/writing/ghostty-devlog-003 Beta invites are nearly random, though. reply swah 9 hours agoparentprevIs there anything \"life changing\" about it, or more like \"out of my way\" quality? reply YorickPeterse 6 hours agorootparentIt's more the latter: Ghostty doesn't introduce any groundbreaking features, instead it's a bunch of incremental improvements/nice-to-have's. reply kyriakos 3 hours agoprevI used to use it on windows until Microsoft released its Windows Terminal and switched over. Any reason to switch back? Windows terminal seems snappy enough. reply acheong08 12 hours agoprevAlacritty doesn’t do well with modifier keys and a lot of keyboard shortcuts don’t work in neovim by default. I recommend using foot instead. reply hkwerf 12 hours agoparentI've been using both for a while and cannot remember having any issues like this. reply asdwar532grf 12 hours agoparentprevNever had any issues with alacritty/neovim, but foot is much faster. Sadly no ligature support though: https://codeberg.org/dnkl/foot/issues/57 reply yjftsjthsd-h 12 hours agoparentprevCan you give an example? I've never hit that, but I might not be using it that hard reply acheong08 11 hours agorootparentAny shortcuts with control/alt don’t work unless you add keybindings to the config with escape sequences. Some distros give you the config by default but that breaks other things such as jumping to the start of a command with ctrl+a reply Fluorescence 7 hours agorootparentThat is not my experience: ctrl-a jumps to the start of a command. I've not seen any issues with Ubuntu, tmux and fish. All tmux and fish keyboard shortcuts have worked without any alacrity configuration (that I can recall). My tmux config adds shortcuts to behave like a conventional tabbed window without any issues e.g. ctrl-n (new tab), ctrl-w (close tab), ctrl-page-up/down to navigate tabs. reply perth 12 hours agoprevThis project looks very cool. Worth noting however that it doesn’t have tabs. reply jabwd 11 hours agoparentIt has tabs on macOS at least, but it f alls in the classic pitfall of cross platform applications where they made the mistake of not using the OS to resolve keystrokes. So my keyboard layout doesn't work with the app at all. I've identified the issues but making a pull request for it and testing it all is a bit of work I haven't gotten round to yet. reply karlshea 12 hours agoparentprevI just tried it and tabs are working at least on Mac. reply Piraty 6 hours agoprevA look at terminal emulators. https://lwn.net/Articles/749992/ https://lwn.net/Articles/751763/ reply swah 9 hours agoprevShout-out also for this smaller project: https://github.com/raphamorim/rio reply mactavish88 8 hours agoprevBeen using Alacritty daily for over a year now on Ubuntu for paid and unpaid (hobby) work and it’s exactly what I need: something that doesn’t get in my way, and it renders nicely. Performance on a ThinkPad with Nvidia graphics card is great. I primarily use it alongside tmux and NeoVim. reply amne 12 hours agoprevI gave it a shot on windows with wsl2. I hit some weird config gotchas because they switched to toml but didn't think it through too much (not a good sign). Then I just could not get my shortcuts to work with tmux and nevim. I use M+pgup/pgdn for session nav and S-left/right for window nav and instead of trying to break my config to get them to work I just gave up. I didn't see any benefits so went back to Windows Terminal. reply asabla 12 hours agoparentHad similar issues as well. I use a Nordic layout for my keyboard (which includes åäö). These extra characters were a pain to bind certain key combinations to. reply naranyala 4 hours agoprevtry the new alternatives [0] https://github.com/raphamorim/rio [1] https://github.com/contour-terminal/contour reply jmacc93 11 hours agoprevI use Alacritty and really like it :). I use it primarily for scripts and other cases where I want a terminal to open extremely fast. Some day I'll get around to finding a way to easily use tabs in it and I can replace Terminator (which I also really like and use, of course; but its a lot slower to open) reply serial_dev 11 hours agoparentI went with learning tmux, it's the industry standard, it has tabs (windows), you can customize it. Although the learning curve was a bit steeper than what I wanted just to have tabs, it works reliably unlike other things I found. reply urmish 2 hours agoprevwezterm + ssh + zellij on remote machine has been working like a charm for me. reply paulcarroty 7 hours agoprevTwo main problems: - no ligatures - no sixel support So I was forced to remove it. reply rsp1984 11 hours agoprevAt the risk of missing something completely obvious: where's the \"emulator\" part in it? What is it emulating? It looks like a terminal (no emulator) to me. Not trolling, just trying to learn. reply pleasecalllater 10 hours agoparentThis is a terminal https://en.wikipedia.org/wiki/Computer_terminal#/media/File:... The software is just emulating the terminal behavior. https://en.wikipedia.org/wiki/Computer_terminal reply rsp1984 10 hours agorootparentThank you. I think it's a bit misleading then to call it a \"terminal emulator\". It's not really emulating one of those old boxes, is it? It's providing a text interface to a computer's functions. That's great but it's not emulating anything. reply debugnik 8 hours agorootparentIt emulates them in the sense that they implement a virtual display and keyboard for the same wire protocols those old boxes used. Those protocols are mostly plain text, but also escape sequences for cursors, colors, layout, etc. Check out the VT100 sequences for example. reply paholg 11 hours agoparentprevLike all similar software, it's emulating a physical terminal: https://en.m.wikipedia.org/wiki/Computer_terminal. reply 5e92cb50239222b 11 hours agoparentprevIf you can get through this, I highly recommend it. https://www.linusakesson.net/programming/tty reply Evidlo 11 hours agoparentprev\"Terminal\" used to refer to a dumb computer that would send user input to a remote mainframe and receive instructions for drawing to the screen. reply enthus1ast 12 hours agoprev'terminator' anyone? reply platzhirsch 11 hours agoparentLoved that one! At least until I discovered tmux and then later on tiled window managers. reply h4kor 12 hours agoparentprevYes! reply fr4nkr 11 hours agoprevI've grown dissatisfied with it, but I can't be assed to switched to anything else since it's the only terminal emulator that renders fonts well, at least on my machine. reply roydivision 12 hours agoprevCurrently my terminal of choice on WSL, coupled with tmux. Works ok, a few bugs, doesn't work well with neovim, character artifacts remain sometimes. But on the whole steady and reliable. reply eternauta3k 12 hours agoparentOne day we'll have a perfect tabbed terminal without tmux bugs. I've been through a bunch of candidates already, Tabby seems to sort of work (mostly). reply evilroot 12 hours agoprevBeen using alacritty for few years but moved to wezterm recently. reply CowOfKrakatoa 11 hours agoparentWhy did you move? reply Zizizizz 2 hours agorootparentAlso fast, the dev is really nice, supports font ligatures, prefer lua config. reply evilroot 6 hours agorootparentprevbasically I don't need to use tmux anymore to manage my tabs and windows reply hawk01 10 hours agoprevInitially the only terminal which supported Wayland. Never looked back ever since reply Veraticus 12 hours agoprevStill no ligature support. There are better alternatives out there — kitty is what I chose. reply jhchabran 11 hours agoparentSame I love my ligatures to death. And there are some interesting goodies. I find the author take on `tmux` being unecessary interesting, albeit it's a quite divisive opinion. Nevertheless, it's refreshing to see the status quo being challenged. But on the other hand, while I totally understand why https://sw.kovidgoyal.net/kitty/faq/#i-get-errors-about-the-... exists, it's quite annoying to handle that, as we often take this bit for granted. It makes sense from a tech pov, but not from a product one. It's a choice and I respect that. It didn't prevent me to use Kitty for years. reply sgarland 7 hours agorootparentI liked kitty, but this was part of what drove me away. My terminal at work spans the bottom half of my monitor, and is typically split into 2-3 panes. I’ll also have multiple named windows at any given time. This works amazingly well for me, and I have no desire to switch. My other problem was having TERMINFO available on remote servers. I’m not about to start installing alternative terminal emulators in prod, and while there is a workaround to losing control characters, IIRC it’s a pain. reply executesorder66 9 hours agoparentprevWhy would you want ligatures? I would prefer to see text as it actually is, not combining multiple characters into one. I can't trust what I am seeing if I know the text might be something it is not. reply alpaca128 8 hours agorootparentSome writing systems like the Arabic script require ligatures for correct text rendering. I think supporting the third most widely used language worldwide is reasonable. Also ligatures are optional, you aren't affected if you don't like the feature. reply eviks 6 hours agorootparentprevThink you can still trust what you're seeing because the char width is different, so it's not hard to differentiate Some prefer text to be seen as it was meant to be, so that === ugliness that can't be fixed at the source due to bad unicode support can at least be fixed at the output reply intothemild 11 hours agoparentprevExactly the same terminal, and the same reason for why I use kitty. reply siproprio 5 hours agoprevI prefer wezterm. It comes bundled with libssh, connecting through ssh to WSL instead of going through wsl.exe makes everything feels at least 100x faster, since it avoid going through conpty. reply KingOfCoders 11 hours agoprevCouldn't get it to nicely play with WSl, I now use Tabby reply keyle 12 hours agoprevIf you're on a mac, wouldn't be best to adopt iTerm2 with its metal rendering? Isn't OpenGL deprecated on macOS? reply fathyb 9 hours agoparentAlacritty uses OpenGL ES 2.0 which is not deprecated. It's shipped OOB in macOS through the ANGLE project by Google, mainly because Safari depends on it to provide WebGL support (it's kind of OpenGL ES for JavaScript). ANGLE translates OpenGL ES so that it runs on top of Metal, D3D, or desktop OpenGL. OpenGL ES 2.0 is probably the most portable GPU rendering API there is, it pretty much runs anywhere. That said, using Metal or D3D should definitely bring noticeable improvements, especially when it comes to memory bandwidth (eg. on Metal no need to send pixels to the GPU memory for atlas-based text rendering). reply nathants 8 hours agoprevdoes it suck less though? reply XorNot 11 hours agoprevWhat's the energy use of these accelerated terminals like? Does using the GPU reduce power use on mobile? reply uggwar 5 hours agoprevNo AI?! reply squigz 11 hours agoprevWhat problem is having a \"fast\" terminal solving? I've been using urxvt for years and have never really found it to be slow. Where might I notice a difference with these \"modern\" \"GPU-accelerated\" terminals? reply jhchabran 11 hours agoparentThe delay in between typing and seeing it rendered, drawing large portions of text (which matters if you spend a lot of time in term based editors) etc ... It's very subjective: some folks (me included) will notice the difference and feel frustrated if it's not fast enough, while others are scratching their head about how it actually makes a difference. It could also be said, that it's of logical to expect certain things to be fast; especially when they've been around for so long. We're drawing text on the screen here, it should be fast. Saying it matters with anything else than feeling/comfort would be overreaching. reply saurik 9 hours agorootparentThe issue is that usually these terminals mean \"higher throughput\" when they say \"faster\", not \"lower latency\". The lowest-latency terminal in every test is Xterm, often by a LOT. Alacritty for a long time was actually quite bad at latency--and notably had a high variance on its latency, which is particularly miserable--but I think it improved recently? From what I remember of these benchmarks, someone using urxvt isn't going to be impressed by the supposed speed of Alacritty, if we are talking latency (and I agree: we should be, and everyone should use Xterm, which is actually an insanely good terminal). As for throughput, I have lived in the terminal for decades, and as long as the various layers don't have massive buffers I honestly don't care how slow the terminal is: if I am dumping megabytes into my terminal backscroll I probably am going \"oh shit\" and am frantically hitting Ctrl-C... a slow terminal with a small buffer handles that almost immediately. I get the impression that there are maybe some use cases involving high-rate screen updates for apps that happen to run in consoles but are really GUIs... I don't use many of those and in fact try to avoid them, but I could maybe see an advantage for a high-throughput terminal to improve their simulated frame rate? reply GuB-42 6 hours agorootparentPeople writing fast terminal emulator care about throughput, latency and resource utilization. Kitty for instance deliberately limit throughput to keep both latency and CPU/GPU usage reasonable. Also, by what metric is xterm so fast? I accept the idea that it is fast, even the fastest, but \"a lot\" seems suspicious to me. From the keyboard to the monitor, there is a lot of hardware and driver latency, I guess tens of milliseconds, so the effect of the terminal, should be relatively minor. I suspect xterm is so fast because the tool used to test it relies on the X server, and because xterm communicates with X directly, the latency will be really low from the point of view of X, but how is it end-to-end? Do we get the same results, with, say, Wayland? reply eviks 4 hours agorootparenthere is some latency tests using an external camera, though that's Windows only, there might've been a similar one for Linux, but not sure https://chadaustin.me/2024/02/windows-terminal-latency/ The other one where xterm is uber low is https://lwn.net/Articles/751763/ is using this tool with software-based screen capture https://pavelfatin.com/typometer/, not sure how reliable that is as a proxy for end-to-end (at the time of the benchmark Wayland wasn't supported) reply mewse 6 hours agoparentprevI agree that I've never had a problem with terminal speeds on Linux. If you're using urxvt, that's probably going to do just fine. Where I have had problems has been on the Mac, where the system default \"Terminal.app\" or popular alternatives like \"iTerm2.app\" can each be catastrophically slow if you have a lot of control codes (as in, for example, rapidly paging through a large document in vim with an intensive color scheme active), and it could just take noticeable fractions of a second to redraw a fullscreen terminal window. Moving to a faster terminal emulator like alacritty or kitty did make a good quality of life improvement for me in that specific use case. reply 5e92cb50239222b 11 hours agoparentprevI only really notice it when accidentally catting a really large file. Although I prefer kitty, any of these modern terminal emulators just rip through megabytes of text in less than a second, while in older ones you have to wait for half a minute or just sigkill them. reply saurik 9 hours agorootparentYour buffer is too big: your terminal shouldn't be sitting there for half a minute, as it should be processing Ctrl-C immediately and unrelatedly to its screen updates and sending it, and the remote process should be blocked on a write to its output (which in turn should prevent it from creating more garbage due to the back pressure) because all the buffers between it and you are full. Having ginormous buffers and then wanting the local terminal to be super fast to clear them quickly is kind of pointless as the use case for streaming megabytes of garbage to the terminal and NOT cancelling the operation are effectively 0. reply barmic12 11 hours agorootparentprevEach time I see a new \"fast\" terminal emulator I bench it with my only way to do it (`time cat large-text-file`) and urxvt is really quicker than other. reply qwertox 10 hours agoparentprevI use Cygwin's mintty on Windows, and the result of `ls` is not instantaneously there. If the windows is resized to big and there are lots of files, I can see each filename get printed out one by one. In Alacritty it shows the entire result immediately. Also, you may have commands or scripts which print out a lot, like which file in a huge list is currently getting processed, where the entire execution time of the command depends mostly on how fast the terminal is able to print those messages. reply ordu 8 hours agoparentprevCompilation of a large project on a multiple cores can be slowed down by a terminal. Especially if the main language of the project is a fast compiling C. I'm not sure that urxvt can be a bottleneck, and if it can you'll not be able to notice the difference with alacritty without measurements, but with others it can be noticeable without any special equipment. reply lttlrck 5 hours agoparentprevI have used Alacritty for a few years. Right now I have about 20 open (in sway) and half of them are non-local SSH sessions... so pretty pointless. I only notice SSH latency when the VPN wobbles. Or throughput if I mis-cat a log file instead of using tail... I complain like crazy if there is any latency in gaming so it seems I'm not latency sensitive in terminals :-) or more likely: reality tempers expectations. reply sim7c00 9 hours agoparentprevalo of gpu accelearted terminals are actuallly very slow. because they add silly features. basic text i/o is almost always slower. even on a good gpu! :/ reply ubercore 7 hours agoparentprev\"fast\" probably depends where you're coming from. Moving to Alacritty (and then WezTerm) from iterm2 was definitely a very noticeable difference for me, and just \"felt\" better. Of course iterm2 isn't exactly slow, but that feeling of UI immediacy in faster terminals does help me focus on the task at hand. If your existing terminal is fast enough to not notice, I suspect you've already hit the point of diminishing returns. reply ulrikrasmussen 11 hours agoparentprevIt's mostly about the perceived responsiveness which I think also shouldn't be understated. reply dale_glass 11 hours agoparentprevAnything that dumps text on the console really fast. An example I run into fairly often is untarring a backup in verbose mode. With modern NVMes, printing out the filenames to a slow console can be a bottleneck. reply padthai 11 hours agoparentprevYou can feel it. Specially as 5e92cb50239222b says in throughput. Urxvt is not one of the slow emulators so you will notice it less specially at lower resolutions. reply ziotom78 11 hours agoparentprevI use Kitty, which is extremely fast, and I often avoid calling `tail` to print the end of a long log file: the terminal is so fast in displaying it that it's useless. Another case is when you mistakenly invoke a command that produces a lot of output. With Kitty, terminal output is so fast that the output ended before I could reach Ctrl+C. reply bardsore 5 hours agorootparentI can't remember what the issue was exactly, but Kitty does something that makes it work not-so-nice when SSHing into some machines. reply datadeft 11 hours agoparentprevYou can ask these questions about pretty much every single performance improvement project. At the end there is always a win: - cost (this is more relevant to large scale infra perf opt) - UX (this is what a fast terminal might be achieving) - energy efficiency (because energy is super cheap these are often overlooked, however battery life might be still relevant) reply jnsaff2 10 hours agorootparent> energy efficiency I care about energy efficiency deeply. But in a terminal? You can't be serious. Each terminal is in the end tied to a single person so there is no runaway scaling of instances possible. Your win in energy consumption is in the single digit watt-hours per person. One could probably compare the energy savings coming from the terminal rendering to the extra energy consumed by the developer trying to improve performance and it might turn out to be a wash. As for the perception of speed by people using the terminal. I too am very puzzled how this is different from audiophile movement where people claim to perceive minuscule differences in THD whatever metric they focus on today. It might be that I've been working over dial-up sessions and intercontinental ssh sessions and the perception of slow starts to creep in when RTT gets to 100ms range. Which is probably orders of magnitude worse and more limiting than the difference between kitty and alacritty. reply datadeft 9 hours agorootparent> But in a terminal? You can't be serious. After reading Mitchell's writings about terminal development I am not sure. > Each terminal is in the end tied to a single person A popular terminal runs on millions of devices. This adds up quickly. https://mitchellh.com/writing reply berkes 10 hours agorootparentprev> energy efficiency I highly doubt that offloading the rendering to a GPU is more energy efficient. I'm quite sure it's the exact opposite: GPUs are power hungry energy-eaters; commonly. reply Delk 9 hours agorootparentGPUs (namely discrete ones) often have high maximum power draw, but that's because they're generally used for tasks that require computational heavy lifting. That doesn't mean they're particularly power-hungry in terms of watts vs. amount of work done. If you offload e.g. video decoding to a GPU, that's usually more energy-efficient than decoding on the CPU. (The heavy lifting is probably more energy-efficient on the GPU, too, but that's not directly relevant here.) reply datadeft 9 hours agorootparentprevSure? https://blogs.nvidia.com/blog/gpu-energy-efficiency-nersc/ reply otabdeveloper4 5 hours agoparentprevPresumably, the same \"problem\" that gold-plated HDMI connectors are solving. reply grnakgi 9 hours agoparentprevWith stacktraces the size of a bible program execution actually slows down if my terminal isn't outputting it fast enough reply larschdk 6 hours agoparentprevIf you accidentally pipe hundreds of thousands of lines of text (e.g. from find) to stdout, you will feel the difference. Some terminals (e.g. xterm) are particularly slow and will stall until it is done processing all the output. urxvt is not the worst, but could be better, yet doesn't always achieve 60 Hz. My gripe with (u)rxvt (last I checked) is the atrocious font rendering and character spacing if you chose a full unicode/nerd font. reply diath 7 hours agoparentprevYeah, I see no difference either, I used to use urxvt for years, then switched to kitty (which is also hardware accelerated like Alacritty), but not for the supposed \"performance\" gains but because it's got better features but I can't really tell the difference. reply lupusreal 11 hours agoparentprevurxvt and xterm are also fast terminals. The noticably slow ones are gnome-terminal, konsole, etc. They have pretty bad latency in the time between pressing a key and that letter appearing on screen. reply bayindirh 5 hours agorootparentNeither Konsole nor GNOME Terminal are as lean and fast as (U)XTerm, however on day to day use, I fail to see input latency on these. I generally use 60-80WPM depending on what I write and how concentrated I am, and there's no noticeable lag from my perspective. GNOME terminal was visibly slow in the days of yore, but given that the libraries powering these are already accelerated, I don't think the difference between these \"accelerated\" terminals are as big as touted w.r.t. GNOME Terminal or KDE's Konsole. reply lupusreal 5 hours agorootparentTo be fair I haven't tried gnome terminal in some years so maybe it's improved. I have used konsole (well, yakuake, but same thing) more recently and was minorly annoyed by the latency, particularly when scrolling in emacs/etc. I have since swapped out yakuake with kitty with tdrop for the \"quake mode\" effect. reply bayindirh 5 hours agorootparentYes, Yakuake uses the same Konsole framework, but they might lag behind in terms of framework version IIUC. Konsole supports more features than Yakuake and feels a bit smoother to me since I drive both daily. Love to collaborate and make some tests with you, too. reply Shorel 11 hours agoprev [–] Modern terminal emulators not being compatible with the TERM environment variable seems insane to me. Yes, it can be unreliable at first, when your software is new. This is expected, and it changes when people start using your software. But if you don't implement compatibility with this env variable, then you are the reason it will not be reliable in any point in the future. reply lupusreal 11 hours agoparent [–] But... Alacritty does support and use the TERM variable. What you talking about? TERM should be set to alacritty, which has been in terminfo for years. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Alacritty is a high-performance, cross-platform terminal emulator that uses OpenGL, supporting BSD, Linux, macOS, and Windows.",
      "It is currently in beta, with some missing features and bugs, and emphasizes integration with other applications rather than reimplementing their functionality.",
      "Alacritty is open-source under the Apache License 2.0, with precompiled binaries available on GitHub and installation possible via various package managers."
    ],
    "commentSummary": [
      "The discussion compares terminal emulators, focusing on features, performance, and user preferences.",
      "Alacritty is praised for speed and GPU acceleration but lacks features like scrollbars and sixel support; WezTerm is noted for Lua configuration and documentation; Kitty is modern but lacks native Windows support.",
      "Users debate the reliability of distribution packages versus developer binaries, with key concerns being security, performance, rendering speed, configuration flexibility, and compatibility with tools like tmux and NeoVim."
    ],
    "points": 145,
    "commentCount": 157,
    "retryCount": 0,
    "time": 1716354560
  }
]
