[
  {
    "id": 40856030,
    "title": "Why is Chile so long?",
    "originLink": "https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long",
    "originBody": "Share this post Why Is Chile So Long? unchartedterritories.tomaspueyo.com Copy link Facebook Email Note Other Discover more from Uncharted Territories Understand the world of today to prepare for the world of tomorrow: AI, tech; the future of democracy, energy, education, and more Over 91,000 subscribers Subscribe Continue reading Sign in Why Is Chile So Long? Tomas Pueyo Jul 02, 2024 59 Share this post Why Is Chile So Long? unchartedterritories.tomaspueyo.com Copy link Facebook Email Note Other 4 Share Chile is so long, it's curved. How long is it? Why not longer? Why is no other country as thin? How does that make Chileans incomprehensible? All your answers in today’s article! Chile is as long as the US and Canada combined. Chile is as long as all of Europe! It can stretch from Norway to Morocco. From London to Baghdad! You can stack over a dozen European countries in Chile north to south. Of course, that means Chile has every possible climate. Chile is so long because of the Andes. Here's a map of elevation in South America. You can't easily pass these mountains, and the tiny sliver of land to their west is Chile. Source The mountains exist because of the Nazca tectonic plate hitting the South American one: Here's a superb (composite) image of a Chilean volcano : But why is Chile so long? Why not longer? You can get a sense by looking at a satellite map of the region. From it, can you guess where most Chileans live? You can see by comparing the satellite map and the map of night lights: Chileans live in the middle of the country, in the northern part of the green stripe. What's happening? Source Winds blow westward close to the Equator and eastward farther south. The Andes stop all the moisture from the Atlantic near the Equator, and from the Pacific farther south. That's why both Brazil and Chile have rainforests. The Chilean one is a temperate rainforest—like in the Pacific Northwest in North America. You can see that reflected in the map of South America’s forests: Source So all of southern Chile is green, but only the northern half of that is warm enough for comfortable living (and close to other countries' centers of population). That's where most Chileans live. Source What about the northern part then, the desert? That area is so dry, it can't support a large population. These flowers in the Atacama Desert only bloom every few years, when rainfall is unusually high. And since it's close to the center of South America, it has neighbors... Few locals and lots of neighbors means this area was contested for a long time after the Spanish Empire collapsed. This is a map of contested areas in South America, 1879: Peru & Bolivia went to war with Chile for that region, but they lost in the War of the Pacific. Why fight? Natural resources: guano and saltpeter. Back then, guano was the world’s main fertilizer (and this area had most of the world's guano, thanks to the climate). Saltpeter was useful for gunpowder. So why is Chile so long, but not longer? A sliver between coast & Andes Far south: too cold for another country Far north: competing neighbors Natural border there: desert. Chile won the war to get the tip. That's also why most Chileans live in the middle of the country: too cold in the south, too hot and dry in the north. You can see that effect in a map of South American roads: Cold, heat, sea and mountains make Chile a country—an extremely isolated one: And that's also the main reason why Chileans are incomprehensible: So isolated from all other Spanish speakers! Here’s some more detail, from Why Do 900 Million People Speak Spanish and Portuguese the Way They Do?: This graph shows how much the Spanish from different countries resemble each other. The greener, the closer. The redder, the farther apart. You can see some countries are very red: You see how red Chilean Spanish is? It means it’s quite different. In the beginning of Grad School, I could understand all my Hispanic classmates, but I had a hard time understanding the Chileans! I couldn’t find any great analysis on this, so if you find it, please let me know. The best hypotheses I could find were: It’s the farthest region from Spain, so the least communicated to the rest of the empire, and hence the one that drifted the most from the homeland. It’s extremely isolated by the Andes, the ocean in the west, the ice in the south, and the desert in the north, making its connection even to Argentina, Bolivia or Peru really hard. It didn’t have silver mines, or a climate for sugar or tobacco farming, so it wasn’t a particularly valuable place to exploit, and remained secondary in the empire, getting fewer visitors from other parts of the empire, and drifting further apart. It has strong influences from other regions, such as German, Italian, or even Basque. But why is no other country as long? You need: A sandwich between sea and continent Oriented north-south, so that it changes climates quickly Far enough from the equator so that the north-south climate does change fast, and so that it’s not too densely populated. The sandwich requires an oceanic plate subducting under a continental plate, which only happens here: From there, take out the areas that are equatorial or too cold: In the western Pacific, that leaves islands, mainly Japan, New Zealand, and maybe the Philippines. But in this part of the world, the mountain chains start from deep under the sea, which generates archipelagos rather than a continental sliver. In the eastern Pacific, it leaves Chile and the US – Mexico – Canada west coast. An elevation map shows how a country could have been viable here: West of the mountain chain that runs through all of the American continent, you can see the green sliver that could have been a country. So why don’t we have a Chile of the north? Mexico was close to Spain, had silver mines interesting to Spain, smaller mountains than the Andes, and is much narrower from sea to sea. All of this made the country much better communicated east-west, so the western coast couldn’t evolve as a separate entity. Uncharted Territories is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber! Subscribe In the US and Canadian coast, the US conquered that area from the east extremely fast, making the independence of the West Coast impossible. We can imagine that, if these regions had been left to continue developing for a few thousand years, a distinct country (or set of countries) would have emerged in the west. So that's why Chile is one of the longest—and the thinnest—countries in the world! If you know somebody who’d enjoy this article, show you think about them and share it! Share Uncharted Territories is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. Subscribe 59 Share this post Why Is Chile So Long? unchartedterritories.tomaspueyo.com Copy link Facebook Email Note Other 4 Share",
    "commentLink": "https://news.ycombinator.com/item?id=40856030",
    "commentBody": "Why is Chile so long? (tomaspueyo.com)617 points by trevin 6 hours agohidepastfavorite204 comments throw4847285 5 hours agoWhen I went to Chile I was about to undertake a cross-country move across the US. Everybody I spoke to in Santiago couldn't imagine a country where you can drive a massive distance like that and move from one major metropolis to another. At the time, I thought they were just reflecting on the fact that Chile is a country where 40% of all people live in one metro area, so there isn't another huge metro area to move to. Looking at those maps, I understand their incredulity. Because of the shape of Chile, you can drive a similar distance and basically cover the entire country, rural, urban, and suburban. It's both a large country and a small one at the same time. reply aeyes 2 hours agoparentThe Concepción metro area is 1 million people, Valparaíso/Viña as well. Chileans love to point out that there isn't much outside of Santiago but it's not really true. reply throw4847285 2 hours agorootparentI was talking to Santiaguinos, so I took it with a grain of salt. reply flobosg 2 hours agorootparentprevWhile that might be true, Chile is a very centralized country, unfortunately. reply jkaptur 39 minutes agorootparentprev\"View of the World from Ruta 70\" reply Izikiel43 29 minutes agoparentprevThat's chile, Argentina is more similar to the US, however most people move from X => Buenos Aires. reply bwanab 2 hours agoprevThat is a really nice bit of information communication. Hat's off! I feel like I learned a lot and that always makes me happy. One quibble. At the end it mentions why Mexico's west was of interest to the Spanish, but neglects possibly the most important part - it was where the Spanish galleons from the Philippines first landed after the grueling trip across the Pacific as detailed beautifully in Neal Stephenson's \"Baroque Cycle\". reply idontwantthis 1 hour agoparentAnd the real history in 1493 by Charles C. Mann. Samurai were documented as guards on galleons brought to Mexico. It needs to be a movie. reply piuantiderp 1 hour agorootparentIf I recall there were also some Aztecs or Mayans brought to fight in Phillipines and SEA reply Perroboc 1 hour agoprevWow, it's wonderful to see my country mentioned here! And the article has a lot of content I didn't know about, too. reply throwup238 5 hours agoprevMy key takeaway from this article is that the best place to go see the Milky Way is deep in the Amazon rainforest… where the tree cover is nearly 100% and there isn’t a single road for a hundred miles. That’s a neat collection of graphics. I’m curious how bespoke the creation process is for each graphic or if this is something everyone just does in ArcGis or similar. That last graphic about the Western US being the only other candidate is interesting because the two sides of the Rockies weren’t connected by a highway until the I70 over Glenwood Canyon was completed in 1992. Before its completion, the western and eastern halves of Colorado were practically different states and it took the interstate highway project half a century to get there because the terrain was so challenging. reply fullstop 4 hours agoparent> My key takeaway from this article is that the best place to go see the Milky Way is deep in the Amazon rainforest… where the tree cover is nearly 100% and there isn’t a single road for a hundred miles. Check out Cherry Springs State Park in Pennsylvania: https://en.wikipedia.org/wiki/Cherry_Springs_State_Park reply jaggederest 1 hour agorootparentPine Mountain Observatory, if you're on the West coast, has some of the darkest skies, best weather and stable atmosphere for good seeing. 24 inch telescope, too. https://pmo.uoregon.edu/ reply tambourine_man 1 hour agoparentprevIt rains almost everyday, mostly in the late evening and night. My guess is clouds would be your main concern, not light pollution. reply FinnKuhn 5 hours agoparentprevThe problem with your takeaway is that you a) won't be able to realistically get deep into the amazon rainforest and b) the tree canopy would cover all of the sky ;) reply namenotrequired 3 hours agorootparentYep. It's way easier to take a boat to the middle of the ocean - fewer roads than even in the amazon :) and the best starry sky of my life reply probably_wrong 34 minutes agorootparentThis is a dream of mine, to soend the night far away from land that there's nothing around but water. Did you already have sea experience, or did you just rent a boat and gave it a try? reply HPsquared 4 hours agorootparentprevAlso, there's likely to be cloud cover and mist, etc. Rainforest! reply w4der 33 minutes agoparentprevNot really, that would probably be the north of Chile on the Atacama desert, there's a reason why the Extremely Large Telescope, Giant Magellan Telescope and Vera C. Rubin are being built there. reply msmitha 11 minutes agorootparentCan confirm, was there in 2001. The clarity of the air owing to lack of moisture and no light pollution means you get amazing views of the milky way. reply jprete 5 hours agoparentprevI think the graphics have numerous sources and mostly/entirely aren't made by the post author. There are five different styles in the first six map images! reply tylermw 54 minutes agoparentprevSeveral of the maps were made by Twitter users @researchremora and @cstats1, using R and the rayshader package. reply grecy 4 hours agoparentprevI've been to many places around the world from the Amazon rainforest to the Atacama Desert in Chile to right around Africa. Without a shadow of a doubt, the interior of Australia is STAGGERINGLY the best for stargazing. It's not even close. This was a single 8 second exposure. [1] and I'm not a great photographer. The milky way was so bright it kept me awake in my tent. [1] https://www.instagram.com/p/CersLuLBfCz/ reply helpfulContrib 22 minutes agorootparentAustralian here, spent my youth in the deep West. I found your description inspiring. I remember feeling, once, that night time was when everything in the universe could be seen, and daytime was when we slept in the shade of the sun, away from it all. reply xeromal 2 hours agoparentprevIt's a fantastic drive if you've never done it reply AnimalMuppet 4 hours agoparentprev> the two sides of the Rockies weren’t connected by a highway until the I70 over Glenwood Canyon was completed in 1992. US 40, 6, and 50 would like a word. They weren't connected by an interstate before that. But you said \"highway\". US 6 was a highway, and it ran through the exact same Glenwood Canyon. reply throwup238 4 hours agorootparentFair point about the exact terminology but those are tiny two lane roads with impassable grades for the majority of commercial traffic. The term highway has drifted in colloquial use (hence your use of the word “was”). reply AnimalMuppet 4 hours agorootparentYes, they were two lane roads. But no, they did not have impassable grades. Neither Loveland nor Berthoud Pass were easy, especially in winter, but they did in fact carry lots of commercial traffic (though I would think twice about sending an oversized load over them). In fact, to this day the old two-lane road of US 6 over Loveland Pass is used to keep hazardous material out of the I-70 tunnels. I mean, I remember around 1968-69, before they finished building Interstate 80 up Echo Canyon, and that tiny two-lane road had to take all the commercial traffic that there was on \"the main street of North America\". reply fluoridation 5 hours agoprevHow is the table of dialects constructed? It's obvious if two dialects are at 1, but what does it mean if they're at 0? They can't be mutually unintelligible, since that would make them different languages. I ask because the dialects spoken in Argentina and in Uruguay are practically identical, save for a few regional words. If the scale being used puts them at 0.35, then it makes me wonder about the usefulness of the scale. reply jhbadger 4 hours agoparentDialects can mean very different things hence the old joke \"a language is a dialect with its own army and navy\", recognizing that the issue is really political rather than linguistic. Many Chinese dialects (like Mandarin and Cantonese) are considered dialects of the same \"Chinese language\" for political reasons but are mutually unintelligible, whereas Danish and Norwegian (the majority bokmal dialect anyway) are considered different languages even though they are pretty mutually intelligible because Norway and Denmark are different countries. As for how the table of Spanish dialects was constructed, the figure gives the link to the paper it was from [1]. Basically they measured differences in dialects by giving pictures of an item (the example shown is a pinwheel) and asking what Spanish speakers from different places called that thing. Given hundreds of different concepts you can see how close Spanish dialects are to each other. [1] https://www.degruyter.com/document/doi/10.1515/opli-2018-003... reply fluoridation 4 hours agorootparentOkay, so the article is wrong for using that bit of data for the argument. It doesn't tell you much about how well two people from two different places will understand each other. If two people are in the same place and one says to the other \"¿me das la veleta?\", but the other would have called the object \"molinete\", chances are they could probably understand what the other person is saying. What makes different dialects of Spanish difficult to understand each other is slang and accent, not different words for common objects. Like, if a Spaniard tells me \"Mariana está en el ordenador\", I'm not going to get confused about what he means even if I would have called it \"computadora\". reply jhbadger 4 hours agorootparentTrue, but that's like saying a British person wouldn't be confused by the phrase \"the trunk of my car\" said by an American even if they would would say \"the boot of my car\" themselves. The fact still remains than \"trunk\" is US dialect and \"boot\" is British, and that the dialects are different. reply fluoridation 3 hours agorootparentI'm not saying the dialects are not different, I'm saying the fact that they're different is separate from how mutually unintelligible they are. Correlated? Yeah, sure. Equivalent? Not even close. reply servilio 3 hours agorootparentprevI agree with you, differences in pronunciation, cadence, etc. should be taken in account as well. Though measuring those could take longer, if possible. reply posix86 4 hours agoparentprev> but what does it mean if they're at 0? They can't be mutually unintelligible, since that would make them different languages. I think it might actually mean unintelligible. If you read on the term \"dialect\" https://en.wikipedia.org/wiki/Dialect it says in part: > There is no universally accepted criterion for distinguishing two different languages from two dialects (i.e. varieties) of the same language. The difference between language is more culturally and politically defined than linguistically; there are different langauges spoken in the world that have a fiar overlap and elligibility, and there are different dialects of the same \"language\" that are basically untelligable. It might be sensible to just consider all spoken systems to be \"dialects\" of each other, and comparing their similarity. Not a linguist though. reply cryptonector 1 hour agoparentprevI agree. Argentine and Uruguayan Spanish are very close. I'd expect to have seen .85 or so. Argentine and Chilean Spanish are not that far apart either -- or at least they weren't 30 years ago. reply prmoustache 4 hours agoparentprevI have no idea. Also there is no standard spanish even in Spain. Like Andalucian spanish and Domenican spanish have a lot in common but vary greatly with other forms of spanish. reply albrewer 3 hours agorootparentWhen I was getting my degree, two of my classmates spoke Spanish as a first language. One was a transfer student from Madrid, and the other was an immigrant from northern Mexico. I was in the room the first time they met and tried speaking Spanish to one another. They couldn't understand each other and communicated solely in English after about 10 minutes. reply Gualdrapo 2 hours agorootparentThe funny thing is that both Spaniards and Mexicans claim to use the most neutral spanish, but you'd find their idiosyncrasies rather quickly - spaniards' 'f' sound of the letter S, and the infinite modisms and particular mexican accent on the other hand. As the Spanish empire extended its spread so widely the language grew pretty complex (as english did!) so not even the most \"neutral\" spanish speaking countries do it as the RAE intends. On the other hand, Chileans really do speak their very own language. reply Phrodo_00 1 hour agorootparent> Chileans really do speak their very own language Only informally. Formal Chilean Spanish is probably one of the most understandable ones, accent-wise. (There's still some vocabulary differences) reply flobosg 1 hour agorootparentThis idea is somewhat prevalent among native Chilean speakers, but I respectfully disagree. Even under formal settings, many of the features of colloquial Chilean variants are present, and often an additional effort to neutralize the accent needs to be made to sound “formal enough” to other Spanish speakers. reply Phrodo_00 30 minutes agorootparentOne thing is that pretty much the only place you'll see formal chilean is in like, the news, or official government communication. We're not very formal people, so even in workplaces or school we wouldn't use 100% formal register. reply flobosg 19 minutes agorootparentSure, that is largely true. But, to state that the formal register of Chilean Spanish is “probably one of the most understandable ones, accent-wise” of all available Spanish registers is, in my humble opinion, quite a long stretch. reply russellbeattie 1 hour agorootparentprevThat's a very anecdotal experience. I met my ex-wife in Madrid where I lived for 4 years and where she was from. That's where I learned Spanish as a second language. After we moved back to California, we obviously met and spoke to many Mexicans over the years. Zero problems communicating for her, ever. Spanish is still Spanish. reply digging 4 hours agorootparentprevThere literally is a standard Spanish, no? I understand it to be based on Castilian. However I understand your point that even within the country of Spain there are many dialects which diverge from \"standard\". reply umanwizard 3 hours agorootparent> There literally is a standard Spanish, no? Not really. Just like English, the standard variety in each country is considered equally \"standard\". > I understand it to be based on Castilian. I'm not sure what you mean by this. As far as I know Castilian is just a synonym for the Spanish language (as opposed to other languages of Spain e.g. Catalan). So the variety spoken in Guatemala and the one in Tenerife are equally \"Castilian\". reply digging 3 hours agorootparentNo, it's not like English. There is: https://en.wikipedia.org/wiki/Standard_Spanish. It is maintained by the: https://en.wikipedia.org/wiki/Royal_Spanish_Academy. In practice, I'm not sure what the impact is. I'm not a native Spanish speaker. But Spanish is not like English in regard to prescriptive norms. reply servilio 3 hours agorootparentSpanish native here, confirming that RSA is the institution that sets the language standard. But, people always deviate from it, though in my experience in word meanings and pronunciation, never in grammar to a degree that it become intelligible to another Spanish speaker. The toughest film to listen to for me was \"The rose seller\"[1] (1998), took me like 10m to get my ear accustomed to their pronunciation. [1] https://www.youtube.com/watch?v=ASrxQCuVT-U reply Gualdrapo 2 hours agorootparentThe paisa accent is very hard, even for us non-paisa colombians - not only for its colloquialisms but for its cadence. reply joseda-hg 3 hours agorootparentprevThere's \"neutral\" spanish, but it's less of a formal standard and more of a rough subset that people recongnize it's generally understandable to most people It being so artificial means that it doesn't fit anywhere, even it if's becoming more common (Kids are growing up listening to Media dubbed to it, so it's not weird seing a Child \"speak like a cartoon\" for a while until their local dialect kicks in) reply prmoustache 1 hour agorootparentIt is what I usually call the \"TV\" or \"media\" standard. Same in french, the french language you listen on TV is very uncommon if you actually talk to french people from different areas of France and it is not even common in Paris. reply cdelsolar 5 hours agoparentprevYeah, I was wondering about these two countries myself. Also it was very strange to see the Peru and Cuba correlation, those two dialects are nothing alike. reply A_D_E_P_T 5 hours agoprevOne of the most interesting drives in my life was Chile from the island of Chiloe to the Tatio Geysers in the Atacama. Just so many different climate zones, and all in relatively close proximity. Chiloe and Puerto Montt were damp, cold, and fog-shrouded in Summer (Jan-Feb), very similar to parts of the coastal pacific northwest. The area to its north, centered around the German-influenced town of Valdivia, was California-like. Very temperate in Summer, and very green. Lots of pastures and rivers. The region becomes progressively more \"Mediterranean\" as you move further north; one gradually sees fewer pastures and woodlands, more vineyards, olive trees, and fruit orchards. Santiago is on the far northern end of this Mediterranean zone. The great wine regions are generally to the south and west of that capital city. A few hours north of Santiago and all is desert -- but it's a fairly live desert, with all sorts of succulent plants and many types of flower. Most of the road traffic in these parts comes from copper miners and their work trucks. Continue north and you're in a dry, mostly empty, moonscape. Antofagasta and Calama are nice enough towns, though, and the interesting drive from the former to the latter takes just two hours but sees you rise from sea level to +2000m. It's such a gentle and relentless slope that you barely notice it. Nothing at all like driving in the Alps. I broke something in my rental car when I continued to the geysers at +4000m, but it was worth it. reply gottorf 3 hours agoparent> Just so many different climate zones, and all in relatively close proximity. Another place like this, perhaps lesser in scale, is the Big Island of Hawaii. Its latitude means the trade winds are blowing from the same direction year-round, bringing moisture to the windward side (e.g. Hilo, HI with 120\" average annual rainfall) and leaving the leeward side dry (e.g. Kailua-Kona, HI with under 20\" average annual rainfall), on the other side of massive volcanoes. And you can go from the ocean to almost 14k feet in elevation in an hour's drive; this may be one of the only places in the world where you can do that. All of this means that as you move around Big Island, based on the precipitation, humidity, and elevation, you're going to see wildly different environments mere minutes' drive from each other. It truly has to be seen to be believed. reply Gud 2 hours agorootparentHawaii was never on my list of places to visit until now, but now I have to go there. Thanks for sharing reply devilbunny 1 hour agorootparentIt's expensive, and it's a long way away from anything else. I've been twice and both times the Big Island was my favorite. Maui and Kauai are spectacular in their own ways, as are the few rural areas of Oahu, but there's nothing like the Big Island. The drive from Kailua-Kona to Hilo over the Saddle Road (which, in itself, goes to around 6600 ft) is spectacular, and if you have enough time to make a day of it, coming back around via the southern ring road is well worth it. If you get up early, Waimea and the surrounding area (esp the NW protuberance of land) are worth seeing as well. Huge variation in biomes in very short distances. reply Gud 50 minutes agorootparentProbably I’d go there for a few weeks. I’ll make it my first stop to the US(if they let me in). reply jghn 1 hour agorootparentprevI was recently in the big island and this was both unexpected and wild to me. The difference of a couple miles could have an enormous impact on the weather over time. We stayed a couple of days in Volcano Village and like clockwork it'd be rainy there but sunny or at least partly sunny just a few miles down the street. Then there are rain forests, cloud forests, deserts, and every thing in between. reply tim333 2 hours agorootparentprevTenerife is a bit like that. 12k feet at the top. reply bostik 39 minutes agorootparentAnd to a lesser extent, Gomera. Just by the sea, beaches and small banana plantations. Go slightly inland and up the hills, you're in an arid region. Continue slightly further up, and you get into a lush, verdant forest. All within maybe 20 minutes' drive. Best part? There's no airport on the island - you have to fly to Tenerife and take a ferry. To this day, the best tomatoes I've ever had. reply pferde 1 hour agorootparentprevYes, Tenerife is awesome, a different biome almost every few kilometers. I've been there hiking several times, and I always see something new! reply hammock 4 hours agoparentprev>so many different climate zones, and all in relatively close proximity Yes. Just mountain climbing in northern Patagonia (between Bariloche & Villarica, really only 100mi of north-south distance) became my favorite part of the world for your reason. In a single day (or two), we could walk in the dry, dusty bottom of a canyon dug out by glacier melt, cross through a humid jungle, rest on the shores of an alpine lake, pick your way across a massive rocky field of a'a lava, up a glacier and look down inside the caldera of an active volcano. The only other place I have been that come close to having that amount of diversity of terrain in a limited area might be the Tetons/Yellowstone. reply js2 4 hours agoparentprevIt's only partly in Chile, but regardless all of the scenery in A Long Way Up is breathtaking: https://en.wikipedia.org/wiki/Long_Way_Up reply pc86 4 hours agoparentprevTorres del Paine in the south is pretty brutal to get to if you're not used to long flight but it is breathtaking. Definitely a bucket list trip if you enjoy nature and wildlife, hiking, etc. reply Etheryte 4 hours agorootparentIt's nice, but unfortunately listed on nearly every tour guide of Chile, so these days it's flooded with tourists most of the time. You'll have a much better time seeing other places slightly off the beaten track. reply drroots23 4 hours agorootparentDuring the summer months yeah, but I've been there last year during the end season and, although there are still lots of tourists, it's not overwhelming and some of the hikes were pretty chill. Going straight to the Torres themselves will usually be crowded (depending on the time of the day). But some of the other hikes less so. I've done the W Circuit (a multi-day trek) and during some days I barely saw another hiker. reply dheera 3 hours agorootparentI hate visiting touristy cities but I mind don't mind it as much in nature areas. Mainly because the nature isn't changing itself for the tourists. I visited Torres de Paine and it was refreshingly different from national parks in the US. On the upside, you can get water and basic snacks at the refugios which reduce the load you have to carry, and makes for an overall safer experience than unsupported wilderness backpacking but still with minimal impact on nature. On the other hand I did not like that they close a lot of viewpoints long before sunset. reply lukan 3 hours agorootparent\"Mainly because the nature isn't changing itself for the tourists.\" Yes, but some tourists change the nature by leaving their garbage etc. reply flobosg 3 hours agorootparentOr by burning it: https://en.wikipedia.org/wiki/Torres_del_Paine_National_Park... reply lukan 1 hour agorootparentThat sounds bad, but in the end: \"Nevertheless, recent paleoenvironmental studies performed within the Park indicate that fires have been frequent phenomena at least during the last 12,800 years.\" So fires are a normal thing there, or they have tourists since 12,800 years .. reply seattle_spring 2 hours agorootparentprevOr blasting their music from a phone or Bluetooth speaker. reply dheera 3 hours agorootparentprevYeah I hate that, but at first glance it didn't seem to be a huge problem in TdP compared to most other national parks around the world I have been to. Most people I encountered seemed quite responsible. Chile is overall a very well-educated country though, and TdP takes significant effort to get to compared to so it is perhaps a natural filter. reply tuzemec 4 hours agorootparentprevReally enjoyed that. The views are surreal. Got lucky with the weather too. reply prpl 3 hours agoparentprevIt’s roughly the equivalent of British Columbia to Mazatlan, except the water is a tiny bit cooler. Santiago is the same latitude as LA, for example. I love Chiloe and Los Lagos region. I would buy a “southern summer” house there if I didn’t have kids in school. reply jvm___ 2 hours agorootparentVancouver when the cherry blossoms are in bloom is interesting, the different elevations and the different progress of the trees is fun to pay attention to. reply hinkley 1 hour agoparentprevI’m told that prior to industrialization there were areas along the Andes (in Peru for sure, presumably Chile as well) where you rarely if ever met the tribes living uphill or downhill from you. It was way easier to travel north and south. reply robarr 1 hour agorootparentQuite the contrary, the management of the different ecological floors was the specialty of the inhabitants of the Andes, even now. The same community owns and uses land at different altitudes, which can range from 1000 to 4000 meters above sea level. This generated an economy based on the exchange of goods along vertical lines. https://haubooks.org/reciprocity-and-redistribution/ https://www.nytimes.com/2006/10/24/obituaries/24murra.html reply pfdietz 5 hours agoparentprevThe Atacama Desert is exceptional, the absolutely best solar energy resource on the planet. reply speed_spread 4 minutes agorootparentBest place to build lithium batteries _and_ charge them! reply dheera 4 hours agoparentprevI travelled to Chile earlier this year and visited Atacama and Torres de Paine. The thing that boggled my mind was that you can't drive between the two without a very long detour through Argentina. Chile has literally no road linking the northern part with the southernmost part without going outside the country. It is also mind boggling that rail is not more popular there. A long, slim country is ideal for high speed rail. reply A_D_E_P_T 1 hour agorootparentI tried to cross the border into Argentina north of Puerto Montt. I wanted to check out the Argentinian side for a day or two. But they wouldn't let me across the border with my rental car, and I got turned back. I suppose the rules are a little bit different in the far south? reply returningfory2 1 hour agorootparentIf you want to bring a Chilean rental car into Argentina you need to obtain and pay for a specific permit at least a few days before you pick up the rental car. Maybe that was missing? When I crossed the border they were very thorough with checking this permit. reply Izikiel43 19 minutes agorootparent> If you want to bring a Chilean rental car into Argentina you need to obtain and pay for a specific permit at least a few days before you pick up the rental car. Classic Argentinian bureaucracy, making the country lose money since time immemorial reply flobosg 3 hours agorootparentprev> It is also mind boggling that rail is not more popular there. A long, slim country is ideal for high speed rail. See one of my other comments in this post regarding the rail in Chile. reply prpl 3 hours agorootparentprevThe bus system is very cheap though, it’s very hard to compete with that reply TremendousJudge 3 hours agorootparentprev>It is also mind boggling that rail is not more popular there That would require the upper class to mix with the poor. Not acceptable in Chile. reply OJFord 1 hour agorootparentBarely, different classes of carriage? I don't know anything about the history of trains or carriages, but in the heyday of railway development in Britain (iron rails, steam locomotive, etc.) it would have been far less acceptable than today too. And still all trains I'm aware of/have been on have two classes of carriage. Indian trains have several, and similar cultural need for that I imagine (I don't really know anything about Chile). reply mFixman 5 hours agoprevIs there a name for this simple style of writing? It reminds me of the style of pop science books written in the late 19th and early 20th century. There's a nice charm in it, like it's trying not to be pretentiously complex. reply mikepurvis 5 hours agoparentThis author wrote a number of pretty influential essays during the early pandemic advocating for mask use, social distancing, and other mitigations. He's a trained educator, so the effectiveness of communication is definitely no accident: https://fortune.com/2020/08/10/the-overnight-coronavirus-exp... reply talldatethrow 1 hour agorootparentMy gf is a trained educator too with two masters somehow related to education. She teaches 8th grade English but has also taught highschool. She can't write or communicate at any level beyond typical hairdresser. Considering it's very hard to fail out of most upper level education unless you simply don't do the work at all, we really should stop giving people so much credit for just getting degrees. It's what you do with it that matters and how you devote yourself on your own time that makes people great. And that's what the previous commenter was doing. Trying to give credit to some education system someone went through is taking away from the person that actually made something of themselves, almost always by themselves. Side note, I graduated with a MechE degree from UC Berkeley. Decent grades. I can honestly say I learned almost nothing. I just did a ton of work they wanted. If I made something of myself in the engineering field, I promise it wasn't because of UC Berkeley. reply mikepurvis 6 minutes agorootparentOkay, fair. Some people are naturally gifted at these things, and others acquire the skills through extensive work in a non-academic context. I've been told I'm a pretty effective communicator/storyteller, and I certainly never studied it formally. reply open_ 3 hours agoparentprevApart from a few other factors, the biggest one that stands out is not stringing you along in a click-baity way, instead just asking a question and giving a direct answer right after the question and in simple direct words. No dark patterns to make you spend a longer time on the webpage for ad metrics. reply hammock 4 hours agoparentprevThe author Tomas Pueyo grew up in a family of filmmakers. For his Stanford MBA he specialized in behavioral psychology, design, storytelling, and scriptwriting. I have to imagine that has some influence on his writing reply dotinvoke 5 hours agoparentprevI read it before on Twitter, it’s probably adapted to fit into the 280-character limit. reply keyle 5 hours agoparentprevHighly entertaining, keeps you surprised as you never know what's happening next, and full of images without being memes. Loved it. reply nsbk 2 hours agoparentprevI thoroughly enjoyed reading the post. A breath of fresh air among all the click-bitey and false buildup so common in content these days. PLEASE DO TRAIN THE GPTs ON THIS GUY reply err4nt 1 hour agoparentprevI thought it would be dense, but it was lighthearted and didn't take itself too seriously, and both shared information and fun questions to ask. I enjoyed the speculation which had not even a shred of political or social agenda anywhere in sight. Just pure fun. reply edouard-harris 4 hours agoparentprevIt's roughly in the style of a children's picture book. That's the same style the best startup pitch decks are written in. reply _visgean 5 hours agoparentprevhonestly it feels like a powerpoint presentation in an article. reply the_arun 4 hours agorootparentI also had fun reading the article & repeated question - why is Chile so long? and sharing another bit of twist. Nicely done. reply callalex 2 hours agorootparentprevApparently it started as a series of xhits or whatever they’re called this week. reply eatonphil 5 hours agoprevThe article mentions it, but I only learned recently that Bolivia did not used to be landlocked. Chile took Bolivia's coastline somewhat recently (late 1800s/early 1900s). > The dispute began in 1879, when Chile invaded the Antofagasta port city on its northern border with Bolivia as part of a dispute over taxes. Within four years Chileans had redrawn the map of South America by taking almost 50,000 square miles of Bolivian territory, including its 250-mile coastline on the southern Pacific Ocean. Bolivia accepted this loss in 1904, when it signed a peace treaty with Chile in return for a promise of the “fullest and freest” commercial access to port. https://time.com/5413887/bolivia-chile-pacific/ reply sidmitra 5 hours agoparentDisclaimer: I live in Chile, but not a Chilean national(nor of similar ethnicity), and certainly not a historian. The dispute is seen differently in Chile and is not as simplistic as Chile invading a port. In general i've gotten the sense that the general populace believes that Bolivia(with its secret alliance with Peru) had other intentions. >In February 1878, Bolivia increased taxes on the Chilean mining company Compañía de Salitres y Ferrocarril de Antofagasta [es] (CSFA), in violation of the Boundary Treaty of 1874 which established the border between both countries and prohibited tax increases for mining. Chile protested the violation of the treaty and requested international arbitration, but the Bolivian government, presided by Hilarión Daza, considered this an internal issue subject to the jurisdiction of the Bolivian courts. Chile insisted that the breach of the treaty would mean that the territorial borders denoted in it were no longer settled. https://en.wikipedia.org/wiki/War_of_the_Pacific >Ill-defined borders and oppressive measures allegedly taken against the Chilean migrant population in these territories furnished Chile with a pretext for invasion. https://www.britannica.com/place/Chile/The-War-of-the-Pacifi... reply cdelsolar 1 hour agorootparentChilenos weones reply aeyes 1 hour agoparentprevChile could have been even longer, during the war the Chilean army took Lima. reply Izikiel43 14 minutes agoparentprevYeah, you are missing the backstory for that, which another commenter mentioned. Bolivia violated a treaty they had with Chile, and also had a secret alliance with Peru. They violated the treaty so they would go to war with Chile, and then team with Peru and try to conquer Chile. However, Chile had a very recently professionalized army and navy trained by the Germans, whereas Bolivia and Peru had peasants conscripted. (To this day the Chilean armed forces are amongst the most trained in the world.) The result? Bolivia lost all of its coastline, and Peru also lost its southern territories. You can summarize the war as in Bolivia and Peru fcked around, and then found out. reply phaser 36 minutes agoprevChilean dialect of spanish is wild. Only a chilean can understand this: \"el weon weon, weon.\" reply Izikiel43 29 minutes agoparentIn general, other south american countries consider chilean not spanish reply onionisafruit 32 minutes agoparentprevCare to translate it for us? gpt says “The dude, dude dude” reply flobosg 31 minutes agorootparentThat guy is an asshole, man. reply racl101 2 hours agoprevThe Chilean Spanish portion of the article made me laugh. I'm a Spanish speaker and the Spanish I speak is closer to Mexican Spanish. I could not for the life of me understand Chileans I met in Canada. Brings back funny memories of 2001 for me. reply santiagobasulto 2 hours agoprevOff topic, but that correlation matrix of \"Spanish similarity\" seems a bit odd. I'm from Argentina, and the spanish in Uruguay sounds practically the same. At least A LOT MORE similar than Cuban or Paraguay as it shows there. reply DavidAdams 2 hours agoparentI'm sure that has a lot to do with the close physical proximity of the capitals of Argentina and Uruguay. reply rob74 4 hours agoprevOn the difference of Chilean Spanish to other \"dialects\": > It’s the farthest region from Spain, so the least communicated to the rest of the empire, and hence the one that drifted the most from the homeland. Er... if you look at the table (https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_...), Chile has quite a lot of red, but actually its Spanish is closer to the Spanish from Spain than that of other South American countries. So it looks like those have drifted further from \"standard\" Spanish, while Chile hasn't as much? reply mechanicalpulse 3 hours agoparent> So it looks like those have drifted further from \"standard\" Spanish, while Chile hasn't as much? I think the chart is saying less about differences relative to Spanish Spanish and more about each regional dialect relative to the others. In the table, the countries appear to be ordered (horizontally as well as vertically) by distance relative to Spain. Assuming there's nothing (like an ocean) to prevent the diffusion and evolution of language, given any cross-location in the grid, the cells nearest should theoretically have little to no gradient. That's clearly not the case with Chile and isolation due to the Andes seems like a reasonable cause. Colombia and Costa Rica also exhibit this effect, though, and I'm not sure why. FARC? They are separated by Panama and the PCZ; has the canal had an effect of preserving Panama's cultural ties relative to other countries at the expense of those of CO/CR? Edit: s/Columbia/Colombia/; s/expensive/expense/ reply woodson 2 hours agorootparentThese differences go back much further in the past, so FARC has nothing to do with it in Colombia (it’s spelled with an “o”). There’s a large linguistic diversity within these countries, which that table doesn’t reflect or account for. reply mynameisvlad 2 hours agorootparent> There’s a large linguistic diversity within these countries, which that table doesn’t reflect or account for. I’m pretty sure that’s the case for every country in the world. reply woodson 1 hour agorootparentOf course, all I said was that the table doesn’t account for it. Aside from that, judge for yourself: https://en.m.wikipedia.org/wiki/Colombian_Spanish reply wageslave99 3 hours agoparentprevPlease note that there is no \"standard\" Spanish. In the Spain there are multitude of dialects and different variants. Even in the same region (e.g. Andalusia) you can find a ton of different variants. All of them are valid, as the RAE and the AAL make it clear. reply alephnerd 3 hours agorootparentRAE is supposed to be the prescriptive source for Spanish, but no one cares about it outside of a subset of Academics in Spain. reply santiagobasulto 2 hours agorootparentThanks god we don't care. Spain wanting to dictate what's real \"spanish\" is like the King of England telling a jamaican that their english is wrong. reply walthamstow 2 hours agorootparentYes, we leave that kind of thing to the French reply aeyes 1 hour agoparentprevSomething that wasn't mentioned here before is that Chile is quite close in terms of grammar. Other South American countries supposedly have deviated more. It's hard to understand some Chilean speakers but that's because they don't modulate their voice and cut or join words. But grammatically they are \"correct\". There is a lot of Chilean slang and it's almost universally understood from north to south. But people are aware of it, it's usually not used at work. And then there are a lot of words which are just different, just about every fruit has a different name. reply prpl 3 hours agoparentprevNew Mexican Spanish is similarly isolated, but the number of speakers is tiny. reply gaudystead 2 hours agorootparentOrale! Was not expecting to see us New Mexicans get called out here on Hacker News, but you're not wrong. It's surprising how much variation there is despite NM being so close to Mexico. reply tomjakubowski 3 hours agoparentprev\"Standard\" Spanish is modern, and, like Chilean, has itself drifted from dialects which were spoken in the era of Spanish colonization. reply alephnerd 3 hours agoparentprevChilean Spanish is heavily influenced by Spanish, German, Italian, and Croat immigrants from a pronunciation and colloquialism standpoint because those were the 4 main immigrant communities to Chile. Also, Spain Spanish is not necessarily \"Standard\" (Castilian) Spanish. reply melenaboija 3 hours agorootparentMy opinion as Spaniard and having a chilean close, is that Chilean Spanish is the closest to mine in terms of pronunciation. And to me what makes the biggest difference is not European migration but native words. reply Phrodo_00 1 hour agorootparentprevMore than any of that, it's influenced by Mapuzungun in a way other countries just aren't exposed - Argentina's Conquest of the Dessert was more brutal, and is the only other modern country where Mapuche land was. reply rob74 3 hours agorootparentprevThat's why I put it in quotes :) reply alephnerd 3 hours agorootparentSpain Spanish isn't \"Standard\" Spanish though. The closest thing to \"Standard\" Spanish is what the RAE prescribes, but no one listens to them. Insurgencies and protests were fought over this fact in Spain during the Francoist and Post-Francoist era (eg. Andalusian, Murcian, Canarian, Leonese) reply Phrodo_00 2 hours agoprev> Far south: too cold for another country Chile has an Antarctic claim going all the way to the pole. If you consider that, it's impossible to go further south If you don't, then we still just run out of land in the Continent. Note that the neighbour competition also applies to Tierra del Fuego, as we've had tensions with Argentina through history over the control of Magallanes Channel. reply seu 4 hours agoprevIt completely ignores the influence of the indigenous languages in the \"dialect\" or variation of Spanish, which is actually a much better explainer than \"distance from spain\". reply novok 40 minutes agoparentHuge mountain ranges separating people that are close in distance is a pretty classic mechanism of creating linguistic diversity / dialects in places that are physically close to each other. You see this with villages in various parts of Asia historically. Indigenous language effecting Spanish is something that would effect everyone in South America, so even if you remove Spain from the table, Colombia, Chile, the Caribbean and Costa Rica will all stand out about how \"different\" they are from the rest of South America, probably from their physical barriers separating them from the rest of the continent. reply TremendousJudge 4 hours agoparentprevI don't think that's a good hypothesis, because in that case, other countries with a huge colonized population such as Mexico or Perú would have less intelligible dialects as well. reply arachnid92 3 hours agorootparentNot all Latin-American countries experienced the same level of mestizaje and colonization. The southern part of Chile, in particular, was never successfully colonized by the Spaniards, and mapudungún, the language of the Mapuche people who live there has had (and continues to have) a tremendous influence on Chilean Spanish. reply ShaggyStyle 4 hours agoprevAll of this is just because Chile is the best country of Chile... if you know what I mean ;-) reply arachnid92 4 hours agoparentSomo el mejor país de Chile hmno. As a Chilean living in the US, seeing this on HN made my day - it’s not often the rest of the world (outside of South America) remembers we exist. reply elzbardico 3 hours agorootparentBelieve me, not being remembered by the rest of the world is sometimes a blessing. reply novok 39 minutes agorootparentprevChile feels like the Canada of South America in some ways. Even has a special work visa category with the USA! reply Yawrehto 5 hours agoprevThe Atacama Desert is so dry NASA uses it to stimulate Mars. Wikipedia also lists five (!) observatories (one under construction, to be home to the Extremely Large Telescope), including the Very Large Telescope (built), ALMA (built), and others.[1] It's basically as close as you can get to space while being on the ground on Earth. [1] en.wikipedia.org/wiki/Atacama_Desert#Astronomical_observatories reply prmoustache 4 hours agoprevIs there a single chilean dialect? Surely in such a long country there must be a huge difference between northern, center and southern chilean. reply flobosg 4 hours agoparentThere are regional variations, but the difference is less than what you would probably expect, applying mostly to intonation/cadence (more marked and melodic in the south, less so in the north) and some vocabulary. Most of the variation in Chilean Spanish is based on socioeconomic status, since Chile's income inequality is rather high. reply Cthulhu_ 3 hours agorootparent> [...] intonation (more marked and melodic in the south, less so in the north) Oddly enough, albeit anecdotal, this is true everywhere; in every country and every continent, people are looser in the south. That said, if it's also true for Chile then it means it's not related to the climate. reply gottorf 3 hours agorootparent> in every country and every continent, people are looser in the south Fun to think about, but I'm sure there are as many counterexamples as there are examples. In the Germanic languages, for example, no one could deny that Swedish or Norwegian are much more sing-songy than stodgy German. reply flobosg 3 hours agorootparentprev> people are looser in the south What does “loose” mean in this context? My first impression would be that the accent in northern Chile is “looser” than the south. reply digging 4 hours agoparentprevDialect and language are sort of a \"coastline problem\". You can find variation between two neighboring villages if you like, but at some point you have to draw a boundary around a group of speakers and call it a dialect. I'd assume the common dialect of Santiago, where most people live in Chile, is considered \"the Chilean dialect,\" but it almost certainly sounds different in rural areas. reply lucideer 2 hours agoprevReading the title, my initial expectation was that this was going to be a Croatia/Bosnia-Herzegovina situation. Refreshing to read that most of the reasons here are geological/meteorological in nature. reply nikolay 56 minutes agoprevI've always concluded entirely based on maps, not historic facts, that it was conquered with a strong fleet and not enough infantry. reply flobosg 45 minutes agoparentWhat made you reach that conclusion? I’m just curious. reply danhau 2 hours agoprevI love how effective the article is at communicating. A digestible idea followed by visual example. Rinse and repeat. I think we could learn something from this for our documentations, or even Jira comments. reply timonoko 13 minutes agoprevBoring shit. But there is nothing particular happening. Just hanging there for 3 months. https://youtu.be/wGFR86yIyyA?si=BkAxEGPm0gGSqAgT reply ferrantim 6 hours agoprevThis is super interesting. Sharing with my kids who are starting geography in school this year. reply afh1 2 hours agoprevIf all articles were written like this, straight to the point and only the important bits, I would read a lot more and skim a lot less... reply cassepipe 5 hours agoprevNo excuse for not building one giant high speed multi-tracks train line from North to South then :) reply flobosg 4 hours agoparentIn the 2000s the Chilean state railway company was involved in a huge corruption scandal as well as bad administrative practices. It’s been slowly recovering, but rail services in Chile still leave a lot to be desired. reply cryptonector 1 hour agoparentprevWhatever for? As TFA notes the vast majority of Chileans live in the middle, in or near Santiago. reply fluoridation 4 hours agoparentprevExcept that the people are not spread that far out that it makes economical sense. reply __MatrixMan__ 2 hours agoparentprevThat sounds like the kind of investment in the commons that a socialist would make. In 1973 the US encouraged a coup to ensure that no such investments were made (https://en.wikipedia.org/wiki/1973_Chilean_coup_d%27%C3%A9ta...). Instead, we applied guns to the affected area and ensured that they would part with their resources as \"fair free-market prices\" (https://en.wikipedia.org/wiki/Chicago_Boys). They've started the process of removing those policies, but only in the last few years. If I had to come up with an excuse for not having trains, I'd chose that. reply golergka 1 hour agorootparentThat's why Chile is the most successful economy on the continent. reply diego_sandoval 1 hour agoprevAs a Valdiviano, I find the Santiago climate too hot and dry. I prefer the south. reply cryptonector 1 hour agoprevThat map of Spanish dialect difficulty... I can confirm. reply ableal 5 hours agoprev\"\"\" Peru & Bolivia went to war with Chile for that region, but they lost in the War of the Pacific. Why fight? Natural resources: guano and saltpeter. Back then, guano was the world’s main fertilizer (and this area had most of the world's guano, thanks to the climate). \"\"\" That fertilizer produced iconic advertising in mid XX Century Portugal and Spain: https://c8.alamy.com/comp/AR22G9/nitrato-de-chile-advertisin... reply 29athrowaway 5 hours agoprevAnother interesting fact about Chile is: no compass is needed. The mountains show where the East is. If the East is to your right you are facing North, otherwise you are facing South. reply arachnid92 3 hours agoparentIn fact, it’s so easy to know where North is that it’s very common to use cardinal directions when describing locations or meeting points in Santiago, as opposed to using landmarks. For example, when meeting a friend you may say “I’ll meet you on the north-eastern corner of the crossing of Pedro de Valdivia and Irarrázaval Avenues”, and everyone involved will know what that means. reply desas 1 hour agorootparentRelatedly, one of the claims made about the Pirahã people is that they have no words for left and right in their language, instead they orient themselves relative to the river bank. reply aeyes 1 hour agoparentprevThe coastal mountain range reaches heights of 3000m, it's not as easy if you are in the valley in between these mountains and the Andes because you'll be surrounded by mountains. https://en.m.wikipedia.org/wiki/Chilean_Coast_Range reply 29athrowaway 1 hour agorootparentBut those don't have snow in them. It is easy to tell them apart. reply KineticLensman 3 hours agoparentprevThis is also true of long linear coastlines, such as the South Coast of England, where (ignoring small bays and harbours), if the sea is to your left (right) then you are facing west (east). I was briefly disoriented when I stayed on the North coast of Cyprus where the situation is the opposite. reply the__alchemist 5 hours agoparentprevI had a similar feel driving through Croatia, although not as extreme: If you don't hit the sea or a border crossing, you are going in the right direction! (With a tau/2 ambiguity you can resolve using the sun) reply umanwizard 3 hours agoparentprevSame thing I use the Empire State Building for when in lower Manhattan. Granted that works over a much smaller area... reply pandalicious 4 hours agoprevAm I misreading this or is that \"How close is Spanish from Different Countries\" graphic kind of jank? There's intersecting lines that are missing, like Puerto Rico and Dominican Republic. reply delecti 3 hours agoparentThe intersection between Puerto Rico and Dominican Republic is the 0.42 right above the \"1\" in the PR column (5th from the left). If you imagine the full graph of all countries horizontally and vertically, there would be a lot of overlap (the PR column and DR row, and the DR column and PR row). So to save that redundancy, for all countries except Spain (very top) and Argentina (far right) you have to look around a bit to see where it crosses any other given country. reply alganet 4 hours agoprevCool article. TIL I learned that Atacama has flower blooms. I miss the Inca though. Talking about Chile without mentioning the Inca Empire is like talking about Italy without mentioning the Roman Empire. reply flobosg 3 hours agoparentEnter the Mapuche (https://en.wikipedia.org/wiki/Mapuche), whom the Inca tried (and failed) to conquer. reply tumidpandora 5 hours agoprevThis is such a clear and engaging read! I wish all articles made learning this fun and accessible reply matreyes 1 hour agoprevWena weon!!! reply flobosg 3 hours agoprevTrivia question: how many time zones does Chile have? reply gottorf 3 hours agoparentGiven that Chile only covers about nine degrees of longitude, the reasonable expectation is that it only has one time zone (excluding any far-flung territories and whatnot). I'm sure you're going to surprise me with the true answer :-) reply Suppafly 3 hours agoparentprevI had to google, I'm surprised that it's 3, I would have assumed that it was just one since it's so narrow. reply flobosg 2 hours agorootparentEverybody forgets Easter Island! (And the other one in the Magallanes and Chilean Antarctica region was added not long ago, 2017 IIRC.) reply Suppafly 1 hour agorootparentI assume maybe the other one is to align more closely with Argentina or something? If you look at the time zone map, they just as easily could have had the whole mainland country on one timezone. Bolivia, Paraguay, and parts of Brazil share the same timezone as the northern part of Chili and are just as far east as the southern parts of Chili. Easter Island makes sense, you don't necessarily expect islands that are far away to share the mainlands timezone. Antarctica is one that probably catches a lot of people since most time zone maps don't even bother to include it and there is no real population there. reply flobosg 1 hour agorootparent> I assume maybe the other one is to align more closely with Argentina or something? It has to do with differences in latitude. In winter, the southernmost region of Chile[1] was completely dark at around 4 PM with the old time zone. Staying on summer time for the whole year gives its inhabitants an additional hour of sunlight. [1]: Which includes, but is not equivalent to, Antarctica: https://en.wikipedia.org/wiki/Magallanes_Region reply k1ns 4 hours agoprevThis article is awesome. I've always wondered why Chile is that shape and I didn't know about the Chilean dialect of Spanish being so far off from the others. Super cool. reply rieg3c 3 hours agoprevChile is a great country, greetings from Saint Bernard reply flobosg 3 hours agoparentShould’ve put it in that other meme collection thread! reply carabiner 1 hour agoprevThey should make it longer. reply golergka 1 hour agoparentBolivians and Peruvians might disagree, violently. reply wruza 2 hours agoprevBecause Andes? See also “chilean empire map” (it’s not serious). reply anothername12 4 hours agoprevI’m gonna round trip motorcycle that later starting with Colombia reply gottorf 3 hours agoparentSounds beautiful. Good luck with your trip. reply syngrog66 3 hours agoprevmany nation shapes don't make any sense. add in the wildly disconnected/schizophrenic sovereign territory of some countries (US and Russia among exemplars) and I've learned one must simply turn one's brain off when analyzing them. Its a circus. reply mqefjh 1 hour agoprevhttps://img-9gag-fun.9cache.com/photo/aBneQZZ_460s.jpg reply nojvek 33 minutes agoparentIf we were superb at building ships and living on the seas, Chilean Empire would have been a thing. reply br1 59 minutes agoprevBecause Chile renounced Patagonia to keep Argentina out of the war with Bolivia and Peru. Argentina is the bully around here. reply WarOnPrivacy 5 hours agoprevThis site owner is living the small-web fantasy we HN'rs keep talking about. reply renewiltord 5 hours agoparentThere are lots of substack sites like this. Probably the new blogspot. The newsletter modal is because that's a choose piece of substack. reply WarOnPrivacy 5 hours agoparentprevnext [4 more] [flagged] pvg 5 hours agorootparentPlease don't complain about tangential annoyances—e.g. article or website formats, name collisions, or back-button breakage. They're too common to be interesting. https://news.ycombinator.com/newsguidelines.html reply WarOnPrivacy 5 hours agorootparentI repented. Publicly, to be an example. reply pvg 5 hours agorootparentEveryone who doesn't post these is already a public example. reply pulketo 3 hours agoprevThis Chile is too long too... reply maxlin 5 hours agoprevOriginally posted on X: https://twitter.com/tomaspueyo/status/1807380049605091537 reply notachatbot1234 3 hours agoprev90% of the content is stolen from other people without appropriate or any attribution. reply TheBlight 3 hours agoprev [–] Isn't this the covid \"Hammer and Dance\" article author? Not getting another click from me for the rest of my life. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Chile's unique length is due to the Andes mountains, creating a narrow strip of land between the mountains and the Pacific Ocean.",
      "The country's geography is shaped by the collision of the Nazca and South American tectonic plates, forming the Andes.",
      "Chile's borders were historically contested, notably in the War of the Pacific, where it gained resource-rich territories."
    ],
    "commentSummary": [
      "Chile's unique geography, with the Andes mountains and the Pacific Ocean as natural boundaries, and historical factors have shaped its long and narrow shape.",
      "The country spans diverse climates, from the Atacama Desert in the north to cold southern regions, influencing its centralized population in Santiago.",
      "Chile's diverse geography also affects its dialect of Spanish, giving it unique characteristics compared to other Spanish-speaking regions."
    ],
    "points": 617,
    "commentCount": 204,
    "retryCount": 0,
    "time": 1719923818
  },
  {
    "id": 40854836,
    "title": "Welcome to Ladybird, a truly independent web browser",
    "originLink": "https://ladybird.org/index.html",
    "originBody": "About News Get Involved Sponsors Donate Welcome to Ladybird, a truly independent web browser. We are building a brand-new browser from scratch, backed by a non-profit. Get Involved About Ladybird Ladybird is a brand-new browser & web engine. Driven by a web standards first approach, Ladybird aims to render the modern web with good performance, stability and security. From its humble beginnings as an HTML viewer for the SerenityOS hobby operating system project, Ladybird has since grown into a cross-platform browser supporting Linux, macOS, and other Unix-like systems. Ladybird is currently in heavy development. We are targeting a first Alpha release for early adopters in 2026. What makes Ladybird unique Truly independent No code from other browsers. We're building a new engine, based on web standards. Singular focus We are focused on one thing: the web browser. No monetization No \"default search deals\", crypto tokens, or other forms of user monetization, ever. News & Announcements Announcement The Ladybird Browser Initiative Announcing our 501(c)(3) non-profit. Thoughts Why we need Ladybird Co-founder Chris Wanstrath shares his thoughts. Announcement Ladybird forks from SerenityOS Read the full announcement. Get Involved Ladybird is currently in heavy development, and there's work to be done in all areas of the browser. We're welcoming new developers every week. The main community hub is our Discord server. All the code is hosted on GitHub. Clone it, build it, and join our Discord if you want to collaborate on it! We're looking forward to seeing you there. Join Discord Get the code Sponsors Platinum Silver Bronze Become a Ladybird supporter Ladybird is funded entirely by sponsorships and donations from people and companies who care about the open web. We accept one-time and recurring monthly donations via Donorbox. If you or your company would like to make a large donation, we would be happy to display your logo on this website! Please contact us about becoming a sponsor. Frequently Asked Questions ? When is it coming? We are targeting Summer 2026 for a first Alpha version on Linux and macOS. This will be aimed at developers and early adopters. ? How many people are working on the browser today? We currently have 4 paid full-time engineers working on Ladybird. There is also a large community of volunteer contributors. ? What's the hiring plan? We have 3 new full-time engineers starting soon. Going forward, we would like to grow the team at a reasonable pace. Building the right team is more important than building it quickly. ? What does \"No code from other browsers\" really mean? The focus of the Ladybird project is to build a new browser engine from the ground up. We don't use code from Blink, WebKit, Gecko, or any other browser engine. For historical reasons, the browser uses various libraries from the SerenityOS project, which has a strong culture of writing everything from scratch. Now that Ladybird has forked from SerenityOS, it is no longer bound by this culture, and we will be making use of 3rd party libraries for common functionality (e.g image/audio/video formats, encryption, graphics, etc.) We are already using some of the same 3rd party libraries that other browsers use, but we will never adopt another browser engine instead of building our own. ? Will Ladybird work on Windows? We don't have anyone actively working on Windows support, and there are considerable changes required to make it work well outside a Unix-like environment. We would like to do Windows eventually, but it's not a priority at the moment. ? Will Ladybird work on mobile devices? We don't have anyone actively working on an Android or iOS port. More effort will be put into mobile once we have the desktop versions in a good state. While there is the start of an Android port in the project repository, mobile is not a priority at the moment. ? What are the sponsor tiers? Platinum USD $100,000 Gold USD $50,000 Silver USD $10,000 Bronze USD $5,000 Sponsors will have their logos displayed on our website, and will be thanked in updates / on social media. Please contact us if you are interested in sponsorship. ? How can you be \"independent\" if you have sponsors? All sponsorships are in the form of unrestricted donations. Board seats and other forms of influence are not for sale. ? Why build a new browser in C++ when safer and more modern languages are available? Ladybird started as a component of the SerenityOS hobby project, which only allows C++. The choice of language was not so much a technical decision, but more one of personal convenience. Andreas was most comfortable with C++ when creating SerenityOS, and now we have almost half a million lines of modern C++ to maintain. However, now that Ladybird has forked and become its own independent project, all constraints previously imposed by SerenityOS are no longer in effect. We are actively evaluating a number of alternatives and will be adding a mature successor language to the project in the near future. This process is already quite far along, and prototypes exist in multiple languages. Sign up for our newsletter We'll e-mail you once a month with updates about Ladybird. About News Get Involved Sponsors Contact Us © 2024. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=40854836",
    "commentBody": "Welcome to Ladybird, a truly independent web browser (ladybird.org)530 points by rapnie 9 hours agohidepastfavorite1 comment dang 1 hour ago [–] Comments moved to https://news.ycombinator.com/item?id=40856791, which is currently on the front page. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ladybird is an independent web browser and engine, initially an HTML viewer for SerenityOS, now supporting Linux, macOS, and other Unix-like systems.",
      "Unique features include no code from other browsers, a singular focus on being a web browser, and no monetization through ads or user data.",
      "An Alpha release is planned for Summer 2026, with development funded by sponsorships and donations, and a team of 4 full-time engineers."
    ],
    "commentSummary": [
      "Ladybird is an independent web browser, and its official website is ladybird.org.",
      "Discussions and comments about Ladybird have been moved to a specific thread on Hacker News, which is currently featured on the front page."
    ],
    "points": 530,
    "commentCount": 1,
    "retryCount": 0,
    "time": 1719911676
  },
  {
    "id": 40854319,
    "title": "Diff-pdf: tool to visually compare two PDFs",
    "originLink": "https://github.com/vslavik/diff-pdf",
    "originBody": "Note: this repository is provided as-is and the code is not being actively developed. If you wish to improve it, that's greatly appreciated: please make the changes and submit a pull request, I'll gladly merge it or help you out with finishing it. However, please do not expect any kind of support, including implementation of feature requests or fixes. If you're not a developer and/or willing to get your hands dirty, this tool is probably not for you. Usage diff-pdf is a tool for visually comparing two PDFs. It takes two PDF files as arguments. By default, its only output is its return code, which is 0 if there are no differences and 1 if the two PDFs differ. If given the --output-diff option, it produces a PDF file with visually highlighted differences: $ diff-pdf --output-diff=diff.pdf a.pdf b.pdf Another option is to compare the two files visually in a simple GUI, using the --view argument: $ diff-pdf --view a.pdf b.pdf This opens a window that lets you view the files' pages and zoom in on details. It is also possible to shift the two pages relatively to each other using Ctrl-arrows (Cmd-arrows on MacOS). This is useful for identifying translation-only differences. See the output of $ diff-pdf --help for complete list of options. Obtaining the binaries Precompiled version of the tool for Windows is available as part of the latest release as a ZIP archive, which contains everything you need to run diff-pdf. It will work from any place you unpack it to. Alternatively, if you use Chocolatey, you can install diff-pdf on Windows with: $ choco install diff-pdf On Mac, if you use Homebrew, you can use it to install diff-pdf with it: $ brew install diff-pdf On Mac, if you use Macports, you can install diff-pdf with: $ port install diff-pdf On Fedora and CentOS 8: $ sudo dnf install diff-pdf Precompiled version for openSUSE can be downloaded from the openSUSE build service. Compiling from sources The build system uses Automake and so a Unix or Unix-like environment (Cygwin or MSYS) is required. Compilation is done in the usual way: $ ./bootstrap $ ./configure $ make $ make install (Note that the first step, running the ./bootstrap script, is only required when building sources checked from version control system, i.e. when configure and Makefile.in files are missing.) As for dependencies, diff-pdf requires the following libraries: wxWidgets >= 3.0 Cairo >= 1.4 Poppler >= 0.10 CentOS: $ sudo yum groupinstall \"Development Tools\" $ sudo yum install wxGTK wxGTK-devel poppler-glib poppler-glib-devel Ubuntu: $ sudo apt-get install make automake g++ $ sudo apt-get install libpoppler-glib-dev poppler-utils libwxgtk3.0-gtk3-dev macOS: Install Command Line Tools for Xcode: $ xcode-select --install and install Homebrew or MacPorts to manage dependencies, then: $ brew install automake autoconf wxmac poppler cairo pkg-config or $ sudo port install automake autoconf wxWidgets-3.0 poppler cairo pkgconfig Note that many more libraries are required on Windows, where none of the libraries Cairo and Poppler use are normally available. At the time of writing, transitive cover of the above dependencies included fontconfig, freetype, glib, libpng, pixman, gettext, libiconv, libjpeg and zlib. Compiling on Windows using MSYS + MinGW First of all, you will need working MinGW installation with MSYS2 environment and C++ compiler. Install MSYS2 by following their instructions. Once installed, launch the MSYS2 MinGW shell. It will open a terminal window; type cd /c/directory/with/diff-pdf to go to the directory with diff-pdf sources. You will need to install additional MSYS components that are not normally included with MSYS, using these commands: $ pacman -Syu $ pacman -S automake autoconf pkg-config make zip pactoys $ pacboy -S gcc:p poppler:p wxWidgets:p Build diff-pdf in the same way as in the instructions for Unix above: $ ./bootstrap # only if building from git repository $ ./configure $ make To build a ZIP archive will all DLLs, run $ make windows-dist Installing On Unix, the usual make install is sufficient. On Windows, installation is not necessary, just copy the files somewhere. If you built it following the instructions above, all the necessary files will be in the created ZIP archive.",
    "commentLink": "https://news.ycombinator.com/item?id=40854319",
    "commentBody": "Diff-pdf: tool to visually compare two PDFs (github.com/vslavik)356 points by Olshansky 11 hours agohidepastfavorite54 comments ydant 4 hours agoRelated - this might be helpful to someone. ImageMagick can do a visual PDF compare: magick compare -density \"$DENSITY\" -background white \"$1[0]\" \"$2[0]\" \"$TMP\" (density = 100, $1 and $2 are the filenames to compare, $TMP the output file) You need to do some work to support multiple pages, so I use this script: https://gist.github.com/mbafford/7e6f3bef20fc220f68e467589bb... This also uses `imgcat` to show the difference directly in the terminal. You can also use ImageMagick get a perceptual hash difference using something like: convert -metric phash \"$1\" null: \"$2\" -compose Difference -layers composite -format '%[fx:mean]' info: I use the fact you can configure git to use custom diff tools and take advantage of this with the following in my .gitconfig: [diff \"pdf\"] command = ~/bin/git-diff-pdf And in my .gitattributes I enable the above with: *.pdf binary diff=pdf ~/bin/git-diff-pdf does a diff of the output of `pdftotext -layout` (from poppler) and also runs pdf-compare-phash. To use this custom diff with `git show`, you need to add an extra argument (`git show --ext-diff`), but it uses it automatically if running `git diff`. reply bigfatfrock 3 hours agoparentNext level, especially with the git attribute calls, well played. I'm still blown away how powerful imagemagick is after using it for a decade or two, what an inspiring piece of open source software. reply tomwheeler 4 hours agoprevIn a previous job, I had to validate the output of an unreliable production publishing system, so I tested dozens of PDF comparison tools available at the time. The best I found was called Delta Walker. It was proprietary commercial Mac-only software, but reasonably inexpensive, accurate, and could handle long PDFs with lots of graphics well. I remember evaluating this diff-pdf tool and finding that it fell short in some way, although it's been so long that I don't recall the specifics. Most of them failed to identify changes or reported false positives. I also remember being disappointed since this one was open source and could easily be scripted. reply pivo 4 hours agoparentIt looks like Delta Walker's added Windows and Linux support: https://www.deltawalker.com/download reply thibaut_barrere 7 hours agoprevI have been using this in a CI pipeline to maintain a business-critical PDF generation (healthcare) app (started circa 2010 I think), here is the RSpec helpers I'm using: https://gist.github.com/thbar/d1ce2afef68bf6089aeae8d9ddc05d... The code contains git-stored reference PDFs, and the test suite re-generate them and assert that nothing has changed. Helped a lot to audit visual changes, or PDF library upgrades! reply tylerflick 4 hours agoparentAre you using singed digests in the PDFs? reply pmarreck 6 hours agoparentprevcould you not just compare the source (or perhaps even the hash) of the PDF and assert on that? reply ydant 4 hours agorootparentI use some custom tools for PDF comparison (visual, textual, and perceptual hash) for my personal records/accounting purposes. A number of the financial and medical institutions I deal with re-generate PDFs every time you request them, but the content is 99-100% identical. Sometimes just a date changes. So I use a perceptual hash and content comparison to automate detecting truly new documents vs. ones that are only slightly changed. reply jabroni_salad 5 hours agorootparentprevIf the document is a legally required disclosure (like a bank's fee schedule for example) then you need to grade that document directly rather than its source code. PDFs are horrible and there is a lot that can go wrong with making them between writing and publishing. reply alexdoesh 5 hours agorootparentprevHashes can change regularly due to metadata. Source checks may also require some filtration or preprocessing before comparison. Visual comparison is the best option here, especially if you have a complex document with multiple third-party components that may change both the hash and source but keep the visual appearance the same. reply poidos 7 hours agoprevReminds me of the tool Bob Nystrom wrote to help himself out when working on the physical edition of Crafting Interpreters: https://journal.stuffwithstuff.com/2020/04/05/crafting-craft... Whole article is worth reading, but if you want the relevant bits search for “ I wrote a Dart script that would take a PDF of the book”. reply jaustin 9 hours agoprevWe've been using this in the Micro:bit Educational Foundation (microbit.org) to fill a gap in hardware design tooling, and get visual diffs of our schematics and gerbers during PCB design iterations. It's kinda wild that's what we ended up doing, but if you want to be sure your radio layout didn't change at all when you're making a minor revision to a different part of the board, visual diffs are perfect. That said, next project we want to try something more integrated with EDA tools. If anyone else has followed this path, we'd love to know. reply mikeyinternews 5 hours agoprevYou can do this with Beyond Compare (it's not free, but not very expensive either) https://www.scootersoftware.com/ reply Rinzler89 4 hours agoparentBeyond Compare is one of those priceless tools I pay for myself instead of waiting for my employer to pay for it. Price/functionality wise it's worth its weight in gold, it's cross platform, and its licensing is very liberal. There's just no FOSS compare tools out there that can match BC. reply hipnoizz 4 hours agorootparentWhat are BC features that you find to be so great? I'm genuinely curious - I heard of lot of BC being 'the tool' for diffing. I'm used to Meld, but my current employee has a pretty strict policy which tools could be used so at some point I've managed a licence for some older version of BC. But for some reason I've found its UI/the way it works a bit less optimal that I was accustomed for. Since I'm using that primarily for text diffs these day I usually use a diff tool from IntelliJ Idea (I have Idea open all the time). reply riedel 2 hours agoprevI always used DiffPDF only to read on their website: > in the view of the EU’s Cyber Resilience Act and an abundance of caution, we have withdrawn all our free software [1] Good to see post-cyberresilience alternatives :) PDF diffs are really great for versioning/comparing PCB-Designs. (The only real use case I had 15 yrs back) [1] http://www.qtrac.eu/diffpdf-foss.html reply yencabulator 1 hour agoparentWhat a convenient excuse for them to try to get people to switch to their proprietary fork. I genuinely need a side-by-side PDF comparison tool, and the diff-pdf tool linked from the main link doesn't do that. Any thoughts? reply rawbert 9 hours agoprevWe use this tool in our team regularly for comparison of PDFs we obtain from third party services that might have changed after code-changes on our side. Big thanks to the author <3 reply deckar01 5 hours agoprevI wrote a pixel-based visual diffing algorithm long ago that was intended for a CI tool that finds all of the UI changes in a PR. I broke the layout of a page I didn’t even know existed as an intern at Inkling and have had this idea in my head ever since. https://github.com/deckar01/narcis reply canistel 9 hours agoprevInterestingly, Github thinks the project is 46% shell, due to the fairly huge wxwin.m4. reply infecto 6 hours agoparentI noticed this a while back with a private project of mine. The Github languages breakdown seems broken. Mine is a Python project with a handful of Jupyter notebooks but many many python files. The LOC must be 80% python files but Github sees the project as 50% Jupyter. reply badlibrarian 5 hours agorootparentYou can tweak/exclude with .gitattributes https://github.com/github-linguist/linguist/blob/master/docs... reply akasakahakada 6 hours agoprevUse this to compare university textbook edition 8 and 9 before buying. reply ant6n 6 hours agoparentUh how can you compare without buying? Or put another way, why buy if you can compare? reply cocodill 5 hours agorootparenttime machine research reply akasakahakada 4 hours agorootparentprevlibgen exist bro reply N0b8ez 4 hours agorootparentBut then why would you need to buy it? reply Foobar8568 3 hours agorootparentBecause for textbooks, paper is often superior. reply strangus 4 hours agoprevhttps://10052.ai has a tool that will visually compare documents(pdfs, doc, image,etc) and cluster them together. It works amazingly well. reply TacticalCoder 3 hours agoprevThis reminds me of a book author who posted here IIRC. He had a little tool allowing him to quickly compare two revisions of his book. For example too make sure typos fixed didn't t break havoc. I remember his tool would show in red what had changed on pages thumbnails. reply ck_one 5 hours agoprevCan anyone recommend a method to deduplicate pdfs? The hash is often different but the content and meta data is 99.99% the same. reply pixelmonkey 3 hours agoparentYou might want strip metadata before doing a comparison, using exiftool. Even though exiftool was originally written for EXIF metadata on JPGs, these days, it supports a lot of metadata standards, including PDF. This command will do it assuming you set filename=`basename your.pdf .pdf`: exiftool -all= -o ${filename}.stripped.pdf ${filename}.pdf That won't help you with small differences in the contents, but might help with small differences in metadata. Running `md5sum` on the stripped PDF should give more reliable dedupe results. I was recently working on a similar problem for JPG, RAW, and MP4 files (photo/video backup) so it is fresh in my mind. reply bob1029 3 hours agoparentprevI would consider rasterizing the PDFs and then hashing the resulting bitmaps. reply strangus 4 hours agoparentprevcp? reply redman25 5 hours agoprevI created a similar in-browser version a while back with mozilla's pdf-js. The diff rendering is all run client side. https://www.parepdf.com The diff-pdf project was my inspiration but I wanted to create a version that was distributable to non-programmers. reply atum47 5 hours agoprevback when I was writing my final paper I faced a similar issue, needed to de-duplicate a bunch of PDF's, so I came up with a simple solution https://github.com/victorqribeiro/dtf reply sva_ 5 hours agoprevCoincidentally I downloaded and tried using this just a while ago. I was trying to see if it can identify an Elsevier fingerprint between two pdfs. It can't, it only compares visible things. I used vbindiff instead. reply smartmic 6 hours agoprevI like this tool better: https://www.qtrac.eu/diffpdf.html It shows the differences in the GUI side-by-side instead of overlayed. reply Tryk 5 hours agoparentFrom the github: Another option is to compare the two files visually in a simple GUI, using the --view argument: $ diff-pdf --view a.pdf b.pdf This opens a window that lets you view the files' pages and zoom in on details. It is also possible to shift the two pages relatively to each other using Ctrl-arrows (Cmd-arrows on MacOS). This is useful for identifying translation-only differences. reply yencabulator 1 hour agorootparentShifting the offset is very far from the experience of a side-by-side diff, and more useful for nudging the images to align them. reply invalidlogin 6 hours agoparentprevI use BeyondCompare 5 for this. reply asah 8 hours agoprevCrazy, I'd have thought that modern multi-modal LLMs can do this, but when I tried Gemini, ChatGPT-4o and Claude they all pooped out: - Gemini at first only diff'd the text, and then when pushed it identified the items in the images and then hallucinated the differences between the versions. It could not produce an image output. - Claude only diff'd the text and refused to believe that there images in the PDFs. - ChatGPT attempted to write and execute python code for this, which errored out. reply ale42 5 hours agoparentVisually comparing two PDFs is something a PC can do deterministically without any resource (and energy) intensive LLMs. People will soon use LLMs for things they are not especially good or efficient at, like computing the sum of numbers in an Excel table... (or are they doing it already?). reply B1FF_PSUVM 9 minutes agorootparentAs a bonus, they'll get a result that looks likely. reply ertgbnm 6 hours agoparentprevThis may be the type of thing that LLMs are currently the worst at. I'm not surprised at all. reply infecto 6 hours agoparentprevThis is definitely not a strength for multi-modal LLM. Multi-modal capabilities are still too flaky especially when looking at a page of a PDF which can have multiple areas of focus. reply pmarreck 5 hours agoparentprevI would fully expect an LLM to not get natively good at this but to know how to reach out to another tool in order to get good at this reply fwn 4 hours agoprevI really like the overlay view and that it is not cloud based. Will try to test it at work. I rely heavily on PDF comparison via PDF-XChange Editor, which is accurate for text, but often has trouble highlighting visual changes correctly. reply jgalt212 7 hours agoprevThanks. I'll give this a shot to see if any counterparties try to sneak in any last second changes to the executable version of the doc. reply Levitating 8 hours agoprev [–] No screenshots? reply colddevil 8 hours agoparent [–] Here is one: https://vslavik.github.io/diff-pdf/ reply Tryk 5 hours agorootparent [–] Can anyone explain how to interpret that screenshot? It just looks like a very blurry text to me. reply pimlottc 5 hours agorootparentIt's showing you both PDFs overlaid on each other. The main window looks blurry because the main text has shifted vertically slightly. The regions that have changes are highlighted in the thumbnails on the left. I agree it's not the best initial example to demonstrate the tool, but it does show how it can be used to detect even minor spacing changes. reply ska 5 hours agorootparentprev [–] If it was sharp, they would be identical. The “blurriness” is doubling, where the lines are not quite aligned. Red text there show you content that is in one and not the other. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The `diff-pdf` tool allows users to visually compare two PDF files, highlighting differences if any.",
      "The repository is not actively developed, and users are encouraged to submit pull requests for improvements but should not expect support or new features.",
      "Installation instructions are provided for various operating systems, including Windows, macOS, and several Linux distributions, with detailed steps for compiling from source."
    ],
    "commentSummary": [
      "Diff-pdf is a tool designed for visually comparing two PDF files, with users discussing its utility and alternatives like ImageMagick, Delta Walker, and Beyond Compare.",
      "Users share scripts and configurations for integrating PDF comparison into workflows, including CI (Continuous Integration) pipelines and git, highlighting practical applications in hardware design and textbook comparisons.",
      "The discussion emphasizes the strengths and limitations of different tools, with preferences split between open-source options and proprietary software based on specific features."
    ],
    "points": 356,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1719905168
  },
  {
    "id": 40853770,
    "title": "Booting Linux Off of Google Drive",
    "originLink": "https://ersei.net/en/blog/fuse-root",
    "originBody": "Booting Linux off of Google Drive Published: [ 2024-07-01 09:20 EDT ] Categories: [ programming ] Tags: [ linux, filesystems ] Competitiveness is a vice of mine. When I heard that a friend got Linux to boot off of NFS, I had to one-up her. I had to prove that I could create something harder, something better, faster, stronger. Like all good projects, this began with an Idea. My mind reached out and grabbed wispy tendrils from the æther, forcing the disparate concepts to coalesce. The Mass gained weight in my hands, and a dark, swirling colour promising doom to those who gazed into it for long. On the brink of insanity, my tattered mind unable to comprehend the twisted interplay of millennia of arcane programmer-time and the ragged screech of madness, I reached into the Mass and steeled myself to the ground lest I be pulled in, and found my magnum opus. Booting Linux off of a Google Drive root. But How? I wanted this to remain self-contained, so I couldn't have a second machine act as a \"helper\". My mind went immediately to FUSE—a program that acts as a filesystem driver in userspace (with cooperation from the kernel). I just had to get FUSE programs installed in the Linux kernel initramfs and configure networking. How bad could it be? The Linux Boot Process The Linux boot process is, technically speaking, very funny. Allow me to pretend I understand for a moment1: The firmware (BIOS/UEFI) starts up and loads the bootloader The bootloader loads the kernel The kernel unpacks a temporary filesystem into RAM which has the tools to mount the real filesystem The kernel mounts the real filesystem and switches the process to the init system running on the new filesystem As strange as the third step may seem, it's very helpful! We can mount a FUSE filesystem in that step and boot normally. A Proof of Concept The initramfs needs to have both network support as well as the proper FUSE binaries. Thankfully, Dracut makes it easy enough to build a custom initramfs. I decide to build this on top of Arch Linux because it's relatively lightweight and I'm familiar with how it works, as opposed to something like Alpine. $ git clone https://github.com/dracutdevs/dracut $ podman run -it --name arch -v ./dracut:/dracut docker.io/archlinux:latest bash In the container, I installed some packages (including the linux package because I need a functioning kernel), compiled dracut from source, and wrote a simple module script in modules.d/90fuse/module-setup.sh: #!/bin/bash check() { require_binaries fusermount fuseiso mkisofs || return 1 return 0 } depends() { return 0 } install() { inst_multiple fusermount fuseiso mkisofs return 0 } That's it. That's all the code I had to write. Buoyed by my newfound confidence, I powered ahead, building the EFI image. $ ./dracut.sh --kver 6.9.6-arch1-1 \\ --uefi efi_firmware/EFI/BOOT/BOOTX64.efi \\ --force -l -N --no-hostonly-cmdline \\ --modules \"base bash fuse shutdown network\" \\ --add-drivers \"target_core_mod target_core_file e1000\" \\ --kernel-cmdline \"ip=dhcp rd.shell=1 console=ttyS0\" $ qemu-kvm -bios ./FV/OVMF.fd -m 4G \\ -drive format=raw,file=fat:rw:./efi_firmware \\ -netdev user,id=network0 -device e1000,netdev=network0 -nographic ... ... dracut Warning: dracut: FATAL: No or empty root= argument dracut Warning: dracut: Refusing to continue Generating \"/run/initramfs/rdsosreport.txt\" You might want to save \"/run/initramfs/rdsosreport.txt\" to a USB stick or /boot after mounting them and attach it to a bug report. To get more debug information in the report, reboot with \"rd.debug\" added to the kernel command line. Dropping to debug shell. dracut:/# Hacker voice I'm in. Now to enable networking and mount a test root. I have already extracted an Arch Linux root into a S3 bucket running locally, so this should be pretty easy, right? I just have to manually set up networking routes and load the drivers. dracut:/# modprobe fuse dracut:/# modprobe e1000 dracut:/# ip link set lo up dracut:/# ip link set eth0 up dracut:/# dhclient eth0 dhcp: PREINIT eth0 up dhcp: BOUND setting up eth0 dracut:/# ip route add default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 dracut:/# s3fs -o url=http://192.168.2.209:9000 -o use_path_request_style fuse /sysroot dracut:/# ls /sysroot bin dev home lib64 opt root sbin sys usr boot etc lib mnt proc run srv tmp var dracut:/# switch_root /sysroot /sbin/init switch_root: failed to execute /lib/systemd/systemd: Input/output error dracut:/# ls sh: ls: command not found Honestly, I don't know what I expected. Seems like everything is just... gone. Alas, not even tab completion can save me. At this point, I was stuck. I had no idea what to do. I spent days just looking around, poking at the switch_root source code, all for naught. Until I remembered a link Anthony had sent me: How to shrink root filesystem without booting a livecd. In there, there was a command called pivot_root that switch_root seems to call internally. Let's try that out. dracut:/# logout ... [ 430.817269] ---[ end Kernel panic - not syncing: Attempted to kill init! exitcode=0x00000100 ]--- ... dracut:/# cd /sysroot dracut:/sysroot# mkdir oldroot dracut:/sysroot# pivot_root . oldroot pivot_root: failed to change root from `.' to `oldroot': Invalid argument Apparently, pivot_root is not allowed to pivot roots if the root being switched is in the initramfs. Unfortunate. The Stack Exchange answer tells me to use switch_root, which doesn't work either. However, part of that answer sticks out to me: initramfs is rootfs: you can neither pivot_root rootfs, nor unmount it. Instead delete everything out of rootfs to free up the space (find -xdev / -exec rm '{}' ';'), overmount rootfs with the new root (cd /newmount; mount --move . /; chroot .), attach stdin/stdout/stderr to the new /dev/console, and exec the new init. Would it be possible to manually switch the root without a specialized system call? What if I just chroot? ... dracut:/# mount --rbind /sys /sysroot/sys dracut:/# mount --rbind /dev /sysroot/dev dracut:/# mount -t proc /proc /sysroot/proc dracut:/# chroot /sysroot /sbin/init Explicit --user argument required to run as user manager. Oh, I need to run the chroot command as PID 1 so Systemd can start up properly. I can actually tweak the initramfs's init script and just put my startup commands in there, and replace the switch_root call with exec chroot /sbin/init. I put this in modules.d/99base/init.sh in the Dracut source after the udev rules are loaded and bypassed the root variable checks earlier. modprobe fuse modprobe e1000 ip link set lo up ip link set eth0 up dhclient eth0 ip route add default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 s3fs -o url=http://192.168.2.209:9000 -o use_path_request_style fuse /sysroot mount --rbind /sys /sysroot/sys mount --rbind /dev /sysroot/dev mount -t proc /proc /sysroot/proc I also added exec chroot /sysroot /sbin/init at the end instead of the switch_root command. Rebuilding the EFI image and... I sit there, in front of my computer, staring. It can't have been that easy, can it? Surely, this is a profane act, and the spirit of Dennis Ritchie ought't've stopped me, right? Nobody stopped me, so I kept going. I log in with the very secure password root as root, and it unceremoniously drops me into a shell. [root@archlinux ~]# mount s3fs on / type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) ... [root@archlinux ~]# At last, Linux booted off of an S3 bucket. I was compelled to share my achievement with others—all I needed was a fetch program to include in the screenshot: [root@archlinux ~]# pacman -Sy fastfetch :: Synchronizing package databases... core.db failed to download error: failed retrieving file 'core.db' from geo.mirror.pkgbuild.com : Could not resolve host: geo.mirror.pkgbuild.com warning: fatal error from geo.mirror.pkgbuild.com, skipping for the remainder of this transaction error: failed retrieving file 'core.db' from mirror.rackspace.com : Could not resolve host: mirror.rackspace.com warning: fatal error from mirror.rackspace.com, skipping for the remainder of this transaction error: failed retrieving file 'core.db' from mirror.leaseweb.net : Could not resolve host: mirror.leaseweb.net warning: fatal error from mirror.leaseweb.net, skipping for the remainder of this transaction error: failed to synchronize all databases (invalid url for server) [root@archlinux ~]# Uh, seems like DNS isn't working, and I'm missing dig and other debugging tools. Wait a minute! My root filesystem is on S3! I can just mount it somewhere else with functional networking, chroot in, and install all my utilities! Some debugging later, it seems like systemd-resolved doesn't want to run because it Failed to connect stdout to the journal socket, ignoring: Permission denied. I'm not about to try to debug systemd because it's too complicated and I'm lazy, so instead I'll just use Cloudflare's. [root@archlinux ~]# echo \"nameserver 1.1.1.1\" > /etc/resolv.conf [root@archlinux ~]# pacman -Sy fastfetch :: Synchronizing package databases... core is up to date extra is up to date ... [root@archlinux ~]# fastfetch I look around, making sure that nobody had tried to stop me. My window was intact, my security system had not tripped, the various canaries I had set up around the house had not been touched. I was safe to continue. I was ready to have it run on Google Drive. Google Gets Involved There's a project already that does Google Drive over FUSE for me already: google-drive-ocamlfuse. Thankfully, I have a Google account lying around that I haven't touched in years ready to go! I follow the instructions, accept the terms of service I didn't read, create all the oauth2 secrets, enable the APIs, install google-drive-ocamlfuse from the AUR into my Arch Linux VM, patch some PKGBUILDs (it's been a while), and lo and behold! I have mounted Google Drive! Mounting Drive and a few very longrsync runs later, I have Arch Linux on Google Drive. Just kidding, it's never that easy. Here's a non-exhausive list of problems I ran into: Symlinks to symlinks don't work (very important for stuff in /usr/lib) Hardlinks don't work It's so slowwwww Relative symlinks don't work at all No dangling symlinks (important for stuff that links to /proc and isn't mounted, or stuff that just hasn't copied over yet) Symlinks outside of Google Drive don't work Permissions don't work (neither do attributes) Did I mention it's SLOW With how many problems there are with symlinks, I have half a mind to change the FUSE driver code to just create a file that ends in .internalsymlink to fix all of that, Google Drive compatibility be damned. But, I have challenged myself to do this without modifying anything important (no kernel tweaking, no FUSE driver tweaking), so I'll just have to live with it and manually create the symlinks that rsync fails to make with a hacky sed command to the rsync error logs. In the meantime, I added the token files generated from my laptop into the initramfs, as well as the Google Drive FUSE binary and SSL certificates, and tweaked a few settings2 to make my life slighty easier. ... inst ./gdfuse-config /.gdfuse/default/config inst ./gdfuse-state /.gdfuse/default/state find /etc/ssl -type f -or -type lwhile read file; do inst \"$file\"; done find /etc/ca-certificates -type f -or -type lwhile read file; do inst \"$file\"; done ... It's nice to see that timestamps kinda work, at least. Now all that's left is to wait for the agonizingly slow boot! chroot: /sbin/init: File not found Perhaps they did not bother to stop me because they knew I would fail. I know the file exists since, well, it exists, so why is it not found? Simple: Linux is kinda weird and if the binary you call depends on a library that's not found, then you'll get \"File not found\". dracut:/# ldd /sysroot/bin/bash linux-vdso.so.1 (0x00007e122b196000) libreadline.so.8 => /usr/lib/libreadline.so.8 (0x00007e122b01a000) libc.so.6 => /usr/lib/libc.so.6 (0x00007e122ae2e000) libncursesw.so.6 => /usr/lib/libncursesw.so.6 (0x00007e122adbf000) /lib64/ld-linux-x86-64.so.2 => /usr/lib64/ld-linux-x86-64.so.2 (0x00007e122b198000) However, these symlinks don't actually exist! Remember how earlier we noted that relative symlinks don't work? Well, that's come back to bite me. The Kernel is looking for files in /sysroot inside /sysroot/sysroot. Luckily, this is an easy enough fix: we just need to have /sysroot linked to /sysroot/sysroot without links: dracut:/# mkdir /sysroot/sysroot dracut:/# mount --rbind /sysroot /sysroot/sysroot Now time to boot! It took five minutes for Arch to rebuild the dynamic linker cache, another minute per systemd unit, and then, nothing. The startup halted in its tracks. [ TIME ] Timed out waiting for device /dev/ttyS0. [DEPEND] Dependency failed for Serial Getty on ttyS0. Guess I have to increase the timeout and reboot. In /etc/systemd/system/dev-ttyS0.device, I put: [Unit] Description=Serial device ttyS0 DefaultDependencies=no Before=sysinit.target JobTimeoutSec=infinity Luckily, it did not take infinite time to boot. I'm so close to victory I can taste it! I just have to increase another timeout. I set LOGIN_TIMEOUT to 0 in /etc/login.defs in Google Drive, and tried logging in again. Thankfully, there's a cache, so subsequent file reads aren't nearly as slow. Here I am, laurel crown perched upon my head, my chimera of Linux and Google Drive lurching around. But I'm not satisfied yet. Nobody had stopped me because they want me to succeed. I have to take this further. I need this to work on real hardware. Now Do It On Real Hardware Fortunately for me, I switched servers and now have an extra laptop with no storage just lying around! A wonderful victim3 for my test! There are a few changes I'll have to make: Use the right ethernet driver and not the default e1000 Do not use a serial display Change the network settings to match my house's network topology All I need is the r8169 driver for my ethernet port, and let's throw in a Powerline into the mix, because it's not going to impact the performance in any way that matters, and I don't have an ethernet cord that can reach my room. I build the unified EFI file, throw it on a USB drive under /BOOT/EFI, and stick it in my old server. Despite my best attempts, I couldn't figure out what the modprobe directive is for the laptop's built-in keyboard, so I just modprobed hid_usb and used an external keyboard to set up networking. This is my magnum opus. My Great Work. This is the mark I will leave on this planet long after I am gone: The Cloud Native Computer. Nice thing is, I can just grab the screenshot4 from Google Drive and put it here! Woe! Cloud Native Computer Be Upon Ye Despite how silly this project is, there are a few less-silly uses I can think of, like booting Linux off of SSH, or perhaps booting Linux off of a Git repository and tracking every change in Git using gitfs. The possibilities are endless, despite the middling usefulness. If there is anything I know about technology, it's that moving everything to The Cloud is the current trend. As such, I am prepared to commercialize this for any company wishing to leave their unreliable hardware storage behind and move entirely to The Cloud. Please request a quote if you are interested in True Cloud Native Computing. Unfortunately, I don't know what to do next with this. Maybe I should install Nix? Thoughts? Comments? Opinions? Feel free to share (relevant) ones with me! Contact me here if you want. I understand mostly because I read this Archwiki article. This section ends up being a wispy summarization. ↩ I set acknowledge_abuse=true, and root_folder=fuse-root. ↩ No computers were (physically) harmed in the making of this project. ↩ I used fbgrab to take the screenshot ↩",
    "commentLink": "https://news.ycombinator.com/item?id=40853770",
    "commentBody": "Booting Linux Off of Google Drive (ersei.net)318 points by jandeboevrie 13 hours agohidepastfavorite130 comments dveeden2 9 hours agoBack in the the day it was possible to boot Sun Solaris over HTTP. This was called wanboot. This article reminded me of that. This was basically an option of the OpenBoot PROM firmware of the SPARC machines. It looked like this (ok is the forth prompt of the firmware): ok setenv network-boot-arguments dhcp,hostname=myclient,file=https://192.168.1.1/cgi-bin/wanboot-cgi ok boot net This doesn't only load the initramfs over the (inter)network but also the kernel. https://docs.oracle.com/cd/E26505_01/html/E28037/wanboottask... https://docs.oracle.com/cd/E19253-01/821-0439/wanboottasks2-... reply kotaKat 7 hours agoparentModern UEFI can do that too! https://ipxe.org/appnote/uefihttp reply giancarlostoro 22 minutes agorootparentI'm wondering if this is how we did a net install of a custom Distro back in a former job, but I don't recall. I just remember it being insanely easy to install the distro over the network, even on a VM. reply Andrex 6 hours agorootparentprevFirst thing I disable on a new PC. reply mywittyname 4 hours agorootparentI was going to say, booting from a random website image sounds like a terrible idea. reply michaelmior 4 hours agorootparentIt's possible to require that any images used be signed using a specific key that is configured in the hardware ahead of time. Even if you don't do that, the same setup can be helpful for provisioning a bunch of machines without accessing any external network. You can configure a small box to act just as a DHCP server and to serve a machine image for network boot. Then you can have all the machines on this subnet automatically load that image as it is updated without the need for any further configuration on each device. I've seen organizations do something similar to this for trade shows when they want a bunch of machines that visitors can interact with and don't want to have to keep them updated individually. Just update the image once and reboot each machine. reply thesuitonym 28 minutes agorootparentOkay but why not just use PXE? Why does everything have to be HTTP? reply xur17 3 hours agorootparentprevIdeally it would be possible to just specify an image url and a hash. Or, even better, a magnet link. reply yjftsjthsd-h 2 hours agorootparentI dunno, I actually think a public key is better than a hash, because it lets you sign updated images without having to update things on the client. Obviously it should be user-controlled, but this feels like a legitimate use. reply xur17 2 hours agorootparentIt is more flexible than a hash, but it's also more complicated. reply mrgaro 8 hours agoparentprevI remember the glorious AIX machines we had which could book from tape backups made with a simple \"mksysbk\" command. :) reply bastawhiz 6 hours agorootparentHow slow was that? reply dspillett 5 hours agorootparentIf it is pulling a filesystem from tape into memory and booting from that, it could be pretty quick. Reading sequentially from tape, if you are already at the right location which is easy if that location is the start of the tape, isn't particularly slow at all – non-sequential access is where tape storage becomes very slow due to massive latency in the physical mechanisms. reply jpalomaki 7 hours agoparentprevBooting over HTTP would be interesting for device like Raspberry. Then you could run without memory card and have less things to break. reply yjftsjthsd-h 4 hours agorootparentI would also prefer HTTP, but Pis can use PXE boot and mount their root filesystem over NFS already:) Official docs are https://www.raspberrypi.com/documentation/computers/raspberr... and they have a tutorial at https://www.raspberrypi.com/documentation/computers/remote-a... reply wang_li 2 hours agorootparentOnce you have PXE you can do all the things -- NFS boot, HTTP boot, iSCSI boot, and so on. There are several open source projects that support this. I think the most recent iteration is iPXE. reply westurner 1 minute agorootparentiPXE: https://en.wikipedia.org/wiki/IPXE : > While standard PXE clients use only TFTP to load parameters and programs from the server, iPXE client software can use additional protocols, including HTTP, iSCSI, ATA over Ethernet (AoE), and Fibre Channel over Ethernet (FCoE). Also, on certain hardware, iPXE client software can use a Wi-Fi link, as opposed to the wired connection required by the PXE standard. Does iPXE have a ca-certificates bundle built-in, is there PKI with which to validate kernels and initrds retrieved over the network at boot time, how does SecureBoot work with iPXE? yjftsjthsd-h 1 hour agorootparentprevThat's true, though I always have felt that if I needed PXE+TFTP to boot the bootloader I might as well just load a kernel+initrd from the same place and be done with it; I couldn't remove the TFTP requirement so anything else would just be extra things to configure. If UEFI can really do pure HTTP (as discussed upthread) then I may need to reevaluate. (Well, for Raspberry Pis I'll have to keep TFTP, but maybe in other contexts I can drop it) reply lesuorac 6 hours agorootparentprevhttps://www.google.com/search?q=raspberry%20pi%20pxe%20booti... There was an article recent for somebody doing it on an Orange Pi [1]. IIUC, you can have one RasPi with an SD Card (I use USB drives but w/e) to be the PXE server and then the rest can all network boot. [1]: https://news.ycombinator.com/item?id=40811725 reply AnimalMuppet 6 hours agorootparentprevWelcome back, diskless workstations! We've missed you... oh, wait, no, we really haven't. This is technically neat, but... How often does the memory card break on a Raspberry? How often does the network break (either Raspberry hardware or upstream)? There are fewer things to break when you run from local hardware. reply ssl-3 53 minutes agorootparentAmusingly, most of the things I regularly use Raspberry Pi hardware for require a functional network as well as functional storage on that network. If I were to netboot these things, then I'd have fewer points of failure than I do now. reply Semaphor 4 hours agorootparentprevI'd say sd card failures are the most common rPI failures. reply prmoustache 8 hours agoparentprevGrub can boot a kernel from http too. reply unixhero 8 hours agoparentprev\"The network is the computer.\" It was a shortlived thing. reply anon35 7 hours agorootparent\"Short-lived\" depends on your perspective. Cloudflare owns the rights to that trademark now; because they believe their mission furthers that vision: https://en.wikipedia.org/wiki/The_Network_is_the_Computer (and John Cage, the Sun employee who coined the phrase, said he was fine with Cloudflare picking it up: https://spectrum.ieee.org/does-repurposing-of-sun-microsyste...) reply msh 7 hours agorootparentprevI guess Chromebook’s is the resurrection of the idea reply Teckla 6 hours agorootparentThanks to Crostini, Chromebooks are also excellent local computing devices. reply bluGill 4 hours agorootparentprevNot really. Chromebooks don't use the LAN. They can run code locally, or on the server in a different timezone. However with Sun if you needed more CPU you could log into all the machines on your local network - all machines shared the same filesystem(NFS) and passwd (I forget this was), so using all the CPUs in the building was easy. It was unencrypted, but generally good enough until the Morris worm. Of course moderns servers have far more CPU power than even the largest LANs back in 1986. Still those of use who remember when Sun was a big deal miss the power of the network. reply toast0 1 hour agorootparent> all machines shared the same filesystem(NFS) and passwd (I forget this was), so using all the CPUs in the building was easy. Sun did this through NIS, originally Yellow Pages/YP, but name changed for trademarks. When I worked at Yahoo, corp machines typically participated in an automounter config so your home would follow you around, it was super convenient (well, except when the NFS server, which might be your personal corp dev machine under your desk, went away, and there was no timeout for NFS operations... retry until the server comes back or heat death of the universe). They used a sync script to push passwords out, rather than NIS though --- a properly driven sync script works almost as fast, but has much better availability, as long as you don't hit an edge case (I recall someone having difficulty because they left the company and came back, and were still listed as a former employee in some database, so production access would be removed automatically) reply MisterTea 5 hours agorootparentprevThat's because Sun just bolted stuff on to Unix. Bell Labs actually achieved that goal in Plan 9 which is still very much alive. reply ktm5j 4 hours agoparentprevI remember doing this to install Solaris while resurrecting an old sparcstation. Fun times! reply Iwan-Zotow 7 hours agoparentprevhttps://unix.stackexchange.com/questions/228452/can-grub-loa... reply rwmj 11 hours agoprevHow about booting Linux off bittorrent? https://libguestfs.org/nbdkit-torrent-plugin.1.html#EXAMPLES The problem with booting Linux off very high latency devices is the kernel tends to time out I/O requests after too short a time (60 seconds I think) so you have to adjust those timeouts upwards. reply yencabulator 3 hours agoparentIf that's a huge problem, you can wedge FUSE in there somehow, as far as I know there's no automatic kernel-side timeout to requests sent to FUSE. reply nemoniac 11 hours agoprevSpeaking of booting Linux from places, what I would like to be able to do is carry a Linux image around with me on my (Android) smartphone, plug the phone into a USB port on a laptop and boot the Linux image from there on the laptop. Does such a thing exist? reply franga2000 10 hours agoparentThis really is nice to have and a sibling comment has already linked to DriveDroid, the solution I'm using for this. Back in the CyanogenMod days, I had an even better setup: there was an app that also let you emulate a USB keyboard and mouse, so I could, with some command-line trickery, boot a computer from an ISO on my phone, then use that same phone as a keyboard and mouse/trackpad, including in the BIOS. reply stragies 10 hours agoparentprevA magisk module to do just that: https://github.com/nitanmarcel/isodrive-magisk needs root, and your kernel needs USB Mass storage gadget support module enabled, which, sadly, LineageOS doesn't enable by default. reply Timber-6539 5 hours agorootparentI have used this many times on my phone running LineageOS. Did not have to enable any kernel features. reply stragies 4 hours agorootparentOn the phones, where the Vendor kernel has this option enabled, Lineage also enables it, e.g. most LGs. But Lineage does not enable it on all kernels, even if it could just be enabled. I observe this on all of my Samsungs, for example. You can use this app to see which USB gadget options are enabled on your kernel: https://github.com/tejado/android-usb-gadget reply Timber-6539 2 hours agorootparentMakes sense. My phone model is a Xiaomi. Don't know why Samsung would ship their kernels without ConfigFS support but I have never had such issues. reply stragies 1 hour agorootparentIt's not about `ConfigFS` as a whole, but specifically `CONFIG_USB_CONFIGFS_MASS_STORAGE`, that is left disabled, while lots of other `CONFIG_USB_CONFIGFS_BLA` are enabled. This and more can be seen in the `device info` screen of the App mentioned above reply Timber-6539 38 minutes agorootparentShould have said *proper ConfigFS support. Anyway, had no prior interest in this kernel feature until you mentioned the anomaly that is specific to certain vendors. You can also do `zcat /proc/config.gzgrep CONFIGFS_` in a root shell (su) inside termux to get what options are set by the default kernel. reply toast0 1 hour agoparentprevAndroid stopped exposing USB Mass Storage, because it's problematic for the core use case of letting you grab pictures and what not from your phone, because it requires exclusive access to a filesystem; that wouldn't be a big deal for you, I don't think, you probably just want to create a large file and expose that as a device, but the implications of exposing the sd card (or the virtual sd card) as mass storage are why it went out of style. I did find this, but it's ancient and may not meet your needs anyway... https://xdaforums.com/t/app-root-usb-mass-storage-enabler-v1... reply Aardwolf 1 hour agorootparentWhat do you mean, usb mass storage was much better for the core use case of getting pictures of your phone than the flaky mtp now is reply toast0 8 minutes agorootparentI mean, yes, but ... If the sd card is mounted by your computer, you can't run any apps on the phone that need to use the sd card. That means, apps you moved to the SD card for space reasons, or apps that might save photos to the SD card (such as messengers). If your computer messes up the filesystem, then you're in a world of hurt. reply hexmiles 11 hours agoparentprevhttps://play.google.com/store/apps/details?id=com.softwareba.... It dosen't work on all smartphone reply senectus1 11 hours agorootparentAlso requires Root access reply sambazi 6 hours agorootparentnot sure if such a thing can work w/o root reply sambazi 6 hours agoparentprevi used drivedroid [0] on in the 2010's for this purpose. handy but never essential. requires root though. [0] https://play.google.com/store/apps/details?id=com.softwareba... reply sandreas 10 hours agoparentprevBoot linux of a Smartphone would take drive emulation, which is possible, but not easily available. To rootless Boot a Linux ON (not from) your phone is possible via tmux APP. Search for \"rootless kali nethunter\" on YouTube. See here: https://m.youtube.com/watch?v=GmfM8VCAu-I reply ce4 10 hours agorootparentThat is not booting a linux-kernel at all. it is just using the existing kernel which Android is based on (also Linux). reply 0x1ceb00da 9 hours agoparentprevGlue a bootable usb to your phone. reply akoboldfrying 6 hours agorootparentYes, do this. Don't under any circumstances try to solve a cute technical challenge -- that would only lead to fun, or worse yet, satisfaction. reply gibspaulding 3 hours agorootparentIt sounds to me like software enlightenment: https://xkcd.com/1988/ reply adriancr 10 hours agoparentprevYou could set up a PXE boot server on the android phone, then set up computer to boot off it. reply ddalex 10 hours agoparentprevWhy just not use Samsung's DeX that gets you a linux desktop when you plug your phone in a usb-c monitor/console reply Crestwave 9 hours agorootparentWasn't Linux on DeX discontinued? reply criddell 8 hours agorootparentYes it was. reply sambazi 6 hours agorootparentprevdifferent use case and requirement for samsung device? reply jstanley 11 hours agoparentprevWhy does it need to be on the phone? Carry a normal USB stick. reply Infinity315 11 hours agorootparentIt doesn't, but consider that the vast majority of us already carry our phones everywhere. Would carrying an extra USB stick be that big of a hassle? No, but I can see the need for booting up a ready Linux image being extremely situational so the vast majority of time you're just carrying dead weight. reply forgotpwd16 11 hours agorootparentYou can have a stick with one boot and one commonly formatted (FAT32/exFAT/ext) partition, Linux image being stored in later. Then it's like a normal stick that can also be used to boot Linux. Ventoy automates this process, allowing you to throw any ISO in a specific directory and boot it. reply 2OEH8eoCRo0 6 hours agorootparentprevWouldn't it be cool if these general purpose computers in our pockets were useful in novel ways? You're only allowed to use it in the prescribed fashion. reply Medox 10 hours agorootparentprevThe USB stick will be forgotten or lost much quicker than the phone. reply lizknope 7 hours agorootparentI have a few Verbatim \"Tuff and Tiny\" USB drives. Like this but without the plastic clip part. I can fit them in my wallet because its about the thickness of 2 credit cards which are also in my wallet. https://www.amazon.com/Verbatim-8GB-Clip-Flash-Drive/dp/B00N... reply Medox 5 hours agorootparentReminds me of the credit card sized (literally [1]) USB stick I still have somewhere but it was too annoying to carry around and hope that next time that cheap stick still works... Using the phone directly still seems the cleanest and most reliable way. Or maybe a combination of both, like those magnetic plugs [2] but with an integrated USB stick. Bonus points if you don't have to take it out at all (until needed) by either connecting the other magnetic part for data transfer and charging or data through USB OTG and wireless charging. One can dream... but the technology will shrink even further so who knows. 1. https://www.amazon.com/Enfain-Flash-Drives-Memory-Credit/dp/... 2. https://www.adafruit.com/product/5524 reply diggan 9 hours agorootparentprevUSB sticks attached to keychains are already widespread in some communities (DJs for example), I'm sure us software people could do it too if we wanted to :) reply zamalek 1 hour agorootparentI leave my keychain at the door when I get home. This is probably a common practice. reply felixg3 2 hours agorootparentprevThat makes sense. I once got falsely identified as a DJ, but it was just a YubiKey. reply Perz1val 4 hours agorootparentprevAlso attach an USB killer for extra thrill reply akoboldfrying 6 hours agorootparentprevI glue phones to all my USB sticks for just this reason. reply eisbaw 8 hours agoprevI wouldn't technically call this \"boot\" since the kernel has already booted... If get google-drive \"mounting\" support into grub, then I'll concede. This just places the rootfs on some strange place. btw, I have a project in my drawer, to place rootfs of my NixOS on IPFS. reply prmoustache 12 hours agoprevCan you really say you are booting off of something remote when you are really booting a rootfs from a local initramfs of several megabytes? reply creshal 11 hours agoparentNot any worse than 32+ megabytes of UEFI booting off of an iPXE bootrom. reply 01HNNWZ0MV43FF 12 hours agoparentprevThat's what I'm saying about hard drives and ROMs reply unixhero 12 hours agorootparentYeah we didn't need those silly hardrives with their crufty filesystems. reply russdill 12 hours agoparentprevTo close the loop, they really need an EFI stub that loads a combined kernel image/ramfs from Drive. reply ceving 12 hours agorootparentiPXE can already boot from a web server: https://ipxe.org/ reply e12e 2 hours agorootparentShould be possible then, if you \"share\" the initrd and Linux image? https://stackoverflow.com/questions/37453841/download-a-file... reply omnicognate 8 hours agoparentprevPerhaps that's what this \"off of\" preposition means. I've often wondered. reply amelius 10 hours agoprevWhat people really want is sub-second booting, especially in embedded. It is a hard problem but somehow nobody seems interested in doing the hard CS research to solve it. reply rwmj 9 hours agoparentThere's tons of work on millisecond boot times going on, in kata-containers, confidential computing, and various \"serverless\" implementations. I wrote a paper about it nearly a decade ago too[1]. [1] http://git.annexia.org/?p=libguestfs-talks.git;a=tree;f=2016... reply amelius 8 hours agorootparentAnd I still can't boot my Linux system in a reasonable time. Perhaps the true problem that needs to be solved is that everybody is somehow (forced at) reinventing the wheel every time. reply bluGill 4 hours agorootparentThe real problem is linux is just a kernel - they cannot force you to have good hardware. If you want fast boot you need to start with the hardware: a lot of hardware has an long init sequence so there is no way the kernel can boot fast as it cannot boot until that hardware is initialized. Then you can look at the kernel, step one is strip out all the drivers for that slow to init hardware you don't have (since those drivers have to insert waits into the boot while they check for the hardware you don't have). If you do this you can save a lot of boot time. Of course in the real world the people who select your hardware don't talk to the people who care about software. So you are stuck with slow boots just because it is too late to go back and do a fill million dollars each board re-spins now that we know our boot times are too slow. It gets worse, even if you select fast init hardware that doesn't mean it really is fast. I've seen hardware that claims to not need long inits, but if you don't insert waits in the boot there are bugs. reply amelius 4 hours agorootparentWell, in many cases people __can__ get a kernel to have decent boot times if they pour sufficient time and energy into it. reply zokier 1 hour agorootparentprevAt least on my completely unoptimized desktop, majority of boot time is already spent in UEFI firmware, not in kernel or userspace startup. So realistically there is limited opportunity to optimize the boot times. reply yencabulator 3 hours agoparentprevLinux boots to your application in 125 ms. There's no hard problem there, just bloat, general-purpose systems, and hardware not designed to boot fast. reply dataflow 7 hours agoparentprev> hard CS research I'm surprised to see this, in what way does it require hard CS research? Isn't it just debugging and implementation pain? reply amelius 7 hours agorootparentI can only guess here. But remember that software package management was a pain too and it took someone to do a Ph.D. on the topic to give us NiX (and it still isn't perfect). reply dataflow 7 hours agorootparentAh I see where you're coming from. I don't see any reason to expect that's the case here though. Package management has some fairly obvious tough CS problems inherent in it -- dependency resolution with version upgrades inherently feels NP-hard, for example. Whereas booting is about making hardware that initializes quickly and then making software that abstracts over a variety of hardware well... within the development budget you have. And then you're stuck with backward compatibility as everything changes. I could be wrong here but it feels like a costly engineering problem more than anything else. (Note I'm not saying you can't do a PhD in it and improve the situation -- you could probably do that for any problem, honestly. Just saying that I think you could get most of the way there by just paying the engineering cost.) reply akoboldfrying 6 hours agorootparentDependency resolution with versions is indeed NP-hard, if versions \"conflict\" (2 versions of the same package can't be installed at the same time). What if they don't conflict, and you just wanna install the fewest possible package versions to satisfy all dependencies? That's NP-hard too. reply amelius 5 hours agorootparentI suppose you could use a generic SAT solver for that. EDIT: https://hal.science/hal-00870846/file/W5_PX_Le_Berre_On_SAT_... reply amelius 7 hours agorootparentprevI'm just seeing that this is a forever lingering problem and I think if only engineering costs were involved the problem would have been solved by now. reply jvdvegt 11 hours agoprevHe casually mentions he boots of S3 as well. Changing S3 for Google Drive mostly adds latency, apparently. But still, nicely done! reply _flux 10 hours agoparentRedundant S3 is easy-ish to selfhost, though, so that could actually be a decent way to setup reliable diskless workstations. reply yencabulator 3 hours agorootparentAt that point you might as well run Ceph and give your diskless workstations a writable block device via RBD. The overhead of an S3 operation per file is quite high. reply _flux 3 hours agorootparentThere are some easier solutions for just S3, like Minio, which I imagine is likely much easier to setup than Ceph (though ceph is not that hard with cephadm). reply yencabulator 3 hours agorootparentBy the time you add the word \"redundant\" in the mix, nothing is really easy anymore. reply yencabulator 3 hours agoparentprevHis S3-compatible bucket was locally hosted, did not go over the internet. reply Vogtinator 5 hours agoprevI did something similar some time ago: Booting from an RPM repository on a Tumbleweed installation DVD. My initial goal was to write a fuse filesystem for mounting RPM packages, but I wanted to see how far it goes. Turns out, pretty far indeed: https://github.com/Vogtinator/repomount/commit/c751c5aa56897... The system boots to a working desktop and it appears like all packages available on the DVD are installed. reply coisasdavida 53 minutes agoprevA few days ago I was able to boot armbian on a tvbox I got from the trash, felt so great, now feels so pedestrian... reply sirjaz 5 hours agoprevWe do this all the time in Windows with Citrix. It is called pvs. It does a small pxe boot and then it streams down the windows server image reply iamleppert 3 hours agoprevCan you boot Google off a Linux drive? reply fsckboy 12 hours agoprevmid 90's, a friend of mine installed Windows NT to, and booted it from, a DAT tape reply kotaKat 6 hours agoparentWhile not booted from, wimlib's support for pipable WIMs means through some shenanigans, you can install modern Windows from tape. I had a bootstrap ISO that would fire up Windows PE, mount my USB DAT tape drive, rewind it, prep the onboard storage, then image direct from tape to disk and make it bootable. I posit that because wimlib supports pipable WIMs that we could pipe an endless stream of QR codes to it (thus making the \"installing Windows from QR codes\" possible)... reply Maakuth 12 hours agoparentprevHow long did it take? Seek times for tapes can be minutes, so fragmentation matters a great deal here. reply raffraffraff 10 hours agoparentprevThat must have been fun. In the late 90s I worked in the server support line for DEC, and the number of times we had to talk people through the \"invisible F6 prompt\" was nuts. reply tryauuum 8 hours agorootparentcan you explain? reply sjsdaiuasgdia 6 hours agorootparentIf your intended system volume was going to require drivers that weren't built into WinNT, you needed to press F6 at a specific point during installation. This would allow you to load a driver that makes the volume visible / usable. This process was specific to installing storage drivers needed for the system volume. All other driver installation happened elsewhere. My memory says there was actually a \"Press F6 to load system storage drivers\" prompt or something displayed by the installer, but it wasn't displayed for all that long a time and I imagine it was effectively invisible for many people. I recall spamming F6 to make sure I wouldn't miss the prompt. reply brnt 11 hours agoparentprevI got PTSD from installing Windows 95 from floppy and after 40 floppies getting read errors... reply raesene9 10 hours agorootparentMy first IT job involved installing a lot of Windows 95 from floppy disk. Luckily each PC I bought came with a set, so I'd build up some \"good sets\" over time after discarding all the disks that had read errors. reply yencabulator 3 hours agorootparentprevThe first time I installed SLS Linux (pre-Slackware), it took some 25 1.44MB floppies and I owned ~20 empty ones. I left the installer running overnight and downloaded more floppies the next day at school. It took an extra day because some floppies had bad sectors, and had to be re-downloaded.. reply beAbU 11 hours agorootparentprevSomewhere in my parents' house there is a massive box with floppies for office 95 (or whatever it was called back then). Not 40 floppies massive, but still a large number. I think we managed to only ever install it once successfully without error. Also, fun semi-related fact: In my country we called 8\" and 5.25\" floppies \"floppies\", and the smaller 3.5\" ones were called \"stiffies\" - because the larger ones were floppy, and the smaller were, well, stiffer. Do with this information as you please. reply exe34 11 hours agorootparenti need to know which country this is, please! reply obrix 9 hours agorootparentHappened also in Finland. It was \"lerppu\" (floppy) for the flexible ones and \"korppu\" (hard biscuit) for the hard ones. reply teschmitt 10 hours agorootparentprevI'm going to wager South Africa based on this blog post: https://jasonelk.com/2015/12/who-knew-that-the-rest-of-the-w... reply cyberpunk 10 hours agorootparentprevCertainly not the UK where inserting your stiffie in to something has rather a different connotation…. reply beAbU 8 hours agorootparentprevSouth Africa! reply sharpshadow 5 hours agoprev“…booting Linux off of a Git repository and tracking every change in Git using gitfs.” That sounds cool! reply pjmlp 12 hours agoprevTfpt boot gets rediscovered. reply yjftsjthsd-h 1 hour agoparentI mean, > Competitiveness is a vice of mine. When I heard that a friend got Linux to boot off of NFS, I had to one-up her. I had to prove that I could create something harder, something better, faster, stronger. sounds like they're well aware of the traditional way to do it, and are deliberately going out of their way to do something different and weird. reply INTPenis 10 hours agoparentprevYou meant to say tftp right? I'm just checking if there is some long lost technology called Tfpt that I have never heard of. reply pjmlp 10 hours agorootparentTypo. reply kvdveer 11 hours agoparentprevBut now with some one else's computer (aka, \"the cloud\") reply pjmlp 10 hours agorootparentIt was always with someone else computer, we used to call it timesharing and thin clients. :) reply throwaway984393 7 hours agorootparentIt was especially fun when you used someone's entire computer lab during night hours ;) reply pjmlp 3 hours agorootparentYep, I had some fun with PVM, for the audience, somehow the alternative that lost to MPI. reply throwaway984393 7 hours agoprev [–] Considering how slow and buggy it is to use as a rootfs, you can instead put an initrd on Google Drive and just boot that. You'll need to make it by hand to get it to a reasonably small size, so picking up a copy of Linux From Scratch, and using libmusl or libuclibc along with BusyBox, will go a long way towards a functional system in a small size. If you want a fuller system you could try 1) convert the filesystem to tmpfs after boot and install packages to RAM, or 2) mount a remote disk image as your roofs rather than keeping individual files remote. The former will be blazing fast but you're limited by your RAM. The latter will be faster than fuse, benefit from io caching, and not have the bugs mentioned. reply remram 4 hours agoparent [–] How do you load the initrd? reply yjftsjthsd-h 1 hour agorootparent [–] UEFI provides a pretty complete environment; it would probably not be too hard to write a .efi program that connected to network and downloads whatever you want from Google Drive (or anywhere else) into RAM and runs it. For that matter, IIRC Linux can already build a combined kernel+initrd into a .efi, so you could make this semi-generic by writing a gdrive.efi that downloaded an arbitrary .efi from gdrive and booted it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A developer successfully booted Linux from Google Drive using FUSE and custom initramfs, showcasing a novel approach to cloud-native computing.",
      "The process involved using google-drive-ocamlfuse to mount Google Drive and transferring Arch Linux, despite challenges like broken symlinks and slow performance.",
      "This proof of concept, tested on real hardware, highlights future possibilities such as booting Linux off SSH or a Git repository, emphasizing the potential for innovative cloud-native solutions."
    ],
    "commentSummary": [
      "A new method has been demonstrated for booting Linux directly from Google Drive, reminiscent of older network booting techniques like Sun Solaris' wanboot.",
      "This approach leverages modern UEFI (Unified Extensible Firmware Interface) capabilities, which can boot from HTTP, making it possible to load both the initramfs (initial RAM filesystem) and the kernel over the network.",
      "The discussion highlights the potential for using similar methods for devices like Raspberry Pi, which can already perform network booting using PXE (Preboot Execution Environment) and other protocols."
    ],
    "points": 318,
    "commentCount": 130,
    "retryCount": 0,
    "time": 1719897623
  },
  {
    "id": 40851919,
    "title": "Getting the World Record in Hatetris (2022)",
    "originLink": "https://hallofdreams.org/posts/hatetris/",
    "originBody": "Hall of Impossible Dreams A repository of code, fiction, nonfiction, and poetry. HOME CATEGORIES TAGS ARCHIVES ABOUT Posts Getting the World Record in HATETRIS Post Cancel Getting the World Record in HATETRIS Posted Aug 11, 20222022-08-11T01:00:00-04:00 by David & Felipe Updated 17 hours ago2024-07-01T21:10:32-04:00 Previous post: Prologue in HATETRIS Tetris That Hates You StickManStickMan #611, by Sam Hughes. HATETRIS is a version of Tetris written in 2010 by programmer and sci-fi author Sam Hughes. According to his initial description of the game: This is bad Tetris. It’s hateful Tetris. It’s Tetris according to the evil AI from “I Have No Mouth And I Must Scream”. (And if you aren’t familiar with Tetris at all, and don’t know the rules or pieces, we recommend trying out the original game for yourself; Wikipedia has an article about how Tetris in particular can consume your life and enter your very dreams, but we’re sure you’ll be fine.) The hatred comes from the way pieces are selected. In most variants of Tetris, the piece selection is pseudorandom, with methods ranging from independently random selection to the more recent Bag Random Generator. In almost every variant that isn’t truly random, the changes to randomness are done to make the player less likely to get two pieces of the same type in a row, or to go too long without seeing a given piece. HATETRIS selects pieces in almost precisely the opposite manner, with a one-move lookahead min-max algorithm: First, check every possible position for all seven pieces. Second, among those positions, examine how ‘good’ each of these moves is for the player, by measuring how high the highest block in the well is. Third, select the piece which has the worst best-case scenario for the player. If there is a tie, break the tie in the piece order S, Z, O, I, L, J, T. There’s no randomness involved: the first, second, and third pieces you get upon starting the game will always be the S piece, and so will most of the others throughout the game. There’s no next piece window, since the next piece isn’t decided until you finish your move. There’s no possibility at all of getting four lines at once with a well-placed I piece, since the game will never under any circumstances give you an I-piece that you could use to clear four lines. And, in general, if you’ve set up to clear a line and there’s any piece at all which denies you that line for at least a turn, that’s the piece you’re going to get. It’s a common experience for players to try the game for the first time with a strategy perfectly sound for normal Tetris and score no points at all, simply because normal Tetris strategy amounts to setting up good situations and then waiting for the odds to be in your favor. With a deterministic algorithm like this one, the odds will never be in your favor. High Scores The flip side of determinism is predictability. Because the algorithm will always return the same move given the same history of moves, it’s possible to plan ahead and come up with complex strategies that one could never use in a non-deterministic game - and it’s possible to share results. The first few records (Mr. Hughes’ initial game of 5 points, and commenter JeremyBowers’ and Kazanir’s claims at seven points) were lost to history, but once replay functionality was added the day after release, the comment section became a leaderboard, and anyone could take an existing replay and copy the moves to try to improve on the same strategy. Commenter Atypical posted the first replay, an eleven-point run, and over the next month, the high score was pushed to 17, 20, 22, 28, and finally 30, all using the same opening sequence of moves to create wells where every piece can be used to clear a line, four or five times in a row. This sequence of moves was so successful, in fact, that every world record run for ten years after its discovery used it. The Atypical strategy consisted of stackingS-pieces to the left of the well, clearing as many lines as possible, building a flat ‘ceiling’ on top of the pieces currently in the well, and then effectively starting from scratch on top of that ceiling. By the time of the 30-point runs, the Atypical strategy was so successful that it was even done a third time, near the end of the game. So far as we know, there isn’t a term for this, so we call this a pseudoloop; you’re not getting back to the same well you had before, but you’re doing the same pattern over and over again. This score of 30 points, set a month after release by the Japanese Slashdot poster Deasuke, held for the next seven years. When we started playing the game in 2013, we assumed that 30 points was as high as humans would ever get, and was probably as high as the game’s mechanics would allow. But around 2017, we started tinkering a bit with machine learning, and the question naturally came up: could a program be written to beat HATETRIS? We floated around a few ideas - including what would have been a very primitive version of a Monte-Carlo tree search - but never got around to implementation, even after commenter chromeyhex eked out another point a few months later and proved that 30 was not the maximum after all. It wasn’t until June of 2021, when commenter knewjade optimized the final few moves of the existing high score to get a score of 32, and then 34 points two days later, that we decided to start coding in earnest. And then, a week after that, knewjade got 41 points…and did so with a somewhat different opening sequence than the one which had been used and improved upon for ten years. And a week later, he pushed it to 45. The Rust emulator was working by that point and the program could play around a hundred random games per second…but that was about all it could do, and we weren’t even close to using any machine learning yet. We breathed a slow sigh of relief as weeks went by and our own project made progress with no new world records being set, until knewjade in late August of 2021 posted a high score completely unlike any game known to exist for HATETRIS, totalling 66 points. This game is beautiful. Pieces set up in clearly unclearable positions turn out to be vital to clearing a line ten moves later, and it isn’t until fifteen points in that knewjade is forced to allow even a single hole higher than the first line. There are no pseudoloops - the shape of the well is constantly changing, and the well is quite frequently piled up almost to the top of the well to then clear multiple lines one after the next. By this point, knewjade had posted an explanation of the code he used to find these new high scores (and this explanation will be key to our success, later), but even without the explanation, it was very clear that there was machine search involved somewhere. The game was simply too novel, discovered too quickly, and optimized too well, to have been done by a human being unaided. So it was possible for a machine to learn HATETRIS - we just had to learn how to teach it. Choosing a Language For starting the project, our shortlist came down to three languages: Mathematica, python, and Rust. Each had various pros and cons: Mathematica: Pros: huge amount of personal experience, huge number of useful built-in functions for machine learning and general analysis, easy to make visualizations or monitor in a dynamic way. Cons: slower than molasses in January. Python: Pros: Lots of good built-in machine learning APIs, like Tensorflow, Keras, and PyTorch. Faster than Mathematica. Cons: Still slower than compiled languages. Rust: Pros: Extremely fast. Cons: Not much in the way of built-in machine learning tools. Everything ultimately came down to speed; no matter what the plan, or what variant of machine learning we were going to do, we’d need vast quantities of data, and we’d need to get that data with a single mid-range desktop computer. And calculating the legal HATETRIS moves was going to take time; the initial implementation of the game in Javascript mentioned that the algorithm is “quite time-consuming to execute, so please forgive me if your browser chugs a little after locking each piece”. So, to get as many games and as much data as we could, we’d need every advantage, starting with the fastest language we personally knew. As a point of reference, the first speed test we did was playing random games with an unoptimized emulator in Mathematica, and the same unoptimized emulator in Rust. Mathematica took 4.3 seconds per game on average, and Rust took 0.035 seconds per game on average. This was such a big difference that we deemed that all of the hassle and aggravation of negotiating with Rust’s borrow checker would be worth it. The Story So Far When we first started on this project, we had a very clear idea of what we thought a winning strategy would be: A Monte Carlo simulation, powered by Machine Learning! Just like they do in AlphaGo and the more generalized AlphaZero. Surely someone had already written an implementation and all we had to do was write an emulator, hook it up to a nebulous AlphaZero implementation and emerge with a world record. How long could it take? Two weeks? MCTS MCTS (Monte-Carlo Tree Search) is a well-trod path in gameplay simulations. Without getting into details, since the methodology behind MCTS is much better explained elsewhere, the core conceit is to make each move in a game into a tree-like structure and then explore the tree. Chaslot et al., 2008 Implementing a tree structure for HATETRIS positions was achievable. It was only after the initial tree implementation that we considered that there would be a lot of repeated wells: after all, in this game you can reach the same position in a number of different ways. A lot of deliberation and a re-factored codebase later, we opted for a directed acyclic graph (DAG) instead, taking identical positions and merging them into the same entry in a graph, rather than making them distinct entries on a tree. This complicated things significantly, but reduced our memory needs by an order of magnitude, at least. Refactoring from tree searches to DAG searches was more work than we’d expected to put in to the project, but was yielding promising results. An early depth first search got us scores of up to 14, with a simple greedy search looking for easy scores. At the time, the record was sitting at 34, so we felt very confident that we were on the right track. It was sobering to realize, also, that “Graph vs Tree” in MCTS was in fact a discussion happening in professional circles. For example, this paper, which we read and didn’t fully comprehend, had a very succinct explanation of how DAGs were different from trees, and why it mattered: We highlight that we fully failed to understand these, because there’s two things we learned from this: Reading the academic papers is important, because sometimes experts have the same problems you do. You don’t have to understand the whole paper (or most of the paper) to derive useful insights. Sometimes looking at the pictures is enough. By this point we had a working emulator and a directed acyclic graph, and were ready to get rolling. MCTS + AlphaZero As it turns out, there is no “AlphaZero generic game engine that magically gets you world records” in Rust. There might be one in Python. Regardless, we could not just plug our MCTS to a magic library and hope for things to happen. Oh no. Instead, we had to build a monstrosity of layers using tch, a Rust-Pytorch-C binding library to make a model to train. The details of this are interesting, but not ultra-relevant to our world record run. We plan on writing a more detailed post-mortem after this blog where we dissect that at length. The main takeaways: Training a model took a long time, in the order of weeks. Mutating hyperparameters to improve results was difficult with long runtimes. We only had a few tens of thousands of games to train on, which made the learning extremely poor. Weeks and weeks of iteration produced worse and worse models, some overtrained, others just terrible. We were likely doing several things that would get us summarily exiled by real machine learning engineers. Now, we are going to intentionally gloss over the giant, annoying mess that was multithreading our MCTS, a tangled web of mutexes, arc(mutexes) and locking paths that we still haven’t cleaned the bugs out of. We even had to make our own branch of tch to support mutexing the learning network. In summary: We tried multithreading. It improved performance. But our models were… awful, taking two full months to get back to where the simple, greedy MCTS search had gotten us in a couple of days. And they showed no signs of ever improving. As a desperate last maneuver, we looked to knewjade’s new shiny record (66, at this point in time). Using knewjade’s heuristic, we generated ten thousand more MCTS games (the best of which scored 20 points), fed them to the model, and let it cook for two weeks. The resulting model was somehow worse than our training data, scoring at most 17. Which meant our poor model was just never going to rise above its training data. Not with the meager resources we could provide it. AlphaHATETRIS was officially dead. The Emulator So, with AlphaHATETRIS dead, what did we have to work with? Well for starters, we’d written a pretty darn good emulator. Our best version is still not the best version that exists, but it worked well for our needs. How does this emulator work, anyway? Well, Well, Well Some quick terminology, since we’ll be using the word “well” and “move” until they lose all meaning: A well is the 20 x 10 area in which the game is played, and any blocks currently in it. In general, when we talk about a well, you can think of it as a snapshot of a game in progress. A piece is the four-block shape being maneuvered around in the well. When the piece cannot move down any further, it merges with the well and stops moving. This generates a new well. A position refers to a legal placement of a piece within the well, be it terminal or not. A terminal position is a piece that has reached a position where it can no longer descend, that is, it is going to become part of the well, exactly where it is. It’s terminal because once this piece is placed, we have created a new well. A move is a placement of a piece within a well, such that it is terminal, and generates a new well. We do not consider non-terminal motion inside the well to be a ‘move’. (Left: A piece, in blue, at the beginning of its move. Center: a piece at the end of its move, in a terminal position. Right: a piece, in blue, at the beginning of the next move. The previous piece has merged with the rest of the well, indicated by the grey squares.) Basic State Management Our first draft was the obvious approach, considering every possible position by every possible piece, and repeating until there are no new positions left. Move generation in this context, refers to only generating the moves for a specific well. That is, each time you get a piece, what are the places the piece could go? Our initial version of the emulator took a well, and considered all the possible positions for the piece inside the well: First, take the initial position, and calculate the positions that could result from going left, right, up or down. Continue calculating the left, right, up, and down motions for each new position you encounter, and remove any illegal positions which intersect a filled square, or go outside the well. Merge any duplicate positions together. When there are no more new positions, check to see which positions aren’t illegal, but which can’t go down. This gives you the possible terminal positions for the piece: the place where the piece can rest and merge with the well. Repeat for all seven pieces. When you’re done, determine which piece the HATETRIS algorithm would give you, pick from that piece’s terminal positions, and with this new well, start again from step 1. It’s a pretty straightforward approach to dealing with wells, and it was fast. It could get the moves for an empty well in 1.1 ms, which was very good compared to Mathematica’s 330 ms with the same algorithm, but we knew we could do better. And we would have to, since we needed several hundred million games to train our machine learning algorithm. The first improvement we made was to cut out considering positions that would only traverse empty space. That is, in a well where the first row is filled, but no others, only really consider the space in lines 2-5. Left: Considering all possible positions. Right: Considering only the positions in the non-empty part of the well. The next logical improvement was to pre-generate the state graph. That is, instead of starting with the piece in the middle and generating positions for a left arrow, a right arrow, an up and a down, we pre-computed and cached all these states in the “blank” space above occupied rows, which meant we saved significant time trying to compute all these positions, at the expense of having to have a pretty large pre-cached data structure. Fortunately there are only a few thousand starting positions for pieces, which we generated programmatically. It wound up being exactly 2457 positions between all 7 pieces. In analyzing the performance of move detection, we discovered that the majority of our time was now spent accessing the hash of positions, since whenever a new positions was explored, we had to check if it already existed. A bit of a further dig and we discovered that most of that time was spent running a hashing algorithm on the positions data for comparison. Which again, made sense…but we knew all our positions were unique among each other. We didn’t need to do any hashing, we could just use the position’s representation as a key directly, if we could find a reasonable way to encode it. So we replaced the hashing algorithm with our own custom version that encoded the position as a binary representation of position, rotation and piece type. This was much faster than having to hash a position, and we knew it guaranteed uniqueness. This doubled the speed of our move finder. At this point, we had a speed of 300 microseconds per core. That’s a ~350% speedup over our initial speed in Rust and a 10,000% speedup over our initial speed in Mathematica. We were confident we’d optimized as much as we possibly could…and still, it wasn’t nearly fast enough. We needed something faster, since all our flamegraphs clearly showed that move calculation was a giant bottleneck in performance. So, we had to pivot. GPU Matrix Operations The first idea we came up with was, fitting the theme of this project, a vague notion based on what we had read computers should be able to do. We could just do some matrix math in a GPU! Our plan was to calculate the legal moves via matrix operations, and speed up those matrix operations dramatically by running them on the GPU. The idea is simple enough: there are a finite number of positions a piece can be in. So, we start with a vector v representing the starting position of a piece, and a matrix M representing all the ways a piece can move from one position to another. The vector v*M (the vector which is the product of multiplying v by M) will then be the vector consisting of all possible positions a piece can be in after one step. v*M² will be the vector consisting of all possible positions a piece can be in after two steps. Do this multiplication n times, and you get v*M^n, a vector consisting of all possible positions a piece can be in after n steps. Eventually, v will stop having new nonzero elements, and then, you’re done - the nonzero elements of v are the positions that the piece can reach in the given well. vCurrent = startingState vReachable = vCurrent while max(vCurrent) > 0: vIntermediate = sign(v1.transitionMatrix) vCurrent = vIntermediate & ~vReachable vReachable |= vIntermediate return vReachable There were various improvements and refinements we did with this idea. Instead of using multiplication, we used Boolean logic operators to keep all the numbers either 0 or 1; instead of a full matrix, we had four vectors representing left, right, down, and rotation movements. The math worked, and gave a modest tenfold speedup when tested in Mathematica, but we estimated that in Rust the speedup would be negligible, due to the large number of redundant operations the CPU would have to do. However, GPUs are specifically designed for a large number of simple redundant operations. If we could calculate the legal moves on a GPU, it might provide a substantial speedup. vCurrent = startingState vReachable = vCurrent while max(vCurrent) > 0: vIntermediate = permute(vCurrent, leftPermutation) vIntermediate |= permute(vCurrent, rightPermutation) vIntermediate |= permute(vCurrent, upPermutation) vIntermediate |= permute(vCurrent, downPermutation) vIntermediate &= vEmpty vCurrent = vIntermediate & ~vReachable vReachable |= vIntermediate return vReachable This required us to get comfortable with difficult topics: writing code to be executed in the GPU via CUDA C and cross-compiling C code so it could run on the GPU. We’ll save the excruciating details of how that worked for the longer post, merely pointing out here that: It can be done. Make sure you’re writing CUDA C and not C++ or plain C. The linker is going to hate you, its not personal, you’ll just have to keep adjusting flags until it works. In the end, we decided not to go this route, since we came up with another emulator improvement which would provide roughly the same speedup without having to deal with the GPU, which to be honest, had proven quite daunting. Let Me Count The Waves Our final approach begun by thinking of the problem differently: First we considered this: given a specific height, there is a finite set of possible positions that fit within that height. (for example, the height 1-4). These positions are not independent of each other. That is to say, if one piece position is blocked due to a filled square, some other piece positions will be blocked as well. For a given four-line area in the grid, there is a limited subset of potential positions for a piece, considering all rotations and positions within that space. In fact, for every piece except the O piece, there are 34 possible positions (including rotations) in a 4 x 10 area. A ‘wave’ can be represented as a binary number that is 34 bits, corresponding to the 34 potential positions available to a piece. The binary represents if the position is reachable for the given piece or not. That is to say, if a position is empty and reachable, the corresponding digit in the wave is 1, and if it isn’t, the corresponding digit is 0. You also have a surface. A surface is the reachable part of a well: That is, any point which has a clear path to the empty top of the well. The key is that a wave and a four-line slice of a surface, together, form a unique transition: the same wave plus the same slice of a surface will always produce the same new wave one line further down. As a result, the number of possible waves and surfaces is finite, and as we calculate moves, we can store the wave-surface transitions that we encounter in a cache, and the next time we encounter that transition, simply look it up from the cache again, rather than calculating the positions from scratch. The final result of all this? From an original time of 330 milliseconds per move on Mathematica, to 1.1 milliseconds per move per core in Rust, to an optimized state-based emulator time of 300 microseconds per move per core, we were now down to 48 microseconds per move per core, on average. And, more importantly, finding the positions that a given piece could reach in a given well was no longer the bottleneck; any further optimization would have to be elsewhere. But why? AlphaHATETRIS was dead, and machine learning wasn’t going to get us there. But the most recent world record holder had some answers for us. StickManStickMan #17, by Sam Hughes. The Era of Knewjade The Knewjade Heuristic We’ve talked a lot in the past few minutes about knewjade (Twitter / GitHub). His heuristic. His beam searches. That’s because his work redefined how we were thinking about and approaching the problem. If nothing else, we were sure we could improve upon what he had done. To understand what we did then, it is important to understand what knewjade did to get 66 points, the highest score ever achieved at that point. More than twice what we had once considered an unbeatable 31. Fortunately, knewjade had published his work, here. While we don’t speak Japanese, Google Translate and staring at pictures helped us understand what was going on. The knewjade approach is also known as a ‘heuristic beam search’. What does that mean? A ‘beam search’ means that you take some number of positions, get all of their children, keep the best ones, and then repeat the process until you run out of positions. For instance, if you had a beam search with a width of twenty-five million, then at every step, you take the best twenty-five million children from all of your existing wells, and use them as your wells for the next step. The ‘heuristic’ part is how you sort the children from best to worst in order to keep the best twenty-five million of them. Fundamentally, the knewjade heuristic is a weighted sum of a few different factors. First, holes (empty squares with at least one full square above), and enclosed holes (empty squares with no path reaching to the surface). Holes and enclosed holes are bad. It makes sense that enclosed holes would be problematic: you must clear lines to get to them, and as we know, clearing lines in HATETRIS is no mean feat. Non-enclosed holes are a little more difficult to reason about, but without getting too technical, the layout of a hole can make it impossible or at least extremely challenging to clear, contributing height to the well, without giving an easy means of clearing lines. (In red: holes. In teal: enclosed holes.) Second, the number of lines containing enclosed holes. We’ve already covered that enclosed holes are bad for clearing lines, but not all enclosed holes are created equal. A line with more than one enclosed hole is about as bad as a line with any number of enclosed holes, since you will have to clear all the lines above it regardless of how many holes there are. Thus, we care more about how many lines have enclosed holes, than the number of overall enclosed holes. As an example, the two left wells in the picture below would score quite differently: the one on the top is much more “clearable” than the one on the bottom, since you only have to clear one line in order to be able to access the enclosed holes instead of three. (Left: two wells with two enclosed holes each; the bottom left well is clearly harder to clear than the top left well. Right, lines containing at least one enclosed hole.) Third, the erasability. How many different pieces can be used to erase a line in this well? The easier it is to erase a line, the easier it is to score. Erasability is good. This well happens to have a very high erasability score, since any piece can clear a line. To demonstrate: (A well which can clear all seven pieces) And fourth, the score. A higher score is good. After all, we want world records. No matter how nice we make a well, all that matters is the score when we inevitably lose. Each of these factors was given a weight, which knewjade generated with a real-valued genetic algorithm, and the resulting sum was the heuristic: an algorithm to evaluate any well, the higher the heuristic, the better the move. Knewjade had several improvements on this basic concept. One improvement was realizing that, since the surface of a well can almost never move down once it’s moved up, it doesn’t matter how many holes or enclosed holes there are below the surface. All that needs to be considered is the part of the well above the lowest line of the surface. A recap: a surface is the “reachable” part of the well, that is any area that can still be reached from the top. However, there is in general one exception to the ‘surfaces can never move down’ rule: when a line at the bottom of the surface can be cleared with an S or Z piece. So, knewjade’s heuristic doesn’t count holes or enclosed holes if an S or Z piece can free them. Knewjade’s approach is brilliant, interesting, and innovative, and we were confident we could copy it. Following Footsteps So, all we had to do was implement this on our own. And as it turns out, implementing this on our own had a whole host of problems. Our calculation of the surface height took a huge amount of time, and at first, before we discovered waveforms, our emulator was extremely slow, and so calculating the erasability of a given well by calculating all of the legal moves possible for that well was extremely time-consuming. For a while, we thought we could get by without the erasability, and this was a mistake: without the erasability, we could only get a score of 41. Our personal record, for sure, but hardly 66 points. So, we implemented erasability - but the slowdown was still a huge problem, so we made a second and much larger mistake: we took a shortcut. Rather than computing the erasability for S, Z, O, I, L, J, and T, every single time, we checked if S could be cleared, and only if it could be cleared checked for Z, and then only if Z could be cleared checked for O, and so forth. This sped up the heuristic evaluation significantly (many positions can’t be cleared by all seven pieces), but even when we improved the emulator and no longer had to worry as much about speed, we kept this shortcut in the code. And the problem with that is simple to state: if you’re setting up a well so that you can clear a line, you need to be able to clear that line with all seven pieces, and it does not matter what order you set this up in. We were throwing out perfectly good setups because the setups weren’t in our arbitrary order, and we had completely forgotten that this assumption was bad. We describe this as a critical mistake, even though it only takes a few sentences to describe, and only one line of code to fix, because it was by far our most time-consuming error, more than any of the tedious debugging for the GPU or multithreading sections. We lost roughly three months due to this, after all was said and done. Knewjade’s beam search had a width of 25 million, and though he could run his in two or three days, we did not have the waveform-based emulator yet, and so our beam search would take three weeks to run. And, with no way of knowing ahead of time how well a given set of heuristic parameters would scale, that’s precisely what we did. Twice. We also had to get the parameters in the first place to test out, which (as we’ll discuss below) also took weeks, and in general we wasted a lot of time looking to improve the wrong parts of the code and not realizing that it was erasability that was limiting us. Perhaps it’s unfair to blame this one mistake for months of wasted time, because even after we fixed the mistake, our implementation of knewjade’s heuristic was not as good as the original. We know this because knewjade was kind enough to send us his original parameters, and when we ran those parameters - in theory, using exactly the same heuristic he did - the beam search returned a score of 53, instead of the 66 he got. We still don’t know why it was that our heuristic did worse, or what the difference between his implementation and ours was. But by then, we’d come up with an additional term of our own, one which would make replicating the world record of 66 a moot point. Mumble Mumble Graph Theory For some months, we’d had a very interesting idea. The idea consisted of the words “graph theory”, which we’d occasionally gravely recite to each other and nod knowingly, with some vague gesticulations, and not much else. Much to our surprise, this turned out to be a workable strategy. Kind of. While writing and making the visuals for this section, we actually discovered that the graph theory heuristic made no difference at all when used on a sufficiently wide beam search, and that we would have gotten 86 points with or without it. This was in large part because the games we mined for data weren’t representative of the kinds of moves that end up setting world records, and because we didn’t mine enough games to have good sampling rates. However, we include this section anyway, since we suspect that a properly implemented version could be a significant improvement; this heuristic by itself gets 38 points on a 25 million beam search, so setting what would have been the world record before 2021 means that there’s something worthwhile going on. John Brzutowski, in his 1988 master’s thesis, proved that for a specific sequence of S and Z pieces, it was impossible to win the game of Tetris, and in the process got the ball rolling on making evil versions of Tetris, since it was now a fact that Tetris could, in theory, be so difficult as to be unwinnable. Part of his analysis was looking at the life cycle of “flats” - the creatures occupying individual lines in a Tetris well. These ‘flats’ are composed of blocks and empty spaces, and one could track an individual ‘flat’ from birth when it is nothing more than an empty line in the well) all the way until death (when it is completely filled, and the line goes away). Brzutowski’s insight was that these ‘flats’ had a very limited number of behaviors each turn. On a given turn, a ‘flat’ can: Be born Remain exactly the same. Fall down a line if there was a cleared line below. Grow (gain more full blocks in its line). Die (become completely full, and vanish). So, we can take a full game, and tag each individual flat in the game, watching it as it moves through its life cycle from birth to death - or, move through its life cycle and then stop, permanently. Because, in a game of Tetris that ends, a given flat will at some point either die (get cleared) or reach a point where it never grows, falls down, or changes ever again. The key insight we had was that some line shapes are more likely to die and get cleared than others, and that graph theory could measure and predict this tendency. Essentially there are “good” lines that clear well, and “bad” lines that are really difficult to clear. In a perfect world where we were furnished with $50,000 a day in AWS credits, we could thoroughly investigate these behaviors over four lines, but with commercial hardware, we could really only focus on one-line transitions. But how do you figure out what makes a line better than its competitors? The answer is where graph theory comes in: We have in this image a complete set of all transitions for all lines (of width 4; the width 10 transition graph was too big to properly visualize, and even this is pushing it). And, with the data from the tens of thousands of MCTS games we had, it was possible to get a frequency for every transition in this graph, ranging from “vanishingly rare” to “happens almost every game”. There is one starting point – the empty line – and two ending points, not shown in this graph: a flat dying to clear a line, or a flat becoming immortal and never changing again. We could model this. Model it how? The Ford-Fulkerson method. Imagine the empty well as a source of water, and the two possible end states are buckets. The “water” that travels through the graph all winds up either in a “immortal” bucket or a “cleared” bucket. The frequency of the transitions in the graph, then, represents how ‘wide’ the channel is. Any flat can eventually be cleared, and any flat can become immortal, but if you have a pipe a foot wide towards one bucket and a drinking straw towards the other bucket, the amount of water in each bucket at the end will be different. What we want is to rank how good different flats are based on how much of the ‘water’ flowing through them eventually goes towards the bucket labeled ‘cleared’. This is what Ford-Fulkerson does (in broad strokes, it doesn’t actually model water), and with Mathematica’s implementation of it, we had clearability, the first part of our graph theory heuristic. The second part was based on similar reasoning. Imagine you have what is frequently an incredible flat when it’s at the top, but the flat is now buried so deep below the surface of the well that no piece will ever reach it. No matter how easy that flat might be to clear in theory, in practice, it’ll never happen. So, we added a second component to the heuristic, permeability. We went through the tens of thousands of MCTS games again and made a second graph, this time detailing which pairs of lines had pieces go from the upper to the lower, and which didn’t. (Left: a well which would have a high permeability score. Right: a well which would have a low permeability score.) So, the graph theory heuristic was the sum of a pair of terms. At each line, the odds that the line would ever eventually be cleared was multiplied by the odds that a piece could get down far enough to get to that line to clear it, with the empty line being by definition the most clearable of all. The higher this heuristic, the better. Putting It Together What we didn’t explicitly say yet, is that these two approaches can be combined. In a very direct way, the knewjade heuristic assesses the quality of a particular well, looking at its shape, considering the piece, and generally calculating its “quality”. The graph theory heuristic, on the other hand, considers only specific lines two at a time, without any broader context of well shape. This joint approach, combining shape and line, gives a more nuanced assessment of the state of the well. What we suspected (though it’s not something we could formally prove) is that the two pieces should balance each other out. The knewjade heuristic looks at the aggregate shapes in a well – the holes and enclosed holes, the height of the surface – but does so in a general way, with no way of (for instance) determining that this hole is less bad than that one. The graph theory heuristic is quite precise, with thousands of parameters determined from millions of positions, but only considers lines in isolation, or lines in neighboring pairs, with no ability to look at the broader context of the well. Together, ideally, they balance out each other’s weaknesses, and can find better games than either could individually. (And as mentioned before, on a large enough scale, none of this matters; the additional effect of the graph theory heuristic term drops to zero as the beam search gets wider, and when doing a full 25 million width beam search, it does not matter if the graph theory term is there or not. But that’s not something we’d learn until many months later, and something that might be fixed by improving the data backing our graph theory approach.) Parameter Optimization So, with the two parts of the heuristic – knewjade’s, and ours – we were ready to go, and all we needed to know were the weights. By how much should a hole be penalized? By how much should a clearable line be rewarded? How important is score? This last question was especially difficult to answer with just intuition; on one hand, weighting score extremely highly means that the beam search will be very greedy and potentially miss better strategies that take more moves to set up, but not weighting scores highly leads to the algorithm putting off scoring indefinitely, always figuring “Eh, scoring would take away this nice clearable line I found!”. We needed some empirical method to figure out what all these weights should be. What we found was a Rust library called Simple(x) Global Optimization, a simpler version of the more well known Bayesian Optimization method. This method, like all optimization methods, takes a set of variables (in our case the weights for the heuristic) and a function of that set of variables (in our case, the number of moves a beam search with those weights ran for), and attempts to find the combination of variables that results in the highest value of the function. The upside was that we didn’t have to use any intuition about which weight was more important than which other weight, because Simple(x) could do it all for us. The downside was that this optimization required hundreds of beam searches before we could be reasonably sure we’d tried a broad enough variety. So, hundreds of beam searches is precisely what we did. With a beam width of 250,000, each search took somewhere between forty-five minutes to two hours, and we let this run for well over a week. Then, after the two failed 25 million width beam searches, and after we discovered the bug, we did the same thing again. By the end, our 250,000 width beam searches had returned a cluster of parameter combinations which lasted for 46 points and 148 moves…and one lone parameter combination which lasted for 46 points and 147 moves, surrounded by very similar combinations of parameters which did much worse. One of the failed 25 million beam searches had been stuck in a local maximum - the parameters had stumbled upon a game that was good, but that was very difficult to improve upon, like climbing to the top of K2 when you’re trying to climb to the top of Mount Everest. As such, we decided not to go for the cluster that lasted 148 moves, but go for the lone combination that lasted 147, on the hopes of not getting stuck in a local maximum once again. And we should make explicit here that ‘hopes’ is what we were running on. We simply didn’t and don’t have the hardware to do many ultra-wide beam searches, and the optimum parameters probably change when you enlarge the width by two orders of magnitude. We both doubt very much that this set of parameters is the best possible. All we know is that it scaled up better than any other set of parameters we’d ever used. Parameter Value Holes 11.2106 Enclosed Holes 83.7646 Enclosed Hole Lines 83.7646 Surface Height -83.7646 Erasability -83.7646 (per piece) Graph Heuristic -2.1413 Score -332.2211 (The graph heuristic weight is included for completeness’ sake; do not try that one at home.) The Final Run It’s worth talking about what exactly we were using to run these beam searches and machine learning models and various other wild ideas, since to us it felt like every paper we read involved spending tens of thousands of dollars at your local cloud provider. We did not have tens of thousands of dollars to spend. We had about $150 on Azure credits, a machine we’d built a while ago with a slightly modern GPU, an i7 CPU, 16gb of RAM and a motherboard so old it wouldn’t accept any more RAM, and a couple laptops we were using for other things, and occasionally running long simulations on. No more than maybe $2,000 in hardware, being generous and counting the laptops. Every few weeks as we’d work on the project, we’d read something about how AlphaZero was able to play 44 million games in nine hours and then run them all through neural network training powered by a fleet of thousands of TPUs, sigh wistfully, and look at our machine learning model, which needed another two weeks to finish training on a measly 10k games. Still, by the time we were running 25 million beam searches at the end it wasn’t awful; a beam search would take roughly four days, a vast improvement over the original 6 week runtime (the original beam searches took 3 weeks, but returned games half as long, so would have taken 6 with the better parameters). An agonizing four days, only to get scores like 53, which had once been impressive but were not exactly the world record. Finally, with our best heuristic ready, and all the graph theory mumble mumble was wired up, we decided we’d do it. We’d use a magical cloud machine and be done in a few hours. We settled on a c5d.18xlarge instance on AWS for $3.50 an hour. The main draw was the 1800 GB SSD and the 72 available cores. With multithreading and some rough back of the napkin math it was slated to take 7 hours. A mere $24.50 for being done. And to be clear, this was our last hurrah. We were considering other ideas, but we knew this was our best shot and that if this failed, we’d likely lack the morale to go back to the drawing board and try again. Things conspired to delay us. COVID. A stolen credit card. Random real life interrupts. Finally, the Friday of Memorial Day, we spun up the 72 core instance. We’d originally planned on running a few trials on a cheaper 16 core instance… but we opted to skip them. After all, we reasoned, if things would finish in 7 hours, we could reassess after that and see what needed to be changed. We installed Rust, copied files over, set up ssh keys… and then hit run. We’d be well within our budget, $24 being less than the $100 or so we’d budgeted for cloud computing. An astute reader will probably guess that we did not leave and come back 7 hours later to a world record. Partially because we sat there, glued to the screen, watching games play out, and partially because something had gone terribly wrong. You see, it turns out our back of the napkin math hadn’t accounted for one thing: file reads and writes. Adding more cores made the threaded processes faster, but now the bottleneck was how quickly we could get in and out of the hard drive. And it was not encouragingly fast. 7 hours later we had achieved a score of 10 points at depth 33. Some more quick back of the napkin math suggested we needed probably another 150 moves in order to tie the world record, so another 35ish hours. 42 times $3.50 was only 147 dollars. Still within our mental budget of “no more than $200 of cloud computing”. Over the next few hours we watched the score inch up, and the depth increase. Never getting as fast as we’d like. It was like watching water slowly, ever so slowly drip into a well, not knowing if it would ever tip over. 10. 25. 35. We still didn’t know if our heuristic could even generate a world record. Watching the score tick up and the cost do the same. Us being us, we had no patience. Instead of watching it tick agonizingly forward, at around the 48 hour mark, when we were starting to see scores of around 63, we decided we’d cheat - we’d take one well, printed out with the output logs, and run a small 10k beam search on a laptop in order to get a lower bound for how good a game was possible. Like opening presents on Christmas Eve rather than Christmas morning, this did spoil a bit of the dramatic tension - but it also confirmed that we would, at bare minimum, get a score of 71 points, and that we would for a fact get the world record. Somehow this made the remaining ten hours of waiting worse, not better. At the 56 hour mark it finished. We’d done it. We’d discovered a 86 point game was possible, and we were only $196 in the hole. Considering the key-frame generation still had to run to give us the moves that the game had played, we might not even exceed our $250 cloud computing budget. StickManStickMan #21, by Sam Hughes. Key-frame generation? Didn’t we already have a winning game? Well, yes and no. We’d had the moves needed to play the winning game, but we also had billions of other moves that did not lead to the winning game. ‘Key-frame generation’ is how we reverse-engineer a game from a beam search. At each timestep, the beam search saves the top N wells (in this case, 25 million), and stores them all to disk. At the end, we take a well from the last available timestep, go through all of the wells in the previous timestep, and calculate all of their children (though we’ve since figured out a better way). When a well from the previous timestep has, as one of its children, the well we’re looking for, we stop, save that well, and go back another timestep to repeat the process. The process of finding each well reminded us a bit of rendering an animation by generating keyframes, hence the name. An obvious question here: why didn’t we store the children of each well on disk, so that we wouldn’t have to recalculate the children again? The first answer is that the complete beam search already takes 225 GB of space, and storing the children would far exceed the available space on both the RAM and hard drive. The second answer is that, by the end, the emulator was fast enough that the extra time taken to read the data from disk would have been more than the time taken to recalculate the children. 56 hours in, we had a gorgeous score of 86, assuming there were no bugs in our emulator (an idea which at the time seemed dangerously possible), and all that was left was to wait for the fairly quick process of keyframe generation to finish. It was midnight, and we asked the fateful question “how long can it actually take? An hour?”. This didn’t seem unreasonable, since keyframe generation was usually by far the fastest part of the process. But, as before, we had not considered the issues of scale. The sheer amount of disk reads and the massive depth we’d reached meant that the 72 cores didn’t speed things up at all, since 90% of the time was spent on the single-core operation of reading the timestep files from disk. Some quick math showed that it was going to take us another 12 hours to finish the process. Another 42 dollars and more agonizing waiting. With nothing to be done about it, we went to bed, vowing to wake up in the morning and input the game. We cannot emphasize enough the sheer frustration at waking up the next day, and seeing it still merrily chugging along, slowly, ever so slowly; the back of the envelope math we’d done had been based on reading files from the end of the search, which were much smaller and faster to read than the files in the bulk of the game. 68 hours in, and the accursed keyframe generator was still only gradually moving forward. Neither of us got to enjoy that Sunday at all, watching it inch forward, bit by bit. Tantalizingly close. StickManStickMan #19, by Sam Hughes. Finally, late that afternoon, it finished. We hopped on a voice call, and put the game in to the online Javascript HATETRIS game, move by move, wondering at each moment if this is where we’d discover a key emulator bug or bad edge case to make all our efforts be for naught. But as the well piled tall on either side, and we fumbled flips here and there, one thing became clear. It was real. The world record was ours. 86 points. We breathed a sigh of relief. It was done. It was finished. Countless hours of engineering time. Endless runs on our machines, 100 dollars over what we’d originally planned to spend on AWS. (It turned out to be $140 over after data transfer costs and such), but it was done. Lessons Learned Up until now, this has been something of a narrative. There’s been a plot, there’s been progress, there’s been a clear (if non-monotonic) improvement from A to B to C. But there’s more stuff we learned, and dead ends we went down, that don’t really fit the story. We’ve captured them here for two reasons. One, we think these are valuable lessons that anyone who dives into this type of problem can benefit from. Two: we did a lot of work, much of which was only tangentially related to getting the world record, and while we’ll save most of that for a future blog post, we want to show some of it off now. These headings will only be loosely coupled, and while we think there’s a few related conclusions, we leave grand sweeping paradigms as an exercise for the reader. Flamegraphs & Attack of the Clones One lesson that came up over and over again throughout this project is that profiling is very important, because we as developers are bad at estimating which parts of code are bottlenecks and which aren’t. In one of the earliest iterations of the emulator, we had an error-handling exception which would format and print a string with state information in the event of a panic, to make debugging easier. We quickly fixed the underlying bug which would cause that string to print, but kept the print statement in anyway. What harm could it do? We had no idea what the relative time cost of any of our code was at that stage, and didn’t find out until later, when we started using flamegraphs (a visual aid showing the proportion of time spent on each function call in a program) to profile our code. We had certain functions we knew for a fact were bottlenecks, so some of the graph wasn’t a surprise. What was a surprise, however, was the mountain sticking up from the surrounding foothills, in the center of the graph: (Click or hover for more details) As it turned out, that string format statement was taking up 17% of the total runtime, all in the event of an error that literally never happened. And that was before all of our other optimizations; if we put this string format statement back into the current emulator, it would take up well over 95% of the runtime by itself. And without code profiling, we still would never have guessed this. Reasoning about runtime is extremely tricky. For all the coding interviews that emphasize calculating the runtime complexity of your program, there is a lot of magic that happens in coding, and the only way to really know what’s going on is to use appropriate tools to detect it. Sure, you should avoid nested for loops inside for loops, but profiling your program can give you even better results. And by the same token, profiling also revealed that we had no need to worry about some things that concerned us. We’d spent significant amounts of time discussing how we were going to fix our various issues with using .clone() to get around borrow issues, and do things properly… but when we looked at the flamegraphs it turns out our 70+ clones were not costing us any time, since they were being optimized away during compilation. What we had assumed was a major time-sink was nothing to worry about at all. Array vs. BTree That said, you can’t just ignore runtime complexity, either. Our original version of the beam search took N wells, calculated all of the children of all of the N wells (typically around 15*N), sorted the list, and then took the best N children in the list to use for the next step. This is all well and good for small values of N, but when scaling up, this quickly becomes untenable; storing all of the children at the same time (as opposed to just storing the top N children) wastes a tremendous amount of memory, making the beam search take up on average fifteen times more RAM than it properly should. We knew we had to change something there. So, we took the obvious route. To summarize in pseudocode: 1 2 3 4 5 6 for well in current_wells: for child in children(well): if child is better than worst_child in new_wells: insert child into new_wells in appropriate_position remove worst_child from new_wells get new worst_child from new_wells And therein lay the problem, though we didn’t figure it out for another month and a half. Reading an arbitrary element from the vector is O(1), but insertion into the middle of a dynamically-sized vector is not an O(1) operation - it’s O(n), scaling with the number of elements in the vector. This caused a huge nonlinear increase in runtime with respect to the beam width; had we tried to do a full 25 million width beam search at this point (and we wouldn’t have tried), it would have taken literal years to finish even with Rust’s impressive compiler magic. We briefly considered using linked lists, despite well-known warnings about how tedious and difficult they could get in Rust, but linked lists presented a different problem. Insertion in between two elements is nice and fast at O(1), but reading through the linked list to find out where to insert is O(n). This was exactly the opposite of the situation with vectors, but it was no closer to being a solution. Upon seeing that we had two data structures, one which could read quickly but insert slowly, and the other which could read slowly but insert quickly, we thought “surely there’s some sort of compromise data structure that does both pretty well”. And sure enough, there was. Rust’s BTreeSet was a built-in data structure based on B-trees, which have logarithmic read times and logarithmic write times. Things were slow enough already that we were willing to accept almost any constant in front of those logarithms, so we switched, and went from insertion taking up more than 90% of the beam search runtime to less than 1% instantly. Data Type Insertion Time Element Read Time Vector O(n) O(1) Linked List O(1) O(n) B-Tree O(log(n)) O(log(n)) Changing the datastructure was the key to unlocking larger beam searches, but this would have been futile without the improvements we got from the flamegraphs, and in turn wouldn’t have worked if we’d spent all our time cleaning up clones. Writing highly efficient code is more of an artform than a science (and we await a flurry of angry tweet from our many reader over this statement). It requires a mix of the right tooling, understanding your code, and figuring out what tradeoffs make sense. Machine Learning (on the cheap) There’s another lesson we learned as we optimized our code as best we could…no amount of optimal code will eliminate the need for absurd amounts of hardware for machine learning. It doesn’t matter how good your emulator is, how blazingly fast you can play games… the sheer amount of training data and training time needed makes trying to solve problems of more than trivial complexity on consumer hardware very very challenging. We’re not machine learning engineers. We don’t have formal backgrounds in machine learning, or in anything remotely close. Mr. Hughes generously said that we “appear to be academic researchers”, but that appearance is purely surface level. It’s possible, as it always is, that we were just doing everything wrong, and someone with a PhD in applied machine learning will show up with a model far better than any beam search we’ve designed. We wish for nothing more. We want user friendly machine learning for amateurs like ourselves. In fact, when we set out on this project, one of the things we wanted to prove was that AlphaZero could be used for a practical purpose without a massive computing cluster. As far as we can tell, it cannot. The cloud costs, in TPUs and GPUs and RAM, to really get this project off the ground would have been considerable. Our models, tiny and poor as they were, still took two plus weeks to train on a very low number of games, and one of the things we’ve realized is that machine learning depends on having vast reams of data. It’s not sufficient to have 100,000 good games; you need tens of millions. And you need to be able to take games generated by your models and train on them. With super slow hardware, its impossible to tweak hyperparameters to figure out the best learning approach. (Which is, as far as we can tell, how the big, successful projects figure out their hyperparameters, careful guessing, and a lot of tweaking.) Its frustrating to learn that the incredible tools that are supposed to revolutionize problem solving are out of the reach of anyone not able to throw significant cash at it. There’s a whole possible blog post on this topic. We’re hardly the first to realize it, but we felt it extremely keenly. Behaviors at Different Well Heights Since we had an emulator handy, while we were waiting to get sufficiently good heuristic parameters for the full case, we thought to explore some smaller wells, and see if there was any obvious trend in maximum score and maximum game length we could extrapolate. The primary motivation behind this was simple: before embarking on programs which would take weeks or even months to run, we wanted to prove to ourselves that knewjade’s record of 66 was beatable, and that it wasn’t simply the maximum possible score attainable in HATETRIS. So, we did a series of breadth-first search runs, up until it exceeded the RAM available on a laptop, and wrote down the results. 10 Blocks Across Height Score Length BFS Width 0 0 0 0 1 0 0 0 2 0 4 21 3 0 6 310 4 1 11 9095 5 4 19 174634 6 8 31 4848325 7 12 43 141514270 8 ≥17 ≥57 ≥1.00e8 … … … … 16 ≥86 ≥247 ≥2.50e7 This set of runs had some interesting results. Among other things, we had assumed (and we were not the only ones) that since there were 10*16 squares in the grid, each one of which could be either filled or not filled, that there were roughly 2^(10*16) ≈ 10^48 possible HATETRIS wells. However, here, the results indicated that the number of possible wells was vastly less; the maximum width of the BFS search increased by a factor of ~30 with each additional line of height, so the maximum number of concurrent states would be somewhere around 10^20: For a game lasting (say) a thousand moves, this would be at most 10^23 possible wells. This was twenty-five orders of magnitude less than we expected, though sadly it was still nine orders of magnitude or so beyond what we could do with commercial brute-force and commercial hardware. For completeness’ sake, we also examined narrower wells, to get as much of a feel for the behavior of HATETRIS with respect to well dimensions as possible. Width 4 is a special case, since an infinite loop there is actually possible in our emulator (and not possible in the newest version of HATETRIS); there’d be no point going any further. Doing BFS for wider wells might be interesting too, but our emulator currently can’t go beyond 10 blocks across, so we left that as a problem for a future date. EDIT (May 22nd, 2024): The original values here were incorrect; this version of the emulator had a bug that only occurred when the well height was reduced; in certain circumstances, a piece which filled a line while sticking out the top of said line would be counted as a clear, rather than ending the game. That has been fixed, and these should hopefully be the correct values. 8 Blocks Across Height Score Length BFS Width 0 0 0 0 1 0 0 0 2 0 3 10 3 1 6 75 4 1 8 1172 5 5 17 12447 6 6 21 159942 7 9 28 2250610 8 11 34 31440780 6 Blocks Across Height Score Length BFS Width 0 0 0 0 1 0 0 0 2 0 2 4 3 0 3 21 4 1 6 142 5 2 8 682 6 5 13 3998 7 6 15 23337 8 8 19 149389 9 9 23 1017165 10 12 28 6995425 11 13 32 50825005 4 Blocks Across Height Score Length BFS Width 0 0 0 0 1 0 0 0 2 0 1 2 3 0 2 5 4 ∞ ∞ 16 5 Blocks Across Height Score Length BFS Width 0 0 0 0 1 0 0 0 2 0 1 3 3 0 2 8 4 1 4 41 5 3 7 134 6 4 10 543 7 5 12 2150 8 6 14 8670 9 7 16 35017 10 8 19 148656 11 10 22 645397 12 11 24 2935961 13 12 26 13436407 14 13 29 61699120 15 15 32 285071640 6 Blocks Across Height Score Length BFS Width 0 0 0 0 1 0 0 0 2 0 2 4 3 0 3 21 4 1 6 139 5 2 8 679 6 4 12 3973 7 6 15 23126 8 7 19 143175 9 8 22 979997 10 11 27 6771901 11 12 30 48488721 12 15 36 362642476 7 Blocks Across Finding The Bug Along the way, trying to come up with optimizations for this state-based emulator, we encountered an interesting bug. ‘Interesting’ because the original implementation of HATETRIS briefly had exactly the same bug, and had it for exactly the same reason: Start a new game and hit “rotate” four times. Note what happens to the piece. Unlike many Tetris games, the rotation process is actually mathematical; each new piece rotates around a “point of origin” which is at the junction point of four squares. The rotation is performed by fiddling with the actual coordinates of each of the four “bits” which make up the piece. Each piece actually has a point of rotation in addition to everything else. The algorithm which tests all the possible positions, actions and final resting places of each possible new piece can do anything you can do: left, right, drop, rotate. The algorithm stores a list of all of these locations and applies all possible transforms to each location in turn in order to generate a complete list. Obviously, each new location thus generated has to be compared with the whole list to make sure it is new. One of my early attempts to make the algorithm faster made it so that it only checked the locations of the four bits, not the central point of rotation. However, in the case of an S or Z piece, the point of rotation is significant. Hitting “rotate” will result in a different piece depending on which way up the piece is. In Tom’s 12-point run, the algorithm moved an S piece to the same location as he did, and hit “rotate”, but because the piece was the other way up, resistance was encountered and nothing happened. With the piece the other way up, which is what Tom did, the rotation is successful and a line is made. In other words, an S or Z piece occupying the same space can in fact be different pieces with different available positions. This means that the optimization of only considering the space a piece is taking up, rather than storing properties like ‘rotation’ and ‘position’ separately, will end up failing in some edge cases. This wouldn’t have been a huge speedup, and it’s not that important, but it was a signal to us that we were slowly but surely following the same path. Echoes of AlphaZero The core premise of the AlphaZero neural architecture is that it is dual-head: the neural network has a policy head, and a value head, and the formula for determining which moves to investigate uses both. The value head is the simpler of the two: it takes in a position and outputs a single number ranging from -1 (meaning a predicted 100% chance of defeat) and +1 (meaning a predicted 100% chance of victory). The value head is what allows the algorithm to decide how good a position is, without having to play the entire game through to the end. StickManStickMan #691, by Sam Hughes. The policy head can be thought of (in very broad strokes, don’t take this too literally) as the ‘gut feeling’. If you’re a chess grandmaster, you don’t play as well as you do by looking at every possible move and counter-move that could be made - the branching factor of chess is simply too high. Instead, your gut feeling tells you to look at moves X, Y, and Z, so you do, and you don’t consider (or only briefly consider) the dozens of other possible moves available. The policy head works something like that, biasing the algorithm so that it does not consider all moves and all branches equally. What we did, combining the overall ‘board sense’ from the knewjade heuristic and the line-by-line precision from the graph theory heuristic is very, very far removed from the original AlphaZero algorithm. Nevertheless, we couldn’t help but be reminded of the balance that the policy head and the value head were supposed to bring to each other when combined. (This section was written long before we discovered that the graph theory heuristic made no difference; our intuition is no more perfect than the policy head’s.) Reversing the Polarity Keyframe generation took quite a while on the world record run, due to the sheer amount of time needed to read hundreds of gigabytes from disk into memory. There’s a better way to do it that didn’t occur to us until afterwards: make the emulator run backwards. That way, rather than calculating every child of every well that’s saved, simply calculate all of the possible parents of the well directly, and see which of those parents is in the previous generation’s well list. If we really needed to speed up the process even further, we would write to a disk database rather than writing each timestep as its own file, and then when calculating the keyframes we’d only have to search the disk database for the dozen or so possible parents of the current well, probably getting the complete game in a few seconds. Unfortunately, the initial idea of taking this idea to the extreme and calculating the entire ‘reverse game tree’ didn’t work; looking further than ten or so moves is currently very impractical, since most possible parents of a well are not reachable HATETRIS states (going back to the earlier discovery about how few reachable HATETRIS states there actually are). It’s possible to filter out some of the unreachable states (for instance, any well that has a partially filled line above a completely empty line is definitely unreachable), but we couldn’t figure out a way to filter out all of the unreachable parents, or even most of them, and so the effective branching factor is too high. If a full reverse emulator is possible, it would potentially allow for diskless beam searches, but right now it’s a bridge too far. The Next World Record We never bothered writing a script to take a list of wells and turn it directly into a valid Base2048 replay; it wouldn’t have been that difficult, but it was never important enough to actually get done. Instead, we printed out the list of wells, went through them one by one, and manually hit the arrow keys on the Javascript version of the game to move each piece where it needed to go. And along the way, we noticed a trend, one that we noticed also in knewjade’s 66 point run. The winning game piled pieces up pretty high, and did so pretty early; it first had a piece touch the top of the well less than halfway through the game (move 120, for a game that lasted 247 moves). Looking at it, it makes sense that piling up pieces benefits the score; the HATETRIS algorithm is based on the height of the well, so maximizing the well height minimizes the amount of information the HATETRIS algorithm has at its disposal, and puts an upper bound on how evil its piece selection can be. So by that logic, a perfect game should keep pieces piled all the way up to the top the whole time. Ours does not - our heuristic indirectly penalizes wells for being too high, because stacking pieces all the way up to the top takes time which could be used to score points and clear lines. And any well which goes too long without clearing any lines tends to get filtered out. The left-hand side of that graph is a land of opportunity, and a better heuristic than ours could probably get more than a hundred points by properly exploiting it. Going back to the analysis on smaller wells, the length of the best possible games seems to increase approximately quadratically. Fitting a quadratic function to the results from well heights 2 through 7 and extrapolating out (and taking the result with a grain of salt), we’d expect the best possible game to last about 290 moves, which, like the previous estimate, would correspond to a best possible score of 102-103 - at the very least, indicating again that the current record is not the best possible game. 86 points is not the end of this story. It is, however, the end of this blog post. Specific Thanks Arta Seify, for writing his thesis on modifying AlphaZero for single-player games, and for helping us quite a bit with implementation details when we emailed him. Dr. Antoine Amarilli for inspiring the small well size experiments. Kevin P. Galligan, for providing insight into what alternate routes there were besides beam searches and MCTS to making a HATETRIS solver, and how far those alternate routes can get. David’s dad, for suggesting B-Trees rather than linked lists or dynamic-sized arrays. えぬ・わん, for making a video analyzing the strategy used in our world record; more analysis than we did ourselves. Aypical, SDA Guest, Ivernis, Deasuke, and chromeyhex, for giving HATETRIS a proper leaderboard and for each setting the bar successively higher. Knewjade, for setting forth both a monumental challenge and the tools needed to eventually overcome it. Sam Hughes, for getting us to waste fourteen months and fourteen thousand words on Tetris. So far. P.S. Ok, so we lied about that last part being the end. If you read this far, (which is, lets face it, unlikely) you’ve heard a lot of griping, seen some things that look semi-magical, and possibly left with the impression that the authors had some sort of incredible knowledge base, or are researchers deeply entwined with the topic. We’re not. We’re not researchers at all. We’re just two people who became obsessed with a problem and put their meager knowledge to use, beating rocks against rocks in different configurations until something resembling a spearhead came out. Our experience with Rust was, up to this point, six blog posts done on introductory Advent of Code problems over the course of six months. We didn’t know much at the start, but we learned. First, we Googled and clicked on the first result. Then we scoured Stack Overflow and papers, and when that failed, we reached out to specialist Discord servers and emailed experts. When existing Rust crates didn’t do what we needed, we made our own Rust crates. We now know a lot of very obscure information about HATETRIS, but you could still fill volumes with things about HATETRIS that we don’t know. Many of the breakthroughs we had were due to ignorance. We pulled out the concept of waveforms because we were terrified that the next thing we’d have to do to push things forward was do complex matrix operations on a GPU. Inventing a new way of thinking about the problem seemed easier. You, too, can do something like this. Find a problem. Become obsessed with it. Learn everything you can about it. Fall down dead ends. Give up, and then keep thinking about the problem at night. Have Eureka moments that lead you down other dead ends. Find a friend willing to get as obsessed as you are. Underestimate the time commitment, and then refuse to back down. Embrace the sunk cost fallacy. As long as you keep thinking about the problem, even if its in short bursts every few years, you’re still making progress. And if you never finish? If all you find are side-paths and obstacles, and it turns out the entire mission was doomed from the outset? That’s okay too. Projects like this nourish us, because there’s a part of the human mind that wants nothing more than to climb the mountain, rappel into the cave, explore the unknown and grapple with it. So, regardless if you’re here because you care about the technical details, or because you saw HATETRIS and said “I heard of that, I think”, if you only take one lesson away from this whole thing, we hope it’s this. You too can do the thing you think is impossible or difficult. If you fail? Write about it anyway. The original title of this post was “How Not to Get the World Record in HATETRIS”. StickManStickMan #620, by Sam Hughes. Next post: Losing the World Record in HATETRIS Programming hatetris rust programming david felipe This post is licensed under CC BY 4.0 by the author. Share Recent Update Getting the World Record in HATETRIS Trackmania I - The History of Machine Learning in Trackmania Prologue in HATETRIS Trackmania II - Trackmania Nightmares Metamorphoses - The Metamorphosis Trending Tags david programming fiction felipe rust writing prompts poetry mathematica hatetris essay Contents Tetris That Hates You High Scores Choosing a Language The Story So Far MCTS MCTS + AlphaZero The Emulator Well, Well, Well Basic State Management GPU Matrix Operations Let Me Count The Waves The Era of Knewjade The Knewjade Heuristic Following Footsteps Mumble Mumble Graph Theory Putting It Together Parameter Optimization The Final Run Lessons Learned Flamegraphs & Attack of the Clones Array vs. BTree Machine Learning (on the cheap) Behaviors at Different Well Heights Finding The Bug Echoes of AlphaZero Reversing the Polarity The Next World Record Specific Thanks P.S. Further Reading Jun 30, 20232023-06-30T19:00:00-04:00 Losing the World Record in HATETRIS Having gotten the world record in the hardest version of Tetris, we promptly lost it again. This post tells the history of the HATETRIS world record as it rose from 86 points to 289, in three week... Jun 17, 20212021-06-17T13:00:00-04:00 Learning Rust with Advent of Code - Day 6 2015 Day 6: Turn regions of a 1000x1000 grid of lights off and on again, and count how many are on at the end. After optimizing our brute-force, we explore other potential improvements and speedup... Jan 12, 20212021-01-12T12:00:00-05:00 Learning Rust with Advent of Code - Day 1 2015 Day 1: The simplest problem of the year, done by complete beginners inexperienced with Rust's syntax, types, and error-handling. Features a 2000x speedup over an equivalent Mathematica progra... Prologue in HATETRIS Advent of Code 2022 Comments powered by giscus. © 2024 Dave and Felipe. Some rights reserved. Powered by Jekyll with Chirpy theme. Trending Tags david programming fiction felipe rust writing prompts poetry mathematica hatetris essay",
    "commentLink": "https://news.ycombinator.com/item?id=40851919",
    "commentBody": "Getting the World Record in Hatetris (2022) (hallofdreams.org)237 points by TheCog 19 hours agohidepastfavorite40 comments pinkmuffinere 2 hours ago> “As long as you keep thinking about the problem, even if its in short bursts every few years, you’re still making progress. And if you never finish? If all you find are side-paths and obstacles, and it turns out the entire mission was doomed from the outset? That’s okay too. Projects like this nourish us, because there’s a part of the human mind that wants nothing more than to climb the mountain, rappel into the cave, explore the unknown and grapple with it.” In addition to the impressive technical details, this is some really beautiful writing reply gnatman 22 minutes agoparent> For some months, we’d had a very interesting idea. The idea consisted of the words “graph theory”, which we’d occasionally gravely recite to each other and nod knowingly, with some vague gesticulations, and not much else. Yes! This part and the cloud budget gag were also awesome. He's a great writer! reply dang 19 hours agoprevRelated: Losing the World Record in Hatetris (2023) - https://news.ycombinator.com/item?id=36558013 - July 2023 (1 comment) Getting the World Record in Hatetris - https://news.ycombinator.com/item?id=32495842 - Aug 2022 (1 comment) Hatetris – Tetris which always gives you the worst piece - https://news.ycombinator.com/item?id=27063894 - May 2021 (245 comments) Hatetris - https://news.ycombinator.com/item?id=4846607 - Nov 2012 (2 comments) Hatetris: Tetris That Hates You - https://news.ycombinator.com/item?id=1253492 - April 2010 (19 comments) reply andrewflnr 13 hours agoparentThe \"Losing the World Record...\" article is especially worth reading. reply DistractionRect 2 hours agoprevSo after reading \"Getting the World Record\" I was brimming with ideas on how one could improve upon their work, only to be squashed upon reading \"Losing the World Record.\" All parties involved has done an excellent job breaking the game, and aside from the (really) hard questions of understanding game, there's not much left except further exploring the parameter space. I simmered on the latter overnight, and a few thoughts occurred to me: - a parameter for fullness (holes + filled blocks that are below the \"surface\"). It might be its own parameter, or used to augment other parameters to discourage behavior that might lead to a the end game. - reachable surface height: rather than taking the lowest height of the surface, compute the reachable height of the following piece - an alternate definition of reachable surface height: the lowest point any of the seven pieces can reach (perhaps augmented by the number of pieces that can reach it) reply uzerfcwn 2 hours agoprevI find it interesting how the author's first approach was to use a black box neural network instead of the evidently simpler beam search. As far as I'm aware, beam search was widely considered to be the simple method for game optimization just a decade ago. Sure, new methods will always replace old methods, just like CNNs replaced SIFT for image processing. However, I feel that beam search is one of those elementary methods that you'd always want to check first, similar to A* and quicksort. Even though there are fancy neural networks for game optimization, pathfinding and sorting, it's easier to get started with elementary methods because they're simple and tractable. reply tschumacher 8 hours agoprevI also burned myself on an overambitious machine learning project in the past. I had and still have little practical experience but I think I learned a common beginner lesson. Existing ML architectures apply worse to new problems than we think. The only sane way to ML is to reproduce something that works and then make small incremental changes. reply somenameforme 4 minutes agoparentI think it's because most people's mental models for machine learning isn't great. They're not like brains or neurons, they're like a really convoluted quadratic regression calculator over an arbitrary number of variables. So if you stick to domains that this is appropriate for, you can actually spin together some pretty neat stuff. I think once one understands the XOR Problem [1], it all starts to mentally come together pretty quickly. [1] - https://www.educative.io/answers/xor-problem-in-neural-netwo... reply TheCog 5 hours agoparentprevI think one of the general takeaways about ML is that barring a few experts, its really challenging to reason about your system. Like, yes, you might expect that a convolutional layer will behave in a specific way under ideal conditions, but the way that behavior manifests is often wildly hard to predict during the early days. I agree that step 1 for most beginner projects should be to start with something that works and then tweak. reply krkartikay 6 hours agoprevI tried writing an AlphaZero clone to play Chess on my home PC (I only had an RTX 3070) and I failed for essentially the same reason as they mentioned: iteration time was too slow and you couldn’t tell if the model was getting any better at all after weeks of training. I thought I’d work on it further and maybe write some blog or put some dev vlogs on YouTube but never got around to doing it. Might do it some day. Till then I’ll just post some links to my Github if anyone wants to check out what I was doing: 1. https://github.com/krkartikay/AlphaZero-proto 2. https://github.com/krkartikay/AlphaZeroFinal 3. https://github.com/krkartikay/mcts-chess reply TheCog 5 hours agoparentPassing this on from Dave, since he doesn't have a HN account: He recommends trying NNUE on a CPU: https://www.chessprogramming.org/NNUE Mostly because he hasn't seen anyone try it on the personal computer scale and would be interested to see how it pans out reply vzaliva 17 hours agoprevDo not miss P.S. section at the end. It is very inspiring! Quote: \"We’re not researchers at all. We’re just two people who became obsessed with a problem and put their meager knowledge to use, beating rocks against rocks in different configurations until something resembling a spearhead came out. ... You, too, can do something like this. Find a problem. Become obsessed with it. Learn everything you can about it. Fall down dead ends. Give up, and then keep thinking about the problem at night. Have Eureka moments that lead you down other dead ends. ... \" reply beng-nl 12 hours agoparentSounds to me like they are superb researchers. (Eureka moments leading you down more deadends is so wel put too.) reply tmountain 9 hours agorootparentYup, this IS research from my perspective. reply VariableStar 8 hours agoparentprevAs a former researcher I can attest this is how research is done :-) reply jimmySixDOF 18 hours agoprevTetris, er, um I mean the use of interlacing cube blocks in random ways not intruding on existing IP, is such a deep well of variations on a theme from the hard core speed cults to a jelly gummy wiggle version to my fave that adds a z-axis [1] -- it just keeps on entertaining. [1] https://github.com/diarmidmackenzie/blocks-arcade reply jsheard 18 hours agoparent> Tetris, er, um I mean TTC has such an iron grip on Tetris that even clones which don't use the name or anything similar to it are still at risk of being shut down, it's ridiculous. It's possibly the only example of game mechanics being de-facto copyrighted, in spite of game mechanics ostensibly not being copyrightable, due to some legal sleight of hand where they successfully argued that the look of Tetris is their exclusive trade dress. That look is inextricably tied to the mechanics, there's no way to make a Tetris clone which doesn't look like Tetris. reply josephcsible 15 hours agorootparent> That look is inextricably tied to the mechanics, there's no way to make a Tetris clone which doesn't look like Tetris. If we lived in a just world, that would make the look uncopyrightable, rather than making the mechanics copyrightable. reply fbdab103 17 hours agorootparentprevHow long does the license persist? Wikipedia says the first version came out in 1985. Or is it somehow a life of the author + century kind of deal? reply jsheard 17 hours agorootparentIANAL, but a quick Google suggests that trade dress protection can be extended indefinitely, the only requirement is that it is still being actively used. TTC exists solely to collect rent on Tetris so they're never going to let it slip away if they can help it. reply gpderetta 6 hours agorootparentprevLego tried the same strategy, but it didn't work for them. What's different for TTC? reply jerf 3 hours agorootparentLego protection was based on patents. They tried to play the \"make a slight variation and extend the patent\" game but were slapped down. Now anyone can make Lego-compatible blocks legally, though of course they can't identify it as Lego. (Although based on the various ones I've gotten as presents, Lego never had anything to fear. The knockoffs sucked before the patent expired and they didn't get any better afterwards. It's still a terrible idea to let knockoffs mix with your real sets, and that's 0% Lego \"purism\" and 100% pragmatics. Maybe there's a good specific knockoff somewhere, but the odds seem poor.) TTC protection is based around other IP constructs. Here's a good sample link from a source that seems to know what is up, which I link to for the legal analysis rather than the details of a 2009 court case: https://www.gamedeveloper.com/game-platforms/exclusive-i-tet... reply nick__m 14 hours agoprevOff topic but I did not know that Hatetris and \"there is no antimemetics divisions¹\" have the same creator : qntm ! 1- https://qntm.org/scp reply andrewflnr 13 hours agoparenthttps://qntm.org/ra is also great, especially if you've read Sam's work and want more. It will appeal to technical types: magic is real and has a rigorous mathematical theory behind it, which is cool as far as it goes, but he takes it in an interesting direction from there. reply NooneAtAll3 9 hours agorootparentRa shows the main flaw of that author in my eyes - he is incapable of making optimistic endings I despise stories that are awesome enough to make me invested, but then make main characters (essentially) lose reply andrewflnr 5 hours agorootparentFine Structure's ending is very optimistic, in fact. (edit: a lot of his short stories are, too.) But yeah, Ra is rather bleak. I guess it's not for everyone, but if you came in from \"There Is No Antimemetics Division\" it won't bother you. reply NooneAtAll3 2 hours agorootparentexactly because I came from antimemetics it bothers me as his default reply BiteCode_dev 10 hours agoparentprevUnderrated book IMO. I enjoyed it more than the 3 body problem: the characters are better written, their motivations make more sense despite having much less time for actually developing them. I was really having fun trying to figure out how to make the best of an impossible to solve situation. And the SCP lore is wonderful. reply mjfisher 11 hours agoparentprevPerhaps not all that offtopic - Hatetris is what happens when you subvert normal the rules and make the game play against you. Anti-mimetics stories are what happens when you subvert the rules of ideas and make them play against you. I can imagine a common space of inspiration there. reply strangus 13 hours agoparentprevThat was a fun book reply RheingoldRiver 13 hours agoparentprevI really enjoyed Fine Structure too reply throwaway81523 5 hours agoprevVery good article. I hadn't seen it before. I wonder why it never mentions SAT solvers at all. I can believe that the approach is hopeless, but a few words on the topic would still have been nice. reply TheCog 2 hours agoparentFrom Dave: Short answer: SAT solvers are hard. Long answer: I actually discussed it with Tim once, long after part 2 of our blog post and after the whole thing settled down. Tim was making an SAT solver based on a post about a homemade Sudoku program that got out of hand (https://t-dillon.github.io/tdoku/), and HATETRIS has a binary grid representation, so it's a logical thing to attempt. So, how would you answer the question of the longest possible game with SAT? The idea would be that you can start with a set of wells S_0, generate a new set S_1, and continue generating sets of all possible wells until you find some N for which S_N is not satisfiable; N-1 is therefore the longest game. Suppose S_0 consists of the starting well, W_0. W_0 is a conjunction of 160 different clauses, each of which is initially set to 'not': W_0 = !x_0_0 && !x_0_1 && ... && !x_15_9 Once you have that, you need some way of getting from W_0 to its possible descendants. There are 2457 possible piece positions in a standard 16x10 HATETRIS well, each of which interacts with at most four squares (fewer for the piece positions within the top four lines), and each of which can be reached at most four ways (from another piece moving down, moving right, moving left, or rotating). This puts a rough estimate of ~39,000 clauses needed for a function which converts W_0 into its children: W_0 -> W_1a || W_1b || W_1c || ... = S_1. Which isn't too bad, as far as SAT solvers go. The problem is that this is very similar to what our first version of the emulator did and that version was a hundred times slower than our current version. SAT is NP-complete in the worst case, and without some huge simplification from putting it in Boolean form, it didn't seem likely to be worth the additional cost. I think there's still a possibility for some kind of solver to aid searches, e.g. \"Given this specific well, you need to clear lines 5 and 6 in order to clear line 4, and you need to clear lines 7, 8, and 9 in order to clear line 6...\", and I think certain properties (such as the minimum number of pieces needed to clear a given line) are computable with SAT, maybe even to the point of making a a pruned-but-provably-optimal game tree search feasible. Putting the raw emulator in SAT form is natural. Putting constraints like these in SAT form requires coming up with a new level of abstraction ourselves. Our only attempt at it was in the Mumble Mumble Graph Theory section; what we learned is that making a new level of abstraction is a lot harder, and we don't know how to do it. reply noman-land 15 hours agoprevMy favorite/least favorite tetris variant is Not Tetris 2, the one that doesn't snap to a grid. It's maddening. All this guy's games are mad at you. https://stabyourself.net/nottetris2/ reply manuelmoreale 10 hours agoparentReminds me this lovely game right here: https://www.trickytowers.com/ reply _glass 10 hours agoprevIt is mentioned that there is the Tetris Effect, which means you do an activity so much that they enter your dreams, thoughts ... etc. This happens to me as a developer, too. Especially for mind-bending stuff, like miniKanren, or first time learning Scheme, learning Emacs. I love that it has a name. reply merlincorey 17 hours agoprevI used to play \"bastet\" which had the same over all idea with a slightly different algorithm since 2005: https://fph.altervista.org/prog/bastet.html reply me_me_me 6 hours agoprevHeed my advice, do not play it. Its horrible, this is what hell will look like. Forever trapped waiting for a piece that will never come - by design. reply old_bayes 17 hours agoprevoh god I've never hated a game so quickly reply lobf 14 hours agoprev [–] Saving reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "HATETRIS, a challenging Tetris variant created by Sam Hughes, uses a deterministic algorithm to always give the player the worst possible piece.",
      "The high score in HATETRIS was pushed to 86 points using Rust optimizations, heuristic beam search, and parameter tuning on AWS.",
      "Key lessons include the importance of profiling, effective data structures, substantial hardware for machine learning, and combining heuristics for better results."
    ],
    "commentSummary": [
      "The discussion centers on achieving a world record in Hatetris, a Tetris variant that always gives the worst possible piece, highlighting the technical challenges and perseverance involved.",
      "Participants share personal experiences, related projects, and reflections on machine learning, neural networks, and simpler methods like beam search in tackling such complex problems.",
      "The conversation also touches on the enduring appeal of Tetris variations, legal challenges of creating clones, and the impact of the Tetris Effect on developers."
    ],
    "points": 237,
    "commentCount": 40,
    "retryCount": 0,
    "time": 1719876365
  },
  {
    "id": 40853845,
    "title": "Mako – fast, production-grade web bundler based on Rust",
    "originLink": "https://makojs.dev/blog/mako-open-sourced",
    "originBody": "Mako is Now Open Source 2024-06-28 by sorrycc 中文版: 《Mako 开源了》。 Hi, I am sorrycc, one of the main maintainers of Mako, and also the creator of Umi, Dva, Father, and other libraries. I am thrilled to announce that Mako is finally open source, the Github url is https://github.com/umijs/mako/ , and I’m excited to formally introduce it to you today. What is Mako? Mako is an “extremely fast” and “production-grade” front-end build tool, based on Rust. The “extremely fast” aspect was our initial motivation for starting the Mako project. Without build speed issues, Mako would not have been necessary. Refer to the Benchmark section below for some data, and we are constantly exploring even faster build speed solutions. The “production-grade” label comes from the fact that since 2023.11.24, Mako has been officially released internally at Ant Group. It has been validated with engineering practices on thousands of projects and all used npm packages and their versions. It has been implemented in hundreds of projects, serving various platforms and business scenarios internally, including management backends, mini-programs, H5 mobile, low-code, marketing, component libraries, component packaging, Serverless Functions, etc., demonstrating fully production-grade capabilities. You can visit https://makojs.dev/docs/features to learn more about Mako’s features. How did Mako come about? Last year (2023.3), our team launched 3 projects, Rust, SSR, and AIG, and we took on the Rust direction to tackle build performance issues. Our team has been exploring faster build speed solutions, including MFSU, which optimizes build speed within Webpack. However, this had certain limitations. We sought a thorough solution through Rust. You might wonder why we didn’t use existing Rust tools but decided to create one ourselves. The reasons are complex. For instance, 1) the maturity level of community libraries and their compatibility with Ant’s needs, we researched all the community Rust build solutions before starting, ultimately deciding on creating our own, 2) having control, due to business reasons, build tools at Ant require a lot of customization, and this proved true as we found many matching needs after internal release, 3) the modern meta-frameworks require compilation-time frameworks, in addition to build, they also have a lot of compilation needs, especially in SSR & RSC scenarios, for example, RSC scenarios required 4 builds internally, 4) the need to learn Rust and for team growth, modern frontend tools are all written in Rust, and we would fall behind if we did not advance. The timeline above is for Mako. Mako kicked off in 2023.3, had its first usable version by 2023.7, was internally released at Ant in 2023.11, and was open-sourced by 2024.6. We initially had 3 members with zero Rust experience, with team members, especially the virtual team, coming and going, learning Rust while digesting build knowledge and working on Mako was challenging, but fortunately, we succeeded and learned a lot in the process. We would like to thank the pioneers in the build domain like Webpack, Farm, and Rspack, as well as ChatGPT. Speed Mako has put a lot of effort into speed. Below is some Benchmark data. The Benchmark ran on a project that Turbopack also tests, on a Mac Book Pro M2 Max. It includes dimensions such as dev cold start time, root node and leaf node HMR time, production Build build time, and JS bundle size. (Note: Farm was not tried successfully using API mode, so no HMR data was generated; RsBuild had some issues upgrading to 0.7, so it’s still on 0.6 for now. RsBuild 0.7 might be a bit faster.) If you’re interested, feel free to clone the repository and try it out yourself. $ git clone git@github.com:umijs/benchmark.git $ cd benchmark $ pnpm i $ pnpm run setup $ pnpm benchmark Here’s how we compare to our previous selves. For Ant Design Pro full project build, Webpack takes 16s, Mako takes 3.9s, a 4x speed improvement. For Ant Design Pro full project build, Mako is almost always real-time hot updates. Intranet Hybrid framework Smallfish project build, based on RSC (React Server Components), scaffold project, build time reduced from 36.7s to 1.2s. It looks a bit exaggerated, but these are real data. These are more examples of speed improvements on such RSC projects. Additionally, Mako also has an experimental SSU feature, similar to the previous MFSU implementation, which does packaging and caching of dependencies. Depending on the ratio of source code to dependencies, it can achieve a 10-50x speed boost in Dev hot start-up. Currently, it can be enabled with the SSU=true environment variable. How to participate? If you want to experience Mako, you can create a Mako + React project with a single command using the scaffolding tool. $ npm create mako If you’re a Umi user, it’s very simple to experience Mako! # Make sure your version is 4.2.0 or above $ npx umi -v 4.2.0 # Enable Mako configuration $ npx umi config set mako {} # Run build or other commands $ npx umi build If you want to discuss issues or suggestions about Mako, you can scan the QR code to join our WeChat group. (If it’s expired or the group is full, please go to https://makojs.dev/docs/feedback for a new QR code.) Or click the following link to join our Telegram group. https://t.me/+EN3fycCw3TI1NDA1 Also, you’re welcome to subscribe to Mako updates via RSS. We’ll post the latest news about Mako and high-quality technical articles related to building. https://makojs.dev/rss.xml If you want to get involved in Mako’s open source, you can visit https://github.com/umijs/mako and CONTRIBUTING document to learn more. Anyone who has submitted Bugfix or Feature PRs can choose to join Mako’s developer DingTalk group. If you plan to deeply promote and apply Mako in your company, or develop based on Mako, you can contact us (mailto:sorrycc@gmail.com) for discussion. We can provide the relevant training, consulting, and more timely support services. Live Q&A Tonight (June 28, 2024) at 9 PM, we’ll be hosting a live Q&A on Bilibili, reservation link available at https://t.bilibili.com/947260122376175622. We welcome everyone to participate, and you can ask anything about Mako. If you have questions about Mako, you can fill in the questionnaire in advance at https://docs.qq.com/form/page/DY2Z6VndTRXBpR1Nh. Acknowledgements The release of Mako would not have been possible without each contributor, especially since most of them have participated in their spare time. Thank you! Those who have submitted code to Mako: hedeng, jiesia, Maple0817, vagusX, chessl, HiLanXiao, JackGuiYang12, zhangpanweb, ctts, goo-yyh, whyer11 Those who are still actively participating in the development of Mako: PeachScript, stormslowly, xusd320, LovePlayCode, Jinbao1001, sorrycc Community members who used Mako in the early stages and provided suggestions: xiaohuoni, xierenyuan The initiator of the project: afc163 Logo designer: golevkadesign The stylish landing page’s PD, designers, and developers: bupthly, 亿元, Wu-kung And many authors of the community’s dependencies libraries! webpack, which inspired lots of ideas of Mako. swc by @kdy1, which powered the parsing, transforming and code generation of Mako. farm by @brightwu, which inspired the tree shaking, plugin system and others of Mako. rspack, which inspired the tree shaking of Mako. oxc-resolver by @Boshen which powered the resolver of Mako. Oxc by @Boshen from which We learned a lot about how to develop efficiently with Rust. biome by @ematipico from which We learned a lot about how to develop efficiently with Rust. Edit this page on GitHub Copyright © 2024-present",
    "commentLink": "https://news.ycombinator.com/item?id=40853845",
    "commentBody": "Mako – fast, production-grade web bundler based on Rust (makojs.dev)208 points by afc163 13 hours agohidepastfavorite151 comments mgaunard 26 minutes agoI'm not a web developer, though I still develop web apps regularly. What exactly is the point of a bundler in the rapid development cycle? If you want your web app to load up fast, it's better if you only need to redownload the parts that actually changed, so you're better off not bundling them. reply aaaaaaabbbbbb 16 minutes agoparentIf you have a lot of files, the initial (dev server) page load times increases linearly with the number of files you have. With a slow bundler, that tradeoff made sense, but with a fast bundler, it is suboptimal. Also, typically the application is split into multiple smaller bundles, so only a slice of the application is rebundled on change. reply mikojan 20 minutes agoparentprevYou need to use some kind of automation to fingerprint your files for optimal caching. Where applicable there simply does not exist a better caching strategy than fingerprint plus Cache-Control: immutable reply rk06 5 hours agoprev> NOTICE: Plugin system is still under development, and the API may change in the future. Killer feature of vite is to leverage existing plugins system of roll up. Do you have plans to build a compat layer for existing ecosystem? Other build tools are doing it. Eg: rspack can use webpack plugins, farm can use vite plugin reply pshu 3 hours agoparentthe issue shows that Mako plans to support the unplugin system, it's a compat solution for existing ecosystem. https://github.com/umijs/mako/issues/1238 reply spankalee 12 hours agoprevThis supports all kinds of non-platform-standard features that may tie your project to this specific bundler, but will tie them to bundlers in general. It would be much better to have projects that work without bundlers, that can use them as an optimization step. reply ollybee 10 hours agoparentBundlers also tie clients to developers without them realizing. I work for a webhost and Many people still assume that if they have access to their hosting then they have their \"source code\". We see often that people migrate a sites after breaking ties with a developer only to find what they have may function, but is unmaintainable. reply 7bit 8 hours agorootparentSounds like a contractual thing, not like a bundler thing. The client should always include a clause into the contract that the client must hand all work over after closing the partnership. reply satvikpendem 3 hours agorootparentYep, just ask for their source code, don't presume that the hosted work is sufficient. reply evilduck 3 hours agorootparentprevYou'd struggle to extract a maintainable codebase from a C# or Golang web server after the fact too. As an industry we've been making simple websites on shared hosting for over a generation, clients who ignore the entire world of information about the dangers and pitfalls on this topic are squarely to blame as negligent. It ranks up there with not paying taxes and then acting shocked when the government comes knocking. While Javascript could potentially be contractually mandated to be written in a way to facilitate production codebase recovery, if you knew enough to ask for that you wouldn't, you'd require them to use your source control and to provide build/deployment scripts instead. reply iamleppert 4 hours agorootparentprevSource code costs extra, everyone knows that! Get the bag! reply hypeatei 5 hours agorootparentprevThe same could be said for compilers, too. Deployed binaries and code have never been the \"source\" of your app. reply interstice 12 hours agoparentprevAs soon as the browser specs catch up to what the bundlers are doing I’d drop them in a heartbeat. Not holding my breath though reply cornedor 12 hours agorootparentYou can get pretty far by using importmaps, you would not have treeshaking or a single bundled file, but it works pretty well. JSDoc can be used to add types to your project (that can be typechecked using typescript). I'm currently building a hobby project using preact, htm and jspm for packages. It's pretty nice to just start building without starting a build tool, having to wait for it to finish, make sure it's not crashed etc. But indeed, I won't use this for production. The only thing I'm still missing is an offline JSPM/esm.sh. reply spankalee 1 hour agorootparentYou do have tree shaking: the browser only loads the modules that are imported. Only import what you use (and don't use barrel files) and you're golden. reply rty32 7 hours agorootparentprevIt works well for a small website. For anything that requires more than a few dependencies, the package management is hell and load time will be insufferable. Also, not everything you grab from npm can just run in the browser even if written in ESM -- things get complicated quickly. reply meiraleal 8 hours agorootparentprevFor offline esm.sh you can use service workers cache, no? Also why not use this config in production? Http2 should give the same performance for multiple small files than a big bundle and it's much better to cache reply spankalee 1 hour agorootparentprevThe browser specs largely have. CSS has advanced enough that I haven't used Less or Sass in many years. Modules make loading easy. Import maps let you use bare module specifiers (or you could use a simple transform in a dev server). CSS modules let you import CSS into JavaScript. I never use a bundler during development. reply crabmusket 6 hours agoparentprevImagine if you could just scp your source code tree onto a CDN and it would automatically bundle it based on how clients import it. reply shepherdjerred 2 hours agorootparentThis sounds similar to https://esm.sh/ reply curtisblaine 1 hour agorootparentUnfortunately singleton peer dependencies (like react) are quite complicated with esm.sh. When esm.sh rewrites a module to import react from the cdn, it kinda \"decides\" which version of react is it at the moment the module is built on the CDN for the first time. That's why react is \"special\" and gets a stable build in esm.sh (essentially pointing to a fixed version no matter which version you specify): to avoid the dreaded \"two copies of react\" error. reply ericyd 4 hours agorootparentprevIsn't this the idea behind CI/CD wotkflows? reply BaculumMeumEst 4 hours agoprevAs someone who highly values minimalism and simplicity in software, seeing another web bundler paraded around as if it's something to celebrate does not spark joy. reply chuckadams 3 hours agoparentWe have bundlers because for a long time we didn't have a module standard due to browsers hanging on to their minimal and simple model of `script src=`. Even now modules are pretty minimal fare. Plus there's all the transpiling and asset transformation, but hey we should all be using document.write and not those \"bloated\" frameworks on top of JS, right? Maybe jQuery if we want to get really bougie? reply phplovesong 13 hours agoprevHow does it compare to esbuild or swc? Its good we have alternatives, and im still mentally scarred from the javascript ecosystem, where almost everything is slow and buggy. But when you compare to an already native tool (like esbuild) you start getting diminishing returns. reply yuzuquat 12 hours agoparentlooking at the docs, this uses swc under the hood reply throwAGIway 9 hours agoparentprevSWC doesn't bundle at all. Esbuild is a pretty good bundler but works well only if your code and dependencies use ESM, it's not as good as other options with CommonJS. reply oefrha 8 hours agorootparentThat’s not the biggest problem of esbuild. Esbuild has poor support for code splitting (it’s the first priority on their roadmap[1]) and limited plugin interface which makes it a poor choice for complex projects. These are the reasons that Vite for instance can’t use esbuild for production builds. While I haven’t tried Mako, it seems to have support for advanced code splitting[2]. No idea how powerful its plugin system is. [1] https://esbuild.github.io/faq/#upcoming-roadmap [2] https://makojs.dev/docs/features#code-splitting reply kurtextrem 4 hours agorootparentAlso, the vite team in collab with a few others is building https://rolldown.rs/, to replace esbuild and rollup in vite. It's goal is to be faster than esbuild, with extended chunking options and so on. reply megaman821 4 hours agoparentprev...or Turbopack or RSpack or Rolldown? Too many choices. I will be sitting this round out until a winner emerges. reply pshu 3 hours agorootparentaccording the current situation in bundlers written in JS，there is no \"really\" winner in my opinion。 webpack or rullup，which one is winner is a very personal thought。 So i think there maybe some similar situation in bundlers written in Rust. reply satvikpendem 3 hours agorootparentAre you Japanese? Those period symbols are interesting. reply pshu 2 hours agorootparent'。' is a Chinese full stop, equivalent to a period in English reply tinco 8 hours agoparentprevThis is built on swc, and they compare themselves to vite, which is built on esbuild. So the answer to your question is that they claim to be roughly twice as fast as esbuild (-based bundlers) in the benchmark in this article. reply kurtextrem 4 hours agorootparentI'm not entirely sure if we can really tell anything about esbuild from that comparison, as vite's production build time is 1300ms (which uses rollup), but dev startup time 1100 (uses esbuild to prebundle). It seems like vite itself has overhead. The only bench I'm aware of was presented in November 2023: https://x.com/boshen_c/status/1719596594985681275?t=x8FaB9Aw..., where esbuild was faster. reply berkes 11 hours agoprevI was confused by the \"Rust\" denotion in the title and presumed it was an alternative builder to compile rust for web (wasm?). It's \"yet another\" bundler for javascript. Built in rust. reply padjo 10 hours agoparentIf they didn’t tell us it was built in Rust how would we ever know how smart the developers are? reply michaelmior 8 hours agorootparentPersonally, I appreciate knowing when something is written in Rust. I know it is very likely I can easily install it and try it out immediately and that it is likely faster than any non-native tool I'm currently using. However, I do find \"based on Rust\" instead of \"written in Rust\" to be an odd choice of terms. reply necovek 5 hours agorootparentJust looking at their benchmarks, it's not particularly fast. es-build looks much better in benchmarks, but it's not written in Rust. It seems they wanted a tool in Rust just-because (experience on the team, preference foe the language...), and then only compared against those. As for the language \"based on Rust\", it's likely bad wording due to them not being native English speakers. reply jokethrowaway 6 hours agorootparentprevYeah, that's how I ended up using prisma... until I realised they didn't have joins All this aside, knowing something is in Rust tells me: - It's fast - It's maintainable (imagine the same project but in C) reply hu3 47 minutes agorootparentprisma not having SQL JOINS for a ling time is how I know I should just ship it when it comes to my projects. reply benrutter 9 hours agoprevI don't work in web, and possibly live under a rock. I'm a little confused around what bundlers actually do? I'd sort of assumed it was a typescript build thing before, but Mako's page gives me enough info to make me realise I'm wrong, but seems to assume people are working with some base knowledge I don't have. Any pointers to information of exactly what bundlers do? The emphasis on speed makes it sound like it's doing a whole bunch of stuff, what are the bottlenecks? Package version resolution? reply brabel 8 hours agoparentAre you familiar with Java? If so, a web bundler is like a build tool which creates a single fat jar from all your source code and dependencies, so all you have to \"deploy\" is a single file... except the fat jar is just a (usually minified) js file (and sometimes other resources like a css output file that is the \"bundled\" version of multiple input CSS files, and other formats that \"compile\" to CSS, like SCSS [1] which used to be common because CSS lacked lots of features, like variables for example, but today is not as much needed). Without a bundler, when you write your application in multiple JS files that use npm dependencies (99.9% of web developers), how do you get the HTML to include links to everything? It's a bit tricky to do by hand, so you get a bundler to take one or more \"entry points\" and then anything that it refers to gets \"bundled\" together in a single output file that gets minified and \"tree-shaken\" (dead code elimination, i.e if you don't use some functions of a lib you imported, those functions are removed from the output). Bundlers also process the JS code to replace stuff like CommonJS module imports/exports with ESM (the now standard module system that browsers support) and may even translate usages of newer features to code that uses old, less convenient APIs (so that your code runs in older browsers). And of course, if you're writing code in Typescript (or another language that compiles down to JS) your bundler may automatically \"compile\" that to JS as well. I've been learning a lot about this because I am writing a project that is built on top of esbuild[2], a web bundler written in Go (I believe Vite uses it, and Vite is included in the benchmarks in this post). It's extremely fast, so fast I don't know why bother writing something in Rust to go even faster, I get all my code compiled in a few milliseconds with esbuild! Hope that helps. [1] https://sass-lang.com/documentation/syntax/ [2] https://esbuild.github.io/ reply alex_suzuki 6 hours agorootparentI already knew what bundlers do, but I’ll just say thank you anyway for writing such an approachable explanation. I might refer to it in the future when someone asks ME what a bundler does :-) reply benrutter 5 hours agorootparentprevThanks! I really appreciate the detailed explanation- makes a whole lot of sense. reply bovermyer 7 hours agorootparentprevI'll admit to being a little outdated on front-end design evolution. Sass/SCSS is no longer needed? Does CSS support nested blocks now? reply __jonas 7 hours agorootparentYes it does! https://developer.mozilla.org/en-US/docs/Web/CSS/Nesting_sel... All major browser do now support it. However I still use the PostCSS Nesting plugin: https://www.npmjs.com/package/postcss-nesting This lets you write the syntax from the specification but it will be transformed to CSS that still works in older browsers, kind of like a polyfill in js. reply dartos 7 hours agorootparentprevVery recent addition, but yes! At long last reply iJohnDoe 8 hours agorootparentprevThank you. Extremely helpful. reply acemarke 41 minutes agoparentprevYes, here's a few excellent articles that explain what problems build tools solve and why they exist: - https://sunsetglow.net/posts/frontend-build-systems.html - https://www.innoq.com/en/articles/2021/12/what-does-a-bundle... - https://www.swyx.io/jobs-of-js-build-tools Loosely put, they're the equivalent of all of `gcc` or `rustc`: compile the source code, run type checking, output object files, transform into the final combined executable output format. reply throwAGIway 9 hours agoparentprevBundlers take many - usually at least hundreds, often tens of thousands - individual source files (modules) and combine them into one or few files. During that, they also perform minification, dead code elimination and tree shaking (removal of unused module exports). It's orthogonal to TypeScript - bundler will invoke a TS compiler during the process and also functions as a dev server, but that's just for nicer DX. Package version resolution is done by package manager, not bundler. reply benrutter 5 hours agorootparentWhen you say dead code elimination, do you mean if I import some huge library just to use a single function, the bindler will shimmy things about so only the single function is being included in package and not the big library? If so, that's amazingly helpful, I'm mostly over in python data land and I wish that existed for applications, although admittedly there's less need. reply throwAGIway 4 hours agorootparentYes, exactly. Pulling a huge npm dependency is usually not a problem if they didn't go out of their way to make it super hard to analyze at build time. This is tree shaking though, dead code elimination means it will find code that isn't used at all and remove it - for example you might have if (DEV) {...}, and DEV is static false at build time, the whole if is removed. So first it performs dead code elimination, then it removes unused imports, and then it calculates what is actually needed for your imports and removes everything else. reply ahzhou 4 hours agorootparentprevConditionally yes. There are many libraries that cannot be tree shaken for various reasons. Libraries typically need to stick to a subset of full JS to ensure that the code can be statically analyzed. reply throwAGIway 3 hours agorootparentBasically the only forbidden thing is dynamically calculating import paths, or dynamically generating the module.exports object. reply flohofwoe 8 hours agoparentprevBundling is the equivalent of static linking, typically combined with dead code elimination (which is called \"tree shaking\" in the web world) plus optionally other optimizations and code transformations. reply throwAGIway 7 hours agorootparentDead code elimination is related to but distinct from tree shaking - it also means that unused code branches get removed, for example constants like NODE_ENV get replaced with a static value, and if you have a static condition that always results to true, the else branch is removed. reply flohofwoe 6 hours agorootparentIn my book that's all covered by the term 'dead code elimination', e.g. removing (or not including in the first place) any code that can be statically proven to be unreachable at runtime. Some JS minifiers (like Google's Closure) can do the same thing in Javascript on the AST level (AFAIK Closure essentially breaks the input code down into an AST, then does static control flow analysis on the AST, removes any unreachable parts, and finally compiles the AST back into minified Javascript). Tree-shaking without this static control flow analysis doesn't make much sense IMHO since it wouldn't be able to remove things like a dynamic import inside an if that always resolves to true or false. reply throwAGIway 6 hours agorootparentYep, that's how it works - you first perform dead code elimination and then tree shaking exactly because it wouldn't remove everything otherwise. Agreed that you need both done one after another in most cases; however you can usually disable either one in bundler configuration and it's a separate step. reply pshu 3 hours agorootparentprevhttps://makojs.dev/blog/mako-tree-shaking explains how mako do the tree shaking stuff, but in Chinese. In my two cents, the tree shaking is more focus on removing unused exports in ES module at top level. it's a mixing with Dead code elimination and link time optimization. reply aaaaaaabbbbbb 7 hours agoparentprevIf you are also looking for broader context beyond what a bundler is, I have written a broader exposition on frontend builds here, which may be useful in understanding how bundlers compare to adjacent build tools: https://sunsetglow.net/posts/frontend-build-systems.html. reply benrutter 4 hours agorootparentThanks, that's actually exactly what I was after without realising it! reply darby_nine 9 hours agoparentprevI've always liked the analogy of a compiler/linker for web assets, personally. reply sandstrom 2 hours agoprevAnother interesting Rust-based Javascript bundler is Oxid / OXC. - https://github.com/oxc-project/oxc - https://oxc.rs It's also what Rolldown (https://rolldown.rs/about) is basing their in-development bundler on. reply jauntywundrkind 12 hours agoprevRspack (ByteDance) just shipped 1.0. There's Farm too. This is from Ant Group. Major influx of build tools all built in Rust, made in China. Turbopack is supposed to be coming, as a total rebuild of bundling. Rolldown seems solid, as a Rust roll-up redo. reply hardwaresofton 12 hours agoparentClearly Rust is catching on as a more approachable, safe and performant C/C++. I personally also think about it as a more-likely-to-make-it-to-production Haskell, with how robust the type system, tooling, and other things are (not to rag on Haskell -- it's a fantastic language and there's lots of overlap in the communities). reply spoiler 11 hours agoparentprevRsbuild has been really nice to use. I migrated a bunch of webpack projects to Rsbuild and it reduced config, and improved DX. One of my favourite features is probably that it understands a tsconfig file: https://rsbuild.dev/config/source/tsconfig-path reply aaronlinzx 12 hours agoparentprevthey need to create new tracks for promotions and KPI, recreating a wheel in rust will achieve just that. It's referred to as technology investment, but it's really speculation. reply pshu 3 hours agorootparentit's maybe a Nash Equilibrium to investing in Rust tools in big tech productivity races. reply alvincodes 7 hours agoparentprevI hadn't heard of any of these, apart from rolldown, thanks! Hopefully docusaurus gets on that train soon reply dluan 11 hours agoprevWhat happens when we reach the tip of bundling? Once you're in ms territory (like esbuild is), then what are the really creative things you can do if say every browser had a little WASM mako or some bundler in it? It's very cool though and seems like a lot of effort went into this. reply tinco 9 hours agoparentIt's in the ms for a small projects. These improvements are not to shave a couple ms off some small codebase, but would shave seconds off of really large projects. The codebase I'm working on right now isn't really large, about 5 years of development with on average 2-3 developers working on it and in vite (esbuild) the build time is 20.78 seconds on my M1 MBP. This project claims to be twice as fast as vite, so it would shave off 10 seconds, that's a significant gain. It would probably have a nice impact on our CI/CD pipeline, if the benchmark is representative of real world codebases. reply aaaaaaabbbbbb 6 hours agorootparentNote that while Vite transpiles with esbuild, it bundles with Rollup, which is single-threaded JS. Vite also uses esbuild to prebundle dependencies for the dev server, but this is separate from production builds. reply dluan 8 hours agorootparentprevI ripped out webpacker and replaced it with esbuild in a big legacy rails app for the front end, probably 2-3 years ago, and its been fantastic and I haven't looked back. It's more or less made front end bundling an afterthought. Going from 3s to 1.5s on my M2 (esbuild to mako) isn't a gamechanger, so for me it feels like it's already getting close to the peak, whatever that might mean. But I was more just asking what's the theoretical limit for this kind of optimization, and at the very least with rust. O(n)? reply tinco 7 hours agorootparentA that would be hard to say. A lower limit would be reading your entire project and the dependencies that are used once, and writing the bundled/minified code once. Possibly some parts of that could be done at the same time as you determine the bounds of the dependencies as you read in the code. So O(n) where n is in operations over lines of code in your project at least. There's probably trade-offs too. Like do you bother with tree shaking to make your end product smaller, or do you not to make your build performance closer to that optimal read-once write-once lower bound. reply mark38848 1 hour agoprevWhy not use a fast language like C, Odin, Hare or Zig? reply leonixyz 9 hours agoprevIs it kind of related to https://www.makotemplates.org/ ? Hence the name? reply giancarlostoro 17 minutes agoparentMako is in Python, so I would be surprised if it is in any way related. reply cmrdporcupine 5 hours agoprevCan I kick it off programmatically inside a Cargo build via build.rs? I tried to go down this road with SWC and ... failed. To be clear: I have JS/HTML artifacts in my repo alongside Rust source. I want to bundle them then ship them inside a produced Rust binary, or at least with it. With one build step using Cargo. reply brabel 1 hour agoparentI was looking if it provided a Rust crate as a lib, similar to how esbuild is just a Go lib (if you want to use it like that) but no luck. reply pshu 3 hours agoparentprevwhat about this https://crates.io/crates/rust-embed reply cmrdporcupine 1 hour agorootparentWell yes I'm using something familiar, to embed the HTML and JS directly. But want to embed a webpacked entity, and have it run through a typescript compiler. But would like something driven from build.rs reply aleksandrh 2 hours agoprevTime to reset the clock. 0 days since a new web bundler was released (in Rust!!). So tired of this ecosystem and its ceaseless tide of churn and rewrites and hypechasing. reply cjpearson 12 hours agoprevThe old joke is that there's a new JavaScript framework every month. That's not really true — we've had the same big three for a decade — but there has been an explosion of new bundlers: vite, esbuild, turbopack, farm, swc, rome/biome, rspack, rolldown, mako. And of course plenty of projects are still using rollup and webpack. Some competition is a good thing, and it seems to have led to a drive for performance in all these projects which I'm not complaining about, but I wonder if more could be gained by working together. Does every major company or framework need their own bundler? reply koito17 10 hours agoparent> The old joke is that there's a new JavaScript framework every month. That's not really true — we've had the same big three for a decade Yup. I know a few people who were using React 10 years ago and still use it today. What has changed frequently is the tooling. e.g. Bower going away in favor of NPM; Gulp/Grunt going away in favor of Webpack, which is slowly going away in favor of Vite; CoffeeScript going away in favor of TypeScript; AMD/CJS/UMD going away in favor of ES modules, and so on. ClojureScript has a great deal of stability in both the language itself and tooling, but nowadays I can't give up the developer experience of TypeScript and Vite. The churn in the tooling of the JS/TS ecosystem is wild, but since about 2021 I have found ESM + TypeScript + Vite to provide fast compile times, fearless refactoring, and a similar level of hot-reloading that I enjoyed in Clojure(Script). Can't say I miss Webpack, though! reply ReleaseCandidat 9 hours agorootparent> ClojureScript has a great deal of stability in both the language itself and tooling Does it still use Google's Closure (they've chosen it just for the name, right?) compiler? Is that still supported by Google? reply koito17 15 minutes agorootparentMajor parts of the compiler have been unchanged since its original public release. It still uses Google Closure Compiler (GCC), but the community understands that was the wrong choice of technology in retrospect. The compiler is still actively developed and used internally by Google. What is going away is the Google Closure Library (GCL), since modern JavaScript now has most of what GCL offered, and it's become easier to consume third party libraries that offer the rest of GCL's functionality. The reason ClojureScript has not moved away from GCC has to do with the fact it performs optimizations -- like inlining, peephole ops, object pruning, etc. -- that ensure ClojureScript's compiler output becomes relatively fast JavaScript code. The closest alternative to GCC's full-program optimization would be Uglify-JS, but it doesn't perform nearly as much optimizations as GCC does. For a concrete example, consider the following code. I am intentionally using raw JS values so that the JS output is minimal and can be pasted easily. (ns cljs.user) (defn f [x] (let [foo 42 bar (- foo x) baz (+ foo bar)] #js {:bar bar :baz baz})) (defn g [x] (let [result (f x)] (when (pos? (.-bar result)) (js/console.log \"It works\")))) (g 0) The ClojureScript compiler will compile this code to something like this var cljs = cljs || {}; cljs.user = cljs.user || {}; cljs.user.f = (function cljs$user$f(x){ var foo = (42); var bar = (foo - x); var baz = (foo + bar); return ({\"bar\": bar, \"baz\": baz}); }); cljs.user.g = (function cljs$user$g(x){ var result = cljs.user.f.call(null,x); if((result.bar > (0))){ return console.log(\"It works\"); } else { return null; } }); cljs.user.g.call(null,(0)); Paste this into `npx google-closure-compiler -O ADVANCED` and the output is simply console.log(\"It works\"); On the other hand, `npx uglify-js --compress unsafe` gives us var cljs=cljs||{};cljs.user=cljs.user||{},cljs.user.f=function(x){x=42-x;return{bar:x,baz:42+x}},cljs.user.g=function(x){return 0 H5 mobile https://medium.com/chia-ux/what-do-chinese-clients-mean-h5-i... > HMR Hot Module Replacement allows all kinds of modules to be updated at runtime without the need for a full refresh. (Abridged from a webpack doc) reply artemonster 10 hours agoprevnext [7 more] [flagged] byte0 10 hours agoparentNow that's a game I wouldn't mind a rewrite of. Imagine Heroes 3 with a modern engine and modding available out of the box instead of people having to reverse engineer it just to keep it alive today. reply BiteCode_dev 10 hours agorootparentExported in WASM to play directly in the browser, including Horn of the Abyss. I would pay for this. You'd probably have to redo the art though, since 3DO will unlikely do this port and I doubt they would licence the IP. reply Aeolun 9 hours agorootparent> I doubt they would licence the IP But would they go after you for using it. reply artemonster 5 hours agorootparentprevHdmod (not the money grab hd edition) is a good nodernized version with lots of QoL, modding scene is active and there is also VCMI engine. All working fine reply apatheticonion 7 hours agorootparentprevSeconded. reply CafeRacer 10 hours agorootparentprevThis reply pjmlp 11 hours agoprevEveryone is making the point that using JavaScript on the server was a BIG mistake, with this ongoing rewrites. We already had our bundlers in Java and .NET land, before nodejs came to be, and life was good. reply berkes 11 hours agoparentThe fact that people keep releasing new bundlers, minifiers, transpilers, package managers and so on, for JavaScript is a loud and clear warning that something is amiss. People (re)write such tools either for fun or to solve a problem (or best: both). Apparently after so much re-writes the problems haven't been solved. To me, this indicates fundamental problems. I'm not familiar enough with the ecosystem to know what those would be, let alone how to truly solve them. But the very fact that we see new builders, transpilers, bundlers every few months is enough to conclude we aren't solving the problems on the correct level or that maybe it cannot be solved at all. Because otherwise one of the many attempts would've solved the problem and \"everyone\" would be using that. reply goosejuice 4 hours agorootparentI believe we see such diversity because of the unique environment in which JS has come to exist. Folks who are writing all these tools are trying too solve problems from the outside in for their small corner of an incredibly large ecosystem. It's a snow ball rolling down an infinitely long mountain. I believe this may never settle. Mainstream browsers have already coalesced on a no build solution but it's profitable, by fame or fortune, to continue building solutions that require bundle and compile steps. Then others use those because off the shelf libs require them and save time and money. reply samaltmanfried 11 hours agorootparentprevThe situation with the tooling constantly changing isn't nearly as bad as the front-end frameworks themselves. I've been updating my knowledge of front-end, and it's an absolute shambles. The official React documentation(https://react.dev/learn/start-a-new-react-project) is telling me that in order to use their framework, I need to use another framework to solve (quote)\"common problems such as code-splitting, routing, data fetching, and generating HTML\"... At their suggestion I've picked NextJS, which is a \"full-stack\" React framework. This means that it has its own back-end which does most of the heavy lifting. So not only will our company have a traditional back-end, we'll also have a BFF (another thing the kids nowadays want), and a back-end that is actually our front-end application. At this point I've forgotten what problem we set out to solve. NextJS' documentation is also *terrible*. This situation is made all the worse by any material online about NextJS that's more than 3 months old being totally inapplicable because the framework changes so often. reply aaaaaaabbbbbb 6 hours agorootparentNext.js et al. provides a set of opinionated packages designed to enable a specific paradigm. For Next.js, that's server-side rendering. For Remix, that's progressive enhancement. If you are happy with client-side rendering and do not desire React on the server, there is not a strong reason to use Next.js; it introduces complexity and churn. reply meiraleal 8 hours agorootparentprevNextjs is the trojan horse sent to destroy React and it worked reply samaltmanfried 7 hours agorootparentIs this how other people feel about NextJS? I've been trying to keep an open mind about it, but its entire design seems so antithetical to what I'm trying to accomplish. Is there a better mainstream alternative? From what I've seen NextJS is pretty commonly used. reply meiraleal 4 hours agorootparentThe mainstream alternative is still to not have a \"backend-for-the-frontend\". If you use something like Rails, django, nodejs, use React connected to them. Or directly to something like supabase. NextJS is the extra complexity nobody needs. It is marketed as the solution to slow starts but React is slow so the solution is terrible over-engineered. A much better fix is to remove React and use something that is already fast like solidjs or Lit. There are much better UI Kits in Lit that I have seen in React and in the end it is just JS so the same people that can could React, can code Lit and SolidJS. reply anonzzzies 5 hours agorootparentprevYep, it’s terrible and everyone is going for it. reply pjmlp 11 hours agorootparentprevDefinitely, otherwise Netscape LiveWire would have been a huge commercial success. reply dgb23 9 hours agorootparentprevEsbuild did solve a major problem, which was very slow builds. Vite wrapps esbuild. Not sure what it provides itself. Then there came several specialized (Rust) tools. For the same reason esbuild was made. I think ultimately they try to solve the same issue: JS is supposed to be a productivity gain over compiled languages. But with ultra slow builds that goes out of the window. reply zoul 11 hours agoparentprevHaving the same language on the client and on the server is a huge productivity booster for me. I can’t imagine writing so many things twice again. Have you tried it? reply pjmlp 10 hours agorootparentUnfortunely I have to, thanks to the Next.js and React only SDKs, that many SaaS products now have as extension mechanism. Also if it is such a great experience, people wouldn't be rewriting the node ecosystem in Dart, Go and Rust. reply dgb23 9 hours agorootparentprevIt’s not necessary to use the same language for that. In many cases you can achieve the same with a clearer separation, with data driven methods and by generally not running so much JS. The typical example is input validation. You want immediate feedback on the client, but obviously you validate on the server. But instead of running literally the same specific code twice, you can use json-schema or your own general data description of what valid input is. You move the specifics from code into data. reply ecmascript 11 hours agoprev [–] Can't people figure out some other tooling besides bundlers? I mean, how many do we really need? It's probably fine, but so are all the others as well. The authors have probably spent a fair amount on time on this project so I don't want to be negative but it's just hard to be excited when it brings nothing new to the table. Why should I use this over Vite or esbuild? Because it's written in Rust? I don't understand why that even matters. Even if it was 10 times faster I wouldn't use it because Vite is fast enough and have all the plugins I would ever need. reply norman784 11 hours agoparentWhy matters that is written in Rust? Because there are already a few JS tools written in Rust, so you can now use the crates from projects like Deno[0], OXC[1], BiomeJS[2], etc to write your own tool with minimal effort. Also note that the Vite team is writing Rolldown[3], and guest what? They are writing it in Rust. [0] https://crates.io/search?q=deno [1] https://crates.io/search?q=oxc [2] https://crates.io/search?q=biome [3] https://rolldown.rs reply rty32 7 hours agorootparentNone of those tools you quoted are production ready based on my investigation, in the sense that if you manage the JS infrastructure of a company of 2000 developers, you would stick with webpack. Lots of Rust based tooling is still half baked and missing things here and there, so much that you wish these people work together to create one (or at most two) tool that is comparable to webpack. reply dsff3f3f3f 4 hours agorootparent> None of those tools you quoted are production ready based on my investigation This is very true and almost all of them are taking far longer to develop than they initially thought. swc/turbopack is being pushed by Vercel and it has been a huge ongoing disaster. reply ecmascript 9 hours agorootparentprevYeah okay, but that's not the reason why people write it in the title. They write it in the title because they know that many engineers like Rust and think people will immedietly be drawn to it. But the language itself is not a goal or at least shouldn't be IMO. Thus it have the opposite effect on me, who do not care about what language my bundler is written in. If I did, it still wouldn't have any competitive advantage since as you point out Vite will soon also be based on Rust. reply podgorniy 9 hours agoparentprevI've read some faq and docs. Their reasons are to have fast builder with flexisbility needed for business cases. If other words they are making internal tooling publically available. Being faster than es-build is not a goal, get people excited about speed is not a goal. Have control over tooling, flexibility, be fast-enough, be opensources are the goals. reply jack_riminton 10 hours agoparentprev [–] You'll get downvoted but I completely agree, it seems rewriting things in Rust and tinkering with bundlers is the new in-vogue thing to do. Lord knows why reply timrichard 9 hours agorootparent [–] I didn't enjoy the Rust hype on here in years past, but I'm always glad of any better tooling. Just an example from the other week... I swapped out NVM for FNM (Rust) and now I don't have to put up with performance issues, especially slow shell startup times. reply ecmascript 9 hours agorootparent [–] Just me being curious since I have used nvm for years without any issues. What do you mean by slow shell startup times? In what way do you use nvm in order to experience any slowness? reply timrichard 7 hours agorootparent [–] I followed the standard nvm install process, to get it loaded from my .zshrc I noticed a second or two in lag between launching the terminal and getting a shell prompt. Commenting out the nvm load as a test removed the delay. I installed fnm, aliased it to be nvm, and everything is snappy. Also nicer if you use tooling to 'nvm use' when changing into a project directory. There are a few issue threads such as this one : https://github.com/nvm-sh/nvm/issues/2724 BTW, this blog post was great for finding the culprit if there is zsh startup latency : https://stevenvanbael.com/profiling-zsh-startup reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mako, a fast, production-grade front-end build tool based on Rust, is now open source and available on GitHub.",
      "Developed to address build speed issues, Mako has significantly reduced build times, e.g., from 16s to 3.9s for Ant Design Pro.",
      "The project, started in March 2023, was internally released at Ant Group in November 2023 and open-sourced by June 2024."
    ],
    "commentSummary": [
      "Mako is a fast, production-grade web bundler developed in Rust, designed to enhance the development cycle by efficiently bundling web applications.",
      "It aims to minimize the tradeoff of slower initial load times often associated with bundling, and plans to support the unplugin system for better compatibility with existing ecosystems.",
      "The discussion highlights the benefits of bundlers, such as optimal caching and code splitting, and compares Mako to other tools like esbuild and swc, noting the ongoing evolution and competition in the web bundler space."
    ],
    "points": 208,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1719898885
  },
  {
    "id": 40851895,
    "title": "Code reviews do find bugs",
    "originLink": "https://two-wrongs.com/code-reviews-do-find-bugs.html",
    "originBody": "Code Reviews Do Find Bugs by kqr , published 2024-08-06 Tags: programming science learning There’s some 2015 research out of Microsoft titled Code Reviews Do Not Find Bugs11 Code Reviews Do Not Find Bugs; How the Current Code Review Best Practice Slows Us Down; Czerwonka, Greiler, Tilford; IEEE International Conference on Software Engineering; 2015. which seems strangely named because reviewers do find bugs. Here’s what the authors say: Contrary to the often stated primary goal of code reviews, they often do not find functionality defects that should block a code submission. Only about 15 % of comments provided by reviewers indicate a possible defect, much less a blocking defect. This is a misleading statistic, because it says nothing about the defect detection rate. Only about 15 % of smokers get lung cancer, but that does not mean we can ignore smoking as a cause – smoking is the cause of more than 80 % of lung cancer cases. The fact that 15 % of code review comments are about defects is not a statement about a lack of detected defects, but rather a statement about how reviewers also write a lot of comments about other things – and we will see more about that later. This does just not support the idea that reviewers do not find defects. For example, if the reviews in their data had an average of four comments each, then more than half of the reviews did get comments about defects! But we don’t need to speculate on how many comments there were in their data, because there has been previous research on this. We have known for a while that code review (as well as pair programming) finds an additional 60 % of defects for only a 15 % increase in time investment.22 Balancing Agility and Discipline; Boehm, Turner, Booch, Cockburn, Pyster; Addison–Wesley Professional; 2003 At this point, we also have more detailed data on the effectiveness of code review. During the first 60 minutes of code review of the day, the reviewer finds roughly one defect per ten minutes of reviewing – as long as they review less than about 50 lines of code per ten minutes.33 Making Software: What Really Works, and Why We Believe It; Oram & Wilson; O’Reilly Media; 2010. In other words, reviews are most effective on small chunks at a time, and mustn’t expand to cover large fractions of the workday. What other activity can you imagine where a single developer can uncover a defect every 10 minutes? Certainly not through manual testing – not even all forms of automated testing beat this rate, given that the total cost of automated testing of a component quickly exceeds 10 minutes of time investment. Code review is ridiculously effective. Of all the quality measures we might have in place, code review is the last one I’d get rid of.44 But if we produce more than about 300 lines of code per developer and day, I would be tempted to let the excess lines of code go unreviewed, and focus reviewing on the most important 300 lines per developer and day. The Microsoft authors also report on how code review is remarkably effective for learning the codebase. The usefulness of code review comments – as judged by the author of a code change – is positively correlated with reviewers’ experience. Without prior exposure to the part of code base being reviewed, on average only 33 % of any reviewer’s comments are deemed useful by the author of a change. However, reviewers typically learn very fast. When reviewing the same part of code base for the third time, the usefulness ratio increases to about 67 % of their comments. By the fourth time, it is equivalent to the project’s long-term average. Granted, they don’t say enough to determine whether “the project’s long-term average” is at a comparatively low or high familiarity level, but it sounds to me like only four code reviews are enough to get people relatively familiar with a completely new part of the codebase. Assuming a reasonably-sized change (50–100 lines of code?) and a reasonable pace of reviewing for a beginner (10–50 lines of code per 10 minutes?) this would mean about 1–2 hours of code review is enough to get familiar with a codebase. That’s a cheat code. Exploration and exploitation are always in conflict; for software engineering, this means knowledge sharing and speed are in conflict. If we put someone experienced with a component on a task, they will finish quickly but we won’t spread knowledge about that component. If we put someone inexperienced on the task, the task is likely to take much longer but we do get knowledge sharing. Or! We ask the inexperienced person to review the code of the experienced person. This takes virtually no time (increases development time by 15 %) and they become familiar with the component as a side effect. We get both knowledge sharing and speed.55 Not to mention that sometimes we want to share knowledge about a component which does not need changes made to it. We can then have people review past changes and get feedback on their reviews from an experienced member of the team. The main thesis of the Microsoft paper seems to be that code review is not worth the time spent on it. We have already seen that when the review load is properly managed, code review is highly effective both in terms of finding defects and learning the codebase. The Microsoft paper goes on to say other things that appear to contradict their thesis, like Feedback on long-term code maintainability covers 50 % of code review comments. Sure, but isn’t this a good thing? Long-term code maintainability is in my experience a large problem in organisations that don’t do peer review. The review is an opportunity for both author and reviewer to prove themselves. This seems like a potential motivator, and not a problem. Code review usefulness is negatively correlated with change size. This is a feature, not a bug. It is an incentive to keep changes small and atomic. Developers spend six hours per week reviewing. This is a bit too much (remembering the “first hour of the day” rule from before) but it should only result in a marginal decrease in productivity – code review ought to still appear to be a clear win. I suspect the real problem with code review in the authors’ experience is one of the last points they raise: The median review turnaround time is 24 hours. The research on code review has been mostly done in lab settings and not in integrated on-the-job situations, so it has not emphasised turnaround time. But having half of the reviews take more than 24 hours seems – in my experience – like way too much. When I did the maths on this at a previous job, the median turnaround time was 6 hours, and that was borderline painful (which was why I ran the numbers in the first place.) In the end, I agree with the authors that we should not blindly copy best practises (i.e. cargo cult practices) but the reported experience in this case does not appear to follow best practices, so before judging best practices we should first make sure we have followed them. If they are impractical to follow in a large organisation, that would be an important observation worth publishing, rather than claiming they don’t work when followed. Sidenotes 1 Code Reviews Do Not Find Bugs; How the Current Code Review Best Practice Slows Us Down; Czerwonka, Greiler, Tilford; IEEE International Conference on Software Engineering; 2015. 2 Balancing Agility and Discipline; Boehm, Turner, Booch, Cockburn, Pyster; Addison–Wesley Professional; 2003 3 Making Software: What Really Works, and Why We Believe It; Oram & Wilson; O’Reilly Media; 2010. 4 But if we produce more than about 300 lines of code per developer and day, I would be tempted to let the excess lines of code go unreviewed, and focus reviewing on the most important 300 lines per developer and day. 5 Not to mention that sometimes we want to share knowledge about a component which does not need changes made to it. We can then have people review past changes and get feedback on their reviews from an experienced member of the team.",
    "commentLink": "https://news.ycombinator.com/item?id=40851895",
    "commentBody": "Code reviews do find bugs (two-wrongs.com)174 points by imadj 19 hours agohidepastfavorite130 comments willio58 18 hours agoAgreed. I mainly manage and review code at this point in my career. I find many bugs, every once in a while finding something that would have caused an outage or notable problem for users. What I find more though is code that isn't thought through. Tech debt and code smell are real, and they affect the performance of a team. Nipping that in the bud takes quality PR reviews and time to meet with submitters around issues you find. Knock on wood but working at the company I do now where I, along with my team, have made quality PR reviews normal.. our codebase is now enjoyable and fun to work on. I highly recommend it! One key aspect is being “kind, not nice”. Be helpful when leaving comments in PRs, but don’t be nice for the sake of avoiding conflict. Also if you find code reviews to be a waste of time I can reccomend one thing I do often - give warnings. I approve and give comments around things I’d like to be fixed in the future for similar PRs. I don’t hold up the merge for little things, but at the same time I won’t let the little things slide forever reply mikepurvis 17 hours agoparent\"Tech debt and code smell are real\" I think what I struggle most with is that often times there's a valid business reason to \"just ship it ASAP\", but the missing piece is the accountability around the conditions attached to that. Like, okay, if we don't want to fix this now because it needs to be in the next release then we can merge it as-is, but you can't document this externally, it can't because part of an API, and there can't be any further development in this direction until X, Y, and Z have been rewritten to be in like with ABC. I find it profoundly hard to get buy-in for those types of discussions. Everyone is happy to smile and nod and the appropriate tickets are filed with deadlines attached, but then the next release rolls around and there's new business-imperative stuff that's the focus and the cleanup tickets are quietly moved to backlog with the deadlines removed. Seeing this repeated over a number of years has left me with kind of a cynicism about the process, where it feels like code review is at least partly an exercise in frustration; I don't have the backing required to insist on doing it right upfront, so instead I'm really just getting a preview of what is going to land in my lap a year or two from now. reply hakunin 16 hours agorootparentCouple of points on this. 1. A lot of problems arise from too few people working on too many things. If it's one-two devs and backlog is growing, the problem is not that you have no time to fix things, but that you're understaffed. If you have enough people, then from the business perspective it shouldn't even be that noticeable that someone is refining previous work, while someone else is building the next thing. 2. If you're not understaffed, then the best time to clean up new code is during or immediately after writing it. A phrase I like to use is \"while it's still fresh in memory\". You're saving time and not adding new bugs, by not having to remember everything again, load all that context back into your head. reply godelski 15 hours agorootparent> If you're not understaffed And it's worth noting that having some fat is good. I can get it when you're a startup and you're trying to pull yourself up by your bootstraps, but at some point of time you need some fat. Too much fat is bad, but no fat is also bad. Startups run lean because they have to but when big businesses run too learn, it's called anorexia. reply pjungwir 4 hours agorootparentIndeed, if you read The Goal or The Phoenix Project, they call this \"slack\". There is a whole theory about why slack matters. reply klooney 17 hours agorootparentprevThe previews are valuable though, it makes you look like a wizard when you already know how something broke. reply pavel_lishin 7 hours agorootparentBut it makes you feel like Cassandra when you keep warning people about the same problems, and keep running into them months and years down the line. You can only post the Surprised Pikachu meme so many times before it loses its luster. reply mikepurvis 5 hours agorootparentprevOften it's more subtle than just \"this is clearly going to take down production in X way at some point.\" The issue is more like feeling that the logic is too entangled and it's going to be hard to maintain later on, or that a library should or should not have been used, or something done with threads should have been async. So yeah, not as cut and dried as \"I said it would happen and it did\" but more like \"I had a feeling this was going to turn out to be a pain and sure enough here I am reviewing code that represents that pain.\" reply patrick451 14 hours agorootparentprevOr incompetent. If you knew this was going to break, why did you approve it? Your only defense is \"there was a lot pressure to get into the release xyz\". There's not much sympathy for that defense. The animal spirits that thought the broken feature were the most important thing ever are long gone, and frustrations about the new outage caused by the previously most important feature ever have taken over. reply klooney 1 hour agorootparentDon't approve it! That's actually a thing you can do. reply jiggawatts 15 hours agorootparentprev\"There is no later.\" is my new mantra. reply majikandy 12 hours agorootparentThat reminds of codebases littered with Todos… where I like to Yoda it… do or do not, there is no todo. reply mikepurvis 5 hours agorootparentA TODO is not inherently bad, but I think intent is important— how likely is it that someone will come back here purely with an intention to address that comment? If not likely, then the TODO will be taken up in the context of future refactoring and in that case it's a gift to the person eventually contemplating that work, helping them understand something about the code or context that you realised too late in the project to be able to act on it. reply jellyfishbeaver 18 hours agoparentprevI am a new manager and I am struggling to get my team to understand the value in code reviews. I have been through so many rewrites and re-re-writes of spaghetti code, I am much more critical now reviewing code, and I am trying to promote this culture on my team. Do you have any suggestions? - The same people leave detailed comments on others' merge requests, but get discouraged when nobody else puts in the same amount of effort for theirs. - People blindly accept suggestions with no resistance or discussion to get the review over with. - People send their MRs to side channels or other teams to get their changes merged in without resistance or back and forth. (I've had to revert several of these). reply ecshafer 17 hours agorootparentGood PR culture is definitely something that has to be built from the ground up, and supported top down. At Shopify, who I think has a really good PR culture we have a few things that I think help (beyond a good CICD, and static analysis tools): 1. PRs are supposed to wait for 2 acceptances, can be shipped with 1, and can be emergency shipped with 0. So the barrier is low, but the culture supports more. We are expected to get 2 reviewers from our team to okay. 2. Depending on the code project, we have to fill out a template for the PR, what is in it, what it changes, what to look for when we test the code, etc. 3. Some areas have code owners that might require an additional review from a specific team. 4. We are expected to check out, and test branches when we review them. So a quick read and LGTM is really discouraged outside of a few small cases. I have seen a lot of places that do the blind PR acceptance, and its tough because without this really being enforced and encouraged that culture is hard to change. reply bobthepanda 12 hours agorootparentAlso there is something to be said that code reviews also work well with code that is meant to be reviewed. The worst kind of peer review happens on PRs that are thousands of lines because nobody wants to read all that and things will be missed. Where I have seen successful code review is where people break code into reviewable bits, and those individual reviews are so fast that they actually end up bring completed faster than if it had been one giant PR. reply anonymoushn 11 hours agorootparentHow much additional time is needed to break a self-contained change that's the smallest it can reasonably be without breaking anything into a bunch of smaller changes though? reply withinboredom 10 hours agorootparentLike 10-15 minutes .... git co master git co my-branch -- . git add -up . # select changes relevant to first pr git commit git reset HEAD --hard # and again... reply anonymoushn 8 hours agorootparentThe question was specifically about scenarios in which this approach wouldn't work, for example because your team doesn't want to approve PRs containing only dead code or because any subset of the change won't compile or won't preserve correct behavior without the others pieces. reply dkdbejwi383 7 hours agorootparentIt helps to have the right tooling in place to ship \"incomplete\" work, e.g. feature flags so that you can ship a very light and not ready for end-users version of some feature, and continue to iterate on it in smaller PRs. e.g. first pass adds a new screen and just dumps the output second pass adds input fields and controls next pass adds validation then add animations etc reply mewpmewp2 5 hours agorootparentIt sounds so good in theory, but in practice: 1. Frequently old code needs to be touched or refactored. Feature flag would not be enough. 2. Even feature flag itself can be a risky addition, and might affect existing customer usage. Most of the time old code does need to be touched, there really aren't those perfect new isolated features, at least in my experience. reply bobthepanda 3 hours agorootparentIf anything refactors should be behind feature flags *because* they are so disruptive. reply jappgar 3 hours agorootparentprevIMO this is a terrible approach, and why I hate the way feature-flags are used nowadays. For example, I'm not approving anything without input validation (frontend or backend). I have no idea if you're actually going to add validation later before the fflag is removed. \"Trust me bro\" doesn't work for me. reply bobthepanda 2 hours agorootparentI mean you can have validation for the features you’ve written already behind the feature flag, while holding off on the stuff that doesn’t exist yet. Feature flags don’t mean throwing the baby out with the bathwater. reply mewpmewp2 5 hours agorootparentprevWe have these things as well, but usually people treat these are bureaucratic obstacles and don't actually perform the steps. E.g. template is ignored, and reviewer doesn't check out, just LGTM and good to go. Few people actually take a more serious look. reply 01HNNWZ0MV43FF 3 hours agorootparentprevWhat's the social atmosphere like? I ask because I had this one job, where the tech team was a few nerdy programmers in one office, before COVID, and a bunch of people in a friend group I wasn't part of, after COVID. By that I mean, before COVID it was common for the founder to take us out for lunch or tennis as like official team building time. I loved this because I'm a picky eater and it's hard for me to make friends, so if the company makes official initiatives, it's easier for me to fit in. After COVID, the official initiatives weakened. The team was too big to take everyone out, and I didn't join the friend groups who naturally found ways to socialize. In that new environment I no longer felt like an equal member of the team, I felt like an outsider who had authority on paper but didn't have any of the camaraderie needed to get things done and survive a work day. Even though everyone repeatedly said I was respected and valued as the most senior programmer, I found it impossible to be a good teammate in that new environment, I felt like I was just spending all day being mean and nobody got a chance to see me as human. That was part of why I quit. In that environment my code reviews sucked. Now I'm at a remote company where once again it feels like everyone is equally non-social, and I'm just gonna ride that as far as it goes. If they get an office I'll probably cash out and go on vacation for a year Edit: almost forgot, the other woman who was part of the original \"nerdy programmer\" team, ended up also burning out and quitting about the same time as I did. She also didn't really make friends in the new environment, and seems much happier pursuing her hobbies and taking it easy between jobs reply shrimp_emoji 1 hour agorootparentCan juniors even be friends with seniors? I feel like it's a \"professor-student\"/\"private-lieutenant\" relationship. I spend all day being mean in code reviews too, and I'm a relative junior compared to most of my team! >:] They do not see me as human because I am not human. I do not have their human emotions and concerns. My only concern is code. They still like and respect me though, it feels like! reply xmprt 17 hours agorootparentprevCulture for code reviews doesn't start out of thin air. Unless you have processes for CI/CD, testing, task estimation, retrospectives, incident postmortems, etc., there's never going to be a point where you will convince people that they're helpful. So start with those. There's always going to be pushback from adding more process, but if there's an understanding amongst the team that keeping things working is P0 then these processes will slowly/naturally come up as the team realizes that investing in them proactively will save them time down the road. reply azov 17 hours agorootparentprevIt takes time. For a team not used to code reviews, they might seem more trouble than they're worth at first. Most likely they will be more trouble than they're worth for the first few months. Keep doing them and eventually your smart developers will figure \"if we have to do this anyway, we may as well find something useful to say\" :) A few things you can do to make it smoother: - Manage expectations. Initially it may be as simple as \"we just want to have a second pair of eyes on every change\" or \"be aware what other team members are up to\" - i.e. communication first, improving code second. - Set up your tooling to make the process smooth. If somebody wants to just get it over with - it should be easier for them to use your official review process then to use some side channel. A vicious alternative is to make using side channels harder ;) - Leverage automation. Run tests, linters, static checkers, etc. on your PRs so that developers get something useful even if no human leaves interesting comments. - If some team members already have experience with code reviews - adjust their workload so that they can do more reviews. They are effectively training others by example. - Make sure that code changes under review are reasonably sized. Encourage submitting changes for review early and often. \"Here is the feature I worked on for 3 months, and it's due on Friday, please review\" won't make anybody happy. - Make it less intimidating. Code reviews are not just for finding bugs and flaws, encourage reviewers to say positive things as well. reply Izkata 2 hours agorootparent> Set up your tooling to make the process smooth. > Leverage automation. Run [..] linters, static checkers [..] These don't make the process smooth unless you set them up to simply give a warning rather than block the build/merge. And with that they'll likely get ignored anyway. I think linters/etc should be avoided until you already have buy-in from the team. reply azov 26 minutes agorootparentIt depends. If your codebase is already free of lint warnings - adding a blocking check to prevent new ones is no big deal. But if your blocking check means that everyone has to drop everything and spend a week fixing code - of course this won't be smooth. PS. Also, plan to have a manual override for whatever autoblocks you set up. Most linters already come with this feature. reply majikandy 12 hours agorootparentprevThis is quite good advice, I feel the “we have to do this anyway” line is more like… “so we might as well make it easy for ourselves”… eg write code that works, you self tested it through tests and manual if needed, so the reviewer doesn’t have to get bogged down in actually running it (start by adding screenshots for this but graduate to not needing them). Keep PRs as small as possible, aka multiple PRs streaming after each other for a single feature card, get the PRs in as soon as valuable and don’t block for nitpics but the shared expectation you start to agree on things that are better and they happen with the next changes. The general mantra being that “if it works then it shouldn’t be blocked” and developer can choose to improve the maintainability there and then or delay it to next or later PRs at their discretion. After all you trust each other. reply spankalee 18 hours agorootparentprevCulture is made, it's not accidental. I would raise all these issues and more in group meetings. Try to get people to understand the many different benefits review brings to both the committer and reviewer - by having them state the benefits they want or could see getting. Talk about various kinds of comments (clear bugs, performance, style, robustness, factoring and organization, etc.), and the various priorities from no-action-required to nits to blockers. Talk about the priority of reviews themselves. Reducing the latency of reviews has a huge positive effect, ime. reply hakunin 16 hours agorootparentprevI've written up some rules that I've successfully applied in my teams. https://max.engineer/mindful-code-reviews reply godelski 15 hours agorootparentprev> The same people leave detailed comments on others' merge requests, but get discouraged when nobody else puts in the same amount of effort for theirs. This is always a precarious situation. Because as soon as these people become jaded, your ability to make good PR culture will also vanish. And they can become jaded for many reasons. If these people are not explicitly or implicitly valued, they will know. If people who are doing the incorrect things are getting promoted first (or even at the same rate!), the same raises/bonuses, and on all accounts are treated equally, the employee will almost always converge to \"well why am I putting in all this extra hard work if it's not benefiting me in any way?\" And I don't think promises of early promotion or similar have a good effect because there's many employees who've had those promises made to them and it not follow through[0]. So there needs to be some, even if incredibly minor reward in the shorter term. Also, do not underestimate the value of explicitly saying \"good job.\" There's often a huge bias in communication where it is only made when something is wrong and when good work is done that it is left unsaid. You don't have to say it for everything, but I think you'll be surprised by how many people have never heard this from management. [0] I wanted to share a story of an instance I had with this. I was a green (mechanical) engineer working at a startup. I had a physics degree instead of a ME, but have always been hands on. But because of this I was paid less and not valued as much. I asked my manager what I would need to do to get promoted and to be on par with everyone else. I got it in writing so I could refer back to it. At my next performance review I was just talked down to. Complaining about how I didn't do this or that (sometimes things that were impossible and sometimes they were weird like \"your code may have been 20% faster but X couldn't understand it so we can't use it\" -- X was a manager who had only been writing in C++ forThe same people leave detailed comments on others' merge requests Call these people out, in public, for doing good work. Tell everyone they are setting the bar and others are not living up to it. > People blindly accept suggestions Coaching, lots of one on one coaching about finding and having a voice. Lots of \"team building\" where you level out the playing field with the strong vs weak voices. Figure out what those quiet ones excel at and do a fun activity around that. Let them find legs... > People send their MRs to side channels or other teams Stick. Harshly worded emails. Down dressing in public. Telling your team that in no uncertain terms that \"this is unacceptable behavior\" As for the chair thrower... He was always fair, he always had his team first, I grew as a person, a manager and an engineer working for him. Its not growing happy go lucky good times while I get a pay check, its Growing pains, spreading that (pain) around is part of your job. reply pavel_lishin 6 hours agorootparent> The office is not a safe space. It well fucking should be a space where I'm safe from my boss throwing large projectiles at me. reply lazyasciiart 16 hours agorootparentprevAs far as dodging projectiles goes: yes the office is supposed to be a safe space, and if someone threw a chair at me, one of us would not work there the next day. (Add normal caveats for \"maybe they threw the chair to save you from the ninja creeping up behind you\".) reply zer00eyz 15 hours agorootparentThe \"chair\" in question was 3 coat hangers and 2 frisbees... I have no idea how it held a human up. The \"throw\" was more of a shove and the thing went flying in my general direction. The only thing that chair was going to hurt was my feelings. It was far less scary than the office where I sat on an ammo shipment. reply 01HNNWZ0MV43FF 3 hours agorootparentHow courageous of you to do a scary job, not to protect other people from having to live hard lives, but so you can be a prick to them on bulletin boards. Maybe I should have done that lol reply danielmarkbruce 14 hours agoparentprevNever realized this was a debated topic. Are there smart people who believe in not having code reviews? What's the best argument against code reviews? reply dkdbejwi383 6 hours agorootparentI worked in a team that didn't do reviews because _everything_ including spikes, research, etc, was done by two engineers pairing. This was remote, cameras on, all day. I found it utterly exhausting. I was somehow working at 100% capacity but producing output at 50% because so much of my cognitive bandwidth was taken up with the pairing process. reply bakje 12 hours agorootparentprevI’ve spoken with a CTO who was against them because they add too much overhead, partly because they’re too late in the process. He encouraged his team to discuss an approach beforehand or to work on something together. Other than that they had a lot of tests and a very structured codebase, I guess it worked for them. reply giancarlostoro 6 hours agoparentprev> “kind, not nice” Always when joining a team the first thing I tell devs is \"I don't care how critical you are, just be honest\" I think setting expectations early on is very critical. I think people not feeling attacked / too defensive of code is a good step forward. People who vehemently defend their code are bad developers imho. reply 01HNNWZ0MV43FF 3 hours agorootparentIt sounds like radical candor and I like it reply saulpw 18 hours agoparentprevHow do you phrase these warnings? \"Next time..\"? I have a hard time being serious with my own warnings if it's fine enough for now. reply elcomet 17 hours agorootparentWe prefix our comments with \"minor:\", and all employees know that this means it's something that would be nice but not necessary to merge reply audiodude 18 hours agorootparentprev\"This is okay for now, but we should think about how we want to serialize these objects. Feel free to remove the N^2 algorithm in a follow up.\" reply est31 18 hours agorootparentThat works great in a setting where you are both employees of the same company, and you respect each other, but it often doesn't work in the open source world, people just disappear and you never hear from them again. It is possible that they do file follow-ups, but in my experience it's rare. reply sfink 17 hours agorootparentYes, even within a company my threshold for accepting a change can vary pretty widely depending on my experience and relationship with the author. For an external contributor or someone I've never collaborated with (by reviewing code or having my code reviewed), I don't accept the code until almost everything is worked out to my satisfaction. With someone I work with regularly, it's not uncommon to accept a change with a comment like \"this is all good, but you need to take X into account which will change almost everything in this patch\" (I exaggerate, but only slightly). I know whether an update could be problematic and whether it is necessary to see it again. Sometimes there are a couple of obvious ways that something could be done, they picked one but weren't tied to it if I had a reason for picking a different one, I picked a different one for $REASON. Most are somewhere in between. Though in some ways it works the other way around. For an unfamiliar open source contributor, I need to be confident that the change is worthwhile. I will be lenient on stylistic things, and I'll just land their patch and then fix it up afterwards. For someone I've worked with a bunch (whether a familiar contributor or a coworker), I will trust their opinion on the underlying quality of a change, but be less tolerant of unnecessary stylistic differences since they should have already come into alignment on those and it's more likely to be an oversight if they missed something. (Plus, I don't want to be fixing up their changes after the fact, given that >90% of patches will come from regular contributors.) reply closeparen 18 hours agoparentprev>time to meet with submitters around issues you find. What! I would be livid if someone scheduled a meeting with me about a PR. We have way too many meetings already, this is one of the only processes that is mercifully async. reply fiddlerwoaroof 15 hours agorootparentMe too, I really dislike meetings that could have been handled by asking me three or four questions in slack or in the PR and then waiting fifteen minutes or so for me to answer. reply willio58 13 hours agorootparentprevTo be clear I make time to meet if the submitter wants to talk through things. I don’t require meeting on every PR. I meet as needed on PRs, pretty infrequently as people get up to speed reply hyperadvanced 16 hours agorootparentprevIt doesn’t need to be formal or very long. I personally enjoy a PR meeting where we can poke at the code and understand it over someone dumping 2,000 lines of code in my lap at lunch time and hoping to get their spaghetti to prod by dinner reply danielmarkbruce 14 hours agorootparentprevLivid? About a meeting to discuss work? Some comments in slack etc sound worse than intended, and people are aware of that and sometimes go out of their way to say it in a way to it's received as intended. reply godelski 18 hours agoprevI think this is really important in that it is bigger than \"code reviews.\" It does show how people greatly misunderstand statistics[0]. And what's even funny is at surface level the claim that code review \"does nothing\" __sounds__ ludicrous. But people \"believe\" because they are annoyed with code review, not because they \"actually\" believe the results. But statistics are tricky. With the example given in the article \"15% of smokers get lung cancer\" compared to \"80% of people with lung cancer smoke.\" These two are not in contradiction with one another but are just different ways to view the same thing. In fact, this is often how people will mislead you (or how you may unintentionally mislead yourself!) with statistics. Another famous example is one that hits HN every once in awhile: \"Despite just 5.8% sales, over 38% of bug reports come from the Linux community\"[1]. In short this one is about how linux users are just more trained to make bug reports and how most bugs are not system specific. So if you just classify bugs by the architecture of those submitting them, you'll actually miss out on a lot of valuable information. And because how statistics work, if the architecture dependence rate was as low as even 50% (I'd be surprised!) then that's still a huge amount of useful bug reports. As a linux user, I've seen these types of bugs, and they aren't uncommon. But I've frequently seen them dismissed because I report from a linux system. Or worse, support sends you to their page that requests you to \"upvote\" a \"feature\" or bug issue. One you have to login to. I can't take a company like that seriously but hell, Spotify did that to me and I've sent them the line of code that was wrong. And Netflix did it to me saying \"We don't block firefox\" but switching user agents gave me access. Sometimes we got to just think a bit more than surface level. So I guess I wanted to say, there's a general lesson here that can be abstracted out. [0] Everyone jokes that stats are made up, but this is equally bad. [1] https://news.ycombinator.com/item?id=38392931 reply ehsankia 18 hours agoparentBasically, code reviews also happen to find a lot of other non-bug stuff (probably nits and style issues). That's why looking at % is dangerous. You could be finding 5 bugs per code review, which is a lot, but if you also make 30 other non-bug comments, suddenly \"only 15% of comments are bugs\". reply godelski 17 hours agorootparentOh I completely agree. There are just a lot of things that can't so easily be measured and many things that can never be. But that doesn't mean they don't matter. Following the point you're making, enforcing good style can result in bugs not happening later on or even save a lot of future time as your code doesn't slowly spaghetti. And I think that's one where people often miss. That spaghetification happens generally through a slower process. By dozens of commits, not by a handful. reply jiggawatts 18 hours agoparentprev> support sends you to their page that requests you to \"upvote\" a \"feature\" or bug issue. Microsoft does this for enterprise products where customers might be paying $100K/mo or even millions. “We hear you, but your complaint is just not popular enough so go away.” “Sure it’s a catastrophic data loss bug that ate your finance transactions, but if other people can’t identify that their seemingly unrelated crash is the exact same issue then no fix for you.” “Now that you did get ten thousand votes on an issue titled ‘Consiser doing your job’, we’ve decided to improve your experience by wiping out the bug forum and starting a new one from scratch that has fewer scathing comments from upset users.” reply lhamil64 17 hours agorootparentMy company/team has very different processes for bugs vs feature requests. If a customer opens a ticket and we determine it's a bug, we will generally fix it in the reported release and later (unless it's a security vulnerability or other major problem). But for feature requests we just tell them to submit it to a community and we evaluate it to see if it's valid and something we'd likely implement given the other work we have on our plate, but not necessarily do it any time soon. reply godelski 17 hours agorootparentSometimes feature requests are actually bugs and can be illustrative of one not properly understanding design. But I think it is important how user feature requests are interpreted. They have a frustration that you might not be aware of but they aren't aware of all the code and constraints. It can even be in design, which is still important. Very often there is a way to resolve a feature request that is not what the user explicitly asks for. But to do that you have to read between the lines, and carefully. Of course, some people go completely the wrong way with this and cough Apple cough decide that they know what is best for the user. It's totally a hard balance to strike, but I think it is very common for it to be framed much simpler. There's the joke that the user is dumb, and maybe they are, but that doesn't mean the issue they face is. It's not always dumb when a person pulls on a door that says push, because it may actually be that the sign and design are saying different things[0]. And personally, I like when users suggest methods of resolving the problem. I might throw that in the garbage, but it can often give me better context clues as to what they're trying to ask for and really does tell me if they're thinking hard about the problem that they care about the product. They just don't have the same vantage point that I do, and that's okay. [0] https://www.youtube.com/watch?v=yY96hTb8WgI reply jiggawatts 16 hours agorootparent> Sometimes feature requests are actually bugs You can have two missing features that add up to a bug in total. For example, I worked with two cloud products from the same vendor where a missing back-end HTTP feature of the CDN product interacted with a missing HTTP front-end feature of the PaaS service such that the two products that have a \"natural fit\" together couldn't actually be used in combination. This made many architectures that ought to have worked a no-go, forcing customers into contorted design patterns or third-party products. IMHO this is a bug (\"Can't use your products\"), but each team individually marked it as a missing feature and then they just ignored this for about three years. Also: not enough people voted the missing features up because not enough people were using the products... because they couldn't. I know this is a bit off-topic here, but it circles back to the \"statistics is hard\" intro in the original blog article. You can make catastrophic business mistakes relying on statistics you don't full understand, such as this example of \"you won't get many complaints for unusable products\". You will get many complaints however for the usable products... they have users to complain. https://en.wikipedia.org/wiki/Survivorship_bias reply godelski 14 hours agorootparent> because not enough people were using the products... because they couldn't. I don't think this is off topic at all. I think is is explicitly on topic, at least the the underlying one. Not just statistics are hard, but it's hard to measure things and even harder to determine causality. Which is often the underlying goal of statistics and data science. To find out why things happen. Measurements are incredibly difficult and people often think they are simple. The problem is that whatever you're measuring is actually always a proxy and has uncertainty. Often uncertainty you won't know about if you don't have a good understanding of what the metric means. You'll always reap the rewards when putting in the hard work to do this, but unfortunately if you don't it can take time before the seams start to crack. I think this asymmetry is often why people get sloppy. reply jiggawatts 13 hours agorootparentThe example I like to use is the confusion around COVID statistics, and how people mis-interpreted them. For example, the rate of infections (or deaths) per day that was reported regularly in the news is actually: rate of infections * measurement accuracy * rate of measurement. I.e.: If more people turn up to be tested, the \"rate\" would go up. If the PCR tests improved, the \"rate\" would go up. A similar thing applies with hospitalisations and deaths. It might go up because a strain is more lethal than another strain, or because more people are infected with the same strain, or because more deaths are attributed to COVID instead of something else. It doesn't help that different countries have different reporting standards, or that reporting standards changed over time due to the circumstances! Etc... It's complicated! reply marcosdumay 17 hours agorootparentprevYou mean they don't censor the bug reports and try to gaslight you into believing their software is flawless anymore? That's a tremendous improvement when compared to the time I interacted with them. reply jiggawatts 16 hours agorootparent> don't censor the bug reports They do, but eventually even the polite but grumpy comments build up to the point that it looks bad. These comments are public -- that's the whole point -- so the only way to hide them is to delete them. Normally this upsets users even more, so the \"trick\" is to \"improve\" the service by dropping the entire forum on the floor and starting over with a new piece of software. Not because it's better in any way, but because it is an implicit DELETE * FROM \"BUGS\". Microsoft is on their... what... third forum now? I lost count. reply poikroequ 17 hours agoprevThe value of code reviews really depends on the code and the person working on the code. For a team who have spent years working on the same repo, code reviews may not hold much value. But if you have a new guy on the team, or a junior, you'll definitely want to review their code. Code reviews can also do more than just find bugs. You can point out a better way of doing things. Maybe this SQL could be more efficient. Maybe you can refactor some bit of code to make it more robust. Maybe you should put a logging statement here. This method name is confusing, may I suggest renaming it to xyz? reply dkdbejwi383 6 hours agoparent> But if you have a new guy on the team, or a junior, you'll definitely want to review their code. Reviews _from_ juniors or new team members are also really valuable, as they don't have the history or tribal knowledge that others may have. They'll often spot things that have gone overlooked because \"that's how it is\". reply gwd 10 hours agoparentprev> For a team who have spent years working on the same repo, code reviews may not hold much value. I have definitely found bugs [ETA during code review] in code written by very senior developers in code they've been familiar with for over a decade. reply kqr 12 hours agoparentprevI got really curious and I'd like to ask you some follow-up questions on your experience in reviewing and receiving reviews. Do you mind shooting an email to hn@xkqr.org? reply phito 9 hours agoparentprevCode reviews also keep the team up to date with what is changing in the code reply topkai22 12 hours agoprevCode reviews don’t just find bugs, they prevent them from being introduced in the first place. Developers are more careful about what they write and submit when they know they’ll have someone else looking at it. We went through a couple iterations of our code review policy on a multi-year project a while back. We never really saw code reviews catch a substantial number of bugs over time, but whenever we pulled back on code reviews we definitely saw the production error rate go up. reply jt2190 17 hours agoprevI’m not sure why the author ignores the “… that should block a submisson” part. The abstract of the paper: > Because of its many uses and benefits, code reviews are a standard part of the modern software engineering workflow. Since they require involvement of people, code reviewing is often the longest part of the code integration activities. Using experience gained at Microsoft and with support of data, we posit (1) that code reviews often do not find functionality issues that should block a code submission; (2) that effective code reviews should be performed by people with specific set of skills; and (3) that the social aspect of code reviews cannot be ignored. We find that we need to be more sophisticated with our guidelines for the code review workflow. We show how our findings from code reviewing practice influence our code review tools at Microsoft. Finally, we assert that, due to its costs, code reviewing practice is a topic deserving to be better understood, systematized and applied to software engineering workflow with more precision than the best practice currently prescribes. “Code Reviews Do Not Find Bugs: How the Current Code Review Best Practice Slows Us Down” https://www.microsoft.com/en-us/research/wp-content/uploads/... reply gwd 10 hours agoparentThe \"that should block submission\" is always one of the trickiest parts. There's a saying: \"Everyone that drives slower than you is an idiot, and everyone that drives faster than you is a maniac.\" But it is true that going faster increases danger, and there is a speed that appropriately balances benefit against risk; but everyone perceives it differently. The same is true of \"code smell\" issues: Everyone who asks you to change things is a pedant who's slowing down the project for pointless aesthetics, and everyone who pushes back against changes you've requested is a cowboy who is going to make the code harder to maintain in the future. So in the paper, how did they decide whether a non-bug change \"should block submission\" or not? reply jt2190 6 hours agorootparentIf a comment points out a bug/defect [1], then it should block. If you think about it, as bugs/defects are removed, the code becomes more correct and thus more stable because it doesn’t need additional changes to remove bugs, so removing bugs reduces the need for future maintenance. If we block due to future maintenance concerns what we’re really asserting is that the requirements are unstable, and that removing today’s bugs is less valuable overall because requirement changes will remove the line of code with the bug and replace it with a new line of code with a new bug. I suppose it depends on the code review process at at a given organization whether that’s the appropriate point at which to block code for architecture/design issues. In my experience the code review step is much too far downstream in the development process and much too narrowly focused on a subset of code to be an effective place for design changes that have significant impact on maintenance. [1] The paper authors reviewed data in Microsoft’s internal code review tool, which is proprietary, so we can’t see what the specific bugs were. reply swatcoder 16 hours agoprevAs with most processes, the dilemma with code reviews is in figuring out how they impact your team and your organization. In a huge org, with thousands of engineers that's already burdened by hours per day of interruptions and process overhead, and release runways that already involve six stamps of bureaucracy, mandatory code revies have very little downside (it's in the noise) but highly variable return (many people are just droning under the weight of process). The org loses nothing much for mandating it, but only certain teams will see a lot of value for it. On the other extreme, a startup with five engineers will get backlogged with reviews (which then get shortchanged) because everbody either is under pressure to either stay in their high-productivity flow or put out some pressing fire. The reviews probably could catch issues and share critical knowledge very regularly, but the org pays a pronounced penalty for the overhead and interruptions. People long for \"one size fits all\" rules, crafting essays and publishing research papers to justify them, but the reality of what's right is often far more idiosyncratic. reply kqr 12 hours agoparentI don't disagree with the idea that \"it depends\" but for me, code review has generally worked better with lower overhead in the \"startup with five engineers\" type organisation. Can I ask you some follow-up questions on your experience in reviewing and receiving reviews? If so, send me an email at hn@xkqr.org! reply epolanski 18 hours agoprevMy beef with code reviews is that often they lead to tremendous amounts of wasted time, that's many thousands spent in a single week sometimes for simple pull requests. Working from 6 years, not much, and not in as many places like others, I have built the opinion that code reviews are like tests, they should be used as a tool when they are necessary, they shouldn't be the default for every change. In best case scenarios is the person creating the pull requests that requests reviews or decides the place needs tests. My opinion obviously applies to product software, for libraries, especially when publicly exposed you want as much discussions and tests as possible. reply simonw 18 hours agoparentThis is certainly true for blocking code reviews. I'm interested in exploring the alternative, which is review-after-commit. There's an article describing those here: https://copyconstruct.medium.com/post-commit-reviews-b4cc216... Code still gets reviewed, but you don't end up with PRs languishing for hours, days or even weeks waiting to get a review from someone. reply interactivecode 17 hours agorootparentI review a lot of code with the mindset of yes and… Basically when I start the PR is approved in my head until I find something blocking. I.e. major problem that causes dataloss, big performance issue or breaks other code. Anything else is a minor comment at most. The PR is approved by default. This gives the dev responsibility and ownership. Plus it increases release cadence Doing a follow up PR to improve or fix something is just as fast as blocking the MR, but blocking the MR can be bad for morale. This strategy might work better in young startups where having the feature _exist_ is better than not shipping. in my experience this builds up responsibility and ownership and removes the whole policing of other peoples work vibe around code review. Also decisions and discussion around formatting, when to test, design, features, functionality, architecture should not happen during code review, they should have happened way before coding, or collaboratively while working. Code review is the worst time for that stuff, imho it should be to sanity check implementation. reply pavel_lishin 6 hours agorootparentprevI'd love to explore that alternative, but I'm not sure how to actually make sure that any errors found/changes suggested after the commit is pushed and deployed actually get implemented. reply YZF 15 hours agorootparentprevI used to do a lot of this in a small team where we didn't block on reviews (we did reviews but didn't block). I was a senior developer on the team and I'd take time to read through new sections of code that came in. That worked pretty well. Interesting enough, this bit of code/project, that didn't have super strict code review requirements, but had a lot of tests, is the code I worked on that I would consider the most robust/high quality. It was run by > 10 million users in a fairly important application. It wasn't huge and it had good tests (and was generally quite testable). That said, it's really hard to control review-after-commit. Maybe we need better tooling for that. In my case, for the areas of code I was involved in, it was small enough to track in my head. reply kqr 12 hours agorootparentprevI really like this idea! It's not like I need to check how any individual developer approaches their work (although that could become a useful mentoring session in some cases) but what matters is what it looks like before going into production. The main difficulty I see with the described approach is that different changes will be interleaved in the trunk and it might be hard to extract just one of them to deploy. But that's what feature flags are for! reply closeparen 17 hours agoparentprevThe discipline of putting up small, coherent, explained, tested, and reviewable units of change, that you have looked over and feel comfortable showing off to other people as your work product, is 80% of the value for me. Whether anyone else actually thinks about it deeply or has something useful to say about it is secondary. reply goosejuice 15 hours agorootparentIndeed. It's kind of like rubberducking. reply kqr 12 hours agoparentprevThis is so far from my experience with code reviews that I'd like to ask some questions to follow up on your experience. Do you mind shooting an email to hn@xkqr.org? reply rebeccaskinner 16 hours agoprevI think the article is taking the wrong view. The statistic cited by the article that 15% of comments were about a bug seems in line with expectations, and I think it would only really be worth discussing if the number were _much higher_ or _much lower_. Instead, I think there are two far more interesting questions to ask: 1. Is the rate at which code review identifies defects sufficient to use code review as a detection mechanism for defects? After nearly 20 years of writing software, I'm pretty convinced that the answer here is no. Some reviewers are better than others, and some circumstances are more favorable to finding defects than others, but we should generally try to build processes that don't assume defects will be caught at a substantial rate by code review. It's nice when it works, but it's not a reliable enough way to catch errors to be a load bearing part of the process. 2. Is mandatory review of all code justified? This is the one I'm on the fence about. In an environment where code reviews are high priority, people are trained to review effectively, and there are minimal organizational politics at play, then I hypothesize that allowing PR authors to decide whether to get a review or not would generally improve quality and velocity because code would ship more quickly and code that would benefit from a review would still be reviewed. In that scenario, I think we'd see the benefits of getting things shipped more quickly when they don't require a review, and reviews would be higher quality because code being flagged for review would be a positive sign to pay more attention. Unfortunately, I could be wrong, and it's not the sort of experiment anyone wants to risk their reputation pushing for, so I doubt we're likely to see an experiment at a large enough scale to know for sure. If we're going to fail one way or another, I'd prefer to fail by doing too much code review rather than not enough. reply kqr 12 hours agoparent> After nearly 20 years of writing software, I'm pretty convinced that the answer here is no. Some reviewers are better than others, and some circumstances are more favorable to finding defects than others, but we should generally try to build processes that don't assume defects will be caught at a substantial rate by code review. I think we agree on this but I'd be interested to hear you share more about your experience with reviewing and getting reviews. If you can take the time, please send an email to hn@xkqr.org so I can ask some more questions! reply david2ndaccount 18 hours agoprevIn my experience, code reviews catch a lot of bugs. However, if you find yourself catching the same kind of bugs over and over again in review you should be finding ways to catch them automatically without involving a reviewer (static analysis, tests, linters, etc.) reply cjriley 17 hours agoparentCompletely agree on utilizing static analysis as much as possible. My first instinct when finding an issue in a code review is to think, \"could we have caught this with aof some kind?\" reply bluGill 17 hours agoprevBugs are 'easy' to fix, I don't worry about finding them. I worry about the interfaces as they quickly become a nightmare to change just because of all the users. reply kqr 12 hours agoparentI'd be interested to hear more about your experience with code reviews. Could you send an email to hn@xkqr.org so that I can ask some follow-up questions, please? reply nitwit005 16 hours agoprev> Developers spend six hours per week reviewing. This is a bit too much It's extremely difficult to adjust the time spent on reviews. The options are unattractive. Do you start blindly accepting changes when you hit the limit, or just stop and not let people merge code? reply BlackFly 11 hours agoprevBear in mind I am pro code review, but... There is a trick in pharmaceutical research where you test a potential candidate drug against placebo to yield a bad study that seems to show benefit. The reason it is a trick is because in many cases the alternative isn't placebo, it is an existing treatment. Then doctors learn about a more \"modern\" treatment, favor it for being modern and the better treatment may not be prescribed. The alternatives to code review aren't doing nothing. The article claims that code reviews find a defect per 10 minutes--but only in the first ten minutes. By this same argument (ignore qualifications, extrapolate the numeric result), fast automated testing can potentially find thousands of defects in a second--if they run that quickly and the defects were already tested for. Static analysers, pair programming, documentation these are all alternatives and there are many more. If you're spending an hour a day reviewing code then you are spending 12.5% of your time doing it. Using it that way comes with an opportunity cost that may be better spent depending on your particular organization and code base. Of course, analysing everything to death also has an opportunity cost, but not analysing it generally leads to moving goal posts where the supposed rationale for doing something keeps changing. Today its purpose is uncovering defects, tomorrow it is knowledge sharing, the day after it is security. It is all of those things, but other practices may achieve these goals with more effective use of time and people's patience. So why am I pro code review? Because choosing to interact and work together as a team, to learn about and compromise with your colleagues makes for good team building while serving other technical purposes. I do think that pair programming can achieve this to a greater level while also being more taxing on individuals. This assumes you control the process and own it though, if it has just become a rote ceremony then my feelings are you probably aren't net benefitting from it: you are simply doing it because you have no choice, not because you believe it to be a valuable use of time. If you have experienced both, a culture where people choose and find value in code reviews and a culture where people are forced to do it unquestioningly, then you may have witnessed how a dicta can destroy the prosocial value of a practice. reply mgreene 17 hours agoprevThe paper's title is a bit provocative but I think the findings are interesting. Mainly around long-held beliefs about what developers perceive as the value vs what is actually happening. You do bring up a good point about using change defect rate though. I wish the researchers had cited that as the preferred unit of measurement. I did some research on change defect rates on popular open source projects and it's all over the map. Ranging from ~12 - ~40% [1]. The future I'd like to see is as developers we use objective measures to justify time investment for review. This is going to be increasingly important as agents start banging out small bug-fix tickets. [1] https://www.shepherdly.io/post/benchmarking-risk-quality-kpi... reply sys_64738 17 hours agoprevThere are various levels to code reviews. Code review tools that are web based are pretty poor in my experience. Anything more than a few lines across multiple files needs a cscope type tool. Also what type of review? Is this a prototype needing a high level design review so that the actual review doesn’t turn into a design review? How often does that occur? Who are the reviewers and what’s the process? Key stakeholders have more influence and you need to consider the reviewer’s experience, knowledge and credibility. Finally how important is the code? Is it kernel code, or high execution daemon code needing race condition and memory leak checking? Are you using static analysis for the code? Does the code even compile and do what it is designed to do? Where are the unit test logs? Lots to consider. reply andirk 16 hours agoprevTechnical debt. Keep it minimal, and when needed, write a task for it to be looked in to later. Coding standards. Don't submit code that has rando extra lines and things that will slow down the next dev from looking in to the past to learn what does what. And most of all, make sure edge cases are covered, often via a truth table of all possible outcomes. I often comment on a PR saying \"blah blah, but not blocking\" so I'll allow it but at least my entitled opinion was known in case that code issue comes up later. My PRs take a long time, because I dig the F in. reply robertclaus 15 hours agoprevI find many standard processes can be described similarly - if you're mindful of what problem they solve, they should be incredibly useful. The tricks are the important but subtle details like not spending 2 hours straight reviewing an excessively long PR. Those are easy to forget once it's just part of the process. reply jonobird1 16 hours agoprevI'm not sure code reviews hold much merit. I've been a web developer for around 12 years and I've worked in companies big and small. I think there should be a manual QA process to test the functionality of what the developer is pushing out. The issue with code reviews is always that they take so much time for another developer and many devs are super busy so they just have a quick review of the PR and approve or feel they have to add some comments. Context switching between what the dev is already doing and having to come to the PR to review properly means they should switch to that Git branch, pull down the code, test it all and check for logical bugs that a static code review won't pick up. For juniors, code reviews are still useful as you will be able to spot poor quality code, but for seniors, not as much for the reasons above, better off having a QA process to find and logic holes rather than expecting devs to invest so much time in context switching. reply hakunin 16 hours agoparentThe problem here is not that developers are too busy, but that code reviews are considered second class citizens to churning out new code. It's like saying \"many devs are super busy working on feature A so they just write quick and dirty code for feature B\". If reviews are integral part of feature production pipeline, there should be no issue to sit down and spend a day reviewing code. For bigger, more complex things it could be a few rounds of reviews. There is an approximate non linear relationship between time it takes to produce the first PR and time it takes to go through all rounds of review. This time can be pretty reliably calculated and taken into account. reply kqr 12 hours agoparentprevI'm a little surprised to hear this. Would you mind sending an email to hn@xkqr.org so that I can ask some follow-up questions, please? reply skywhopper 16 hours agoparentprevNah, automated testing cover basic functionality. For most PRs, a senior familiar with the code wouldn’t need to check it out and manually test anything, that’s not what “code review” is most of the time. If you need them to look at the code in a running state, that should be part of the CI process, not a manual task for the developer. A good reviewer can call out bad strategic coding decisions or misinterpretations of the requirements. QA is another layer of review entirely. reply sarchertech 18 hours agoprevI remember a time before you needed an approval to merge a PR (I also remember a time before PRs or any widespread version control system). I can count on one hand the number of times someone has caught a bug in my code that should have stopped deployment. Not that I haven’t deployed serious bugs to deployment, but they’ve almost never been caught by someone reviewing my code. Occasionally someone suggests a better way to do something, or asks a question that ends up with me coming up with a better way of doing something. But those situations are also rare. And I can’t think many times at all when the impact was worth the time spent on the process. Pair programming and collaboration can be hugely beneficial, but the minimal effort PR approval culture we’ve developed is a very poor substitute. reply dgb23 18 hours agoparentBoth code reviews and pair programming can be very useful if they serve a specific purpose. Getting someone up to speed with unfamiliar code, disentangling hairy code so it becomes clearer, hunting down bugs or finding unknown unknowns such as bugs or unnecessary complexity. However in many cases not looking at the screen when doing these kinds of things is more helpful. It's often more beneficial to build a mental model in your head and then riff off each other. Rather drawing things on a board or writing down stuff in a markdown file, explaining things in simple terms, than actually coding or reading actual code. Not sure if that still counts as pair programming or code reviewing but this free form way of talking about code is very effective. reply kqr 12 hours agoparentprevIt certainly sounds like you write seriously high-quality code! And judging from your profile, I'd be inclined to think you know what you are talking about. I'd like to ask a little more around your experience here. Do you mind sending an email to hn@xkqr.org so that I can ask some follow-ups? reply wrsh07 18 hours agoparentprevI've caught bugs in reviews, but even better I've requested tests and those tests have caught bugs Even a low effort code review can identify missing unittests reply 29athrowaway 17 hours agoprevIf you have a spellchecker, code formatter and a linter, code reviews improve significantly. Much better than having to do that work by hand, or reviewing it by hand, leaving code reviews for higher level ideas. reply zelos 11 hours agoparentExactly. Code reviews shouldn't be about code formatting or anything that can be automated away with linters, formatters, code coverage limits and static analysis. If the build is green for the PR, then all that is already acceptable. reply Mathnerd314 17 hours agoprevMy question is, do human reviewers find more bugs than ChatGPT? Because finding a cofounder costs a lot but asking ChatGPT is free. https://www.thatsoftwaredude.com/content/12848/chatgpt-can-d... says it is mediocre, but that was a year ago and honestly mediocre code reviews seem sufficient. reply sriharshamur 13 hours agoprevWhat are some amazing blogs/resources to read to learn how to review PRs? reply bigcat12345678 15 hours agoprevHah? Code review of cuz finds bugs... It's like people do see... reply some_furry 17 hours agoprev> During the first 60 minutes of code review of the day, the reviewer finds roughly one defect per ten minutes of reviewing – as long as they review less than about 50 lines of code per ten minutes. Oh. It normally takes me a few seconds to find bugs in code. I always felt this was average performance for assessing software. If the average time is ten minutes per defect, I need to recalibrate my expectations for myself. reply jonobird1 16 hours agoparentIt really depends on the code. To find a CSS bug, yes easy peasy. To find a logic hole in a payment integration of what someone has missed or should have implemented but didn't (eg webhooks), then this requires a lot more time and the developer basically has to sit down properly to work out exactly what should have been implemented / how they would have developed it, and then cross-check it against what has been done, otherwise you won't be able to easily find those logical holes which effectively are bugs, just not simple code bugs like a missing semicolon. reply some_furry 16 hours agorootparentMy day job is auditing cryptography. I'd probably be slower to find the root cause of a CSS bug than most of the folks that read HN. :3 reply lazyasciiart 16 hours agoparentprevPresumably you understand that how long it takes to find bugs in code depends on the code. If not, then I hope you've read the code for Linux and SSL, etc. reply some_furry 16 hours agorootparentYes, of course it depends a lot on context. I've never had an incentive to read the Linux kernel code. I routinely find and disclosed cryptography library bugs, though usually mostly hobby projects like the \"I thought it would be cool if there was a PHP implementation of GHASH\" sort rather than like OpenSSL. reply grumple 16 hours agoprevI find things wrong with virtually every nontrivial pull request when I’m the reviewer. Sometimes these are minor issues, but I spot bugs and edge cases all the time. I see some comments about time. How long does a code review take? I can review hundreds of lines of code in a few minutes. It is much easier to review code than to write code imo, especially as you gain experience. For bigger efforts, get eyes on it throughout the process. I’ve met a lot of developers who assume their code will just work right after they write it. They don’t test it, via code or manual qa. Then they act surprised when the stakeholder tells them it doesn’t work. Do the job right the first time. Slow is smooth and smooth is fast. reply farmeroy 15 hours agoparentI'm always surprised how often I get a pull request which either doesn't build or has failing unit tests or both. These are pretty easy to address at least - but when I think that certain code might be difficult to maintain, be an anti-pattern, or possibly present bugs in non-obvious ways, I find it really hard to effectively address those issues and often end up doubting my own suggestions reply aitchnyu 11 hours agoparentprevWhen I was working with Django, those who added code ran it in their systems. With lambda, which we mostly deploy and test in the cloud, people tend to dump code and leave. reply alex_lav 18 hours agoprev [–] Code reviews can find bugs. More often, code reviews become opportunities for team members to bikeshed. Worse, an opportunity for a non-team member to exert power over a project. reply spankalee 18 hours agoparentBikeshedding in a team can be good. If you're all painting the shed, it helps to agree on the color. More generally, code review is a great opportunity for incrementally gaining or encouraging alignment across the team. What the team chooses to align on and how strongly are left up to it, so hopefully they choose to not get bogged down in inconsequential details, but completely skipping the pretty cheap chance for reenforcing all kinds of cohesion would be a big mistake in my opinion. reply alex_lav 17 hours agorootparentYou're making a lot of positive-upsided assertions about code review. My point is there is too much opportunity for negative behavior. It's the same as everything in tech, in life, \"It can be good if everyone does their part to keep it good\". And yet, most don't. reply spankalee 17 hours agorootparent\"most don't\" is a strong claim. In my experience, core review has been undoubtedly good. I would never run or join a company without it. I'm writing code solo for the moment, and code review is maybe the thing I miss the most. reply alex_lav 17 hours agorootparent> \"most don't\" is a strong claim. I'm happy to be reasonable. I guess my greater feeling is that most devs aren't great at identifying when they should identify restraint. For the same reason that most devs are abysmal interviewers, I think devs forget that code review is ultimately a human endeavor. Give your average dev the smallest amount of power and not enough guardrails and legitimate silliness ensues. > I'm writing code solo for the moment, and code review is maybe the thing I miss the most. I feel as though \"code review\" is taking on too many meanings in this conversation. Code review in the form of a second (or more) qualified dev reading and commenting on code for the greater good? Obvious good. Code review in the form of github PRs at a non-FAANG company? Skip it. Kangaroo court. reply sadops 16 hours agorootparentprevnext [2 more] [flagged] alex_lav 14 hours agorootparentSenior team members are usually the worst offenders. reply sadops 16 hours agoparentprevFrom where I sit, it's usually the people writing the bugs who are so averse to code reviews. reply alex_lav 3 hours agorootparentEveryone that writes software writes bugs. reply 29athrowaway 17 hours agoparentprev [–] Code reviews can be an opportunity for sabotaging performance or for dominance. I have seen it numerous times. Conspiracies to delay code reviews for high performers in stacked ranking organizations is common. They can also be ruined by having the not rotating the reviewer role among eligible reviewers in the team, in that case, everything just represents the opinion of a specific group. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The 2015 Microsoft research titled \"Code Reviews Do Not Find Bugs\" claims that only about 15% of code review comments indicate possible defects, but this statistic is misleading.",
      "Previous research indicates that code reviews and pair programming can find an additional 60% of defects with only a 15% increase in time investment, especially effective on small code chunks.",
      "The Microsoft paper's thesis is contradicted by evidence showing code reviews' effectiveness in defect detection and learning the codebase, with the real issue being the median review turnaround time of 24 hours."
    ],
    "commentSummary": [
      "Code reviews are effective in identifying bugs, tech debt, and code smells, contributing to a more maintainable codebase.",
      "The discussion highlights the importance of building a supportive code review culture, including practices like using feature flags, breaking down changes into smaller parts, and setting clear expectations.",
      "The debate includes various perspectives on the efficiency and necessity of code reviews, with some advocating for alternatives like pair programming and automated testing to complement or replace traditional reviews."
    ],
    "points": 174,
    "commentCount": 130,
    "retryCount": 0,
    "time": 1719876193
  },
  {
    "id": 40856791,
    "title": "Ladybird Web Browser becomes a non-profit with $1M from GitHub Founder",
    "originLink": "https://lunduke.locals.com/post/5812560/ladybird-web-browser-becomes-a-non-profit-with-1-million-from-github-founder",
    "originBody": "Sign up to Follow Lunduke Lunduke News • Science & Tech Sign up to Follow Lunduke Ladybird Web Browser becomes a non-profit with $1 Million from GitHub Founder The \"From Scratch\" browser is preparing to take on Mozilla & Google Bryan Lunduke July 01, 2024 The original founder of GitHub (Chris Wanstrath) has partnered up with the founder of SerenityOS and the Ladybird web browser (Andreas Kling) to create \"The Ladybird Browser Initiative\" -- a USA-based non-profit dedicated exclusively to building a brand new web browser. From scratch. While many have claimed that developing a new web browser \"from scratch\" is an impossible goal, the founders of The Ladybird Browser Initiative believe they can do it. What's more, they are confident it can be done without taking any funding from corporate deals or advertising revenue. Their goal? To have a fully functional \"Alpha\" version of the Ladybird browser ready sometime in 2026. Ladybird Funding Roughly one year ago, the Ladybird Browser received their first major sponsorship ($100,000 from Shopify). Now, with the creation of a 501(c)(3) non-profit (accompanied by a $1 Million dollar pledge from the GitHub founder), Ladybird is preparing to become the only major web browser which does not treat the user like the product being sold. \"Today, every major browser engine is open source, which is wonderful, but there's still one issue: they're all funded by Google's advertising empire. Chrome, Edge, Brave, Arc, and Opera all use Google's Chromium. Apple receives billions to make Google the default search engine in Safari, and Firefox has a similar deal where they receive hundreds of millions each year. The world needs a browser that puts people first, contributes to open standards using a brand new engine, and is free from advertising's influence.\" The fact that every major web browser engine is funded by advertising (specifically, via Google) is, indeed, a concern -- which makes the idea of a web browser free from that influence incredibly interesting. But how, exactly, is Ladybird going to pull this off? \"Unlike traditional business models that rely on monetizing the user, Ladybird is funded entirely by sponsorships and donations from companies and individuals who care about the open web. Our non-profit will not pursue corporate deals or revenue outside of unrestricted donations. The software and its source code will be available for free, forever.\" While it's easy to dismiss the notion of \"funding a web browser via donations\" as an unachievable, whimsical goal... Ladybird has already had some significant success in that area (not least of which, the $1 Million dollars from the GitHub founder), resulting in Ladybird already having 4 paid, full time developers (with 3 more programmers \"starting soon\"). So, maybe this approach is not as \"unachievable\" and \"whimsical\" as it first seems. No Corporate Control Also fascinating is this statement: \"Our non-profit will not pursue corporate deals or revenue outside of unrestricted donations.\" What does that mean, in practice? It means Ladybird won't be doing corporate deals for default search engines. Or marketing campaigns for other companies. This means that, if they can stick to their guns, Ladybird stands a real chance of a truly independent web browser... one which no company can control. In fact the Ladybird Browser Initiative even has a policy specifically not allowing corporate donors to buy board seats: \"All sponsorships are in the form of unrestricted donations. Board seats and other forms of influence are not for sale.\" This is a huge deal. Massive. A problem many non-profit foundations face is corruption of their core mission via corporate control of their boards. There are many examples throughout the Open Source world of exactly this sort of problem (looking at you, Linux Foundation), and to see Ladybird recognize this problem -- and take action to prevent it -- right from the start? Color me impressed. The Current Status The first public \"Alpha\" release of Ladybird may be a ways out (slated for 2026), but the current development versions are already quite far along. \"We can already do some of our daily browsing with Ladybird, like managing GitHub issues and pull requests, and commenting on Hacker News. The browser is improving every day, as our community of contributors are actively fixing bugs and adding features.\" Testing of a recent build of Ladybird confirmed that statement. Many websites function perfectly -- including some quite complex sites. While many other websites were... less than functional. Lots of work has clearly been done, with lots more left to do. Can the development team improve Ladybird to a point where it will be usable, as a primary web browser, some time in next few years? Considering the progress to date... it seems entirely possible. \"We won't be chasing buzzwords\" The Lunduke Journal reached out to The Ladybird Browser Initiative's co-Founder, Andreas Kling, with a burning question... Now that the Ladybird web browser has an official nonprofit, with multiple full time developers working on it, you are clearly moving towards direct competition with the likes of Google and Mozilla. The eye of Sauron is upon you. How does that feel? Kling's response: \"Feels great! The web is one of humanity's greatest inventions, and it deserves diverse, competing implementations to truly thrive. The industry has been heading in a troubling direction for years, with companies like Microsoft and Opera abandoning their own browser engines in favor of Chromium. We obviously don't have the resources of companies like Google, Apple, and Mozilla, so things will take some time. However, I'm extremely optimistic about the road ahead. We have a fantastic community of developers working on Ladybird, and we're making solid, consistent progress. One thing we have going for us is focus. Unlike the major players, we're *completely* focused on one thing only: the web browser. We won't be chasing buzzwords or looking for alternative revenue streams. Our goal is to build a good browser and give it away for free, while soliciting nothing but unrestricted donations from anyone who likes what we're doing.\" There's a lot here to be excited about. No chasing buzzwords. No alternative revenue streams. Total focus on the web browser. A brand new, from scratch browser engine. No advertising or Big Tech influence. A rag-tag team of rebels going, toe to toe, with the Big Tech web browser makers. While, according to the Ladybird team, they are a ways off from a major public release... it's hard not to feel a bit optimistic about what this could mean for the future of web browsing. This may be early days still, but the possibilities are tantalizing. The Lunduke Journal is rooting for you, Ladybird. Join the Lunduke Community To read more articles like this, sign up and join my community today Sign Up 40 14 What else you may like… Videos Podcasts Posts Articles Bryan Lunduke@Lunduke July 01, 2024 Watch Out Firefox & Chrome: Here Comes Ladybird Ladybird Web Browser becomes a non-profit with $1 Million from GitHub Founder. The \"From Scratch\" browser is preparing to take on Mozilla & Google. The Article: https://lunduke.locals.com/post/5812560/ladybird-web-browser-becomes-a-non-profit-with-1-million-from-github-founder 00:35:27 36 10 Reply Bryan Lunduke@Lunduke June 29, 2024 Open Source is not Socialism (or Communism) No. Free Software and Open Source Software are not Socialist or Communist in nature. If anything, Open Source is a distinctly Capitalist concept. 00:11:09 33 82 Reply Bryan Lunduke@Lunduke June 29, 2024 Keep Big-Tech-Free Tech Journalism Alive The Lunduke Journal covers the stories that no other Tech News outlet is willing to touch. From major leaks from IBM, Red Hat, & Microsoft -- to in-depth investigations into Mozilla, Wikipedia, and The Linux Foundation -- many stories only get covered by The Lunduke Journal. Subscribe Here (with a discount through July 4th): https://lunduke.locals.com/post/5786973/subscribing-to-supporting-the-lunduke-journal 00:15:50 17 5 Reply Bryan Lunduke@Lunduke November 22, 2023 The futility of Ad-Blockers Ads are filling the entirety of the Web -- websites, podcasts, YouTube videos, etc. -- at an increasing rate. Prices for those ad placements are plummeting. Consumers are desperate to use ad-blockers to make the web palatable. Google (and others) are desperate to break and block ad-blockers. All of which results in... more ads and lower pay for creators. It's a fascinatingly annoying cycle. And there's only one viable way out of it. Looking for the Podcast RSS feed or other links? Check here: https://lunduke.locals.com/post/4619051/lunduke-journal-link-central-tm Give the gift of The Lunduke Journal: https://lunduke.locals.com/post/4898317/give-the-gift-of-the-lunduke-journal The futility of Ad-Blockers 21 25 Reply Bryan Lunduke@Lunduke November 21, 2023 openSUSE says \"No Lunduke allowed!\" Those in power with openSUSE make it clear they will not allow me anywhere near anything related to the openSUSE project. Ever. For any reason. Well, that settles that, then! Guess I won't be contributing to openSUSE! 🤣 Looking for the Podcast RSS feed or other links? https://lunduke.locals.com/post/4619051/lunduke-journal-link-central-tm Give the gift of The Lunduke Journal: https://lunduke.locals.com/post/4898317/give-the-gift-of-the-lunduke-journal openSUSE says \"No Lunduke allowed!\" 42 24 Reply Bryan Lunduke@Lunduke September 13, 2023 \"Andreas Kling creator of Serenity OS & Ladybird Web Browser\" - Lunduke’s Big Tech Show - September 13th, 2023 - Ep 044 This episode is free for all to enjoy and share. Be sure to subscribe here at Lunduke.Locals.com to get all shows & articles (including interviews with other amazing nerds). \"Andreas Kling creator of Serenity OS & Ladybird Web Browser\" - Lunduke’s Big Tech Show - September 13th, 2023 - Ep 044 25 9 Reply Bryan Lunduke@Lunduke 15 minutes ago 6 1 Reply ArchieT@ArchieT 6 hours ago I got an advertisement in the mailbox.... Save $1000 off your next phone ... yada yada.. geez! if I'd spent so much on a phone that I could save $1000, I'd be compelled to stare at it constantly, too! 11 3 Reply MGaddict@MGaddict 6 hours ago Hi folks, I'm back... Sorry, I've been out for a while and haven't had time to post or keep up. But, I'll do better. In News from yesterday.... Cedar Fair now has control of Six Flags Entertainment. The merger will still use the name Six Flags, but will trade under the Cedar Fair stock FUN. It will also be run by the Cedar Fair C suite. (It's not computer nerdy. I know.) I had a chance to sit with a sales rep for Red Hat Linux this week. He talked about how bad Red Hat had done a terrible job with messaging around the pull of the source code, and the only thing he hated about it, was that he can't talk about it. But he said they were making major changes to Fedora and Centos which should be released and announced later this year if they can get their act together. He basically implied that Fedora was going to be the feeder for RHEL, a place to test features and whatnot, and completely open sourced. Centos was going to be an identical copy of RHEL so developers don't have to sign up ... 8 4 Reply Bryan Lunduke@Lunduke 14 hours ago Don't wave the LGBT flag? SUSE & openSUSE says you are \"Rotten Flesh\". Wave the Pride Flag or else... Linux company hopes you are \"unwelcome\" everywhere. The following article was originally published on May 28, 2023 in a different publication. While the topics covered are extremely political and polarizing -- these events and statements, by significant organizations within the computer industry, are important to record. As such, this article is being re-published here, on The Lunduke Journal. Both openSUSE and SUSE have a long history of discrimination against those with Conservative-leaning values. The recently departed CEO of SUSE famously equated \"Conservative\" and \"Right Wing\"... with \"Biggoted\". And openSUSE (which is funded and controlled by SUSE) seems to be continuing in that tradition. Since deleted Tweet from Di Donato, SUSE's ex-CEO. I'm documenting it here as one example -- of oh-so-many -- of the types of discrimination happening throughout the open source and Linux world right now. NOTE: I spent several years working at SUSE -- and was elected to the openSUSE Board. I left both multiple years ago, and no longer have any affiliation with either SUSE or openSUSE. In a recent post to one of the openSUSE mailing lists, someone raised their concern about usage of the \"LGBTQ\" flag colors used with the openSUSE Subreddit: This reads to me to be a fairly level headed raising of an issue. And, as stated, the goal of the email was to modify imagery in order to \"make the [openSUSE] subreddit more welcoming to everyone, regardless of their background or beliefs.\" What does the LGBTQ image in question currently look like? It looks like this: The notion that this imagery should be changed appeared to be supported by a number of people. With some pointing out that openSUSE has a tendency to only celebrate one \"group\"... at the exclusion of all others: \"It seems that you have forgotten to celebrate programmer's day, volunteer's day, mother's day, father's day, worker's day, women's day, families' day, ... :-(( Celebrating one day and not others is not very inclusive :-( Celebrating many days would mean creating more images, thus more work. Another option would be not celebrating any day, except for openSUSE's birthday :-)\" Again. You'll note the message is level-headed, kind, and in no way attacking of any specific group. So. How did openSUSE and SUSE leadership respond to these issues being raised? Not. Well. Here, Lars Marowsky-Bree, a high level employee at SUSE, stated that he is \"quite happy to not be welcoming to those who feel offended by rainbow colors.\" Atilla Pinter (openSUSE Board Member), chimed in with the following: \"the rainbow logo proved to be a great way of filtering out toxic individuals with a non-inclusive, disrespectful behavior early on, this is not a secret\" \"And here's another misunderstanding, we will absolutely __NOT__ tolerate you.\" Whew! Intense! A clear statement, from openSUSE leadership, that they will \"not tolerate\" people who raise concerns about the rainbow flag usage. Interestingly, that same openSUSE Board Member (Pinter) went on to declare the following: \"last I checked for example Christianity wasn't facing much oppression in the world, and didn't require much (if any) support\" According to reports from 2022, 360 million Christians faced extreme levels of persecution, world-wide -- with close to 6,000 killed specifically for their faith. Do several other groups experience persecution? Heck yes, they do. (I'm Jewish, I've seen a lot of that first hand.) But to claim that Christians do not face \"much oppression\" and don't need \"any support\" is ridiculous and shows a clearly biggoted, biased view of the world. Doesn't stop there. Yet another openSUSE Board Member (Gertjan \"Knurpht\" Lettink) wrote this gem: \"Wanna be a bigot, a homophobe, then this community is not for you. If that means loss of users, so be it. Cutting out the rotten flesh is healthy. And needs to be done rather yesterday than tomorrow. Their membership needs to be revoked, they need to be banned, not moderated. The colors are about including people, with full respect for their being who they are. If you can't bring yourself to that, [CENSORED] off, find yourself some excluding \"community\".\" Holy smokes. Rotten flesh! In other words: If you don't pledge total loyalty to the LGBT flag, you are \"rotten flesh\" and you need to be banned from the openSUSE community entirely. Accompanied by some intense swearing. And, you'll note, this was in response to emails that were simply expressing a desire to not actively fly the \"Pride Flag\". And this is from the openSUSE leadership. The people with total control over moderation and project membership. One of those openSUSE community members who politely raised concerns about the LGBT flag usage responded -- again, rather reasonably -- with this: \"Rotten flesh. So I am rotten flesh that needs to be cut out to you. That's quite the insult. Are insults permitted under your precious code of conduct? Or are some insults just more equal than others? Either way, this does not feel very inclusive to me.\" At which point, Richard Brown -- SUSE employee, and past openSUSE Board Chairman -- got into the mix: \"yes, rotten flesh is a perfectly apt description\" Yowza. Both openSUSE and (parent company) SUSE are doubling down on the whole \"if you don't actively praise the LGBT flag, you are rotten flesh\" stance. He continued: \"I really don't care where they go, as long as it's not anywhere with openSUSE in the name. Ideally, I would hope they find that every other Linux, open source, and free software community is equally unwelcoming to them\" Once again... Are you Conservative? Don't pledge your allegiance to the LGBT flag? You are not welcome with openSUSE... and SUSE leadership hopes that you will not be welcome anywhere in the Linux or open source world. SUSE and openSUSE leadership says that openly, proudly, and repeatedly. Then one of the very highest ranking individuals within SUSE -- the CTO himself, Gerald Pfeifer... who also serves as the self-appointed openSUSE Chairman of the Board -- chimed in: Which messages will be moderated? What actions will be taken by the openSUSE Board? Based on what we've seen from both SUSE employees and the openSUSE Board (who, again, view most conservatives as \"Rotten Flesh\")... my guess is that no action is going to be taken against the cruel, biggoted, profane attacks by his own team against the conservatives within the openSUSE community. At which point, as the number of messages raising concerns about these aggressive, mean-spirited, biggoted attacks -- almost entirely from SUSE employees and openSUSE leadership, targetting the conservative community members -- began to increase... The mailing list was locked down. And then, just in case people might complain about that sort of discrimination against conservatives in other places, the other primary openSUSE mailing list was locked down as well: If you are Conservative... remember that SUSE and openSUSE considers you to be \"Rotten Flesh\"... and that you must be silenced and banned. Their words. Repeated and confirmed by their leadership. Is this the only example of such attacks on those with \"Conservative values\" in the Tech world? Oh, heck no. Unfortunately, this sort of thing happens with regularity. Update In the days the followed the original publishing of this article, many Conservatives were banned from participating within the openSUSE project -- including mass bannings in the openSUSE mailing lists, sub-Reddit, and other systems. The Lunduke Journal received numerous emails from long-time openSUSE members who were banned -- in many cases without warning -- after making a statement that was not sufficiently, enthusiastically positive regarding the \"Pride Flag\". This wave of banning included yours truly. Which is fascinating, considering my history with SUSE. A former elected Board Member of openSUSE. One of the highest profile employees in SUSE history. In fact... for several years, my name was so intimately tied to the SUSE and openSUSE brand that SUSE corporate issued a press release on the day I left the company. 2017 press release from SUSE But I, like so many others, did not actively waive the Pride Flag. This was an unforgivable offense. Punishable by banning, and a formal declaration of being \"Rotten Flesh\" who should not be welcome in any other \"Linux, open source, and free software community\". To date, neither SUSE nor openSUSE has changed their \"Rotten Flesh\" policy... and none of the banned conservative contributors -- none of which, to my knowledge, made any discriminatory statements -- have been allowed to rejoin the project. Read full Article 15 10 Reply Bryan Lunduke@Lunduke June 30, 2024 Last week at The Lunduke Journal (June 23 - June 29, 2024) Microsoft Write! Computers in 1961! Ridiculous Amounts of RAM! Socialism! This week I decided, on a bit of a whim, to publish the 2024 edition of \"Linux Sucks\" over on YouTube. Of course, all of you on Lunduke.Locals.com have had that show since February (along with every other version of Linux Sucks, from every year). But, hey. Gotta throw a bone to the YouTube die-hards every now and then, right? 😎 Also, this week, we got to spend time talking about both Microsoft Write running on an Atari ST... and Socialism. So, all in all, I'd call it a good week. The Videos How much RAM will you need in 5 years? Lunduke's Nerdy Q & A - June 26, 2024 Open Source is not Socialism (or Communism) The Articles Funny Programming Pictures Part XLVI Lunduke Computer Operating System Status - June 28, 2024 A tour through computing in 1961... over 60 years ago Microsoft Write - The First Word Processor for Windows (ported to Mac... and Atari ST) Previous Few Weeks June 16 - June 22, 2024 June 9 - June 15, 2024 June 2 - June 8, 2024 May 26 - June 1, 2024 May 19 - May 25, 2024 May 12 - May 18, 2024 May 5 - May 11, 2024 Reminder: Check out The Lunduke Journal Link Central page for all the handy URLS. Podcast RSS feeds, contact info, direct links to some of the big shows and articles and a bunch of other goodies. And be sure to subscribe to The Lunduke Journal to help support the work... and make sure you don't miss out on anything. Read full Article 6 0 Reply Bryan Lunduke@Lunduke June 28, 2024 Funny Programming Pictures Part XLVI Make fun of Kubernetes... or make fun of Docker? Why not both! If they had someone with heart, they could become Captain Planet. It's too big a risk. Just shoot. Is the C programming language in the room with us now? I like this one because it is making fun of CSS. Fools, I say! To be fair, I was probably drunk when I coded that part. FOOLS! Don't do it. It's a trap! Hoisted by thine own petard! It's funny because it's terrifying. \"Lol! What moron wrote... Oh.\" Success! After reading this comic strip, I need to curl up and have a good cry. [Insert observation about the 1980s here.] srand() is a lie. Read full Article 25 9 Reply See More Sign Up To Lunduke Sign Up for free to see more from this community or subscribe to Lunduke for $6/month to support Lunduke for more interaction and exclusive content. Login Signup Available on mobile and TV devices Powered by Locals",
    "commentLink": "https://news.ycombinator.com/item?id=40856791",
    "commentBody": "Ladybird Web Browser becomes a non-profit with $1M from GitHub Founder (lunduke.locals.com)153 points by mapper32 4 hours agohidepastfavorite347 comments szastamasta 2 minutes agoAs much as I would love to see this succeeded, I simply cannot believe that you can sustain a browser development without millions of dollars. Web got so complicated. And it's perfect for all these huge ads companies owning browser engines. Nobody can catch up with this. There's only one way we can make sure we can get really independent browsers: SIMPLIFY THE WEB - Limit the platform to absolute minimum - give way to render things, fetch stuff from the network, etc. - Get rid of CSS - leave just some basic rendering primitives, so libraries can be created to paint on the canvas. We don't need 78 new animation primitives. We'll build them ourselves if we have a sensible canvas and execution platform. - Move JS out of the browser to a WebAssembly compiler and make browsers run only WebAssembly - Or keep JS in the browser but don't add any new features, features should be in libraries outside of the browser. Language should be as simple as possible. - Get rid of all semantic html junk. We only need some basic blocks to move things around. This way we can have simple browsers and move all complexity to client libraries, which you can pick and replace when needed. Just keep things as simple as possible and let people build on that. (updated whitespace) reply awesomekling 8 hours agoprevHello friends, Ladybird founder here! Here's a short video from Chris Wanstrath announcing our non-profit yesterday, and kicking things off with a $1M donation: https://www.youtube.com/watch?v=k9edTqPMX_k Happy to answer questions :) reply account42 6 hours agoparentSeeing someone ignore the naysayers and attempt the so-called impossible task of developing a new independent browser is awesome to see. It brings a glimmer of hope that the internet is not doomed to be ruled by advertising companies with only a stagnant controlled opposition browser as the alternative. That said, Ladybird is obviously far from becoming the daily driver for the average webizen. What do you think is going to be the first milestone where Ladybird is going to be able to be a real alternative (even if limited to certain use cases) and in what timeframe do you think this can be accomplished? Also, do you already have any plans or ideas for how to improve the web browsing experience beyond what existing browsers provide or is your focus entirely on the engine catching up for now? reply awesomekling 5 hours agorootparent> What do you think is going to be the first milestone where Ladybird is going to be able to be a real alternative (even if limited to certain use cases) and in what timeframe do you think this can be accomplished? At the moment, we are focusing primarily on our own use cases as developers, since those are the easiest to test and qualify. So websites like GitHub, web specifications, MDN, etc. are likely going to be very high fidelity before other parts of the web catch up ;) > Also, do you already have any plans or ideas for how to improve the web browsing experience beyond what existing browsers provide or is your focus entirely on the engine catching up for now? We are definitely focused on the engine catching up right now. There is an incredible amount of work to do, and we're doing the best we can :) reply acedTrex 58 minutes agorootparentI think thats a very smart plan, get the websites that devs frequent up and running relatively reliably to help drive more dev use and therefore more willing contributors. reply Ygg2 23 minutes agorootparentprev> Seeing someone ignore the naysayers and attempt the so-called impossible task of developing a new independent browser is awesome to see Well the impossibility isn't so much in making a browser but making a browser that manages to get a chunk of web audience. That means presence on mobile, feature and performance parity with Chrome, surprasing Chrome on some level (e.g. Safari having better vendor lock-in). reply vrinsd 15 minutes agoparentprevHi Andreas, First, thanks for this project and making your self accessible! Will \"plug-in\" or \"add-on\" support be a first-party concept in Ladybird? I ask that because in years past a few other browsers (Konqueror, Falkon, Dillo, etc) made it pretty far but lacking add-ons, useful capability such as 'NoScript' or 'uBlock' or even a tab manager made them non-starters. reply jchw 5 hours agoparentprevI don't have much to add here, just wanted to say that I think this is a tremendous gift to the Internet that we loved. It would suffice to say that after many hard reality checks I don't really feel like there are any browser vendors that feel like good stewards of the open web, and it seemed like a new browser that actually managed to break out would be infeasible... until Ladybird showed up. And now, I'm typing this reply in Ladybird. Of course, it has a long way to go before it is going to be a good daily driver, but I truly believe this is the beginning of something great. I've been consistently surprised by what works, and the rate of improvement is staggering at times. My question: Has anyone given any thoughts regarding the stance to take with DRM features, e.g. Widevine/Encrypted Media Extensions? It seems like since our previous stewards of the open web didn't care enough, now making a browser with substantial marketshare without this may be hard. Seems like a hard problem, I really do wonder where Ladybird will stand if it continues on its current lightning fast trajectory. reply F3nd0 8 hours agoparentprevCongratulations on the kick-off! Now that Ladybird is no longer a part of SerenityOS, will you consider a switch to a licence which not only grants, but also protects user freedoms (e.g. the GPL, MPL, EUPL)? Also, any thoughts on having official communication channels on some open, freedom-respecting platforms, rather than Discord only? reply awesomekling 7 hours agorootparentThanks F3nd0! There are currently no plans to switch to a less permissive license. And we're perfectly happy using proprietary services like GitHub and Discord as long as they make our work easier and more enjoyable. We recently evaluated a number of alternatives, and found that they all introduced more friction than we were comfortable with. Although the task of building a browser is itself challenging, we're a pragmatic project :) reply dataflow 7 hours agorootparent> There are currently no plans to switch to a less permissive license. Hey, just a reality check: in the event that you actually do become wildly successful, this means that others (Google, Microsoft, etc.) will be able to fork the browser and then develop it faster than you - thus leaving you behind and taking away your users! Would highly recommend leaving yourself some mechanism to prevent that, unless you're really okay with the project defeating itself through its own success. reply awesomekling 7 hours agorootparentYes, we are aware of how permissive licenses work. If someone forks our code and does a better job with it than we do, fair game. :) reply dataflow 7 hours agorootparentNote they won't have to do a better job in the long run, just a good enough job in the short run to leave you behind. But yeah, as long as you're keeping this in mind :) best of luck! reply freehorse 6 hours agorootparentNot even that sometimes, browser popularity can just be a matter of advertising (eg how chrome took off in the internet explorer offboarding era even though there were objectively equal or better alternatives at the time by just using google's internet omnipresence at the time for advertising). Sadly, modern internet is governed more by advertising industry rather than any kind of open-internet principles. But ultimately this is all developers' decisions and I respect that. If anything, if a major company decided to take off and invest, they could do it in any case, publishing their modified source code would not make that much of difference essentially. It is really refreshing to see at last a browser that does not absolutely depend on google's resources in any way. reply guappa 5 hours agorootparentprevJust so you know, chromium exists now as an open source project because KDE developers used GPL. reply cabalamat 1 hour agorootparentprevBut if they embrace, extend and extinguish, in a way that harms your users' freedom, that would not IMO be a good outcome. reply bigstrat2003 56 minutes agorootparentThose users can always use the original browser. They haven't lost anything. reply cabalamat 27 minutes agorootparentImagine Ladybird is developed and is successful. Lots of people use it to read websites. But then Badcorp takes the code and builds their own varient with extensions. Badcorp is big and has lots of market share. Lots of people use Badcorps's browser, and because lots of people are using it, lots of web developers code for it, including coding for its extensions. Soon, lots of websites -- including Badcorp's own websites, and they have lots of popular ones -- use the extensions in the Badcorp browser. Then people still using Ladybird can't use it for most websites. They have lost something. reply eitland 7 hours agorootparentprevReality check: 1. All the BSDs have been out there for decades without anyone running with it. 2. Google and Microsoft - while being a shadow of their former selves technically - are probably still very capable of reimplementing whatever they want. 3. If Ladybird gets so wildly popular, lets celebrate wildly! reply Y_Y 6 hours agorootparentYou wouldn't count OSX as someone running with BSD? reply eitland 6 hours agorootparentI run Mac OS. I am aware that it builds on BSD. Yet BSD is very alive and nobody who wants BSD is lost to Mac. At least I personally have never heard anyone deliberating over a free BSD vs Mac. Edit: and of course upvote. Apple ran with it. But they didn't run away with it. We still have it. Actually we have some patches thanks to them. As I mentioned in my other reply: Open source is not a zero sum game. reply BirAdam 6 hours agorootparentprevWell, macOS is sort of BSD, but not quite. The kernel isn’t really BSD despite large sections being originally taken from BSD. The XNU kernel isn’t really BSD anymore. Then, the userland (BSD is both kernel and userland developed together) isn’t really BSD anymore, and Apple neglects their UNIX userland anyhow. reply criddell 3 hours agorootparentprevDon’t forget the PS5! At it’s heart it’s just a computer running FreeBSD. reply rsprinkle 6 hours agorootparentprevCisco's OS is a fork of BSD. reply marcus0x62 6 hours agorootparentWhich one? They have dozens of “OSes” across their various products. Cisco IOS is absolutely not based on BSD - it is a proprietary kernel, and such that it even has a “userland”, a proprietary userland. IOS XE is based on Linux. Most of the voice stuff is Linux. Perhaps you are thinking of Juniper’s JunOS, which is based on FreeBSD? reply eitland 6 hours agorootparentprevI don't know. But if so, what? Have you caught anyone deciding to go with Cisco instead of BSDs on their servers or their laptop? I'm serious here: Open source isn't a zero sum game. Partially thanks to the permissive license of BSD we now have both Mac OS and JunOS (edited: it said Cisco first), which is a good thing, not a bad thing. The problem with Chrome isn't that it exist but that it has been forced upon us and the fact that we know they have used questionable methods to establish it as the dominant browser. reply ecef9-8c0f-4374 7 hours agorootparentprevKHTML was the basis for Chrome and Safari. A valid concern reply eitland 6 hours agorootparentChrome in itself is not the problem. Competition is good. Firefox is better now thanks to Chrome. Neither is Safari. Safari is actually part of the solution. Safari has saved Firefox and other browsers by being the only option on iOS for a long time and a better choice for many (because of battery usage) on Mac OS. Without Safari I am afraid we would all be locked into Chrome now. The problem is that Google, like Microsoft before them, 1. used their dominant position in one market to force their way into dominating another market, 2. used various underhanded tactics to make users think Chrome were better while in reality it was just given better treatment by their backend servers and also the Googles frontend devs[1] 3. and that unlike Microsoft they still haven't got a multi billion fine for it and haven't been forced to advertise alternative browsers for months. [1]: see various bugs[2] in everything from the core of the Angular framework to Google Calendar to YouTube [2]: yes, I am generous enough to consider them bugs. I am fairly certain though that bugs that doesn't affect Chrome aren't exactly considered top priority. reply TheDong 6 hours agorootparent> Safari is actually part of the solution ... > Google, like microsoft,If you're going to complain about 1-3 for google and ms, I don't think you can praise safari in the same breath. Apple's abused their position with the iPhone to make safari relevant, and unlike Chrome and IE, users can't just install another browser. Apple's behavior is the only reason I can't run my own addons I've written for firefox on iOS (they run _fine_ on android of course), why I can't run uBlock origin on iOS, and so on. Apple's behavior on iOS is far more egregious than anything microsoft or google has ever done. I never once had to run IE or Chrome unwillingly since I could always install netscape, or mosaic, or firefox. I'm forced to run Safari, unable to decently block ads, unable to use the adons I've written, unable to fork and patch my browser to fix bugs, and I've generally had my software freedoms infringed... and if I don't run safari, then I can't talk to my family group chat (no androids allowed, sms breaks the imessage group features too much) or talk to my grandma who only knows how to use facetime. I wish so much I could use a phone with firefox, but I can't justify having a spare iPhone just to talk to my family, so I'm kinda forced to suffer through safari, held hostage by apple's monopolistic iMessage behavior. The only thing that comes close to Apple's behavior is Google's campaign to force Chromebooks upon children in classrooms, requiring them to use Chrome, but at least Google isn't holding their grandmother's hostage... and managed work/school devices already are kinda expected to have substantially less freedom than personal devices, so it feels much less egregious. reply mastercheif 20 minutes agorootparentOrion Browser includes experimental Firefox extension support on iOS https://kagi.com/orion/ reply rimunroe 4 hours agorootparentprevMaybe I missed something but your arguments seem be about how Apple’s locking down of iOS/iPadOS and Safari are harmful to user freedom. That’s a very different argument from the one the person you’re replying to was making. They were saying that the popularity of Apple’s mobile devices coupled with their only running Safari holds back a Chrome monopoly in the browser space. If people don’t support Safari they lose out on a large portion of users. reply jampekka 6 hours agorootparentprev> Safari has saved Firefox and other browsers by being the only option on iOS for a long time Amazing. https://en.m.wikipedia.org/wiki/1984_(advertisement) reply eitland 6 hours agorootparentHehe. But more seriously: it is actually the truth. Kind of in in the same way that people are thankful for Churchill: not because he was a fantastic man in every way (he wasn't) but because he saved us from something even worse. reply jampekka 6 hours agorootparentBig Brother keeps Oceania safe from Eurasia and Eastasia. And especially from Emmanuel Goldstein. reply josephd79 6 hours agorootparentprevI thought the other browsers on IOS were just skins of webkit / safari ? reply freehorse 6 hours agorootparentYes, and the commenter claims that in this context this is actually good because it halted chrome/chromium's dominance in the internet (and I actually agree). It may sound paradoxical, but context is important imo. reply eitland 6 hours agorootparentprevThat is to a large degree correct. I even thought it wasn't necessary to test them separately but I recently heard from someone with more and more recent experience that some differences exist, particularly around prefixed css attributes. Can't say for sure though, but that was why I wrote my comment above somewhat defensively. reply soundnote 6 hours agorootparentprevEU law does force them to advertise alternative search engines. I just updated Chrome on my work laptop and they gave me a slate of search engines. My Chrome defaults to Brave Search now. reply BirAdam 6 hours agorootparentprevWebKit is still an open project as is Blink. Why would this be concerning? reply ecef9-8c0f-4374 24 minutes agorootparentMy comment was a response. It's a concern for Ladybird not Webkit. It's about the licence. But OP is ok with that so. reply teekert 7 hours agorootparentprev\"Better\" is a subjective term. I would probably stay on OG Ladybird if it meant MS/Google-ified LB starts screenshotting/OCRing/Uploading/LLMing all the data, even if it were to become faster and more slick. Slow computing it's sometimes called [0] I sometimes experience some friction (really acceptable though) on Firefox, it has never lured me to Edge of Chrome. Some people have standards you know ;) [0] https://www.slowcomputingbook.com/ reply hfgjbcgjbvg 5 hours agorootparentprevThey’re backed by Shopify. If Google or Microsoft forked it that would probably be the best thing they could hope for. reply adwn 3 hours agorootparentprev> Hey, just a reality check: It's rather condescending of you to assume that the developers of Ladybird aren't fully aware of the consequences that their choice of license entails. reply dataflow 2 hours agorootparentThat certainly wasn't the intention. Was there really a need to turn this into a personal swipe? This is a common outcome many smart and talented developers have historically come to regret. You can find their stories all over the web, including right here on HN. I didn't want to see the same thing happen here, is all. reply enriquto 6 hours agorootparentprev> (...) switch to a less permissive license. License \"permissiveness\" is a relative concept. From the point of view of the users of your software, the GPL is more permissive than MIT, since they have permission to see the source code. If you release software under MIT or BSD licenses, you allow middlemen to strip this right to users of your software. reply mrighele 5 hours agorootparent> you allow middlemen to strip this right to users of your software. That's not true. Somebody can take the source code and build something closed on top of it, but the original code will be already free, and you will always have the right to see it. For example, PlayStation OS is based on FreeBSD (AFAIK). They took it, adapted it and added a lot of stuff. Did you lose the right to see the source code of FreeBSD ? No. Can you see the source code of PlayStation OS ? No, but you never had that right, so you have not been stripped of anything. reply freedomben 5 hours agorootparentGP is clearly talking about this is the same context that the GPL does. This is a decades-long running debate and it isn't as simple as you and the sibling commenters are trying to make it. Of course it doesn't change the original project. But when people take the codebase and build a new product on it, what GP says is absolutely the case. The devs can withhold all code and rights to it from the next user. This is most commonly an issue when it comes to libraries rather than end products, but not always. It doesn't also have to mean that the original project dies or disappears, it can just rob from their growth potential. Examples are quite easy to find. There's been a big hullaballoo over cloud providers taking open source projects and competing with them by offering managed versions of the service that are well-integrated into their ecosystems. Economically this is also a problem because the cloud provider can then undercut the price of the managed service compared to the official one since they aren't bearing the burden of building/maintaining the codebase. I'm by no means against \"permissive\" licensing (MIT, etc), I think they have their time and place just like GPL, etc, but I am against dismissing valid concerns with shallow replies. reply bigstrat2003 51 minutes agorootparentprev> If you release software under MIT or BSD licenses, you allow middlemen to strip this right to users of your software. No you don't. You're being extremely disingenuous with this phrasing. No matter how many other parties take the source code and make a closed source product out of it, the users of your software will always have the same rights you granted them to begin with. No freedom has been lost. And before you say \"but your users won't have the same rights to the derivative works\", that isn't a loss of freedom. They never had those rights to begin with, therefore they cannot lose them. Not gaining something is not the same as losing it. reply skrebbel 6 hours agorootparentprevDon’t spread FUD please. Middlemen can’t change Ladybird’s license or prevent anyone from seeing its source code. I know that’s not what you meant, but it is what you said. reply freedomben 5 hours agorootparentIf you look at the parent comment directly above in the hierarchy, it is pretty clear that they are talking about a company coming in and taking it, adding stuff to it, and calling it their own browser. I think you have to try pretty hard to read in that GP is saying that the original source code license would be changed. reply flykespice 6 hours agorootparentprevThat is a complete nonsensical claim & willful attempt at spreading misinformation: Permissive licenses doesn't grants you less freedom than GPL, infact it grants you more because the user also has the freedom to modify source code without being enforced to make it public. Companies copying the codebase to their propietary ones won't automatically strip right of users, licenses don't work like that, the original codebase will still be fine. Whether said companies will contribute back is irrelevant. reply hfgjbcgjbvg 5 hours agorootparentYou can copy GPL code, modify it and use it personally and nobody is going to care unless you’re making tons of money. The entities pushing for MIT style licensing are massive and for profit. reply bigstrat2003 47 minutes agorootparent> The entities pushing for MIT style licensing are massive and for profit. I license all my stuff with permissive licenses because (in my opinion) they are more free than the GPL and such licenses. I don't have any massive for-profit company pushing me to do so. Mr. Kling is also not a massive for-profit company, he's just a guy making the software he wants to make. Your argument is in very bad faith. reply guappa 5 hours agorootparentprevSo pre-civil war USA was more free, because people had the freedom to own slaves? We have to simply ignore the bit about slaves having no freedom… (If you read this comment and think I am pro-slavery, you are not apt at human communication and should take steps to improve) reply freedomben 5 hours agorootparentI'm guessing you're being downvoted for comparing software to slavery. Generally speaking, the modern society seems to have forgotten that the world isn't binary - you can make comparisons and have similarities that are far apart on the spectrum so aren't equalities, but can still find informative meaning. But to your point, this exact argument was used by top southern politicians to justify slavery! It was the freedom of the slave owner, their right to own property, that justified slavery. James Hammond famously made this argument to congress shortly before the Civil War broke out. If this is interesting to you, Eric Larson just released a great book called \"The Demon of Unrest\" that covers this. reply unclenoriega 4 hours agorootparentprevWho are the slaves in this analogy? reply tristan957 3 hours agorootparentI would say that the users are the slaves. Without GPL software, we could end up in situations where hardware vendors stop shipping software updates, so we are slaves to capitalism by having to buy things we shouldn't need to buy. This goes hand in hand with right to repair in my opinion. reply gavinhoward 47 minutes agorootparentprevLess permissive licenses protect users more. https://gavinhoward.com/2023/12/is-source-available-really-t... reply pferde 8 hours agorootparentprevIndeed. This is something I could see myself contributing to (or attempting to, anyway), but as soon as I saw Discord+Github, I lost all interest. Github I can understand to some extent, it's a convenient temporary staying place until they can afford, community-wise, to move to something truly open, but Discord? In this day and age? reply dandellion 6 hours agorootparentAgreed, Discord is a terrible platform and I wish people stopped using it. I expect in the next five years or so it'll undergo a very rapid enshitification and people will start using other things after that, but by then we'll have a decade of lost content. reply komadori 6 hours agorootparentDitto. Discord is fantastic platform to use and I'm a member of so many interesting communities across a range of subjects, but it does seem so very precarious to rely on the company to keep it going as it is. reply thiht 1 hour agorootparentprev> but Discord? In this day and age? Discord IS the platform of this day and age, what the hell are you talking about? You might not like Discord for whatever reasons, but trying to make it sound outdated or legacy is very weird sounding. reply paulcole 6 hours agorootparentprev> but Discord? In this day and age? What’s your recommended alternative? reply zzo38computer 44 minutes agorootparentIRC. And for slow discussions with long messages, you can use NNTP. (However, GitHub is accessible by git in case you only want to download the repository, regardless of what else they do; however, having multiple mirrors on other services as well can be helpful) reply freedomben 5 hours agorootparentprevMatrix is a wonderful alternative reply account42 4 hours agorootparentBetter but a the real alternative is what we had before: publicly visible forums, mailing lists with an archive, etc. I'm not going to sign up for your discussion group without being able to get a feel for the community first. reply pferde 1 hour agorootparentIndeed. There can never be just one platform for project communication, because there are different kinds of communication - mostly sorted between synchronous and asynchronous. So, IRC, Matrix (these can even be interconnected) for synchronous, mailing lists or forums for asynchronous. And of course issue tracker, where some topical communication can happen as well, but that could completely be covered by mailing lists. There's no reason to ever have anything non-open in your FOSS project's infrastructure. reply guappa 5 hours agorootparentprevdiscuss? reply bigstrat2003 57 minutes agorootparentprevThe BSD license protects user freedoms just fine. reply endgame 6 hours agorootparentprevThis seems very important given how KHTML lead to the current near-monoculture in the browser space. reply mysterydip 6 hours agoparentprevIt's been so refreshing watching this project blossom from literally almost nothing. I wish you success :) Hopefully I can contribute at some point because I think this browser has the best chance of shaking up the monopoly, and I want to daily drive it. reply SushiHippie 8 hours agoparentprevHow does ladybird compare to Servo? https://servo.org/ reply awesomekling 7 hours agorootparentI can't speak for Servo, but my understanding is that they have very different goals than we do. Servo wants to build an embeddable engine for controlled sets of HTML/CSS/JS content, with a focus on modularity and parallelism. Ladybird wants to build a usable browser for the open web, warts and all, with a focus on compatibility and correctness. I'm a big fan of Servo and I hope they become a huge success! Competition and new ideas in browser engines will benefit all of us! :) reply mananaysiempre 6 hours agorootparent> Servo wants to build an embeddable engine That’s what they pivoted to after being expelled from Mozilla, but that wasn’t the original goal, was it? It’s the safer(?) one they turned to when the job security evaporated. (Not sure if that changes anything, just feel obligated to point out the retcon here.) reply spankalee 1 hour agorootparentIt would be very cool if Servo were picked up as the engine for a new browser. reply rizky05 7 hours agorootparentprevServo is just the engine at this point. Ladybird has the whole thing. reply freedomben 5 hours agoparentprevAre you working full time on this now? How many people are working on it and about how much time per week are they able to do? Is this expected to hold steady or do expect changes over the coming weeks, months, or years? Not trying to pry into your personal lives, just wondering because there's a lot of meaningful information behind the answers to those questions. reply awesomekling 5 hours agorootparentYes! I'm already working on it full time, along with 3 employees. In the next month, we are bringing on 3 more. Given the limitations of our funding model, we won't be building a huge team, but rather a small team that allows us to maintain a runway of at least 1.5 years. :) reply yuvadam 8 hours agoparentprevHow does Ladybird avoid Mozilla's fate? How can it be a long term sustainable project? reply awesomekling 8 hours agorootparentIt depends on what you mean by “Mozilla’s fate”. In general, we are setting a much narrower goal than Mozilla and hope that focusing on only browsers will allow us to keep things simple and more sustainable financially. :) reply yuvadam 8 hours agorootparentMozilla is dependent on advertising money from Google, is that only because they ventured in other directions? I'm not intimate with their finances, but it seems just building a browser is a large enough - expensive - R&D effort. Are you planning on charging your users? reply tinco 7 hours agorootparentI think it's the other way around. They determined that to become less reliant on Google for revenue they should explore other directions, and that hasn't been very succesful. Though I don't fully understand why pulling funding for new browser technology was part of their strategy going forward. Servo was one of the projects that made me excited about using Firefox. I bet that big announcements about moving Firefox to Rust would have consistently bumped usage numbers. As much as people voice their opinions about the RiiR movement in the comments here, it's clear people love those kinds of projects just for the technical novelty. I know I do. reply awesomekling 7 hours agorootparentprevWe will never charge our users, or attempt to monetize them in any way. Our nonprofit will run on unrestricted donations only. reply mananaysiempre 6 hours agorootparentYou personally I believe without reservation about this, but the thing about creating a legal person is that it’s separate from you. Its control can—and in the long run, will—change hands. So please, please write this down somewhere, ideally somewhere binding on its future (can donations have conditions?). reply awesomekling 5 hours agorootparentWe've committed to this in our application for tax-exempt status, so it's something the organization will be stuck with. :) reply coldpie 6 hours agorootparentprevI wish you luck, more competition in the browser space is sorely needed. But please, please spend more time thinking about your finances. The surface of planet \"Startups That Will Figure Out A Business Model Later\" is like 99.9% graveyard. You're going to be asking people to depend on your software for an extremely important part of their lives. If you don't have a path to sustainability, you're going to do a lot of harm when you close up shop. Between the lack of a business plan and your responses about licensing, I'm afraid I feel you're coming at this from a naive point of view. This is a seriously important line of software you're entering, please do take some time to take it seriously. Will watch your progress and again, I genuinely love to see your project. Good luck. reply account42 4 hours agorootparentA non-profit foundation taking donations is a \"business\" plan and IMO the only one that has a chance of building a true user agent in the long run. That doesn't mean that it is guaranteed to succeed but I don't think there is a better funding option thatwon't come with conflicting incentives. reply coldpie 3 hours agorootparentNo, \"people give us money\" is not a business plan. When you're starting a business (yes, non-profits are businesses) and employing people, you need to be thinking about marketing, user acquisition & conversion, pricing structures, corporate sponsorships, and so on. I know it's not as much fun as programming, but neither is eating out of your neighbor's trash because you can't pay your bills. reply logicprog 5 hours agorootparentprevDespite that, I hope you'll consider a \"pay what you can\" popup when downloading the browser, or a donation button built into the browser settings page along with a one-time reminder, or something like that. I don't think that would be monetizing your users in any negative, extractive sense like ads do, it would still essentially just be a donation, just asked for in a more obvious way and made easy and convenient to do as part of using the app, instead of a vague separate thing that'll take work to find and that won't occur to most people to do. Personally I think charging users for software (as long as it is also FOSS) is totally fine, it's probably the only sustainable model for software that isn't ads or corporate sponsorship, and it actually serves to align the incentives of the software's developers more closely with users, instead of doing anything bad, but I respect that line. reply abrookewood 7 hours agorootparentprevUnless you are planning to live off the interest from your donations, how will this be possible? reply awesomekling 6 hours agorootparentWith a simple two-part strategy: 1. We keep the team small enough that there's always at least 1.5 years of runway in the bank. 2. We continue fundraising actively. reply Sammi 8 hours agorootparentprevI've heard Andreas Kling say that they will not accept donations that have strings attached. This means they can never sell search engine placement to Google for instance. This is what ties Mozilla to Google. reply awesomekling 7 hours agorootparentThat's right. The Ladybird Browser Initiative will only accept unrestricted donations. We're missing out on a fair bit of money this way, but we believe it's the right path for us. reply tomaytotomato 7 hours agorootparentprevIts easy to avoid the fate of Mozilla, don't get involved and distracted by lots of side projects. https://wiki.mozilla.org/Past-projects reply account42 4 hours agorootparentIt does seem the apple doesn't fall far from the money tree. reply sirwhinesalot 8 hours agorootparentprevDon't throw money away into non-browser related projects while constantly pissing off your loyal userbase. reply imp0cat 7 hours agorootparentLook, I am as annoyed as you are with the constant barrage of \"rewritten in Rust\" projects, but if Mozilla did not try various other projects that are not browser, there would be no Rust. reply sirwhinesalot 7 hours agorootparentRust wasn't a Mozilla project per se, it was something a person who happened to be working for Mozilla was messing around with and it got internal traction. But I'm actually ok with a lot of the non-firefox projects that they have like the VPN. What I do have an issue with is the foundation, throwing money away at various projects that have very little to do with making firefox better. From \"trusworthy AI\" research grants to giving 387k to the Mckensie Mack group or 375k to the New Venture Fund (I get Mozilla are lefties but what does this have to do with Firefox?) plus some other organizations that I can't even tell if they aren't just money laundering fronts as they don't appear to actually do anything. That and the C-Suite being complete parasites. The CEO of Mozilla corp makes almost as much in a year as the Mozilla foundation makes from donations. Remove the parasites and the senseless spending of the foundation and you could develop Firefox with the ~20% of revenue that doesn't come from Google. reply adwn 7 hours agorootparentprevIf I recall correctly, Rust was born with building a browser engine in mind, or at least it was one of its earliest motivations. So Rust would have been a thing even if Mozilla had focused on their core product. reply Suppafly 46 minutes agorootparent>So Rust would have been a thing even if Mozilla had focused on their core product. Plus, while Firefox is their main product, it's been decades since Mozilla has been solely a browser company. It's like saying Microsoft should stop making Office because it detracts from their OS business. Companies can make more than one product. Some of those products are going to have shorter lifespans or smaller userbases than others and that's OK. reply m0llusk 6 hours agorootparentprevAlso the Mozilla originated Fluent project for localization is another example of a stand out approach. It would be interesting to see how localization fits with the Ladybird browser project as a whole. Making use of a custom implementation of Fluent might actually be a good way of moving forward. reply mananaysiempre 6 hours agorootparentDo people actually use Fluent? When I showed it to some professional translators, the reaction was along the lines of: “Hmm, interesting, but does it fit into my existing [roughly speaking XLIFF] tooling? No? Then no.” More generally, a technical translator’s flow is turning a table of strings into a table of strings with minimal distractions and the occasonal look at the reference; I’m not sure Fluent—however nice it looks—facilitates that. reply metalloid 5 hours agorootparentprevInstead of rebuild 'everything' in Rust, we just can use AI to optimize C/C++. We don't need another programming language. reply account42 4 hours agorootparentWow you actually managed to make me hate the inane \"why not rewrite it in rust\" commenters a tiny bit less. reply Aeolun 8 hours agorootparentprevAsk for money from the start? reply account42 4 hours agorootparentAnd don't ignore or intentionally alienate the users who might be inclined to donate. reply fguerraz 6 hours agorootparentprevMozilla's fate? You mean building a browser that works? Indeed, I doubt very much that Ladybird will get there. reply Tepix 6 hours agorootparentI use Firefox every day, but they have lost so much market share that they have become pretty insignificant. They seem to have an oversized and poor management with fat paychecks. reply soundnote 5 hours agorootparentDon't know about oversized, it felt partly more that eg. Baker was mostly interested in Mozilla as a platform for activism, not in making a good tool for users. The new interim CEO seems to have breathed life into actual browser development. reply fabrice_d 19 minutes agorootparentThe new interim CEO has been there for such a short time that she can't possibly have breathed life in anything (she managed to get sued by the former CPO for health based discrimination though, so there's that). reply mikkelam 27 minutes agoparentprevI absolutely adore your coding videos where you implement new features. Any chance we'll get more of those with Ladybird? reply ColinHayhurst 8 hours agoparentprevThis is a welcome initiative speaking from a personal and professional perspective, and as CEO of an independent search engine; we are all too well aware of the power of money and defaults. This immediately comes to mind as akin to the Signal vis-a-vis WhatsApp etc. Here there is an obvious reason to use Signal and a well-understood proposition. What might it be for Ladybird? And how will you differentiate? reply awesomekling 7 hours agorootparentTo be honest, we are so far behind everyone else today that we're 100% focused on catching up technically, and not thinking much about differentiation. :) That said, I do think we'll find ways to differentiate given our uncommon situation with no ties to the advertising industry. This gives us the ability to experiment with privacy measures more aggressive than others may be comfortable with for fear of losing funding, for example. reply ColinHayhurst 4 hours agorootparentWith no ties, direct AND indirect, that does make Ladybird uncommon, like Pale Moon. Our own approach to privacy is as radical as it gets in search: \"No Tracking, Just Search\". As we often say: tracking, not ads, is the fundamental problem. Contextual ads do not need necessarily to have tracking. Though the duopoly of search ad networks makes that a hard road too. Good luck. Excited to see how Ladybird progresses. reply skywal_l 8 hours agoparentprevWhat is the biggest challenge you expect for ladybird to be successful and do you consider this project still a \"hobby\" now? Thanks again for your hard work! reply awesomekling 8 hours agorootparentWe have a number of big challenges in the immediate future, but I think the biggest one of all will be the long tail of compatibility and correctness issues that inevitably awaits us after everything falls into place. This is definitely more than a hobby at this point. I already manage 3 employees, with 3 more joining in the next month! reply ykonstant 7 hours agorootparentI hope that you continue your herculean efforts to investigate the specs and insist on correctness; the resulting implementations, dug up inconsistencies and edge cases will undoubtedly be of independent interest and invaluable to the community. reply ledgerdev 6 hours agorootparentprev> We have a number of big challenges in the immediate future, but I think the biggest one of all will be the long tail of compatibility and correctness issues No kidding... how about get it roughly working on hacker news, and make it the hackers way to start each day, and pull in as much help and community as possible from here? reply networked 7 hours agoparentprevI have two questions, if you don't mind. 1. Legacy hardware support. Is it a goal for Ladybird to build for 32-bit and big-endian CPUs out of the repository? 2. Electron. Do you have any plans to work on an Electron alternative based on Ladybird further down the line? No free Electron alternative other than Sciter seems to use the same browser engine on all platforms. There may be value in one that implements the latest web standards. reply awesomekling 6 hours agorootparent1. We are not focusing on legacy hardware support. Given our release date is far in the future, we are mainly targeting the kind of devices most people will have a few years from now. 2. No concrete plans, but it's not outside the realm of possibilities. reply stephen_g 6 hours agorootparentprevMaybe item (2) is more up Servo’s alley than what Ladybird is trying to do? Servo seem to be focusing on making an embeddable engine, Ladybird is intended to be a full browser… reply fouc 6 hours agoparentprevI remember watching one of the early videos of you starting working on the browser, and you said something along the lines of wanting a browser that was sort of a dumb renderer - one that didn't attempt to be a whole Operating System. Does Ladybird still follow that ideal? reply awesomekling 6 hours agorootparentThat was a long time ago indeed! To be honest, I think I was partly saying that because I was scared of the idea of supporting the entire web platform. It seemed so far away at the time. :) Going forward, we want to support the open web as it exists, so you can actually use Ladybird to interact with all your websites. We may not agree that every web platform API is awesome and perfect, but we will honor the open standards to the best of our ability. reply wwwwwwwweb 8 hours agoparentprev> we have almost half a million lines of modern C++ to maintain. ...We are actively evaluating a number of alternatives and will be adding a mature successor language to the project in the near future. This process is already quite far along, and prototypes exist in multiple languages. What languages have prototypes and where can I learn more? reply awesomekling 6 hours agorootparentWe have not been debating this publicly as it has a 100% chance of devolving into a bikeshed discussion :) reply ledgerdev 5 hours agorootparentMy favorite type of discussion! Language choice would seem super important long, long term and could provide long run advantage over other engines. Given the goals and philosophy of Ladybird zig seems like a complementary choice, and headed in the same direction in terms of community and freedom. And Perhaps just a sprinkle of something more verifiable than zig on the edges where correctness and safety are super critical. Have a look into tigerbeatle (https://github.com/tigerbeetle/tigerbeetle/blob/main/docs/TI...) and their philosophy. reply ykonstant 6 hours agorootparentprevClearly there is a furious internal war between CLispers and Haskellers! reply kamov 6 hours agorootparentprevWhatever language you end up choosing, I hope it will be a memory safe one. Browsers' main purpose is to interact with the outside world, and they even have to run third party code (JS) all the time, so minimizing attack surface would go a long way I think reply awesomekling 5 hours agorootparentYes, our next language will be a memory safe one. reply ArtixFox 2 hours agorootparentpls pls pls go for one of those languages with some level of formal verification! it'd be soo cool to see a formally verified browser! But, ladybird is one of the coolest things I saw in 2024!!! reply PedroBatista 8 hours agoparentprevWhat’s the biggest technical challenge you envision in the future? It’s the amount of “standards” you need to implement and maintain? What’s the JavaScript engine situation? reply awesomekling 6 hours agorootparentThere are a ton of standards at a glance, but when you look closer, you realize that much of it isn't implemented by other browsers either, and you only need a fraction of it to render 90%+ of the web. The last 10% will be a huge challenge, but we've got a long way to go before then. The JavaScript engine is our own LibJS, currently sitting at 94.3% pass rate on https://test262.fyi/ (although the number might be a little outdated, it's supposed to be higher! Need to investigate this..) reply rurban 54 minutes agoparentprevChris is awesome! Congrats, Andi reply klohto 1 hour agoparentprevis there still space on your crew? i’d love to join, should i just start committing? reply awesomekling 54 minutes agorootparentWe’re always open to new developers! Find a website that doesn’t work right, then try to figure out why, and see if you can fix it :) The best for a beginner is usually to start with some simple page you made yourself, since you know how it’s supposed to work, and can debug more easily. And come join us on Discord, there are new people getting into the codebase all the time :) reply klohto 43 minutes agorootparentThanks Andreas! Completely forgot about the current Discord meta. reply ironmagma 8 hours agoparentprevIf Ladybird is \"forked\" from SerenityOS now, does that mean the mainline won't run on Serenity any longer? reply awesomekling 8 hours agorootparentThat’s right. A version of Ladybird remains in the SerenityOS repo, and people are cherry-picking changes as we go. Over time, I expect them to diverge enough that this becomes impractical, as Ladybird now allows 3rd party code while SerenityOS does not. It’s up to the SerenityOS community how to handle this. reply dailykoder 5 hours agoparentprevWill it block ads are have the ability to run extensions to do so? I can't use modern web without an ad blocker reply awesomekling 5 hours agorootparentWe will absolutely have the ability to block ads. The web is downright unpleasant without this feature! reply pkphilip 6 hours agoparentprevAndreas, this is awesome :)! But please do consider putting up some screenshots of the browser - including how it renders the popular sites. reply codetrotter 7 hours agoparentprevHoly cheeseballs! That’s amazing. Big congrats, you deserve it :D reply ledgerdev 5 hours agoparentprevHey please be sure to design and at least mock out a way to host/run a collection of local LLM models in a generic manner. You could give the models access to context/content/history and to bubble up functionality within the browser. I can see tons of potential for something trusted and local which I'm comfortable giving full access to browsing history and not owned by big tech. This could be key differentiator over other browsers. reply freedomben 5 hours agorootparentI agree, though this does not seem like something that should be built until the browser is at least usable, which currently they're projecting an alpha release in 2026. By then things might be totally different, so don't architect yourself into a corner with it, but I also wouldn't invest much or any time into it right now. Focus on building good APIs/extension points though, and those will be immensely useful whether for local LLMs, extensions, or anything. reply ledgerdev 5 hours agorootparentYeah, wasn't thinking about actually building it out, just mocking it out and taking into consideration to allow for it as you build out browser. So much easier to plan for rails, rather than foist into something later on. edit: > Focus on building good APIs/extension points though, and those will be immensely useful whether for local LLMs. I think we're saying the same thing, focus on good extension points for the local LLM use case. reply courseofaction 8 hours agoparentprevWhat's the pitch for those who currently use firefox? reply Sammi 7 hours agorootparentFinally get out from under Google's thumb. As soon as Ladybird is half as good as Firefox, then this is reason enough for me to switch. I've lost faith in Mozilla's leadership, and I believe the root cause is the Google money that they rely on. reply Aeolun 8 hours agorootparentprevSomething about only being a browser company? Mozilla is many things, but purely browser focused is not it. reply PedroBatista 8 hours agorootparentI would say the browser it’s not even in their mind at this point. High level people inside Mozilla not only implied but said it directly. reply nalinidash 7 hours agorootparentThough,very recently,they are giving more attention to Firefox, or at least want us to see this way. For example: the reddit AMA on firefox unofficial subreddit[1],the mozilla connect post on things they are working on[2]etc. [1]:https://new.reddit.com/r/firefox/comments/1de7bu1/were_the_f... [2]:https://connect.mozilla.org/t5/discussions/here-s-what-we-re... reply ajrowls 7 hours agorootparentprevSource for this claim? reply beretguy 7 hours agorootparentprevMaybe they’ll add tab groups. reply nalinidash 5 hours agorootparentThey are currently working on it. reply Oxodao 6 hours agoparentprevWhat's your point of view about quirks as you can find in other browsers and how do you plan to handle websites that rely on unintended browser behavior ? reply awesomekling 6 hours agorootparentThese days, all major browsers are taking interoperability very seriously. There’s even efforts like the annual “Interop 202x” where people vote on which interop bugs browsers should focus on fixing. We benefit greatly from this of course, and we will do what we can to contribute when we’re mature enough! That said, there will always be websites relying on bugs, and for that we will need a way to selectively emulate alternate behaviors in some cases. We are looking at a few different solutions for this but it’s not a huge priority right now as there are far lower hanging fruit in front of us. reply Oxodao 5 hours agorootparentThanks! Good luck with your project, this single-handedly gave me back faith in the modern web when I found out a few month ago about the progress you guys made since I last saw it reply hakanderyal 6 hours agoparentprevJust wanted to add a note for the roadmap: Please make sure it can compete with Safari on battery usage, so those who are mobile on a Mac are not left behind. Best of luck! reply Y_Y 8 hours agoparentprevWhat's the trouble with the Android port? reply awesomekling 7 hours agorootparentIt's an unmaintained prototype without anyone actively working on it. Once we get the desktop version into decent shape, we will direct more attention to mobile platforms. At the moment there's just too much important low-hanging fruit that's easier to develop (and debug!) on desktop :) reply kosolam 8 hours agoparentprevHey Andreas! Why you don’t just fork the code of Firefox or Chromium's and start from that point, building a Browser company like some others? reply awesomekling 8 hours agorootparentHey kosolam! There are already many forks and ports of existing browsers. Do we really need another one? :) By building a new engine, we can increase ecosystem diversity and put all these open standards to the test. We regularly find, report, and sometimes even fix bugs in the various web standards - stuff we find just by being the first to try and implement everything from scratch in a long time! We also believe it’s good for the world to have more engines that aren’t directly or indirectly funded primarily by the advertising industry. reply criddell 7 hours agorootparentRelying on open standards is risky. It seems to me the de facto standard is whatever Chrome or Blink does. reply ykonstant 7 hours agorootparentThat's the unique value proposition of Ladybird. It uses the open standards as the jumping point, investigates and de facto documents the divergence of modern browsers from them. It is a precious and important work. reply criddell 6 hours agorootparentHow is knowing where the published standards diverge from de facto standards precious and important work? You say that's where the value is, but the subset of people and organizations who would pay for that (if it's valuable, people will pay, right?) has to be pretty small. reply ykonstant 6 hours agorootparent>(if it's valuable, people will pay, right?) No? There are tons of valuable contributions, pure and applied, that \"people\" (markets) do not pay for at all, or pay pittance relative to their usefulness. reply paddim8 5 hours agorootparentprevIt makes it much easier to build new engines in the future. Even if only a few people are interested in this knowledge, they can make a big impact with the software they write. reply bn-l 7 hours agorootparentprevSo freaking cool reply Sammi 7 hours agorootparentprevGoogle paid Apple $20 billion in 2022 to be Safari’s default search engine. They paid half a billion to be Firefox's default search engine. Here's a tweet with a couple of diagrams that illustrate how much control Google has over all browsers (including Firefox and Safari): https://x.com/awesomekling/status/1793937129250214344 reply hurutparittya 7 hours agorootparentprevI'm also curious about this. When it was just a toy project it made sense to write everything from scratch. If it's supposed to eventually be usable by people, a hard fork of Chromium, or at least some Chromium components might make more sense. Having a browser that improves hackability and user freedom while working just as well as Chromium sounds like heaven to me. Anyways, I'm clueless about browser development so I might be completely wrong. reply daghamm 26 minutes agoprevFor comparison, in 2022 Mozilla had $1.3B in assets and over $500M in revenue: https://assets.mozilla.net/annualreport/2022/mozilla-fdn-202... I want ladybird to succeed and show the world how ridiculous the Mozilla situation has been. reply dbcooper 8 hours agoprev>Why build a new browser in C++ when safer and more modern languages are available? >Ladybird started as a component of the SerenityOS hobby project, which only allows C++. The choice of language was not so much a technical decision, but more one of personal convenience. Andreas was most comfortable with C++ when creating SerenityOS, and now we have almost half a million lines of modern C++ to maintain. >However, now that Ladybird has forked and become its own independent project, all constraints previously imposed by SerenityOS are no longer in effect. We are actively evaluating a number of alternatives and will be adding a mature successor language to the project in the near future. This process is already quite far along, and prototypes exist in multiple languages. reply alkonaut 7 hours agoparentNice to see. The only thing that would meaningfully set it apart from the others would be to have a core that isn’t a big ball of C++. That would potentially allow it to be developed and maintained with less resource than the other browsers, and that would be the only way this ever reaches any kind of impact. reply fregonics 6 hours agorootparentIf I'm not wrong Firefox is already Rust. The language was even created inside Mozilla. reply kobalsky 6 hours agorootparentOnly around 11% of it is Rust according to https://4e6.github.io/firefox-lang-stats/ , which by the way is no small feat given how huge the code base is. reply alkonaut 5 hours agorootparentprevIt is. They realized that writing a modern browser (i.e. one that for example uses multiple cores efficiently by doing layout/rendering/etc in parallel) is almost impossible in C++. To the point where creating a whole new language just to solve the problem would be a smaller undertaking. Which says something about the scope of this problem. And I really do think they are right. reply tombert 32 minutes agorootparentWhy is it almost impossible? I'm a little out of practice with C++ but I thought the modern C++ features were considered pretty solid in regards to memory safety and the like? reply mirsadm 14 minutes agorootparentprevEh that is a huge stretch. Besides Firefox is still significantly less performant than Chromium. reply skywal_l 8 hours agoparentprevJakt[0] was being developped by Andreas at some point. It seems stall for now. [0] https://github.com/SerenityOS/jakt reply richardwhiuk 8 hours agoparentprevSo half a million lines of tech debt? reply vaylian 8 hours agorootparentI think that's too pessimistic. The code is there and it can be used to push the project forward. If some part of it is not good enough, then an alternative implementation can be created (potentially in a different language) reply neocritter 8 hours agorootparentA classic: https://www.joelonsoftware.com/2000/04/06/things-you-should-... >> \"The idea that new code is better than old is patently absurd. Old code has been used. It has been tested. Lots of bugs have been found, and they’ve been fixed. There’s nothing wrong with it. It doesn’t acquire bugs just by sitting around on your hard drive.\" >> \"Each of these bugs took weeks of real-world usage before they were found. The programmer might have spent a couple of days reproducing the bug in the lab and fixing it. If it’s like a lot of bugs, the fix might be one line of code, or it might even be a couple of characters, but a lot of work and time went into those two characters.\" >> \"When you throw away code and start from scratch, you are throwing away all that knowledge. All those collected bug fixes. Years of programming work.\" It's an older piece, but like good old code, it still holds up. Newer tools and technology have improved the creating of new code, but they've also made improving old code easier in equal measure. reply silotis 5 hours agorootparentIt's a good point in general, but in this case it's not clear if the cost of re-writing the existing codebase is less than the cost of staying with a memory-unsafe language. We know from past experience that it takes an extreme amount of time and effort to harden a browser written in C++ against malicious web content. The Ladybird codebase is not particularly \"old\" in any sense of the word. Judging by Github's stats most of the code is less than 4 years old and it is still a long ways from being ready for general use. I think it's safe to say Ladybird still has a vast amount of work to be done fixing vulnerabilities that arise from lack of memory safety. I find it quite plausible that the cost of re-writing the existing code in Rust is less than the cost of fixing all of the current and future bugs in the C++ codebase that Rust would catch at compile time. reply neocritter 4 hours agorootparentThat is the sneaky thing about rewrites. The \"Ship of Theseus\" rewrite is reasonably safe based on the article and what I could find of people sharing their experiences with rewrites. Fix what needs fixing, but swap in the newer better language/framework/whatever a piece at a time. It works! People get in trouble when they decide to rewrite the whole thing. You might be right in this case, but I'm sure every person who began a doomed rewrite project felt the the benefits outweighed the risks. Viewed in the rear view mirror of history, the Netscape rewrite was a good thing in a technical sense. As far as I understand it gave us the foundation for Firefox and the Gecko engine. It was just bad business in context because it let other browsers run laps around it while the rewrite proceeded. It let IE get a foothold that didn't shake for many years until Netscape became Firefox. Rewriting the new browser in Rust would probably be similar from a technical POV. But from a business standpoint, we seem to be at an inflection point where a new browser might be able to enter in the cracks of discontent over sketchy AI features in Edge and the slow-boiling attempts to break ad blocking in Chrome. If they divert resources now to a rewrite, they could miss this opportunity to do to Chrome what Firefox did to IE. It sounds like the plan is a Ship of Theseus rewrite anyway, so they'll get there in time without the risk of distraction. reply 8474_s 2 hours agorootparentprevOld code does acquire new bugs by sitting in your hard drive, since it interfaces with dozens of libraries and APIs that don't care about how well test the code is: every path of code is dependent on multiple components playing well and following standards/APIs/formats that old code has no knowledge of. Also, the mountain of patch-fixes and \"workarounds\" in the end force the programmers into a corner, where development is hobbled by constraints and quirks of \"battle-tested\" code, that will be thrown away as soon as it couldn't support fancy new feature X or cannot use fancy new library API without extra layers of indirection. reply noduerme 7 hours agorootparentprevThe only exception is if you have 500k LOC in a language whose runtime is going to be deprecated on all platforms overnight. I'm referring to the uh, retrospectively unfortunate decision I made in 2007 to start building large scale business app frontends in AS3. I guess I should be thankful for the work, having to rewrite everything in TS from scratch a decade later. (At least the backends didn't have to be torn down). reply Tade0 7 hours agorootparentI wonder how many businesses suffered the same? I remember Flash as a complete, straight-to-business platform that allowed me to just focus on getting stuff done. It was a sound decision back then. reply neocritter 7 hours agorootparentprevThere's a parallel universe where someone convinced you to rewrite it in something else from the start and you spent years on the rewrite instead and it never went anywhere. Could you have done that emergency rewrite without 10 years of becoming an expert in the problem you were solving? The alternative universe has you spending time becoming an expert in a new language instead and maybe not getting anywhere with the rewrite. reply voidwtf 6 hours agorootparentprevMy current employer, similarly, invested a significant amount of resources into Silverlight. Luckily only one component of the application had been switched to Silverlight, but a significant amount of code was written to be the core of that effort and future components before browsers/MS killed it overnight. reply ramon156 8 hours agorootparentprevWould another language have avoided this? reply Sammi 7 hours agoparentprevAlso the web standards themselves are written in an object oriented style. Using a non oo language like rust is therefore an uphill battle where you end up fighing against the language. The web standards just lend themselves naturally to be implemented in an oo language like c++. reply pjc50 7 hours agorootparent?! Rust is roughly equally as OO as C++ is. Which is not surprising given its aim to replace C++. https://doc.rust-lang.org/book/ch17-00-oop.html reply Sammi 7 hours agorootparentRust does not make it simple or easy to reference objects from objects. You will be fighting the borrow checker if you try. This is what I mean. The web standards have lots of references between everything. This type of object oriented programming means having lots and lots of cycles in your object graph. This makes Rust very veeeery unhappy. The Servo people are trying, and they have been trying for a looong time... reply r3trohack3r 2 hours agorootparentI don't understand, isn't this what Arc is for? An \"automatically garbage\" collected pointer? Or is it not well behaved for this use case (i.e. blowing the stack on free) reply Avamander 6 hours agorootparentprevTrue, but the patterns allowed on the web (or in GUIs for that matter) are incredibly painful in Rust. There was a nice article about the GUI part: https://www.warp.dev/blog/why-is-building-a-ui-in-rust-so-ha... These points are even more painful with web standards. reply kamov 6 hours agorootparentprevI think that pioneering the work of reimplementing web standards in not strictly OOP language will make the implementation easier for anyone else in the future, surely many of the problems exist by virtue of being done for the first time reply satyanash 7 hours agoprevNo talk of the license on the frontpage. Visiting the GitHub repo tells me it is 2-clause BSD license. It's high time we had a GPLv3 web browser, otherwise, this risks the same fate as the rest of the browsers with proprietary forks. This of course comes at the cost of not being able to support non-free parts of the web standard such as DRM. reply account42 3 hours agoparent> This of course comes at the cost of not being able to support non-free parts of the web standard such as DRM. That would be a benefit, not a cost. reply fsflover 4 hours agoparentprev> This of course comes at the cost of not being able to support non-free parts of the web standard such as DRM. LGPLv3 would solve that, wouldn't it? reply mronetwo 8 hours agoprevNitpick (or is it?) but the website is soulless and just bad. The website design communicates that this is just another immature project, desperately looking for a VC funding, just following modern design trends where \"design == aesthetics\". Yuck. I am happy to see the project thrive. reply aniviacat 7 hours agoparentI don't know if that's true for non-developers. (Of course non-developers aren't the target yet, but they hopefully will be in the future.) I'd assume that non-developers are usually the main audience for a project website like this. Developers can simply look at the Github readme and get their near plain text overview there. reply ohmyiv 5 hours agoparentprev> Nitpick (or is it?) We're all nitpicking no matter what our thoughts are on the design. I have my own thoughts on the design, but I'm more excited about the product than to put any more care in what the website looks like. It's easy enough to ignore and doesn't have an effect on the product. reply Sammi 7 hours agoparentprevWhere's the Ladybird?? reply bezier-curve 7 hours agoparentprevHave to agree, though I think as the saying goes, \"don't hate the playa, hate the game\". Capitalism sucks. Sorry for my non-HN-like comment, but it's the truth. reply FireInsight 7 hours agoprevI think people in this comment section are too harsh on the website. I think the design is pleasing and functional, and the project is communicated about clearly. The AI laptop is a bit of a shame, and the logo being bland instead of clever is a bummer, though. But plenty of products have a similar front page style, and it doesnt make me feel like it's a soulless startup. reply aquova 6 hours agoparentI agree, after reading the comments, I was expecting a complete monstrosity, but it's a simple, informative website. That style of website design is used because it's appealing and easy to parse. I'm not sure what people were expecting. I must admit I'm not crazy about the logo though. It's fine at the top of a page, but I cant see it as my browser icon on my desktop, and it's much less appealing and identifiable than the old Ladybird. reply cfiggers 5 hours agoparentprevI actually really like the logo. It's a simple, mathematically-defined curve that also resembles an abstract ladybird opening its wings. You don't find that clever? reply beretguy 5 hours agorootparentI'd rather see an actual ladybird somewhere than some facebook's new meta-like logo. reply spencerchubb 50 minutes agoprevCan anyone explain like I'm an idiot concrete reasons how Google Chrome's dominance is bad for the web? Preferably things that have actually happened, not what might happen reply RiverCrochet 42 minutes agoparentGoogle tried to get this through, and was only prevented because competing browsers didn't play along. https://en.wikipedia.org/wiki/Federated_Learning_of_Cohorts reply stewx 47 minutes agoparentprevOne answer: Google's interests are at cross-purposes. They are simultaneously making money from showing you advertisements, but also giving you a browser, and sometimes these conflict. For example, they recently rolled out a new on-by-default \"feature\" to identify yourself to advertisers. Another answer: concentration of power and market share stifles innovation. Look at what happened to Internet Explorer when Microsoft was the only game in town. reply metabagel 23 minutes agoparentprevWould you want to have all smart TVs manufactured by the dominant advertising company? How do you think that would turn out? reply parhamn 23 minutes agoparentprevIMO the more interesting question is \"why not fork Chromium\"? The corporate effects of a browser monopoly are pretty obvious. The less obvious question, and Im genuinely curious, is why do you need to rewrite the engines when there are at least 2 good compliant open source ones? The only way an engine rewrite is worthwhile is if yours is significantly leaner or faster, both seem very unlikely. An seemingly-impossible milestone of hitting party isnt that interesting, is it? reply skeaker 26 minutes agoparentprevWhat's wrong with looking at what might happen? reply bradley_taunt 5 hours agoprevLove the project, but that website is pretty cold and soulless (as mentioned by others). I quickly put together a \"cleaner\" design for anyone interested, which also uses the original (and objectively better) logo: https://ladybird-dev.netlify.app/ reply beretguy 5 hours agoparentI love this version SO MUCH BETTER. Clean, easy to read and I don't have to scroll down for half an hour to get to the bottom. I hate \"modern design\", whatever it is. To much padding, to much useless css and styles. reply aAaaArrRgH 5 hours agoparentprevHard disagree. If you're a fan of the strictly functional \"what's CSS?\" look, you might as well stick to viewing README.md on GitHub and call it a day. reply endemic 53 minutes agoparentprevYeah, that original logo is way better. Kind of reminiscent of the Firefox logo before it got abstracted away into minimalism. reply kome 3 hours agoparentprevThis version is clearly superior, both in design and use. Great start! reply hipinspire 7 hours agoprevIt is a great honor to see a website I designed and coded at the top of the Hacker News front page! A big thank you to Chris Wanstrath for allowing me to work on it. I hope Ladybird becomes a mainstream browser, and I feel this is a moment similar to when Firefox rebranded from Phoenix. P.S. Check out my UI/UX portfolio at https://hipfolio.co reply marvinborner 6 hours agoparentIt's really rare to see websites that look modern while still being very minimal and fast. No JS, no frameworks - great job! reply hipinspire 5 hours agorootparentThank you! Coming from an OS developer, it's a great honor! reply awesomekling 7 hours agoparentprevThank you for making the website! :) reply hipinspire 5 hours agorootparentThank you, Andreas! Keep up the great work! reply chappi42 6 hours agoparentprevIt's beautiful! -- Cool that Chris Wanstrath gives massive support to this project (financial and (most likely) time). reply hipinspire 5 hours agorootparentThank you very much! That is right! reply parasti 5 hours agoparentprevFYI, a couple of sections are cut off on mobile. reply hipinspire 4 hours agorootparentThanks for sharing! Could you please email a screenshot with the phone model, OS version, and browser name to the email address in my HN profile? reply bArray 6 hours agoprevDiscussed previously: https://news.ycombinator.com/item?id=40845951 https://news.ycombinator.com/item?id=40845954 reply dang 1 hour agoparentThanks! Macroexpanded: Welcome to Ladybird - https://news.ycombinator.com/item?id=40845951 - July 2024 (94 comments) The Ladybird Browser Initiative - https://news.ycombinator.com/item?id=40845954 - July 2024 (13 comments) Ladybird browser update (June 2024) [video] - https://news.ycombinator.com/item?id=40838973 - June 2024 (1 comment) Ladybird browser spreads its wings - https://news.ycombinator.com/item?id=40746804 - June 2024 (304 comments) Ladybird browser update (March 2024) [video] - https://news.ycombinator.com/item?id=39889576 - April 2024 (2 comments) Understanding Complexity Like an Engineer – The Case of the Ladybird Browser - https://news.ycombinator.com/item?id=39342887 - Feb 2024 (55 comments) The Ladybird browser project - https://news.ycombinator.com/item?id=39271449 - Feb 2024 (284 comments) Ladybird browser update (July 2023) [video] - https://news.ycombinator.com/item?id=36939402 - July 2023 (1 comment) Chat with Andreas Kling about Ladybird and developing a browser engine - https://news.ycombinator.com/item?id=36620450 - July 2023 (65 comments) Shopify Sponsored Ladybird Browser - https://news.ycombinator.com/item?id=36502583 - June 2023 (1 comment) I have received a $100k sponsorship for Ladybird browser - https://news.ycombinator.com/item?id=36377805 - June 2023 (166 comments) Early stages of Google Docs support in the Ladybird browser - https://news.ycombinator.com/item?id=33511831 - Nov 2022 (84 comments) Github.com on Ladybird, new browser with JavaScript/CSS/SVG engines from scratch - https://news.ycombinator.com/item?id=33273785 - Oct 2022 (1 comment) Ladybird: A new cross-platform browser project - https://news.ycombinator.com/item?id=32809126 - Sept 2022 (473 comments) Ladybird: A truly new Web Browser comes to Linux - https://news.ycombinator.com/item?id=32014061 - July 2022 (8 comments) Ladybird Web Browser - https://news.ycombinator.com/item?id=31987506 - July 2022 (2 comments) Ladybird Web Browser – SerenityOS LibWeb Engine on Linux - https://news.ycombinator.com/item?id=31976579 - July 2022 (2 comments) reply CrimsonCape 1 hour agoprevDoes awesomekling get to remain BDFL of Ladybird? I appreciated the project because it gave the impression that all the pork was stripped away and 100% focused on the engineering. Meanwhile Mozilla spends a massive chunk of money on the organization and the philanthropy and the blog posts, and the activism, and the salaries of people who have little resemblance to engineers. reply awesomekling 48 minutes agoparentI’m still the BDFL but my role is evolving a bit as I’m now also running the nonprofit. We are definitely a stripped down operation, and we will spend as much of our funding as possible on engineer salaries for the foreseeable future. reply PedroBatista 8 hours agoprevBest of luck. If these guys succeed medium to long term they also prove it’s actually possible to build a browser if you focus on building a browser and not anything else. It would be a statement of hope that we are not condemned to Google’s corporate strategy and the absolute rot the Mozilla foundation has become. I know pretty much everything is not in their favor but I truly believe it’s still possible for a couple of guys with their head between their shoulders to actually “change the World”. I need to sleep at night after all. reply bayindirh 8 hours agoprevI wonder what would happen if Ladybird matures well to compete with Firefox and Chrome (hope so), and it's just forked away by some company and completely closed down in a whim, because BSD-2 allows that. reply rice7th 8 hours agoparentAnd so? Yes people (and companies) would fork your code, but the most realistic scenario would be that the original ladybird would still be the most relevant browser of it's family, just like firefox, so the problem kinda resolves by itself reply bayindirh 6 hours agorootparentThen why KDE's Konqueror is not the most prominent browser of the KHTML family, but Safari is? reply efilife 6 hours agorootparentprevImagine if ladybird gets used regularly by ~1000 nerds, which is its current audience, then gets forked by microsoft and the current ME gets replaced by ladybird. Even if ladybird got over 9000 users, there's no competing with megacorps. Also, its* not it's reply paddim8 5 hours agorootparentWell maybe they're ok with that? They want browser diversity. Getting Microsoft to use a new engine is better for diversity than if they just used chromium like now. reply bayindirh 5 hours agorootparentGetting Microsoft to use a new engine and contribute back to the original repository is better for diversity, but forking and running away with it is certainly not. reply r3trohack3r 2 hours agorootparent> Forking and running away with it is certainly not If your goal is browser diversity, this would take an ecosystem of 2 browser engines and turn it into an ecosystem of 4. That seems in-line with the goal of browser diversity. reply beretguy 5 hours agorootparentprev> Getting Microsoft to use a new engine and contribute back to the original repository is better for diversity Oh no no no. We don't need microsoft contributing anything into this. They will mess up everything and push their agenda. reply bayindirh 5 hours agorootparentIdeally, yes. Microsoft should stay away from this, but I wanted to highlight that adopting a technology doesn't automatically make it better for diversity. Google was almost killing Go overnight because they wanted more user data from people using the language. reply PedroBatista 8 hours agoparentprevWhy is that such a problem other than the human factor of seeing your code being used by some guys you don’t like? reply zogrodea 8 hours agorootparentI think the issue isn't the potential forking, but that the potential fork may become a dominant and closed one. If one values the web being somewhat open/less monopolistic, an open source web browser would be more appealing. I have faith in the Ladybird browser project to avoid such a situation though. reply bayindirh 7 hours agorootparentprev> seeing your code being used by some guys you don’t like? This is not even in the list of my concerns. I just don't like to see efforts of hundreds if not thousands of volunteers are rolled into a closed source application and distributed for the profit of a couple of people who pat themselves on the back because they got their next car/house/whatever for free. This is why I prefer GPL over BSD/MIT. reply bigstrat2003 40 minutes agorootparentThat sounds no different from \"code being used by some guys you don't like\" to me, to be honest. If some company took my permissively licensed work and turned it into a commercial product, why would I take issue? I put my work out there for the betterment of all, and it is still bettering the world even in its new form. I have no complaints with that. reply master-lincoln 8 hours agorootparentprevIt supports capitalistic predatory tactics that erode our society. Better to exclude them... reply mnmalst 4 hours agoparentprevPersonally am asking myself what the benefits of the BSD clause compared to a more restrictive license are. The only reason I personally can see is that they want to have to option to close the browser themself in the future. reply bigstrat2003 43 minutes agorootparentBelieve it or not, plenty of people prefer permissive licenses because they grant more freedom. Not everyone agrees with the GPL. reply infecto 7 hours agoparentprevLots of big assumptions there. 1) Ladybird matures with a community around it. 2) A company actually cares enough to fork it. 3) Said fork becomes the dominant version. 4) Company closes down fork. reply bayindirh 7 hours agorootparentYeah, I did these assumptions because I saw potential in the project and witnessed the cycle enough times to worry about its future. On the other hand, it's a food for thought. Just to play with and explore the possibilities. reply rty32 8 hours agoparentprevIf you the amount of features in Chrome and Firefox (just those in the standard, nothing extra), you would know \"mature well to compete\" is a long way away, if not impossible. And I don't see any problem with forking. Tons of browser bugs were found, reported and fixed exactly because companies forked them. And remember that Blink is forked from Webkit. reply bayindirh 8 hours agorootparentI have seen IE's rise and fall. Netscape's rise, burn and rebirth as Firefox, saw Safari as a fork of KHTML and rise of Chrome. Ladybird might be added to this list. It's not impossible. It'll be a winding and hard road to go, but it is not a path with no end. You don't need to fork a codebase to fix its bugs. It's GitHub's workflow (fork -> PR -> merge). What I meant, as noted in this thread, is a hard and closed fork propelled with money and corporate greed, which eclipses the open and primary version and drown it in the process. EEE'ing it, basically. This is why I prefer GPL (preferably V3+). If you want to improve it, it's open. If you want to monetize and EEE it, then nah. It's not allowed. reply 95 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Ladybird Browser Initiative, a non-profit founded by GitHub's Chris Wanstrath and SerenityOS's Andreas Kling, aims to develop a web browser free from corporate and advertising influence.",
      "With $1 million from Wanstrath and previous funding from Shopify, Ladybird plans to release an alpha version by 2026, focusing on user privacy and open standards.",
      "The initiative has already hired several full-time developers and made significant progress, despite skepticism, aspiring to offer a truly independent browsing experience."
    ],
    "commentSummary": [
      "Ladybird Web Browser has transitioned to a non-profit organization with a $1M donation from GitHub Founder Chris Wanstrath.",
      "Founder Andreas Kling addressed the project's future, emphasizing optimism despite doubts about developing a new browser without significant funding.",
      "The team aims to support open web standards, maintain a small team for financial sustainability, and keep the project open-source under a permissive license while exploring memory-safe languages for future development."
    ],
    "points": 153,
    "commentCount": 348,
    "retryCount": 0,
    "time": 1719928905
  },
  {
    "id": 40857041,
    "title": "With fifth busy beaver, researchers approach computation's limits",
    "originLink": "https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/",
    "originBody": "With Fifth Busy Beaver, Researchers Approach Computation’s Limits Read Later Share Copied! Comments Read Later Read Later computability With Fifth Busy Beaver, Researchers Approach Computation’s Limits By Ben Brubaker July 2, 2024 After decades of uncertainty, a motley team of programmers has proved precisely how complicated simple computer programs can get. Read Later Kristina Armitage and Nico Roper/Quanta Magazine By Ben Brubaker Staff Writer July 2, 2024 View PDF/Print Mode computabilitycomputer sciencecomputer-assisted proofsgamesmathematicspatternsproofsAll topics Introduction Once upon a time, over 40 years ago, a horde of computer scientists descended on the West German city of Dortmund. They were competing to catch an elusive quarry — only four of its kind had ever been captured. Over 100 competitors dragged in the strangest creatures they could find, but they still fell short. The fifth busy beaver had escaped their clutches. Of course, that slippery beast and its relatives aren’t actually rodents. They’re simple-looking computer programs that take a surprisingly long time to run. The search for these unusually active programs has connections to some of the most famous open questions in mathematics, and roots in an unsolvable problem as old as computer science itself. That’s precisely what makes the hunt so compelling. Three of the Dortmund participants summed up the prevailing attitude in a postmortem report: “Though we know we cannot win the war against the mathematical law, we would like to win a battle.” The spiritual sequel to the Dortmund hunt began two years ago, when a graduate student named Tristan Stérin launched a website announcing the Busy Beaver Challenge. This time, the participants would cooperate, and everyone was welcome. Over time, the online community grew to include more than 20 contributors from around the world, most of them without traditional academic credentials. Today, the team declared victory. They’ve finally verified the true value of a number called BB(5), which quantifies just how busy that fifth beaver is. They obtained the result — 47,176,870 — using a piece of software called the Coq proof assistant, which certifies that mathematical proofs are free of errors. “The sociological and mathematical engineering that they’ve done to get this far is really impressive,” said Cristopher Moore, a computer scientist at the Santa Fe Institute. “I’m surprised how fast they did it,” said Damien Woods, a computer scientist at Maynooth University in Ireland and Stérin’s adviser. “That’s really like Usain Bolt territory.” The search for the busy beaver is ultimately a trophy hunt. The specific value of BB(5) doesn’t have applications in other areas of computer science. But for busy beaver hunters, the hard-fought victory over mathematical impossibility is its own reward. It may be the last battle they’ll ever win. To Halt or Not to Halt The programs that interest busy beaver hunters aren’t written in any ordinary programming language — they’re instructions for venerable (and theoretical) computers called Turing machines. The pioneering computer scientist Alan Turing conceived of these hypothetical devices in 1936 as a way to mathematically model the process of computation. Turing machines perform computations by reading and writing 0s and 1s on an infinite tape divided into square cells, using a “head” that operates on one cell at a time. Every machine has a unique set of rules that governs its behavior. Each of these rules specifies what the head should do when it moves into a new cell, depending on whether it encounters a 0 or a 1 already there. This means a Turing machine’s instructions can be summarized in a table with one row for each rule and two columns (one for when the head encounters a 0 and the other for when it encounters a 1). One rule might be, “If you read a 0, replace it with a 1, move one step to the right, and consult rule C,” in the first column, and “if you read a 1, leave it unchanged, move one step to the left, and consult rule A,” in the second. This is what all the rules look like, except for one special rule that tells the machine when to stop running. (You can play around with Turing machines using an interactive simulator on the Busy Beaver Challenge website.) Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters Kristina Armitage/Quanta Magazine Introduction But just because there’s a way for a Turing machine to halt, that doesn’t mean it will ever actually do so. It could, in the simplest case, get stuck in an endless loop that cycles through a few states. Is there any guaranteed way to tell if a Turing machine with a particular set of rules will halt or run forever? That’s the essence of the halting problem, the famously thorny problem that makes the busy beaver hunt so intoxicating. Turing proved that the halting problem has no general solution — you can never be sure if an approach that works for one machine will work for another. The halting problem isn’t always hard for specific machines. Some, for instance, halt relatively quickly. This three-rule Turing machine halts after 11 steps. Kristina Armitage/Quanta Magazine; Rui Braz for Quanta Magazine; source: Justin Blanchard Introduction Others fall into infinite loops that are easy to spot. This three-rule Turing machine quickly enters an infinite loop. Kristina Armitage/Quanta Magazine; Rui Braz for Quanta Magazine; source: Iijil Introduction But spend enough time playing with Turing machines, and you’ll occasionally encounter one that resists this easy classification. Will its journey ever end, or is it doomed to wander the tape forever? “Until you run it long enough, you’re not going to have any idea what the heck it’s doing,” Moore said. “And how long is long enough?” Bringing Up Beavers Beavers enter the story with the mathematician Tibor Radó, who was no stranger to long journeys. Born in Hungary in 1895, he entered university to study civil engineering, but his education was derailed by the outbreak of World War I. Dispatched to the Russian front, he was captured and sent to a prison camp in Siberia, where he began to study mathematics under the tutelage of a fellow prisoner. After four years, Radó managed to escape. He traveled thousands of miles across the Russian Arctic and eventually made it back to Budapest, where he returned to school and published dozens of math papers in the 1920s, before accepting a faculty job at Ohio State University in 1930. He stayed there for 35 years. Even the wildest journeys sometimes halt abruptly. Late in life, Radó became interested in the theory of computation. He wasn’t satisfied with Turing’s proof, which involved mind-bending self-referential arguments about the infinite set of all possible Turing machines. To distill the essence of the halting problem into a simpler form, Radó imagined sorting Turing machines into groups based on how many rules they had — one group for all one-rule Turing machines, another for all two-rule machines, and so on. Sure, that leaves infinitely many such groups, since a Turing machine can have any number of rules. But the number of distinct machines in every group is finite, since there are only so many possible combinations of rules. It’s easier to reason about these finite groups than to consider all machines at once. In a 1962 paper, Radó used these groups to define what he called the “Busy Beaver game.” In 1962, Tibor Radó invented the busy beaver game by reformulating a famously unsolvable problem about the behavior of Turing machines. Courtesy of The Ohio State University Archives To play, start by picking a group — that is, the number of rules your machines will have. Feed each machine in the group a tape with 0s in every cell. Some machines will hum along forever. The rest will eventually halt. Of these, some will halt quickly, some will take longer, and one will be the last to stop running. Every group will have a longest-running member, and Radó called these especially industrious machines busy beavers. In the group with n rules, the number of steps that the busy beaver machine takes before halting is the corresponding busy beaver number BB(n). The goal of the game is to nail down the exact values of these numbers. To succeed, you must determine the runtime of every machine that halts, to see which takes the longest. You must also prove that all the rest never stop. Measuring runtimes is reasonably straightforward, since it’s easy to simulate Turing machines on an ordinary computer. But proving that a machine runs forever amounts to solving the halting problem for it: a specific version of a task that’s certifiably impossible in its most general form. “We’re playing at this edge of unknowability,” said Shawn Ligocki, a software engineer and Busy Beaver Challenge contributor. But where exactly does unknowability begin? Turing machines with just a few rules look pretty simple. How hard could it be to understand a program that fits on an index card? Brady’s Bunch of Beavers The one-rule case is easy, because there are effectively only two possibilities. If the rule tells the Turing machine to halt when it sees a 0, it stops on the first step. Any other rule will cause the machine to march along the tape forever, since it will encounter a 0 in every cell. That means BB(1) = 1. Beyond this baby beaver, a hunter armed with only pencil and paper quickly encounters a problem. With two rules, there are already over 6,000 distinct Turing machines to consider; that number swells to millions with three rules, and to billions with four. Working all these cases out by hand is out of the question. “Obviously, you cannot do this,” Ligocki said. “And even if you could, no one would believe you.” Allen Brady developed busy beaver hunting techniques throughout the 1960s and determined the value of the fourth busy beaver number in 1974. Courtesy of Elizabeth Brady That means this problem rooted in the foundations of computation can only be solved with the help of computers. A fairly simple program suffices to prove that BB(2) = 6. But BB(3) is already much harder to find. Soon after Radó introduced the game, a handful of researchers began the hunt. One of them was Allen Brady, a mathematics graduate student at Oregon State University. Perhaps inspired by the university’s beaver mascot, Brady set out to see how many of the beasts he could bag. He quickly realized that the key to making progress was to ignore any differences between Turing machines that don’t matter. Consider, for instance, a machine with many rules where the first one tells it to halt if it reads a 0. “What’s in the rest of those transitions doesn’t matter, because it immediately halts,” Ligocki said. Most of these machines are redundant, as far as the busy beaver game is concerned, so you can rule them all out at once. Brady integrated this process into a computer program for simulating Turing machines, which constructed a sort of family tree for machines with the same number of rules, based on the similarity of their initial behavior. The program split the tree into multiple branches only when differences between machines became relevant, and lopped off whole branches in which the simulation halted or entered an infinite loop. Writing this computer program was one thing, but Brady still had to find a computer powerful enough to run it. In 1964 that wasn’t easy. He ended up securing access to a computer in a primate research lab 90 miles away, in a Portland suburb fittingly named Beaverton. The SDS 920 was a powerful computer in the early 1960s. As a graduate student, Brady had to drive 90 miles to Beaverton, Oregon, to run his busy beaver hunting program on one. Courtesy of Science History Institute Introduction Midway through his work, Brady learned that he’d been scooped: Radó’s graduate student Shen Lin had already proved that BB(3) = 21. (He and Radó would publish the results in 1965, less than a year before Radó’s death.) Undaunted, Brady pressed on and wrote a dissertation that confirmed Lin’s results and made partial progress on BB(4) — a case that Radó had deemed “entirely hopeless.” BB(4) was difficult not just because of the sheer number of cases, but because four-rule machines are capable of much richer behavior. All two-rule machines that don’t halt get stuck in easily detectable endless loops. In the three-rule case, a few dozen machines run forever without looping. Proving that these machines never halted required different techniques. With four rules, there are thousands of these non-looping machines. After graduating, Brady identified new species of non-halting Turing machines and gave them fanciful names like shadow trees and tail-eating dragons. In 1966, he discovered a four-rule machine that ran for 107 steps before halting, and he conjectured that it was the elusive fourth busy beaver. He was correct, but it took him until 1974 to prove that no halting machine ran longer. By then Brady had taken up long-distance running himself, competing in marathons around the country while working as a professor of computer science at the University of Nevada, Reno. He wrote up his proof in an internal technical report, and didn’t publish it in an academic journal until nine years later. It was the last busy beaver number humanity would know for over 40 years. Take Five The year Brady published his proof was also the year of the Dortmund competition — the first big hunt for the fifth busy beaver. With five rules, there are nearly 17 trillion possible Turing machines — even just listing them all at a rate of one per millisecond would take over 500 years. Techniques like Brady’s family-tree method that narrowed the search space would be indispensable, but programs would still have to run extremely fast to have any hope of success. The Dortmund contestants each developed their own beaver search programs and presented the longest-running five-rule Turing machines they could find — the busiest one halted after over 100,000 steps. Coverage of the contest in Scientific American in 1984 introduced the game to a new generation of researchers. One of them soon demolished the Dortmund record with a machine that halted after over 2 million steps. Among the other new hunters were Heiner Marxen and Jürgen Buntrock, graduate students in Berlin who began working on the problem together in their spare time. They developed new mathematical techniques for accelerating the simulation of Turing machines. But their interest faded after they failed to dethrone the 2-million-step champ. Years later, in 1989, Marxen was working as a programmer at a company that had acquired a powerful new computer, and he decided to dust off his beaver-hunting program. He left it running over the weekend, hoping to reproduce the discovery of the 2-million-step machine. Instead, his program found one that halted after a whopping 47,176,870 steps. At first he thought there must have been a bug in the code. “After several hours I stopped debugging and started to have a strange feeling,” Marxen wrote in an email. Buntrock soon replicated the result, and they published a paper about it in early 1990, in the heady months that followed the fall of the Berlin wall. In fact, Marxen had caught the busy beaver, but it would take over 30 years to prove that all remaining machines never halted. In the early 2000s, a Bulgarian computer scientist named Georgi Ivanov Georgiev came tantalizingly close. At the time, he was employed as a systems administrator for the state-owned telecommunications company, and the job demanded little of him. He worked obsessively on BB(5) for two years, spending hours every day refining a computer program that could identify exotic new species of non-halting machines. The final product was 6,000 lines of dense uncommented code, which took over a week to run. It left around 100 Turing machines unresolved. After analyzing those machines by hand, he winnowed the list down to just 43 holdouts. Georgi Georgiev, also known as Skelet, classified all but 43 five-rule Turing machines in 2003. The holdouts, notoriously difficult to analyze, were named Skelet machines in his honor. Genka Georgieva Introduction In 2003, Georgiev posted his results online under the pseudonym Skelet, Bulgarian for skeleton. “As a student I was very thin, and my classmates came up with the nickname,” he explained in an email. Marxen encouraged Georgiev to keep going, but the two years of intense work had taken their toll. “At the end of this period, I cannot create any new ideas,” Georgiev said. “I was very tired.” It was a common outcome for busy beaver researchers. For decades, they’d labored alone or in pairs, without much recognition from the broader academic community. It would take a collective effort to finish the job. Calling All Hunters That effort began with Tristan Stérin. He became adept at computer programming at an early age after befriending a competitive coding enthusiast on an instant messaging platform in the late 2000s. But he soon realized the culture of programming contests wasn’t a good fit. “I’m not a competitive person,” he said. “I like to see a problem and think about it for three months rather than having 30 minutes.” That inquisitive spirit led Stérin from France to graduate school in Ireland, where he worked with Woods on DNA computing, the study of how to implement algorithms using strands of DNA. In the summer of 2020, Woods sent him a survey paper about busy beavers by the computer scientist Scott Aaronson. Stérin was instantly transfixed. After collaborating with Woods on a paper about the capabilities of larger Turing machines, he turned to BB(5), resolving to prove once and for all that Marxen and Buntrock’s 47-million-step machine really was the fifth busy beaver. “I had the strong intuition that I could not do it myself,” Stérin said. “But I also had the intuition that it could be done.” In 2022, Tristan Stérin initiated the Busy Beaver Challenge, an online collaboration to conclusively determine the value of the fifth busy beaver number. “I definitely could never have done this on my own,” he said. Graham Murphy Photography From the beginning, Stérin knew that a conclusive proof would have to be well documented and reproducible, because any tiny software bug would be fatal to the whole effort. Georgiev’s program was incredibly sophisticated, but other researchers found it impenetrable. “When you go back and try to review his code, you just give up,” said Justin Blanchard, a software developer and former math graduate student who joined the Busy Beaver Challenge. Any new approach would effectively have to start from square one. Stérin decided to build on the traditional approach, but with some tweaks. He would start by using Brady’s family-tree method to eliminate redundant Turing machines and identify which ones halted within 47 million steps. But unlike Brady or his successors, Stérin didn’t include any code to weed out machines that ran forever. Instead, he planned to tackle those using self-contained programs, one for each method of proving a Turing machine will never halt. Dividing the task into pieces this way would make it easier for collaborators to work on each part independently and cross-check their results. At the end of 2021, Stérin wrote the computer program for the first step. It produced a list of about 120 million Turing machines that would be enough to determine BB(5) — all the rest were redundant. Of those 120 million, roughly a quarter halted before Marxen and Buntrock’s machine, leaving 88 million that were still under consideration. To help analyze these machines, Stérin built an online interface for visualizing their behavior on “space-time diagrams,” two-dimensional grids of dark and light squares representing 0s and 1s, respectively. Each row in a diagram documents one step in a Turing machine’s evolution. The top row represents the tape after the first step, the second row shows it after the second step, and so on. Viewed this way, the machines in Stérin’s menagerie spring to life, displaying a dizzying variety of different patterns. Establishing that Marxen and Buntrock really had found the fifth busy beaver would mean proving that every one of them ran forever. Kristina Armitage/Quanta Magazine; source: Busy Beaver Challenge (busy beaver, #7410754, #14263231) Introduction That was the part Stérin knew he couldn’t do alone. Plus, he had other obligations — he’d founded a software startup with some friends, and he still had to finish his dissertation. In the spring of 2022, Stérin and a few early converts started a forum and separate chat server on the independent platform Discord. Then it was time to find contributors. The Busy Beaver Bug It didn’t take long for Shawn Ligocki to join the team. Perhaps it was fate: He was born in Beaverton in 1985, though he first heard of busy beavers in 2004, at the end of his first semester of college. Over winter break, he started tinkering with beaver search algorithms together with his father, Terry, an applied mathematician at Lawrence Berkeley National Laboratory. A month later, when Ligocki was back in college and busy with classes, his father called him, excited. He’d decided to test one of their algorithms on a variant of the original busy beaver game invented by Brady, and found a machine that shattered Brady’s record. They reached out to Brady, who’d retired — he was delighted and publicized the result on his website. Shawn Ligocki soon found himself in email correspondence with busy beaver researchers around the world. “The community was very, very welcoming,” he said. “That’s when I caught the busy beaver bug.” Shawn Ligocki has been interested in the busy beaver search since 2004, when he was a freshman in college. He introduced the Busy Beaver Challenge team to a promising 30-year-old technique called the closed tape language method. Kira Treibergs Introduction One memorable encounter occurred while Ligocki was visiting Germany the summer after his sophomore year, when he took a side trip to Berlin to meet up with Marxen. “We got through the language barrier through the medium of busy beavers,” he said. The medium of beer also helped. Ligocki ended up having too many and missed his train back to Hamburg. The busy beaver bug stuck with Ligocki throughout college, but when he graduated and found a job, life got in the way. He returned to the hunt from time to time, but never for long. In early 2022, he set up an online discussion group to help researchers stay in touch. Then in May, Stérin discovered the mailing list and sent an invitation to join the Busy Beaver Challenge. Ligocki needed no convincing. Justin Blanchard helped transform the closed tape language method into one of the team’s most powerful techniques. Tommy Riley York One of his first contributions to the project was reviving a technique invented by Marxen, which they’d discussed in that Berlin pub 16 years earlier. Called the “closed tape language method,” it was a new way to identify patterns on a Turing machine’s tape that indicate it will never halt. This is the basic strategy behind programs that identify loopers and many other species of non-halting machines, but the closed tape language method had the potential to identify a much broader class of patterns using a unified mathematical framework. Ligocki wrote a blog post introducing his new collaborators to the technique, but even though the theoretical idea was very general, he didn’t know how to write a program that would cover all the cases. Blanchard figured out how to do that shortly after joining the project in the fall, but his program was relatively slow. Then two other contributors found ways to make it run much faster. Within the span of a few months, the closed tape language technique had gone from a promising idea to one of their most powerful tools. It could even handle 10 of Georgiev’s 43 holdouts, nicknamed Skelet machines in his honor. “This thing would never have existed with any one person contributing,” Ligocki said. A Monster Approaches As the months passed, new contributors discovered the Busy Beaver Challenge and began chipping away at different parts of the problem. But many machines remained unsolved, and two developed especially fearsome reputations. The first was Skelet #1, which kept alternating between phases of predictable and chaotic behavior. Then in March 2023, Ligocki and Pavel Kropitz — a Slovakian contributor who doesn’t speak English and communicates with the rest of the team using Google Translate — developed a series of ideas that finally cracked it open. Using a souped-up version of Marxen and Buntrock’s 30-year-old accelerated simulation technique, they discovered that the tug-of-war between order and chaos did end, but only after more than a trillion trillion steps. Then it finally settled into a repeating cycle that was itself unusually long. Practically all infinite loops begin repeating within 1,000 steps; Skelet #1’s was more than 8 billion steps long. “Who ordered that?” Blanchard said. “Where did that come from? Why is it here?” Kristina Armitage/Quanta Magazine; source: Busy Beaver Challenge (skelet #1, skelet #17) The machine’s behavior was so strange, and the proof combined so many different ideas, that for nearly five months Ligocki wasn’t sure of the result. That period of uncertainty was dispelled by a new contributor — a 21-year-old self-taught programmer named Maja Kądziołka, who mostly goes by the single name mei. Kądziołka grew up in Poland and attended the University of Warsaw for one semester in fall 2021 before dropping out — the rigidity of the curriculum and the move to remote instruction after a surge of Covid-19 cases didn’t fit well with their learning style. They worked at a software company for a little over a year but increasingly found the work draining, and began looking for something more intellectually stimulating. They found it in Coq, the software designed to encode and certify the validity of mathematical proofs. algorithms The Most Important Machine That Was Never Built May 3, 2023 Read Later The Busy Beaver Challenge contributors were already using computer programs in their proofs, but like paper-and-pencil proofs, computer programs are vulnerable to errors. In Coq proofs, the code won’t run unless every line logically follows from the preceding ones, making errors effectively impossible. To Kądziołka, figuring out how to craft these proofs began to feel like a game. “It’s almost addictive,” they said. “I started at a normal hour, and then it was night. Then it was morning.” After learning Coq, Kądziołka began looking for an open problem to test it out. That’s when they found the Busy Beaver Challenge. A few weeks later, they’d translated several of the team’s proofs into Coq, including Ligocki and Kropitz’s proof that Skelet #1 never halts — Ligocki could finally be sure about it. Suddenly, an even higher standard of rigor than Stérin’s emphasis on reproducibility seemed possible. And it had all started with someone who had no formal training at all — an amateur mathematician. “Let’s remember that means a lover of mathematics,” Moore said. “It is not a pejorative term.” The Dam Breaks Around the same time, a graduate student named Chris Xu made a breakthrough on the second monstrous machine — Skelet #17. It was usually easy to summarize the behavior of even the most fiendish five-rule Turing machines once you figured out how they worked. “Then you encounter some bullshit like Skelet 17, and you go, ‘Nah, the universe is trolling us,’” Kądziołka said. Understanding Skelet #17 by studying the patterns on its tape was like deciphering a secret message wrapped in four layers of encryption: Cracking one code just revealed another totally unrelated code, and two more below that. Xu had to decipher all of them before he could finally prove that the machine never halted. Xu’s proof was brilliant, but it involved some mathematical intuition that nobody knew how to formalize in the precise terms demanded by Coq. What’s more, the Busy Beaver Challenge’s work wasn’t done: While Skelet #1 and #17 were the two machines that had seemed most formidable, some others remained to be solved, and still more had only been solved using inefficient programs. That was no way to convince the world. “We wanted to make sure that it was something reasonably reproducible,” Blanchard said, “and also not write a proof where we would say, ‘Step 63: Let this program run for six months.’” Over the following months, the community slowly cobbled together proofs for the remaining machines, but most had yet to be translated into Coq. Then in April a mysterious new contributor known only by the pseudonym mxdys came in to finish the job. Nobody on the team knows where mxdys is located or any other personal details about them. In a Discord direct message exchange, they mentioned a long-standing interest in mathematical games, but they declined to provide more information about their background. On May 10, mxdys posted a characteristically succinct message to the Discord server: “The Coq proof of BB(5) is finished.” Stérin replied a minute later with a series of seven exclamation points. In a matter of weeks, mxdys had refined the community’s techniques and synthesized their results into a single 40,000-line Coq proof. “This is not a thing that’s easy to formalize,” said Yannick Forster, a Coq expert at the French national research institute Inria who reviewed the proof. “I’m still positively shocked.” The machine that Marxen and Buntrock had discovered over 30 years earlier, which halted after 47 million steps, really was the fifth busy beaver. “These news are very exciting for me,” Georgiev wrote in an email. “I never expected that this problem would be solved in my time.” But for another Busy Beaver pioneer, the news came too late. Allen Brady died on April 21, less than a month before the proof was finished. He was 90 years old. Where Beavers Roam The Busy Beaver Challenge contributors have begun to draft a formal academic paper describing their results, supplementing mxdys’ Coq proof with a human-readable one. That’ll take a while: Most machines were proved non-halting in multiple ways, and the team will need to decide how best to combine the results into a single proof. Abstractions blog How the Slowest Computer Programs Illuminate Math’s Fundamental Limits December 10, 2020 Read Later Meanwhile, part of the team has moved on to the next beaver. But just four days ago, mxdys and another contributor known as Racheline discovered a barrier for BB(6) that seems insurmountable: a six-rule machine whose halting problem resembles a famously intractable math problem called the Collatz conjecture. Connections between Turing machines and the Collatz conjecture date back to a 1993 paper by the mathematician Pascal Michel, but the newly discovered machine, dubbed “Antihydra,” is the smallest one that appears unsolvable without a conceptual breakthrough in mathematics. That adds an extra layer of significance to the BB(5) result. “It’s conceivable that this is the last busy beaver number that we will ever know,” Aaronson said. There are many variants of the original busy beaver problem, and some Busy Beaver Challenge contributors plan to keep working on these. But not everyone intends to continue this work. They each came to the project on their own, for their own reasons, and their journeys are beginning to diverge. Stérin wants to develop software tools to facilitate collaborative online projects in other areas of mathematics. “The thing that BB challenge brought me is the deep, deep, deep conviction that it’s an extremely effective way of performing research,” he said. “It deserves to have a bigger stage.” Related: Computer Scientists Attempt to Corner the Collatz Conjecture Decades-Old Graph Problem Yields to Amateur Mathematician Building the Mathematical Library of the Future Kądziołka too is pulling back, after developing a fascination with the European international rail network. “I will probably come back to busy beaver things again at some point, but currently it’s not the thing on my mind,” they said. “I’m currently pursuing becoming a train driver.” Ligocki thinks he’ll keep up his busy beaver hunting, but after 20 years of switching between bursts of intense activity and not thinking about beavers at all, he’s learned not to put too much stock in his predictions. “It’s kind of like the halting problem,” he said. “You just never can quite tell what’s going to happen.” Editor’s note: Scott Aaronson is a member of Quanta Magazine’s advisory board. By Ben Brubaker Staff Writer July 2, 2024 View PDF/Print Mode computabilitycomputer sciencecomputer-assisted proofsgamesmathematicspatternsproofsAll topics Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article Tracing the Hidden Hand of Magnetism in the Galaxy",
    "commentLink": "https://news.ycombinator.com/item?id=40857041",
    "commentBody": "With fifth busy beaver, researchers approach computation's limits (quantamagazine.org)152 points by LegionMammal978 4 hours agohidepastfavorite33 comments tromp 2 hours ago> There are many variants of the original busy beaver problem, and some Busy Beaver Challenge contributors plan to keep working on these. One such variant is a functional busy beaver defined in terms of the lambda calculus [1]. Since it measures program size in bits rather than states, it allows many more values to be determined (37 so far versus only 6 for TMs), and the gap between the largest known value and values beyond Graham's Number is a mere 13 program bits. A closely related variant [2] can be directly expressed in terms of Kolmogorov complexity, which Mikhail Andreev argues [3] is crucial for applications in Information Theory. [1] https://oeis.org/A333479 [2] https://oeis.org/A361211 [3] https://arxiv.org/pdf/1703.05170 reply pvg 2 hours agoprevSome comments on this result by Scott Aaronson https://scottaaronson.blog/?p=8088 And for leisure-class beavers, some big related threads from earlier this year: https://news.ycombinator.com/item?id=40453221 https://news.ycombinator.com/item?id=38113792 https://news.ycombinator.com/item?id=37910297 reply titanomachy 2 hours agoprevI worked for a couple years with a formidable and incomprehensibly smart engineer who ascended the IC ranks faster than anyone I’ve seen at an elite tech company. He quit the job a few years ago, and when I asked him his plans he told me he was going to work on the busy beaver problem. I can’t help but wonder if he is mxdys, the pseudonymous contributor mentioned in the article who wrapped up the formal proof of BB(5). I’ll probably never know. reply jebarker 1 hour agoparentIf it were them would you be surprised that they wanted to remain anonymous? reply kryptiskt 2 hours agoprevOne notable thing here is that the proof is a Coq proof. I wonder if it is the first significant proof that starts out implemented in a theorem prover, instead of being a known proof translated to such a system. Note that there have been computer-assisted proofs before (four-color theorem, Kepler's conjecture), but those were not done in a formally verified setting until later. reply LegionMammal978 2 hours agoparentAs far as I am aware, all of the proofs and techniques for each machine were present before mxdys managed to get the whole theorem into Coq: the main problem was that the deciders and manual proofs were disorganized and somewhat suspect. The worst offenders here were Skelet #1, which needed a bespoke program to accelerate it to its ultimate pattern [0], and Skelet #17, which took Xu seven pages' worth of dense reasoning to prove non-halting [1]. The full Coq proof put a much-needed degree of confidence into these results. [0] https://www.sligocki.com/2023/03/13/skelet-1-infinite.html [1] https://discuss.bbchallenge.org/t/skelet-17-does-not-halt/18... reply poikroequ 1 hour agoparentprev> [The four color theorem] was the first major theorem to be proved using a computer. https://en.m.wikipedia.org/wiki/Four_color_theorem I guess maybe I don't understand what you mean by \"formally verified setting\", but I believe the four color theorem was first proven using a computer. > Although flawed, Kempe's original purported proof of the four color theorem provided some of the basic tools later used to prove it. It sounds like Kempe laid some of the groundwork, but then the theorem was ultimately proved using a computer. I could be wrong though, I'm not an expert in this area. reply nyssos 41 minutes agorootparentThe original four color theorem proof used a computer as a computational aid for some nasty casework: the procedure for checking each case and the list of cases that needed to be checked were found by hand. Proving something in a theorem prover means the proof itself is an object constructed in the prover's language. reply ks2048 1 hour agoparentprevApparently, this is the proof in 19,000 lines of Coq: https://github.com/ccz181078/Coq-BB5/blob/main/BB52Theorem.v reply smokel 1 hour agoprevThe original Busy Beaver paper by Tibor Radó (\"On Non-Computable Functions\") is actually quite easy and fun to read. For a modern version of the paper with some additional notes, see https://data.jigsaw.nl/Rado_1962_OnNonComputableFunctions_Re... reply phaedrus 2 hours agoprevI wrote program to solve the cutting stock problem (https://en.wikipedia.org/wiki/Cutting_stock_problem) for a personal project. I couldn't (or didn't want to) use any existing program for it because my stock involved cutting pieces shaped like either /---/, /---|, or |---| and I didn't want to waste material on the 45 cut. I find it interesting that the description of Brady's program to optimize search for BB(4) by cutting out search subtrees whose differences don't matter is fairly close to a description of what I did to make my program fast. reply nickdrozd 1 hour agoprevCongratulations to the team! So the (blank tape) halting problem is solved for 5-state 2-color Turing machine programs. Has anyone tried applying these same techniques to the 2-state 4-color case? That seems like it would probably be tractable, although generally speaking colors are more powerful than states, so there might be some surprises there. (6-state 2-color and 2-state 5-color both seem intractable, perhaps even provably so.) By the way, there is an extremely stupid but disturbingly widespread idea that humans are able to just intuit solutions to the halting problem, using the mind's eye or quantum mechanics in the brain or whatever. Needless to say, this did not factor into the proof. reply LegionMammal978 1 hour agoparent> Has anyone tried applying these same techniques to the 2-color 4-state case? I assume you mean the 4-color case. As I understand it, the deciders currently in use are sufficient to prove all the 2×4 holdouts non-halting. So the current champion gives us Σ(2,4) = 2,050 and S(2,4) = 3,932,964, barring some big errors in the decider design. The result just hasn't been organized in one place. > (6-state 2-color and 2-state 5-color both seem intractable, perhaps even provably so.) Yes, 2×5 has the Hydra, and 6×2 has the Antihydra, which compute the same iteration, but with different starting points and halting conditions. The standard conjecture (related to Mahler's 3/2 problem) is that this iteration is uniformly distributed mod 2, and a proof of that conjecture would very likely prove both machines non-halting, by yielding suprema and infima on the cumulative ratio of 0s to 1s. But of course there is no known method of proof. reply srcreigh 25 minutes agoparentprev> By the way, there is an extremely stupid but disturbingly widespread idea that humans are able to just intuit solutions to the halting problem, using the mind's eye or quantum mechanics in the brain or whatever. Needless to say, this did not factor into the proof. The year is 52,000 CE and humans have solved BB(18) in the sense of exhaustively categorizing halting vs non-halting 19-state no-input programs. They have used a proof generator based on a logical theory called Aleph*, and at that time it had been known for 1.5k years that ZFC is incapable of establishing BB(18). Compared to the year 2024 CE, considerable millennia before Aleph* came into use, it is clear that no program written at that point in history was capable of even using brute force proof checking to solve BB(18) in theory (like how we can enumerate and check ZFC proofs today to solve BB(??) in theory). That's what is meant by the \"humans intuit solutions to the halting problem\" position. AFAIK, there's no known hard, theoretical reason why the above laid out future history cannot take place. And due to BB being incomputable, humans had to develop new theory to be able to construct the programs required. Something has to be accredited for the results, and it can't be computation since the programs did not exist. reply LegionMammal978 12 minutes agorootparent> AFAIK, there's no known hard, theoretical reason why the above laid out future history cannot take place. Probably the biggest issue is that they'd have no method to establish that Aleph* is consistent. To continue this BB chain indefinitely, you must invent further and further first-order theories, each of which might not be consistent, let alone Σ₁-sound. And with an Σ₁-unsound theory, any halting proof might not hold up in the standard model of the integers. You'd effectively have to postulate an indefinite amount of oracular knowledge. In any case, the BB-related evidence for that position rested on BB(5) being determinable by extending the techniques used for BB(4). But in fact, it turns out that similar extensions don't even get you to BB(6). So there isn't anything to support the position, other than the pure speculation that anything is physically achievable given enough time. reply ganzuul 8 minutes agoparentprev> extremely stupid This is simply a test for if consciousness has infinite computational resources. reply tromp 1 hour agoparentprev> the 2-color 4-state case? You mean the 2-state 4-color case... reply nickdrozd 1 hour agorootparentFixed, thanks reply wodenokoto 2 hours agoprevSo we were just lucky that all non-halting programs of length 5 just happened to be provably non-halting? reply tromp 2 hours agoparentThe article touches on that: > But just four days ago, mxdys and another contributor known as Racheline discovered a barrier for BB(6) that seems insurmountable: a six-rule machine whose halting problem resembles a famously intractable math problem called the Collatz conjecture. Connections between Turing machines and the Collatz conjecture date back to a 1993 paper by the mathematician Pascal Michel, but the newly discovered machine, dubbed “Antihydra,” is the smallest one that appears unsolvable without a conceptual breakthrough in mathematics. reply LegionMammal978 2 hours agoparentprevYes. In fact, Allen Brady feared as early as 1988 that there would be a totally intractable machine with 5 states [0]: > Prediction 5. It will never be proved that Σ(5) = 1,915 and S(5) = 2,358,064. (Or, if any larger lower bounds are ever found, the new values may be substituted into the prediction.) > Reason: Nature has probably embedded among the five-state holdout machines one or more problems as illusive as the Goldbach Conjecture. Or, in other terms, there will likely be nonstopping recursive patterns which are beyond our powers of recognition. Luckily, this prediction did not come to pass, but only by a margin of one extra state. [0] Allen Brady, \"The Busy Beaver Game and the Meaning of Life\", in Rolf Herken (ed.), The Universal Turing Machine: A Half-Century Survey, Oxford University Press, 1988, pp. 259–277. This chapter can also be found in the 2nd ed., Springer, 1995, pp. 237–254. reply ks2048 2 hours agoprevAccording to Scott Aaronson's blog post on this, there are 16,679,880,978,201 5-state Turing machines. I wonder if we know what percentage of them halt? Edit: number of TM for n states: (4n + 1)^(2n). Found this (for smaller n), which is the kind of analysis I was curious about: https://github.com/LukasKalbertodt/beaver reply jl6 3 hours agoprevBB(0) = 0 BB(1) = 1 BB(2) = 4 BB(3) = 6 BB(4) = 13 They just proved that BB(5) = 47,176,870. It is known that BB(6) must be at least 10^10^...^10 (a tower of exponents fifteen levels high). https://en.wikipedia.org/wiki/Busy_beaver#Known_values_for_%... reply pdonis 3 hours agoparentThe definitions of the \"BB\" function don't all appear to be the same. The article referenced in this overall discussion says BB(2) = 6. In the notation of the Wikipedia article you reference, this would be S(2) = 6; S is the number of steps. What has now been proved is that S(5) = 47,176,870. However, your BB values for 0, 1, 2, 3, and 4 match the Wikipedia article's notation for Sigma; Sigma is the number of 1s written on the tape at halting. In that notation, what has now been proved is Sigma(5) = 4098. reply LegionMammal978 3 hours agorootparentYeah, this is a bit confusing, and the subject of repeated internal controversy. Most of the twentieth-century authors focused on the number of 1s, Σ(n), following Radó's original practice of treating σ(M) as the score of a machine M in the \"Busy Beaver game\". But when Aaronson re-popularized it in 2020 [0], he used BB(n) to denote the number of steps (which Radó called S(n)), and the bbchallenge project has been using this latter convention for publicity. Pascal Michel's website [1] has all the Σ(n) and S(n) bounds up to n = 7. Personally, I think both functions have their strengths and weaknesses. Σ(n) is easier to calculate for machines that run too long to be simulated directly (e.g., Skelet #1 from the article) but leave a known pattern on the tape, and it also has historical priority. But S(n) has a simpler argument for being undecidable, since it provides a trivial filter for testing if a candidate machine cannot halt. Also, σ(M) is a bit weird in that it has no lower bound in terms of s(M), since an adversarial machine could do a colossal amount of work before wiping its tape at the end. Regardless, past BB(3), there isn't any known size where the champion machines for Σ(n) and S(n) are different. (At least, the sets of champion machines aren't disjoint: Σ(5) = 4098 is shared by both the S(5) champion and another machine that runs a quarter as long.) The score of a machine is dominated by googological strength rather than technicalities in the definition. [0] https://scottaaronson.blog/?p=4916 [1] https://bbchallenge.org/~pascal.michel/ha reply nickdrozd 1 hour agorootparent> past BB(3), there isn't any known size where the champion machines for Σ(n) and S(n) are different. My feeling is that this trend cannot continue forever, and for infinitely many N they are different. If they are always the same, then you could find the steps champion just by finding the marks champion. This would be convenient, because as you pointed out, steps are more logically important, while marks are more practically important. But this feels too good to be true, and so it probably isn't. reply LegionMammal978 1 hour agorootparentHmm, around n = 2 or k = 2, there are only 2 added transitions for a machine to do \"the next big thing\" googologically, so that doesn't leave much slack for many different machines at the same level. But maybe that could happen closer to the n = k line, where each increment adds many new transitions. Or to the contrary, maybe each increment just does several \"next big things\". reply pdonis 2 hours agorootparentprevThanks for this information, it's very helpful! Also I had no idea that \"googological strength\" was a thing. :-) reply Sharlin 2 hours agorootparentI'll just leave this here: https://googology.fandom.com/wiki/Googology_Wiki reply Natsu 2 hours agoparentprevLooking at the pictures on Wikipedia regarding those programs, it's interesting how they seem to result in fractals. reply LegionMammal978 2 hours agorootparentThis mainly has to do with the BB(5) champion having \"bouncing\" behavior: it moves from the left side of the current pattern to the right side and back again, each time extending it slightly. Since the time it takes to grow the pattern is strictly proportional to its current size, you end up with a bunch of parabolas that appear self-similar. reply bryan0 2 hours agoprevAaronson’s post on BB(5): https://scottaaronson.blog/?p=8088 reply nayuki 1 hour agoprev [–] From the article: > To distill the essence of the halting problem into a simpler form, Radó imagined sorting Turing machines into groups based on how many rules they had — one group for all one-rule Turing machines, another for all two-rule machines, and so on. Sure, that leaves infinitely many such groups, since a Turing machine can have any number of rules. But the number of distinct machines in every group is finite, since there are only so many possible combinations of rules. > With two rules, there are already over 6,000 distinct Turing machines to consider; that number swells to millions with three rules, and to billions with four. I'm pretty sure the standard terminology is \"states\", not \"rules\". This deviation made it harder to understand. Each state produces 2 transition rules, depending on the symbol at the tape head. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers have determined the value of BB(5), representing the complexity of a simple computer program known as the fifth busy beaver, after decades of effort.",
      "The value was verified using the Coq proof assistant, ensuring mathematical accuracy, and the fifth busy beaver halts after 47,176,870 steps.",
      "This achievement involved a diverse team, including contributions from both amateur mathematicians and experts, and may be the last busy beaver number determined due to the immense difficulty of BB(6)."
    ],
    "commentSummary": [
      "Researchers are approaching the computational limits with the fifth busy beaver problem, which determines the maximum steps a Turing machine with a given number of states can take before halting.",
      "A significant milestone has been achieved with a proof using Coq, a formal verification tool, marking progress in the field.",
      "The fifth busy beaver number, BB(5), has been proven to be 47,176,870 steps, though challenges like the intractable six-rule machine related to the Collatz conjecture remain."
    ],
    "points": 152,
    "commentCount": 33,
    "retryCount": 0,
    "time": 1719930451
  },
  {
    "id": 40857517,
    "title": "Meta 3D Gen",
    "originLink": "https://ai.meta.com/research/publications/meta-3d-gen/",
    "originBody": "Our approach Research Meta AI Meta Llama Blog Try Meta AI About us Responsibility People Careers Overview Infrastructure Resources Demos Clear Clear Our approach > Research > Meta AI Meta Llama Blog Try Meta AI GRAPHICS COMPUTER VISION Meta 3D Gen July 02, 2024 Abstract We introduce Meta 3D Gen (3DGen), a new state-of-the-art, fast pipeline for text-to-3D asset generation. 3DGen offers 3D asset creation with high prompt fidelity and high-quality 3D shapes and textures in under a minute. It supports physically-based rendering (PBR), necessary for 3D asset relighting in real-world applications. Additionally, 3DGen supports generative retexturing of previously generated (or artist-created) 3D shapes using additional textual inputs provided by the user. 3DGen integrates key technical components, Meta 3D AssetGen and Meta 3D TextureGen, that we developed for text-to-3D and text-to-texture generation, respectively. By combining their strengths, 3DGen represents 3D objects simultaneously in three ways: in view space, in volumetric space, and in UV (or texture) space. The integration of these two techniques achieves a win rate of 68% with respect to the single-stage model. We compare 3DGen to numerous industry baselines, and show that it outperforms them in terms of prompt fidelity and visual quality for complex textual prompts, while being significantly faster. Download the Paper AUTHORS Written by Raphael Bensadoun Tom Monnier Yanir Kleiman Filippos Kokkinos Yawar Siddiqui Mahendra Kariya Omri Harosh Roman Shapovalov Emilien Garreau Animesh Karnewar Ang Cao Idan Azuri Iurii Makarov Eric-Tuan Le Antoine Toisoul David Novotny Oran Gafni Natalia Neverova Andrea Vedaldi Publisher Arxiv only Research Topics Graphics Computer Vision Related Publications July 02, 2024 GRAPHICS COMPUTER VISION Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials Yawar Siddiqui, Tom Monnier, Filippos Kokkinos, Mahendra Kariya, Yanir Kleiman, Emilien Garreau, Oran Gafni, Natalia Neverova, Andrea Vedaldi, Roman Shapovalov, David Novotny July 02, 2024 Read the Paper July 02, 2024 GRAPHICS COMPUTER VISION Meta 3D TextureGen: Fast and Consistent Texture Generation for 3D Objects Raphael Bensadoun, Yanir Kleiman, Idan Azuri, Omri Harosh, Andrea Vedaldi, Natalia Neverova, Oran Gafni July 02, 2024 Read the Paper June 20, 2024 COMPUTER VISION ICON: Incremental CONfidence for Joint Pose and Radiance Field Optimization Weiyao Wang, Pierre Gleize, Hao Tang, Xingyu Chen, Kevin Liang, Matt Feiszli June 20, 2024 Read the Paper June 17, 2024 COMPUTER VISION Move Anything with Layered Scene Diffusion Jiawei Ren, Frost Xu, Jerry Wu, Ziwei Liu, Tao Xiang, Antoine Toisoul June 17, 2024 Read the Paper See All Papers Latest News Hardware MSVP: Meta’s first ASIC for video transcoding May 18, 2023 Help Us Pioneer The Future of AI We share our open source frameworks, tools, libraries, and models for everything from research exploration to large-scale production deployment. Join our Team Our approach About AI at Meta Responsibility People Careers Research Infrastructure Resources Demos Product experiences Meta AI Latest news Blog Newsletter Foundational models Meta Llama Our approach Our approachAbout AI at MetaResponsibilityPeopleCareers Research ResearchInfrastructureResourcesDemos Product experiences Meta AI Latest news Latest newsBlogNewsletter Foundational models Meta Llama Privacy Policy Terms Cookies Meta © 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40857517",
    "commentBody": "Meta 3D Gen (meta.com)144 points by meetpateltech 3 hours agohidepastfavorite45 comments wkat4242 1 hour agoI can't wait for this to become usable. I love VR but the content generation is just sooooo labour intensive. Help creating 3D models would help so much and be the #1 enabler for the metaverse IMO. reply samspenc 37 minutes agoparentThere are a few services that do this already, but they are all somewhat lacking, hopefully Meta's paper / solution brings some significant improvements in this space. The existing ones: - Meshy https://www.meshy.ai/ one of the first movers in this space, though it's quality isn't that great - Rodin https://hyperhuman.deemos.com/rodin newer but folks are saying this is better - Luma Labs has a 3D generator https://lumalabs.ai/genie but doesn't seem that popular reply jsheard 1 hour agoparentprevVR is especially unforgiving of \"fake\" detailing, you need as much detail as possible in the actual geometry to really sell it. That's the opposite how these models currently work, they output goopy low-res geometry and approximate most of the detailing with textures, which would be immediately register as fake with stereoscopic depth perception. reply spookie 3 minutes agorootparentYup. I'm doing a VR project, urban environment. Haven't really found a good enough solution for 3D reconstruction from images. Yes, there is gaussian splatting, NeRF and derivatives, but their outputs _really don't look good_. It's also necessary to have the surface remeshed if you go through that route, and then you need to retexture it. Crazy thing being able to see things up to scale and so close up :) reply Liquix 2 minutes agorootparentprevdoes displacement mapping not hold up in VR? reply SV_BubbleTime 58 minutes agorootparentprevAgreed. Everyone I see text to 3D, it’s ALWAYS textured. That is the obvious give-away that it is still garbage. Show me text to wireframe that looks good and I’ll get excited. reply surfingdino 6 minutes agoprevNot sure how adding Gen AI is going to make VR any better? I wanted to type \"it's like throwing good money after bad\", but that's not quite right. Both are black holes where VC money is turned into papers and demos. reply Filligree 3 minutes agoparentThe ultimate end goal is a VR game with infinite detail. Sword Art Online, however, remains fiction. Perhaps for the best. reply iamleppert 1 hour agoprevI tried all the recent wave of text/image to 3D model services, some touting 100 MM+ valuations and tens of millions raised and found them all to produce unusable garbage. reply architango 1 hour agoparentI have too, and you’re quite right. Also the various 2D-to-3D face generators are mostly awful. I’ve done a deep dive on that and nearly all of them seem to only create slight perturbations on some base model, regardless of the input. reply jampekka 1 hour agoparentprevThe gap from demos/papers to reality is huge. ML has a bad replication crisis. reply SV_BubbleTime 53 minutes agorootparentSAI showed Stavle Diffusion 3 pictures of women laying on grass. If you haven’t been following SD3… https://arstechnica.com/information-technology/2024/06/ridic... reply LarsDu88 52 minutes agoprevThis is crazy impressive, and the fact they have the whole thing running with a PBR texturing pipeline is really cool. That being said, I wonder if the use of signed distance fields (SDFs) results in bad topology. I saw a paper earlier this week that was recently released that seems to build \"game-ready\" topology --- stuff that might actually be riggable for animation. https://github.com/buaacyw/MeshAnything reply jsheard 46 minutes agoparentThe obvious major caveat with MeshAnything is that it only scales up to outputs with about 800 polygons, so even if their claims about the quality of their topology hold up it's not actually good for much as it stands. For reference a modern AAA game character model can easily exceed 100,000 polygons, and models made to be rendered offline can be an order of magnitude bigger than that. reply explaininjs 2 hours agoprevLooks fine, but you can tell the topology isn’t good based on the lack of wireframes. reply tobyjsullivan 1 hour agoparentThey seem to admit as much in Table 1 which indicates this model is not capable of \"clean topology\". Somewhat annoyingly, they do not discuss topology anywhere else in the paper (at least, I could not find the word \"topology\" via Ctrl+F). reply jsheard 1 hour agoparentprevCredit where it's due, unlike most of these papers they do at least show some of their models sans textures on page 11, so you can see how undefined the actual geometry is (e.g. none of the characters have eyes until they are painted on). reply SV_BubbleTime 56 minutes agorootparentSans texture is not wireframe though. They have a texture, it’s just all white. The wire frame is going to be unrecognizable-bad. Still a ways to go. reply dyauspitr 1 hour agoparentprevThat doesn’t matter for things like 3D printing and CNC machining. Additionally, there are other mesh fixer AI tools. This is going to be gold for me. reply jsheard 1 hour agorootparentHowever if you 3DP/CNC these you'll only get the base shape, without any of the fake details it painted over the surface. Expectation vs. reality: https://i.imgur.com/82R5DAc.png reply dyauspitr 34 minutes agorootparentThat’s still not bad. I can use the normal and texture maps to generate appropriate depth maps to put the details in and do some final Wacom touch ups. Way better than making the whole thing from scratch. reply eropple 1 hour agorootparentprev> That doesn’t matter for things like 3D printing and CNC machining It absolutely does. But great, let's look forward to Printables being ruined by off-model nonsense. reply dyauspitr 33 minutes agorootparentWhy does it matter. As long as there are no holes, my vectric software doesn’t care. reply SV_BubbleTime 56 minutes agorootparentprevIt matters so much more, GP is just being hopeful and soon to be disappointed. reply nuz 2 hours agoparentprevSuch a silly argument. Fixing topology is a nearly solved problem in geometry processing. (Or just start with a good topology and 'paste' a texture onto it like they develop techniques for here.) reply zemo 1 hour agorootparentdepends what you're talking about and what your criteria is. In gamedev, studios typically use a retopology tool like topogun (https://www.topogun.com/) to aid in the creation of efficient topologies, but it's still a manual task, as different topologies have different tradeoffs in terms of poly count, texture detail, options for how the model deforms when animated, etc. For example you may know that you're working on a model of a player character in a 3rd person game where the camera is typically behind you, so you want to spend more of your budget on the _back_ of the model than the _front_, because the player is typically looking at their character's back. If your criteria is \"find the minimum number of polygons\", sure, it's solved. That's just one of many different goals, and not the goal that is typically used by gamedev, which I assume to be a primary audience of this research. reply explaininjs 2 hours agorootparentprevNo… it’s not. But if you know something I don’t the 5 primes will certainly be happy to pay you handsomely for the implementation! reply nuz 2 hours agorootparenthttps://github.com/wjakob/instant-meshes reply explaininjs 2 hours agorootparentA piece of software that hasn’t been touched in 5 years, let alone adopted in any professional production environment? Cool… reply portaouflop 1 hour agorootparentAFAICT it’s used in professional applications and software does not need to be constantly updated, especially if it’s not for the web. reply RicoElectrico 2 hours agorootparentprevIt's an essential skill for reading scientific papers to notice what isn't there. It's as important as what is there. In my field, analog IC design, if we face a wall, we often do some literature review with a colleague and more often than not, results are not relevant for commercial application. Forget about Monte Carlo, sometimes even there aren't full PVT corners. reply jampekka 26 minutes agorootparentThis is indeed a side effect from research papers being read more outside academia (which is strictly a good thing in itself). In research one learns that most (almost all) papers oversell their results and a lot of stuff is hidden in the \"Limitations\" section. This is a significant problem, but not that big a problem within academia as everybody, at least within the field, knows to take the results with a grain of salt. But those outside academia, or outside the field, often don't take this into account. Academic papers should be read a bit like marketing material or pitch decks. reply 999900000999 58 minutes agoprevWould love for an artist to provide some input, but I imagine this could be really good if it generates models that you can edit or start from later . Or, just throw a PS1 filter on top and make some retro games reply rebuilder 1 hour agoprevI’m puzzled by the poor texture quality in these. The colours are just bad - it looks like the textures are blown out (the detail at the bright end clip into white) and much too contrasty ( the turkey does that transition from red to white via a band of yellow). I wonder why that is - was the training data just done on the cheap? reply firtoz 1 hour agoparentIt seems to be very well compared to the alternatives, however there's a long way to go forward indeed reply anditherobot 1 hour agoprevCan this potentially support : - Image Input to 3D model Output - 3D model(format) as Input Question: What is the current state of the art commercially available product in that niche? reply egnehots 1 hour agoparentThis a pipeline for text to 3D. But it's using for 3D gen, a model that is more flexible: https://assetgen.github.io/ It can be conditioned on text or image. reply moffkalast 1 hour agoparentprevMeshroom, if you have enough images ;) reply Simon_ORourke 1 hour agoprevAre those guys still banging on about that Metaverse? That's taken a decided back seat to all the AI innovation in the past 18 months. reply dvngnt_ 1 hour agoparentzuck has said before that ML will help make the \"metaverse\" more viable. he still needs a moat with its own ecosystem like the iphone reply localfirst 1 hour agoprevcan somebody please please integrate SAM with 3d primitive RAGging? This is the golden chalice solution as a 3d modeler, having one of those \"blobs\" generated by Luma and likes aren't very useful reply GaggiX 2 hours agoprevIn the comparison between the models only Rodin seems to produce clean topology, hopefully in the future we will see a model with the strength of both, hopefully from Meta as Rodin is a commercial model. reply kgraves 2 hours agoprev [–] Can this be used for image to 3D generation? What is the SOTA in this area these days? reply tobyjsullivan 1 hour agoparentThe paper suggests Rodin Gen-1 [0] is capable of image-to-shape generation. [0] https://hyperhuman.deemos.com/rodin reply Fripplebubby 1 hour agoparentprev [–] I think what they did here was go text prompt -> generate multiple 2d views -> reconstruction network to go multiple 2d images to 3d representation -> mesh extraction from 3d representation. That's a long way of saying, no, I don't think that this introduces a component that specifically goes 2d -> 3d from a single 2d image. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Meta 3D Gen (3DGen) is a cutting-edge pipeline that generates 3D assets from text in under a minute, excelling in prompt fidelity and quality.",
      "It supports physically-based rendering (PBR) and generative retexturing, outperforming industry standards in both speed and visual quality.",
      "3DGen integrates Meta 3D AssetGen and Meta 3D TextureGen, representing 3D objects in view, volumetric, and UV spaces."
    ],
    "commentSummary": [
      "Meta is developing a new tool, Meta 3D Gen, aimed at improving VR content generation, which is currently labor-intensive.",
      "Existing services like Meshy, Rodin, and Luma Labs lack the quality needed for detailed VR models, highlighting the need for better solutions.",
      "The community is hopeful that Meta's solution will address issues such as poor texture quality and inefficient topology in current 3D model generation tools."
    ],
    "points": 144,
    "commentCount": 45,
    "retryCount": 0,
    "time": 1719933565
  },
  {
    "id": 40857009,
    "title": "Adding Mistral Codestral and GPT-4o to Jupyter Notebooks",
    "originLink": "https://github.com/pretzelai/pretzelai/blob/main/README.md",
    "originBody": "Hey HN! We’ve forked Jupyter Lab and added AI code generation features that feel native and have all the context about your notebook. You can see a demo video (2 min) here: https:&#x2F;&#x2F;www.tella.tv&#x2F;video&#x2F;clxt7ei4v00rr09i5gt1laop6&#x2F;viewTry a hosted version here: https:&#x2F;&#x2F;pretzelai.appJupyter is by far the most used Data Science tool. Despite its popularity, it still lacks good code-generation extensions. The flagship AI extension jupyter-ai lags far behind in features and UX compared to modern AI code generation and understanding tools (like https:&#x2F;&#x2F;www.continue.dev and https:&#x2F;&#x2F;www.cursor.com). Also, GitHub Copilot still isn’t supported in Jupyter, more than 2 years after its launch. We’re solving this with Pretzel.Pretzel is a free and open-source fork of Jupyter. You can install it locally with “pip install pretzelai” and launch it with “pretzel lab”. We recommend creating a new python environment if you already have jupyter lab installed. Our GitHub README has more information: https:&#x2F;&#x2F;github.com&#x2F;pretzelai&#x2F;pretzelaiFor our first iteration, we’ve shipped 3 features:1. Inline Tab autocomplete: This works similar to GitHub Copilot. You can choose between Mistral Codestral or GPT-4o in the settings2. Cell level code generation: Click Ask AI or press Cmd+K &#x2F; Ctrl+K to instruct AI to generate code in the active Jupyter Cell. We provide relevant context from the current notebook to the LLM with RAG. You can refer to existing variables in the notebook using the @variable syntax (for dataframes, it will pass the column names to the LLM)3. Sidebar chat: Clicking the blue Pretzel Icon on the right sidebar opens this chat (Ctrl+Cmd+B &#x2F; Ctrl+Alt+B). This chat always has context of your current cell or any selected text. Here too, we use RAG to send any relevant context from the current notebook to the LLMAll of these features work out-of-the-box via our “AI Server” but you have the option of using your own OpenAI API Key. This can be configured in the settings (Menu Bar > Settings > Settings Editor > Search for Pretzel). If you use your own OpenAI API Key but don’t have a Mistral API key, be sure to select OpenAI as the inline code completion model in the settings.These features are just a start. We&#x27;re building a modern version of Jupyter. Our roadmap includes frictionless, realtime collaboration (think pair-programming, comments, version history), full-fledged SQL support (both in code cells and as a standalone SQL IDE), a visual analysis builder, a VSCode-like coding experience powered by Monaco, and 1-click dashboard creation and sharing straight from your notebooks.We’d love for you to try Pretzel and send us any feedback, no matter how minor (see my bio for contact info, or file a GitHub issue here: https:&#x2F;&#x2F;github.com&#x2F;pretzelai&#x2F;pretzelai&#x2F;issues)",
    "commentLink": "https://news.ycombinator.com/item?id=40857009",
    "commentBody": "Adding Mistral Codestral and GPT-4o to Jupyter Notebooks (github.com/pretzelai)129 points by prasoonds 4 hours agohidepastfavorite41 comments Hey HN! We’ve forked Jupyter Lab and added AI code generation features that feel native and have all the context about your notebook. You can see a demo video (2 min) here: https://www.tella.tv/video/clxt7ei4v00rr09i5gt1laop6/view Try a hosted version here: https://pretzelai.app Jupyter is by far the most used Data Science tool. Despite its popularity, it still lacks good code-generation extensions. The flagship AI extension jupyter-ai lags far behind in features and UX compared to modern AI code generation and understanding tools (like https://www.continue.dev and https://www.cursor.com). Also, GitHub Copilot still isn’t supported in Jupyter, more than 2 years after its launch. We’re solving this with Pretzel. Pretzel is a free and open-source fork of Jupyter. You can install it locally with “pip install pretzelai” and launch it with “pretzel lab”. We recommend creating a new python environment if you already have jupyter lab installed. Our GitHub README has more information: https://github.com/pretzelai/pretzelai For our first iteration, we’ve shipped 3 features: 1. Inline Tab autocomplete: This works similar to GitHub Copilot. You can choose between Mistral Codestral or GPT-4o in the settings 2. Cell level code generation: Click Ask AI or press Cmd+K / Ctrl+K to instruct AI to generate code in the active Jupyter Cell. We provide relevant context from the current notebook to the LLM with RAG. You can refer to existing variables in the notebook using the @variable syntax (for dataframes, it will pass the column names to the LLM) 3. Sidebar chat: Clicking the blue Pretzel Icon on the right sidebar opens this chat (Ctrl+Cmd+B / Ctrl+Alt+B). This chat always has context of your current cell or any selected text. Here too, we use RAG to send any relevant context from the current notebook to the LLM All of these features work out-of-the-box via our “AI Server” but you have the option of using your own OpenAI API Key. This can be configured in the settings (Menu Bar > Settings > Settings Editor > Search for Pretzel). If you use your own OpenAI API Key but don’t have a Mistral API key, be sure to select OpenAI as the inline code completion model in the settings. These features are just a start. We're building a modern version of Jupyter. Our roadmap includes frictionless, realtime collaboration (think pair-programming, comments, version history), full-fledged SQL support (both in code cells and as a standalone SQL IDE), a visual analysis builder, a VSCode-like coding experience powered by Monaco, and 1-click dashboard creation and sharing straight from your notebooks. We’d love for you to try Pretzel and send us any feedback, no matter how minor (see my bio for contact info, or file a GitHub issue here: https://github.com/pretzelai/pretzelai/issues) williamstein 2 hours agoThere are many other Jupyter notebooks with extensive AI integration. These are less (or not at all) open source, but more mature in some ways, having been iterated on for over a year: - https://noteable.io/ -- pretty good, but then they got acquirehired out of existence - https://deepnote.com -- also extensive AI integration and realtime collaboration - https://github.com/jupyterlab/jupyter-ai -- a very nice standard open source extension for gen AI in Jupyter, from an Amazon. JupyterLab of course also has fairly mature realtime collaboration now. - https://colab.google/ -- has great AI integration but of course only with Google-hosted models - https://cocalc.com -- very extensive AI integration everywhere with all the main hosted models, mostly free or pay as you go; also has realtime collaboration. (Disclaimer: I co-authored this.) - VS Code has a great builtin Jupyter notebook, as other people have mentioned. Am I missing any? reply prasoonds 2 hours agoparentThank you for the list - I think I've come across all of these in my research! I'll try highlight the differences for each. - https://noteable.io/ - as you say, it doesn't exist anymore - https://deepnote.com - Deepnote is closed source sadly - you can't run it locally, you can't tweak it, you need to learn a new interface and switch to it - https://github.com/jupyterlab/jupyter-ai - I actually mentioned this in the post but in my experience, the UX and features are far behind what we've built already. I'd love to hear from anyone who's tried jupyter-ai to give us a shot and let me know what we're missing! The plus side of jupyter-ai is of course that it supports way more models and the codebase is a lot more hackable than what we've built. - https://colab.google/ - closed-source, similar challenges as with Deepnote. Another big challenge is that if you want to use Colab as a company, AFAICT, you need use their enterprise version (so that you can have native data collectors, support guarantees etc) and that only works with GCP so if you're an AWS shop, this might be a deal-breaker. - https://cocalc.com - hadn't used it so far but congrats on a great project! Will check it out. Didn't look in detail but first impressions makes it look like a fairly different interface from Jupyter. One of our goals was to go to where the users already are - that meant Jupyter. So that's definitely a major difference. - VSCode - as I've mentioned elsewhere, we're targeting a more of an analytics usecase with the features we're building. VSCode has AI features of course! But we'll look quite different once we build more items on the roadmap :) reply williamstein 2 hours agorootparent> Didn't look in detail but first impressions makes it look like a fairly different interface from Jupyter. That is correct, in that it is a completely different implementation. Unlike Deepnote and Colab, we try to maintain the same keyboard shortcuts and other semantics as JupyterLab, as much as we can. If you don't already, we would love it if you came to the JupyerLab weekly dev meeting and demoed pretzelai: https://hackmd.io/Y7fBMQPSQ1C08SDGI-fwtg?view People from Colab, VS Code, etc. regularly come to the meeting and demo their JupyterLab related notebook work, and it's really good for the community. reply prasoonds 1 hour agorootparentOh cool! I'll definitely try to make it in one of the meetings :) reply spmurrayzzz 31 minutes agoparentprevmarimo is very good, been using it for a few months now and have switched over to it for most of my notebook-related tasks (it ships with copilot support) https://github.com/marimo-team/marimo reply stared 2 hours agoparentprevhttps://www.cursor.com/ - an AI-first VS Code clone VS Code (and Cursor) has so nice Jupyter support that I find it much better to use it for my workflow, rather than using any dedicated solution for Jupiter Notebooks only. reply prasoonds 1 hour agorootparentAgree with Daksh in the sibling comment. I think it's like you said - different people have different workflows and some might prefer using VSCode. IME though, most data scientists (and all data analysts) I worked with preferred using the company hosted internal Jupyter instance for their work. Also, as we build more features, we're definitely going in the direction of more analytics workloads (live collaboration, leaving comments, google-doc type versioning, fully AI driven analyses similar to OpenAI Interpreter mode etc) and with these features, I think there will be a clear divergence of feature-set in VSCode/PyCharm vs Pretzel. If I may ask, are you more on the engineering side (MLE) or more on the data side (Data Analyst)? EDIT: Just saw your other comment! reply dakshgupta 2 hours agorootparentprevIMO data scientists often are used to the jupyter form factor instead of the editor form factor, so I see why they would prefer this thing. reply stared 2 hours agorootparentI am a data scientist myself, one who moved from academia, vide https://p.migdal.pl/blog/2016/03/data-science-intro-for-math.... I used Jupyter Notebook before it was popular and back when I was a PhD student. I pushed in a few places for the unorthodox way of exploring data in a browser. Now, I am back - but only thanks to wonderful code editors and their good support of Jupyter Notebooks. I recommend VSC (or, this year, Cursor) as the default environment for data sci. reply prasoonds 1 hour agorootparentThat's a cool blogpost! I'm mostly using Cursor now (just waiting until someone makes a kick-ass Emacs package so I can switch back!) so I can definitely see your perspective. I'd be curious to hear a bit more about the kind of work you do that made you switch. Also if there's anything you miss in VSC/Cursor vs Jupyter. If you don't mind a small email exchange, let me know and I'll drop you a message :) reply TidbitsTornado 3 hours agoprevThis is a great implementation by your team + contributors. Simple but effective. And nice to see you’ve kept it open source instead of some other Show HN submissions where they take open source work, make is closed, change a few things, and claim they’ve created something great. Im curious to see if you continue building out some other features. While these are great features (copilot, chat, etc), I’d think most users would expect their IDE to have it out of the box (or with an extension) these days reply prasoonds 2 hours agoparentThanks for the kind words. Keeping Pretzel open-source was important to us - partly for trust reasons. When most people use Jupyter, they do so with sensitive data. Making a closed source tool simply wouldn't work. I wouldn't have trusted a closed source jupyter alternative with my company's data unless the counterparty was huge and well-known. To your second point - completely agree that most users would expect these feature from their IDEs today. But, only two IDEs support Jupyter Notebooks: VSCode and PyCharm. You can certainly use them for notebook work but most AI extensions written for VSCode wouldn't be optimized for notebook work (for eg, GH Copilot apparently has difficulty completing code across different cells as per a friend). Secondly, to your point, this is just a start - we're going to be building a lot more Data Analysis specific features that don't exist in any IDE. I think there's a decent space for a tool a like this. reply williamstein 3 hours agoparentprev> And nice to see you’ve kept it open source instead of some other Show HN submissions where they take open source work, make is closed, change a few things, and claim they’ve created something great. The seem to have taken a \"BSD-3-Clause\" licensed project and change it to AGPLv3 licensed one. That's not the same thing, but it's similar to what you're concerned about. reply prasoonds 2 hours agorootparentThis is true. All new added code is licensed under AGPLv3. But I fail to see how it's the same thing as modifying and open-source tool and re-selling it as a closed source tool. This is what AGPL gives us - anyone can use Pretzel however they want. They can even re-package and re-sell it if they want so long as they too open-source their modifications and improvements. Selecting the license for an open-source tool backed by a company is tricky. You want your code to be open-source for it's benefits (for eg, for us one benefit is building trust with people working with sensitive data). But, the history of open-source tools is full of tools that another company just started reselling without doing any of the work (sentry, mongodb etc). So, you need to find a balance. AGPLv3 strikes the right balance for us. reply williamstein 2 hours agorootparent> ... I fail to see how it's the same thing ... You're right that it is not the same thing, which is why I wrote \"That's not the same thing [...]\" in the comment you're responding to. I have done the same as you guys (building an AGPLv3 or 'worse' product on top of BSD licensed code) many, many times! Anyway, what you're doing is really exciting! reply prasoonds 2 hours agorootparentThat's fair, I was mostly responding to \"but it's similar to what you're concerned about\" because I didn't think the concerns are the same (but I can see your perspective on it too! While we are \"giving away\" the code, we're definitely posing some limitation). Thanks for the kind words, we're exited to be building this :) reply williamstein 58 minutes agorootparentI would also be happy to video chat with you guys anytime, since we've built similar things over the years (wstein at sagemath.com). reply chad1n 38 minutes agoprevI don't really get the appeal of this, I'd just use vscode with Jupyter if I really wanted \"ai\" integration since I can then access the whole ecosystem of extensions. The idea isn't that bad, but it lacks purpose. reply ramonverse 4 hours agoprevRamon here, the other cofounder of Pretzel! Quick update: Based on some early feedback, we're already working on adding support for local LLMs and Claude Sonnet 3.5. Happy to answer any questions! reply westurner 7 minutes agoparenthttps://news.ycombinator.com/item?id=38355385 : LocalAI, braintrust-proxy; promptfoo, chainforge, mixtral braintrust-proxy: https://github.com/braintrustdata/braintrust-proxy LocalAI: https://github.com/mudler/LocalAI E.g promptfoo and chainforge have multi-LLM workflows. Promptfoo has a YAML configuration for prompts, providers,: https://www.promptfoo.dev/docs/configuration/guide/ What is the system prompt, and how does a system prompt also bias an analysis? /? \"system prompt\" https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... reply morsch 41 minutes agoprevThese editors all focus on programming, does anybody have a recommendation for more general note-taking? I'd like to do things like organizing very rough notes, having them reformatted according to a general template, apply changes according to a prompt, maybe ask questions that refer to a collection of notes, ... reply lschneider 3 hours agoprevGithub Copilot is the most useful tool I've found in a long time and having that in Jupyter Notebooks is just awesome. I've been missing that for quite some time. Great work guys! reply skybrian 3 hours agoparentYou can also open Jupyter notebook files in VS Code, which would be another way to get AI autocomplete. I’m not enough of a Jupyter user to know whether it would make sense to use VS Code all the time. reply prasoonds 3 hours agorootparentYeah, this is definitely a good way to access AI code completion (inline or otherwise) in Jupyter notebooks. In fact, I know some data folks who've been using Jupyter from day 1 switching to VSCode simply because their company buys a copilot license for everyone and they really miss it their Jupyter workflow. reply prasoonds 3 hours agoparentprevAgree. We actually tried getting GitHub Copilot to work with Jupyter but GH doesn't have an official API. We actually took some time to reverse engineer an implementation from neovim GH Copilot extension [1] and from Zed [2] but found it too flaky and too much trouble in the end. Meanwhile, we also found a better speed/quality tradeoff with Codestral (since it has a fill-in-the-middle version, unlike a general LLM) so we decided to go with Codestral. This is inspired by continue.dev using Codestral for tab completion :) [1] https://github.com/github/copilot.vim [2] https://zed.dev/blog/copilot reply mritchie712 3 hours agoprev> GitHub Copilot still isn’t supported in Jupyter What do you mean by this? I've been using Copilot in VS Code .ipynb files for over a year now. reply prasoonds 3 hours agoparentIt's as others say - in VSCode there support for Copilot but most Data Scientists and specially analysts who don't spend most of their day in a text editor still use Jupyter Lab (or Notebook - I mean the software, not the file format) and with Codestral, we've found similarly good completions (sometimes better than Copilot) but at a much better speed and cost. reply wolftickets 3 hours agoparentprevI assume via Jupyter Notebook or Lab ( not VS Code running it ) reply Bjartr 3 hours agoparentprevThey likely mean Jupyter Notebook the application, not the notebook file format. reply widepeepo8 32 minutes agoprevCodeium(https://codeium.com/) already supports this, along with VSCode jupyter notebook extensions. It has 400k downloads on the VSCode extension store. don't really see the point of this when codeium already exists.. reply carreau 3 hours agoprevCurious about the limitations that made you fork it instead of making an extension. reply prasoonds 3 hours agoparentSo we discuss this briefly on our FAQ but let me try to expand on it. Our goal is to make a modern literate programming tool. On a surface level, a tool like that would end up looking very similar to Jupyter, though with better features. We've mentioned some things we'd like to have in this final tool in our README and also in the post above. Our first thought was to make a tool from scratch. The challenge was, it's very hard to get people to switch and so, we had to go where people already are - that meant Jupyter. We could've made this one feature an extension with some difficulty (in-fact, our early experiments, we started by making an extension). It would have some downsides - we wouldn't have granular control over certain core Jupyter behaviours like we do right now (for eg, we wanted to allow creating hidden folders to store some files). But we probably could have made a 95% working version of Pretzel work as a jupyter extension. The bigger reason we chose to fork was because down the line, we want to completely change the code execution model to being DAG based to allow for reproducible notebooks (similar to https://plutojl.org/ for eg). Similarly, we want to completely remove Codemirror and replace it with Monaco (the core editor engine in VSCode) to provide a more IDE like experience in Jupyter. These things simply couldn't have been done as extensions. reply dakshgupta 2 hours agoprevCurious on why you went with Codestral for autocomplete, does it outperform other local models? How is the performance compared to GPT or Claude for autocomplete? Any plans to finetune Codestral for this specific usecase? reply prasoonds 1 hour agoparentSo, we were tipped off to Codestral being really good because of continue.dev - for reference, that's a VSCode extension that gives you similar features to Cursor. After we trialled it out head-to-head against GPT-4o for fill-in-the-middle completion, in my experience (purely vibe based), it produced better completions maybe twice as fast as GPT-4o. We haven't tried vs Sonnet 3.5 yet - my hunch is that on the speed/quality/cost space, Sonnet will end up doing better than Codestral for some folks. Against general purpose local models (taking Llama-70B as a high-water mark), Codestral does better far better on code related tasks while being less than 1/3rd the size (22B!). That said, I'm definitely exited to try out DeepSeek Coder v2 - by all reports, it's amazing model for code completion and will likely also beat out Codestral. I don't think we're planning to fine-tune Codestral though (or any model for that matter). The latest models keep on becoming faster, better and cheaper AND they already work quite well. My thinking at this time is that waiting it out and having a big AI lab make a more capable general model is a better strategy. reply superkuh 18 minutes agoprevAt this point I'm almost afraid to ask but my attempts to figure it out have failed. What is a Jupyter notebook? Where is the code running? On your computer? On someone elses computer? reply mathiasn 1 hour agoprevHave you seen Livebook? Best Jupyter Notebook ever!! https://livebook.dev/ reply skybrian 3 hours agoprevAre the file formats the same? Are there any Pretzel-specific extensions? reply prasoonds 3 hours agoparentWe're just a fork of Jupyter so everything - notebook files, keybindings, extensions, settings should just work. We pull all of your config from the ~/.jupyter folder so you should be able to switch between Jupyter and Pretzel from different python environments (though you might see some warnings) reply renewiltord 1 hour agoprev [–] I just use PyCharm and Copilot plugin. Works like a charm. reply prasoonds 1 hour agoparent [–] Yeah PyCharm and VSCode are definitely great options (though PyCharm is paid and VSCode AI extensions aren't notebook tailored). If you ever get a chance, I'd love to get your feedback on Pretzel - I think Codestral is a better and faster inline completion model than GH Copilot's GPT4 class model plus I think we might do context-relevant questions better :) reply renewiltord 1 hour agorootparent [–] I'll give it a crack over the holiday. My primary mechanism is that I talk inline to the program. import pandas as pd # read a csv in with a pipe delimiter pd.read... # AI fills this in I saw your demo and I get the \"Enter AI mode\" thing but I like this flow, esp since I use ideavim. Perhaps the only improvement would be if I had another mode in the editor for AI that was keyboard accessible. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Pretzel is a new fork of Jupyter Lab that integrates AI code generation features, addressing the lack of such extensions in the original Jupyter.",
      "Key features include inline tab autocomplete, cell-level code generation, and a sidebar chat, all designed to enhance the coding experience with contextual AI assistance.",
      "Pretzel aims to modernize Jupyter with additional features like real-time collaboration, SQL support, a visual analysis builder, and a VSCode-like interface, making it a comprehensive tool for data scientists."
    ],
    "commentSummary": [
      "Pretzel is a free, open-source fork of Jupyter Lab, adding AI code generation features for a more integrated and context-aware experience.",
      "Key features include inline Tab autocomplete using Mistral Codestral or GPT-4o, cell-level code generation, and a sidebar chat with context from the current cell or selected text.",
      "Pretzel aims to modernize Jupyter with features like real-time collaboration, SQL support, and a visual analysis builder, distinguishing it from other AI-integrated tools like Noteable, Deepnote, Jupyter-ai, Colab, and CoCalc."
    ],
    "points": 129,
    "commentCount": 41,
    "retryCount": 0,
    "time": 1719930236
  },
  {
    "id": 40852084,
    "title": "Switzerland mandates software source code disclosure for public sector",
    "originLink": "https://joinup.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland",
    "originBody": "Switzerland mandates software source code disclosure for public sector: A legal milestone New Open Source law in Switzerland Axel Thévenet Published on: 30/05/2024 News Switzerland has enacted the \"Federal Law on the Use of Electronic Means for the Fulfilment of Governmental Tasks\" (EMBAG), establishing a mandatory requirement for open source software within public sector bodies. This legislative shift, championed by key figures such as Professor Dr. Matthias Stürmer, head of the Institute for Public Sector Transformation at the Bern University of Applied Sciences, signifies a paradigm shift in how governmental software development and procurement are approached. \"Switzerland's new 'public money public code' law is a great opportunity for government, the IT industry and society. All stakeholders benefit from this new regulation since the public sector can reduce vendor lock-in, companies can grow their digital business solutions, and taxpayers spend less on IT solutions and receive better services due to increased competition and innovation.\" Professor Dr. Matthias Stürmer Professor Dr. Matthias Stürmer has been a pivotal advocate for this change. With a background in digital sustainability and open source community building, Stürmer has long argued for the benefits of OSS in enhancing digital transparency and reducing dependency on proprietary software. His involvement in various capacities, including his role at the Research Center for Digital Sustainability and as president of the open source association CH Open. The EMBAG law stipulates that all public bodies must disclose the source code of software developed by or for them, unless precluded by third-party rights or security concerns. This mandate aims to ensure greater transparency, security, and efficiency in government operations by promoting the use of OSS, which allows for public scrutiny and contribution to the software code. One of the critical aspects of this law is encapsulated in Article 9, which not only mandates the disclosure of source code but also allows public bodies to offer additional services related to support, integration, or IT security, provided these services align with public tasks and are offered at a cost-covering remuneration. This provision ensures that while fostering OSS, the government can also maintain a competitive balance and avoid market distortion. The journey to this legislative milestone was not without its challenges. The concept of making OSS mandatory in the public sector was initially met with resistance. Key stakeholders, including members of the Swiss Parliament and various governmental bodies, engaged in extensive debates. Concerns ranged from potential intellectual property issues to fears of compromising security. However, through persistent lobbying and advocacy, notably by the Parliamentarian Group for Digital Sustainability (Parldigi), a consensus was reached, leading to the final compromise that forms the current EMBAG law. The implementation of EMBAG is expected to serve as a model for other countries considering similar measures. The law aims to promote digital sovereignty and encourage innovation and collaboration within the public sector. As Switzerland adopts this approach, the benefits of open source software—greater security, cost efficiency, and enhanced public trust—may become more apparent. Source: https://www.ti8m.com/de/blog/open-source-gesetz-schweiz Photo by Nadine Marfurt on Unsplash Report abusive content Share Login or create an account to comment.",
    "commentLink": "https://news.ycombinator.com/item?id=40852084",
    "commentBody": "Switzerland mandates software source code disclosure for public sector (europa.eu)124 points by coloneltcb 19 hours agohidepastfavorite18 comments transpute 17 hours agoU.S. DoD Open-Source FAQ (2021), https://dodcio.defense.gov/Open-Source-Software-FAQ/ Both entirely new programs and improvements of existing OSS have been developed using U.S. government funds. There are far too many examples to list; a few examples are.. Security-Enhanced Linux (SELinux) bind’s implementation of DNS security (DNSSEC) BSD TCP/IP suite - Provided the basis of the Internet A recent (2019) example is Ghidra, https://ghidra-sre.org. reply jowea 17 hours agoprev> The EMBAG law stipulates that all public bodies must disclose the source code of software developed by or for them, unless precluded by third-party rights or security concerns. How big of a hole is this going to be? > One of the critical aspects of this law is encapsulated in Article 9, which not only mandates the disclosure of source code but also allows public bodies to offer additional services related to support, integration, or IT security, provided these services align with public tasks and are offered at a cost-covering remuneration. This provision ensures that while fostering OSS, the government can also maintain a competitive balance and avoid market distortion . Finally, government getting into the SasS action. reply userbinator 17 hours agoparentIt seems \"security concerns\" has become a catch-all these days for \"we don't want to do it\". reply cangeroo 15 hours agorootparentA court would likely decide that the supplier is in malicious non-compliance and may be able to assign financial penalties. So it's important that the penalties are significant enough to deter non-compliance. reply hcfman 9 hours agoparentprevGood observation! That's the standard waiver lopohole the size of a truck. Remember the net neutrality law? In principle providers should not be able to block the smtp port. Except they do. In the Netherlands they block this with Ziggo. Except they don't. Cause they open it again if you pay more for the business version. reply intelVISA 17 hours agoprevMost public sector code is not made public for the shame it would bring the country. reply aitchnyu 9 hours agoparentWe need a CRAPL fork https://matt.might.net/articles/crapl/ reply darby_nine 17 hours agoparentprevEh nothing shameful about code that does the job reply jagged-chisel 16 hours agorootparentI think that’s the problem. In so many cases, it doesn’t do the job. reply Woodi 13 hours agoprevIt would be good if they mandate public sector own their own source code, build procedures including on future hardware, tests, documentation, etc and rights to grow it further. Disclosing to public is secondary but useful. reply Brian_K_White 18 hours agoprevGood! And good luck with that. I think Brazil made noises like this for a short time some years ago. I don't think it went anywhere but it is clearly the sane ideal, and is just a failing that we don't have it. A normal failing like countless others, bit still a failing. To me it never made sense for any public facilities to rely on anything the public couldn't at least audit, let alone modify to remove any artificial private-serving restrictions like undocumented file formats and artificial lack of inteteroperability with other software and old versions of the same software etc. Maybe eventually this will be a thing, but will probably take forever. Assuming this doesn't really stick long term, at least it seems that very gradually, more municipalities are trying. Sooner or later maybe it will start to stick, maybe only in some smaller places at first that can get away with being opinionated and principled, and too small for MS and Oracle to fight too hard over. But those may beget a few others. Maybe once tiny town down the road does it, slightly larger town realizes they could too. And then maybe you have a world where say 2% of public official things don't use Office or Oracle etc. That starts to make it important for everyone else to support agnostic compatibility as a real thing they actually have to support instead of just forcing all their users to use Edge or Chrome or Office etc. And once that starts to happen, once most services and products actually work with firefox and libreoffice etc, it makes it less crazy and unimaginable for some larger less hippy idealist municipalities to actually consider the principled argument. They have less ammo to shoot it down. reply IG_Semmelweiss 17 hours agoparentWhat ia your perspective on why this failed implementation in Brazil? Was it because mon compliance was not punished ? Or perhaps there was no system tontest for compliance? reply mlinhares 16 hours agorootparentThere was a push from the government itself to buy open source but not to require companies to publish or make their sources available. Not sure if this was what the OP was talking about. It was later undone because providing support for these alternatives sucked (open office and the like), people didn't want to use tools they had no experience with and corruption, as the big players could just bribe people to buy closed source software. reply darajava 16 hours agoprevI would love for the gov.uk source code to be public. It’s some of the best software I’ve ever used, let alone software in the public sector. reply tvararu 13 hours agoparenthttps://github.com/alphagov/whitehall reply kseifried 16 hours agoprevThe EMBAG law stipulates that all public bodies must disclose the source code of software developed by or for them, unless precluded by third-party rights or security concerns. \"unless precluded by third-party rights\" Oh. Well then. Nothing to see here. reply whamlastxmas 4 hours agoparentI agree. Every vendor is going to build software by making 90% of it a proprietary library and then 10% a wrapper around that which is useless to everyone. Also literally any application that uses authentication could argue that it’s a security concern to release code reply CivBase 16 hours agoprev [–] Curious how they plan to enforce this. Will they be auditing their own organizations? Are theg requiring govt organizations to go through some kind of review before they're allowed to deploy new software? Are they relying on whistleblowers? Or is this basically just a declaration with the expectation that their organizations will act in good faith going forward? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Switzerland has enacted the \"Federal Law on the Use of Electronic Means for the Fulfilment of Governmental Tasks\" (EMBAG), mandating open source software (OSS) in public sector bodies.",
      "The law, led by Professor Dr. Matthias Stürmer, aims to reduce vendor lock-in, lower taxpayer costs, and enhance services through increased competition and innovation.",
      "EMBAG promotes transparency and efficiency by requiring public bodies to disclose software source code, unless restricted by third-party rights or security concerns, and allows them to offer additional IT services at cost-covering remuneration."
    ],
    "commentSummary": [
      "Switzerland's EMBAG law mandates public sector software source code disclosure, with exceptions for third-party rights or security concerns.",
      "The law aims to promote open-source software (OSS) and allows public bodies to offer related services at cost-covering rates, though critics worry about potential loopholes and unclear enforcement.",
      "This initiative could lead to broader OSS adoption in public services, despite challenges in auditing and compliance."
    ],
    "points": 124,
    "commentCount": 18,
    "retryCount": 0,
    "time": 1719877702
  },
  {
    "id": 40849840,
    "title": "When RAND made magic in Santa Monica",
    "originLink": "https://asteriskmag.com/issues/06/when-rand-made-magic-in-santa-monica",
    "originBody": "The Roots of RAND Internal Culture and Talent Finding an Institutional Footing Diversification and Decline When RAND Made Magic in Santa Monica Pradyumna Prasad Jordan Schneider RAND’s halcyon days lasted two decades, during which the corporation produced some of the most influential developments in science and American foreign policy. So how did it become just another think tank? ZEBU Between 1945 and 1960, RAND operated as the world’s most productive research organization. Initially envisioned as a research arm of the Air Force, RAND made century-defining breakthroughs both in basic science and applied strategic analysis. Its members helped define U.S. nuclear strategy, conceptualized satellites, pioneered systems analysis, and developed the earliest reports on defense economics. They also revolutionized much of STEM: RAND scholars developed the basics of game theory, linear programming, and Monte Carlo methods. They helped conceptualize generalized artificial intelligence, developed the basics for packet switching (which enables data transmission across networks), and built one of the world’s first computers. Today, RAND remains a successful think tank — by some metrics, among the world’s best. 1 In 2022, it brought in over $350 million in revenue, and large proportions still come from contracts with the US military. Its graduate school is among the largest for public policy in America. But RAND’s modern achievements don’t capture the same fundamental policy mindshare as they once did. Its military reports may remain influential, but they hold much less of their early sway, as when they forced the U.S. Air Force to rethink several crucial assumptions in defense policy. And RAND’s fundamental research programs in science and technology have mostly stopped. Gone are the days when one could look to U.S. foreign policy or fundamental scientific breakthroughs and trace their development directly back to RAND. How was magic made in Santa Monica? And why did it stop? The Roots of RAND Economists, physicists, and statisticians — civilian scientists to that point not traditionally valued by the military — first proved their utility in the late stages of World War II operational planning. American bomber units needed to improve their efficiency over long distances in the Pacific theater. The scientists hired by the Army Air Force proposed what at the time seemed a radical solution: removing the B-29 bomber’s armor to reduce weight and increase speed. This ran counter to USAAF doctrine, which assumed that an unprotected plane would be vulnerable to Japanese air attacks. The doctrine proved incorrect. The increased speed not only led to greater efficiency, it also led to more U.S. planes returning safely from missions, as Japanese planes and air defense systems were unable to keep up. 2 Civilian scientists were suddenly in demand. By the end of the war, all USAAF units had built out their own operations research departments to optimize battle strategy. When the war ended, the question turned to how to retain the scientific brain trust it had helped to assemble. General Henry “Hap” Arnold, who had led the Army Air Force’s expansion into the most formidable air force in the world, had started to consider this question long before the war had ended. He found an answer in September 1945, when Franklin Collbohm, a former test pilot and executive at Douglas Aircraft, walked into Arnold’s office with a plan: a military-focused think tank staffed by the sharpest civilian scientists. Collbohm did not have to finish describing his idea before Arnold jumped and agreed. Project RAND was born. Arnold, along with General Curtis LeMay — famous for his “strategic bombing” of Japan, which killed hundreds of thousands of civilians — scrounged up $10 million from unspent war funds to provide the project’s seed money, which was soon supplemented with a grant from the Ford Foundation. This put RAND into a privileged position for a research organization: stably funded. On top of that financial stability, RAND built what would become one of its greatest organizational strengths: a legendarily effective culture, and a workforce to match it. Internal Culture and Talent In an internal memo, Bruno Augestein, a mathematician and physicist whose research on ballistic missiles helped usher in the missile age, highlighted a set of factors that catalyzed RAND’s early success. In short: RAND had the best and brightest people working with the best computing resources in an environment that celebrated excellence, welcomed individual quirks, and dispensed with micromanagement and red tape. Early RAND leadership was, above all else, committed to bringing in top talent and jealously guarded the sort of intellectual independence to which their academic hires were accustomed. Taking the mathematics department as an example, RAND hired John Williams, Ted Harris, and Ed Quade to run it. While these were accomplished mathematicians in their own right, these three were also able to attract superlative talents to work under and around them. As Alex Abella writes in Soldiers of Reason, his history of RAND, “No test for ideological correctness was given to join, but then none was needed. The nation’s best and brightest joining RAND knew what they were signing on for, and readily accepted the vision of a rational world — America and its Western allies — engaged in a life-and-death struggle with the forces of darkness: the USSR.” As the Cold War intensified, the mission became the sell. The aim of RAND, as the historian David Hounshell has it, “was nothing short of the salvation of the human race.” 3 The researchers attracted to that project believed that the only environment in which that aim could be realized was independent of the Air Force, its conventional wisdom, and — in particular — it’s conventional disciplinary boundaries RAND’s earliest research aligned with the USAF’s (the Army Air Force had become its own service branch in 1947) initial vision: research in the hard sciences to attack problems like satellite launches and nuclear-powered jets. 4 However, the mathematician John Davis Williams, Collbohm’s fifth hire, was convinced that RAND needed a wider breadth of disciplines to support the Air Force’s strategic thinking. He made the case to General LeMay, who supervised RAND, that the project needed “every facet of human knowledge to apply to problems.” 5 To that end, he argued for recruiting economists, political scientists, and every other kind of social scientist. LeMay, once convinced, implored Williams to hire whoever it took to get the analysis right. And so they did. RAND’s leadership invested heavily in recruiting the best established and emerging talent in academia. An invitation-only conference organized by Williams in New York in 1947 brought together top political scientists (Bernard Brodie), anthropologists (Margaret Mead), economists (Charles Hitch), sociologists (Hans Speier), and even a screenwriter (Leo Rosten). The promise of influence, exciting interdisciplinary research, and complete intellectual freedom drew many of the attendees to sign up. Within two years, RAND had assembled 200 of America’s leading academics. The top end of RAND talent was (and would become) full of past (and future) Nobel winners, and Williams worked around many constraints — and eccentricities — to bring them on. For instance, RAND signed a contract with John von Neumann to produce a general theory of war, to be completed during a small slice of his time: that spent shaving. For his shaving thoughts, von Neumann received $200 a month, an average salary at the time. Beyond the biggest names, RAND was “deliberate, vigorous, and proactive” in recruiting the “first-rate and youthful staff” that made up most of its workforce. The average age of staff in 1950 was under 30. 6 Competition between them helped drive the culture of excellence. Essays and working papers were passed around for comments, which were copious — and combative. New ideas had to pass “murder boards.” And the competition spilled into recreational life: Employees held tennis tournaments and boating competitions. James Drake, an aeronautical engineer, invented the sport of windsurfing. The wives of RAND employees — who were, with a few notable exceptions, almost all male — even competed through a cooking club where they tried to make the most \"exotic\" recipes. After bringing in such extraordinary talent, RAND’s leadership trusted them to largely self-organize. Department heads were given a budget and were free to spend it as they felt fit. They had control over personnel decisions, which allowed them the flexibility to attract and afford top talent. As a self-styled “university without students,” RAND researchers were affiliated with departments with clear disciplinary boundaries, which facilitated the movement of researchers between RAND and academia. But in practice, both departments and projects were organized along interdisciplinary lines. The mathematics department brought on an anthropologist. The aeronautics department hired an MD. This hiring strategy paid off in surprising ways. For instance, while modeling the flow of drugs in the bloodstream, a group of mathematicians stumbled upon a technique to solve a certain class of differential equations that came to be used in understanding the trajectory of intercontinental ballistic missiles. The caption of this image, from the May 11, 1959, issue of Life magazine, reads: ‘After-hours workers from RAND meet in home of Albert Wohlstetter (foreground), leader of RAND’s general war studies. They are economists gathered to discuss study involving economic recovery of U.S. after an all-out war.’ Leonard McCombe / The LIFE Picture Collection via Getty Images. Finding an Institutional Footing RAND was at the forefront of a postwar explosion in federal funding for science. Hundreds of millions of dollars poured into universities, think tanks, and industrial R&D labs. Almost all of it was directed toward one purpose: maintaining military superiority over the Soviet Union. In 1950, over 90% of the federal research budget came from just two agencies: the Atomic Energy Commission and the Department of Defense. 7 Significant portions of this funding went toward basic research with no immediate military applications. 8 Vannevar Bush, the influential head of the war-era Office of Scientific Research and Development, had argued for this approach in his 1945 book Science, the Endless Frontier: Freeing up scientists to follow their own research interests would inevitably lead to more innovation and ensure American technological dominance. Bush’s was not the only, or even the dominant, view of how postwar science should be organized — most science funding still went toward applied research — but his views helped inform the organization of a growing number of research institutions. 9 No organization embodied this model more than RAND. Air Force contracts were the financial backbone of the organization. They provided the money required to run RAND, while profits were used to fund basic research. In the 1950s, USAF contracts comprised 56% of RAND’s work, while other sponsors made up just 7%. 10 That left more than a third of RAND’s capacity open to pursue its own agenda in basic research. Many of the developments made there would be used in their applied research, making it stronger — and more profitable — in the process. This flywheel would become critical to RAND’s success. Not all of these developments were successful, especially at first. RAND’s early research efforts in systems analysis — an ambitious pursuit in applying mathematical modeling that RANDites were optimistic could produce a holistic “science of warfare” — were flops. The first project, which aimed to optimize a strategic bombing plan on the Soviet Union, used linear programming, state-of-the-art computing, and featured no fewer than 400,000 different configurations of bombs and bombers. It proved of little use to war planners. Its assumptions fell prey to the “specification problem:” trying to optimize one thing, in this case, calculating the most damage for the least cost led to misleading and simplistic conclusions. 11 But RAND would soon find its footing, and a follow up to this work became a classic of the age. The 1954 paper Selection and Use of Strategic Air Bases proved the value of RAND’s interdisciplinary approach — though its conclusions were at first controversial. Up to the 1950s, there had been little analysis of how the Strategic Air Command, responsible for the United States’s long range bomber and nuclear deterrent forces, should use its Air Force bases. At the time, the SAC had 32 bases across Europe and Asia. The study, led by political scientist Albert Wohlstetter, found that the SAC was dangerously vulnerable to a surprise Soviet attack. The SAC’s radar defenses wouldn’t be able to detect low-flying Soviet bombers, which could reduce American bombers to ash — and thereby neutralize any threat of retaliation — before the Americans had a chance to react. Wohlstetter’s study recommended that the SAC keep its bombers in the U.S., dispersed at several locations to avoid concentration at any place. LeMay, RAND’s original benefactor and commander of the SAC, resisted Wohlstetter’s conclusions. He worried the plan would reduce his control over the country’s nuclear fleet: With the SAC based in the U.S., LeMay would have to cede some authority to the rest of the U.S. Air Force. He pushed against it many times, proposing several alternatives in which the SAC kept control over the bombers, but no plan fully addressed the vulnerabilities identified by the report. Undaunted — and sure of his logic — Wohlstetter pushed his conclusions even further. He proposed a fail-safe mechanism, where nuclear bombers would have to receive confirmation of their attack from multiple checkpoints along the way, to prevent rogue or mistaken orders from being followed. Wohlstetter went around LeMay, to Defense Secretary Charles Wilson and General Nathan Twining, chairman of the Joint Chiefs of Staff, who ultimately accepted the study’s recommendations in full. It took over two decades, but they proved their value in 1980 when a faulty chip erroneously warned of an impending Soviet strike. While no order for a retaliatory attack was issued, had there been one, the fail-safe mechanism would have prevented the bombers from actually attacking the USSR. Selection and Use of Strategic Air Bases was a triumph for RAND. Not only had they provided correct advice to the USAF, they had also proved their independence from the institution’s internal politics. And the flywheel would prove its value many times over. RAND’s basic research helped drive the development and strategy of ICBMs, the launch of the first meteorological satellite, and, later, on cost reductions in ICBM launch systems. Diversification and Decline RAND’s conclusions ran counter to USAF doctrine several times — and each time RAND fought to maintain its independence. When the USAF commissioned RAND to study the Navy’s Polaris program — in order to show that it was inferior to the Air Force’s bombers for nuclear weapon delivery — RAND found that the Polaris missiles were, in fact, superior. The same happened with another study, which challenged the effectiveness of the B-70 bomber in 1959. Over time, however, these tensions added friction to the relationship. To make matters worse, between 1955 and 1960, the USAF’s budget declined in both absolute terms, and relative to the rest of the defense community. In 1959, the Air Force froze RAND’s budget, presumably due to the budget cuts — and their disputes with RAND. This situation was not unique to the USAF, or to RAND. As the 1950s rolled into the ’60s, scientists at civilian institutions increasingly moved to disentangle themselves from their military benefactors. Throughout the decade, DOD funding for basic research would only continue to decline. 12 RAND weathered the transition by successfully seeking out new customers — the AEC, ARPA, the Office of the Comptroller, the Office of the Assistant Secretary of Defense for International Security Affairs (ISA), NASA, the NSF, the NIH, and the Ford Foundation, to name a few. The percent of the outside funding coming from the USAF dropped from 95% when RAND started to 68% in 1959. 13 But their success came at a cost: This diversification is what led to RAND losing its edge in producing the cutting edge of policy and applied science. Funding diversification reshaped both RAND’s culture and output. The increased number of clients made scheduling researchers’ work harder. Each client expected a different standard of work, and the tolerance levels for RAND’s previously freewheeling style varied. The transaction costs of starting a new contract were much higher and the flexible staffing protocols that had worked for the USAF in the 1950s needed to be systematized. The larger organization led to ballooning internal administration expenses. Along with all of this, RAND’s increased size attracted more political detractors. In 1958, a RAND paper called Strategic Surrender, which examined the historical conditions for surrender, had generated a political firestorm. Politicians were furious with RAND for exploring conditions under which it would be strategic for the U.S. to surrender. Senators weren’t particularly interested in the study itself, but those who wanted to run for president (like Stuart Symington of Missouri) used it as evidence that the Eisenhower administration was weak on defense. The Senate even passed a resolution (with an 88–2 margin) prohibiting the use of federal funds for studying U.S. surrender. RAND’s management, realizing that an intentional misinterpretation of their work potentially threatened future funding streams, now had to consider the wider domestic political context of their work. All of these factors changed RAND’s culture from one that encouraged innovation and individuality to one that sapped creativity. But the biggest change was yet to come. In 1961, Robert McNamara took over the Department of Defense and brought with him a group of RAND scholars, commonly called the “Whiz Kids.” Their most important long-term contribution to U.S. governance was the Planning-Programming-Budgeting System. PPBS took a Randian approach to resource allocation, namely, modeling the most cost-effective ways to achieve desired outcomes. In 1965, after President Johnson faced criticism for poor targeting of his Great Society spending, he required nearly all executive agencies to adopt PPBS. Many RAND alumni were hired by McNamara and his team to help with the Great Society’s budgeting process. In 1965, Henry Loomis, the deputy commissioner on education, approached RAND about conducting research on teaching techniques. Franklin Collbohm, RAND’s founder and then president, declined. He preferred that RAND stay within the realm of military analysis. RAND’s board disagreed and would eventually push Collbohm out of RAND in 1967. The board thought it was time for a change in leadership — and to RAND’s nonmilitary portfolio. The entry of a new president, Henry S. Rowen, an economist who had started his career at RAND, cemented this change. By 1972, the last year of Rowen’s tenure, almost half of all RAND projects were related to social science. For better or worse, this eroded RAND’s ability to take on cutting-edge scientific research and development. RAND entered domestic policy research with a splash — or, rather, a belly flop. The politics of social policy research were markedly different from working with the DOD. For one, there were substantially more stakeholders — and they were more vocal about voicing their disagreements. One crucial example is when RAND proposed police reforms in New York City, but pressure from the police unions forced them to retract. John Lindsay, the Republican mayor of New York, had tasked RAND with improving the New York Police Department, which had recently been implicated in narcotics scams, corruption, and police brutality. The report showed that in less than 5% of the cases in which an officer was charged with a crime or abusing a citizen did the officers receive anything more than a reprimand. The findings were leaked to The New York Times, which added to the impression among the police that RAND was the mayor’s mouthpiece. RAND, for the first time, had to face the reality of local politics: a sometimes hostile environment, multiple stakeholders who sometimes acted in bad faith, and none of the free reign that characterized their first decades. RAND’s experience with the police report, and the controversy over the study of surrender, led RAND to be more conservative about the research it put out. And additionally, the focus on policy research crowded out the scientific research. For example, beginning in the 1970s, RAND’s applied mathematics research output slowed to a trickle, before stopping altogether in the 1990s. It was replaced by mathematics education policy. The same is true for physics, chemistry, and astronomy. Another emblematic development in the dilution of RAND’s focus was the founding in 1970 of the Pardee RAND Graduate School, the nation’s first Ph.D.-granting program in policy analysis. While the idea of training the next generation in RAND techniques is admirable, RAND in the early years explicitly defined itself as a “university without students.” RAND is still an impressive organization. It continues to produce successful policy research, which commands the eyes of policymakers in over 82 federal organizations and across dozens of local and even foreign governments. Still, their work today is inarguably less groundbreaking and innovative than it was in the ’50s. This relative decline was partially caused by internal policy choices, and partially by the eventual loss of their initial team of leading scientists. But part of it was also inevitable: We no longer live in an era when branches of the U.S. military can cut massive blank checks to think tanks in the interests of beating the Soviets. The successes of 1950s RAND do come with lessons for modern research organizations — about the importance of talent, the relevance of institutional culture, and the possibilities of intellectual freedom — but the particular conditions that created them can’t be replicated. It is remarkable that they existed at all. Sign up for our newsletter to get Asterisk’s latest interviews, essays, and more. Subscribe According to the University of Pennsylvania’s Global Go To Think Tank Index Report. ↩ Similar stories of outsiders applying quantitative thinking improving performance also played out in other branches. Such experiences were also seen in the Navy, where better usage of anti-submarine depth charges led to higher efficiency to the extent that German naval planners thought that the U.S. had invented a new type of depth charge. ↩ D. Hounshell, “The Cold War, RAND, and the Generation of Knowledge, 1946–1962,” Historical Studies in the Physical and Biological Sciences 27, no. 2(1997): 237–267. ↩ Unfortunately, the researchers at RAND couldn’t figure out how to make a nuclear plane that didn’t irradiate the pilots. ↩ Sharon Ghamari-Tabrizi, The Worlds of Herman Kahn: The Intuitive Science of Thermonuclear War (Cambridge: Harvard University Press, 2005), 52. ↩ Abella, Soldiers of Reason. ↩ Dan Kevles, “Cold War and Hot Physics: Science, Security, and the American State, 1945–1956,” Historical Studies in the Physical and Biological Sciences 20, no. 2 (1990): 244. ↩ Audra J. Wolfe, Competing with the Soviets: Science, Technology, and the State in Cold War America (Baltimore: The Johns Hopkins University Press, 2013), 36. ↩ Ibid. 37–42. ↩ Bruce L.R. Smith, The Rand Corporation: Case Study of a Nonprofit Advisory Corporation (Cambridge: Harvard University Press, 1966), 167. ↩ D. Hounshell, “The Cold War, RAND, and the Generation of Knowledge, 1946–1962,” Historical Studies in the Physical and Biological Sciences 27, no. 2(1997): 237–267. ↩ Wolfe, Competing with the Soviets, 134–138, 145. ↩ Bruce L. R. Smith, The RAND Corporation: Case Study of a Nonprofit Advisory Corporation (Cambridge: Harvard University Press, 1966). ↩ Pradyumna Prasad authors the Bretton Goods substack and hosts the accompanying podcast. He is a first year undergraduate at the National University of Singapore. Jordan Schneider is the creator of the ChinaTalk podcast and newsletter. Published June 2024 Have something to say? Email us at letters@asteriskmag.com. Next Golden States Further Reading More: science history It’s 2024 and Drought is Optional Casey Handmer Manufacturing Bliss Nadia Asparouhova Silicon Valley’s Gold Rush Roots Peter Westwick The Fault in Our Forecasts Susan Hough About Highlights By highlighting text and “starring” your selection, you can create a personal marker to a passage. What you save is stored only on your specific browser locally, and is never sent to the server. Other visitors will not see your highlights, and you will not see your previously saved highlights when visiting the site through a different browser. To add a highlight: after selecting a passage, click the star . It will add a quick-access bookmark. To remove a highlight: after hovering over a previously saved highlight, click the cross . It will remove the bookmark. To remove all saved highlights throughout the site, you can click here to completely clear your cache. All selections have been cleared. Subscribe Sign up for our newsletter to get Asterisk’s latest interviews, essays, and more. Subscribe",
    "commentLink": "https://news.ycombinator.com/item?id=40849840",
    "commentBody": "When RAND made magic in Santa Monica (asteriskmag.com)121 points by mitchbob 23 hours agohidepastfavorite45 comments moandcompany 20 hours ago(Disclosure: I once worked at RAND, but at a much later time in its history) RAND's heydays were during the period of WW-II and post-war period including the so-called Cold-war era. From my point of view, RAND during its golden days was very much like Google or Bell Labs during their peaks, with many historically prominent computer scientists and mathematicians having worked at RAND in some capacity. Several people I had worked with were there during the golden days and would reflect on them with great nostalgia... Back then, special names we use today like \"computer science\" or \"data science\" were not commonly used. In this era, this field was simply called \"Operations Research\" (i.e. the application of quantitative methods and data analysis to improve operational and strategic decision making). - Without going off course too much, I previously made the case that places like the RAND Corporation for all practical purposed invented the field of what we call data science today, but may so-called data science practitioners would not know what the RAND Corporation was, nor would many people at the RAND Corporation in modern times have connected the dots to recognize that they had pioneered this field. For anyone interested in reading more on the theme of applying quantitative methods / operations research in the area of US public policy, it's reading about the \"Whiz Kids\": - https://en.wikipedia.org/wiki/Whiz_Kids_(Department_of_Defen... reply jebarker 5 hours agoparentMy first job out of school was in defense operations research. Not at RAND, so maybe of limited relevance. But I found it less like modern data science and more like GOFAI. The work was mostly coming up with hand engineered models of military operations and then guesstimating the crucial variables since they were impossible to actually measure. I also observed that the analysis was rarely independent so it could inform policy in an unbiased way but instead was shaped to support particular policy choices. reply ancorevard 15 hours agoparentprevAny books recommendations for this part of history? reply MrSkelter 11 hours agorootparent“Wizards of Armageddon” is one of the best books about anything ever. It makes articles like the one linked redundant. reply eru 12 hours agorootparentprevNot directly about RAND, but related to Operations Research: Tom Körner has an excellent book called 'The Pleasures of Counting'. See eg https://www.ams.org/notices/199803/comm-bkrev-blank.pdf for a review. reply moandcompany 15 hours agorootparentprevWill try to update this post if I come across a good book. This RAND Blog Post covers activities that happened during RAND's first seventy-five years of history, which is still nice, as well as browsing through some of the publicly available papers and reports: - https://www.rand.org/pubs/articles/2023/rand-turns-75-a-look... - https://www.rand.org/about/history.html - https://www.rand.org/pubs/papers/P7857.html - https://www.rand.org/content/dam/rand/pubs/papers/2009/P3705... - https://apps.dtic.mil/sti/tr/pdf/ADA255904.pdf Books: - Soldiers of Reason (https://www.goodreads.com/book/show/2467227.Soldiers_Of_Reas...) I haven't read this book myself, but it may scratch your itch - History of Operations Research in the United States Army (https://books.google.com/books?id=KqtZ5XpcDHEC) Some articles on RAND in general: - https://www.theatlantic.com/magazine/archive/1963/09/the-ran... - https://www.mentalfloss.com/article/22120/rand-corporation-t... Related back to the topic of \"magic\": - There's a RAND paper that I recall reading while I was there on designing an office campus for intentional serendipity as part of cultivating a research organization. I hope I can find a copy online so I can link it to this article, as many of the ideas were incorporated into the design of RAND's future/replacement campus in Santa Monica, CA. - The ideas on office/campus design were quite good and even included the subject of floor planning and desk assignments. Despite the inherent draw of organizations to divide office space by departments and functions, the RAND ideas were to deliberate interleave the locations of personnel such that people would have increased chances of collaborating with others that they would not naturally be drawn to directly in executing their work. This extended further to how walkways and passageways should be designed to connect floors, buildings etc... ensuring that people would pass by and see other people/functions/departments that they would not normally see or consider in their day-to-day work. I recall trying to cite some of these ideas when I worked in other research organizations (e.g. Google Research) where one of the principal complaints was siloing/lack of collaboration, yet teams were allowed to physically silo themselves in seating plans (by their own request/demands). - I never got to see the original campus, as it was demolished and later turned into a public park. However, the drawings and photographs of the original campus reminded me of something that resembled an American high school or small university campus. - There are many small details about working at RAND that were part of deliberate efforts to influence an individual's experiences and decisions to improve their creative/work potential. For example, the equivalent of Vacation/PTO time at RAND is called \"sabbatical time.\" RAND employees were paid more, on an hourly equivalent rate, when taking their \"sabbatical time\" than for regular work time; this idea was not implemented to reduce financial liability of unspent PTO time for the company under modern standards, but because it was believed and understood --through research-- that employees were more likely to bring their best selves to work when having sufficient and periodic time away from their work -- often bringing back new ideas that wouldn't have emerged simply by grinding away at a problem... So they hoped to incentivize employees to take that time away from a problem by paying them more during their time off. reply walterbell 1 hour agorootparent> the RAND ideas were to deliberate interleave the locations of personnel such that people would have increased chances of collaborating with others that they would not naturally be drawn to directly in executing their work. This extended further to how walkways and passageways should be designed to connect floors, buildings etc... ensuring that people would pass by and see other people/functions/departments that they would not normally see or consider in their day-to-day work. This type of cross-specialty pollination is feature of Hacker News design and moderation. reply HeyLaughingBoy 3 hours agorootparentprevNot a book, but Steve Blank's blog has a lot of interesting Silicon Valley history. reply helf 16 hours agoparentprevThanks for the tidbits! I'm a huge fan of electronics and computer and related history. Id be interested in any stories you have about your time there :) reply kayo_20211030 4 hours agoprevEven in the late 60's and 70's, RAND did some seminal work in the modeling of estuarine and coastal flows using the computers of the day. It was incredibly practical work that was used through the 90's, and that's still cited today. They were wonderful papers for the time. reply Animats 21 hours agoprevGen. LeMay was in charge of RAND? Didn't know that. He was the \"bomb them back to the Stone Age\" general. The USAF was insanely well funded in the 1950's. The military got about 40% of the US government budget back then. The USAF bought most of the world's transistors. They ran several ICBM programs, a bomber program, SAGE, and accumulated huge fleets of aircraft. Even the mediocre airplanes where produced in large quantity. The B-47, the first good jet bomber, was built in quantity 2,042. In comparison, only 744 B-52 bombers were ever built, and many of those are still in use. reply joe_the_user 21 hours agoparentI recall that one of Rand's area of research was how a nation could survive a nuclear attack. They definitely nuclear hawks. The USAF may get less of the budget as percentage of GDP but I'd wager the budget might equivalent in absolute terms since US economy is larger. I think the real reason they have far fewer planes deployed is this: \"The cost of acquiring and maintaining major posture components has tended to grow in real terms over time\" [1] as a Rand Corporation report circa 1990 observed. [1] https://www.rand.org/content/dam/rand/pubs/reports/2009/R380... p. 7 reply moandcompany 20 hours agorootparentWhile people may like to call the RAND Corporation as an entity of \"nuclear hawks,\" it seems a bit dismissive of the mission and nature of what the RAND Corporation was chartered to do. They were tasked, and encouraged, to apply their creativity, brain power, quantitative skills, to study decision spaces, future possibilities and analyze these to arrive at recommendations and methods for best achieving desired outcomes, as well as identifying and understanding blind spots in thinking. In the above context of nuclear war, I don't believe nuclear war was an organizationally desired outcome, however they had to contemplate it and its implications. This is the organization that concluded based on application of quantitative methods (e.g. game theory) that for example, pursuing a credible strategy of mutually assured destruction was objectively the best way to avoid a nuclear war. I recommend looking for references to the phrase \"Thinking the Unthinkable\" to get additional insight to some of RAND's studies. reply Spooky23 17 hours agorootparentThink tanks are not about the talent, they are about who pays the bills. The USAF paid the bills. The guy signing the checks was Curtis LeMay, who was a… reactionary who ended up as running mate to the George Wallace. He was an enthusiastic proponent of nuclear war and inspiration for Dr. Strangelove. MAD came a bit later, many of the key folks assumed and accepted that nuclear conflict was inevitable. And they may have been right. reply ferfumarma 16 hours agorootparentThe article provides several concrete examples where RAND drew conclusions counter to the implied interests of the USAF. In the absence of counterexamples your argument sounds plausible, but incorrect. reply Spooky23 5 hours agorootparentFortunately, other resources exist. Try reading the book “Soldiers of Reason”. RAND was literally founded to figure out how to wage nuclear war. It evolved after Vietnam. Particularly in the 50s and early 60s, the firm was the brain of the Air Force, period. In that era, several of the principals fully expected that there would be a nuclear exchange in the 60s or 70s. reply moandcompany 2 hours agorootparent> RAND was literally founded to figure out how to wage nuclear war. It evolved after Vietnam. Particularly in the 50s and early 60s, the firm was the brain of the Air Force, period. This is literally a stretch of reality. Was the Jet Propulsion Laboratory (JPL) founded to figure out how to wage intergalactic space domination, and is CalTech the brain of NASA? RAND, and the concept of FFRDCs (as well as UARCs), was created in the mid 1940s because of the recognition that the US government's partnership and direct ties to private sector industries for many national security matters was overexposed to the private sector's self-interest or potential conflict of interest. It was founded to create a gap between the government and private sector of contractors that bid on contracts to (mass) produce \"weapons\" systems. The thinking was, because the US Government and its armed services do not (sufficiently) have its own organic or dedicated personnel or a workforce for \"R&D,\" it needed an expert workforce (i.e. \"think-tanks\") to help research requirements, core technologies, and guide the rest of the \"R&D\" process for \"weapons\" systems development -- and those experts should not be the companies that ultimately produce (i.e. prime contractors that bid on production contracts) those systems because of conflicts of interest. Similarly, by being directly involved in the \"R&D\" of a system's requirements/design, etc, conflicts of interest might preclude those contractors from being able to bid and be awarded contracts to produce those systems under US Federal Acquisition Regulations (FAR) The US Army Air Corps, which later became the Air Force, were reliant on R&D efforts from for-profit contractors such as Douglas Aircraft (it's worth mentioning that this is the same era of Howard Hughes and Hughes Aircraft) to develop requirements, \"weapons\" systems designs, and ultimately produce those systems. The starting pieces of the RAND Corporation were a split-off of Douglas Aircraft's R&D groups to create organizational distance and gaps for mitigating conflict of interest. [Note: this doesn't mean that the idea of \"self-licking ice cream cones\" don't exist in the world of FFRDCs/UARCs, and the tendency of large organizations or bureaucracies to act in a manner to perpetuate their own existence certainly applies] See US FAR 35.017-2: https://www.acquisition.gov/far/35.017-2 https://crsreports.congress.gov/product/pdf/R/R44629 reply moandcompany 16 hours agorootparentprevIndeed, everyone and every organization ends up having to consider how the bills get paid (i.e. \"be careful about biting the hand that feeds). That's probably a universal understanding. Yet we also have real life examples where people and organizations still act in a manner that differs from providing the most expedient or most self-interested outcome. RAND itself is the place where Daniel Ellsberg leaked the Pentagon Papers from. reply BJones12 20 hours agorootparentprev>The USAF may get less of the budget as percentage of GDP but I'd wager the budget might equivalent in absolute terms since US economy is larger. In 1952 the military budget was 41.4 billion. A CPI calculator [1] puts that at 486.98 billion today. The current budget is 910 billion [2]. So the military budget has doubled since 1952. [0] https://www.presidency.ucsb.edu/documents/annual-budget-mess... [1] https://data.bls.gov/cgi-bin/cpicalc.pl?cost1=41.40&year1=19... [2] https://en.wikipedia.org/wiki/Military_budget_of_the_United_... reply jdougan 21 hours agoparentprevLeMay was a pussycat compared to General Thomas Power. > Restraint? Why are you so concerned with saving their lives? The whole idea is to kill the bastards. At the end of the war if there are two Americans and one Russian left alive, we win! https://en.wikipedia.org/wiki/Thomas_S._Power reply sillywalk 16 hours agorootparentProfessor William Kaufmann from the RAND Corporation, losing his patience, noted: \"Well, you'd better make sure that they're a man and a woman.\" reply vkou 7 hours agorootparentprevUtter madness, and correctly derided as such when the 'enemy' expresses such sentiments. reply PaulHoule 47 minutes agoprevThis book https://www.amazon.com/If-Then-Simulmatics-Corporation-Inven... describes the rise and fall of a would-be competitor to RAND that I enjoyed. reply maroonblazer 18 hours agoprevRAND is a pretty remarkable organization. I recently came across their proposal for an independent Palestinian state, dated 2005, referred to as \"The Arc\". https://www.rand.org/pubs/research_briefs/RB9119.html The above links to a more comprehensive PDF. reply dboreham 15 hours agoprevMy seasonal neighbor now in his 80s worked at RAND, and also studied under Ed Lorenz. This reminds me that I need to go spend some time with him before fall arrives. reply nataz 17 hours agoprevIn my experience with RAND they always reminded me of a resource extraction company. Think oil and gas, but their trade was government contracts. Add in a couple of big names to justify the cost, staff it with jr people/post grads, shine it up with some fancy graphics and quant-ish formulas and poof, a million dollar study. Of all the FFRDC beltway bandit think tanks, they felt the most like an MBA consultant shop. Lots of overhead, questionable return on investment. While they do have history and prestige, I'm not convinced anything they deliver is uniquely insightful. reply AlbertCory 21 hours agoprevI had an offer from them. Thankfully, I turned it down for Xerox. (this was much later than most of the events described in here( reply b20000 20 hours agoparentwhat was the reason? reply AlbertCory 19 hours agorootparentYou're really asking \"why choose Xerox, the Office of the Future, over a mainframe job?\" reply b20000 17 hours agorootparenti thought xerox parc had lost its glamour and was being mismanaged by the parent company… maybe that was just a rumour reply AlbertCory 1 hour agorootparent\"Xerox PARC\" is not one word. This whole story has been discussed here ad nauseum. There are several books on it, including one by me. reply jhbadger 3 hours agorootparentprevHe's talking about 50 years or so ago -- he was there during the glory days of PARC. reply surfingdino 13 hours agoprev> We no longer live in an era when branches of the U.S. military can cut massive blank checks to think tanks in the interests of beating the Soviets. Well, that's about to change. reply photochemsyn 19 hours agoprevRAND's role in the Vietnam War is widely derided on many grounds, from the highly unethical behavior exposed in the Pentagon Papers to technical incompetence in programs like Igloo White, the 'electronic fence' that was supposed to keep the NVA from infiltrating weapons, soldiers and supplies into South Vietnam. So maybe they were destroyed by largesse of the Vietnam War government contracting programs? Eisenhower's famous comments about the military industrial complex are well known, but the later bits of that speech are worth reading (and contrasting to a certain recent spectacle of ignominious incompetence): > \"Today, the solitary inventor, tinkering in his shop, has been overshadowed by task forces of scientists in laboratories and testing fields. In the same fashion, the free university, historically the fountainhead of free ideas and scientific discovery, has experienced a revolution in the conduct of research. Partly because of the huge costs involved, a government contract becomes virtually a substitute for intellectual curiosity. For every old blackboard there are now hundreds of new electronic computers. The prospect of domination of the nation's scholars by Federal employment, project allocations, and the power of money is ever present — and is gravely to be regarded. Yet, in holding scientific research and discovery in respect, as we should, we must also be alert to the equal and opposite danger that public policy could itself become the captive of a scientific-technological elite.\" > \"It is the task of statesmanship to mold, to balance, and to integrate these and other forces, new and old, within the principles of our democratic system — ever aiming toward the supreme goals of our free society.\" reply prpl 19 hours agoprevIs it too simple to just say the MBA happened? reply RandomCitizen12 4 hours agoparentYes, that is too simple. That may not be accurate, and if accurate stifles investigation into the root cause. reply pphysch 4 hours agoprevIn 2019, RAND published Extending Russia [1], which explored various and prescient hostile means to deal with its current government. It recommended economic warfare against Russia, which, since 2022, will go down as one of the great geopolitical blunders of the 21st century. My questions are to what extent that report affected the openness and credibility of RAND? [1] - https://www.rand.org/pubs/research_reports/RR3063.html reply MaxPock 3 hours agoparentTheir follow up report recommends pursuing a peace treaty as the war is no longer served Americas interests and is actually harmful. reply relaxing 20 hours agoprev> One of my favorite past-times, particularly when conversation got too multi-voiced in the office, was to wander the corridors of the abandoned basement. The firm, it transpires, was in the process of constructing a brand spankin’ new office building, right next door. The old one was going to be torn down. So it was in a state of, shall we say, disrepair. In fact, it looked as though they’d stopped doing anything with it, several years earlier. > But I found the basement irresistible. It drew me in like a tractor beam. Long, stale, sunless corridors, cracked linoleum at your feet, illumined by flickering fluorescent light-fixtures. Like something out of (or inspired by) Last Year at Marienbad. Nary a footstep now treads down those halls, which had overheard such secrets, hushed whispers, momentous occasions and portentous events. > One day, to my surprise, I turned the corner, and there, sitting in his cell, was none other than Manuel Noriega, the ex-dictator of Panama. Seeing as how I did not know him personally, but recognized him from his many media appearances, I hastened to introduce myself. “How are they treating you?” I asked. “Si si, not so bad. Every now and then some junior CIA type comes in and we do some more – what is it, water-surfing? Boogie-boarding? No, no, water-boarding. But it is more for his pleasure, than mine.” I told him that the U.S. actually had given Panama the canal. “Yeah, I heard about that,” he replied. “But how about all of the new peoples who are there now, think of all of the opportunities for a little friendly mordida!” I said I was gonna mosey on, but I’d be back. “Please bring me some of the CDs by the band Pink Floyd,” he said. “They are like the thinking man’s AC/DC – I got so sick of all that puerile metal crap they were blasting at me when I was in the compound.” “Better than Sadam Hussein,” I replied. “They got him in a spider hole, and it didn’t look as though he was enjoying any music!” “They got Sadam, too?” he replied, querulously. - David Kronemyer, My Days at RAND Corporation https://web.archive.org/web/20080815050205/http://kronemyer.... reply dayofthedaleks 3 hours agoparentThird paragraph marks this as a work of fabulism. reply relaxing 2 hours agorootparentIt’s very much real. reply eschneider 1 hour agoparentprevBoogie-boarding... O_o reply robertclaus 15 hours agoprevIt feels like a place like this would easily attract top talent nowadays. Does anybody know of places actually operating this way other than a few skunk works teams reporting to bigger corporations? reply nine_k 14 hours agoparentSuch organizations, while capable of bringing really large (and lucrative) breakthroughs, can't produce them reliably, let alone on a schedule. While at it, they require a constant and rather high upkeep. So they can only exist on thick streams of resources, which can be emitted either by huge corporations (Xerox PARC, Lockheed's skunkworks, IBM and Google research centers, etc), or governments, the latter almost invariably from its military branch. reply nimbius 16 hours agoprev [–] The thing that killed RAND was government oversight and neoliberalism. These days its not possible to innovate something like switched ethernet (which RAND had a hand in) unless you submit bids from forty GSA vendors and hold fifty meetings on which third party implementation consultants you need to hire for the work neoliberalism insists you not do anymore as a corporation because outsource culture is king. wrap it all up in a mountain of project managers and \"best practices\" because youre too chicken-shit to do anything that 200 other companies dont do, and viola. the punishment for failure FAR outweighs the reward for any breakthrough you think you can achieve. youre not a thinktank anymore youre just a consulting firm with a particularly attractive media spend. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "RAND Corporation's golden era, spanning two decades, led to major advancements in nuclear strategy, satellites, systems analysis, and early computing.",
      "Initially a research arm of the Air Force, RAND's success was driven by a talented, independent, and interdisciplinary team, contributing to fields like game theory, AI, and packet switching.",
      "Over time, RAND's focus shifted due to strained relations with the Air Force and diversification into social policy research, leading to a decline in cutting-edge science and innovation."
    ],
    "commentSummary": [
      "RAND Corporation was highly influential during WWII and the Cold War, similar to the peak periods of Google or Bell Labs.",
      "It was a hub for prominent computer scientists and mathematicians, contributing significantly to the field now known as data science, originally termed \"Operations Research.\"",
      "Despite its historical significance and innovative office designs for collaboration, RAND's modern recognition has diminished, with its legacy including both groundbreaking research and controversial strategies like those during the Vietnam War."
    ],
    "points": 121,
    "commentCount": 45,
    "retryCount": 0,
    "time": 1719863300
  },
  {
    "id": 40849363,
    "title": "A Git story: Not so fun this time",
    "originLink": "https://blog.brachiosoft.com/en/posts/git/",
    "originBody": "A Git story: Not so fun this time July 1, 2024 Table of contents Linus Torvalds once wrote in a book that he created Linux just for fun, but it ended up sparking a revolution. Git, his second major creation, also an accidental revolution. It’s now a standard tool for software engineers, but its origin story wasn’t so much fun this time, at least for Linus. Linus doesn’t scale 1998 was a big year for Linux. Major companies like Sun, IBM, and Oracle started getting involved with Linux. That spring, Linus’s second daughter was born, and his family had been living in California for about a year, settling into their new life. Even though Linux hadn’t brought Linus much financial gain, he was doing well both professionally and personally. On the other hand, the Linux kernel developer community was growing, and the existing collaboration methods were becoming insufficient. Linus started struggling to keep up with the pace of code changes from developers, becoming a bottleneck in the process. On September 28, 1998, Linus was reading the Linux kernel mailing list as usual when he came across this message: Please don’t waste your time on creating these patches. These things are functional in the vger tree. This message annoyed Linus. Linux code changes relied heavily on Linus himself. If you wanted to make a change, you’d email the mailing list, and if Linus saw and approved it, he’d incorporate your patch into his version and release new versions on FTP from time to time. Linus liked to work this way because it allowed him to control all changes. And everyone trusted Linus to manage Linux. However, since David Miller, a senior Linux kernel developer, set up a CVS server called vger, some people thought they could bypass Linus and just submit changes to vger. This wasn’t the first time Linus encountered this issue, and he responded unhappily on the mailing list: Note that saying “it’s in vger, so you’re wasting your time” is still completely and utterly stupid. The fact that it is in vger has absolutely no bearing, especially as there’s a lot of stuff in vger that will probably never make it into 2.2. A heated debate ensued between Linus and a few developers, who complained about Linus’s slow responses, sometimes requiring three emails to get a reply from the “benevolent dictator.” “These people should look at themselves in the mirror,” Linus thought. “I have to read so many emails a day. If sending three emails is too much trouble, I’d rather not have the patch.” He left this message before storming off: Quite frankly, this particular discussion (and others before it) has just made me irritable, and is ADDING pressure. Go away, people. Or at least don’t Cc me any more. I’m not interested, I’m taking a vacation, and I don’t want to hear about it any more. In short, get the hell out of my mailbox. Linus’s emotional outburst prompted some people to offer help. One of the open source movement leaders, Eric S. Raymond, author of the famous essay “The Cathedral and the Bazaar,” calmly urged: People, these are the early-warning signs of potential burnout. Heed them and take warning. Linus’s stamina has been astonishing, but it’s not limitless. All of us (and yes, that means you too, Linus) need to cooperate to reduce the pressure on the critical man in the middle, rather than increasing it. Larry McVoy also extended a helping hand. In an email titled “A solution for growing pains,” he wrote: The problem is that Linus doesn’t scale. We can’t expect to see the rate of change to the kernel, which gets more complex and larger daily, continue to increase and expect Linus to keep up. But we also don’t want to have Linus lose control and final say over the kernel, he’s demonstrated over and over that he is good at that. Figure out a means by which Linus can surround himself with some number of people who do part of his job. Add tools which make that possible. The mechanism which allows all this to happen is a distributed source management system… Larry was developing a new version control system called BitKeeper. The origin of BitKeeper In the early 1990s, Sun Microsystems introduced an internal tool called Network Software Environment (NSE) to manage their code, but NSE was slow and had a terrible user experience. Some engineers even quit in frustration. Larry McVoy, a seasoned operating system developer with a background in performance work, was approached by Sun’s management to improve NSE’s performance. When Larry looked at NSE’s code, he was surprised. “This thing wasn’t designed with performance in mind at all.” He also discovered that NSE was built on top of SCCS, a version control system from the 1970s, older than CVS and Subversion. Instead of trying to fix the deeply flawed NSE, Larry chose a different path: he wrote NSElite in Perl, implementing resync/resolve commands on top of SCCS, similar to Git’s clone/pull/push commands today. NSElite was much faster than NSE, so Sun’s engineers started abandoning NSE for NSElite. Seeing this, a Sun VP saw a business opportunity and formed an eight-person team to rewrite Larry’s Perl scripts in C++ and turn them into a product called TeamWare. TeamWare was likely the first distributed version control system (DVCS), and it eventually became essential for developing Sun’s Solaris operating system. Engineers who used TeamWare couldn’t go back: unlike CVS and Subversion, TeamWare allowed you to clone the entire project to your local machine, make changes locally, and merge your version back into the remote version when ready. The team consisted of eight experienced C programmers. Since C++ was the hot new language, they learned C++ while developing TeamWare. Before TeamWare was completed, Larry continued developing NSElite, which would make the TeamWare team look bad: one guy with Perl was outpacing eight people with C++. The VP then told Larry, “This has been reported to Scooter (Scott McNealy, Sun’s CEO). If you release it again, you’re fired.” In 1991, Larry stopped developing NSElite but couldn’t shake the idea of building a DVCS. He thought commercial software would follow TeamWare’s lead, but none did. In 1997, Larry began developing a DVCS called BitKeeper. However, it wasn’t until September 1998, when he saw Linus on the verge of burnout on the mailing list, that he felt truly motivated to take BitKeeper seriously. Linux kernel adopts BitKeeper One fall day in 1998, Larry invited Linus Torvalds, David Miller, and Richard Henderson to his home. After dinner, they sat on the floor and started brainstorming ways to reduce Linus’s workload. They drew diagrams on the floor for three or four hours, mostly based on how TeamWare had been working within Sun Microsystems. Larry knew them well. In this framework, developers could use BitKeeper to work independently without interfering with each other. When Linus did the final integration, he wouldn’t lose the history of the changes, making it easier for him to review the code. “Alright, if you build it and it works as you say, I’ll use it,” Linus said. “No problem, I’ve done this before. It should take about six months,” Larry replied. Larry quickly realized he had underestimated the complexity of the task. He founded a company called BitMover and recruited some version control experts to help build BitKeeper. Nineteen months later, in May 2000, BitKeeper’s first version was released. By then, BitMover was a team of seven people. The first version of BitKeeper included a command-line tool called bk and some graphical interface tools. The bk clone/pull/push commands functioned similarly to git clone/pull/push. At that time, Sun’s TeamWare was already well-regarded, and BitKeeper was TeamWare on steroids. For example, while TeamWare only allowed data transfer over NFS file systems, BitKeeper could transfer files over HTTP, which made it more distributed. As a result, BitKeeper soon brought BitMover a healthy cash flow. By 2002, BitMover had grown to a 25-person team, completely self-sufficient without external funding. Larry McVoy, Linux Expo, 1999 In January 2002, Linus’s workload issue resurfaced. Patches submitted by developers were either taking too long to get a response or were being ignored. Someone wrote “a modest proposal” to try to address the problem. In the discussion, someone casually mentioned, “BitKeeper is a really nice tool,” reminding Linus of that dinner three years ago at Larry’s house. Linus asked, “How many other people are actually using bitkeeper already for the kernel?” As it turned out, some kernel developers had already been using BitKeeper. The Linux PowerPC (PPC) team started testing BitKeeper in December 1999, and BitMover set up a bkbits.net server to support them. A few days later, on February 5, 2002, the mailing list saw Linus begin testing BitKeeper. From then on, the main Linux kernel developers started adopting BitKeeper. You didn’t have to use BitKeeper to contribute to development, but if you did, the process went something like this: # Download the repository bk clone bk://linux.bkbits.net/linux-2.5 linux-2.5 bk clone linux-2.5 alpha-2.5 # Pull changes from another place cd alpha-2.5 bk pull bk://gkernel.bkbits.net/alpha-2.5 # Edit files and push changes back to the remote bk vi fs/inode.c bk push bk://gkernel@bkbits.net/alpha-2.5 To send changes to Linus, you’d email the mailing list with something like: Here is an update for something something... Please pull from: bk://gkernel.bkbits.net/alpha-2.5 example/file1.c6 ++++++ example/file2.c4 ---- 2 files changed, 6 insertions(+), 4 deletions(-) No more free BitKeeper Larry McVoy allowed Linux kernel developers to use BitKeeper for free, but there were some strings attached. For example, the free user license required: You couldn’t turn off Open Logging, which sent usage records to the BitMover server. You couldn’t use BitKeeper for version control if you were working on version control software. You had to get BitMover’s permission if you wanted to run BitKeeper alongside other similar software. The Linux community, full of free software advocates, had mixed reactions. Some scoffed at these terms, while others avoided them. However, for Linus and the main Kernel developers, the key point was that BitKeeper reduced their workload. Since there were no better alternatives at the time, they accepted BitKeeper’s terms for the convenience it offered. Linus had always been open-minded about proprietary software. He had chosen the GPL for the Linux kernel purely to keep the commercial market from “tainting” Linux. The GPL fit his needs, so he used it. But he never thought all software had to be free software; he believed authors had the right to distribute their software however they wanted. To him, software use wasn’t a social movement. Free software advocates didn’t share his view. Some extreme ones even considered proprietary software to be evil. These hackers preferred the freedom to modify software over the convenience of BitKeeper. Larry felt the pressure from the community. To address the issue, the BitKeeper team set up a BitKeeper-to-CVS mirror in 2003, allowing those who didn’t want to install BitKeeper to access code history via CVS. However, the history from CVS was incomplete compared to BitKeeper, and people weren’t satisfied. “Why should our data be locked in BitKeeper’s proprietary format, and why are we prohibited from using other tools to read our own data?” In response, Andrew Tridgell (Tridge), the Australian programmer behind Samba and rsync, started developing a free BitKeeper client in February 2005 to solve the problems faced by free software users. Tridge did the following. “Here’s a BitKeeper address, bk://thunk.org:5000. Let’s try connecting with telnet.” $ telnet thunk.org 5000 Trying 69.25.196.29... Connected to thunk.org. Escape character is '^]'. “We’re connected. Why not type the help command?” help ? - print this help abort - abort resolve check - check repository clone - clone the current repository help - print this help httpget - http get command [...] “The BitKeeper server is kind enough to list all the commands.” “So clone must be the command to download the repository?” He typed clone and found that the output was a series of SCCS-formatted files. With that, the “reverse engineering” was mostly done; the rest was just writing the program. Linus somehow learned what Tridge was doing — perhaps Tridge told him privately. Linus then informed his friend Larry. Larry was not impressed. A free third-party client would ruin BitKeeper’s business model. Larry, seeking help from Linus and Stuart Cohen (then CEO of OSDL, now the Linux Foundation), wanted to ask Tridge to stop. Stuart Cohen chose to stay out of it, considering it none of OSDL’s business. But Linus didn’t want to lose BitKeeper, so he worked hard to mediate, trying to find a compromise acceptable to both sides. Tridge firmly believed he wasn’t doing anything wrong, thinking a third-party client would be a win-win for BitKeeper and kernel developers. In April 2005, he released SourcePuller on Freshmeat (later merged into SourceForge). In the README, he wrote: An open client combined with the ability to accurately import into other source code management tools would have been a big step forward, and should have allowed BitMover to flourish in the commercial environment while still being used by the free software community. I would also like to say that BitMover is well within its rights to license BitKeeper as it sees fit. I am of course disappointed at how BitMover has portrayed some of my actions, but please understand that they are under a lot of pressure. Under stress people sometimes say things that perhaps they shouldn’t. Larry disagreed with the win-win idea. Supporting kernel development cost money. Not only did they not make money, but they were also risking harm to their existing business model. To protect BitMover’s livelihood, he chose to revoke the free use license from BitKeeper. After weeks of negotiation, Linus was fed up with playing mediator. With no more free BitKeeper available, Linus was furious. He publicly blamed Tridge on the forum, saying he “just tore down something new” and “screwed people over.” Linus could have paid for BitKeeper himself, but he couldn’t ask other kernel developers to do the same, so he needed a new solution. He kept on writing: Now, I’m dealing with the fall-out, and I’ll write my own kernel source tracking tool because I can’t use the best any more. That’s ok - I deal with my own problems, thank you very much. On April 6, 2005, Linus announced on the mailing list that the Linux kernel was parting ways with BitKeeper. He first thanked Larry and his team for their help over the past three years. Then he said he would be offline for a week to find a replacement. Finally, he added: Don’t bother telling me about subversion. If you must, start reading up on “monotone”. That seems to be the most viable alternative. Monotone Monotone was created by Graydon Hoare. In 2001, Graydon, who lived in Canada, wanted to work more easily with his Australian friend. So they developed a system similar to today’s Continuous Integration (CI), which wasn’t widely known yet. Their system ensured that the code always passed tests. In 2002, Graydon became interested in combining version control with CI. At that time, only Aegis had such a concept. Graydon also saw his friends using BitKeeper and thought that merging Aegis with DVCS could be an opportunity. That’s how Monotone came into being. Remarkably, Graydon later joined Mozilla and created the Rust programming language. Unfortunately, Linus picked a bad time to play with Monotone. Monotone 0.7 had decent performance, but starting from v0.14, developers began adding many validation mechanisms. Just before Linus downloaded Monotone, Graydon released v0.17 and then went on vacation. This version included a lot of rigorous checks to ensure data integrity before writing to the database, but these checks hadn’t been optimized, slowing down performance. The release notes for 0.17 mentioned: not yet fully optimized; “pull” may be very slow and use lots of cpu Someone tested downloading Monotone with Monotone itself, and it took two hours, with 71 minutes of CPU time. “A heavily sedated sloth with no legs is probably faster,” they commented. Linus reported the performance issues to the Monotone developers. On April 10, 2005, Monotone 0.18 was released, with many operations running at least twice as fast. Although Linus was listed as a contributor in the 0.18 release, according to Monotone developer Nathaniel Smith: Linus hasn’t actually contributed any code to Monotone, or, to the best of my knowledge, any SCM besides git. He didn’t really provide any suggestions either, beyond “this is too slow!” ;-). He’s credited there because it was in discussions with him that I found the right test case to track down one of our major performance bugs. I debated for a bit whether I should actually credit him by name for that, exactly because it was likely to give people strange ideas, but, figured, if it had been anyone else I would have, so… *shrug*. Meanwhile, inspired by Monotone’s design, Linus started writing some C code from scratch. Git v0.01: First look On April 7, 2005, Linus uploaded a thing called Git and wrote on the mailing list: here’s a quick challenge for you, and any crazy hacker out there: if you want to play with something really nasty (but also very very fast), take a look at kernel.org:/pub/linux/kernel/people/torvalds/. First one to send me the changelog tree of sparse-git (and a tool to commit and push/pull further changes) gets a gold star, and an honorable mention. I’ve put a hell of a lot of clues in there. This was Linus’s first public mention of Git. The URL had the following files and directories: git.git/ 09-Apr-2005 16:09 - sparse.git/ 07-Apr-2005 20:07 - git-0.01.tar.bz2 07-Apr-2005 14:25 39K git-0.01.tar.bz2.sign 07-Apr-2005 14:25 248 git-0.01.tar.gz 07-Apr-2005 14:25 40K ... sparse-git.tar.bz2 08-Apr-2005 17:26 15M git-0.01.tar.bz2 had about 1,000 lines of C code: --------------------------------------------------------------------- File blank comment code --------------------------------------------------------------------- ./read-cache.c 31 14 219 ./update-cache.c 32 23 198 ./commit-tree.c 23 26 128 ./show-diff.c 8 5 73 ./cache.h 17 23 53 ./write-tree.c 11 7 53 ./read-tree.c 4 5 39 ./init-db.c 4 14 38 ./Makefile 14 0 26 ./cat-file.c 2 5 21 --------------------------------------------------------------------- SUM: 146 122 848 --------------------------------------------------------------------- Unlike today’s Git, which uses a single executable file, the earliest version of Git that Linus uploaded compiled into seven separate executables: init-db update-cache show-diff write-tree read-tree commit-tree cat-file The init-db command was simple. It created a directory named .dircache/objects in the current directory and then created 256 subdirectories numbered in hexadecimal from 00 to ff inside .dircache/objects. The .dircache/objects directory represented an object database with the following types of objects: Blob: the file contents. Tree: directories, essentially containing names of files (blob) and directories (trees). Changeset: defined by the names of two trees, representing the change from tree A to tree B. “Changeset” was an early term for what later became known as a “commit.” Here object names are not file or directory names but the SHA-1 hash of their compressed content. Linus borrowed this idea from Monotone, but while Monotone used SQLite to store SHA-1 object names and contents, Linus chose to use system calls and the filesystem directly. SHA-1’s uniqueness meant that the Git database would almost never have two objects with different names but identical content. If an object’s name was ba93e701c0fe6dcd181377068f6b3923babdc150, Git would store it in .dircache/objects/ba/ as a file named 93e701c0fe6dcd181377068f6b3923babdc150. The seven executables focused on different operations around this “content-addressable” filesystem. For example: write-tree: Creates a tree object, writing the snapshot of a directory into the database. commit-tree: Creates a changeset, linking two trees in the database, similar to today’s git commit. update-cache: Adds a file to the .dircache/index, akin to today’s git add to the staging area. Linus liked the SHA-1-based naming idea as soon as he saw it in Monotone — because it was simple. Simplicity was also what Linus liked about Unix. In his book “Just for Fun,” he described Unix: This simple design is what intrigued me, and most people, about Unix (well, at least us geeks). Pretty much everything you do in Unix is done with only six basic operations (system calls)… And you can build up pretty much everything from those six basic system calls. Git followed this philosophy, with a data model simpler than CSV, Subversion, or BitKeeper. It essentially stored the state of the directory before and after changes, without tracking what specific files or lines changed. This information was already embedded in the before and after states of the trees. The Git prototype Linus wrote in two days was simple. No extra validation. No relational database. Just C code, SHA-1 hashes, and system calls, completely tailored to Linus’s needs. Meanwhile, the Monotone project, entering its third year, was feature-rich and had to cater to a wide range of use cases. Plus, Monotone’s original author Graydon had added a bunch of unoptimized code before going on vacation, leaving it without leadership. Monotone couldn’t match Git’s speed since it was at a disadvantage. The sparse-git.tar.bz2 file Linus initially uploaded was likely the first Git repository ever. Sparse was a static analyzer for C that Linus wrote in 2003. If you’re still interested in Linus’s challenge, you can slightly modify the extracted sparse-git.tar.bz2 and use today’s git log command to read the change history: # Assuming you are in the sparse-git directory mv .dircache .git mkdir .git/refs git log Git’s early contributors The initial version of Git sparked lively discussion. A few days later, Linus created a dedicated mailing list for Git, allowing the Linux Kernel mailing list to get back on track. In the first month, the Git mailing list saw around 2,600 messages, while the Linux kernel, the most collaborative software project in history, had 7,000-9,000 messages each month during the same period. For experts in the version control field, Git was just another project. Linus’s first upload of Git contained only a few low-level operations. It lacked essential commands like clone and merge, making it far from a usable version control system. And Linus’s constant praise of Git unintentionally belittled other version control systems. This irritated Bram Cohen, the creator of BitTorrent. At the time, Bram was promoting his own version control system, Codeville. Codeville was already a mature DVCS comparable to Monotone and featured an advanced merge algorithm. Seeing how Linus and his followers talked about merge algorithms, Bram felt that Linus, an outsider, was reinventing the wheel. “Git is weekend hack which looks like a weekend hack,” Bram wrote. Bram got a point, but this wasn’t just any weekend hack — it was Linus Torvalds’s hack, the Linux kernel creator’s hack. As a folk hero in the open-source software world, Linus’s every move is under the spotlight. Young developers looked up to him, seeing him as a role model. Consequently, after Linus uploaded Git, it quickly attracted a group of young developers eager to join the discussion and development. One of the early contributors was Petr Baudis from the Czech Republic. The day Linus announced Git, Petr downloaded the code, became enchanted, and started contributing. Given the early Git’s usability issues, Petr developed git-pasky (pasky being Petr’s alias), which eventually became Cogito. If Git’s foundation was the plumbing, Cogito was the porcelain — the user-friendly interface. In software development terminology, comparing low-level infrastructure to plumbing is hard to trace, but the use of “porcelain” to describe high-level packaging originated in the Git mailing list. To this day, Git uses the terms “plumbing” and “porcelain” to refer to low-level and high-level commands, respectively. Additionally, Petr set up the first project homepage for Git, git.or.cz, and a code hosting service, repo.or.cz. These websites were the “official” Git sites until GitHub took over. Petr contributed externally by building on top of Git and creating services around it. Another early contributor, Junio Hamano, contributed directly from within Git itself. He later took over as Git’s maintainer from Linus. He still holds this position today. The successor Junio Hamano is a software engineer from Japan. Around 1995, about a year after graduating, he was sent to Los Angeles by his employer, Twin Sun, and has lived in the US ever since. There, he met Paul Eggert, who was also working at the same company at the time. Paul Eggert has maintained many free or open-source software projects, including RCS (an early version control system) and Tar. He is currently a professor at UCLA and the maintainer of the timezone database. Influenced by Paul, Junio developed an interest in the world of open-source software. Although he wasn’t a kernel developer, he subscribed to mailing lists for open-source projects like the Linux kernel just for fun. In April 2005, Junio saw Linus’s announcement on the mailing list that the Linux kernel was parting ways with BitKeeper. Junio had always wanted to make a mark in the open-source world, and this new project called Git seemed like a great opportunity — brand new, no historical baggage, easy to get into. He downloaded the tarball, spent about two hours reading through the initial Git code in one setting. He was impressed by how well it was written. After the initial release of Git, Linus quickly added commit and diff commands, but there was no merge yet. Although Linus had never written version control software before, he had used BitKeeper for three years. Before that, he had ten years of “version control human” experience. He knew what kind of merge algorithm he wanted. However, since the merge logic was more involved, Linus thought it might be better suited to a scripting language, writing: I’ve been avoiding doing the merge-tree thing, in the hope that somebody else does what I’ve described. I really do suck at scripting things, yet this is clearly something where using C to do a lot of the stuff is pointless. A week went by with no takers. Junio, between projects at the time, had some free time, so he wrote what Linus wanted in Perl and posted it to the mailing list. I now have a Perl script that uses rev-tree, cat-file, … and merge (from RCS). Quick and dirty. Junio probably picked up some knowledge of RCS from his mentor Paul, so he had some understanding of version control software. In his email, he also detailed about 30 test cases covering various code branches. It was already 1 AM, and with his kids waking up at 7 AM, Linus usually went to bed by 10 PM. But seeing Junio’s Perl script, Linus was thrilled and couldn’t help but reply: That’s exactly what I wanted. Q’n’D is how the ball gets rolling. He eagerly continued the discussion with Junio. “Merge with git-pasky II” originally started with Petr asking Linus about merging his version, but it soon diverted into a discussion on merge algorithms. During the discussion, Linus also explained why Git’s internals didn’t need to handle file renames. Over the next 48 hours, starting from the midnight on April 14, Junio and Linus exchanged a dozen emails in that thread. Junio patiently revised the code to meet Linus’s vision for merging. It was clear from his words that Junio was a big fan of Linus. For example, Junio would quote Linus’s words from four years ago, “I’m always right,” and would adequately flatter Linus. At midnight on April 16, Linus had a brainwave and mentioned he had a “cunning plan.” Damn, my cunning plan is some good stuff. Or maybe it is so cunning that I just confuse even myself. But it looks like it is actually working, and that it allows pretty much instantaenous merges. Linus cleverly reused the existing index, introducing the concept of “stages” on top of it, which significantly simplified the implementation of merge. Junio marveled at Linus’s solution: I really like this a lot. It is so simple, clear, flexible and an example of elegance. This is one of the things I would happily say “Sheeeeeeeeeeeeeesh! Why didn’t I think of THAT first!!!” to. This meant that Junio’s previous Perl code would be wasted, but the new solution was so brilliant that Junio accepted it wholeheartedly. The merge algorithm was just the beginning. Junio continued to contribute more patches to Linus, gradually earning Linus’s trust. Linus had mentioned before that he wouldn’t maintain Git long-term. Once the time was right, he would hand Git over to someone else and return to his main job with the Linux kernel. Junio was the obvious choice, as Linus appreciated his “good taste” in writing code. So, three months later, on July 26, Linus announced that he was passing the role of Git maintainer to Junio. Junio also posted an announcement: As some of you seem to have noticed even before the announcement by Linus, the official GIT repository at kernel.org is now owned by me. As Linus said in his message, this does not mean he is leaving us, so please do not panic. I would also like to thank Twin Sun Inc (my employer) and NEC for promising to support me working on GIT on a part time basis from now on. I expect to be spending 8 to 12 day-job hours per week; evenings and weekends are my own time as before. My tentative plan is to make Wednesdays and Saturdays my primary GIT days. Earlier, I was producing as many patches as ideas cross my mind, throwing all of them at the list to see which ones stick, relying on somebody with a good taste upstream to drop all the bad ones. Although it has been fun working that way with Linus, regrettably, I ended up wasting a lot of his time. I will slow down and be more careful as the “shepherd of the main repository” from now on. At least for now, you will see patches from me posted on the list like everybody else’s, before they hit the main repository. Under Junio’s leadership, Git 1.0.0 was released on December 21. 19 years later (as of July 2024), Junio is working at Google and still maintains Git. This article mentions Linus more often than Junio, but the biggest contributors to Git as it exists today are the persistent efforts of Junio and other developers in the background. “1% inspiration and 99% perspiration” might be a cliché, but it holds very true for successful projects like Git and the Linux kernel. GitHub and the Ruby people Although Git garnered a fair amount of attention early on, it was still pretty niche. In January 2006, the X Window team switched from CVS to Git, which wowed Junio. He didn’t expect such a big project like X Window to go through the trouble of changing version control systems. After BitKeeper, many DVCSes started to emerge, including Monotone, Mercurial, Darcs, Bazaar, Arch, and Fossil. The most notable among them was Mercurial, created by Matt Mackall. It was released just a few days after Git, with more complete features and a more user-friendly interface. It also had backing from Google Code and BitBucket. The version control market was like the Wild West, with each system holding its own. What truly pushed Git to the top and made it mainstream was GitHub. Or, as Linus put it, it’s the Ruby people, strange people, who made Git an overnight success. In February 2007, Git 1.5 was released, finally making Git more usable for normal people. At the time, Git was the hot new thing being talked about at Ruby meetups in San Francisco. Tom Preston-Werner, co-founder of GitHub, first heard about Git from his colleague Dave Fayram. Tom considered Dave to be the “patient zero” for the spread of Git adoption in the Ruby community. Despite Git’s popularity in the Ruby community, the only Git hosting service available at the time was Petr Baudis’s repo.or.cz, which was quite basic. For example, your code had to be public with no option for private repositories. Tom saw a big opportunity there. In 2007, social media was booming with Facebook, YouTube, and Twitter leading the way. Tom came up with an idea called GitHub: a social media hub for programmers for sharing Git repositories and exchanging ideas. One day in October 2007, Tom met Chris Wanstrath at a sports bar in San Francisco. They had met before at Ruby meetups but didn’t know each other well. Tom struck up a conversation and shared his GitHub idea. Chris found it interesting and agreed to join. At that time, both Tom and Chris had full-time jobs, so they spent their evenings and Saturdays building GitHub. Tom designed the user interface and used a Ruby library called Grit to interact with Git repositories, while Chris built the website with Ruby on Rails. Three months later, they started sending out invites to friends to test GitHub. In February 2008, PJ Hyett joined as the third co-founder. On April 10, GitHub officially launched with the tagline “Social Code Hosting.” GitHub, August 2008 Rails, the killer app for Ruby, switched from Subversion to GitHub just before GitHub’s launch, giving Git an even bigger boost in the Ruby community. Most people writing Ruby at the time were developing Rails applications. When they saw their go-to framework using GitHub, more Ruby developers followed suit. Merging Git and GitHub with conflict Scott Chacon wasn’t your typical Git + Ruby guy. Besides writing Ruby code, he was an excellent speaker, writer, and evangelist. He created videos, wrote documentation, and taught people how to use Git. He also had an in-depth understanding of Git internals and wrote an ebook called “Git Internals.” For three years, the “official” homepage for Git had been git.or.cz, set up by Petr Baudis in 2005. Scott wanted to create a more user-friendly homepage for beginners. In July 2008, he reorganized the contents from git.or.cz and launched a new homepage, git-scm.com. He then asked for feedback from Git core developers (especially Petr) on the Git mailing list. While Git had been popular in the Ruby community for a while, Ruby people were rarely seen on the Git mailing list. Most Git core developers were experienced C programmers active on the mailing list, while the Ruby crowd, mostly younger web developers, hung out at meetups, web forums, and GitHub, and probably never used a mailing list in their lives. The two groups didn’t interact much, and Scott’s post about git-scm.com on the Git mailing list was one of the few early interactions between them. Another issue for Git core developers was that Tom, without any discussion, forked and customized the Git daemon using Erlang to meet GitHub’s own needs. This was because, first, Tom wasn’t familiar with C, and second, posting on the mailing list was terrifying. The list was full of people smarter than you, and if you didn’t format your messages correctly, you’d look like an idiot. The process was just too slow, so Tom decided to handle it himself. Git-scm.com had a banner saying “hosting donated by GitHub,” which led some to question Scott’s motives. Some expressed dissatisfaction that GitHub was making money off Git while core Git developers didn’t see a share. However, most of the feedback was positive, and eventually, git-scm.com became the official Git homepage, with git.or.cz retiring. Tom met Scott at a Ruby meetup. He thought, “This guy could become either a powerful ally or a dangerous foe.” In October 2008, Scott joined GitHub, continuing his mission to spread the word about Git. He wrote more documentation, offered consulting services, and taught companies how to use Git. He also wrote the book “Pro Git,” which became the official Git book. GitHub’s evangelism strategy worked perfectly, expanding Git’s reach beyond the Ruby community. And GitHub itself was the biggest beneficiary. In October 2008, Google sponsored the first GitTogether conference. About 20 people from both the Git and GitHub teams met at Google’s headquarters in Mountain View. They put aside their differences, knowing that only by working together could they all become stronger. GitTogether 2008 Epilogue Unable to compete with Git and GitHub, BitKeeper eventually had to exit the market. In 2016, the team open sourced its code. This grandparent of DVCS, which inspired Git, Mercurial, Monotone, and others, is now a piece of history for people to observe and study. When asked for his thoughts, Larry McVoy responded: Hind sight is 20-20. The BitKeeper business had a good run, we were around for 18 years. It made enough that I and my business guy are retired off of what we made. On the other hand, we didn’t make enough for everyone to retire if they wanted to. We had a github like offering and it’s pretty clear that we should have put a bunch of money into that and open sourced BitKeeper. All I can say is it is incredibly hard to make that choice when you have something that is paying the bills. Shoulda, coulda, woulda, my biggest regret is not money, it is that Git is such an awful excuse for an SCM. It drives me nuts that the model is a tarball server. Even Linus has admitted to me that it’s a crappy design. It does what he wants, but what he wants is not what the world should want. Now, Larry enjoys his retirement. He likes to spend his time fishing with his kids. In a 2022 survey by Stack Overflow, Git had a market share of 94%, so much so that the following year, Stack Overflow stopped asking which version control system people used. Never in history has a version control system dominated the market like Git. What will be the next to replace Git? Many say it might be related to AI, but no one can say for sure. What we can be sure is that the transition will likely involve a series of occasional events and a group of talented hackers. References Other than the links in the article, additional references are listed below: “Just for Fun: The Story of an Accidental Revolutionary” by Linus Torvalds and David Diamond, 2002 “BitKeeper – Enterprise-ready version control, now open-source” on Hacker News Larry McVoy Interview with KernelTrap Larry McVoy Interview with LinuxWorld Linuxexpo 1999: Day 2: BitKeeper “How Tridge reverse engineered BitKeeper” on LWN.net “Tridgell drops Bitkeeper bombshell” on The Register “No More Free BitKeeper” on KernelTrap “The kernel and BitKeeper part ways” on LWN.net “not rocket science (the story of montone and bors)”, Graydon Hoare on LiveJournal “A Git Origin Story” by Zack Brown “10 Years of Git: An Interview with Git Creator Linus Torvalds” from the Linux Foundation Petr Baudis on LinkedIn Junio Hamano on LinkedIn “Version Control Shenanigans”, Bram Cohen on LiveJournal “Gitメンテナ　濱野 純”, 技術評論社 “How I Turned Down $300,000 from Microsoft to go Full-Time on GitHub” by Tom Preston-Werner Replacing Git with Git featuring Scott Chacon, the Changelog podcast GitTogether Group Photo, Junio Hamano on LiveJournal Larry McVoy’s resume",
    "commentLink": "https://news.ycombinator.com/item?id=40849363",
    "commentBody": "A Git story: Not so fun this time (brachiosoft.com)121 points by thunderbong 23 hours agohidepastfavorite26 comments hoistbypetard 21 hours agoThanks for sharing a fun read. Bitkeeper was neat, and my overall take on it mirrors Larry McVoy's: I wish he had open sourced it, made his nut running something just like github but for Bitkeeper, and that it had survived. I only had one interaction with him. In the early '00s, I had contributed a minor amount of code to TortoiseCVS. (Stuff like improving the installer and adding a way to call a tool that could provide a reasonable display for diffs of `.doc` and `.rtf` files.) I had a new, very niche, piece of hardware that I was excited about and wanted to add support for in the Linux kernel. Having read the terms of his license agreement for Bitkeeper, and intending to maintain my patches for TortoiseCVS, I sent him an email asking if it was OK for me to use Bitkeeper anyway. He told me that it did not look like I was in the business of version control software (I wasn't!) and said to go ahead, but let him know if that changed. I use git all the time now, because thankfully, it's good enough that I shouldn't spend any of my \"innovation tokens\" in this domain. But I'd still rather have bitkeeper or mercurial or fossil. I just can't justify the hit that being different would impose on collaboration. reply sunshowers 10 hours agoparentLike I tell lots of people, check out Jujutsu. It's a very Mercurial-inspired-but-better-than-it UI (the lead dev and I worked on Mercurial together for many years) with Git as one of the main supported backends. I've been using it full time for almost a year now. reply yencabulator 2 hours agoparentprevI was a heavy user of BitKeeper. To me, Git is almost exactly like a ground-up cleaner rewrite of BitKeeper. Gitk and git-gui are essentially clones of the BitKeeper GUI. I don't understand why you'd want to keep using BitKeeper. reply hoistbypetard 1 minute agorootparentI think my memory is probably colored by BitKeeper being my first DVCS. I was never a heavy user of it. I was exposed to BitKeeper when I was managing my team's CVS server. On my next team, we moved to svn, which always felt like cvs with better porcelain from a developer perspective, but when administering that server fell onto my plate, I liked it a lot better than CVS. And I thought BitKeeper would be nicer from a developer perspective. Then on my next team, we used mercurial. I really, really, really liked mercurial, both as a developer and as a dev infrastructure administrator. It also sucked a lot less on Windows than git or BitKeeper. The last time I had to decide for a new team, mercurial and git were the obvious options. I went with git because that was clearly what the world liked best, and because bringing new team members up to speed would require less from me that way. All that goes to say... my direct comparison of git and bitkeeper came from when bitkeeper was mature and git decidedly was not. Then I lumped it in with mercurial (which I really would still prefer, right now) and fossil (ditto). You're probably exactly right about BK. reply nmz 16 hours agoparentprevI wouldn't put fossil in that list of collaboration, since its not really a collaborative tool, or more like, there are barriers to that collaboration, like creating a username for each fossil repository. That's a huge barrier in my view. It would be nice if there was something like a general auth identity that can be used everywhere but that's still not implemented. FWIW, mercurial seems to have an advantage over git, and that support for BIG repositories which seems to be provided by facebook of all people, so until facebook moves to git, mercurial lives on. reply thunderbong 15 hours agorootparentYou can have one repository and link all the others to it via \"Login Groups\" https://www.fossil-scm.org/home/doc/trunk/www/caps/login-gro... reply cxr 20 hours agoprevThere's a screenshot purporting to be of GitHub from May 2008. There are tell-tale signs, though, that some or all of the CSS has failed to load, and that that's not really what the site would have looked like if you visited it at the time. Indeed, if you check github.com in the Wayback Machine, you can see that its earliest crawl was May 2008, and it failed to capture the external style sheet, which results in a 404 when you try to load that copy today. Probably best to just not include a screenshot when that happens. (Although it's especially silly in this case, since accessing that copy[1] in the Wayback Machine reveals that the GitHub website included screenshots of itself that look nothing like the screenshot in this article.) 1.reply philipwhiuk 19 hours agoparentThanks - I was struggling to believe GitHub would have launched with something as bad looking - 2008 was not CERN era looking webpages! reply eliangcs 18 hours agoparentprevAuthor here. That's a good catch, thanks! I've replaced it with a newer screenshot from August 2008. reply cryptonector 20 hours agoprev> In a 2022 survey by Stack Overflow, Git had a market share of 94%, ... > Never in history has a version control system dominated the market like Git. What will be the next to replace Git? Many say it might be related to AI, but no one can say for sure. I doubt it's getting replaced. It's not just that it's got so much of the market, but also that the market is so much larger than back in the days of CVS. It's hard to imagine everyone switching from Git. Switching from GitHub, feasible. From Git? That's much harder. reply jbaber 20 hours agoparentIt does feel like asking \"What will replace ASCII?\" Extensions, sure, but 0x41 is going to mean 'A' in 5050 AD. reply eliangcs 12 hours agorootparentAuthor here. I don’t think ASCII is the right comparison. True, it would be really hard for anything to compete with Git because a lot of infrastructures we have are already deeply integrated with Git. But think about x86 vs. ARM and how AI might change our ways of producing code. reply fragmede 14 hours agoparentprevGit shortcomings are well known by this point, so \"all\" a successor project has to do is solve those problems. Git scales to Linux kernel sized projects, but it turns out there are bigger, even more complex projects out there, so it doesn't scale to Google-sized organizations. You would want to support centralized and decentralized operation, but be aware of both, so it would support multiple remotes, while making it easier to keep them straight. Is the copy on Github up to date with gitlab, the CI system, and my laptop and my desktop? It would have to handle binaries well, and natively, so I can check-in my 100 MiB jpeg and not stuff things up. You'd want to use it both as a monorepo and as multirepos, by allowing you to checkout just a subtree of the monorepo. Locally, the workflow would need to both support git's complexity, while also being easier to use than git. Anyway, those are the four things you'd have to hit in order to replace git, as I see them. If you had such a system, getting people off git wouldn't be the issue - offer git compatibility and if they don't want to use the advanced features, they can just keep using their existing workflow with git. The problem with that though, is that then why use your new system. Which gets to the point of, how do you make this exist as a global worldwide product? FAANG-sized companies have their own internal tools team to manage source code. Anywhere smaller doesn't have the budget to create such a thing from scratch but You can't go off and make this product and then sell it to someone because how many companies are gonna go with an unproven new workflow tool that their engineers want? What's the TAM of companies for whom \"git's not good enough\", and have large enough pocketbooks? reply cryptonector 2 hours agorootparentYou say this, but Git has made great strides in scaling to huge repositories in recent years. You can currently do the \"checkout just a subtree of the monorepo\" just fine, and you can use shallow clones to approximate a centralized system (and most importantly to use less local storage). > If you had such a system, getting people off git wouldn't be the issue - offer git compatibility and [...] Git is already doing exactly that. reply Borg3 10 hours agorootparentprevYou are right. GIT is not DVFS, its DVCS. It was made to track source code, not binary data. If you are putting binary to DVCS, you are doing something wrong. But, there are industries that need it, like game industry. So they should use tool that allow that. I heard that Plastic-SCM is pretty decent at it. Never used it so cant tell personally. Replacing GIT is such a stupid idea. There is no ONE tool to handle all cases. Just use right one for your workflows. I, for example, have a need to version binary files. I know GIT handles them badly, but I really like the tool. Solution? I wrote my own simple DVFS tool for that usecase: dot.exe (138KB) Its very simple DVFS for personal use, peer to peer syncing (local, TCP, SSH). Data and Metadata are SHA-1 checksumed. Its pretty speedy for my needs :) After weeks of use use I liked it so much, I added pack storage to handle text files and moved all my notes from SVN to DOT :) reply superfish 21 hours agoprevGreat read! I’m sure I’m not the first to point out that Junio (the appointed git “shepherd”) works at Google where mercurial is the “recommend local vcs” internally instead of git. reply mulmboy 21 hours agoprev> Additionally, Petr set up the first project homepage for Git, git.or.cz, and a code hosting service, repo.or.cz. These websites were the “official” Git sites until GitHub took over. Is this true? I thought GitHub had no official affiliation with the git project reply jimbobthrowawy 21 hours agoparentI think some github employees have written code that went into git, but it's not an official affiliation. The quotes on \"official\" imply non-official to me. i.e. official seeming to people who don't know any better. reply roywashere 21 hours agoparentprevThe git repo is on kernel.org nowadays with mirrors on repo.or.cz and GitHub. But I think they mean here what the official git project ‘site’ is with docs and so on. And that is now https://git-scm.com/ and indeed as the article describes that was initially set up by GitHub people, to promote git reply arp242 21 hours agoparentprevThat's why \"official\" in in quotes. As in: \"de-facto standard\". reply cxr 19 hours agorootparentNot really. git-scm.org is the de facto \"official\" site for the Git project in about the same way that French is the de facto \"official\" language of France. They meant exactly what they wrote: GitHub took over hosting duties for the official Git site (because they did). reply xiwenc 21 hours agoprevIt’s been awhile since i actually finished reading an article this long. Very well written! I tried to find out who the author is or how come he/she knows so much. No luck. Anyone else knows or OP care to chip in? reply dudus 17 hours agoprevI never heard the term porcelain before, but I liked this tidbit. \"In software development terminology, comparing low-level infrastructure to plumbing is hard to trace, but the use of “porcelain” to describe high-level packaging originated in the Git mailing list. To this day, Git uses the terms “plumbing” and “porcelain” to refer to low-level and high-level commands, respectively. \" Also, unrelated, the \"Ruby people, strange people\" video gave me a good chuckle. https://www.youtube.com/watch?v=0m4hlWx7oRk&t=1080s reply sergius 6 hours agoprevThis story is missing the impact that Tom Lord's TLA had on the git design. reply nyanpasu64 9 hours agoprevFYI Mercurial's developer is now known as Olivia Mackall; sadly the Google infobox has failed to pick up the updated information. reply globular-toast 8 hours agoprev [–] I've heard the story before but this was still fun to read. I didn't realise quite how rudimentary the first versions of git were. It really makes you wonder: was git the last opportunity to establish a ubiquitous version control system? Will there ever be another opportunity? Regardless of git's technical merits, one thing I'm extremely happy about is that it's free software. It seemed to come just before an avalanche of free software and really changed the way things are done (hopefully for good). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Linus Torvalds created Git out of necessity in 2005 after the free license for BitKeeper, a previously used version control system, was revoked.",
      "Git's development was inspired by Monotone but aimed to be simpler and faster, quickly gaining contributors and popularity, especially within the Ruby community.",
      "GitHub, launched in 2008, significantly boosted Git's adoption, leading to its current dominance in the version control market with a 94% share."
    ],
    "commentSummary": [
      "The post discusses the history and evolution of version control systems, particularly focusing on Git and its predecessors like BitKeeper and Mercurial.",
      "It highlights the dominance of Git in the market, with a 94% share according to a 2022 Stack Overflow survey, and debates whether any future system could replace it.",
      "The conversation includes personal anecdotes and opinions on various version control systems, emphasizing Git's widespread adoption and integration into modern development workflows."
    ],
    "points": 121,
    "commentCount": 26,
    "retryCount": 0,
    "time": 1719861052
  },
  {
    "id": 40850313,
    "title": "Venezuela is first Andean country to lose all of its glaciers",
    "originLink": "https://www.nbcnews.com/news/latino/-great-sadness-venezuela-first-andean-country-lose-glaciers-rcna153784",
    "originBody": "Climate in Crisis 'A great sadness': Venezuela is first Andean country to lose all of its glaciers Scientists explain the loss of the Humboldt Glacier, the last in the Sierra Nevada, which they believe makes the South American country the first in modern history to lose all its glaciers. The Humboldt glacier, in Merida, Venezuela, seen on April 16, 2019.Jose Manuel Romero / AP file Print Save Create your free profile or log in to save this article May 25, 2024, 11:00 AM UTC By Albinson Linares, Noticias Telemundo For the people of the Venezuelan state of Mérida, the glaciated peaks of its Sierra Nevada have been a source of pride since time immemorial: The mountains are part of the regional identity and the origin of various legends in the area that relate them to mythical white eagles. However, none of the six glaciers that crowned the mountains remain. The International Climate and Cryosphere Initiative (ICCI), a science advocacy organization, recently declared that the Humboldt Glacier — also known as La Corona, or \"the crown\" in Spanish — is already \"too small to be classified as a glacier.” In March, Venezuelan scientists had warned that the glacier had dramatically shrunk. \"Our tropical glaciers began to disappear since the '70s and their absence is felt. It is a great sadness and the only thing we can do is use their legacy to show children how beautiful our Sierra Nevada was,” Alejandra Melfo, an astrophysicist at the Universidad de los Andes in Mérida, said in an interview with Noticias Telemundo. Venezuela had six glaciers in the Sierra Nevada, located about 16,000 feet above sea level. By 2011, five had already disappeared, but the Humboldt Glacier located near the second highest mountain in the country, Humboldt Peak, resisted the onslaught of the weather. Scientists believe its disappearance makes Venezuela the first country in the Americas — and the first country in modern history — to lose all its glaciers. Glaciers are large masses of ice that have formed due to the accumulation of snow over centuries. According to the United States Geological Survey (USGS), they typically exist where average annual temperatures reach near-freezing levels and winter precipitation causes significant accumulations of snow. An important aspect of glacier development is that temperatures during the rest of the year should not cause the complete loss of the previous winter’s snow accumulation, this is how glaciers are maintained and how they grow. And that’s what failed in the Humboldt case. \"In the case of the Humboldt, it's a process of erosion that has been going on for years without stopping,\" Melfo said. With the increase in global temperatures due to climate change, the melting of large ice masses is a continuous phenomenon that, among other things, contributes to raising sea levels around the world. \"It is the end of a glacial cycle. And in the intertropical zones, basically below 5,000 meters, almost all the glaciers have been disappearing,\" said Maximiliano Bezada, a geological researcher at the University of Minnesota. \"The case of Humboldt was iconic because it is at 4,800 meters and yet it remained for quite a long time, and that is a climatic anomaly.\" Although the Humboldt Glacier was expected to last at least another decade, scientists had been unable to monitor the area where it's located due to the country’s political turmoil. “Venezuela’s glaciers are not the first to disappear, some have disappeared in Colombia and other countries. What happens is that Venezuela had few and all in the Sierra Nevada, I saw how the glaciers of Pico La Concha and Pico Bolívar disappeared. That is why it is the first country to run out of glaciers,” Melfo said. 'The consequences of higher temperatures' Due to their large mass, glaciers tend to flow like very slow rivers. Although there is no universal consensus on how large an ice mass must be to be considered a glacier, the USGS states that a commonly accepted standard is about 25 acres. The case of the Humboldt glacier is not the only one. Glaciers around the world are shrinking, and some are disappearing faster in defiance of scientific projections. A 2023 study analyzed the planet’s 215,000 terrestrial glaciers more comprehensively than previous research and concluded that, if temperatures continue to increase, 83% of the world’s glaciers will be gone by the year 2100. “Although the end of the glacier was something that was going to happen due to the cycle we are experiencing, there is no doubt that global warming, a product of greenhouse gases, has of course accelerated the disappearance process,” Bezada said. Between 1952 and 2019 alone, Venezuela’s glacier surface went from 2,317 square kilometers to just 0.046 square kilometers, according to a 2020 study. “There are several projects that monitor change in the Sierra Nevada with temperature sensors buried in the ground and that are measured every six months. The evidence shows warming, in addition, the plants that grow there are changing because climate change is already felt in the peaks of the Andes,” Melfo said. Researchers believe that the El Niño climate phenomenon influenced the melting of the Humboldt Glacier, because it causes warmer temperatures that accelerate the disappearance of tropical glaciers. “The speed at which glaciers are melting is evidence of climate change. However, this is not new. Glaciers began to disappear a long time ago, but the speed has changed due to high temperatures,\" Melfo said. \"Beyond the glaciers, we are seeing rapid changes in the composition of species, plants and animals, and this is recorded. Denying climate change has become a very dangerous thing for everyone.\" The Andes region — a mountain range running through parts of Argentina, Bolivia, Chile, Colombia, Ecuador, Peru and Venezuela — has seen a temperature rise of at least 0.10 degrees Celsius over the past seven decades. For several scientists, that is one of the main reasons why Venezuela has lost all its glaciers. “In the Andean zone of Venezuela, there have been some months with monthly anomalies above average, which is exceptional in those tropical latitudes,” said Maximiliano Herrera, climatologist and weather historian. However, the melting of the glacier is also an opportunity for further study. Melfo said that the end of the glacier in Venezuela marks the beginning of a new process in the area and an event that will have to be investigated. \"Life starts to rise and colonize the rock. The lichens come first, then the mosses create the soil, organic matter is created and that creates conditions for the plants to arrive, and then the animals come. This is how an ecosystem is assembled; it's called primary succession and it is a unique process,\" she said. Meanwhile, what little ice remains on Humboldt will continue to melt. Residents of Mérida, including Melfo, say the glacier will continue to exist as long as the white vestiges can be seen from the city — which stopped happening with the other glaciers. “For the people of Mérida, perhaps the most beloved glacier was that of Pico Bolívar, which since 2012 was a remnant of a glacier. However, people continued to say that it was a glacier until the last bit of ice that could be seen from the city disappeared in 2020,\" Melfo said. \"I think the same thing is going to happen with the Humboldt: until the last piece disappears, we are going to continue saying that it is a glacier.\" An earlier version of this story was first published in Noticias Telemundo. Albinson Linares, Noticias Telemundo",
    "commentLink": "https://news.ycombinator.com/item?id=40850313",
    "commentBody": "Venezuela is first Andean country to lose all of its glaciers (nbcnews.com)115 points by Brajeshwar 22 hours agohidepastfavorite40 comments getoj 21 hours agoVenezuelan singer-songwriter Jorge Drexler, who grew up around these glaciers, wrote a poignant lament[1] in anticipation of this day. The gist is that at this point the only thing to do is to grieve for the world we have already lost. I don't think there's anything else to say. Y cuando el momento llegue, honremos nuestras heridas / Celebremos la belleza que se aleja hacia otras vidas / Y aunque la pena nos hiera, que no nos desampare / Y que encontremos la manera de despedir a los glaciares (When the moment comes, let us honor our wounds / celebrate the beauty that goes off to other lives / and although the sorrow stings, I hope it will remain / and that we find a way to say goodbye to the glaciers) [1]https://www.youtube.com/watch?v=iNsFF_eaXBU reply brezelgoring 20 hours agoparentHi! Jorge Drexler is not Venezuelan but from Uruguay [1]. I should know, I'm from there as well and he is one of our few cultural exports aside from Football. [1] - https://es.wikipedia.org/wiki/Jorge_Drexler reply getoj 14 hours agorootparentYou're right of course - I realized my mistake several hours later, but much too late to edit... → Uruguayan singer-songwriter Jorge Drexler, who grew up around some other glaciers reply jaimebuelta 21 hours agoparentprevNot to take away the poetry, but Jorge Drexler is from Uruguay https://en.wikipedia.org/wiki/Jorge_Drexler reply nullwriter 20 hours agorootparentIn a way, I'm happy its not Venezuela. Although still sad that this is happening reply swayvil 21 hours agoparentprevJorge is one hard-hitting poet. Dang. reply Tao3300 20 hours agoparentprev> the only thing to do is to grieve for the world we have already lost Tears won't put a glacier back. reply margalabargala 21 hours agoprev> Between 1952 and 2019 alone, Venezuela’s glacier surface went from 2,317 square kilometers to just 0.046 square kilometers, according to a 2020 study. Checked the study because those numbers seemed suspect. That's 2.3 square kilometers, not 2300. reply harlanlewis 20 hours agoparentThis may be the study: https://www.tandfonline.com/doi/full/10.1080/15230430.2020.1... Quote from the abstract: > In Venezuela, glacial area has decreased 98 percent between 1952 and 2019 (from 2.317 km2 to 0.046 km2). So it appears you are correct. I looked it up because I was skeptical of your skepticism - Washington state is at a very different latitude, but at 1/5 the area of Venezuela has ~450 sq km of glaciers. Mt Rainier alone has 90 sq km. https://glaciers.us/glaciers.research.pdx.edu/Glaciers-Washi... There’s no arguing against extreme glacial retreat (I started this by fact-checking your downplay), but this article does feel pretty sensational about a place that didn’t really have glaciers to begin with. reply margalabargala 20 hours agorootparentI did not mean to downplay severity. I live in an area with a few dozen glaciers, and I've spent the last decade watching them become smaller and smaller with each passing year. The article being off by three orders of magnitude annoyed me because the loss of that quantity of ice in one location in just 70 years would be catastrophic; if we assume 40 meter thickness, that's 58 cubic kilometers of water added into the local watershed. As it stands, the statistic is \"just\" depressing. reply harlanlewis 19 hours agorootparentApologies for misreading your intent, I hear you and am in full agreement. reply Etheryte 20 hours agoparentprevMany countries use comma as the decimal separator, in fact, using comma is more common than using a dot if you go by the number of countries. [0] [0] https://en.wikipedia.org/wiki/Decimal_separator reply MaulingMonkey 20 hours agorootparentThey usually do not mix decimal seperators in the same sentence however, and as leading zeros are generally avoided on integers, \"0.046\" is pretty clearly using a period as the decimal seperator. reply moralestapia 20 hours agorootparentprevAny countries that use both? Because they also wrote \"0.046\". reply HPsquared 21 hours agoparentprevCould that be from confusion between the use of comma as decimal symbol and periods to denote thousands? (German practice) reply margalabargala 20 hours agorootparentI'm familiar with the practice, but it must be quite the confusion to mix both in the same sentence. reply bogota 40 minutes agoprevI follow a tour guide in Colombia who takes people up the glaciers there. It’s really sad to see them all melting away year after year. reply beeandapenguin 20 hours agoprevA related article from NASA Earth Observatory has a slider to compare satellite images of the glacier. https://earthobservatory.nasa.gov/images/152893/humboldt-gla... reply bamboozled 21 hours agoprevI don’t really have words for this. It’s hard to contemplate why have done this to our home. We’re like a group of vandals just breaking things for the hell of it. Such beauty and the home to many species, wiped out… reply p51-remorse 20 hours agoprevSo, we’re all onboard for nuclear, right? And we’re all going to vote for anyone who will fast track building nuclear plants and cut through some regulatory crap? If this is an emergency, and it looks like it is, let’s start treating it that way. Clean energy is a solved problem. reply lanstin 20 hours agoparentIf only your post were from 2001 instead of a time when solar + batteries is so much faster to deploy and cheaper to build than nuclear. Tho, of course, there is a good amount of funding for nuclear in Biden's climate change law. It kept us in California from moth-balling a nuclear plant, but the new money seems to be for industrial sized battery plants. reply lanstin 19 hours agoprevhttps://academic.oup.com/oocc/article/3/1/kgad008/7335889?lo... a nice summary of the current math. reply bluedino 20 hours agoprevAt the risk of sounding completely ignorant, haven't the glaciers been disappearing since the ice age? Didn't some sort of glacial period last end about 10,000 years ago? reply Synaesthesia 21 hours agoprevKilimanjaro will soon lose its glacier too. reply nickburns 21 hours agoprev\"Scientists believe its disappearance makes Venezuela the first country in the Americas — and the first country in modern history — to lose all its glaciers [emphasis added].\" Title inaccurate. This goes well beyond only 'Andean countries.' EDIT: To the 4+ dol—I mean, people who have now downvoted this comment: 'the Americas' is commonly geographically understood to mean the land masses of both North and South America. There are glaciers present in both 'Americas.' The Andean mountains are only present in South America. Jesus, this place is stupid today. reply flykespice 20 hours agoprevCan it be reversed? reply photochemsyn 19 hours agoprevCoincidentally, Venezuela is producing about 800,000 barrels of oil per day (on the heavy dirty side) and has a goal of increasing production to a million barrels per day. The USA (including Alaska) by comparison is currently producing 13.2 million barrels a day, a steep increase from 2008 when only 5 million bpd were being produced. A remarkable number of politicians who campaign on 'slowing climate change' have in reality (and hypocritically) directly facilitated this growth in oil production by blocking efforts to limit pipeline expansion, enforce environmental laws already on the books, and so on. As far as Venezuela glaciers, consensus appears to be that they probably had melted completely around the time of the Holocene warm period c. 9000 years ago, and their reforming was evidence of the beginning of a long slow slide into another glacial era (which would have taken 70,000 years or so to reach the next glacial maximum, on the 100 ky cycle). That's now been put aside as we head full tilt back towards Pliocene conditions. reply goldname 20 hours agoprevdont worry theyll grow back reply insane_dreamer 21 hours agoprevAnd yet, in the US, CO2 emissions are about where they were in 1990 (which is better than 2005, but very far from where it should be) https://www.eia.gov/environment/emissions/carbon/ reply TaylorAlexander 21 hours agoparentWhat are the emissions when we account for goods manufactured overseas? In 1990, much more of our manufactured goods were included in US emissions. Now most of our manufactured goods have their emissions in other countries. reply philipkglass 20 hours agorootparentThe term for this is \"consumption based emissions.\" You can find charts for it at Our World In Data. Here's the chart for the US along with an explanation of the methodology: https://ourworldindata.org/grapher/consumption-co2-per-capit... The US is improving even after accounting for imports. Consumption-based emissions were 20.3 tons per capita in 1990 and peaked in 2005 at 22.7 tons per capita, declining to 14.9 tons per capita as of 2022. Of course present emissions per capita are not as low as if imports had no CO2 footprint. reply SV_BubbleTime 19 hours agorootparentSo, China and India are pretty nuts. reply TaylorAlexander 9 hours agorootparentYeah. I believe the reason is rapid industrialization. As far as I’m aware that tends to be associated with high emissions. There is some hope that as African nations industrialize, they can use greener technology so we don’t see the same pattern repeat there. The population in Africa is nearly that of India and it’s growing rapidly. reply insane_dreamer 20 hours agorootparentprevReally good point; that's why we have to look at global emissions; I just pointed to US ones as I couldn't find global ones more recent than 2021 (which are here: https://www.iea.org/data-and-statistics/data-tools/greenhous... The picture is bleak; globally we are rapidly approaching 2x 1990 levels reply cchance 20 hours agorootparentYa notice how energy has gone down, but industry based co2 production has doubled lol reply cchance 20 hours agoparentprevIsn't this just \"ENERGY\" related emissions... it doesn't account for CO2 as a whole emissions just those in relation to production of energy, farming etc, aren't accounted for nor all the CO2 sources we technically just shipped overseas as we reduced local production but increased imports. reply RONROC 21 hours agoprev [–] Climate change is real but its effects are overblown. Weeping for a glacier that would of melted a few years later regardless of public opinion seems insufficient reply ljsprague 20 hours agoparentAgreed. I'm much more concerned about deforestation in the Amazon. reply CodeWriter23 20 hours agoparentprev [–] I’m open to listening to Climate Scientist that considers Astrophysics as a factor. The rest can keep their pseudoscience to themselves as far as I’m concerned. reply SV_BubbleTime 20 hours agorootparent [–] Sorry, best we can do are celebrities wagging their fingers at you. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Venezuela has become the first Andean country to lose all its glaciers, with the Humboldt Glacier in the Sierra Nevada now too small to be classified as a glacier.",
      "The International Climate and Cryosphere Initiative (ICCI) confirmed this status, noting that Venezuela had six glaciers in the Sierra Nevada, but only the Humboldt Glacier remained by 2011.",
      "Scientists attribute the glacier's disappearance to climate change and rising global temperatures, with a 2023 study predicting that 83% of the world's glaciers could disappear by 2100 if temperatures continue to rise."
    ],
    "commentSummary": [
      "Venezuela is the first Andean country to lose all its glaciers, with the glacier surface shrinking from 2.317 square kilometers in 1952 to just 0.046 square kilometers in 2019.",
      "This drastic reduction underscores the severe impact of climate change on the environment.",
      "The loss has prompted discussions on the accuracy of these figures and the broader emotional and environmental implications of glacial retreat."
    ],
    "points": 115,
    "commentCount": 40,
    "retryCount": 0,
    "time": 1719865850
  }
]
