[
  {
    "id": 36175000,
    "timestamp": 1685783639,
    "title": "Fq: Jq for Binary Formats",
    "url": "https://github.com/wader/fq",
    "hn_url": "http://news.ycombinator.com/item?id=36175000",
    "content": "fqTool, language and decoders for working with binary data.Basic usage is fq . file or fq d file.For details see usage.md.Backgroundfq is inspired by the well known jq tool and language and allows you to work with binary formats the same way you would using jq. In addition it can present data like a hex viewer, transform, slice and concatenate binary data. It also supports nested formats and has an interactive REPL with auto-completion.It was originally designed to query, inspect and debug media codecs and containers like mp4, flac, mp3, jpeg. But has since then been extended to support a variety of formats like executables, packet captures (with TCP reassembly) and serialization formats like JSON, YAML, XML, ASN1 BER, Avro, CBOR, protobuf. In addition it also has functions to work with URL:s, convert to/from hex, number bases, search for things etc.In summary it aims to be jq, hexdump, dd and gdb for files combined into one.NOTE: fq is still early in development so things might change, be broken or do not make sense. That also means that there is a great opportunity to help out!GoalsMake binaries accessible, queryable and sliceable.Nested formats and bit-oriented decoding.Quick and comfortable CLI tool.Bits and bytes transformations.HopesMake it useful enough that people want to help improve it.Inspire people to create similar tools.Supported formatsaac_frame, adts, adts_frame, aiff, amf0, apev2, apple_bookmark, ar, asn1_ber, av1_ccr, av1_frame, av1_obu, avc_annexb, avc_au, avc_dcr, avc_nalu, avc_pps, avc_sei, avc_sps, avi, avro_ocf, bencode, bitcoin_blkdat, bitcoin_block, bitcoin_script, bitcoin_transaction, bits, bplist, bsd_loopback_frame, bson, bytes, bzip2, cbor, csv, dns, dns_tcp, elf, ether8023_frame, exif, fairplay_spc, flac, flac_frame, flac_metadatablock, flac_metadatablocks, flac_picture, flac_streaminfo, gif, gzip, hevc_annexb, hevc_au, hevc_dcr, hevc_nalu, hevc_pps, hevc_sps, hevc_vps, html, icc_profile, icmp, icmpv6, id3v1, id3v11, id3v2, ipv4_packet, ipv6_packet, jpeg, json, jsonl, macho, macho_fat, markdown, matroska, mp3, mp3_frame, mp3_frame_vbri, mp3_frame_xing, mp4, mpeg_asc, mpeg_es, mpeg_pes, mpeg_pes_packet, mpeg_spu, mpeg_ts, msgpack, ogg, ogg_page, opus_packet, pcap, pcapng, pg_btree, pg_control, pg_heap, png, prores_frame, protobuf, protobuf_widevine, pssh_playready, rtmp, sll2_packet, sll_packet, tar, tcp_segment, tiff, tls, toml, tzif, udp_datagram, vorbis_comment, vorbis_packet, vp8_frame, vp9_cfm, vp9_frame, vpx_ccr, wasm, wav, webp, xml, yaml, zipIt can also work with some common text formats like URL:s, hex, base64, PEM etc and for some serialization formats like XML, YAML etc it can transform both from and to jq values.For details see formats.md and usage.md.Presentations\"fq - jq for binary formats\" at FOSDEM 2023 - video & slides\"fq - jq for binary formats\" at No time to wait 6 - video - slides\"fq - jq for binary formats\" at Binary Tools Summit 2022 - video - slidesInstallUse one of the methods listed below or download a pre-built release for macOS, Linux or Windows. Unarchive it and move the executable to PATH etc.On macOS if you don't install using one of the method below you might have to manually allow the binary to run. This can be done by trying to run the binary, ignore the warning and then go into security preference and allow it. Same can be done with this command:xattr -d com.apple.quarantine fq && spctl --add fqHomebrew (macOS)brew install wader/tap/fqMacPortsOn macOS, fq can also be installed via MacPorts. More details here.sudo port install fqWindowsfq can be installed via scoop.scoop install fqArch Linuxfq can be installed from the extra repository using pacman:pacman -S fqYou can also build and install the development (VCS) package using an AUR helper:paru -S fq-gitNixnix-shell -p fqFreeBSDUse the fq port.AlpineCurrently in edge testing but should work fine in stable also.apk add -X http://dl-cdn.alpinelinux.org/alpine/edge/testing fqBuild from sourceMake sure you have go 1.18 or later installed.To install directly from git repository (no clone needed) do:# build and install latest releasego install github.com/wader/fq@latest# build and install latest mastergo install github.com/wader/fq@master# copy binary to $PATH if neededcp \"$(go env GOPATH)/bin/fq\" /usr/local/binTo build, run and test from source:# build and rungo run .# build and run with argumentsgo run . -d mp3 . file.mp3# just buildgo build -o fq .# run all tests and build binarymake test fqTODO and ideasSee TODO.mdDevelopment and adding a new decoderSee dev.mdThanks and related projectsThis project would not have been possible without itchyny's jq implementation gojq. I also want to thank HexFiend for inspiration and ideas and stedolan for inventing the jq language.Similar or related worksToolsHexFiend Hex editor for macOS with format template support.binspector Binary format analysis tool with query language and REPL.kaitai Declarative binary format parsing.Wireshark Decodes network traffic (tip: tshark -T json).MediaInfo Analyze media files (tip mediainfo --Output=JSON and mediainfo --Details=1).GNU poke The extensible editor for structured binary data.ffmpeg/ffprobe Powerful media libraries and tools.hexdump Hex viewer tool.hex Interactive hex viewer with format support via lua.hachoir General python library for working binary data.scapy Decode/Encode formats, focus on network protocols.Projects and StandardsLet's Solve the File Format ProblemPRONOM file format registrySustainability of Digital Formats at Library of CongressData Format Description LanguageLicensefq is distributed under the terms of the MIT License.See the LICENSE file for license details.Licenses of direct dependencies:Forked version of gojq https://github.com/itchyny/gojq/blob/main/LICENSE (MIT)Forked version of readline https://github.com/chzyer/readline/blob/master/LICENSE (MIT)github.com/BurntSushi/toml https://github.com/BurntSushi/toml/blob/master/COPYING (MIT)github.com/creasty/defaults https://github.com/creasty/defaults/blob/master/LICENSE (MIT)github.com/gomarkdown/markdown https://github.com/gomarkdown/markdown/blob/master/LICENSE.txt (BSD)github.com/gopacket/gopacket https://github.com/gopacket/gopacket/blob/master/LICENSE (BSD)github.com/mitchellh/copystructure https://github.com/mitchellh/copystructure/blob/master/LICENSE (MIT)github.com/mitchellh/mapstructure https://github.com/mitchellh/mapstructure/blob/master/LICENSE (MIT)github.com/pmezard/go-difflib https://github.com/pmezard/go-difflib/blob/master/LICENSE (BSD)golang/snappy https://github.com/golang/snappy/blob/master/LICENSE (BSD)golang/x/* https://github.com/golang/text/blob/master/LICENSE (BSD)gopkg.in/yaml.v3 https://github.com/go-yaml/yaml/blob/v3/LICENSE (MIT)Parts of go crypto/tls and github.com/zmap/zcrypto https://github.com/zmap/zcrypto/blob/master/LICENSE (Apache)",
    "summary": "- FqTool allows working with binary formats using a CLI tool similar to the language jq.\n- It can inspect, slice, concatenate, and transform binary data, supporting nested formats and providing an interactive REPL.\n- Fq can work with a variety of formats, including media codecs, packet captures, and serialization formats like JSON, YAML, and XML.",
    "hn_title": "Fq: Jq for Binary Formats",
    "original_title": "Fq: Jq for Binary Formats",
    "score": 592,
    "hn_content": "Developer Ingve has released 'Fq', a new project on Github that enables users to create and contribute to a centralised repository for binary parsers. In a Hacker News thread, Ingve states that he was motivated to create Fq after being frustrated at the lack of centralised documentation and tooling support for \"obsucre binary formats\". The thread includes discussions on other programs and tools, their limitations, and ideas for future developments in the space.Fq, a tool for programmatically documenting binary formats, was featured on Hacker News. Users commented on its usefulness in debugging and analyzing binary data, and discussed options for using it on Ubuntu or Debian. Some alternative tools for JSON querying was also mentioned, including XPath 3.1 and SpyQL. There were also comments on the name of the tool and suggestions for a more descriptive name. One user requested help in understanding a binary file, for which users suggested using debuggers and low-level tools such as Rizin/Cutter or Binary Ninja.",
    "hn_summary": "- Ingve has released 'Fq', a tool for programmatically documenting binary formats and contributing to a centralized repository\n- Users discuss Fq's usefulness in debugging and analyzing binary data and mention alternative tools for JSON querying\n- There are comments on the name of the tool and suggestions for more descriptive names, and users suggest using debuggers and low-level tools for understanding binary files."
  },
  {
    "id": 36174801,
    "timestamp": 1685781045,
    "title": "Red Hat dropping support for LibreOffice",
    "url": "https://lwn.net/ml/fedora-devel/20230601183054.12057.45907@mailman01.iad2.fedoraproject.org/",
    "hn_url": "http://news.ycombinator.com/item?id=36174801",
    "content": "LWN.netNews from the sourceContentWeekly EditionArchivesSearchKernelSecurityEvents calendarUnread commentsLWN FAQWrite for usUser: Password: | |LibreOffice packagesThread information [Search the fedora-devel archive] Matthias Clasen [this message] ` Demi Marie Obenour  ` Christian Schaller   ` Demi Marie Obenour    ` Christian Schaller   ` Sandro    ` Mattia Verga via devel     ` Michael J Gruber    ` Matthias Clasen     ` Stephen Smoogen      ` Peter Robinson       ` Stephen Smoogen       ` Christian Schaller    ` Matthew Miller     ` Sandro      ` Leslie Satenstein via devel       ` Vitaly Zaitsev via devel        ` Peter Boy        ` Michael Catanzaro      ` Peter Boy       ` Mattia Verga via devel     ` Ben Cotton      ` PGNet Dev ` Gwyn Ciesla via devel  ` Kevin Kofler via devel   ` Jiri Vanek    ` Mattia Verga via devel  ` Ivan Chavero  ` blinxen ` Terry Bowling  ` Peter Robinson  ` Robert Marcano via devel ` Ralph Bromley  ` Ralph Bromley   ` Peter Boy  ` Samuel Sieb   ` Vitaly Zaitsev via devel ` John Iliopoulos  ` Michael CatanzaroFrom:  Matthias Clasen <mclasen-AT-redhat.com>To:  devel-AT-lists.fedoraproject.orgSubject:  LibreOffice packagesDate:  Thu, 01 Jun 2023 18:30:54 -0000Message-ID:  < 20230601183054.12057.45907@mailman01.iad2.fedoraproject.org>Hey, as you've probably seen, the LibreOffice RPMS have recently been orphaned, and I thought it wouldbe good to explain the reasonsbehind this.The Red Hat Display Systems team (the team behind most of Red Hat\u2019s desktop efforts) has maintainedthe LibreOffice packages in Fedora for years as part of our work to support LibreOffice for Red HatEnterprise Linux. We are adjusting our engineering priorities for RHEL for Workstations andfocusing on gaps in Wayland, building out HDR support, building out what\u2019s needed forcolor-sensitive work, and a host of other refinements required by Workstation users. This is workthat will improve the workstation experience for Fedora as well as RHEL users, and which, we hope,will be positively received by the entire Linux community. The tradeoff is that we are pivoting away from work we had been doing on desktop applications andwill cease shipping LibreOffice as part of RHEL starting in a future RHEL version. This also limitsour ability to maintain it in future versions of Fedora. We will continue to maintain LibreOffice in currently supported versions of RHEL (RHEL 7, 8 and 9)with needed CVEs and similar for the lifetime of those releases (as published on the Red Hatwebsite). As part of that, the engineers doing that work will contribute some fixes upstream toensure LibreOffice works better as a Flatpak, which we expect to be the way that most peopleconsume LibreOffice in the long term. Any community member is of course free to take over maintenance, both for the RPMS in Fedora andthe Fedora LibreOffice Flatpak, but be aware that this is a sizable block of packages anddependencies and a significant amount of work to keep up with.Matthias_______________________________________________devel mailing list -- devel@lists.fedoraproject.orgTo unsubscribe send an email to devel-leave@lists.fedoraproject.orgFedora Code of Conduct: https://docs.fedoraproject.org/en-US/project/code-of-cond...List Guidelines: https://fedoraproject.org/wiki/Mailing_list_guidelinesList Archives: https://lists.fedoraproject.org/archives/list/devel@lists...Do not reply to spam, report it: https://pagure.io/fedora-infrastructure/new_issueCopyright \u00a9 2023, Eklektix, Inc.Comments and public postings are copyrighted by their creators.Linux is a registered trademark of Linus Torvalds",
    "summary": "- Red Hat Display Systems team, responsible for supporting LibreOffice for Red Hat Enterprise Linux (RHEL), is shifting their engineering priorities towards improving workstation experience for Fedora and RHEL users in areas such as Wayland, HDR, and color-sensitive work, among others.\n- As part of this pivot, Red Hat will cease shipping LibreOffice as part of future RHEL versions, which will also limit their ability to maintain it in future versions of Fedora.\n- Red Hat will continue to maintain LibreOffice in currently supported RHEL versions, contributing upstream fixes to ensure that LibreOffice works better as a Flatpak, which they expect to be the way most people consume LibreOffice in the future. However, any community member is free to take over maintenance, but should be aware that it is a sizable block of packages and dependencies that require significant work to keep up with.",
    "hn_title": "Red Hat dropping support for LibreOffice",
    "original_title": "Red Hat dropping support for LibreOffice",
    "score": 354,
    "hn_content": "Red Hat will no longer support LibreOffice RPMs in Fedora; LibreOffice will work better as a Flatpak, which is expected to be the primary way to consume it; it is still possible for community members to take over the maintenance of RPMS; maintaining a sizable block of packages and dependencies is a significant amount of work for anyone who decides to take on the task; Flatpak is not suitable for everyone as it requires multiple parallel runtimes, which can increase the security space one needs to monitor.Red Hat engineers will contribute to the improvement of LibreOffice as a Flatpak, helping it work better as a containerized application for RHEL and Fedora Linux systems. The company expects Flatpak to become the most popular way of installing LibreOffice in the long run, and runtimes rather than libraries are required. Sandboxing is expected to increase in importance as Red Hat focuses on enterprise-y features and improves security. Issues related to support for multiple Linux distributions and fragmented libraries are brought up, but coordinated efforts by developers will result in progress, as seen with Amazon, Valve, and Arch Linux who were initially only available on Ubuntu before other Linux distros enabled redistribution. It was eventually possible to encourage Valve to support Arch Linux and upstream improvements have been of help.Users of LibreOffice are debating whether or not the software should be sandboxed to prevent suspicious activity and unauthorized access to sensitive system resources like the microphone or location data. While some argue that the code can be audited to ensure there's no malicious intent, others believe that sandboxes offer a safer solution. Some have criticized Flatpak as a delivery method, saying it mixes packaging and sandboxing poorly and is not effective enough at the former. Guix has been suggested as a better solution. Despite issues with sandboxing, many continue to use LibreOffice and believe that the benefits outweigh the risks.Red Hat has ended support for the installation of LibreOffice by default on Red Hat Enterprise Linux (RHEL) and Fedora Workstation in order to free up resources and focus on developing gaps in image and video editing capabilities. Despite this, LibreOffice can still be installed manually by users. The primary focus of the move is aimed to enhance RHEL for Workstations, leading to improved colour-sensitive work and adding HDR support. Meanwhile, the popularity of Google Docs and Office 365 means that desktop document editing software has become somewhat obsolete. Some workplaces still use such software but the majority of people now prefer online solutions. Conversely, with Linux desktop lacking sufficient HDR and colour management tools, the decision by Red Hat is seen by some as necessary if Linux is to be used in creative industries.Red Hat has announced that they will no longer support LibreOffice in their RHEL package repositories, stating that they want to focus on improving workstation experience with HDR. However, this decision does not mean that users cannot still install and use LibreOffice through other means. Collabora Office Online, an online version of LibreOffice, is a server version that Collabora contributes to, but it doesn't have a free online demo. Additionally, Red Hat has not given up on desktop Linux, as they are still investing more into desktop Linux than others. They are continuing to do work on things like Pipewire, Wayland, Flatpak, Gtk, Gnome, AMD graphics drivers, making the Nvidia graphics drivers situation improve, and more.- A company is no longer supporting a crucial business application, including bug-fixes and packaging fixes.\n- RH's desktop team likely has limited resources and is prioritizing parts of the ecosystem that benefit their business customers, such as investing in Wayland's HDR support.\n- The decision to no longer support the business application is seen as a sensible one.\n- Users who want to use LibreOffice can still install it via Flatpak.\n- RH's ability to afford running their business is not relevant to the decision.",
    "hn_summary": "- Red Hat will no longer support LibreOffice RPMs in Fedora, but users can still install it manually or via Flatpak.\n- Red Hat engineers will contribute to optimizing LibreOffice as a Flatpak for RHEL and Fedora Linux systems.\n- Sandboxing is debated as a solution to prevent unauthorized access to system resources, but some criticize Flatpak's delivery method while others suggest Guix as a better alternative."
  },
  {
    "id": 36172461,
    "timestamp": 1685751695,
    "title": "Intelligent Brains Take Longer to Solve Difficult Problems",
    "url": "https://www.bihealth.org/en/notices/intelligent-brains-take-longer-to-solve-difficult-problems",
    "hn_url": "http://news.ycombinator.com/item?id=36172461",
    "content": "Jump to page contentOpen/close searchPressDeEnAbout usTranslationResearchCareerNewsBIHNewsPress release31 May 2023Intelligent brains take longer to solve difficult problems\u00a9 BIH | Petra RitterDo intelligent people think faster? Researchers at the BIH and Charit\u00e9 \u2013 Universit\u00e4tsmedizin Berlin, together with a colleague from Barcelona, made the surprising finding that participants with higher intelligence scores were only quicker when tackling simple tasks, while they took longer to solve difficult problems than subjects with lower IQ scores. In personalized brain simulations of the 650 participants, the researchers could determine that brains with reduced synchrony between brain areas literally \u201cjump to conclusions\u201d when making decisions, rather than waiting until upstream brain regions could complete the processing steps needed to solve the problem. In fact, the brain models for higher score participants also needed more time to solve challenging tasks but made fewer errors. The scientists have now published their findings in the journal Nature Communications.CookiesThis website uses cookies. These are small text files that are stored on your end device. Your browser accesses these files. The use of cookies increases the user-friendliness and security of this website. You decide for which categories you want to agree to the use of cookies and for which not. Note: It is not guaranteed that you will be able to access all functions of this website without restrictions if you make the appropriate settings.You can change or revoke your consent at any time by clicking on the Settings button at the bottom of the website. For more information on the use of cookies on this website, please refer to the Privacy Policy.Necessary cookiesNecessary cookies CookiesRequired cookies guarantee core functions such as security, network management, and accessibility. You can disable them by changing your browser settings. However, this may affect the way the website works.Web Statisticsaktivate Web Statistics CookiesVideosaktivate Videos CookiesEmbedded Contentaktivate Embedded Content CookiesConfirm SelectionSelect AllYou can change your cookie settings at any time and activate the change by reloading the website.",
    "summary": "- Researchers at BIH and Charit\u00e9 \u2013 Universit\u00e4tsmedizin Berlin found that participants with higher intelligence scores were only faster in completing simple tasks but took longer to solve difficult problems than those with lower IQ scores.\n- The personalized brain simulations of 650 participants revealed that brains with reduced synchrony between brain areas \"jump to conclusions\" when making decisions, while higher scoring participants needed more time to solve challenging tasks but made fewer errors.\n- The findings have been published in the journal Nature Communications.",
    "hn_title": "Intelligent Brains Take Longer to Solve Difficult Problems",
    "original_title": "Intelligent Brains Take Longer to Solve Difficult Problems",
    "score": 346,
    "hn_content": "Intelligent brains take longer to solve difficult problems, according to a study by the Berlin Institute of Health. This poses a challenge in job interviews where time is limited, and interviewers may prioritize correctness over the thought processes behind solving a problem. Industry experts criticize the current interview process used in tech for placing too much emphasis on rote memorization and not enough on practical problem-solving skills. Additionally, interviewees may feel intense pressure during the interview process, similar to the stress of handling an emergency technical incident. Several tech companies are taking more holistic approaches to evaluate candidates, including getting to know them as people and assessing problem-solving skills instead of memorization.The article is a collection of comments on various aspects of tech interviews, hiring processes, and team dynamics. Some of the points raised include the importance of psychological safety in promoting creativity and innovation, the need for organizations of all sizes to prioritize hiring quality candidates and provide ample time for interviews, and the challenges of evaluating candidates' problem-solving abilities while avoiding undue emphasis on correct answers. Other considerations mentioned include the importance of maintaining grace and civility in personal and professional relationships, as well as the role of emotional intelligence in coping with adversity and overcoming handicaps.The post discusses the typical interview process for developer and design/UX roles, which includes a coding or design test and a technical/team fit interview. There is some debate in the comments about whether candidates should be paid for their time during the interview process or not, with some arguing that it's a waste of time if a company is stretching out interviews excessively. Some readers share their experiences of interviews that have lasted longer or shorter than expected. The importance of finding the right candidate based on a company's needs and job fit is emphasized.The article discusses the subjective nature of interviews and the potential for biases such as lack of diversity and favoritism towards certain personalities. The interview process is often flawed as it doesn't assess actual problem-solving skills but instead recitation of stock answers, which is an unrealistic measure of intelligence. Companies may not be looking for exceptional candidates but average ones willing to do an average job. The ability to approach problems with open-mindedness and come up with creative solutions is different from institutionalized and tunnel-visioned thinking promoted by education systems, which hinder divergent thinking. The interview process doesn't always account for cultural fit, which is an essential aspect of job satisfaction and faster onboarding. Some companies have a hiring committee that approves a job offer, which contributes to the hiring process's delay.No meaningful content found.- Intelligent brains take longer to solve difficult problems, according to a new study.\n- Researchers created a digital model of the human brain using brain scans and mathematical models.\n- Individualized \"in silico\" brains behave differently from one another, matching the intellectual performance and reaction times of their biological counterparts.\n- There is a problem with the \u201cstar developer\u201d mentality of leaving buggy code in production.\n- People are very eager to take articles as examples and use them to slam individuals they have a vendetta against, while looking away from the other extreme which has the exact same problem. Going too fast is a problem. So is going too slow and getting close to a deadline and then business forces you to get disciplined and deliver something not battle-tested.\n- Abstraction solves a lot of hard problems, but it is also costly.Researchers have found that people with higher IQs typically needed more time to solve complex problems in order to produce correct answers, whilst those participants with a lower IQ tended to reach wrong conclusions more rapidly. In personalised brain simulations of the 650 participants, those whose simulated brains were wired to make more computation mistakes when less time was available to solve problems scored lower in IQ tests than those who took longer on the same tasks but made fewer mistakes. However, some critics have questioned the validity of the study, arguing that it should have been carried out on real human brains rather than simulations.Researchers found a link between slower problem-solvers and higher average functional connectivity in brain regions, along with better results; intelligent individuals tend to control their System 1 and urge for intuitive answers more effectively than others; the novel aspect here is the researchers digitally simulating the neural processes underlying System 1 and System 2; there is a lack of knowledge about the human brain structures, and many biases are at play in decision-making theories.",
    "hn_summary": "- Intelligent brains take longer to solve difficult problems according to a study by the Berlin Institute of Health.\n- The tech industry's interview process is criticized for placing too much emphasis on rote memorization rather than practical problem-solving skills, which can lead to pressure and stress during the interview process.\n- Several tech companies are taking a more holistic approach to evaluation, including assessing problem-solving skills and getting to know candidates as people.\n- The interview process can be flawed due to potential biases and a lack of assessment of actual problem-solving skills, leading to a focus on stock answers rather than creative thinking.\n- The importance of psychological safety, hiring quality candidates, and cultural fit is emphasized.\n- Debate surrounds whether candidates should be paid for their time during interviews or not.\n- Abstraction solves many hard problems but comes at a cost.\n- Researchers created a digital model of the human brain using brain scans and mathematical models, finding a link between slower problem-solvers and higher average functional connectivity in brain regions.\n- There is a lack of knowledge about human brain structures, and biases are at play in decision-making theories."
  },
  {
    "id": 36180316,
    "timestamp": 1685824651,
    "title": "GPS (2022)",
    "url": "https://ciechanow.ski/gps/",
    "hn_url": "http://news.ycombinator.com/item?id=36180316",
    "content": "- GPS is a valuable invention that uses satellites orbiting the earth to help determine a location with high accuracy.\n- GPS receivers use trilateration to determine location based on distance measurements from multiple points of reference.\n- Time of flight can be used as a measure of distance by using a constant velocity to calculate the distance traveled.\n- Sound can be used to make distance measurements by emitting a signal from a known location and recording the time it takes to reach a receiver.\n- Clock synchronization is crucial for accurate positioning, and the bias between clocks can affect distance measurements and the accuracy of positioning.\n- The position and bias of multiple receivers can be determined by using a third emitter at a known location.The post discusses using distance measuring to pinpoint location in three dimensions and how it differs from flat measurement. Sound waves were used initially, but light and radio waves are better carrier options. Obstacles like hills and the curvature of the earth require emitters to be placed high, and satellites help with this. Elliptical orbits are necessary to stay in proximity to Earth, with a semi-major axis determining the duration of orbit. Geostationary and geosynchronous orbits have limitations for global positioning, so GPS uses non-geostationary orbits, with inclination and orbital period determining their positions in the sky for observers on Earth.- GPS consists of 6 different orbits with a total of 30 active satellites, which improve accuracy and ensures redundancy.\n- Satellites are not evenly distributed within an orbit, and as Earth rotates, the number of visible satellites changes.\n- Each part of the Earth is easily covered by at least 4 satellites, allowing the receiver to calculate its position and clock bias.\n- Relativistic effects are accounted for by satellites broadcasting three coefficients that allow the receiver to correct for any offset or speed change of that satellite\u2019s clock.\n- GPS receivers try to find such a set of four solutions, three position coordinates and the clock bias, that will minimize the error. \n- The calculated clock bias is very useful in many applications that require time synchronization.\n- The information sent by a GPS satellite is collectively known as a navigation message and consists of 25 frames, each with 5 subframes.\n- Each subframe contains telemetry information, timestamps, satellite clock corrections, and ephemeris parameters.\n- Almanac data is provided for all satellites, which allows the receiver to approximate when a new satellite would rise above the horizon.The navigation message of GPS satellites is divided into frames, subframes, and individual bits of data, each equal to 0 or 1. The transmission of data is done through radio waves in a specific range of the radio spectrum that can reach the receivers on Earth in any weather conditions. Modern GPS satellites transfer only 50 bits of data per second, which is why they use binary phase-shift keying modulation for transfer. The method of encoding is required to filter out overlapping data bits from multiple satellites which has to be distinguished, and GPS solves this problem by using a binary code that repeats over time and consists of a predetermined number of so-called chips known as PRN codes. The PRN codes have two essential properties: auto-correlation and cross-correlation, responsible for detecting alignment and distinguishing between different satellites. The receiver doesn't need to send anything to the satellites, as it just listens to their signals.",
    "summary": "- GPS uses satellites orbiting the earth to determine a location with high accuracy.\n- Different methods, such as trilateration and time of flight, are used to measure distance and determine positioning.\n- GPS consists of six different orbits with a total of 30 active satellites, which provide redundancy and improve accuracy.",
    "hn_title": "GPS (2022)",
    "original_title": "GPS (2022)",
    "score": 310,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginGPS (2022) (ciechanow.ski)310 points by tkiolp4 13 hours ago | hide | past | favorite | 29 commentslondons_explore 2 hours ago | next [\u2013]By the way...Gold codes (this article calls them chipping codes) can be used to solve a lot of engineering problems where you need to synchronise two things. Eg. \"I want to transmit an infrared signal and receive it somewhere else, but the signal isn't bright enough to detect! - no worries, use a 1023 bit gold code, and suddenly you get a 30x effective brightness increase, and perfect time sync, with no hardware changes!\"However... beware that you should never transmit the codes once per millisecond. Thats the GPS rate, and GPS is very easy to accidentally interfere with if you use their gold codes. Instead transmit at some other data rate (ie. once per 1.2 milliseconds), or generate your own gold code set, and you won't disrupt GPS.replysieste 10 hours ago | prev | next [\u2013]Ah, from ciechanow.ski, so upvoted instinctively. Only then I realised this is from 2022. Anyway, it's nice to see this post again.replyturkeytail 4 hours ago | parent | next [\u2013]I was hoping this was new as well.replyendorphine 2 hours ago | prev | next [\u2013]Off-topic: I was looking at the first visualization (the globe with the satellites) and thought to myself: \"how cool is that the author also drew the stars in the galaxy behind the globe?\". Only after 3 seconds I realized this was just dust on my screen.replymartyvis 1 hour ago | parent | next [\u2013]I went back and noticed the same. Most be the genuine blackness of AMOLED screens.replyIndigoIncognito 1 hour ago | parent | prev | next [\u2013]Hahareplydan-robertson 10 hours ago | prev | next [\u2013]See also: http://lea.hamradio.si/~s53mv/navsats/theory.htmlreplyMarekKnapek 6 hours ago | parent | next [\u2013]The article says that GLONASS time counts days from zero to 1461, then resets back to zero. This is 4 years if we think leap year is once 4 years. But it is not. Leap year is once 4 years, but each 100 years it is not, except each 400 years it is. This is on average 365.2425 days per year not 365.25 days per year. Is GLONASS not long term thinking ahead enough?replythemerone 6 hours ago | root | parent | next [\u2013]GLONASS also depends on leap seconds, which is why Russia is opposed to eliminating them by 2035.replysgtnoodle 2 hours ago | root | parent | next [\u2013]Leap seconds are completely arbitrary by committee, aren't they? I'm curious how there could be a technical dependency.replyfanf2 1 hour ago | root | parent | next [\u2013]GLONASS transmissions have fields for earth orientation parameters that are too small to allow for unbounded DUT1: it has a built-in assumption that its system time is close to earth rotation angle.replytverbeure 7 hours ago | parent | prev | next [\u2013]See also: http://www.aholme.co.uk/GPS/Main.htmreplymatheusmoreira 9 hours ago | prev | next [\u2013]Every article from this domain is a work of art.replyheyoni 9 hours ago | parent | next [\u2013]Ok good cause I saw how tiny my scroll bar got and was wondering if I should invest the time to read the whole thing!replymatheusmoreira 8 hours ago | root | parent | next [\u2013]You won't be disappointed. Check out the archives for even more.https://ciechanow.ski/archives/I recommend the mechanical watch demonstration.replyIndigoIncognito 2 hours ago | prev | next [\u2013]Correct me if I am wrong, but was this not a duplicate of a post (top of all time on HN)? Aren't duplicates not allowedreplynameequalsmain 1 hour ago | parent | next [\u2013]> Are reposts ok?> If a story has not had significant attention in the last year or so, a small number of reposts is ok. Otherwise we bury reposts as duplicates.https://news.ycombinator.com/newsfaq.htmlreplyajay-d 11 hours ago | prev | next [\u2013]see https://news.ycombinator.com/item?id=29981188replydang 10 hours ago | parent | next [\u2013]Thanks! Macroexpanded:GPS - https://news.ycombinator.com/item?id=29981188 - Jan 2022 (285 comments)replyuserbinator 5 hours ago | prev | next [\u2013]Once you understand the theory, you can look at this for actual code and calculations on received GPS data: https://news.ycombinator.com/item?id=35550339replyas4296 9 hours ago | prev | next [\u2013]This is so crazy, never even realized how complex location tracking is...replyUser23 7 hours ago | prev [\u2013]GPS satellites don\u2019t correct for relativistic effects. They just set the Earth as the preferred frame, which is a great choice for a terrestrial positioning system.I\u2019ll see if I can find the paper it\u2019s quite interesting.Edit: I can't find the specific paper I'm thinking of. It's one that discusses how when other orbiting bodies want to use GPS they have to make a bunch of complex corrections that terrestrial users don't. But a search for Earth Centerered Inertial Frame will find you plenty of papers discussing the general concept.replyfsh 3 hours ago | parent | next [\u2013]GPS satellites don't compensate for relativistic effects (except for the huge offset built into their atomic clocks), but receivers certainly do. The satellite orbits are slightly elliptical which leads to varying gravitational time dilation. If this is not taken into account, positioning is off by around 10 m [1]. This is an effect from general relativity, so it might be left out in simple textbook explanations.[1] https://gssc.esa.int/navipedia/index.php/Relativistic_Clock_...replyrzimmerman 6 hours ago | parent | prev | next [\u2013]I believe there is a correction for the onboard satellite atomic clocks, which run faster than ground/ECI clocks due to a combination of special and general relativistic effects. The correction is a simple one - they just calibrate the clock with a small polynomial. IIRC nothing but the linear and constant terms are even required or used.replysillysaurusx 6 hours ago | parent | prev [\u2013]If you do run across the paper, please post it. It sounds quite interesting.replyOldGuyInTheClub 3 hours ago | root | parent [\u2013]\"Relativity in the Global Positioning System\" by Neil Ashby of the University of Colorado is excellent. Chapter 6 discusses relativistic corrections for satellites using GPS.Living Rev. Relativity, 6, (2003), 1https://link.springer.com/content/pdf/10.12942/lrr-2003-1.pd...Ashby knows whereof he speaks. He is credited with properly accounting for general relativistic effects in what is now the GPS constellation.https://en.wikipedia.org/wiki/Neil_Ashbyreplycornflake23 2 hours ago | root | parent [\u2013]This is a fantastic reference! Thank you!Quote from the paper: \u201cRelativistic principles and effects which must be considered include the constancy of the speed of light, the equivalence principle, the Sagnac effect, time dilation, gravitational frequency shifts, and relativity of synchronization.\u201cSo many factors to unpack yet the solution is right there.replyOldGuyInTheClub 2 hours ago | root | parent | next [\u2013]You're very welcome. I revisit it periodically and understand a little more each time.replydefrost 1 hour ago | root | parent | prev [\u2013]Interestingly while all those points factor in it would be possible to have a working GPS system without \"understanding\" the error or having any grasp of relativity.To expand on that, consider if the satellites went up (with ideas of basic triangulation from beacons orbiting) and then the drifting error for a supposedly fixed ground position was noticed what could be done?The 'unknown cause' error function over time twixt fixed position and uncorrected GPS calculation can be fed into a Kalman filter to derive weights that eliminate the error.Typically what happens in many instrumentation applications is models are created to derive functions to emit answers, errors are noticed, people think hard to add extra terms to account for errors and eventually either all errors are accounted for or some residual 'wobble' remains which can be smoothed away by an adaptive error model.To this day in high precision GPS applications post processing runs are used to improve accuracy that account for relativity factors, atmospheric twinkle factors, (other factors I'd have to look up), and still there's a bit or error left over that can be sweep away (for a time) with a Kalman filter.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Article from ciechanow.ski on GPS from 2022 resurfaces on Hacker News, garnering attention and discussion.\n- Comments discuss technical aspects of GPS, such as the use of gold codes and relativistic effects, and offer additional resources for further reading.\n- Some comments are off-topic, with users commenting on the design of the article or their personal difficulties reading it."
  },
  {
    "id": 36173020,
    "timestamp": 1685758226,
    "title": "The NixOS Foundation's Call to Action: S3 Costs Require Community Support",
    "url": "https://discourse.nixos.org/t/the-nixos-foundations-call-to-action-s3-costs-require-community-support/28672",
    "hn_url": "http://news.ycombinator.com/item?id=36173020",
    "content": "domenkozarGreat contributor1dHi all,TL;DR - Kicking off an effort to secure long-term funding for our S3 costs and exploring alternatives. This comes after multiple years where Logicblox has been graciously sponsoring the S3 costs for Nix! An enormous thank you to them.The LogicBlox team (which has since been acquired by Infor) has been providing significant support to the Nix ecosystem by sponsoring our S3 buckets. They have asked to transfer the ownership of the costs and give us a good heads up (timeline discussed below). We are now working on transferring the expenses/ownership to the foundation.DetailsEstimated Monthly Costs - ~$9000 / month for hosting cache.nixos.org 178, see the breakdown for more details 797.Deadline - Aiming for July 1stInitial Potential Solution BrainstormWe\u2019re exploring different solutions for this, including getting direct sponsoring from a hosting provider (AWS or Cloudfare) and having the foundation paying for the S3 buckets through community sponsorship.So far the most likely solutions are:Migrating the buckets to Cloudflare R2 132, and using the generous OSS sponsorship offer they recently announced 265. That would incur a fixed cost of around $32k for the migration.Keeping the bucket as it is and paying it in full ($9k/month at the moment, steadily rising as the cache keeps growing)Keeping the budget, but garbage-collecting it. We could shrink probably shrink the costs a lot (realistically up to 70%), but there are heavy tradeoffs at play here since the data in the cache is sometimes very valuable.Call to Action & Next StepsFundraising: We will start a general fundraiser for the cache, as every option currently on the table would require significant costs.Creating a NixOS community task force to investigate these possibilities further: If you are interested in joining, please comment or reach out. - https://matrix.to/#/#foundation:nixos.org 68General request to everyone who has thoughts on this topic to join the discussion/brainstorming: https://matrix.to/#/#foundation:nixos.org 68Are there any other providers we can explore?We will follow up with Cloudflare/AWS to receive more information and explore any other options/opportunities.Domen, Ron, Jonas, Eelco, Th\u00e9ophane4 Replies39created1dlast reply38m73replies16.7kviews42users434likes44linksFrequent Posters1244333Popular Links797 NixOS Foundation's Financial Summary: A Transparent Look into 2022 nixos.org265 Launching our new Open Source Software Sponsorships Program cloudflare.com179 cache.nixos.org is up nixos.org132 Cloudflare R2 | Zero Egress Distributed Object Storage | Cloudflare cloudflare.com105 Storj - Make the world your data center storj.ioThere are 73 replies with an estimated read time of 29 minutes.Summarize This Topic",
    "summary": "- The LogicBlox team, which has been sponsoring Nix's S3 buckets, is transferring ownership and expenses to the NixOS Foundation.\n- The estimated monthly cost for hosting is around $9000 with a deadline of July 1st.\n- The NixOS Foundation is exploring different solutions, including migrating buckets to Cloudflare R2, paying in full, or garbage-collecting it. They will also start fundraising and create a task force to investigate further options.",
    "hn_title": "The NixOS Foundation\u2019s Call to Action: S3 Costs Require Community Support",
    "original_title": "The NixOS Foundation\u2019s Call to Action: S3 Costs Require Community Support",
    "score": 294,
    "hn_content": "The NixOS Foundation has issued a 'Call to Action' for community support due to high S3 storage costs. A post on Hacker News raised concerns about the high costs and potential risks of using cloud services, arguing that more people should consider self-hosting instead of relying on cloud storage. While some commenters agreed that it was possible to handle petabyte storage and traffic globally through self-hosting solutions, others felt it required significant expertise and time to do it well and maintain it consistently. The discussion also involved debates around the marketing strategies of cloud providers and the pros and cons of using cloud services versus self-hosting for businesses. The post highlights the importance for tech communities to focus on sustainable and cost-effective solutions for data storage and management.Developers of the open-source operating system NixOS have opted for an experimental approach to how its users receive software updates. Mirroring and distributing the roughly 500 terabytes required to handle cache data and updated software packages is a major challenge, but the development team have found co-location and self-hosted storage solutions to be a cost-effective alternative to using a commercial AWS S3 server. Using Minio software, developers are looking for volunteers to act as mirrors on their own home networks or other locations to help them store the huge amounts of data required. Paid-for hosting schemes with small, distributed servers are also being employed. Respondents to the idea have suggested such raid mirrors, CDNs, and mesh networking solutions as practical alternatives.NixOS Foundation relied on donated cloud services, including Fastly for CDN and S3 for storage, to host their open-source project, but with the donor withdrawing support, they are left to address the issue of 425 TB of data storage and 1.5 PB of monthly data transfer. Some users suggest migrating to Hetzner or designing a distributed CDN, but the lack of a detailed plan to transition to the new system and the complexity of managing multi-petabyte storage systems present a challenge. Telehouse Docklands in London charges high colocation fees, contrary to popular belief, and LINX is a peering exchange, not an internet backbone. Most colocation facilities competing on price have poor connectivity and should be avoided. Users rely on hardware support and advise sending quote requests to providers such as Fujitsu, IBM, and HP, with an emphasis on IOPS and file access to determine the right solution. Building a cheaper system from scratch or designing a solution that fits specific usage patterns is also an option.There is a debate about the efficiency and sustainability of OpenBSD's hosting practices. The conversation includes discussion around the usefulness of hardware heterogeneity, bug hunting, and the potential for cost savings by using the cloud. Storj, a decentralized storage service, is also discussed, with some critiquing the concept of being paid in cryptocurrency tokens, and the sustainability of its early subsidy. Some suggest using a distributed CDN instead of cloud services, and discuss the potential costs and considerations of hosting one's own storage server. Finally, there is conversation around egress fees charged by cloud providers like AWS, and potential investigations by regulators due to anti-competitive practices.The Tech Times discussed the high egress fees charged by AWS and called them \"anti-competitive pricing\", although some commenters disagreed. The article explains the implications of NixOS's need for a massive binary cache to guarantee reproducibility of builds, and how LogicBlox's sponsorship helped maintain it. The binary cache allows users to download pre-built packages rather than rebuilding all packages on every update, and the article outlines the benefits of pinning all dependencies. The article also addresses the question of why NixOS needs to store such a significant amount of data and what makes it valuable to the research community.The NixOS foundation is facing a storage crisis due to the huge amounts of cache data stored in AWS S3, with estimates suggesting it would cost $32k to migrate the data to another platform. The cache is the result of many years of builds, and comprises both compressed and uncompressed versions of packages, alongside duplicated data. This has led to a discussion of potential options to reduce storage costs, including looking at compression ratios and using IPFS, GNUnet, Tahoe-LAFS, or a decentralized mirror list. It has been suggested that NixOS's existing hydra build farm could be used to rebuild the cache somewhere else, though this could require the building of a new cluster of dedicated build machines.Users offer storage solutions for a company facing issues with historic data caches.\nHetzner storage boxes offer a cost-effective solution but with limitations on concurrent connections.\nMigrating data to Cloudflare R2 52 could require a fixed cost of around $32k for migration due to egress from S3.\nUsers suggest leaving historical data in S3 and avoiding egress costs.\nWasabi offers cheap storage options with limitations on egress amounts.\nAWS provides OSS sponsorship, and some open-source usage of their infrastructure is possible.\nUsers suggest that the EU take steps to reduce lock-in by mandating cloud portability.",
    "hn_summary": "- The NixOS Foundation is calling for community support due to high S3 storage costs, and some suggest self-hosting as an alternative to cloud storage.\n- NixOS developers are using co-location and self-hosted storage solutions to handle petabyte storage, and are seeking volunteers to act as mirrors on their own home networks.\n- There is a debate around the efficiency and sustainability of hosting practices, suggestions for cost-effective storage solutions include hardware support, designing a specific solution, and using distributed CDNs. Cloud providers' egress fees and anti-competitive pricing are also discussed, and some users suggest AWS OSS sponsorship and EU-mandated cloud portability to reduce lock-in."
  },
  {
    "id": 36173441,
    "timestamp": 1685763213,
    "title": "Decoding small QR codes by hand (2012)",
    "url": "https://blog.qartis.com/decoding-small-qr-codes-by-hand/",
    "hn_url": "http://news.ycombinator.com/item?id=36173441",
    "content": "Decoding small QR codes by hand2012-04-21It's not hard to decode QR codes with a pen and paper. For this guide I'm going to grab a random QR code from google images and show the process of decoding it by hand. QR codes contain a lot of error correction information and they can survive a lot of errors, but that's a lot harder to do using just a pen and paper (and 99% of the QR codes you encounter don't have any missing bits, so it's rarely necessary). So I'll highlight where the error correction information is stored, but I won't explain it in this guide.The picture I found is from http://mikejcaruso.blogspot.ca/2011/04/qr-code-tattoos.htmlBefore we begin we should rotate it to the proper orientation. QR codes always have 3 timing patterns (big black squares) in all the corners except for the bottom-right. So we need to rotate our picture 90 degrees counterclockwise:The first thing we should learn is what QR code version we're looking at. The version basically just represents the physical size of the QR code. Count the number of pixels (or modules) across the QR code, subtract 17, and divide by 4. For example, our tattoo QR code is 25 modules wide, and (25-17)/4 = 2, which means this is a version 2 QR code. Very big QR codes (versions 7-40) have a few extra features, but most consumer QR codes are fairly small and simple, so you don't need to worry about that.Next, we will figure out our QR code's format marker. Every QR code stores two identical copies of the format marker, but we only need one of them. The format marker is 15 bits long: 5 bits of format information, and 10 bits for error correction. The first 5 bits of the format marker hold the error correction level (2 bits) and the data mask (3 bits). These 5 bits are found here:So in our case the format information is 01100. However this number has been XOR'ed with 10101 before being written into the QR code. So we must flip bits 1, 3 and 5. After flipping the bits, we get a format information string of 01100^10101 = 11001. The first two bits of this value are the error correction level (the amount of error correction data included in the QR code). Again, we can ignore this. The last 3 bits of the format string are 001, and this is the most important piece of information. This means the body of the QR code has been masked against the mask number 001. Here is a table of all the possible mask numbers and their appearance:Here's where you need the pen and paper. The reason QR codes are masked in the first place is that sometimes particular combinations of data bytes produce QR codes with certain undesirable features (like big empty blocks in the middle). These undesirable features confuse the QR code reader, so the data is masked against a value in order to make the code easier to process when it's scanned by a QR code reader. The computer then unmasks the original data bytes using the same process, and retrieves the data.You can imagine the masking process as essentially covering the surface of the QR code in one of the patterns seen above, starting from the top left corner. In our case we have a mask reference number 001, which means all of the odd-numbered rows are black. Once we've tiled the surface of our original QR code using the mask pattern, then every black pixel in the mask means we need to invert the corresponding bit in the original QR code. So in our case, we need to (in our mind, or using the pen and paper) invert all of the bits on odd-numbered rows. Note that we only mask the data pixels, and not the timing patterns or the format marker (otherwise we wouldn't know how to unmask it to get the mask reference number!). The data areas are the yellow areas in this picture:I've highlighted the data areas of the tattoo QR code below:Note that there's a little island in the middle of the data area that we must work around. That's called an alignment pattern, and whenever you see one in the data just skip past it to read the data bytes.From now on we need to always remember the mask pattern above, and whenever we read bits from the data section we need to account for the mask pattern, and flip any bits that would be masked off by it (in our case, that's every odd row).The data section consists of [header][data] chunks. Technically QR codes are allowed to have several of these chunks, but most QR codes just have one big chunk that holds all the data, so it won't matter. The header has an encoding type and a length (the number of data bytes). The encoding type is always 4 bits, but the length is stored in 8-10 bits depending on the encoding type. Here's the encoding type of our tattoo:But remember, every odd row needs to have its bits inverted. To help us remember, I'll use green to highlight every cell that should be inverted when we read it:Now, the encoding type is stored as the bottom-right 4 bits, starting from the bottom right and working left and right in a zig-zag motion.So in our case, the tattoo itself has the bits 1000. However the bottom row is masked, so we invert the first two bits: 0100. This means that our QR code's encoding type is 0100. Here's the table of encoding types:0001 Numeric0010 Alphanumeric0100 8-bit ByteThe other encoding types are rarely used in consumer QR codes. They're used for encoding japanese characters, custom charsets and spreading a message across several QR codes in series. For our purposes these 3 encodings will be enough.So that means that our QR code uses 8-bit byte encoding. The next piece of information is the length field, or the number of characters (clusters of bits) that are in the message. Like I said, the length field changes size depending on the encoding type. Here's the number of bits in the length field, for each encoding type:Numeric (10 bits)Alphanumeric (9 bits)8-bit Byte (8 bits)Since we're using 8-bit byte mode, our length field is 8 bits long. We read the next 8 bits in a vertical zig-zag motion, like this:So the tattoo itself contains the bits 11011100 (reading from bottom to top). However we need to mask two of these rows, so the actual length field has the value 00010000. That's 16 in decimal, which means this QR code has a message that is sixteen 8-bit bytes long. After the length field, the bytes themselves are stored, one after another, MSB first. We continue climbing in a vertical zig-zag motion until we hit the top, and then we curl over and continue downwards as seen in this picture:So the first byte would be 10000110 (masked), which is 01001101 (unmasked). That corresponds to ASCII character 'M'. The next byte would be 10101101 (masked), which is 01100001 (unmasked). That corresponds to ASCII character 'a'. So far we've decoded \"Ma\".Continuing up and around the corner: 10100000 (masked), or 01100011 (unmasked). That's ASCII 'c'. Then it's 'i'.By continuing in this way, we can decode the full message: Maci Clare Peltz.Commentsheavyw8tSo WTF is Maci Clare Peltz supposed to be?qartisMy guess is someone's girlfriend's name, but I'm not sure.Raymond DecellesProbably the tattoo owner's girlfriend, wife, mother, daughter, whatever.Lukehow do we know that it XORed with 10101?qartisISO 18004:2006, section 6.9.1 paragraph 4 says:The 15-bit error corrected format information shall then be XORed with the Mask Pattern 101010000010010, in order to ensure that no combination of Error Correction Level and data mask pattern will result in an all-zero data string.where the first 5 bits of the Mask Pattern are applied to the 5 data bits of the format information.Les PotterSo how do you zigzag around the alignment thingy? Also, the red box at the top of the QR is only 7 bits wide. Can you explain why?Les PotterYour paragraph on the format code says it's 14 bits long, but then below the spec is quoted as saying it 15 bits long. Can you explain?qartisWhoops, that was a typo. You're correct, the format code is 15 bits long.qartisMy previous pictures had a border line incorrectly drawn, making it look like there were only 7 bits along the top edge. I have redone the pictures to hopefully make it a bit more clear. As for zig-zagging around the alignment pattern, the easiest way to think about it is that you simply skip past the bits that are occupied by the alignment pattern. Here's an image from Wikipedia that shows several examples of zig-zags passing near alignment patterns (image credit Walter Tuvell, wtuvell)Martie AndersonI'm stuck on deciphering this code. Any takers? Thanks, Martie (sorry it's so faint.)qartisHi Martie, that code isn't a QR code, it's a Data Matrix code. It represents the text string: \"358166070831158\". I have attached a clearer version here for you to attempt to decode (see the Data Matrix wikipedia article: https://en.wikipedia.org/wiki/Data_Matrix). If there is enough interest I can create a blog post about decoding other 2D barcode formats by hand.Martie AndersonAnything you can do would be so helpful. The code was adhered to the back of my phone. Could it be a new format of GPS tracking? Is thishe what is put on produce to track sales? Thanks for all of your help.\u5218\u6587\u666fIf there are some errors in the data code, I wonder how you can decode it?Irihttps://uploads.disquscdn.com/images/5c239e6cf4e9e5ded58cac253f360a820253225c446f7898317aeb3dbe9b3811.jpg I am stuck decoding a qr code.... I have tried several ways. It was sent a long time ago so maybe it has expired. Any takers?http://elpapelillo.wordpress.comFelfaIt's a base64 encoded text. Literally, this QR code says: ENC;(...):Lz0YbziKr+6AIUiR9l8jwISyBWES4ah/xVBBIMV4eTs=QR codes never expire.IriThank you Felfa! I got the same code from a QR decoder... I have no idea what this code means. Could it be a further encrypted message or is it a line of code you think?PointyOintmentGPS? It's literally just a label. It was probably used in the factory to track parts and completed phones moving through the assembly and packaging processes.kamrom dechuI scanned the tattoo QR code into Pokemon Moon. It gave me a Taillow.Ninan NanerMay you teach me to decode qr code as show below,please?I try several time as follow your solution to decode but I still can't get the answer \"A1\".Thank you very much. I hope you will see my question and answer me in early.https://uploads.disquscdn.com/images/51d2418d871d509ef1ee0076aa38b94dc13ea44b3b868f7ec112d3c4939d2de7.jpgDavid KonsumerIt's binary data, base64 encoded. You can get the binary by pasting Lz0YbziKr+6AIUiR9l8jwISyBWES4ah/xVBBIMV4eTs= here: http://www.motobit.com/util/base64/decoderNinan NanerI got it. Thank you.Edmund FrenchHi there,I'm in the process of decoding a QR code, and using this guide as..well, a guide, but one thing I can't get my head around - the tattoo is clearly 25x25, but the pictures shown which aren't the tattoo are 21x21. I don't have any programming experience or anything similar, so I suspect I'm missing something obvious.. I've gone right up to the 'divide into 8 bit blocks' stage, but don't know how to section it up before I decode, because the sizes don't match.Any help greatly appreciated.",
    "summary": "- This article provides a guide on how to manually decode a small QR code using pen and paper. \n- The guide explains how to determine the QR code version and format marker and how to account for error correction information. \n- It also explains how to decode the message within the QR code by accounting for the mask pattern and reading the length and byte fields.",
    "hn_title": "Decoding small QR codes by hand (2012)",
    "original_title": "Decoding small QR codes by hand (2012)",
    "score": 293,
    "hn_content": "The article discusses hand-decoding QR codes. The comment section discusses various issues related to QR codes, including their error correction, use cases, privacy concerns, and how to build a QR code reader from scratch. Some of the readers provide feedback on their experience with QR code scanning apps and suggest alternatives. The commenters also offer tips on how to improve the accuracy of OCR on QR codes.The post discusses how to detect and decode QR codes from noisy images and video streams, and the challenges involved. There are standard algorithms and approaches applied in the electronics and signal processing subject area. QR code alignment markers are designed to be easy to detect, regardless of angle or partial obstruction. There is no detailed spec for QR code decoders, building a fast and robust QR code decoder is hard and valuable. There are several techniques and tips to consider, such as image processing, perspective correction, and pixel patterns. Decoding a QR code by hand is a feat similar to solving a Rubik\u2019s cube. It is unlikely to need to decode by hand and is an excellent way to teach implementors of automated QR code readers and writers.",
    "hn_summary": "- The article discusses hand-decoding QR codes, and the comment section delves into various issues related to QR codes, including error correction, use cases, and privacy concerns.\n- Commenters provide feedback on QR code scanning apps and suggest alternatives, as well as offering tips on improving OCR accuracy for QR codes.\n- QR code decoding from noisy images and video streams poses significant challenges, and while there are standard algorithms and approaches, building a fast and robust decoder remains a valuable and difficult task, with techniques like image processing and perspective correction to consider. Hand decoding QR codes is similar to solving a Rubik's cube and serves as a way to teach implementors of automated QR code readers and writers."
  },
  {
    "id": 36179853,
    "timestamp": 1685821281,
    "title": "Don't let Reddit kill 3rd party apps",
    "url": "https://old.reddit.com/r/Save3rdPartyApps/comments/13yh0jf/dont_let_reddit_kill_3rd_party_apps/",
    "hn_url": "http://news.ycombinator.com/item?id=36179853",
    "content": "- Reddit's recent policy change will raise the price to make calls to their API, effectively killing many beloved third-party mobile apps\n- This includes apps like Apollo, Reddit is Fun, Narwhal, and BaconReader, which offer quality-of-life features not seen in the official mobile app\n- This change also affects other ways of customizing Reddit, such as Reddit Enhancement Suite and the use of the old.reddit.com desktop interface\n- Many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free\n- On June 12th, many subreddits will be going dark to protest this policy, and some will go away permanently unless the issue is adequately addressed\n- Redditors can complain by messaging the mods of /r/reddit.com or submitting a support request, as well as spreading the word and boycotting Reddit's competition on June 12th and 13th\n- Many users are frustrated with the official Reddit app's inferior functionality and have pledged to stop using Reddit altogether if third-party apps are killed.",
    "summary": "- Reddit's new policy will make it more expensive to access their API, causing third-party mobile apps to shut down.\n- Beloved apps like Apollo, Reddit is Fun, Narwhal, and BaconReader will be affected, along with customization options like Reddit Enhancement Suite and old.reddit.com. \n- This decision has sparked backlash from subreddit moderators and users who rely on these apps for community management and better features than the official app. Some subreddits will go dark, and users plan to boycott Reddit's competition on June 12th and 13th.",
    "hn_title": "Don't let Reddit kill 3rd party apps",
    "original_title": "Don't let Reddit kill 3rd party apps",
    "score": 290,
    "hn_content": "A post on Hacker News discusses Reddit's user-hostile interview process and aggressive monetization tactics. The company's leadership is allegedly pressuring the company to boost advertiser numbers at the cost of user experience. Users point out that Reddit's mobile app pushes users to install it and that the quality of signals on the platform is lower than other social media platforms. Image hosting site Imgur also comes under criticism for pushing users to view content through their app and questionable business practices. The need for third-party apps to ensure a better user experience is highlighted. However, some users note that privacy concerns and the need for revenue may drive companies to make user-hostile decisions despite losing traffic.Users are expressing frustration with recent changes at Reddit which make it difficult to use the site in a mobile browser and restrict access to API features, which they say will take away from the community aspect of Reddit. Some users also criticize the platform's development of new, \"worse\" client applications in an attempt to push people away from third-party apps, and the principles of bait-and-switch tactics. However, others think Reddit ought to be able to charge for operational API access and suggests that this could be a fair alternative to keep the platform profitable. Concerns are also raised about the platform's policies on user-generated content and monetization tactics. Several users propose alternatives to Reddit in light of these changes.Reddit is making changes to its API that may impact third-party apps, leading to criticism and concerns about the platform's future.\n\nThe cost of Reddit's API access charges around 10 times more than the revenue per user they would expect if the users accessed Reddit via the web or official app.\n\nReddit is believed to be wanting to focus on ad revenue to increase company revenue ahead of its initial public offering.\n\nThis has caused some discussion about the future of Reddit, with some suggesting it could lose the hobby subs or become entirely commercial.Reddit users are frustrated with the lack of improvement on popular third-party Reddit app, Apollo, despite recent donations to developer. Some users opt to switch to web or official app, while others suggest creating a Reddit clone. The debate on whether third-party apps should be allowed unfettered access to Reddit API has also been reignited. Several subreddits have gone private or plan to do so due to this issue. Reddit recently introduced new pricing for API access, which some believe could lead to the company gradually phasing out third-party apps. Mainstream social media companies generally do not allow third-party clients in an unfettered capacity.- Developers of third-party Reddit apps are protesting changes to the platform's API that they argue will stifle innovation and make their apps unsustainable\n- The changes will impact apps that allow users to browse Reddit without advertising, paywalls or tracking\n- The community of developers staging the protest say that they are willing to coordinate a strike and stop working on their apps until Reddit re-evaluates the changes and considers other options\n- Reddit is struggling to generate profits as an advertising platform and is currently attempting to salvage its IPO and woo investors\n- Critics accuse Reddit of undervaluing the goodwill of its users, and that these changes will ultimately make the platform less valuable in the long term if moderators and users lose trust in it\n- There are concerns that the changes may affect blind people and those who use screen readers, potentially creating a basis for legal action.",
    "hn_summary": "- Reddit's aggressive monetization tactics and API changes have sparked criticism from users and third-party app developers\n- Users are frustrated with the quality of signals on the platform and push for installing the official mobile app\n- Concerns arise about privacy, user-hostile decisions, and potential monopoly with Reddit's recent pricing changes to API access"
  },
  {
    "id": 36178265,
    "timestamp": 1685811399,
    "title": "Don't store cash in Venmo & PayPal, US regulator warns",
    "url": "https://www.cnn.com/2023/06/02/investing/payment-apps-safety/index.html",
    "hn_url": "http://news.ycombinator.com/item?id=36178265",
    "content": "What is a bank run?01:59Experts warn AI could pose 'extinction' risk for humanity02:06CNN tried an AI flirt app. It was shockingly pervy03:1901:55New YorkCNN \u2014 Payment apps like PayPal and Venmo might be convenient, but they\u2019re not banks \u2014 and a federal financial services watchdog is worried that too many consumers are treating them as such.Some consumers are using services like PayPal, Venmo, Cash App and Apple Pay for direct deposit of paychecks, or simply storing lots of cash in them. But the Consumer Financial Protection Bureau wants people to know they don\u2019t have the same protections as a bank or credit union.CFPB Director Rohit Chopra warned in a Thursday statement that payment services like PayPal, Venmo, Cash App and Apple Pay \u201care increasingly used as substitutes for a traditional bank or credit union account but lack the same protections to ensure that funds are safe.\u201dMore than three-quarters of US adults have used at least one payment app, the agency said.The watchdog released the comments in the wake of high profile bank failures like Silicon Valley Bank and Signature Bank. Their customers were made whole because account holders at federally insured financial institutions are guaranteed to get back up to $250,000 per account if the bank fails. (In the case of those two banks, the FDIC even abolished the limit, covering all deposits.)Payment apps, however, are not federally insured on the institution level. If one of those companies were to go under, then, customers could lose their funds.Billions of consumer dollars at risk, agency saysThere are billions of dollars at risk for consumers as a result of payment apps encouraging customers to store funds rather than just make transactions, said the CFPB in its report. These apps are also not immune to the same type of panic-based bank run that closed down Silicon Valley Bank and others recently, the agency added.PayPal Holdings (PYPL), which owns both PayPal and Venmo, did not reply to a request for comment Friday. Neither did rival Block (SQ), which owns Cash App as well as payment system Square.But industry trade group the Financial Technology Association, which represents both firms, defended the safety of the funds.\u201cTens of millions of American consumers and small businesses rely on payment apps to better spend, manage, and send their money. These accounts are safe and transparent,\u201d the group said in the statement. \u201cFTA members provide clear and easy-to-understand terms in all their products and prioritize consumer protection every step of the way.\u201dBeyond FDIC insurance: How protected is your money outside of banks?Some money held in certain types of payment app accounts \u2014 PayPal Savings, for example \u2014 are indeed deposited in FDIC-member banks and thus would be protected. But much of the funds are held by the services themselves, without federal insurance.The CFPB did not provide an estimate of how much money is held in payment apps, although it did say that transaction volume across all US service providers was estimated at approximately $893 billion across all of 2022 and may reach nearly $1.6 trillion by 2027.The agency also noted the payment apps make money by investing funds their customers store on the apps, similar to how banks invest their customers deposits. But unlike insured bank deposits, those stored funds would be at risk if the payment apps\u2019 investments lose value \u2014 which itself could spark a run on the the deposits, the CFPB said.The agency also made reference to last year\u2019s failure of crypto currency platform FTX, which left customers unable to access hundreds of millions of dollars worth of their assets, leaving them to become creditors in the bankruptcy cases.\u201cIf a nonbank payment app was to go bankrupt as a result of these risks, customers may not be the only creditors with claims on the company\u2019s remaining assets,\u201d said the CFPB. \u201cEven if consumers do not ultimately lose any funds, they may face significant delays in accessing their funds while the bankruptcy process unfolds.\u201d",
    "summary": "- Payment apps like PayPal and Venmo lack the same protections as a traditional bank or credit union account and are not federally insured on the institution level.\n- There are billions of dollars at risk for consumers as payment apps encourage customers to store funds rather than just make transactions, and these apps are not immune to bank runs.\n- Some money held in payment app accounts, such as PayPal Savings, are deposited in FDIC-member banks and thus, would be protected, but much of the funds are held by the services themselves without federal insurance, which could be at risk if the payment apps' investments lose value.",
    "hn_title": "Don\u2019t store cash in Venmo and PayPal, US regulator warns",
    "original_title": "Don\u2019t store cash in Venmo and PayPal, US regulator warns",
    "score": 279,
    "hn_content": "The US regulator has issued a warning against keeping unsecured funds in Venmo and PayPal accounts. The regulator's advisory explains that these accounts are not protected in the same way that bank accounts are, and the money that is exchanged through Venmo and PayPal is effectively converted to \"PayPal or Venmo bucks\" and not subject to banking regulations. PayPal transferred $143bn through its platform during Q2 2020, and its users \"spend 39% more on average than customers who don\u2019t use the digital wallet service.\" Users frequently transfer funds through the apps to pay for services that are small or irregularly provided. Critics argue that the government\u00a0should regulate the services that hold\u00a0these funds, rather than simply issuing warnings.The Consumer Financial Protection Bureau (CFPB) has issued a warning to American citizens about using payment apps like Venmo and PayPal as they are not FDIC-insured and could fail without government support. In response, some users called for more government regulation while others argued against it. The article also highlights instances of PayPal terminating accounts without warning and plans to fine users for \"misinformation.\" Additionally, European customers of PayPal are protected as the EU branch is classified as a bank. Overall, the post raises questions about government intervention, financial stability, and user protection.Consumers are warning against using PayPal due to its aggressive fraud detection that often results in false positives which can lock users out of their accounts; banks are more regulated than PayPal and have a banking regulator to complain to; the Consumer Financial Protection Bureau advises that funds in payment apps are at greater risk compared to accounts with deposit insurance; in Europe, PayPal is a bank which insures deposits, and SEPA allows for instant free EUR transactions between all European banks; people are turning to easy to use digital payments as there is a real need for them but the regulation is lacking; there is no perfect payment system because risk is inherent in any transaction; crypto is not a solution to this problem either as cryptocurrency exchanges can suffer from similar risks as traditional payment systems.The Consumer Financial Protection Bureau warns users about depositing cash in payment apps like PayPal and Venmo because users do not have the same protections as traditional banks. The apps are only required to have minimal insurance and sometimes hold onto the funds, making it difficult to access during financial emergencies. Additionally, some customers complain about\u00a0PayPal's \"buyer-biased\" attitude and its seemingly arbitrary policies toward holding customer payments. It is legal for Venmo and PayPal to push the responsibility to customers and make a profit, but the practices also come at a risk. Users can minimize their risk by only keeping funds they are willing to lose to a random event.\u00a0 In India, the UPI system aims to eliminate the need for intermediaries.\u00a0\u00a0\u00a0",
    "hn_summary": "- The US regulator warns against keeping unsecured funds in Venmo and PayPal accounts, as the money is not subject to banking regulations.\n- Some users call for more government regulation, while others argue against it, raising questions about financial stability and user protection.\n- PayPal has aggressive fraud detection resulting in false positives, and termination of accounts without warning, but is classified as a bank in Europe and insures deposits."
  },
  {
    "id": 36177762,
    "timestamp": 1685808256,
    "title": "This site is no longer solar powered for now",
    "url": "https://www.andrewjvpowell.com/articles/this-site-is-no-longer-solar-powered-for-now/",
    "hn_url": "http://news.ycombinator.com/item?id=36177762",
    "content": "AJVP Home About The Linux RainThis Site Is No Longer Solar Powered (for now...)28 January 2023Been a while since I wrote anything on here and the reasoning actually has little to do with the subject matter: I've just been busy/slack/distracted, whatever you care to throw a dart at, it will hit a target.Anyway, I made this post back in September 2021. All was trucking along fine until just a few months ago from the time of this writing, when one day I realised I no longer had the Raspberry Pi responding to pings and well, no internet access either.Upon investigation, no this was no power loss or lack of sun... the little Netgear AC800s modem had blown up. No, not figuratively, LITERALLY.Images speak for themselves...So yes, lesson learned, lithium-ion batteries do indeed go boom sometimes. I was actually aware this could happen and technically shouldn't have left the battery in the device while it was hooked up to power constantly... but the thing is, the device was never stable unless it was plugged into both USB power and had it's battery inserted. External power was never quite enough, with enough activity the thing was liable to randomly reboot.Anyway, so that's that. Remarkably, only the modem and a few surrounding cables were destroyed. The solar charge controller and the Raspberry Pi were, remarkably, unharmed, if not carrying a bit of spare black soot on their surfaces. Where to from here? Well, my internet situation is quite different now. I have Starlink and no longer the old satellite broadband now, as a primary internet connection, so the Optus 4G connection was becoming a bit superfluous anyway (except for when the power goes out at home, obviously). But with Optus' data breach scandal and what not, I wasn't going to be running back to them either.So, for now, I have no solar powered internet connection but if something cheap and cheerful comes along I would be tempted to set it up again (this time a mini modem/router that doesn't require a constantly inserted battery to function properly).How is this site running right now, you might ask? Easy, I took the Raspberry Pi back inside my home and hooked it up to the internet there. The RPi does need a new SD card though, as it's been failing for a while now, so I will likely shift this site to my Vultr VPS, but that's the beauty of a lightweight static website - can move it around willy nilly, no problem at all!Copyright\u00a9 2015-2023 Andrew JV Powell | Contact: andyjvp [at] tutamail.com | Built with mkws",
    "summary": "- The author's solar-powered internet connection was disrupted due to a blown-up modem that had a lithium-ion battery in it, which was never supposed to be left in while constantly plugged into a power source.\n- The author now uses Starlink as their primary internet connection, and they would consider setting up a solar-powered internet connection again if they find a cheap and reliable modem/router that doesn't require a constantly inserted battery to function properly.\n- The author moved their website to their Vultr VPS and will likely shift it to a new SD card as the current one is failing.",
    "hn_title": "This site is no longer solar powered for now",
    "original_title": "This site is no longer solar powered for now",
    "score": 279,
    "hn_content": "A post on Hacker News highlights the fun and challenges of self-hosting servers, considering the difficulties and the level of expertise required. Some commenters agree that self-hosting is a great learning experience, while others argue that it's not worth the time and effort and that it's better to use external tools or services. The post triggers an interesting discussion that touches on different aspects of self-hosting, including the costs, the management's perception, the reliability, and the quality of software and AI tools supporting self-hosting.The comments section contains a discussion about experiences with old computer systems and internet speeds of the past. Some users discuss difficulties with hosting servers and accessing the internet in rural areas with slow speeds. Others share tips for extending the battery life of hotspots and using industrial SD cards for increased reliability. One user suggests looking into USB modems for affordable connectivity options. Several commenters share memories of various technologies from the past, such as PHP-Nuke and LiPo pouch batteries.An online discussion highlights the dangers of lithium-ion batteries, with anecdotes of explosions and fires caused by faulty batteries or incorrect usage. Suggestions for safer battery options include lithium iron phosphate or lead-acid batteries. The discussion also includes tips for storing and charging batteries safely, along with warnings about the unreliable nature of SD cards. Concerns are raised about the importance of proper design and regulation to prevent battery-related accidents. Despite the risks, some users advocate for the use of lithium-ion batteries in renewable energy storage, while others suggest alternative solutions like super capacitors.A discussion on the use of lithium-ion batteries touches on topics such as their safety, differences between industrial and consumer-grade battery packaging, battery chemistry, and battery management practices. The conversation highlights the prevalence of lithium-ion batteries in many devices, including small electronics, e-bikes, cameras, and even hearing aids. Battery safety concerns are also raised, with mention of instances where batteries have failed and caused damage. The conversation concludes with participants discussing fire-retardant battery boxes as a potential solution to safe disposal and storage.",
    "hn_summary": "- The post on Hacker News discusses the pros and cons of self-hosting servers, with some commenters suggesting it's a great learning experience, and others saying it's not worth the effort.\n- The comments section includes discussions on past technologies, accessing the internet in rural areas, and battery safety, with tips on extending battery life and using safer battery options.\n- Battery safety concerns are raised, along with the prevalence of lithium-ion batteries in many devices, and suggestions for fire-retardant battery boxes as a potential solution for safe disposal and storage."
  },
  {
    "id": 36179850,
    "timestamp": 1685821277,
    "title": "Still Love Telnet",
    "url": "https://bash-prompt.net/guides/telnet/",
    "hn_url": "http://news.ycombinator.com/item?id=36179850",
    "content": "Bash Prompt Guides whoamiWhy You Should Still Love TelnetTelnet, the protocol and the command line tool, were how system administrators used to log into remote servers. However, due to the fact that there is no encryption all communication, including passwords, are sent in plaintext meant that Telnet was abandoned in favour of SSH almost as soon as SSH was created.For the purposes of logging into a remote server, you should never, and probably have never considered it. This does not mean that the telnet command is not a very useful tool when used for debugging remote connection problems.In this guide, we will explore using telnet to answer the all too common question, \u201cWhy can\u2019t I ### connect\u203d\u201d.This frustrated question is usually encountered after installing a application server like a web server, an email server, an ssh server, a Samba server etc, and for some reason, the client won\u2019t connect to the server.telnet isn\u2019t going to solve your problem but it will, very quickly, narrow down where you need to start looking to fix your problem.telnet is a very simple command to use for debugging network related issues and has the syntax:telnet <hostname or IP> <port>CopyBecause telnet will initially simply establish a connection to the port without sending any data it can be used with almost any protocol including encrypted protocols.There are four main errors that you will encounter when trying to connect to a problem server. We will look at all four, explore what they mean and look at how you should fix them.For this guide we will assume that we have just installed a Samba server at samba.example.com and we can\u2019t get a local client to connect to the server.Error 1 - The connection that hangs foreverFirst, we need to attempt to connect to the Samba server with telnet. This is done with the following command (Samba listens on port 445):telnet samba.example.com 445CopySometimes, the connection will get to this point stop and hang indefinitely:telnet samba.example.com 445Trying 172.31.25.31...CopyThis means that telnet has not received any response to its request to establish a connection. This can happen for two reasons:There is a router down between you and the server.There is a firewall dropping your request.In order to rule out 1. run a quick mtr samba.example.com to the server. If the server is accessible then it\u2019s a firewall (note: it\u2019s almost always a firewall).Firstly, check if there are any firewall rules on the server itself with the following command iptables -L -v -n, if there are none then you will get the following output:iptables -L -v -nChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target   prot opt in   out   source        destinationChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target   prot opt in   out   source        destinationChain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target   prot opt in   out   source        destinationCopyIf you see anything else then this is likely the problem. In order to check, stop iptables for a moment and run telnet samba.example.com 445 again and see if you can connect. If you still can\u2019t connect see if your provider and/or office has a firewall in place that is blocking you.Error 2 - DNS problemsA DNS issue will occur if the hostname you are using does not resolve to an IP address. The error that you will see is as follows:telnet samba.example.com 445Server lookup failure: samba.example.com:445, Name or service not knownCopyThe first step here is to substitute the IP address of the server for the hostname. If you can connect to the IP but not the hostname then the problem is the hostname.This can happen for many reasons (I have seen all of the following):Is the domain registered? Use whois to find out if it is.Is the domain expired? Use whois to find out if it is.Are you using the correct hostname? Use dig or host to ensure that the hostname you are using resolves to the correct IP.Is your A record correct? Check that you didn\u2019t accidentally create an A record for something like smaba.example.com.Always double check the spelling and the correct hostname (is it samba.example.com or samba1.example.com) as this will often trip you up especially with long, complicated or foreign hostnames.Error 3 - The server isn\u2019t listening on that portThis error occurs when telnet is able to reach to the server but there is nothing listening on the port you specified. The error looks like this:telnet samba.example.com 445Trying 172.31.25.31...telnet: Unable to connect to remote host: Connection refusedCopyThis can happen for a couple of reasons:Are you sure you\u2019re connecting to the right server?Your application server is not listening on the port you think it is. Check exactly what it\u2019s doing by running netstat -plunt on the server and see what port it is, in fact, listening on.The application server isn\u2019t running. This can happen when the application server exits immediately and silently after you start it. Start the server and run ps auxf or systemctl status application.service to check it\u2019s running.Error 4 - The connection was closed by the serverThis error happens when the connection was successful but the application server has a built in security measure that killed the connection as soon as it was made. This error looks like:telnet samba.example.com 445Trying 172.31.25.31...Connected to samba.example.com.Escape character is '^]'.Connection closed by foreign host.CopyThe last line Connection closed by foreign host. indicates that the connection was actively terminated by the server. In order to fix this, you need to look at the security configuration of the application server to ensure your IP or user is allowed to connect to it.A successful connectionThis is what a successful telnet connection attempt looks like:telnet samba.example.com 445Trying 172.31.25.31...Connected to samba.example.com.Escape character is '^]'.CopyThe connection will stay open for a while depending on the timeout of the application server you are connected to.A telnet connection is closed by typing CTRL+] and then when you see the telnet> prompt, type \u201cquit\u201d and hit ENTER i.e.:telnet samba.example.com 445Trying 172.31.25.31...Connected to samba.example.com.Escape character is '^]'.^]telnet> quitConnection closed.CopyConclusionThere are a lot of reasons that a client application can\u2019t connect to a server. The exact reason can be difficult to establish especially when the client is a GUI that offers little or no error information. Using telnet and observing the output will allow you to very rapidly narrow down where the problem lies and save you a whole lot of time.\u00a9 2023 Elliot Cooper CopyrightMade with Hugo \u00b7 Theme Hermit \u00b7",
    "summary": "- Telnet, a protocol and command line tool, used to be how system administrators logged into remote servers before SSH was developed.\n- Although Telnet is not secure and should not be used for logging in remotely, it can be a useful tool for debugging connection issues.\n- Telnet can be used to narrow down the source of connection problems by checking for error messages related to firewall rules, DNS problems, incorrect servers or ports, and server security measures.",
    "hn_title": "Still Love Telnet",
    "original_title": "Still Love Telnet",
    "score": 272,
    "hn_content": "The post on Hacker News reminisces about the users' college days when telnet was still in use for registration of classes. Telnet was quickly replaced by web interfaces, but some users are still using it on a regular basis to test connectivity to web servers or other services. Users share their experiences of using telnet in college, using it to get better class spots, connecting to clusters of VMS machines, and even using it to access the internet because web interfaces could not handle the load. Users recommend using nc instead of telnet to connect to non-telnet servers. There is a discussion around the security of using telnet in modern times, with some arguing that a secure channel like WireGuard makes it safe to return to legacy telnet.This post discusses the limits and differences between 10base5 and 10base2 Ethernet. The comments provide insights into using telnet versus SSH for network connections and debugging, with some preferring netcat over telnet. There are also mentions of security vulnerabilities in telnet and SCP. Some readers reminisce about the early days of the internet and using telnet to learn about networking protocols. Telnet-based BBS is still popular in Taiwan, but telnet support is deprecated in PTT. Overall, the post and comments provide historical and technical context for networking protocols and their use in different environments.The comments on a Hacker News post discuss telnet and its use cases. Telnet is outdated and removed from servers nowadays, and netcat is a cleaner solution for moving files over SMTP. However, telnet was the first internet application, and it is still muscle-memory for some IT professionals. Different tools in this vein include Ncat, mConnect, Putty, and Windows Terminal. Telnet is risky because it can expose security vulnerabilities, and SSL/TLS have made tampering with network traffic more difficult. Nonetheless, some find telnet fun to play with, especially for troubleshooting. The comments have links to neater netcat tricks and to NASA's JPL Horizons service in command-line form.",
    "hn_summary": "- Users reminisce about using telnet in college and for testing connectivity to web servers or other services\n- Some users recommend using nc instead of telnet, while others argue for the security of using telnet with a secure channel like WireGuard\n- The comments provide historical and technical context for networking protocols and their use in different environments, including security vulnerabilities and different tools in this vein."
  }
]
