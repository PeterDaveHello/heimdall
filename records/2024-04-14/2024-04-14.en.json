[
  {
    "id": 40024062,
    "title": "FCC Urged to Block 5G Fast Lanes in Net Neutrality Vote",
    "originLink": "https://cyberlaw.stanford.edu/blog/2024/04/harmful-5g-fast-lanes-are-coming-fcc-needs-stop-them",
    "originBody": "By Barbara van Schewick on April 11, 2024 at 5:18 pm The FCC is set to vote on April 25 to restore its authority over the companies we pay to get online, and reinstate federal net neutrality protections that were jettisoned by the Trump administration in 2017. Net neutrality protections are supposed to ensure that we, not the internet service providers (ISPs) we pay to get online, get to decide what we do online. The FCC released its draft rules early in April and there’s much to celebrate in them. Mobile carriers like T-Mobile, AT&T and Verizon that have been degrading video quality for mobile users will have to stop. The FCC kept in place state neutrality protections like California’s net neutrality law, allowing for layers of enforcement. The FCC also made it harder for ISPs to evade net neutrality at the point where data enters their networks. However, there’s a huge problem: the proposed rules make it possible for mobile ISPs to start picking applications and putting them in a fast lane - where they’ll perform better generally and much better if the network gets congested. T-Mobile, AT&T and Verizon are all testing ways to create these 5G fast lanes for apps such as video conferencing, games, and video where the ISP chooses and controls what gets boosted. They use a technical feature in 5G called network slicing, where part of their radio spectrum gets used as a special lane for the chosen app or apps, separated from the usual internet traffic. The FCC’s draft order opens the door to these fast lanes, so long as the app provider isn’t charged for them. That means we could soon see fast lane offerings like this: Or we could see add-ons like Enhanced Video Conferencing for $10 a month, or one-time 24-hour passes to have Prioritized Online Gaming. This isn't imagination. The ISPs write about this in their blogs and press releases. They talk about these efforts and dreams openly at conferences, and their equipment vendors plainly lay out how ISPs can chop up internet service into all manner of fast lanes. These kinds of ISP-controlled fast lanes violate core net neutrality principles and would limit user choice, distort competition, hamper startups, and help cement platform dominance. Net neutrality means that we, the people who use the internet, get to decide what we do online, without interference from ISPs. ISPs do not get to interfere with our choices by blocking, speeding up or slowing down apps or kinds of apps. Apps compete on a level playing field, and users, not ISPs, determine which apps are successful. Letting ISPs decide which apps get to be in a fast lane violates these principles. Apps that are in a fast lane work better than those that are not, especially when the network is busy and apps in the regular lane start suffering. If HBO Max is in a fast lane, it will continue to work well even if the network is busy, while all other video is buffering. Differences in performance, including relative differences in performance, matter. Even small differences in load times affect how long people stay on a site, how much they pay, and whether they’ll come back. Those differences also affect how high up sites show in search results. Thus, letting ISPs choose which apps get to be in a fast lane lets them, not users, pick winners and losers online. And as we’ve seen in the past, programs like this favor the most popular apps, even when the program is supposedly open to all apps in a category and no apps are paying the ISP. So the biggest apps will end up in all the fast lanes, while most others would be left out. The ones left out would likely include messaging apps like Signal, local news sites, decentralized Fediverse apps like Mastodon and PeerTube, niche video sites like Dropout, indie music sites like Bandcamp, and the millions of other sites and apps in the long tail. Legislators, government agencies, attorneys general in states both red and blue, public interest groups, startups, and open-source technologists are all working to reduce the power and dominance of the biggest platforms. The FCC should be working to help that effort by creating a level playing field and banning these ISP-controlled 5G fast lanes. Meaningful net neutrality protections prohibit ISPs from speeding up and slowing down apps and kinds of apps. ISPs can pick winners and losers by putting winners in a fast lane or losers in a slow lane. This is a what it would look like if an ISP put everything except YouTube and TikTok in a slow lane. This is what it would look like if an ISP put YouTube and TikTok in a fast lane. It’s the same picture. The effect is the same. In either case, disfavored apps will find it harder to compete. Meaningful net neutrality protections need to protect against both. This is not controversial. President Obama’s November 2014 net neutrality proposal included this protection: “The rules I am asking for are simple, common-sense steps that reflect the Internet you and I use every day.” That included, he said, a brightline ban on ISPs “intentionally slow[ing] down some content or speed[ing] up others — through a process often called “throttling” — based on the type of service or your ISP’s preferences.” Even proposed Republican net neutrality bills prohibited ISPs from speeding up and slowing down apps and kinds of apps. Many, including me, thought the 2015 Order did so, too. Almost certainly, the millions of Americans who celebrated the 2015 Open Internet Order and fought the 2017 repeal think that net neutrality protections ban fast lanes and slow lanes. The draft order takes a different approach. The no-throttling rule that the FCC proposed in October explicitly prohibited ISPs from slowing down apps and classes of apps; it was silent on whether the rule also applies to speeding up. Given the mobile ISPs’ public statements about their plans for 5G fast lanes, public interest groups, startups, and members of Congress asked the FCC to clarify in the Order that the no-throttling rule also prohibits ISPs from speeding up apps and classes of apps. The draft order did not do that. While draft order acknowledges that some speeding up of apps could violate the no-throttling rule, it added some unclear, nebulous language suggesting that the FCC would review any fast lanes case-by-case, without explaining how it would do that.1 This language gives the FCC maximum flexibility to accept or reject specific fast lanes in the future as it sees fit. According to the draft order, the agency “could” find a violation of the no-throttling rule, if: an ISP speeds up specific apps (but not necessarily classes of apps), and the decision to speed up is “unreasonably discriminatory,” and the speeding up has the effect of “‘impair[ing] or degrad[ing]’ other … apps not given the same treatment.” In other words, the proposed no-throttling rule is a bright line rule for slow lanes – ISPs can’t slow down apps or kinds of apps; but for fast lanes, it’s a fuzzy, unclear case-by-case standard. For example, would it be “unreasonably discriminatory” to create a 5G fast lane that includes the most popular apps in a category since it responds to consumer preferences? Does an unreasonably discriminatory fast lane need to technically degrade or impair the apps that are not in the fast lane for the FCC to find a violation of the no-throttling rule? There is no way to predict which kinds of fast lanes the FCC might ultimately find to violate the no-throttling rule. This gives ISPs cover to flood the market with various fast-lane offerings, arguing that their version does not violate the no-throttling rule and daring the FCC to enforce its rule. And if the mobile ISPs do this, the cable companies will soon follow. Cable companies have the tech to build their own fast lanes, and increasingly they compete with 5G to the Home services. If T-Mobile and Verizon start selling home plans that have “enhanced streaming video,” you can bet the cable companies will launch their own version. The FCC would then investigate these offerings case-by-case in lengthy and costly proceedings. In the meantime, apps that are not in the fast lane will suffer. Entrepreneurs and application providers that are not included in a fast lane will have to decide whether to try to get into the fast lane, file an FCC complaint, or just silently suffer. Companies that do file complaints will waste years litigating the meaning of “unreasonably discriminatory,” all the while going up against giant telecoms that stockpile lawyers and lobbyists. Unless you are a high-paid telecom lawyer who bills by the hour, the proposed test for what’s a good or bad fast lane is a nightmare. Not all 5G slices are harmful. Just to be clear, net neutrality proponents are not asking the FCC to ban network slicing. There’s lots of ways for ISPs to use slices for things that are not normal internet service such as a dedicated slice for a farming operation using remote controlled tractors, slices for telemetry data and oversight of autonomous cars, or providing a slice for a stadium’s video system at a crowded game. There are good reasons to isolate this kind of traffic, and it can be done without reducing user choice or tilting the online playing field. Under the FCC’s draft order, such services would be so-called enterprise service offerings, to which the Open Internet protections don’t apply. But the 5G fast lanes ISPs are imagining for regular internet access – where ISPs decide which apps or kind of apps get a fast lane – would cause real harm and violate the core tenets of net neutrality. We don’t need our ISP deciding for us what’s important and what’s not; we want our ISP to let us decide and stick to the job of connecting our devices to the services we want to use. It’s not even clear why such fast lanes are necessary for consumer internet access. As one industry analyst noted, isn’t 5G already supposed to be the fast lane for everything? Luckily, there’s still time to fix this. The FCC can and should edit the draft order ahead of the vote on April 24 and clarify in the Order that the no-throttling rule also prohibits ISPs from creating fast lanes for select apps or kinds of apps. The FCC just needs to put this fix in the fast lane to get it done before it votes on April 25. 1 2024 Draft Order, para. 492 (“Our interpretation of “throttling” encompasses a wide variety of conduct that could impair or degrade an end user’s ability to access content of their choosing; thus, we decline commenters’ request to modify the rule to explicitly include positive and negative discrimination of content. We agree, however, with Free Press that a BIAS provider’s “unreasonably discriminatory” decision to speed up specific content, applications, or services could “impair or degrade” other content, applications, or services not given the same treatment.” (footnotes omitted)). Focus Areas: Architecture and Public Policy Related Topics: Network Neutrality Add new comment Your name E-mail The content of this field is kept private and will not be shown publicly. Comment * Disable rich-text Notify me when new comments are posted Once you hit Save, your comment will be held for moderation before being published. You will not see a confirmation message once you hit the Save button but please be assured your comment has been submitted and we will review it. What code is in the image? * Enter the characters shown in the image.",
    "commentLink": "https://news.ycombinator.com/item?id=40024062",
    "commentBody": "The FCC needs to stop 5G fast lanes (stanford.edu)393 points by rsingel 18 hours agohidepastfavorite268 comments KaiserPro 18 hours agoThe thing that is actually missing from this entire essay is competition. The biggest single reason why the USA's (and to a lesser extent Canada's) internet is shite is because of the monopolies that exist. In the EU there are similar offers for \"enhanced\" access, but its not speeding up/slowing down apps, but giving \"free\" access, as in not counting to your data cap. Instead of making the FCC stop fast lanes, the FCC should either be breaking up infrastructure from retailers (ie allowing regulated priced access like openreach) or splitting up operators and fining ones that dont provide proper access. reply holmesworcester 16 hours agoparentActually, the empirical record on this shows that we see more net neutrality violations by ISPs in marketplaces with high competition.[1] This is counter-intuitive but here's how it works: In a competitive marketplace ISPs have tighter margins and look for every opportunity for cost savings, so if throttling a high-bandwidth application only affects a small percentage of customers, and only a tiny tech-savvy minority of those affected will accurately attribute the effect to ISP throttling, it will incur only the tiniest competitive pressure on the ISP, so the ISP will do it to increase profits. We actually saw more net neutrality violations in competitive EU markets than in the US, until EU-level net neutrality rules passed. Another way to look at the limits of competitive pressure is from a startup's point of view: if your startup is offering a new videoconferencing service, how will competition help you when a rogue ISP breaks your service for 10% of your customers by throttling your service but putting Zoom in a fastlane? Your customers will not think \"oh, I'd better switch to a better ISP,\" when ~10% of call participants are unintelligible. They will think, \"oh, this new service sucks, I'm going to stick to Zoom.\" Competitive pressure on ISPs does not protect nascent startups with small userbases from ISPs. And yet, everything we care about on the Internet started as a nascent startup with a small userbase. Competition is great for keeping prices down and the US needs more of it. But to protect the long tail of startups and all the new ways people use the Internet from ISPs you need net neutrality laws. 1. https://dl.acm.org/doi/10.1145/2700055. Key finding: Relying on consumer switching behavior to provide more comprehensive competitive discipline was insufficient for a variety of reasons, including the presence of switching costs. reply jallen_dot_dev 16 hours agorootparentWhy doesn't the monopoly employ the same cost-saving measures for even bigger margins? reply AnthonyMouse 15 hours agorootparent> Why doesn't the monopoly employ the same cost-saving measures for even bigger margins? They would. The issue is that competition alone wouldn't fix it, because there is an information deficit. Some people will pick the lowest price and not realize that the ISP offering it is taking kickbacks from incumbent services to degrade their own competitors. And since this is always bad -- it's anti-competitive in the market for over-the-top services, so this is an anti-trust rule -- it should be prohibited regardless of whether there is competition in the ISP market. Because you need it in order to preserve competition in the markets for other services. reply oceanplexian 5 hours agorootparentExcept I live in one of the places that has widespread competition (Utah) and can pick from one of dozens of Fiber Internet providers, including some that can provide 10Gbps service, a cable company, and even technically Starlink. How many of them are throttling content to prevent competition in this hypothetical anti-net neutrality scenario? Exactly zero. Which is evidence to me that Net Neutrality is a sham, what more people need is a free market. Not another government monopoly with some regulations slapped on. reply AnthonyMouse 4 hours agorootparentThey're two independent things. You can still require network neutrality in a competitive market with multiple providers. Whether a market would converge on providers violating network neutrality depends on the characteristics of the market and its customers etc. But if nobody would have violated it anyway, what's the benefit of not having the law? Whereas if you don't have the law and do have violations, that's bad. reply CrazyCatDog 5 hours agorootparentprevHow competative was the isp market in Utah before Google fiber subsidized the massive build-out? Google threw in the towel on wiring more new cities about mid-way through the SLC build, which makes need think perhaps the biggest obstacle to your thesis bearing fruit, is upfront infrastructure investments… reply parineum 14 hours agorootparentprevSo the solution there is transparency. I'd be much happier if the government regulations gave me information to make an informed decision rather than forced a decision on me. reply AnthonyMouse 14 hours agorootparentTransparency is part of the problem. It makes the anti-competitive practice easier to carry out because customers don't know they're getting screwed. But there's still a potential anti-trust issue even with perfect information. Suppose Facebook doesn't want anyone using their competitors, so they subsidize the cost on some ISPs that then block their competitors. The customers of those ISPs are 15% of the market, and they know the other competitors are blocked, but they want the discount. Then the other 85% of people have to use Facebook in order to communicate with anyone on one of those ISPs, and social networks have a network effect, so now everybody is stuck on Facebook even if they don't use one of those ISPs, because they know somebody who does. This is anti-competitive and so an anti-trust problem. reply parineum 12 hours agorootparentI think it's much more likely people stop using Facebook in that condition. People may be \"stuck\" with Meta because everyone is on it but the situation you're describing is a big difference between zero friction to make an account and join everybody else and change your ISP so you can talk to your grandma and look at cats on instagram. I'd rather have choice and transparency and see if the situation you've described arises. It sounds completely unrealistic to me and we don't have to make laws and regulations cover every single edge case right away, they can be modified as we go. reply digestivetires 3 hours agorootparent> I'd rather have choice and transparency it is very hard to force trancparancy. Transparancy (at least how I see it) is matter of culture. For example, if you open up ISP accounting books to the public, creative people will find ways to hide things. Instead of line item “10M € kickback from facebook”, there will be “10M € sale to facebook”. reply makeitdouble 8 hours agorootparentprev> think it's much more likely people stop using Facebook in that condition. For the US, looking at iMessage's example, I'd say the trend would go the other way and Facebook getting way more power. reply shkkmo 9 hours agorootparentprev> people stop using Facebook in that condition. You've failed to understand the example. Nobody would have to change ISPs to use Facebook because Facebook paid off the ISPs for some form of exclusivity. It is Facebook's competitors who would struggle wity user acquisition because not only do you have to convince users to change ISPs to use your competing platform, but you have to convince all your frienda and family to switch too if you wanna be able to call them. > It sounds completely unrealistic You are incredibly naive then. This sort of thing regularly happens all around the you. Kickbacks, exclusivity and companies colluding for competitive advantage is commonplace, not unrealistic. reply ToucanLoucan 12 hours agorootparentprevI’d say the exact opposite. It’s clear the majority of customers here cannot make an informed decision either by way of incompetence about the technical aspects that would enable them to detect bad faith behavior on the part of ISPs, or lack of transparency, or outright lack of competition in their market. Competition does not work to increase quality if the customer cannot judge it. The entire benefits of markets and competition break down and become irrelevant. Instead: make it a utility, subject to regulation and codes as any other. I don’t need to be a plumber to ensure I get adequate sewer service, I don’t need to be an electrician to ensure that I get adequate electrical service, why should I need to be sysadmin to make sure I get adequate network service? It makes no sense. In fact, I’d go so far as to say that it makes even less sense because those examples require less education overall than you would to detect bad faith behavior on the part of your ISP. if you don’t have enough water pressure for your shower to function, you don’t need to be a plumber to diagnose that. If your homes electrical service is so bad that you can’t run your appliances you don’t need to be an electrician to judge that. But how do you know if your given ISP is throttling Netflix without substantial IT in your background? I don’t think it’s an outrageous opinion that any Tom, Dick, or Harry, who is participating in this market should be able to get the service to a reasonable standard of quality that they are paying for without needing to verify it independently. reply oceanplexian 5 hours agorootparent> It’s clear the majority of customers here cannot make an informed decision either by way of incompetence about the technical aspects that would enable them to detect bad faith behavior on the part of ISPs Unfortunately, if consumers can’t make an informed decision, then there isn’t a snowball’s chance in hell that the government, which is full of technically incompetent bureaucrats, is going to somehow make the right decision for them. I’d sooner trust an average 15 year old to regulate the Internet than literally any elected politician or professional lobbyist. reply scarface_74 11 hours agorootparentprevThe only reason utilities are regulated are because they are natural monopoly. It doesn’t make sense to have more than one utility company with right of way to dig up streets to create the needed infrastructure. To an extent, cellular is a natural oligopoly. Each carrier needs enough spectrum to have decent service. But it isn’t a monopoly. reply AnthonyMouse 6 hours agorootparent> To an extent, cellular is a natural oligopoly. Each carrier needs enough spectrum to have decent service. But it isn’t a monopoly. It's a natural monopoly in exactly the same way any other utility is. \"It doesn't make sense to have more than one utility build towers everywhere to create the needed infrastructure.\" In theory if only one company did it you would only need one set of towers and costs would be lower. But a private monopoly doesn't exactly optimize costs either, and some utilities cost more to duplicate than others. It's much more expensive to have redundant roads than redundant cables running along the same set of utility poles or in the same cable trench, and cell towers are on that end of the range. The spectrum is a red herring. You could operate live auctions to bid on spectrum in real time in areas of scarcity instead of allocating it permanently to particular companies. This would also give companies the incentive to operate more towers at lower power levels, because you'd only need to bid on spectrum in the same collision domain and lower power levels would cause that to be smaller areas with less contention, lowering their spectrum costs. reply Nullabillity 9 hours agorootparentprevAgriculture isn't a natural monopoly either, but that doesn't mean we shouldn't have food safety standards. reply scarface_74 9 hours agorootparentYes because something that will literally kill you if there aren’t standards is analogous to net neutrality. But even if it were, it’s #199542 why HN commenters don’t understand what a “monopoly” is and why utilities that require physical infrastructure which are natural monopolies aren’t the same as cellular where there are three healthy competitors. reply avar 15 hours agorootparentprevAnd some people will pick the ISP where Disney's subsidizing the subscription to make Netflix look bad, and not care because they're only using the connection for SSH terminals and email. Don't assume that people only pick these plans because they're uninformed. reply AnthonyMouse 15 hours agorootparentThe informed customers aren't the issue. If Disney is paying to make Netflix look bad, it's because somebody is getting fooled into thinking Netflix is to blame for this, otherwise what is Disney getting for their money? So that plan is an anti-competitive measure, regardless of whether it also presents an arbitrage opportunity for customers who don't care about video streaming. If its only customers were the arbitrageurs then Disney would have no reason to pay and it wouldn't exist. reply saghm 14 hours agorootparentprev> Some people will pick the lowest price and not realize that the ISP offering it is taking kickbacks from incumbent services to degrade their own competitors > And some people will pick the ISP where Disney's subsidizing the subscription to make Netflix look bad, and not care because they're only using the connection for SSH terminals and email It seems unlikely that there are anywhere close to as many of the latter as the former reply HeatrayEnjoyer 15 hours agorootparentprevIf the FCC does not do something, they will. As to why it has not happened yet: it is easier to corrupt a new infrastructure from the beginning than change one that is already entrenched. reply pipes 16 hours agorootparentprevI thought net neutrality was about ISPs trying to get netflix, facebook etc to pay them extra not to throttle. The only throttling I've heard of here in the UK (which has lots of providers and competition) is on torrenting. Are there examples of what you are talking about with zoom etc? Because as far as I can reason: if an isp throttled something like that in a high competition market, they'd lose their customers. And if it was a low user / start up phase app it wouldn't provide any competitive advantage for an isp to throttle it. reply vineyardmike 7 hours agorootparentGetting a high-traffic service to pay extra or degrading other services are basically the same thing. Because the obvious question is “what happens if they don’t pay”? The obvious answer is throttling. > And if it was a low user / start up phase app it wouldn't provide any competitive advantage for an isp to throttle it. What we’ve seen in developing nations is internet that’s subsidized but only for certain companies (eg free Facebook, paid everything else) and people just use Facebook and have 0 access to the outside internet. There are examples in the US at least, albeit less severe. It was (is?) common for cell phone companies to offer unlimited data cellphone plans, but they throttle video streaming to a lower resolution. Then offer “unmetered streaming of Netflix” (pick your VOD provider) while, again, degrading the video stream of other companies. I’m pro-net neutrality but also I question if subsidized internet would actually be bad. If you can take a heavily metered or poor service, and subsidize it, then that could be the tool that helps bring internet to more people at less cost to those users. Advertisers would basically be subsidizing internet through these giants. The catch would be to find rules that don’t throttle competition which I don’t know if that’s possible. reply Too 5 hours agorootparentTaken straight out the mafia for dummies handbook. \"It would be a shame if something were to happen to the bandwidth of your service in our network\". reply braiamp 14 hours agorootparentprevIt is multiple things based on a simple concept: no traffic should be discriminated based on source, destination or type. That means that netflix ones and zeros are treated the same as facebook, same as your web page filled with cat pics, same as torrents. reply digestivetires 3 hours agorootparentCan there be technical things why cerain services get lower level service? I’ve read that ISP buys various links to to other networks at various prices. So maybe something like: if facebookBar server is on pricier linkFoo and for that reason ISP buys cheaper version of linkFoo effectively downgrading facebookBar service (along with everything on linkFoo)? If such scenario is realistic, maybe it could be due to valid financial stuff, not due to anticompetetive behaviour. (Just saying, some technically valid scenarios should be taken into account) reply withinboredom 14 hours agorootparentprevThis isn’t at all true in the way you are portraying it. Of course, if you have more of something, you have more of the related things. If you have more oranges, more oranges are going to be rotten. This is obvious if you can think about it for more than 30s. The overall net effect isn’t what you say it is though. reply nox101 12 hours agorootparentprevSelection bias. They only picked UK and US. Plenty of countries in Asia have robust competition and is arguably a reason why they are so cheap and so good. One company offers twice the speed for the same price. People quickly start switching and new accounts (people coming of age) go to that cheaper better company. The other companies are forced to follow suit or lose their customers. reply holmesworcester 11 hours agorootparentYes, competition works for factors that the majority of consumers are aware of, like price and speed. But it doesn't work for enforcing net neutrality. If you model it, how could competition work to protect a YC startup with 1,000 or 10,000 users? You can't start an alternative ISP at that scale, so it's unthinkable that a new ISP would emerge just to serve that throttled startup's pissed off users. And again, only a tiny minority of users would correctly attribute throttling-induced failure to the ISP. Most will attribute it to the new startup being janky. Even or those who do correctly attribute it, what are they going to do? Convince everyone they want to use this new product with to switch ISPs? reply eru 6 hours agorootparentprevNet neutrality is pretty silly as a regulation, and most economists are against it. You are right that net neutrality, and competitive markets (and thus low prices for consumers) don't really go together. reply cyberax 5 hours agorootparentMost economists? BS. Most economists understand that ISPs in the US are a natural monopoly, you simply can not have more than 1 or 2 choices in most locations. And when there is no possibility of competition, regulation becomes necessary. reply eru 4 hours agorootparentHuh, ISPs are far from a natural monopoly. What makes you think they are? Especially if you take mobile broadband, paid 'public' wifi and satellite internet into account. (Regulations that make market entry harder push things into the monopoly direction, but that's far from 'natural'. See some of the recent troubles SpaceX has been having.) See also https://siepr.stanford.edu/publications/policy-brief/net-neu... or https://www.cato.org/regulation/winter-2011-2012/economics-n... > Network neutrality makes competition and consumer welfare dependent on law and lobbying, not natural competition. So you’ve chosen the area in which the telcos are strongest on which to fight! reply wkat4242 17 hours agoparentprev> In the EU there are similar offers for \"enhanced\" access, but its not speeding up/slowing down apps, but giving \"free\" access, as in not counting to your data cap. That's also in breach of EU net neutrality laws. A Dutch ISP lost a lawsuit over this for providing free Spotify traffic. I don't remember which one, I think it was T Mobile (now called Odildo or something lol) reply f1shy 17 hours agorootparentOdildo? Cant be truth in a country where almost all people speak english! reply wkat4242 17 hours agorootparentIt's actually Odido but everyone I know calls it Odildo :P it was really a stupid name choice reply blackbeans 17 hours agorootparentI must be weird, but I like the name. It's a palindrome and I dig their symmetrical logo. And of course, it is clever marketing. Even here we are talking about it. reply Cthulhu_ 17 hours agorootparentprevI suspect it's a brand name they tested across multiple languages, etc reply beeboobaa3 17 hours agorootparentMost countries are somewhat familiar with english slang, such as the word dildo. reply arp242 9 hours agorootparentIt's not slang, it's just a word. And the Dutch for dildo is ... dildo (I would have expected shared roots in French or some such, but apparently it's a loanword from English since the 70s). reply plugin-baby 17 hours agorootparentprevSpanish: jodido reply wkat4242 16 hours agorootparentHaha yes that means fucked (as in \"you're fucked\"). I speak Spanish and I didn't actually think of that. reply papichulo2023 14 hours agorootparentprevKinda funny how neutrality is hurting consumers. I dont think many of us thought about this potential benefit. reply wkat4242 17 minutes agorootparentIt's not hurting consumers. These companies are not coming up with these plans because they're cheaper for the consumers. They're doing it to entrench them into their service and then extract money in other ways. reply deanishe 14 hours agorootparentprevIt was always going to hurt consumers short-term. I don't know why anyone is surprised. Maybe it's just because I'm old and remember the clusterfuck when the EU decided one TV company couldn't hold the rights to all the football matches. (They divvy the rights up in such a way that you can't see a single competition on just one service, let alone just one team's matches.) reply EPWN3D 17 hours agoparentprevI was definitely someone who wrote the FCC (futilely) in support of net neutrality in 2017, and I figured the inevitable outcome of the FCC decision back then would be skyrocketing broadband costs, fast lanes, etc. Except none of it happened. It turns out there's actually kind of okay competition in this space. Maybe not as much as there should be, but prices have stayed reasonable, broadband access is expanding, and people by and large don't seem bothered by data caps when they're subject to them, and they have access to reasonably priced, uncapped plans. All that said, I certainly won't say no to reinstating net neutrality, since I don't think you can argue it'll make anything worse. In fact it might make competition easier. But it's not the existential pillar to online existence that we seemed to think it was. reply free_bip 17 hours agorootparentAFAIK the actual reason most of these things did not appear is because of many states passing their own net neutrality laws, such that it would be a regulatory nightmare to offer services in violation of net neutrality without coming under fire. reply holmesworcester 16 hours agorootparentThe California law is particularly strong and had a huge impact. The other big factor is the threat of new FCC rules, state laws, or federal law. As long as net neutrality advocates can pose a credible threat of passing rules that, from the ISP's point of view, are more restrictive than the status quo, ISPs have to think twice before engaging in what John Oliver famously called \"cable company f*ckery\". reply ricardobeat 17 hours agorootparentprevThat's because the internet went to shit and actually very little happens outside of major platforms anyway. This type of traffic shaping would just cement it as-is, making it almost impossible for a new platform to come up. reply gruez 17 hours agorootparentTiktok would beg to differ. Starting a new social network is hard, but bandwdith/net neutrality is the least of your problems. reply AnthonyMouse 15 hours agorootparentOne of the issues here is decentralized services. If you're starting a new centralized service, you can pay a CDN which itself is already paying the danegeld or is too big to degrade without the ISP's customers blaming the ISP. That's a tax but if you're state-funded or VC-funded you can just eat it. Whereas if you want to build something based on IPFS or just host your own website out of your home/business, ISPs have the incentive to thwart this, because then they couldn't double dip anymore. See also cable companies explicitly designing slow upload speeds into the most widely deployed versions of DOCSIS. So then you're creating a bias towards centralized closed-source services instead of open standards and self-hosting. reply holmesworcester 16 hours agorootparentprevThis is some research it would be cool to see: was TikTok adoption measurably slowed in countries where net neutrality violations were common? For example, it's the norm across Africa for providers to offer plans with radically lower per-GB costs for WhatsApp, Youtube, and other mainstream apps, as a way to price discriminate and charge a premium to tech and white collar workers who need access to the actual Internet. In such countries you would expect TikTok adoption to happen more slowly than expected. reply peddling-brink 17 hours agorootparentprevI know there’s a gun pointed at my head, but listen, nobody has pulled the trigger yet, it’s fine. reply gruez 17 hours agorootparentSounds like your position is one where no empirical evidence could convince you otherwise, because even if the apocalypse did not come to pass you would use the \"gun pointed at me but they didn't pull the trigger\" excuse. reply AnthonyMouse 15 hours agorootparentWe can turn this around though, can't we? If the ISPs have no designs on violating network neutrality then why do they oppose it? If you repeal the law against burglary and then burglary doesn't immediately skyrocket, would you say that we shouldn't have a law against burglary? Of course not, because regardless of how often it happens, you'd like it to never happen and would want to prosecute it any time it does regardless of how often. reply peddling-brink 16 hours agorootparentprevHuh? > \"Mobile carriers like T-Mobile, AT&T and Verizon that have been degrading video quality for mobile users will have to stop.\" This is literally what the article is about. It's happening now, it's been happening, it will continue to happen unless the laws get restored. reply gruez 16 hours agorootparent1. If your claim was that the net neutrality doomsayers from 2017 were correct, then your original comment of \"[...] nobody has pulled the trigger yet, it’s fine\" does a terrible way of conveying that. Any reasonable person reading that comment would interpret that as you conceding that the the doomsayers' predictions have failed to pass, but nonetheless refuse to admit the predictions were incorrect because it was only a matter of time before the predictions would become true. 2. \"Net neutrality\" is a term that doesn't have a precise meaning, and I'd rather not get into a fight about what it really means. That said, in the context of this discussion about the net neutrality fight in 2017, and whether the doomsayers' prediction came to pass, I think it's fair to compare to the pre-2017 net neutrality regime. In that context it's not clear whether \"degrading video quality for mobile users\" would be illegal. For instance \"network management\" was explicitly allowed, and only \"pay for priority\" would be banned[1]. Moreover there was a court case a few years before where FCC fought to prevent bittorrent being throttled, and lost the case on appeal. [1] https://en.wikipedia.org/wiki/Net_neutrality_in_the_United_S... reply holmesworcester 16 hours agorootparentprevMobile ISPs like T-Mobile are quite open about wanting to offer plans that privilege certain services over others. reply freedomben 16 hours agorootparentprev> I know there’s a gun pointed at my head, but listen, nobody has pulled the trigger yet, it’s fine. reply gosub100 16 hours agorootparentprevIt's been 7 years, but any day now we'll wake up to broken online video, random timeouts, paltry data caps, and skyrocketing costs. reply peddling-brink 16 hours agorootparent> Mobile carriers like T-Mobile, AT&T and Verizon that have been degrading video quality for mobile users will have to stop. \"Not with a bang but a whimper.\" reply michaelmrose 15 hours agorootparentprevThis is like the folks who compare the covid death rate with treatment, mitigations, and vaccination to prove we could have let it run its course in 2020. Public sentiment was pretty high and we actually had network neutrality for the first 40 years of the Internet not to mention the over 100M people who live in states that adopted laws. https://www.ncsl.org/technology-and-communication/net-neutra... reply PoignardAzur 17 hours agorootparentprevYeah, the discourse around the Net Neutrality thing was intense. I was one the few people who argued it wouldn't change much, and I remember being struck by the state of near-internet-apocalypse people were predicting at the time. Helps that I was seeing the whole thing from the outside as a non-US-resident. reply doublepg23 17 hours agorootparentI have to take the L on going with the flow there. It's impossible to build a case that repeal of net neutrality was apocalyptic. reply ethbr1 17 hours agorootparentThat the potential of a future FCC reinstating it precluded ISPs' baser instincts? Their goal was to avoid excess, so maybe they could argue that net neutrality wasn't a good idea anyway, so they could gradually introduce new revenue streams from apps/platforms. reply PoignardAzur 17 hours agorootparentThat repeal lasted five years, with virtually none of the visible effects people predicted. By contrast, when the Trump administration started tearing down environmental regulations, mining companies jumped on the occasion within months. If ISPs are playing the long game, they're being incredibly patient about it. reply holmesworcester 16 hours agorootparent> If ISPs are playing the long game, they're being incredibly patient about it. They actually are, and this is how politics and lobbying work. In 2017 it made no sense for US ISPs to run ragged over net neutrality when the 2020 election was looming and far from predictable. Even less once Biden gets elected. Plus there was the credible threat of state-level laws, which are even worse from the ISPs standpoint since each might go farther than the FCC rules in certain ways. The California law passed and was a really big deal. If you're looking for a controlled experiment of what the world looks like without net neutrality rules, just look to countries where there was never any such movement or credible threat of them. Across Africa, for example, 1GB of mobile data can cost 10x more if you're accessing the normal Internet, vs. a mainstream service like WhatsApp or Youtube. ISPs use net neutrality violations for price discrimination to extract more from white collar workers who need access to the Internet beyond WhatsApp-- which is fine until you think about the effects on any new WhatsApp competitor. reply pydry 16 hours agorootparentprevMuch as I agreed with net neutrality, I could see that it was being driven mainly by big tech lobbying for their profit margins. This is also why the attention and outrage was way out of proportion to the actual impact. reply whamlastxmas 16 hours agorootparentprevI’m constantly having buffering videos across many websites and paying significantly more for this shitty service than nearly anywhere else in the world pays for something significantly better. reply beeboobaa3 17 hours agorootparentprev> It turns out there's actually kind of okay competition in this space. Maybe not as much as there should be, but prices have stayed reasonable, broadband access is expanding, and people by and large don't seem bothered by data caps when they're subject to them lol. This is better attributed to you getting used to the shitty situation you, and everyone else in your country, is dealing with. Your speeds are shit and you're paying too much for them, and those \"not bothered by data caps\" just don't know better anymore. reply seabird 17 hours agorootparentI pay $50/month for 300/30 in the middle of nowhere. Symmetric gigabit is available for $80ish/month in small cities around me. Unlimited phone data is widely available and fairly priced. It's not impossible for things to be acceptable for the vast majority of use cases just because some predicted apocalyptic event which was hyped up by certain large players (and not out of the goodness of their hearts) didn't come to be. reply plowjockey 16 hours agorootparent$90/month for 25/2.5 Mbps here. I honestly never thought we'd see that kind of speed. In late 2015 it went from 512 kbps to 10/1 Mbps on a new system. Four years later (2019) they upgraded it to the present speed with no increase in price. It's all wireless and since we're in AT&T telco territory there is no chance of them doing anything (the phone lines have been in the ground since the late '70s), so this independent telco built out as a WISP almost 20 years ago. They're looking at doing their own FTTH in this area. reply ericfr11 16 hours agorootparentprevWow, that is very expensive reply freedomben 16 hours agorootparentI'm afraid to tell you what I pay for starlink for speeds much lower than that. Still very grateful as without starlink is have 20 M down and still pay $75 per month for it reply plowjockey 8 hours agorootparentprevBetter than Hughsnet which was the only option for a long time other than cellular. reply samatman 6 hours agorootparentprevI've got a symmetric gigabit. I could have five but what would I even do with it? reply gruez 17 hours agorootparentprev>Your speeds are shit and you're paying too much for them, and those \"not bothered by data caps\" just don't know better anymore. None of what you've listed would be fixed by net neutrality. reply lostlogin 16 hours agoparentprev> The biggest single reason why the USA's (and to a lesser extent Canada's) internet is shite is because of the monopolies that exist. New Zealand went from having a single provider for service and infrastructure, to having actual options. The breakup of the monopoly was imposed by regulation [1]. Following this there was a lot of taxpayer investment in fibre and while it’s been a flawed rollout, it’s made a hell of a difference. I’m on symmetric gigabit and have 2gb/s, 4gb/s and 8gb/s options if I pay more. [1] under history section https://en.m.wikipedia.org/wiki/Internet_in_New_Zealand reply jszymborski 17 hours agoparentprev> and to a lesser extent Canada's Not to turn this into a pissing contest, but Canada's internet is far more shite and far more captured by an oligopoly. Independent ISPs are harder to find than competition up here in the North. reply randomdata 17 hours agorootparentCanada isn't so bad off when it comes to wired service. Several ISPs are owned by the government: Sasktel, Bruce Telecom, Tbaytel, CityWest. And many more are co-operatives owned by the customers. The mobile space is more challenging. A number of those co-ops and government ISPs were running mobile service back in the mid 2000s, but they never found the customer base and most of them eventually shut it down, Tbaytel and Sasktel being the exceptions. That said, many of those ISPs have more recently turned to reselling Big 3 service, so you can still at least minimize how much the Big 3 take, giving the small guy at least some of the cut. Maybe some day they can take that small cut and build out their own network again? But, you get what you choose to become a customer of, I suppose. reply gruez 17 hours agorootparent>Several ISPs are owned by the government: Sasktel, Bruce Telecom, Tbaytel, CityWest That's cold comfort to the overwhelming majority of people who aren't served by such ISPs. Population of... Saskatchewan (Sasktel): 1.1M Bruce County (Bruce Telecom): 66.5k Thunder Bay District (Tbaytel): 146k Prince Rupert, British Columbia (CityWest): 13k That makes up a total of 1.3M, against Canada's population of 37.0M. Moreover, looking at Sasktel's website[1], their prices don't look too competitive. They're asking for $105/month for 1G (promotional offer, regular price $150), which is actually worse than what corporate ISPs offer, eg. $110/month for 1.5G (promotional offer, regular price $130)[2]. [1] https://www.sasktel.com/store/browse/Personal/Internet/Inter... [2] https://www.rogers.com/internet/packages reply randomdata 16 hours agorootparent> That's cold comfort to the overwhelming majority of people who aren't served by such ISPs. But is actually warm comfort as it shows a proven model that anyone, anywhere in Canada can also do. It's just a matter of whether or not the people actually care if they are a customer of an independent, or if being a customer of a major is just as good or better. > Moreover, looking at Sasktel's website[1], their prices don't look too competitive. Sure. Nobody said owning your own business allowed it to operate for free. Publicly-owned and co-op businesses are not a panacea. But they are independent and free of a major private business, which is the topic at hand. Saskatchewan's population is ~80% rural, and Sasktel doesn't operate outside of Saskatchewan. It isn't terribly surprising that it costs more to service rural areas, and without much in the way of an urban base to help subsidize the operation. But this does indicate that other providers are operating within reasonable margins. Indeed, Canada is a very expensive place to do business in, and not just in telecom. You are never going to see cheap internet compared to other countries, or much of anything, without radically upheaving what the country stands for. reply mardifoufs 14 hours agorootparentprevThose are completely irrelevant in 95% of Canada. There's bell, Rogers, and Telus. I guess Videotron in Quebec too. That's pretty much it and even then, here in Quebec it's either Videotron or bell, or their resellers. At least in Montreal. reply randomdata 12 hours agorootparent> Those are completely irrelevant in 95% of Canada. But quite relevant as they provide a proven, working model that can be used anywhere in Canada. That's the beauty of public/cooperative ownership – all people have to do is do it. > here in Quebec it's either Videotron or bell What about CoopTel, Sogetel, and Téléphone de Courcelles? reply mardifoufs 7 hours agorootparentWell I'm not saying they are irrelevant in the sense that they don't provide a good model for what an ISP should be, but more so that they are irrelevant because they don't provide services to the vast majority of people. Also a part from sogetel, those are either very small or regional. Even sogetel is regional and doesn't really provide services outside small villages and cities. That's not bad, but it's not enough to say that Canada's market isn't deeply uncompetitive. Even the US has tons of cooperative and WISPs that follow a similar coop pattern. reply parrot987 17 hours agorootparentprevThis is similar to what I see too. I've actually gotten a borderless phone plan from AT&T just so I don't have to deal with the Canadian oligopoly. reply yftsui 17 hours agoparentprevGiving “free data pass” to limited set of apps is even more harmful IMO, the monopolies can afford pay the network infrastructure but small app developers will not be able to. reply ethbr1 17 hours agorootparentThis. If ISPs want to QoS traffic into different lanes... fine. But those lanes should: - Be general categories of use - Only be created by regulation - Be freely accessible to any app - Not involve any app-ISP payment reply itopaloglu83 16 hours agorootparentOr, or, hear me out. The companies that need such high speed networks, should pay the infrastructure companies and get their own communication lines built, instead of buying QoS access on publicly funded projects. reply ethbr1 13 hours agorootparentI don't think any company should be able to buy QoS access. They should simply qualify for it on the basis of their use case. E.g. \"video streaming\" or \"real-time telecom\" reply itopaloglu83 12 hours agorootparentI agree. What do you think about fair use policies? Things like having 250GB/Month kind of limits. The internet infrastructure was built with certain utilization and speed in mind. Instead of owning up to the fact that it’s not as good as it used to be, these companies are selling quality of service products. Otherwise it’s too much of a publicity hit if they admit it. reply ethbr1 8 hours agorootparentI'm in favor of things that ultimately benefit the consumer. \"Unlimited\" plans have always irked the hell out of me, because they rarely are. I think capped totals (ideally without overage charges and with slow-lane bandwidth until reset) are perfectly fine. But I'm 100% against named exclusions that don't count against a cap -- that's unfairly preferring an existing incumbent, and doesn't benefit the consumer in the larger/competition sense. reply Too 5 hours agorootparentprevThis is what big CDN and cloud vendors do. You can see them as part of the infrastructure. For big users of cloud you can get dedicated connections, for example Azure ExpressRoute. That's a complete different game than that between end-customers, ISPs and service providers. reply marcinzm 18 hours agoparentprevYes I'm sure it's all due to competition and not the EU's 2015 law that explicitly requires net neutrality (Net Neutrality Regulation 2015). > In the EU there are similar offers for \"enhanced\" access, but its not speeding up/slowing down apps, but giving \"free\" access, as in not counting to your data cap. They do that because speeding up/slowing down apps is illegal and they are using loopholes in the law to get around that. reply godelski 17 hours agorootparent> Yes I'm sure it's all due to competition and not the EU's 2015 law that explicitly requires net neutrality (Net Neutrality Regulation 2015). Why do these have to be in contention? Regulations are a critical factor in ensuring competition in markets. Without regulations monopolies quickly come to power because your power and influence is not linearly (or sublinearly) correlated to your size (even excluding lobbying power). A free market is a ,,well'' regulated market. A laissez-faire market is only free in passing. reply marcinzm 16 hours agorootparent> Why do these have to be in contention? I never claimed. I simply pointed out that claiming something illegal is not being done by corporations due to increased competition is inherently a BS argument. It's not being done because it's illegal irrespective of the competitive landscape. reply itopaloglu83 16 hours agorootparentprevA free market is not a lawless market but instead free within regulations. However, the amount of regulation should not make it impossible for competitors to join the market either. With the amount of subsidies in the US for ISPs, I think the services they render might be event called a public service, more than a utility. reply godelski 16 hours agorootparentWe don't disagree. I just thought it was obvious enough that an over regulated market isn't free that it need not be stated explicitly. Especially since this is the general belief. reply itopaloglu83 12 hours agorootparentSorry for not clarifying. I do agree with your initial statement and wanted to add something to it, not criticize it. reply godelski 9 hours agorootparentOkay, I was not quite sure if you were criticizing, rebuting, or what. Thanks for clarifying. reply kristopolous 16 hours agorootparentprevOne is an explicit policy stating expectations and the other is a speculative hypothesis that the same policy will naturally happen through some form of economic osmosis if only we leave things unmolested enough for an unspecified duration. I for one, would rather not rely on the assumption of magic. We know what we want and it's achievable directly. Let's not Rube Goldberg it. reply terse-broccoli 17 hours agorootparentprevYeah, but the loophole is also illegal. (so it’s not a loophole?) reply passwordoops 17 hours agoparentprevThe biggest single reason why the USA's (and to a lesser extent Canada's) {insert industry} is shite is because of the monopolies that exist. reply spxneo 16 hours agorootparentppls comments on this thread towards Canada really struck a nerve with their cluelessness about Canada. People from other countries always act like it's some shining example of the Western world, but that's not the real deal at all. Canada is basically just three big resource companies propped up by a massive housing bubble that traps newcomers in debt slavery in a form of reverse colonialism where they trick immigrants to become serfs paying rent so people who bought homes in the 80s (after working for like 6 months) can keep flipping it to the next wave of immigrants and blame them with the media owned by the very oligarchs that are supposed to regulate the real estate industry (lol!). They don't even bother using or valuing the skills and experience these immigrants bring - you've got surgeons from the UK working as cashiers, immigrants without income so all they can do is start businesses or become traders, all to line the pockets of the ultra-rich oligarchs who get everything for cheap and flip at insane markups. They have every Prime Minister wrapped around their little finger, letting them monopolize everything and then screwing over everyone that comes to this miserable piece of land. Take this one famous billionaire in Vancouver - I'm not gonna name names, but this dude practically owns all the salmon in BC, along with Aboriginal monopolies that were handed out just because of what has been described in anthropology textbooks as \"white guilt\". Then there's another billionaire from Ottawa who has a monopoly on the legal drug market - guy ended up getting choked out with a wire, and the RCMP just called it an \"accident.\" Oh, and let's not forget the billionaire who somehow scored the exclusive rights to run the only online casino in BC. The list goes on and on. There's no such thing as a free market in Canada - it's just a banana republic country club for the rich old Canadians at the top. Actually, I'm not even sure if the casino guy was born in Canada, but he definitely looks like he could be. So yeah, to a lesser extent makes no sense here as somebody that has decades of experience with that country. At least America still recognizes the value of some free market and competition with or without a housing bubble. reply lolinder 17 hours agoparentprevThis was my thought. My municipality has been working towards laying a city-owned fiber network that ISPs compete on, and if that goes through I would have no problem with some of them running the kind of programs described in TFA. If consumers want it they'll choose those ISPs, if they don't they'll choose ones that offer flat rates for all traffic. The problem with unregulated broadband isn't the lack of regulation in the abstract, it's the lack of regulation over a sector that has 2(±1) choices per household and no easy path for new entrants. reply spullara 17 hours agoparentprevBest internet in the country is offered by a monopoly in Chattanooga. Up to 25 Gbit up/down. reply godelski 16 hours agorootparentMonopoly? That's a bit bold of a claim. The provider you're talking about is the utility company. You might not know why the utility company provides the internet either. It's because before that they couldn't get the other companies (AT&T, Comcast, Hughe, Verizon) to offer good speeds and reasonable rates. The utility also doesn't take a profit. Mind you, those other companies still operate and no one is holding them back. They just decided that the profit margins weren't worth it, though they did lobby against NoogaNet. It's not a monopoly. It's a city coming together and saying Fuck you, give us good internet or we're going to build our own internet w̶i̶t̶h̶ ̶b̶l̶a̶c̶k̶j̶a̶c̶k̶ ̶a̶n̶d̶ ̶h̶o̶o̶k̶e̶r̶s̶ And overnight all those companies increased their speeds. They found what they were happy with and NoogaNet still decided \"fuck it, we're going to just be better.\" I really REALLY wish more people/cities would take this \"fuck you, we'll do it ourselves\" attitude. Waiting on others to fix our problems clearly isn't working. reply AnthonyMouse 14 hours agorootparentIt's weird that we keep seeing this happen and work but then it isn't more popular. Government services are typically inefficient, but so are private monopolies for almost exactly the same reasons. If you put them into competition with each other then they both have more competition and have to do better. reply godelski 9 hours agorootparentI think it is because it requires significant cooperation. And by significant, I mean size, not the actual amount of action required by an individual. This is an interesting problem to me and seems to be quite a prolific issue. I think it is because everyone feels like they are a tiny meaningless cog in a giant machine. But this confuses me. Even tiny cogs play an important role. Even if your function is redundant, that redundancy is built in for a reason. I hear the common sentiment \"you're replaceable\" and I think people take this to be \"perfectly\" fungible. But you may be a replaceable worker, but that also doesn't mean replacing you is easy. They usually gotta look for someone new, pay them more, and then train them (this is why I'm also really confused why companies won't increase existing workers' salaries against new hires. Because your current workers likely have significantly more utility than a new worker. You lose money by doing this. Not to mention essentially give away your work practices to competitors, weirdly leveling the playing field). But it infuriates me when there are things that are universally hated, have relatively easy solutions, AND no one does anything. Be it a boss/manager who just says no to pressing a button that enables functionality where all the work has already been done and tested. Or simply voting in a new politician when everyone hates the current one. Or how 1 in 4 Americans dislike both Trump and Biden. How the early primary states will not even use their advantage to push towards a different candidate because we're playing this stupid game of chicken where people act like the primaries aren't actually the BEST time to vote or signal for a different candidate. I just don't get it... And I've always been a fan of government directly participating in the market. (Even though I generally like weaker/smaller governments.) They can set a baseline. Gov is always participating, regardless, since they do regulations and all that, so I don't buy those arguments. But there are many more things becoming natural monopolies as advantage is provided by scale. A government actor essentially is able to set pseudo regulations by participating. USPS helps make FedEx and UPS better, but now they get so many cuts that UPS uses them as last mile deliverers despite operating in the region. Still, USPS ensures mail gets to people who would otherwise not be able to even get mail. I don't see why we don't have similar services from broadband and telecommunications. They are essential services these days. Plus, it would create a lot of good quality jobs as not only those people needed to maintain the systems but even all the contractors to do the initial buildouts. reply AnthonyMouse 7 hours agorootparent> Or simply voting in a new politician when everyone hates the current one. Oh, we already know how this one works. People generally like their elected representative, because that's how they won in that district. The district has e.g. a large employer, and the representative makes sure those jobs for the people in the district aren't lost. Even though that's the very thing people in other districts are complaining about, and in order to get that one thing the representative had to betray the citizenry in 250 other subtle ways to get votes from 250 other districts. This is why federal legislation was originally meant to be limited in scope and require approval from both the House and the Senate, the latter of which was meant to be appointed by the state legislatures and thereby more inclined to reject that kind of populist vote buying and expansion of federal power. But we changed all that without thinking it through and now we suffer the consequences. reply godelski 6 hours agorootparent> People generally like their elected representative This is definitely part of it but not all of it. There's more. I hear people complaining about the exact people they vote for. I think another part of the problem is simply parties. We vote along lines rather than actual beliefs. I actually believe we'd be better off without them. Or at least affiliations on ballots. Like how we do judges. Hand out a booklet, let people vote by mail and take their time. But don't give people the super lazy version. Some friction is good, too much is bad. The issue I see is it just makes tribalism very easy. And it's very easy to abuse this. Even countries with more than two parties only effectively have two either via major parties or through coalitions. America just has their coalitions under two big umbrellas (Biden and AOC in the same party? Trump and Romney? Those would be different parties in many European countries, but under the same coalitions) reply AnthonyMouse 6 hours agorootparentThat most often happens in one-party districts because the incumbent doesn't have to please the voters when the district would never go for the other party. The two party system itself is caused by first-past-the-post voting. In that system if there are more than two parties, the two most similar parties split the vote and both lose, giving them the incentive to merge together instead of running against each other, until there are only two left. Score voting/approval voting fixes this. reply godelski 3 hours agorootparentIt's not __caused__ by FPTP, but yeah that certainly doesn't help. But I am glad that my excessive campaigning on this site for Approval/Star/cardinal systems has had some effect :) (Very happy to see ordinal systems not being suggested) There's much more complexity to it all, but yeah, voting systems are important. The cardinal systems are just about better embedding preference while minimizing the capacity to hack. But they still assume rational voters. These cardinal systems may make strategic voting less effective, but they don't prevent them. A major benefit to be though is transparency, since it is easier to understand the tallying. Especially when it is (parallel) column sum and argmax. Much easier to understand than multi-round elections. (Could you imagine the Arizona recount with RCV...) But again, you can build more representation and transparency into the system but it doesn't remove the human component. Where name recognition is a major predictor in winner. Where people are not investing time to vote. This takes a much larger cultural shift to have things like giving people time to research their candidates. But a single extra day off is probably just going to be used to catch up on all the more immediate issues we have. We're all constantly playing catch-up and truth of the matter is that politics is much more abstract than these things and so it gets de-prioritized. Voting systems won't fix that (obviously I still actively advocate for cardinal systems though. I'm a firm believer in addressing problems from the bottom up) reply bsder 11 hours agorootparentprev> I really REALLY wish more people/cities would take this \"fuck you, we'll do it ourselves\" attitude. This is hard. Start here: https://madned.substack.com/p/thin-pipe-part-i The problem is the activation energy and a bunch of people who will oppose you no matter how useful something is. reply glitchc 17 hours agorootparentprevThat's amazing. I just upgraded my home network to 10G to take advantage of my 1.5G internet connection. reply CyberDildonics 17 hours agorootparentprevWhy are you calling their municipal fiber internet a monopoly? Not only is it a utility, here is a list of 10 other broadband providers including att fiber, xfinity and verizon 300mb 5g: https://broadbandnow.com/Tennessee/Chattanooga Pretty ridiculous and disingenuous to call it \"monopoly\". reply spullara 6 hours agorootparentDoes someone else have access to that infrastructure that can offer the service? Utilities are granted monopolies. reply CyberDildonics 4 hours agorootparent> Utilities are granted monopolies. You can say that as many times as you want, but you don't have any evidence or even an explanation. If there were ten power lines and ten water pipes to your house would say each of those twenty companies had a monopoly? Repeating something isn't evidence of anything. reply nostromo 8 hours agoparentprevI'd agree with this comment if it was 2010. But today the US has good internet speeds -- in general much better than Europe despite it's bigger geographic size and less-dense population. https://worldpopulationreview.com/country-rankings/internet-... reply fulafel 3 hours agorootparentDespite the category mismatch (continent vs country) .. Europe and USA have very similar population densities (~35 p/km2) [0] [1] [2] [3] Also, many sparsely populated European countries have relatively good internet speeds (eg Iceland, Sweden). [0] https://database.earth/population/europe/density [1] https://www.worldometers.info/world-population/europe-popula... [2] https://www.worldatlas.com/articles/european-countries-by-po... [3] https://data.worldbank.org/indicator/EN.POP.DNST?locations=U... reply jabroni_salad 7 hours agoparentprevT-mobile offers it in the US still: https://www.t-mobile.com/tv-streaming/binge-on In this mode, video streams will be limited to 480p but will not count against your bandwidth cap. reply rjzzleep 5 hours agoparentprev> the USA's (and to a lesser extent Canada's) internet is shite Why to a lesser extent? In my experience Canada's was way worse than the US, which I honestly didn't think would be possible. reply mardifoufs 14 hours agoparentprevIf that's true, then why does the US have higher average and median broadband speeds than pretty much every European country[0]? The narrative that is seen online isn't necessarily representative of the reality, Americans just like to complain more. In my experience, bundled data whatsapp/YouTube or whatever else is much more common in Europe too and no one really complains because again, Americans are just that much more vocal. [0] for mobile, they are also in the top 15. For fixed broadband, they are 5th. https://www.speedtest.net/global-index#fixed reply iknowstuff 14 hours agorootparentHere’s some better research https://research.rewheel.fi/downloads/Wireless_market_operat... reply wzyboy 15 hours agoparentprevI immigrated from China to Canada and I'm not sure if monopoly is the root cause. In China, ISP is state-controlled and 100% monopoly, yet the plans are dirt cheap compared to those in Canada. I just looked up the price in my hometown in China: 1000 Mbps fibre internet + 3 mobile phone lines (105 GB data) + IPTV = 249 CNY tax included (30 USD / 42 CAD / 28 EUR) The 1000 Mbps fibre Internet plan alone (no phones no TVs) I have in Canada is $65 + tax. And it's a discounted plan. The price on the ISP website is $100. Also in China phone plans have fast lanes as well. SNS and video streaming data are treated separately (cheap or even free). reply seanmcdirmid 15 hours agorootparentI lived in China for 9 years and always found the internet, even for going just to Chinese sites, to be really slow. Like sure you have 5G, but the overall internet trunks are just saturated and not built out enough. Maybe it has gotten better since I left Beijing in 2016? It was definitely cheap and affordable. But I always felt a huge speed bump (along with easy access to foreign web sites) when I went to Thailand or Indonesia for vacation. reply alephnerd 13 hours agorootparent> always found the internet, even for going just to Chinese sites, to be really slow A lot of that is because of the GFW. MITM/TLS decryption/DPI has a massive performance overhead (and why the first question any agent based security product is ask is whether it is \"in the path of traffic\"). It's basically a giant version of Zscaler Private Access (ZPA) The performance hit is a major reason why a lot of edge computing development has happened in the Chinese ecosystem (you can't guarantee stuff works with latency, so how do you solve that) This is an older investigation (2017) by ThousandEyes about this - https://www.thousandeyes.com/blog/benchmarking-network-perfo... Note that the infra has changed drastically since 2017. reply seanmcdirmid 10 hours agorootparentHmm, then I’m not even sure why they bother with lines out anymore. They’ve blocked pretty much everything abroad, it seems like they could speed things up by just scrapping the GFW and physically disconnecting their internet from the rest of the world. reply alephnerd 9 hours agorootparent> it seems like they could speed things up by just scrapping the GFW and physically disconnecting their internet from the rest of the world If you do that, international commerce for China grinds to a complete halt (though ik one very large F50 that is in the process of completely decoupling in the next 2 years) Especially because this kind of an en masse disconnection means completely disconnecting Chinese assets abroad from their mainland HQs. Down the grapevine, I have heard some provinces testing that kind of a whitelist, but I'm not sure how true that is. If an actual nationwide whitelist is implemented, I think that is proof enough that war be coming. Even Roskomnadzor didn't try implementing a similar system until the 2022 escalation. reply seanmcdirmid 6 hours agorootparentThat makes sense, but at least China has to pay a cost for keeping it kind of opened but mostly closed. It is also really hostile for foreign tourists. You'd be surprised how many people still go to China and have all their trip plans stored in Google docs...doh. Although if you come with a foreign SIM and use roaming, you circumvent the GFW automatically for some reason. reply alephnerd 4 hours agorootparent> Although if you come with a foreign SIM and use roaming, you circumvent the GFW automatically for some reason That's because when your SIM is in international roaming, traffic is routed by the local telco to a tunnel back to the home telco provider. This ofc decreases margins significantly (because those bytes are routed via fiber or satellite by a Transit Service) and is why roaming costs are so high. > It is also really hostile for foreign tourists. You'd be surprised how many people still go to China and have all their trip plans stored in Google docs...doh Oof. You'd have to be living under a rock to not know that Google is banned in China, but I guess some tourists just aren't tech savvy, so who am I to judge. > China has to pay a cost for keeping it kind of opened but mostly closed Not really. As an individual you are definetly paying a performance cost in the form of low latencies and speeds, but this is also why edge computing solutions (eg. Compute offloading, packet size optimizations, etc) are heavily researched by Chinese players compared to Western players. In isolation, it's a good forcing function for innovation. That said, it is absolutely 1984-esque. Also, a lot of these innovations seem to be a result of the Urumqi and Lhasa riots from 10-15 years ago as well as Tahrir Square, so clearly maintaining the political status quo seems to be top of mind. It's bad for business, but China (and especially Xi) has seemed to have taken a very statist approach after the 2015-16 financial crisis. reply seanmcdirmid 3 hours agorootparent> Oof. You'd have to be living under a rock to not know that Google is banned in China, but I guess some tourists just aren't tech savvy, so who am I to judge. We hosted an ACM conference in 2011 in Beijing. One of my friends came, first trip to China, really smart guy just finishing up his PhD in EECS at UCB, but OMG did he mess that one up. We had to use the guest wifi in my office so he could make offline copies. If you aren't used to it, and don't follow China closely, you could be very technical and still be caught off guard. Lots of people will tell you China is just a normal tourist spot like Japan, Thailand, or Indonesia, but it really isn't. > Also, a lot of these innovations seem to be a result of the Urumqi and Lhasa riots from 10-15 years ago as well as Tahrir Square, so clearly maintaining the political status quo seems to be top of mind. I was in Beijing for those. A lot of things blocked afterwards, we slowly lost more services that we had previously. I would say 2008 was a peak for Chinese internet liberalization (and well, lots of other liberalization, I also spent 6 months in 2002 so can compare), and then it just tanked from that point on to present. They made a show for the Olympics and then decided they didn't need to bother anymore. It doesn't help that Xi is much more assertive and autocratic than Hu was. reply wzyboy 8 hours agorootparentprev> I lived in China for 9 years and always found the internet, even for going just to Chinese sites, to be really slow. Did you have your VPN / proxy on? That might be one of the reason as Chinese internet is only fast for traffic within its borders. Traffic that crosses borders are super slow in terms of throughput AND latency (if not blocked altogether). If you have your VPN / proxy on, your request basically crosses the borders twice before it reaches the destination web server. Another reason I can think of is the mobile ISP incompatibility. For some ridiculous reasons, most \"foreign\" phones' (iPhones exempt) do not have full radio coverage when connected to CMCC. reply seanmcdirmid 6 hours agorootparentWe tried many VPNs, and they all would stop working after paying for the mandatory few months, so I eventually gave up. IT is slow inside China even without using a VPN, and only accessing domestic Chinese websites (well, if you don't have YouTube, at least you have tons of pirated content to view). This is with a wired line from China Telecom, China Unicom internet is fine for text viewing, I don't I bothered much with video (and really, it is slower than China Mobile 5G, I guess this has changed now). reply gswdh 15 hours agorootparentprevCommunist and capitalist monopolies are two completely different things. reply Larrikin 14 hours agoparentprevI haven't checked lately, but Comcast tried that data cap crap and was completely pushed back on in every economically important state they tried it in or there was actually an option someone could switch too. I was shocked in Chicago when I got an overage fee, but I promptly switched to RCN even before Illinois shut it down. reply alephnerd 16 hours agoparentprev> The biggest single reason why the USA's (and to a lesser extent Canada's) internet is shite is because of the monopolies that exist Hot take - Reliance Jio+Bharti Airtel, China Mobile+Telecom+Unicom, and NTT+KDDI are basically duo/triopolies yet were able to roll our 5G nationwide in just 2-4 years in India, China, and Japan while keeping competitive pricing, and make the US market look free in comparison. The issue seems to be the relative lethargy of the FCC and regulators, along with issues around deprecating older infra. This doesn't mean we should go all Reagan, but if this is streamlined at the executive level, it would really simplify everything. reply Xelbair 17 hours agoparentprev>In the EU there are similar offers for \"enhanced\" access, but its not speeding up/slowing down apps, but giving \"free\" access, as in not counting to your data cap. there were such offers. about 10 years ago, but they are illegal EU-wide. reply deanishe 14 hours agoparentprevThe worst part is, imo, US taxpayers paid for all that infrastructure. These ISPs absolutely should be forced to open their infrastructure to other providers, like in Europe, and for the same reasons. reply palata 13 hours agorootparent> The worst part is, imo, US taxpayers paid for all that infrastructure. Isn't that exactly how it always worked? Whatever public service works well is privatised (for some reason I don't get), and whatever is a source of cost stays public. Such that the taxpayer keeps paying, and some people get rich by screwing them. reply kevin_thibedeau 17 hours agoparentprevThe FCC did that with DSL. The incumbent telcos retaliated by not maintaining their copper plant and killing their own line of business as an ISP. reply AnthonyMouse 14 hours agorootparentThe mistake there was in leaving the private monopoly intact whatsoever. If you want to have ISP-level competition, one of the better ways to do it is to have the government install cable trenches along the roads which the government then owns and provides cheap access for anyone to lay cable. Once the trenches exist, wiring a neighborhood with fiber is then far less expensive and makes it feasible to have multiple competitors. reply ThatMedicIsASpy 17 hours agoparentprevAll the free access has been removed in Germany a while ago because of net neutrality. The free access also came with a limit like bitrate and video resolution. reply blackeyeblitzar 18 hours agoparentprevI think there is limited room for competition in many of these categories. For example, the infrastructure costs for telecoms make it very difficult for new competition (like a startup) to enter the market. The existing ones benefited from past funding and a lack of competition, but have captured market share. In some cases, there are other practical limitations, for example, splitting up wireless spectrum. Apart from Starlink I’m not sure there can be viable alternatives in this space reply dave4420 18 hours agorootparentYou force the infrastructure operator to allow competitors to use their infrastructure on a fair basis. It’s what happens in Europe (including the UK). It works. reply ryandrake 17 hours agorootparentOR, (and I know this is near heresy) you force the infrastructure operator to allow competitors to use their infrastructure regardless of whether it is fair to that operator. This isn't a schoolyard playground. We don't have to play fair and treat these megacorporation with kid gloves. When the shoe is on the other foot, corporations don't play fair with us. \"Fair\" doesn't even come into the picture when they are in the conference room deciding their prices and terms. So why should the government treat them fairly when it comes to a regulatory solution? reply dave4420 13 hours agorootparent“Fair” as in “on the same terms that their own retail unit gets”, without any terms that would be anticompetitive. And no cross subsidisation. (I meant “fair to competitors”, but I think you thought I meant “fair to the infrastructure owner”.) reply blackeyeblitzar 18 hours agorootparentprevIn Europe they only do this for the last mile as far as I know, and this actually also prevents innovation since again there isn’t competition that can meaningfully introduce alternatives (let’s say cable versus fiber versus whatever). But I agree that approach is still an important tool (certainly better than nothing) and the US should adopt it. reply cycomanic 17 hours agorootparent> In Europe they only do this for the last mile as far as I know, and this actually also prevents innovation since again there isn’t competition that can meaningfully introduce alternatives (let’s say cable versus fiber versus whatever). But I agree that approach is still an important tool (certainly better than nothing) and the US should adopt it. Actually many places offer choice between cable and DSL variants. But once there is fiber in the ground it actually doesn't make much sense to go with anything else, so choices disappear (only for connection type, not ISP). With fiber it's much cheaper to provide high speed access (and there is a much clearer update path). reply tuwtuwtuwtuw 17 hours agorootparentprevI live in sweden and can pick from roughly 30 different ISPs where I live. I don't live in some big city, but in a smaller village. There is tons of room for competition if the laws are set up to push for it. reply blackeyeblitzar 13 hours agorootparentDo you know how they are set up? What elements of their networks they share? reply thomastjeffery 16 hours agoparentprevI live in a city with a competitive municipal network and Google fiber. If you live in a house down the street from me, you can get 1gbit for $70. Yet somehow, I'm paying $100 for 190mbit. The price and ISP (not the speed) are literally written into my apartment's lease agreement. This is an apartment managed by the same developer who owns every other apartment I can afford, so it's not as if I have any bargaining power here, either. My parents, who live in a remote area, but happen to be next to a major fiber line, pay even more than I do for less than 20mbit FTTH! I think we have made a grave mistake obsessing over the word, \"monopoly\". It doesn't take a monopoly for anti-competitive behavior to absolutely ruin a market. Even if healthy competition thrives in a market, some participants will find a way to abuse some customers. We shouldn't be so lazy that we point a finger at what's working, and pretend the rest doesn't exist. reply scarface_74 11 hours agoparentprevThere is no “monopoly” on cellular service. There are three national carriers and a few regional carriers that have their own network. How exactly do more carriers competing locally even work? You slice the spectrum they are allowed and have worse service? Do you remember when t-mobiles spectrum allocation was so bad that you couldn’t get a signal inside of a building? reply wredue 17 hours agoparentprevCanadas ISP situation was far better when Crown corporations were providing better, cheaper services. In standard fashion, conservative government successfully convinced half the population that it’d be better if the crowns were sold. Spoiler: it has gotten way way worse. Not better. reply WarOnPrivacy 16 hours agoparentprevBroadband funding just funded some competition here. Before: One ISP. Spectrum $120/mo 1Gb down & 40Mb up. After: New choices of 8 fiber ISP. Opts inc $35 250Mb/250Mb, $50 1Gb/1Gb, $70 2.5Gb/2.5Gb, $120 10Gb/10Gb. ISPs spend billions on politicians to make sure (the most possible) Americans don't have choices. They get their money's worth. ref: https://www.commondreams.org/news/2022/04/28/infuriating-tel... reply godelski 17 hours agoparentprevI lived in Tennessee when Google Fiber was announced there. At the time Chattanooga (and a few small towns) already had fiber internet that were offered by the utilities companies. It was an absolute shitshow. Actually, a shitshow would have been cleaner. Immediately AT&T rolls out gigabit internet, but not everywhere. I was in one of the small towns with gig and the previous renter had AT&T. AT&T literally cut the lines into the apartment instead of disconnecting them, causing me to have a $50 install fee (the technician was clearly also annoyed). Then Google, AT&T, and Comcast got into a big fight and it got political. Politicians would talk about how Google coming in was preventing competition (I shit you not) and attacking the little guys. Then a judge ruled that Google couldn't operate on telephone polls because Google would \"cause danger to employees\" and \"be a union violation\" (not the unions saying these things, it was AT&T. Obviously this made people think the unions were blocking things and continued to get mad at unions)[0]. So basically one of a Comcast and AT&T technician had to be there while Google would place in fiber and you know how it goes. It was a literal circus and the whole while it was politicized and misinformation was spreading like wildfire. Big Tech screwing over the little guys. Big Tech coming after the public utilities (never happened). Unions making everything impossible. Something about Big Tech and liberals/trans/gays taking over at some point. Like the on the ground conversations that would happen were mindbogglingly dumb. It actually was hard to figure out what was actually going on because every person and news article would have a unique story to tell. But the weirdest thing to me is about how nearly everyone I knew was a self-proclaimed Libertarian who hated government yet was licking their boots ad propping them up because they didn't want those gay/liberal/furry/godless/ techies rolling in decreasing competition and destroying the free market. That's when I truly started to believe that there's no such thing as a Libertarian (or any other cleanly encapsulated idea, but Libertarians are in your face), it's just a label. Because I watched anti-government free market devotees bend over backwards to protect monopolies and not even have a clue of the cognitive dissonance. It also made me really pay attention to how this happens more often than we care to think (including how we ourselves do it). [0] https://www.tennessean.com/story/money/2017/11/22/judge-rule... reply freedomben 15 hours agorootparentLibertarian does seem to mean different things to different people, but if somebody is supporting government or propping them up because they are concerned about preserving or maintaining current or traditional social values, that is the definition of a social conservative, not a libertarian. A libertarian position on that would be a \"you do you\" , but don't force others to do \"you.\" A \"the government should enforce or promote this\" is a social conservative position. But yes, I mostly agree. Most of the people I know who would identify as libertarian, suddenly become much more comfortable with government action when the government is wanting to do something they like, or is even run by their person. Once \"the other side\" gets in control, they seem to rediscover their libertarian principles. Seeing this was a good reminder to me that we should look at actions, not words, when deciding who to vote for. reply godelski 14 hours agorootparentMost of these people would repeat the common lines of taxation is theft, government is bad, prefer small government, complain about things like that existence of USPS/FDA (and an inaccurate story about peanut butter)/health instructors, and all those things you'd stereotype of those positions. They'd also take positions like you say about things like drugs (despite the state having a lot of dry counties, including the one Jack Daniels is in...). Truth is that people say they believe a lot of things but don't act as if those beliefs are true. I think people like labels more than beliefs. A common one is how common it is to say that all politicians are corrupt. I know people that say that like it's a catch phrase and then when we talk post voting they vote in incumbents. ¯\\ _ ( ツ ) _ / ¯ reply throwaway35777 18 hours agoparentprev> The biggest single reason why the USA's (and to a lesser extent Canada's) internet is shite... Speak for yourself, but I live on the west coast and my Internet connection is great. Edit: downvoters, what are the problems with U.S. internet? reply lxgr 16 hours agorootparentBoth experiences can be true in the same country. For me, internet is great (both wired and wireless). For wired, I have a choice of cable and FTTH in my apartment, both cancelable month-by-month and without any bullshit fees (\"taxes and surcharges\", yeah, believe it or not I also pay taxes and I don't make it your problem, ISP!) beyond the sticker price. No idea if this is due to competition, regulation, or both; I suspect that at least the \"no bullshit fees\" part is due to the latter, as I can't imagine major US corporations all somehow collectively dropping them in one region but not the other. I also don't doubt that it is significantly worse for somebody living elsewhere. Data caps seem to still be a thing for wired access in some places. reply KaiserPro 15 hours agorootparentprevHeres a little illustration. I used to work for a multinational company that had its main office in london and a number of satellite offices around the world. We wanted to install decent internet into everywhere so we could begin to manage our data in a more effective way. London: look for a good offer, phone up a few ISPs, get a quote, work out if we have spare capacity in the building (we did) boom, 1 gigabit install inside a month. Redwood city: 6 months. we had some sort of shitty T3 line installed as a stopgap. It never reached SLA. I had to phone the NOX, get a report. I then phoned the EMEA president of $large_International_network_provider to complain personally that I had to do the work of half his fucking company to get dailup++ installed. I left before they managed to get actual fibre into the building. Santa Monica: \"we cant install fibre as the previous engineer reported seeing eyes under the building\" Try and use a different company. Turns out that there is only that company in santa monica (Can't remember which) Ok, order an upgrade to what we already have. \"line is bad needs replacing\" cue me having to _fucking fly out_ and manage the fourth attempt at upgrading because the company are such useless fucking pricks. domestic wise I am in the suburbs, they've just rolled out fibre to the house. I have 900 meg down with 100(might be more) up for £50 a month. Thats the pricy version with a fixed ipv4 address. I can get a less fancy version for £30. reply lamontcg 15 hours agorootparentprev> Edit: downvoters, what are the problems with U.S. internet? once you get outside of truly major metro areas, internet access tends to go to shit. i've got 1G fiber internet in Seattle now, but in Everett ~25M shared access comcast is the best you can do in a lot of places. and it isn't like you need to be surrounded by cows and horses to have bad internet, you can have the boeing factory just down the road, but you're living in a ~100k population city as opposed to a tech hub. reply seattle_spring 18 hours agorootparentprevWhat's your Internet speed up and down, provider, and monthly cost? Actual monthly cost, not temporary promotions. reply JumpCrisscross 17 hours agorootparentI’m currently doing 6.3/9.1 with 81ms latency on AT&T. I’m seeing Europe averaging 48 Mbps [1], though my experience in Italy and the UK has been far spottier than in America. (Lot of people in this thread confusing home and mobile internet. I get 1Gb/35 for $65 at home, but that’s irrelevant.) [1] https://www.statista.com/statistics/689876/average-mobile-sp... reply ricardobeat 17 hours agorootparentThat average looks outdated, and includes a lot of rural and under-developed areas. It also varies a lot per country[1]. Most people in urban areas can get deals like 300-500Mbps forother countries roughly in the same range as the US. The same range of what variable? How do you measure/define this? reply mynameisvlad 16 hours agorootparentThere are several definitions for what makes a country “developed” and the US is solidly in all of them. https://en.m.wikipedia.org/wiki/Developed_country I’m not sure how you can possibly argue that the US is not “developed”. > The same range of what variable? How do you measure/define this? Feel free to take any of those lists and compare the US to countries around them in those lists. The countries might differ slightly, but the notion of what is a “developed” country has been firmly established for a long time now. reply umanwizard 16 hours agorootparent> I’m not sure how you can possibly argue that the US is not “developed”. The U.S. is considered developed only because it’s extremely rich. However, the general state of its infrastructure, education, governance, media, etc. is more typical of a developing country in many ways. That’s my point: all these lists of things the U.S. is worse at than every developed country are collectively what it means to be developed, more so in my mind than just being rich. reply trimethylpurine 16 hours agorootparentprevYou compare cities, since you need to include average income. reply trimethylpurine 16 hours agorootparentprevMy prices are much lower in the states than in my place in Italy right now. Service sucks here too. Anyway you're ignoring income. Seattle is around triple the median of France for example. You need to compare cities of similar size and income. reply throwaway35777 17 hours agorootparentprev> but you're still getting slower speeds for higher prices than you should And what is your solution to that? reply seattle_spring 17 hours agorootparentNot vote for politicians that are ardently anti-consumer and anti-infrastructure? We’re talking about what exists, not who you can call to upgrade your internet :/ reply Aspos 17 hours agorootparentprevWhat is great about paying $50 for such low bandwidth? reply SirensOfTitan 17 hours agorootparentprevSymmetrical 1G, Verizon, 60/month in NYC reply BobaFloutist 17 hours agorootparentprevThere's actually a couple of local providers that aren't bad, for example, https://www.sonic.com/. $40/month (if you don't rent a modem/eerio, which, why would you) for 10 gigs up and down, not to mention excellent customer service. But I will happily admit that they're a bit of an outlier and the offerings in much of the country are complete shit. reply teaearlgraycold 17 hours agorootparentprev$70/month for 10Gb/10Gb Actual speeds are more like 5/7. But I’m happy! reply f1shy 17 hours agorootparentIn the great Europe (Germany, Telekom) I pay 50 for 16MB/4MB… good deal! reply seattle_spring 17 hours agorootparentprevIn the US? Can you link to the promo page showing where others can obtain such a deal? Even if you deliver, surely you know that such a connection is an extreme, extreme outlier? reply tick_tock_tick 11 hours agorootparentThat's not really that rare in the USA though? Most decently sized cities have some form of fiber offering that will at-least give you a gig for $50 a month or so. reply teaearlgraycold 17 hours agorootparentprevCalifornia. I have multiple multi-gig fiber options available and they compete. https://www.sonic.com/residential/internet Looks like the prices must vary by location. They don’t have a price there. reply burnte 18 hours agoprevISPs are desperate to be part of the monetary exchange of services over their infrastructure, they've been trying to become more than \"dumb pipes\" for decades and virtually no one wants that. Imagine if the water company could charge you more for a glass of water than a toilet flush. reply Too 5 hours agoparentBad example, because drinking vs flushing water can have real differences in properties affecting their price, availability and quality. Just like QoS can be meaningful to differentiate low-latency vs high bandwidth. The problem starts when service level is is based on the service-provider, not the type content, when Spotify music is cheaper than Apple music, even though both are just music. A more accurate analogy would be if the cost was based on the brand of the faucet, or if electricity was charged differently for using your stove vs running your AC. Or if roads had a fast-lane to drive to Costco, while the rest share a jammed single lane. reply lsllc 18 hours agoparentprevWell they sort of do already — typically you pay less for water for irrigation (usually because sewerage is metered by water usage and obv if it goes on the lawn it’s not going down the drain). In places like Florida however irrigation water is reclaimed and not treated the same was as drinking water and has totally separate plumbing and metering (and pricing). reply loeg 18 hours agorootparentI'd push back on \"typically.\" In my municipality, they have no way of measuring water used for gardening / lawncare independently from drinking water. So it all gets billed to the same drinking water and sewage rate. reply toast0 17 hours agorootparentprev> Well they sort of do already — typically you pay less for water for irrigation (usually because sewerage is metered by water usage and obv if it goes on the lawn it’s not going down the drain). Aren't you paying more for your lawn water then? If your sewer bill is based on your water bill[1]: a gallon of water for drinking results in a bill for a gallon of sewage treatment, which you'll use. A gallon of water for irrigation results in a bill for a gallon of sewage treatment which you won't use. Caveats: maybe you pee on the lawn, probably you perspire, sewer pipes are leaky: some of your sewage escapes out, some of your irrigation water escapes in. [1] this is common, but I don't think anywhere close to universal; even ignoring lack of universal municipal water and lack of universal municipal sewage. Flatrate by connection size is also common. Approximately zero households have individual sewer meters, but some commercial/industrial customers may have them so they can be billed on actual usage. reply lsllc 11 hours agorootparentThere's a second meter that tracks the irrigation usage and that's how they subtract the sewer charges for irrigation. Of course you have to pay extra for the meter to be installed and there's often an additional \"standing charge\" for that extra meter in every bill, but it's usually since the sewer rates are quite high, it's worth doing. My municipality uses 75% of the water usage (minus the reading from the meter used for irrigation) as the basis for the sewer charge. reply sidewndr46 12 hours agorootparentprevThe number of places in Florida that do that is tiny. reply lsllc 11 hours agorootparentI suppose it depends, but it's pretty common to see signs saying \"Non-Potable Reclaimed Water used for Irrigation\" in and around housing developments, hotels, shopping and commercial areas as well as resorts and golf courses. According to this, Florida uses 820M gals of reclaimed water per day although this isn't all necessarily used for irrigation. https://floridadep.gov/water/domestic-wastewater/content/flo... reply Waterluvian 9 hours agorootparentprevSo you’re not using the sewer then? Isn’t that completely logical not to pay for it? reply cycomanic 17 hours agoparentprevI find it interesting how nobody blinks an eyelid at the massive profits raked in by companies like Google, Facebook etc. but as soon as the ISPs that create the infrastructure that makes all this happen (and innovate massively in the process) want some piece of the cake everyone cries foul. Now I actually strongly support net neutrality and maybe ISPs don't really need a piece of the cake, but it is still interesting how the online companies have captured most of the profits, but are also considered the good guys in his scenario. reply ninkendo 16 hours agorootparent> but as soon as the ISPs that create the infrastructure that makes all this happen (and innovate massively in the process) want some piece of the cake everyone cries foul I pay my ISP well over $100 a month for their service. Far more than I pay outright to Google or Meta or Apple. Why should they try to skim even more off the top? reply masklinn 17 hours agorootparentprev> are also considered the good guys in his scenario. You can have multiple bad guys. Just because one of them is the worse guy doesn't mean the other one is good. reply otterley 17 hours agorootparentprevThere’s a reason for that. Neither Google nor Facebook are infrastructure providers. Infrastructure is a different business, and, since it frequently has natural monopolies, we regulate it so to provide the greatest good for the public and maximize stability and functionality. Infrastructure is an enabling foundation for competitive enterprise. reply rsanek 17 hours agorootparenthow is gcp not infrastructure? reply otterley 16 hours agorootparentPublic infrastructure, like water, sewage, and electricity. I.e., utilities. Telecommunications is another. GCP is B2B; compute infrastructure isn’t generally consumed by the public as a whole. reply LordKeren 17 hours agorootparentprevMost people view ISPs as a utility provider, so it should be expected that people would be annoyed at the idea that they get to double dip in the profit. I pay my electric company (the ones that create the infrastructure to make an ISP possible and have massively innovated in the process) the same for kWh if it’s for a lightbulb or my work laptop reply mattnewton 12 hours agorootparentprevInfrastructure like that is a natural monopoly - I certainly would have an easier time switching from Google than I would Comcast, the latter would require me to move or put up with 90's era internet over copper lines. reply spacebanana7 16 hours agorootparentprevWhat innovations to ISPs make? I thought they largely just installed equipment from the same group of vendors. I’m genuinely curious if anyone knows of any. reply metaphor 12 hours agorootparentYou're staring right at it: 5G --> 3GPP --> ATIS[1] --> includes every major ISP in the US Equipment manufacturers are just one piece of a much, much bigger puzzle. Standards development towards at-scale adoption, global interoperability, etc. is just as important; consumers just see the end game of all that backend work, and to be quite frank, it's grossly underappreciated. [1] https://www.atis.org/overview/membership/members/ reply quickslowdown 15 hours agorootparentprevIt would probably be easier to root for the ISPs if they weren't a bunch of monopolistic assholes. I know that's the reason I personally root against them. reply Buttons840 17 hours agorootparentprevReminds me of how maintaining essential system like the banking systems are seen as cost centers and run on a tight budget, but if some young men make a webpage that barely works venture capitalists are tripping over themselves trying to shove millions into their hands. reply eknkc 17 hours agoparentprevI expected electricity grids to do that. Different prices for EV charging, for home use etc. reply acheron 16 hours agoparentprevHave they? You’d think after 30+ years of commercial ISPs they’d have actually done something by now if they were “trying”. reply blackeyeblitzar 18 hours agoprevWe need neutrality up and down the stack elsewhere too. I would consider hosting (including DNS, cloud infrastructure), financial services (banks, PayPal, stripe), and others as needing their version of net neutrality laws, where they cannot refuse customers or treat them differently or pick winners/losers or charge differently for different use cases. These are all utilities that are necessary to survive in today’s societies, and therefore they must be treated as if they were publicly run, through the power of regulations. reply whimsicalism 18 hours agoparentYou cannot mandate both neutrality and liability for things on the payment stack, it is too burdensome. Personally I would prefer neutrality over liability. reply blackeyeblitzar 18 hours agorootparentAgree, and I like the phrasing of neutrality over liability - captures this tradeoff well. reply Aurornis 17 hours agoparentprev> where they cannot refuse customers Having seen the degree to which spammers, scammers, and malicious hackers will abuse services to no end (often while carefully avoiding explicit violations of the law) I can assure you that you do not want this. Forcing every company to host everyone only sounds good in theory. reply blackeyeblitzar 13 hours agorootparentWe force power utilities and such to support all users. These companies can solve the problem and pay the costs. But if the laws for scammers aren’t adequate that’s a separate issue that should be solved on its own. reply Zigurd 17 hours agoprevI think the article gets network slicing wrong. Using network slicing instead of the traffic shaping that the mobile edge router probably supports is a strange idea. The showcase network slicing use case was public safety comms. Network slicing is AFAIK not much used because it clashes with roaming. The article describes network slicing as reserving spectrum for certain apps. That's not how it works. It reserves capacity. Still, zero-rating and traffic shaping should not be used to favor apps, especially not on a pay to play basis, for all the same net neutrality arguments as ever. reply _pigpen__ 12 hours agoparentSo surprised I had to scroll too far for this reply. I actually work for one of the major US carriers. My job is literally to figure out how to apply the technical capabilities of 5G to solve business problems. NONE of the US carriers have figured out how to actually deliver network slicing beyond, say, reserving capacity for first responders. And, as you say, it’s about capacity, not speed per se. We want to make sure that, say, an AGV can offload kinematics to the MEC and navigate in real time in dynamic environments. The poster child for network slicing is the surgeon doing telesurgery over a 5G network (But that’s likely to remain a poster child). We’re figuring out how to provide network slices for autonomous vehicles, mobile teleoperation, etc., in all use cases we’re examining it because something BAD could happen absent guaranteed capacity. I have never ever heard anyone talk about using network slicing for QoS for consumer apps. reply 310260 17 hours agoparentprevThis is correct. Slicing can offer significant performance gains in certain situations. For example, lower latency when certain users need it while not overburdening the network by having to give that to every user. reply apitman 16 hours agoprevMy experience with 5G is that it's strictly worse than LTE. At this point, if I see the 5G symbol on my phone I'm conditioned to expect the internet to barely work. Requests frequently seem to just hang. reply r00fus 15 hours agoparentAre you possibly on a 2nd-tier plan (like mine, I have grandfathered T-Mobile \"simple choice\" @ $10/line)? MNVOs like Mint, etc are also typically 2nd-tier. Telcos typically downrate 2nd-tier data, so if it's there's congestion, we feel it most. reply lxgr 16 hours agoparentprevThen something is definitely up with either your device or your local network base station(s). I used to have major problems with one network one particular street corner where data throughput would reliably drop to zero on 5G, but calls still went through somehow (even though they're also data on 5G, albeit with a different QoS). Signal strength was always shown as full. A phone restart would sometimes, but not always, fix it – without moving anywhere! Never happened again since switching away. 5G is a standard/protocol; it doesn't somehow inherently prevent bad network management. reply wreckdropibex 16 hours agoparentprevMy experience with 5G is that it's strictly better than LTE. At this point, if I see the 5G symbol, I'm conditioned to expect there to be 10-100x more bandwidth available than with LTE and latencies to be at levels at par with wired connections. reply pokstad 15 hours agoprevFast lanes are the biggest selling point of 5G due to limited backhaul bandwidth. Instead of eliminating fast lanes, force ISPs to provide access to fast lanes equally ( must issue, not may issue). reply alephnerd 16 hours agoprevHot take from rest of HN: I don't think lack of competition is the cause for the slow uptake in the US. Reliance Jio+Bharti Airtel, China Mobile+Telecom+Unicom, and NTT+KDDI are basically duo/triopolies yet were able to roll our 5G nationwide in just 2-4 years in India, China, and Japan while keeping competitive pricing, and make the US market look free in comparison. The issue seems to be the relative lethargy of the FCC and regulators, along with issues around deprecating older i",
    "originSummary": [
      "The FCC will vote on restoring net neutrality protections on April 25 to prevent ISPs from favoring select apps with fast lanes, including potential 5G fast lanes.",
      "Draft rules aim to allow mobile carriers to maintain video quality but could lead to certain apps having an unfair advantage, impacting user choice and competition.",
      "Proponents of net neutrality are pushing the FCC to define and ban fast lanes to protect smaller apps and startups from potential harm and uncertainty."
    ],
    "commentSummary": [
      "The article emphasizes the significance of net neutrality rules amidst concerns about unfair practices in the ISP sector, notably concerning 5G fast lanes.",
      "It delves into arguments surrounding competition, monopolies, governmental involvement, and the effects on consumer accessibility and pricing.",
      "Various viewpoints on net neutrality, ISP regulations, and market competitiveness are discussed, with global examples shedding light on the outcomes of enforcing or abolishing net neutrality laws."
    ],
    "points": 393,
    "commentCount": 268,
    "retryCount": 0,
    "time": 1713024550
  },
  {
    "id": 40028643,
    "title": "Remembering Ray Harrell: The Power of Quiet Impact",
    "originLink": "https://bittersoutherner.com/feature/2023/obituary-for-a-quiet-life",
    "originBody": "THE BITTER SOUTHERNER Stories Features Podcast About Newsletter General Store Stories/ Features Podcast About/ Newsletter/ General Store/ For the sake of the story. For the love of the South. Obituary for a Quiet Life A man passes away without a word in the mountains of North Carolina, and his grandson sets out to write about the importance of a seemingly unimportant life. Stories/ Features Podcast About/ Newsletter/ General Store/ A man passes away without a word in the mountains of North Carolina, and his grandson sets out to write about the importance of a seemingly unimportant life. Essay by Jeremy B. Jones June 6, 2023 My grandfather died this year, but you wouldn’t know it. In fact, he preferred you didn’t. Ray Harrell came up as the youngest of eight in the Cataloochee Valley in the 1930s — outrunning mountain lions and driving cattle off the mountain and crashing borrowed jeeps — and on January 20, nine decades later, he passed from this earth without a sound. That’s how he wanted it. You won’t find a headstone. Nobody gathered for a funeral. He was here, sitting on that porch he shared with his wife of nearly 70 years, and then he wasn’t. Dust to dust. I was driving home after a day of teaching when Grandma called me. The cancer slowly draining him of life for the past year had held him in bed that morning, and it seemed he would stay there for the rest of his life. “Would you write your papaw’s obituary?” she asked, ever practical even amid the loss of the love of her life. There was plenty to tell. He’d stolen a school bus as a teenager and backed it over a teacher’s car. He’d been shipped to Germany with the Army in 1950, where he flew up the ranks despite accidentally firing artillery through an empty house. He’d led the union at the textile mill where he worked most of his life. But he never talked much about any of that. What he set out to do was build a small life in Fruitland, North Carolina, to raise up his daughters and do the dishes and fix the broken garage door. He set out to live quietly — and then pass away just the same. When I sat down to write, I found myself dropping details into a template — son of, survived by. The obituary form puts a particular pressure on what matters, on what should be remembered and praised, but what does one say about a life that aimed to carry on in the background, that had no interest in a name in newsprint or an award on the mantel? Ray Harrell, son of Jim and Cora, was content to sit still and watch the breeze scatter the leaves? Ray Harrell, sergeant first class, arranged the bills in his wallet in descending order? Ray Harrell, survived by Grace, whistled the same invented tune year after year while searching for the right nail in the shed? I filled in the expected details and sent the obituary to the newspaper, but I knew it wasn’t right. It captured nothing of the life he lived. What I returned to in the days after he passed, as the ladies from church covered the table in casseroles and Grandma slept in a bed alone for the first time since she was 19, was the sheer audacity of a quiet life. Ray Harrell after a day driving a laundry truck. His bride, Grace, snapped the photo outside their first house. When the notable figures of our day pass away, they wind up on our screens, short clips documenting their achievements, talking heads discussing their influence. The quiet lives, though, pass on soundlessly in the background. And yet those are the lives in our skin, guiding us from breakfast to bed. They’re the lives that have made us, that keep the world turning. They’re taking out the trash before we notice and walking up the road to see if the mail’s come. They’re showing us how to lay out the biscuit dough at just the right thickness. They took our sons up on the tractor on spring afternoons. They helped the neighbor with the busted sink. They jumped in the river to pull an 18-month-old out. They caught the man who’d been pinned by the forklift, his back broken, and held him as he died. They slipped money into their nephew’s pocket when he hadn’t a penny to his name but was too ashamed to admit it. They did the laundry. They swept the floor. They played in the yard like a kid. They ate a pack of saltines and climbed into bed night after night until there were no more nights, only all the people left behind who’d carry on living because making a little life on a piece of land off Fruitland Road is about the holiest thing we can think of. All around us are these lives — heads down and arms open — that ignore the siren call of flashy American individualism, of bright lights and center stage. I’m fine right here is the response from the edge of the room, and that contentment is downright subversive. How could you want only that? the world demands. There’s more to have, always more. The newlyweds pose outside of Grace's childhood home in Fruitland, north carolina. The home stood across the road from where Ray and Grace built their house — and lives — together. What Ray Harrell had was a reliable tractor and a fiery woman. He had a pat of cornbread waiting at noon dinner and an RC Cola every night before bed. He had kids and grandkids and great-grandkids enough to fill the house every Christmas. And that was plenty. “We’ve had a good life,” he said to me nearly every time I visited in his final year, and I knew it to be true even if it might have seemed odd from a distance. On paper, this small life above Clear Creek should have left a long list of regrets, of what ifs. But this life was the life, the very thing he and my grandmother Grace set out to make when they married in the little church up the road in 1954. On those visits, I settled down with the cornbread and asked for stories. Over time, I collected histories I’d never known. I learned of the stolen school bus and the crashed jeeps and the cow he got stuck in the mud. I learned of Papaw winning big playing cards while stationed in Germany during the Korean War, and then taking his earnings and traveling all across Europe. I learned of him being fired — over and over — from the textile mill. “How come?” I asked. “Well, because I was aggravating, I guess.” That was right, mostly. He said no when no one wanted to hear it, rallied the union when the bosses didn’t want to see it. Like when they told him to climb 10 feet without a harness and swap out a roller by himself. “I told them I wasn’t a-gonna do it.” They fired him, the union lawyers stepped in, and he came back to work. “He’s a stubborn old man,” Grandma said. Maybe that was right, too, but as I pieced together these stories of seeing the world and fighting back against injustice, I realized that a quiet life isn’t a passive life. Sitting still on the porch doesn’t mean letting the world go by. He and Grandma took their camper across the country. He served as president of the union. Being content doesn’t mean being blind. It means knowing the difference between a good fight and a selfish one. “I believe in standing up for what is right,” he said between bites of corn. “And I oughtn’t say this, but everybody liked me.” “Why?” Grandma asked. “I wouldn’t have thought you’d have to ask that. I’m a good old boy.” The best time of his life was when his girls were little, Ray said as he neared the end. He and Grace raised two daughters: Joy (pictured left) and Debbie. What I’ll miss most is the sound of his voice, cooked up in the North Carolina mountains out of remnants from across an ocean. There always thar, fire always far. I loved the phrase ever which a’way but loose. Loved how things liked to happen. How hello was what do you say and how being still meant setting awhile. Even his voice was quiet, throaty and clipped in the way of men in these mountains — a voice meant for conversations beyond a crowd, meant for the group of men eyeing the door, aiming to be outside where it’d be easier to talk about nothing or just as soon not talk at all. He could go hours without saying a word, but a flash of wit always waited on his tongue. For nearly 70 years he kept up a constant, good-natured banter with Grandma over anything and everything. “I can’t rightly remember,” she said on one of my story-seeking visits. “You’re getting too old to remember all that, woman.” “I surely am.” “I know the feeling.” A month before he passed, faded and worn down to a wheelchair, his head still popped up when Grandma walked into the kitchen: “Hey thar, pretty girl.” The morning after Grandma called me, I took my boys by to see Papaw for the last time. He’d been unresponsive for a day, but when we entered the bedroom, he was awake again. He couldn’t find his voice — he’d been breathing through his mouth, and his throat was too dry to speak up — so I leaned in. He looked to my sons and said, “Hey, fellers.” They waved. “I love you,” I told him. “Love you, buddy,” he whispered. “You done good,” I said because that’s how he would’ve said it, but also because that’s how I meant it. He’d done so much good, even if it couldn’t be listed on official records or captured in the stat sheet of an obituary. The good of his life was ever-rippling water, quiet and steady, and my boys and I would long be swept up in it. Jeremy B. Jones is the author of the memoir Bearwallow, which won gold in the 2015 Independent Publisher Book Awards and was named the 2014 Appalachian Book of the Year in nonfiction. His essays appear in Oxford American, Garden & Gun, and Brevity, among others, and he serves as series co-editor of the book series In Place from West Virginia University Press. He teaches at Western Carolina University. More from BS Publishing Food Stories Peach Waffle House Vistas Subscribe to Our Newsletter Email Address Sign Up Thank you! FEATURES PRINT EDITION PODCAST GENERAL STORE FOODWAYS COCKTAILS PHOTO ESSAYS SPONSORED STORIES ABOUT US TEAM CONTACT NEWSLETTER MEDIA KIT CUSTOMER SERVICE PRIVACY POLICY SUBMISSIONS MEMBERSHIPS THE BITTER SOUTHERNER ©2023 ALL RIGHTS RESERVED.",
    "commentLink": "https://news.ycombinator.com/item?id=40028643",
    "commentBody": "Obituary for a Quiet Life (bittersoutherner.com)330 points by conanxin 6 hours agohidepastfavorite81 comments zorrolovsky 3 hours agoBeautiful writing. It comes at an interesting time for me. I'm in a full blown mid-life crisis where my state of mind fluctuates between full contentment and wishing I was doing more with life. This article made me think. On the one hand, I'm content because I come from an unprivileged background. My family was abusive. Me and my brothers struggled with mental health. We ran away from home as soon as we could. Where I was born there were not any decent jobs, so the future was bleak. Today, I have a decently-paid job in tech, good life/work balance, a nice clean house, and self-caring habits. I have a great mental and physical health, good relationships and a decent financial position. I traveled the world and had incredible experiences. I've got everything I dreamed about when I struggled mentally, physically and financially. On the other hand, achieving all my dreams took me to a place where my mind says \"I've done it all, let's just enjoy what I've got. Let's enjoy life\". And that works for a while but then one day I resent being too complacent. I want to do more. Launch projects, earn more money, live more experiences. The voice of ambition says: \"you're 45 years old, stop thinking like a 80 year old, move your ass and live more life\" Still working to find that fine balance between contentment and ambition. As a human I'm skeptic I will find the right answer. We tend to work in cycles/moods... reply cik 2 minutes agoparentI completely relate to this. At 41 years old, I met my life's goal, a goal I never thought I would attain (and it's not wealth). Rather than be empowering and celebratory, that turned out to be debilitating, taking me years, until I found a new path. I'm still starting down that path, but at least now I have a goal that will take me 20-25 more years. People will tell you to focus on you. People will tell you to focus on money. People will tell you to focus on neither. The reality is that what motivates you, gives you meaning, and continues to propel you might change. There's no right answer, and that's healthy. The process, I think is the important part, no matter how painful that may be. reply The_Colonel 2 hours agoparentprev> I want to do more. Launch projects, earn more money, live more experiences. The only thing you need is to stop this idea that living a richer life means earning/spending a lot of money / reaources. There's so much personal development you can do without participating in the materialistic rat race. reply dakiol 33 minutes agorootparent> There's so much personal development you can do without participating in the materialistic rat race. That takes money, although in a different form: time. I can only enjoy those experiences if I have time for them (and I’m not talking about enjoying them after working 8h during the day, because I end up exhausted and cannot enjoy anything at all). So, in order to enjoy things I need to work less, which means less money. That’s the price. It’s always money reply hereonout2 19 minutes agorootparentThis is true for almost all of us though? Nearly everyone has to work at least 5x 8 hour days a week - some much more. Some have complex family needs that must be attended to before any personal time can even be considered. There is always some time though, it just needs to be made and scheduled and worked on. We can choose to veg out in front of Netflix, or doom scroll, or peruse hacker news, but we can also choose to do something else possibly more fulfilling. Of course not as good as having more disposable money and fewer work commitments but painting it as an all or nothing situation feels very defeatist. reply goodpoint 23 minutes agorootparentprev> That takes money, although in a different form: time > That’s the price. It’s always money Tell that to unemployed people. To children. To retired people. To people with serious sickness. Time is not money. reply amarcheschi 2 hours agorootparentprevAs a young cs students where even the uni professors tell us there's more about it than just money, what would you say is something regarding personal development to do? reply elros 1 hour agorootparentLearning things for fun and not just for profit. Physical development, learning a new sport. Spiritual development, meditating, observing. Engaging in arts, creating, exploring. Helping the less fortunate, volunteering, teaching. Traveling, learning about different cultures, different languages. Cooking. Spending time in nature, watching animals, birds, mushrooms, sunsets. Photography. These are just some examples, the list is endless :-) Personally I’ve grown a lot from gardening and weightlifting. Having children made me more human. reply orthoxerox 1 hour agorootparentprevGet a hobby that you can do outdoors with other people. Hiking, hunting, paddling, sailing, bouldering, volunteering, playing sports, LARPing, reenacting... Embed yourself into the local community, become a pillar of it. Start a family and support your children, don't try to mould them into what you wish you could have been. reply sentfromrevolut 58 minutes agorootparentWhy not? Jos Verstappen molded Max Verstappen into being the man he wished he could have been and it's worked out great for them both. If I have a kid I will force him to become a football player. I think the key will be dopamine. He will only have a football to play with each day and no distractions like phone, books, computer, friends , etc. reply hereonout2 47 minutes agorootparentprevDuring my late 20s I realised I was very good at my programming job but not much use at anything else. It was quite a disappointing realisation. I started to do less and eventually no programming outside of office hours and instead invest my spare time in different hobbies and experiences. I found gaining these new skills really helped build my confidence. 15 years later I'm not just a programmer, I'm a also a motorcyclist, experienced carpenter, been a member of certain meet up groups for over a decade, travelled to a few exotic locations, flown upside down in a plane, the list goes on. None of these things are exceptional but doing this extra stuff has given me enough dimensions that I kind of feel comfortable with the way I've done the last 15 years. This along with starting a relationship and building a family is enough for me now. Sure, I could have done more but compared to the corporate quagmire of my 20s things are very different. reply xvilka 52 minutes agorootparentprevI would disagree. If you think only about yourself - yes, it's not about the money. But if you want make life of your children, grandchildren, etc better, the only answer is money, building generational wealth. reply soufron 31 minutes agorootparentAbsolutely not. Children and grandchildren are their own persons. The world is full of people who got rich through heritage and who live miserable lives - even when being materially fulfilled. I would add that this state of mind denotes a characteristic control anguish. When you're dead, you're dead. You need to let go. reply xvilka 22 minutes agorootparentOf course it doesn't guarantee the success, but it helps a lot. reply idiotsecant 2 minutes agorootparentVery nearly without exception children who come from backgrounds of generational wealth are terrible people, in my experience. ricardobeat 4 minutes agorootparentprevDepends on the definition of “success”. If it’s about raising good people, with decent values and a drive to make the world better, a fat inheritance is probably not a good predictor. famahar 2 hours agoparentprevHave you considered getting into art? I find art projects to be big motivator and fills me with ambition. The great thing is I do it for myself so I can feel content knowing I don't need to fulfill the needs of an audience. You can be ambitious as you want. Making concrete sculptures, woodworking,oil painting, restoring old furniture, developing a game (physical or digital), writing short stories, researching and writing a book or zine on a random niche subject. I find that making art fills that hole that exists when I'm not doing much in life. reply herodoturtle 1 hour agoparentprevThanks for sharing, and congratulations on your achievements (especially considering your beginnings). You and I are of similar age, and have a similar backstory, so if I may, I’d like to suggest the following: Help others. For me my midlife crisis was quickly eradicated when I turned my surplus time and resources to assisting the needy through volunteer work. I hope this resonates with you - it was a significantly positive turning point in my life, which gave me a great deal of perspective and gratitude. reply padraigf 1 hour agoparentprevI just got a new book on this subject: Midlife: A Philosophical Guide, by Kieran Setiya (https://www.amazon.co.uk/Midlife-Philosophical-Guide-Kieran-...). Not got too far into it, but I like it so far. reply goodpoint 21 minutes agoparentprev> Launch projects, earn more money, live more experiences. Pick one. The \"grind\" mindset about money for the sake of money is the opposite of personal growth. reply dzink 3 hours agoprevHe is not wrong. “If you can meet with Triumph and Disaster And treat those two impostors just the same” - R. Kipling Media riles up those who have been limited or deprived by circumstances. It waves flags and triggers emotions and creates envy and conjures social ladders to political influence, or financial gains, or popularity and public attention, or peaks of history. The reality though is that those apply to the people who don’t know better - the new grads, the hungry and ambitious, the midlife-crisis sufferers, the naive who haven’t encountered bad people or circumstances. If you’ve seen a lot or you know evil, you don’t need a public life where you may attract it. When you know what you have and value it, a quiet life is the best way to protect it. People value privacy when they have something to lose. If you know what you want to do and can do it without attention, you are much better off doing than dealing with collateral damage from unpredictable attention. The media today is becoming incredibly propaganda filled and charged. This is a highly combustible environment. Big geopolitical risks are coming and publicity risks making you a target. When low interest rates paid for VC-subsidized press the world was filled with startup success stories and drums up for startups and their potential gains. That meant many promising entrepreneurs took money at unsustainable expected ROI and lost years of their life working for a promise. Another word for that is lottery. When the dust settled having a quiet business and chugging along profitably proved to be like the little mice who survived underground after the asteroid hit. If you are a cat who just caught a mouse, would you go to a hill to advertise to all local predators that you are about to enjoy fresh meat? reply wuj 2 hours agoparent> If you know what you want to do and can do it without attention, you are much better off doing than dealing with collateral damage from unpredictable attention. To achieve this state where one can operative effectively without external validation often requires them to initially engage with the public sphere. This exposure is important to getting opportunities, especially when starting out with no resources. The purpose of working is to be able to transcend this phase and do more autonomous and focused work... reply p1esk 3 hours agoparentprevI don’t know, try to explain your point of view to people like Trump or Musk. reply flakeoil 2 hours agorootparentMaybe the world would have been a better and friendlier place if the two people you mentioned, and others like them, had an attitude a bit more muted and humble. reply kunley 2 hours agorootparentprevBut what for? People like them are not a point of reference to relate everything, you know reply forgetfreeman 2 hours agorootparentprevIt'd be easier to explain Shakespeare to a fish. Sociopaths aren't generally much for outside counsel. reply ttiurani 3 hours agoprev> All around us are these lives — heads down and arms open — that ignore the siren call of flashy American individualism, of bright lights and center stage. I’m fine right here is the response from the edge of the room, and that contentment is downright subversive. How could you want only that? the world demands. There’s more to have, always more. Beautiful writing, and I feel this part especially elevates it. Going forward, we collectively need to recognize and celebrate these people who know when they have enough for a good life. Who can stop craving more fame, wealth and possession, and just appreciate what they have. Because only by doing so, can we leave enough resources for others, near or far, now and in the future, to have the same. reply bigstrat2003 3 hours agoparentThat part caught my attention as well. There's a danger in the seductive whisper of \"you need more\". Whether it's material goods, power, fame, or whatever else, pursuing external things like these is a hole which can never be filled. It seems to me that true happiness is to be found inward. If you can learn to find happiness where you are right now, then you can have a good life regardless of your external circumstances. I had two really powerful insights when I was a teenager. The first was when I got a Christmas gift I really wanted (a walkman iirc), and it struck me that actually having it didn't fulfill me nearly as much as I had thought it would. The other was when my grandpa died, and I would have given anything to have him back (and I still would). These two experiences made me realize that stuff is hollow and unimportant, and what truly matters in this world are people. Being with the people you love is the greatest thing we can have, and unlike material possessions can never be replaced once it's gone. I think that a simple life is far underrated. If all I ever do is spend time with my family and friends, and make the world around me just a bit better in some small way, I feel like that's enough. reply taco-hands 1 hour agoparentprevThis made me think of Ralph Waldo Emerson's poem \"What is success\": To laugh often and much; To win the respect of intelligent people and the affection of children; To earn the approbation of honest critics and endure the betrayal of false friends; To appreciate beauty; To find the best in others; To give of one's self; To leave the world a bit better, whether by a healthy child, a garden patch, or a redeemed social condition; To have played and laughed with enthusiasm and sung with exultation; To know even one life has breathed easier because you have lived - This is to have succeeded. reply miramba 12 minutes agorootparentThat was beautiful and inspiring. reply GeoAtreides 2 hours agoparentprev> the world demands. There’s more to have, always more. is it really the world? or is it the ad industry? the social media algorithms? bet if we shutdown the ad industry and accept only sorted by date for social media the world will quiet down tremendously reply kmarc 39 minutes agorootparentDunno, I don't use social media, neither see ads (adblock), but the older I get, the more I want to explore, learn about history, travel to places. I agree with the sentiment (social media / ad algorithms influencing the... influenceables), but I have also met people who are outside these bubbles. Granted they are the bit older folks, pre-smarthpone people, mostly retirees. reply zilti 2 hours agorootparentprevIt wasn't really that different in that regard before social media, you know. reply GeoAtreides 2 hours agorootparentThe uptick in teenage self-harm and suicides says otherwise. Of course it was different, people in 1940 and 1950 were not doomscrolling endlessly throughout the day while algorithms enmeshed them in self-contained bubbles and bombard them with personalized ads, no, they were listening to radio, read newspapers, talked in person more. Social media is a new and never seen before phenomenon, with its own advantages and disadvantages. reply mtlguitarist 1 hour agorootparentI think there's a bif citation needed on whether social media influences anxiety and depression in younger people. It's a nice scapegoat, but the world is harder and more competitive than it's ever been. I can't work in a textile mill and become a union president and support a family. The job doesn't exist anymore, and even if it did it wouldn't pay enough to achieve those coveted milestones of a \"quiet life.\" reply szundi 26 minutes agorootparentprevThere can be other reasons too coinciding in time. reply alfagre 3 hours agoparentprev> Going forward, we collectively need to recognize and celebrate these people who know when they have enough for a good life. I see where you are coming from, but that's exactly missing the point. The article is about somebody who wouldn't have wanted to be celebrated by you. Who just wanted to live his life, out of the spotlight. By elevating him and his live to celebration status, that's the oppposite of what he would have wanted. Recognize, sure. A nod in passing, then move on. reply ttiurani 2 hours agorootparentIndeed, this is a vexing problem. Role models influence so much of peoples' behavior, that I fear they are needed to change what is considered success. But the people suited to be role models rarely want to be. I don't know the answer, but hope some of these kinds of people would allow themselves to be (reluctantly) also celebrated. reply jddj 2 hours agorootparentprevTelling though, isn't it. The collective addiction to celebrity shows up even in a context like this one. reply grecht 4 hours agoprevVery moving. Often, this is called a \"quiet, simple life\". I like that this obituary does not do that. Being there for your family, acting in accordance with your values and standing up for yourself, being content with what you have - this is not \"simple\" at all. Someone to look up to. reply threatofrain 3 hours agoparentWhat you describe is simple, especially in a wealthy nation during peace. What doesn't sound so simple was leading union politics or rapidly rising through the ranks while deployed abroad. This person was certainly not quiet. reply gatinsama 1 hour agorootparentSimple, not easy reply epicureanideal 3 hours agoprev“ after a day driving a laundry truck. His bride, Grace, snapped the photo outside their first house.” Driving a laundry truck.. first house.. Life was so much better a few decades ago. reply tossandthrow 7 minutes agoparentdet think you'd be able to drive a truck and buy your first house today also. No, that house is not going to be in Palo alto, and it is not going to be newly renovated. His house probably wasn't either. i think this sentiment stems from an at core inflated expectation to life. I know of plenty of out if the city places where housing prices hasn't changed over the previous 15 years and where you probably would be able to find subsistence to pay you mortgage and get food on the table. reply dewey 3 hours agoparentprevBut then, he also had to serve in war. Medical care was not that advanced, you couldn't read about any niche topic you want online. Easy to see things through rose tinted glasses. reply onion2k 2 hours agorootparentI wonder how many people would happily trade access to the web for a world where a laundry truck driver can afford a house. I imagine it's quite a lot. reply jimnotgym 3 hours agorootparentprevHe had to serve in Germany during the Korean war. Still he got called up and posted away from his home, so you still have a point. I think it was people born in 1950 that had it easier, especially in the UK, since we didn't go to Vietnam. reply MenhirMike 2 hours agorootparentIn the US, the people that were born in the 1950s got to spend their teenage years not knowing if the Soviet Union is going to start World War III (the Cuban Missile Crisis in 1962 was definitely a forming event for many teenage minds), then got to go through the 70s with an energy crisis and the potential draft to Vietnam, and then another energy crisis, and then got to experience the Chernobyl disaster in the 80s, wondering if they should re-watch \"Duck and cover\" and wonder why that hole in the ozone layer gets bigger and bigger. Every generation has its ups and downs. For my generation, I have to deal with sky-high real estate prices, but I also have access to an unprecedented amount of free entertainment, free knowledge, the cheap supercomputer in my pocket allows me to stay in touch with anyone that I want, and when I go to the doctor, I probably won't see people in iron lungs anymore. I can travel to anywhere in the world for ridiculously low prices, and if I don't speak the language, a live translation app will do the work for me. No, it's not all sunshine and roses, and people are right to call out issues with the current state of the world because things are NOT alright. But it's not like things were sunshine and roses for our grandparents generation either. reply tossandthrow 11 minutes agorootparentthe point is that what you see as the roses and sunshine of your generation is increasingly seen as the \"missile crisis\" of our generation. on top of that you have skyrocketing real estate prices. reply twojobsoneboss 2 hours agoparentprevNear Fruitland NC for 365k. Not too bad at all https://redf.in/tmYs3p reply listenallyall 2 hours agoparentprevGiven the age and location of that house, are you confident it had indoor plumbing? reply Aloha 4 hours agoprevBeing content is like a drug. The fire reduces, but does go out, you feel warmth in the familiar rather than the new, and you find yourself beset, wondering whatever you did to deserve this joy. I hope to sone day some can say the same about me. reply davideous 3 hours agoparentThe Bible speaks about this: “But godliness with contentment is great gain, for we brought nothing into the world, and we cannot take anything out of the world. But if we have food and clothing, with these we will be content. But those who desire to be rich fall into temptation, into a snare, into many senseless and harmful desires that plunge people into ruin and destruction. For the love of money is a root of all kinds of evils. It is through this craving that some have wandered away from the faith and pierced themselves with many pangs.” — 1 Timothy 6:6-10 ESV reply GeoAtreides 2 hours agorootparentHere is the King James version, which I find it much more beautiful (from a literary point of view): But godliness with contentment is great gain. For we brought nothing into this world, and it is certain we can carry nothing out. And having food and raiment let us be therewith content. But they that will be rich fall into temptation and a snare, and into many foolish and hurtful lusts, which drown men in destruction and perdition. For the love of money is the root of all evil: which while some coveted after, they have erred from the faith, and pierced themselves through with many sorrows. reply derriz 2 hours agorootparentMaybe but it makes much less sense to me. The meaning of “the love of money is the root of all kinds of evil” is very different to “the love of money is the root of all evil”. The former seems like a reasonable claim. The latter is surely untrue? I know of lots of evil acts NOT motivated by money or the love of money. reply davideous 29 minutes agorootparentHere are a few key paragraphs from a sermon that has the most compelling explanation of that sentence that I've heard: > When Paul said in 1 Timothy 6:10, “The love of money is the root of all evils,” what did he mean? He didn’t mean that there’s a connection between every sinful attitude and money — that money is always in your mind when you sin. I think he meant that all the evils in the world come from a certain kind of heart, namely, the kind of heart that loves money. > Now what does it mean to love money? It doesn’t mean to admire the green paper or the brown coins. To know what it means to love money, you have to ask: What is money? I would answer that question like this: Money is simply a symbol that stands for human resources. Money stands for what you can get from man, not from God! (“Everyone who thirsts, come to the waters. He who has no money come buy and eat!” Isaiah 55:1.) Money is the currency of human resources. > So the heart that loves money is a heart that pins its hopes, and pursues its pleasures, and puts its trust in what human resources can offer. So the love of money is virtually the same as faith in money — belief (trust, confidence, assurance) that money will meet your needs and make you happy. > Therefore the love of money, or belief in money, is the flip side of unbelief in the promises of God. Just like Jesus said in Matthew 6:24 — you cannot serve God and money. You can’t trust or believe in God and money. Belief in one is unbelief in the other. A heart that loves money — banks on money for happiness, believes in money — is at the same time not banking on the promises of God for happiness. > So when Paul says that the love of money is the root of all evils, he implies that unbelief in the promises of God is the taproot of every sinful attitude in our heart. From: https://www.desiringgod.org/messages/battling-unbelief-at-be... reply GeoAtreides 2 hours agorootparentprevIf you're looking for clear, unambiguous moral guidance, then sure, you have a point. For me it's more about how it sounds, the poetry of it all, and less about guiding my life, my spiritual life or my morality. reply ako 2 hours agorootparentprevPlease don’t do this, there are many people and stories that speak to this. Now it looks like you’re claiming this for one particular religion, when it’s completely unrelated to religion. reply rramadass 1 hour agorootparentYour comment is downright petty and silly. Wisdom/Insight/Life Advice wherever it comes from is always valuable. It is up to you to tease out the kernel of knowledge from the chaff of religiosity. I am no Christian, but i found Robert Alter's The Wisdom Books: Job, Proverbs, and Ecclesiastes quite interesting and would advice you to a study of the same. reply ossyrial 1 hour agorootparentprevHe is sharing a quote from a religious book, it makes sense to cite it, no? If they quoted the Qur'an, a Buddhist Sutra, a piece by Kahlil Gibran, or a quote by Adam Smith, I would all expect a citation to be honest. A few comments around we see a quote by Rick Roderick, and one by the Beatles. I don't see why this is fundamentally different and deserves critique. reply vouwfietsman 9 minutes agorootparentQuoting a religious/ideologist book is inherently different to quoting an individual author or a non-religious/spiritual text, because the act of quoting itself is part of a tradition of (in this case evangelical) propagation of the religion/ideology. We can pretend to see contemporary bible-quoting as a secular thing, but in these cases history matters. For instance, in the above quote in the part \"It is through this craving that some have wandered away from the faith and pierced themselves with many pangs.\" it is obvious that the quoted passage goes beyond a non-religious moral text and veers into religious moral judgement. Furthermore, quoting a passage does not isolate you from the whole of the work, as you would probably take offense to me quoting WWII dictators even if the quote makes sense for the topic in isolation. What I'm saying is all quite obvious and on the nose behavior by religious (or ideologist) people, who absolutely view quoting as a religious/ideologist act as described above. reply pbourke 2 hours agorootparentprevThis text sits at the wellspring of Western culture, such as it is. You don't need to accept any metaphysical claims that it makes in order to appreciate its wisdom. reply acidioxide 2 hours agorootparentprevThere is nothing wrong with drawing on the values that a text carries without necessarily agreeing with it in its entirety. This quote captures the point of the post above quite well. reply zilti 2 hours agorootparentprevYou should work on your very warped perception. reply monero-xmr 3 hours agoparentprevBeing content is not about lack of goals or striving. It’s about enjoying the journey, appreciating what you have, being OK psychologically even if your grand plans don’t come to fruition. I am always working towards multiple goals in parallel, from short to long to ultra long term. But the cadence of regular life - the routines we do daily and weekly and yearly - are the things that sustain existence. My children, wife, extended family, friends, acquaintances, the holidays, the laughs and stories and memories. I like exercising, I like coffee, I like learning. I can make all the money in the world but the real mass of life is not changed, and money is unnecessary to live a fulfilling life. reply happytiger 4 hours agoprevThis is beautiful. Thank you. I think people don’t understand how important just being there for your family actually is. Sometimes it’s enough just to be reliable, stand for good and just be present. Sounds like he really knew it. reply nonrandomstring 4 hours agoparentA Rick Roderick quote comes to mind; \"\" Now, I hate the movie The Big Chill, let me make that clear, and I hope I can’t be sued for hating a movie, I hate The Big Chill, because it’s about members of my generation, all of whom have become swine. The only person in the movie I like is dead when the movie starts, and they are having his funeral, and the old preacher says something quite profound. He asks the crowd of young yuppies, he goes \"Isn’t our common life together and just being a good man enough to sustain us anymore?\" And the answer to that is 'No, it’s not'. \"\" reply fbdab103 4 hours agoprev>He’d stolen a school bus as a teenager and backed it over a teacher’s car. \"Boys will be boys\" definitely got a lot more mileage than I had previously thought. reply Aeolun 47 minutes agoprevI feel like this is the truth for the vast majority of people? Nobody I know is out to do more than live their lives as best they can, and then pass away quietly and contendedly. In between there’s a ton of challenges. Many more than I’d ever have expected growing up or only looking at Facebook, but everyone makes it work. reply ornornor 3 hours agoprevNice read, thank you. > Ray Harrell after a day driving a laundry truck. His bride, Grace, snapped the photo outside their first house. Ah the days when you could be a delivery truck driver and buy a house… Not so much for us anymore. reply twojobsoneboss 2 hours agoparentNear Fruitland NC for 365k. Not too bad at all https://redf.in/tmYs3p reply orthoxerox 1 hour agoparentprevYou could still buy one if they still built 70m2 houses: 9m2 kitchen 15m2 sitting room 39m2 bedrooms 24m2 bathrooms 6m2 mud room 5m2 of various storage But why buy/build one if mortgages are cheap? reply alfagre 3 hours agoparentprevNot in central SF, no. But in the rural midwest you definitely can. Just like that dude. reply fallous 3 hours agoprevThere is an admirable maturity and wisdom in understanding the scope of your life and what is important, and working to make the world as you wish it to be within those confines. Too often we aggrandize ourselves by spending time worrying about the problems of the world far beyond our control and do not try and address them in the realms in which we do have some sway. reply notincel 2 hours agoprevThis is nice story. That said, I feel like the people praising \"the quiet life\" are missing that this man found a companion at ~20yrs old and with that companion had a family and kids and grand kids. Plenty of people never find that anchor/base/partner https://www.pewresearch.org/social-trends/2021/10/05/rising-... It's arguably easy to be content when you have good support around you. Bad or no support and it's much harder. reply cryptozeus 4 hours agoprevA month before he passed, faded and worn down to a wheelchair, his head still popped up when Grandma walked into the kitchen: “Hey thar, pretty girl.”Quiet Life > stolen a school bus reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The obituary honors Ray Harrell, a man from North Carolina, who led a quiet yet influential life according to his grandson.",
      "Ray Harrell, though low-key, was known for his strong sense of justice and advocacy for righteousness.",
      "The essay highlights the significance of unassuming individuals like Ray Harrell, whose impactful contributions often go unrecognized but profoundly touch others' lives."
    ],
    "commentSummary": [
      "The article delves into the conflict between contentment and ambition amid mid-life crises, stressing personal growth and finding a harmony between the two.",
      "It suggests engaging in hobbies and aiding others as paths toward fulfillment, underscoring the significance of inner joy, meaningful connections, and leading a straightforward, influential life.",
      "Referencing biblical passages and contrasting generational viewpoints on success and satisfaction, the piece advocates acknowledging and honoring individuals content with achieving \"enough\" for a fulfilling life."
    ],
    "points": 334,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1713068678
  },
  {
    "id": 40025339,
    "title": "Inflation Unveiled: Experts Claim 18% in 2022 Excluding Interest Costs",
    "originLink": "https://www.forbes.com/sites/theapothecary/2024/03/23/summers-inflation-reached-18-in-2022-using-the-governments-previous-formula/",
    "originBody": "FORBESBUSINESSPOLICY EDITORS' PICK Summers: Inflation Reached 18% In 2022 Using The Government’s Previous Formula Avik Roy Forbes Staff The Apothecary Contributor Group Follow Click to save this article. You'll be asked to sign into your Forbes account. Got it Former National Economic Council Director Lawrence Summers is pictured before President Barack Obama and Vice President Joe Biden spoke about Middle Class Working Families Task Force, Friday, Jan. 30, 2009, in the East Room of the White House in Washington. (AP Photo/Charles Dharapak) COPYRIGHT 2009 AP. ALL RIGHTS RESERVED. THIS MATERIAL MAY NOT BE PUBLISHED, BROADCAST, REWRITTEN OR REDISTRIBUTED. Numerous commentators—especially those defending President Biden’s economic record—have puzzled over why Americans are sour about the state of the U.S. economy. Unemployment rates have returned to pre-pandemic lows, commentators correctly point out, and the official rate of inflation is declining. So why are Americans ignoring the view of many experts that the economy is doing well? According to a striking new paper by a group of economists from Harvard and the International Monetary Fund, headlined by former Treasury Secretary Larry Summers, the answer is that Americans have figured out something that the experts have ignored: that rising interest rates are as much a part of inflation as the rising price of ordinary goods. “Concerns over borrowing costs, which have historically tracked the cost of money, are at their highest levels” since the early 1980s, they write. “Alternative measures of inflation that include borrowing costs” account for most of the gap between the experts’ rosy pictures and Americans’ skeptical assessment. Inflation is not an objective number, but a judgment call At the heart of the issue is a misconception that bedevils academics, journalists, and ordinary Americans: the idea that the official inflation rate is an objective number, impervious to human biases, much in the way that someone’s height or weight can be objectively measured with a ruler and a scale. In fact, the formula used to calculate the inflation rate is subjective. It requires economists to make hundreds of judgment calls about how one assesses the overall trajectory of prices. What goods and services should be included in the “basket” of prices in the formula? How should those goods and services be weighted against each other? How do we account for the fact that poor people consume different things than rich people, or that people in different parts of the country may consume different things in different proportions? And, most relevant to the new research: What is the best way to measure changes in the price of important things like housing? There has always been considerable debate about this. The most widely used measure of inflation in the U.S. is the Consumer Price Index for All Urban Consumers, or CPI-U, which is put out by the U.S. Bureau of Labor Statistics (BLS). This formula has undergone numerous revisions from its creation in 1919 to the present day. Consumer prices no longer include the price of money Most notably, as Summers and his coauthors Marijn Bolhuis, Judd Cramer, and Karl Schulz point out, in 1983 the BLS eliminated interest costs from its calculations of consumer price inflation. The argument at the time, made by BLS economist Robert Gillingham, was that including home mortgage interest rates in the CPI formula was overstating inflation. Instead, Gillingham argued, the BLS should estimate what homeowners could charge if they rented out their homes, and use that to calculate housing inflation. This change had a huge impact on the calculation of CPI, write Bolhuis et al., because the BLS removed housing prices and financing costs from the official CPI formula, even though everyday Americans still experienced those costs in the real world. “Owners’ equivalent rent”—the new CPI measure—amounts to over a quarter of the Consumer Price Index today. Bolhuis et al. point out that the elimination of interest costs from CPI isn’t just about housing. “New and used vehicles combine to represent nearly 7 percent of the CPI,” they point out, but “exclude financing costs.” Given that four-fifths of all new cars were purchased using auto loans, this makes no sense. Furthermore, more people buy consumer goods with credit cards than with cash—and yet the interest costs of credit cards aren’t included in the official BLS formula. “Measurements of the cost of living that exclude financing costs,” Bolhuis et al. argue, “will understate the pressure under which consumers, who rely on credit for many purchases, have found themselves.” Inclusive of interest costs, inflation reached 18% in November 2022, and remains elevated. NBER.ORG What would inflation look like under the pre-1983 formula? Bolhuis et al. then went on to see if they could recalculate the official CPI numbers using a pre-1983-like formula that incorporated the cost of mortgage interest, auto loan interest, and credit card interest on the cost of living. They found three things: first, that the pre-1983-like formula led to a dramatically different estimate of inflation in 2022 and 2023, peaking at 18 percent in November 2022. Second, they found that consumer sentiment—as measured by the widely-used University of Michigan Index of Consumer Sentiment—correlated much more strongly with the pre-1983 CPI formula than it did with the modern one that excludes interest costs. Third, they found these differences to be also true in Europe: higher interest rates were correlated with lower consumer sentiment, and vice versa. This was an important finding, as some have suggested that the gap between American consumer sentiment and the official government statistics is a result of Americans’ mistrust of institutions and mainstream sources of information. “We find little evidence that the United States, despite its rising partisanship, social distrust, and large reported levels of overall ‘referred pain’ differ meaningfully” in their economic perceptions from those in peer nations. “Consumers are including the cost of money in their perspective on their economic well-being, while economists are not,” the authors conclude. Since home and auto purchases “are integral to American consumers’ sense of their economic well being but their price is not included in official inflation measures, it is no wonder that sentiment lags traditional measures of economic performance.” The gap between CPI and the pre-1983 formula could widen over time There are other obvious problems with relying on the declining rate of official CPI inflation to gauge what consumers should be feeling. Inflation is cumulative; a decline in the rate of inflation does not reverse the price increases from previous years; it simply means that prices are now rising at a slower rate. Most importantly, the exclusion of interest costs from the CPI and the Federal Reserve’s preferred measure of Personal Consumption Expenditures could become a growing problem over time, due to the ever-expanding federal debt. As the debt increases, the federal government has to borrow more money from U.S. and foreign investors. But as would-be lenders to the U.S. see America as increasingly insolvent, investors will demand higher interest rates to lend us that money. Higher rates of government borrowing lead to higher rates for home mortgages, credit cards, student loans, car loans, and every other form of borrowing. And, as we’ve seen, these higher interest rates lead to higher price inflation, whether or not the Bureau of Labor Statistics recognizes it as such. In recent years, the Federal Reserve has suppressed these higher interest rates by printing new dollars out of thin air to lend to the U.S. government. But printing new money can also cause inflation, by decreasing the purchasing power of each preexisting dollar in circulation. We need a healthier debate on how to measure consumer price inflation Those who believe in the primacy of experts have long attacked those who question the accuracy of the BLS’ inflation measures. Balaji Srinivasan, the venture capitalist and entrepreneur, was criticized by mainstream commentators for investing in Truflation, an attempt at independently developing a measure of inflation using real-time price data from a variety of sources. But whether one likes or dislikes Truflation’s methodology, we should be encouraging independent thinking on how best to measure prices in the economy. As the IMF-Harvard analysis shows, the Bureau of Labor Statistics is capable of making misjudgments. My colleagues Jackson Mejia and Jon Hartley at the Foundation for Research on Equal Opportunity have shown that even relatively low rates of inflation disproportionately harm the poor, because the poor lack the financial wherewithal to absorb higher consumer prices. It’s important—and healthy—for us to look at different measures of consumer prices. Everyone has a stake in the outcome, especially those who live paycheck to paycheck. Follow me on Twitter or LinkedIn. Check out my website or some of my other work here. Send me a secure tip. Avik Roy Follow I am Forbes' Policy Editor, and president of a non-partisan think tank, the Foundation for Research on Equal Opportunity (FREOPP.org), which focuses on expanding economic opportunity to those who least ... Read More Editorial Standards Print Reprints & Permissions",
    "commentLink": "https://news.ycombinator.com/item?id=40025339",
    "commentBody": "Summers: Inflation Reached 18% in 2022 Using the Government's Previous Formula (forbes.com/sites/theapothecary)285 points by robertn702 15 hours agohidepastfavorite276 comments tonymet 14 hours agoI recommend people use many different indicators to get a mental model of inflation, and you will notice that CPI does not represent inflation well. The memes of Arby’s 5 for $5 becoming 4 for $10 are more informative than the CPI numbers. Don’t let the shock at the grocery store wear off – it’s real and painful despite what the news tells you. True inflation would measure the amount of prosperity achieved per hour worked. Take 1963 as an Example. Sears sold entire two story home kits with all materials for $1600. An Italian rifle in 1963 was $20. McDonalds burgers were 15¢ . Postage was 5¢ and had only increased 5 times in the previous 100 years. You might retort that average household income is $70000 now vs $6200 in the early 60s– a tremendous boon. Remember in 1963 only the man was working, and typically supported 4 kids, a wife and often parents in the home. In other words you had 1 man working 50 hours a week afford a house and support 5-6 other people. Today you have 2 people working 100 hours a week to support 1-2 additional people , while living in an apartment and living in a run down and crime infested neighborhood. In case you think this is academic, look at the occupations for those who lived in today’s wealthiest neighborhoods. Today Palo Alto, Menlo Park, and other super zips are exclusively $500k incomes and up. In the 1960 census records you will find these good neighborhoods occupied with plumbers, painters and other blue collar workers. My point is that inflation isn’t abstract and it isn’t a law of nature. It’s a deliberate approach to stealing your prosperity while you cheer it on. Summers is right more than he’s wrong. Real inflation has always been higher than the bogus CPI numbers, and the past 5 years it’s been accelerating. reply woodruffw 13 hours agoparent> Remember in 1963 only the man was working, and typically supported 4 kids, a wife and often parents in the home. This is a ridiculous exaggeration: the average US household was 3.7 people in the 1960s, not over 6[1]. There are good reasons to hold politicians to task for recent abnormally high inflation. But this comment is more of an atavistic fever dream of the past than an expression of those reasons. Edit: another source puts it at 3.3[2]. [1]: https://www.statista.com/statistics/183657/average-size-of-a... [2]: https://www.statista.com/statistics/183648/average-size-of-h... reply TeMPOraL 3 hours agorootparentThat's missing forest for the trees. The more important part is that average 3.7 people household was a single-income one. I would rather disagree with GP's: > My point is that inflation isn’t abstract and it isn’t a law of nature. It’s a deliberate approach to stealing your prosperity while you cheer it on. A lot of the inflation, including how suddenly a single-income household isn't a viable option for most people in the West, is market working as intended - quickly consuming any surplus money, should it suddenly become greater than 0 on average, and slowly eating into any value that isn't bare-minimum strictly necessary to move a product. reply fireflash38 1 minute agorootparentI think people are asking the wrong questions when it comes to inflation. It's not which president is at fault... It's who is profiting from it? It's not the minimum wage worker. It's not the standard office worker. What class has shown absolutely insane growth in wealth and income in the face of what looks like crippling inflation? reply michaelt 1 hour agorootparentprev> That's missing forest for the trees. However, when a person is making a post saying \"don't trust those dodgy manipulated numbers\" and offering alternative numbers, their post is a lot less convincing if their numbers are also dodgy reply 4death4 9 hours agorootparentprevThe average household also includes empty nesters and people who have moved out yet haven't started a family yet. The average number of children per family in the 60s was 2.3, which means quite a few families had 3 or 4 children. reply ta1243 2 hours agorootparentFar more divorced now too, so more demand on housing, and more people want to live in cities than in the 1960s, leading to even more demand. It all comes down to the cost of housing, at least in the UK where housing has been ridiculous for over 20 years. That housing is driven up to soak all available income by artificially constrained supply. All available income has increased on a household basis because of egalitarian reasons -- more women work now, which means that more women have to work now. The excess income is lost to housing costs. reply bugbuddy 9 hours agorootparentprevAccording to our experience of the last 7 years, we should expect interest rate cuts, tax cuts, and more fiscal expansion either at the same time or in some sequence. Each of them will help solve our problem. There is no fiscal conservative left in America. reply voisin 7 hours agorootparent> There is no fiscal conservative left in America. Truer words have never been spoken. Fiscal conservatism died with Reagan. reply unyttigfjelltol 2 minutes agorootparentFiscal conservatism died with fiat and John Maynard Keynes' \"In the long run we are all dead.\" sanp 6 hours agorootparentprevYes, Reagan the fiscal conservative who tripled the deficit and national debt: https://www.pbs.org/wgbh/commandingheights/shared/minitext/e... reply imtringued 2 hours agorootparentGreek austerity imposed by Germans had resulted in the doubling of debt as percentage of GDP. reply Rinzler89 16 minutes agorootparentWhich Germans imposed Greek austerity? AFAIK Greek austerity was imposed by Greece's major creditors, but Germany was only one of many. reply MisterBastahrd 6 hours agorootparentprevIn what way was Reagan a fiscal conservative other than making the poor targets for pain? He destroyed half the social safety net in this country while running on a hideously bigoted platform and STILL ended up spending an insane amount of money compared to his predecessors. The only fiscal conservative of the past 50 years in the White House was Bill Clinton. reply MathMonkeyMan 3 hours agorootparentI saw an interview where Bill quipped \"You know how we balanced the budget? We used a little thing called 'arithmetic'.\" reply lostlogin 2 hours agorootparentImagine a candidate who could make a quick, sharp and accurate quip. Out here in the wider world, American elections are more terrifying every time they come around. reply rayiner 2 hours agorootparentprev> He destroyed half the social safety net in this country Democrats controlled the House the whole time, so how’d he manage that? > while running on a hideously bigoted platform What a remarkable assertion. reply fire_lake 1 hour agorootparentThe monkey tape is revealing. reply rayiner 1 hour agorootparentRevealing of what? That racist jokes were normalized back in the 1970s? It’s not like we stopped telling exactly that same joke—we just changed the social norm around who is allowed to tell that joke. Are you more likely to treat people fairly because you won’t tell that joke (but would still laugh at the similar Dave Chapelle bits?) and what does it have to do with his platform? reply camgunz 2 hours agorootparentprevNeoliberal democrats reply bongodongobob 6 hours agorootparentprev\"Fiscal conservativism\" is the equivalent of a household not purchasing any insurance, not going to the doctor or dentist, and saying \"look how affordable everything is if we cut out all those stupid things? It's wasteful spending!\" Then you get into a car accident, go to the hospital, lose your job, and cry about the inefficiency of the market because you now have a huge bill that you can't pay. It's short sighted at best. True fiscal conservatism would be all about social safety nets and free education to grow the economy, but y'all just want to save a few hundred bucks on your property taxes, everything else be damned. reply gumby 4 hours agorootparentWoah, you sound like Adam Smith (the real one, not the one worshipped by alleged acolytes who clearly never read a word he wrote). reply bugbuddy 5 hours agorootparentprevYou are using a straw man. The reason we have a democracy and freedom of speech is so that each of us can voice our opinions and vote for those that share them. Unfortunately, nothing is perfect. reply bongodongobob 5 hours agorootparentI'm using the term as it's used 9/10 times it comes up. I've never in my life met a self proclaimed fiscal conservative that didn't just mean \"I want lower taxes\". The way to lower taxes is a healthy and intelligent population. That is seen as a cost but is actually an investment that pays massive dividends. That's what a fiscal conservative would do, invest at the societal level. Otherwise they're basically just a libertarian. reply latency-guy2 5 hours agorootparentSo a strawman. You set up the premise, you set up your misunderstanding, and then expect everyone else to follow your misunderstanding. You've even redefined what a \"fiscal conservative\" would actually do (if you were the one defining it). Then you pulled in \"libertarian\" out of nowhere. Which is an obvious set up for another strawman, so lets lean into it. Whats a \"libertarian\"? reply ben_w 4 hours agorootparentI have no skin in this because I don't live in the USA and don't want to, but no, everything in the comment you replied to falsifies \"So a strawman\". You can be wrong without being a strawman. When every example you have of X is Y, it's not a \"strawman\" to say \"all X are Y\" — when you're wrong like that, it's a black swan. reply mistermann 3 hours agorootparent> You can be wrong without being a strawman. Sometimes yes, but not always. > but if every example you have of X is Y Is that actually true though? Are you not assuming perfect rationality on behalf of the poster, and that they have an adequate sample size, which tends to be subject to who the individual associates with. > it's not a \"strawman\" to say \"all X are Y\" That depends on the truth of the matter. >when you're wrong, it's a black swan. Only if the initial guess was correct. You may be describing appearances. That which cannot be seen does in fact exist, it just doesn't seem like it because it exists in a different realm, and how our culture is trained to think about such problems spaces. reply rayiner 2 hours agorootparentprev> True fiscal conservatism would be all about social safety nets and free education to grow the economy Which is why Italy and France have such strong economies, right? What’s really standing in the way of economic growth is that the government isn’t paying for people to get free degrees in left wing studies. reply tossandthrow 1 hour agorootparentor the Scandinavian countries that generally have higher spending power than the us. remember not to conflate a strong economy with an economy that is worth living in. you can possess minimum paid jobs in order to make profits for shareholders and never see a dime of that wealth yourself, but alas, you live in a strong economy. reply kcplate 10 hours agorootparentprevOk putting the fever dream aside, even at 3.7 people per household the 1963 to 2024 numbers as it relates to income vs cost of living is pretty eye opening. You are not really disproving the general point by getting fussy over the numbers. reply woodruffw 10 hours agorootparentThe current average US household has 3.1 members. There’s an important discussion to be had about cost of living and stagnant wages despite productivity, but as I said in another comment: that conversation needs to be factually grounded. Vague reactionary handwringing about the good old days isn’t going to cut it, especially when the good old days weren’t all that great by contemporary standards (or for contemporary American demographics). reply notjoemama 9 hours agorootparentIf we’re to correct the exuberance of emotion then this reactionary reply doesn’t fit either. On the topic, I found this informative: https://www.in2013dollars.com/us/inflation/1963?amount=1 “ $1 in 1963 is equivalent in purchasing power to about $10.21 today, an increase of $9.21 over 61 years. The dollar had an average inflation rate of 3.88% per year between 1963 and today, producing a cumulative price increase of 920.69%.” Also: https://www.census.gov/library/publications/1964/demo/p60-04... “ The median income of all families in 1963 was about $6,200; but for families headed by college graduates, the median was $9,700. The median for all families was about $290, or 5 percent, higher than in 1962. Consumer prices rose during this period by about 1 percent; therefore, not all of this amount represented a net gain in purchasing power for the average family.1 Median family income in current dollars has more than doubled in the postwar period (from about $3,000 in 1947 to about $6,200 in 1963). This rise was accompanied by a gradual upward shift of families on the income scale. However, consumer prices have risen substantially during this period so that only about three-fifths of the increase in current-dollar incomes represented an increase in real income. In terms of constant (1963) dollars, median family income increased from $4,200 in 1947 to $6,200 in 1963. This increase was less pronounced than the increase in current-dollar income, but it was nevertheless substantial.” reply mapt 1 hour agorootparentThe entire point of this discussion is whether we should question the CPI figures you are using to 'debunk'... this discussion. reply kcplate 9 hours agorootparentprevYou still haven’t addressed the greater point. Instead you are fixating on the accuracy of least important number in the point the original commenters post. I suspect it’s because it’s the only one you can pick at. The point being can the average single income household of 3.x in 2024 afford house, car, groceries, etc at the same ability as the average single income family household of 3.x in 1963? reply eru 6 hours agorootparentprevWhat stagnant wages? The labour share of GDP has held roughly constant over the decades. reply chiefalchemist 9 hours agorootparentprev> There are good reasons to hold politicians to task for recent abnormally high inflation. Well, maybe 25% for the budget deficits. The Fed is responsible for 75%. They keep over-goosing the economy. They keep saturating the money supply. That devaluing is what inflation reflects. That is your money is worth less (and appears like prices going up). reply tonymet 12 hours agorootparentprevthe average lifespan in the middle ages was 35 too. does that mean there were no old people? reply woodruffw 12 hours agorootparentYour comment explicitly mentions averages. It's a matter of basic fact that the average working-age male in 1963 was not supporting 5 other people with his salary. reply tonymet 12 hours agorootparentThey are not census statistics they are an amateur assembling statistics using public census data. The methods are not published reply woodruffw 12 hours agorootparentThe method is listed in the description below the statistics. Again: if you think these numbers are suspect, you are encouraged to find a different citation that contradicts them. Without that, your complaints are unsubstantiated. reply abduhl 12 hours agorootparentprevNo, but the “typical” person isn’t old. Just like the “typical” man didn’t support 6 people in the 1960s. reply tonymet 12 hours agorootparentnext [2 more] [flagged] woodruffw 12 hours agorootparentThese are the US Census Bureau's numbers. If you're going to contradict the US Census Bureau, then you're going to need to provide some actual sources here. Without that, this is low-effort trolling. reply shrubble 6 hours agorootparentprevYou can listen to Bing Crosby's Christmas album, to the song \"It's Beginning to Look a Lot Like Christmas\", where the parents having 4 children (household size thus 6) is described, as an anecdotal supporting note... since it was a popular song for the masses, 4 kids was not seen as unusual. reply thebigman433 5 hours agorootparentYou cant seriously be comparing actual cited stats for household size to lyrics from a song that was popular? reply shrubble 5 hours agorootparentI specifically stated it was anecdotal... here are the census stats in graph form however: https://www.census.gov/content/dam/Census/library/visualizat... ; 2.5 kids plus 2 adults is 4.5 in the household. reply thebigman433 5 hours agorootparent4.5 in the household is very specifically not 4 kids, like you claim is common. Just an insane random hill to die on reply shrubble 5 hours agorootparentYou're deliberately misunderstanding. Have a nice day. reply TeMPOraL 3 hours agorootparentprevWhy not? Stats are numbers compiled for someone at some point. A song this popular is a snapshot into how people lived and perceived themselves back then. A measurement of sorts. A disagreement between the two is a good indicator that the stats are suspect, or not the right stats to be looking at reply gumby 9 hours agoparentprev> Today Palo Alto, Menlo Park, and other super zips are exclusively [A slight exaggeration] $500k incomes and up. In the 1960 census records you will find these good neighborhoods occupied with plumbers, painters and other blue collar workers. This was unfortunately a deliberate consequence of the dot com boom, not something that happened in previous tech booms. Until around 2000 Palo Alto actually had a lower median income than some surrounding towns due to a policy of promoting section 8 housing, some SRO residences for the homeless etc. Those prior booms didn't suck in as many outsiders and mostly were nerds making fun tech (think of the mac). NYT amusingly published an article were they said how weird the SV was because people who drove mercedes cars still shopped at Costco rather than at \"proper\" shops appropriate to their \"station\". Dot com sucked in a bunch of people who came only for the money (\"I'm starting a company -- need a tech cofounder\" is the complete opposite of those days when it was \"I'm starting a company -- we're big enough that we need some business people\"). Then we started to have fancy restaurants and pretentiously-named magazines about how to spend your money. And then in 2000 the real estate people got control of the city council. The SROs were turned into boutique hotels and the city was re-organzied for the lucky. PA used to be a town where the Grateful Dead, Jefferson Airplane, and the like got started. Harold and Maude was (partially) filmed here. But such things are now inconceivable. reply Rinzler89 19 minutes agorootparent>PA used to be a town where the Grateful Dead, Jefferson Airplane, and the like got started. Harold and Maude was (partially) filmed here. But such things are now inconceivable. I remember how in the 80's and 90's there were still movies like Mrs. Doubtfire with characters on minimum wage renting in downtown San Francisco lol reply epicureanideal 3 hours agorootparentprevAlthough what goes up can come down... if some other state or region within California permitted large amounts of construction, enabled businesses to move in, and threw a few hundred million at building a great university, property values here would drop a lot. With less intention and planning it will take longer, but could still happen, and there are some natural pressures pushing things in that direction. reply flakeoil 2 hours agorootparentprevIt took off when they lowered the interest rates after the dot com crash. The issue was the too low for too long interest rates that drove the increase in home ownership (and rents). reply randomdata 13 hours agoparentprev> In other words you had 1 man working 50 hours a week afford a house... With inflation, we want to know about the change in value of the dollar only. We don't want to factor in the change in value of houses, food, etc. There is a place for understanding that too, but inflation is not it. Something like a cost of living index is more suitable to that kind of information. On that note, houses are unquestionably more valuable today. For one, they are twice the size they were 60 years ago. We can all agree that a bigger house has more value than a small house, at least within reason. You can fit more in it, it is more comfortable, etc. and that is valuable. They are also a lot safer. That too is more valuable. As such, a housing costing x% more today than as compared to some time in the past does not mean that inflation is x%. Again, we only want to know about how the dollar changed in value, not housing. Of course, if you only have numbers, it is impossible to know what share is due to housing being more valuable and what share is the dollar being less valuable, although we can say with great certainty that it is some combination of both. CPI tries to tess out what is the dollar portion only by looking at a large basket of goods of things people buy frequently. Where you see common moment in the change in price across all items in the basket, that is assumed to be the change in value of the dollar. It's not perfect. There is no perfect metric. You are quite right that one should look at many different models, even though none of them will be perfect either. It is all good information, none of it great, but at some point you have to pick a single number. On average, it will be close enough. reply vineyardmike 7 hours agorootparent> houses are unquestionably more valuable today… They also have better insulation and construction, they’re all wired for electricity and plumbing, they all have advanced HVAC. Fancier kitchens with more plumbing, appliances and nicer materials. People have access to more furniture and fixtures and appliances to fill more home - no one needed laundry rooms before a washer/drier was invented. Few had garages. Don’t let survivorship bias fool you - the 1950s homes that working class families had were not that nice. The homes today cost more because more goes into them. We could all live in stuck huts we made ourself like in 1750 and everyone could afford two houses in 2024. Instead, housing has gone up because the utility of that housing has gone up. Oh and of course we’re not making nearly as many per-capita as we used to. So the scarcity is going up. reply cpursley 2 hours agorootparentThe increase in housing prices are not at all proportional to these advancements in building techniques and materials. reply vineyardmike 1 hour agorootparentIt absolutely raises the “floor” of the housing costs - more materials simply means more costs. And the labor to do extra work means more costs - and quality labor is much more expensive today. Same reason a bigger house means more costs. I would posit - admittedly without data - that outside of major metros where land is the clear dominant cost, most costs for housing increase is labor. There are houses and empty lots available within 15min of downtown Cleveland that are selling forPick whatever word you like if \"inflation\" is reserved for economists because regular people are \"just too dumb to understand\". Regular people understand inflation just fine. How useful it is to them is debatable, but it doesn't have to be for everyone. It's okay if some measurements are only useful to scientists and economists. The measure of the speed of light doesn't mean much in my day to day life either, but we don't have to abolish it because of that. > We need a concept for debasement / hidden tax that allows people to hold their policymakers accountable. I think what most people are looking for is simply cost of living measure. They want to know by how much the costs to live (housing, food, etc.) have increased over inflation. Which we have. But that one might actually be a case of being \"too dumb to understand\", explaining why it is not commonly put to use. Inflation is, indeed, a much simpler concept. Or it may be that the ultimate cost of living measurement comes from one's own personal accounting records[1], negating the need to reach for any 'universal' perspective. [1] But I suspect most people don't keep any accounting records, so most likely the first one. reply JumpCrisscross 9 hours agorootparent> what most people are looking for is simply cost of living measure You may have cracked the conundrum right there. People use inflation as a gauge of COL. That is incorrect, but understandable given the lack of a well-publicised national COL metric. reply randomdata 8 hours agorootparent> People use inflation as a gauge of COL. Which is interesting as you'd think actually living, and incurring the costs that go along with it, would be a much more useful gauge. Probably goes along with my suspicion that most people, especially those not already accounting for business activities, don't keep any meaningful record of their transactions. Hard to calculate COL without data. But at the same time, there isn't much effort in publishing national COL metrics as it is presumed that people will already know their own situation, which is always going to be way more telling. Individual COL can vary widely, even between neighbours, let alone on a national scale. reply JumpCrisscross 6 hours agorootparent> you'd think actually living, and incurring the costs that go along with it, would be a much more useful gauge Not for a monetary authority. Given how much drama we have around even our Census Bureau, this gap makes sense. (Also, for every complaint about a given inflation gauge, one increases the parameter and thus bitchable space by orders of magnitude when it comes to COL.) > there isn't much effort in publishing national COL metrics as it is presumed that people will already know their own situation But political leaders won’t. reply jimkleiber 3 hours agorootparentprevFor me, I'm not surprised inflation went up. We had a global lockdown during which some industries made a lot of money and some industries made little to no money. Once the lockdown ended, I assume the ones who made a lot started to lose sales and increased their prices to keep growing. I assume the ones who didn't make a lot of money started to increase sales again and probably increased their prices to recover the money they didn't make. I imagine both of them want to make sure they have enough money to survive another global crisis, especially the ones that almost didn't survive it. So, yes, I think the government has a role in trying to limit inflation (and also increase wages), I just think that some inflation makes sense from those dynamics above. reply epicureanideal 3 hours agorootparentprev> We need a concept for debasement / hidden tax that allows people to hold their policymakers accountable. This is a really good idea and I hope someone popularizes a new measure. reply maxerickson 11 hours agorootparentprev5x? And you think the US in general has gotten more dangerous? reply tonymet 9 hours agorootparentwhat's your opinion? reply dmoy 8 hours agorootparentThe US gets more and less dangerous over time, it varies. It's presently a little bit more dangerous than the early 60s, but way less dangerous than the 70s-90s. reply esoterica 2 hours agorootparentprevYou are completely mathematically illiterate if you think that annual inflation is 3-5 times higher than the reported value. The average annual inflation since 1960 is 3.7%. If the real annual inflation were 3x that (11.1%) then we would have seen 85000% cumulative inflation since 1960. A gallon of gasoline cost $0.30 in 1960, so it would cost $250 in 2024 under 850x inflation. In reality a gallon of gas costs $3.60 today, which is not far off from the 10.5x inflation the CPI measures over that time frame (the same CPI you claim is massively understated). You're running around this thread smugly declaring yourself too smart to fall for the government's lies while failing to spend a few seconds doing the trivial arithmetic that would disprove all of your deeply held beliefs. Which of your other political or economic beliefs will fall apart with a little bit of middle school math? reply imtringued 2 hours agorootparentprevI don't know what to tell you, but buying a house from a previous owner at double or tripple the price is not a hidden tax. reply mrcode007 7 hours agorootparentprevMost of what you have said starting with the definition is incorrect. I suggest you read BLS handbook on methodology. reply wakawaka28 5 hours agorootparentprev>On that note, houses are unquestionably more valuable today. For one, they are twice the size they were 60 years ago. We can all agree that a bigger house has more value than a small house, at least within reason. You can fit more in it, it is more comfortable, etc. and that is valuable. They are also a lot safer. That too is more valuable. Keep in mind, demand was higher with the baby boom than it is today. Houses also used to be built to much higher specifications. Old houses were made with tons of premium timber that is still valuable even 50+ years later. reply mistermann 13 hours agorootparentprev> With inflation, we want to know about the change in value of the dollar only. By \"we\", you are referring to you and others who want to know only this. Some people (not many) want to know what is going on comprehensively, and in fact. For example: I would like to know if there is any strategic changing of formulas to improve appearances going on, like there has been at pretty much every single job I have ever worked on. But to be fair, this is a subjective personal preference, and an unusual one at that. Most people prefer simplistic, memetic representations of reality (though, few can agree on which memes). reply randomdata 13 hours agorootparent> By \"we\", you are referring to you and others who want to know only this. Right. I am referring to all those who want to know only this, along with everyone else. Because those who want to know something else would use another measure. Those complaining that inflation doesn't give you some other economic indicator is like someone complaining that temperature is not a good measure of distance. Well... duh. > Some people (not many) want to know what is going on comprehensively Absolutely. Which is why we have many different ways to look at inflation. In fact, don't White House economists use 30-some-odd different measures of inflation throughout the course of their work? But eventually you are going to want to put it to practical use, mathematically, and our formulas require a single number. CPI is the one we picked to standardize on (but, of course, you can choose another if you want). It won't be 100% accurate – determining that is fundamentally impossible and you know that going into it – but it will be good enough. reply mistermann 10 hours agorootparent> Right. I am referring to all those who want to know only this, along with everyone else. \"along with everyone else\" is incorrect, because you have no way of knowing what other people want (and worse, maybe no way to know that). And the only way you \"know\" what \"all those who want to know only this\" is because it is a tautology, it is necessarily true. Though, you have no way of knowing what percentage of the population thinks like you do, so it is not particularly informative knowledge. > Because those who want to know something else would use another measure. Some people (me) would like to see all methodologies maintained indefinitely on a chart, so we can see how different versions of The Truth vary over time. I am interested to see if changes in methodology tend to correlate with changes in the \"vibe\" of the cost of making ends meet people are experiencing. I prefer this approach because it is more transparent, and because I do not trust my government, or the perceptions of my fellow Westerners (because of the way they think: how it \"is\", is how it seems to be....which tends to correlate quite nicely with how it is said (repeatedly) to be). > Those complaining that inflation doesn't give you some other economic indicator is like someone complaining that temperature is not a good measure of distance. It is also \"like\" someone whining about how appliances don't last as long as they used to, but \"is likes\" are often more misinformative than informative (perhaps why they are so popular?). > Well... duh. Are you blaming others for the way you think? > Absolutely. Which is why we have many different ways to look at inflation. And also why I do not want historic \"truth discovery\" methodologies memory holed. > In fact, don't White House economists use 30-some-odd different measures of inflation throughout the course of their work? Don't know, but I do not trust them. Also, \"in fact\" terminating with \"?\" is a rather interesting approach. > But eventually you are going to want to put it to practical use, mathematically, and our formulas require a single number. Maybe we should get better formulas, because reality does not fit so nicely into simple, reductive, misleading models. > CPI is the one we picked to standardize on No, \"we\" did not pick it, someone else picked it \"on our behalf\"...according to \"democracy\" we are trained to believe, though it is not both flawlessly true and not misinformative. > (but, of course, you can choose another if you want). I can't get it published as \"fact\". > It won't be 100% accurate – determining that is fundamentally impossible and you know that going into it – but it will be good enough. Good enough to satisfy people that want to be satisfied, but not good enough to satisfy all. reply randomdata 10 hours agorootparent> No, \"we\" did not pick it, someone else picked it \"on our behalf\" With a gun to your back, eh? We can use whatever source of inflation we want. Nobody is selecting for us. But, as it happens, CPI is the one we've chosen as the default. If we change our minds, we don't have to default to it forevermore. It's up to us. > Are you blaming others for the way you think? I don't think. You do enough of that for all of us. No need for me to duplicate efforts. I relay the state of the world to the thinkers so they don't have to. The efficiency of specialization! > Good enough to satisfy people that want to be satisfied, but not good enough to satisfy all. Which, again, is why we have many sources of inflation. Pick a different one if need be. Indeed, there is good reason why there is more than one. And if inflation isn't the right tool for the job, which is probably the case, use a different economic measure. There are many tools in the toolbox. You don't have to measure distance with temperature. Let's be real, the only reason we talk about inflation at all is because it is shares a relationship with interest rates. Interest rates are what people actually care about here. As principal value declines with inflation that makes borrowing more attractive, thus interest rates need to compensate, thus a change in inflation rate serves as a useful leading indicator of interest rate movement. If it weren't for that, it is doubtful that anyone, economists and statisticians aside, would even know that inflation is a used measure. Beyond interest rates, it doesn't mean much to Average Joe. Average Joe is more worried about things like cost of living. Inflation isn't meant to be useful to Average Joe, though, it is for economists who need to look at much more than Average Joe. Average Joe is free to use it if we wants, but it's funny when he starts complaining that it doesn't work right when misapplied. reply tsimionescu 5 hours agorootparentPeople discuss inflation because everyone from the Economist to Yellen to the President brings up inflation numbers whenever people start feeling their COL increase, or when people demand better state services etc. It is one of the most widely publicized economic indicators, along with GDP, unemployment rate, and foreign debt. But in many of these discussions, it is deliberately being presented as equivalent to COL, which is never addressed separately. So, in reality, for the vast majority of people who learn about these numbers from the media, not economics degrees, \"inflation\" actually refers to COL, except that the numbers they are given are the ones for what economists call inflation. Given that a word is defined by what the majority of the people using it mean by it, I think inflation in common English is closer in meaning to COL than to the technical economics term inflation. Edit: typos reply mistermann 6 hours agorootparentprev> We can use whatever source of inflation we want. Nobody is selecting for us. But, as it happens, CPI is the one we've chosen as the default. If we change our minds, we don't have to default to it forevermore. It's up to us. a) Who, specifically, is \"we\" in this context? b) What is your information source for these facts? > Beyond interest rates, it doesn't mean much to Average Joe. What is your information source for the meaning contained within the minds of the average Joe? Please be specific, please at least try to speak truthfully. reply tastyfreeze 4 hours agorootparentprevGeneral rule of people. If you have seen it at work it is happening in government. Being a public servant doesn't change human nature. reply usaar333 5 hours agoparentprev> Remember in 1963 only the man was working, and typically supported 4 kids, a wife and often parents in the home. Things are a lot cheaper if you keep them in a 1200 square foot house > Today you have 2 people working 100 hours a week to support 1-2 additional people , while living in an apartment and living in a run down and crime infested neighborhood. Highly doubt people at this income rank were buying houses in 1960 and living comfortably. > Summers is right more than he’s wrong Entire argument is whether you should count interest or not. I can see arguments both ways reply nytesky 13 hours agoparentprevThe “one income household” model of the 50s worked for two reasons. 1) the rest of the world was in ruins, so for 50s-60s US was sole industrial power more or less. 2) artificial labor “scarcity” where POC and women were banned from many occupations. The remaining available labor (ie white men) had more leverage. reply impossiblefork 4 hours agorootparentThe 1950s situation can be restored without introducing gender inequality or occupational bans though. A four day work-week would bring us at least a little bit closer to the 1950s situation, and improve the leverage of workers. 4 x 2 > 5, of course, but 4 x 2 is still less than 5 x 2. reply tonymet 12 hours agorootparentprevIs the argument that true inflation should be worse than CPI because it helps with diversity? reply riskable 9 hours agorootparentIt has more to do with a hidden class structure below your average white family, working for much less, providing goods and services at a discount. Inflating the means of the average white family in a way that wouldn't be possible today because we're not as purposefully racist or sexist as we used to be. In order to make a better comparison one should compare what was affordable to the average black family in the 1960s (or whatever previous time period you choose for which we have figures) to today. There's other factors like the aftermath of WW2, the real and \"soft\" power the US held back then in comparison to today, and the role women played in the economy. Today's world is a lot different from then but the truth is that the wealth and power we've amassed since then should have us in a better position, not worse. The factors at play in today's economy are not benefiting the common man nearly as much as they should. We're beginning to look more and more like a post-scarcity economy every day yet our laws, regulations, and culture are not evolving with the times. The fact that land and homes are vastly inflated compared to regular every day goods and even the \"durable\" kind is strong evidence that our entire economic system stands on precipice of great change. Either we're just getting started on a great collapse or a great sea change in politics and economic systems. I very much doubt things are going to go back to the way they were... Ever. We as a society can decide to spread our prosperity around or we can increasingly suffer for the lack of it by continuing the status quo. reply lowkey 6 hours agorootparentprevFrom the article, the biggest discrepancy between CPI and true inflation is a result of a change in the formula made in 1987 that removed interst rates aka the cost of money from CPI. The CPI formula replaced the actual cost of financing homes and autos with a new term, owner's equivalent rent. The argument made by the underlying paper [1] is that the older calculation better reflects the cost of living increases experienced by consumers and more closely correlates with the widely used University of Michigan Index of Consumer Sentiment. Also, notable is that consumers care much more about the cumulative multi-year effect of inflation while economists only worry about year/year changes in the rate of inflation as can be seen here [2] (worth a click) [1] https://www.bls.gov/pir/journal/gj02.pdf [2] https://twitter.com/darioperkins/status/1770783161330323925/... reply disgruntledphd2 3 hours agorootparentThe really interesting thing about their proposed measure is that it reduces the period of extremely low interest rates post GFC. We'd be living in a very different world had this been our north star throughout that decade. reply grobbyy 9 hours agorootparentprevI think the argument is that inflation is complicated by globalism. reply EnigmaFlare 7 hours agorootparentprev3) Lack of technology meant housework was so much more difficult that it actually required a full-time housewife or maid. reply hackerlight 4 hours agorootparentprevHousing costs. reply dennis_jeeves2 5 hours agoparentprev>It’s a deliberate approach to stealing your prosperity while you cheer it on. Excellent way to put it. To put things in perspective if one works for 5 days a week, you are paying the govt (all taxes + inflation) about 3 days of your earnings. You only get to keep what you earn for 2 days. reply thebigman433 5 hours agoparentprev> In case you think this is academic, look at the occupations for those who lived in today’s wealthiest neighborhoods. Today Palo Alto, Menlo Park, and other super zips are exclusively $500k incomes and up. In the 1960 census records you will find these good neighborhoods occupied with plumbers, painters and other blue collar workers. How much is this related to inflation compared to the complete refusal of the Silicon Valley suburbs to building new housing? If rich people want to move somewhere, and people living in that area dont build houses for them to move into, its going to drive the prices up, because the wealthy people will go there no matter what. Also your whole bit about the past being so much better is insane. Hard to tell what is you exaggerating and what is a serious argument. My partner and I make ~100k + 40k combined a year, and we rent an apartment in one of the nicest SF neighborhoods, save for retirement, go out and do (paid) things every weekend, and still save a good chunk of money every month. We also have gym memberships, own cars, buy nice groceries, etc. Inflation does suck, and the sticker shock is bad, but the high inflation also stems from policies that have let us have insanely good unemployment levels. Post 2008 we saw less inflation, but unemployment stayed high for almost a decade. Unemployment is already down to super low levels post 2020, which is better for everyone. Average and lower wage workers have also seen large growths in what they make. reply bjornsing 2 hours agoparentprev> Today you have 2 people working 100 hours a week to support 1-2 additional people , while living in an apartment and living in a run down and crime infested neighborhood. Is that really true, or is it more a feeling many Americans have? As a Swede it’s a bit hard to relate to. reply jlmorton 1 hour agoparentprev> McDonalds burgers were 15¢. Okay, it was the McDonald's hamburger that seems to have been $0.15 in 1963. That is $1.53 in CPI-inflated 2024 dollars. The cost today is $2.19. That's about a 0.6% difference in the compounding inflation rate over 61 years. reply sanp 6 hours agoparentprevPerhaps a Cost of Thriving Index? https://manhattan.institute/article/the-cost-of-thriving-ind... reply ProfessorLayton 13 hours agoparentprevThere are 153 million more people in the U.S. today than in 1963. The reason these neighborhoods are exclusive to the wealthy is that housing there is scarce despite growing demand due to job growth. Housing in places like the Bay Area is such a big portion of monthly expenses that stuff like Arby's 4 for $10 or whatever isn't whats hurting people the most. Lots of these issues just come down to housing and restrictive zoning. reply tonymet 12 hours agorootparent95% of zips in 1963 were safe and livable. Now everyone is competing to live in 15% of zipcodes You address the supply side of the \"housing crisis\", what about demand? reply kibwen 10 hours agorootparent> 95% of zips in 1963 were safe and livable. I've been trying to give your comments the benefit of the doubt, but now it's abundantly clear that you're fundamentally unserious about having a conversation grounded in reality. reply ProfessorLayton 12 hours agorootparentprev>You address the supply side of the \"housing crisis\" Why the scare quotes especially when no such term was used? >what about demand? \"...growing demand due to job growth\"95% of zips in 1963 were safe and livable. 95% of white suburban zips might have been safe and livable, but nowhere close to 95% of all zips. reply thfuran 4 hours agorootparentPay no attention to the red lines behind the curtain. reply zeroonetwothree 6 hours agorootparentprevThis is absurd. Crime is far lower than it was in 1963. reply EasyMark 4 hours agorootparentprevIt's also quite expensive partially because of garbage regulations on lot sizes and what can be built. NIMBYism is alive and well. reply WA 3 hours agoparentprev- People lived in way smaller houses back then. - People had only one car. - People ate meat once per week. - People had way fewer things in their houses. You gotta consider increases in material possessions as well if you want to calculate inflation properly. reply abeppu 12 hours agoparentprev> True inflation would measure the amount of prosperity achieved per hour worked. I think this isn't a measure of inflation per se, because productivity changes are big over the decades. But I do think looking at costs in terms of hours of work is really helpful. I think back to an event in some HS extracurricular when a group of students got to ask questions of a gubernatorial candidate, and one kid asked if he was going to do anything to make college more affordable at state schools, and this candidate (perhaps keenly aware that almost none of the students could vote) basically laughed it off and talked about working at restaurants to put himself through school (I think in the 70s). How many hours of (unskilled?) labor was a semester of tuition then, versus 30 years later? How many hours was a tankful of gas, or rent for half an apartment, or a heating bill? How feasible is it really to work one's way through even a public school? reply woodruffw 12 hours agorootparentI agree with the point about the cost of education. In real terms, however, the cost of a tank of gas is about what it was in the 1960s[1]. Today's average is $3.63[2], which is about $0.34 in 1960 dollars. [1]: https://www.creditdonkey.com/gas-price-history.html reply listenallyall 9 hours agorootparentI never understand the \"in X dollars\" argument, especially when looking back longer than about a decade. The CPI only considers a certain basket of goods, it's not representative of a cost of living (that's what this thread is about), various things change price at radically different rates. How much was an iPhone or Xbox in 1960 dollars? What was the typical cable TV bill? What did a typical American pay for a California roll or a burrito in 1960? Alternatively, given your 10x price boost, why isnt the cost of a television set or vacuum cleaner in the multiple thousands? reply tastyfreeze 3 hours agorootparentThe comparison doesn't work on manufactured products. You can really only compare commodities. Anything that is manufactured has a multitude of factors that will reduce cost of a product significantly over time. If the circuitry in an Xbox were constructed in 1960 no government on the planet would have been able to afford it. It would also be difficult to find enough power to run it or a place big enough to build it with the technology of the time. reply awwaiid 8 hours agorootparentprevYes -- the whole thing should be how many hours it takes to buy X instead of how many dollars. It's then interesting to see how that looks in different economic brackets. Maybe in one bracket a car costs 1000 hours, and in another the same car costs 350 hours (so might as well get a 700 hour car. Still cheaper). reply jogjayr 5 hours agoparentprevI randomly ran across this blog post https://economistwritingeveryday.com/2024/04/10/grocery-infl... today. It says fast food prices have gone up faster than grocery prices or inflation. I don't eat fast food so I don't know if it's true. But it got me thinking. Maybe the likes of Doordash are to blame, at least indirectly. Food delivery companies have proved that people will pay $15 for a lukewarm McDonald's burger if it's brought to their doorstep. So there is obviously some room to increase prices even for in-store purchases. reply panarky 5 hours agoparentprevPrice inflation tells you very little about how well the average person lives. The average person today has a far higher standard of living than the average person in 1963. reply TMWNN 9 hours agoparentprev>The memes of Arby’s 5 for $5 becoming 4 for $10 are more informative than the CPI numbers. Don’t let the shock at the grocery store wear off – it’s real and painful despite what the news tells you. \"The thing I have noticed is when the anecdotes and the data disagree, the anecdotes are usually right. There's something wrong with the way you are measuring it\". —Jeff Bezosreply ben_w 4 hours agorootparentHuh, so that looks like a way to deal with Goodhart's law? reply adriand 14 hours agoparentprevBut it’s not like our standard of living has remained static while we need to work more. A lot has changed. In 1960 the average single family home was 1300 square feet, now it’s more than double that, and it’s packed with amazing amenities and entertainment options. What would an iPad cost in 1960? Obviously the question is kind of nonsensical and yet on the other hand, if you were to try and quantify the price of our ability to work from home, for instance, we have a way better deal going than they did in 1960. You could retort that this is the inevitable march of technological progress, but could it be the result of hard work and innovation including the hard work and innovation of women in the work force? reply fragmede 13 hours agorootparentWhat did a college education cost in 1960? I would gladly trade WFH to be the one person supporting a family of 6. (Me, partner, two kids, two grandparents.) The Internet's great and all (although sometimes it seems like it was a mistake), but we're so far from 1 very average person being able to support a middle class life style for 6 people. Median income in 1960 was $5,600, which is equivalent to $60,000 today, but according to the EPI*, to provide for a family of 6, I'd need to make about $150k/yr to live in Cincinnati, Ohio (in SF it's $280k). Which isn't a lot in the FAANG world, but the point is that a very average not-very-smart person was able to provide for that many people back then. How many very average not-very-smart unskilled people do you know make $150k/yr; how many smart people do you know that make less than that? * https://www.epi.org/resources/budget/. reply woodruffw 12 hours agorootparent> Which isn't a lot in the FAANG world, but the point is that a very average not-very-smart person was able to provide for that many people back then They weren't. The average household income in the 1960s (i.e., from a single breadwinner) was supporting a household of 3-4 people not 6[1][2]. The claim that you could support a family of 6 on a single breadwinner's income in 1960 and achieve anything close to 2024's quality of life is an egregious misrepresentation by the GGP. [1]: https://www.statista.com/statistics/183657/average-size-of-a... [2]: https://www.statista.com/statistics/183648/average-size-of-h... reply fragmede 7 hours agorootparentI mean, lower it to 4, the EPI calculator still gives $100k. Are there that many jobs paying that for someone who's pretty average in Cincinnati? reply zeroonetwothree 6 hours agorootparentprevThe standard of living today is immensely higher. If you wanted to live at 1960 level you could certainly afford to do so. You’d have 1,000 sq ft of house, a single unreliable car, almost never go out to eat or travel, etc. reply fragmede 4 hours agorootparentIs it? sure we have the Internet and big TVs and fast cars, but how much time do we actually have to enjoy them? quality of life is measured in more than just the things you have. I mean, yeah, if you're getting Doordash every meal and spending all your money that way, that's on you. Trader Joe's is frigging great, imo. but eating at home and having an older car isn't going to get me to a place where one median American salary can comfortably support a meaningful amount of people. this is after we decry the other ills of there 1960's, of racism and sexism, which hopefully it's obvious I don't want to go back to, but letting both parents work somehow became both parents need to work for middle America and I'm just tired of my friends living at the edge. reply firstplacelast 3 hours agorootparentprevI was reading murder Wikipedia the other day and one of the guys got out of prison the second time and was able to pick up a job making 1k/week in the late 70’s (49-50k/year) in SoCal. That’s what I was making a decade ago in SoCal with a college degree (slightly more with OT). Ohh to live the life of an uneducated violent offender in the 70’s. https://en.m.wikipedia.org/wiki/Lawrence_Bittaker_and_Roy_No... reply imnotlost 5 hours agorootparentprevAh, the 1850s when life was good! The US Post is great and all, but I would gladly trade the US post for a large beaver-hunting territory! Horses are too fast! Walking is better. Or whatever... come on! reply fragmede 4 hours agorootparentso the tradeoff, for having to have both parents working for a very average family, is that they can surf the Internet and get Doordash? you come on. I'm not denying that we have a better quality of living today, but how much time do you have outside of weekends to just go fishing or whatever? all these labor saving devices were supposed to give us more leisure time but instead we're worrying harder than ever! reply ben_w 4 hours agorootparent> instead we're worrying harder than ever I was going to say this typo was accurate, but now I realise I've never actually seen a detailed analysis of how much people worried in the past, just confident claims it was so. reply imnotlost 3 hours agorootparentprevI understand, times are hard. Always were. When was this chill time when we could just take off fishing for a week or two? Random breakdown of time :) * 1800s * 1900-WW1 * WW1-WW2 * WW2-1980 * 1980-Now And yeah, single breadwinner households were a thing back in the day it was generally because women didn't have a choice at all. I'm pretty sure you have more options and choice today as to how you want to live your life, but if you want a family you gotta feed the little bastards one way or another, that has always been a \"worry\". reply tossandthrow 13 hours agorootparentprevThe main thing is, that I could actually support a household of 6 people on a single income if I was allowed to fix the comfort at the 60s level. 1. No flying on vacation and only simple camping as vacation 2. No technology: Computers, phone, television. Nothing, and no associated costs with subscriptions, etc. 3. Eat like it was the 60s, mainly potatoes (I am from Northern Europe). That said: I truly believe in the parent commenters key idea. We need to create more real prosperity for people. But in order to do that, we need to adjust the activities – Marketing and expensive dead-end projects (read: projects that occupy a lot of person-hours) does not achieve real prosperity. reply citizen_friend 6 hours agorootparentNo. Because the things that cost significant amounts of money aren't computers, phones, and tvs (notice that poor people have these). It's the minimum bar to be a player in society that has been raised. 1960s - could have a good career without college education and it was inexpensive - can afford a house - can often not have a car 2020s - need bachelors degree to get started, probably also need a professional degree - houses occupy - need cars (likely for all adult family members) reply woodruffw 13 hours agorootparentprevNo, you couldn't. The average working male earning 6200 USD a year in 1963 was supporting 2-3 other people (i.e., the nuclear family), not 5. This is almost directly in line, via inflation, with the average US household income and size in 2024. I agree with the larger point about prosperity, and I think there are ways in which the US (and other developed countries) have gone backwards in QoL metrics. But a serious conversation about that needs to start with numbers rooted in reality, not a rose-glass view of the past. reply tossandthrow 13 hours agorootparentYes, so I am saying that a median income today could sustain a 6 person household if you were allowed to fix your comfort level to the level of the 60s. That is 3 more than a single median income supported in the 60s. I am definitely not trying to paint a rose-glass view of the past. I am saying that we do have more prosperity today than we had 60 years ago. I am also saying that we pay of a lot of time to have things that provide diminishing returns. (Ie. would you rather have flush toilets or access to facebook - style of reasoning). Maybe the famous 80% value for 20% cost is also inflating? reply woodruffw 13 hours agorootparentSorry, I badly misread your post! I agree about the diminishing returns. reply Retric 13 hours agorootparentprevTake your typical family of 4 living on 2 incomes today. Are they living in a 1,500sf house (median size in 1960)? Without AC, no cable TV, no computers, 1 car, no exotic / organic foods except from the garden, few toys, 60’s era medicine. Do they actually repair or even make clothes? How about home repairs? My mother was a teen in the 60’s and while objectively they were well above the median income for the time period in many ways they lived like extremely poor people do in 2024. Some of that was actually saving money for retirement, but mostly it was just far lower expectations. reply woodruffw 13 hours agorootparentRight. By virtually every metric, the average American family is materially more prosperous than they would have been in the 1960s. Backwards movement in QoL metrics is mostly on the left tail: impoverished Americans have access to AC and refrigerators, but often live in food deserts or are subjected to perverse policies in our social safety net (e.g. welfare cliffs that punish people for working by taking away benefits that enable them to work). reply lowkey 6 hours agorootparentprevYou make some valid points but one nitpick: what we call organic food today, they simply called food in the 60's since all food was by definition organic. reply GeneralMayhem 5 hours agorootparentThat is abjectly false. Synthetic pesticides have been used since before the second world war. Silent Spring was written in 1962 about the effects of the amounts of DDT that had already accumulated in the environment by that point. reply impossiblefork 3 hours agorootparentprevWe were actually flying on vacation in the 1960s though. My maternal grandfather was a school principal and his wife didn't need a job. They went to England and Spain on vacation. We also of course absolutely loved potatoes. We still do. reply tonymet 12 hours agorootparentprevLike peter theil says, in 40 years only technology has improved , the real world has declined. Should we value technology so much that we cheer on the loss of the real world? reply zeroonetwothree 5 hours agorootparentWhat exactly has declined? reply huytersd 13 hours agorootparentprevMainly potatoes is bullshit. reply tyfon 2 hours agorootparentSild og poteter (herring and potatoes) is still a meme for being poor in Norway. Potatoes are a main staple in many ways outside of the cities even to this day. reply bryanlarsen 11 hours agorootparentprevNot for Northern Europe in the 50's. reply tonymet 11 hours agorootparentprevSome aspects have improved, and others have declined. Home entertainment has more options, we spend more time at the TV and computer. Other aspects of life have declined. It's challenging because there are qualitative and aesthetic aspects to the process, so it takes some discussion to come up with a good understanding. Regardless CPI is misleading. The amount of time spent working over a lifetime to support the family and cover taxes has grown significantly, at a higher rate than CPI suggests. reply zeroonetwothree 5 hours agorootparentWhat specifically has declined? When I compare life that my grandparents had to now it is absurdly better in every way. reply tsimionescu 5 hours agorootparentCommunity/social life has greatly declined for almost everyone. Home appliances are fancier today, but they are far less reliable. Furniture is much worse in almost every way (e.g. my grandma sleeps today on the same bed and spring mattress that her parents-in-law bought, some 60-70 years ago, and it is still extremely comfortable). Clothes are far less durable as well. Fruits and vegetables are typically worse in taste. Education is extraordinarily more expensive. Job security is much worse. reply fulafel 3 hours agorootparentprevThe opulent space per inhabitant (as families are also smaller) is now viewed by many as a negative in face of the climate crisis, not to mention the cost of housing and the resulting need to work more. reply gedy 13 hours agorootparentprev> What would an iPad cost in 1960 I don't think that the cost of a computer should silently get included into basics like rent for a roof over your head, food, and medical treatment. reply willcipriano 9 hours agorootparentprev> 1960 the average single family home was 1300 square feet, now it’s more than double that It's the same house. They put drywall up in the basement and walls around the porch and call it a sun room. reply mikelitoris 5 hours agoparentprevThe extremely short summary of where all that prosperity went: up and abroad. The capitalist class hollowed out the middle income USA by siphoning solid jobs off abroad and pocketing the difference. You can thank all the neolib useful idiots for that. It is not really the result of interest rates. reply philwelch 29 minutes agoparentprevI also have like six different machines in my house that would each, single-handedly, put the entire computing infrastructure of the Apollo program to shame. And my corneas have been reshaped into the ideal form by a computer-controlled laser, giving me 20/10 vision. I haven’t done it yet, but I could get my entire genome sequenced. A $20 Italian rifle sounds like a good deal but today you can buy a machine that literally prints guns (some assembly required). Any one of these things would be worth millions if not billions of dollars in the 1960’s. This also explains why Palo Alto is so much more expensive these days. Some the things I mentioned were invented around there, which made a lot of those people rich. Other things have become more affordable too. In 1960, a round trip flight from New York to London cost $550. I can find similar fares right now. In 1984, a Macintosh cost $2500, had 128 KB of RAM and a 9 inch 512 by 342 pixel display. For half as many dollars today, you can buy an iMac with a 24 inch 4.5K display and 8 GB of RAM. Now, I will admit that many things are needlessly more expensive, and while the reasons for this are complicated, I don’t think it’s any coincidence that many of these cost increases are directly associated with institutions getting taken over by parasitic classes of administrators and bureaucrats. If you go to college, you’re not just paying for the inherent costs of the college; you’re also paying for the growing administrative bureaucracy that has infested the institution. If you go to the doctor, you’re not just paying your local family doctor; you’re paying an entire bureaucracy that has reduced your family doctor—who used to own a private practice—to the status of a corporate employee, plus a completely separate “health insurance” bureaucracy. (It turned out that the doctor who reshaped my corneas with lasers was happy to just take cash though!) Governments are some of the worst effected. The cost to build the US interstate highway system was, adjusted for inflation, about 618 billion dollars. The 2021 infrastructure bill totaled 1.2 trillion dollars, but are we really getting the equivalent of two complete interstate highway systems? But hey, it could be worse—it’s not like they actually collected all the tax dollars they needed to pay for it! That’s a problem for future America. I don’t envy those guys! reply seanmcdirmid 5 hours agoparentprev> Remember in 1963 only the man was working, and typically supported 4 kids, a wife and often parents in the home. They used older kids to watch younger kids, and generally let the kids fend more for themselves (my boomer dad was the oldest of 8 kids, and that was his experience, but having his grandparents die of spanish flu after WW2 hurt and helped a bit). I actually kind of admire that, and think we've lost something with more hands on parenting. I totally agree. In a sense, FAANG salaries aren't especially high by historical standards, it is just that everyone else has fallen so far behind. $500k/year household income is firmly middle class, and is like earning $135k in 1980, my dad made more than that contracting in building nuclear plants with an associates degree from Spokane Community College. reply thfuran 4 hours agorootparent>In a sense, FAANG salaries aren't especially high by historical standards You can't be serious. >$135k in 1980, my dad made more than that contracting in building nuclear plants That's over six times the median household income in 1980. $135k today would still be nearly twice the median household income. reply seanmcdirmid 3 hours agorootparentIt wasn't that much back then, especially when the industry was feast or famine (and it did implode in 1986 or so). But really, my only point was \"a guy who had an associates degree from a CC could earn that much.\" My buying power is essentially worse than my dad's, although I put in a lot more time in school for it, and supposedly made the right career choice, things just suck these days and techies are keeping their heads above water but not much more. reply demondemidi 5 hours agoparentprevCrime infested neighborhoods? You mean like living with a bunch of billionaires as neighbors? reply mint2 9 hours agoparentprevThere’s a number huge flaws in all that logic. Comparing Palo Alto circa 1960 to Palo Alto circa 2020 is frankly bizarre. But if we’re using that logic why stop at 1960? Coulda had that land for almost nothing in 1700, so there was infinite inflation from 1700 to 1960! Gasp! But what’s the result if we look at the price of a compute that a 1960 worker could buy vs a 2020 person? Let’s see a modern household has the equivalent to a very large number of 1960 mainframe computers, looks like their buying power has gone up infinitely! Or lots in prime La neighborhoods, super affordable in 1860! That means people have lost so much purchasing power because they’re hard to afford now! reply roenxi 6 hours agorootparent> so there was infinite inflation from 1700 to 1960 Infinite is exaggerating but the US dollar has lost >95.0% of its value since the 1700s. So that observation is technically wrong but intuitively is fairly reasonable. If you assumed infinite inflation since then you'd be accurate enough for casual conversation. reply cmmeur01 5 hours agorootparentprevLove to eat and live in compute. reply throw0101c 13 hours agoparentprev> Take 1963 as an Example. Sears sold entire two story home kits with all materials for $1600. How big (area-wise) were those houses? What kind of heating did they have? How air-tight/leaky/drafty were they (which would dictate OpEx on heating)? Did they have air conditioning? What kind of electrical service could they handle (60A? 100A? 200A?)? Did that include the foundations/footings/slab? Were those parts insulated (i.e., how cold were your feet)? Did they come with sprinklers or even smoke/fire alarms? > And you weren’t getting an HGTV-approved home in the 1950s. Those cheap homes everyone was buying were 700-900 square feet with two to three bedrooms and one bathroom. Most had no basement, porch or back deck. You were lucky if you got a one-stall garage. > No open floor plans, granite countertops, stainless steel appliances, walk-in closets, man caves or room to entertain. Most homes were bare bones. * https://awealthofcommonsense.com/2024/01/americans-are-bette... I'm not sure how many folks would like to live in a current $1600-equivalent house. > My point is that inflation isn’t abstract and it isn’t a law of nature. It’s a deliberate approach to stealing your prosperity while you cheer it on. If you think inflation is bad, try deflation (1930s). > Summers is right more than he’s wrong. Real inflation has always been higher than the bogus CPI numbers, and the past 5 years it’s been accelerating. The pre-1983 algorithms were moved away from for a reason: do you know that reason? Was it a good or bad reason(s)? Why? > In 1983, the government switched from using home prices — which also included mortgage payments and maintenance costs — to using rental prices to gauge the cost of housing. > The cost of housing for people who own their property is now measured using what is called “owners’ equivalent rent”: how much their house would cost to rent if they did not own it. > The idea is that homes are an investment. House prices appreciate, and you may eventually sell for a profit a property that you have purchased. Rent, however, represents consumption. It does not leave you with an asset that you can sell down the road. > Critics often argue that by leaving home prices out of the equation, the inflation metric underestimates the cost of living at moments when home prices are increasing markedly and when it costs first-time buyers more to get a foothold in the market. Some even claim that if the government used the old methodology, its reported inflation rate would be much higher today than it was during the 1980s. * https://archive.ph/zvtPw / https://www.nytimes.com/2022/05/24/technology/inflation-meas... Housing prices are not considered in the CPI (\"cost of living\") because they are mostly an asset: > House prices are an interesting case. Houses are considered capital investment by the [US] BLS. So, when the value of your home increases that's a good thing as you didn't consume the house. In other words, you don't need to replace the house. Consumption goods are different in that you need to replace the thing you bought. Inflation is very bad for consumption goods because it costs you more to replace that thing each time you need it (food, for instance). * https://web.archive.org/web/20210929154549/https://www.pragc... > The BLS views housing as a mostly “investment” item as opposed to a consumption item. So, for instance, when you consume a hot dog and have to replace it then the cost of replacement is a direct reflection on your well-being. A $1 hot dog that costs $2 one year later is a material change in living standards, all else equal, since the hot dog is an asset that you literally consume. A house is much more complex. [...] > Of course, anyone who owns a house knows that it’s not that simple. You do basically consume your house over time. For instance, my home has appreciated substantially since I purchased it just 5 years ago and underwent a hellish remodel. At that time the cost of replacement was roughly $300 per square foot. But in the ensuing years the cost of replacement has increased to $400 per square foot. As my physical home falls apart over the years I will need to replace it. But the key point is that, as I replace these components the housing market is likely to revalue the total home value to account for this investment. So even though I am consuming my house over time I am very likely to recoup those costs. * https://www.pragcap.com/should-house-prices-be-in-the-cpi/ Upkeep is a part of the CPI (as is Rent, under the broader Shelter category), but house/land prices are not. The \"C\" in CPI stands for consumer. Housing assets aren't in the CPI for the same reasons stocks and bonds are not: we don't consume them to live. 'Shelter' is considered in the CPI generally though (and with-in that things like home repair (lumber, plumbing) are accounted for); for Canada: * https://www150.statcan.gc.ca/n1/pub/71-607-x/2018016/cpi-ipc... And as the Bank of Canada notes, there is no internationally agreed upon method: > International statistical agencies have unanimously adopted the net acquisition approach for durables, but there is no consensus about the best approach to the treatment of OA in the CPI16 (Table 1). Rental equivalence is the most popular approach among countries belonging to the Organisation for Economic Co- operation and Development.17 Johnson’s (2015) recent review of the U.K. CPI proposes using CPIH, which includes the costs of OA and is based on a rental- equivalence approach, as the U.K.’s main measure of inflation. Several countries in the European Union have refrained from incorporating OA into their CPI, although Eurostat is currently conducting a pilot study for the euro area based on the net acquisition approach. Australia and New Zealand use a net acquisition approach, while Sweden and Finland—like Canada—are using a partial user-cost approach. No country has adopted a full-fledged user-cost approach. * https://www.bankofcanada.ca/wp-content/uploads/2015/11/boc-r... In the StatCan CPI paper there is some explanation towards the complexities of shelter / owner accommodation: * https://www150.statcan.gc.ca/n1/pub/62-553-x/2019001/chap-10... * https://www150.statcan.gc.ca/n1/pub/62f0014m/62f0014m2017001... reply jmyeet 6 hours agoparentprevI agree with this: inflation as an economic measure is an intentional policy tool to transfer wealth from the poor to the wealthy. In the last few months we've seen headlines about inflation \"levelling off\" but that just means prices aren't growing as fast. The 20-30% increases in housing in particular aren't going down. In fact, it's intentional government policy to make sure house prices and rents never go down. You mention Silicon Valley and others dismiss this as a result of the dot com bubble but it's really not. It's zoning policy. IIRC the smallest lot in Menlo Park or Mountain View is ~10,000 square feet. But you see it elsewhere. The average house price in London is ~706k GBP. 30 years ago it was ~70k. Inflation is used to justify wage suppression. Whatever the formula, it doesn't accurately reflect to cost-of-living crisis we're in. reply hklijlyh 13 hours agoparentprevnext [7 more] [flagged] whateveracct 13 hours agorootparentAlso it's not hard to find cheap food at the grocery store. Whole free-range, locally grown chicken for 99c/lb is commonplace in my neck of the woods. It's the convenience/brand power stuff that is really spiked. Fast food falls into that. reply lispisok 12 hours agorootparentHonestly, calling BS on this. The cheapest large package mass produced factory farmed chicken at my local big retailer grocery store is $2/lb. The nicer stuff is more like $5/lb. reply adriand 11 hours agorootparentIf people want cheaper food, they should eat less meat or no meat at all. It blows my mind how cheap it is to eat a vegetarian diet. Dried black beans are $1/pound. That is a lot of food for very little money! Rice is super cheap. Potatoes are super cheap. If you rely on staple vegetarian food for the bulk of your calories and then “decorate” with fresh fruits and vegetables, you can eat very well for not a lot of money. reply whateveracct 8 hours agorootparentHeh the $1/lb isn't a lie - you can get whole chicken for as cheap as your dried beans! Just gotta pay attention to sales. reply whateveracct 8 hours agorootparentprevMaybe it's because I'm in WA - a huge agricultural state. I get Draper Valley Farms whole chickens for 99c/lb on the regular. It's $2.89/lb (already a good price) when not on sale, but the sale has been happening a couple times a month like clockwork now. The Draper Valley Farms stuff is generally cheaper than the Kroger-branded stuff, no matter the cut. Like right now, boneless thighs are 50c cheaper per lb (no sales). It's $6/lb vs $6.50/lb. Bone-in is $3.79/lb! The Kroger brand doesn't even offer that variety for some reason. A few lbs of that + some orzo (cheap) + some staple produce (shallot, cherry tomatoes, garlic) can make you 6 very filling and delicious meals. When you compare it to fast food, the difference is staggering - definitely a divergence compared to the diff years ago. It's the convenience stuff that is truly spiking. Groceries are definitely a lower % of my income than half a decade ago. The barrier to most people is they can't process a whole chicken. reply tonymet 12 hours agorootparentprevFood , services, insurance , construction costs, healthcare costs, property taxes , materials , fuel , energy reply brandonmenc 6 hours agoparentprev> Remember in 1963 only the man was working, and typically supported 4 kids, a wife and often parents in the home. Yeah, and unless they were like, a doctor or a lawyer, they were living in borderline poverty. reply caesil 14 hours agoprevI don't really understand the argument at the heart of this article, which is \"we should include interest rates in CPI\". How do interest rates effect everyday people exactly, other than price inflation on goods and services (which is included separately in CPI)? The only way seems to be interest rates on personal loans and mortgages. So if anything, we should only include interest rates in proportion to how many people are taking out major loans during the sampled period (and maybe some additional amount based on the effect on adjustable-rate mortgages, etc). Blindly stacking interest rates on top of CPI doesn't really make sense as a measure of personal inflation, and \"it feels like stuff got more expensive\" (as a lot of other comments here argue) isn't so much an argument for this strategy so much as an argument that the CPI 'basket of goods' needs to be rebalanced in other ways. reply caseysoftware 6 hours agoparent> \"The only way seems to be interest rates on personal loans and mortgages.\" Yes, exactly. As noted in the article and the underlying study, 80% of car purchases are done via a loan and financing is not part of the inflation measure. When you look at buying a home, most are also done via loans and still financing is not part of the measure. In both cases, interest rates are a factor in affordability and cost. > Blindly stacking interest rates on top of CPI doesn't really make sense Well then it's good that's not what they're doing. reply robocat 22 minutes agorootparent> interest rates are a factor in affordability and cost Paradoxically over a long term, interest rates don't affect house affordability much. People bid on houses at the limit of what they can spend - the constraint is their income not the interest rate. As interest rates fall, people pay the same interest payments but bid higher on the house price (driving house prices up). As interest rates rise, people spend the same amount monthly (on interest payments) but borrow less in total and can bid less on houses. It is a steady-state argument, so other things do matter (income changes, mortgage qualification rules, immigration into the area, dynamic effects of interest rate changes). Rent has other factors but the constraint of income has parallel effects. reply usaar333 5 hours agorootparentprevI think this is valid for car purchases. I don't buy this is reasonable for home purchases. They already factor imputed rent in CPI; you'd have to somehow do some sort of complex weighing of own vs rent to factor mortgages (complex since it only affects new purchases given most folks are on fixed rate mortgages) reply woodruffw 13 hours agoparentprevThe argument is bunk, and your observation is correct: inflation can be higher than the current CPI predicts, but this does not somehow imply that the CPI basket should factor instruments that do not disproportionately affect ordinary Americans' finances (or double-count ones already accounted for more directly). reply abeppu 13 hours agoparentprev> So if anything, we should only include interest rates in proportion to how many people are taking out major loans during the sampled period Is that right? What about people that didn't buy a home in 2023 because interest rates were high (i.e. they the impact of high interest rates was so large that they _wouldn't appear_ in your weighting because they were pushed out of the market)? reply ethbr1 13 hours agoparentprev> The only way seems to be interest rates on personal loans and mortgages. Most interest rates across the economy are set in relation to a benchmark rate, which loosely follow the Fed rate. E.g. the US prime rate. This effects essentially all credit that isn't fixed rate, which is a huge portion. How this effects you -- the price of credit that businesses use to function, which essentially every business uses, ultimately shows up in the cost of goods. reply Cyph0n 13 hours agoparentprev> So if anything, we should only include interest rates in proportion to how many people are taking out major loans during the sampled period It goes both ways: in that case, we should also discount from CPI calculation the effect of sub-3% mortgages, low/zero interest auto loans, forgiven fraudulent PPP loans, etc. reply bdjsiqoocwk 13 hours agoparentprevIncluding interest rates in CPI muddles the distinction between the price of something vs how to fund the acquisition of something. reply PKop 13 hours agorootparentInterest expense is a real cost people pay. Why ignore it? reply ethbr1 13 hours agorootparentThe reason to ignore it would be mechanical: it's more difficult to measure something when the measurement includes a thing that is adjusted by the measurement. For purposes of setting Fed rates, it makes sense to exclude it. For purposes of measuring perceived inflation, it makes sense to include it. reply PKop 13 hours agorootparent\"inflation rate\" is a nebulous thing. Interest expense and interest rates, concretely paid by people like any other expense is not any more nebulous than tracking other expenditures. We already know the interest rate and various categories of interest expense paid by population. It is just not included. Your rationale sounds very much like \"we shouldn't include it because the inflation rate would be higher\". There is nothing mechanically weird about not ignoring a real expense the economy and people bear the cost of. This isn't touchy feely, this is concrete costs people pay. Not tracking is purely political. reply ethbr1 13 hours agorootparent> Your rationale sounds very much like \"we shouldn't include it because the inflation rate would be higher\". What is the CPI actually used for? To set various levers at the central bank level to manage inflation and keep the economy humming along. One of those levers is... the Fed funds rate... which in turn influences most other interest rates. So you'd be incorporating interest into the measurement used to set interest. reply mitthrowaway2 3 hours agorootparentCPI is used for other things too, including contract negotiations and standard of living comparisons. Anyway, recursive sums like that are nothing unusual; as long as the sum converges it's not a problem. Any negative feedback amplifier does the same thing. reply JumpCrisscross 9 hours agorootparentprev> What is the CPI actually used for? Technically, they pay closer attention to PCE. reply IshKebab 12 hours agorootparentprevIt isn't exactly. Increasing interest can mean you have to pay liabilities unexpectedly early. But it's really the difference between your income and interest that matters. If your income is keeping up with inflation then higher inflation doesn't make you worse off; it just means you are paying off debts faster. reply bdjsiqoocwk 13 hours agorootparentprevIf in a year a burger goes from $5 to $10 and the Fed rate goes from 2% to 5%, what do you think the inflationary factor should be in your methodology? reply boppo1 13 hours agoparentprev>How do interest rates effect everyday people exactly, other than price inflation on goods and services (which is included separately in CPI)? We artificially made interest rates low (look up open market operations). Low rates make risky ventures more financially attractive by making the DCF denominator smaller. People look to invest in growth instead of reliable revenue. That is, \"bet on the future\" becomes dramatically more attractive than \"goods and services being made now\". Additionally, it devalues wages and increases the value of financial assets. It's literally \"rich get richer: the policy\". Anyone who is upset about NFTs millionares existing while EMS workers and teachers struggle, or upset about billionaires' staggering wealth inequality, or fraudulent do-nothing scam businesses like WeWork and Theranos, obviously stupid ventures like Juicero, or basically any economic upside-downness that most laypeople have recently come to blame on \"capitalism\" need look no further than LIRP and ZIRP. We snapped all the fingers of the invisible hand, but did it far upstream of anything that average people pay attention to. Anyone who wasn't paid in equity got fucking robbed over the last 20 years. I don't really agree that interest should be included in CPI, but I do agree that CPI (and PCE) is an absolute joke that doesn't measure what it claims to. reply PKop 13 hours agoparentprevWhat is confusing? The argument for including them is that people pay them. >Blindly stacking Stawman nonsense that literally no one suggested reply csomar 2 hours agoprevThe CPI is kinda fine and should not include interest rates. The CPI is used to measure price inflation and not individual misery and should be left to do just that. Wait, there is actually a misery index: https://en.wikipedia.org/wiki/Misery_index_(economics) It would have been better to invest in such an index. Here is a simplified example: The US is made of two cities; NYC and midland. Inflation rate is 0% for both and misery is non-existent. midland now has no jobs. None. So people move to NYC and inflate prices there. Inflation in NYC is 20% while deflation in midland is 30%. The Fed works the numbers and says that overall inflation is around 2% for the whole country and so everything is fine. The reality is that misery is sky high; people are being burnt by prices in NYC and can't find jobs/buyers in midland. They have to move at high personal costs or close their businesses in the midland. On the other hand, they struggle to make a living in the new NYC town. reply kalkin 6 hours agoprevInteresting that the article doesn't mention what seems to be an obvious takeaway if you believe that interest rates explain the gap between CPI and sentiment: raising interest rates to fight inflation will make people feel inflation is worse. I'm suspicious that this isn't mentioned because Summers and Roy are inflation hawks who've advocated the Fed raise rates and the alleged fact that people will experience this as increased inflation at least in the short term is politically inconvenient for them, even as they'd like to claim inflation is worse than the CPI says so they can claim vindication for their hawkishness... reply mike_hearn 5 hours agoparentIt does seem to say that: As the debt increases, the federal government has to borrow more money from U.S. and foreign investors. But as would-be lenders to the U.S. see America as increasingly insolvent, investors will demand higher interest rates to lend us that money. Higher rates of government borrowing lead to higher rates for home mortgages, credit cards, student loans, car loans, and every other form of borrowing. And, as we’ve seen, these higher interest rates lead to higher price inflation, whether or not the Bureau of Labor Statistics recognizes it as such. reply bjornsing 2 hours agoprevIn Sweden we measure inflation both with and without interest rate changes. The latter measure is called KPIF (“konsumentprisindex med fast ränta” / “consumer price index with fixed interest rate”). The central bank inflation target of 2% is formally for this KPIF. As I understand it KPIF includes borrowing costs (e.g. car loans), but at a fixed fake / interest rate. It sounds complicated, but I think this is actually the right approach. reply alephnerd 13 hours agoprevHere is the actual paper - https://www.nber.org/papers/w32163 Fundamentally, the argument is \"The Cost of Money is Part of the Cost of Living\" (as the paper's title states). The trillion dollar question is whether it really does. Based on the backtesting done the paper, it spiked extremely high in late 2023, and then drastically fell to 1980s levels. If we use Summers' argument, then the Reagan era was a high inflation era as well (as the paper itself shows). Tbf, this is the very reason the CPI was changed. The rate of change of Cost of Goods has fallen, and incomes at the median level has risen, but housing remains expensive. That said, lower interest rates aren't going to change squat, as the number of houses built has basically crashed to nil after 2008. There is a supply issue and it's not because of zoning - it's because financing dried up after the entire real estate financial sector collapsed in the 2008-11 period. The Forbes contributer themselves is not a good source, as they gloss over a significant portion of the paper, and their think tank (FREOPP) is partisan [0] P.S. I am opposed to partisan shilling on both sides of the aisle on policy related subjects. We are all on the same team - America - and we better darn act like it. Screw the EPI and screw FREOPP. [0] - https://www.c-span.org/video/?529864-3/avik-roy-freedom-cons... reply slibhb 14 hours agoprevIt's interesting that consumer sentiment apparently tracks the older formula more closely. Presumably we have data that could allow us to include \"the price of money\" in inflation metrics, perhaps weighed based on how much the average American borrows. reply jeffbee 14 hours agoparentHeadline consumer sentiment is polluted by junk like this article. People report their personal household situation is fine and they expect it to continue being at least this good or better in 1 and 5 years. But they've heard so much shadowstats horseshit on the radio that they are compelled to stake out a negative view on the economy as a whole. In the latest UMich consumer survey majority of respondents expect their incomes to grow faster than prices, in fact the reported probability of real personal income rising has never been higher in the history of the survey. And, with respect to inflation, consumers expect incomes to rise about 2.5% per year, and that expectation is higher than the expected increase in prices. During times of very high inflation respondents reported expectations of 6% nominal income increases. So this is all consistent with the idea that inflation as people actually experience it has been moderate. But, further down the February results, you can see that record numbers of people report hearing negative news stories about prices, way way way higher than in 1980! Which is totally crazy if you were here in 1980! You can also read further and see that expectation of rising unemployment have been consistently high for the last 5 years, and reports of having heard news stories about unemployment have been at record highs, while responses about the probability of losing their own job are at record lows and of course objective unemployment is almost dangerously low. reply Phiwise_ 11 hours agorootparent>But, further down the February results, you can see that record numbers of people report hearing negative news stories about prices, way way way higher than in 1980! Which is totally crazy if you were here in 1980! If you had taken a moment to consider the data presented in the article instead of dismissing it out of hand because it offends your sensibilities, you would realize it states that it obviously implies it is not crazy to hear more news about inflation nowadays than in the 1980s, because it shows inflation is worse nowadays than in the 1980s. Feel free keep raving about how you get a much better vibe from the economy today despite the info if that's what matters more to you, though. reply bryanlarsen 11 hours agorootparent> because it shows inflation is worse nowadays than in the 1980s. Obviously you didn't live through the 1980's, because that is obviously false to anybody who has. reply Phiwise_ 9 hours agorootparent>If these facts are so right, why do they sound false to me? Again, this appeal to the vibe you're getting right now is not compelling to anyone who actually cares about economics. reply Nimitz14 8 hours agorootparentHis vibes agree with what economists think. Look up what happened in the late 70s and early 80s. reply rafaelero 7 hours agorootparentprevNothing you said has anything to do with the article and its proposal to incorporate interest rates into inflation. Maybe it's your type of post that should be considered polution. reply PKop 13 hours agorootparentprevWhat does any of this have to do with ignoring the price of money, a real cost that people have to pay? reply ein0p 14 hours agoprevThat seems subjectively accurate, looking at my grocery store receipts and $13/lb meat. Certainly more accurate than “3.5%” bullshit the “free press” is asking us to believe. reply Cyph0n 13 hours agoparentAnother indicator is how quickly people resort to strawman arguments instead of responding to the point - “why are you buying good cuts of meat??”. reply throw0101c 13 hours agoparentprev> That seems subjectively accurate, looking at my grocery store receipts and $13/lb meat. Certainly more accurate than “3.5%” bullshit the “free press” is asking us to believe. You do know that the CPI (and CPE) are made up of components, right? Like Shelter, Energy, Transportation… Food. Food can go up more that 3.5% while other items (like Transportation/Energy/Oil) go down, so on average the prices you see have gone up by 3.5%. The individual components may be more (or less) than the 3.5% average. Further, the CPI is an average basket of goods and services (taken from spending surveys done by many people), which may or may not correspond to what you personally put in your own basket. In Canada, StatCan has a Personal Inflation Calculator where you can enter budget as see your personal inflation rate which may be different than the headline inflation rate: * https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2020cal... * https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2020015... Further, the number you see in headlines is a national average which may be different to what has happened to your local prices. TL; DR: model of reality ≠ reality. reply ein0p 11 hours agorootparentCPI is designed to make the government look good, hence the article. reply throw0101c 11 hours agorootparent> CPI is designed to make the government look good, hence the article. The CPI is run by the Bureau of Labor Statistics: > The \"food price index\" evolved into what we now call the Consumer Price Index (CPI). During World War I, rapid in­creases in prices, particularly in shipbuilding centers, made a more comprehensive index essential for calculating cost-of-living adjust­ments in wages. Studies of family expenditures were conducted in 92 industrial centers in 1917–19 in order to provide appropriate weighting patterns for the index. Periodic collection of prices was started and, in 1919, the Bureau of Labor Statistics (BLS) began publication of separate consumer price indexes for 32 cities. Regular publication of a national index, the U.S. city average, began in 1921, and indexes were estimated back to 1913. * https://www.bls.gov/opub/hom/cpi/history.htm It is one of most examined numbers in statistics, and while the \"best\" way† to do things is debated, are there any non-tin-foil hat people that think that the numbers are actually wrong given the published methodologies? Entire research projects (which have released source code) have examined the official numbers and found that they track things fairly well: * https://en.wikipedia.org/wiki/MIT_Billion_Prices_project † Often no such thing exists, but rather trade-offs in various metrics. reply tsimionescu 5 hours agorootparent> are there any non-tin-foil hat people that think that the numbers are actually wrong given the published methodologies? No, but the whole point of the poster above, and of the article we're commenting on, is that the methodologies themselves are wrong (i.e. that they don't measure what people really care about, they measure something that the government thinks will look better than reality). This is a very common problem in economics: numbers agree very well with the models, but the models themselves are barely applicable to reality. reply Phiwise_ 9 hours agorootparentprev>> CPI is designed to make the government look good, hence the article. >The CPI is run by the Bureau of Labor Statistics: ... https://www.bls.gov/opub/hom/cpi/history.htm You do notice that your link to back up disagreeing with the assertion of potential government bias is to a .gov domain, surely? reply raincole 5 hours agorootparentI really like how they put Labor in italics. As if that disputed the fact it's part of the government. reply 542458 5 hours agorootparentprevIf the CPI was designed to make the government look good it wouldn’t use a modified Laspeyres index which introduces overestimation bias by assuming substitution does not happen between basket adjustments. It would be trivial to use a different index type which introduces the opposite bias, but they don’t. reply maxerickson 13 hours agoparentprevMeat was already expensive a year ago, it isn't unlikely that the price increased about 3.5%. And then of course, they often report monthly numbers on an annualized basis. reply ein0p 10 hours agorootparentWe’re at a point where my bigtech six figure circles are starting to notice and switch to chicken. But by all means do please continue to deny reality. Because by the looks of it we’re headed into a Carter style stagflation for the next 15 years. reply esoterica 2 hours agoparentprevDid you read the article at all? Unless you were buying meat with personal loans the issue of whether or not interest expenses should be included in CPI has no relev",
    "originSummary": [
      "Economists from Harvard and the IMF, led by Lawrence Summers, claim that the 2022 inflation rate surged to 18% because the CPI formula excludes interest costs.",
      "Rising interest rates, not factored into official inflation figures, are adding economic strain on Americans based on the researchers' argument.",
      "The analysis emphasizes the necessity of reevaluating how consumer price inflation is measured, suggesting that different measures can affect diverse socioeconomic groups disparately."
    ],
    "commentSummary": [
      "The article explores inflation discrepancies, especially in the Consumer Price Index (CPI), highlighting its impact on prosperity and economic disparities.",
      "It discusses historical events, political ideologies, changing living standards, interest rates' influence on inflation, and housing affordability.",
      "Emphasizes the significance of diverse viewpoints and historical contexts in analyzing inflation's societal effects and the call for improved economic indicators."
    ],
    "points": 285,
    "commentCount": 277,
    "retryCount": 0,
    "time": 1713036282
  },
  {
    "id": 40023319,
    "title": "Tree-Shaking: Optimizing WebAssembly Efficiency",
    "originLink": "https://wingolog.org/archives/2023/11/24/tree-shaking-the-horticulturally-misguided-algorithm",
    "originBody": "tree-shaking, the horticulturally misguided algorithm 24 November 2023 11:41 AM schemeguilehootwasmwebassemblydcetree-shakinggcgarbage collectionpythongoclojureclojurescriptcompilersigalia Let’s talk about tree-shaking! looking up from the trough But first, I need to talk about WebAssembly’s dirty secret: despite the hype, WebAssembly has had limited success on the web. There is Photoshop, which does appear to be a real success. 5 years ago there was Figma, though they don’t talk much about Wasm these days. There are quite a number of little NPM libraries that use Wasm under the hood, usually compiled from C++ or Rust. I think Blazor probably gets used for a few in-house corporate apps, though I could be fooled by their marketing. You might recall the hyped demos of 3D first-person-shooter games with Unreal engine again from 5 years ago, but that was the previous major release of Unreal and was always experimental; the current Unreal 5 does not support targetting WebAssembly. Don’t get me wrong, I think WebAssembly is great. It is having fine success in off-the-web environments, and I think it is going to be a key and growing part of the Web platform. I suspect, though, that we are only just now getting past the trough of disillusionment. It’s worth reflecting a bit on the nature of web Wasm’s successes and failures. Taking Photoshop as an example, I think we can say that Wasm does very well at bringing large C++ programs to the web. I know that it took quite some work, but I understand the end result to be essentially the same source code, just compiled for a different target. Similarly for the JavaScript module case, Wasm finds success in getting legacy C++ code to the web, and as a way to write new web-targetting Rust code. These are often tasks that JavaScript doesn’t do very well at, or which need a shared implementation between client and server deployments. On the other hand, WebAssembly has not been a Web success for DOM-heavy apps. Nobody is talking about rewriting the front-end of wordpress.com in Wasm, for example. Why is that? It may sound like a silly question to you: Wasm just isn’t good at that stuff. But why? If you dig down a bit, I think it’s that the programming models are just too different: the Web’s primary programming model is JavaScript, a language with dynamic typing and managed memory, whereas WebAssembly 1.0 was about static typing and linear memory. Getting to the DOM from Wasm was a hassle that was overcome only by the most ardent of the true Wasm faithful. Relatedly, Wasm has also not really been a success for languages that aren’t, like, C or Rust. I am guessing that wordpress.com isn’t written mostly in C++. One of the sticking points for this class of language. is that C#, for example, will want to ship with a garbage collector, and that it is annoying to have to do this. Check my article from March this year for more details. Happily, this restriction is going away, as all browsers are going to ship support for reference types and garbage collection within the next months; Chrome and Firefox already ship Wasm GC, and Safari shouldn’t be far behind thanks to the efforts from my colleague Asumu Takikawa. This is an extraordinarily exciting development that I think will kick off a whole ‘nother Gartner hype cycle, as more languages start to update their toolchains to support WebAssembly. if you don’t like my peaches Which brings us to the meat of today’s note: web Wasm will win where compilers create compact code. If your language’s compiler toolchain can manage to produce useful Wasm in a file that is less than a handful of over-the-wire kilobytes, you can win. If your compiler can’t do that yet, you will have to instead rely on hype and captured audiences for adoption, which at best results in an unstable equilibrium until you figure out what’s next. In the JavaScript world, managing bloat and deliverable size is a huge industry. Bundlers like esbuild are a ubiquitous part of the toolchain, compiling down a set of JS modules to a single file that should include only those functions and data types that are used in a program, and additionally applying domain-specific size-squishing strategies such as minification (making monikers more minuscule). Let’s focus on tree-shaking. The visual metaphor is that you write a bunch of code, and you only need some of it for any given page. So you imagine a tree whose, um, branches are the modules that you use, and whose leaves are the individual definitions in the modules, and you then violently shake the tree, probably killing it and also annoying any nesting birds. The only thing that’s left still attached is what is actually needed. This isn’t how trees work: holding the trunk doesn’t give you information as to which branches are somehow necessary for the tree’s mission. It also primes your mind to look for the wrong fixed point, removing unneeded code instead of keeping only the necessary code. But, tree-shaking is an evocative name, and so despite its horticultural and algorithmic inaccuracies, we will stick to it. The thing is that maximal tree-shaking for languages with a thicker run-time has not been a huge priority. Consider Go: according to the golang wiki, the most trivial program compiled to WebAssembly from Go is 2 megabytes, and adding imports can make this go to 10 megabytes or more. Or look at Pyodide, the Python WebAssembly port: the REPL example downloads about 20 megabytes of data. These are fine sizes for technology demos or, in the limit, very rich applications, but they aren’t winners for web development. shake a different tree To be fair, both the built-in Wasm support for Go and the Pyodide port of Python both derive from the upstream toolchains, where producing small binaries is nice but not necessary: on a server, who cares how big the app is? And indeed when targetting smaller devices, we tend to see alternate implementations of the toolchain, for example MicroPython or TinyGo. TinyGo has a Wasm back-end that can apparently go down to less than a kilobyte, even! These alternate toolchains often come with some restrictions or peculiarities, and although we can consider this to be an evil of sorts, it is to be expected that the target platform exhibits some co-design feedback on the language. In particular, running in the sea of the DOM is sufficiently weird that a Wasm-targetting Python program will necessarily be different than a “native” Python program. Still, I think as toolchain authors we aim to provide the same language, albeit possibly with a different implementation of the standard library. I am sure that the ClojureScript developers would prefer to remove their page documenting the differences with Clojure if they could, and perhaps if Wasm becomes a viable target for Clojurescript, they will. on the algorithm To recap: now that it supports GC, Wasm could be a winner for web development in Python and other languages. You would need a different toolchain and an effective tree-shaking algorithm, so that user experience does not degrade. So let’s talk about tree shaking! I work on the Hoot Scheme compiler, which targets Wasm with GC. We manage to get down to 70 kB or so right now, in the minimal “main” compilation unit, and are aiming for lower; auxiliary compilation units that import run-time facilities (the current exception handler and so on) from the main module can be sub-kilobyte. Getting here has been tricky though, and I think it would be even trickier for Python. Some background: like Whiffle, the Hoot compiler prepends a prelude onto user code. Tree-shakind happens in a number of places: partial evaluation will evaluate unused bindings for effect, possibly eliding them fixing letrec will do the same CPS frequently traverses the program, following only referenced function, value, and control edges, e.g. via renumbering There is an explicit dead-code elimination pass which tries to elide unused effect-free allocations, a situation that can arise due to other optimizations Finally there is a standard library written in raw-ish WebAssembly, whose definitions (globals, tables, imports, functions, etc) are included in the residual binary only as neeeded. Generally speaking, procedure definitions (functions / closures) are the easy part: you just include only those functions that are referenced by the code. In a language like Scheme, this gets you a long way. However there are three immediate challenges. One is that the evaluation model for the definitions in the prelude is letrec*: the scope is recursive but ordered. Binding values can call or refer to previously defined values, or capture values defined later. If evaluating the value of a binding requires referring to a value only defined later, then that’s an error. Again, for procedures this is trivially OK, but as soon as you have non-procedure definitions, sometimes the compiler won’t be able to prove this nice “only refers to earlier bindings” property. In that case the fixing letrec (reloaded) algorithm will end up residualizing bindings that are set!, which of all the tree-shaking passes above require the delicate DCE pass to remove them. Worse, some of those non-procedure definitions are record types, which have vtables that define how to print a record, how to check if a value is an instance of this record, and so on. These vtable callbacks can end up keeping a lot more code alive even if they are never used. We’ll get back to this later. Similarly, say you print a string via display. Well now not only are you bringing in the whole buffered I/O facility, but you are also calling a highly polymorphic function: display can print anything. There’s a case for bitvectors, so you pull in code for bitvectors. There’s a case for pairs, so you pull in that code too. And so on. One solution is to instead call write-string, which only writes strings and not general data. You’ll still get the generic buffered I/O facility (ports), though, even if your program only uses one kind of port. This brings me to my next point, which is that optimal tree-shaking is a flow analysis problem. Consider display: if we know that a program will never have bitvectors, then any code in display that works on bitvectors is dead and we can fold the branches that guard it. But to know this, we have to know what kind of arguments display is called with, and for that we need higher-level flow analysis. The problem is exacerbated for Python in a few ways. One, because object-oriented dispatch is higher-order programming. How do you know what foo.bar actually means? Depends on foo, which means you have to thread around representations of what foo might be everywhere and to everywhere’s caller and everywhere’s caller’s caller and so on. Secondly, lookup in Python is generally more dynamic than in Scheme: you have __getattr__ methods (is that it?; been a while since I’ve done Python) everywhere and users might indeed use them. Maybe this is not so bad in practice and flow analysis can exclude this kind of dynamic lookup. Finally, and perhaps relatedly, the object of tree-shaking in Python is a mess of modules, rather than a big term with lexical bindings. This is like JavaScript, but without the established ecosystem of tree-shaking bundlers; Python has its work cut out for some years to go. in short With GC, Wasm makes it thinkable to do DOM programming in languages other than JavaScript. It will only be feasible for mass use, though, if the resulting Wasm modules are small, and that means significant investment on each language’s toolchain. Often this will take the form of alternate toolchains that incorporate experimental tree-shaking algorithms, and whose alternate standard libraries facilitate the tree-shaker. Welp, I’m off to lunch. Happy wassembling, comrades! related articles requiem for a stringref missing the point of webassembly a world to win: webassembly for the rest of us just-in-time code generation within webassembly the half strap: self-hosting and guile a register vm for guile 2 responses Hubert says: 27 November 2023 2:25 AM Très belle discussion! I followed the link to the Pyodide REPL example, noting the 20MB download, but this is an repl and so I expect it brings a lot of capability with it (compared to “just an app”). Typing 3 + 5 semicolon and enter in it, it replied with 8, which is nice. What I wonder then is if a scheme repl coded using guile-Hoot (for example) could be expected to form a much smaller download? Also, I noticed that the Pyodide REPL kept one of my machine’s cores 100 percent busy at all times (even when not interacting with it; in Firefox) and would hope that other repls (eg. for Scheme) would be less “computationally” demanding. Ole Laursen says: 27 November 2023 3:03 PM On a horticultural note, it’s common to have to shake weeds violently to get the dirt off their roots. Trees grow as weed too, but are extremely difficult to pull out unless they are very small. So weed shaking might be a better name. Perhaps also in other respects more appropriate. Comments are closed.",
    "commentLink": "https://news.ycombinator.com/item?id=40023319",
    "commentBody": "Tree-shaking, the horticulturally misguided algorithm (2023) (wingolog.org)209 points by andsoitis 20 hours agohidepastfavorite126 comments __s 19 hours agoI've kept openEtG's wasm blob (card game engine)is there so no need to bring in Box or anything. Getting away from floats/hashmaps helped reduce type diversity 7. design algorithms with size in mind, I have a couple lookup tables where I pack bits https://github.com/serprex/openEtG/blob/2011007dec2616d1a24d... encodes an adrenaline mechanic where multiple attacks give lower attack power creatures more attacks than higher attack power creatures. Care was taken comparing how much decoding logic cost compared to storing unpacked values. AI evaluation uses 6 bit fixed precision because 64 encodes more efficiently than 128 in webassembly Similarly there's a targeting mechanism with AND/OR & predicates. I used to have an AST like format with each predicate getting an enum & AND/OR being a slice of expressions. Now each expression is 32 bit integers encoding expression in polish notation, AND/OR have 2 bit codes & predicates are 6 bits (polish notation won over reverse polish here because with polish notation I was able to have AND/OR short circuit evaluation) reply crabmusket 6 hours agoparent> 1. avoid floats (fixed point arithmetic saved quite a bit of space) This is really interesting, since WASM has built in float types of course - is there any more detail you can go into / examples you can show us? I have a problem at work where I was thinking fixed point arithmetic might help, because I know my maximum resolution needs (e.g. I know the problem will never care about sub-millimetre positioning). I'd be interested to hear more about related issues. reply josephg 9 hours agoparentprevMore things that I've found helped: - Use wasm-opt from binaryen. That seems to reliably drop wasm size by ~20-30%. ( https://github.com/WebAssembly/binaryen ) - Use brotli compression for serving wasm bundles to the browser, and make sure your web server is setup to use the brotli compressed files. (Its a 1 line change in nginx, for example). Brotli drops the size of wasm bundles by about 3x. Its much better than gzip for wasm. reply WanderPanda 15 hours agoparentprevI've been working on a C++ deep RL library (RLtools) and also created some WASM examples (https://rl.tools). I didn't pay any attention to the binary size at all but it turns out it is also just around 200-300kb (including everything, deep learning forward/backward, RL algo and dynamics simulation). Even though it's not prohibitive rn, I'm curious how small it could be and hopefully find some time soon to squeeze it down reply 01HNNWZ0MV43FF 19 hours agoparentprevWow! Do you have numbers anywhere showing the space saved? Especially for step 6, using a Vec as a Box, I would not expect that to save much. reply pdpi 18 hours agorootparent> Especially for step 6, using a Vec as a Box, I would not expect that to save much. It's not that using a Vec as a Box saves anything at all. It's that generics require monomorphisation, and that eats up a bunch of space, and more instances of generic types translates into more space. If your application uses Vec elsewhere, you've already paid the binary size price for using it. Vec is close enough to Box that the functional differences don't warrant the extra code generation. reply __s 19 hours agorootparentprevUnfortunately nothing concrete, it's a few kb here & there. I'd estimate I've saved ~300kb overall. I'd have to go back to compare these things. Removing floats saved more space than I expected Also important is configuring compiler correctly, [profile.release] opt-level = \"z\" lto = \"fat\" codegen-units = 1 reply nextaccountic 12 hours agorootparentprevhe meant Box (aka fixed-size vec or heap allocated array) rather than Box (a single heap allocated element) reply chongli 17 hours agoparentprevavoid floats (fixed point arithmetic saved quite a bit of space) Can someone help me understand how this works? I thought JavaScript uses doubles for everything. Is WASM completely different in this regard? reply colejohnson66 16 hours agorootparentYes. WASM has proper integer and floating-point types. reply wongarsu 15 hours agorootparentAnd even JavaScript only conceptually uses doubles everywhere, JavaScript engines do use integers where they get away with it. Your loop counter is almost certainly an int. You can use this to your advantage for optimization purposes if you carefully craft your statements to probably fit in integers (e.g. by adding bitwise operations) reply rowanG077 10 hours agoparentprevWhy do floats and strings have such a high cost? reply josephg 8 hours agorootparentStrings seem to have a high cost because there's a lot of complexity in rust's format! macros. And the generated code seems to end up with a lot of obscure ways it can panic. I've found just having one stray dbg!() in my rust code can add ~20kb to my wasm bundle size. Look at what a single dbg!(some_u32) generates: https://rust.godbolt.org/z/bex9z8vx7 . Its also calling into a bunch of garbled functions in the standard library - which will bring in a lot more code. I suspect zig's comptime approach might work much better for for this sort of thing, if we want smaller binary sizes. reply 38 7 hours agoparentprevjesus christ, just do a desktop app. by your own admission you only saved 300k with all that. a desktop app at 700k is nothing, which means you could ignore all these optimizations and focus on improving speed or adding features reply titzer 19 hours agoprevTree-shaking is such a bad misnomer. Virgil's compiler calls this \"reachability analysis\" and it's built into the compilation model. The compiler will parse and typecheck a program's (and libraries' code), and run initializers, but after that the compilation proceeds by exploring from the main entrypoint(s) and only reachable code is analyzed and ends in the final binary. It will happily generate a program (without runtime system) that just consists of a single main function. The runtime system is only necessary for stacktraces and GC, and can be omitted if desired. reply lispm 17 hours agoparentThe name \"treeshaker\" for an application delivery tool possibly originated in Lisp. The first time I've found it was in Lucid Common Lisp, a (no longer available) commercial implementation of Common Lisp for UNIX. Lucid CL 4.1 in 1992 included a tool called Treeshaker. Lucid CL was one of those Lisps which have the idea of an image (see for example the \"image\" feature of Lisp 1 in 1960), a saved memory dump of the current heap of a running Lisp. An application then is an image plus a runtime. The image typically includes almost all code AND data from the memory, which sometimes creates the wish to create smaller images for application delivery. Lucid CL then included a tool, which before saving that image, removes all kinds of unused code and data, depending on some meaning of what „unused“ means. For example the symbol table may have variables, types, functions, etc. which are not referenced anywhere. A treeshaker tool might also get a list of things to remove. Thus in a graph of reachable Lisp data&code, the connections are pruned. Either a GC or a specialized piece of code then collects the garbage, shrinks memory (-> shakes the tree and everything which is cut loose is falling down) and dumps it as a possibly smaller image. The treeshaker thus was not a compiler tool, but a tool to remove what was determined to be unused code of a Lisp heap. Remember, by default such a Lisp image would also contain a compiler, an interpreter and an implementation of a read-eval-print loop. Thus if we break (-> interrupt a thread which then provides a REPL) a running program into such a read-eval-print loop, we could still use all the code, which is in this heap (which was restored from an image). Thus it would make sense to remove the compiler too, and possibly the read-eval-print loop, too. reply munificent 10 hours agorootparentI could be wrong, but I've heard that the term originated in Smalltalk. Smalltalk is also image-based, and tree-shaking was a way to produce a smaller image for deploying. reply lispm 2 hours agorootparentprevReferences: Lucid Inc. used the word internally at least since 1987, mentioning a treeshaker for Lucid CL 3.0 on the VAX. \"Lisp Systems in the 1990s\", Layer/Richardson, 1991 https://dl.acm.org/doi/10.1145/114669.114674 From above: \"In contrast, tree shaking uses the approach of eliminating --shaking out-- what is not needed in a static fashion. Programmers specify the requirements of their application and the unneeded parts of the Lisp system are removed using their detailed knowledge of the application. The disadvantages of tree shaking are that it requires programmer intervention and that a function which is shaken out cannot be easily restored.\" \"Building Common Lisp Applications with Reasonable Performance\", Boreczky/Rowe, 1993, https://dl.acm.org/doi/10.1145/1040032.174174 \"Lisp: Good News, Bad News, How to Win Big\", Gabriel, (not sure from when this version is, the original article is from 1989) https://www.dreamsongs.com/Files/LispGoodNewsBadNews.pdf From Gabriel's essay: > \"1.6.3 The Treeshaker > Most Lisp development systems, including Lucid’s, provide all the resources of the Lisp system by default, and this in turn leads to a style of development in which the programmer makes use of whatever tool happens to be most convenient. Because much of the basic Lisp system (or any development system built on top of the basic Lisp system) will generally be unused by a given application, it is very worthwhile to have a tool for excising these unused parts. This tool is called the Treeshaker. > Treeshaker execution occurs in three phases: walking, testing and writing. In the walking phase, the Treeshaker accumulates a set of objects that need to be included in the saved image. After making this set, the treeshaker runs a test of the application to check that all objects which are used in a typical run have been included. The writing phase then generates an executable image which will run the application. > To a first approximation, the walk phase is just a matter of computing the connected component of the Lisp image (treated as a directed graph in the obvious way) generated by the application’s toplevel function. However, because of the way that Lisp objects are generally connected this usually includes almost the entire Lisp image including the unused subsystems. Therefore the treeshaker uses several techniques to find connections between objects that do not actually need to be followed in the walk.\" > \"The name Treeshaker is meant to be evocative of the idea of actually shaking a tree to dislodge dead branches or other trash.\" On the more funny side, LispWorks has a keyword to the DELIVER function :shake-shake-shake , which invokes the treeshaker during application delivery. https://www.lispworks.com/documentation/lw80/deliv/deliv-key... reply layer8 16 hours agoparentprevThe correct general term is “dead-code elimination” [0]. Reachability analysis is commonly used do determine what code can be removed, but other methods are possible, and the analysis by itself doesn’t remove any code, that’s a subsequent step. “Tree-shaking” as commonly used implies that the granularity of the removal is functions, whereas dead-code elimination can generally be at arbitrarily fine levels, for example eliminating branches of conditional expressions, and can be based on all kinds of static program analyses. [0] https://en.wikipedia.org/wiki/Dead-code_elimination reply GrumpySloth 9 hours agorootparentAlthough true, in most cases when people talk about dead code elimination, they refer to eliminating code inside a function, whereas tree-shaking unambiguously refers to inter-procedural dead code elimination. reply SkyPuncher 18 hours agoparentprevMany things in software are misnomers. Personally, I think it’s an amazing name. The first time I saw the term, I knew exactly what it was without any further research. You shake a tree to remove the loose things. In this case, it was clear that unused packages are being “shaken” from the tree. reply cout 9 hours agorootparentIt makes sense to me now, but the first time I heard the term it brought to mind Wreckx-n-Effect. I am glad there was no connection. reply torgoguys 13 hours agorootparentprevThe reason I didn't like the name when I first came across it is that I think of shaking the tree for harvesting the fruit. The fruit is what you want, not what you want to eliminate. But it's an ok term overall. reply wtetzner 14 hours agoparentprev> Tree-shaking is such a bad misnomer. I don't think so. I never considered tree-shaking to refer to the plants, rather the data structure. If you imagine the diagram of some source code as a physical object, then shaking it would cause anything unreachable from the root to fall away. I really don't see how reachability analysis is any different. One term just invokes a more spacial sense of reasoning. reply IshKebab 13 hours agorootparentReachability analysis is a far far far far superior term because it actually describes what it is. Wtf is \"tree shaking\"? I was confused about this for ages until I realised it was just a fucking stupid term for dead code elimination. If your term is confusing as fuck until you say \"it just means X\" then that is a stupid useless idiotic term. reply paulddraper 18 hours agoparentprevHow so? There is lots of code (tree). Some of the code is not connected to the entry point (trunk). Tree shaking removes the disconnected parts (loose leaves, dead branches). reply naasking 18 hours agorootparentDead branches and loose leaves are still connected to a real tree, that's why it's a misnomer. \"Raking\" would be a better name if you want to keep to the metaphor. Dead code elimination is the most precise term, and is already well established. reply rurban 5 hours agorootparentTree shaking is the established lisp term, but not used for compilers, but packagers, to shrink images. Dead branches are NOT stored in the pruned image. Dead code elimination came 20 years later with C compilers. The problem with treeshaking - I wrote my first for my lisp 30 years ago, it was trivial - is the lack of compile-time evaluation. The more the compiler knows, the more it can prune. Every run-time branch, late binding and esp. dynamic call by string kills it. With simple tricks you can eliminate 90% of your code. IO, error handling, the number tree, lots of slack in the stdlib's. With GUI even more. I heard from CL images shrinked from 2GB down to a floppy disk. reply lispm 17 hours agorootparentprevOne is pruning dead stuff and shaking the tree is then letting them fall down. The garbage collector then takes it away. reply em-bee 17 hours agorootparentprevdead branches and loose leaves are connected to a real tree in the same way that dead code is connected to the program in a file. if you break off the dead branch, nothing happens to the tree, just like when you remove unused code, nothing happens to the program. reply naasking 16 hours agorootparent> if you break of the dead branch, nothing happens to the tree, just like when you remove unused code, nothing happens to the program. Indeed, and this has been known since the 80s as dead code elimination. So why are we using a new, less descriptive, more confusing term again? reply HumanOstrich 14 hours agorootparentLanguage and terminology evolve over time. It can be uncomfortable and challenging to adapt. Some new developers might be introduced to the concept initially as \"tree-shaking\". It's not wrong; it just differs from your preference. reply naasking 13 hours agorootparentI learned of tree shaking first, and DCE is clearly superior as a term: 1) it's actually descriptive, 2) there's a large literature using this term to look for further information, and 3) as the original poster noted, it's not actually a misnomer. There is literally no advantage to the new term that I can think of. reply Dylan16807 7 hours agorootparentDCE is too general. Tree-shaking is specifically the form of DCE where you remove unreferenced functions/modules. Especially important is that you can do tree-shaking without analyzing control flow, while by default \"DCE\" implies you're analyzing control flow. And I don't think tree-shaking is a misnomer. Depending on how you visualize the metaphor, unreferenced functions are either barely attached or not attached. Shaking them off is simple and sufficiently realistic. reply lolinder 18 hours agorootparentprevTree shaking is also well established in the JavaScript world, more so than DCE, so it's pretty natural for it to be used in a wasm context. reply naasking 16 hours agorootparentDCE is a standard compiler optimization that's been been around since at least the 80s. It's done in multiple different ways, and \"tree shaking\" is just one more way. Whether the term DCE is known doesn't seem relevant to what is the most descriptive and meaningful term for this optimization. reply fenomas 2 hours agorootparentI can't speak to origins, but currently in the JS world DCE and tree-shaking refer to different things. \"Tree-shaking\" normally refers to when the bundler omits unreachable code, that a more naive bundler would have included. It's an oft-discussed topic because it wasn't possible to do in some earlier module formats, and some bundlers do it better than others. In this context the \"tree\" mostly refers to the dependency tree. In contrast DCE usually refers what the JS engine does at runtime, via whatever means. But DCE isn't much discussed, unless one talking about v8 internals or the like. reply ratmice 8 hours agorootparentprevDCE has been around at least since 1971 Frances E. Allen's \"A catalogue of optimizing trasformations\", but I don't have her earlier papers/internal ibm memos to be able to say, but the section on DCE in that paper didn't appear to contain any further references. reply paulddraper 17 hours agorootparentprevHave you... Ever seen a tree? And what happens when the wind blows? Shaking and raking are hardly different in kind. reply naasking 16 hours agorootparent> And what happens when the wind blows? And wind blowing has what to do with compiler optimizations again? > Shaking and raking are hardly different in kind. The only way they're similar is that they're both kinda dumb names for this optimization that has had a standard name for 40 years. reply paulddraper 12 hours agorootparent> And wind blowing has what to do with compiler optimizations again? The wind blowing shakes the tree. When the tree shakes, the dead branches and loose leaves are removed. --- This is similar to when a bundler will traverse the connected code graph and remove the things that are not attached. reply hinkley 18 hours agoparentprevProving yet again that there aren’t enough gardeners in computer science. The metaphor we use for optimization is “low hanging fruit” which no orchard owner would ever do. It’s massively wasteful, be you a programmer or a farmer. It’s what amateurs do. I do tree shaking. Pick a tree (subject matter in the code) and get all of the fruit that’s willing to fall off before moving to the next. It’s more efficient, more effective, and more sustainable. It works with human factors instead of against them. What we call tree shaking is more like tree pruning. Specifically what you’d call thinning (tracing a misplaced or damaged branch back to the parent and cutting it there). reply mankyd 18 hours agorootparent> The metaphor we use for optimization is “low hanging fruit” which no orchard owner would ever do. This is just over-extending the metaphor. The term has existed long before software was a thing, and refers simply to grabbing something that's easy. That's it. The same goes for tree-shaking. The author does the same thing - over-extends the metaphor. Tree shaking simply means giving everything a jiggle and seeing what comes loose. It's easy to understand and shouldn't be read into any more than that. reply leononame 15 hours agorootparentprevI believe low hanging fruit is not specific to CS. Regardless, it is a perfect metaphor. You want to eat an apple: which one do you pick? Taking the low-hanging fruit is less work right now and gets you to your immediate goal, but disregards general efficiency. Sure, picking a whole tree is more efficient. But if you want a single apple, taking the low hanging fruit is the fastest approach. The metaphor works because it actually implies that it's not the most efficient approach, just the easiest reply hinkley 15 hours agorootparentAs I said, it’s what amateurs do. We are not amateurs. reply db48x 14 hours agorootparentEveryone, even the amateurs and complete non–gardeners, know that this is not the best way to pick fruit. The whole point of the phrase is to point out that someone was lazy. It is saying that all they did was the absolute minimum amount of work. reply wtetzner 14 hours agorootparentprevIt's still a good metaphor. Nobody said picking low hanging fruit is the best approach in harvesting fruit or in computer science. reply CyberDildonics 15 hours agorootparentprevAre you intentionally missing the point to find a reason to talk about what you know about harvesting fruit? reply hinkley 14 hours agorootparentI think you might be projecting. reply Izkata 18 hours agorootparentprev> and cutting it there I think the idea behind calling it \"shaking\" is these branches and leaves that are already cut (inaccessible from the root), and just need a strong breeze to shake the tree and make them fall out. reply hinkley 14 hours agorootparentThose are called widowmakers, and shaking the tree rarely frees them. We had an ice storm this year and there are loads of them all over town still. reply im3w1l 13 hours agorootparentprevYou think of orchard owners, but that's not the image it conjures for me. I remember the neighborhood of my childhood. The fruit trees there were 90% decoration. Usually someone would pick one (1) fruit whenever they felt like getting one. Most of the fruits would never get picked at all. The ground would be full of overripe and rotting fruit, until someone could be bothered to clean it up. reply azakai 18 hours agoprev> If your language’s compiler toolchain can manage to produce useful Wasm in a file that is less than a handful of over-the-wire kilobytes, you can win. I agree that tiny binaries will open up new use cases for wasm! And WasmGC definitely helps. As more context, Java and Kotlin can do fairly well there today, around 2-3 K: https://developer.chrome.com/blog/wasmgc https://twitter.com/bashorov/status/1661377260274720770 Though as Andy says, it depends which APIs you use - I am sure there are Java/Kotlin APIs that would pull in large amounts of code, so you do need to be careful there. But these languages are already doing a lot better than C++ and Rust on code size, thanks to WasmGC (no need to bundle several K of memory management code, in particular). reply josephg 8 hours agoparentI'm curious if wasmgc will help with rust as well. I can imagine it helping when handling javascript objects. And I think it could be used as an alternative, less efficient memory allocator. But even so, the default rust allocator in wasm is probably fine in most cases. Once you start compiling for size, using wasm-opt and brotli compressing your wasm code, you can fit a massive amount of code in less than 100kb of downloaded content. And its a mistake to directly compare the cost of 100kb of wasm with 100kb of bundled javascript. Javascript is many times slower to parse and initialize. The download time is real, but actual time-to-first-paint is much better using 100kb of wasm vs 100kb of javascript. But smaller is better. I'm quite excited for Java, Kotlin, C#, Python, Go and friends to all become viable languages for web applications. I'm curious what the resulting size of real applications will end up being. I suspect one of the biggest differences will be in how the frameworks are made. Virtual DOM diffing will always be more complex and slow than reactive component libraries like Svelte, Solidjs, Leptos (rust) and so on. Once wasmgc lands everywhere, I think which web framework you use will have a much bigger impact on performance than language. reply sroussey 18 hours agoprevWhy did tree shaking as a phrase come to exist when “dead code elimination” had been around forever? reply munificent 10 hours agoparent\"Dead code elimination\" usually refers to smaller-scale compiler optimizations where within a function, you're discarding pieces of code that will never be reached. \"Tree-shaking\" refers to a whole-program analysis where you discard entire modules and functions if they are never invoked. They are conceptually the same, but a compiler author will likely have to implement them separately, so having two names helps. reply wruza 5 hours agorootparentFeels like it became “usually” only recently, cause before “web2.0” DCE always meant eliminating both codepaths and unreachable symbols. reply fweimer 17 hours agoparentprevIf it really originated in the Lisp context (as someone claimed here), it's because it's about as much about eliminating unnecessary data and metadata as it's about executable code. reply Sakos 16 hours agoparentprev1) What words persist or become mainstream has little to do with how old they are. Tree shaking is evocative and is probably more appealing/approachable to say than \"dead code elimination\", so it became the more popular term. 2) I was curious about which term actually came first. The first use of \"dead-code elimination\" I could find was this 1973 dissertation: https://research-repository.st-andrews.ac.uk/bitstream/handl... I couldn't find any use of the term \"tree shaking\" or \"tree shaker\" in the realm of computing on Google Scholar (it was all citrus tree or other arboreal topics, weird). The earliest discussion I could find with the word is this on comp.lang.lisp: https://groups.google.com/forum/#!topic/comp.lang.lisp/pspFr... reply zem 16 hours agoparentprevit's an evocative phrase, and sounds more colloquial than \"dead code elimination\". not hard to see why it caught on. reply Solvency 18 hours agoparentprevwhy did \"dead code elimination\" come to exist when dead/dying trees have existed for millions of years? reply gardenhedge 14 hours agoparentprevI like dead code elimination much better. reply ElectricSpoon 19 hours agoprev> Wasm makes it thinkable to do DOM programming in languages other than JavaScript Does it really? AFAIK, if I want to do any kind of DOM manipulation in say, rust, I need bindings that will basically serialize calls to be done on the JS side. So with the current incarnation of wasm, I believe you're still stuck with JS. reply __s 19 hours agoparentImportant to include the preceding \"With GC,\" In theory you can import DOM functions from runtime & call with references to dom objects now, bypassing JS to call directly into runtime (I say in theory because I'm not in the know whether this is actually possible, but GC at least brings prerequisite mechanisms to get to that point) reply posix86 18 hours agorootparentHow does GC help with that? reply __s 18 hours agorootparentGC feature in wasm extends to having opaque references outside linear memory (which may reference objects controlled by host system's gc) avoiding need for js caller to handle resource being freed by wasm code with a pool or something keyed by handles (integers) passed to wasm reply SpaghettiCthulu 18 hours agorootparentprevI think it would enable WASM code to hold references to DOM objects that have been designed around garbage collection. reply josephg 8 hours agoparentprevI've been playing around with leptos for rust lately - which is a super fast framework for doing web frontend work with rust via wasm. It seems fine, honestly. Basically the same as solidjs: #[component] fn App() -> impl IntoView { let (count, set_count) = create_signal(0); view! {\"Click me: \"{move || count()}} } There's some extra size overhead from wasm compared to javascript, but its honestly not that bad. After wasm-opt and brotli compression, the wasm bundle for this counter app is 37kb. So its in the same general ballpark as react, but much faster once its up and running. I haven't tried doing direct DOM manipulation with it. But for general components it seems great. reply dwoldrich 16 hours agoprevMy philosophy is to work hard at optimizing my javascript with algorithms and design simplifications for size/performance to make room (in bundle size and CPU) for parts of my code that require brute force compute to solve. In my ClubCompy project, I use WASM to implement a FAT filesystem atop local storage, which has proven to be very computationally expensive. And, I plan to use WASM for pixel-perfect sprite collision detection when I reintroduce that feature later this year. My first implementation of collision detection was in plain javascript. With 256 sprites on the screen all colliding with one another, the framerate dropped to below 1fps. I believe I can get that done on a worker thread basically for free and have no performance impacts. reply mrob 13 hours agoparent>pixel-perfect sprite collision detection This is something that sounds like a good idea when you first hear it, but feels unpleasant when you actually play it. Most 2D games use rectangular collision hitboxes for good reason: it's easier for the player to predict if sprites will collide or not. With pixel-perfect collisions, the same movement will collide or not depending on the phase of the animation cycles. It feels bad to fail a movement that always worked before just because the animations happened to line up poorly. And pixel perfect isn't even realistic in many cases; small details on sprites can represent things like cloth or hair that in reality wouldn't cause a hard collision. And sprites often move multiple pixels per frame, so colliding individual pixels increases the chance of them clipping through each other. Simple, predictable collision detection is generally best. reply wizzwizz4 15 hours agoparentprev1fps is the kind of frame rate you should be getting with 20000 collisions, not 256. Your algorithm is the bottleneck, here, not the programming language. You say \"pixel-perfect\". If you have enough spare memory, one simple algorithm would be: render an offscreen canvas of the whole arena, draw each sprite as a stencil in a different colour, and test against that. Linear time, and no need to segment anything. (You might need to use the high bits of the canvas, though: I don't know how anti-fingerprinting measures work, but I expect they replace the low bits of a canvas' data with noise.) reply tapirl 3 hours agoprev> If your language’s compiler toolchain can manage to produce useful Wasm in a file that is less than a handful of over-the-wire kilobytes, you can win. Zig is perfect for this. Personally, I don't think this is an important factor if Wasm file size is less than 100K. It does matter if the file size is over MB. Builtin GC is only important for some apps, not all. It is best to make your web app GC-free. The most important factor for apps using Wasm to succeed is still performance benefit. reply kentonv 19 hours agoprevThis article is very correct: Wasm has a code size problem. This is a problem in browsers because all that code has to be downloaded to start the site. It's also a problem for serverless architectures, where code is often loaded from cold storage to a specific server on-demand while a client waits. Tree-shaking might help, but I feel like it's only an incremental optimization. Fundamentally the reason Wasm programs are so bloated is because they have to bring their whole language runtimes and standard libraries with them. In contrast, with JavaScript, the implementation and basic libraries are provided by the browser. But obviously the browser can be expected to have language runtimes for every language pre-loaded... ... or... could it? I think we need to consider another approach as well: Shared libraries and dynamic linking. WebAssembly supports dynamic linking. Multiple Wasm modules can be loaded at the same time and call each other. However, many Wasm toolchains do not attempt to support it. Instead, they are often design to statically link an entire program (plus language runtime) into a single gargantuan module. Pyodide (CPython on Wasm) is a counter-example. It is designed for dynamic linking today. This is precisely why Cloudflare Workers (a serverless platform) was recently able to add first-class support for Python[0]. (I'm the tech lead for the overall Workers platform.) A single compiled copy of the Pyodide runtime is shared by all Workers running on the same machine, so it doesn't have to be separately loaded for each one. If dynamic linking were more widely supported, then we could start thinking about an architecture where browsers have various popular language runtimes (and perhaps even popular libraries) preloaded, so that all web pages requiring that runtime can share the same (read-only) copy of that code. These runtimes would still run inside the sandbox, so there's no need for the browser to trust them, just make them available. This way we can actually have browsers that have \"built-in\" support for languages beyond JavaScript -- without the browser maintainers having to fully vet or think about those language implementations. [0] https://blog.cloudflare.com/python-workers reply azornathogron 18 hours agoparent> browsers have various popular language runtimes (and perhaps even popular libraries) preloaded, so that all web pages requiring that runtime can share the same (read-only) copy of that code. That sounds a lot like the idea from some years past that commonly used JavaScript frameworks would be served from a few common CDNs and would be widely enough used to be almost always in cache in the browser, and therefore won't need to actually be downloaded for most pages (hence, the size of the js frameworks shouldn't matter so much) I'm no expert but from what I understand, that didn't really work out very well. A combination of too many different versions of these libraries (so each individual version is actually not that widely used), and later privacy concerns that moved browsers toward partitioning cache by site or origin. Maybe other reasons too. Of course, you didn't mention caching and perhaps that's not what you had in mind, but I think it's a tricky problem (a social problem more than a technical one): do you add baseline browser support for increasing numbers of language runtimes? That raises the bar for new browsers even further and anyway you'll never support all the libraries and runtimes people want. Do you let people bring their own and rely on caching? Then how do you avoid the problems previously encountered with caching JS libs? reply kentonv 18 hours agorootparentThese are good questions and I think there's more than one answer that's worth exploring. I think that the privacy problems caused by shared caches could be solved, without simply prohibiting them altogether. Like, what if you only use the shared cache after N different web sites have requested the same module? But if we really can't get around that problem, then I think another approach worth exploring is for there to be some sort of curated repository somewhere of Wasm modules that are popular enough that browsers should pre-download them. Then the existence of the module in a user's browser doesn't say anything about what sites they have been to. Versioning is a problem, yes. If every incremental minor release of a language runtime is considered a separate version then it may be rare for any two web sites to share the same version. The way the browser solves this for JavaScript is to run all sites on the latest version of the JS runtime, and fully commit to backwards compatibility. If particular language runtimes could also commit to backwards compatibility at the ABI level, then you only need to pre-download one runtime per language. I realize this may be a big cultural change for some of them. It may be more palatable to say that a language is allowed to do occasional major releases with breaking changes, but is expected to keep minor releases backwards-compatible, so that there are only a couple different runtime version needed. And once a version gets too old, it falls out of the preload set -- websites which can't be bothered to stay up to date get slower, but that's on them. This is definitely the kind of thing where there's no answer that is technically ideal and people are going to argue a lot about it. But I think if we want to have the web platform really support more than just JavaScript, we need to figure this out. reply thenameipicked 15 hours agorootparentI think a better model would be for the site itself to provide the modules, but the browser will hash and cache them for the next site that may want to use the same module. This way, there's no central authority that determines what is common enough. This model does not allow for versioning. For this model, it would be risky to allow it (one website could provide a malicious model that infects the next site you visit). reply wizzwizz4 15 hours agorootparentprev> Like, what if you only use the shared cache after N different web sites have requested the same module? That would still let websites perform timing attacks to deanonymise people. There's no way to verify that \"N different websites\" isn't just the same website with N different names. Though, we could promote certain domains as CDNs, exempt from the no-shared-cache rules: so long as we added artificial delay when it \"would have\" been downloaded, that'd be just as safe. We're already doing this with domains (HSTS preload list), so why not CDNs? Web browser developers seem to labour under the assumption that anyone will use the HTML5 features they've so lovingly hand-crafted. Who wants something as complicated as:Eat me Lorem ipsum and so on and so forth…when we have the stunning simplicity of: Eat me Lorem ipsum and so on and so forth…Example modified from https://mui.com/material-ui/react-accordion/. Though, in fairness, the developer UX is much better: Eat me Lorem ipsum and so on and so forth… Maybe the problem isn't the libraries. Maybe the problem is us. reply troupo 12 hours agorootparentThe problem is the libraries. Browsers are still mostly incapable of delivering usable workable building blocks especially in the realm of UI. https://open-ui.org/ is a good start, but it will be a while before we see major pay offs. Another reason is that the DOM is horrendously bad at building anything UI-related. Laying out static text and images? Sure, barely. Providing actual building blocks for a UI? Emphatically no. And that's the reason why devs keep reinventing controls. Because while details/summary is good, it's extremely limited, does not provide all the needed features, and is impossible to properly extend. reply lelanthran 13 hours agorootparentprevMaybe not so tricky. What's wrong with having package management for dynamics libs built into the browser, using signed packages? Any dynamic lib that is referenced, say /glibc.6.0.2, is downloaded only once, ever. This is a problem Linux distributions more or less solved ages ago for distribution packages. Why does a new, more complicated and over-engineered thing need to be invented when a tried and tested mechanism exists? reply skybrian 18 hours agoparentprevIt seems like limited dynamic linking support could go a long way. For example, there could be a Go shared library that includes the runtime and core parts of the standard library that many programs use. It would decrease the size of all Go programs, without needing to have dynamic library support within an app. The language runtime might not need heavy optimization for space. It’s already loaded, and as long as any program uses a function, it’s not wasted space. It changes the cost model for optimizing programs in that language for space. Since included standard library functions are free (if you’re using the language at all), you might as well use them. Though, the problem reoccurs with commonly used libraries and frameworks. You’d also want Cloudflare’s standard library for Go to be shared when running on Cloudflare. One problem with this model is that languages don’t evolve in lockstep with the runtime. Either there would be limited support for different versions of a language, or the shared libraries available would pile up over time, resulting in limited sharing between apps. JavaScript has the “you don’t get a choice” versioning model, which requires strong backward compatibility and sometimes polyfills. It might not be as suitable for other languages. When a runtime really wants to cut down on space, it can be done by limiting plugin diversity. Though there are complaints, “you must use JavaScript” worked out pretty well for browsers. Maybe we don’t need a lot of different WebAssembly-based languages? It’s a tower of babel situation. Diversity has costs. reply screcth 18 hours agoparentprevCould it be possible to do \"profile guided tree-shaking\" to build a small module with all the code that's necessary for the application and pull-in less used functionality on-demand using dynamic linking? If tree-shaking was done based on production information it may be possible to prune a lot of dead/almost-dead code without having to implement sophisticated static analysis algorithms. reply nurple 16 hours agorootparentA lazy chunked delivery strategy like used in the k8s stargz-snapshotter[0] project could be effective here, where it only pulls chunks as needed, but it would probably require wasm platform changes. [0] https://github.com/containerd/stargz-snapshotter reply kevindamm 16 hours agorootparentprevThere is a substantial risk there unless you can hit all the edge cases and error conditions when profiling. Even a good fuzzer can miss a very rare state. Then when you hit it in real use there's no code to handle it! Profile-based optimization and JITting is plausible because the corner cases are still there, just not optimized. reply screcth 16 hours agorootparentI completely agree, that's why in that case you could download the missing code from the server and load it using dynamic linking. The server would then mark it as reachable so it's delivered as part of the main bundle next time. I would expect the bundle to converge quickly to the set of functions that are actually reachable. Aditionally, it's very likely that the sets of reachable code of two versions of the same app have significant overlap, so the information collected for version N could be used as a starting point for N+1, and so on. reply avodonosov 11 hours agorootparentprev\"less used functionality on-demand\" - so the code to handle the rare case remains available, on demand. reply avodonosov 11 hours agorootparentprevI experimented with that for javascript: https://github.com/avodonosov/pocl reply aledalgrande 16 hours agoparentprev> we could start thinking about an architecture where browsers have various popular language runtimes (and perhaps even popular libraries) preloaded that could potentially lead to hundreds of versions of runtimes downloaded in the browser, filling up the cache with binaries that might be used by 1 site each reply jonnycomputer 15 hours agoparentprevLot I don't know about how browsers are shipped, but it seems to me like browsers could easily get away with packing in a few languages and their STLs as part of their default installs. Python is what, 25MB? Would another couple hundred megs of disk space be such a big deal? reply lxgr 14 hours agorootparentPossibly – if you can find a single version of Python that everybody will be happy with, forever. Being able to cache runtimes and libraries like that across sites would be nice, though (but probably enables fingerprinting, so one Python runtime per origin it is). reply nextaccountic 18 hours agoparentprevDoes browsers support wasm with dynamic linking? reply tomjakubowski 16 hours agorootparentThe way Emscripten does it, IIRC, doesn't require any special browser support. The toolchain generates glue code in JavaScript to support calls between dynamically linked Wasm modules. reply kentonv 18 hours agorootparentprevYes. reply nextaccountic 18 hours agorootparentDo you happen to know where can I check out the cutoff version for each browser? https://caniuse.com/?search=wasm doesn't have it (or other things like WasmGC for that matter) reply kentonv 18 hours agorootparentI believe dynamic linking has been a core feature of WebAssembly from the beginning. You have always been able to load multiple Wasm modules in the same isolate and make them call each other. (But, language toolchains have to actually be designed to use this feature. Most aren't.) reply beepbooptheory 18 hours agoparentprevI think I agree overall, just want to point out that with Wasm, you still end up using a fair bit of the built-into-browser js to accomplish things not purely computational. Especially in this context with Hoot [1], where things like appendChild are external functions you call inside the scheme. One could theoretically do this for much of the js standard library in any kind of wasm context. 1. https://spritely.institute/news/building-interactive-web-pag... reply kentonv 18 hours agorootparentIndeed, I/O APIs (anything that talks to the outside world) are another sore point for WebAssembly, as browsers do not currently expose any particular APIs directly to Wasm, only to JavaScript. So Wasm has to make calls to a JavaScript middleman layer to use those APIs. But browsers are understandably hesitant to create a whole parallel API surface designed specifically for Wasm callers. That's a lot of work. I am not totally convinced that this is a real problem, vs. just something that makes people feel bad. Like, if you are coding Rust, the idea that all your \"system calls\" are calling into a layer of JavaScript feels disgusting. But is it a real problem? Most of these calls are probably not so performance sensitive that this FFI layer matters that much. If it is a real problem, I'd guess the answer is for browsers to come up with a more efficient way to expose WebIDL-defined APIs to Wasm, but without reinventing any individual APIs. Being derived from WebIDL, they are still going to have JS idioms in their design, but maybe we can at least skip invoking actual JavaScript. reply nox101 9 hours agoprevTwo other examples of apps that use wasm. Google Maps uses wasm so if you need an app lots of people use that uses wasm then that's pretty big. Google Earth is now entirely wasm but Google Earth is not that popular (https://earth.google.com/) reply fulafel 19 hours agoprev> Wasm makes it thinkable to do DOM programming in languages other than JavaScript Can't help but picking this out for correction - people have been doing it for a long time in compile-to-JS languages - eg ClojureScript, TypeScript, ReasonML and many others. And people have also been compiling native-ish stuff for the web a long time before Wasm through asm.js & emscripten, like C and through that C-based languages such as Python: https://en.wikipedia.org/wiki/Asm.js#Adoption reply malkia 15 hours agoprevAnother example - flutter can tree shake unused icons/glyphs from fonts - https://www.reddit.com/r/FlutterDev/comments/f4h3l9/tree_sha... reply lxgr 14 hours agoparentPDFs can do the same thing for embedded fonts, I believe. reply low_tech_punk 13 hours agoprevA microcosm of the wasm issue was captured in this thread: https://github.com/isomorphic-git/isomorphic-git/issues/268 The community had good reasoning around implementing a web based git in JavaScript from scratch instead of compiling libgit2 to wasm. reply avodonosov 11 hours agoprevA possible alternative to tree shaking: https://github.com/avodonosov/pocl reply mirekrusin 14 hours agoprevIt feels like OCaml is well positioned for this kind of flow analysis to perform aggressive tree shaking. With GC support in WASM OCaml should produce tiny binaries. reply mindslight 19 hours agoprevIsn't the tree shaking metaphor based on how some fruit trees are harvested? When you shake the tree, the ripe fruit falls off. It's not the best metaphor in that with fruit harvesting you want the fruit, whereas when storing a serialized image you discard what falls off, but alas. reply modeless 11 hours agoparentNuts are typically harvesting by shaking. Fruit is usually picked by hand since it's more delicate and will get bruised if it falls too far. The shaking is quite violent, but it doesn't hurt the tree. reply internetter 19 hours agoprevThe big utility of WASM for me, like OP hints at, is bringing things that would be infeasible to port to the web to it, like, say https://pgaskin.net/kepubify/ and other conversion tools (eg ffmpeg-wasm). Much preferable to downloading something or uploading a file to some random person’s server reply AtNightWeCode 17 hours agoprevI have Blazor apps running on Cloudflare pages. They download fast and the performance is great. The load time is terrible though. I think it is unsolvable with .NET. I think the core issue is how everything is entangled by design in oo langs. Also, the amount of money put into js is hard to compete with. Then to also have copy/paste as a lang feature in js is like cheating. Third. With Blazor at least you still need js and skills in that area. I think this is my main issue. reply mdasen 16 hours agoparent> I think the core issue is how everything is entangled by design in oo langs. It's not an issue with object orientation. An issue is that languages of that era often relied on reflection for many use cases. People are actually working hard to rid large parts of .NET from these use cases and mark them as safe for eliminating unused code. When there's the possibility of using reflection to call a method, you don't really know what you can safely eliminate. It might look like nothing is calling `Foo.Bar()`, but what if someone has done `Reflection.getClass(someClass).runMethod(someVar)` and those variables have been set to \"Foo\" and \"Bar\"? For example, Dart doesn't allow reflection with precompiled apps because it allows them to safely eliminate unused code (https://docs.flutter.dev/resources/faq#does-flutter-come-wit...). Dart is an object oriented language, but it has eschewed runtime code generation and runtime reflection for compile time code generation. .NET is also headed in this direction, but that doesn't happen overnight. However, as others have pointed out, part of the issue will be that non-JS languages will still need to ship implementations of standard library stuff that's included in the JS runtime in the browser (at least the pieces of the standard library you're using post-tree-shaking). reply neonsunset 12 hours agoparentprevBlazor...is not great at this. Currently, the packaging model does not do the justice to capabilities of .NET trimming because of the limitations of how the WASM is currently packaged on top of Mono. If you want to see how well it can actually trim (which everyone seems to like calling tree-shaking, even though it's not exactly right), it is better to try out building regular applications with AOT - they produce small binaries. The experimental support in runtimelab for NativeAOT-LLVM targeting WASM provides much smaller bundle sizes and much better performance but given that it still is under dotnet/runtimelab rather than dotnet/runtime, I don't know when it will be available. reply hiddencost 19 hours agoprevAs someone who regularly shakes his fiddle leaf fig to encourage growth, title confused me. reply FrustratedMonky 19 hours agoprevMaybe off-topic. But can't you use WASM to create GUI's like Photoshop, with no JavaScript or DOM? Isn't the bigger goal of GUI's on WASM is we can jettison JavaScript/DOM and go back to writing GUI's like 10-20 years ago, with simpler libraries. Like SKIA, or something. Using non-web GUI libraries, since they could be compiled to WASM and run in web. EDIT: Native. I mean pre-web, when GUI libraries were native, everything ran locally. Seemed like WASM would let apps be built like that again, but would be in browser for deployment. reply codelikeawolf 18 hours agoparentI don't think that's a very good goal. Jettisoning the DOM means jettisoning accessibility and being able to leverage everything that the browser gives you out-of-the-box. You have to render to a canvas and build everything from scratch. I think Wasm is great for supplementing a JS app, not replacing it (e.g. using a Wasm module to do some calculations in a Worker). I like to use the right tool for the job, and trying to use something other than JS to build a web app just seems a little janky to me. At one point, there was a Host Bindings proposal that would enable you to do DOM manipulation (it looks like it was archived and moved to the Component Model spec [1]). That would probably be the ideal way to avoid as much JS as possible. However, browser vendors have been heavily optimizing their JS runtimes, and in some cases, Wasm may actually be slower than JS. I've been following Wasm's progress for several years, which has been slow, but steady. Ironically, I think the web is actually the worst place to use it. There's so much cool non-web stuff being done with it and I'm more interested to see where that goes. [1] https://github.com/WebAssembly/component-model?tab=readme-ov... reply 01HNNWZ0MV43FF 19 hours agoparentprevIt'll have to be GPU accelerated somehow, outside the wasm boundary. At 1080p it's hard to make pixels move fast enough to get away with CPU rasterization. reply troupo 12 hours agoparentprev> But can't you use WASM to create GUI's like Photoshop, with no JavaScript or DOM? Yes, you can. If you have the time and the money. To quote Figma: \"Pulling this off was really hard; we’ve basically ended up building a browser inside a browser.\": https://www.figma.com/blog/building-a-professional-design-to... And that's just for the canvas part. Figma's UI is React. you need a good UI library if you want to do it like native. And native platforms have those. There's nothing of the sort for any of WebGL/Canvas/WebGPU reply wizzwizz4 15 hours agoparentprevWasm doesn't let you do that unless the native bindings are exposed. The web is really not a bad interface for building GUIs: Microsoft reckoned it was the way forward, back in 1999. https://learn.microsoft.com/en-us/previous-versions/ms536496... reply FrustratedMonky 13 hours agorootparentI'm aware web pages exist. I don't think there is much argument that HTML+JavaScript was actually a set backwards that we've been trying to build out of for 20 years. What the web solves is mass distribution. But for programming it is awful. reply wizzwizz4 12 hours agorootparentAre you familiar with the WAI's Authoring Practices Guide? https://www.w3.org/WAI/ARIA/apg/patterns/ \"Old-fashioned\" desktop GUI systems, like Win32 MDI, are built out of composeable widgets. HTML is built out of composeable widgets. Whatever you do with Wasm and direct pixel rendering? That isn't. The travesty that is modern web development is, absolutely, a step back from what we had back in the day. But that's not inherent to the web: it's a deficiency of practice. Many web APIs are delightful, and while they're all clunky, Win32 MDI also has its footguns. https://devblogs.microsoft.com/oldnewthing/20120213-00/?p=83... reply FrustratedMonky 11 hours agorootparentI agree. Still looking for something that bridges that gap, to make modern web pages as simple as old WinForms. The only web based tools that I've come across that seem to hide all the JavaScript/html, and be 'simple' are tools like Elmish, or some of the other functional programming 'DSL's. Where the page is kind of composed by functions that compile into the JavaScript. With JavaScript, by the time I'm manipulating the DOM, I keep thinking some tool should be handling this for me. reply skywhopper 19 hours agoprev [–] As things go along, I’m more and more mystified by WASM’s apparent design. It feels like 1996 Java for applets, but without the built-in GC, stdlib, or even the most basic hooks into the browser. Which means it’s basically useless for what I assume its goal is, of letting you use languages other than JavaScript to code a web page. Without trivial DOM access, what’s the point? Other proposed usages like for FaaS-style edge widget computing honestly don’t make a lot of sense. Why target an artificial VM for that purpose instead of existing architectures that work just fine with less overhead. For compute that could happen in either the browser or the edge, maybe, but how much is that level of portability really realistic or worthwhile? I’m guessing it might be in a few narrow cases, but it’s not going to be a common pattern. reply codelikeawolf 18 hours agoparentIn a nutshell, Wasm is essentially a CPU with a tiny instruction set. It's very primitive and minimal, but I think that was the point. If you need to do something with numbers in a web app, it's pretty neat. If you need to work with strings, you're going to end up crying in the fetal position under your desk. reply Rusky 13 hours agoparentprevThe current iteration of WebAssembly was always an \"MVP.\" It's got the core instruction set and memory model to run, essentially, C programs safely and efficiently, and just enough interop with the host to get data in and out. But it was always the plan to expand on that, and make a wider set of use cases easier and more efficient. Working directly with the DOM really requires some amount of integration with the GC that manages the DOM, for example. The thing that makes this interesting outside the browser is the security model. Unlike typical environments used for FaaS or whatever else, it's capability based and starts from literally zero- everything a WebAssembly module can touch has to be passed in explicitly when it's instantiated. That's a lot narrower, lighter weight, and more flexible than things like containers. reply FrustratedMonky 18 hours agoparentprev [–] I might not be understanding. But I thought WASM was to replace .NET and JAVA VM's. But, without a VM, to be more a pass through to the underlying CPU. So much faster. So compile down to a 'byte code' like thing, that does not run on a VM, but runs on the underlying HW. So goal was speed. And to allow other languages to compile to it. reply ben-schaaf 18 hours agorootparent> So compile down to a 'byte code' like thing, that does not run on a VM, but runs on the underlying HW. I think you may be confusing \"system\" virtual machines and \"process\" virtual machines. The VM here is the thing executing the WASM bytecode; it works the same was as .NET and JAVA VMs. reply FrustratedMonky 13 hours agorootparentI understand it is a VM like Java. I was just under the impression that it was somehow better, more streamlined, that would offer enough performance improvement that you could start treating it like running a 'native' local app. Like if I build a 'native' app, a 'thick client', I could now run it on WASM in a browser. Thus not need any local installs, but have same performance. I've seen some apps doing that. But guess it isn't considered 'the way' for the future? reply troupo 12 hours agorootparentprev [–] > But I thought WASM was to replace .NET and JAVA VM's. It's name is literally web assembly. It's goal was never and still isn't to replace those VMs. It was literally an idea to create a faster code sandbox for the web based on the idea's from Mozilla's asm.js > to be more a pass through to the underlying CPU. So much faster. So compile down to a 'byte code' like thing, that does not run on a VM, but runs on the underlying HW. wat. > So goal was speed. And to allow other languages to compile to it. Yes, it was. Has nothing to do with the fantasy of replacing JVM and .Net VM or running directly on hardware. reply FrustratedMonky 11 hours agorootparent [–] Of course, that is where it started. I'm probably being loose in terminology. I assumed that to gain this speed, that it was a little closer to the metal than a VM like Java. That it must have some kind of pass through to allow commands to run on the local HW, not just emulated in a VM. So like a VM in that you can compile to it, but it would execute natively. From the FAQ. \"WebAssembly aims to execute at native speed by taking advantage of common hardware capabilities available on a wide range of platforms. It is a low-level assembly-like language with a compact binary format that runs with near-native performance\" And when looking at the Use Cases, it seems to be trying to do a lot more than javascript. https://webassembly.org/docs/use-cases/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article delves into the hurdles and achievements of leveraging WebAssembly for web development, showcasing challenges with languages such as C# and Python.",
      "Emphasizing the significance of efficient tree-shaking to minimize file size, it addresses the forthcoming browser backing for reference types and garbage collection.",
      "It also sheds light on the challenges of optimizing tree-shaking in languages like Scheme and Python, alongside exploring the possibility of DOM programming in non-JavaScript languages, concluding with a nod to Pyodide and various REPLs' computational requirements."
    ],
    "commentSummary": [
      "The article explores the tree-shaking algorithm to minimize wasm bundle sizes in Rust and WASM applications, emphasizing software optimization terminologies and dead code elimination challenges.",
      "It highlights the advantages and hurdles of WebAssembly in web development, discussing performance optimization and size reduction potentials using WASM.",
      "Moreover, it covers optimizing code in browsers, handling dynamic libraries, and enabling multiple languages in browsers through WebAssembly, shedding light on diverse optimization techniques and benefits for web applications and code efficiency."
    ],
    "points": 209,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1713018020
  },
  {
    "id": 40025195,
    "title": "Self-Install Solar Kit for Renters: Off-Grid Backup Power Solution",
    "originLink": "https://sunboxlabs.com",
    "originBody": "sunboxlabs Home Solar Kit Mini Solar Kit Grid-tied Solar Panel About Blog Contact Easy, self-install solar for your condo rooftop, balcony or back yard Create power from the sun for backup, savings, or energy independence. How it works Backup for power outages. It's like a UPS (uninterruptable power supply) that primarily charges from sunshine. We don't even notice power outages or public safety shut-offs anymore (same would go snowstorm outages or hurricane outages elsewhere). Saves you money the rest of the year until the sun is down & battery is empty, then falls back to the grid. It generally pays for itself in 4 years with those savings. Benefits Built To Go - take it with you if you move. Throw it in the back of a truck. Nothing is permanently attached or wired in. The Sunpower T5s are built to withstand up to 120 mph winds while lying on the roof. Landlord-friendly - Non destructively place panels on your roof without making holes. I did ask my landlord for permission as a common courtesy. Plug-in Hybrid - In normal operation the system runs off solar & battery, but can seamlessly flip to utility pass-through mode if both other sources are exhausted. Like a plug-in hybrid car can avoid range anxiety with a backup gas engine for long trips, the system removes the worry of running out of power if you go over your self-generation that day. Utility-friendly - This system is off-grid as far as the utility is concerned. It never feeds back into the grid, only ever drawing if necessary. Tracking You can track the usage and inputs with an app - I got a (bad and expensive) tracker dongle but I'd strongly recommend Solar Assistant Stored sunlight runs the place Stored sunlight runs my kitchen, dining & living room - fridge, induction stove (Ikea, placed on gas stove), kettle, entertainment system, and everything else. It could also run microwaves and space heaters. It doesn't run my lights - it's a PITA to get an alternate power system to everywhere I want lights. But LEDs nowadays are in the 2-5 watt range, so consumption of those is minimal. The system powers all of my high-power devices above, which makes a way bigger dent with fewer cables. The Secret Sauce The secret sauce is that the sunbox is usually off-grid and never pushes power back into the grid. The only reason it's connected to the wall at all is that if it runs out of power it can pull energy from the wall. The sunbox (and its satellite on the roof - the solar panels) are acting as a \"solar buffer\" between your devices and the wall. It's not wired into the meter, doesn't require a permit, etc. Wall plug for pass-through UPS mode & cables through window-gap to solar panels The Downside The potential downside is that you need to run your own \"alternate electricity system\" through the house (ie. long white extension cables) to each room, as you're side-stepping the house's built-in wiring in the walls and using your own that you can redirect to the sunbox. Main 2,500W power distribution strip. Relatively neat wiring from the box to the fridge, induction cooktop and on to the living room. Components & Cost - $1,124 total $200 for 1.2kW solar (used) - 4 x 320W Sunpower T5s @ $50 - though if there's no used panels near you then new ones 4 x 455W = $746 is great too $494 for 3kW inverter/controller/UPS all-in-one - 3kW pure sine wave inverter, 4kW MPPT solar charge controller, UPS function - falls back to grid when battery empty $418 for 2.5kWh LiFePo4 battery Cables / Tender: https://amzn.to/43NkcuJ - $14.79 https://amzn.to/4cwxY8Y - $30.42 https://amzn.to/4cuS3fx - $13.00 https://amzn.to/43u3ikz x2 - $17.00 https://amzn.to/43u3r7B - $12.99 https://amzn.to/43y5Qhx - $8.89 Total: $114.09 => $1,124 total Remote tracking (optional): https://amzn.to/3Vs3COI - $7.99 https://amzn.to/3TPaXGI - $23.92 https://amzn.to/4a6UMdI - $6.99 https://solar-assistant.io - $55.83 Total (additional): $94.73 How to guide Coming soon, for now refer to Will Prowse’s wiring guide on his very-similar 48V 3000W off-grid solar system which I followed and works great for me! Financial Payback & Embodied Energy Financial payback period for 3000W System cost : $1,124 on Amazon in 2024 Yearly energy creation: 365d * 4.26hsun/d * 1.280kW = 2,000kWh/y (but more like 1,000kWh/year after losses) Yearly value creation: 1,000kWh/y * $0.55/kWh in SF = $550/y energy created 100W system payback period: $1,124 / $550 = 2 years until payback How green is it: Production footprint PV (source): 2,900kWhee/kW * 1.28kW = 3,712kWh embodied energy Production footprint LiFePo4 battery (source): 106kWhee/kWh * 2.4kWh = 254kWh embodied energy Annual energy production system: 1100kWh/y Payback period: 3966kWh / 1100kWh/y = 3.5 year footprint payback FAQ What’s the catch? Seems to good to be true? Well, this thing sits between your devices and the wall. So you need to neatly run extension cables from every room in the house to the “sun box”, and then run one cable from the box to the panels, and another to the wall (optional, just so it can fall back to pulling power from the wall). Photos of this are coming soon. Will it ever push power back into the wall? Nope! It’ll only ever draw from the wall in the event that both the sun is down and the battery is dead (so your fridge won’t go off overnight for example). Is this legal? Yes, see above. No difference to plugging your fridge into your wall, as far as the utility is concerned. Want some help? Set up a call with us and we can plan your system! Email Us Home Solar Kit Mini Solar Kit Grid-tied Solar Panel About Blog Contact Shipping Refunds, Returns & Warranty © sunboxlabs 2021. All Rights Reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=40025195",
    "commentBody": "My $1k self-install, off-grid solar backup build for renters (sunboxlabs.com)204 points by nikodunk 15 hours agohidepastfavorite199 comments neilv 14 hours agoThe HTML title starts \"The Landlord-Friendly...\". It really depends on the landlord. I like the idea of solar, and of backups, and of figuring out how to live comfortably in rentals, and of being mobile, but... I'm pretty sure that my own real-life landlord would flip out, if he came to the door, and saw that charger box bolted to the wall, and the bare terminals of an Alibaba special \"SCREMOWER\" large lithium battery pack. Before he even saw that cabling. Which I think (with those lengths, and tacked up like that) would be an electrical code violation here. Would insurance even cover a fire? Also, if there's later an expensive roof leak, there'd be questions about whether it had been caused by installation of the panels (even though no holes were drilled). And is there a liability risk if the panel gets blown off. And would insurance cover any of that? Were I in landlord's position myself, I'd have much of the same concerns. reply repiret 13 hours agoparentAs a landlord, I would not approve of this tomfoolery in any of my buildings. Safety hazards I see include: Solar panels on the roof that aren’t bolted dow; I don’t care what wind speed they’re rated for. Wires running from them to the inside of the house not in conduit and not secured. A high energy battery pack not NRTL listed. Extension cords draped through the house permanently installed (within the expansive definition of permanently installed used by the NEC) In addition running the wires in through a cracked window creates an unacceptable risk of water damage. That said, it’s a cool project. Just do this in a barn you own not a house I own. reply xbmcuser 11 hours agorootparentMy question for you if you are a landlord at what price would a battery and solar system would make it profitable for you to install and then sell the electricity to the tenants. With the slowdown in ev cars as well as battery production increases as well as steep fall in solar wafer prices I think we are likely to see a big surge in home battery installations in the next 2-3 years. reply repiret 4 hours agorootparentThe math really isn't that different from \"should I install solar on my house\". Although I live (and own rental properties) in an area with lots of sunshine, we also have relatively inexpensive electricity, about 15% cheaper than the US national average. Every time I look into solar, the answer is the same: it will take longer for it to pay off for me than the lifetime of the components. The only places around here where solar pays off is where the grid isn't already available, in which case the cost of solar installation often dwarfs the cost of extending the grid. Even once solar makes sense for the house I live in, its a tougher sell in a rental: If I were to do install solar on a rental, there's the added complexity of \"how do I charge the tenant for electricity?\". I could not charge them, but have higher rent. But it takes a pretty sophisticated tenant to properly account for the value there, so that would make the units appear less price competitive than they actually are. I could install a meter and charge them the same way as a power company does. But does that make me a power company? Are there a bunch of new rules I would have to follow? What do I do if someone doesn't pay the bill? I'm sure I could figure it all out, but it makes the investment less attractive, which means the price of solar relative to buying from the grid has to be even better before I would go down that route. (edited for typos) reply justinzollars 11 hours agorootparentprevThis depends on the interest rate. Today there is a huge 30% federal tax credit that would take 1/3 off of any such installation. That said, the tax credit is still not enough to cover the price increases due to inflation and interest cost of financing a system. I spent a large amount of time trying to make this work this year, and it just feels foolish. You'd be buying really expensive energy just for the novelty of saying you have solar. reply harmmonica 10 hours agorootparentThis. I had this grand plan to convert (almost) everything to electric and then install solar but it would take roughly 16 years to pay back the solar install based on our current electricity bill. Then I’ve tried to rationalize it based on added resale value, which, where we’re located, might command a small premium to the install price, but even that seems questionable and we don’t have any plan to move. It seems like there are two justifications for solar if you’re on the grid. Either you want to do right by the environment (totally good, though very pricey, reason to do it!) or your electricity costs are very high. If there are others I’d love to understand them. Maybe if you’re a prepper (not making fun) then that’s another reason. reply toast0 7 hours agorootparentSomeone on a forum I'm on has a solar setup because they have poor grid reliability. Solar + battery + transfer switch provides them with good availability. It's way easier to capacity plan with a fuel based generator though. My 35kW generator can go at least several days on a 500 gal propane tank, regardless of weather. Potentially indefinitely if propane delivery is available, but I lose phone service when the power is out beyond 4 hours, so I'd have to venture out to get signal to call, and if power is out for more than a few days, the weather is probably pretty bad and delivery may not be available. With a solar + battery system, handling potential multiday outages, I'd be concerned about my winter where there's less than 9 hours of daylight and it's often mostly overcast, and I'm running my heatpumps to warm the house. But if I have solar/battery capacity to make that work, I'm going to have way too much capacity for most of the year. Solar + battery for grid backup makes more sense in places with shorter duration outages and were peak electricity use is in the summer rather than the winter. reply xbmcuser 4 hours agorootparentprevWith the way prices are dropping for solar and batteries I would recommend doing the calculation again 3-5 years from now as with the current cost trajectory specially if it is just 20-30% more expensive. I think even prices for electric appliances will drop as more people start to use electric appliances like heat pumps etc as they will also enjoy economies of scale and labour cost drop as more installers get used to working with them. reply coryrc 9 hours agorootparentprevMy FIL had a 10kw natural gas generator installed, which is negative ROI. He could have gotten solar with battery backup for a positive ROI. reply jonnycoder 13 hours agorootparentprevWhile the article probably doesn’t use UL listed equipment, I’ve found that equipment exists that does such as eg4. They run 48v which makes it legal in addition to being Ul listed. It’s typically the installation between solar panels and power inverter/converter that needs to be up to code. reply jrockway 13 hours agorootparentprevThere is also the risk of lightning hitting the wires and causing damage indoors. reply asdefghyk 11 hours agorootparentprevAs a landlord how does one stop people/tenants using \"under rated\" extension cords ? and therefore causing a fire. How does one stop tenants using \"dodgy\" chargers to charge their electric bike or whatever, and the battery bank causes a fire.? Does your insurance cover these situations??? reply repiret 3 hours agorootparentI can't even stop my family that lives with me from overloading crappy extension cords; most people, including my tenants, don't know enough to avoid overloading extension cords. Frankly, all extension cords with a NEMA 5-15 or 1-15 plug should be required to either be rated for 20A, or include over-current protection; and the fuses should be shaped to prevent you from putting an over-current fuse in the fuse holder. But alas it doesn't work that way in the US. (It does in some countries). That said, I drive by all my properties periodically, and my property manager does annual walk through; large battery banks, excessive extension cords tacked to the walls, and solar panels sitting on the roof with wires run through a window would all get flagged in such a walkthrough, any my rental agreements allow me to require the tenant to correct unsafe conditions, which all of those are. And I do have good insurance. There's a pervasive believe on HN that you can't get insurance that covers variations of not-to-code, not-properly-permitted, and/or not-done-by-licensed-electrician electrical installations. There very may well be insurance that excludes these things, but its easy to get insurance that covers those things, and mine does. If my tenants do dumb-ass stuff that burns the building down, I'm covered, even if that dumb-ass stuff involves electricity. reply djbusby 11 hours agorootparentprevYou can't stop it. You can spot it when happens and ask them to fix/remedy. Remind them of lease terms, etc. And make sure you have good insurance. reply earthscienceman 12 hours agorootparentprev\"Just do this in a barn you own not a house I own.\" Someday we'll wonder why we thought it was a good idea to make the need for shelter into an investment vehicle. Until then, I hope people use your properties as they see fit. reply dylan604 11 hours agorootparentThere are a lot of people that can afford to rent a house, but would not qualify for a mortgage to buy a house. If houses were not available to rent, there would be plenty of people unable to live in a house. I'm in a fortunate situation where my landlord is not a slumlord. When things need looking into, it gets taken care of in a timely manner. I do not have any issue with someone choosing to have this as a business. reply BHSPitMonkey 4 hours agorootparentprevThe GP's statement doesn't at all suggest that they're looking at this property as an investment vehicle; The house could be ROI-neutral and its owner would still not like to see it burn down from uninspected, unsafe electrical work. reply akira2501 10 hours agorootparentprev> the need for shelter into an investment vehicle. It's likely the shelter will be on this earth longer than I will? We didn't make it that way, it is that way. reply bartvk 2 hours agorootparentThat fact alone doesn't make it into an investment vehicle. There's a set of circumstances that make it so. Low interest rates, being able to use leverage (borrow money, buy a house then rent it out), and higher-than-inflation price increase of houses. reply bartvk 2 hours agorootparentprevYour rather carefully worked comment is being downvoted already. I agree with you, but I think that here, plenty of people have the dream of early retirement. Don't get me wrong, I like that dream too. I just have my thoughts about the current housing market, which to me has aspects of an investment market. reply waveBidder 12 hours agorootparentprevthere's nothing wrong with paying someone else to maintain your dwelling and dealing with capital costs. people don't have a problem with the market solutions to the basic right to food, for the most part. The main problem comes with the unearned profit that comes from owning land that benefits from improvements made by others. tldr: land value tax and less restrictive zoning yesterday reply sudobash1 13 hours agoparentprevThe extension cord \"alternate electricity system\" as they call it seems particularly harrowing. You had better make sure that you know what the load rating is on each of those cords and what they are going to be supplying (or better yet, just don't do this). Unlike household wiring, there will be no breakers. reply angiosperm 13 hours agorootparentThe \"load rating\" on the cords exceeds the total power delivery capability of the system. It has its own circuit breakers. The manufacturers are well aware of risks, for liability reasons if nothing else, and have contained them in the uniform-electrical-code mandated manner. The system is no more risky than any other plugged-in appliance. We don't need to invent problems. Extension cords are just extension cords. reply fragmede 13 hours agorootparentno they're not. Not when you're dealing with potentially large loads. an extension cord rated for 13 amps with 16 gauge wiring, with a 110v dryer running on it, will cause a fire, sooner or later. A proper 10-gauge, 20 amp-rated extension cord will not. that this system won't exceed ratings is a fair point, but extension cords are not just extension cords. reply angiosperm 12 hours agorootparentObviously the extension cord you use needs to be rated for the power it carries. Anyone buying extension cords can see there are different sizes. They are well-labeled, and it is easy to look up the gauge needed for its length and what is to be plugged into it. A correctly-rated extension cord is no more hazardous than the same-rated Romex, and often cheaper. All the appliances mentioned are rated to be used with appropriate extension cords, and cords are sold at retail for such use. reply fragmede 9 hours agorootparent\"obviously\" is doing a lot of work there. What's obvious to you isn't obvious to the next guy, who's just going to look for the cheapest cord there is. They're not well marked at Home Depot, you have to bother to look for the right gauge, the cables aren't even necessarily in the right place, and if you don't know jack about being an electrician, it's easy to buy a cheap 2-prong 18-gauge indoor-rated cable for use outside in a wildly inappropriate fashion. No one at Home Depot is going to stop you and ask what you're about to do with the cable. yes, For people with half of a clue, it's possible to buy the right cable and be safe, but we have to plan for the lowest common denominator, and tell people that extension cords are just extension cords when they come in all sorts of flavors, some of which are happy to burn your house down, is irresponsible. reply icehawk 6 hours agorootparentThey're very well marked at Home Depot. The store brand, which is general most prominent, gauge is color coded: 6AWG - Gray / 12AWG - Yellow / 14AWG - Pink / 16AWG - Orange. There's one exception to this where 14 AWG cable is using orange labeling normally used on 16AWG wire but that's the opposite of a safety issue. And they have generally have the rated amperage for the length of the cable. reply fragmede 4 hours agorootparentyeah but there's no test that asks if you know the difference between a watt and an amp. If you're coming from the paint department, how are you to know that the color is material? I just like orange, it's my favorite color. reply bigtunacan 13 hours agorootparentprevYou lost all credibility with, \"Extension cords are just extension cords.\" For any type of generator running exterior to interior would require rated extension cords to reduce fire risk. reply angiosperm 12 hours agorootparentThe extension cords mentioned are all interior-to-interior. There is no magickal difference between an extension-cord wire and a like-gauge Romex wire. The former bends easier. The only outdoor wiring mentioned is 48V. reply spacecadet 13 hours agoparentprevNo insurance would. Yes, looks super hazardous for a lay person to attempt. Ive taught a bunch of in person classes on DIY solar and I would never have published this, its asking people to get evicted or worse. I should add, mine are all in the context of fringe living... vans, campers, boats, alleyways, etc. reply r00fus 13 hours agoparentprevI think the Lithiun-Iron-Phosphate battery is actually not a fire hazard (not nearly as much as Lithium NMC ones - which are quite rare also). Explaining that to the landlord may not be fruitful however. reply mdaniel 10 hours agorootparentI always thought any concentration of power represents an opportunity for things to go off the rails; do you happen to have a citation for \"not a fire hazard\" that I could read up on? That's actually one of my bigger concerns with these solar into battery stunts is where to place such a massive array of batteries such that if something caught fire it wouldn't take out my roof or other flamable stuff reply 20after4 2 hours agorootparentLiFePo4[1] is not 100% safe but it's a much safer chemistry compared to the other common alternatives. This is because LiFePo4 chemistry isn't prone to thermal runaway. Thermal runaway is really bad. Typical lithium rechargeable batteries can't handle overheating without starting a chain reaction: an uncontrollable thermal runaway followed by a literally inextinguishable inferno. If you short circuit the LiFePo battery it still is going to turn into a welder. It can still start a fire. If you don't short circuit it, under normal conditions it shouldn't spontaneously combust. 1. Note: Confusingly LiFePo4 (Lithium Iron Phosphate) looks a lot like LiPo (Lithium Polymer), however, LiPo batteries are some of the most prone to fire while LiFe batteries are the least prone to fire. reply dubcanada 13 hours agorootparentprevThey are classified a fire hazard in Canada. reply angiosperm 13 hours agorootparentIncorrectly, if so. reply Scoundreller 10 hours agorootparentprevWho/what certifies things as \"fire hazards\" in Canada? reply cavisne 13 hours agoparentprevGood video on the issues with extension cords in the US https://www.youtube.com/watch?v=K_q-xnYRugQ&t=1131s reply Spivak 13 hours agorootparentYeah, I spent the money on good quality 12/3 extension cords that can safely pull more power than the circuit will deliver and have been quite happy with them. Being able to run a space heater off them is really nice in the winter. reply secabeen 10 hours agoparentprev> Would insurance even cover a fire? ... And would insurance cover any of that? (leaks, etc.) Yes. Insurance is a contract, and the standard insurance contracts used by nearly all insurers do not contain exclusions for permits, code violations, or things like this. They would absolutely not renew you after a loss caused by something like this, and would probably report the loss to the industry databases. Insurance companies will often try to impose liability on other parties when losses happen, but they don't sue their own customer, as the whole point of an insurance contract is that they are assuming liability for loss in exchange for your premium. (If you believe this to be otherwise, try to find a recorded instance of an insurer denying coverage for code violations or un-permitted work. I've never been able to do so, and would be very interested in reading the case study.) If you want to be sure, just ask your insurer for a copy of your contact, and read it. They aren't that complex. reply mozman 7 hours agoparentprevThe haphazard cabling and use of potentially subpar cables to deliver power is a fire waiting to happen. I wouldn’t condone this or any variation thereof that violates the NEC, a lot of liability is being assumed by doing this. I realize not everyone can afford a new home but with the proper knowledge and tools you can make electrical changes to achieve your goals that can be reversed on move out. I might have previously done things against my landlords wishes but it was done - and removed - professionally. The other option is to talk to your landlord and do it right, making it permanent upon your separation from the property. reply cmclaughlin 13 hours agoparentprevI just left a similar comment. We were probably composing a the same time. Good point about the possibility of a roof leak and placing blame. I didn’t think of that. reply 35mm 4 hours agorootparentYou can get flat cables for solar DC wiring designed to pass through the gap in a closed window: https://es.ecoflow.com/products/super-flat-cable?currency=EU... reply hinkley 13 hours agorootparentprevYears ago I fantasized about making a transformer designed to pass through a window. One coil on the outside, one on the inside. Unfortunately I don’t think you can split the core of a transformer and still get anywhere near the efficiency Also more recently I learned that these things can vibrate. Which would not be good for a window. You’d be better off passing a wire ribbon around the sash. reply Animats 12 hours agorootparentSplit transformers for power transmission exist, but are rare. Here's a 3 KW system used for non-contact charging of electric forklifts, industrial mobile robots, and such.[1] 93% efficiency claimed. Probably not worth the trouble just to get power through a window. [1] https://www.wiferion.com/us/ reply hindsightbias 10 hours agoparentprevLooking at the video, his apartments wiring probably dates to the 50’s or so. Which would be the norm here. Hard to do worse. Most landlords here are pretty low maintenance (both ways) as long as you pay on time and willing to bend. Did not blink an eye when I asked to go roof WISP and drilled my own hole next to the cable line. No roof penetration so they didn’t care. I’m thinking of asking about a weighted panel to cover the 4-9pm PG&E quadruple pricing via a LFP bank. reply flemhans 13 hours agoparentprevYeah at certain points I thought they were trolling. But still inspired me to perhaps to something like this that bypasses the meter and the city grid, but just a little more limited in scope than running duplicate wiring everywhere. reply choilive 11 hours agoprevWow... This should be added to the FAQ's under \"Whats the catch?\": At least a dozen code violations that risks burning down your/your landlord's property, serious injury or worse - loss of life - and opens yourself to VERY large liabilities. A more proper way to do this would be to have one self contained outdoor box rated to contain high energy batteries, have your inverter and PDU as part of that package and then plug your the panels to that. When you have a power outage go out and grab your backup battery box. This eliminates the bulk of the issues. Although, that raises the obvious solution that you could just spend a bit more money and get one of those self contained \"battery generators\", which have been properly engineered and designed, and are also pretty portable. Another thing I would add is adding some sandbags to the solar panels so that they don't fly off the roof in a high wind scenario. Theres a reason why when doing a rooftop installation code will specify this if not being directly bolted. (Technically a structural engineer will need to do a load calculation, but for this size of install the risks are minimal compared to the risks inherent in the rest of the system) reply cameldrv 13 hours agoprevAll of the code/safety/landlord issues notwithstanding, the price is pretty incredible. If I plug my address into the PVWatts calculator, given the insane price increases from PG&E over the past few years, the payback period is one year. Beyond the fantastic economics, you're getting a decent emergency backup system that should cover at least your fridge, lights, and various electronics. reply smallerfish 13 hours agoprevTangent: can anybody recommend a hybrid invertor that can prioritize solar over grid _without also_ prioritizing battery over grid when solar isn't available? Context: I have a solar + battery system for backup power purposes. We have long enough grid outages every so often that make it worthwhile, and I need to keep the batteries charged in preparation for those outages. However, 98% of the time the batteries are charged and the solar power is just being wasted (there is no grid tie back here); I'd like to actually use it. The invertor (which is cheap chinese) can prioritize \"renewable over grid\" and thus use the solar during the day, but in this mode it then uses the batteries at night, and recharges them from grid when it runs them down; this means lots of battery cycles and also potential for backup to be foiled if the grid goes down at the wrong time. reply jonnycoder 13 hours agoparentCheck out the EG4 specs from signature solar. They have been reviewed a lot by Will Prowse on youtube and it’s what I would buy. reply ThatPlayer 2 hours agorootparentI have a similar Growatt from siganture solar. I'm pretty sure they're made by the same manufacturer as EG4. The cheaper one can do it, in a solar > utility > battery priority mode. But depending on your solar panel and consistent power draw, I'd maybe use the solar > battery > utility mode. It'll let you set a point to switch from battery to utility, the highest at 95%. That way when your usage is below your solar generation, you can still use the solar to charge the battery. A bit more wear and tear on the battery, but even less solar wasted. Assuming you can handle the batteries only being at 95% if you have an outage. If your usage is less than your solar generation, could even set it lower. I've been looking at something similar but different. My grid is fine, but I want to be able to use the batteries based on my time-of-use plan prices. I have less solar panels, but would want to charge my battery using grid power when prices are lower. reply nikodunk 13 hours agorootparentprevSeconded. The thing I’m using here is basically an EG4 knock off and I copied the wiring from the Will Prowse EG4 3000W mobile solar power guide (linked under how to) - which makes me think it’s the same board inside. reply mcbishop 12 hours agorootparentprevI like that their 3K inverter works with a 48-volt battery bank. They seem incredibly low cost for the value. reply beAbU 13 hours agoparentprevSunsynk will give you what you want. You can define a minimum battery level, after which it'll switch to grid if there is not enough solar to supply the load. If there is no grid then It'll continue to use battery until a final emergency cut-off that shuts the whole system down. The battery setting can be configured on a timer, so you can have different cut-offs for dulifferent times of the day. reply zo1 10 hours agorootparentCan't second this enough. I have a Sunsynk inverter here in South Africa where we deal with multiple-daily grid outages. So the priority is always set (based on time of day) to keep the batteries charged \"just in case\". If Solar can't provide enough juice, it sucks from the grid. The whole thing is actually quite elegant. It turns \"electricity\" into this fungible thing like it was supposed to be in the first place. More pro points, you can plug in an electric-start generator and configure it to start automatically as needed in order to supplement the solar. Going further still, you can plug in a wind-turbine and have it blend it into this whole system. Makes me wish I could install a wind turbine on my roof. A fair bit of solar, coupled with a little bit of wind suddenly makes your batteries go a really long way towards being fully off-grid capable. reply doctoboggan 12 hours agoparentprevDefinitely check out Will Prowse on YouTube, and see his website here: https://www.mobile-solarpower.com He has spec'd out a lot of DIY Solar Packages and lists the BoM on his website. reply mcbishop 12 hours agoparentprevAnother option is Phocos. You can set the PV / grid / battery priority order. reply thot_experiment 14 hours agoprevI have 1.2kW of used Sunpower panels I bought for $70/pop about 3 years ago. Buying decommissioned commercial install panels is insanely cost effective. It's crazy how cheap they go. reply greazy 14 hours agoparentDo they maintain efficiency? reply nikodunk 14 hours agorootparentYeah! The Sunpower T5s mentioned above are still performing at near-max performance as far as I can tell. Things like shading or dust will influence modern panels way more than their age at this point IMO. Past 20 years I don't know - but for the next 10 years, it's seems to be a pretty good hack :) reply arrowsmith 13 hours agorootparentWhy were they decommissioned if they're still at near-max performance? reply sangnoir 12 hours agorootparentI suppose the same reason companies get rid of perfectly serviceable laptops and servers: depreciation and chasing after fractionally larger efficiencies. reply nikodunk 13 hours agorootparentprevYa re-upping gov/state incentives is the theory I’ve heard in a few places. See e-bikes/EVs/general combustion leases where the same happens. Luckily, same as housing and transportation it dumps a bunch of lightly used but performant gear into the market for people like me. reply thot_experiment 13 hours agorootparentprevBecause capitalism is a helluva drug. reply hinkley 13 hours agoparentprevDo you buy “end of life” panels or panels removed during a remodel? reply SkyPuncher 8 hours agorootparentI've looked into it. My understanding is commercial installs are more sensitive to efficiency than consumers. I believe it's far more economical for them to squeeze everything they can out of an acreage than it is to simply build new. Between panels losing efficiency and newer, more efficient panels coming on the market, commercial installs tend to cycle out panels well before the end of their life. This leaves a second-hand market with some pretty crazy discounts. reply 35mm 4 hours agorootparentAlso the cost of the structure supporting the panels is usually a lot more than the panels. reply ryjiao 13 hours agoparentprevDo you have any ideas for where I could get a similar deal? reply dvdbloc 14 hours agoparentprevAny tips or guides on the best ways to get them? I’m interested reply voisin 13 hours agoparentprevWhere did you source them? reply SkyPuncher 8 hours agorootparentI was considering purchasing from this company: https://www.santansolar.com/product-category/solar-panels/ reply nikodunk 13 hours agorootparentprevSee links on https://sunboxlabs.com reply brudgers 13 hours agoprevRead your lease because most landlords are not going to be down with renters putting stuff on the roof...anyway… These days, $1k will buy a fair bit of a China made power brick. No need for solar access — for when the power goes out in a storm and/or at night. A big brick or several small ones is also less work; can live out of the way when not in use; and can be used when tailgating or car camping. For food cooling a small chest freezer has broad utility and unpowered will stay cool through a moderate outage. reply cmclaughlin 13 hours agoprevI’m surprised the landlord is ok with this. I understand the panels might be rated to withstand some amount of wind, but there’s a huge liability if this project lead to injury. A good job was done considering the load on the indoor wiring, but the exposed wires on the outside of a building concern me. Typically wires have some level of insulation and/or conduit that reduces and contains the spread of fire. If wind did move the panels around, those wires could pull loose and start a fire. SF does not perform frequent building inspection, but if an inspector saw this they would almost certainly cite that this violates building code. In the event of injury, insurance might not pay out given how this is setup. reply avar 12 hours agoparentAround the 2 minute mark in the video you can see he's ratchet strapped the panels together, and in turn that strap is attached to the roof (looks to be looped around a pipe?). So he's not just relying on the wind rating of the panels. A better and perhaps code compliant way to do this (this is sometimes done this way here in NL, no idea about the US) is to bolt the panels to e.g. an aluminum frame, which you'd then hold to the roof with ballast, e.g. cinder blocks or heavy yard tiles. Depending on the panel area, frame and amount of ballast you can easily prove that there's no way the result would move due to weather, unless you were experiencing such apocalyptic winds that the house itself would be destroyed anyway. reply anonymousiam 8 hours agoprevNice Project! I did a similar project in 2003, but obviously the technology has improved a lot since then. I've previously posted some details here: https://news.ycombinator.com/item?id=36000824 The thing that stood out to me about this project was the lack of any hardware to secure the panels to the roof, which is absolutely necessary to prevent wind damage. reply pbnjay 13 hours agoprevAs someone living in NC and paying only $0.09/kwh, that $0.55/kwh in SF is just nuts to me! This setup has a 12 year payoff here... reply worstspotgain 12 hours agoparentThe rate schedules are complex. I'm paying ~$0.43/kWh, itemized as $0.13/kWh generation (Clean Power SF) and $0.30/kWh distribution (PG&E). If you use very little on the residential schedule I think it can drop pretty low, probably around $0.15/kWh. reply danans 4 hours agorootparent> If you use very little on the residential schedule I think it can drop pretty low, probably around $0.15/kWh. The lowest price on the PG&E tiered rate plan E1 (implied by the words \"If you use very little ...\") is $0.42/kWh. Even the most variable rate EV2A plan has an off-peak price of $0.35/kWh. I don't see any way to get a price of $0.15 kWh. reply worstspotgain 1 hour agorootparentI stand corrected, it's been a while since I last looked at rates. I think the ~$0.15/kWh I remembered was from SVP in Santa Clara, not PG&E. https://www.siliconvalleypower.com/residents/rates-and-fees reply worstspotgain 51 minutes agorootparentBTW, the actual lowest rates for SF are closer to ~$0.26/kWh, and may be lower during the winter months at the lowest usage tier (\"below baseline.\") https://www.pge.com/assets/pge/docs/account/alternate-energy... I can't work it out exactly without doing more research than is worth. As I said, the schedules are complex, maybe someone more versed in this can chime in. Hopefully SF will finally manage to force PG&E to sell it the city's grid. I doubt it will lead to rates as low as Santa Clara's, though. https://sfpuc.org/about-us/news/its-high-time-san-francisco-... reply pbnjay 10 hours agorootparentprevMy power is resold by the city so they don’t break it out, but a nearby county is 4.55c per kWh distribution charge and 5.96c per kWh generation charge. reply kshacker 13 hours agoprevI do not want to fight with the utility or the insurance for such work, but this made me think: Can I set up something (I have a house) in my backyard + frontyard to just charge my EV? Catch the sun when it can, and then charge the car when connected. My PG&E bill says 56% of my usage is from midnight to 6 AM which is just EV + fridge. Although I pay a low rate on that, but imagine dropping half of your usage. I specifically pick out the EV as an example because by definition my system would never need to connect to the house or the grid, so I guess all I have is a disconnected battery (powerwall) to insure. reply 8xeh 10 hours agoparentYou _can_ do it, but EV charging is a big load for a few hours. That's not really what solar is good at. Solar likes smaller loads spread throughout the day. If you go super cheap (the \"$1000\" system in the article), you'll be able to put a couple miles into the car in the afternoon on \"level 1\" charging. It's not nothing but it's not really practical for a car (but probably fine for an electric bike/moped). Also, most of the available power is unused since the battery is so small. So you get a battery big enough to hold everything your panels can generate. You get a more powerful 240V inverter, a nice 8-10 kWh battery, and move to Southern California. With the best possible circumstances in July, you can fill up that battery every day, and add 19 miles to your car overnight. Now you're at $10,000 for about 6,500 miles per year. If the battery lasts 8 years (LFP can do 3000 cycles, 1 cycle per day = 8.2 years), you're paying 19¢/mile (and only if you use all of the power you generate). Compare that to just plugging into the wall, which is 3-6¢/mile. reply ThatPlayer 0 minutes agorootparentI would argue those prices a bit. A pair of 5kWh rackmount LFP batteries is only about $3,000. Assuming you're charging overnight, you can definitely get by with a 120V inverter like OP. Get a charger that does NEMA 5-20 for 16A and it'll transfer 10 kWh in 5 hours. I still agree that from the wall is better. reply conk 6 hours agoparentprevI’ve been considering this for my home. I have solar already but with an EV my usage exceeds my generation. Second hand panels like this ones in this article are cheap. I could get a set of those and sting them into an EcoFlow Ultra which has the solar inverter and ~5kWh battery. Then plug an EVSE directly into the 240v plug on the eco flow. Eco flow also has an API so I could get fancy with the software and change what gets charged based on the car or battery charge levels. It would cost ~$6K. I estimate I’d save about $1500/yr from my electric bill. ROI isn’t great but most home projects have an even worse ROI so I still might do it just for kicks. Would also be nice to have a big Eco Flow battery I could use for other stuff. reply yummypaint 13 hours agoparentprevYou might consider something on the opposite end of the spectrum, specifically net metering. If your grid connection is reliable, it's even more economical to get a solar system without batteries that feeds the grid. Where I'm located people pay the difference between the two without regard for when the power was generated or consumed. It also means your system is more efficient because there are no battery losses. reply mcbishop 12 hours agorootparentNet metering is no longer available in PG&E territory. reply dragonwriter 7 hours agorootparentAll the information I can find indicates that it remains available for new hookups. Of course, since April 2023, new hookups are under NEM 3.0, which is significantly less beneficial to the generator than earlier NEM programs. reply jobs_throwaway 11 hours agorootparentprevhow ass backwards reply toast0 7 hours agorootparentIf you look at CalISO graphs, solar is very dominant already to the point where there's consistent energy exports during daytime. Why would they want to incentivize more grid attached small solar at this point? reply jonnycoder 13 hours agoparentprevYes very easy with a ground mount with 4 panels, a battery and inverter. I should write an article about it because I had planned to build something myself and keep all equipment outside and build a small wooden enclosure away from the house for it. reply thechao 12 hours agorootparentMy EV lives outside & right beneath the only safely accessible part of my roof to put solar on... so an explanation would be grand! My only issue is that I need solar->battery->car, as the car is at work 3/7 days... reply asdefghyk 11 hours agoprevAbout under rated extension cords. My question is if in a house a person plugs in a under rated extension cord into a normal powerpoint and connects equipment to the other end, such that the current exceeds the extension cords current rating , and a FIRE results, would the insurance company pay??? ( ie this is in a house without any of the this DIY solar. cables or battery etc) . would be interesting question. reply zo1 10 hours agoparentNo idea of the specifics. But a good heuristic to go off of is to assume that no they won't pay out if they can find anything that is remotely plausible to have been the cause or contributing factor. reply coyotespike 14 hours agoprevI love how clear and to the point this page/guide is. Beautifully summarizes the downsides as well as the upsides. The system is even tempting to me as a homeowner not renter, but a similarly simple system that doesn't require running wires through the house might work better. reply bryanlarsen 14 hours agoprevI've lost 2 freezers worth of food in the last 25 years due to power outages. I have since purchased a battery that can run a freezer in summer for a few hours or a furnace fan in winter for several days for the next outage. Adding a solar panel so I can use that battery continuously wouldn't pay for the battery, but it'd sure offset it considerably. reply fooker 13 hours agoparent>run a freezer in summer for a few hours. You can 'run' a freezer for about 10-12 hours by purchasing 5-10$ worth of ice from a grocery store. For something that happens twice in 25 years, that seems like the more pragmatic way to go? reply thaumaturgy 13 hours agorootparentYou can do that so long as nobody else in the area affected by the outage had the same idea and got there before you. The last major outage (due to an ice event), I hit the stores within the first hour of the outage and they were already cleaned out of water, propane, ice, and getting rapidly cleaned out of other supplies. reply smeej 11 hours agorootparentI really don't want to be rude here, but I live in a place where we constantly throw the frozen stuff outside into the snow when the power goes out, so I'm genuinely confused. If it was an ice event, why would you have to travel to get ice? reply thaumaturgy 10 hours agorootparentWe're getting side-tracked a bit here. In this case: it happened in an area where most folks are accustomed to mild weather year-round and I don't recall seeing even a single box of food kept outside; I was out for propane, and only noted a few other things that got hard to find much more quickly than expected; the power outage itself lasted until long after the freezing conditions did, because the outage was caused by massive tree destruction that took out power infrastructure over a large area. This happened back in January and there are still cleanups happening here and there from it. The bell curve for outages seemed to be a few days at the least, to about 5 to 10 days for most, to about three weeks for some in outlying areas. You can find some reasonable articles by searching for \"2024 oregon ice storm\". In any case, point was, whatever supplies you think you'll need for an extended power outage are likely to become scarce really quickly. reply bryanlarsen 11 hours agorootparentprevBattery is for freezer in summer and for furnace fan in winter. reply BenjiWiebe 11 hours agorootparentAnd the comment above mentions that the power outage was due to ice, so highly unlikely to be in the summer. reply Retric 10 hours agorootparentSure but the poster was worried about multi day power outages in the summer. Local issues don’t cause 4 day outages it’s stuff like hurricanes or major grid infrastructure issues from construction mishaps. Ex: https://islandfreepress.org/outer-banks-news/07272018-ayeara... reply Riseed 10 hours agorootparentprevI've lived in places where the \"ice event\" that caused the power to go out was freezing rain. That kind of ice can make trees heavy enough to lose limbs into power lines and makes roads slick enough for vehicles to crash into transformers and power poles (hence the power outages), without outdoor temperatures necessarily being cold enough to preserve frozen goods and without there being enough easily available ice outside (e.g. ~.5cm covering on all surfaces) to bring inside for stuffing the freezer. reply thaumaturgy 10 hours agorootparentThat is almost exactly what happened here. We basically had sleet for about a full day, it was relentless. In an area that never snows and rarely freezes, a neighbor went actually ice skating down the street. I still have microspikes from my previous life in the mountains, and was one of few people who could get around confidently -- and even then, it was a bit sketchy here and there. I've never seen anything like it. Individual blades of grass were embedded in solid capsules of ice. I regret not taking the time to get the camera out and do a bunch of photography, but I had my hands full the entire time. A few nights later, the ice had barely begun to thaw, and then it refroze and then started snowing. I stood outside my home for a bit in the darkness, and listened to the sounds of tree limbs cracking, breaking, snapping, and crashing, like a steady rhythm, for a while. Just, \"boom, crash. ... boom, crash. ... boom, crash. ...\" reply singlepaynews 12 hours agorootparentprevThe difference is the battery can engage automatically. Do you want to monitor for the rare, yet anticipatable event? A self-critique: power outage isn't going to occur without notifying the person, except for maybe being out of town. That said, one less problem to solve in response to rare, anticipatable event. reply fooker 6 hours agorootparentYes, a fire or short circuit taking out your battery would have a similar probability. So you are trading between different categories of disasters. reply pseudosavant 11 hours agorootparentprevGet a 12V power inverter and power it off and idling car, or even better an EV. The max draw for most fridges/freezers isn't very high actually, and the average load is very low. reply bryanlarsen 10 hours agorootparentInstantaneous current can be pretty high as the compressor kicks in. reply avar 12 hours agoparentprevDid you consider buying a larger freezer (or sacrificing space), and just filling part of it with freezer gel packs? I wonder what the cost/benefit calculation is for that v.s. an entire solar backup system. reply Scoundreller 10 hours agorootparentNaw, fill it up with salty water bottles. Drive the phase change to happen well below 0 centigrade. 23% saltwater will help hold your freezer at -21C (which is probably too salty to freeze in most freezers, but you get the point). reply avar 10 minutes agorootparentYes, you can DIY-it, although I'm a bigger fan of using box-shaped freezer-certified tupperware, it's more space-efficient. But the commercial product is cheap enough to buy if it's going to be your backup plan. reply neilv 13 hours agoparentprevWere they the lid on top freestanding freezers? How long were the outages, and what was the environment? reply bryanlarsen 13 hours agorootparentYes, lid on top. 4 day outages in both cases. reply lolinder 13 hours agorootparentWould a few hours of runtime actually save your freezer food in the event of another 4 day outage? reply briffle 13 hours agorootparentWhen I last had a multi-day outage, we hooked our generator up to our freezer. We would run for one hour, then off for 3-4 hours. Also good schedule for making more coffee, charging phones, etc. reply Retric 13 hours agorootparentprevIt’s likely, freezers don’t operate continuously. reply coffeebeqn 13 hours agorootparentprevIt’s not a few hours. It’s all sunlight hours plus a few hours from the battery per day reply lolinder 13 hours agorootparentTFA's system, yes, but OP just bought a battery and is now considering adding a solar system. reply melenaboija 14 hours agoprevI love this. I have been waiting for some sort of off grid solar kit that I can install \"Ikea\" install, i.e. with almost no idea about the matter take the instructions, plug and play. reply bryanlarsen 13 hours agoparentFor more money and less effort you can purchase a \"solar generator\". It's a funny name for something that's basically a battery + inverter + mppt, but \"solar generator\" is the best thing to punch into Google. reply newsclues 13 hours agoparentprevThese exist, multiple brands make and sell battery and solar ecosystems. reply winter_blue 13 hours agoprevIt sounds like the author of this piece lives in a jurisdiction without net metering. (The UK, perhaps?) If you have net metering, being able to push power back into the grid is a major plus. reply epistasis 8 hours agoparentThe bigger factor is that he's renting, and therefore whether the jurisdiction has net metering or not doesn't matter. But he's in San Francisco and California does not have net metering. I've been considering doing something like this as any grid-tied system is about $3/W for power, plus $500/kWh for storage. But an off-grid system done on your own is about $0.60/W plus $200/kWh for storage. reply Toutouxc 13 hours agoparentprevIt’s also a major pain in the ass in places where the grid isn’t exactly prepared for that. My parents are allowed to sell power from their EV installation. Their neighbor, who built a much smaller one a few months later, got denied. reply FireBeyond 12 hours agoparentprevI pity the poor linemen if you hook this contraption to feed back into the grid. reply valianteffort 13 hours agoprevYou can buy 256Wh battery banks for around $150 now. You can pair them with a timer for charging/topping off at night when electricity is cheap. They even accept solar input. Throw one in every room and between appliances like the fridge or oven. Now you have a UPS for your whole house and the cheapest energy rates throughout the day. reply epistasis 12 hours agoparentDo those have an inverter built in? If not, at $600/kWh very pricy compared to what this guy used at $190/kWh for batteries, or $360/kWh including the inverter: https://www.amazon.com/dp/B08G81TKC6?ie=UTF8&th=1&linkCode=s... Also, $190/kWh is so cheap. Its hard to believe how fast costs are falling for energy storage. reply ianburrell 10 hours agorootparentIf is he talking power bank, then big ones, usually called power stations, have inverters. But they can’t be used as UPS since they cut power when switching sources. reply xyzzy123 12 hours agoparentprevHm fridge sure, but oven? 256Wh is going to power an electric oven for like, 5 minutes. Doesn't seem useful. reply grobbyy 12 hours agoparentprevMy experience is that power banks and UPSes fail more often than my power. I keep a couple charged, but with nothing plugged in. I sometimes plug things in before a major storm, planned outage, or after an unplanned one. reply smeej 11 hours agorootparentThis is funny to me because mine just died unceremoniously during a snowstorm and it made me realize there should really be a testing cycle built in. reply magicbuzz 12 hours agoprevThe all-in-one 3kW inverter/controller that he uses is for 110V AC output (using the 48V battery). In the article he linked to, the system uses an EG4 3000EHV-48 that also outputs 110V AC. Are there equivalent all-in-ones that would provide 230/240V AC for use in Australia/New Zealand? reply avar 12 hours agoparentIf you search for the manufacturer shown (PowMr) it looks like they make both 110v and 220v variants. This looks to be the same or similar product for 220v: https://a.aliexpress.com/_EwlP4Cf reply mcbishop 12 hours agorootparentI think this is single phase. 230V is a common single-phase voltage outside North America. reply mcbishop 12 hours agoparentprevI don't know of a 3kW inverter that outputs split phase. But you could get the higher-rated EG4 6000XP. reply Scoundreller 8 hours agorootparentAU/NZ 240V wouldn't be split phase reply happytiger 13 hours agoprevWhat’s the status in insurance for this thing? Generally this doesn’t seem like it would be covered under renters insurance. I can’t imagine a landlord in existence that wouldn’t throw a fit about something like this. reply 35mm 4 hours agoprevAny tips for going through doors with the cabling? reply turtlebits 11 hours agoprevForget the landlord (who is already unlikely to give roof access, let alone run electrical wires outside), this immediately fails the WAF (wife acceptance factor) due to the hideous cable install. reply blcknight 10 hours agoparentI know right? I love the caption on one of those photos about “relatively neat” cable runs. reply deeth_starr_v 12 hours agoprevThis reminds me of the time when I built a battery stereo power amplifier and then only used it a few times because I didn’t want to risk burning the apartment complex down. It was fun building it though. reply _pdp_ 13 hours agoprevIf this is legal, it is excellent. When I remodelled our home some years ago, I had to rewire everything, including putting ethernet cables everywhere. It is not such a big deal if you are in the middle of it. reply millebe 13 hours agoprevThis is dangerous and illegal everywhere in the United States. DO NOT DO THIS! All 50 states have adopted NFPA 70, the National Electric Code, and the linked article shows a bunch of things that absolutely DO require a permit and would absolutely FAIL to be approved: First and foremost, running bare high voltage DC wires through an open window is in violation of a pile of building codes and very dangerous. The linked solar panels have an open circuit voltage of 64.8V, so with four of them in parallel there can be 260V of direct current. This can and will kill you, especially if you touch it in such a way where muscular tetanus prevents you from releasing the cable. Electrical extension cords are intended to be temporary, and the article's use of them violates a bunch of codes. Here are some of the relevant ones: 400.10 Uses Permitted (A) Uses Flexible cords and flexible cables shall be used only for the following: (1) Pendants. (2) Wiring of luminaires. (3) Connection of portable luminaires, portable and mobile signs, or appliances. (4) Elevator cables. (5) Wiring of cranes and hoists. (6) Connection of utilization equipment to facilitate frequent interchange. (7) Prevention of the transmission of noise or vibration. (8) Appliances where the fastening means and mechanical connections are specifically designed to permit ready removal for maintenance and repair, and the appliance is intended or identified for flexible cord connection. (9) Connection of moving parts. (10) Where specifically permitted elsewhere in this Code. (11) Between an existing receptacle outlet and an inlet, where the inlet provides power to an additional single receptacle outlet. The wiring interconnecting the inlet to the single receptacle outlet shall be a Chapter 3 wiring method. The inlet, receptacle outlet, and Chapter 3 wiring method, including the flexible cord and fittings, shall be a listed assembly specific for this application. 400.12 Uses Not Permitted Unless specifically permitted in 400.10, flexible cables, flexible cord sets, and power supply cords shall not be used for the following: (1) As a substitute for the fixed wiring of a structure (2) Where run through holes in walls, structural ceilings, suspended ceilings, dropped ceilings, or floors (3) Where run through doorways, windows, or similar openings (4) Where attached to building surfaces Exception to (4): Flexible cord and flexible cable shall be permitted to be attached to building surfaces in accordance with 368.56(B). (5) Where concealed by walls, floors, or ceilings or located above suspended or dropped ceilings Exception to (5): Flexible cord and flexible cable shall be permitted if contained within an enclosure for use in Other Spaces Used for Environmental Air as permitted by 300.22(C)(3). (7) Where subject to physical damage 400.17 Protection From Damage Flexible cords and flexible cables shall be protected by bushings or fittings where passing through holes in covers, outlet boxes, or similar enclosures. You absolutely cannot and should not run bare wires through a window. This manages to violate basically all of Chapter 3 of the NEC: 300.3 Conductors (A) Single Conductors Single conductors specified in Table 310.104(A) shall only be installed where part of a recognized wiring method of Chapter 3. 300.4 Protection Against Physical Damage Where subject to physical damage, conductors, raceways, and cables shall be protected. 300.6 Protection Against Corrosion and Deterioration Raceways, cable trays, cablebus, auxiliary gutters, cable armor, boxes, cable sheathing, cabinets, elbows, couplings, fittings, supports, and support hardware shall be of materials suitable for the environment in which they are to be installed. 300.11 Securing and Supporting (A) Secured in Place Raceways, cable assemblies, boxes, cabinets, and fittings shall be securely fastened in place. 300.12 Mechanical Continuity — Raceways and Cables Raceways, cable armors, and cable sheaths shall be continuous between cabinets, boxes, fittings, or other enclosures or outlets. 310.10 Uses Permitted (C) Wet Locations Insulated conductors and cables used in wet locations shall comply with one of the following: Be moisture-impervious metal-sheathed Be types MTW, RHW, RHW-2, TW, THW, THW-2, THHW, THWN, THWN-2, XHHW, XHHW-2, or ZW Be of a type listed for use in wet locations (D) Locations Exposed to Direct Sunlight Insulated conductors or cables used where exposed to direct rays of the sun shall comply with (D)(1) or (D)(2): Conductors and cables shall be listed, or listed and marked, as being sunlight resistant Conductors and cables shall be covered with insulating material, such as tape or sleeving, that is listed, or listed and marked, as being sunlight resistant Both the solar panels and the inverter are listed products and are required to be installed in accordance with their listings. In particular, this means they must be permanently fastened to the structure in the manner of the manufacturer's instructions. 110.3 Examination, Identification, Installation, Use, and Listing (Product Certification) of Equipment (B) Installation and Use Listed or labeled equipment shall be installed and used in accordance with any instructions included in the listing or labeling. The solar panels must be fastened to the structure in a way that resists wind and weather loads. There are entire sections of the NEC and various IBC codes devoted to this. Other various code sections that this would fail: 110.8 Wiring Methods Only wiring methods recognized as suitable are included in this Code. The recognized methods of wiring shall be permitted to be installed in any type of building or occupancy, except as otherwise provided in this Code. 110.12 Mechanical Execution of Work Electrical equipment shall be installed in a neat and workmanlike manner. 110.13 Mounting and Cooling of Equipment (A) Mounting Electrical equipment shall be firmly secured to the surface on which it is mounted. Wooden plugs driven into holes in masonry, concrete, plaster, or similar materials shall not be used. 110.26 Spaces About Electrical Equipment Access and working space shall be provided and maintained about all electrical equipment to permit ready and safe operation and maintenance of such equipment. (A) Working Space Working space for equipment operating at 1000 volts, nominal, or less to ground and likely to require examination, adjustment, servicing, or maintenance while energized shall comply with the dimensions of 110.26(A)(1), (A)(2), (A)(3), and (A)(4) or as required or permitted elsewhere in this Code. (B) Clear Spaces Working space required by this section shall not be used for storage. When normally enclosed live parts are exposed for inspection or servicing, the working space, if in a passageway or general open space, shall be suitably guarded. (E) Dedicated Equipment Space All switchboards, switchgear, panelboards, and motor control centers shall be located in dedicated spaces and protected from damage. (1) Indoor Indoor installations shall comply with 110.26(E)(1)(a) through (E)(1)(d). (a) Dedicated Electrical Space. The space equal to the width and depth of the equipment and extending from the floor to a height of 1.8 m (6 ft) above the equipment or to the structural ceiling, whichever is lower, shall be dedicated to the electrical installation. No piping, ducts, leak protection apparatus, or other equipment foreign to the electrical installation shall be located in this zone. (2) Outdoor Outdoor installations shall comply with 110.26(E)(2)(a) through (c). (a) Installation Requirements. Outdoor electrical equipment shall be the following: (1) Installed in identified enclosures 110.27 Guarding of Live Parts (A) Live Parts Guarded Against Accidental Contact Except as elsewhere required or permitted by this Code, live parts of electrical equipment operating at 50 to 1000 volts, nominal shall be guarded against accidental contact by approved enclosures or by any of the following means: (1) By location in a room, vault, or similar enclosure that is accessible only to qualified persons. (3) By location on a balcony, gallery, or platform elevated and arranged so as to exclude unqualified persons. (4) By elevation above the floor or other working surface as follows: A minimum of 2.5 m (8 ft) for 50 volts to 300 volts between ungrounded conductors (B) Prevent Physical Damage In locations where electrical equipment is likely to be exposed to physical damage, enclosures or guards shall be so arranged and of such strength as to prevent such damage. reply angiosperm 12 hours agoparentWires from panels in parallel will all be at, typically, 48VDC. Voltages add only when you wire in series. No \"live parts\" are exposed in modern systems. The quoted regulations govern construction. Residents have much greater latitude. All the appliances mentioned are approved for use with rated extension cords. reply thereisnospork 12 hours agorootparentNotably, even in construction/industrial settings, there are typically broad exemptions for 'low voltage' wiring[0], typically defined as Circuits operating at less than 50 volts shall be installed in a neat and workmanlike manner. Cables shall be supported by the building structure in such a manner that the cable will not be damaged by normal building use. The only possible violation of 720.11 for duct tapingDO NOT DO THIS! You're probably right, but just to rules lawyer this a bit for fun: Flexible cords and flexible cables shall be used only for the following: [...] (9) Connection of moving parts. He could mount his panels on plywood on caster wheels, and then prevent excess moment by tying those \"moving parts\" by chain to cinder blocks. The rules don't specify that you must have a reason that isn't dumb to make those parts move. The \"400.12 Uses Not Permitted\" section gives the list in \"400.10\" a blanket exemption (\"unless specifically permitted in 400.10\"), and that's the section that would forbid running the wires through a window. reply millebe 12 hours agorootparentThe rules specify equipment must be installed in a manner per its listing, and there are at least four nationwide codes that cover the attachment of solar panels. In California I would guess there are more, stricter codes (e.g. seismic). Even if you managed to make the panels movable, this would fail 690 of the NEC: 690.31 Wiring Methods (A) Wiring Systems All raceway and cable wiring methods included in this Code, other wiring systems and fittings specifically listed for use in PV arrays, and wiring as part of a listed system shall be permitted. Where wiring devices with integral enclosures are used, sufficient length of cable shall be provided to facilitate replacement. Where PV source and output circuits operating at voltages greater than 30 volts are installed in readily accessible locations, circuit conductors shall be guarded or installed in Type MC cable or in raceway. The ampacity of 105°C (221°F) and 125°C (257°F) conductors shall be permitted to be determined by Table 690.31(A)(b). For ambient temperatures greater than 30°C (86°F), the ampacities of these conductors shall be corrected in accordance with Table 690.31(A)(a).0 reply coryrc 9 hours agoparentprevThese things aren't permanently installed, so the sections you cite don't apply. reply mentos 13 hours agoparentprevCurious to hear what you’d recommend to bring this setup in line with safe and legal practices reply millebe 12 hours agorootparentYour choices are either: - Install this equipment in a permanent manner consistent with its listings and all applicable codes. \"Off-grid\" does not mean \"do whatever you want\", it means you aren't connected to a fixed grid. - Buy equipment that is designed (and listed) for portable PV storage. This would most commonly be used for RVs and the like, and would look more like a generator than a house panel. You still don't get to drape extension cords all over your home in lieu of permanent wiring if you do this. - Start a company, design a product that can allow temporary whole-circuit backups without transfer switches and all the usual stuff, and somehow convince a NRTL to list it. Good luck. reply complexworld 13 hours agoprevWhen the battery is full where does the power produced by the panels go? reply repiret 13 hours agoparentSolar panels can sit in the sun without producing any power at all just fine. The sun will cause a voltage to develop on the solar panels output terminals, but if that voltage is not enough to cause current to flow, for example, because of battery charge controller is not drawing current, or because they’re not connected to anything, nothing bad happens. reply ThatPlayer 1 hour agoparentprevI don't know if OP's inverter supports it (looking at the manual real quick shows that it should), but the one I have will let you set any loads to use the battery when it's fully charged. Then set a point when it'll switch off battery, say 90%, and use the excess solar (after loads) to charge the battery again. So keeping the battery between 90%-100%, while still using most of the solar. I don't have any loads setup on mine because I don't want to run cables everywhere like that, so my battery just sits fully charged until I need it. reply epistasis 8 hours agoparentprevExactly the same place the power would go if the panels were in sun but the wires weren't connected to anything reply threemux 12 hours agoprevThe quality of the components in this system is suspect. Check out Mobile Solar Power/ Will Prowse for unbiased, in depth reviews for this stuff reply ProllyInfamous 9 hours agoprevYou should absolutely NEVER place solar panels directly upon a roof as many of the linked website photographs demonstrate. Solar cells need ventilation on their undersides, and without it will rapidly be damaged (i.e. become more inefficient). Long-term, water trapped underneath may encourage shinglerot. reply ricardobeat 12 hours agoprevHmm.. I wouldn't trust that \"2,500W power distribution strip\", or the extension cord itself, to actually be safe when you have a fridge, living room appliances and the induction cooktop pulling 1.2KW all at once. Fire waiting to happen. reply chgs 12 hours agoparentDo US cables not have appropriate fuses? If it’s a 10A cable then have a 10A fuse. Pull more than that and the fuse goes. reply ricardobeat 11 hours agorootparentGuess you're from the UK? I think it's one of the only places in the world that does that. No, usually not, though better power strips will have one. But you don't need to go over the specified amps to cause a fire, there are multiple places that could overheat - extension cable, connections, solder points - while still being under the fuse rating if this thing is running at max power for a long time. The main job of a fuse is to protect against power surges / short circuits. reply selfie 12 hours agoprevHow is self install possible if you are not a licensed electrician. Something like this could shock someone if not earthed properly, for example. reply arrowsmith 14 hours agoprev\"We don't even notice power outages or public safety shut-offs anymore\" I don't notice these where I live, because they literally never happen. Are there really places in the first world in 2024 where blackouts still happen frequently? reply thaumaturgy 13 hours agoparent\"Frequently\" is a bit subjective. This is one of those things where it might only happen in a specific area once every couple of years (for more than a few minutes or hours), but when it happens, it sticks around in people's memory -- usually because losing power is a great way to suddenly get a good look behind the facade of modern living. Even people living in parts of California suffering under the reign of PG&E and their \"power safety\" shutoffs during potential fire events don't really experience prolonged, frequent outages, but they are a memorable nuisance (speaking as someone who lived in one of those areas). That said, if you haven't experienced this yet, that's great, but it's likely that you will in the not-too-distant future. Power infrastructure almost everywhere is getting a bit wobbly for a couple of reasons: much of it is well beyond its originally designed lifetime, much of it hasn't been maintained as well as it should have been, and we are currently living through the disruptive effects of an increasingly unstable climate that have been predicted for decades. If your power comes from hydro, then freshwater ecosystems are experiencing deeper and longer drought cycles and the dam that provides that power is probably getting a bit old. If you live in a hurricane area, you're eventually going to get hit by a really bad one. If you live in an area that gets cold, you'll eventually get hit by a severe ice storm. If you live near a wooded area, it's going to burn. If you live deep in an urban setting and your power comes from a nuclear plant and everything has been well enough funded end-to-end to keep it in good working order, then congratulations, you probably won't experience any of these events directly. But a lot of other people are, regardless of who they or their neighbors vote for. reply zefhous 13 hours agoparentprevI live in Boulder, Colorado. We had the Marshall Fire[1] a couple years ago, which burned down 1084 structures on a day with high winds. These winds are pretty normal around here on occasion, at least multiple times each year. What's not normal is that last week, our utility (Xcel Energy) decided to preemptively shut off power to 55,000 customers to reduce risk before a forecasted wind event with high fire-risk[2]. They had intended to restore power the next day, but some went without power for a couple days. The communication and execution of the shutdown seemed poor, and the infrastructure problems that led to the shutdown are still here. The impression I have from comments in local groups is that they are trying to avoid liability and have not adequately invested in fixing shoddy infrastructure that is going to be safe here. People are expecting regular shutoffs to become the new normal. Wind storms aren't going away, fixing the infrastructure would take a long time, and people don't think Xcel is interested in spending the money, even though they can likely afford to. This has definitely left me thinking about a DIY battery+solar solution to keep my heating system running, as well as fridge/freezers. [1] https://en.wikipedia.org/wiki/Marshall_Fire [2] https://www.cpr.org/2024/04/08/for-the-first-time-a-colorado... reply loloquwowndueo 14 hours agoparentprevYes. They are very common in parts of Canada during winter. They get fixed relatively quickly for sure but it’s a yearly occurrence. reply moooo99 14 hours agorootparentI’m curious as to what the reasons for such regular shutoffs are. I’m now 24 years old and I cannot recall ever experiencing a power outage, ever. So either I’m extraordinarily lucky or they aren’t as common here reply beeeeerp 13 hours agorootparentI live in rural CO, and we get them pretty regularly. Extreme weather is pretty common out here, and the infrastructure isn’t as redundant for the mountain communities (I assume due to the cost/benefit ratio of building new lines). It’s not just power - we had a forest fire one year that burned a microwave tower & killed our cell phones _and_ internet for a week. The local businesses struggled for a day or two, because no one really carries cash anymore. I should add that kind of like the OP, I added an enphase LiFePO4 house battery and panels. They’ll keep critical loads running basically indefinitely, which has been a welcome change. We have gas heat, but I used to get nervous in the winter when the power went out (our boiler requires electricity to run). reply toast0 7 hours agorootparentprevI live outside Seattle. We frequently get outages because trees fall on the lines. As most of where I live is glacier carved terrain, the soil conditions are very difficult for both undergrounding cables and for tree root establishment. When there is sustained heavy rains, the ground saturates, and if there are high winds afterwards, trees fall over. I'm worse off than many, because I live on an island, and my electric service comes in across the water from a penisula. There's an awful lot of non-redundant paths through the penisula. On the island, there is no redundancy either, but there is a plan to create a ring between the three substations, which should help. Most of my outages are only a few seconds. At the substation, they have reclosers [1], circuit breakers that will open when shorts or abnormal currents are detected, and then quickly reclose (thus the name) as many shorts are transient. But when a tree falls on the line, that needs a truck rolled out to investigate, and often another one or two to repair. And conditions are similar across the area, so if one tree is on a line, there will be many. My local infrastructure is low priority because it serves few customers. Ice storms are pretty nasty too, because then you've got potentially a lot more trees falling, and also hazardous road conditions that prevent or slow repair work. When I lived in other places, power outages were much more rare. I would have never considered a whole house generator in those places, but I have one here and most of the houses I looked at had them. I would certainly install one if there wasn't one already. [1] https://en.m.wikipedia.org/wiki/Recloser reply bryanlarsen 14 hours agorootparentprevFreezing rain and tornadoes. https://en.wikipedia.org/wiki/January_1998_North_American_ic... reply loloquwowndueo 13 hours agorootparentprevRecent examples: https://en.m.wikipedia.org/wiki/2023_Canada_ice_storm And https://www.msn.com/en-ca/weather/topstories/more-than-12600... reply ronsor 14 hours agorootparentprevUnfortunately, I think OP is in San Francisco. reply loloquwowndueo 13 hours agorootparentPower failures happen there as well. https://en.m.wikipedia.org/wiki/1989_Loma_Prieta_earthquake reply bhaney 13 hours agorootparentprevPoor soul reply 0x0000000 13 hours agoparentprevThis was less than a month ago: 85,000 homes without power in one metro area, many of them for 2 or 3 full days. https://www.timesunion.com/weather/article/capital-region-ad... Most of the US Northeast is at risk of major power outages during strong storms, especially early/late nor'easters which bring ice and heavy wet snow. I guess you could say the US is not a first world country if you want to throw shade, but I'm not buying it. reply Scubabear68 13 hours agoparentprevI live in NJ in the US. The Emerald Ash Borer has decimated ash tree populations here, leaving millions of dead ash trees, many next to power lines. Electric companies are overwhelmed and slow to chop dead ones down. Add in global warming bringing excessive intense rain storms to soften up the ground, and wind storms happening several times a year, and the result is we lose power at least once or twice a year. Some neighbors in very heavily wooded roads lose power 5+ times a year. reply prmoustache 11 hours agoparentprevNot sure Spain can be considered a first world country but we small (5-10min) intermittent power outages in my neighborhood whenever there is sustained large amount of rain. Funny enough, it seems to put the nearest cell phone antenas down as well as I can't even rely on tethering my mobile phone connection to work from home. reply callalex 13 hours agoparentprevThe private for-profit “utility” in California, PG&E, is extremely corrupt but voters can’t do anything about it because it’s a one-party state which means the only people that run for the opposition party are completely looney. Look up the history of the Paradise fire and “public safety power shutoffs”. reply epistasis 7 hours agorootparentOne party has nothing to do with itx it's more just standard PUC malfeasance and corruption which is endemic across the country. Ohio, for example, is anything but a one party state yet has legislators going to prison for being bribed by utilities to pass outrageous legislation. reply grosswait 13 hours agoparentprevYes, much of the rural us east coast experiences a few a month. So many trees mean that even with continuous maintenance, odds are good that a storm or two a month will have an impact to at least some parts of any given service area. reply r00fus 13 hours agorootparentUS needs to start burying power lines. So many benefits and it doesn't look like crap. reply epistasis 7 hours agorootparentThat's runs afoul of the unions that run the poles. reply 1992spacemovie 13 hours agorootparentprevBuried power is 2x to 10x more expensive per mile. reply epistasis 8 hours agoparentprevWelcome to California, where the infrastructure is creaking and falling apart, power is unbelievably expensive, the housing is decrepit and eye-blistering expensive, and people just refuse to improve the system because they don't want more people to move here. I had two 3 minute+ power drops yesterday. The local university lost power for 10+ hours, and scientists -80C freezers had to be emergency evacuated to other locations. reply rgrieselhuber 14 hours agoparentprevnext [10 more] [flagged] bobsomers 13 hours agorootparentCalling California a “failed state” over this seems absurd when the most extreme example in recent history is the Texas freeze power outage in 2021 which left 4.5 million homes without power for several days during winter storms. Somewhere between 250-700 people died because of it. reply rgrieselhuber 13 hours agorootparentIt’s not the reason I call it a failed state but it does occur with more frequency than other states. It’s a matter of something that happens in an emergency vs ongoing issues. reply simonklitj 13 hours agorootparentWhat is the reason, then, that California cannot be considered a first world state, and instead a failed state? And are there other states that used to have this designation, but have lost it in your view? Just curious. reply rgrieselhuber 13 hours agorootparentExploding deficits, tent cities, shit covered sidewalks, blackouts, palpable corruption, to name a few. No, I don’t think it’s limited to California, that state just kind of serves as a time machine for the rest of the country. reply simonklitj 12 hours agorootparentAh, okay. I think we have different ideas of what constitutes a failed state. reply FireBeyond 12 hours agorootparentprevNo, it doesn't. Texas has the most number of outages in the last 20 years of all states, where an outage is defined by the DOE has a power failure affecting 50,000 people or more. > https://www.texasstandard.org/stories/report-texas-has-the-m... It's amazing how much people will let their biases color their worldview. Texas has the most \"ongoing issues\" with power of any state. reply arwineap 13 hours agorootparentprevYou're being delusional. Maybe reconsider reply newsclues 13 hours agorootparentprevReoccurring problems in California compared to a single storm in Texas? lol reply FireBeyond 12 hours agorootparentLOL indeed: Report: Texas has the most major power outages of any state in the U.S. > The study, which covers a time span of 20 years ... looks at a 20-year period from about 2001 to 2021. That’s really the basis of the data, the Department of Energy > https://www.texasstandard.org/stories/report-texas-has-the-m... Sounds like Texas has rather a lot of \"reoccurring problems\". More than California, in fact. reply Cheer2171 13 hours agoprev [–] > It's not wired into the meter, doesn't require a permit, etc. This is 100% a fire hazard and would get your home insurance voided. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Sunboxlabs offers an accessible solar kit for various spaces like condos, rooftops, balconies, or backyards, promoting backup power, savings, and energy independence through solar energy generation.",
      "The kit seamlessly transitions to utility pass-through mode when needed, appealing to landlords, being off-grid, and avoiding excess power fed back to the grid.",
      "The system entails running extension cables to the \"sun box\" from each room, accompanied by cost details, financial payback analysis, production footprint information, remote monitoring, and an instructional manual, ensuring convenience and legality."
    ],
    "commentSummary": [
      "The article discusses challenges of installing off-grid solar backup systems for renters, highlighting safety hazards, landlord approval, and legal implications.",
      "It explores factors like federal tax credits, electricity costs, and environmental concerns influencing the feasibility of solar energy for renters.",
      "Various aspects of solar energy use, safety regulations, insurance considerations, power outages, and potential solutions like DIY setups are covered, reflecting the rising trend of DIY battery and solar solutions due to repeated outages."
    ],
    "points": 204,
    "commentCount": 199,
    "retryCount": 0,
    "time": 1713034744
  },
  {
    "id": 40028338,
    "title": "Truth Social Adheres to AGPL License After Compliance Request",
    "originLink": "https://boehs.org/node/truth-social",
    "originBody": "You Have Power: Making Truth Social Comply With The AGPL in blog date 4/13/2024 A hot minute ago, there was this interesting trend of Republicans being ostracized by mainstream social media, then forming their own. In these places, their version of the truth can proliferate without the moderation they’ve grown to despise. To do this, the conventional strategy is to reskin open-source social media platforms without attribution. There is, of course, a certain irony to the fact that the labor they exploit is frequently performed by liberals, queers, socialists, and other groups they’ve sworn to destroy, but I digress. Luckily, the platforms they leech off are not entirely defenseless. The code of Mastodon is released under the AGPL, a strict open source license that prevents redistribution without disclosure of derivative source code. Both gab and Truth Social have been identified as derivative work of Mastodon, and hence both are bound by the provisions of the AGPL. Mastodon has successfully defended its codebase a number of times, including in 2021, when they successfully convinced Truth Social to release its code. Truth Social continued these releases until December 20th, 2022, when the uploads stopped. How embarrassing. To conduct a request under the AGPL, I need to prove that Truth Social uses AGPL licensed code, and that I have accessed said code. The latter is incredibly easy — the login page fetches /api/v1/instance, which is a pretty distinct Mastodon characteristic. Still, what’s to say that they didn’t just do a faithful, clean room implementation of the Mastodon API? The login page source code makes zero reference to ‘Mastodon’, so I was playing with this familiar API looking for a tell. Yeah, I think I found it. With this in mind, I set my sights on the legal department. Somehow, I doubted they would reply to me. I also started poking around on the frontend, which is unambiguously powered by Soapbox, another piece of software licensed under the AGPL. They also make “open source” releases of Soapbox. I was curious if these releases would be up-to-date (they aren’t), but what I found was really quite interesting: Simply uploading your compiled code and calling it “open source” does not count as compliance, even if it was up-to-date. At this point, the SFC was taking interest. While I have more than enough grounds for the above request, if they don’t comply, the next challenge before a public exposé is proving that the Mastodon codebase has actually been changed since its last open source release. This, of course, is incredibly plausible, given the frontend code obviously has. But we need proof. Kindly, I was provided with a Truth Social account (I do not want my phone number on there, in the event that a little birdie gives maia arson crimew another issue of “the shitposters”). I then clicked around, and discovered the following endpoints in a minute: /api/v4/truth/ads?device=desktop /api/v1/truth/policies/pending /api/v1/truth/carousels/suggestions /api/v1/truth/policies/pending /api/v1/groups/tags Unsurprisingly, Mastodon does not have an ads endpoint. It also doesn’t have a v4 API. Neither does the open source release. The truth directory does exist. It’s at /app/controllers/api/v1/truth/. Unfortunately for Trump Media & Technology Group, the files are missing here. $ tree app/controllers/api/v1/truth app/controllers/api/v1/truth ├── admin │ └── accounts_controller.rb ├── emails_controller.rb ├── passwords_controller.rb └── trending └── truths_controller.rb $ rg carouselswc -l 0 Of course, Republicans are categorically inclusive, which is why they bundle code from a third fediverse codebase that’s AGPL licensed — Pleroma: (nice localization, btw). I was, of course, expecting this to go nowhere. I’m just Evan. TMTG could just drag their feet with the hopes that I give up. I, of course, had no intent of doing so — I was very serious when I said that I would take this matter to the press if I had to. Surprisingly, however, this story doesn’t end with a public boxing match between me and the 45th president. I decided that I would give them 7 days before escalating. This weekend, I received an email stating that they had complied — 2 days before my internal deadline. I checked the source code and sure enough, it is up-to-date as far as I can tell. I’ve released it here: Automatically updated dump of Truth Social’s source code (reskinned Mastodon) Once again, this was absolutely not the outcome I expected. Some people might be disappointed by it. I might be relieved. After I sent that email, I was a little worried about what I was getting myself into. The Truth Social Legal Team. Imagine. But it went my way. The real takeaway is that you do have power. Don’t be scared of the big guys. Speak their language, play on their court. Stand up for what you believe in. You can win. Finally, I want to thank Truth Social for complying appropriately. While we couldn’t be further apart politically, I respect that they followed the law in a timely manner without a fight. In terms of the code — I haven’t looked at it yet. It’s diverged significantly from Mastodon, but the resemblance is there. They’ve cherry-picked specific commits from upstream, but not all of them. I’m sure there are some goodies to be found. I encourage all of you to go looking for them alongside me, as that is your right. Tell me what you find. God speed.",
    "commentLink": "https://news.ycombinator.com/item?id=40028338",
    "commentBody": "[flagged] Making Truth Social Comply with the AGPL (boehs.org)147 points by Tomte 7 hours agohidepastfavorite68 comments truthsocial 6 hours agoThank you for your request (routed through legal, which added a day or so of latency). Main issue is we don't have an automated pipeline to update the published tarball/zipfile from our internal source control system, so it has to be done manually, and no one has that as a specific task. We also review the source for IP/security concerns before releasing. We will probably add a quarterly task to update it, until/unless we start maintaining a public branch and do it automatically. reply gpm 6 hours agoparent> We will probably add a quarterly task to update it, until/unless we start maintaining a public branch and do it automatically. Unless you only update the code running on the website quarterly, I don't think this complies with the license. reply margalabargala 6 hours agorootparentStrictly speaking, the source code needs to be made to users upon request. It doesn't need to be proactively published. That's just the easiest way to do it. So it would be within the license to update \"quarterly, and whenever someone bothers to ask\". reply gpm 6 hours agorootparentI don't believe that's true (as discussed with citation to the license in reply to a sibling comment to your one here). reply dbmikus 6 hours agorootparentprevJust curious, does AGPL require actively publishing the source code, or making it available upon request within a reasonable timeframe? reply db48x 6 hours agorootparentIt depends on how the program is itself distributed. For programs that users interact with over the network, the program must have a way to offer those users the source code as well, though it need not be located on the same server. Paragraph 6d: Convey the object code by offering access from a designated place (gratis or for a charge), and offer equivalent access to the Corresponding Source in the same way through the same place at no further charge. You need not require recipients to copy the Corresponding Source along with the object code. If the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements. This just means that it should have some user–visible page that describes the software and any open–source components it uses, and that this same page should offer a way to download their source code. If you use an open–source component but haven’t modified it, you can send your users to its own webpage to download it if you prefer, but if you have modified it then you have to allow them to download the modified code. reply truthsocial 6 hours agorootparentWhich we maintain at: https://help.truthsocial.com/legal/open-source/ -- the issue is that had gotten out of date. reply db48x 5 hours agorootparentWhile the open source community does actively try to avoid lawsuits, others have let their source code releases get out of date with their actual website before. Usually this results in intervention from a group such as the SFC, backed with very gentle and politely–worded reminders that lawsuits are possible and are occasionally necessary. I believe that they will also remind you that revocation of the license is a possible remedy, although one that they earnestly hope to avoid. Their goal will be to help you find a way to get yourself back into compliance with the license, making the lawsuit unnecessary. They’re pretty good at this; approximately 90% of organizations that find themselves out of compliance manage, with the SFC’s help, to get themselves back on track without involving the courts. You can read more about it at https://sfconservancy.org/copyleft-compliance/ if you want. reply ok_dad 5 hours agorootparentprevSo, you don’t maintain it. Irregular updates aren’t maintenance. Maintenance is regular and scheduled. Stop trying to weasel your way out of the law! reply db48x 5 hours agorootparentNot the law, these are just license terms. reply ok_dad 5 hours agorootparentContract law covers licenses. Just because it’s not criminal doesn’t mean it’s not important to follow. Also, regardless of the fact this is contract law, do you think it’s okay to take code other made and use it without following the licenses? Especially for a rich media corporation? That’s shameful if true. reply db48x 5 hours agorootparent> do you think it’s okay to yadda yadda yadda No, I never said that. You made it up yourself and pretended that I said it. There is a difference between honoring an agreement between equals (such as a license) and obeying the law. reply ok_dad 5 hours agorootparentI never said you said it, I asked it. As stated previously, license are contract law. reply db48x 3 hours agorootparentYou imagined some meaning not present in the words I wrote, and asked me if that’s what I meant. This is a way of implying that my words had this imagined meaning. You should avoid doing that. Contract law does not explicitly state that every provision of every contract must always be followed. By definition, contract law really has nothing to do with the specific circumstances of any particular agreement; if it did, it would just be a law about those circumstances and not about contracts. In fact, it was not until two years ago that a court acknowledged that the GPL really is a contract (https://sfconservancy.org/news/2022/may/16/vizio-remand-win/). All I am saying is that you shouldn’t ask them not to try to weasel out of their obligations under “the law”, but instead to ask that they not try to weasel out of their obligations under the terms of the AGPL. This is a contract that they entered in to not just with the authors of the open–source software that they rely on, but also with their users. It would be dishonorable to renege. reply rvz 5 hours agorootparentprev> Also, regardless of the fact this is contract law, do you think it’s okay to take code other made and use it without following the licenses? Especially for a rich media corporation? That’s shameful if true. Not defending Truth Social, but let's ask GitHub that same question after Microsoft trained on GPL and AGPL source code for its GitHub Copilot uses and it is known for outputting GPL and AGPL code. [0] As Truth Social should comply with the AGPL, GitHub should do the same and open source the whole of Copilot. [0] https://codeium.com/blog/copilot-trains-on-gpl-codeium-does-... reply gpm 6 hours agorootparentprevMy understanding is it requires active publishing, but I'm not a lawyer. Here's what I believe to be the relevant section > 13. Remote Network Interaction; Use with the GNU General Public License. > Notwithstanding any other provision of this License, if you modify the Program, your modified version must prominently offer all users interacting with it remotely through a computer network (if your version supports such interaction) an opportunity to receive the Corresponding Source of your version by providing access to the Corresponding Source from a network server at no charge, through some standard or customary means of facilitating copying of software. This Corresponding Source shall include the Corresponding Source for any work covered by version 3 of the GNU General Public License that is incorporated pursuant to the following paragraph. I'm particularly looking at \"from a network server at no charge, through some standard or customary means of facilitating copying of software\", I don't believe \"upon emailed request\" qualifies. reply sgtnoodle 3 hours agorootparentIs email not customary? It seems like it would be fine as long as they respond in a timely manner, and provide access instructions. Also, in this situation it seems like that's exactly what happened. I suppose what might be non-compliant is if their website doesn't explicitly document the process to access the source, i.e. \"send an email to this addressm to request the most up-to-date source code.\" reply margalabargala 6 hours agorootparentprevThe latter. reply maxbond 6 hours agoparentprevWhat's the work culture like at Truth Social? Are you guys mostly remote? How many developers are there? Are you hiring a lot of new people? Is there an ideological current to the workplace culture? I won't be applying, but I'm genuinely curious what it's like to work at a company in such a unique situation. reply truthsocial 6 hours agorootparentPretty good! Relatively small team (between 10 and 100), biased toward senior with a few ~5 year more intermediate people, mostly remote across the US although we do have an office and try to get together monthly to quarterly. Ironically, lots of open source contributors. We are hiring for a few roles but mostly just being opportunistic rather than needing to hire. Remarkably little turnover for a tech company. We've all worked at multiple other places made the conscious decision to make this a good place to work. Biggest challenges are supporting multiple platforms (iOS, Android, Web), all the backend infra, etc at scale with a small team -- i.e. normal startup stuff. Also the perennial challenge of doing new features vs. making things more robust. A lot of info in the SEC filings as well as news articles (many of which are predictably biased for partisan reasons). reply choppaface 6 hours agorootparentIt’s not political bias when your co-workers get caught and enter a guilty plea: https://amp.cnn.com/cnn/2024/04/03/business/trump-truth-soci... reply fnordpiglet 6 hours agoparentprevMasks don’t protect against viral licenses either. IP isn’t a valid claim to withhold the source. Security needs to be managed outside the code via vaults and other runtime secret stores. There’s no leg to stand on for not releasing the entire code consistently. reply KRAKRISMOTT 6 hours agorootparentThe other mastodon instances voluntarily chose to refuse to peer with Truth Social. Maybe they should show their face in court too. reply defrost 6 hours agorootparentOn what basis? Can you expand on what legal obligation to peer you believe they have? reply ok_dad 6 hours agoparentprevMaybe you should rectify this legal requirement rather than continue to flout it? Put your code where your mouth is and start producing your source continually, as is the requirement from the original developers. You wonder why people seem to hate MAGA folks: it’s because of stuff like this where you have a CLEAR duty under the license (or law in many other cases) and choose to ignore it, disrespecting everyone who creates mastodon upstream. reply fsckboy 6 hours agorootparentyou mean continue to flout it. And people hate MAGA because of open source licensing? I don't think so. reply ok_dad 6 hours agorootparentThanks, not an English major. People hate them because they ignore the law and community standards, such as in this case, like I said. This is one example of many, but you know that and are arguing in bad faith rather than reading my words as intended. Don’t bother responding, or do and get the last words, I don’t really care to argue with trolls today. reply buildbot 6 hours agoparentprev> We also review the source for IP/security concerns before releasing. Any modifications you make need to also be open sourced. reply truthsocial 6 hours agorootparentBest practice when releasing source code generally is making sure no one left API keys, etc. in source code. (Obviously you never check secrets in in the first place, keeping them separate, but it's still worth automated and manual review before releasing.) reply h0l0cube 6 hours agorootparentBest practice is to not have secrets in your source code. Those should be supplied by an internal service, or injected by your build pipeline at the least. reply buildbot 6 hours agorootparentprevThat's not IP, that's secrets. IP needs to be included. reply davorak 6 hours agorootparentLogos, art, and similar? I would have guessed that would not need to be included. reply h0l0cube 5 hours agorootparentThose would be provided by a CDN, with some storage service underneath that. Configuration secrets that (transitively) point to these services should be injected by the build system and have no business being in source code. reply monocasa 6 hours agorootparentprevTrade secrets are a type of IP. reply h0l0cube 5 hours agorootparentThey mean 'configuration secrets'. Those variables used for internal authorization and configuration that should never be leaked outside the organization. If source code of AGPL software is modified and used for an online service, it needs to be published in respecting the license, and best any 'trade secrets' are isolated. The only other alternatives are to use the code as-is or build a proprietary solution from scratch. reply birdiesanders 6 hours agoparentprevYou could just, like, turn it all off and go on holiday. reply truthsocial 6 hours agorootparentWe believe in free speech and giving a voice to the deplatformed, so while we could, we won't. reply bavent 6 hours agorootparentYou mean solely for the deplatformed, and not necessarily free speech for anyone else? Edit: I was banned for saying Ashley Babbit was committing a crime and that we should not have double standards where she is a martyr but George Floyd can’t be. reply truthsocial 6 hours agorootparentI don't think our policy would have flagged that post on its own, let alone banned an account over it; if that happened it was an error. reply simfree 6 hours agorootparentprevWhy did you ban me then? Just like Free Speech Extremist all over again, can't actually live up to the claims you make. reply yyyfb 6 hours agorootparentprevISIS and Al Qaeda are deplatformed too. Will you carry their speech? reply truthsocial 6 hours agorootparentWe try to adhere to https://help.truthsocial.com/legal/terms-of-service/ reply bingbangboom 6 hours agorootparentprev(Reposting: Why was the following comment, word-for-word, immediately flagged? I see nothing wrong with it.) They should. It's important for everyone, even those you personally deem to be the worst of humanity, to have a voice. Assuming they follow the rules on the site, which would probably be based on US law. This is how my ideal social media would be ran. reply wumeow 6 hours agorootparentprevGiven who your owners are, I sincerely doubt that. reply colesantiago 6 hours agorootparentprevSo strongly consider it and deplatform yourself and go to Gab where we can completely ignore you. We don't need another echochamber where we hear the orange man scream all day. reply moomoo11 6 hours agorootparentIf you don’t like it just ignore it. Just let all of them echo each other lol. I have to do that with X because I joined and I’m bombarded by lunatic shit because it forces me to follow Elon when I sign up. All these social media sites suck. reply choppaface 6 hours agorootparentprevLike FTX, their site is not about the “product” its about creating bagholders https://www.justice.gov/usao-sdny/pr/two-individuals-plead-g... reply colesantiago 6 hours agoparentprevNever had Truth Social on HN on my bingo card at all. Still not good enough. You still need to address this though, you are exploiting open source software by ignoring the license. reply choppaface 6 hours agoparentprev> Main issue is we don't have an automated pipeline to update the published Main issue is probably that your team is too busy trying to one-up FTX https://www.bloomberg.com/news/articles/2024-04-03/trump-spa... reply bavent 6 hours agoparentprevHey how do you reconcile claiming to be censorship-free but then banning people who post things that, even being standard conservative viewpoints, differ from the MAGA narrative? Isn’t that censorship? reply truthsocial 6 hours agorootparentProbably misidentified as spam; filtering isn't really based on content, but at various times we've used third party tools to deal with abuse and have been constantly improving and bringing those in-house. If you email support with the details they can address it. The biggest footgun I remember was some religious content (Christ on the cross, specifically) being identified as bad by some of these tools and filtered, which we obviously prioritized correcting. No UGC site really has this solved 100%. Look at Twitter today with the porn reply bots. Facebook has 3-4 orders of magnitude more employees dedicated to filtering content than we have in our entire company. Automation (\"AI\" plus multiple signals) is the solution, but it's a hard problem. reply ultimoo 6 hours agoprevGood on them for complying: https://github.com/boehs/truthsocial/tree/main/source Looks like a straightforward ruby on rails app. I don't have a legal background so I'm curious what would have happened if they hadn't complied? Fined in a civil case? reply internetter 6 hours agoparentYes, the SFC (Software Freedom Conservancy) is a charity that provides legal support for free software developers, and actually backed up mastodon in the last instance of this: https://sfconservancy.org/blog/2021/oct/21/trump-group-agplv... reply fnordpiglet 6 hours agoprevI’m surprised they need such a sophisticated ads system for serving the MyPillow ad they’re still trying to collect on. reply buildbot 6 hours agoprevGood! Companies need to be called out for this more. For example, Phase One, a very high end digital camera company, started using Linux in their digital backs. They were completely unaware of the impacts of GPL!!! At first they refused, until I literally just linked them the Vizio case by SFC. I got a source download of the (mostly AMD/Xilinx) software the next day :) reply zja 6 hours agoprevThe post about hacking Gab’s AI prompt that they linked to towards the end of the article was wild: https://infosec.exchange/@bontchev/112257849039442072 reply bigfatfrock 6 hours agoparentAgreed, I was expecting semi-typical internet bullshit but the personal confirmations were amazing! reply angusturner 6 hours agoprevGreat write up. The Github mirror is also quite convenient. reply colesantiago 6 hours agoprevThis is a great start with Truth Social, lets also do something with this poor student, who's AGPL software is being still used by Andrew Tate's \"The Real World\" scam. Can we make them comply with the AGPL as well? See: https://insrt.uk/post/andrew-tate-stealing-software-revolt reply internetter 6 hours agoparentThey should email compliance@sfconservancy.org, the non-profit that is currently suing Vizio and previously represented Mastodon in this case. reply tick_tock_tick 6 hours agoprevWow sounds like they comply better then pretty much any company I wasn't expecting that when I started the article. reply sroussey 6 hours agoparentAgreed, though AGPL is quite different than GPL and I’m not aware of many (any?) public companies that have their main code base covered by that license. reply ApolloFortyNine 7 hours agoprevTldr, they complied when asked. The write up could have done without a good portion of it just bashing Republicans every other line, it didn't add anything at all to an otherwise fine writeup. reply bingbangboom 6 hours agoprevnext [2 more] [flagged] bigfatfrock 5 hours agoparentDon't worry dude, you're still here. reply akira2501 6 hours agoprev [–] > that the labor they exploit is frequently performed by liberals, queers, socialists, and other groups they’ve sworn to destroy You know... people with significantly different ideologies also write code. reply jrflowers 6 hours agoparentThis is a good point because “frequently performed by” means “exclusively performed by” reply fnordpiglet 6 hours agoparentprev [–] I think the word is “frequently” which isn’t “exclusively” and the subject was “open source,” not code. I don’t think it’s controversial most free software / open source people fall into these categories much to the cryptofascist science denying qanon follower free software nerds dismay. reply akira2501 4 hours agorootparent [–] I'd even challenge \"frequently\" to the extent that it rises to an obvious point of \"exploitation\" when \"their\" code is used. It claims ownership and a position that is neither relevant the copyright issues presented nor, in my opinion, even true. It's probably not controversial here on Hacker News, but many people live inside this HN valley bubble that's pretty solidly disconnected from the rest of the country and even the world. You've made this particular case here perfectly by attempting to connect identity to open source. Which, I do find annoying, as many people make the same assumptions you do towards me in my work, as if presumptively pushing politics into an engineering conversation is a worthwhile or welcome activity. The mixture of faux shock and bullying in response is, sadly, nothing new to me either. Anyways, you're welcome to openly have as closed of a mind as you like, but I will always find the behavior baffling and worthy of comment. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Republicans have established their own social media platforms to share content without moderation.",
      "These platforms are discovered to be utilizing code from Mastodon, licensed under AGPL.",
      "The author, Evan, investigates and demands compliance from Truth Social, a platform by Trump Media & Technology Group, which eventually releases its updated source code, highlighting accountability and legal adherence."
    ],
    "commentSummary": [
      "The discussion centers on Truth Social's adherence to the AGPL license, highlighting the significance of sharing the source code and following open-source license conditions.",
      "It addresses company culture, software development hurdles, content moderation, and legal responsibilities concerning free software licenses.",
      "The conversation delves into the involvement of various groups in coding and open-source communities, showcasing ideological conflicts within the tech sector."
    ],
    "points": 147,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1713064240
  },
  {
    "id": 40023892,
    "title": "Evolution of Web Design: CSS Through Ages",
    "originLink": "https://eev.ee/blog/2020/02/01/old-css-new-css/",
    "originBody": "Sat Feb 01, 2020 Old CSS, new CSS I first got into web design/development in the late 90s, and only as I type this sentence do I realize how long ago that was. And boy, it was horrendous. I mean, being able to make stuff and put it online where other people could see it was pretty slick, but we did not have very much to work with. I’ve been taking for granted that most folks doing web stuff still remember those days, or at least the decade that followed, but I think that assumption might be a wee bit out of date. Some time ago I encountered a tweet marvelling at what we had to do without border-radius. I still remember waiting with bated breath for it to be unprefixed! But then, I suspect I also know a number of folks who only tried web design in the old days, and assume nothing about it has changed since. I’m here to tell all of you to get off my lawn. Here’s a history of CSS and web design, as I remember it. (Please bear in mind that this post is a fine blend of memory and research, so I can’t guarantee any of it is actually correct, especially the bits about causality. You may want to try the W3C’s history of CSS, which is considerably shorter, has a better chance of matching reality, and contains significantly less swearing.) (Also, this would benefit greatly from more diagrams, but it took long enough just to write.) The very early days In the beginning, there was no CSS. This was very bad. My favorite artifact of this era is the book that taught me HTML: O’Reilly’s HTML: The Definitive Guide, published in several editions in the mid to late 90s. The book was indeed about HTML, with no mention of CSS at all. I don’t have it any more and can’t readily find screenshots online, but here’s a page from HTML & XHTML: The Definitive Guide, which seems to be a revision (I’ll get to XHTML later) with much the same style. Here, then, is the cutting-edge web design advice of 199X: “Clearly delineate headers and footers with horizontal rules.” No, that’s not a border-top. That’s an . The page title is almost certainly centered with, well, . The page uses the default text color, background, and font. Partly because this is a guidebook introducing concepts one at a time; partly because the book was printed in black and white; and partly, I’m sure, because it reflected the reality that coloring anything was a huge pain in the ass. Let’s say you wanted all your s to be red, across your entire site. You had to do this: 1 ... …every single goddamn time. Hope you never decide to switch to blue! Oh, and everyone wrote HTML tags in all caps. I don’t remember why we all thought that was a good idea. Maybe this was before syntax highlighting in text editors was very common (read: I was 12 and using Notepad), and uppercase tags were easier to distinguish from body text. Keeping your site consistent was thus something of a nightmare. One solution was to simply not style anything, which a lot of folks did. This was nice, in some ways, since browsers let you change those defaults, so you could read the Web how you wanted. A clever alternate solution, which I remember showing up in a lot of Geocities sites, was to simply give every page a completely different visual style. Fuck it, right? Just do whatever you want on each new page. That trend was quite possibly the height of web design. Damn, I miss those days. There were no big walled gardens, no Twitter or Facebook. If you had anything to say to anyone, you had to put together your own website. It was amazing. No one knew what they were doing; I’d wager that the vast majority of web designers at the time were clueless hobbyist tweens (like me) all copying from other clueless hobbyist tweens. Half the Web was fan portals about Animorphs, with inexplicable splash pages warning you that their site worked best if you had a 640×480 screen. (Any 12-year-old with insufficient resolution should, presumably, buy a new monitor with their allowance.) Everyone who was cool and in the know used Internet Explorer 3, the most advanced browser, but some losers still used Netscape Navigator so you had to put a “Best in IE” animated GIF on your splash page too. This was also the era of “web-safe colors” — a palette of 216 colors, where every channel was one of 00, 33, 66, 99, cc, or ff — which existed because some people still had 256-color monitors! The things we take for granted now, like 24-bit color. In fact, a lot of stuff we take for granted now was still a strange and untamed problem space. You want to have the same navigation on every page on your website? Okay, no problem: copy/paste it onto each page. When you update it, be sure to update every page — but most likely you’ll forget some, and your whole site will become an archaeological dig into itself, with strata of increasingly bitrotted pages. Much easier was to use frames, meaning the browser window is split into a grid and a different page loads in each section… but then people would get confused if they landed on an individual page without the frames, as was common when coming from a search engine like AltaVista. (I can’t believe I’m explaining frames, but no one has used them since like 2001. You know iframes? The “i” is for inline, to distinguish them from regular frames, which take up the entire viewport.) PHP wasn’t even called that yet, and nobody had heard of it. This weird “Perl” and “CGI” thing was really strange and hard to understand, and it didn’t work on your own computer, and the errors were hard to find and diagnose, and anyway Geocities didn’t support it. If you were really lucky and smart, your web host used Apache, and you could use its “server side include” syntax to do something like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 (actual page content goes here) Mwah. Beautiful. Apache would see the special comments, paste in the contents of the referenced files, and you’re off to the races. The downside was that when you wanted to work on your site, all the navigation was missing, because you were doing it on your regular computer without Apache, and your web browser thought those were just regular HTML comments. It was impossible to install Apache, of course, because you had a computer, not a server. Sadly, that’s all gone now — paved over by homogenous timelines where anything that wasn’t made this week is old news and long forgotten. The web was supposed to make information eternal, but instead, so much of it became ephemeral. I miss when virtually everyone I knew had their own website. Having a Twitter and an Instagram as your entire online presence is a poor substitute. … So, let’s look at the Space Jam website. Case study: Space Jam Space Jam, if you’re not aware, is the greatest movie of all time. It documents Bugs Bunny’s extremely short-lived basketball career, playing alongside a live action Michael Jordan to save the planet from aliens for some reason. It was followed by a series of very successful and critically acclaimed RPG spinoffs, which describe the fallout of the Space Jam and are extremely canon. And we are truly blessed, for 24 years after it came out, its website is STILL UP. We can explore the pinnacle of 1996 web design, right here, right now. First, notice that every page of this site is a static page. Not only that, but it’s a static page ending in .htm rather than .html, because people on Windows versions before 95 were still beholden to 8.3 filenames. Not sure why that mattered in a URL, as if you were going to run Windows 3.11 on a Web server, but there you go. The CSS for the splash page looks like this: 1Haha, just kidding! What the fuck is CSS? Space Jam predates it by a month. (I do see a single line in the page source, but I’m pretty sure that was added much later to style some legally obligatory policy links.) Notice the extremely precise positioning of these navigation links. This feat was accomplished the same way everyone did everything in 1996: with tables. In fact, tables have one functional advantage over CSS for layout, which was very important in those days, and not only because CSS didn’t exist yet. You see, you can ctrl-click to select a table cell and even drag around to select all of them, which shows you how the cells are arranged and functions as a super retro layout debugger. This was great because the first meaningful web debug tool, Firebug, wasn’t released until 2006 — a whole decade later! The markup for this table is overflowing with inexplicable blank lines, but with those removed, it looks like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 ...That’s the first two rows, including the logo. You get the idea. Everything is laid out with align and valign on table cells; rowspans and colspans are used frequently; and there are some s thrown in for good measure, to adjust vertical positioning by one line-height at a time. Other fantastic artifacts to be found on this page include this header, which contains Apache SSI syntax! This must’ve quietly broken when the site was moved over the years; it’s currently hosted on Amazon S3. You know, Amazon? The bookstore? 1 2 3 4 5 6 7Okay, let’s check out jam central. I’ve used my browser dev tools to reduce the viewport to 640×480 for the authentic experience (although I’d also have lost some vertical space to the title bar, taskbar, and five or six IE toolbars). Note the frames: the logo in the top left leads back to the landing page, cleverly saving screen space on repeating all that navigation, and the top right is a fucking ad banner which has been blocked like seven different ways. All three parts are separate pages. Note also the utterly unreadable red text on a textured background, one of the truest hallmarks of 90s web design. “Why not put that block of text on an easier-to-read background?” you might ask. You imbecile. How would I possibly do that? Only thehas a background attribute! I could use a table, but tables only support solid background colors, and that would look so boring! But wait, what is this new navigation widget? How are the links all misaligned like that? Is this yet another table? Well, no, although filling a table with chunks of a sliced-up image wasn’t uncommon. But this is an imagemap, a long-forgotten HTML feature. I’ll just show you the source: 1 2 3 4 5 6 7 8I assume this is more or less self-explanatory. The usemap attribute attaches an image map, which is defined as a bunch of clickable areas, beautifully encoded as inscrutable lists of coordinates or something. And this stuff still works! This is in HTML! You could use it right now! Probably don’t though! The thumbnail grid Let’s look at one more random page here. I’d love to see some photos from the film. (Wait, photos? Did we not know what “screenshots” were yet?) Another frameset, but arranged differently this time. 1They did an important thing here: since they specified a background image (which is opaque), they also specified a background color. Without it, if the background image failed to load, the page would be white text on the default white background, which would be unreadable. (That’s still an important thing to keep in mind. I feel like modern web development tends to assume everything will load, or sees loading as some sort of inconvenience to be worked around, but not everyone is working on a wired connection in a San Francisco office twenty feet away from a backbone.) But about the page itself. Thumbnail grids are a classic problem of web design, dating all the way back to… er… well, at least as far back as Space Jam. The main issue is that you want to put things next to each other, whereas HTML defaults to stacking everything in one big column. You could put all the thumbnails inline, in a single row of (wrapping) text, but that wouldn’t be much of a grid — and you usually want each one to have some sort of caption. Space Jam’s approach was to use the only real tool anyone had in their toolbox at the time: a table. It’s structured like this: 1 2 3 4 5... ... ...A 3×3 grid of thumbnails, left to the browser to arrange. (The last image, on a row of its own, isn’t actually part of the table.) This can’t scale to fit your screen, but everyone’s screen was pretty tiny back then, so that was slightly less of a concern. They didn’t add captions here, but since every thumbnail is wrapped in a table cell, they easily could have. This was the state of the art in thumbnail grids in 1996. We’ll be revisiting this little UI puzzle a few times; you can see live examples (and view source for sample markup) on a separate page. But let’s take a moment to appreciate the size of the “full-size, full-color, internet-quality” movie screenshots on my current monitor. Hey, though, they’re less than 16 KB! That’ll only take nine seconds to download. (I’m reminded of the problem of embedded video, which wasn’t solved until HTML5’stag some years later. Until then, you had to use a binary plugin, and all of them were terrible.) (Oh, by the way: images within links, by default, have a link-colored border around them. Image links are usually self-evident, so this was largely annoying, and until CSS you had to disable them for every single image with .) The regular early days So that’s where we started, and it sucked. If you wanted any kind of consistency on more than a handful of pages, your options were very limited, and they were pretty much limited to a whole lot of copying and pasting. The Space Jam website opted to, for the most part, not bother at all — as did many others. Then CSS came along, it was a fucking miracle. All that inline repetition went away. You want all your top-level headings to be a particular color? No problem: 1 2 3 H1 { color: #FF0000; } Bam! You’re done. No matter how many s you have in your document, every single one of them will be eye-searing red, and you never have to think about it again. Even better, you can put that snippet in its own file and have that questionable aesthetic choice applied to every page of your whole site with almost no effort! The same applied to your gorgeous tiling background image, the colors of your links, and the size of the font in your tables. (Just remember to wrap the contents of yourtags in HTML comments, or old browsers without CSS support will display them as text.) You weren’t limited to styling tags en masse, either. CSS introduced “classes” and “IDs” to target only specifically flagged elements. A selector like P.important would only affect , and #header would only affect . (The difference is that IDs are intended to be unique in a document, whereas classes can be used any number of times.) With these tools, you could effectively invent your own tags, giving you a customized version of HTML specific to your website! This was a huge leap forward, but at the time, no one (probably?) was thinking of using CSS to actually arrange the page. When CSS 1 was made a recommendation in December ‘96, it barely addressed layout at all. All it did was divorce HTML’s existing abilities from the tags they were attached to. We had font colors and backgrounds becauseandexisted. The only feature that even remotely affected where things were positioned was the float property, the equivalent to , which pulled an image to the side and let text flow around it, like in a magazine article. Hardly whelming. This wasn’t too surprising. HTML hadn’t had any real answers for layout besides tables, and the table properties were too complicated to generalize in CSS and too entangled with the tag structure, so there was nothing for CSS 1 to inherit. It merely reduced the repetition in what we were already doing with e.g.tags — making Web design less tedious, less error-prone, less full of noise, and much more maintainable. A pretty good step forward, and everyone happily adopted it for that, but tables remained king for arranging your page. That was okay, though; all your blog really needed was a header and a sidebar, which tables could do just fine, and it wasn’t like you were going to overhaul that basic structure very often. Copy/pasting a few lines ofandwasn’t nearly as big a deal. For some span of time — I want to say a couple years, but time passes more slowly when you’re a kid — this was the state of the Web. Tables for layout, CSS for… well, style. Colors, sizes, bold, underline. There was even this sick trick you could do with links where they’d only be underlined when the mouse was pointing at them. Tubular! (Fun fact: HTML email is still basically trapped in this era.) (And here’s about where I come in, at the ripe old age of 11, with no clue what I was doing and mostly learning from other 11-year-olds who also had no clue what they were doing. But that was fine; a huge chunk of the Web was 11-year-olds making their own websites, and it was beautiful. Why would you go to a business website when you can take a peek into the very specific hobbies of someone on the other side of the planet?) The dark times A year and a half later, in mid ‘98, we were gifted CSS 2. (I love the background on this page, by the way.) This was a modest upgrade that addressed a few deficiencies in various areas, but most interesting was the addition of a couple positioning primitives: the position property, which let you place elements at precise coordinates, and the inline-block display mode, which let you stick an element in a line of text like you could do with images. Such tantalizing fruit, just out of reach! Using position seemed nice, but pixel-perfect positioning was at serious odds with the fluid design of HTML, and it was difficult to make much of anything that didn’t fall apart on other screen sizes or have other serious drawbacks. This humble inline-block thing seemed interesting enough; after all, it solved the core problem of HTML layout, which is putting things next to each other. But at least for the moment, no browser implemented it, and it was largely ignored. I can’t say for sure if it was the introduction of positioning or some other factor, but something around this time inspired folks to try doing layout in CSS. Ideally, you would completely divorce the structure of your page from its appearance. A website even came along to take this principle to the extreme — CSS Zen Garden is still around, and showcases the same HTML being radically transformed into completely different designs by applying different stylesheets. Trouble was, early CSS support was buggy as hell. In retrospect, I suspect browser vendors merely plucked the behavior off of HTML tags and called it a day. I’m delighted to say that RichInStyle still has an extensive list of early browser CSS bugs up; here are some of my favorites: IE 3 would ignore all but the lasttag in a document. IE 3 ignored pseudo-classes, so a:hover would be treated as a. IE 3 and IE 4 treated auto margins as zero. Actually, I think this one might’ve persisted all the way to IE 6. But that was okay, because IE 6 also incorrectly applied text-align: center to block elements. If you set a background image to an absolute URL, IE 3 would try to open the image in a local program, as though you’d downloaded it. Netscape 4 understood an ID selector like #id, but ignored h1#id as invalid. Netscape 4 didn’t inherit properties — including font and text color! — into table cells. Netscape 4 applied properties onto the list marker, rather than the contents. If the same element has both float and clear (not unreasonable), Netscape 4 for Mac crashes. This is what we had to work with. And folks wanted to use CSS to lay out an entire page? Ha. Yet the idea grew in popularity. It even became a sort of elitist rallying cry, a best practice used to beat other folks over the head. Tables for layout are just plain bad, you’d hear! They confuse screenreaders, they’re semantically incorrect, they interact poorly with CSS positioning! All of which is true, but it was a much tougher pill to swallow when the alternative was— Well, we’ll get to that in a moment. First, some background on the Web landscape circa 2000. The end of the browser wars and subsequent stagnation The short version is: this company Netscape had been selling its Navigator browser (to businesses; it was free for personal use), and then Microsoft entered the market with its completely free Internet Explorer browser, and then Microsoft had the audacity to bundle IE with Windows. Can you imagine? An operating system that comes with a browser? This was a whole big thing, Microsoft was sued over it, and they lost, and the consequence was basically nothing. But it wouldn’t have mattered either way, because they’d still done it, and it had worked. IE pretty much annihilated Netscape’s market share. Both browsers were buggy as hell, and differently buggy as hell, so a site built exclusively against one was likely to be a big mess when viewed in the other — this meant that when Netscape’s market share dropped, web designers paid less and less attention to it, and less of the Web worked in it, and its market share dropped further. Sucks for you if you don’t use Windows, I guess. Which is funny, because there was an IE for Mac 5.5, and it was generally less buggy than IE 6. (Incidentally, Bill Gates wasn’t so much a brilliant nerd as an aggressive and ruthless businessman who made his fortune by deliberately striving to annihilate any competition standing in his way and making computing worse overall as a result, just saying.) By the time Windows XP shipped in mid 2001, with Internet Explorer 6 built in, Netscape had gone from a juggernaut to a tiny niche player. And then, having completely and utterly dominated, Microsoft stopped. Internet Explorer had seen a release every year or so since its inception, but IE 6 was the last release for more than five years. It was still buggy, but that was less noticeable when there was no competition, and it was good enough. Windows XP, likewise, was good enough to take over the desktop, and there wouldn’t be another Windows for just as long. The W3C, the group who write the standards (not to be confused with W3Schools, who are shady SEO leeches), also stopped. HTML had seen several revisions throughout the mid 90s, and then froze as HTML 4. CSS had gotten an update in only a year and a half, and then no more; the minor update CSS 2.1 wouldn’t hit Candidate Recommendation status until early 2004, and took another seven years to be finalized. With IE 6’s dominance, it was as if the entire Web was frozen in time. Standards didn’t matter, because there was effectively only one browser, and whatever it did became the de facto standard. As the Web grew in popularity, IE’s stranglehold also made it difficult to use any platform other than Windows, since IE was Windows-only and it was a coin flip whether a website would actually work with any other browser. (One begins to suspect that monopolies are bad. There oughta be a law!) In the meantime, Netscape had put themselves in an even worse position by deciding to do a massive rewrite of their browser engine, culminating in the vastly more standards-compliant Netscape 6 — at the cost of several years away from the market while IE was kicking their ass. It never broke 10% market share, while IE’s would peak at 96%. On the other hand, the new engine was open sourced as the Mozilla Application Suite, which would be important in a few years. Before we get to that, some other things were also happening. Quirks mode All early CSS implementations were riddled with bugs, but one in particular is perhaps the most infamous CSS bug of all time: the box model bug. You see, a box (the rectangular space taken up by an element) has several measurements: its own width and height, then surrounding whitespace called padding, then an optional border, then a margin separating it from neighboring boxes. CSS specifies that these properties are all additive. A box with these styles: 1 2 3 width: 100px; padding: 10px; border: 2px solid black; …would thus be 124 pixels wide, from border to border. IE 4 and Netscape 4, on the other hand, took a different approach: they treated width and height as measuring from border to border, and they subtracted the border and padding to get the width of the element itself. The same box in those browsers would be 100 pixels wide from border to border, with 76 pixels remaining for the content. This conflict with the spec was not ideal, and IE 6 set out to fix it. Unfortunately, simply making the change would mean completely breaking the design of a whole lot of websites that had previously worked in both IE and Netscape. So the IE team came up with a very strange compromise: they declared the old behavior (along with several other major bugs) as “quirks mode” and made it the default. The new “strict mode” or “standards mode” had to be opted into, by placing a “doctype” at the beginning of your document, before thetag. It would look something like this: 1Everyone had to paste this damn mess of a line at the top of every single HTML document for years. (HTML5 would later simplify it to .) In retrospect, it’s a really strange way to opt into correct CSS behavior; doctypes had been part of the HTML spec since way back when it was an RFC. I’m guessing the idea was that, since nobody bothered actually including one, it was a convenient way to allow opting in without requiring proprietary extensions just to avoid behavior that had been wrong in the first place. Good for the IE team! The funny thing is, quirks mode still exists and is still the default in all browsers, twenty years later! The exact quirks have varied over time, and in particular neither Chrome nor Firefox use the IE box model even in quirks mode, but there are still quite a few other emulated bugs. Hello! Eevee here, almost two years later. You may notice the preceding link is broken. Well, it seems Mozilla made the completely baffling decision to nuke all Mozilla-specific information from MDN on the grounds that it really belongs in Firefox documentation, then failed to add it to the Firefox documentation. So some critical technical information that's also of deep historical interest, like exactly what quirks mode even does in Firefox, is now lost, except for the unreadable archived copy. This also reduces the only mention of quirks mode on MDN to this lone article, which says very vaguely what it is but doesn't offer so much as a glimpse at what the differences actually are. What a fucking circus. Modern browsers also have “almost standards” mode, which emulates only a single quirk, perhaps the second most infamous one: if a table cell contains only a single image, the space under the baseline is removed. Under normal CSS rules, the image is sitting within a line of (otherwise empty) text, which requires some space reserved underneath for descenders — the tails on letters like y. Early browsers didn’t handle this correctly, and some otherwise strict-mode websites from circa 2000 rely on it — e.g., by cutting up a large image and arranging the chunks in table cells, expecting them to display flush against each other — hence the intermediate mode to keep them limping along. But getting back to the past: while this was certainly a win for standards (and thus interop), it created a new problem. Since IE 6 dominated, and doctypes were optional, there was little compelling reason to bother with strict mode. Other browsers ended up emulating it, and the non-standard behavior became its own de facto standard. Web designers who cared about this sort of thing (and to our credit, there were a lot of us) made a rallying cry out of enabling strict mode, since it was the absolute barest minimum step towards ensuring compatibility with other browsers. The rise and fall of XHTML Meanwhile, the W3C had lost interest in HTML in favor of developing XHTML, an attempt to redesign HTML with the syntax of XML rather than SGML. (What on Earth is SGML, you ask? I don’t know. Nobody knows. It’s the grammar HTML was built on, and that’s the only reason anyone has heard of it.) To their credit, there were some good reasons to do this at the time. HTML was generally hand-written (as it still is now), and anything hand-written is likely to have the occasional bugs. Browsers weren’t in the habit of rejecting buggy HTML outright, so they had various error-correction techniques — and, as with everything else, different browsers handled errors differently. Slightly malformed HTML might appear to work fine in IE 6 (where “work fine” means “does what you hoped for”), but turn into a horrible mess in anything else. The W3C’s solution was XML, because their solution to fucking everything in the early 2000s was XML. If you’re not aware, XML takes a much more explicit and aggressive approach to error handling — if your document contains a parse error, the entire document is invalid. That means if you bank on XHTML and make a single typo somewhere, nothing at all renders. Just an error. This sucked. It sounds okay on the face of things, but consider: generic XML is usually assembled dynamically with libraries that treat a document as a tree you manipulate, then turn it all into text when you’re done. That’s great for the common use of XML as data serialization, where your data is already a tree and much of the XML structure is simple and repetitive and easy to squirrel away in functions. HTML is not like that. An HTML document has little reliable repeating structure; even this blog post, constructed mostly fromtags, also contains surprise s within body text and the occasionalbetween paragraphs. That’s not fun to express as a tree. And this is a big deal, because server-side rendering was becoming popular around the same time, and generated HTML was — still is! — put together with templates that treat it as a text stream. If HTML were only written as complete static documents, then XHTML might have worked out — you write a document, you see it in your browser, you know it works, no problem. But generating it dynamically and risking that particular edge cases might replace your entire site with an unintelligible browser error? That sucks. It certainly didn’t help that we were just starting to hear about this newfangled Unicode thing around this time, and it was still not always clear how exactly to make that work, and one bad UTF-8 sequence is enough for an entire XML document to be considered malformed! And so, after some dabbling, XHTML was largely forgotten. Its legacy lives on in two ways: It got us all to stop using uppercase tag names! So long , hello . XML is case-sensitive, you see, and all the XHTML tags were defined in lowercase, so uppercase tags simply would not work. (Fun fact: to this day, JavaScript APIs report HTML tag names in uppercase.) The increased popularity of syntax highlighting probably also had something to do with this; we weren’t all still using Notepad as we had been in 1997. A bunch of folks still think self-closing tags are necessary. You see, HTML has two kinds of tags: containers like ... and markers like . Since acan’t possibly contain anything, there’s no such thing as . XML, as a generic grammar, doesn’t have this distinction; every tag must be closed, but as a shortcut, you can writeto mean . XHTML has been dead for years, but for some reason, I still see folks writein regular HTML documents. Outside of XML, that slash doesn’t do anything; HTML5 has defined it for compatibility reasons, but it’s silently ignored. It’s even actively harmful, since it might lead you to believe thatis an empty tag — but in HTML, it definitely is not! I do miss one thing about XHTML. You could combine it with XSLT, the XML templating meta-language, to do in-browser templating (i.e., slot page-specific contents into your overall site layout) with no scripting required. It’s the only way that’s ever been possible, and it was cool as all hell when it worked, but the drawbacks were too severe when it didn’t. Also, XSLT is totally fucking incomprehensible. The beginning of CSS layout Back to CSS! You’re an aspiring web designer. For whatever reason, you want to try using this CSS thing to lay out your whole page, even though it was clearly intended just for colors and stuff. What do you do? As I mentioned before, your core problem is putting things next to each other. Putting things on top of each other is a non-problem — that’s the normal behavior of HTML. The whole reason everyone uses tables is that you can slop stuff into table cells and have it laid out side-by-side, in columns. Well, tables seem to be out. CSS 2 had added some element display modes that corresponded to the parts of a table, but to use them, you’d have to have the same three levels of nesting as real tables: the table itself, then a row, then a cell. That doesn’t seem like a huge step up, and anyway, IE won’t support them until the distant future. There’s that position thing, but it seems to make things overlap more often than not. Hmm. What does that leave? Only one tool, really: float. I said that float was intended for magazine-style “pull” images, which is true, but CSS had defined it fairly generically. In principle, it could be applied to any element. If you wanted a sidebar, you could tell it to float to the left and be 20% the width of the page, and you’d get something like this: 1 2 3 4 +---------+sidebarHello, and welcome to my website!| +---------+ Alas! Floating has the secondary behavior that text wraps around it. If your page text was ever longer than your sidebar, it would wrap around underneath the sidebar, and the illusion would shatter. But hey, no problem. CSS specified that floats don’t wrap around each other, so all you needed to do was float the body as well! 1 2 3 4 5 6 7 +---------+ +-----------------------------------+sidebar| Hello, and welcome to my website!||| +---------+Here's a longer paragraph to show| that my galaxy brain CSS float| nonsense prevents text wrap.+-----------------------------------+ This approach worked, but its limitations were much more obvious than those of tables. If you added a footer, for example, then it would try to fit to the right of the body text — remember, all of that is “pull” floats, so as far as the browser is concerned, the “cursor” is still at the top. So now you need to use clear, which bumps an element down below all floats, to fix that. And if you made the sidebar 20% wide and the body 80% wide, then any margin between them would add to that 100%, making the page wider than the viewport, so now you have an ugly horizontal scrollbar, so you have to do some goofy math to fix that as well. If you have borders or backgrounds on either part, then it was a little conspicuous that they were different heights, so now you have to do some truly grotesque stuff to fix that. And the more conscientious authors noticed that screenreaders would read the entire sidebar before getting to the body text, which is a pretty rude thing to subject blind visitors to, so they came up with yet more elaborate setups to have a three-column layout with the middle column appearing first in the HTML. The result was a design that looked nice and worked well and scaled correctly, but backed by a weird mess of CSS. None of what you were writing actually corresponded to what you wanted — these are major parts of your design, not one-off pull quotes! It was difficult to understand the relationship between the layout-related CSS and what appeared on the screen, and that would get much worse before it got better. Thumbnail grid 2 Armed with a new toy, we can improve that thumbnail grid. The original table-based layout was, even if you don’t care about tag semantics, incredibly tedious. Now we can do better! 1 2 3 4 5 6caption caption caption ...This is the dream of CSS: your HTML contains the page data in some sensible form, and then CSS describes how it actually looks. Unfortunately, with float as the only tool available to us, the results are a bit rough. This new version does adapt better to various screen sizes, but it requires some hacks: the cells have to be a fixed height, centering the whole grid is fairly complicated, and the grid effect falls apart entirely with wider elements. It’s becoming clear that what we wanted is something more like a table, but with a flexible number of columns. This is just faking it. You also need this weird “clearfix” thing, an incantation that would become infamous during this era. Remember that a float doesn’t move the “cursor” — a fake idea I’m using, but close enough. That means that this , which is full only of floated elements, has no height at all. It ends exactly where it begins, with all the floated thumbnails spilling out below it. Worse, because any subsequent elements don’t have any floated siblings, they’ll ignore the thumbnails entirely and render normally from just below the empty “grid” — producing an overlapping mess! The solution is to add a dummy element at the end of the list which takes up no space, but has the CSS clear: both — bumping it down below all floats. That effectively pushes the bottom of theunder all the individual thumbnails, so it fits snugly around them. Browsers would later support the ::before and ::after “generated content” pseudo-elements, which let us avoid the dummy element entirely. Stylesheets from the mid-00s were often littered with stuff like this: 1 2 3 4 5 .thumbnail-grid::after { content: ''; display: block; clear: both; } Still, it was better than tables. DHTML As a quick aside into the world of JavaScript, the newfangled position property did give us the ability to do some layout things dynamically. I heartily oppose such heresy, not least because no one has ever actually done it right, but it was nice for some toys. Thus began the era of “dynamic HTML” — i.e., HTML affected by JavaScript, a term that has fallen entirely out of favor because we can’t even make a fucking static blog without JavaScript any more. In the early days it was much more innocuous, with teenagers putting sparkles that trailed behind your mouse cursor or little analog clocks that ticked by in real time. The most popular source of these things was Dynamic Drive, a site that miraculously still exists and probably has a bunch of toys not updated since the early 00s. But if you don’t like digging, here’s an example: every year (except this year when I forgot oops), I like to add confetti and other nonsense to my blog on my birthday. I’m very lazy so I started this tradition by using this script I found somewhere, originally intended for snowflakes. It works by placing a bunch of images on the page, giving them position: absolute, and meticulously altering their coordinates over and over. Contrast this with the version I wrote from scratch a couple years ago, which has only a tiny bit of JS to set up the images, then lets the browser animate them with CSS. It’s slightly less featureful, but lets the browser do all the work, possibly even with hardware acceleration. How far we’ve come. Web 2.0 Dark times can’t last forever. A combination of factors dragged us towards the light. One of the biggest was Firefox — or, if you were cool, originally Phoenix and then Firebird — which hit 1.0 in Nov ‘04 and went on to take a serious bite out of IE. That rewritten Netscape 6 browser core, the heart of the Mozilla Suite, had been extracted into a standalone browser. It was quick, it was simple, it was much more standard-compliant, and absolutely none of that mattered. No, Firefox really got a foothold because it had tabs. IE 6 did not have tabs; if you wanted to open a second webpage, you opened another window. It fucking sucked, man. Firefox was a miracle. Firefox wasn’t the first tabbed browser, of course; the full Mozilla Suite’s browser had them, and the obscure (but scrappy!) Opera had had them for ages. But it was Firefox that took off, for various reasons, not least of which was that it didn’t have a giant fucking ad bar at the top like Opera did. Designers did push for Firefox on standards grounds, of course; it’s just that that angle primarily appealed to other designers, not so much to their parents. One of the most popular and spectacular demonstrations was the Acid2 test, intended to test a variety of features of then-modern Web standards. It had the advantage of producing a cute smiley face when rendered correctly, and a fucking nightmare hellscape in IE 6. Early Firefox wasn’t perfect, but it was certainly much closer, and you could see it make progress until it fully passed with the release of Firefox 3. It also helped that Firefox had a faster JavaScript engine, even before JIT caught on. Much, much faster. Like, as I recall, IE 6 implemented getElementById by iterating over the entire document, even though IDs are unique. Glance at some old jQuery release announcements; they usually have some performance charts, and everything else absolutely dwarfs IE 6 through 8. Oh, and there was that whole thing where IE 6 was a giant walking security hole, especially with its native support for arbitrary binary components that only needed a “yes” click on an arcane dialog to get full and unrestricted access to your system. Probably didn’t help its reputation. Anyway, with something other than IE taking over serious market share, even the most ornery designers couldn’t just target IE 6 and call it a day any more. Now there was a reason to use strict mode, a reason to care about compatibility and standards — which Firefox was making a constant effort to follow better, while IE 6 remained stagnant. (I’d argue that this effect opened the door for OS X to make some inroads, and also for the iPhone to exist at all. I’m not kidding! Think about it; if the iPhone browser hadn’t actually worked with anything because everyone was still targeting IE 6, it’d basically have been a more expensive Palm. Remember, at first Apple didn’t even want native apps; it bet on the Web.) (Speaking of which, Safari was released in Jan ‘03, based on a fork of the KHTML engine used in KDE’s Konqueror browser. I think I was using KDE at the time, so this was very exciting, but no one else really cared about OS X and its 2% market share.) Another major factor appeared on April Fools’ Day, 2004, when Google announced Gmail. Ha, ha! A funny joke. Webmail that isn’t terrible? That’s a good one, Google. Oh. Oh, fuck. Oh they’re not kidding. How the fuck does this even work The answer, as every web dev now knows, is XMLHttpRequest — named for the fact that nobody has ever once used it to request XML. Apparently it was invented by Microsoft for use with Exchange, then cloned early on by Mozilla, but I’m just reading this from Wikipedia and you can do that yourself. The important thing is, it lets you make an HTTP request from JavaScript. You could now update only part a page with new data, completely in the background, without reloading. Nobody had heard of this thing before, so when Google dropped an entire email client based on it, it was like fucking magic. Arguably the whole thing was a mistake and has led to a hell future where static pages load three paragraphs of text in the background using XHR for no goddamn reason, but that’s a different post. Along similar lines, August 2006 saw the release of jQuery, a similar miracle. Not only did it paper over the differences between IE’s “JScript” APIs and the standard approaches taken by everyone else (which had been done before by other libraries), but it made it very easy to work with whole groups of elements at a time, something that had historically been a huge pain in the ass. Now you could fairly easily apply CSS all over the place from JavaScript! Which is a bad idea! But everything was so bad that we did it anyway! Hold on, I hear you cry. These things are about JavaScript! Isn’t this a post about CSS? You’re absolutely right! I mention the rise of JavaScript because I think it led directly to the modern state of CSS, thanks to an increase in one big factor: Ambition Firefox showed us that we could have browsers that actually, like, improve — every new improvement on Acid2 was exciting. Gmail showed us that the Web could do more than show plain text with snowflakes in front. And folks started itching to get fancy. The problem was, browsers hadn’t really gotten any better yet. Firefox was faster in some respects, and it adhered more closely to the CSS spec, but it didn’t fundamentally do anything that browsers weren’t supposed to be able to do already. Only the tooling had improved, and that mostly affected JavaScript. CSS was a static language, so you couldn’t write a library to make it better. Generating CSS with JavaScript was a possibility, but boy oh boy is that ever a bad idea. Another problem was that CSS 2 was only really good at styling rectangles. That was fine in the 90s, when every OS had the aesthetic of rectangles containing more rectangles. But now we were in the days of Windows XP and OS X, where everything was shiny and glossy and made of curvy plastic. It was a little embarrassing to have rounded corners and neatly shaded swooshes in your file browser and nowhere on the Web. Thus began a new reign of darkness. The era of CSS hacks Designers wanted a lot of things that CSS just could not offer. Round corners were a big one. Square corners had fallen out of vogue, and now everyone wanted buttons with round corners, since they were The Future. (Native buttons also went out of vogue, for some reason.) Alas, CSS had no way to do this. Your options were: Make a fixed-size background image of a rounded rectangle and put it on a fixed-size button. Maybe drop the text altogether and just make the whole thing an image. Eugh. Make a generic background image and scale it to fit. More clever, but the corners might end up not round. Make the rounded rectangle, cut out the corner and edges, and put them in a 3×3 table with the button label in the middle. Even better, use JavaScript to do this on the fly. Fuck it, make your entire website one big Flash app lol Another problem was that IE 6 didn’t understand PNGs with 8-bit alpha; it could only correctly display PNGs with 1-bit alpha, i.e. every pixel is either fully opaque or fully transparent, like GIFs. You had to settle for jagged edges, bake a solid background color into the image, or apply various fixes that centered around this fucking garbage nonsense: 1 filter: progid:DXImageTransform.Microsoft.AlphaImageLoader(src='bite-my-ass.png'); Along similar lines: gradients and drop shadows! You can’t have fancy plastic buttons without those. But here you were basically stuck with making images again. Translucency was a bit of a mess. Most browsers supported the CSS 3 opacity property since very early on… except IE, which needed another wacky Microsoft-specific filter thing. And if you wanted only the background translucent, you’d need a translucent PNG, which… well, you know. Since the beginning, jQuery shipped with built-in animated effects like fadeIn, and they started popping up all over the place. It was kind of like the Web equivalent of how every Linux user in the mid-00s (and I include myself in this) used that fucking Compiz cube effect. Obviously you need JavaScript to trigger an element’s disappearance in most interesting cases, but using it to control the actual animation was a bit heavy-handed and put a strain on browsers. Tabbed browsing compounded this, since browsers were largely single-threaded, and for various reasons, every open page ran in the same thread. Oh! Alternating background colors on table rows. This has since gone out of style, but I think that’s a shame, because man did it make tables easier to read. But CSS had no answer for this, so you had to either give every other row a class like(hope the table’s generated with code!) or do some jQuery nonsense. CSS 2 introduced the > child selector, so you could write stuff like ul.foo > li to style special lists without messing up nested lists, and IE 6! Didn’t! Fucking! Support! It! All those are merely aesthetic concerns, though. If you were interested in layout, well, the rise of Firefox had made your life at once much easier and much harder. Remember inline-block? Firefox 2 actually supported it! It was buggy and hidden behind a vendor prefix, but it more or less worked, which let designers start playing with it. And then Firefox 3 supported it more or less fully, which felt miraculous. Version 3 of our thumbnail grid is as simple as a width and inline-block: 1 2 3 4 5 6 .thumbnails li { display: inline-block; width: 250px; margin: 0.5em; vertical-align: top; } The general idea of inline-block is that the inside acts like a block, but the block itself is placed in regular flowing text, like an image. Each thumbnail is thus contained in a box, but the boxes all lie next to each other, and because of their equal widths, they flow into a grid. And since it’s functionally a line of text, you don’t have to work around any weird impact on the rest of the page like you had to do with floats. Sure, this had some drawbacks. You couldn’t do anything with the leftover space, for example, so there was a risk of a big empty void on the right with pathological screen sizes. You still had the problem of breaking the grid with a wide cell. But at least it’s not floats. One teeny problem: IE 6. It did technically support inline-block, but only on elements that were naturally inline — ones likeand , not . So, not ones you’d actually want (or think) to use inline-block on. Sigh. Lucky for us, at some point an absolute genius discovered hasLayout, an internal optimization in IE that marks whether an element… uh… has… layout. Look, I don’t know. Basically it changes the rendering path for an element — making it differently buggy, like quirks mode on a per-element basis! The upshot is that the above works in IE 6 if you add a couple lines: 1 2 3 4 5 6 7 8 .thumbnails li { display: inline-block; width: 250px; margin: 0.5em; vertical-align: top; *zoom: 1; *display: inline; } The leading asterisks make the property invalid, so browsers should ignore the whole line… but for some reason I cannot begin to fathom, IE 6 ignores the asterisks and accepts the rest of the rule. (Almost any punctuation worked, including a hyphen or — my personal favorite — an underscore.) The zoom property is a Microsoft extension that scales stuff, with the side effect that it grants the mystical property of “layout” to the element as well. And display: inline should make each element spill its contents into one big line of text, but IE treats an inline element that has “layout” roughly like an inline-block. And here we saw the true potential of CSS messes. Browser-specific rules, with deliberate bad syntax that one browser would ignore, to replicate an effect that still isn’t clearly described by what you’re writing. Entire tutorials written to explain how to accomplish something simple, like a grid, but have it actually work on most people’s browsers. You’d also see * html, html > /**/ body, and all kinds of other nonsense. Here’s a full list! And remember that “clearfix” hack from before? The full version, compatible with every browser, is a bit worse: 1 2 3 4 5 6 7 8 9 10 11 12 13 .clearfix:after { visibility: hidden; display: block; font-size: 0; content: \" \"; clear: both; height: 0; } .clearfix { display: inline-block; } /* start commented backslash hack \\*/ * html .clearfix { height: 1%; } .clearfix { display: block; } /* close commented backslash hack */ Is it any wonder folks started groaning about CSS? This was an era of blind copy/pasting in the frustrated hopes of making the damn thing work. Case in point: someone (I dug the original source up once but can’t find it now) had the bone-headed idea of always setting body { font-size: 62.5% } due to a combination of “relative units are good” and wanting to override the seemingly massive default browser font size of 16px (which, it turns out, is correct) and dealing with IE bugs. He walked it back a short time later, but the damage had been done, and now thousands of websites start off that way as a “best practice”. Which means if you want to change your browser’s default font size in either direction, you’re screwed — scale it down and a bunch of the Web becomes microscopic, scale it up and everything will still be much smaller than you’ve asked for, scale it up more to compensate and everything that actually respects your decision will be ginormous. At least we have better page zoom now, I guess. Oh, and do remember: Stack Overflow didn’t exist yet. This stuff was passed around purely by word of mouth. If you were lucky, you knew about some of the websites about websites, like quirks mode and Eric Meyer’s website. In fact, check out Meyer’s css/edge site for some wild examples of stuff folks were doing, even with just CSS 1, as far back as 2002. I still think complexspiral is pure genius, even though you could do it nowadays with opacity and just one image. The approach in raggedfloat wouldn’t get native support in CSS until a few years ago, with shape-outside! He also brought us CSS reset, eliminating differences between browsers’ default styles. (I cannot understate how much of a CSS pioneer Eric Meyer is. When his young daughter Rebecca died six years ago, she was uniquely immortalized with her own CSS color name, rebeccapurple. That’s how highly the Web community thinks of him. Also I have to go cry a bit over that story now.) The future arrives, gradually Designers and developers were pushing the bounds of what browsers were capable of. Browsers were handling it all somewhat poorly. All the fixes and workarounds and libraries were arcane, brittle, error-prone, and/or heavy. Clearly, browsers needed some new functionality. But just slopping something in wouldn’t help; Microsoft had done plenty of that, and it had mostly made a mess. Several struggling attempts began. With the W3C’s head still squarely up its own ass — even explicitly rejecting proposed enhancements to HTML, in favor of snorting XML — some folks from (active) browser vendors Apple, Mozilla, and Opera decided to make their own clubhouse. WHATWG came into existence in June 2004, and they began work on HTML5. (It would end up defining error-handling very explicitly, which completely obviated the need for XHTML and eliminated a number of security concerns when working with arbitrary HTML. Also it gave us some new goodies, like native audio, video, and form controls for dates and colors and other stuff that had been clumsily handled by JavaScript-powered custom controls. And, um, still often are.) Then there was CSS 3. I’m not sure when it started to exist. It emerged slowly, struggling, like a chick hatching from an egg and taking its damn sweet fucking time to actually get implemented anywhere. I’m having to do a lot of educated guessing here, but I think it began with border-radius. Specifically, with -moz-border-radius. I don’t know when it was first introduced, but the Mozilla bug tracker has mentions of it as far back as 1999. See, Firefox’s own UI is rendered with CSS. If Mozilla wanted to do something that couldn’t be done with CSS, they added a property of their own, prefixed with -moz- to indicate it was their own invention. And when there’s no real harm in doing so, they leave the property accessible to websites as well. My guess, then, is that the push for CSS 3 really began when Firefox took off and designers discovered -moz-border-radius. Suddenly, built-in rounded corners were available! No more fucking around in Photoshop; you only needed to write a single line! Practically overnight, everything everywhere had its corners filed down. And from there, things snowballed. Common problems were addressed one at a time by new CSS features, which were clustered together into a new CSS version: CSS 3. The big ones were solutions to the design problems mentioned before: Rounded corners, provided by border-radius. Gradients, provided by linear-gradient() and friends. Multiple backgrounds, which weren’t exactly a pressing concern, but which turned out to make some other stuff easier. Translucency, provided by opacity and colors with an alpha channel. Box shadows. Text shadows, which had been in CSS 2 but dropped in 2.1 and never implemented anyway. Border images, so you could do even fancier things than mere rounded borders. Transitions and animations, now doable with ease without needing jQuery (or any JS at all). :nth-child(), which solved the alternating rows problem with pure CSS. Transformations. Wait, what? This kinda leaked in from SVG, which browsers were also being expected to implement, and which is built heavily around transforms. The code was already there, so, hey, now we can rotate stuff with CSS! Couldn’t do that before. Cool. Web fonts, which had been in CSS for some time but only ever implemented in IE and only with some goofy DRM-laden font format. Now we weren’t limited to the four bad fonts that ship with Windows and that no one else has! These were pretty great! They didn’t solve any layout problems, but they did address aesthetic issues that designers had been clumsily working around by using loads of images and/or JavaScript. That meant less stuff to download and more text used instead of images, both of which were pretty good for the Web. The grand irony is that all the stuff you could do with these features went out of style almost immediately, and now we’re back to flat rectangles again. Browser prefixing hell Alas! All was still not right with the world. Several of these new gizmos were, I believe, initially developed by browser vendors and prefixed. Some later ones were designed by the CSS committee but implemented by browsers while the design was still in flux, and thus also prefixed. So began prefix hell, which continues to this day. Mozilla had -moz-border-radius, so when Safari implemented it, it was named -webkit-border-radius (“WebKit” being the name of Apple’s KHTML fork). Then the CSS 3 spec standardized it and called it just border-radius. That meant that if you wanted to use rounded borders, you actually needed to give three rules: 1 2 3 4 5 element { -moz-border-radius: 1em; -webkit-border-radius: 1em; border-radius: 1em; } The first two made the effect actually work in current browsers, and the last one was future-proofing: when browsers implemented the real rule and dropped the prefixed ones, it would take over. You had to do this every fucking time, since CSS isn’t a programming language and has no macros or functions or the like. Sometimes Opera and IE would have their own implementations with -o- and -ms- prefixes, bringing the total to five copies. It got much worse with gradients; the syntax went through a number of major incompatible revisions, so you couldn’t even rely on copy/pasting and changing the property name! And plenty of folks, well, fucked it up. I can’t blame them too much; I mean, this sucks. But enough pages used only the prefixed forms, and not the final form, that browsers had to keep supporting the prefixed form for longer than they would’ve liked to avoid breaking stuff. And if the prefixed form still works and it’s what you’re used to writing, then maybe you still won’t bother with the unprefixed one. Worse, some people would only use the form that worked in their pet choice of browser. This got especially bad with the rise of mobile web browsers. The built-in browsers on iOS and Android are Safari (WebKit) and Chrome (originally WebKit, now a fork), so you only “needed” to use the -webkit- properties. Which made things difficult for Mozilla when it released Firefox for Android. Hey, remember that whole debacle with IE 6? Here we are again! It was bad enough that Mozilla eventually decided to implement a number of -webkit- properties, which remain supported even in desktop Firefox to this day. The situation is goofy enough that Firefox now supports some effects only via these properties, like -webkit-text-stroke, which isn’t being standardized. Even better, Chrome’s current forked engine is called Blink, so technically it shouldn’t be using -webkit- properties either. And yet, here we are. At least it’s not as bad as the user agent string mess. Browser vendors have pretty much abandoned prefixing, now; instead they hide experimental features behind flags (so they’ll only work on the developer’s machine), and new features are theoretically designed to be smaller and easier to stabilize. This mess was probably a huge motivating factor for the development of Sass and LESS, two languages that produce CSS. Or… two CSS preprocessors, maybe. They have very similar goals: both add variables, functions, and some form of macros to CSS, allowing you to eliminate a lot of the repetition and browser hacks and other nonsense from your stylesheets. Hell, this blog still uses SCSS, though its use has gradually decreased over time. Flexbox But then, like an angel descending from heaven… flexbox. Flexbox has been around for a long time — allegedly it had partial support in Firefox 2, back in 2006! It went through several incompatible revisions and took ages to stabilize. Then IE took ages to implement it, and you don’t really want to rely on layout tools that only work for half your audience. It’s only relatively recently (2015? Later?) that flexbox has had sufficiently broad support to use safely. And I could swear I still run into folks whose current Safari doesn’t recognize it at all without prefixing, even though Safari supposedly dropped the prefixes five years ago… Anyway, flexbox is a CSS implementation of a pretty common GUI layout tool: you have a parent with some children, and the parent has some amount of space available, and it gets divided automatically between the children. You know, it puts things next to each other. The general idea is that the browser computes how much space the parent has available and the “initial size” of each child, figures out how much extra space there is, and distributes it according to the flexibleness of each child. Think of a toolbar: you might want each button to have a fixed size (a flex of 0), but want to add spacers that share any leftover space equally, so you’d give them a flex of 1. Once that’s done, you have a number of quality-of-life options at your disposal, too: you can distribute the extra space between the children instead, you can tell the children to stretch to the same height or align them in various ways, and you can even have them wrap into multiple rows if they won’t all fit! With this, we can take yet another crack at that thumbnail grid: 1 2 3 4 5 6 7 .thumbnail-grid { display: flex; flex-wrap: wrap; } .thumbnail-grid li { flex: 1 0 250px; } This is miraculous. I forgot all about inline-block overnight and mostly salivated over this until it was universally supported. It even expresses very clearly what I want. …almost. It still has the problem that too-wide cells will break the grid, since it’s still a horizontal row wrapped onto several independent lines. It’s pretty damn cool, though, and solves a number of other layout problems. Surely this is good enough. Unless…? I’d say mass adoption of flexbox marked the beginning of the modern era of CSS. But there was one lingering problem… The slow, agonizing death of IE IE 6 took a long, long, long time to go away. It didn’t drop below 10% market share (still a huge chunk) until early 2010 or so. Firefox hit 1.0 at the end of 2004. IE 7 wasn’t released until two years later, it offered only modest improvements, it suffered from compatibility problems with stuff built for IE 6, and the IE 6 holdouts (many of whom were not Computer People) generally saw no reason to upgrade. Vista shipped with IE 7, but Vista was kind of a flop — I don’t believe it ever came close to overtaking XP, not in its entire lifetime. Other factors included corporate IT policies, which often take the form of “never upgrade anything ever” — and often for good reason, as I heard endless tales of internal apps that only worked in IE 6 for all manner of horrifying reasons. Then there was the entirety of South Korea, which was legally required to use IE 6 because they’d enshrined in law some security requirements that could only be implemented with an IE 6 ActiveX control. So if you maintained a website that was used — or worse, required — by people who worked for businesses or lived in other countries, you were pretty much stuck supporting IE 6. Folks making little personal tools and websites abandoned IE 6 compatibility early on and plastered their sites with increasingly obnoxious banners taunting anyone who dared show up using it… but if you were someone’s boss, why would you tell them it’s okay to drop 20% of your potential audience? Just work harder! The tension grew over the years, as CSS became more capable and IE 6 remained an anchor. It still didn’t even understand PNG alpha without workarounds, and meanwhile we were starting to get more critical features like native video in HTML5. The workarounds grew messier, and the list of features you basically just couldn’t use grew longer. (I’d show you what my blog looks like in IE 6, but I don’t think it can even connect — the TLS stuff it supports is so ancient and broken that it’s been disabled on most servers!) Shoutouts, by the way, to some folks on the YouTube team, who in July 2009 added a warning banner imploring IE 6 users to switch to anything else — without asking anyone for approval. “Within one month… over 10 percent of global IE6 traffic had dropped off.” Not all heroes wear capes. I’d mark the beginning of the end as the day YouTube actually dropped IE 6 support — March 13, 2010, almost nine years after its release. I don’t know how much of a direct impact YouTube has on corporate users or the South Korean government, but a massive web company dropping an entire browser sends a pretty strong message. There were other versions of IE, of course, and many of them were messy headaches in their own right. But each subsequent one became less of a pain, and nowadays you don’t even have to think too much about testing in IE (now Edge). Just in time for Microsoft to scrap their own rendering engine and turn their browser into a Chrome clone. Now CSS is pretty great now. You don’t need weird fucking hacks just to put things next to each other. Browser dev tools are built in, now, and are fucking amazing — Firefox has started specifically warning you when some CSS properties won’t take effect because of the values of others! Obscure implicit side effects like “stacking contexts” (whatever those are) can now be set explicitly, with properties like isolation: isolate. In fact, let me just list everything that I can think of that you can do in CSS now. This isn’t a guide to all possible uses of styling, but if your CSS knowledge hasn’t been updated since 2008, I hope this whets your appetite. And this stuff is just CSS! So many things that used to be impossible or painful or require clumsy plugins are now natively supported — audio, video, custom drawing, 3D rendering… not to mention the vast ergonomic improvements to JavaScript. Layout A grid container can do pretty much anything tables can do, and more, including automatically determining how many columns will fit. It’s fucking amazing. More on that below. A flexbox container lays out its children in a row or column, allowing each child to declare its “default” size and what proportion of leftover space it wants to consume. Flexboxes can wrap, rearrange children without changing source order, and align children in a number of ways. Columns will pour text into, well, multiple columns. The box-sizing property lets you opt into the IE box model on a per-element basis, for when you need an entire element to take up a fixed amount of space and need padding/borders to subtract from that. display: contents dumps an element’s contents out into its parent, as if it weren’t there at all. display: flow-root is basically an automatic clearfix, only a decade too late. width can now be set to min-content, max-content, or the fit-content() function for more flexible behavior. white-space: pre-wrap preserves whitespace, but breaks lines where necessary to avoid overflow. Also useful is pre-line, which collapses sequences of spaces down to a single space, but preserves literal newlines. text-overflow cuts off overflowing text with an ellipsis (or custom character) when it would overflow, rather than simply truncating it. Also specced is the ability to fade out the text, but this is as yet unimplemented. shape-outside alters the shape used when wrapping text around a float. It can even use the alpha channel of an image as the shape. resize gives an arbitrary element a resize handle (as long as it has overflow). writing-mode sets the direction that text flows. If your design needs to work for multiple writing modes, a number of CSS properties that mention left/right/top/bottom have alternatives that describe directions in terms of the writing mode: inset-block and inset-inline for position, block-size and inline-size for width/height, border-block and border-inline for borders, and similar for padding and margins. Aesthetics Transitions smoothly interpolate a value whenever it changes, whether due to an effect like :hover or e.g. a class being added from JavaScript. Animations are similar, but play a predefined animation automatically. Both can use a number of different easing functions. border-radius rounds off the corners of a box. The corners can all be different sizes, and can be circular or elliptical. The curve also applies to the border, background, and any box shadows. Box shadows can be used for the obvious effect of casting a drop shadow. You can also use multiple shadows and inset shadows for a variety of clever effects. text-shadow does what it says on the tin, though you can also stack several of them for a rough approximation of a text outline. transform lets you apply an arbitrary matrix transformation to an element — that is, you can scale, rotate, skew, translate, and/or do perspective transform, all without affecting layout. filter (distinct from the IE 6 one) offers a handful of specific visual filters you can apply to an element. Most of them affect color, but there’s also a blur() and a drop-shadow() (which, unlike box-shadow, applies to an element’s appearance rather than its containing box). linear-gradient(), radial-gradient(), the new and less-supported conic-gradient(), and their repeating-* variants all produce gradient images and can be used anywhere in CSS that an image is expected, most commonly as a background-image. scrollbar-color changes the scrollbar color, with the downside of reducing the scrollbar to a very simple thumb-and-track in current browsers. background-size: cover and contain will scale a background image proportionally, either big enough to completely cover the element (even if cropped) or small enough to exactly fit inside it (even if it doesn’t cover the entire background). object-fit is a similar idea but for non-background media, like s. The related object-position is like background-position. Multiple backgrounds are possible, which is especially useful with gradients — you can stack multiple gradients, other background images, and a solid color on the bottom. text-decoration is fancier than it used to be; you can now set the color of the line and use several different kinds of lines, including dashed, dotted, and wavy. CSS counters can be used to number arbitrary elements in an arbitrary way, exposing the counting ability ofto any set of elements you want. The ::marker pseudo-element allows you to style a list item’s marker box, or even replace it outright with a custom counter. Browser support is spotty, but improving. Similarly, the @counter-style at-rule implements an entirely new counter style (like 1 2 3, i ii iii, A B C, etc.) which you can then use anywhere, though only Firefox supports it so far. image-set() provides a list of candidate images and lets the browser choose the most appropriate one based on the pixel density of the user’s screen. @font-face defines a font that can be downloaded, though you can avoid figuring out how to use it correctly by using Google Fonts. pointer-events: none makes an element ignore the mouse entirely; it can’t be hovered, and clicks will go straight through it to the element below. image-rendering can force an image to be resized nearest-neighbor rather than interpolated, though browser support is still spotty and you may need to also include some vendor-specific properties. clip-path crops an element to an arbitrary shape. There’s also mask for arbitrary alpha masking, but browser support is spotty and hoo boy is this one complicated. Syntax and misc @supports lets you explicitly write different CSS depending on what the browser supports, though it’s nowhere near as useful nowadays as it would’ve been in 2004. A > B selects immediate children. A ~ B selects siblings. A + B selects immediate (element) siblings. Square brackets can do a bunch of stuff to select based on attributes; most obvious is input[type=checkbox], though you can also do interesting things with matching parts of . There are a whole bunch of pseudo-classes now. Many of them are for form elements: :enabled and :disabled; :checked and :indeterminate (also apply to radio and ); :required and :optional; :read-write and :read-only; :in-range/:out-of-range and :valid/:invalid (for use with HTML5 client-side form validation); :focus and :focus-within; and :default (which selects the default form button and any pre-selected checkboxes, radio buttons, and s). For targeting specific elements within a set of siblings, we have: :first-child, :last-child, and :only-child; :first-of-type, :last-of-type, and :only-of-type (where “type” means tag name); and :nth-child(), :nth-last-child(), :nth-of-type(), and :nth-last-of-type() (to select every second, third, etc. element). :not() inverts a selector. :empty selects elements with no children and no text. :target selects the element jumped to with a URL fragment (e.g. if the address bar shows index.html#foo, this selects the element whose ID is foo). ::before and ::after should have two colons now, to indicate that they create pseudo-elements rather than merely scoping the selector they’re attached to. ::selection customizes how selected text appears; ::placeholder customizes how placeholder text (in text fields) appears. Media queries do just a whole bunch of stuff so your page can adapt based on how it’s being viewed. The prefers-color-scheme media query tells you if the user’s system is set to a light or dark theme, so you can adjust accordingly without having to ask. You can write translucent colors as #rrggbbaa or #rgba, as well as using the rgba() and hsla() functions. Angles can be described as fractions of a full circle with the turn unit. Of course, deg and rad (and grad) are also available. CSS variables (officially, “custom properties”) let you specify arbitrary named values that can be used anywhere a value would appear. You can use this to reduce the amount of CSS fiddling needs doing in JavaScript (e.g., recolor a complex part of a page by setting a CSS variable instead of manually adjusting a number of properties), or have a generic component that reacts to variables set by an ancestor. calc() computes an arbitrary expression and updates automatically (though it’s somewhat obviated by box-sizing). The vw, vh, vmin, and vmax units let you specify lengths as a fraction of the viewport’s width or height, or whichever of the two is bigger/smaller. Phew! I’m sure I’m forgetting plenty and folks will have even longer lists of interesting tidbits in the comments. Thanks for saving me some effort! Now I can stop browsing MDN and do this final fun part. State of the art thumbnail grid At long last, we arrive at the final and objectively correct way to construct a thumbnail grid: using CSS grid. You can tell this is the right thing to use because it has “grid” in the name. Modern CSS features are pretty great about letting you say the thing you want and having it happen, rather than trying to coax it into happening implicitly via voodoo. And it is oh so simple: 1 2 3 4 .thumbnail-grid { display: grid; grid: auto-flow / repeat(auto-fit, minmax(250px, 1fr)); } Done! That gives you a grid. You have myriad other twiddles to play with, just as with flexbox, but that’s the basic idea. You don’t even need to style the elements themselves; most of the layout work is done in the container. The grid shorthand property looks a little intimidating, but only because it’s so flexible. It’s saying: fill the grid one row at a time, generating as many rows as necessary; make as many 250px columns as will fit, and share any leftover space between them equally. CSS grids are also handy for laying out s, something that’s historically been a massive pain to make work — acontains any number of s followed by any number of s (including zero), and the only way to style this until grid was to float the s, which meant they had to have a fixed width. Now you can just tell the s to go in the first column and s to go in the second, and grid will take care of the rest. And laying out your page? That whole sidebar thing? Check out how easy that is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 body { display: grid; grid-template: \"header header header\" \"left-sidebar main-content right-sidebar\" \"footer footer footer\" / 1fr 6fr 1fr ; } body > header { grid-area: header; } #left-sidebar { grid-area: left-sidebar; } /* ... etc ... */ Done. Easy. It doesn’t matter what order the parts appear in the markup, either. On the other hand The web is still a little bit of a disaster. A lot of folks don’t even know that flexbox and grid are supported almost universally now; but given how long it took to get from early spec work to broad implementation, I can’t really blame them. I saw a brand new little site just yesterday that consisted mostly of a huge list of “thumbnails” of various widths, and it used floats! Not even inline-block! I don’t know how we managed to teach everyone about all the hacks required to make that work, but somehow haven’t gotten the word out about flexbox. But far worse than that: I still regularly encounter sites that do their entire page layout with JavaScript. If you use uMatrix, your first experience is with a pile of text overlapping a pile of other text. Surely this is a step backwards? What are you possibly doing that your header and sidebar can only be laid out correctly by executing code? It’s not like the page loads with no CSS — nothing in plain HTML will overlap by default! You have to tell it to do that! And then there’s the mobile web, which despite everyone’s good intentions, has kind of turned out to be a failure. The idea was that you could use CSS media queries to fit your normal site on a phone screen, but instead, most major sites have entirely separate mobile versions. Which means that either the mobile site is missing a bunch of important features and I’ll have to awkwardly navigate that on my phone anyway, or the desktop site is full of crap that nobody actually needs. (Meanwhile, Google’s own Android versions of Docs/Sheets/etc. have, like, 5% of the features of the Web versions? Not sure what to make of that.) Hmm. Strongly considering writing something that goes more into detail about improvements to CSS since the Firefox 3 era, similar to the one I wrote for JavaScript. But this post is long enough. Some futures that never were I don’t know what’s coming next in CSS, especially now that flexbox and grid have solved all our problems. I’m vaguely aware of some work being done on more extensive math support, and possibly some functions for altering colors like in Sass. There’s a painting API that lets you generate backgrounds on the fly with JavaScript using the canvas API, which is… quite something. Apparently it’s now in spec that you can use attr() (which evaluates to the value of an HTML attribute) as the value for any property, which seems cool and might even let you implement HTML tables entirely in CSS, but you could do the same thing with variables. I mean, um, custom properties. I’m more excited about :is(), which matches any of a list of selectors, and subgrid, which lets you add some nesting to a grid but keep grandchildren still aligned to it. Much easier is to list some things that were the future, but fizzled out. display: run-in has been part of CSS since version 2 (way back in ‘98), but it’s basically unsupported. The idea is that a “run-in” box is inserted, inline, into the next block, so this: 1 2 3 Title Paragraph Paragraph displays like this: Title Paragraph Paragraph And, ah, hm, I’m starting to see why it’s unsupported. It used to exist in WebKit, but was apparently so unworkable as to be removed six years ago. “Alternate stylesheets” were popular in the early 00s, at least on a few of my friends’ websites. The idea was that you could list more than one stylesheet for your site (presumably for different themes), and the browser would give the user a list of them. Alas, that list was always squirrelled away in a menu with no obvious indication of when it was actually populated, so in the end, everyone who wanted multiple themes just implemented an in-page theme switcher themselves. This feature is still supported, but apparently Chrome never bothered implementing it, so it’s effectively dead. More generally, the original CSS spec clearly expects users to be able to write their own CSS for a website — right in paragraph 2 it says …the reader may have a personal style sheet to adjust for human or technological handicaps. Hey, that sounds cool. But it never materialized as a browser feature. Firefox has userContent.css and some URL selectors for writing per-site rules, but that’s relatively obscure. Still, there’s clearly demand for the concept, as evidenced by the popularity of the Stylish extension — which does just this. (Too bad it was bought by some chucklefucks who started using it to suck up browser data to sell to advertisers. Use Stylus instead.) A common problem (well, for me) is that of styling the label for a checkbox, depending on its state. Styling the checkbox itself is easy enough with the :checked pseudo-selector. But if you arrange a checkbox and its label in the obvious way: 1Description of what this does …then CSS has no way to target either theelement or the text node. jQuery’s (originally custom) selector engine offered a custom :has() pseudo-class, which could be used to express this: 1 2 3 4 /* checkbox label turns bold when checked */ label:has(input:checked) { font-weight: bold; } Early CSS 3 selector discussions seemingly wanted to avoid this, I guess for performance reasons? The somewhat novel alternative was to write out the entire selector, but be able to alter which part of it the rules affected with a “subject” indicator. At first this was a pseudo-class: 1 2 3 label:subject input:checked { font-weight: bold; } Then later, they introduced a ! prefix instead: 1 2 3 !label input:checked { font-weight: bold; } Thankfully, this was decided to be a bad idea, so the current specced way to do this is… :has()! Unfortunately, it’s only allowed when querying from JavaScript, not in a live stylesheet, and nothing implements it anyway. 20 years and I’m still waiting for a way to style checkbox labels.was an attribute that would’ve made aelement’s CSS rules only apply to other elements within its immediate parent, meaning you could drop in arbitrary (possibly user-written) CSS without any risk of affecting the rest of the page. Alas, this was quietly dropped some time ago, with shadow DOM suggested as a wildly inappropriate replacement. I seem to recall that when I first heard about Web components, they were templates you could use to reduce duplication in pure HTML? But I can’t find any trace of that concept now, and the current implementations require JavaScript to define them, so there’s nothing declarative linking a new tag to its implementation. Which makes them completely unusable for anything that doesn’t have a compelling reason to rely on JS. Alas.and . RIP. Though both can be easily replicated with CSS animations. That's it You’re still here? It’s over. Go home. And maybe push back against Blink monoculture and use Firefox, including on your phone, unless for some reason you use an iPhone, which forbids other browser engines, which is far worse than anything Microsoft ever did, but we just kinda accept it for some reason. Posted by Eevee in blog Sat Feb 01, 2020 #tech",
    "commentLink": "https://news.ycombinator.com/item?id=40023892",
    "commentBody": "Old CSS, new CSS (2020) (eev.ee)141 points by Tomte 10 hours agohidepastfavorite48 comments sussmannbaka 3 hours agoFast forward a few years and > ... …every single goddamn time. is in fashion again! Only now it’s called class=\"text-red-500\" :o) reply mdhb 1 hour agoparentI do continue to find it weird how CSS is just relegated to this second class citizen when it comes to web development and huge numbers of folks seemingly have little to no interest in learning it beyond what they can copy and paste. That wouldn’t fly in any other language. reply LudwigNagasena 15 minutes agorootparentYou wouldn’t need 3 languages to build UI in any other language. reply mtsr 35 minutes agorootparentprevFor me a big part is that global CSS doesn’t match component based web applications as well. Coordinating global class names becomes a pain quickly. Then you move to scoped CSS and suddenly CSS doesn’t add much anymore. reply TiredOfLife 11 minutes agoparentprevYou are looking at the compiled output. reply josephg 8 hours agoprevI'm wondering if we'll ever see Houdini make its way into browsers. The idea is that instead of modern CSS, the browser provides a bunch of hooks for various parts of its layout engine. You can then provide custom code that uses those hooks to implement any layout system you want. CSS is big and complex, and it still needs to support the whole legacy of web applications going back forever. Most applications just use a tiny subset of CSS. Houdini could allow smaller, faster layout engines with none of the legacy stuff. And because your app ships its own layout engine, if there's a feature you want, you can just add it to the layout engine and it'll instantly work in every browser. I have no idea whats happened with it though. Now that flexbox, grid, sticky and a few other things are in all browsers, CSS feels good enough. But maybe I'm lacking imagination. https://developer.mozilla.org/en-US/docs/Web/API/Houdini_API... Oh, it looks like chrome and safari both already support a lot of Houdini: https://houdini.glitch.me/ reply nicoburns 6 hours agoparentThe one thing I'd really like for web layout is a \"stretch unit\" that works similarly to CSS Grid's fr units in that it would be defined as \"taking up a proportion of available space after other siblings have been sized\" except: - It would have no automatic minimum, so it would actually be equivalent to minmax(0, 1fr) (this would make it much more performant, avoiding the exponential time complexity of many existing CSS layout modes. - It could be used for the width/height properties (and potentially other places such as margin/padding/inset) If you had that along with a simplified 1-dimensional display mode (i.e. like flexbox except with the flexing disabled) then I think most people probably wouldn't want much more in most circumstances. Houdini is interesting, but as someone who has spent a lot of the last year implementing a web layout engine [0], I'm a little skeptical that JS is ever going to be fast enough to really compete with built-in layout modes. It could be an interesting use case for WASM if the problem of passing data into the WASM VM cheaply (perhaps by reference) can be solved. [0]: https://github.com/DioxusLabs/taffy reply josephg 4 hours agorootparent> It could be an interesting use case for WASM if the problem of passing data into the WASM VM cheaply (perhaps by reference) can be solved. WASM Reference Types should hopefully solve this. The WASM working group seems to have some good momentum - so I'm hopeful this (or a similar replacement spec) will land sooner rather than later. https://github.com/WebAssembly/reference-types/blob/master/p... reply junon 56 minutes agoparentprevI was told I was the first to try webassembly in Houdini resulting in the browser to crash. Filed a bug and it was closed for inactivity. It seems like nobody is working on this now. reply _heimdall 5 hours agoparentprevI honestly hope Houdini never makes it into a final spec. The demo use cases are interesting, but the last thing we need is more complexity in web development. Browsers today already act more like operating systems than document viewers. Houdini basically takes it a step further allowing every app to bring its own renderer. Linux leans heavily into this today and it makes mundane tasks like global theming a huge pain in the butt. reply josephg 4 hours agorootparent> the last thing we need is more complexity in web development. Thats one way to think about it. Another is that Houdini lets the browser be more simple - because CSS (as it exists today) can be moved into a reusable library that can be shared between browsers. In theory, if all the browsers supported houdini, they wouldn't need to maintain their own CSS implementations. reply pwdisswordfishc 2 hours agorootparentI can't wait for crypto miners in pure CSS ^W Houdini reply tapirl 4 hours agoparentprevHoudini needs JavaScript, which is a big obstacle for it to become popular. reply chilmers 26 minutes agorootparentWhy is it an obstacle? reply croes 4 hours agorootparentprevJQuery, React, Vue, Svelte etc. all need JavaScript and became popular. reply tapirl 3 hours agorootparentJQuery, React, Vue, Svelte etc indeed do some essential functionality things a few users need. Houdini is different. It is more about layout and styling. reply zilti 2 hours agoparentprevWe need DSSSL back. reply holoduke 2 hours agoparentprevYes only thing missing is full support of the web animation specs. For example scrolltimelines is missing in ios and firefox. That one is really needed to get similar performance in web app compared to native. reply p4bl0 4 hours agoprev> It [Firefox] was quick, it was simple, it was much more standard-compliant, and absolutely none of that mattered. > > No, Firefox really got a foothold because it had tabs. The article doesn't mention it but at this time, equally attractive along with tabs, was the pop-up blocker! Truly the first ad-blocker like thing. And it was awesome too :). reply dhosek 8 hours agoprevKind of reminds me of my thinking (back in 1995) that I wanted to write a browser that would have a menu option to show what the output would look like with different browsers (this was back before writing a browser was essentially writing an operating system). I remember some really awful attempts at styling before CSS, the worst beingitem text to change the size of the list bullets (which, of course, only worked on Netscape and broke rendering entirely on other browsers). reply kmoser 6 hours agoprev> Let’s say you wanted all your s to be red, across your entire site. You had to do this: ... …every single goddamn time. Hope you never decide to switch to blue! This was never a big problem for me because in those days I wrote Perl scripts to generate my pages. I just defined $h1_color = 'red' and ran the script to crank out the static HTML pages. Boss (me :) wants to change the color to blue? Just change 'red' to 'blue' and re-run the script. reply cqqxo4zV46cp 5 hours agoparentYour own, worse, CSS, that requires a build toolchain. You were ahead of your time! reply bmacho 1 hour agorootparentIt isn't easy: - to have no build toolchain - to work without javascript - to have single configuration points reply codegeek 5 hours agorootparentprevTo be fair, things like SASS and LESS have been out there for a while. Tailwind requires build in production. reply cuu508 4 hours agorootparentI think we're talking 1995-2000 here, not 2006 (when sass appeared), 2009 (when less appeared), or 2018 (when Tailwind appeared) reply dang 9 hours agoprevRelated: Old CSS, New CSS (2020) - https://news.ycombinator.com/item?id=29531941 - Dec 2021 (97 comments) Old CSS, New CSS - https://news.ycombinator.com/item?id=22215931 - Feb 2020 (244 comments) reply audiodude 8 hours agoprevI distinctly remember working at a company where I had to upload the new assets for our rounded buttons, which were a grid of 3x3 image elements. LOL clearfix. I also never really had to fight with IE 6 compatibility, but when I fought it, it fought back hard. Also explaining to designers why we can't do translucent backgrounds (also IE 6). reply Inviz 6 hours agoparentthere was a way to use package image in a non-standard way (iirc using Offsets in Photoshop) and use negative background position to emulate 3x3 grid image with less elements. Was an advanced technique. reply Brajeshwar 7 hours agoparentprevAh, Yes, the 3x3. Whenever this pops up, I remember a lot of fond memories of the early days of front-end development. I wrote about ours at https://brajeshwar.com/2005/splice9-bitmap-window-resizer-co... I remember “feathering” the curves in Photoshop for a smoother finish to the rounded corners. My team, especially the new ones, would go -- heck, the trick, the trick, we learn a trick. ;-) The struggles were real, and the fun was short and intermittent but worth every moment. reply uxcolumbo 4 hours agorootparentGood ol’ times. A list apart, yayhooray, … and your articles helped me learn web design. reply JimDabell 1 hour agoprev> A year and a half later, in mid ‘98, we were gifted CSS 2. (I love the background on this page, by the way.) This was a modest upgrade that addressed a few deficiencies in various areas, but most interesting was the addition of a couple positioning primitives: the position property, which let you place elements at precise coordinates, and the inline-block display mode, which let you stick an element in a line of text like you could do with images. inline-block was actually introduced in CSS 2.1, which came a few years after CSS 2. reply huksley 3 hours agoprevAwesome read! And yes, :has() is supported now by all major browsers. https://developer.mozilla.org/en-US/docs/Web/CSS/:has reply Dalewyn 3 hours agoparentKeeping in mind that \"all\" major browsers is Chrome, Chrome, Chrome, Chrome, Firefox, Chrome, Chrome, Safari, and Chrome. reply blackoil 7 hours agoprevInterestingly, both IE and NN had `box-sizing: border-box;` as default behaviour, and at least for me that was sensible behavior. Probably a better decision at that point would have been to update spec and add a quirks mode other way around. reply JimDabell 1 hour agoparentborder-box was the original behaviour in an early draft of the specification, but it was changed to content-box before final publication. Browsers that jumped the gun and released with draft behaviour got it wrong. And it wasn’t default behaviour so much as the only behaviour – the box-sizing property that allowed web developers to control this came a long time afterwards. reply lovegrenoble 8 hours agoprevI'm using \"display:flex\" on almost everything, and as you said, flexbox is suitable for almost every situation. Also, for anyone struggling with flexbox - I use this tool to streamline the process: https://flexboxcss.com reply o11c 7 hours agoparentI only dabble in HTML, but for the kinds of layout I find myself doing, grid comes up more than flex does. Subgrid is needed for some tasks, but poorly supported still. Container queries are a less-limited alternative to media queries. When writing custom rules for other people's websites (using the Stylus extension), elem[attr=value] and variants (^=, etc) are very useful. :has() is useful for styling the parent of the actual element with the attributes but not in all browsers yet. Last I checked it is still not possible in the wild to implement fully automatic dark-mode (etc.) theming (using HSL) even though colorspaces are in the spec for the relevant functions. reply lelanthran 2 hours agorootparent> I only dabble in HTML, but for the kinds of layout I find myself doing, grid comes up more than flex does. It depends on whether the content is fixed to desktop monitors or responsive to mobile screens. Grid doesn't give the same responsiveness flexibility when the page is displayed on mobile. In my experiments with grid vs flexbox, every single time I used grid, I had to switch over to flexbox the minute I needed the content to display on mobile screens. My usage of grid turned out to be simply a different form of tables, which don't work well (or at all) on mobile screens. reply kmoser 6 hours agoparentprevI prefer this one since it shows you the resulting HTML/CSS markup, and lets you change the number of flex items: https://flexbox.tech/ reply divbzero 3 hours agoprevDoes anyone know the history of the Space Jam website? I’m curious who created it and which blessed souls have kept it up for so long. (May its existence never be relegated to the Wayback Machine…) reply hnatiukr 4 hours agoprev> Oh, and everyone wrote HTML tags in all caps. I don’t remember why we all thought that was a good idea. Maybe this was before syntax highlighting in text editors was very common (read: I was 12 and using Notepad), and uppercase tags were easier to distinguish from body text. The use of uppercase HTML tags in the early days wasn't primarily due to memory concerns. It was more about readability and consistency. As HTML evolved, lowercase tags became the standard for better readability and compatibility with XML. Another point that in the early days of computing, memory was a precious resource, and every byte mattered. Some developers believed that using uppercase characters could save memory because uppercase letters have simpler representations in ASCII, occupying fewer bits. However, this difference was extremely marginal and hardly made a noticeable impact on memory usage. reply bazoom42 3 hours agoparentWhat? Upppercase and lowercase occupy the same amount of bits. ASCII uses 7 bits for all characters (although in practice 8 bits). reply fallous 2 hours agorootparentIn the early days of computing ASCII was not universally used and often character spaces were less than 8 bits and lacked lower-case, or were mixed charsets like PETSCII that had upper-case letters and the extra charspace were filled with graphics. For a text-only system you could store the doc with 6 bit chars since you could ignore the upper charspace populated with graphics. reply 4ndrewl 3 hours agoprevThank you for this. I had totally forgotten about \"web safe colors\"! reply chris_wot 1 hour agoprevIn the comments the guy who invented quirks mode actually explains its history! Someone update Wikipedia, please… I cannot. reply ramesh31 4 hours agoprevGod bless CSS. I mean just look at the alternatives. There's really nothing else in existence with such power and flexibility. Any time I spend in native land it's always a feeling of pure freedom and enjoyment coming back to the web platform. reply mdhb 58 minutes agoparentFlutter is a nice alternative I found in that a lot of thought really went into how to design a UI framework from the ground up using everything we now have learned over the years about what works, what is important and without having to worry about backwards compatibility but could take a greenfield approach. With that one exception I otherwise agree, CSS especially in 2024 is actually very nice to use for the most part. reply tunesmith 5 hours agoprev [–] > Generating CSS with JavaScript was a possibility, but boy oh boy is that ever a bad idea. lol. As a backend developer that pretends to be full-stack, I enjoyed the hell out of reading this. CSS is such a mosh pit that it's just about impossible to find a summary of why things developed as they did. Plus I feel curiously reinforced about the times I've come at this with fresh backendy ideas, asking frontend devs \"uh, why are we doing it this way?\" and they only make strangled noises in response. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text explores the evolution of web design from HTML tables to modern CSS layout techniques, focusing on challenges and advancements.",
      "It discusses the dominance of Internet Explorer 6, the emergence of Firefox and Safari, and the development of new CSS properties such as Flexbox and Grid.",
      "Emphasizes the importance of keeping up with modern web design practices, including browser compatibility, for creating responsive and visually appealing websites."
    ],
    "commentSummary": [
      "The discussion centers on the evolution of CSS in 2020, with users seeking increased innovation and control over web layout.",
      "Topics cover the potential influence of Houdini on web development, proposed enhancements for CSS Grid, global CSS constraints, advantages of component-based web apps, historical challenges in web design, and the value of different CSS functionalities.",
      "Additionally, browser compatibility issues, advanced CSS selector usage, early computing memory consumption, web-safe color considerations, and frontend development intricacies are highlighted."
    ],
    "points": 141,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1713023286
  },
  {
    "id": 40029283,
    "title": "Challenges of Selling Developer Tools: Devs' Lack of Purchasing Power",
    "originLink": "https://twitter.com/d_feldman/status/1779203622351339955",
    "originBody": "The problem with trying to sell developer tooling is that developers have no purchasing authoritySalesperson needs to spend $1000? No big deal. Finance needs to spend $100,000? No big deal. Engineer wants to buy a $50 book? They need forms signed from their VP in triplicate.— Daniel Feldman (@d_feldman) April 13, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40029283",
    "commentBody": "Problem with selling developer tools is that devs have no purchasing authority (twitter.com/d_feldman)123 points by notRobot 3 hours agohidepastfavorite107 comments jimnotgym 3 hours agoNearly right. I don't think many sales and finance people have that kind of authority either. That's why you see everyone using the company tools or free tiers. You need to sell to peoples bosses. Save time, make projects more transparent, take away freedom, that sort of thing. This is probably why Excel is so ubiquitous. Also that Excel is the most powerful tool that Corporate IT will let you have. Try and get Corporate IT to let you have WSL on your machine if you work in sales or Finance. That is probably why web apps are so popular. Corporate IT have to know about it to block you. A marketing manager can probably put Basecamp on her credit card, but it would be a huge job to get anything self hosted last IT with their policy of 'we are in charge of the computers and we will decide how you run your business'. reply Gigachad 2 hours agoparentPretty much. Companies won't approve buying an individual book, but they will approve a subscription to a learning platform. It's too much work to approve all these random purchases, but if you don't review them, you end up paying for a bunch of unused subscriptions all over the place as well as people buying a ton of stuff that doesn't really benefit the company that much. reply anonymousiam 40 minutes agorootparentBack in the day at Hughes Aircraft, and later, at least for a while, at Boeing, we had a \"Library\", though which anyone could request a book. If the library did not have it, they would purchase a copy, and \"loan\" it to the requestor indefinitely. If another request for the same book came in, the original requestor would be asked to \"return\" it to the library. The library also maintained subscriptions to all relevant technical journals and standards publications. This system was awesome because book purchases did not require management approval, so there were no denials and little delay involved. reply danpalmer 1 hour agorootparentprevA learning platform that costs the same as a book per month per employee, and doesn’t have the book on it. reply jiggawatts 1 hour agorootparentYou weren't listening. It's one platform, which means that the guy that costs the company $200K annually who approves expenditures wasn't overworked and could eliminate a bunch of waste across twenty teams. I mean sure, a cynical person might ask why even bother paying that guy when his salary could be divided up into $10K per team for a hundred books a year per team, but that kind of talk gets you dragged in front of HR for a \"discussion\". reply tw04 2 hours agoparentprevExcel is ubiquitous because literally anyone can use it. Unlike a database, there is a direct visual representation of what you’re building. It is included in all m365 licenses and has been relatively cheap for a perpetual license for years. As for allowing WSL for sales, have you ever actually worked with someone in sales? At 99% of companies, even the most technically literate sales person can just barely send an email attachment without help. What exactly do you think they’re going to do with WSL?? reply jimnotgym 59 minutes agorootparentYes I have been on the senior management team of several companies and have worked with sales. Your lazy stereotype is as bad a suggesting programmers all sit in dark rooms with starwars T shirts and Body Odour issues. I have seen sales people create very complex excel models, and use low code tools to build their own pipelines because corporate IT were too pig ignorant to help them. I have seen them use screen recorders to beat the lack of API access. Ihave seen finance people use WSL, Cygwin, Python, Anaconda and more. reply constantcrying 24 minutes agorootparentprev>Excel is ubiquitous because literally anyone can use it. Unlike a database, there is a direct visual representation of what you’re building. Oh no. Excel includes an entire programming language, namely VBA macros and if you give it to engineers they will use it. The reason Excel is ubiquitous is because it is Microsoft and someone is paying. The same is true for Matlab. A company getting Matlab licenses is much, much easier than someone getting a python installation. It isn't a money problem. It is an Anti-Money prolem. If you can't pay someone you can't use it. reply jsdwarf 47 minutes agorootparentprevExcel is so ubiquitous because it is the only IDE/Programming Language/Database Environment business users can run in a restricted corporate IT environment. reply flir 1 hour agorootparentprevIn a lot of companies, web sits under marketing... reply olivierduval 53 minutes agoparentprev> a huge job to get anything self hosted last IT with their policy of 'we are in charge of the computers and we will decide how you run your business' ... because we are also in charge of: - the bills for the servers/networks/storage to \"self host\" your new shiny application - the installation/upgrade/administration/support of the servers/networks... and of your application (because the finance department doesn't know how to do it) - the integration of your \"self hosted\" application into the AD (for the SSO), mail system, slack, backup/restore system (in case of crash or hack)... and the maintenance of all of it - eventually ensure that the application datas can be exported to other apps or migrated (when the new shiny self hosted app will be less new... and a new new new shiny self hosted app will be bought) - the cybersecurity of your \"self hosted\" application... and of the whole corporate IT !!!!! Remember: a single application is enough to compromise the whole corp IT (OK... it can be segmented, 0-trusted, and so... be it increase attack surface and cybersecurity cost anyway) In fact: BUYING a \"self hosted\" application is the EASY part, the HARD part is to make it RUN, DAY-TO-DAY, for AS LONG AS REQUIRED for the business (including legal requirements sometimes to keep datas for long time) OK, when \"local IT\" ask for application, they usually can manage part of it technically but... either they wont (because they just dont have time! Remember: they want the tools to do their job, but the tool is NOT their job) or they cant (because they're devs and not admin sys/net sys and they dont know) At most: they can use some \"sandbox\" unconnected to \"corp IT\", but then they either need to forget all nice things (like backup systems or AD) or to implement it and maintain it (shadow IT)... IMHO, that's part of the explanation for the \"SaaS\" and \"Cloud\" development: externalizing all of these costs reply jimnotgym 24 minutes agorootparentAll of which is true. I used to run a smallish IT team. The problem comes with the failure to offer an alternative to solve the issue the person has. My algorithm always started with, can we do this with our existing O365 licence. You can't have Trello or Asana, because we have Planner already. You can't have Slack because we have Teams. You can have Basecamp because the manager put a great case of why She couldn't do that on Teams. You can't have Jira because you only want bug tracking and it is too complex for your little team, how about self-hosted Redmine? reply pjerem 2 hours agoparentprevMy experience is that while sales can have good tools at department level, they do not have a lot of buying power However it looks like marketing people have a lot of buying power, probably since their job involves buying a lot of random things. reply endymi0n 3 hours agoprevIf you have to fight for a 50$ book, you‘re probably just at the wrong place. That being said, some developers wanted to test Notion internally, so they got an informal account with a credit card. Turns out they built an important overview in it and send the link around, so everyone who wanted to take a look at it (half the company) implicitly created an account and our CFO got hit by a 10k bill next month. And that‘s how devs having no purchase authority stories usually start... reply VS1999 2 hours agoparentHow does anything think setting up a system where you can get billed for clicking a link is a good idea? Along with no sensible monthly limit on the credit card. The whole setup is beyond ridiculous, and it's hard to believe this is how \"devs having no purchase authority stories usually start\". reply Ekaros 3 minutes agorootparentAren't this sort of dark patterns exactly what are expected from growth hacking and getting numbers look good? Whole sub-set of companies are incentivised to use these tactics... reply maccard 2 hours agorootparentprevI work in a small company and we use a few services that bill for active users, and sync with g suite. It reduces the overhead of admin for me significantly as it means I know we're only paying for people who use the service that month. > Along with no sensible monthly limit on the credit card. A £1000 limit doesn't stop you from generating a £10000 invoice. It just means you need to go higher with your tail between your legs to pay the bill. reply isbvhodnvemrwvn 2 hours agorootparentprevBilling by active users is quite common. reply rightbyte 2 hours agoparentprevThis is just an example of predatory pricing models and dark patterns. There is reason many SaaS companies usually have no prepaid or fixed cost roof pay options. They are scammers. reply sverhagen 2 hours agoparentprevDevelopers (or anyone) buying tools can often also be a sort of local optimization, at the expense of the larger organization. For instance fragmentation, so that you can't find things through a single search anymore, or need to log into different teams' tools separately. Not to mention the compliance nightmare if you want to be SOC compliant while teams are all managing their own tools full of company IP. Buying books and other learning resources is great, though. reply ChrisMarshallNY 1 hour agoprevHa. I used to work in a sales-oriented subsidiary of an engineering company. In the early days, I could take people out for a $100 lunch, no problem, but I couldn’t buy a $30 card for my computer. In the parent corporation, on the other hand, they could fairly easily get a $5,000 test rig, with no issue, but needed to fill out forms in triplicate to take you out to a fast food greasy spoon. Towards the end of my tenure, you basically couldn’t do anything, at either place, without said forms. But many successful dev tool companies have made their money by marketing to bosses, as opposed to devs. That goes for many fields; not just tech. reply bjt12345 50 minutes agoprevI purchase my own software licences and claim it on tax. Because it's a false economy. I've won awards at work, became indispensable on certain projects, and have been given pay rises, choose the work I want to do, through finding the affordable right tools for the job and purchasing them. My Jetbrains licenses are a classic example of this. I couldn't imagine refractoring code without it. If the cost cutting stopped, I'd have more competition in the workplace. reply kmac_ 2 hours agoprevIt depends on the company. One company I worked for had a policy of \"Just buy what you need that makes your work easier: books, licenses, and even hardware. Management time spent on decisions is too expensive, so we default to instant approval.\" Did developers go on a buying spree? No, the same amount of stuff was bought as before the policy. And it did make life easier. reply olivierduval 45 minutes agoparentActually, it's just considering books, licences and hardware as disposables like pen and papers... and it can usually be true for some \"small\" local software (like an IDE, provided that either you trust the devs with admin rights or that corp IT can allow software installation). You can give either a \"small\" bugdet for everybody (and you wont be a software the same year that you buy a new laptop) or managed by the team/department But it doesn't work when you need corp IT for corp IT integration reply redditor98654 1 hour agoparentprevNetflix? reply rrr_oh_man 1 hour agorootparentDon’t hire idiots and assholes and this policy becomes pretty self policing. reply elric 2 hours agoprevI only had this issue the one time while I was an employee: I wanted a Thinkpad, but management insisted I got a shitty Dell. In the end, they got me a Thinkpad. Other than that, whenever I've asked for a book or some tool, I simply got it, even expensive split keyboards. Now that I'm self employed, I just buy what I need. Which isn't much, really. Very few \"developer tools\" are useful enough to spend money on, let alone try to integrate them in my workflow. That last part has become much more important to me over the years. reply cjk2 1 hour agoparentCorporate life... I got a shitty Dell. It broke. I got another shitty Dell. That broke. I got another shitty Dell. That broke. I got a shitty Dell. BUT WE ONLY HAVE A CONTRACT WITH DELL. Perhaps you shouldn't have a contract with Dell? Silence. Then the brain gets going. You realise the best bits of your life are when the Dell breaks because it takes 5 days for them to work out how to send a new one out through the layers of PO and ordering politics which are responsible for the account with Dell in the first place. That is 5 days of bliss where you can't do ANYTHING because of the vicious corporate security policy so you sleep for 5 days, catch up on friends, be a human again. I love Dell. I don't want a ThinkPad. But I own a MacBook for my own use. reply chillfox 2 hours agoparentprevIf you have to ask, then you don’t have authority. reply maccard 1 hour agorootparentYou can have authority while still having someone be accountable to the org. We had a situation where we were paying for three different presentation tools and two whiteboarding tools for a team of 30 people because two people had minor preferences. I have to request a limited card for recurring spends, which comes with a \"why\" box. It makes people think about what they're buying just a tiny bit more. But I've never had a single purchase denied (other than the time I accidentally paid for a personal holiday on my work card because Google pay's default payment card on device and online are linked) reply moooo99 2 hours agorootparentprevIt depends on how strictly the request is scrutinized. I can spend exactly 0€ myself. But when I request a new machine, the order is placed immediately. On the other hand I requested three months access to frontend masters which was promptly denied citing I should use our Udemy subscription. reply samus 2 hours agorootparentprevIf you get what you ask for without fuss, then it's not an issue. It becomes an issue if you have to slog your way through corporate bureaucracy^H^Hzy to get basic things. reply maccard 1 hour agorootparentAnd asking isn't a problem - it stops three different teams signing up for slack, campfire, teams. reply srvaroa 44 minutes agoprevA business model based on engineers as the decision makers is perfectly possible. But it is confined to tools where an engineer can make a local optimisation without direct impact beyond that scope. IDEs are the best example. Engs in a company can be allowed to make whatever personal IDE decision that makes each one of them more productive, and the global impact of aggregating those individual decisions will be ok. Jetbrains is a testament to this. But this is not the same for every tool. The thread author focuses on examples that fall in this second category like Redis, Terraform, AWS, etc. You have two factors at play. First that, unlike with IDEs, sprawl resulting from individual decisions in databases, infra management or cloud infra becomes a problem. For both! The company has to maintain a heterogeneous stack. The seller can’t make a meaningful enterprise deal just because some team chose Redis. This means that you will want to do some standardisation. At that point the impact of the choice and the size of the license become big enough that, in the same way as eng leads will want a say, finance will too, for good reason. And needless to say, the moment finance is in the picture you will have to justify the choice in a language that is challenging for most engineers. reply Epa095 3 hours agoprevUnless you can put on azure/AWS/Google cloud. I can't buy a pencil without approval, but I can spend thousands in our cloud without asking anyone. reply nevon 2 hours agoparentAnd there's the magic of the Amazon marketplace. Let's you buy non-AWS services while still ending up on the AWS bill and contributing to any potential spending commitment the company has. reply Aeolun 29 minutes agorootparentDoesn’t actually work because purchasing on marketplace is still restricted. reply jimnotgym 48 minutes agoparentprevIndeed. I asked a dev to set up an ftp server. He was a decent Linux admin and had done this plenty of times on a £10 vps. This time he chose an AWS service that cost over a grand a month. It caused me lots of trouble when I got my credit card bill, and we were already well into the next month of charges. After that I had to take tighter control. reply technofiend 1 hour agoparentprevSame and it's going to be a huge, uphill slog to get the right people to consider localstack. But if we purchase a corporate license the savings would instantly pay for it so I feel compelled to try even though it is isn't really my day job to do so. reply constantcrying 17 minutes agoprevIn my experience it's not about purchasing authority. Otherwise free software should be available without issue. But in large companies IT won't let you install things on your own devices. The problem isn't money, you can get money at most companies fairly easily. The problem is that you actually need to be allowed to use it, which is far harder and far more costly than the cost of the product. reply Simon_ORourke 2 hours agoprevCorrect - and this can be extended into any ML/AI team within a company too. The folks wanting to build something advanced or innovative will never have the authority themselves to get the tooling they need. Writing from experience here, my team wanted to get a application (or even a trial of a particular application) that would help with LLM hosting and model building, and it had to go up to SVP level to get sign-off. reply delichon 2 hours agoprevHere's my puchasing power: \"Boss, if we buy this developer tool it will save X hours of developer time.\" ... where X is large compared to the price of the tool. It works well enough that we use it often enough for Boss to be skeptical. reply sverhagen 2 hours agoparentAnd skeptical they should be. Overestimating benefits, whether it's for a tool or something like a re- architecture, is right up there with underestimating effort, probably highly related... Doesn't mean there aren't worthwhile tools, because there are, but they're few and fast between. reply olivierduval 41 minutes agoparentprevHow much time before you boss says: \"OK, during the last 3 months you told me that all these tool would save you in total 1 dev/year... so I will reduce your team by 1 dev but keep the work and deadlines\" ? ;-) reply maayank 1 hour agoparentprev“Developer time is not a KPI and we pay you the same whether you work 160, 180 or 200 hours a month” reply pflenker 1 hour agoprevI have never even heard of a company where a single person on the level of an engineer was able to spend 100k without getting approval. Just ask for example sales persons on engineer level how easy it is to get 50€ for something they think will have a huge impact on closing a deal. They have the exact same problems. reply animuchan 2 hours agoprevSo true. Getting a Copilot subscription for $10/mo was an uphill battle. My daily supply of coffee alone costs the company more that that. reply atq2119 1 hour agoparentMaybe I'm a dinosaur, but I wouldn't just approve an individual Copilot subscription either. The problem isn't the money, it's the copyright and whether trade secrets are being leaked. Those things can surely be solved, but it's far from trivial. reply McAtNite 1 hour agorootparentThe general gist I’m getting from this comment section is a general lack of awareness over DLP and security. The thing half these comments are complaining about exist for very good reasons. reply zarzavat 1 hour agorootparentprevOkay imagine you’re an employee. You are ranked against your coworkers based on individual productivity, either explicitly or implicitly. You can choose to either spend $10/month to get a big productivity multiplier, or you can play it by the book, not use it, and be the first one out the door the next time the company decides it needs to find efficiencies in a down market. What do you choose? reply cuu508 54 minutes agorootparentI would choose to play it by the book. reply jiggawatts 1 hour agorootparentprevEvery company I know that balked at using the \"enterprise\" version of either an OpenAI product or the equivalent Azure Open AI service already uses Microsoft 365, Teams, Azure DevOps, and Azure itself. \"We can't just give some unknown company our data!\" screeched management. \"You already have.\" reply hnick 1 hour agoparentprevYou need to present a business case. Offer to give up the coffee. reply nerdponx 2 hours agoparentprevStill trying to get our team Copilot subscription for 2 months now. reply bratbag 1 hour agoparentprevI had to perform due diligence on that. The cost was meaningless. reply flakeoil 2 hours agoparentprevWow, they must use expensive coffee beans. reply tempay 1 hour agorootparentNot really. 3 cups a day, 5 days a week, 4 weeks a month = 60 cups of coffee. If we say 15g of beans per cup means you'll use 2 one pound bags in a month which could easily be $20-$40. reply samus 2 hours agoparentprevYou guys get coffee? /s reply jessekv 3 hours agoprevI always liked the Sublime Text model. You pay once, and keep your licence no matter where you work. Same with my keyboard. I like to own my tools. reply watermelon0 3 hours agoparentJetbrains tools are the same; you can buy personal subscription, and use the tools no matter where you work. If you have a subscription for 12 consecutive months, you get perpetual fallback license for version of the tools that were available at the start of the period. reply isbvhodnvemrwvn 2 hours agorootparentKeep in mind you can't use personal license at work. reply boojing 2 hours agorootparentYou can: https://sales.jetbrains.com/hc/en-gb/articles/207240855-Can-... reply sverhagen 2 hours agorootparentprevYou can, if you paid for it yourself. As long as the employer doesn't \"pay, reimburse, or in any way finance your personal license\". reply genocidicbunny 2 hours agoparentprevEverywhere I've worked the managers liked Sublimes model too. To the point where at one place we built a few plugins for Sublime because so many of the engineers were using it. It was cheap enough that reimbursing engineers for the license was easy to get approved and everyone liked being able to hold onto their individual license after. reply 000ooo000 2 hours agoparentprevLINQPad's model is similar but it didn't stop my last company refusing to allow me to use my personal copy due to \"licensing\". Some companies (read: managers) just can't be f'd reading a brief web page and applying 10 seconds of thought even if it means there's a chance a developer might be more productive, or god forbid, happier. reply cheema33 26 minutes agoprevAt my company, I can buy pretty much anything I want. I do buy hardware often. But software dev tools? I am trying hard to think of one and coming up empty. Save for GitHub/Copilot, ChatGPT and Anthropic subscriptions. Those things are the only software dev tools I have found worth paying for. reply vertis 21 minutes agoparentYeah, there are definitely exceptions to this. I had a company credit card for quite a while at a previous company. It did result in a bunch of other devs coming to me to get small things purchased (this was an appropriate use). The number of tiny things that were then not subject to silly red tape just provides supporting data for the original tweet though. There are also examples like Slack where it becomes a ground up movement that eventually results in the company purchasing the requested tool. (Context: I was the lead engineer on the company emerging technology team, buying 3D printers, VR headsets, and hackathon supplies and many many things of this nature + travel related expenses) reply toenail 3 hours agoprevIf your management doesn't get you the stuff you need to be productive your company is a failure. Move somewhere else. reply genocidicbunny 3 hours agoparentDepends on the tool. I've seen engineers ask for an IDA license to try to debug a pretty simple memory overrun crash. The manager rightfully told that engineer to go use Visual Studio first. Otoh, if management isn't willing to drop $50 on a one time purchase that increases your productivity, it's definitely a flag. Maybe not a red one, but at least mauve. reply pflenker 2 hours agorootparentMy own stance as a lead is that it costs more than 50€ just discussing the thing, so we might as well just buy it. reply umanwizard 10 minutes agorootparentIDA costs thousands of dollars per seat reply PeterisP 33 minutes agorootparentprevSure, but in the parent example it's more like a 2k-3k license, which makes sense only if you're going to use it regularly. reply Hammershaft 53 minutes agorootparentprev50€ can be literally less than 30 minutes of discussion over the item being bought. reply criddell 22 minutes agorootparentA discussion involves two people, so halve that. A then consider the opportunity cost. A relatively rare 50€ purchase likely isn’t worth any discussion. reply pompino 2 hours agoparentprevThe problem is who decides what really matters? Every department is biased towards their own needs. Upper management is usually clueless when it comes to technical needs, even if they've done the job before - because it was probably 10+ years ago. reply maccard 1 hour agorootparentI think it's less about does it really matter, and more about do we have a solution for this/is this something that will spread and we need to negotiate a price on. reply xvilka 32 minutes agoparentprevMost companies in fact are. Just look at the survival rate. reply andersa 2 hours agoparentprevThat really depends on how much money they are happily paying you to be unproductive. reply Aeolun 36 minutes agoprevNot entirely correct, I have purchase authority for several million dollars a month in AWS costs. A new mouse however… reply nabla9 49 minutes agoprevTypically there is a price limit. Below the limit, there is an assigned budget for the dev team. You can buy online and the price is visible. Above that sum you must do sales negotiation and the price is not public in the sellers site. If buying the tools for the whole team costs a few grand, you can buy it online. If the sum is higher the price is negotiated and costs the company at least five figures. reply wongarsu 3 hours agoprevHence the common strategy to onboard companies when the company is still small (when developers either have purchasing authority or sit in a room with somebody who has) and try to lock them in forever reply Brajeshwar 2 hours agoprevSelling dev-tools to devs is like selling toys to kids - you target the parents (or the paying CxOs in the company). One should learn from the likes of Slack, Postman, etc. -- make it the de-facto tools for the devs/users and make them happy, then they go and ask their parents/approvers to buy them. reply TeMPOraL 45 minutes agoparentThat's how you make parents feel good about themselves, that they did something useful, while their kids are unhappy with shit pseudo-toys they got. That's how amateurs and people who mistake priorities in edutainment do things. Pros know that you always target the kids - not just for toys, but for many other categories of wares too. Kids may have no spending authority, but they're much better at marketing to their parents than you can possibly hope for. Like, there's a reason you see Paw Patrol merch on every other kid everywhere - they release a highly addictive animated show for kids, and kids do the rest. The reason this doesn't work with devs is because unlike parents of kids, people with spending authority usually don't care, as devs are a cost centre and a number on a chart, not people generating value. reply forgotpasagain 3 hours agoprevCreate a developer tool that \"makes easier\" purchasing developer tools. edit: popped as joke idea, but thinking about it might make sense if both developers and developer tools have this pain rn. reply bjornsing 3 hours agoprevHasn’t this begun to change though? I did a brief stint at Sinch (the Swedish Twilio) and “developer go-to-market” was an established term there. My impression is that developers have started using so many cloud services and APIs that the old school approach (“nobody in engineering buys anything!”) is starting to crumble. reply Rastonbury 2 hours agoparentAuthor been living under a rock?Engineering/dev first companies been popular since the 2000s. Developer salaries are often the most expensive thing, so everyone in the c-suite cares that their people are more efficient. Developer love is table stakes if you want to be put in front of someone who can purchase. If only sales were as easy as emailing the CEO or CTO and having them agree to a meeting reply _the_inflator 2 hours agoprevThe conclusion is correct however the premises are not correct. 1000 devs buying individually on average tools for 100 USD/month doesn’t make sense in any organization. Controllers will have their say and architecture or CTO should have their say, too. Tool usage corresponds with IT strategy. Procurement tends to count in large numbers. That’s why a business unit usually decides. It is up to the devs to raise the Business Case. IT departments are usually considered Loss Centers. That’s why there is another road block, but not against productivity per se. reply dannyw 3 hours agoprevI agree with the point, but isn’t Jetbrains a good example of selling to developers? reply smdyc1 3 hours agoparentIf there was a way to get a company licence, I'd have bought it for our dev team. reply toenail 3 hours agorootparentEr what? https://www.jetbrains.com/business/ reply smdyc1 1 hour agorootparentIt's triple the cost of a single user license for the same thing. Beancounters don't like that. reply jimnotgym 42 minutes agorootparentPeople don't like that reply technosavie 2 hours agoprevIn europe, my work, which has 600 circa devs, cannot use any other browser than Chrome. Have to get multi levels of sign offs to even login in Gmail. When I raised this issue, they simply buried me in paperwork + got almost no support from co-workers. reply hankchinaski 1 hour agoprevYou sell to CTO not developer, like you sell to CFO or to head of HR or head of Sales reply lloydatkinson 26 minutes agoprevI don't even bother trying to get money back. I buy, for example, GitKraken at any new job I start at. reply bitwize 2 hours agoprevIt's pretty much like all enterprise software: you sell to the people with the purchasing authority. Meaning sales are often closed on the golf course. reply t43562 2 hours agoparent...and get terrible solutions which the people on the golf course don't care about since they don't use them - or if they do they only use the reporting part of the feature set - so that's got to be great but the rest can be shit. reply badgersnake 1 hour agorootparentE.g. Atlassian reply jongjong 46 minutes agoprev\"Problem with selling developer tools is that devs have no purchasing authority\" Wow, I said almost this exact sentence to my co-founder just a few days ago to explain to him why my no-code serverless platform which allowed me to build our entire startup, bug-free, in record time cannot be anything more than a side project or tool for my own usage and cannot be monetized. It doesn't matter than I can build something 10x as fast and avoid 99% of bugs. Those with decision ability are brainwashed to think that the way to reduce bugs is TypeScript and the way to build software fast is React. reply fxtentacle 2 hours agoprevThere's plenty of consulting companies where developer = owner. Also, JetBrains, Ida, Visual Studio Pro, VMware Workstation, Docker Enterprise, Colab Pro, HuggingFace, ... There's lots of paid tools primarily targeting developers. reply throwaway83jf82 2 hours agoparentThe tweet says that companies will be more successful if they can find a way to market dev tools to non-devs (coo/cfo) in the organization that have the authority to approve larger purchases and can push these tools down the hierarchy reply t43562 1 hour agoprev....hence the great value of open source because a lot of those managers don't give a thought to what you put in your requirements.txt or package.json. reply pompino 3 hours agoprevYour department head should have discretionary funds to cover $1000 easily. I understand this tweet is in jest, but cmon. reply holoduke 2 hours agoprev [–] A good thing in my opinion. 95% of the tools are worthless. In a lot of cases a personal preference of a dev. Not a shared one. And sometimes sold by a sales representative to a dev. Important to have a guarden. reply digestivetires 32 minutes agoparentI would wager that some tools are like gloves or shoes, very important to have a good individual fit, to get best of performance. reply bartvk 2 hours agoparentprev [–] Important for what reason? reply jimnotgym 38 minutes agorootparent [–] Perhaps because interoperability of a team is more important that one dev? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Selling developer tools to companies presents challenges due to developers usually lacking purchasing authority.",
      "The discussion covers the utilization of Excel and web apps in businesses, obstacles with self-hosting apps, and the intricacies of tool procurement within large organizations.",
      "Addressed topics include bureaucratic obstacles, procurement procedures, and the significance of managerial backing for purchasing choices, alongside emphasizing team compatibility and selecting tools tailored to individual requirements for enhanced performance."
    ],
    "points": 124,
    "commentCount": 108,
    "retryCount": 0,
    "time": 1713078800
  },
  {
    "id": 40027249,
    "title": "Exploring Super Mario 64's Invisible Walls",
    "originLink": "https://www.youtube.com/watch?v=YsXCVsDFiXA",
    "originBody": "SM64’s Invisible Walls Explained Once and for All Watch later Share 0:00 0:00 / 3:45:24•Watch full videoLive",
    "commentLink": "https://news.ycombinator.com/item?id=40027249",
    "commentBody": "Super Mario 64's invisible walls explained [video] (youtube.com)119 points by mbStavola 11 hours agohidepastfavorite42 comments bumbledraven 9 hours agoThis is a new explainer by pannenkoek2012, the video game researcher best known for his discussion of \"parallel universes\" in Super Mario 64. He rarely publishes for general audiences these days, and the description says this video took him 10 months to make. https://en.wikipedia.org/wiki/Pannenkoek2012 https://knowyourmeme.com/memes/05x-a-presses-but-first-we-ne... reply nimish 9 hours agoprevThere's something wholesome that there's someone out there with a PhD in Super Mario 64. Long live the eccentric. reply g___ 9 hours agoprevFor over a decade, the author of this video has been leading an effort to complete Super Mario 64 with the smallest amount of A presses, often using extremely complex strategies. Here's a 5h video with the history. Bismuth says the history video took roughly 1500-2000 hours. https://www.youtube.com/watch?v=yXbJe-rUNP8 reply redox99 8 hours agoprevThe amount of effort in this video is astounding. Quote from the author > If you’ve wondered where I’ve been for the past 10 months, it was working day and night on this one video. In other words, I never actually left, I’ve been working on sm64 the whole time. So I didn’t forget about you guys :) reply allanrbo 7 hours agoprevMy goodness, 3+ hours on this topic! I truly admire the passion! Fascinating! reply stemlord 10 hours agoprevHow on earth does it take 4 hours to explain? I'm sure it's a lovely video but anyone care to tldr? reply Eduard 8 hours agoparentit's a surprisingly deep topic involving Super Mario's 64 game mechanics such as \"quarter steps\", integer arithmetic, float-to-integer conversions, the chosen collision detection implementation and plenty more. There are eight different causes that manifest in the observed \"invisible wall\" symptoms. I find the level of detail given appropriate, and consider it as a valuable insight into game engine design as it was appropriate for the time. reply wtallis 5 hours agorootparentI also think it helps to appreciate the historical context: this game was a major milestone in the development of the 3D platformer genre. Some of the bugs or treacherous optimizations may look naive to us now, but there had been few if any opportunities to make those mistakes prior to Super Mario 64. And in spite of the glitches, the game managed to be a huge success and highly influential even outside the platformer genre. This video does a wonderful job of illustrating how a handful of underlying issues can combine and manifest in so many different ways, and this was only the tip of the iceberg of 3D game physics glitches. And some of these issues are things games can still fall prey to today. reply duskwuff 5 hours agorootparentVideos like these can also be a fantastic way of introducing viewers to CS and math topics that they wouldn't otherwise have been exposed to. The video game theme gets them in the door; the detailed analysis teaches them some things which are applicable beyond that game. reply Kikawala 9 hours agoparentprevhttps://www.youtube.com/watch?v=YsXCVsDFiXA&t=3228s reply VelesDude 8 hours agorootparentThanks for that. I will go through the whole video later but that at least covered the basic premise. Essentially, due to the technique used for collision detection, tiny gaps in the geometry causes collision system to treat parts of the scene as having very thin walls that stretch to the top of the play space. Depending on if Mario's quarter steps align with this little gap means that a collision can be made despite it not being visible. Also explains why they impact Mario sometimes and not others. Like throwing a marble through a mesh fence but you cannot see the fence. Odds are you will make it through but it is essentially chance. reply savrajsingh 9 hours agorootparentprevThis is exactly it, thanks! reply nickitolas 9 hours agoparentprevI think most of it is that he shows and explains every invisible wall in the game (Or tries to). The basic explanations are about an hour and a half. It uses graphics for explaining almost everything and does it in quite a bit of detail. reply ranger_danger 9 hours agoparentprevYou should see the \"0.5 A presses\" video: https://www.youtube.com/watch?v=kpk2tdsPh0A reply bakugo 8 hours agoparentprevHis explanations are just very thorough. If the topic of how 3D video games are programmed interests you at all, there's many, many more hours worth of interesting content on both his main channel and his second uncommentated channel (uncommentatedpannen). reply Waterluvian 9 hours agoparentprevI skimmed it and it’s trying to be the authoritative “phd thesis” on the topic. Still, many sections felt far too wordy and long. Technical communication is a difficult skill. reply VS1999 7 hours agorootparentTrue. If he wanted to make it a proper phd thesis he'd use language to muddy the waters so no one could understand what he was saying. reply orbital-decay 4 hours agorootparentGood PhD theses are usually the opposite, they are lengthy to be approachable by a non-expert, unlike ordinary research papers. reply throwaway74432 7 hours agoprevI don't mean to knock this video or anyone that gets a kick out of it. But does anyone else feel a sense of despair when they see that someone has put so much time and effort into something like this? I feel the same about speedrunners. Yes, they aren't hurting anyone, and yes they're following their passion, but I still feel an instinctual sense of despair when I see someone work so hard on something like this. I'm sincerely not trying to hate on anyone. reply bongodongobob 7 hours agoparentNot at all. It's the reason we have literally everything we have. This is the type of person that society needs. We've got enough db admins or golfers or LoL players or whatever it is you deem is worthy of your time. There's a reason you have a nice mattress to sleep on. Some guy literally studies mattress springs so you don't have to. You should take some psychedelics or MDMA or something because your viewpoint is kind of fucked up and is likely projection of the fact that your own life is also meaningless and lacks purpose. There is no meaning or purpose, it's up to you to decide. This dude is crushing it and you feel sad? Kinda gross. reply throwaway74432 6 hours agorootparentI feel very deeply that my life is full of meaning, so it can't be projection. Not interested in trying to suppress my feelings with drugs either. reply bongodongobob 6 hours agorootparentSounds like you're a DARE kid. Promise you that some mushrooms, LSD, or MDMA isn't suppressing anything. You definitely need a perspective change and those are very good at doing that. I hope you find a way to treat your dismissiveness of the human condition and enjoy your limited time here. reply icebergonfire 6 hours agorootparentI love videogames, understanding how a speedrun is made is technically fascinating for me and I am also known to love some other things under the appropiate set and setting[1]... but I'll defend the OP because certainly don't think it follows that someone is a bad human that needs to do drugs just because they don't see the allure of Super Mario 64 and the people who are knowledge-hungry and obsess in understanding its guts. [1]: Readers please do the research before experimenting, you are tweaking your brain's running config with extremely opaque tooling that is not fully understood. Most of the time the calamity-event chance is low, it's a high impact event if it happens. Plural of anecdotes is not data, and oh do people confuse these. reply throwaway74432 6 hours agorootparentprevI'm not dismissing anyone, nor am I a \"DARE kid\", nor am I projecting my own \"meaningless life.\" I'm simply sharing my own unprocessed genuine reaction to this kind of content, and trying to see if anyone else can relate to it. You obviously don't, which is fine, but I don't see why you seem to be taking it personally. reply mazdayasna 6 hours agorootparentprevThis is probably the most condescending comment I have read on HN all year. reply bongodongobob 5 hours agorootparentCondescending is feeling sorry for someone who is doing brilliant shit because it's a waste of time, they should be bettering themselves. Like working harder at their job, or having a normal hobby like playing golf or watching football or fishing. You know, normal things like I do. It just seems so sad they what they are doing is a waste of time. Sorry I didn't add a \"I don't mean to be a dick\" comment like parent did. reply pests 2 hours agorootparentWho says he doesn't? Stop being so judgemental, get your nose out of others business. He may have a more fulfilling life than you even. Go find a hobby you actually enjoy instead of harassing someone whose found theirs. reply nonethewiser 6 hours agorootparentprev> Not at all. It's the reason we have literally everything we have. This is the type of person that society needs I think this misses his point. I believe the despair is precisely that we dont need speedrunners and such. And that its not benefitting is like the mattress spring expert is. > There is no meaning or purpose If you believe this, then surely you can understand why he would feel despair over something that justifies itself in there being no meaning nor purpose. reply icebergonfire 6 hours agoparentprevWhether you consider videogames worthy of extended time and attention or not, that's entirely subjective and you are correct (for yourself) whatever your take is. Even in the case of assuming that you consider videogames completely worthless and a blight on humanity, surely you can appreciate that the person in this video has demonstrated an ability to reverse-engineer and understand extremely complex systems that were designed and shipped under very tight deadlines and not-very-good tooling... plus they have the ability to teach this knowledge in ways that non-experts can easily follow and understand. I would not say loving videogames makes for a good engineer, but I will say that my engineering growth was boosted by the opportunities granted to those videogames I loved when I was younger and how easy it was to inspect and disassemble them. For some The Cutting Room Floor is a website about unused content, but for other people that website is a gateway drug to needing to peel behind the curtain and understand how the sausage is made. reply vsnf 7 hours agoparentprevMy despair is that you think he should have spent his effort on something you find, I assume, to be more productive than this. He’s an expert is a video game, it’s wonderful that we have the material abundance to allow that. reply eddieroger 7 hours agoparentprevSome people really like to know how things work and are willing to put a lot of time in to understanding the thing that interests them. I don't feel despair. I'm glad they have a passion and feel so strongly about something that they wish to dedicate their time to their passion. If anything, I'm a little jealous. To each their own. reply eska 3 hours agoparentprevPsychologically speaking my knee jerk diagnosis would be that you have an ego problem. Some random guy out there does something that doesn’t have anything to do with you, but you feel “attacked” because it makes you question your own lifestyle and values. And no, please don’t take substances to fix psychological issues that just take some awareness and reflection. reply nonethewiser 6 hours agoparentprevI guess I just wonder how someone can afford to spend 10 months working on a SM64 video full time. Self-funded by his YouTube videos? Ok. Lives at home and taken care of by enabling parents? Suddenly not a harmless passion project. reply silver_silver 5 hours agoparentprevI agree. The insights are a small subset of what you’d discover writing a game. It’s like watching someone paint a wall with a model brush. This to me is an example of an unhealthy special interest. I don’t doubt that it makes them happy, but one has to wonder about the personal consequences of a lifestyle which allows for a 10 month project like this. Will they still be content after another decade of this, or will they regret spending their youth studying a toy? reply modeless 6 hours agoparentprevIt seems to me that if/when AI gets good enough to take over all the jobs then stuff like this is what we'll have left to do. We can always make up games to play and compete on and analyze. Maybe that's depressing to you, but I guess I don't see anything wrong with it. reply fb03 7 hours agoparentprevNot really. I wish I had: - that much drive and - that much time to sink into pleasurable (useful or not) endeavor watching people talk about something they have a passion in (whatever that topic might be) is really interesting to me reply bakugo 7 hours agoparentprevOur eternally insatiable urge to learn how things around us work and create new things from that knowledge is what makes us human. This is a bit of an extreme case, yes, but it's still fundamentally the same thing: someone dedicating their time to understanding something and sharing that knowledge with others, even if it's not particularly useful knowledge. Pannen's insane dedication to SM64 and the quality of his content have earned him a sort of small cult following over the years of people who watch almost every video he uploads, including me. With that in mind, it's hard for me to say the time was wasted on his part. reply add-sub-mul-div 5 hours agoparentprev> But does anyone else feel a sense of despair when they see that someone has put so much time and effort into something like this? No, but I feel a sense of despair when someone is so solipsist as to consider their own values as some kind of objectivity against which to measure others. reply mondobe 9 hours agoprev[video] reply Lammy 9 hours agoparent> (youtube.com) reply Karuma 9 hours agoprev [3 more] [flagged] CydeWeys 9 hours agoparentAI-generated comments are not allowed on Hackernews. See: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... reply jdlshore 9 hours agoparentprev [–] It failed—that’s just the preamble. The video’s probably too long for it. You should know better than to use AI without checking the results. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The video delves deep into the concept of invisible walls in Super Mario 64 over a 3-hour and 45-minute duration."
    ],
    "commentSummary": [
      "A video by pannenkoek2012 on invisible walls in Super Mario 64 is sparking discussions on the game's intricate mechanics and glitches, shedding light on its impact on 3D platformer development and game engine design.",
      "The video is lauded for its educational content, introducing computer science and math concepts, but opinions are divided on the significance of niche interests like speedrunning, with debates on the value of passion projects versus concerns about their practicality and personal implications.",
      "Hackernews has prohibited AI-generated comments for being inaccurate, emphasizing the importance of manual verification to maintain quality discussion."
    ],
    "points": 119,
    "commentCount": 42,
    "retryCount": 0,
    "time": 1713051748
  },
  {
    "id": 40022651,
    "title": "Factors shaping navigation skills beyond genetics",
    "originLink": "https://knowablemagazine.org/content/article/society/2024/why-do-some-people-always-get-lost-but-others-dont",
    "originBody": "LAYOUT MENU Insert PARAGRAPH Insert IMAGE CAPTION caption full caption right caption left caption center Insert SIDEBAR WITH IMAGE Position LEFT Position RIGHT Position CENTER Standard Q&A expert Insert SIDEBAR NO IMAGE Position LEFT Position RIGHT Position CENTER Standard Q&A expert Insert YMAL WITH IMAGES Position LEFT Position RIGHT Insert YMAL NO IMAGES Position LEFT Position RIGHT Insert NEWSLETTER PROMO Insert IMAGE CAROUSEL 1 Slide 2 Slides 3 Slides 4 Slides 5 Slides 6 Slides 7 Slides Insert PULLQUOTE Position LEFT Position RIGHT Insert VIDEO CAPTION full width center LAYOUT MENU CREDIT: KNOWABLE MAGAZINE Scientists are homing in on how navigation skills develop. Society Why do some people always get lost? Research suggests that experience may matter more than innate ability when it comes to a sense of direction By Bob Holmes 04.10.2024 Facebook Twitter Linkedin WhatsApp Pocket Reddit Flipboard Email Print Republish Support sound science and smart stories Help us make scientific knowledge accessible to all Donate today Like many of the researchers who study how people find their way from place to place, David Uttal is a poor navigator. “When I was 13 years old, I got lost on a Boy Scout hike, and I was lost for two and a half days,” recalls the Northwestern University cognitive scientist. And he’s still bad at finding his way around. The world is full of people like Uttal — and their opposites, the folks who always seem to know exactly where they are and how to get where they want to go. Scientists sometimes measure navigational ability by asking someone to point toward an out-of-sight location — or, more challenging, to imagine they are someplace else and point in the direction of a third location — and it’s immediately obvious that some people are better at it than others. “People are never perfect, but they can be as accurate as single-digit degrees off, which is incredibly accurate,” says Nora Newcombe, a cognitive psychologist at Temple University who coauthored a look at how navigational ability develops in the 2022 Annual Review of Developmental Psychology. But others, when asked to indicate the target’s direction, seem to point at random. “They have literally no idea where it is.” YOU MAY ALSO LIKE Society Reading a Pacific navigator’s mysterious map may require a shift in perspective Physical World GPS is going places Living World How animals follow their nose While it’s easy to show that people differ in navigational ability, it has proved much harder for scientists to explain why. There’s new excitement brewing in the navigation research world, though. By leveraging technologies such as virtual reality and GPS tracking, scientists have been able to watch hundreds, sometimes even millions, of people trying to find their way through complex spaces, and to measure how well they do. Though there’s still much to learn, the research suggests that to some extent, navigation skills are shaped by upbringing. Nurturing navigation skills The importance of a person’s environment is underscored by a recent look at the role of genetics in navigation. In 2020, Margherita Malanchini, a developmental psychologist at Queen Mary University of London, and her colleagues compared the performance of more than 2,600 identical and nonidentical twins as they navigated through a virtual environment, to test whether navigational ability runs in families. It does, they found — but only modestly. Instead, the biggest contributor to people’s performance was what geneticists call the “nonshared environment” — that is, the unique experiences each person accumulates as their life unfolds. Good navigators, it appears, are mostly made, not born. A remarkable, large-scale experiment led by Hugo Spiers, a cognitive neuroscientist at University College London, gave researchers a glimpse at how experience and other cultural factors might influence wayfinding skills. Spiers and his colleagues, in collaboration with the telecom company T-Mobile, developed a game for cellphones and tablets, Sea Hero Quest, in which players navigate by boat through a virtual environment to locate a series of checkpoints. The game app asked participants to provide basic demographic data, and nearly 4 million worldwide did so. (The app is no longer accepting new participants except by invitation of researchers.) Through the app, the researchers were able to measure wayfinding ability by the total distance each player traveled to reach all the checkpoints. After completing some levels of the game, players also had to shoot a flare back toward their point of origin — a dead-reckoning test analogous to the pointing-to-out-of-sight-locations task. Then Spiers and his colleagues could compare players’ performance to the demographic data. Several cultural factors were associated with wayfinding skills, they found. People from Nordic countries tended to be slightly better navigators, perhaps because the sport of orienteering, which combines cross-country running and navigation, is popular in those countries. Country folk did better, on average, than people from cities. And among city-dwellers, those from cities with more chaotic street networks such as those in the older parts of European cities did better than those from cities like Chicago, where the streets form a regular grid, perhaps because residents of grid cities don’t need to build such complex mental maps. Orienteering – a sport that combines cross-country running with map-based navigation – is popular in Nordic countries. This may be one reason why people from those countries tend to be better navigators than people from elsewhere. CREDIT: BORDER LINERS ORIENTEERING CLUB / FLICKR Results like these suggest that an individual’s life experience may be one of the biggest determinants of how well they navigate. Indeed, experience may even underlie one of the most consistent findings — and clichés — in navigation: that men tend to perform better than women. Turns out this gender gap is more a question of culture and experience than of innate ability. Nordic countries, for example, where gender equality is greatest, show almost no gender difference in navigation. In contrast, men far outperform women in places where women face cultural restrictions on exploring their environment on their own, such as Middle Eastern countries. This cultural aspect, and the importance of experience, are also supported by studies of the Tsimane, a traditional Indigenous community in the Bolivian Amazon. Anthropologist Helen Elizabeth Davis of Arizona State University and her colleagues put GPS trackers on 305 Tsimane adults to measure their daily movements over a three-day period, and found no difference in the distance moved by men and women. Men and women also were equally adept at pointing to out-of-sight locations, they reported in Topics in Cognitive Science. Even children performed extremely well at this navigation task — a result, Davis thinks, of growing up in a culture that encourages children to range widely and explore the forest. Most cultures aren’t like the Tsimane, though, and women and girls tend to be more cautious about exploring, for good reasons of personal safety. Not only do they gather less experience at navigating, but nervousness about security or getting lost also has a direct effect on navigation. “Anxiety gets in the way of good navigation, so if you’re worried about your personal safety, you’re a poor navigator,” says Newcombe. The Santa Barbara Sense of Direction Scale is widely used in navigation research. Studies suggest that people are fairly accurate at evaluating their own sense of direction. Personality, too, appears to play a role in developing navigational ability. “To get good at navigating, you have to be willing to explore,” says Uttal. “Some people do not enjoy the experience of wandering, and others enjoy it very much.” Indeed, people who enjoy outdoor activities, such as hiking and biking, tend to have a better sense of direction, notes Mary Hegarty, a cognitive psychologist at the University of California, Santa Barbara. So do people who play a lot of video games, many of which involve exploring virtual spaces. To Uttal, this accumulating evidence suggests that inclination and early experience nudge some people toward activities that involve navigation, while those who are temperamentally less inclined to explore, who have less opportunity to wander or who have an initial bad experience may be less likely to engage in activities that require exploration. It all snowballs from there, Uttal speculates. “I think a combination of personality and ability pushes you in certain directions. It’s a developmental cascade.” Mental mappers That cascade presumably influences acquisition of the specific skills that are hallmarks of good navigators. These include the ability to estimate how far you’ve traveled, to read and remember maps (both printed and mental), to learn routes based on a sequence of landmarks and to understand where points are relative to one another. Much of the research, though, has focused on two specific subskills: route-following by using landmarks — for example, turn left at the gas station, then go three blocks and turn right just past the red house — and what’s often termed “survey knowledge,” the ability to build and consult a mental map of a place. Of the two, route following is by far the easier task, and most people do pretty well at it once they’ve taken a route a few times, says Dan Montello, a geographer and psychologist also at UC Santa Barbara. In a classic experiment from almost two decades ago, Montello’s student Toru Ishikawa drove 24 volunteers, once a week for 10 weeks, on two twisting routes in a tony residential area of Santa Barbara that they’d never visited before. Later, almost every person could accurately state the order of landmarks along each route and roughly estimate the distance travelled between them. But they varied widely in their ability to identify shortcuts between the two routes, point to landmarks not visible from where they stood, or sketch a map of the routes. Those who couldn’t identify shortcuts or find landmarks may suffer from an inability to create accurate mental maps, the researchers think. Volunteers were driven repeatedly along two connected routes in an unfamiliar neighborhood and then asked to draw a map of the routes from memory. Their maps differed widely in quality, as these examples show. Map 1 (top left), from an excellent navigator, matches the actual routes almost perfectly; map 4 (bottom right), from a poor navigator, shows almost no correspondence to reality apart from the existence of two routes. Research by Newcombe and her then graduate student Steven Weisberg underscores the importance of such mental maps in navigation. They asked 294 volunteers to use a mouse and computer screen to navigate along two routes through a virtual town. Once the volunteers had learned the routes and the landmarks they contained, the researchers asked them to stand at one landmark and point to others on both routes. People fell into three classes, the researchers reported in 2018 in Current Directions in Psychological Science. Some people had formed a good mental map: They could point accurately to landmarks on both the same and different routes. Others had good route knowledge but struggled to create an integrated map: They were good at pointing within a route, but poor between routes. A third group was poor at all the pointing tasks. That ability to build and refer to a mental map — a person’s survey knowledge — goes a long way toward explaining why they’re better navigators, Montello says. “When the only skill you have is the ability to think in terms of routes, you can’t be creative to get around barriers.” Survey knowledge gives the ability to navigate creatively, he says. “That’s a pretty stunning difference.” Not surprisingly, better navigators may also be better at switching modes and choosing the most appropriate navigational strategy for the situation they find themselves in, says cognitive neuroscientist Weisberg, now at the University of Florida. This could mean using landmarks when they are obvious and mental maps when more sophisticated calculations are needed. “I’ve moved toward thinking that our better navigators are also using a lot of alternate strategies,” Weisberg says. “And they’re doing so in a much more flexible way that affords different kinds of navigation, so that when they find themselves in a new situation, they’re better able to find their way.” Volunteers followed two routes in a virtual-reality urban setting and then were placed along one route and asked to point to out-of-sight landmarks on both the same route and the other route. Based on their accuracy in pointing (measured by how many degrees off the correct direction they were; 90 degrees is chance performance), researchers divided the volunteers into three groups: People with good mental maps (green), who pointed accurately both within and between routes; people with good route knowledge (orange), who pointed accurately within a route but not between routes; and people who were bad at both pointing tasks, indicating poor overall navigational ability (blue). When Weisberg moves around Gainesville where he lives now, for example, he keeps track of north, because that works well in a city with a regular street grid; when he goes home to the winding streets of Philadelphia, he relies more on other cues to stay oriented. Researchers do not yet know whether every bad navigator is simply poor at survey knowledge, or whether some of the lost might be failing at other navigational subskills instead, such as remembering landmarks or estimating distance traveled. Either way, what can poor navigators do to improve? That’s still an open question. “We all have our pet theories,” says Elizabeth Chrastil, a cognitive neuroscientist at the University of California, Irvine, “but they haven’t reached the level of testing yet.” Pros and cons of GPS Simply practicing seems like it should work — and, indeed, it does in lab experiments. “We can improve people’s navigational abilities in virtual environments,” says Arne Ekstrom, a cognitive neuroscientist at the University of Arizona. It takes about two weeks to show fairly dramatic gains — but it’s not yet clear whether people are really becoming better navigators or just getting better at finding their way through the particular virtual environments used in the experiments. Stay in the Know Sign up for the Knowable Magazine newsletter today Support for the notion that people might improve with practice also comes from studies of what happens when people stop using their navigation skills. In a 2020 study published in Scientific Reports, for example, neuroscientists Louisa Dahmani and Véronique Bohbot of McGill University in Montreal recruited 50 young adults and questioned them about their lifetime experience of driving with GPS. Then they tested the volunteers in a virtual world that required them to navigate without GPS. The heaviest GPS users did worse, they found. A follow-up with 13 of the volunteers three years later revealed that those who had used GPS the most during the intervening period experienced greater declines in their ability to navigate without GPS, strongly suggesting that GPS reliance causes diminished skills, rather than poor skills leading to greater GPS use. Experts also suggest that struggling navigators like Uttal could try paying closer attention to compass directions or prominent landmarks as a way to integrate their movements into a mental map. For Weisberg, the only way he learns spaces in an integrated way is by paying attention to major cardinal directions or prominent landmarks like the ocean. “The more attention I pay, the better I can link things to the map in my head.” He recommends that struggling navigators ask themselves which way is north 10 times a day, referring to a map if necessary. This, he suggests, could help them move beyond mere route knowledge. There’s another option for those who don’t really care about improving their skills as long as they just don’t get lost, Weisberg notes: Just make sure your GPS is handy. 10.1146/knowable-041024-1 Bob Holmes is a science writer based in Edmonton, Canada, and a special contributor for Knowable Magazine. He thinks he’s pretty good at navigation, but that’s what most men say. Republish This Article Anthropology Gender Equity Physical World Psychology Society Technology The Mind Stay in the Know Sign up for the Knowable Magazine newsletter today Share this article Facebook Twitter Linkedin WhatsApp Pocket Reddit Flipboard Email Print Republish Support Knowable Magazine Help us make scientific knowledge accessible to all Donate TAKE A DEEPER DIVEExplore Related Scholarly Articles ANNUAL REVIEW OF DEVELOPMENTAL PSYCHOLOGY Spatial Navigation in Childhood and Aging Our ability to navigate develops through childhood and adolescence, then declines as we age. This review looks at how the mix of strategies people use changes over time. ANNUAL REVIEW OF NEUROSCIENCE How Do You Build a Cognitive Map? The Development of Circuits and Computations for the Representation of Space in the Brain Groups of neurons in the brain work together to form a mental map of the world. This review explores how this map develops. ANNUAL REVIEW OF NEUROSCIENCE Place Cells, Grid Cells, and the Brain’s Spatial Representation System This 2008 review lays out what was then known about the specialized nerve cells in the brain that keep track of location. Two of the three authors went on to win the Nobel Prize in 2014 for this work. More From The awake ape: Why people sleep less than their primate relatives Deep underground, robotic teamwork saves the day",
    "commentLink": "https://news.ycombinator.com/item?id=40022651",
    "commentBody": "Research into why some people have a better sense of direction (knowablemagazine.org)118 points by Brajeshwar 22 hours agohidepastfavorite146 comments netsharc 18 hours agoOne tip I like is to set your navigation app to \"north up\". This way you're aware which direction (in general) you're heading towards. If you know you're going south east and there's a detour, you know you need to find a parallel street heading south-east-ish. If translating the arrow pointing left and the next turn is down to \"turn right ahead\" is confusing, on Google Maps at least the top of the screen still has arrows pointing left or right how far away you are from the turn, so this info is still there. The tip is from Jeremy Clarkson of Top Gear, who does a lot of driving. reply boneitis 0 minutes agoparentI'm astonished. I would have theoretically days the same thing that the sibling comments are about getting north north. But, that is already the default (at least on my phone), but who knows for how much longer. The app quite aggressively tries to keep you from getting comfortable with this mode but instead wants to derail your sense of direction in general. First, it was a minor inconvenience to lock your orientation, then they hid it deep inside a settings menu, before eventually removing entirely the ability to lock the map to the cardinal directions, and everyone I complain about this to acts like I'm crazy. I'd love ago given up. reply svat 17 hours agoparentprevStrong agree; came here to recommend this — this is something I came up with by myself and thought I was the only one who did this; glad to find others think the same. Doing this has greatly improved my sense of direction (to much better than it was before I started using GPS/navigation). It's like getting instant feedback for your direction sense (e.g. I was driving west and just now I turned left, so I'm now driving south), and remaining oriented about where different places are wrt each other. A couple of screenshots for anyone confused: Before: https://media.mathstodon.xyz/media_attachments/files/112/264... After: https://media.mathstodon.xyz/media_attachments/files/112/264... reply Animats 4 hours agoparentprevStan Honey, who invented car navigation systems (Etak, pre-GPS), once told me that they started out with always displaying maps with north at the top. He's a sailor, and sailors have used maps with north at the top for centuries. So the car nav system just followed marine navigation. They discovered in user testing that about 20% of the population cannot rotate a map in their head. So they rotated the map in software. Keeping the labels in normal orientation was tough. Now everybody does that. reply analog31 12 hours agoparentprevI have to have my map on \"north up\" or I get lost. I'm 60. I also grew up in the US Midwest, where there's a NSEW square grid of roads over a large portion of the region. reply emmelaich 10 hours agoparentprevI usually \"north up\" but when navigating, the navigation view gives you more of what's ahead in screen space. I wish \"north up\" would do the same; I'm sure it's do-able. reply xtreme 7 hours agorootparentIt's not doable because your current location needs to be in the center of the screen in north up mode but can be placed lower in regular mode. Also the non square aspect ratio of the phone screen means that you don't get the same field of view in all four directions. reply Dylan16807 6 hours agorootparent> your current location needs to be in the center of the screen in north up mode No it doesn't, so you just identified an easy opportunity for improvement. reply LeoPanthera 3 hours agorootparentprevMy car has two screens, a big one for the overview map and a small one for the \"next turn\" map. I always said the big view to north up. Works well. reply conductr 8 hours agoprevI have a keen sense of orientation and direction. I don’t know my innate physical situation however I know I’m an “observer” personality. I am always aware of my surroundings and often people watching, etc. As a kid I just stared out the car window and noticed everything. Then I quickly correlated everything (I’d see a random sign and know to ask for ice cream because the ice cream shop was near, stuff like that.) However, I grew up during the paper maps era and sometimes I’d just take note of street signs and intersections because I was usually helping my mom get unlost. My wife on the other hand I think I know well enough to say she’s completely oblivious to her surroundings and wouldn’t venture far from home without a GPS. She’s definitely not an observer (ok, sometimes of other women’s clothing if anything) but oblivious is the best word I can use to explain it. Our 5 year old son is like me. He observes a lot and especially when on drives. It helps we never allowed screens in the car and he’s just bored, which is good. But he notices all the things around places we frequent and also likes to look at the GPS screen and tell what every indicator is. I don’t know what my point is other than maybe some people just find it more interesting and try harder / practice more from an early age ? reply trappist 4 hours agoparentI have often been described as oblivious (I prefer \"focused\") and I have yet to encounter someone with a worse sense of direction/orientation than mine. I could tell endless funny stories about how bad it is. OP mentions a study involving navigating within a game, and I have the same problem in games. I simply cannot learn my way around a \"map\", as far back as Doom and still today. I can eventually learn specific routes, and eventually enough of these that I can perform reasonably well, but I don't form a mental model of the map even if I've played it hundreds of times and even if it's relatively small. But I can follow directions, and I did passably well at military \"land navigation\" using a map, a compass and a protractor. I would love to better understand why this is. My best guess currently is that \"oblivious\" is quite important - I've tried, many times, to start noticing landmarks so that I could use them later to get to a place without GPS or directions, but I always find myself having missed everything, or having \"forgotten to notice\" anything. My mind wanders, I guess. reply cinntaile 3 hours agorootparent> But I can follow directions, and I did passably well at military \"land navigation\" using a map, a compass and a protractor. Then your sense of direction is quite alright. reply quartesixte 4 hours agoparentprevI am like you. I grew up without screens, and grew up spending a lot of time in car trips. I remember distinctly being keenly aware of my surroundings out the window, and playing games with my parents on how many exits I had left before we got off the highway. In amusement parks, I was charged with the map and navigating to the next ride (a six year old!). Now, whenever I travel to a new place, I at the very least make sure to track the journey there so I can, by memory, journey back the same way. I make note of any distinct landmarks along my route, and pay attention to the logic of the local connecting roads, in case I must detour. I then compare that against any heuristics I have about city planning and my initial preview of the area on a map. The trick is that this is all rather effortless and intuitive, if not instinctual. I wonder if my habits as a child, and my parents’ reinforcements of said habits, made it so. reply hilbert42 5 hours agoparentprevI'm good at navigating also, I put this down to being out in the mountains, on trails and such as a young kid. I come from the southern hemisphere so I discovered I needed to re-orientate myself when I first went to the northern hemisphere which didn't take long. I recall being in New York and for a day or so I found myself walking 180° the wrong way - going north when I was supposed to be heading south, etc. Obviously I'm navigating by the sun or the brightest part of the sky. It wasn't until I was first in the northern hemisphere that I realized this as back home I was doing it automatically without being aware of the fact. reply stouset 4 hours agoparentprevAs a counterpoint I’m constantly focused on other things than what’s in front of me. I’m often absorbed in my phone or thinking over some problem in my head. But I can almost always instantaneously orient myself as long as I started out oriented or have even a vague sense of the geography of an area. I just “know” which way to leave an elevator or train station as long as the layout and exits are sensible (NYC is sometimes hard, Paris is often impossible). Even if I’m mentally focused on other things. reply madaxe_again 3 hours agoparentprevDitto. I find it really hard to understand how people get lost - it’s like “well, how did you get here?”. As a small child I would take myself off on excursions, often through deep snow in woods with bears and wolves, or in a post-industrial waste filled with lord knows what hazards - but getting lost was never even something which occurred to me, even as I’d set off off trail, as I would just know that home is that way. I apparently wandered off by myself in Hong Kong aged 2, miles from home, only to then successfully get the right tram back with a backpack full of booty I’d collected on my adventure. My poor parents I think became numb to it after a while - although the time in the alps had helicopters and all sorts when I nonchalantly turned up back at my grandmother’s a few hours later. My kiddo seems to be the same. She’s all of 14 months old and can navigate her way through forest from A to B, and isn’t shy about taking a short cut rather than following the path. My wife is having kittens. For me, it’s “yes this is what children do as I recall”. I honestly can’t say if it’s nature or nurture - I can’t recall ever learning to navigate, and she seems to just have an excellent sense of what is where from the get go - she’ll set off in a seemingly random direction, I’ll follow her, and we’ll end up at her favourite pond, or by the mint beds, or at the truck, within which she’ll then be like “ok now you drive and I’ll scream if you turn the wrong way, we’d better be going to see auntie Maria”. reply FiatLuxDave 19 hours agoprevOne thing I don't see mentioned as a hypothesis for a factor in a good sense of direction is inner-ear ability (directional proprioception). A few years ago I met Buzz Aldrin at a NASA conference, and he told me that he thought that people with a poor innate direction sense make good astronauts, because having good directional proprioception tends to lead to serious spacesickness. The UCL game study would miss this because people can't use bodily cues when navigating online. VR sickness is quite related to this. Anecdotally, my mother had a balance disorder, and could get lost very quickly in even familiar surroundings, while I get motion sick quite easily but have very good direction sense. reply Red_Leaves_Flyy 8 hours agoparentCounterpoint. I have excellent directional ability whether blind hiking through an untraveled forest, paper maps, or plotting a course. I also do not suffer any form of motion sickness on land sea or in air. Haven’t been to space but would go in exchange for being subject of an experiment so long as I can take pictures and return to earth safely. reply jemmyw 13 hours agoparentprevI wonder if this applies to me. I never learnt navigation skills but I have a very good sense of direction and I'm also very quick to motion sickness in games and on boats. I actually consider it to be slightly dangerous that I'm over confident about where I am and the direction I'm facing. It has led to be marching down the wrong track, not realising I'm on a parallel path that then sightly deviates. reply SkyPuncher 18 hours agoparentprevThis is really interesting. I have amazing directional awareness in real life, but the literal worse in video games. reply emmelaich 10 hours agorootparentZork drove me nuts in this way. I have a good sense of direction and maps but I never put the map of Zork together in my head. reply quickslowdown 15 hours agorootparentprevSame, my friends get frustrated playing Minecraft or other large open world games with me because I'm constantly lost. We walk 30 seconds or so away from the base and suddenly I'm turned around and have no concept whatsoever of which direction I came from or how to get back. Which just doesn't happen to me in real life reply chasd00 8 hours agorootparentHeh my kids ever so gently asked me to stop gaming with them because I was perpetually lost in open world games or so bad in a gun battle i contributed negative value to the team. reply hobs 13 hours agorootparentprevIt's definitely a skill different to the physical one though, and one that needs plenty of practice - mapping your virtual world and keeping a running tally of all the objects and things you literally cant see except through a tiny box is not something that comes naturally to most. reply yzydserd 3 hours agoprevI lament the vast reduction of street signs, at least in my country, that can be used for navigation. Like a sign that says to turn left for City X 15mi away. These used to be ubiquitous- you could get between city A and B through those signs alone. Sat Nav means there is vastly less need for signposting routes between major towns or landmarks. Growing up before sat nav, even as a child passenger, these signs helped me build a mental model of what was where and possibly train an early sense of direction. When my kid was young I’d frequently ask them to draw to scale on paper the mental maps they have of where everything in their world is. I reckon this helped form their sense of direction. If you have a youngster and not tried this then give it a go, it’s illuminating. “Point to where you think X is” also helps train a kids sense of direction through feedback loops. reply beAbU 2 hours agoprevI recently moved from the southern to the northern hemisphere. My (subjectively) good sense of direction and spatial awareness was _completely_ thrown off, and it took me about 3 months to reorient myself and gain the confidence I had before. All because the sun is now in the wrong part of the sky. reply ggm 7 hours agoprevFor many years I persisted in claiming this ability. Evidence to the contrary required me to say I formerly had it, but i tend to believe it was itself, a false belief. I have a very rich interior model of the world and my orientation inside that model. The problem is the model diverges from reality in matters of substance like the exact meaning of \"left\" and \"right\" based on my current frame of reference, who I am speaking to, how flustered I am, and especially if I think I am holding or viewing the map upside down, evidence to the contrary notwithstanding. reply twodave 10 hours agoprevI’m pretty good navigating when I’m alone. If anyone else is in the car it’s like I’m on autopilot to “wherever my subconscious would like to go today.” So I use the GPS just to snap me out of it so I don’t miss turns. reply parasti 18 hours agoprevI largely credit my spatial awareness to studying maps and also learning levels in Nexuiz (the original Nexuiz, a Quake-like video game) and how teleport entrances/exits are oriented. That felt like learning a skill that at one moment just clicked and I haven't lost it since. reply yazzku 18 hours agoparentThat and the minimap in Diablo 2. Some people can't tell left from right anymore when the car is pointing South. reply eszed 17 hours agoprevOne game I've played with myself whenever I've moved to a new area is to drive or walk until I've felt irremedially lost, and then break out the map or GPS to get back home. (I remember once or twice trying it with random dice rolls at intersections, but this didn't work as well as taking the least-familiar or most interesting-looking choice.) It's a great way to discover places you'd otherwise never visit, and is a fantastic way to give yourself a gestalt sense of the locality. reply UncleOxidant 13 hours agoprevI think those of us who came up before GPS and phones had an advantage in developing a sense of direction (and I'll add here a sense of orientation). I do tend to be aware of the cardinal directions and can generally point them out with reasonable accuracy when asked. Unfortunately, when I give people directions I tend to say \"Just to the East of such & such\" or \"Go south from there\" and people kind of give me a blank expression (especially younger folks who haven't navigated without a phone/GPS) and I have to figure out a different way to describe the orientation. To me it makes sense, but giving cardinal directions seems to be making less sense to people. I think the other (related) aspect to this is being able to find some place again after you've been there once. Usually I don't need to consult a map to find a place if I've been there once, but I know people who find this difficult and will continue to consult online maps even after they've been somewhere before. So someone might ask me \"how do I get to that place\" and I'll reply, \"we were there just last month - same place\" and then I have to remember that not everyone is able to find a place they've only been to once before. reply vsuperpower2020 12 hours agoparentIt's probably not a blank stare. Most of the time young people don't actually want non-GPS directions and are just being polite while you finish talking. reply mewpmewp2 9 hours agorootparentYeah it is totally this. If someone is giving me directions like that, I am thinking, \"why on earth are they doing that?\", and waiting to be able to grab my phone. reply Scrapemist 6 hours agorootparentThen why ask for directions in the first place? reply krisoft 48 minutes agorootparentUsually the situation is that we ask for an address, and get told directions instead. reply Shadowmist 5 hours agorootparentprevNobody asked. reply angiosperm 12 hours agoparentprevThere are languages that have no relative directions. You never \"turn left\", you only \"turn south\" or whatever. People who grow up with one of those as their first language all have absolute direction, even two-year-olds. If their boat overturns at sea in a storm, they will never doubt whether their boat blew away to the north or south. Everybody has to get it right just to be able to speak with comprehensible grammar, just the way you need to know what is past or to come. reply mewpmewp2 9 hours agorootparentWhat are some languages like that? Also does this ability mean they might have any beyond random ability to tell north and south when they were dropped to a new location, being blindfolded before? I assume there are hints like sun position depending on the day, so that could help them. reply defrost 9 hours agorootparentSeveral [1] (of many in total [2]) of Australian indigenous languages - although all native speakers tend to have exceptional spatial orientation. Also, traditionally they're territorial over large areas (eg: quarter the size of the UK) but over the course of a lifetime commonaly travel all corners of tat area - \"randomly dropped\" means they'll recognise vegetation, landforms, spot shadows, see water flow trace on the ground from up high looking out .. all the natural world things that orientate people who live there in the same manner as (most) urban people navigate cities; major freeways, tall buildings, changing architecture styles from region to region. [1] https://en.wikipedia.org/wiki/Guugu_Yimithirr_language [2] https://mgnsw.org.au/wp-content/uploads/2019/01/map_col_high... reply mewpmewp2 9 hours agorootparentBut I guess if they were taken from there and dropped somewhere in the northern hemisphere they would fail? reply Taniwha 6 hours agorootparentDepends - as I learned when I moved to the US at least some of my mental maps are based on where the sun is in the sky (and the sun and moon are upside down there) took me a few months for it to all turn around in my head, there are still parts of the first places I visited which are backwards in my mental maps 40 years later reply defrost 8 hours agorootparentprevIn the sense of not knowing where they are in (say) germany, a country they've never visited, then \"yes\" they'd \"fail\". They might even have to resort to pulling out their iPhone and ringing a relative who's living in Germany. In the sense of not being able to survive in a Mexican desert if they were originally a desert dweller .. then I suspect they'd get by - ditto coastal, river, forrest, dwellers. Survival skils transfer well enough across known similar habitats, a western desert nomad would be on the tough end of a learning curve in Alaska. reply mewpmewp2 8 hours agorootparentI mean that they would lose ability to tell where is north. Because theoretically, but probably not in practice they could have some sort of magnetic sense like birds are thought to have so it would translate beyond hemispheres. But unlikely since they never needed cross hemisphere ability. Also haven't heard of people developing a magnetic sense so far. But I do think some mammals may have magnetic sense so maybe... I specifically meant fail as in ability to determine north, not survival, put down or any sort of other negative reason to be clear. reply defrost 8 hours agorootparent> I mean that they would lose ability to tell where is north. You're aware, I trust, that the sun rises in the east and sets in the west, regardless of hemisphere? FWiW this isn't a theorectical \"what if\" .. right from the get go Europeans were taking southern hemisphere indigenous people to the northern hemisphere: https://australian.museum/about/history/exhibitions/trailbla... https://www.nma.gov.au/defining-moments/resources/aboriginal... reply datascienced 9 hours agoparentprevIf it is not urgent I like to get lost without the GPS and use it as a backup. Then I learn where stuff is! reply delfinom 10 hours agoparentprevI know plenty of people who are at the age they should have learnt to navigate without phones and they still suck at direction. It could just be a problem just like how 4% of the population have no ability to visualize mentally aka aphantasia reply luma 11 hours agoparentprevThe poster you’ve replied to mention that they are 53. They for sure learned to drive and move around the world for a couple decades before consumer GPS navigation solutions were affordable for hobbyists. That post resonated with my own life. I had a passenger seat full of atlases, then later mapquest printouts, then some of the early handheld GPS solutions as soon as I could afford them. As they mention, it isn’t something that seems to be learned later in life, for me I rely on GPS because I’m hopeless without it. reply yzydserd 3 hours agorootparent> The poster you’ve replied to mention that they are 53. They for sure learned to drive and move around the world for a couple decades before consumer GPS navigation solutions were affordable for hobbyists. Garmin portable units like the Street Pilot were available in 1998 for 400usd when the 53 year old would have been 27 years old. reply lolinder 11 hours agorootparentprevYou're replying to a top level comment that's presumably responding to TFA. The comment you're referring to is here: https://news.ycombinator.com/item?id=40026374 reply konstantinua00 10 hours agorootparentwebsite navigation is also a skill, apparently reply 8organicbits 11 hours agoprevYou can score yourself on the quiz mentioned in the article here: https://hegarty-lab.psych.ucsb.edu/node/226 reply addminztrator 19 hours agoprevPeople keep telling me to get lost but I never do... I really need to learn this skill reply alwaysrunning 19 hours agoprev\"the unique experiences each person accumulates as their life unfolds. Good navigators, it appears, are mostly made, not born\" As the self proclaimed worst person in the world with directions, I can vouch for this. I was never taught how to find north, south, east, west as a kid, was never told to pay attention to landmarks on your way somewhere, never told to pay attention to street names, so on. And as a ultra runner my wife actually stopped coming to my races for a while bc you are expected to arrive at the next aid station around a certain time and if I wasn't familiar with the area I would get lost and she would worry that I was killed by a bear or smth. Since the advent of GPS on your wrist and such I don't get lost nearly as much. I honestly liked getting off course, being somewhere and seeing views most of all humanity would never see. But I still fail the test of 'point towards the lake' from sitting on my own couch. I can't quite make the connection in my mind, like driving I can't quite map out the entire route and often get streets confused. reply bongodongobob 12 hours agoparentThat's wild to me. I don't know how you wouldn't pay attention to those things. No one told me to pay attention to landmarks, I don't understand why you wouldn't. Very interesting. reply mewpmewp2 9 hours agorootparentI don't because it is hard to pay attention. I have always something else I am thinking about and it overrides ability to look at buildings or landmarks. I have to put in a lot of effort to intentionally look at buildings and memorise them. But also I wonder if somehow I care less about the buildings. When I am travelling and visiting landmarks or sights it just seems like something I do because everyone does it and people reacting to it seems like they just do it to react. I guess they do feel something. But I don't see much difference compared to being myself there vs what I could also see in Google images. So it always feels to me as if people are hyping up the fact of themselves being there. I do enjoy the sun and hot climate though so I like travelling for those reasons. Sure, I could go into thinking how awesome those landmarks are and the history, how they were built, but I feel like I have other things to think about as well. reply krisoft 30 minutes agorootparentBtw landmarks in the navigational sense are not the same as landmarks in a tourist sense. A tourist landmark would be “the grand canyon” or the “eifel-tower”. A navigational landmark is something like “a scrawny bush which seems to have grown leaning on that big rock with a flat top”, “the 3 story building where the middle level had a fresh coat of paint on the corner window frames”, or “corner of a park where 3 roads meet, and one of them has a deli with the picture of a prawn in the window” reply rossant 5 hours agorootparentprevSame here. I get lost all the time. I always forget to make attention to landmarks and surroundings. reply masklinn 3 hours agorootparentI also get lost all the time. When I pay attention to landmarks they don’t “stick”, and neither does travel time. I’ll have vague recollections, but as often as not they’ll cause issues because I’ll vaguely recollect at the wrong location. GPS has saved my bacon time and again. reply bongodongobob 7 hours agorootparentprevNot sure what you mean. I just mean \"ok here's the McDonald's, the turn is coming up soon. Ok yup it's a right, there's the red building it's just past that.\" reply freitzkriesler2 18 hours agoparentprevI was never told any of that either nor was I taught that in any capacity in school. However, the key difference ive noticed is being in the moment IE paying attention to your immediate environment and not getting lost in thought (or phone) that differentiates those who have an intuitive sense of direction versus those that don't. With that said, I don't feel comfortable when I don't know which way is north so I always try and figure that out first. reply shitter 18 hours agorootparentI think this is it for me. Since I was a kid, I’ve always gotten lost in thought when walking around and don’t readily absorb my surroundings as a result. Even when I actively try to do so, it’s still hard to navigate because my brain isn’t well-trained to think that way. reply parpfish 19 hours agoprevwhen I lived in a city with an underground transit system, it was interesting how my mental map developed in a non-contiguous way. I’d learn lots of little disconnected areas around each transit station. But it would take a long time to learn how all those little maps would relate to each other. And each time I started realizing how two of those little “islands” were related by streets on the surface, my initial reaction was always disbelief. in my mind they were each distinct little areas and it didn’t seem possible that you could just walk from one to the other reply life-and-quiet 19 hours agoparentThis is such a great description of learning in general. You get pockets of information, and then BAM suddenly you can see how they relate. reply rnewme 19 hours agoparentprevI had the same experience. Even walking the same street down from one side during night and then adjacent during the day, not realizing it is the same place for weeks. The one day I had most mind melting moment xd reply marcosdumay 18 hours agorootparentIMO, living in neighborhoods where the streets are not organized in a grid is the most disorienting thing. You suddenly discover that those two places, that need completely different routes to get into are right at the side of each other. And you do that again and again, at completely random places. reply KptMarchewa 12 hours agorootparentThat's rather a description of a tendency to cut neighboring areas, rather than grid system. There's plenty of places in the world where places close to itself are close to travel between. reply senkora 19 hours agoparentprevThis is why I love doing long runs in the city. It helps me connect all the little islands in my mind together. reply the_sleaze9 8 hours agorootparentI got a great tidbit a long time ago, whenever you move to a new city and want to get to know it, start training for a marathon. You'll know every nook cranny and hole-in-the-wall in no time. reply ghaff 18 hours agoparentprevAs an undergrad that was so me with Boston/Cambridge which, in many cases, I saw as T stops that were not really connected at street level. I still remember one time I made 2 line changes in downtown Boston, walked about a block, and realized I was back where I started :-) reply tetha 19 hours agoparentprevI was about to say exactly the same thing. Early one, a city kind of feels like an old school point and click adventure. There is train station x, and to the left of one exit is this location, to the right of that exit is that location. But eventually there is that realization: Oh wait. 15 minutes down this street is that other train station. 8 minutes down that street is a bus line which connects to the line going home. It's a bit of a rush to make these connections. And that in turn opens up interesting options. I could just walk with people I've been hanging out with at a concert, because I'll just know how to get back home. Or from some venues, there is good food nearby so you grab that and eat while walking somewhat towards home for 20 minutes on a sunny evening. reply dasil003 18 hours agoparentprevWhen I moved to London the fact that cycling was my primary mode of transportation meant I quickly learned the overall distance and distribution of common destinations and landmarks in central London to a much greater depth than many acquaintances who had lived there for years. reply zabzonk 18 hours agoparentprevthe london tube map is a classic of this - the map is all about how to navigate the tube system, not about distances above or below ground. i moved to london about 40 years ago, and it took me a while to work this out. reply chiph 19 hours agoprevThe article focuses on latent ability. And goes somewhat into the classification of people who use direction vs. those that use landmarks to navigate. There's a graphic in the article with four maps drawn from memory by different people. They say that #1 is perfect and that #4 is bad. As a programmer, I see them as connected graphs and that both are nearly a match to each other. But #4 has a different orientation and doesn't show curves in the road. But IMO it would still allow you to get to the locations marked if you turned the paper as you moved. There are also people who have lost their sense of direction due to injury. I had a neighbor who could not go to the supermarket by themselves because of brain damage (from a car accident). They were totally reliant on a family member - or later a GPS unit just to travel as little as 3-4 blocks. reply jprete 19 hours agoparentUnfortunately, you've completely missed the point of the four drawings - seeing whether the drawer could identify and use likely routes that they weren't shown. If map #1 is accurate, then I can turn right when I get to the tree and take a shortcut to the brick wall, or cut across from the lamps to the green box without going through the four-road crossroad. Map #4 will be misleading at best for understanding the whole area - if I try a shortcut from that map, I'll either get to the wrong destination or leave the original area and be totally lost. reply jeffbee 18 hours agoparentprevEverything in map #4 is backwards with respect to left/right turns. reply Scubabear68 19 hours agoprevI’m in my 50’s, so when I learned to drive there was no GPS or phones or anything to help me. I liked to explore and see things, so it all had to be done by maps. So I quickly learned to oriented myself against NSEW and the roads. Later in life I likewise got into hiking prior to GPS being widely available. That really motivated me to be aware of my environment and directions. I am not perfect at it and can get disoriented if I’m not careful, but generally speaking I almost always have a background thread in my head keeping track of where I am and my orientation when driving. This came in incredibly handy a few months ago when my phone died and I was picking up my son at a friend’s house an hour away I had only visited once before. It took a bit but I was able to find the house again with zero electronic aids. reply ghaff 18 hours agoparentI'm more careful hiking but I don't have maps from this century in my car--and don't actually know what is in there other than knowing I have a satchel with some maps in it. I should probably do an inventory one of these days. It's really easy to depend on your phone for lots of things and then not to have a backup plan if it fails. reply jonah 18 hours agorootparent\"It's really easy to depend on your phone for lots of things and then not to have a backup plan if it fails.\" We see this so often in search and rescue. People take off on some random hike they found on an app without charging their battery and without knowing how long the hike will take them. So, sooner or later, it gets dark and they start using their phone as a flashlight which kills the battery on their only navigation device. But, ehh, since they probably don't know how to read a map or orient themselves on it or find their way back to the trail which they invariably deviated from as some point and went ahead instead of turning back. (Also, not a lot of cell coverage in the backcountry anyway and probably didn't cache the maps.) /Rant reply ghaff 18 hours agorootparentI'll take shortcuts on very familiar easy local trails. But anything else, I'll have map, compass, headlight, water, some extra clothing, at least a minimal first aid kit, etc. re: getting dark. I so often see people heading up a trail at 3pm or whatever. Maybe they're just planning to go up a ways but I wouldn't count on it. I've observed that even fairly experienced people can be pretty bad about establishing a sensible timeline. reply tekla 18 hours agorootparentprevPeople are so used to the luxuries of modern life, that even a minor inconvenience becomes life threatening. People go on hikes with no food, a single bottle of water, and its a 13 mile hike up this mountain. Blank looks when I ask \"do you know where you might get more water????\" reply euroderf 17 hours agoprevA software complaint. In mapping apps, why can't I get an indicator of where the sun is in the sky ? Then if there's no landmarks, or I'm at an awful intersection, or whatevs, I can use sun position to get oriented. reply emmelaich 10 hours agoparentI'd also like some sense of zoom. Like graticules of 1k or 10k; they could even change. If it makes the screen too busy, make it just ticks on the edges. reply euroderf 3 hours agoparentprevAlso I'd like an option to keep North at the top unless & until I manually twist the map. Auto-orienting away from North is extremely unhelpful nearly all of the time. reply ghaff 17 hours agoparentprevIf you have a working phone, you have a compass though. There are ephemeris apps for photography but not sure what that adds to just getting oriented with a compass, whether on your phone or a separate mechanical device. reply bqmjjx0kac 12 hours agorootparentIn my experience, the compass can be totally backwards when you're around tall buildings. reply sramsay 13 hours agoprevWhenever I say, \"I probably have the worst sense of direction of anyone you will ever meet,\" people invariably say, \"Oh, me too!\" And I say, \"Really? So you are never surprised by what you see when you walk out of the building you've been working in for 20 years (you know where the exits are, you just can't figure out which exit leads to which side)? When you're sitting in a room in your house you can determine -- within, say, ten or fifteen minutes -- what room is above/below you? You routinely get lost going to places you've been to hundreds of times in your own city? There are perhaps only two or three places you can get to in said city without a GPS receiver, but that's about it. You are never, ever without a compass? Anywhere?\" Really, folks. I've been like this my whole life (I'm 53), and I have no other cognitive deficiencies that I know of. But when people talk about \"mental maps,\" I'm not entirely sure what they're talking about. When someone says, \"Oh, I know a shortcut\" it's always an absolute revelation. Navigating anywhere is like being asked to memorize a 19-digit number. Whenever I hear about greater or lesser abilities with navigation -- and how one might go from lesser to greater -- I always assume they are not talking about people like me. I really feel like I'm truly impaired when it comes to this, and I'd love to know why! reply KptMarchewa 12 hours agoparentI'm the absolute opposite way. One of the stories my parents usually like to tell is when I was like 5 we were in unfamiliar city, they got lost and could not find the car for over an hour ignoring me, and when they finally listened to me I've managed to get them back to the car in 5 minutes. I can easily recollect how to get from points A to B in cities I've been once 5 years ago. reply jvm___ 10 hours agorootparentI have a map in my head of all the roads I've ever been down. Adding to it is a treat, I love adding new roads to it. The limits are that I don't remember all the hundreds of Craigslist pickups I've done. Also, I navigate by always knowing which way the CN tower is relative to my current location, I live within 100kms of it. If we go on vacation the reference location switches to wherever we're staying. reply mhandley 11 hours agorootparentprevI'm like you - my mum and her sister were both infamously bad at navigation, and family stories tell how they got lost driving home from the city centre. Eventually they paid attention to two-year old me standing up in the back seat (this was before cars had seat belts in the back) saying \"it's that way!\". Apparently I navigated them all the way home across the city at the age of two. Now I don't know how much this was exaggerated, but as long as I can remember, I've always had near-perfect navigational skills while my mum is hopeless, so there's probably some truth to it. Given my mum was so bad, even when I was very small, my parents would give me the map to navigate from the back seat whenever we went anywhere new. My father would usually drive, and he was a good navigator so may not have needed me, but sometimes my mother would drive. Either way, I would navigate across the country. I don't know how young I was when we started this, but probably about seven. I always loved maps. Only when I was an adult did I discover that different people thought about navigation in different ways. Most people, it seems, navigate by waypoints. \"Turn left at the Red Lion pub\" and so on. Some people, including me, can navigate by absolute directions - \"go north east, then west\" and so on, and actually think this way. If you ask me which way is north, in the daytime I'm pretty much perfect, no matter the weather. At night or indoors, I'm good, but sometimes can be a bit off - maybe up to 45 degrees. Not sure exactly what I'm picking up from outdoors, even when it's cloudy, but I know I'm completely reversed if I visit Australia, so likely something to do with polarised light. So is it learned? Sure, I got a huge amount of practice when I was young in pre-GPS days. But I could do it at the age of two, so probably there was some capability there from the start. Now I'm in my fifties and use GPS everywhere, mostly for traffic guidance. But I do feel I'm not as good at raw navigation as I used to be. But in the 1980s when I was first driving long distance, I'd stare at a map for a few minutes, and then drive 200 miles across England without needing to look at a map again. For those from the US, in England, 200 miles is long way and a lot of junctions! Not sure I could do that these days, so maybe it is practice. Or maybe I'm just getting old. reply datascienced 9 hours agorootparentprevKids are dumb fallacy right there. Kids are gonna be better at you at some things even from 4 yo! reply akira2501 11 hours agoparentprev> But when people talk about \"mental maps,\" I'm not entirely sure what they're talking about. In the visual theater of my mind I can literally construct a top down view map and place myself in it dynamically. When I want to determine which exit to use, I use this mechanism and then route myself through it. It's something that /seems/ to turn on and off when I need to make the next turn decision, but if I've used it recently, it's easier to recall than it is the first time. For a building, it's typically nailing down the elevator lobby's orientation with respect to the rest of the city around it, then building a smaller mental map from an individual floor that is also referenced to the lobby. If I need to think about how my desk is oriented to larger features in the city, I have to do two orientation and projection steps in my mind. Anyways.. do you think visually or textually? reply mewpmewp2 10 hours agorootparentData point from me. I also think I have terrible ability to remember places or directions. I feel like it is maybe because I am not paying attention to all the details. I would think I am at the very least bottom 5 percent performer. People say something like \"oh we turned from here, I remember this building\". I wonder how they are remembering something like that and why I never do. I feel many of my anxious situations in life have been where I was asked to do something where people expected me to know where to go and I just had no idea. I think textually, but not seeing text, rather hearing it as one continous line of thought and maybe some odd less focused lines of thought in parallel. I had a cognitive abilities test done by a psychologist. Visual memory was one of the worst percentually. The test included I think some sort of drawing with lines and recreating it later in the test after doing some other activities inbetween. Strongest area was abstract logical reasoning. Which was top 1 percent. But my main concerns were memory and why I did the test in the first place. reply nicoburns 9 hours agorootparent> oh we turned from here, I remember this building\". I wonder how they are remembering something like that and why I never do. My memory is primarily visual such that I can replay a video like experience in my head of a lot of events. This extends to things like spellings which I will recall as a visual representation of the word. reply mewpmewp2 9 hours agorootparentHow would you even have the storage room for a video. Not doubting, but just crazy to think for me. It probably must be some very deeply compressed video that gets reconstructed from objects from the internal structure somehow and then perhaps constructed runtime, meaning it won't be the same everytime. reply mixmastamyk 8 hours agorootparentNot like a recorded video, more like a video game, drawn on demand with vectors ;-). reply eru 10 hours agorootparentprev> Anyways.. do you think visually or textually? What about verbally? reply akira2501 10 hours agorootparentI can't speak to that. I guess that might be owing to how visual my thinking is, I perceive verbal thinkers as reading a book in their mind, which I only now realize is a terrible metaphor. reply mewpmewp2 9 hours agorootparentOne maybe a stupid question. If your thinking is visual, wouldn't you have to close your eyes to be able to think? Or how can you still see? Is it like augmented reality? Actually since I think, I think by hearing a continous record of text, when I do that, it does make it hard to listen to people. I have to attune that record exactly to what people are saying and it is something I have had challenges doing my whole life. Then I have to fight, put effort in, to be able to keep it on track. I prefer watching films with same language subtitles for that reason. Then I read the subtitles and doing that my thought track is somehow in sync. But it is impossible to keep the thought track in sync with realtime voice. I could only repeat it out of sync. If people had subtitles, on top of their heads as they were talking I could pay attention much better in social situations. reply eru 8 hours agorootparent> If your thinking is visual, wouldn't you have to close your eyes to be able to think? When I think verbally, I don't have to use ear plugs to think. Though very noisy environments make it harder. When I think visually, I don't have to close my eyes to think. But visually noisy environments make it harder. I guess that's (part of) why people sometimes stare off into space when deep in thought? reply nicoburns 9 hours agorootparentprev> One maybe a stupid question. If your thinking is visual, wouldn't you have to close your eyes to be able to think? Kinda like multiple monitors on a computer. It's possible to see both at once. I do often do my best sleeping in bed at night with my eyes closed however. reply mewpmewp2 9 hours agorootparentBut with multiple monitors you have to look at one at a time, and if you do that you won't see the others? So if you are focusing on a visual thought shouldn't you be unable to see the real world? Or you are kind of zoomed out far enough that you do, but then you are seeing it side by side with real world? But still then are one of those things more blurry depending on where you focus exactly? It is fascinating to try and understand it. It doesn't feel like I can relate to it at all or see how it is possible. reply mixmastamyk 8 hours agorootparentPeople have talked about a disorder? where folks can’t picture things in their mind. Believe called aphantasia. https://en.m.wikipedia.org/wiki/Aphantasia reply teaearlgraycold 8 hours agorootparentprevFor me it’s very similar to the 3D maps in games like Doom (the one from 2016) or Deep Rock Galactic. reply Tagbert 8 hours agoparentprev'But when people talk about \"mental maps,\" I'm not entirely sure what they're talking about. ' For me, knowing where things are in the space around me or in the larger navigation zone is like knowing where the parts of my body are. After spending just a little time in a space, it all feels like one thing and I can mentally point to various places within that space. I can still get turned around if I have been going through multiple corridors inside with no visibility outside, particularly underground and particularly if some of the corridors are slightly off of rectilinear. Then I can come out thinking I am facing south and it turns out to be east. However, the next time I move though that space, chances are it will all connect up in my mind and then I will know where I am and which direction is which. My husband is a little more like you. When we exit a building, he will seemingly choose a direction at random. It almost seems like he kind of gets it but backwards and almost always goes the opposite direction. He is not as far off as you. He can learn to navigate familiar spaces but it takes him a long time. reply bqmjjx0kac 13 hours agoparentprevI am also like this. I had a fight once with my SO where they were upset with me for not trying to level up my navigation skills. I have a growth mindset about many other things, but I've just absolutely given up on navigation without a smartphone. I also have a hard time recognizing faces of celebrities, but not people I know in real life. From reading about prosopagnosia and other agnosias, I suspect there's something funny with my fusiform gyrus. reply mhandley 10 hours agorootparentI have a hard time visualizing things when I'm fully awake. Ask me to picture my wife or my kids' faces, and I can't do it. I feel I can subconsiously visualize them with no problem, but as soon as a try to consciously do it, the picture disolves. Same with any fully awake visualization - can't quite see the image in my head - it's like it's in my peripheral vision but scoots away as soon as I look. But I can lucid dream, and do things like complex 3D mechanism design while lucid dreaming (that I can later turn concrete using CAD). Anyway, I have no problem with navigation - I can look at a map, and navigate from the (non visualizable!) memory for ages (an hour if hiking, maybe several hours if driving), and pretty much always tell you where north is. But I still cannot bring the image of the map back into my conscious mind. The brain is a very weird thing indeed. reply mewpmewp2 10 hours agorootparentWhat does visualisation of someone face even mean. If I have to ask that does it mean I have aphantasia? I don't think I have it, but I don't know. Like are you seeing colors in your mind eye, because surely visualization should require it. I am definitely not seeing any colors. reply koyote 8 hours agorootparentprevCounter data point: I am an excellent navigator but can't recognise people I know on the street, even if I know them reasonably well. If I know I will be meeting them, and I know them well I mostly recognise them but even then I am sometimes surprised when they show up and say hello to me. Celebrities is even worse... (Good) navigation is not really about recognising landmarks (although that helps) but about having a mental version of the map of the place you are in, with you in the centre. Think of it like the GTA mini-map that live updates as you walk around. I think that comes naturally to some people and just does not exist for many others. reply erwinmatijsen 12 hours agorootparentprevI've always linked my inability to navigate to my inability to visualize things in my head. Even in the area where I've been living for about 15 years now, I still struggle to determine routes if I don't travel them very regularly. This afternoon, we drove to a place in the city nearby. By now, after so many years, I can guess which exit to take, but I don't know whether to turn left or right at the end of the exit until I'm at the end and recognise it from previous times I've been there. But I can't picture it in my head beforehand. reply neRok 10 hours agorootparentI also have aphantasia but can navigate just fine. I read a comment on here once from someone with aphantasia that couldn't navigate in the real world, but they worked in network admin and knew that layout just fine (knew where everything routed and what it connected to etc). I pondered that if they could remember cable routes, why don't they apply the same mental map to roads? Roads are fixed and have a beginning and end too! But they reckon they could not. So it's a strange problem. reply mewpmewp2 10 hours agorootparentI think the challenge is relating your current locatiom in a 3d environment to a top down 2d map? The 3d environment is full of noise and info which is a lot to take in while something like routing is very simple, and you don't have to convert your own placement in 3d map to 2d. Also routing likely has good intentional reasons why something follows the other. While roads have evolved more naturally throughout history. reply koyote 8 hours agorootparentprevCounter data point: I am an excellent navigator but can't recognise people I know on the street, even if I know them reasonably well. If I know I will be meeting them, and I know them well I mostly recognise them but even then I am sometimes surprised when they show up and say hello to me. Celebrities is even worse... reply 7thpower 12 hours agorootparentprevAre you me? If I had been born 15 years earlier, before GPS nav, you would not be reading this because I would be dead in a ditch somewhere. reply datascienced 9 hours agorootparentprevI can’t remember faces of people I see say 4 times a year and who are not friends. A random parent at the school for example. reply lesuorac 8 hours agoparentprevWell, people with Aphantasia [1] don't have to have poor navigation sense. You could try to study a map of an area you want to be in and think about where you were on it one day and where you wanted to go to. [1]: https://en.wikipedia.org/wiki/Aphantasia reply pesus 8 hours agoparentprevI'm not quite as bad, but I'm still pretty damn bad. If you're a 10/10 on the bad-at-directions scale, I'm probably at a 7- 7.5. Any chance you have ADHD or anything along those lines? reply fouc 4 hours agoprevI think the interesting litmus test for having a good sense of direction - or at least one form of it - is being able to successfully navigate by car while driving, to a destination they originally saw 20 years ago, as a 10-year old car passenger. And that's for a city they hadn't driven in before. reply jerjerjer 7 hours agoprevGPS and map apps nerfed noticeably my ability to navigate-in-my-mind and a sense of direction in general. I wonder if it's a loss of a skill or just me getting older. reply spacecadet 13 hours agoprev\"Internal GPS\" here, but grew up navigating the deep Maine woods. Also spent time navigating a single engine over the Alaskan bush and various rally/overland races. I really like navigation, dead reck, etc. It aint wrong, takes alot of practice and interest in navigation to become fluent. reply eternityforest 11 hours agoprevI have no idea where I am, ever, unless I've been there literally a dozen times. Even then it's not a guarantee. If I wasn't actively paying attention I won't just passively pick up knowledge about the route. One of my personal rules is to treat rotation as if it's an ultra complex operation only computers should do. I won't even try to read a map that's not oriented to match reality, and I will assume I got the map upside down unless I have multiple references points to confirm(Phone compasses seem to mess up more than the actual GPS...). I also regularly confirm direction by making sure the GPS says I'm actually going towards where I think I am. I will check the map again after every turn, I assume that any rotation invalidates whatever nonsense I think I know about where I am. If it's unfamiliar enough that I even think about using a map at all, I am very careful because of how many times I've gotten lost a block or two away from my destination and wound up going half a mile the wrong way following upside down maps. This extends to other areas of life. If I have to compare any two things in different orientations I assume it's a high failure rate part of the project. One would probably assume this causes me a lot of mental discomfort... but luckily I also have maybe a bit too much trust in computers. I can always just use my phone. If it ever runs out of battery I can ask for directions. If I ever decide to solo hike or something like that, I will probably get a book on navigation and study as best I can, but also bring a satellite beacon. reply majmanhn 19 hours agoprevTIL about orienteering- seems fun! Also interesting (and maybe intuitive) to see reliance on GPS correlates with diminished navigational skills. reply emmelaich 9 hours agoprevNot sure if related but I often imagine a map of concepts when trying to understand or remember things. Linux kernel, software skills, career progression. All maps. reply yoyohello13 19 hours agoprevI would say I’m a good navigator. I credit my ability to easily navigate around cities to playing 100s of hours of GTA as a kid. reply post_break 18 hours agoprevI’m very good with knowing where I am and where I’m going. It’s like a sixth sense compass I have built in. I don’t know if it was learned or what but at times it feels like a super power. Grew up without GPS but did start driving around the time it got good. reply ninetyninenine 19 hours agoprevThey should also correlate navigational ability with IQ. If such a correlation exists or doesn’t exist says a lot about navigation. An informal test: Are there any really smart people here with credentials and credibility to prove it who are also complete garbage at navigation? reply eightys3v3n 18 hours agoparentAwesome and productive suggestion. :D It seems we already have one piece of evidence but I would add: Often the people who live in the middle of nowhere are not thought of as smart, but they can drive or walk 10s or 100s of km through the wilderness and get to their destination. While those working high paying jobs in a city often use a GPS to drive anywhere off their usual route and never use any roads outside the main roads that are familiar to their route. I for example, can completely avoid rush hour going with the direction of rush hour, by taking a different road. This wouldn't work if most people in the city were good navigators (assuming they cared of course, but I would argue good navigators way-find more creatively even when they don't care much). reply rossant 5 hours agoparentprevI have a PhD and get lost all the time. GPS makes it a bit easier, although I always have to walk a few seconds to check my direction by looking at the movements of my GPS position. reply gherkinnn 13 hours agoparentprevAnecdotally speaking I see no pattern. I can't see IQ predicting whether one gets lost in a telephone box or not. What I have noticed is that basement and lab dwellers are hopeless at navigating. reply julian_t 17 hours agoparentprevMy wife has very poor navigation skills, but is currently completing her second masters out of six degrees. So pretty smart, I guess. But she's also really dyslexic, and we've wondered if that could have anything to do with it. reply neom 13 hours agorootparentFWIW: Never met a dyslexic bad at navigation, your wife is the first I've heard of and I ask every other dyslexic I've met. I'm extremely dyslexic and extremely good at navigating. Look at Google maps once and generally don't need to again, I just keep the mental image of the map in my head. Can she hold the mental photo of the map? Does she mixes up her left and right? Does she also have dyscalculia? reply kevinventullo 19 hours agoparentprevI have a PhD in pure math yet rely on GPS for navigating all but the most familiar routes. reply latency-guy2 18 hours agorootparentI also maintain a PhD, not in pure math, I know which direction I am facing at all times and can navigate without explicitly referencing a physical map. How close are we to developing a representative sample? reply dschroer 18 hours agoparentprevMy partner is a medical doctor. She can't navigate around. I don't think there is any link. Navigation was something that I was taught early and is a skill like anything else. reply wolverine876 10 hours agoparentprev> credentials The more common stereotype is a negative correlation, nerdy smart people getting lost, unable to dress themselves, etc. I say 'stereotype' because that word very strongly correlates with BS. Still, I expect a negative correlation to intellectual credentials: Those take a lot of work doing things that usually don't involve navigation. Anthropologists I expect to be pretty good at it, and archaelogists and architectural historians are probably awesome. MDs, mathematicians - sorry. reply bqmjjx0kac 12 hours agoparentprev> Are there any really smart people here with credentials and credibility to prove it who are also complete garbage at navigation? Anecdatum: I think I'm smarter than the average bear. I have an MS and work at a FAANG. However, I'm absolute shit at navigation. Last month, I hung out with a friend who is similarly bad at navigation and we lost the car for 15 minutes. reply at_a_remove 3 hours agoprevIf I am going somewhere unfamiliar, I do use a map ... but only to make directions that I internalize beforehand. I believe that this mental exercise improves your sense of direction and general orientation. I don't merely do a \"turn here onto Route X,\" rather I note if I will be passing a particular road on the left, if I will be going through a town, and so on. My turns are always in the \"left/east onto,\" including both my personal orientation and world orientation. It is a little time-consuming but there is an eventual payoff. reply VoodooJuJu 19 hours agoprevI wish it talked more about place-naming, routes, roads, and all that. I can't give you directions to a lot of places because I can't memorize the arbitrary sequence of route 123, then left on 56A, exit 6, then sharp right onto 9. They're just mostly arbitrary, indistinguishable roads. The numbers have some meanings [1], but it's not enough. Routes and roads should be named according to distinguishable landmarks or features, maybe in addition to their number. Birch Parkway better be dotted with birch trees. Cathedral Street better have a big cathedral that rises up above the other buildings. The canyon road flanked with sandstone should be called Red Rock Pass. These names are not only prettier than random numbers, but they're meaningful and useful. Of course places and features change over time, but not that dramatically, and even if they do, just rename them. Constantinople is now Istanbul. We can change the meaningful names, but keep the number IDs. [1] https://en.wikipedia.org/wiki/United_States_Numbered_Highway... reply jprete 18 hours agoparentUS highway numbering was meant for machines, not people - even if the machines of the time consisted of people obeying rules and following instructions. reply tekla 18 hours agoprevSome people refuse to learn. I've always been fascinated that people forget that the sun rises in the east and sets in the west and if you can see the sun, you can have a general idea of where you are going (assuming you know roughly when noon is). Some are just amazed that I can tell where we are going until I remind them I can see their shadows. reply wolverine876 10 hours agoparentTip: Having tried to communicate the same thing, shadows are easier for people to work with. They point precisely in a certain direction rather than 'that big bright ball is over there'. Now coming up with the precise direction the shadow is pointing is trickier but usually people need little precision, maybe the 8 most cardinal directions on the compass. reply JoeAltmaier 18 hours agoprevDefinitely not genetic. Folks in the same close family have diametrically opposed abilities in this line. I blame GPS navigation for a strong dip in talent in this generation. They refuse to show you the map beyond a postage-stamp area in the immediate vicinity. Making it utterly impossible to get your bearings and make good decisions. You become totally dependent on the device. reply ramenbytes 10 hours agoparent> They refuse to show you the map beyond a postage-stamp area in the immediate vicinity. Making it utterly impossible to get your bearings and make good decisions. I didn't realize this until I started using a Thomas Guide in the past year, and then it hit me like a bag of bricks. It's so much easier to (re)orient myself with a properly sized and detailed map. Not to mention I don't have to fiddle with Google Maps to coax it into showing me street names. I don't think Google Maps is very good at actually being a map. reply wcedmisten 18 hours agoparentprevTotally agree on the device dependence. Sometimes I'll navigate a route a few times with GPS and then try to find my way there without it, just to learn the route. I was thinking it would be cool to make an app that helps you learn navigation. Maybe like a game to find your way to a given place, and you get hints if you're off track. reply gedy 18 hours agoparentprevWhile true, I do wonder if there's something more innate. My mother is totally unable to find her way around, but I've always had a keen awareness of directions. E.g. my memories and even dreams include position of things N, E, W, & S reply freitzkriesler2 18 hours agoprev [–] Before smartphone gps, navigation was something I was really proud of having as a skill. I could find my way around town by just landmarks and directions from those landmarks. Nowadays that skill is entirely lost. I recall playing arma 3 and needing to use a map and compass. That was a fun exercise . reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Navigation skills are predominantly influenced by upbringing, experiences, and cultural aspects rather than genetics, with individuals from Nordic regions and rural areas often excelling in this area.",
      "Good navigators demonstrate abilities such as estimating distances, map reading, and constructing precise mental maps, skills that can be honed through practice.",
      "Depending heavily on GPS technology might potentially decrease navigation skills over time; engaging in outdoor activities, exploration, and mental map development are considered beneficial for enhancing navigation competence."
    ],
    "commentSummary": [
      "Navigation skills can vary among individuals, influenced by factors like upbringing, technology use, and cognitive abilities.",
      "Setting navigation apps to \"north up\" mode can enhance one's sense of direction for some individuals.",
      "The discussion explores the significance of spatial awareness, the influence of technology on navigation, and the potential links between intelligence and navigation proficiency."
    ],
    "points": 118,
    "commentCount": 146,
    "retryCount": 0,
    "time": 1713010645
  }
]
