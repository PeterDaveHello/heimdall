[
  {
    "id": 38920043,
    "title": "Polars: A Fast and Versatile Open-Source Data Processing Framework",
    "originLink": "https://pola.rs/",
    "originBody": "DataFrames for the new era 15M+ Downloads to date 21.6k+ Github stars Get Started 01Fast Polars is written from the ground up with performance in mind. Its multi-threaded query engine is written in Rust and designed for effective paralellism. Its vectorized and columnar processing enable cache-coherent algorithms and high performance on modern processors. 02Easy to use You will feel right at home with Polars if you are familiar with data wrangling. Its expressions are intuitive and empower you to write readable and performant code at the same time. 03Open Source Polars is and always will be open source. Driven by an active community of developers. Everyone is encouraged to add new features and contribute. It is free to use under the MIT license. Built by developers for developers to achieve up to 50x Performance Why use Polars Polars was benchmarked against several other solutions on the independent TPCH Benchmark. This benchmark aims to replicate data wrangling operations used in practice. Polars easily trumps other solutions due to its parallel execution engine, efficient algorithms and use of vectorization with SIMD (Single Instruction, Multiple Data). Compared to pandas, it can achieve more than 30x performance gains. Learn more → The benchmark was performed on a n2-highmem-16 with scale factor 10 including IO. The queries are open source. Quick install Polars is written from the ground up making it easy to install. Select your programming language and get started! Python Rust JavaScript pip install polars [dependencies] polars = { version = \"x\", features = [\"lazy\", ...]} const pl = require('nodejs-polars'); Support Support for all common data formats Polars supports reading and writing to all common data formats. This allows you to easily integrate Polars into your existing data stack. Text: CSV & JSON Binary: Parquet, Delta Lake, AVRO & Excel IPC: Feather, Arrow Databases: MySQL, Postgres, SQL Server, Sqlite, Redshift & Oracle Cloud Storage: S3, Azure Blob & Azure File How Polars will make your life easier 01 Easy to use Write your queries the way they were intended. Polars, internally, will determine the most efficient way to execute using its query optimiser. 02 Embarrassingly Parallel Complete your queries faster! Polars fully utilises the power of your machine by dividing the workload among the available CPU cores without any additional configuration, nor serialization overhead. 03 Apache Arrow Polars utilises the Apache Arrow memory model allowing you to easily integrate with existing tools in the data landscape. It supports zero-copy data sharing for efficient collaboration. 04 Close to the metal Polars is written from the ground up, designed close to the machine and without external dependencies. This allows for full control of the ecosystem (API, memory & execution). 05 Written in Rust The core of Polars is written in Rust, one of the fastest growing programming languages in the world. Rust allows for high performance with fine grained control over memory. 06 Out of core Want to process large data sets that are bigger than your memory? Our streaming API allows you to process your results efficiently skipping the need to keep all the data in memory. User guide Discover more in our User Guide Your One-Stop Resource for all information Service offerings Our services, your next step forward Transforming possibilities to solutions",
    "commentLink": "https://news.ycombinator.com/item?id=38920043",
    "commentBody": "PolarsHacker NewspastloginPolars (pola.rs) 831 points by tosh 17 hours ago| hidepastfavorite344 comments j1elo 16 hours agoIt&#x27;s cristal clear that this page has been written for people who already know what they are looking at; the first line of the first paragraph, far from describing the tool, is about some qualities of it: \"Polars is written from the ground up with performance in mind\"And the rest follows the same line.Anyone could ELI5 what this is and for what needs it is a good solution to use?EDIT: So an alternative implementation of Pandas DataFrame. Google gave me [0] which explains:> The pandas DataFrame is a structure that contains two-dimensional data and its corresponding labels. DataFrames are widely used in data science, machine learning, scientific computing, and many other data-intensive fields.> DataFrames are similar to SQL tables or the spreadsheets that you work with in Excel or Calc. In many cases, DataFrames are faster, easier to use, and more powerful than tables or spreadsheets because they’re an integral part of the Python and NumPy ecosystems.[0]: https:&#x2F;&#x2F;realpython.com&#x2F;pandas-dataframe&#x2F; reply anigbrowl 16 hours agoparentYes, it&#x27;s annoying negative feature of many tech products. Of course it&#x27;s natural to want to speak to your target audience (in this case, data scientists who like Pandas but find it annoyingly slow&#x2F;inflexible), but it&#x27;s quite alienating to newbies who might otherwise become your most enthusiastic customers.I am the target audience for Polars and have been meaning to try it for several months, but I keep procrastinating about because I feel residual loyalty to Pandas because Wes McKinney (its creator) took the time to write a helpful book about the most common analytical tools: https:&#x2F;&#x2F;wesmckinney.com&#x2F;book&#x2F; reply jeroenjanssens 8 hours agorootparentRitchie Vink (the creator of Polars) deliberately decided not to write a book so that he (and his team) can focus full time on Polars itself.Thijs Nieuwdorp and I are currently working on the O&#x27;Reilly book \"Python Polars: The Definitive Guide\" [1]. It&#x27;ll be a while before it gets released, but the Early Release version on the O&#x27;Reilly platform gets updated regularly. We also post draft chapters on the Polars Discord server [2].The Discord server is also a great place to ask questions and interact with the Polars team.[1] More information about the book: https:&#x2F;&#x2F;jeroenjanssens.com&#x2F;pp&#x2F;[2] Polars Discord server: https:&#x2F;&#x2F;discord.gg&#x2F;fngBqDry reply baq 8 hours agorootparentSlightly offtopic: it&#x27;s a tragedy that projects like this use discord as the primary discussion forum. It&#x27;s like slack in that knowledge goes to die there. reply theLiminator 7 hours agorootparentYeah one thing that helps a bit is that they try to encourage that you post your questions to stack overflow and they&#x27;ll answer it. reply jeroenjanssens 7 hours agorootparentprevLuckily our book will also be available in hard copy so you can digest all that hard-won knowledge in an offline manner :) reply tonyedgecombe 6 hours agorootparentI&#x27;ll wait until chatGPT can regurgitate it. reply Xunjin 5 hours agorootparentI do understand your \"snarky\" comment humoring, however do buy a copy if you want to support them, it&#x27;s neither cheap or easy to make a book. reply throwmeback 3 hours agorootparentprevlosing all nuance by virtue of getting dopamine quicker? count me in! reply Fuzzwah 7 hours agorootparentprevI often see this comment, and every time I think; but having people come to the information AND the community is better for the project. reply baq 7 hours agorootparentShort term perhaps, but long term having a non-indexed community is inconvenient for newcomers. reply amne 4 hours agorootparentmicrosoft copilot can summarize discussions. with some orchestration it could extract even from past discussions question+answers and structure them in a stackoverflow-like format.source: we use this feature in beta as part of the enterprise copilot license to summarize Teams calls. Yes, it listens to us talking and spits out bullet points from our discussions at the end of the call. It&#x27;s so good it feels like magic sometimes.note on copilot: any capable model could probably do it. I just said copilot because it does it today. reply zknow 1 hour agorootparentprevthere are projects that you can use to index discord servers, unfortunately a lot of communities just don&#x27;t use them. reply thijsn 6 hours agorootparentprevThat&#x27;s why Ritchie is very active on, and often refers to, Stackoverflow as well! Exactly to document frequent questions, instead of losing them to chat history. reply throwmeback 3 hours agorootparentprevby community do you mean all the people who make an account just to ask a question on the project&#x27;s discord, only ever open it to check if someone answered and then never use discord again? reply lr1970 4 hours agorootparentprevThere is a free Polars user guide [0] as a part of Polars project. It was known as \"polars-book\" before it has been was in-tree [1].[0] https:&#x2F;&#x2F;docs.pola.rs&#x2F;user-guide&#x2F;[1] https:&#x2F;&#x2F;github.com&#x2F;pola-rs&#x2F;polars&#x2F;tree&#x2F;main&#x2F;docs&#x2F;user-guide reply bomewish 5 hours agorootparentprevAny plans to try fine tune an LLM specialised in polars? That would really be the killer feature to get major adoption IMO. reply esel2k 4 hours agorootparentprevIs there a book that is even more basic for more junior people in regards to dataframe &#x2F; storage solutions for ML applications to recommend? Thank you reply godelski 12 hours agorootparentprev> it&#x27;s quite alienating to newbies who might otherwise become your most enthusiastic customers.Newbies are your best target audience too! They aren&#x27;t already ingrained in a system and have to learn a new framework. They are starting from yours. If a newbie can&#x27;t get through your docs, you need to improve your docs. But it&#x27;s strange to me how mature Polars is and that the docs are still this bad. It makes it feel like it isn&#x27;t in active&#x2F;continued development. Polars is certainly a great piece of software, but that doesn&#x27;t mean much if you can&#x27;t get people to use it. And the better your docs, the quicker you turn noobs into wizards. The quicker you do that, the quicker you offload support onto your newfound wizards. reply sanderjd 11 hours agorootparent\"Newbies\" to data science are indeed a good target audience, before they are already attached to pandas. But this doesn&#x27;t imply they know nothing. It&#x27;s very unlikely that someone both 1. has a need to do the kind of data analysis that polars is good at, and 2. has never heard of the \"data frame\" concept. reply petre 4 hours agorootparentprevThe docs are okay, but the feature set is lacking compared to pandas, which is understandable since this is at version 0.2. I was exploring if it&#x27;s possible to use this, but we need diff aggregation which it doesn&#x27;t have, so it&#x27;s a no go right now. reply cmdlineluser 3 hours agorootparentDo you mean something like `.agg(pl.col(\"foo\").diff())`?Or is diff aggregation its own thing? (I tried searching for the term, but didn&#x27;t find much.) reply petre 3 hours agorootparentNevermind, it has it but it&#x27;s under Computation in polars.Series.diff and I was looking under Aggregation. This is great.For instance you&#x27;ve got a time series with an odometer value and you want the a delta from the previous sample to compute the every trip. reply theLiminator 12 hours agorootparentprev> But it&#x27;s strange to me how mature Polars is and that the docs are still this bad.Interesting, I&#x27;ve personally found them quite good and compared to datafusion or duckdb they&#x27;re dramatically better. I agree pandas has better docs, but one of the strengths of polars is that I find I often don&#x27;t need the docs due to putting lots of careful thought into designing a minimal and elegant API, not to mention they&#x27;re actually care about subtle quirks like making autocomplete, type hinting, etc. work well. reply godelski 12 hours agorootparentSounds like we might be coming from different perspectives. I honestly don&#x27;t use any DF libraries often, and really only Pandas. I used to use pandas a fair amount, but that was years ago, and now I only have to reach for it a few times a year. So maybe the docs are good for people that already have deeper experience. Because I think just the fact that you have used datafusion and duckdb illustrates that you&#x27;re more skilled in this domain than I am, because I haven&#x27;t used those haha.But I do think making good docs is quite hard. You usually have multiple audiences that you might not even be aware of. Which makes one of the most important things to do is keep an open ear to listen for them. It&#x27;s easy to get trapped thinking you got your audience but you&#x27;re actually closing the door to many more groups (unintentionally). It&#x27;s also just easy to be focused on the \"real\" work and not think about docs. reply sanderjd 10 hours agorootparentWhat, specifically, is bad about the docs? This whole thread is people who just looked at the home page, saw that it is \"DataFrames\", but didn&#x27;t know what that means and came here to complain. Nobody has said anything about issues with the docs for someone who understands what a data frame is (or spent like two minutes looking that up) but is struggling to figure out how to use this library specifically. reply godelski 9 hours agorootparentI think your experience is probably making it difficult to understand the noob side of things. For me, I&#x27;ve struggled with simply slicing up a dataframe. And as I specified, these aren&#x27;t tools I use a lot, so the \"who understands what a data frame is\" probably doesn&#x27;t apply to me very well and we certainly don&#x27;t need the pejorative nature suggesting that it is trivially understood or something I should know through divine intervention. I&#x27;m sure it&#x27;s not difficult, but it can take time for things to click.Hell, I can do pretty complex integrals and derivatives and now so much of that seems trivial to me now but I did struggle when learning it. Don&#x27;t shame people for not already knowing things when they are explicitly trying to learn things. Shame the people that think they know and refuse to learn. There&#x27;s no reason to not be nice.Having done a lot of teaching I have a note, don&#x27;t expect noobs to be able to articulate their problems well. They&#x27;re noobs. They have the capacity to complain but it takes expertise to have clarify that complaint, turning it into a critique. I get that this is frustrating, but being nice turns noobs into experts and often friends too. reply sanderjd 39 minutes agorootparentI really think this is a misunderstanding of the purpose of different kinds of documentation. The documentation of a new tool for a mature technique is just not the primary place to focus on writing a beginners&#x27; tutorial &#x2F; course on using that technique. Certainly, \"the more the merrier\" is a good mantra for documentation, so if they do add such material, all the better. But it is very sensible for it to not be the focus. The focus should be, \"how can you use this specific iteration of a tool for this technique to do the things you already know how to do\".Nobody is suggesting that you should be an expert on data frames \"through divine intervention\". But the place to expect to learn about those things is the many articles, tutorials, courses, and books on the subject, not the website of one specific new tool in the space.If you&#x27;re really interested in learning about this, a fairly canonical place to start would be \"Python for Data Analysis\"[0] by Wes McKinney, the creator of pandas and one of the creators of the arrow in-memory columnar data format that most of these projects build atop now.This is a (multiple-) book length topic, not a project landing page length topic.0: https:&#x2F;&#x2F;wesmckinney.com&#x2F;book&#x2F; reply leksak 8 hours agorootparentprevI can&#x27;t speak for the Python side of the Polars docs but coming from Python and Pandas to Rust and Polars hasn&#x27;t always been easy. To be fair, that isn&#x27;t just about docs but also finding articles or Stack Overflow answers for people doing similar things. reply sanderjd 21 minutes agorootparentThat certainly makes sense! reply anjanb 5 hours agorootparentprevI&#x27;m a dataframes noob. I saw this post and the performance claims attracted me. I went to chatGPT to understand what dataframes were about. Then on udemy, I searched for a polar course. A course required pre-requisites : a bit about jupyter notebooks and pandas. Then I went through a few modules of a pandas course. Now, I&#x27;m going through a polars course. Altogether, I spent about 2-3 hours to setup the environment and know what this is all about.A little bit context would have helped to have attracted a lot more noobs.g reply sanderjd 35 minutes agorootparentYour first paragraph makes perfect sense! I was nodding along. But then your concluding sentence was a bit of a record scratch for me. This all worked as intended! You knew what the project was about - \"data frames\" - and what might make it attractive to you - the performance claims - and then you went and followed exactly the right path to get the context you needed to understand what&#x27;s going on with it. It&#x27;s a big topic that you were able to spin up on to a basic level in 2-3 hours, by pulling on strings starting at this landing page. This is a very successful outcome.I&#x27;d also recommend this book: https:&#x2F;&#x2F;wesmckinney.com&#x2F;book&#x2F;. It&#x27;s not about polars, but you&#x27;d be able to transfer its ideas to polars easily once you read it. reply _dain_ 3 hours agorootparentprev\"How To Be A Pandas Expert\"[1] is a good primer on dataframes. There&#x27;s a certain mental model you need to use dataframes effectively but it&#x27;s not apparent from reading the official docs. The video makes it explicit: dataframes are about like-indexed one-dimensional data, and every dataframe operation can be understood in terms of what it does to the index.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=oazUQPrs8nw reply thecodedmessage 8 hours agorootparentprevThe Rust docs are for some reason much worse than the Python docs, or at least that used to be the case replydavedx 8 hours agorootparentprevI&#x27;m a data engineering newbie and I found it very clear, and it gave me an enthusiastic feeling (not an \"alienating\" feeling).This whole thread just comes across as unmitigated pedantry to me. reply dns_snek 7 hours agorootparentPresumably you were introduced to the concept of DataFrames and how they&#x27;re used through some other source, because Polars landing page doesn&#x27;t even bother to mention it&#x27;s used for data analysis and documentation simply assumes you&#x27;re already familiar with the core concepts.Compare that to Pandas which starts with the basics, \"pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\" It then leads you to \"Getting started\" guide which features \"Intro to pandas\" that explains the core concepts. reply traceroute66 3 hours agorootparentprev> Yes, it&#x27;s annoying negative feature of many tech products.Sadly its not only tech products, but also things like security disclosures too.It always follows the same pattern: - Spend $X time coding&#x2F;researching something. - Spend $not_enough_time documenting it. - Spend $far_too_much_time thinking about &#x2F; \"engaging with the community\" in deciding on a cute name, fancy logo and cool looking website. reply tomrod 14 hours agorootparentprevWes has also worked hard to improve a lot of the missteps of pandas, such as through pyarrow, which may prove even more impactful than pandas has been to date.Polars is also a wonderful project! reply adolph 13 hours agorootparentPolars is also based on McKinney’s Arrow project.Polars is a DataFrame interface on top of an OLAP Query Engine implemented in Rust using Apache Arrow Columnar Format as the memory model.https:&#x2F;&#x2F;github.com&#x2F;pola-rs&#x2F;polars&#x2F;blob&#x2F;main&#x2F;README.md reply codyvoda 2 hours agorootparentWes also literally created another Python dataframe project, Ibis, to overcome many of the issues with pandashttps:&#x2F;&#x2F;ibis-project.orgmost data engines and dataframe tools these days use Apache Arrow, it&#x27;s a bit orthogonal reply lnxg33k1 11 hours agorootparentprevIt’s annoying only because it’s on hacker news, because what are the odds of getting on it if you don’t know what is it and don’t have a need for it? reply vaylian 8 hours agorootparentIt&#x27;s annoying because a single leading sentence would be enough to explain a product. Some of the words (for example \"Data Frame\") in that sentence can be links to other pages if that&#x27;s necessary. It&#x27;s a small change but it makes a huge difference. reply thecodedmessage 8 hours agorootparentprevI mean, pretty high. What if your boss just tells you to learn polars, and you don’t know why? Saying what something is, is just good communication, and can help clarify for people who are confused. reply lnxg33k1 8 hours agorootparentGuess in the remote event that you&#x27;re told to learn a new skill that you don&#x27;t know anything about, you go to pola.rs website and see \"DataFrames for the new era\" and start getting documentation from there, about what DataFrame is, the website is clearly showing what is it, it&#x27;s your duty to understand what is it, I would argue that if you knew what DataFrames are you would be saying \"Why is it saying something so basic and don&#x27;t just show me the good stuff?\"I for example hate website that try to serve newbies, newbies have a lot of content if they are interested, it&#x27;s not that all the web needs to serve them reply azangru 8 hours agorootparentprev> What if your boss just tells you to learn polars, and you don’t know why? Saying what something is, is just good communicationShouldn&#x27;t the good communication happen when the boss tells you to learn polars? Like, why are you telling me this, boss; what is it that you need done? reply blowski 8 hours agorootparentprevThese workplaces where bosses tell employees to learn unheard-of tools with zero context sound terrible. reply DylanDmitri 16 hours agoparentprevIt’s pandas, but fast. Pandas is the original open source data frame library. Pandas is robust and widely used, but sprawling and apparently slower than this newcomer. The word “data frames” keys in people who have worked with them before. reply dkga 16 hours agorootparentActually pandas is not the original open source data frame library, perhaps only in Python. There is a very rich tradition in R on data.frames, which includes the unjustly neglected data.table. reply p4ul 16 hours agorootparentYep! Unless I&#x27;m mistaken, R (and its predecessor S) seems to have been the first to introduce the concept of a dataframe.One could also argue that dataframes are basically in-memory database tables. And in that case, S and SQL probably tie in terms of the creation timeline. reply ayhanfuat 16 hours agorootparentThe difference is dataframes can also be seen like matrices. You can do row operations, row + column operations, multiply rows and columns, multiply different matrices, transpose them etc. These kind of things don&#x27;t really make sense in DB tables (and they are generally not supported and you jump through hoops to do similar things in DBs). reply kkoncevicius 8 hours agorootparent> The difference is dataframes can also be seen like matrices. You can do row operations, row + column operations, multiply rows and columns, multiply different matrices, transpose them etc.I think this is overblowing the similarities to matrices. Matrices have elements all of the same type, while data.frames mix numbers, characters, factors, etc. You certainly cannot transpose a data.frame and still have a data.frame that makes sense. Multiplying rows would not make sense either, since within one row you will have different types of data. Unless you have a data.frame that is all numeric, but in that case one should probably be using a matrix in the first place. reply ayhanfuat 6 hours agorootparent> Unless you have a data.frame that is all numeric, but in that case one should probably be using a matrix in the first place.They still have their advantages with row&#x2F;column labels, NaN handling etc. These are not operations I am speculating about by the way. I am most familiar with pandas and the dataframe there has transpose, dot product operations and almost all column operations have their correspondence in rows (i.e. you either sum(axis=0) or sum(axis=1)). reply kkoncevicius 5 hours agorootparentOh, based on the comment you replied to I thought this was about R. In R matrices can handle NaNs and NAs, have column and row labels, have dot products and much more. reply p4ul 15 hours agorootparentprevYes, that&#x27;s totally fair; dataframes are more flexible in that sense. reply p4ul 13 hours agorootparentOh, and another important difference is memory layout. The dataframe implementations mostly (or all) use column-major format. Whereas most conventional SQL implementations use row-major format, I believe. reply theLiminator 9 hours agorootparentI think most OLTP databases are row oriented whilst most OLAP are column. reply xwowsersx 14 hours agorootparentprevI feel like the predecessor of R should be Q! reply p4ul 13 hours agorootparentThe way that I&#x27;ve heard the story, S was short for \"statistics\", and R was chosen because the authors were _R_obert [Gentleman] and _R_oss [Ihaka].Statisticians are funny! reply bonadrag 3 hours agorootparentprev> which includes the unjustly neglected data.tableSo so true.I was working on an adhoc project that needed a quick result by the end of the day. I had to pull this series of parquet files and do some quick and dirty analysis. My first reflex was to use python with pandas, quick and easy. Python could not handle the datasets, too large. I decided to give R and data.table a go and it went smoothly. I am usually a python user but from time to time I feel compelled to jump back to R and data.table. Phenomenal tool. reply 7thaccount 16 hours agorootparentprevYeah. I think Wes McKinney liked the data frames in R, but preferred the programming language of Python. I&#x27;ve heard somewhere that he also got a lot of inspiration from APL. reply Cacti 12 hours agorootparentR is literally designed to do statistics and has first class support and language feature support for many specialized tasks in statistics and closely related fields.Python is literally designed to be easy to program with in general.Well, it turns out when you’re dealing with terabytes of data and TFLOPS, the programming becomes more important than the math. Not all R devs are happy about this and they are very loud about it.But it shouldn’t really surprise anyone. That is literally how those languages are designed.Most of the R devs I know like this are just butthurt they are paid less and refuse to switch because they’re obstinate, or they’re a little scared they’re being left behind. first group is all over the place, but the second group tends to skew older of course reply mjhay 3 hours agorootparentR is heavily influenced by Scheme. Not only is it heavily functional, but it has metaprogramming capabilities allowing a high level of flexibility and expressiveness. The tidyverse libraries use this heavily to produce very nice composable APIs that aren&#x27;t really practically possible in Python.R is fine. The issue is more in the ecosystem (with the aforementioned exception of the tidyverse). reply disgruntledphd2 5 hours agorootparentprev> Most of the R devs I know like this are just butthurt they are paid less and refuse to switch because they’re obstinate, or they’re a little scared they’re being left behind. first group is all over the place, but the second group tends to skew older of courseLook, I started with R and use mostly Python these days, but this is not really a fair take.R is (still) much, much, much better for analytics and graphing (the only decent plotting library in python is a ggplot clone). The big change (and why Python ended up winning) is that integrating R with other tools (like web stuff, for example) is harder than just using Python.pandas (for instance) is like an unholy clone of the worst features from both R and Python. Polars is pretty rocking, though (mostly because it clones from Spark&#x2F;dplyr&#x2F;linc).It&#x27;s another example of Python being the second best language for everything winning out in the marketplace.That being said, if I was starting a data focused company and needed to pick a language, I&#x27;d almost certainly build all the DS focused stuff in R as it would be many many times quicker, as long as I didn&#x27;t need to hire too many people. reply Cacti 12 hours agorootparentprevMy friend. You cannot make people like R. We all know about and study data.table, so it’s not neglected, we just don’t use that implementation.Mainly because R sucks for anything that isn’t statistics. reply bee_rider 16 hours agorootparentprevAh, like polar bears are a much more aggressive implementation of the idea behind panda bears? That’s a pretty funny name if so. reply Icathian 16 hours agorootparentYeah. The name always makes me chuckle reply sesm 2 hours agorootparentNext re-implementation will be called grizzl.ys, hand-written in Y86 assembly. reply debo_ 16 hours agorootparentprevI don&#x27;t know, I think the name is kind of polar-izing&#x2F;pun reply p4ul 15 hours agorootparentOh, I&#x27;m not sure. I&#x27;d say it&#x27;s bear-ly polarizing.I&#x27;m so sorry. reply kevindamm 14 hours agorootparentDepends on your frame of mind. reply xwowsersx 14 hours agorootparentThis thread is turning into pandamonium reply p4ul 14 hours agorootparentI&#x27;m worried it&#x27;s going to get grizzly. reply debo_ 12 hours agorootparentThanks folks, you all made my day. \"Frame of mind\" was my favorite. I&#x27;m surprised I didn&#x27;t think of some of these, I must be getting... Rust-y replymaliker 16 hours agorootparentprevPandas has also moved to Apache Arrow as a backend [1], so it’s likely performance will be similar when comparing recent versions. But it’s great to have some friendly competition.[1] https:&#x2F;&#x2F;datapythonista.me&#x2F;blog&#x2F;pandas-20-and-the-arrow-revol... reply jasonjmcghee 14 hours agorootparentNot according to DuckDB benchmarks. Not even close.https:&#x2F;&#x2F;duckdblabs.github.io&#x2F;db-benchmark&#x2F; reply keithalewis 3 hours agorootparentOuch! It is going to take a lot of work to get Polars this fast. If ever. reply hyperpl 13 hours agorootparentprevPolars has an OLAP query engine so without any significant pandas overhaul, I highly doubt it will come close to polars in performance for many general case workloads. reply dash2 6 hours agorootparentThis is a great chance to ELI5: what is an OLAP query engine and why does it make polars fast? reply disgruntledphd2 5 hours agorootparentPolars can use lazy processing, where it collects all of the operations together and creates a graph of what needs to happen, while pandas executes everything upon calling of the code.Spark tended to do this and it makes complete sense for distributed setups, but apparently is still faster locally. reply mjhay 1 hour agorootparentLaziness in this context has huge advantages in reducing memory allocation. Many operations can be fused together, so there&#x27;s less of a need to allocate huge intermediate data structures at every step. reply disgruntledphd2 1 hour agorootparentyeah, totally, I can see that. I think that polars is the first library to do this locally, which is surprising if it has so many advantages. reply mjhay 46 minutes agorootparentIt&#x27;s been around in R-land for a while with dplyr and its variety of backends (including Arrow, the same as Polars). Pandas is just an incredibly mediocre library in nearly all respects. replythejosh 16 hours agorootparentprevMemory and CPU usage is still really high though. reply vietvu 9 hours agorootparentprevNot with eager API. reply gmfawcett 16 hours agorootparentprev> Pandas is the original open source data frame library...ehh, not quite. R and its predecessor S have Pandas beat by decades. Pandas wasn&#x27;t even the first data frame library for Python. But it sure is popular now. reply p4ul 14 hours agorootparentThat&#x27;s interesting! I didn&#x27;t realize there had been prior dataframe libraries in Python!Out of curiosity, what was&#x2F;were the previous libraries? reply melagonster 9 hours agorootparentit is built in data structure and function in R. reply p4ul 2 hours agorootparentOh, yes, I was aware that R (and its predecessor S) have a native dataframe object in the language.It seemed that gmfawcett was indicating that there was a dataframe library in _Python_ that existed prior to Pandas. I was curious what that library was&#x2F;is, as I&#x27;d not heard that before. reply melagonster 40 minutes agorootparentok, guess I misunderstood both comments of you two. ´_>` replyayhanfuat 16 hours agorootparentprevNot *original* but probably most commonly used. reply drbaba 16 hours agorootparentYeah, I believe Pandas was inspired by similar functionality in R. reply froh 16 hours agorootparentprevyup I first met data frames in R and pandas is the Python answer to R isn&#x27;t it reply tomrod 13 hours agorootparentIf I understand correctly, Pandas original scope was indexed in-memory data frames for use in high frequency trading, making use of the numpy library under the hood. At the time it was written you had JPMC&#x27;s Athena, GS&#x27;s platform, and several HFT internal systems (C++ my friends in that space have mentioned). Pandas just is so darn useful! I&#x27;ve been using it since maybe version 0.10, even got to contribute a tiny bit for the sas7bdat handling. reply froh 6 hours agorootparentindeed it&#x27;s both: it was created for financial analytics, and it provides R dataframe features to python. thanks for.making me detour into the history of it. replymadeofpalk 16 hours agoparentprevI was going to say - it always feels so humbling seeing pages like this. \"DataFrames for the new era\" okay… maybe I know what data frames are? \"Multi-threaded query engine\" ahh, so it’s like a database. A graph comparing it to things called pandas, modin, and vaex - I have no clue what any of these are either! I guess this really isn’t for me.It’s a shame because I like to read about new tech or project and try and learn more, even if I don’t understand it completely. But there’s just nothing here for me.This must be what normal people go through when I talk about my lowly web development work… reply theLiminator 15 hours agorootparentIt&#x27;s pretty much just an alternative to SQL that&#x27;s a lot easier&#x2F;natural to use for more hardcore data analysis.You can much more easily compose the operations you want to run.Just think of it as an API for manipulating tabular data stored somewhere (often parquet files, though they can query many different data sources). reply youainti 14 hours agorootparentData tables tend to also be a standard ingestion format for statistical tools in many cases. reply _dain_ 3 hours agorootparentprevDataframes and SQL have overlapping functionality, but I wouldn&#x27;t say that dataframes are an \"alternative\" to SQL. The tradeoffs are very different. You don&#x27;t have to worry about minimizing disk reads or think about concurrency issues like transactions or locks, because a dataframe is just an in-memory data structure like a list or a dict, rather than a database. Dataframes also aren&#x27;t really about relational algebra like SQL is. reply Joeboy 4 hours agoparentprevI&#x27;m currently getting dragged into \"data\" stuff, and I get the impression it&#x27;s a parallel universe, with its own background and culture. A lot of stuff is like \"connect to your Antelope or Meringue instances with the usability of Nincompoop and the performance of ARSE2\".Anyway, probably the interesting things about polars are that it&#x27;s like pandas, but uses a more efficient rust \"backend\" called Arrow (although I think that part&#x27;s also in pandas now) and something like a \"query planner\" that makes combining operations more efficient. Typically doing things in polars is much more efficient than pandas, to the extent that things that previously required complicated infrastructure can often be done on a single machine. It&#x27;s a very friendly competition, created by the main developer of pandas.As far as I can tell everybody loves it and it&#x27;ll probably supplant pandas over time. reply Galanwe 3 hours agorootparent> As far as I can tell everybody loves it and it&#x27;ll probably supplant pandas over time.I&#x27;ve been using pandas heavily, everyday, for something like 8 years now. I also did contribute to it, as well as wrote numpy extensions. That is to say, I&#x27;m fairly familiar with the pandas&#x2F;numpy ecosystem, strengths and weaknesses.Polars is a breeze of fresh air. The API of pandas is a mess:* overuse of polymorphic parameters and return types (functions that accept lists, ndarrays, dataframes, series or scalar) and return differently shaped dataframes or series.* lots of indirections behind layers of trampoline functions that hide default values behind undocumented \"=None\" default values.* abuse of half baked immutable APIs, favoring \"copy everything\" style of coding, mixed with half supported, should-have-been-deprecated, in-place variants.* lots and lots of regressions at every new release, of the worst kind (\"oh yeah we changed the behavior of function X when there is more than Y NaNs over the window\")* Very hard to actually know what is delegated to numpy, what is Cython&#x2F;pandas, and what is pure python&#x2F;pandas.* Overall the beast seemed to have won against its masters, and the maintainers seem lost as to what to fix versus what to keep backward compatible.Polars fixes a lot of these issues, but it has some shortcomings as well. Mainly I found that:* the API is definitely more consistent, but also more rigid than pandas. Some things can be very verbose to write. It will take some years for nicer simpler \"shortcuts\" and patterns to emerge.* The main issue IMHO is polars&#x27; handling of cross sectional (axis=1) computations. Polars is _very_ time series (axis=0) oriented, and most cross sectional computations require to transpose the data frame, which is very slow. Pandas has a lot of dedicated axis=1 implementations that avoid a full transposition. reply ritchie46 3 hours agorootparentMany axis=1 operations in pandas do a transpose under the hood, mind you. Axis=1 belongs in matrices, not in heterogeneous data. They are a performance footgun. We make the transpose explicit. reply Galanwe 1 hour agorootparent> Many axis=1 operations in pandas do a transpose under the hood, mind youSure, but many others are natively axis=1-aware and avoid full transposition.> Axis=1 belongs in matrices, not in heterogeneous data.I&#x27;m not sure to understand what that means. Care to elaborate?> They are a performance footgun.You don&#x27;t get to only solve the problems that are efficient to solve...> We make the transpose explicit.Yes, but when you do mixed time series &#x2F; cross sectional computations, you cannot always untangle both dimensions and transpose once. Sometimes your computation intrinsicely interleaves cross sectional and time series. In these case, which happen a lot in financial computations, then explicitly fully transposing is very slow. reply btbuildem 1 hour agorootparentprevAll domains seem to have this kind of in-group shorthand, regardless of scale of the community. reply pama 11 hours agoparentprevIn fairness, the title of the page is “Dataframes for the new Era”. The “Get Started” link below the title links to a document that points to the GitHub page, which explains what the library is about to people with data analysis backgrounds: https:&#x2F;&#x2F;github.com&#x2F;pola-rs&#x2F;polars reply TylerE 10 hours agorootparentBut annoyingly, not the , thus the useless HN headline. reply andrewflnr 9 hours agorootparentI wish HN had secondary taglines we could use to talk about the actual content or relevance of an article apart from its headline. reply mekster 7 hours agoparentprevHow come some submissions don&#x27;t even describe what it is about than just the name of it? It&#x27;s really puzzling how everyone is meant to know what it is by its name. reply pixelpoet 4 hours agorootparentI&#x27;ve mentioned this before and got downvoted because of course everyone is a web dev and knows what xyz random framework (name and version number in the title, nothing else) is. reply notatoad 11 hours agoparentprevI think something like dataframes suffers from having a name that isn&#x27;t obscure enough. You read \"dataframes\" and think those are two words you know, so you should understand what it is.If they&#x27;d called them flurzles you wouldn&#x27;t feel like you should understand if it&#x27;s not something you work with. reply WesolyKubeczek 10 hours agorootparentFor me, “data frames” are forever associated with MPEG reply drbaba 16 hours agoparentprevAbove that it says “DataFrames for a new era” hidden in their graphics. I believe it’s a competitor to the Python library “Pandas”, which makes it easy to do complex transformations on tabular data in Python. reply CobrastanJorji 16 hours agorootparentIt seems like it&#x27;s a disease endemic to data products. Everybody, the big cloud providers and the small data products, build something whose selling point is \"I&#x27;m the same as Apache X but better.\" But if you don&#x27;t know what Apache X is, you have to go read up on that, and its website might say \"I&#x27;m the same as Whatever Else but better,\" and you have to go read up on that. I don&#x27;t want to figure out what a product does by walking a \"like X but better\" chain and applying diffs in my head. Just tell me what it does!I get that these are general purpose tools with a lot of use cases, but some real quick examples of \"this is a good use case\" and \"this is a bad use case, maybe prefer SQL&#x2F;nosql&#x2F;quasisql&#x2F;hadoop&#x2F;a CSV file and sed\" would be really helpful, please. reply sanderjd 12 hours agorootparentI dunno, I get the criticism, but also, every field assumes a large amount of \"lingua franca\" in order to avoid documenting foundational things over and over again.Programming language documentation doesn&#x27;t all start with \"programming languages are used to direct computers to do things\"; it is assumed the target audience knows that. Database documentation similarly doesn&#x27;t start out with discussing what it means to store and access data and why you&#x27;d want to do that.It&#x27;s always hard to know where to draw this line, and the early iterations of a new idea really do need to put more time into describing what they are from first principles.I remember this from the early days of \"NoSQL\" databases. They spilled lots of ink on what they even were trying to do and why.But in my view this isn&#x27;t one of those times. I think \"DataFrames\" are well within a \"lingua franca\" that is reasonable to expect the audience of this kind of tool to understand. This is not an early iteration of a concept that is not widely familiar, it is an iteration of an old, mature, and foundational concept with essentially universal penetration in the field where it is relevant.Having said all that, I came across this \"what is mysql\" documentation[0] which does explain what a relational database is for. It&#x27;s not the main entry point to the docs, but yeah, sure, it&#x27;s useful to put that somewhere!0: https:&#x2F;&#x2F;dev.mysql.com&#x2F;doc&#x2F;refman&#x2F;8.0&#x2F;en&#x2F;what-is-mysql.html reply esafak 13 hours agorootparentprevIf you don&#x27;t know what the comparison product is either then you are not the target customer. This is a library for analyzing and transforming (mostly numerical) data in memory. Data scientists use it. reply makapuf 10 hours agorootparentprevSee also: Is it pokemon or big data https:&#x2F;&#x2F;pixelastic.github.io&#x2F;pokemonorbigdata&#x2F; reply ryandrake 15 hours agorootparentprevI run into the same problem. I don&#x27;t know what Pandas are (besides the bears) and at some point up the \"it&#x27;s like X\" chain, I guess you have to stop and admit you&#x27;re just not the target user of this tech product. reply selcuka 13 hours agorootparent> I guess you have to stop and admit you&#x27;re just not the target user of this tech product.On the other hand, how can you become a target user if you don&#x27;t know that a product category exists? reply sanderjd 12 hours agorootparentThis project is a solution to a particular kind of problem. The way you become a target user of that solution is by first having the problem it&#x27;s a solution to.If you have the problem \"I want to analyze a bunch of tabular data\", you&#x27;ll start researching and asking around about it, and you&#x27;ll quickly discover a few things: 1. people do this with (usually columnar &#x2F; \"OLAP\") sql query interfaces, 2. people usually end up augmenting that with some in memory analyses in a general purpose programming environment, 3. people often choose R or python for this, 4. both of those languages lean heavily on a concept they both call \"data frames\", 5. in python, this is most commonly done using the pandas library, which is pervasive in the python data science &#x2F; engineering world.Once you&#x27;ve gotten to that point, you&#x27;ll be primed for new solutions to the new problems you now have, one of which is that pandas is old and pretty creaky and does some things in awkward and suboptimal ways that can be greatly improved upon with new iterations of the concept, like polars.But if you don&#x27;t have these problems, then the solution won&#x27;t make much sense. reply esafak 13 hours agorootparentprevThat&#x27;s on you. If you want to become a data engineer and data scientist -- the two software positions most likely to use polars -- get learning. Or don&#x27;t: learn it when you need it. replygodelski 12 hours agoparentprevI try to use polars each time I have to do some analysis where dataframes helps. So basically any time I&#x27;d reach for pandas, which isn&#x27;t too often. So each time it&#x27;s fairly \"new\". This makes me have a hard time believing everyone that is saying \"Pandas but faster\" has used Polars, because I can often write Pandas from memory.There&#x27;s enough subtle and breaking changes that it is a bit frustrating. I really think Polars would be much more popular if the learning curve wasn&#x27;t so high. It wouldn&#x27;t be so high if there were just good docs. I&#x27;m also confused why there&#x27;s a split between \"User Guide\" and \"Docs\".To all devs:Your docs are incredibly important! They are not an afterthought. And dear god, don&#x27;t treat them as an afterthought and then tell people opening issues to RTFM. It&#x27;s totally okay to point people in the right direction without hostility. It even takes less energy! It&#x27;s okay to have a bad day and apologize later too, you&#x27;ll even get more respect! Your docs are just as important as your code, even if you don&#x27;t agree with me, they are to everyone but you. Besides technical debt there is also design debt. If you&#x27;re getting the same questions over and over, you probably have poor design or you&#x27;ve miscommunicated somewhere. You&#x27;re not expected to be a pro at everything you do and that&#x27;s okay, we&#x27;re all learning.This isn&#x27;t about polars, but I&#x27;m sure I&#x27;m not the only one to experience main character devs. It makes me (and presumably others) not want to open issues on __any__ project, not just bad projects, and that&#x27;s bad for the whole community (including me, because users find mistakes. And we know there&#x27;s 2 types of software: those with bugs and those that no one uses). Stupid people are just wizards in training and you don&#x27;t get more wizards without noobs. reply bbkane 11 hours agorootparentAs another data point, I switched to Polars because I found it much more intuitive than Pandas - I coulnt remember how to do much in pandas in the rare (maybe twice a year) times I want to do data analysis. In contrast, Polars has a (to me anyway) wonderfully consistent API that reminds me a lot of SQL reply godelski 9 hours agorootparentMaybe that&#x27;s it, because I don&#x27;t really use SQL much. Reaching for pandas about the same rate. Maybe that&#x27;s the difference? But I come from a physics background and I don&#x27;t know many physicists and mathematicians that are well versed in SQL. But I do know plenty that use pandas and python. So there&#x27;s definitely a lot of people like me. Also I could be dumb. Totally willing to accept that lol. reply orhmeh09 10 hours agorootparentprevI also use Pandas very infrequently (it has been years). Usually, for data analysis, I&#x27;m reaching for R + tidyverse&#x2F;data.table&#x2F;arrow. I have found Python and Pandas to be inelegant and verbose for these tasks.As of last week, I have a need to process tabular data in Python. I started working with polars on Friday, and I have an analysis running across 16 nodes today. I find it very intuitive. reply sanderjd 10 hours agorootparentprevYep, been using pandas for years now, still have no real mental model for it and constantly have to experiment or chat with our AI overlords to figure out how to use it. But SQL and polars make sense to me. reply killjoywashere 12 hours agorootparentprevThe story of Polars seems to be shaping up a bit like the story of Python 3000: everything probably could have been done in a slow series of migrations, but the BDFL was at their limit, and had to start fresh. So it takes 10 years for the community to catch up. In the mean time, there will be a lot of heartache. reply theLiminator 12 hours agorootparentI honestly don&#x27;t believe something like polars could&#x27;ve evolved out of pandas.It&#x27;s a complete paradigm shift.There&#x27;s honestly not much that probably could&#x27;ve been shared at the point polars was conceived. Maybe now there&#x27;s a little more (due to the arrow backend) but still very little probably. reply jmspring 13 hours agoparentprevYou were right that the page is written for those that know what they are looking for, which is just fine. If you are getting started in DS&#x2F;ML&#x2F;etc and you have used numpy, pandas, etc. polars is useful in some cases. A simple one, it loads dataframes faster (from experience with a team I help) than pandas.I haven&#x27;t played enough to know all it&#x27;s benefits, but yes it&#x27;s the next logical step if you are in the space using the above mentioned libraries, it&#x27;s something one will find. reply the__alchemist 15 hours agoparentprevDataframes in Python are a wrapper around 2D numpy arrays, that have labels and various accessors. Operations on them are OOM slower than using the underlying arrays. reply twelvechairs 13 hours agorootparentThere&#x27;s a very good point here but I don&#x27;t think its made clear.If your data fits into numpy arrays or structured arrays (mainly if it is in numeric types), numpy is designed for this and will likely be much faster than pandas&#x2F;polars (though I&#x27;ve also heard pandas can be faster on very large tables).Pandas and Polars are designed for ease of use on heterogeneous data. They also include a python &#x27;Object&#x27; data type which numpy very much does not. They are also designed more like database (e.g. &#x27;join&#x27; operations). This allows you to work directly with imported data that numpy won&#x27;t accept - after which Pandas uses numpy for underlying operations.So I think the point is if you are running into speed issues in Pandas&#x2F;Polars, you may find that the time-critical operations could be things that are more efficiently done in numpy (and this would be a much bigger gain than moving from Pandas to Polars) reply YetAnotherNick 15 hours agorootparentprevI don&#x27;t know where this myth originated from but I have seen this in multiple places. Even if you think about it 2d numpy arrays can&#x27;t have different type for different columns. reply theLiminator 15 hours agorootparentActually numpy has something called a structured array that is pretty much what what you described. reply billyjmc 14 hours agorootparentprevWell, if you use structured arrays or record arrays, you can do this (more or less).https:&#x2F;&#x2F;numpy.org&#x2F;doc&#x2F;stable&#x2F;user&#x2F;basics.rec.html reply FrustratedMonky 14 hours agorootparentprev\"myth originated\"It&#x27;s in the documentation.I just learned pandas recently, and I would have said this same thing. Not because I read through the numpy code, but because I read the documentation.Is it wrong? Can&#x27;t a user pick up a new tool and trust some documentation without reading through 100&#x27;s of libraries built on libraries.When was last time someone traced out every dependency, so they can confidently say something is \"Myth\". reply YetAnotherNick 12 hours agorootparentWhere is it written in pandas documentation? Pandas dataframe is stored in list of 1d numpy arrays, not a single 2d array. reply ayhanfuat 6 hours agorootparentThe columns with common dtypes are grouped together in something called \"blocks\" and inside those blocks are 2D numpy arrays. It is probably not in the documentation because it is seen as implementation detail but you can see the block manager&#x27;s structure in this article (https:&#x2F;&#x2F;dkharazi.github.io&#x2F;blog&#x2F;blockmanager&#x2F;) or in this talk (https:&#x2F;&#x2F;thomasjpfan.github.io&#x2F;scipy-2020-lightning-talk-pand...). replyUltimatt 8 hours agoparentprevRight... but the title before the first line reads \"DataFrames for the new era\". If you don&#x27;t know what a data frame is then, yes, it&#x27;s for people who already know that. reply esafak 13 hours agoparentprevMarketing is a skill that needs to be learned. You have to put yourself in the shoes of a person who knows nothing about your product. This does not come naturally to the engineers who make these products and are used to talking to other specialists like themselves. reply sanderjd 12 hours agorootparentThis is true in general but I&#x27;m not sure it&#x27;s what&#x27;s going on here.Marketing is also very concerned with understanding who your target audience(s) are and speaking their language.I think talking about \"DataFrames\" is exactly that; the target audience of this project knows what that means. What they are interested in is \"ok but who cares about data frames? I&#x27;ve been using pandas for like fifteen years\", so what you want to tell them is why this is an improvement, how it would help them. Dumbing it down to spend a bunch of space describing what data frames are would just be a distraction. You&#x27;d probably lose the target audience before you ever got to the actual benefits of the project. reply davedx 8 hours agoparentprevI don&#x27;t use dataframes in my day job but have dabbled in them enough that I found this website pretty easy to digest.You&#x27;d really have to be a complete data engineering newbie to not understand it I think?I mean, where do you draw the line? You wouldn&#x27;t expect a software tool like this to explain what it is in language my grandma would understand, I don&#x27;t think? reply drbaba 7 hours agorootparent> You&#x27;d really have to be a complete data engineering newbie to not understand it I think?I do occasionally use Pandas in my day job, but I honestly think very few programmers that could have use for a data frame library would describe themselves as a “data engineer” at all.In my case, for example, I’m just a physicist - I don’t work with machine learning, big data, or in the software industry at all. I just use Pandas + Seaborn to process the results of numerical simulations and physical experiments similarly to how someone else might use Excel. Works great. reply nnevatie 11 hours agoparentprevNoticed exactly the same - there&#x27;s no description of the library whatsoever on the landing page. It is implied that it is a DataFrame library, whatever that means. reply sanderjd 10 hours agorootparentMaybe this is sort of like the opposite of how scam emails are purposefully scammy, so that only people who can&#x27;t recognize scams will fall for them. Only people who know what \"a DataFrame library\" is - which is an enormous number of people, since this is probably the most broadly known concept in data science &#x2F; engineering - will keep reading this, and they are the target audience. reply nnevatie 7 hours agorootparent> which is an enormous number of peopleWhile that may be, I think it would make sense to describe the project in a succinct way on the first page a visitor lands. reply sanderjd 51 minutes agorootparentIt is described in a succinct way. \"DataFrames\" is that description. It&#x27;s the very first text on the page. It&#x27;s really the same as having the word \"database\" be the first text on the landing page of a new database project. If you don&#x27;t know what the word \"database\" means, the landing page for a new database project is really not the place to expect to learn about that. The \"data frame\" concept is not quite as old or broad as the concept of \"databases\", but it&#x27;s really not that far off. It&#x27;s decades old, and is about as close to a universal concept for data work as it&#x27;s possible to get. reply nhinck3 4 hours agorootparentprevBut you&#x27;re not the audience? There is very little to gain by tailoring the introduction to people who aren&#x27;t the audience.You don&#x27;t go car parts manufacturer expecting an explanation of what an intercooler is. reply vietvu 9 hours agoparentprevIt&#x27;s fine to me. Tech UI is bad and weird, but not like if you gain 5x customers with better UX. reply _dain_ 16 hours agoparentprevpandas dataframes but faster reply SalmoShalazar 12 hours agoparentprevIt’s not written for you and that’s fine. This is a library targeted at a very specific subset of people and you’re not in it. reply aterp 13 hours agoparentprevHad the exact same thought seeing this. Too many of these websites are missing a simple tldr of the thing actually is. Great, it&#x27;s fast, but fast at what?? reply sanderjd 11 hours agorootparentIt has that simple tldr, it&#x27;s the very first word, \"DataFrames\". Everyone in this thread just doesn&#x27;t know what that means, and that&#x27;s fine, I get that, but seriously, that&#x27;s the simple summary. Data frames aren&#x27;t an obscure or esoteric concept in the data analysis space; quite the opposite. reply Cacti 12 hours agoparentprevI hate this doc style that has become so popular lately. They get so wrapped up in selling you their story that they forget to tell you basic shit. Like what it is. Or how to install it.The PMs literally simplified things so much they simplified the product right ought of the docs. reply orhmeh09 11 hours agorootparentIt is right there on the page, set to Python by default:> Quick install > Polars is written from the ground up making it easy to install. Select your programming language and get started! reply bee_rider 16 hours agoparentprevJust once I’d like to see “this library was written to fulfill head-in-the clouds demands by management that we have some implementation, without regards to quality.” reply minimaxir 16 hours agorootparentFor posterity, polars was a hobby product that started in 2020: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23768227> As a hobby project I tried to build a DataFrame library in Rust. I got excited about the Apache Arrow project and wondered if this would succeed.> After two months of development it is faster than pandas for groupby&#x27;s and left and inner joins. I still got some ideas for the join algorithms. Eventually I&#x27;d also want to add a query planner for lazy evaluation. reply bee_rider 14 hours agorootparentDefinitely not intended as a slight toward this project, just (what I thought was) a funny thought about that expression. reply sanderjd 11 hours agorootparentprevThat has absolutely no relation to this project. What in the world are you talking about? reply bee_rider 1 hour agorootparentI’m just responding to> \"Polars is written from the ground up with performance in mind\"It is a common thing to see, I thought it would be funny to imagine the opposite. reply ritchie46 10 hours agorootparentprevTrust me. It does. ;) reply sanderjd 10 hours agorootparentWhat do you mean? What \"management\" was this created to fulfill the demands of? replydang 16 hours agoprevRelated:Detailed Comparison Between Polars, DuckDB, Pandas, Modin, Ponder, Fugue, Daft - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37087279 - Aug 2023 (1 comment)Polars: Company Formation Announcement - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36984611 - Aug 2023 (52 comments)Replacing Pandas with Polars - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34452526 - Jan 2023 (82 comments)Fast DataFrames for Ruby - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34423221 - Jan 2023 (25 comments)Modern Polars: A comparison of the Polars and Pandas dataframe libraries - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34275818 - Jan 2023 (62 comments)Rust polars 0.26 is released - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34092566 - Dec 2022 (1 comment)Polars: Fast DataFrame library for Rust and Python - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29584698 - Dec 2021 (124 comments)Polars: Rust DataFrames Based on Apache Arrow - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23768227 - July 2020 (1 comment) reply dangoodmanUT 14 hours agoparentso you took my original username reply mkl 10 hours agorootparentFrom 2014-03-29, https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7494093:> A couple of personal points that I may as well insert here. The account I&#x27;m now using, dang, was used briefly in 2010 by someone who didn&#x27;t leave an email address. I feel bad for not being able to ask them if they still want it, so I&#x27;m considering this an indefinite loan. If you&#x27;re the original owner, please email me and I&#x27;ll give it back to you. The reason I want the name dang is that (a) it&#x27;s a version of my real name and (b) it&#x27;s something you say when you make a mistake.You&#x27;re probably too late. reply Terretta 4 hours agorootparent> You&#x27;re probably too late.From the 2014 thread, it was a (four years and) three months offer:“I was thinking that because it&#x27;s just software, we could restore the old account to its exact prior state. But the attention that accrues to a moderator account would make that impossible. So I guess I&#x27;ll keep the offer open for three months, after which we can make some other arrangement.” reply KomoD 8 hours agorootparentprev> So I guess I&#x27;ll keep the offer open for three months, after which we can make some other arrangement.Like a decade too late it seems reply RockyMcNuts 1 hour agorootparentprevnot sure if this is a joke but hey you should check out this new slowpoke meme, it&#x27;s kind of coolhttps:&#x2F;&#x2F;imgflip.com&#x2F;memegenerator&#x2F;Slowpoke reply subroutine 13 hours agorootparentprevsweet summer child reply serjester 16 hours agoprevUsed pandas for years and it always felt like rolling a ball uphill - just look at doing something as simple as a join (don&#x27;t forget to reset the index).Polars feels better than pandas in every way (faster + multi-core, less memory, more intuitive API). The library is still relatively young which has its downsides but in my opinion, at minimum, it deserves to be considered on any new project.Easily being able to leverage the Rust ecosystem is also awesome - I sped up some geospatial code 100X by writing my own plugin to parallelize a function. reply nerdponx 12 hours agoparent> just look at doing something as simple as a join (don&#x27;t forget to reset the index)It&#x27;s slightly ironic that you mention this, because I always thought the biggest problem with Pandas was its documentation. Case in point: did you know there&#x27;s a way to join data frames without using the index? It&#x27;s called \"merge\" rather than \"join\".Pandas was originally very heavily inspired by R terminology and usage patterns, where the term \"merge\" to mean \"join\" was already commonplace. If I didn&#x27;t already know R when I started learning Pandas (~2015), I don&#x27;t think I&#x27;d have been able to pick it up quickly at all. reply baq 8 hours agorootparent> I always thought the biggest problem with Pandas was its documentation. Case in point: did you know there&#x27;s a way to join data frames without using the index? It&#x27;s called \"merge\" rather than \"join\".chatgpt (even the free tier) solved that problem for me. I ask it what I want in sql terms (or just plain english) and it tells me the pandas spell invocation. It even started to make sense after a few kLOC... reply lvncelot 8 hours agorootparentprevFor me, Pandas fits in neatly with Matplotlib in the niche category of \"R-inspired Python libraries that are somewhat counter-intuitive due to said R-inspiration\" reply tda 7 hours agorootparentMatplotlib is MATLAB inspired, but otherwise your point stands. reply lvncelot 2 hours agorootparentRight, brainfart reply djhn 11 hours agorootparentprevI had to check the R documentation for merge in disbelief, because it didn&#x27;t ring a bell. Between data.table&#x27;s [ syntax and dplyr joins I can&#x27;t remember the last time I&#x27;ve used merge! reply snthpy 9 hours agoparentprevI am very curious to know how you feel about PRQL (prql-lang.org) ? IMHO it gives you the ergonomics and DX of Polars or Pandas with the power and universality of SQL because you can still execute your queries on any SQL compatible query execution engine of your choice, including Polars and Pandas but also DuckDB, ClickHouse, BigQuery, Redshift, Postgres, Trino&#x2F;Presto, SQLite, ... to name just a few popular ones.The join syntax and semantics is one of the trickiest parts and is under discussion again recently. It&#x27;s actually one of the key parts of any data transformation platform and is foundational to Relational Algebra, being right there in the \"Relational\" part and also the R in PRQL. Most of the PRQL built-in primitive transforms are just simple list manipulations like map, filter or reduce but joins require care to preserve monadic composition (see for example the design of SelectMany in LINQ or flatmap in the List Monad). See this comment for some of my thoughts on this: https:&#x2F;&#x2F;github.com&#x2F;PRQL&#x2F;prql&#x2F;issues&#x2F;3782#issuecomment-181131... That issue is closed but I would love to hear any comments and you are welcome to open a new issue referencing that comment or simply tagging me (@snth).Disclaimer: I&#x27;m a PRQL contributor. reply serjester 48 minutes agorootparentFirst time I’ve heard of it but seems very cool. My background is data science though so being able to use DS libraries or even apply a python function is why I find myself in Pandas &#x2F; Polars. This seems very powerful for a data engineer.I also think it’s awesome you guys have a duckdb integration - maybe I’ll try it out. reply theLiminator 7 hours agorootparentprevDo you compile to substrait or to SQL strings? reply snthpy 5 hours agorootparentSQL strings as the final output but there are two intermediate representations that can be serialized to JSON.There&#x27;s an open issue for Substrait but I don&#x27;t think that anyone&#x27;s started any work on that yet. reply benrutter 6 hours agoprevI&#x27;m really excited about Polars and it&#x27;s speed performance is super impressive buuutt. . . It annoys me to see vaex, modin and dask all compared on the same benchmarks.For anyone who doesn&#x27;t use those libraries, they are all targeted towards out-of-core data processing (i.e. computing across multiple machines because your data is too big). Comparing them to a single core data frame library is just silly, and they will obviously be slower because they necessarily come with a lot of overhead. It just wouldn&#x27;t make sense to use polars in the same context as those libraries, so seeing them presented in benchmarks as if they are equivalents is a little silly.And on top of that, duckdb, which you might use in the same context as polars and is faster than polars in a lot of contexts, isn&#x27;t included in the benchmarks.The software engineering behind polars is amazing work and there&#x27;s no need to have misleading benchmarks like this. reply oreilles 3 hours agoparentI don&#x27;t know about the others but you can use Dask on a single machine, and it&#x27;s also the easiest way to use Dask. It allows parallelizing operations by splitting dataframes into partitions that get processed in individual cores on your machine. Performance boost over pandas can be 2x with zero config, and I&#x27;ve seen up to 5x on certain operations. reply codyvoda 4 hours agoparentprevIbis, a Python dataframe created by the creator of pandas, uses DuckDB as the default backend and generally beats Polars on these benchmarks (with exceptions on some queries) reply mmastrac 16 hours agoprevWhen we shipped Jupyter support in Deno, `nodejs-polars` was one of the cornerstone library for data science we supported.https:&#x2F;&#x2F;blog.jupyter.org&#x2F;bringing-modern-javascript-to-the-j...I&#x27;m not personally a Data Science guy, but considering how early the JS&#x2F;Jupyter ecosystem is, it was surprisingly quick to get pola.rs-based analysis up and running in TypeScript.The JS bindings certainly need a bit of love, but hopefully now that it&#x27;s more accessible we&#x27;ll see some iteration on it. reply swyx 9 hours agoparentTIL. always wanted pandas in JS! reply maliker 16 hours agoprevBiggest advantage I found when I evaluated it was the API was much more consistent and understandable than the pandas one. Which is probably a given, they’ve learned from watching 20 major versions of pandas get released. However, since it’s much rarer, copilot had trouble writing polars code. So I’m sticking with pandas and copilot for now. Interesting barrier to new libraries in general I hadn’t noticed until I tried this. reply epolanski 16 hours agoparentYou&#x27;re the first person I ever encounter that publicly states to prefer a library because of its copilot support.Not making a judgement, just finding it interesting.Anyway, for what is worth, Copilot learns fast in your repos, very fast.I use an extremely custom stack made of TS-Plus a TypeScript fork that not even the author itself uses nor recommends and Copilot churns very good TS-Plus code.So don&#x27;t underestimate how good can copilot can get at the boilerplate stage once he&#x27;s seen few examples. reply digdugdirk 15 hours agorootparentUmm... Could you please link to a resource so someone can parse what your last two paragraphs mean?That sounds really interesting and valuable, I just have no idea where to start. reply Tigress8780 14 hours agorootparentGiven examples, Copilot can generate code for extremely rare languages or data structures. For example, it worked fine when I was writing for an obscure scripting language found in a railway simulation game. reply swyx 9 hours agorootparentto further elaborate, Copilot automatically grabs most recent 20 files with same extension to get code examples. you dont have to do anything special to make this happen. it just improves quietly over time. reply bko 14 hours agorootparentprevI think he means he uses an obscure programming language and co-pilot still gives him functioning code if he gives a few examples. Not sure if copilot is very context aware where you can feed it an entire code-base, but maybe you can point GPT to read the documentation reply epolanski 7 hours agorootparentprevAs other users said, copilot learns from the rest of your files too.Thus it works even for relatively obscure stuff like this https:&#x2F;&#x2F;github.com&#x2F;ts-plus reply earthling8118 10 hours agorootparentprevIt was pretty straightforward to read. Maybe take another look? You can use a search engine to find this TS-Plus thing they talk about. reply janoelze 14 hours agorootparentprevhttps:&#x2F;&#x2F;dev.to&#x2F;effect&#x2F;the-case-for-ts-18b3 reply humbleharbinger 16 hours agoparentprevI had a similar experience using danfo.js, another data frame library in js. Copilot straight up hallucinate functionality and method names.Not a big deal because I just read the docs but it was annoying that I couldn&#x27;t have copilot just spit out what I need. reply im_down_w_otp 15 hours agorootparentThis is really interesting to see these two posts. I can now imagine where AI tools actually inhibit innovation in many domains simply because they’re optimized for things that are already entrenched and new entrants won’t be in the training data. Further inhibiting adoption compared to existing things and thus further inhibiting enough growth to make it into model updates. reply xpe 15 hours agorootparentIt is a healthy mindset to see this phenomenon as \"interesting\". I can get there when I dial up my mindfulness, but my default mode here is rather judgy; as in \"please ppl! pick the better tool as evaluated over a 4+ hour timeframe (after you&#x27;ve got some muscle memory for the API) instead of a 15 minute evaluation\".Forgive me for ranting here, but have people forgotten how to bootstrap their own knowledge about a new library? Taking notes isn&#x27;t hard. Making a personal cheat-sheet isn&#x27;t hard. I say all this AND I use LLMs very frequently to help with technical work. But I&#x27;m mindful about the tradeoffs. I will not let the tool steer me down a path that isn&#x27;t suitable.I&#x27;m actually hopeful: there is an unexpected competitive advantage to people who are willing to embrace a little discomfort and take advantage of one&#x27;s neuroplasticity. reply mncharity 13 hours agorootparentprev> I can now imagine where AI tools actually inhibit innovation [...] new entrants won’t be in the training dataI still imagine the opposite impact... Welcome to no-moats-lang.io! So, you&#x27;ve created yet another new programming language over the holidays? You have a sandbox and LSP server up, and are wondering what to do next? Our open-source LLMs are easily tuned for your wonderful language! They will help you rapidly create excellent documentation, translators from related popular languages, do bulk translation of \"batteries\" so your soon-to-be-hordes of users can be quickly productive, and create both server and on-prem ChatOverflowPilotBots! Instant support for new language versions, and automatic code update! \"LLM&#x27;s are dynamite for barriers to entry!\" - Some LLM Somewhere Probably.Once upon a time, a tar file with a compiler was MVP for a language. But with little hope of broad adoption. And year by year, user minimum expectations have grown dauntingly - towards extensive infrastructure, docs, code, community. Now even FAMG struggle to support \"Help me do common-thing in current-version?\". Looking ahead, not only do LLMs seemingly help drop the cost of those current expectations to something a tiny team might manage, but also help drop some of the historical barriers to rapid broad adoption - \"Waiting for the datascience and webdev books? ... Week after next.\"We might finally be escaping decades of language evolution ecosystem dysfunction... just as programming might be moving on from them? :&#x2F; reply fpgaminer 15 hours agorootparentprevHow is that different from humans who prefer tools they know to tools they don&#x27;t? reply FridgeSeal 15 hours agorootparentBecause it’s like willfully choosing the more painful and difficult tool that occasionally stabs you in the hand, because you’re now used to being stabbed in the hand.Continuing to choose it in the face of - in their own words - a better option, is a bit mind-boggling to me. reply BadHumans 15 hours agoparentprevCopilot support is a chicken and egg problem. It needs to train on others code but if people don&#x27;t write Polars code without Copilot then Copilot will not get better at writing Polars code. reply naiv 9 hours agoparentprevThe Polars lib changes rapidly. I am not using Copilot but achieved very good results with ChatGpt if you set system instructions to let it know that eg with_column was replaced with with_columns etc. and add the updated doc information to the system instructions. reply xpe 15 hours agoparentprevYou recognize the API is more consistent and understandable, but you want to stay with Pandas only because Copilot makes it easier? Please, (a) for your own sake and (b) for the sake of open source innovation, use the tool that you admit is better.About me: I&#x27;ve used and disliked the Pandas API for a long time. I&#x27;m very proactive about continual improvement in my learning, tooling, mindset, and skills. reply chemicalnovae 15 hours agorootparent> Please, (a) for your own sake and (b) for the sake of open source innovation, use the tool that you admit is better.This is...such a strange take. To follow your logic to an extreme, everyone should use a very small handful of languages that are the \"best\" in their domain with ne&#x27;er a care for their personal comfort or preference.> for your own sakeThey&#x27;re sticking with Pandas exactly for their own sake since they like being able to use Copilot.> for the sake of open source innovationOhh by all means let&#x27;s all be constantly relearning and rehashing just to follow the latest and greatest in open source innovation this week.Tools are designed to be _used_ and if you like using a tool _and_ it does the job you require of it that seems just fine to me; especially if you&#x27;re also taking the time to evaluate what else is out there occasionally. reply xpe 48 minutes agorootparentI&#x27;ll attempt to clarify my rationale:(a) For one&#x27;s own sake, please pick the better tool as evaluated over suitable timeframe (perhaps an hour or two, after you&#x27;ve got some familiarity and muscle memory for the API) instead of only a brief evaluation (e.g. only 15 minutes).(b) Better open source tools (defined however you want), which benefit us all, get better uptake when people think beyond merely the short-term.The essence of my argument is \"think beyond the short-term\". Hardly controversial.Don&#x27;t miss the context: LLMs are giving people even more excuses for short-term thinking. Humans are terribly tempted for short-sighted \"victories\". reply earthling8118 10 hours agorootparentprevIs it really that strange of a take? To use the best tool available for a job. That doesn&#x27;t sound strange at all.Doubly so if it involves copilot. There&#x27;s no way to get training data without people writing it. This sound like a direct application of a greedy algorithm: trading long term success for short term gain. That&#x27;s not the ideal way to live. reply xpe 44 minutes agorootparentYes, the greedy algorithm metaphor is an interesting connection!I also like thinking about this as a feedback loop (as explained by systems dynamics), since it provides nice concepts for how systems change over time. reply __mharrison__ 15 hours agoparentprevCopilot support is basically non existent for Polars. It does a decent job of writing basic pandas... (But could do a lot better). reply bradhilton 15 hours agoparentprevI use polars, but I&#x27;ve also run into this problem with copilot. reply imgabe 10 hours agoprevThere must be a corollary to Greenspun&#x27;s Tenth Rule (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Greenspun&#x27;s_tenth_rule) that any sufficiently complicated data analysis library contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of SQL.I use Pandas from time to time and I&#x27;ll probably try this out, but I always find myself wishing I&#x27;d just started with shoving whatever data I&#x27;m working with into Postgres.It&#x27;s not like I&#x27;m some database expert either, I&#x27;m far more comfortable with Python, but the facilities for selecting, sorting, filtering, joining, etc tabular data are just way better in SQL. reply snthpy 10 hours agoparentI recommend you look at DuckDB and the duckdb-prql extension.DuckDB allows you to work on your Polars and Pandas (and any data on Arrow format) directly using SQL without needing any data copying or duplication.The duckdb-prql allows you to use PRQL (prql-lang.org) which gives you all the power and universality of SQL with the ergonomics and DX of Polars or Pandas (IMHO).Disclaimer: I&#x27;m a PRQL contributor. reply theLiminator 7 hours agoparentprevImo lazy dataframe syntax is a far superior frontend to a query engine. Polars also has SQL support, but really the frontend isn&#x27;t generally where bugs come from but instead come from the query engine.Postgres would be an order of magnitude slower than OLAP query engines for the types of queries that people do with them. reply sanderjd 10 hours agoparentprevYou could do that, but it would likely both perform significantly worse (if you&#x27;re doing \"analytical\" kinds of queries) and be a lot less flexible and expressive.But you may want to look into DuckDB, which has a sql implementation that is not ad hoc, bug ridden, slow, or incomplete (though I honestly don&#x27;t know about the formality of its specification). And it is compatible with polars :) reply codyvoda 3 hours agoparentprevthe creator of pandas created Ibis, which has a Postgres backend, for reasons like this: https:&#x2F;&#x2F;ibis-project.org&#x2F;backends&#x2F;postgresqlthis is a better approach to Python dataframes and SQL reply wenc 16 hours agoprevI don’t use Polars directly, but instead I use it as a materialization format in my DuckDB workflows.Duckdb.query(sql).pl() is much faster than duckdb.query(sql).df(). It’s zero copy to Polars and happens instantaneously while Pandas takes quite a while if the DataFrame is big. And you can manipulate it like a Pandas DataFrame (albeit with slightly different syntax).It’s greater for working with big datasets. reply grej 12 hours agoparentThis is a really nice insight that I wasn&#x27;t aware of. Many thanks. reply sanderjd 11 hours agoparentprevVery cool! reply frogamel 13 hours agoprevA few months ago I tried migrating a large pandas codebase to polars. I&#x27;m not much of a fan of doing analytics&#x2F;data pipelining in Python - a complex transformation takes me 2-5x as long in pandas compared to Julia or R (using dataframes.jl & dplyr).Unfortunately polars was not it. Too many bugs on standard operations, unreliable interoperability with pandas (which is an issue since so many libraries require pandas dataframes as inputs), the API is also very verbose for a modern dataframe library, though it&#x27;s still better than pandas.Hopefully these will get resolved out over time but for now I had the best luck using duckdb on top of pandas, it is as fast as polars but more stable&#x2F;better interoperability.Eventually I hope the Python dataframe ecosystem gets to the same point as R&#x27;s, where you have a analytics-oriented dataframe library with an intuitive API (dplyr) that can be easily used alongside a high-performance dataframe library (data.table). reply nerdponx 12 hours agoparentI got annoyed at the verbosity as well. Pandas is fairly verbose compared to eg data.table, but Polars really feels more like using \"an API\" than \"a data manipulation tool\".I probably wouldn&#x27;t use it for EDA or research, but I have started to use it in certain production scripts for the better performance.R dplyr + data.table is still my favorite data manipulation experience. I just wish we had something like Matplotlib in R: ggplot is too high level, base graphics are too low level. Also Scikit-Learn is much more modular than Caret, which I don&#x27;t really miss using. reply dash2 6 hours agorootparentHave you tried the \"grid\" graphics package in R? It&#x27;s the basis for ggplot. It&#x27;s a bit of an unsung hero, the documentation is not great, but I think it is a very solid library. reply nerdponx 2 hours agorootparentIs it usable on its own? I only ever interacted with it in trying to hack around something I didn&#x27;t like in ggplot, and it didn&#x27;t seem like something I could use \"by hand\". In hindsight it does sound a lot like what MPL does. I can take a look! reply billyzs 9 hours agorootparentprev> I just wish we had something like Matplotlib in Rplotly could be worth a try, i use its python bindings and much prefer it to matplotlib, but i don&#x27;t know much about the quality of it&#x27;s R API reply blt 9 hours agorootparentprevyeah, I haven&#x27;t used Polars but from skimming the docs it looks kind of enterprisey. I don&#x27;t want to type `df.select(pl.col(\"a\"))` instead of `df[\"a\"]`. reply theLiminator 7 hours agorootparentLatter also works. reply snthpy 9 hours agoparentprevI am very curious to know how you feel about PRQL (prql-lang.org) ? It aims to give you the ergonomics dplyr wherever you use SQL (by compiling to SQL).IMHO this gives you the DX of dplyr &#x2F; Polars &#x2F; Pandas combined with the power and universality of SQL because you can still execute your queries on any SQL compatible query execution engine of your choice, including Polars and Pandas but also DuckDB, ClickHouse, BigQuery, Redshift, Postgres, Trino&#x2F;Presto, SQLite, ... to name just a few popular ones.I&#x27;d love to hear your thoughts, either in a Discussion on Github (https:&#x2F;&#x2F;github.com&#x2F;PRQL&#x2F;prql&#x2F;discussions) or on our Discord (https:&#x2F;&#x2F;discord.com&#x2F;invite&#x2F;XWxbCrWr)!Disclaimer: I&#x27;m a PRQL contributor. reply aexl 12 hours agoparentprevNice, you have experience in data frames in R, Python and Julia! Which one of those do you like the most? I know that the ecosystem isn&#x27;t really comparable, but from your experience, which one is the best to work with for core operations, etc.? reply nerdponx 11 hours agorootparentNot OP but R data.table + dplyr is an unbeatable combo for data processing. I handily worked with 1bn record time series data on a 2015 MBP.The rest of the tidyverse stuff is OK (like forcats), but the overall ecosystem is a little weird. The focus on \"tidy\" data itself is nice up to a point, but sometimes you want to just move data around in imperative style without trying to figure out which \"tidy verb\" to use, or trying to learn yet another symbol interpolation &#x2F; macro &#x2F; nonstandard eval system, because they seem to have a new one every time I look.Pandas is a real workhorse overall. Data.table is like a fast sports car with a very complicated engine, and Pandas is like a work van. It&#x27;s a little of everything and not particularly excellent at anything and that&#x27;s ok. Also its index&#x2F;multiindex system is unique and powerful. But data.table always smoked it for single-process in-memory performance.Until DuckDB and Polars, there was no Python equivalent of data.table at all. They&#x27;re great when you want high performance, native Arrow (read: Parquet) support, and&#x2F;or an interface that feels more like a programming library than a data processing tool. If you&#x27;re coming from a programming background, or if you need to do some data processing or analytics inside of production system, those might be good choices. The Polars API will also feel very familiar to users of Spark SQL.For geospatial data, Pandas is by far superior to all options due to GeoPandas and now SpatialPandas. There is an alpha-stage GeoPolars library but I have no idea who&#x27;s working on it or how productive they will be.If you had to learn one and only one, Pandas might still be the best option. Python is a much better general-purpose language than R, as much as I love R. And Pandas is probably the most flexible option. Its index system is idiosyncratic among its peers, but it&#x27;s quite powerful once you get used to using it, and it enables some interesting performance optimization opportunities that help it scale up to data sets it otherwise wouldn&#x27;t be able to handle. Pandas also has pretty good support for time series data, e.g. aggregating on monthly intervals. Pandas also has the most extensibility&#x2F;customizability, with support for things like custom array back ends and custom data types. And its plotting methods can help make Matplotlib less verbose.I&#x27;ve never gotten past \"hello world\" with Julia, not for lack of interest, but mostly for lack of time and need. I would be interested to hear about that comparison as well. reply sanderjd 11 hours agorootparentHa I like your description of pandas as a work van. I totally have that same feel for it. It&#x27;s great because it works, not because it&#x27;s great :) reply hpcjoe 1 hour agorootparentprevAt a previous job, I regularly worked with dfs of millions to hundreds of millions of rows, and many columns. It was not uncommon for the objects I was working with to use 100+ GB ram. I coded initially in Python, but moved to Julia when the performance issues became to painful (10+ minute operations in Python that tookoperations on very large datasets can take multiple minutes in pandas. Polars is supposed to reduce that to a few seconds.Good example; I can see how efficiency would matter for workflows like that.I work with dataframes in the 10&#x27;s-100&#x27;s millions of rows (mostly in tidyverse, but also pandas and base python and R), and find most data wrangling operations are close to instant on modern laptops. Plotting is another story (not sure if polars helps there).So the case for efficiency is weak at the 10-100 million row dataframe size (unless doing some intense computations), but gains strength as the size of the dataframe grows.Would be a fun aside to test all these frameworks side by side with some 1m&#x2F;10m&#x2F;100m&#x2F;1bn row joins, filters, summary calcs, maps etc to get some concrete data on where efficiency starts to become noticeable and starts to matter. I think at sub 100m rows it probably doesn&#x27;t. Not for the kinds of operations I do anyway. reply dash2 5 hours agorootparentI&#x27;d be interested to know what proportion of users of dataframes are working at different orders of magnitude.Most of my life I&#x27;ve had databases of like 1000. Now I have a big one of about 500K! So for me, speed is almost a non-issue. But that is my specific field. reply antonvs 3 hours agoparentprevThere are lots of cases where execution times really matter. We use polars for exactly that reason. reply sanderjd 11 hours agoparentprevPersonally I prefer its API as well, but that seems to be a more controversial opinion than its often-huge performance wins. reply 90 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Polars is an open-source data processing framework designed for efficient parallelism and optimal performance.",
      "It supports various data formats and outperforms other solutions like pandas in terms of speed and efficiency.",
      "Polars is compatible with Apache Arrow and offers an out-of-core streaming API for large datasets. It is free to use under the MIT license with an active community of developers."
    ],
    "commentSummary": [
      "The Polars library is being discussed as an alternative to Pandas for faster and more flexible data analysis.",
      "Users are comparing Polars' benefits, documentation, usability, and performance to other libraries like Pandas, R, and Julia.",
      "The discussions highlight Polars' speed, clean API, but also mention its learning curve and lack of documentation."
    ],
    "points": 831,
    "commentCount": 344,
    "retryCount": 0,
    "time": 1704756774
  },
  {
    "id": 38923741,
    "title": "Python 3.13 Introduces JIT Compilation for Improved Performance",
    "originLink": "https://tonybaloney.github.io/posts/python-gets-a-jit.html",
    "originBody": "Toggle navigation Menu Home Projects Contributions Courses Podcasts Talks Blog Python 3.13 gets a JIT by Anthony Shaw, January 9, 2023 Happy New Year everyone! In late December 2023 (Christmas Day to be precise), CPython core developer Brandt Bucher submitted a little pull-request to the Python 3.13 branch adding a JIT compiler. This change, once accepted would be one of the biggest changes to the CPython Interpreter since the Specializing Adaptive Interpreter added in Python 3.11 (which was also from Brandt). In this blog post, we’re going to have a look at this JIT, what it is, how it works and what the benefits are. What is a JIT? JIT, or “Just in Time” is a compilation design that implies that compilation happens on demand when the code is run the first time. It’s a very broad term that could mean many things. I guess, technically the Python compiler is already a JIT because it compiles from Python code into Bytecode. What people tend to mean when they say a JIT compiler, is a compiler that emits machine code. This is in contrast to an AOT (Ahead of Time) compiler, like the GNU C compiler, GCC or the Rust compiler rustc which generates the machine code once and distributes as a binary executable. When you run Python code, it is first compiled into bytecodes. There are plenty of talks and videos about this process online so I don’t want to rehash this too much, but what is important to note about Python bytecodes is: They mean nothing to the CPU and require a special bytecode interpreter loop to execute They are high level and can equate to 1000’s of machine instructions They are type agnostic They are cross-platform For a very simple Python function f() that defines a variable a and assigns the value 1: def func(): a = 1 return a It compiles to 5 bytecode instructions, which you can see by running dis.dis: >>> import dis >>> dis.dis(f) 34 0 RESUME 0 35 2 LOAD_CONST 1 (1) 4 STORE_FAST 0 (a) 36 6 LOAD_FAST 0 (a) 8 RETURN_VALUE I have a more interactive disassembler called dissy as well if you want to try something more complicated. For this function, Python 3.11 compiled into the instructions LOAD_CONST, STORE_FAST, LOAD_CONST, and RETURN_VALUE. These instructions are interpreted when the function is run by a massive loop written in C. If you were to write a very crude Python evaluation loop in Python equivalent to the one in C, it would look something like this: import dis def interpret(func): stack = [] variables = {} for instruction in dis.get_instructions(func): if instruction.opname == \"LOAD_CONST\": stack.append(instruction.argval) elif instruction.opname == \"LOAD_FAST\": stack.append(variables[instruction.argval]) elif instruction.opname == \"STORE_FAST\": variables[instruction.argval] = stack.pop() elif instruction.opname == \"RETURN_VALUE\": return stack.pop() def func(): a = 1 return a If you gave this interpreter our test function, it would execute them and print the results: print(interpret(func)) This loop with a big switch/if-else statement is an equivalent, albeit simplified version of how CPython’s interpreter loop works. CPython is written in C and compiled by a C compiler. For the sake of simplicity I’ll build out this example in Python. For our interpreter, everytime you want to run the function, func it has to loop through each instruction and compare the bytecode name (called the opcode) with each if-statement. Both this comparison and the loop itself add an overhead to the execution. That overhead seems redundant if you run the function 10,000 times and the bytecodes never change (because they are immutable). It would be more efficient to instead generate the code in a sequence instead of a evaluating this loop every time you call the function. This is what a JIT does. There are many types of JIT compiler. Numba is a JIT. PyPy has a JIT. Java has lots of JITs. Pyston and Pyjion are JITs. The JIT that is proposed for Python 3.13 is a copy-any-patch JIT. What is a copy-and-patch JIT? Never heard of a copy-and-patch JIT? Don’t worry, nor had I and nor have most people. It’s an idea only proposed recently in 2021 and designed as a fast algorithm for dynamic language runtimes. I’ll try and explain what a copy-and-patch JIT is by expanding our interpreter loop and rewriting it as a JIT. Before, the interpreter loop did two things, first it interpreted (looked at the bytecode) then it executed (ran the instruction). What we can do instead is to seperate those tasks and have the interpreter output the instructions and not execute them. A copy-and-patch JIT is the idea that you copy the instructions for each command and fill-in-the-blanks for that bytecode arguments (or patch). Here’s a rewritten example, I keep the loop very similar but each time I append a code string with the Python code to execute: def copy_and_patch_interpret(func): code = 'def f():' code += ' stack = []' code += ' variables = {}' for instruction in dis.get_instructions(func): if instruction.opname == \"LOAD_CONST\": code += f' stack.append({instruction.argval})' elif instruction.opname == \"LOAD_FAST\": code += f' stack.append(variables[\"{instruction.argval}\"])' elif instruction.opname == \"STORE_FAST\": code += f' variables[\"{instruction.argval}\"] = stack.pop()' elif instruction.opname == \"RETURN_VALUE\": code += ' return stack.pop()' code += 'f()' return code This result for the original function is: def f(): stack = [] variables = {} stack.append(1) variables[\"a\"] = stack.pop() stack.append(None) return stack.pop() f() This time, the code is sequential and doesn’t require the loop to execute. We can store the resulting string and run it as many times as we like: compiled_function = compile(copy_and_patch_interpret(func), filename=\"\", mode=\"exec\") print(exec(compiled_function)) print(exec(compiled_function)) print(exec(compiled_function)) What was the point in that? Well the resulting code does the same thing, but it should run faster. I gave the two implementations to rich bench and the copy-and-patch method runs faster (Keep in mind though that loops in Python are very slow compared to C.) Why a copy-and-patch JIT? This technique of writing out the instructions for each bytecode and patching the values has upsides and downsides compared to a “full” JIT compiler. A full JIT compiler would normally compile high-level bytecodes like LOAD_FAST into lower level instructions in an IL (Intermediate Language). Because every CPU architecture has different instructions and features, it would be monumentally-complicated to write a compiler that converts high-level code directly to machine code and supports 32-bit and 64-bit CPUs, as well as Apple’s ARM architecture as well as all the other flavours of ARM. Instead most JIT’s compile first to an IL that is a generic machine-code-like instruction set. Those instructions are things like “PUSH A 64-bit integer”, “POP a 64-bit float”, “MULTIPLY the values on the stack”. The JIT can then compile IL into machine-code at runtime by emitting CPU-specific instructions and storing them in memory to be later executed (similar to how we did in our example). Once you have IL, you can run all sorts of fun optimizations on the code like constant propagation and loop hoisting. You can see an example of this in Pyjion’s live compiler UI. The big downside with a “full” JIT is that the process of compiling once into IL and then again into machine code is slow. Not only is it slow, but it is memory intensive. To illustrate this, data from recent research “Python meets JIT compilers: A simple implementation and a comparative evaluation” showed that Java-based JITs for Python like GraalPy, and Jython can take up to 100 times longer to start than normal CPython and consume up to an additional Gigabyte of RAM to compile. There are already full JIT implementations for Python. Copy-and-patch was selected because the compilation from bytecodes to machine code is done as a set of “templates” that are then stitched together and patched at runtime with the correct values. This means that your average Python user isn’t running this complex JIT compiler architecture inside their Python runtime. Python writing it’s own IL and JIT would also be unreasonable since so many are available off-the-shelf like LLVMs and ryuJIT. But a full-JIT would require those being bundled with Python and all the added overheads. A copy-and-patch JIT only requires the LLVM JIT tools be installed on the machine where CPython is compiled from source, and for most people that means the machines of the CI that builds and packages CPython for python.org. So how does this JIT work? The copy-and-patch compiler for Python works by extending some new (and honestly not widely known about) APIs to Python 3.13’s API. These changes enable pluggable optimizers to be discoverable at runtime in CPython and control how code is executed. This new JIT is an optional optimizer for this new architecture. I assume that it will be the default in future versions once the major bugs have been squashed. When you compile CPython from source, you can provide a flag --enable-experimental-jit to the configure script. This will generate machine-code templates for the Python bytecodes. This happens by first copying the C code for each bytecode, for example for LOAD_CONST, the simplest: frame->instr_ptr = next_instr; next_instr += 1; INSTRUCTION_STATS(LOAD_CONST); // Not used unless compiled with instrumentation PyObject *value; value = GETITEM(FRAME_CO_CONSTS, oparg); Py_INCREF(value); stack_pointer[0] = value; stack_pointer += 1; DISPATCH(); The instructions for this bytecode are first compiled by the C compiled into a little shared library and then stored as machine code. Because there are some variables normally determined at runtime, like oparg, the C code is compiled with those parameters left as 0. There is then a list of the 0 values that need to be filled in, called holes. For LOAD_CONST, there are 2 holes to be filled , the oparg and the next instruction: static const Hole _LOAD_CONST_code_holes[3] = { {0xd, HoleKind_X86_64_RELOC_UNSIGNED, HoleValue_OPARG, NULL, 0x0}, {0x46, HoleKind_X86_64_RELOC_UNSIGNED, HoleValue_CONTINUE, NULL, 0x0}, }; All of the machine code is then stored as a sequence of bytes in the file jit_stencil.h which is automatically generated by a new build stage. The disassembled code is stored as a comment above each bytecode template, where JIT_OPARG and JIT_CONTINUE are the holes to be filled: 0000000000000000 : pushq %rbp movq %rsp, %rbp movq (%rdi), %rax movq 0x28(%rax), %rax movabsq $0x0, %rcx 000000000000000d: X86_64_RELOC_UNSIGNED __JIT_OPARG movzwl %cx, %ecx movq 0x28(%rax,%rcx,8), %rax movl 0xc(%rax), %ecx incl %ecx je 0x3dmovq %gs:0x0, %r8 cmpq (%rax), %r8 jne 0x37movl %ecx, 0xc(%rax) jmp 0x3dlock addq $0x4, 0x10(%rax) movq %rax, (%rsi) addq $0x8, %rsi movabsq $0x0, %rax 0000000000000046: X86_64_RELOC_UNSIGNED __JIT_CONTINUE popq %rbp jmpq *%rax The new JIT compiler, will when activated copy the machine-code instructions for each bytecode into a sequence and replace the values for each template with the arguments for that bytecode in the code object. The resulting machine code is stored in memory and then each time the Python function is run, that machine-code is executed directly. You can see the JITted code if you compile my branch and try it on this test script then give it to a disassembler like Ada Pro or Hopper. At the moment, the JIT is only used if the function contains the JUMP_BACKWARD opcode which is used in the while statement but that will change in the future. Is it faster? The initial benchmarks show something of a 2-9% performance improvement. You might be disappointed by this number, especially since this blog post has been talking about assembly and machine code and nothing is faster than that right? Well, remember that CPython is already written in C and that was already compiled to machine-code by the C compiler. In most cases, this JIT will be executing almost the same machine-code instructions as it was before. However, think of this JIT as being the cornerstone of a series of much larger optimizations. None of which are possible without it. For this change to be accepted, understood and maintained in an open-source project it needs to start simple. The future is bright, the future is JIT compiled The challenges with the existing interpreter being compiled ahead-of-time are that there are fewer opportunities for serious optimizations. Python 3.11’s adaptive interpreter was a step in the right direction, but it needs to go a lot further for Python to see a step-change in performance. I think that whilst the first version of this JIT isn’t going to seriously dent any benchmarks (yet), it opens the door to some huge optimizations and not just ones that benefit the toy benchmark programs in the standard benchmark suite. Share on Twitter Copyright © Anthony Shaw 2020",
    "commentLink": "https://news.ycombinator.com/item?id=38923741",
    "commentBody": "Python 3.13 Gets a JITHacker NewspastloginPython 3.13 Gets a JIT (tonybaloney.github.io) 575 points by todsacerdoti 8 hours ago| hidepastfavorite266 comments haberman 3 minutes agoThe article describes that the new JIT is a \"copy-and-patch JIT\" (I&#x27;ve previously heard this called a \"splat JIT\"). This is a relatively simple JIT architecture where you have essentially pre-compiled blobs of machine code for each interpreter instruction that you patch immediate arguments into by copying over them.I once wrote an article about very simple JITs, and the first example in my article uses this style: https:&#x2F;&#x2F;blog.reverberate.org&#x2F;2012&#x2F;12&#x2F;hello-jit-world-joy-of-...I take some issue with this statement, made later in the article, about the pros&#x2F;cons vs a \"full\" JIT:> The big downside with a “full” JIT is that the process of compiling once into IL and then again into machine code is slow. Not only is it slow, but it is memory intensive.I used to think this was true also, because my main exposure to JITs was the JVM, which is indeed memory-intensive and slow.But then in 2013, a miraculous thing happened. LuaJIT 2.0 was released, and it was incredibly fast to JIT compile.LuaJIT is undoubtedly a \"full\" JIT compiler. It uses SSA form and performs many optimizations (https:&#x2F;&#x2F;github.com&#x2F;tarantool&#x2F;tarantool&#x2F;wiki&#x2F;LuaJIT-Optimizat...). And yet feels no more heavyweight than an interpreter when you run it. It does not have any noticeable warm up time, unlike the JVM.Ever since then, I&#x27;ve rejected the idea that JIT compilers have to be slow and heavyweight. reply jjice 2 hours agoprevThe last two-ish years have been insane for Python performance. Something clicked with the core team and they obviously made this a serious goal of theirs and the last few years have been incredible to see. reply eigenvalue 1 hour agoparentIt’s because the total dollars of capitalized software deployed in the world using Python has absolutely exploded from AI stuff. Just like how the total dollars of business conducted on the web was a big driver of JS performance earlier. reply pletnes 1 hour agoparentprevMicrosoft are paying core devs to work on it full time, for one. reply crabbone 54 minutes agoparentprevThere were no noticeable performance improvements in the course of the last two years. I have no idea what you are talking about.The major change that&#x27;s been going on in Python core development team is that Microsoft gets more and more power over what happens to Python. Various PSF authorities had strong links to Microsoft until today the head of PSF is straight up a Microsoft employee. Microsoft doesn&#x27;t like to advertise this fact, because it rightfully suspects that rebranding Python as \"Microsoft Python\" would scare off some old-timers at least, but de facto it is \"Microsoft Python\".The community gone from bad to worse. Any real discussion about the language stopped years ago. Today it&#x27;s a pretty top-down decision making process where there&#x27;s no feedback, no criticism is allowed etc. My guess is that Microsoft doesn&#x27;t have a plan for the third \"E\" here, but who knows? Maybe eventually they&#x27;ll find a way to move Python to CLR and will peddle their version of it? -- I wouldn&#x27;t be surprised if that happened, actually. reply attractivechaos 33 minutes agorootparent> There were no noticeable performance improvements in the course of the last two years.In fairness, Python did get faster. Python 3.9 took 82 seconds for sudoku solving and 62 seconds for interval query. Python 3.11 took 53 and 43 seconds, respectively [1]. v3.12 may be better. That said, whether the speedup is noticeable can be subjective. 10x vs 15x slower than v8 may not make much difference mentally.[1] https:&#x2F;&#x2F;github.com&#x2F;attractivechaos&#x2F;plb2 reply kzrdude 2 minutes agoprevHow do you access optimizations such as dead code removal and constant propagation using this technique? reply vanderZwan 5 hours agoprevI think it&#x27;s really cool that Haoran Xu and Fredrik Kjolstad&#x27;s copy-and-patch technique[0] is catching on, I remember discovering it through Xu&#x27;s blog posts about his LuaJIT remake project[1][2], where he intends to apply these techniques to Lua (and I probably found those through a post here). I was just blown away by how they \"recycled\" all these battle-tested techniques and technologies, and used it to synthesize something novel. I&#x27;m not a compiler writer but it felt really clever to me.I highly recommend the blog posts if you&#x27;re into learning how languages are implemented, by the way. They&#x27;re incredible deep dives, but he uses the details-element to keep the metaphorical descents into Mariana Trench optional so it doesn&#x27;t get too overwhelming.I even had the privilege of congratulating him the 1000th star of the GH repo[3], where he reassured me and others that he&#x27;s still working on it despite the long pause after the last blog post, and that this mainly has to do with behind-the-scenes rewrites that make no sense to publish in part.[0] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2011.13127[1] https:&#x2F;&#x2F;sillycross.github.io&#x2F;2022&#x2F;11&#x2F;22&#x2F;2022-11-22&#x2F;[2] https:&#x2F;&#x2F;sillycross.github.io&#x2F;2023&#x2F;05&#x2F;12&#x2F;2023-05-12&#x2F;[3] https:&#x2F;&#x2F;github.com&#x2F;luajit-remake&#x2F;luajit-remake&#x2F;issues&#x2F;11 reply checker659 5 hours agoparentM. Anton Ertl and David Gregg. 2004. Retargeting JIT Compilers by using C-Compiler Generated Executable Code. In Proceedings of the 13th International Conference on Parallel Architectures and Compilation Techniques (PACT &#x27;04). IEEE Computer Society, USA, 41–50.https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.5555&#x2F;1025127.1025995 reply lifthrasiir 4 hours agorootparentWhile bears a significant resemblance, Ertl and Gregg&#x27;s approach is not automatic and every additional architecture requires a significant understanding of the target architecture---including an ability to ensure that fully relocable code can be generated and extracted. In comparison, the copy-and-patch approach can be thought as a simple dynamic linker, and objects generated by unmodified C compilers are far more predictable and need much less architecture-specific information for linking. reply vanderZwan 4 hours agorootparentDoes Ertl and Gregg&#x27;s approach have any \"upsides\" over copy-and-patch? Or is it a case of just missing those one or two insights (or technologies) that make the whole thing a lot simpler to implement? reply lifthrasiir 4 hours agorootparentI think so, but I can&#x27;t say this any more confident until I get an actual copy of their paper (I used other review papers to get the main idea instead). reply vanderZwan 4 hours agorootparentprevAnton Ertl!At the moment, the JIT is only used if the function contains the JUMP_BACKWARD opcode which is used in the while statement but that will change in the future.Isn&#x27;t this the main reason why it&#x27;s only a 2-9% improvement? Not much Python code uses the while statement in my experience. reply milliams 7 hours agoprevBrandt gave a talk about this at the CPython Core Developer Sprint late last year https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HxSHIpEQRjs reply pjmlp 6 hours agoprevFinally!Regardless of the work being done in PyPy, Jython, GraalPy and IronPython, having a JIT in CPython seems to be the only way beyond \"C&#x2F;C++&#x2F;Fortran libs are Python\" mindset.Looking forward to its evolution, from 3.13 onwards. reply Iridescent_ 5 hours agoprevWasn&#x27;t CPython supposed to remain very simple in its codebase, with the heavy optimization left for other implementations to tackle? I seem to remember hearing as much a few years back. reply toyg 4 hours agoparentThat was the original idea, when Python started attracting interest from big corporations. It has however become clear that maintaining alternative implementations is very difficult and resource-intensive; and if you have to maintain compatibility with the wider ecosystem anyway (because that&#x27;s what users want), you might as well work with upstream to find solutions that work for everyone. reply lifthrasiir 4 hours agoparentprevThe copy-and-patch approach was explicitly chosen in order to minimize additional impacts on non-JIT-specific code base. reply mg 5 hours agoprevI love Python and use it for everything other than web development.One reason is performance. So if Python has a faster future ahead of it: Hurray!The other reason is that the Python ecosystem moved away from stateless requests like CGI or mod_php use and now is completely set on long running processes.Does this still mean you have to restart your local web application after any change you made to it? I heard that some developers automate that, so that everytime they save a file, the web application is restarted. That seems pretty expensive in terms of resource consumption. And complex as you would have to run some kind of watcher process which handles watching your files and restarting the application? reply onetoo 5 hours agoparentThe restart isn&#x27;t expensive in absolute terms, on a human level it&#x27;s practically instant. You would only do this during development, hopefully your local machine isn&#x27;t the production environment.It&#x27;s also very easy, often just adding a CLI flag to your local run command.edit: Regarding performance, Python today can easily handle at least 1k requests per second. The vast vast vast majority of web applications today don&#x27;t need anywhere near that kind of performance. reply ubercore 4 hours agorootparentBeen working with python for the web for over a decade. This is basically a solved issue, and the performance is a non-issue day to day. reply mg 2 hours agorootparentprevThe thing is, I don&#x27;t run my applications locally with a \"local run command\".I prefer to have a local system set up just like the production server, but in a container.Maybe using WSGI with MaxConnectionsPerChild=1 could be a solution? But that would start a new (for example) Django instance for every request. Not sure how fast Django starts.Another option might be to send a HUP signal to Apache: apachectl -k restartThat will only kill the worker threats. And when there are none (because another file save triggered it already), this operation might be almost free in terms of resource usage. This also would require WSGI or similar. Not sure if that is the standard approach for Django+Apache. reply onetoo 1 hour agorootparentI would still recommend running it properly locally, but whatever. Pseudo-devcontainer it is. I assume the code is properly volume mounted.In production, you would want to run your app through gunicorn&#x2F;uvicorn&#x2F;whatever on an internal-only port, and reverse-proxy to it with a public-facing apache or similar.Set up apache to reverse proxy like you would on prod, and run gunicorn&#x2F;uvicorn l&#x2F;whatever like you would on prod, except you also add the autoreload flag. E.g. uvicorn main:app --host 0.0.0.0 --port 12345 --reloadIf production uses containers, you should keep the python image slim and simple, including only gunicorn&#x2F;uvicorn and have the reverse proxy in another container. Etc. reply neurostimulant 5 hours agoparentprevIf you run the debug web server, (e.g. Django&#x27;s `manage.py runserver`) command, yes it has watcher that will automatically restart the web server process if there is a code changes.Once you deploy it to production, you usually run it using a WSGI&#x2F;ASGI server such as Gunicorn or Uvicorn and let whatever deployment process you use handles the lifecycle. You usually don&#x27;t use watcher in production.Basically similar stuff with nodejs, rails, etc. reply BiteCode_dev 3 hours agoparentprevIn dev, this is handled mostly by the OS with things like inotify, so it has little perf impact.In prod, you don&#x27;t do it. Deployment implies sending a signal like HUP to your app, so that it reloads the code gracefully.All in all, everybody is moving to thid, even php. This allows for persitent connexion, function memoization, delegation to threadpools, etc reply gklitz 1 hour agoparentprev> That seems pretty expensive in terms of resource consumption. And complex as you would have to run some kind of watcher process which handles watching your files and restarting the application?What? No, in reality it’s just running your app in debug mode (just a cli flag), and when you save the files the next refresh of the browser has the live version of the app. It’s neither expensive nor complex. reply hyperman1 1 hour agoprevThe article presents a copy and patch jit as something new, but I remember DOS&#x27;s quickbasic doing the same thing. It generated very bad assembly code in memory by patching together template assembly blocks with filled in values, with a lot of INT instructions toward the quickbasic runtime, but it did compile, not interprete. reply lucidguppy 5 hours agoprevIf python became fast, there&#x27;s a chance it may become a language eater. reply csjh 42 minutes agoparent2-9% isn&#x27;t changing any language hierarchies reply p4bl0 6 hours agoprevThis was a fantastic, very clear, write-up on the subject. Thanks for sharing!If the further optimizations that this change allows, as explained at the end of this post, are covered as well as this one, it promises to be a very interesting series of blog posts. reply darrenBaldwin03 14 minutes agoprevWoah - very interesting! reply hawk01 4 hours agoprevIt never hurts for any language to get an uplift in performance. Exciting to see python getting that treatment reply matsemann 4 hours agoprevWhat is it really JIT-ing? Given it says that it&#x27;s only relevant for those building CPython. So it&#x27;s not JIT-ing my Python code, right? And the interpreter is in C. So what is it JIT-ing? Or am I misunderstanding something?> A copy-and-patch JIT only requires the LLVM JIT tools be installed on the machine where CPython is compiled from source, and for most people that means the machines of the CI that builds and packages CPython reply lifthrasiir 4 hours agoparentCode fragments that implement each opcode in the core interpreter loop are additionally compiled in the way that each fragment is compiled into a relocatable binary. Once processed in that way, the runtime code generator can join required fragments by patching relocations, essentially doing the job of dynamic linkers. So it is compiling your Python code, but the compiled result is composed of pre-baked fragments with patches. reply fer 6 hours agoprevThe bit everyone wants:> The initial benchmarks show something of a 2-9% performance improvement.Which is underwhelming (as mentioned in the article), especially if we look at PyPy[0]. But it&#x27;s a step forward nonetheless.[0] https:&#x2F;&#x2F;speed.pypy.org&#x2F; reply woadwarrior01 6 hours agoparent> At the moment, the JIT is only used if the function contains the JUMP_BACKWARD opcode which is used in the while statement but that will change in the future.It&#x27;s a bit less underwhelming if you consider that only function objects with loops are being JITed. nb: for loops in Python also use the JUMP_BACKWARD op. reply lifthrasiir 4 hours agoparentprevPyPy was never able to get fast enough to replace CPython in spite of its lack of compatible C API. CPython is trying to move fast without breaking C API, and 2--9% improvement is in fact very encouraging for that and other reasons (see my other comment). reply eviks 6 hours agoprev> The initial benchmarks show something of a 2-9% performance improvement. You might be disappointed by this number, especially since this blog post has been talking about assembly and machine code and nothing is faster than that right?Indeed, reading the blog post build much higher expectations reply G3rn0ti 6 hours agoparentJust running machine code itself does not make a program magically faster. It‘s all about the amount of work the machine code is doing.For example, if the JIT compiler realizes the program is adding two integers it could potentially replace the code with two MOVs and a single ADD. However, what about the error handling in the case of an overflow? Python switches to its internal BigInt representation in this case and cannot rely on architecture specific instructions alone once the result gets too large to fit into a register.Modern programming languages are all about trading performance for convenience and that is what makes them slow — not because they are running an interpreter and not compiling to machine code. reply jokoon 43 minutes agoprevwhat are those future optimization he talks about?he talks about an IL, but what&#x27;s that IL? does that mean that the future optimization will involve that IL? reply jagaerglad 6 hours agoprevCan someone explain what a JIT compiler means in the case of an interpreted language? reply pjmlp 6 hours agoparentBasically a JIT (Just In Time), is also known as a dynamic compiler.It is an approach that traces back to original Lisp and BASIC systems, among others lesser kwown ones.The compiler is part of the language runtime, and code gets dynamically compiled into native code.Why is this a good approach?It allows for experiences that are much harder to implement in languages that tradicionally compile straight to native code like C (note there are C interpreters).So you can have an interpreter like experience, and code gets compiled to native code before execution on the REPL, either straight away, or after the execution gets beyond a specific threshold.Additionally, since dynamic languages per definition can change all the time, a JIT can profit from code instrumentation, and generate machine code that takes into account the types actually being used, something that an AOT approach for a dynamic language cannot predit, thus optimizations are hardly an option in most cases. reply irjustin 6 hours agoparentprevDid you read the article?> For our interpreter, everytime you want to run the function, func it has to loop through each instruction and compare the bytecode name (called the opcode) with each if-statement. Both this comparison and the loop itself add an overhead to the execution. That overhead seems redundant if you run the function 10,000 times and the bytecodes never change (because they are immutable). It would be more efficient to instead generate the code in a sequence instead of a evaluating this loop every time you call the function.> This is what a JIT does. There are many types of JIT compiler. Numba is a JIT. PyPy has a JIT. Java has lots of JITs. Pyston and Pyjion are JITs. reply cturner 6 hours agorootparentThe article will be a confusing read to someone who does not know what a JIT is.Look at the paper after the heading \"What is a JIT?\"The first paragraph moves towards an answer - \"compilation design that implies that compilation happens on demand when the code is run the first time\" But then it backtracks on this and says that it could mean many things, and gets wishy-washy, and says that python is already a JIT.The second paragraph says, \"What people tend to mean when they say a JIT compiler, is a compiler that emits machine code.\" What point is the author trying to make here? An Ahead of Time compiler emits machine code. But then it goes on to say that an Ahead of Time compiler also emits machine code. So what is a JIT?The third paragraph starts talking about about mechanism, which is a distraction from the question it posed above - what is a JIT?The article talks around points instead of making points. reply helboi4 6 hours agorootparentYeah as a junior without a CS degree I was reading this article thinking \"this is very interesting\" but found it very hard to really grasp the difference between Ahead of Time and JIT from their explanations. Just that it was different from the previous python interpreter method, which seems woefully inefficient. I do know that Java has a JIT and I&#x27;ve read about this, but I guess it became quickly clear that I didn&#x27;t really understand it since I couldn&#x27;t follow this article. I think I will need to read more about this elsewhere and come back to fully grasp the impact. reply pjc50 52 minutes agorootparent> very hard to really grasp the difference between Ahead of Time and JITJIT = \"just in time\" = bytecode is converted to native code while the program is running, either at the startup of the program or just before a particular function is called. Sometimes even after the function is called (since the JIT process itself takes time, it may be optimal to only run it once a function has been called N times or taken M microseconds total run time)AOT = \"ahead of time\" = bytecode is converted to native code before the program starts. i.e. by the developer during their distribution or deployment process. AOT compilation knows nothing about the specific run time conditions. reply dikei 5 hours agorootparentprevIt&#x27;s pretty clear to me.>> JIT, or “Just in Time” is a compilation design that implies that compilation happens on demand when the code is run the first time.>> What people tend to mean when they say a JIT compiler, is a compiler that emits machine code.A JIT compiler is a compiler that emits machine code the first time that code is run, vs an AOT compiler which emits machine code when the code is built. reply vanderZwan 5 hours agorootparentDid you already know what a JIT was before reading the article though? Confirming what you already know is a different thing than grokking it the first time. Plus in my brief but intense experience as someone teaching programming to artistic types who are scared of maths, it&#x27;s more useful to evaluate explanations by the possibility of being misunderstood and overwhelming, than the possibility of correctly interpreting it. replyLewisVerstappen 6 hours agoprevGreat article, but small typo when the author says \"copy-any-patch JIT\" reply ericvsmith 6 hours agoparentThat’s not a typo, that’s the name of the technique. reply kragen 6 hours agorootparenti think it&#x27;s &#x27;copy-and-patch&#x27; reply ericvsmith 5 hours agorootparentD’oh! Of course you’re correct. I skipped over “any”, and focused on “patch”. Sorry about that. reply kragen 4 hours agorootparentno harm done :) replyeterevsky 5 hours agoprevI&#x27;m even more excited to noGIL in 3.13. I wonder how these two features will play together? reply agounaris 1 hour agopreva 2-9% improvement at global scale is insane! This is not a small number by any means. reply wrd83 6 hours agoprevHonestly I don&#x27;t understand the pessimistic view here. I think every release since Microsoft started funding python has increased high single digit best case performance.Rather than focussing on the raw number compare to python 3.5 or so. It&#x27;s still getting significantly faster.If they keep doing this steady pace they are slowly saving the planet! reply systems 2 hours agoparentI think the pessimism really comes from a dislike for PythonWhile very very very popular, Python is i think is very disliked languages, it doesnt have or it is not built around the current programming language features that programmers like, its not functional or immutable by default, its not fast, the tooling is complex, it uses indentation for code blocks (this feature was cool in the 90s, but dreaded since at least 2010)so i guess if python become fasters, this will ensure its continued dominance, and all those hoping that one day it will be replace by a nicer , faster language are disappointedthis pessimism is the aching voice of the developers who were hoping for a big python replacement reply dbrueck 19 minutes agorootparentTo each his own, but the things you list are largely subjective&#x2F;inaccurate, and there are many, many, many developers who use Python because they enjoy it and like it a lot. reply oblio 4 hours agoparentprevWhen did Microsoft start funding Python?Also, such a shame that it takes sooo long for crucial open source to be funded properly. Kudos to Microsoft for doing it, shame on everyone else for not pitching in sooner.FYI Python was launched 32 years ago, Python 2 was released 24 years ago and Python 3 was released 16 years ago. reply epcoa 6 hours agoparentprevSorry, but reality bites https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Amdahl%27s_law reply vanderZwan 5 hours agorootparentIt&#x27;s not that simple.Amdahl&#x27;s Law is about expected speedup&#x2F;decrease in latency. That actually isn&#x27;t strongly correlated to \"saving the planet\" afaik (where I interpret that as reducing direct energy usage, as well as embodied energy usage by reducing the need to upgrade hardware).If anything, increasing speed and&#x2F;or decreasing latency of the whole system often involves adding some form of parallelism, which brings extra overhead and requires extra hardware. Note that prefetching&#x2F;speculative execution kind of counts here as well, since that is essentially doing potentially wasted work in parallel. In the past boosting the clock rate the CPU was also a thing until thermodynamics said no.OTOH, letting your CPU go to sleep faster should save energy, so repeated single-digit perf improvements via wasting less instructions does matter.But then again, that could lead to Jevons Paradox (the situation where increasing the efficiency encourages more wasteful than the increase in efficiency saves - Wirth&#x27;s Law but generalized and older, basically).So I&#x27;d say there&#x27;s too many interconnected dynamics at play to really simply state \"optimization good\" or \"optimization useless\". I&#x27;m erring on the side of \"faster Python probably good\".[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jevons_paradox reply jmakov 2 hours agoprevHow&#x27;s this different than running pypy? reply dagw 2 hours agoparentIt supports all your existing python code and python libraries (at the cost of being significantly slower than PyPy). reply jmdeschamps 2 hours agoprevMaybe the article should be dated \"January 9, 2024\" ??? (or is it really a year old article?) reply Pxtl 1 hour agoprevI still don&#x27;t get why they didn&#x27;t reduce API of the interpreter internals in Python 3 so that things like this would be more achievable.If you&#x27;re going to break backwards compatibility, it&#x27;s not like Unicode was the only foundational problem Python 2 had. reply ageitgey 6 hours agoprevFor the lazy who just want to know if this makes Python faster yet, this is foundational work to enable later improvements:> The initial benchmarks show something of a 2-9% performance improvement.> I think that whilst the first version of this JIT isn’t going to seriously dent any benchmarks (yet), it opens the door to some huge optimizations and not just ones that benefit the toy benchmark programs in the standard benchmark suite. reply vanderZwan 4 hours agoparentYou&#x27;re right, and in this case \"foundational work\" even undersells how minimal this work really is compared to the results it already gets.I recommend that people watch Brandt Bucher&#x27;s \"A JIT Compiler for CPython\" from last year&#x27;s CPython Core Developer Sprint[0]. It gives a good impression of the current implementation and its limitations, and some hints at what may or may not work out. It also indirectly gives a glimpse into the process of getting this into Python through the exchanges during the Q&A discussion.One thing to especially highlight is that this copy-and-patch has a much, much lower implementation complexity for the maintainers, as a lot of the heavy lifting is offloaded to LLVM.Case in point: as of the talk this was all just Brandt Bucher&#x27;s work. The implementation at the time was ~700 lines of \"complex\" Python, ~100 lines of \"complex\" C, plus of course the LLVM dependency. This produces ~3000 lines of \"simple\" generated C, requires an additional ~300 lines of \"simple\" hand-written C to come together, and no further dependencies (so no LLVM necessary to run the JIT. Also \"complex\" and \"simple\" qualifiers are Bucher&#x27;s terms, not mine).Another thing to note is that these initial performance improvements are just from getting this first version of the copy-and-patch JIT to work at all, without really doing any further fine-tuning or optimization.This may have changed a bit in the months since, but the situation is probably still comparable.So if one person can get this up and running in a few klocs, most of which are generated, I think it&#x27;s reasonable to have good hopes for its future.[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HxSHIpEQRjs reply lifthrasiir 5 hours agoparentprevAn important context here is that the same code was reused for interpreter and JIT implementations (that&#x27;s a main selling point for copy-and-patch JIT). In the other words, this 2--9% improvement mostly represents the core interpreter overhead that JIT should significant reduce. It was even possible that JIT itself might have no performance impact by itself, so this result is actually very encouraging; any future opcode specialization and refinement should directly translate to a measurable improvement. reply formerly_proven 4 hours agorootparentCopy&patch seems not much worse than compiling pure Python with Cython, which roughly corresponds to \"just call whatever CPython API functions the bytecode interpreter would call for this bunch of Python\", so that&#x27;s roughly a baseline for how much overhead you get from the interpeter bit. reply lifthrasiir 3 hours agorootparentThere is no reason to use copy-and-patch JIT if that were the case, because the good old threaded interpreter would have been fine. There are other optimization works in parallel with this JIT effort, including finer-grained micro operations (uops) that can replace usual opcodes at higher tiers. Uops themselves can be used without JIT, but the interpreter overhead is proportional to the number of (u)ops executed and would be too large for uops. The hope is that copy-and-patch JIT combined with uops have to be much faster than threaded code. reply blagie 5 hours agoparentprevFrom the write-up, I honestly don&#x27;t understand how this paves the way. I don&#x27;t see an architectural path from a cut-and-paste JIT to something optimizing. That&#x27;s the whole point of a cut-and-paste JIT. reply londons_explore 3 hours agorootparent> . I don&#x27;t see an architectural path from a cut-and-paste JIT to something optimizing.One approach used in V8 is to have a dumb-but-very-fast JIT (ie. this), and keep counters of how often each block of code runs (perhaps actual counters, perhaps using CPU sampling features), and then any block of code running more than a few thousand times run through a far more complex yet slower optimizing jit.That has the benefit that the 0.2% of your code which uses 95% of the runtime is the only part that has to undergo the expensive optimization passes. reply Sesse__ 25 minutes agorootparentNote that V8 didn&#x27;t have a dumb-but-very-fast JIT (Sparkplug) until 2021; the interpreter (Ignition) did that block counting and sent it straight to the optimizing JIT (TurboFan).V8 pre-2021 (i.e., only Ignition+TurboFan) was significantly faster than current CPython is, and the full current four-tier bundle (Ignition+Sparkplug+Maglev+TurboFan) only scores roughly twice as good on Speedometer as pure Ignition does. (Ignition+Sparkplug is about 40% faster than Ignition alone; compare that “dumbness” with CPython&#x27;s 2–9%.) The relevant lesson should be that things like very carefully designed value representation and IR is a much more important piece of the puzzle than having as many tiers of compilation as possible. reply uluyol 15 minutes agorootparentIn case anyone is interested, V8 pre-ignition&#x2F;TurboFan had different tiers [1]: full-codegen (dumb and fast) and crankshaft (optimizing). It&#x27;s interesting to see how these things change over time.[1]: https:&#x2F;&#x2F;v8.dev&#x2F;blog&#x2F;ignition-interpreter reply lumpa 5 hours agorootparentprevThere&#x27;s a lot of effort going on to improve CPython performance, with optimization tiers, etc. It seems the JIT is how at least part of that effort will materialize: https:&#x2F;&#x2F;github.com&#x2F;python&#x2F;cpython&#x2F;issues&#x2F;113710> We&#x27;re getting a JIT. Now it&#x27;s time to optimize the traces to pass them to the JIT. reply fulafel 1 hour agorootparentprevSupport for generating machine code at all seems like a necessary building block to me and probably is quite a bit of effort to work on top of a portable interpreter code base. reply guenthert 4 hours agorootparentprevIsn&#x27;t it the case that Python allows for type specifier (type hints) since 3.5, albeit the CPython interpreter ignores them? The JIT might take advantage of them, which ought to improve performance significantly for some code.That what makes Python flexible is what makes it slow. Restricting the flexibility were possible offers opportunities to improve performance (and allows for tools and humans to spot errors more easily). reply a-french-anon 4 hours agorootparentIsn&#x27;t CL a good counter-example to that \"dynamism inherently stunts performances\" mantra? reply guenthert 3 hours agorootparentTo the contrary. In CL some flexibility was given up (compared to other LISP dialects) in favor of enabling optimizing compilers, e.g. the standard symbols cannot be reassigned (also preserving the sanity of human readers). CL also offers what some now call &#x27;gradual typing&#x27;, i.e. optional type declarations. And remaining flexibility, e.g. around the OO support, limits how well the compiler can optimize the code. reply Joker_vD 3 hours agorootparentBut type declarations in Python are not required to be correct, are they? You are allowed to write def twice(x: int) -> int: return x + x print(twice(\"nope\"))and it should print \"nopenope\". Right? reply Ringz 2 hours agorootparentYep. Therefore it’s better to def twice(x: int) -> int: if not isinstance(x, int): raise TypeError(\"Expected x to be an int, got \" + str(type(x))) return x + x reply sgerenser 32 minutes agorootparentSurely this is the job for a linter or code generator (or perhaps even a hypothetical ‘checked’ mode in the interpreter itself)? Ain’t nobody got time to add manual type checks to every single function. reply jhardy54 1 hour agorootparentprevThis can have substantial performance implications, not to mention DX considerations. replyDifwif 3 hours agorootparentprevAFAIK good JITs like V8 can do runtime introspection and recompile on the fly if types change. Maybe using the type hints will be helpful but I don&#x27;t think they are necessary for significant improvement. reply cuchoi 2 hours agorootparentDoesn&#x27;t Python already do this? https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=shQtrn1v7sQ reply amelius 2 hours agorootparentprevAre there any benchmarks that give an idea of how much this might improve Python&#x27;s speed? reply mike_hearn 1 hour agorootparentWell, GraalPython is a Python JIT compiler which can exploit dynamically determined types, and it advertises 4.3x faster, so it&#x27;s possible to do drastically better than a few percent. I think that&#x27;s state of the art but might be wrong.That&#x27;s for this benchmark:https:&#x2F;&#x2F;pyperformance.readthedocs.io&#x2F;Note that this is with a relatively small investment as these things go, the GraalPython team is about ~3 people I guess, looking at the GH repo. It&#x27;s an independent implementation so most of the work went into being compatible with Python including native extensions (the hard part).But this speedup depends a lot on what you&#x27;re doing. Some types of code can go much faster. Others will be slower even than CPython, for example if you want to sandbox the native code extensions. reply pletnes 1 hour agorootparentprevPypy is a different JIT that gives anything from slower&#x2F;same to 100x speedup depending on the benchmark. They give a geometric mean of 4.8x speedup across their suite of benchmarks. https:&#x2F;&#x2F;speed.pypy.org&#x2F; reply formerly_proven 4 hours agorootparentprevYou can&#x27;t really on type annotations to help interpret the code. reply Someone 4 hours agorootparentprevIt should be fairly easy to add instruction fusing, where they recognize often-used instruction pairs, combine their C code, and then let the compiler optimize the combined code. Combining LOAD_CONST with the instruction following it if that instruction pops the const from the stack seems an easy win, for example. reply ncruces 1 hour agorootparentIf it was that easy, you&#x27;d do that in the interpreter and proportionally reduce interpretation overhead. reply Someone 59 minutes agorootparentIn the interpreter, I don’t think it wouldn’t reduce overhead much, if at all. You’d still have to recognize the two byte codes, and your interpreter would spend additional time deciding, for most byte code pairs, that it doesn’t know how to combine them.With a compiler, that part is done once and, potentially, run zillions of times. reply ncruces 29 minutes agorootparentIf fusing a certain pair would significantly improve performance of most code, you&#x27;d just add that fused instruction to your bytecode and let the C compiler optimize the combined code in the interpreter. I have to assume CPython as already done that for all the low hanging fruit.In fact, for such a fused instruction to be optimized that way on a copy-and-patch JIT it&#x27;d need to exist as a new bytecode in interpreter. A JIT that fuses instructions is no longer a copy-and-patch JIT.A copy-and-patch JIT reduces interpretation overhead by making sure the branches in the executed machine code are the branches in the code to be interpreted, not branches in the interpreter.This is make a huge difference in more naive interpreters, not so much in an heavily optimized threaded-code interpreter.The 10% is great, and nothing to sneeze at for a first commit. But I&#x27;d actually like some realistic analysis of next steps for improvement, because I&#x27;m skeptical instruction fusing and other things being hand waved are it. Certainly not on a copy-and-patch JIT.For context: I spent significant effort trying to add such instruction fusing to a simple WASM AOT compiler and got nowhere (the equivalent of constant loading was precisely one of the pairs). Only moving to a much smarter JIT (capable of looking at whole basic blocks of instructions) started making a difference. replyattractivechaos 49 minutes agoparentprevI wouldn&#x27;t be so enthusiastic. Look at other languages that have JIT now: Ruby and PHP. After years of efforts, they are still an order of magnitude slower than V8 and even PyPy [1]. It seems to me that you need to design a JIT implementation from ground up to get good performance – V8, Dart and LuaJIT are like this; if you start with a pure interpreter, it may be difficult to speed it up later.[1] https:&#x2F;&#x2F;github.com&#x2F;attractivechaos&#x2F;plb2 reply vlovich123 26 minutes agorootparentPyPy is designed from the ground up and is still slower than V8 AFAIK. Don’t forget that v8 has enormous amounts of investment from professionally paid developers whereas PyPy is funded by government grants. Not sure about Ruby & PHP and it’s entirely possible that the other JIT implementations are choosing simplicity of maintenance over eking out every single bit of performance.Python also has structural challenges like native extensions (don’t exist in JavaScript) where the API forces slow code or massive hacks like avoiding the C API at all costs (if I recall correctly I read that’s being worked on) and the GIL.One advantage Python had is the ability to use multiple cores way before JS but the JS ecosystem remained single threaded longer & decided to use message passing instead to build WebWorkers which let the JIT remain fast. reply attractivechaos 19 minutes agorootparentPyPy is only twice as slow as v8 and is about an order of magnitude faster than CPython. It is quite an achievement. I would be very happy if CPython could get this performance but I doubt. reply chaxor 43 minutes agoparentprevAnyone know if there will be any better tools for cross-compiling python projects?The package management and build tools for python have been so atrociously bad (environments add far too much complexity to the ecosystem) that it turns many developers away from the language altogether. A system like Rust&#x27;s package management, build tools, and cross compilation capability is an enormous draw, even without the memory safety. The fact that it actually works (because of the package management and build tools) is the main reason to use the language really. Python used to do that ~10 years ago. Now absolutely nothing works. It takes weeks to get simple packages working, only can do anything under extremely brittle conditions that nullify the project you&#x27;re trying to use this other package for, etc.If python could ever get it&#x27;s act together and make better package management, and allow for cross-compiling, it could make a big difference. (I am aware of the very basic fact that it&#x27;s interpreted rather than compiled yada yada - there are still ways to make executables, they are just awful). Since python is data science centric, it would be good to have decent data management capabilities too, but perhaps that could be after fundamental problem are dealt with.I tried looking at mojo, but it&#x27;s not open source, so I&#x27;m quite certain that kills any hope of it ever being useful at all to anyone. The fact that I couldn&#x27;t even install it without making an account made me run away as fast as possible. reply mcoliver 2 minutes agorootparentHave you taken a look at Nuitka with GitHub actions for cross compilation? https:&#x2F;&#x2F;github.com&#x2F;Nuitka&#x2F;Nuitka-Action reply riperoni 13 minutes agorootparentprevI can&#x27;t answer your initial question, but I do like to pile onto the package management points.Package consumption sucks so bad, since the sensible way of using are virtual envs where you copy all dependencies. Then for freezing venvs or dumping package versions, so you can port your project to a different system, doesn&#x27;t consider only packages actually used&#x2F;imported in code, but it just dumps everything in the venv. The fact you need external tools for this is frustrating.Then there is package creation. Legacy vs modern approach, cryptic __init__ files, multiple packaging backends, endless sections in pyproject.toml, manually specifying dependencies and dev-dependencies, convoluted ways of getting package metadata actually in code without having it in two places (such as CLI programs with --version).Cross compilation really would be a nice feature to simply distribute a single file executable. I haven&#x27; tested it, but a Linux system with Wine should in theory be capable of \"cross\" compiling between Linux and Windows.Still, like you, as a beginning I would prefer a sensible package management and package creation process. reply simonw 34 minutes agorootparentprev\"It takes weeks to get simple packages working\"Can you expand on what you mean by that? I have trouble imagining a Python packaging problem that takes weeks to resolve - I&#x27;d expect them to either be resolvable in relatively short order or for them to prove effectively impossible such that people give up. reply chaxor 9 minutes agorootparent- Trying to figure out what versions the scripts used and specifying them in a new poetry project - Realizing some OS-dependent software is needed so making a docker file&#x2F;docker-compose.yml - Getting some of it working in the container with a poetry environment - Realizing that other parts of the code work with other versions, so making a different poetry environment for those parts - Trying to tie this package&#x2F;container as a dependency of another project - Oh actually, this is a dependency of a dependency - How do you call a function from a package running in a container with multiple poetry environments in a package? - What was I doing again? - 2 weeks have passed trying to get this to work, perhaps I&#x27;ll just do something elseRinse and repeat.¯\\_(ツ)_&#x2F;¯ That&#x27;s python! reply schemescape 40 minutes agoparentprevDoes the benchmark suite track memory usage and disk space?I’m sure “industrial” uses of Python will happily trade those for speed, but sometimes I prefer the small size&#x2F;low resource usage of an interpreter, so I’m curious about the impact there. reply Topfi 5 hours agoparentprevHonestly, 2-9% already seems like a very signficant improvement, especially since as they mention \"remember that CPython is already written in C\". Whilst it&#x27;s great to look at the potential for even greater gains by building upon this work, I feel we shouldn&#x27;t undersell what&#x27;s been accomplished. reply spacechild1 5 hours agorootparent> \"remember that CPython is already written in C\"What is this supposed to say? Most scripting language interpreters are written in low level languages (or assembly), but that alone doesn&#x27;t say anything about the performance of the language itself. reply eequah9L 21 minutes agorootparentI think they mean that a lot of runtime of any benchmark is going to be spent in the C bits of the standard library, and therefore not subject to the JIT. Only the glue code and the bookkeeping or whatnot that the benchmark introduces would be improved by the JIT. This reduces the impact that the JIT can make. reply nertirs 3 hours agorootparentprevThis means, that a lot of python libraries like polars or tensorflow are written not in python.So python programs, that already spend most of its cpu time running these libraries code, won&#x27;t see much of an impact. reply gh02t 1 hour agorootparentIsn&#x27;t the point that if pure Python was faster they wouldn&#x27;t need to be written in other [compiled] languages? Having dealt with Cython it&#x27;s not bad, but if I could write more of my code in native Python my development experience would be a lot simpler.Granted we&#x27;re still very far from that and probably won&#x27;t ever reach it, but there definitely seems to be a lot of progress. reply __MatrixMan__ 44 minutes agorootparentSince Nim compiles to C, a middle step worth being aware of is Nim + nimporter which isn&#x27;t anywhere near \"just python\" but is (maybe?) closer than \"compile a C binary and call it from python\".Or maybe it&#x27;s just syntactic sugar around that. But sugar can be nice. reply bomewish 5 hours agorootparentprevAlso recall that a 50% speed improvement in SQLite was caused by 50-100 different optimisations that each eeked out 0.5-1% speedups. On phone now don’t have the ref but it all adds up. reply boxed 5 hours agorootparentMany small improvements is the way to go in most situations. It&#x27;s not great clickbait, but we should remember that we got from a single cell at some time to humans through many small changes. The world would be a lot better if people just embraced the grind of many small improvements... reply toyg 5 hours agorootparentprevMarginal gains. https:&#x2F;&#x2F;www.bbc.co.uk&#x2F;news&#x2F;magazine-34247629 reply Akronymus 5 hours agorootparentprevI tried searching for that article because I vaguely recall it, but can&#x27;t find it either. But yeah, a lot of small improvements add up. Reminds me of this talk: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=NZ5Lwzrdoe8 reply Topfi 5 hours agorootparentHere is a source for the SQLite case: https:&#x2F;&#x2F;topic.alibabacloud.com&#x2F;a&#x2F;sqlite-387-a-large-number-o... reply Akronymus 4 hours agorootparentThat looks like blogspam to me, rather than an actual source. reply formerly_proven 4 hours agorootparentprevhttps:&#x2F;&#x2F;sqlite-users.sqlite.narkive.com&#x2F;CVRvSKBs&#x2F;50-faster-t... reply IshKebab 3 hours agorootparentprevThat&#x27;s true, and Rust compiler speed has seen similar speedups from lots of 1% improvements.But even if you can get a 2x improvement from lots of 1% improvements (if you work really really hard), you&#x27;re never going to get a 10x improvement.Rust is never going to compile remotely as quickly as Go.Python is never going to be remotely as fast as Rust, C++, Go, Java, C#, Dart, etc. reply inglor_cz 1 hour agorootparentDoes it matter?Trains are never going to beat jets in pure speed. But in certain scenarios, trains make a lot more sense to use than jets, and in those scenarios, it is usually preferable having a 150 mph train to a 75 mph train.Looking at the world of railways, high-speed rail has attracted a lot more paying customers than legacy railways, even though it doesn&#x27;t even try to achieve flight-like speeds.Same with programming languages, I guess. reply adastra22 5 hours agorootparentprevWhat is being accomplished then? reply gray_-_wolf 5 hours agorootparent2-9% reply sylware 2 hours agoparentprevI removed the SDKs of some big (big for the wrong reasons) open source projects which generates a lot of code using python3 scripts.In those custom SDKs, I do generate all the code at the start of the build, which takes a significant amount of time for mostly non-pertinent anymore&#x2F;inappropiately done code generation.. I will really feel python3 speed improvement for those builds. reply cqqxo4zV46cp 6 hours agoprevUnfortunate to see a couple of comments here drive-by pulling out the “x% faster” stat whilst minimising the context. This is a big deal and it’s effectively a given that this’ll pave the way for further enhancements. reply benrutter 4 hours agoparentThis is so true!A JIT compiler is a big deal for performance improvements, especially where it matters (in large repetitive loops).Anyone cynical about the potential a python JIT offers should take a look at pypy which has a 5x speed up over regular python, mainly though JIT operations: https:&#x2F;&#x2F;www.pypy.org&#x2F; reply pjmlp 6 hours agoparentprevIt is a very big deal, as it will finally shift the mentality regarding:- \"C&#x2F;C++&#x2F;Fortran libs are Python\"- \"Python is too dynamic\", while disregarding Smalltalk, Common Lisp, Dylan, SELF, NewtonScript JIT capabilities, all dynamic languages where anything can change at any given moment reply pdimitar 6 hours agorootparentWhat do you mean by \"it will shift the mentality\"? There is no magical JIT that will ever make e.g. the data science Python & C++ amalgamations slower than a pure Python. Likely never happening, too.Also no mentality shift is expected on the \"Python is too dynamic\" -- which is a strange thing to say anyway -- because Python is not getting any more static due to these JIT news. reply superlopuh 5 hours agorootparentI&#x27;m fairly certain that this is false, and am working on proving it. In the cases that Numba is optimised for it&#x27;s already faster than plausible C++ implementations of the same kernels.https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;36526708&#x2F;comparing-pytho... reply eigenspace 2 hours agorootparentNumba is basically another language embedded in Python. It (sometimes severely) modifies the semantics of code. reply pas 4 hours agorootparentprevit&#x27;s not faster, it&#x27;s about as fast as C++ compiled with O3 optimizations. which is great and also much more likely to be true. reply pjmlp 6 hours agorootparentprevPython with JIT is faster than Python without JIT.Having a Python with JIT, in many cases it will be fast enough for most cases.Data science running CUDA workloads isn&#x27;t the only use case for Python. reply eesmith 5 hours agorootparentI think Python without a JIT in many cases is already fast enough for most cases.I don&#x27;t do data science. reply pjmlp 4 hours agorootparentSure, for UNIX scripting, for everything else it is plainfully slow.I know Python since version 1.6, and is my scripting language in UNIX like environments, during my time at CERN, I was one of the CMT build infrastructure build engineer on the ATLAS team.It was never been the language I would reach for when not doing OS scripting, and usually when a GNU&#x2F;Linux GUI application happens to be slow as mollasses, it has been written in Python. reply sirsinsalot 3 hours agorootparentMy teams deploy Python web APIs and yes, it is slow compared to other languages and runtimes.But on the whole, machines are cheaper than other engineering approaches to scaling.For us, and many others, fast enough is fast enough. reply andrewaylett 3 hours agorootparentprevA Python web service my team maintains, running at a higher request rate and with lower CPU and RAM requirements than most of the Java services I see around us, would like a word with you. reply pjmlp 3 hours agorootparentI guess those Java developers really aren&#x27;t. reply IggleSniggle 3 hours agorootparentprevHow many requests per second are we talking, ballpark, and what&#x27;s the workload? reply eesmith 1 hour agorootparentprevThere&#x27;s a lot of Django going on in the world.shrug. If we&#x27;re talking personal experience, I&#x27;ve been using Python since 1.4. It&#x27;s been my primary development language since the late 1990s, with of course speed critical portions in C or C++ when needed - and I know a lot of people who also primarily develop in Python.And there&#x27;s a bunch of Python development at CERN for tasks other than OS scripting. (\"The ease of use and a very low learning curve makes Python a perfect programming language for many physicists and other people without the computer science background. CERN does not only produce large amounts of data. The interesting bits of data have to be stored, analyzed, shared and published. Work of many scientists across various research facilities around the world has to be synchronized. This is the area where Python flourishes\" - https:&#x2F;&#x2F;cds.cern.ch&#x2F;record&#x2F;2274794)I simply don&#x27;t see how a Python JIT is going to make that much of a difference. We already have PyPy for those needing pure Python performance, and Numba for certain types of numeric needs.PyPy&#x27;s experience shows we&#x27;ll not be expecting a 5x boost any time soon from this new JIT framework, while C&#x2F;C++&#x2F;Fortran&#x2F;Rust are significantly faster. reply pjmlp 1 hour agorootparent> There&#x27;s a lot of Django going on in the world.Unfortunely.> And there&#x27;s a bunch of Python development at CERN for tasks other than OS scriptingOf course there is, CMT was a build tool, not OS scripting.No need to give me CERN links to me to show me Python bindings to ROOT, or Jupyter notebooks.> PyPy&#x27;s experience shows we&#x27;ll not be expecting a 5x boost any time soon from this new JIT framework, while C&#x2F;C++&#x2F;Fortran&#x2F;Rust are significantly faster.I really don&#x27;t get the attitude that if it doesn&#x27;t 100% fix all the world problems, then it isn&#x27;t worth it. reply formerly_proven 4 hours agorootparentprevI really wouldn&#x27;t mind Python being faster than it is and I really didn&#x27;t mind at all getting an practically free ~30% performance increase just by updating to 3.11. There&#x27;s tons of applications which just passively benefit from these optimizations. Sure, you might argue \"but you shouldn&#x27;t have written that parser or that UI handling a couple thousand items in Python\" but lots of people do and did just that. reply fnord123 5 hours agorootparentprev> it will finally shift the mentality regarding \"C&#x2F;C++&#x2F;Fortran libs are Python\"But pjmlp, I use Python because it&#x27;s a wrapper for C&#x2F;C++&#x2F;Fortran libs. - Chocolate Giddyup reply astrolx 1 hour agorootparentI can dig it! reply pjmlp 4 hours agorootparentprevJust like Tcl happens to be. reply japanman185 6 hours agorootparentprevDisregarding the fact that python is an awful programming language for anthing other than jupyter notebooks reply pjmlp 6 hours agorootparentAnother one that hasn&#x27;t seen UNIX scripting in shell languages or Perl, Apache modules, before Python came to be. reply BossingAround 6 hours agorootparentprevFacts are objective; \"Python is awful\" is your opinion. reply cqqxo4zV46cp 3 hours agorootparentprevThis comment is really just bordering on a rule violation and doesn’t add to the conversation at all. reply moffkalast 3 hours agorootparentprevAh I&#x27;d say the exact opposite, python in general is pretty good but jupyter sucks because the syntax isn&#x27;t compatible with regular python and I avoid it like the plague. reply crabbone 48 minutes agoparentprevI don&#x27;t see this as an enhancement.Not pursuing JIT or efficient compilation in general was a deliberate decision way back when Python made some kind of sense. It was the simplicity of implementation valued over performance gains that motivated this decision.The mantra Python programmers liked to repeat was that \"the performance is good enough, and if you want to go fast, write in C and make a native module\".And if you didn&#x27;t like that, there was always Java.Today, Python is getting closer and closer to be \"the crappy Java with worse syntax\". Except we already have that: it&#x27;s called Groovy. reply frakt0x90 39 minutes agorootparentWhat are you talking about? From what I can read here there is no syntax change. Just a framework for faster execution. Plus, Python&#x27;s usecase has HEAVILY evolved over the last few years since it&#x27;s now the defacto language for machine learning. It&#x27;s great that the core devs are keeping up with the time.The language is definitely getting more complex syntactically, and I&#x27;m not a huge fan of some of those changes but it&#x27;s no where near Java or C++ or anything else. You can still write simple Python with all of these changes. reply adonese 5 hours agoparentprevis it any different or comparable to numba or pyjion? Not following python closely in recent years but I recount those two projects with huge potential reply drbaba 5 hours agorootparentI don’t know Pyjion, but I have used Numba for real work. It’s a great package and can lead to massive speed-ups.However, last time I used it, it (1) didn’t work with many third-party libraries (e.g. SciPy was important for me), and (2) didn’t work with object-oriented code (all your @njit code had to be wrapped in functions without classes). Those two has limited for which projects I could adopt Numba in practice, despite loving it in the cases it worked.I don’t know what limitations the built-in Python JIT has, but hopefully it might be a more general JIT that works for all Python code. reply kragen 6 hours agoparentprevmaybe, maybe not. time will tell. ahead-of-time compilation is even better known for improving performance and yet perl&#x27;s compile-to-c backend turned out to fail to do that reply cube2222 6 hours agorootparent> ahead-of-time compilation is even better known for improving performanceNot necessarily, not for dynamic languages.With very dynamic languages you can make only very limited assumptions about e.g. function argument types, which lead you to compiled functions that have to handle any possible case.A JIT compiler can notice that the given function is almost always (or always) used to operate on a pair of integers, and do a vastly superior specialized compilation, with guards to fallback on the generic one. With extensive inlining, you can also deduplicate a lot of the guards. reply kragen 5 hours agorootparentyes, that is true. but aot compilers never make things slower than interpretation, and they can afford more expensive optimizationsalso, even mature jit compilers often only make limited improvements; jython has been stuck at near-parity with cpython&#x27;s terrible performance for decades, for example, and while v8 was an enormous improvement over old spidermonkey and squirrelfish, after 15 years it&#x27;s still stuck almost an order of magnitude slower than c https:&#x2F;&#x2F;benchmarksgame-team.pages.debian.net&#x2F;benchmarksgame&#x2F;... which is (handwaving) like maybe a factor of 2 or 3 slower than selftypically when i can get something to work using numpy it&#x27;s only about a factor of 5 slower than optimized c, purely interpretively, which is competitive with v8 in many cases. luajit, by contrast, is goddam alien technology from the futurewith respect to your int×int example, if an int×int specialization is actually vastly superior, for example because the operation you&#x27;re applying is something like + or *, an aot compiler can also insert the guard and inline the single-instruction implementation, and it can also do extensive inlining and even specialization (though that&#x27;s rare in aots and common in jits). it can insert the guards because if your monomorphic sends of + are always sending + to a rational instance or something, the performance gain from eliminating megamorphic dispatch is comparatively slight, and the performance loss from inserting a static hardcoded guess of integer math before the megamorphic dispatch is also comparatively slight, though nonzerothis can fall down, of course, when your arithmetic operations are polymorphic over integer and floating-point, or over different types of integers; but it often works far better than it has any right to. in most code, most arithmetic and ordered comparison is integers, most array indexing is arrays, most conditionals are on booleans (and smalltalk actually hardcodes that in its bytecode compiler). this depends somewhat on your language design, of course; python using the same operator for indexing dicts, lists, and even strings hurts it heremeanwhile, back in the stop-hitting-yourself-why-are-you-hitting-yourself department, fucking cpython is allocating its integers on the heap and motherfucking reference-counting them reply ptx 5 hours agorootparentThere is already an AOT compiler for Python: Nuitka[0]. But I don&#x27;t think it&#x27;s much faster.And then there is mypyc[1] which uses mypy&#x27;s static type annotations but is only slightly faster.And various other compilers like Numba and Cython that work with specialized dialects of Python to achieve better results, but then it&#x27;s not quite Python anymore.[0] https:&#x2F;&#x2F;nuitka.net&#x2F;[1] https:&#x2F;&#x2F;github.com&#x2F;python&#x2F;mypy&#x2F;tree&#x2F;master&#x2F;mypyc reply kragen 4 hours agorootparentthanks, i&#x27;d forgotten about nuitka and didn&#x27;t know about mypyc! reply actionfromafar 4 hours agorootparentCheck out:https:&#x2F;&#x2F;shedskin.github.io&#x2F;Python to C++ translation reply vanderZwan 4 hours agorootparentprev> fucking cpython is allocating its integers on the heap and motherfucking reference-counting themAnd here I thought that it was shocking to learn that v8 allocates doubles on the heap recently. (I mean, I&#x27;m not a compiler writer, I have no idea how hard it would be to avoid this, but it feels like mandatory boxed floats would hurt performance a lot) reply kragen 4 hours agorootparentnanboxing as used in spidermonkey (https:&#x2F;&#x2F;piotrduperas.com&#x2F;posts&#x2F;nan-boxing) is a possible alternative, but i think v8 works pretty hard to not use floats, and i don&#x27;t think local-variable or temporary floats end up on the heap in v8 the way they do in cpython. i&#x27;m not that familiar with v8 tho (but i&#x27;m pretty sure it doesn&#x27;t refcount things) reply vanderZwan 3 hours agorootparent> i think v8 works pretty hard to not use floatsCorrect, to the point where at work a colleague and I actually have looked into how to force using floats even if we initiate objects with a small-integer number (the idea being that ensuring our objects having the correct hidden class the first time might help the JIT, and avoids wasting time on integer-to-float promotion in tight loops). Via trial and error in Node we figured that using -0 as a number literal works, but (say) 1.0 does not.> i don&#x27;t think local-variable or temporary floats end up on the heap in v8 the way they do in cpythonThis would also make sense - v8 already uses pools to re-use common temporary object shapes in general IIRC, I see no reason why it wouldn&#x27;t do at least that with heap-allocated doubles too. reply kragen 3 hours agorootparentso then the remaining performance-critical case is where you have a big array of floats you&#x27;re looping over. in firefox that works fine (one allocation per lowest-level array, not one allocation and unprefetchable pointer dereference per float), but maybe in chrome you&#x27;d want to use a typedarray? reply vanderZwan 3 hours agorootparentMaybe, at that point it is basically similar to the struct-of-arrays vs array-of-structs trade-off, except with significantly worse ergonomics and less pay-off. replyngrilly 4 hours agorootparentprevI so much agree with your comment on memory allocation. Everybody is focusing on JIT, but allocating everything on the heap, with no possibility to pack multiple values contiguously in a struct or array, will still be a problem for performance. reply pjmlp 6 hours agorootparentprevAhead-of-time compilation is a bad solution for dynamic languages, so that is an expected outcome for Perl.The base line should be how heavily dynamic languages like my favourite set, Smalltalk, Common Lisp, Dylan, SELF, NewtonScript, ended up gaining from JIT, versus the original interpreters, while being in the genesis of many relevant papers for JIT research. reply kragen 6 hours agorootparentwhen i wrote ur-scheme one of the surprising things i learned from it was that ahead-of-time compilation worked amazingly well for scheme. scheme is ruthlessly monomorphic but i was still doing a type check on every primitive argumenti didn&#x27;t realize they ever jitted newtonscript reply pjmlp 6 hours agorootparentNewtonScript 2.0 introduced a mechanism to manually JIT code, functions marked as native get compiled into machine code.Had the Newton not been canceled, probably there would be an evolution from that support.See \"Compiling Functions for Speed\"https:&#x2F;&#x2F;www.newted.org&#x2F;download&#x2F;manuals&#x2F;NewtonToolkitUsersGu... reply kragen 6 hours agorootparentthis is great, thanks! but it sounds like it was an aot compiler, not a jit compiler; for example, it explains that a drawback of compiling functions to native code is that they use more memory, and that the compiler still produces bytecode for the functions it compiles natively, unless you suppress the bytecode compilation in project settings reply pjmlp 5 hours agorootparentYeah, I guess if one wants to go more technical, I see it as the first step of a JIT that didn&#x27;t had the opportunity to evolve due to market decisions. reply kragen 5 hours agorootparenti guess if they had, we would know whether a jit made newtonscript faster or slower, but they didn&#x27;t, so we don&#x27;t. what we do know is that an aot compiler sometimes made newtonscript faster (though maybe only if you added enough manifest static typing annotations to your source code)that seems closer to the opposite of what you were saying in the point on which we were in disagreement? reply pjmlp 4 hours agorootparentI guess my recolection regarding NewtonScript wasn&#x27;t correct, if you prefer that I put it like that, however I am quite certain in regards to the other languages in my list. reply kragen 4 hours agorootparenti agree that the other languages gained a lot for suremaybe i should have said that up front!except maybe common lisp; all the implementations i know are interpreted or aot-compiled (sometimes an expression at a time, like sbcl), but maybe there&#x27;s a jit-compiled one, and i bet it&#x27;s greatprobably with enough work python could gain a similar amount. it&#x27;s possible that work might get done. but it seems likely that it&#x27;ll have to give up things like reference-counting, as smalltalk did (which most of the other languages never had) reply cryptos 6 hours agoprevI always wondered how Python can be one of the world&#x27;s most popular languages without anyone (company) stepping up and make the runtime as fast as modern JavaScript runtimes. reply CJefferson 6 hours agoparentA big part of what made Python so successful was how easy it was to extend with C modules. It turns out to be very hard to JIT Python without breaking these, and most people don’t want a Python that doesn’t support C extension modules.The JavaScript VMs often break their extensions APIs for speed, but their users are more used to this. reply toyg 5 hours agorootparentJS doesn&#x27;t really have the tradition of external modules that Python has, for a long time it only really existed inside the browser. reply amelius 2 hours agorootparentprevOn the other hand, rewriting the C modules and adapting them to a different C API is very straightforward after you&#x27;ve done 1 or 2 of such modules. Perhaps it&#x27;s even something that could be done by training an LLM like Copilot. reply Pxtl 1 hour agorootparentprevWhich is why I&#x27;m shocked that Python&#x27;s big \"we&#x27;re breaking backwards compatibility\" release (Python 3) was mostly just for Unicode strings. It seems like the C API and the various __builtins__ introspection API thingies should&#x27;ve been the real focus on breaking backwards compatibility so that Python would have a better future for improvements like this. reply dagw 6 hours agoparentprevanyone (company) stepping up and make the runtime as fast as modern JavaScript runtimes.There are a lot of faster python runtimes out there. Both Google and Instagram&#x2F;Meta have done a lot of work on this, mostly to solve internal problems they&#x27;ve been having with python performance. Microsoft has also done work on parallel python. There&#x27;s PyPy and Pythran and no doubt several others. However none of these attempts have managed to be 100% compatible with the current CPython (and more importantly the CPython C API), so they haven&#x27;t been considered as replacements.JavaScript had the huge advantage that there was very little mission critical legacy JavaScript code around they had to take into consideration, and no C libraries that they had to stay compatible with. Meaning that modern JavaScript runtime teams could more or less start from scratch. Also the JavaScript world at the time were a lot more OK with different JavaScript runtimes not being 100% compatible with each other. If you &#x27;just&#x27; want a faster python runtime that supports most of python and many existing libraries, but are OK with having to rewrite some your existing python code or third party libraries to make it work on that runtime, then there are several to choose from. reply mike_hearn 1 hour agorootparentGoogle&#x2F;Instagram have done bits, but the company that&#x27;s done the most serious work on Python performance is actually Oracle. GraalPython is a meaningfully faster JIT (430% faster vs 7% for this JITC!) and most importantly, it can utilize at least some CPython modules.They test it against the top 500 modules on PyPI and it&#x27;s currently compatible with about half:https:&#x2F;&#x2F;www.graalvm.org&#x2F;python&#x2F;compatibility&#x2F;But investment continues. It has some other neat features too like sandboxing and the ability to make single-binary programs.The GraalPython guys are working on the HPy effort as well, which is an attempt to give Python a properly specified and engine-neutral extension API. reply skriticos2 4 hours agorootparentprevJS also had the major advantage of being sandboxed by design, so they could work from there. Most of the technical legacy centered around syntax backwards compatibility, but it&#x27;s all isolated - so much easier to optimize.Python with it&#x27;s C API basically gives you the keys to the kingdom on a machine code level. Modifying something that has an API to connect to essentially anything is not an easy proposition. Of course, it has the advantage that you can make Python faster by performance analysis and moving the expensive parts to optimized C code, if you have the resources. reply Pxtl 1 hour agorootparentprevNode.js and Python 3 came out at around the same time. Python had their chance to tell all the \"mission critical legacy code\" that it was time to make hard changes. reply hot_gril 12 minutes agoparentprevJS&#x27;s syntax has improved in the past several years and new runtimes like NodeJS have expanded its horizons, but before that happened, Python on its own was way easier for non-web scripts, web servers, and math&#x2F;science&#x2F;ML&#x2F;etc. Optimized native libs and ecosystems for those things got built a lot earlier around Python, in some cases before NodeJS even existed.Python&#x27;s syntax is still nicer for mathy stuff, to the point where I&#x27;d go into job coding interviews using Python despite having used more JS lately. reply est31 6 hours agoparentprevPython is already fast where it matters: often, it is just used to integrate existing C&#x2F;C++ libraries like numpy or pytorch. It is more an integration language than one where you write your heavy algorithms in.For JS, during the time that it received its JITs, there was no cross platform native code equivalent like wasm yet. JS had to compete with plugins written in C&#x2F;C++ however. There was also competition between browser vendors, which gave the period the name \"browser wars\". Nowadays at least, the speed improvements for the end user thanks to JIT aren&#x27;t also that great, Apple provides a mode to turn off JIT entirely for security. reply nyanpasu64 5 hours agorootparentHaving recently implemented parallel image rendering in corrscope (https:&#x2F;&#x2F;github.com&#x2F;corrscope&#x2F;corrscope&#x2F;pull&#x2F;450), I can say that friends don&#x27;t let friends write performance-critical code in Python. Depending on prebuilt C++ libraries hampers flexibility (eg. you can&#x27;t customize the memory management or rasterization pipeline of matplotlib). Python&#x27;s GIL inhibits parallelism within a process, and the workaround of multiprocessing and shared memory is awkward, has inconsistencies between platforms, and loses performance (you can&#x27;t get matplotlib to render directly to an inter-process shared memory buffer, and the alternative of copying data from matplotlib&#x27;s framebuffer to shared memory wastes CPU time).Additionally a lot of the libraries&#x2F;ecosystem around shared memory (https:&#x2F;&#x2F;docs.python.org&#x2F;3&#x2F;library&#x2F;multiprocessing.shared_mem...) seems poorly conceived. If you pre-open shared memory in a ProcessPoolExecutor&#x27;s initializer functions, you can&#x27;t close them when the worker process exits (which might be fine, nobody knows!), but if you instead open and close a shared memory segment on every executor job, it measurably reduces performance, presumably from memory mapping overhead or TLB&#x2F;page table thrashing. reply amelius 2 hours agorootparent> Python&#x27;s GIL inhibits parallelism within a process, and the workaround of multiprocessing and shared memory is awkward, has inconsistencies between platforms, and loses performanceWell, imho the biggest problem with this approach to paralellism is that you&#x27;re stepping out of the Python world with gc&#x27;ed objects etc. and into a world of ctypes and serialization. It&#x27;s like you&#x27;re not even programming Python anymore, but more something closer to C with the speed of an interpreted language. reply mkesper 5 hours agorootparentprevThat&#x27;s why optional GIL will be so important. reply pas 4 hours agorootparentprev> Depending on prebuilt C++ libraries hampers flexibility (eg. you can&#x27;t customize the memory management or rasterization pipeline of matplotlib).But what is the counterfactual? Implementing the whole thing in Python? It seems much more work than forking&#x2F;fixing matplotlib. reply ngrilly 4 hours agorootparentprevWhat would you use instead of Python? reply pas 4 hours agorootparentCython? :o reply ephimetheus 6 hours agorootparentprevI think usually the term “browser wars” refers to the time when Netscape and Microsoft were struggling for dominance, which concluded in 2001.JavaScript JITs only emerged around 2008 with SpiderMonkey’s TraceMonkey, JavaScriptCore’s SquirrelFish Extreme, and V8’s original JIT. reply lifthrasiir 5 hours agorootparentThere were multiple browser wars, otherwise you wouldn&#x27;t need -s there ;-) reply bjackman 2 hours agoparentprevJavaScript has to be fast because its users were traditionally captive on the platform (it was the only language in the browser).Python&#x27;s users can always swap out performance critical components to another language. So Python development delivered more when it focussed on improving strengths rather than mitigating weaknesses.In a way, Python being slow is just a sign of a healthy platform ecosystem allowing comparative advantages to shine. reply JodieBenitez 6 hours agoparentprevBecause it&#x27;s already fast enough for most of us ? Anecdote, but I&#x27;ve had my share of slow things in Javascript that are not slow in Python. Try to generate a SHA256 checksum for a big file in the browser...Good to see progress anyways. reply jampekka 6 hours agorootparentPython&#x27;s SHA256 is written in C. And I&#x27;d quess Web Crypto API for JS is in the same ballbark.SHA256 in pure Python would be unusably slow. In Javascript it would be at least usably slow.Javascript is fast. Browsers are fast. reply JodieBenitez 5 hours agorootparentHave you tried to generate a SHA256 checksum for a file in the browser, no matter what crypto lib or api is available to you ? Have you tried to generate it using Python standard lib ?I did, and doing it in the browser was so bad that it was unusable. I suspect that it&#x27;s not the crypto that&#x27;s slow but the file reading. But anyway...> SHA256 in pure Python would be unusably slowNone would do that because:> Python&#x27;s SHA256 is written in CHence why comparing \"pure python\" to \"pure javascript\" is mostly irrelevant for most day to day tasks, like most benchmarks.> Javascript is fast. Browsers are fast.Well, no they were not for my use case. Browsers are really slow at generating file checksums. reply jiripospisil 4 hours agorootparentJust for giggles I tried this and I&#x27;m getting ~200ms when reading and hashing 50MB file in the browser (Chromium based) vs ~120ms using Python 3.11.6.https:&#x2F;&#x2F;gist.github.com&#x2F;jiripospisil&#x2F;1ae8b877b1c728536e382fc...https:&#x2F;&#x2F;jsfiddle.net&#x2F;yebdnz6x&#x2F; reply JodieBenitez 4 hours agorootparentNot so bad compared to what I tried a few years ago. Might finally be usable for us... reply jampekka 2 hours agorootparentAll major browsers have supported it for over eight years. Maybe the problem was between the seat and the keyboard?https:&#x2F;&#x2F;caniuse.com&#x2F;mdn-api_crypto_subtle reply JodieBenitez 2 hours agorootparentMaybe 8 years is not much in a career ? Maybe we had to support one of those browsers that did not support it ? Maybe your snarky comment is out of place ? And even to this day it&#x27;s still significantly slower than Python stdlib according to the tester. So much for \"why python not as fast as js, python is slow, blah blah blah\". reply adastra22 5 hours agorootparentprevThe Pytthon standard lib calls out to hand optimized assembly language versions of the crypto algos. It is of no relevance to a JIT-vs-interpreted debate. reply masklinn 4 hours agorootparentIt absolutely is relevant to the \"python is slow reee\" nonsense tho, which is the subject. Python-the-language being slow is not relevant for a lot of the users, because even if they don&#x27;t know they use Python mostly as a convenient interface to huge piles of native code which does the actual work.And as noted upthread that&#x27;s a significant part of the uptake of Python in scientific fields, and why pypy despite the heroic work that&#x27;s gone into it is often a non-entity. reply jampekka 4 hours agorootparentPython is slow, reee.This is a major problem in scientific fields. Currently there are sort of \"two tiers\" of scientific programmers: ones who write the fast binary libraries and ones that use these from Python (until they encounter e.g. having to loop and they are SOL).This is known as the two language problem. It arises from Python being slow to run and compiled languages being bad to write. Julia tries to solve this (but fails due to implementation details). Numba etc try to hack around it.Pypy is sadly vaporware. The failure from the beginning was not supporting most popular (scientific) Python libraries. It nowadays kind of does, but is brittle and often hard to set up. And anyway Pypy is not very fast compared to e.g. V8 or SpiderMonkey.Reee. reply pas 3 hours agorootparentThe major problem in scientific fields is not this, but the amount of incompetence and the race-to-the-bottom environment which enables it. Grant organizations don&#x27;t demand rigor and efficiency, they demand shiny papers. And that&#x27;s what we get. With god awful code and very questionable scientific value. reply jampekka 2 hours agorootparentThere are such issues, but I don&#x27;t think they are a very direct cause of the two language problem.And even these issues are part of the greater problem of late stage capitalism that in general produces god awful stuff with questionable value. E.g. vast majority of industry code is such. reply JodieBenitez 3 hours agorootparentprev> Julia tries to solve this (but fails due to implementation details)Care to list some of those details ? (I have zero knowledge in Julia) reply jampekka 2 hours agorootparentThis is quite a good intro: https:&#x2F;&#x2F;viralinstruction.com&#x2F;posts&#x2F;badjulia&#x2F; reply affinepplan 1 hour agorootparentfyi: the author of that post is a current Julia user and intended the post as counterpoint to their normally enthusiastic endorsements. so while it is a good intro to some of the shortfalls of the language, I&#x27;m not sure the author would agree that Julia has \"failed\" due to these details reply jampekka 16 minutes agorootparentYes, but it&#x27;s a good list of the major problems, and laudable for a self-professed \"stan\" to be upfront about them.It&#x27;s my assesment that the problems listed in there are a cause why Julia will not take off and we&#x27;re largely stuck with Python for the foreseeable future. adgjlsfhk1 2 minutes agorootparentIt is worth noting that the first of the reasons presented is significantly improved in Julia 1.9 and 1.10 (released ~8 months and ~1 month ago). The time for `using BioSequences, FASTX` on 1.10 is down to 0.14 seconds on my computer (from 0.62 seconds on 1.8 when the blog post was published).Scarblac 5 hours agorootparentprevThe point of Python is quickly integrating a very wide range of fast libraries written in other languages though, you can&#x27;t ignore that performance just because it&#x27;s not written in Python. reply el_oni 6 hours agoparentprevI think the thing with python is that it&#x27;s always been \"fast enough\" and if not you can always reach out to natively implemented modules. On the flipside javascript was the main language embedded in web browsers.There has been a lot of competition to make browsers fast. Nowadays there are 3 main JS engines, V8 backed by google, JavaScriptCore backed by apple, and spidermonkey backed by mozilla.If python had been the language embedded into web browsers, then maybe we would see 3 competing python engines with crazy performance.The alternative interpreters for python have always been a bit more niche than Cpython, but now that Guido works at microsoft there has been a bit more of a push to make it faster reply albertzeyer 6 hours agoparentprevIn lots of applications, all the computations already happen inside native libraries, e.g. Numpy, PyTorch, TensorFlow, JAX etc.And if you have a complicate computation graph, there are already JITs on this level, based on Python code, e.g. see torch.compile, or TF XLA (done by default via tf.function), JAX, etc.It&#x27;s also important to do JIT on this level, to really be able to fuse CUDA ops, etc. A generic Python JIT probably cannot really do this, as this is CUDA specific, or TPU specific, etc. reply Yasuraka 4 hours agoparentprevYou might want to checkout Mojo, which is not a runtime but a different language, but also designed to be a superset of Python. Beware though that it&#x27;s not yet open source, which is slated for this Q1https:&#x2F;&#x2F;docs.modular.com&#x2F;mojo&#x2F;manual&#x2F;edit: The main point I forgot to mention - it aims to compete with \"low-level\" languages like C and Rust in performance reply rfoo 6 hours agoparentprevBecause the reason why Python is one of the world&#x27;s most popular language (a large set of scientific computing C extensions) is bound to every implementation details of the interpreter itself. reply yellowstuff 6 hours agoparentprevThere have been several attempts. For example, Google tried to introduce a JIT in 2011 with a project named Unladen Swallow, but that ended up getting abandoned. reply pansa2 6 hours agorootparentUnladen Swallow was massively over-hyped. It was talked about as though Google had a large team writing “V8 for Python”, but IIRC it was really just an internship project. reply kragen 6 hours agorootparentwell, there were a couple of guys working on it reply xiphias2 6 hours agoparentprevBillions of dollars of product decisions use JS benchmark speed as one of the standard benchmarks to base buying decision on (for a good reason).For machine learning speed compiling to the right CUDA &#x2F; OpenCL kernel is much more crucial, so there&#x27;s where the money goes. reply fractalb 5 hours agoparentprevI still scratch my head why it’s not installed by default on Windows. reply tgv 5 hours agoparentprevTeaching. So many colleges&#x2F;unis I know teach \"Introduction to Programming\" with Python these days, especially to non-CS students&#x2F;pupils. reply bigfishrunning 4 hours agorootparentI think python is very well suited to people who do computation in Excel spreadsheets. For actual CS students, I&#x27;d rather see something like scheme be a first language (but maybe I&#x27;m just an old person) reply hot_gril 0 minutes agorootparentThey do both Python and Scheme in the same Berkeley intro to CS class. But I think the point of Scheme is more to expand students&#x27; thinking with a very different language. The CS fundamentals are still covered more in the Python part of the course. fer 6 hours agoparentprevEasy and the number-crunching libs are optimized away in (generally) C. reply PartiallyTyped 6 hours agorootparentand FORTRAN. reply FergusArgyll 3 hours agoparentprevBecause it doesn&#x27;t useGrossCamelCaseAsOften reply AndrewDucker 6 hours agoparentprevAlways interested in replies to this kind of comment, which basically boil down to \"Python is so slow that we have to write any important code in C. And this is somehow a good thing.\"I mean, it&#x27;s great that you can write some of your code in C. But wouldn&#x27;t it be great if you could just write your libraries in Python and have them still be really fast? reply hot_gril 2 minutes agorootparentPure JS libs are more portable. In Python, portability doesn&#x27;t matter as much. reply dannymi 6 hours agorootparentprev>I mean, it&#x27;s great that you can write some of your code in C. But wouldn&#x27;t it be great if you could just write your libraries in Python and have them still be really fast?That really depends.To make the issue clear, let&#x27;s think about a similar situation:bash is nice because you can plug together inputs and outputs of different sub-executables (like grep, sed and so on) and have a big \"functional\" pipeline deliver the final result.Your idea would be \"wouldn&#x27;t it be great if you could just write your libraries in bash and have them still be really fast?\". Not if you make bash into C, tanking productivity. And definitely not if that new bash can&#x27;t run the old grep anymore (which is what usually is implied by the proposal in the case of Python).Also, I&#x27;m fine with not writing my search engines, databases and matrix multiplication algorithm implementations in bash, really. So are most other people, I suspect.Also, many proposals would weaken Python-the-language so it&#x27;s not as expressive anymore. But I want it to stay as dynamic as it is. It&#x27;s nice as a scripting language about 30 levels above bash.As always, there are tradeoffs. Also with this proposal there will be tradeoffs. Are the tradeoffs worth it or not?For the record, rewriting BLAS in Python (or anything else), even if the result was faster (!), would be a phenomenally bad idea. It would just introduce bugs, waste everyone&#x27;s time, essentially be a fork of BLAS. There&#x27;s no upside I can see that justifies it. reply el_oni 6 hours agorootparentprevit depends what speed is most important to you.When i was a scientist, speed was getting the code written during my break, and if it took all afternoon to run that&#x27;s fine because i was in the lab anyway.Even as i moved more into the software engineer direction, and started profiling code more, most of the bottlenecks come from things like \"creating objects on every incovation rather than pooling them\", \"blocking IO\", \"using a bad algorithm\" or \"using the wrong datasctructure for the task\". problems that exist in every language, though \"bad algorithm\" or \"using the wrong datasctructure\" might matter less in a faster language you&#x27;re still leaving performance on the table.> \"Python is so slow that we have to write any important code in C. And this is somehow a good thing.\"The good thing is that python has a very vibrant ecosystem filled with great libraries, so we don&#x27;t have to write it in C, because somebody else has. We can just benefit from that when the situation calls for it reply dagw 6 hours agorootparentprevBut wouldn&#x27;t it be great if you could just write your libraries in PythonEverybody obviously wants that. The question is are you willing to lose what you have in order to hopefully, eventually, get there. If Python 3 development stopped and Python 4 came out tomorrow and was 5x faster than python 3 and a promise of being 50-100x faster in the future, but you have to rewrite all the libraries that use the C API, it would probably be DOA and kill python. People who want a faster &#x27;almost python&#x27; already have several options to choose from, none of which are popular. Or they use Julia. reply AndrewDucker 4 hours agorootparentWhy are you assuming that they&#x27;d have to rewrite all of their libraries? I don&#x27;t see anything in the article that says that. reply dagw 4 hours agorootparentThe reason this approach is so much slower than some of the other &#x27;fast&#x27; pythons out there that have come before is that they are making sure you don&#x27;t have to rewrite a bunch of existing libraries.That is the problem with all the fast python implementations that have come before. Yes, they&#x27;re faster than &#x27;normal&#x27; python in many benchmarks, but they don&#x27;t support the entire current ecosystem. For example Instagram&#x27;s python implementation is blazing fast for doing exactly what Instagram is using python for, but is probably completely useless for what I&#x27;m using python for. reply AndrewDucker 4 hours agorootparentAaah, so it&#x27;s not this approach that you&#x27;re saying is an issue, it&#x27;s the ones that significantly change Python. Gotcha, that makes sense. Thank you. reply bdd8f1df777b 6 hours agorootparentprevYes, but not so good when the JIT-ed Python can no longer reference those fast C code others have written. Every Python JIT project so far has suffered from incompatibility with some C-base Python extension, and users just go back to the slow interpreter in those cases. reply AndrewDucker 4 hours agorootparent\"not so good when the JIT-ed Python can no longer reference those fast C code others have written\"I don&#x27;t see an indication in the article that that&#x27;s the case. Am I missing something? reply kragen 4 hours agorootparentthis was a big obstacle for pypy specificallyhttps:&#x2F;&#x2F;www.pypy.org&#x2F;posts&#x2F;2011&#x2F;05&#x2F;numpy-follow-up-692862769...https:&#x2F;&#x2F;doc.pypy.org&#x2F;en&#x2F;latest&#x2F;faq.html#what-about-numpy-num...i&#x27;m not sure what version they gave up at reply JodieBenitez 6 hours agorootparentprevBetween writing C code and writing Python code, there is also Cython.But sure, I&#x27;m all for removing build steps and avoiding yet another layer. reply pdpi 5 hours agorootparentprevlanguages don’t need to all be good at the same thing. Python currently excels as a glue language you use to write drivers for modules written in lower-level languages, which is a niche that (afaik) nobody else seems to fill right now.While I’m all for making Python itself faster, it would be a shame to lose the glue language par excellence. reply PartiallyTyped 6 hours agoparentprevMeta has actually been doing that — helping improve python&#x27;s speed — with things like [1,2][1] https:&#x2F;&#x2F;peps.python.org&#x2F;pep-0703&#x2F;[2] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36643670 reply tomwphillips 6 hours agoparentprevBecause enough users find the performance sufficient. reply IshKebab 3 hours agoparentprevTwo reasons:1. Javascript is a less dynamic language than Python and numbers are all float64 which makes it a lot easier to make fast.2. If you want to run fast code on the web you only have one option: make Javascript faster. (Ok we have WASM now but that didn&#x27;t exist at the time of the Javascript Speed wars.) If you want to run fast code on your desktop you have a MUCH easier option: don&#x27;t use Python. reply 16 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Python 3.13 might introduce a Just-in-Time (JIT) compiler to enhance code performance.",
      "The JIT compiler compiles code into machine code on demand, removing the need for a bytecode interpreter loop.",
      "The new JIT compiler, a copy-and-patch JIT approach, converts high-level bytecodes into lower-level instructions in an Intermediate Language (IL) to optimize code execution.",
      "Initial benchmarks indicate a 2-9% performance improvement, although the impact on benchmarks may not be substantial.",
      "This JIT compiler lays the foundation for future significant optimizations in Python."
    ],
    "commentSummary": [
      "The Python community is actively discussing and exploring topics related to performance optimization and the use of JIT compilers.",
      "Python 3.13 introduces a new JIT compiler called \"copy-and-patch JIT,\" which is generating excitement and interest.",
      "The discussions cover a wide range of topics including Python development under Microsoft, the impact of long-running processes, JIT compilation benefits and challenges, confusion between JIT and AOT compilation, type declarations, performance comparisons, package management challenges, and the trade-offs between C and Python for performance-critical code."
    ],
    "points": 578,
    "commentCount": 266,
    "retryCount": 0,
    "time": 1704789358
  },
  {
    "id": 38917820,
    "title": "Loose bolts found on United's 737 Max 9 plug doors raise concerns",
    "originLink": "https://theaircurrent.com/feed/dispatches/united-finds-loose-bolts-on-plug-doors-during-737-max-9-inspections/",
    "originBody": "Air safety reporting by The Air Current is provided without a subscription as a public service. Please subscribe to gain full access to our all scoops, in-depth reporting and analyses. United Airlines has found loose bolts and other parts on 737 Max 9 plug doors as it inspects its fleet of Boeing jets following the Friday rapid depressurization aboard an Alaska Airlines jet of the same make, according to three people familiar with the findings. The discrepant bolts and other parts on the plug doors have been found on at least five aircraft, one of the people told The Air Current. A Boeing representative did not immediately respond to a request for comment. A spokeswoman for the Federal Aviation Administration declined to comment on the United findings, and pointed to the agency’s earlier statements. United confirmed the findings in a statement, saying, “Since we began preliminary inspections on Saturday, we have found instances that appear to relate to installation issues in the door plug – for example, bolts that needed additional tightening. These findings will be remedied by our Tech Ops team to safely return the aircraft to service.” The findings aboard the five United aircraft will likely significantly widen the fall-out from the grounding, intensifying the focus on Boeing and Spirit AeroSystems. The pair together is responsible for the assembly, installation and quality checks of the aircraft structure. Later Monday, Alaska Airlines confirmed it, too, had found issues with the plug doors on its grounded jets. “As our maintenance technicians began preparing our 737-9 Max fleet for inspections, they accessed the area in question. Initial reports from our technicians indicate some loose hardware was visible on some aircraft,” the company wrote. Related: Inside the strained union of Boeing and Spirit AeroSystems Across the five United aircraft, there is little consistency in the locations of the errant parts, according to documents reviewed by The Air Current. In one instance, United found that the bolts that affix the lower hinge of the plug door were not fully seated, and that the washers on the bolts could “spin”. Following @jonostrower‘s scoop on United finding 737-9s with loose door plug screws, a source sent this image of one of the door plug’s lower hinge bracket with a note that 2 screws are not screwed all the way in. https://t.co/sz1d997PdL pic.twitter.com/d6hgHAEb2u — Edward Russell (@ByERussell) January 8, 2024 Another aircraft was found to have loose bolts on the upper forward guide fitting on the plug and another on the forward guide roller that is an attachment point to the fuselage on the door frame. Additionally, screws that are part of the lower hinge bracket at the bottom of the plug on another aircraft were found to not be fully screwed in. The five aircraft were delivered to United between November 2022 and September 2023, according to ch-aviation, and would likely not have been through a heavy maintenance C check that occurs every 4,000 to 6,000 hours or two to three years. United is the only other U.S. airline to fly the 737 Max 9 and is the largest operator with 79 in its fleet. Alaska operates 65. Boeing earlier Monday confirmed that it had formally distributed a Multi-Operator Message (MOM) to 737 Max 9 operators, prescribing the specific inspection criteria that would satisfy the emergency airworthiness directive issued by the FAA on January 6, a day after the Alaska accident. Alaska on Monday morning said that before inspections could begin, the FAA would need to approve operators’ inspection processes to ensure compliance, and that the airline would need to develop detailed inspection instructions and processes for its maintenance technicians to follow. Alaska said that it canceled roughly 140 flights for Monday due to the 737 Max 9 grounding. NTSB investigators announced late Sunday that they had recovered the plug that violently separated from the Alaska flight at 16,000 feet. No one was hurt in the accident. The board has not released any specific findings related to the door or said whether the accident was in any way caused by discrepancies in the plug installation. Elan Head and Howard Slutsken also contributed to this article. Share Jon Ostrower Jon Ostrower is Editor-in-chief of The Air Current, where he leads coverage of the global aerospace and aviation industries. Prior to launching TAC in June 2018, Mr. Ostrower served as Aviation Editor for CNN Worldwide, guiding the network’s global coverage of the business and operations of aviation. Mr. Ostrower joined CNN in 2016 following four and a half years at the Wall Street Journal. Based first in Chicago and then in Washington, D.C., he covered Boeing, aviation safety, and the business of global aerospace. Before that, Mr. Ostrower was editor of FlightBlogger for Flightglobal and Flight International Magazine covering the development of the Boeing 787 Dreamliner and other new aircraft programs from 2007 to 2012. He is also an instructor at the University of Southern California in the Viterbi School of Engineering's Aviation Safety and Security program. Mr. Ostrower, a Boston native, graduated from The George Washington University’s School of Media and Public Affairs with a bachelor’s degree in Political Communication. He is based in Seattle. RELATED Alaska, United pull Max 9s from service pending clarity from FAA",
    "commentLink": "https://news.ycombinator.com/item?id=38917820",
    "commentBody": "United finds loose bolts on plug doors during 737 Max 9 inspectionsHacker NewspastloginUnited finds loose bolts on plug doors during 737 Max 9 inspections (theaircurrent.com) 470 points by etimberg 20 hours ago| hidepastfavorite672 comments MarkMarine 9 hours agoI was responsible for safe for flight inspections on military aircraft and the photo included in that post is completely insane to me.Those bolts being loose (and they are BIG bolts) would mean multiple people in the installation process didn’t do their jobs, and signed their life on the line saying they did.When I did maintenance, there was someone (QA) there to witness every torqued bolt, inspect every safety wire and installed part.There is something rotten in Boeing. reply RF_Savage 9 hours agoparentThe management imported from McDonnel-Douglas?The same management that drove it to ground?The fish rots from the head. And these constant problems sure do sound like a new company culture of cutting corners instead engineering first. reply leptons 8 hours agorootparentThe \"MAX\" in 737 MAX means \"maximum profit\", not \"maximum safety\". reply siva7 8 hours agorootparentYou&#x27;re joking but it&#x27;s the real meaning conveyed to their customers, the airliners. reply rob74 7 hours agorootparentYeah, that&#x27;s why the leading low-fare airlines (Southwest, Ryanair) love it - so it&#x27;s up to the customers to say that they no longer want to fly with an over 50 year old design that was initially a regional airplane but is now being used for transatlantic flights. replymarkdown 9 hours agorootparentprev> The management imported from McDonnel-Douglas?I&#x27;ve heard this since they killed hundreds of people in the two crashes. Why are they being protected? They have names. reply rob74 8 hours agorootparentBecause the shareholders like the management? Cutting corners to increase (short-term) profits is more popular with them than focusing on quality. And now that the company has been in the red consistently since 2019 (https:&#x2F;&#x2F;www.statista.com&#x2F;chart&#x2F;20660&#x2F;boeing-earnings-loss&#x2F;), of course the answer has to be to lower costs even more wherever possible in order to return to profitability... reply kakwa_ 8 hours agorootparentprevIt&#x27;s not necessarily a question of persons (and the CEO did a resigned after the Max crashes).It&#x27;s more a question of culture (oversimplifying, sales vs engineering) and this is harder to change most of the time. Apparently, even the Max debacle was not enough. reply aredox 6 hours agorootparentThe MD \"moles\" managed to change the culture of Boeing pretty quickly from engineering- to sales-first. https:&#x2F;&#x2F;www.theatlantic.com&#x2F;ideas&#x2F;archive&#x2F;2019&#x2F;11&#x2F;how-boeing... https:&#x2F;&#x2F;archive.ph&#x2F;vy5p7 reply sushibowl 5 hours agorootparentSome of these executive quotes read (admittedly with the benefit of hindsight) like satire.> But the nearest Boeing commercial-airplane assembly facility would be 1,700 miles away. The isolation was deliberate. “When the headquarters is located in proximity to a principal business—as ours was in Seattle—the corporate center is inevitably drawn into day-to-day business operations,” Condit explained at the time.Oh man, wouldn&#x27;t want that to happen.> With ethics now front and center, Condit was forced out and replaced with Stonecipher, who promptly affirmed: “When people say I changed the culture of Boeing, that was the intent, so that it’s run like a business rather than a great engineering firm.”Indeed. reply yencabulator 1 hour agorootparentprevWith a 63 million golden handshake for job well done, on top of the all the money he previously made.https:&#x2F;&#x2F;www.imdb.com&#x2F;title&#x2F;tt11893274&#x2F; reply markdown 7 hours agorootparentprev> and the CEO did a resigned after the Max crashesThat was a funny one. They replaced him with his chairman... hence, more of the same. reply rvba 9 hours agorootparentprevLooks like the installer did their job poorly and the QA rubber stamped it without checking. Are the QAs required to make photos to prove that they did their job? Like those food delivery people.Alternative is wrong bolts, or sabotage.But more possible - one lazy QA ghosting. reply goku12 3 hours agorootparentThey&#x27;re finding problems on multiple aircrafts. This isn&#x27;t one QA. In fact, forget QA missing this. Bolts on aerospace systems are supposed to be properly torqued and arrested in most cases. How do the assembly people make such big mistakes?In my experience, no one puts their job on the line over silly reasons like this, unless there is intense pressure (unrealistic deadlines, heavy workload and poor working conditions) that makes mistakes like this inevitable. I wouldn&#x27;t be surprised if an honest independent review of either company found ridiculous cost-cutting measures and&#x2F;or emotional overload. reply mywacaday 5 hours agorootparentprevI would doubt one lazy QA, more likely a over worked and time short QA in a company culture that does not allow them to speak up when they need additional support. reply legacynl 4 hours agorootparentExactly. This is a failure of management. reply glcihgnwe 8 hours agorootparentprevnext [9 more] [flagged] aredox 6 hours agorootparentThe MD merger is the reason quality nosedives. Management is responsible for ensuring a robust quality culture. If (if!) a few DEI trainings are enough to destroy that quality culture, then something is very wrong at Boeing anyway, and it was only a question of time.But of course, the parent comment isn&#x27;t made in good faith. The 737 MAX crashes happened end 2019-2020, and Boeing didn&#x27;t release its first-ever diversity report more than a year later: https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;lorenthompson&#x2F;2021&#x2F;04&#x2F;30&#x2F;boeing...As for why it didn&#x27;t nosedive immediatly after the merger, these kind of bankruptcies tend to happen \"Gradually, Then Suddenly\". reply nmacias 7 hours agorootparentprevthis site, yikes. In summary, we don’t know what happened yet, but you assume it’s the direct and obvious outcome of ? And that ?In that’s the game, then, I suspect the Spotify team was onsite to record a behind the scenes at Boeing podcast, and in the process replaced the locking nuts with Joe Rogan stickers. reply yftsui 7 hours agorootparentprevI heard a similar story regarding Boeing’s North Charleston factory due to that push, it leads to some Boeing customers request the last inspection done in the Everett factoryinstead before delivery. My bigger worry is 787 as apparently it is moving to SC. reply matthewmacleod 7 hours agorootparentprev“This aircraft failed because Boeing is too woke” is a pretty amazing take, I’ll grant you that. reply didntcheck 7 hours agorootparent\"because they were prioritizing other factors instead of competency\"That&#x27;s not a particularly outlandish take, and the other factor is orthogonal reply Snow_Falls 5 hours agorootparentDo you believe that other factor is wokeness, or is it maximising profit reply foldr 6 hours agorootparentprevGP appears to have a bee in their bonnet about wokeness (see post history). Unless they provide some evidence to support their take, I see no reason to take it seriously. reply boxed 7 hours agorootparentprevYou can prop up a bad system for many years by having a lot of workers still around from the old system. It takes time to fully drive a company as good as Boeing into the ground.Managers think they are the reason anything happens, but fortunately in this case this is a delusion. In places where a great manager tries to turn a business around that is broken that&#x27;s a bad thing. reply lvl102 4 hours agorootparentprev[REDACTED] reply throwup238 4 hours agorootparent737 Max 9s are made in Renton, WA. reply storf45 3 hours agoparentprevFrom when I worked as an engineer on the assembly line for smaller jets, know that there would be a record trail of exactly who completed the work, who signed off on it and what the work order steps were for anything related to these assemblies and components. This would include the work done at Boeing and their suppliers. Will be interesting to ultimately hear the root cause here. reply x86x87 1 hour agorootparentLet me ask this: assuming they did not tighten the bolts correctly and qa didn&#x27;t check it, what are the odds they keep an accurate paper trail? reply whatever1 8 hours agoparentprevBolts can get unscrewed with vibrations. So probably a design error, they did not use the correct type of bolt (the one with the safety pin). reply gregoriol 7 hours agorootparentDon&#x27;t they have many ways to prevent bolts from unscrewing? I know at least a few by doing mechanical stuff on motorcycles, and it seems that other planes don&#x27;t have such problems (at least not within 2 months after the last inspection). reply aredox 6 hours agorootparentThere are washers, or thread lock glue, but it is still a question of correct execution: has the glue been applied? Was the glue batch used before its shelf life? Were the parts degreased before glue application?Or did anyone decided to cut corners by using an old batch&#x2F;skipping degreasing&#x2F;not putting glue because they were late on delivery? reply MarkMarine 2 hours agorootparentsafety wire and cotter pins are preferred methods on aircraft. reply somewhereoutth 5 hours agorootparentprevMy understanding is that the bolts did have castle nuts and retaining wires in the design. So either they were incorrectly fitted, or the bolts themselves were under specified with regard to strength. reply 0xbadc0de5 3 hours agorootparentThe door hinge bolt had a castellated nut and pin, but the screws holding the hinge mount to the airframe apparently had no retaining wire. See leaked photo at: https:&#x2F;&#x2F;twitter.com&#x2F;ByERussell&#x2F;status&#x2F;1744460136855294106&#x2F;ph... reply aziaziazi 4 hours agorootparentprevNot sure what happened from “the design” to “the field”. The two loosen bolts in the picture are not castle nuts. reply MarkMarine 2 hours agorootparentprevThose bolts aren’t drilled for safety wire. reply stevehawk 5 hours agorootparentprevah. i&#x27;ve been wondering what the method of securing the bolts would have been and have not seen anyone mention it. torque values or threadlocker is rarely enough for the FAA. it&#x27;s usually safety wire, castle nuts, lock washers, etc. reply DANmode 4 hours agoparentprev> signed their life on the lineClearly this is hyperbole. reply MarkMarine 2 hours agorootparentIt wasn’t in the military. Doing this would land you in Leavenworth. reply stjohnswarts 4 hours agoparentprevDid you torque every bolt every time before every flight? reply MarkMarine 2 hours agorootparentEvery bolt you could see was checked before every flight yes. Every important bolt you couldn’t see during inspection was torqued, witnessed by QA, secured via safety wire or cotter pin, and secondary torque holding was then inspected by QA.This thing is obviously not just an interior part, look at the meat in those castings, and it’s obviously safety critical, look at the cotter pins on other bolts. Sounds like it was going to be installed behind interior paneling and not inspected every day. For something like that, every important bolt should be secured by secondary methods, torqued and witnessed installed correctly. This looks like a failure in engineering (not having wire on this bolts), then a profound failure in assembly with multiple people not doing their jobs (not torquing, not witnessing, faking logs), risking the lives of passengers.If this happened at cruising altitude and speed, people would have died. I can’t find the flight number but I believe 9 people died when a jet lost cabin pressure and a piece of the plane while decompressing during cruising altitude over water. reply defrost 2 hours agorootparentprevEvery scheduled maintainance that had that on the punch list, yes.With a seperate follow through by another party to check the work.That&#x27;s SOP for USAUUKEU military air mechanical crews. reply jasode 19 hours agoprevI found it interesting that Boeing did proactively tell airlines to inspect 737 MAXs for a possible loose bolt in a different part of the plane (rudder section) at least 8 days before the January 5th event. Example story: https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;aerospace-defense&#x2F;boeing-ur...Unfortunately, Boeing did not know they had other issues with the plug door bolts. reply nolok 16 hours agoparentImagine the quality of the manufacturing and QA &#x2F; final inspection to have that kind of issue. reply ethbr1 16 hours agorootparentI expect even at its worst, software development could learn a lot from aircraft QA.Especially since most shops have pretty much tossed professional career QA out the window. reply vegetablepotpie 15 hours agorootparentI work in the defense industry, it’s very much like the aerospace industry in that we deal with human life as a consequence of our work. We have software QA departments that operate very much like manufacturing or aerospace QA.Software QA provides nothing of value to software development; having it as a dedicated function works against the overtly stated goals of the function and counterintuitively acts to degrade quality within software by mandating strict top down process and brittle end-to-end testing.Although Software QA is intended to be an independent verification body that provides engineering organizations with tools and resources, in practice they function as a moral crumple zone [1] within the complex socio-technical defense industrial system, being one of the groups that the finger will be pointed to when something goes wrong and absorb shock to the business in the event of a failure. As a result they have a strong incentive to highly systematize their work with specific process steps, to shield them from liability, which can be applied generically to all projects.Good software teams build quality into projects by introducing continuous integration, unit testing, creating feedback, and tightening these feedback loops. This acts to find problems quickly and resolve them quickly. Software QAs need for high level, top down, generic systemization requires them to work against these principles in practice. Bespoke project specific checks, such as unit testing, is not viewed as contributing to the final product and is discouraged by leadership who see it as waste.To give an example of how these dynamics destroy quality in software. I once found a bug in software on a piece of test equipment where a logarithmic search function was not operating on a strictly sorted list. When I pointed this out to my leadership I was told that if we changed any part of code, it would require a new FQT, which would be too expensive to conduct and was not in the budget. Although the bug would have been trivial to solve, and was clearly wrong and would not provide any benefits by remaining in the test equipment software, the process required for changes prevented solving the issue.[1] https:&#x2F;&#x2F;papers.ssrn.com&#x2F;sol3&#x2F;papers.cfm?abstract_id=2757236 reply shermantanktop 13 hours agorootparentI’m going to be using “moral crumple zone” in every conversation I possibly can from now on. reply BlueUmarell 9 hours agorootparent\"Hey, wanna hang out with a beer this evening?\"\"Nah, I don&#x27;t need to slouch anymore in this moral crumple zone!\"\"We need this new feature in our program!\"\"If we implement this it means the management fell in a moral crumple zone\"\"What seat would you have to have for your flight?\"\"Anywhere, but not in the moral crumple zone, please\" reply shermantanktop 9 hours agorootparentAn example from my actual work life, lightly fictionalized—Them: “Please review this design.”Me: “Ok, sure, when do you plan to start coding?”Them: “Oh, it’s already in beta.”Me: “So you can’t do anything with my feedback, but you’ll say I reviewed it?”Them: “Well…”Me: “You’re putting me in a moral crumple zone here!” reply amluto 14 hours agorootparentprev> We have software QA departments that operate very much like manufacturing or aerospace QA.I don’t work in this industry, but this seems fairly ridiculous on its face: software is not at all like manufacturing.In manufacturing, there’s a design and a manufacturing process, and a critical function of QA is ensuring that the manufactured produce is manufactured to spec.With software, the software is written, compiled, and then repeatedly copied. And something should verify that it’s copied correctly, but this is straightforward and boring.So software QA ought to be much more like the kind of validation that happens when designing hardware, not like the kind of testing and validation that happens as products are manufactured. reply irrational 13 hours agorootparentIdeally there should be a solid spec written and then qa can test against the spec. Maybe there is somewhere that does write solid specs, including accounting for corner cases, but in my 25 years working professionally in the industry, I’ve never seen it. reply _glass 8 hours agorootparentI work in MedTech. We do this. A design has to be reviewed by QA, and is then tested, and the test is reviewed again. So just to counter the narrative, there are companies that do that, and it is working. In other jobs I also saw the cargo cult of QA. But in some industries it is just crucial, otherwise the pressure is too high to cut corners to implement something. It is a good mechanism to counter the need to move fast and break things. reply sgerenser 2 hours agorootparentprevI work in software for CPU design&#x2F;verification. Even here, where in theory there should be a rock-solid spec, there&#x27;s not. There&#x27;s a 12,000 page architectural specification, which is very helpful for specifying all the end-user visible state. But the microarchitectural specification is scattered all over different PDFs, visio docs, excel sheets, and sometimes the only spec is the RTL code itself. reply stickfigure 11 hours agorootparentprevThe only complete and precise specification of software is the code itself. If some other form of specification was complete, we would be able to auto-generate the code. reply cogwheel 10 hours agorootparentThis is beside the point. The code specifies what the product _is_, not what it \"should\" be. If you ask for a word processor and I deliver a perfectly bug-free and feature-complete calculator would you really believe it lived up to spec? reply _gabe_ 10 hours agorootparentThis is also beside the point. I think both of you are trying to warn against the dangers that lie on both sides of this coin: people can invest too heavily in a specification and waste an enormous amount of time, and people can immediately jump into coding and code something that does not do what it was intended to do. Like with all things in life, there’s a balance between these two extremes that’s correct.You need some level of specification so you know what you’re building, but you have to keep in mind that the final code defines what the behavior truly is. Sometimes, that behavior unintentionally becomes part of the specification because users begin to rely on it.I do like the fact that you both used hyperbole to succinctly illustrate the dangers of veering too far in either direction though :) reply legacynl 2 hours agorootparentprev> this seems fairly ridiculous on its faceI think that&#x27;s why people always tell each other to not take things at face value.Of course there is a big difference between sw and hw QA, in the thing that they test, and how they test them.But they are also very similar. Any QA department has to think about ways that things can go wrong, and what things to test for, how to test, which testing methods, which standards to handle, keeping certifications, etc. During testing you also need to keep reevaluating if you actually are catching each problem&#x2F;bug and how to implement changes in your company that decreases the amount of problems or increase the amount that you catch.I think in that way there&#x27;s a lot of overlap in thinking about business processes and how to identify problems with them.Of course once a specific binary gets tested and approved by QA it shouldn&#x27;t matter if it gets copied or whatever as long as you make sure its the same binary (by a checksum for example).But still making sure that errors don&#x27;t reach the customer, is vital in any QA. If errors does happen, QA is the department that can make sure that it doesn&#x27;t happen again. And ofc be able to proof in court that you did your due diligence if something does happen. reply jl6 4 hours agorootparentprevI&#x27;m not going to argue with the general thrust of your comment, which I think is insightful as to how incentives can compromise objectives. But...> To give an example of how these dynamics destroy quality in software. I once found a bug in software on a piece of test equipment where a logarithmic search function was not operating on a strictly sorted list. When I pointed this out to my leadership I was told that if we changed any part of code, it would require a new FQT, which would be too expensive to conduct and was not in the budget. Although the bug would have been trivial to solve, and was clearly wrong and would not provide any benefits by remaining in the test equipment software, the process required for changes prevented solving the issue.I&#x27;ve seen this happen where it was a bad thing, but also where it was a good thing.It&#x27;s all about risk.What risk does the software defect pose to the mission? What risk is inherent in making any change to the software? Noting that even trivial changes can be fat-fingered and thus are a source of risk. I&#x27;ve seen it go wrong this way: a seemingly trivial change was made, but the developer accidentally checked an extra file into source control, causing a further defect.And then: what is the cost of mitigating these risks? Maybe the software defect is as trivial as its fix. Maybe an acceptable fix would be to write up a workaround in the documentation.I don&#x27;t think it&#x27;s always wrong to say no to fixing issues. I also don&#x27;t think it&#x27;s always right that a separate QA department contributes nothing to the organization, even if they act as a handbrake on the software developers (sometimes, precisely because they do that). Human factors are real. reply 9659 14 hours agorootparentprevAbout 2000, Software QA (and almost all traditional QA activities) were changed. The focus was on process over inspection. \"Design in quality, do not inspect it into the product\"Suppliers (to include software) were expected to manage the quality of the product they provided; the purchaser would focus on how they managed the process, not in the compliance of every part.This had a chance until software process was tossed in the name of \"agile\". reply steve_gh 9 hours agorootparentI recall a bug I was involved with at a telecoms equipment market in the early 2000s. The bug only showed up in our biggest base stations in high load situations. We diagnosed the bug, and there were a couple of parts to it. Sloppy software design in an optional hardware module (no state machine) was one part - and was fixed. But there was another underlying issue in the way message queues were handled.Anyhow, the fix for this was created and written. But we never got to put it into production. The reason: the company didn&#x27;t have a lab test facility that could put a sufficient load on the software to prove it. Even though we were getting field failures because of this issue that were getting a bad rep, we couldn&#x27;t fix it because even though the old code was known to be buggy, we couldn&#x27;t prove the new code. So the process said we couldn&#x27;t ship it. reply bb88 13 hours agorootparentprevHere&#x27;s a stupid question: How do you know your process is good unless you inspect it?\"Hey Bob I know you&#x27;re a competent engineer, but don&#x27;t worry about specifying a certain type of bolt or loctite, the untrained assembly personnel will figure it out. I&#x27;m sure they won&#x27;t let 200 people die in a plane crash.\" reply zilti 4 hours agorootparentMake it impossible to use a wrong bolt, and train the assembly workers. reply ethbr1 15 hours agorootparentprev> Good software teams build quality into projects by introducing continuous integration, unit testing, creating feedback, and tightening these feedback loops.Agreed, for good software teams.I would content that most software teams at most companies are not good.Which is to ask, with an average to bad software team is it better to have integrated or separate QA? reply ajmurmann 10 hours agorootparentIf your devs aren&#x27;t good what are the chances of your QA team being good enough to make up for their short comings? The dynamics laid out by the parent comment will just hit even harder. Your best bet is to enforce basic practices like continuous integration, coverage goals and maybe a coverage ratchet as a merge gate. Training and education on areas were the team is weak is also a must. reply vegetablepotpie 14 hours agorootparentprevDoes it make sense to degrade the performance of good software teams because bad software teams exist?Ideally we’d always have good software teams, but in the real world sometimes you have to build software with bad teams.Leaders have options, they can do things like reduce scope, increase budget, increase schedule, or full on abandon or cancel the project. These are all options available to leaders, but they require tradeoffs and decisions to be made on a project by project basis.It is scalable to have a strict process that everyone has to follow, then impose a watchdog to enforce it on a wide scale. It may not be better to have separate QA, but it is easier for those in charge. reply ethbr1 14 hours agorootparentIt makes the most sense to me to match the org structure to the teams you have.If I&#x27;m trying to build something with undertrained, demoralized, underpaid engineers... it&#x27;s not optimal to use methods intended for self-motivated, high-performance teams.And nothing says there must be company-wide mandates. Maybe this area gets a formal, independent QA team, but this other area doesn&#x27;t.My experience just doesn&#x27;t bear out that collapsing the QA function into development always leads to better outcomes.I&#x27;ve seen the opposite happen too often, and QA be the sole bulwark between idiocy and customers. reply bb88 13 hours agorootparentprev> Ideally we’d always have good software teams, but in the real world sometimes you have to build software with bad teams.Here&#x27;s a real, perhaps unexpected counterpoint. Say you have a good software team. How do they build good software with bad management? reply iancmceachern 10 hours agorootparentQuit and do it for someone else reply xyzzy_plugh 13 hours agorootparentprevThey quit. reply bb88 13 hours agorootparentExactly! reply fzingle 11 hours agorootparentprev> Does it make sense to degrade the performance of good software teams because bad software teams exist?Consider the classic statistic \"most drivers think they are above average\".I posit that the same is true of software teams, almost every team will self-assess as above average, i.e. good. Those teams will then imagine that, being good, they build quality into the process and very little verification QA is done.I have worked as a software consultant for 15 years now. I&#x27;ve worked with at least 40 separate software teams in that time. Every single team manager would pep talk with \"this is the best team I&#x27;ve ever seen\". Some of this is obviously blowing smoke to get people to work harder and feel good. But over the years I&#x27;ve had candid conversations with managers and realized that most of the time the genuinely think their team is really good, truly top 10-20%.Here&#x27;s the rub. Being a consultant, I&#x27;m almost always brought in by higher level management because something is going horribly wrong. The team can&#x27;t deliver quickly. The software they deliver is bug ridden. They routinely deliver the wrong software (i.e. incorrect interpretation of requirements.)Often times these problems are not only the fault of the development team, management has issues too. But in every single case, the development team is in dire straits. They have continuous integration sure, and unit tests, and nightly builds, and lots of green check marks. But the unit tests test that the test works. The stress tests have no reality based basis for expected load. The continuous integration system builds software but it can&#x27;t be deployed in that form for x, y & z reasons, so production has a special build system, etc...In 15 years I have never once encountered a team that would not benefit from a QA team doing boring, old school, black box manual testing. And the teams that most adamantly refuse to accept that reality are precisely those that think they are really top tier because they have 90+% unit test coverage, use agile and do nightly builds.So, my question is, do you (I don&#x27;t mean the specific \"you\" here, rather everyone should ask themselves this, all the time) think that most bad software teams know they are bad? Including the one you are part of? Would it really hurt to have some ye olde QA, just in case, you know, you are actually just average? :) reply shiroiuma 10 hours agorootparentI&#x27;m curious: in your many years of being a consultant to these bad teams, where the manager really thought they were top 20%, did you get a chance to talk to the rank-and-file team members, and did they paint a very different picture of the team health and software quality than their manager?Also, did you run across any orgs where they basically refused to use a process like Agile, and instead just did ad-hoc coding, insisting that this was the best way since it worked just fine for them back when they were a 5-person startup? reply ethbr1 2 hours agorootparentNot parent, but in my experience as a consultant working with bad teams, the rank and file were &#x27;doing the job.&#x27;You usually had a few personality archetypes:- The most technical dev on the team, always with a chip on their shoulder and serious personality issues, who had decided to settle for this job for (reasons)- The vastly undertrained dev who was trying to keep up with the rest of the team, but would eventually be found out and tossed, usually to blame for a major issue- The earnest and surprisingly competent meek dev, who presumably didn&#x27;t have enough confidence to apply to a better job, but easily could have made it on merit, work ethic, and skill- The over-confident dev who read a bit of SDLC practice, and could see every tree while missing the forestThe key is that, aside from the incompetent person, they had all always been working there for awhile. Consequently, there wasn&#x27;t good or bad health and quality: there was just \"the system\" (at that company) and dealing with it.And none of these folks ever worked at 5-person startups. ;) I think it was definitely more an issue of SDLC \"unknown unknowns\" they should be doing, than willful decisions not to. reply fzingle 1 hour agorootparentprev> I&#x27;m curious: in your many years of being a consultant to these bad teams, where the manager really thought they were top 20%, did you get a chance to talk to the rank-and-file team members, and did they paint a very different picture of the team health and software quality than their manager?Yes, generally I join teams and work as an engineer or sometimes as a team lead, so I&#x27;m talking to all the team members.Most start up teams are composed of junior developers, often pretty smart people. Usually 5 or fewer years of experience. Many times these are people who have already accomplished stuff they didn&#x27;t think they could do. So that generally means that yes they think pretty highly of themselves. To a degree it is quite justifiable, they tend to be very accomplished but in a narrow domain. Unfortunately they don&#x27;t realize that their technical accomplishments in a specific field does not mean that they are experts everywhere. Their managers understand that these are smart people and assume again that this is therefore a good team.Non start ups that I join are usually just plain dysfunctional.> Also, did you run across any orgs where they basically refused to use a process like Agile, and instead just did ad-hoc coding, insisting that this was the best way since it worked just fine for them back when they were a 5-person startup?Usually more the opposite. In my experience I come across teams that are sure they must not need any help because they follow all the rules in Scrum and have great code coverage metrics.It is really common to see this kind of thing. I call it \"the proxy endpoint fallacy\". It can crop up anywhere that there is something that can be measured. In that example, it would be confusing adherence to Scrum with having a working SDLC or perhaps confusing code coverage metrics with the objective of having bug-free releases.This isn&#x27;t a software only fallacy. In politics, GDP is often confused with societal well-being. Always be wary of your metrics and change them as required to keep you tracking your actual goals. replylegacynl 3 hours agorootparentprevI think you&#x27;re sort of misunderstanding the role of QA.You think that QA is a liability shield, but that is only a side effect of the work that they actually do.The task of QA is exactly that: an entity that tries to assure that the quality is up to some standard. Even in favourable conditions mistakes happen, so how do you make sure as a company that not 1 in every 100 product are faulty and tarnishes the good reputation that your company has spent so much time and money on to build? You hire a QA to make sure problems get caught before delivery.But if all humans make mistakes, and QA is human, how do you make sure that the QA doesn&#x27;t make a mistake? A never ending chain of QAs expecting each other?No of course not. One thing that helps with reducing errors is to have a rigid protocol that is followed to the letter everytime. Pilots, for example, have a preflight checklist that they have to run every time they operate the plane.The rigid protocol of QA teams is therefore an essential part of their jobs.Although from your standpoint as a developer it might seem strange that QA is &#x27;preventing&#x27; you from fixing a bug, it is actually very reasonable.Especially since you work in the defence industry, I hope you understand that it is very important that the software that operates radars, planes, missiles, bombs, etc is working exactly as expected. Understandably there is a great deal of effort made to assure that when those things are needed they work exactly to spec.So in your example it is probably very reasonable that any change you make needs to go through some rigorous process. The fact that it &#x27;only&#x27; was about test equipment, doesn&#x27;t matter because test equipment is just as, if not more important as the stuff it tests.The reason why QA has the side-effect of being a &#x27;liability shield&#x27; is that it gives companies the ability to argue (and proof) after the fact that the company did their due diligence in making sure that the product was to spec.Especially certification is basically to get an external organisation to approve your QA. In that case if you get sued you can rightfully claim that you did everything that was legally asked of you, and if there is blame, then it is the certifying company using insufficient standards. reply bb88 14 hours agorootparentprev> Good software teams build quality into projects by introducing continuous integration, unit testing, creating feedback, and tightening these feedback loops.No. Good software teams are led by competent, technical management. Managers who aren&#x27;t afraid to get down into the dirty details. Managers who aren&#x27;t afraid to roll up their sleeves and write code if they need to.The process doesn&#x27;t matter. The management of what is or is not important does. Agile is just one process out of many.Imagine an accounting team led by someone who never did accounting in their life: \"Just make the numbers work out! I don&#x27;t care how you do it! My bonus is at stake!\" reply MattPalmer1086 3 hours agorootparentSigh... This myth that the only people who can competently manage developers are other developers has been floating round for decades.For some reason, developers seem remarkably blind to the skills other roles and disciplines require. Only a developer can do that, everyone else is basically useless fluff. Maybe it&#x27;s a form of arrogance or just deep unself-awareness. reply pi-e-sigma 49 minutes agorootparentLet&#x27;s apply your reasoning to medicine. I&#x27;m sure you would be completely fine with managers telling your surgeon what parts of the surgery can be &#x27;optimized away&#x27;. reply MattPalmer1086 17 minutes agorootparentHaha, funny strawman. My reasoning is that non developers are capable of managing developers, notably people who have good management skills.Your contention is that the surgeon should be running the hospital. reply pi-e-sigma 14 minutes agorootparentHahah, indeed. So have you seen a law department in a company headed by someone who doesn&#x27;t come from law background? How about a finance department headed by some schmuck who doesn&#x27;t know anything about finance? madhadron 9 hours agorootparentprev> Good software teams are led by competent, technical management....or perhaps with no managers at all. I&#x27;m less and less convinced of the importance of management in engineering except to give investors an illusion of control. reply johnnyworker 13 hours agorootparentprevBut that doesn&#x27;t contradict the parent, does it? I&#x27;d say you both make good points. reply bb88 13 hours agorootparentWell... here&#x27;s a thought experiment.Let&#x27;s say you have a bunch of school children and architects create a skyscraper. I&#x27;ve given both groups the process to design a skyscraper.So in both cases, I should end up with a safe building? reply withinboredom 9 hours agorootparentI’d bet the children would come out better simply because they have parents who are likely multi-disciplined as a group. A disparite group will (almost) always come up with better results than a homogeneous one (at least in my experience) reply johnnyworker 9 hours agorootparentprevWhy not both? Am I missing something? You can have feedback loops and CI and all that, \"good craftsmanship\" or \"good practices\" (not \"best\" practices because those often suck hah), where of course opinions vary on the details of that -- and then someone who is also good at the craft who spends more or most time on helping the rest work together, i.e. manage&#x2F;lead them. reply Eisenstein 15 hours agorootparentprevIt sounds like they are calling something QA but using it as a liability shield. It makes sense that you are upset about that, but naming something QA and having it do something else doesn&#x27;t mean that QA as an effort is bad. It means that the people doing that are being deceptive. reply vegetablepotpie 15 hours agorootparentFair point, you are correct in your inference that there are some bad actors in my workplace. However, I’ll argue that the fundamental dynamics of bifurcating the responsibility of quality from software leads to a steady state where all QA departments end up as a liability shield given enough time.This is driven by Pournelle&#x27;s iron law of bureaucracy [1], which says that people who promote the bureaucracy rather than the mission of the bureaucracy will get promoted within the organization and come to dominate its decision making.For example, in schools, administrators make more money than teachers. This is despite both groups having similar levels of education and intelligence. The reason for this is that administrators know the laws and regulations of the environment they’re working in and ensure the continuity of the organization. Despite not directly contributing to the organization’s stated mission of education, they are in charge of the organization and take more benefits from it.Software QA has similar dynamics. A QA department may start out making good faith contributions to the organization. Eventually there are product failures, eventually leadership needs a scapegoat to show they’re doing something, and eventually QA takes the blame. People get moved, demoted, or fired. QA realizes its risk, and takes steps to mitigate it. They create a highly systematized workflow and process, adopt or introduce standards. Then assert that following process equates to good outcomes. When bad outcomes occur, they point to their strict adherence to following process as evidence of innocence.If the process does not support the work or mission, that is a cost they are happy to impose on other functions to deal with. This is the final state until a system disruption happens.[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Jerry_Pournelle reply moring 9 hours agorootparentI have seen a case of Software QA taking a very different shape, so I&#x27;d like to argue that the outcome you describe is not intrinsic to software QA, but rather to company culture.The case I&#x27;m talking about does not have a separate QA department, but QA people as part of every software team. If a product fails, that team is responsible, so software devs are in the same boat as QA. They focus on learning from these failures, so no scapegoat is needed. Process does get followed, but not as a defense mechanism, but because not doing so introduces noise that is an obstacle to improvement. In case of bad outcomes, people do point out that they followed process because then it is clear that the process is involved in the failure and should be improved.Unfortunately, companies with that kind of culture are rare. reply Eisenstein 14 hours agorootparentprevBut what makes &#x27;software QA&#x27; fundamentally different than &#x27;non-software QA&#x27; to give it the problems you foresee? reply nikau 13 hours agorootparentBecause every QA is something new for development barring regression testing.An equivalent software QA to building planes would be to verify a known process with existing tooling. reply xwolfi 11 hours agorootparentprevIt&#x27;s like saying communism isnt the problem, but that it s how every single group attempted to implement it that should be blamed.Sure, maybe, but if nobody ever can implement the theoretical utopia, maybe we should talk of things humans can do instead and ditch the unimplementable idea.QA cannot be done by a separate team the way you dream: it will always be a political buffer zone staffed by the cheapest half-competent people you can find, expulsing good people into dev or management. Or you merge it into dev&#x2F;solution design.The reason is simple: just like contract law, you only care about quality once you are in trouble and need to reverse back the source of the issue to give to the client a post mortem. Otherwise, you care first about velocity, or $ input&#x2F;hr of effort. reply Eisenstein 11 hours agorootparentOther fields do QA just fine. reply __loam 9 hours agorootparentprevHigh quality comment reply Robotbeat 14 hours agorootparentprevI agree.I’m regularly critical of Boeing Defense (particularly space contracts where I’m a huge Boeing skeptic), but I think people are pretty off base if they think Boeing is just completely incompetent.Airliner safety is insanely good. Just vast seas of competence, but when there’s a super rare failure, the incorrect impression people get is that Boeing (or Airbus) is just full of incompetency. Almost nothing that humans do is held to the same standard. Not spaceflight, not software, not healthcare, and certainly not automotive.Flying a 737 Max with a bad door and without the fix to the angle of attack sensor is probably still better per mile than driving. In spite of going at 10 times the speed and miles above the Earth.You can almost argue it’s held to a higher standard than it should, slowing development of cleaner aviation (and therefore killing more people in the future due to tertiary effects of climate change, etc).It kind of annoys me when comment sections are filled with people talking about how incompetent Boeing is. It feels like out of shape slobs on their La-Z-boy chairs talking about how incompetent or slow some professional sports players are. Like, airliner safety is just a totally different league than almost anyone else plays in. On the worst day, their better than almost anyone else is on their best. reply ethbr1 13 hours agorootparent> Airliner safety is insanely good.Because I dug it up for another comment, commercial carriers operating under Part 121 (roughly: scheduled passenger and cargo operation) had 4 fatal incidents in the last 10 years. [0]Totalling 6 deaths.In 10 years of US commercial carrier aviation.One of those was literally &#x27;the engine exploded and threw part of the turbine into the cabin (and also shredded some of the wing)&#x27;!!Which resulted in 1 person dying and a successful landing.[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38921664 reply thsksbd 13 hours agorootparentYa but your sample size is way too small to measure the death rate. Aircraft deaths are rare, but flying is too.The two MAX 8s that fell from the sky were 100% Boeing&#x27;s fault and could have happened in the US. If 5% of airline traffic is in the US you can renormalize those hundreds of dead and you get dozens dead. reply chx 4 hours agorootparentWe know US pilots have been warning about the same issues that led to the deathly crashes later but were ignored. The thing is, one part of US commercial aviation being so safe is a lot of pilots responsible for the jet airliners are ex-military. Someone mentioned Southwest Airlines Flight 1380, yup, captain Tammie Jo Shults was one of the first Navy female fighter pilots. Miracle on the Hudson? Sully Sullenberger was an Air Force captain and training officer. Civilian training, no matter how good, is just no replacement for military training and experience.I can&#x27;t find specific numbers but estimates say about one in three has a military background. That&#x27;s an awful lot. reply mschuster91 4 hours agorootparent> I can&#x27;t find specific numbers but estimates say about one in three has a military background. That&#x27;s an awful lot.Not surprising given that pilot training is really really expensive. Airlines love former military pilots because they are a significantly lower financial risk for them. Put them into type rating and off they go, it&#x27;s rare that one ends up as a dud. reply bb88 13 hours agorootparentprev> Totalling 6 deaths. In 10 years of US commercial carrier aviation.Okay, awesome. But how much of that was luck with the 737 Max that they didn&#x27;t crash on US soil by US airlines? reply thsksbd 13 hours agorootparentMost of it. Statistically. Its not hard to assign part of the deaths from the MAXes to the US. reply ethbr1 13 hours agorootparentprevHow much was a rigorous safety regime and high quality training? reply chx 4 hours agorootparentMilitary training. See my comment above: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38925089 reply Eisenstein 13 hours agorootparentprev> It kind of annoys me when comment sections are filled with people talking about how incompetent Boeing is. It feels like out of shape slobs on their La-Z-boy chairs talking about how incompetent or slow some professional sports players are.People do this with everything though, and air travel induces a large amount of fear in the populace. Not only are we not generally comfortable flying in the air for obvious reasons, but when it happens almost everyone has to concede control to a few people in the cockpit and on the ground. Driving, even if exponentially more dangerous, affords the illusion of control of one&#x27;s outcome, given driving or having someone you know driving, and control over the vehicle maintenance, etc, as well as familiarity with the control and mechanism of the vehicle. These things don&#x27;t exist with airplanes for the vast majority of people.So, you can see why there is a need to find a human component to air travel problems, because that is something one can fix (fire the incompetent people, fine them, whatever), as opposed to all of the other things which must be accepted or rejected entirely.It is entirely in line with human nature to do this, regardless of its accuracy or effectiveness. reply mschuster91 4 hours agorootparentprev> Airliner safety is insanely good. Just vast seas of competence, but when there’s a super rare failure, the incorrect impression people get is that Boeing (or Airbus) is just full of incompetency. Almost nothing that humans do is held to the same standard. Not spaceflight, not software, not healthcare, and certainly not automotive.And there&#x27;s good reasons for that. Spaceflight actually is regulated pretty strictly (partially, because any spaceworthy rocket is effectively a missile), and space pilots and tourists both sign up for such missions fully knowing that they will have a very significant chance of dying one way or another - there simply hasn&#x27;t been enough human spaceflight activity to work out and understand all the failure modes, unlike with other forms of transportation.Humans, unlike birds, aren&#x27;t naturally wired to travel by air... they need to be able to trust their lives to a significantly higher degree to someone else behaving like they should, because unlike in a car they have zero control (or the illusion of control) in an aircraft.Additionally, the inherent security risk of an airliner is very high: what is a widebody airplane at its core? Hundreds of tons of weight, a decent portion of which is fuel, propelled at near-supersonic speed, and only two people in control of it. Anything goes bonkers and you can get thousands of people killed and injured (see 9&#x2F;11).In contrast, cars, even trucks, have way less capability to cause damage simply because they weigh so much less. The only thing that comes close is railways, and hell I don&#x27;t get what the US is doing there, there&#x27;s barely any regulation compared to European standards (see the videos I linked at https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38725988). reply kennethrc 5 hours agorootparentprevSo much THIS reply panick21_ 11 hours agorootparentprevBeing better then driving shouldn&#x27;t be the standart. Specially driving in the US.Flying isn&#x27;t safer then trains I would assume.Flying has the advantage of being seperated from almost everything else. Most accidents happen when there is mixed traffic, specially cars operated by people with minimal training. reply maigret 4 hours agorootparenthttps:&#x2F;&#x2F;turbli.com&#x2F;blog&#x2F;the-safest-transport-modes-ranked-by... reply rectang 15 hours agorootparentprevIs it plausible that Boeing has \"learned\" from software&#x2F;startup&#x2F;venture-capital culture with regards to tolerating higher risk to minimize costs?I suspect it&#x27;s rather a case of parallel evolution between McDonnell Douglas brass and software startup culture, since cost-cutting culture goes back many decades (remember \"Chainsaw\" Al Dunlap[1] ?) — but I wonder if there&#x27;s a more direct influence.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Albert_J._Dunlap reply FabHK 13 hours agorootparentHere&#x27;s a Netflix documentary (in the wake of the MCAS crashes) that alleges that after the merger with McDonnell Douglas, the culture of the firm changed. Previously dominated by engineers, it was now dominated by MBAs with a focus on profit and shareholder value.\"With impressive clarity, Downfall: The Case Against Boeing reveals corporate corruption that&#x27;s enraging in its callousness and frightening in its scope.\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Downfall:_The_Case_Against_Boe... https:&#x2F;&#x2F;www.netflix.com&#x2F;hk-en&#x2F;title&#x2F;81272421 reply Robotbeat 14 hours agorootparentprevBoeing Airliners are much safer now than before they merged with McDonnel-Douglas. (Because basically all airliners are.) And I say that as a regular Boeing critiquer. reply fsh 10 hours agorootparentThe 737 NG from before the merger has a much better safety track record than the 737 MAX. reply Groxx 15 hours agorootparentprevIn lots of ways, the \"learning\" there would just be \"capitalism\".It&#x27;s inherently short-sighted unless forced to do otherwise by legislation. Cutting small corners pays off A LOT until the hammer falls, so there&#x27;s a massive advantage to doing it &#x2F; you need to do it if competition is doing it, or you eventually shut down as they take all your business.It&#x27;s inherently a race to the bottom. Sometimes that&#x27;s a net gain, sometimes it isn&#x27;t. reply mc32 14 hours agorootparentAll major economic systems of all major national economies over the last century have perverse incentives. It’s not a capitalist thing.Other systems had incentives such as, get it running by such and such date or have yourself and relatives sent to inhospitable place. So people rushed flawed designs into production.That said, upper management at Boeing needs a shake-up. People need to get fired. They need to do what Intel is trying and that is to get more engineers in charge, or at least grant them veto power on designs. reply acdha 14 hours agorootparent> All major economic systems of all major national economies over the last century have perverse incentives. It’s not a capitalist thing.It should be a lesson against dogmatic pursuit of absolutes: capitalism comes in a wide range of flavors, and the worst is if it’s completely unrestrained. Communism produced worse and worse results the further it got from any sort of public accountability, etc.The two problems that I see is that the concept of nuance is somewhat at odds with having a simple concept to teach kids at school, and there’s always a group which is more motivated to game the system than the average person who really just wants to hang out with their friends, raise a family, etc. rather than play political games. Boeing didn’t start it by any means but they’ve benefited enormously from decades of reduced oversight and elevated pay driven by a sort of cartoon libertarianism where letting people get enormously rich will motivate them to build great things unfettered by “red tape”. reply mschuster91 4 hours agorootparentprev> All major economic systems of all major national economies over the last century have perverse incentives. It’s not a capitalist thing.They have, but post-Thatcher neoliberal capitalism has taken the existing perverse incentives and made them exponentially worse. We&#x27;re on a course heading straight to feudalism, just with fancy titles with legal rights replaced by economic might. reply boringg 14 hours agorootparentprevBut all those communist airlines had no problems at all - exceptional build quality and operational efficiency! &#x2F;S reply mc32 14 hours agorootparentYep, Chernobyl being a prime example. Or Komarov&#x27;s failed re-entry after complaining about the design faults of the vehicle long before launch. Then there was the more uhhm run of the mill backyard blast furnace campaign which contributed to misallocation of workforce which then led to mass starvation. reply boringg 2 hours agorootparentThere are many many more examples. I find it so tiresome to see young people just use capitalism as a catch all for the failure of something. It&#x27;s such a lazy and uninformed argument.I&#x27;m not carte blanche defending capitalism - its a mixed bag but it sure outpaces the competing systems put forward to date. It does need some stronger safeguards against industry self regulation - that has a bad track record. reply mc32 1 hour agorootparentI think we&#x27;re on the same page. Economic systems need failsafes so that they don&#x27;t suffer from positive feedback loops.What anti-capitalist sympathizers, in my view, don&#x27;t realize is that this is due to people being in the loop. These economic systems are merely vehicles, some better than others, but the conductors are people, be they communists or capitalists. At least with capitalisms there is a delayed regulator (negative feedback) in communism it&#x27;s up to the system to decide if it needs to modify itself. replythrowup238 14 hours agorootparentprev\"Better to ask for forgiveness than for permission\"Ironically, I believe it was Grace Hopper who said it... Whoops. reply ssivark 14 hours agorootparentThat adage is okay, but for it to work not everything can be forgiven — there actually has to be an expectation to be held responsible towards acting on good faith. reply cf1241290841 14 hours agorootparentprevCockpit resource management is also something a lot of industries can learn from. As well as human error analysis. How an error came to be is often much more interesting then the personal shortcomings of the person who caused it. reply Symbiote 7 hours agorootparentprevAt it&#x27;s best, software QA and related methods should be equal to airline manufacture.Think of railway signalling systems, control-by-wire bits of modern cars, medical equipment, etc. Where the design of the software is formally proven, and the implementation verified to ensure it fits the design. reply williamdclt 4 hours agorootparentprevof course, but most of us aren&#x27;t working on products where a quality problem would kill hundreds of people. Having aircraft-level QA would be plain silly, you don&#x27;t expect that level of quality from most other industry like eg guitar manufacturing, do you? reply dilyevsky 15 hours agorootparentprevWould you pay at least 2x for your software to have couple more nines of reliability? I’m gonna guess that “no”. At places where it costs $$$ to have bugs shipped to the end customer (e.g phones) or where there’re regulatory requirements they still have dedicated qa. reply bb88 13 hours agorootparentIt depends.1% of 10000 is 100..01% is 1.If someone came up to me and said, \"Hey I can save you 99% of expected costs with 1% of your profit.\", I might go for it. reply dilyevsky 12 hours agorootparentWhich is what i said in second part of my comment. For most software businesses the cost of shipping a bug is trivial and&#x2F;or poorly measured so due to McNamara fallacy it is readily exchanged for well measured cost of having a functioning qa team reply darylteo 16 hours agorootparentprevsoftware development: what is QA? reply bb88 13 hours agorootparentThat&#x27;s where failed software devs &#x2F; management go to. reply ShadowBanThis01 16 hours agorootparentprevExcept, of course, from Boeing&#x27;s aircraft-software QA... which killed hundreds of people already. reply actionfromafar 15 hours agorootparentThe problem was not really the software in isolation, but that pilots expected the 737 NG to behave exactly like the old version - because Boeing decided it was too expensive to retrain pilots. reply unyttigfjelltol 14 hours agorootparentThe problem was software that prioritized input from a fauly external sensor, over pilot control, and literally crashed planes directly into the ground. At a certain step in the sequence it was not physically possible for a pilot to pull hard enough on the control element to counteract the software. Could they have disabled the system? Only if they could figure out the specific software trying to crash the plane.Is that what you meant by \"the problem wasn&#x27;t the software?\" Because the pilots should have been trained to unplug the computer to stop it from crashing the plane? reply SoftTalker 11 hours agorootparentPilots should (are supposed to) disable the auto-trim if it&#x27;s doing something uncommanded&#x2F;unexpected. Runaway trim can happen for reasons other than faulty software. MCAS was a new factor and they should have been told about it, I don&#x27;t dispute that at all. reply drtgh 2 hours agorootparentThe manufacturer company put in larger engines than the aircraft is designed for. And they did it to avoid all the homologation licences and design costs involved in bringing a new aircraft to market with the appropriate tolerances, and to compete with another company&#x27;s aircraft in time (Loss of sales).They introduced MCAS in the aircraft for to balance by software a hardware issue, a big design negligent issue which can lead to stalling. It is beyond to trim an aircraft, and because of this there is a big difference in the scale of the values that the algorithm manages from a trimming.It is not my field, but I think it is not a simple factor, and that it should not be put this over the Pilots like if it were a normal aircraft that received a simple update. Every pilot flying that plane should have been warned that it was not a classic plane with a classic update.If this type of behaviour by aircraft manufacturers becomes the norm, costs over safety, we as passengers will suffer it, as other passengers unfortunately suffered it, while they blame the Pilots. In addition that nowadays the China&#x27;s aircraft manufacturing industry wants to enter global market. Some days ago I read they want permission (homologations approvals) for to enter in the European Union.PS: They also cut costs retiring backup sensors, delegating responsibility for a vital system due the MCAS to the buyer as if it was an unimportant feature; disaster was the order of the day. And the spending cuts were not limited to that, as we have seen in recent days. reply disillusioned 14 hours agorootparentprevEven more ridiculous, Boeing offered a second source of truth option, but marked it as an upcharge, which the airlines in question rejected. \"No thanks, no need for a second AoA sensor, one is none is probably fine!\" reply bshacklett 21 minutes agorootparentAdditionally, two feels like a really strange number. I would think three for a tiebreaker would be standard for any sensor with that much impact (no pun intended). reply ethbr1 14 hours agorootparentprevPilots are definitely trained how to disable the autopilot, if needed.Afaic, the fault apportionment was Boeing documentation > airlines >> pilots > Boeing technical design. reply acdha 14 hours agorootparentThis wasn’t related to autopilot and they removed mention of the MCAS system from the documentation to support the main selling point of the 737 MAX, which was that existing 737 pilots would be able to switch easily without recertification. They knew that they’d lose most sales to Airbus if the aircraft were compared on their merits so they were banking hard on their huge pool of certified pilots as the competitive edge.If you listen to podcasts, these two episodes of Causality are excellent:https:&#x2F;&#x2F;engineered.network&#x2F;causality&#x2F;episode-33-737-max&#x2F;https:&#x2F;&#x2F;engineered.network&#x2F;causality&#x2F;episode-50-737-max-ethi... reply bb88 13 hours agorootparentYou might enjoy this. I have a pin that blinks \"AOA Disagree\".Back when I flew regularly before covid, I was tempted to create a bunch of these and hand them out to the flight crew for the flights I flew on. reply acdha 2 hours agorootparentHa, playing hardball! I wonder whether you’d find pilots who are Boeing loyalists who’d take offense, or if those guys are even madder at the current management for letting them down. reply diabeetusman 14 hours agorootparentprevNot sure why you’re bringing up autopilot— the MCAS system runs even when the autopilot is disabled.Edit: Also, how does the fault lie with the airlines? Boeing didn’t document the existence of MCAS in the flight manual or training materials. reply numpad0 11 hours agorootparentWasn&#x27;t MCAS designed to activate when A&#x2F;P is disconnected, also? reply ethbr1 13 hours agorootparentprevBecause the comment I was replying to>> Because the pilots should have been trained to unplug the computer to stop it from crashing the plane?Yes.The fault lies with the airlines because I don&#x27;t for a second believe they didn&#x27;t put pressure on Boeing to get the MAX certified without mandating retraining.And then once that was done, didn&#x27;t dig into the details too hard about what changes were made.I have a low tolerance for &#x27;I set up all the conditions and incentives to encourage you to break the law... but you should take all the blame when it explodes.&#x27;At some point, the customer has to take some responsibility for what they asked for. reply actionfromafar 5 hours agorootparentIt’s easier to blame Boeing because they made the damn thing its documentation. We know for a fact they are at fault. Some or all of the airlines may or may not have put pressure on Boeing. replyWalterBright 15 hours agorootparentprevThe expense for retraining pilots falls on the airline.Retraining has its own problems. No matter how well retraining is done, pilots still make mistakes from doing the right thing for the previous plane that is the wrong thing for the one they are currently flying.Adjusting airplanes to fly the same way is a major safety advantage. reply ethbr1 15 hours agorootparentArguably, Boeing hit the uncanny safety valley -- similar enough so that pilots and airlines relaxed, but different enough so that relaxation ultimately killed people. reply WalterBright 15 hours agorootparentThe emergency procedure for runaway trim was the same for both aircraft types, and was not followed. After the first crash, an Emergency Airworthiness Directive was issued to all MAX pilots reiterating the procedure, which was not followed in the second crash, as well as not reacting to an overspeed warning.Unreported by the media, there was another MAX incident before the first crash. The crew had no knowledge of MCAS, but did follow the emergency runaway trim procedure, and continued the flight and landed safely. reply 9659 14 hours agorootparent\"Runaway stab trim\". It is a memory item, every pilot should be able to perform it from memory.Turn off the motor, and the trim is manual. There is a crank right there in the cockpit. If it is too hard to turn, change aircraft configuration to reduce the forces required to. Pilot know how to do this. This pilot stuff, they understand the forces on the flight controls and what impacts them.Boeing made an engineering mistake. The pilots also made an operational mistake. Unfortunately, both mistakes at the same time were fatal.I pray that pilot training has improved. And that Boeing has made systems level changes to the aircraft that will preclude it happening in the future.And that is how aviation becomes safer every year; at a significant cost of customers lives. reply ethbr1 13 hours agorootparent> And that is how aviation becomes safer every year; at a significant cost of customers lives.\"Significant\" might be inaccurate.It looks like FAA Part 121 accidents over the last 10 years with fatalities have been... 4. [0]For a total of 6 fatalities.[0] https:&#x2F;&#x2F;www.ntsb.gov&#x2F;Pages&#x2F;AviationQueryV2.aspx; 2018 (1 passenger fatality) https:&#x2F;&#x2F;www.ntsb.gov&#x2F;investigations&#x2F;Pages&#x2F;DCA18MA142.aspx ; 2019 (3 crew fatalities, cargo flight) https:&#x2F;&#x2F;www.ntsb.gov&#x2F;investigations&#x2F;Pages&#x2F;DCA19MA086.aspx and (1 passenger fatality) https:&#x2F;&#x2F;www.ntsb.gov&#x2F;investigations&#x2F;Pages&#x2F;DCA20MA002.aspx ; 2022 (1 ramp fatality) https:&#x2F;&#x2F;data.ntsb.gov&#x2F;carol-repgen&#x2F;api&#x2F;Aviation&#x2F;ReportMain&#x2F;G... reply kennethrc 5 hours agorootparentOne of which (Atlas Flight 3591) was Pilot error:> The probable cause of this accident was the inappropriate response by the first officer as the pilot flying to an inadvertent activation of the go-around mode, which led to his spatial disorientation and nose-down control inputs that placed the airplane in a steep descent from which the crew did not recover. reply WalterBright 12 hours agorootparentprevThat low accident rate is nigh inconceivable. It&#x27;s an incredible achievement. reply ethbr1 2 hours agorootparentThe fatal accident count is higher for GA, but I didn&#x27;t normalize against flight hours or flights, just glanced at it.I&#x27;m sure there&#x27;s been a study somewhere that attempts to untangle all the factors that differ between commercial carriers and GA, to see which safety is most sensitive to -- continuous highly professional maintenance, highly trained and experienced crew, rigorous airliner certification regime, etc. reply SAI_Peregrinus 13 hours agorootparentprevBoeing also reduced the size of the manual trim wheels, which let them become impossible to turn sooner than on previous 737s. reply WalterBright 12 hours agorootparentThe electric trim switches override MCAS. This was explained in the Emergency Airworthiness Directive sent to all MAX pilots after the first crash.Also, overspeeding the airplane makes it much harder to turn the manual trim wheel. The cockpit voice recorder on the EA flight recorded the overspeed warning horn, which the crew did nothing about (they were at full power, should have pulled the throttles back).The LA crew restored normal trim twenty-five times before crashing. What they never did was turn it off after restoring normal trim. replyShadowBanThis01 12 hours agorootparentprevIf a pilot can&#x27;t be expected to maintain the pitch of a plane on takeoff, he has no business flying ANYTHING.What Boeing did (and is STILL doing) is expect pilots to know or remember obscure NON-PILOTAGE (and in the case of MCAS, BURIED) trivia to prevent disaster.Now... what&#x27;s the more-responsible approach? Expect pilots to pilot, or expect them to recall an ever-growing list of workarounds to incompetent system design? reply gmokki 7 hours agorootparentThe whole MCAS was just unnecessary feature (bug fix). Without it the plane would have worked just fine. The pilots would just have had to go some amount of training scenarios to get the certification on how the MAX plain flies. reply ShadowBanThis01 12 hours agorootparentprevWrong. reply echohack5 16 hours agorootparentprevQA was literally invented for the airline industry.Software QA when actually practiced is more advanced now than airline QA. reply paranoidrobot 15 hours agorootparent> Software QA when actually practiced is more advanced now than airline QA....eh, I think \"when actually practiced\" is doing a lot of carrying there.What do you mean by \"actually practiced\".Outside of the aerospace and healthcare industries, I&#x27;m not sure there are many software shops that are doing QA to a level I would like to trust anyone&#x27;s life with. reply serf 15 hours agorootparentprevwhat does advanced mean when comparing things so unlike from each other?also software is the least likely comparison I would have made; software quality is a shit-show on a general level, and the vast public is quite aware of this every time a subway timeboard blue-screens or gets frozen on an AMI screen, or the POS machine that they&#x27;re forced to interact with at work does something equally as stupid. reply booleandilemma 14 hours agorootparentprevNah, in the software world, the truth is QA is where the people who can&#x27;t get jobs as programmers end up. I&#x27;ve seen testers go on to become programmers, but I&#x27;ve never seen a programmer become a tester. Maybe it&#x27;s different for real-time or life-critical systems, sure, but I can confidently say this is how it is in web development. reply MilStdJunkie 1 hour agorootparentprevGiven everything I&#x27;ve seen so far, I&#x27;d bet good money that what happened here was miscommunication between Spirit and Boeing. Spirit started out locking down the plug, then Boeing asked them to just loosely attach it[1] so Boeing could yank the plug for interior&#x2F;wiring&#x2F;AC&#x2F;paint, then someone at Boeing forgot about the \"loosely\". So now, they get in a hurry (maybe the AC&#x2F;interior didn&#x27;t need any access to work on, which makes sense for this MAX variant, it wouldn&#x27;t need as many hatches to pull wire) and it went down the Renton line as if the plug was fully installed. It&#x27;s enough to pass high blow inspection and other inspections, but then over time that \"shipment config\" attachment vibrated out, and pop goes the plug.Almost certainly systemic issue though, so that sucks. Sucks real bad.They need to get a Tiger Team or whatever together to look at everything with a shipment config, and make sure those \"ship kits\" don&#x27;t leak into the real actual airplane configuration. This is . . ok, this is really manufacturing 101 stuff, but well, things happen.I&#x27;m in the industry, but haven&#x27;t touched the MAX, so take this with a grain of salt.[1] Basically a \"shipping\" or train configuration reply garyfirestorm 14 hours agorootparentprevBolts are most likely tightened with a torque wrench or a gun that is set to a torque spec. Over tightening a bolt is as bad as a loose bolt. I speculate these passed QA from Boeing because they might have been correctly torqued to the spec. What happens in field is hard to understand. One possibility is vicinity to the engine can cause extreme vibrations, these can make them loose. Other possibility is the maintenance side of things - maybe a badly calibrated torque wrench could be the reason. Mechanical systems are not inherently immutable. reply kevin_thibedeau 14 hours agorootparentWhen it&#x27;s happening on a two month old plane it&#x27;s a production problem. reply FredFS456 14 hours agorootparentprevI would expect lock wire or some other method of ensuring the bolt does not un-torque itself. Especially for bolts that are not required to be removed past final assembly... reply onlyrealcuzzo 10 hours agorootparentprevIt&#x27;s a QA process better than almost every other industry in the world...Sure, it failed, and it isn&#x27;t perfect.But planes have had a long track record of being absurdly safe. reply justinclift 15 hours agorootparentprevMaybe an inadequate torque specification for the bolt tightening? reply AdrianB1 16 hours agorootparentprevNope. It is most probably caused by operational stress - rudder assembly is moving, fuselage is also working (compression and decompression cycles on take off and landing, thermal expansion and compression). I bet they don&#x27;t just put red Loctite on it to keep it from getting loose. My bet is design flaws, not manufacturing or QA.EDIT: I saw the pictures of bolts with pins and bolts without pins. The ones with pins cannot get loose, the others can. Let&#x27;s see what happened. reply 0xEF 15 hours agorootparentI don&#x27;t know about you, but in my industry, \"QA\" also means extensive testing to ensure that part&#x2F;assembly&#x2F;etc doesn&#x27;t break with expected operations. So, yeah, from where I&#x27;m standing, this was a QA problem. Something did not get checked or tested as it probably should have. reply ooboe 12 hours agorootparentprevThe 4 restraining nuts and bolts on the door have a cotter pin like mechanism to prevent them from loosening. If assembled correctly they cannot loosen unless the pin fails. reply otikik 8 hours agoparentprevThat’s “testing in production”, but beast-sized. reply mihaaly 9 hours agoparentprevI recall a running joke from my childhood - from a former communist East European counry - about a certain car saying you should finish the assembly at home after purchase, tightening the screws before first use. Despite being a famously poor quality car - even in the sloppy East European practices - that supposed to be a joke not to follow suit! reply AdrianB1 16 hours agoparentprevThey are not related. Probably different types of bolts, for sure different stress types. Rudder assembly is a moving part, these false door panels are not. reply akira2501 15 hours agorootparent> these false door panels are not.It&#x27;s not a control surface, but it is a \"moving part.\" That&#x27;s what&#x27;s baffling to me, that they spent a lot of effort building this hinge and pin roller system, and designed the door to hinge open up to 15 degrees.It makes me wonder if there&#x27;s maintenance procedures that at some point would require the operation of that door to successfully complete. Otherwise, the mechanism itself seems so incredibly overwrought, with lots of additional bolts, castle nuts, retaining pins, and even sprung hinges at the bottom.Does anyone know why this \"plug-type non-plug door\" is built this way? reply paranoidrobot 15 hours agorootparentIt&#x27;s built to be an actual emergency exit.It needs to be usable depending on how many passengers the interior is configured for.So it has all of the door bits there. Maybe some parts like the emergency escape slide are not installed.e: I should be clear that it&#x27;s not usable as an emergency exit, as configured by Alaska. However the operator could choose to activate it later and install a usable exit. reply mannykannot 11 hours agorootparent> It&#x27;s built to be an actual emergency exit.If you are correct, then the implication is that the concern extends beyond door plugs for MAX-9 737s to all emergency exit doors on all models of aircraft sharing this design. This is somewhat reminiscent of the huge problem with the 688 (Los Angeles) class submarines, where the discovery of a faulty weld that had passed inspections raised doubts about all welds. reply Pasorrijer 15 hours agorootparentprevThis is not correct. To the passengers, this just looks like another seat next to a window with a plug installed. It&#x27;s not a door.If there was a reconfiguration to a seating standard that required the extra exit, the plug would be removed and a proper door would be installed, with the associated interior pieces. reply paranoidrobot 13 hours agorootparent> To the passengers, this just looks like another seat next to a window with a plug installed. It&#x27;s not a door.This is true.However there&#x27;s still common hardware in there to allow the plug to be installed and maintained. This is why it&#x27;s a complicated set of kit vs just bolting in a permanent fixture. reply deelowe 14 hours agorootparentprevWhere did you see that? My understanding is that it&#x27;s an optional plug door that&#x27;s used to assist with interior installation. Once the interior is done, it&#x27;s bolted shut and interior paneling is installed over top. From the inside, you can&#x27;t tell it&#x27;s there. reply paranoidrobot 13 hours agorootparentMy source is [1], specifically at about 5:05.Alaskan airlines chose a 178 passenger configuration for their 737-9, and so are not required to have a mid-cabin exit door.Lion Air&#x27;s chosen to go with a 221 passenger configuration, and so are required to have an operating door.Obviously changing up the number of seats isn&#x27;t done on-demand, you&#x27;d need to go for a refit&#x2F;maintenance cycles.But if Alaskan decided to change density, or sold the aircraft to someone else who decided to change density - then they could go and do this.[1] https:&#x2F;&#x2F;youtu.be&#x2F;nw4eQGAmXQ0?t=305 \"The Boeing 737 Technical Channel\" reply deelowe 1 hour agorootparentAhh. Well, in the case of the Alaska flight, it&#x27;s a plug door and not used as an exit. It&#x27;s pinned in place with large pin that has a bolt, a castle nut and cotter pin which lock the pin. reply yread 7 hours agorootparentprevThis is not true. It&#x27;s designed to be opened when inspecting the fuselage for corrosion or stress cracks at the opening. To open it you have to remove the interior plastic panels and undo the 4 bolts that this accident is about reply Scoundreller 15 hours agorootparentprevmy guess is: to replace gaskets&#x2F;seals reply MBCook 16 hours agorootparentprevI think the point is there were at least two sets of loose bolts at the same time. reply heads 17 hours agoprevBolts and machine screws are very interesting. One mistake I, an amateur bike mechanic, made for years was not greasing bolts properly before assembly.It sounds counterintuitive but without grease a bolt (or machine screw) will bind early with a high torque well before it is correctly tensioned lengthways. The torque is just a proxy for the tension and it is this tension which is needed to fasten your components together as intended.The grease means that when the torque to turn the bolt reaches the correct value then the bolt is also under the correct tension instead of being because it got stuck in the thread half way. reply johnwalkr 14 hours agoparentIt&#x27;s a complex topic. Depending on the design, lubrication may be required or forbidden. And if it&#x27;s required, it should normally be on the threads only, under the head is usually forbidden.And it&#x27;s very important to understand that in most mechanical design with fasteners, the fasteners provide tension, and friction between 2 faces actually carries the load. Too little tension then fasteners can be sheared off. Too much, then the fasteners may not have remaining strength available for loads that act to add tension to the fasteners.Using a torque wrench to reach target tension is normally only about +&#x2F;-30% accurate. Usually design margin allows for this but in very critical applications where margin is not feasible, calibration is done on a sample of the same materials, etc, or a more direct measurement done. More direct measurement can mean hollow fasteners that allow you to measure the amount of stretch, use of ultrasonic measurement to measure stretch, washers with integrated strain gauges, or cleverly designed \"tension indicating\" washers or fasteners. There are many types so I just those keywords for anyone interested.I am not saying that this design required such complex methods and sizing these fasteners should not be difficult. There is probably a mistake or lack of control in the assembly process. reply jacquesm 14 hours agorootparentLots of good stuff in this comment but I&#x27;m confused about the +&#x2F;- 30% accuracy quote, in my experience it is relatively easy to reach sub 10% accuracy based on comparing different (good quality) torque wrenches against each other and against a calibrated one.Is there something I am missing here? reply johnwalkr 13 hours agorootparentIt&#x27;s easy to calibrate torque wrenches to +&#x2F;-5% of each other for _torque_. Calibrating a torque value to _tension_ of a fastener depends not only on the accuracy of the tool, but on materials, lubrication, temperature, process, etc. +&#x2F;- 30% actually depends on having a good process. This only accounts for variations in tolerance, surface finish, etc. If you add lubricant under the fastener head when you are not supposed to, you can easily reach +50 or +100% tension. reply jacquesm 6 hours agorootparentAh, I see your point now, I thought you meant it to be a direct cause of the torque wrenches themselves to be off. That makes good sense and aligns with my experience.After manufacturing tension tends to drop over time so starting off with a &#x27;+&#x27; may not be entirely bad assuming it isn&#x27;t extreme and that it doesn&#x27;t cause the materials to deform more than permitted. The way I understand it: you apply a certain torque to a fastener in order to get to minimum levels of tension and friction (which still have an engineering reserve) on the fastener itself to guarantee a seal and to stop the fastener from coming loose, so under-tension is far worse than over-tension as long as the over-tension does not result in damage to fastener or the materials, and the allowed tolerances for over-tension are quite large (up to +150% or so normally before any permanent deformation would occur).Unless you are using &#x27;stretch&#x27; bolts which tend to elongate to accommodate any over-tension to end up with something quite close to the intended value. This stretching tends to be non-elastic so you&#x27;d have to replace a stretch bolt every time you unfasten it or there is a pretty good chance that it will break and&#x2F;or that the threads under the ending position of the nut will have deformed so that they end up being stripped if you refasten them because the nut will travel a bit further on every refastening. reply nkurz 13 hours agorootparentprevI presume his point is that you are measuring torque (potentially very accurately) but what you actually care about is tension. It&#x27;s the variable factors affecting the relationship between torque and tension that results in most of the +&#x2F;- 30% accuracy in tension, not the measurement of the torque. reply brettnak 13 hours agorootparentprevThe desire of fastener tension is clamping force or fastener stretch in some cases, not fastener torque. I think what the parent is saying is that a perfectly torqued fastener is only about 30% accurate in terms of clamping force. reply talldatethrow 10 hours agorootparentprevIve been working on cars and motorcycles and everything else other than airplanes for almost 25 years now, from motor swaps to transmission rebuild and custom suspension. The only time I ever use is a torque wrench is on engine internals, or smaller fancy areas into aluminum. Everything else, over the years, you learn by feel.You pay attention to the size of the bolt, the material it&#x27;s going into, and it&#x27;s overall job. Yes you&#x27;ll mess it up a few times a long the way. Hopefully you&#x27;re a lot more careful when you see that the cost of making a mistake is a difficult extraction or alteration of some sort. Personally, I think you&#x27;ll run into bolt&#x2F;thread failure 10x more from improper insertion, dirty threads, corrosion, and overall entropy than you will from over torquing once you learn a few early lessons.I&#x27;ve done countless brake jobs, tire rotations, oil changes, spark plugs, valve cover gaskets, shock and bushing changes, without a torque wrench. I&#x27;ve yet to ever had a problem from it after going a little too hard when I was 16 yrs old and learning what bolts and materials can hold what. reply pests 9 hours agorootparentThe size of a bolt head is directly related to it&#x27;s target&#x2F;max torque due to the increased leverage from the larger rotation. This wasn&#x27;t obvious to me at first but it&#x27;s helped for rough guesses when I didn&#x27;t know exact values. reply Dalewyn 7 hours agorootparentprevAt the Costco where I get my car&#x27;s tires swapped out (summer&#x2F;winter tire swap) or rotated, the technician always tightens all the wheel nuts with a torque wrench.Then another, different technician comes by and checks all the nuts again with his own torque wrench.When all is done and I get the sign off paperwork, they strongly encourage me to stop by next time I&#x27;m there so they can quickly check the wheel nuts again with a torque wrench.So please, don&#x27;t \"do it by feel\". That&#x27;s how you Boeing. I know I would never patronize your shop again if I saw you being so callous.A true craftsman double and triple checks his work objectively with other craftsmen, not be proud he can do it blindfolded with one arm behind his back. reply ssl-3 14 hours agoparentprevTorque specs only apply to clean and clear threads that are free of corrosion and grease -- unless otherwise-specified.Threads that are this way do not get stuck half-way.If the threads are already boogered up for whatever reason, then the torque specification is already wrong: The threads aren&#x27;t clean, clear, and free of corrosion and grease. This can result in under-tensioned fasteners when using a torque wrench as a guide, since boogered threads (rather obviously) can present an impingement that allows a torque wrench to click off before proper tension is reached.However, grease is not a magical antidote to this condition.If the threads (boogered or not) are greased, then the torque spec is also wrong: Greased threads are also not clean and clear, and free of corrosion and grease. This can result in over-tensioned fasteners when using a torque wrench as a guide, since grease is (rather obviously) a lubricant -- allowing things to slide more-freely in a way that doesn&#x27;t allow a torque wrench to click off until somewhere beyond ideal tension.---So what do, then, as a home-gamer with a bicycle or maybe a car in the rust belt (but never an aircraft) full of dissimilar metals that are constantly rotting?You could perhaps kit up to do the Junker test such as in DIN 65151, and make a study of how different greases affects things. You can even make a career out of publishing your studies.Or: Just make sure the threads are clean, clear, and dry, and then assemble with an anti-seize paste which does not have lubricating qualities that affect final tension yield. (Permatex makes some, as do others.)---(And in aircraft, always do what the engineers say. If the engineers are wrong, then: Stop doing whatever it is that you&#x27;re doing, and consult them.) reply WheatMillington 16 hours agoparentprevOnly grease fasteners if specified by the manufacturer, otherwise you&#x27;re going to apply much higher than specified tension at the same torque value. reply Scoundreller 15 hours agorootparentI need manufacturers to give \"frame spent 3 decades in the salt belt, questionable metal compatibility and won&#x27;t be taken apart until it breaks again\" torque specs.It&#x27;s like they think I&#x27;m going to take this thing apart and put it back together every year.j&#x2F;k, finding torque specs for a decades old steel bike is a lost cause reply serf 15 hours agorootparenta good machinists handbook will give you torque specs that take into account fastener size, material, and thread-locking style.[0]mine is much older than linked version, but i doubt they&#x27;d revise that whole section out of it.[0]: https:&#x2F;&#x2F;www.amazon.com&#x2F;Machinerys-Handbook-Toolbox-Erik-Ober... reply nikau 13 hours agorootparentprevIn the car world that torque is measured in ugga duggas from the impact wrench reply NegativeLatency 16 hours agoparentprevI keep a toothbrush covered in grease for just this purpose.It’s also a magnetic one so I can stick it to stuff and it stays put. reply TaylorAlexander 15 hours agorootparent> I keep a toothbrush covered in grease for just this purpose.Speaking from personal experience, this is also useful for brushing a robot&#x27;s teeth. reply shmeeed 8 hours agorootparentprevWhere does one find a magnetic toothbrush? reply NegativeLatency 2 hours agorootparentIt’s an old Sonicare brush head (a couple of fairly strong magnets are mounted to the bottom), there are also some kinda neat suction cup toothbrush holders you could use reply myself248 16 hours agoparentprevThere are different torque-to-tension equations for lubricated and unlubricated fasteners, of various materials and platings. reply deelowe 14 hours agoparentprevA properly designed service manual will specific if the fastener should be lubed. If it doesn&#x27;t say lube&#x2F;thread locker should be used, then the fastener should be torqued dry. reply loeg 13 hours agorootparentIn bicycle applications it is common to elide explicit instruction to use grease. Nevertheless it should be used. reply WalterBright 15 hours agoparentprevYes, that&#x27;s the way aircraft fasteners are put on.There&#x27;s another reason to grease them - the grease keeps the water out which prevents corrosion.In working on my cars, I always use a bit of grease when assembling fasteners. I&#x27;ve never had one come loose, nor have any rusted themselves on. reply stjohnswarts 4 hours agoparentprevIn some cases (some spark plugs are what I can think of) explicitly tell you NOT to grease them, as that will let you over-torque them and potentially damage threads (aluminum heads, steel plugs). So using grease is not always the recommended procedure. reply Zetobal 1 minute agoprevThat&#x27;s what happens if your employees don&#x27;t care about your company. reply fshbbdssbbgdd 18 hours agoprevCheck out this video showing how the plug is supposed to be installed: https:&#x2F;&#x2F;youtu.be&#x2F;maLBGFYl9_o?t=540Some of the bolts that would be loosened when the plug is opened during maintenance have a pin to prevent them from turning. That pin is present in this photo: https:&#x2F;&#x2F;x.com&#x2F;byerussell&#x2F;status&#x2F;1744460136855294106?s=46&t=s...However, the same photo shows other critical bolts that hold the whole hinge on the door are loose, and there’s not meant to be a pin on those.I’m curious how the decision is made whether to include that pin in the design. Did they idiot-proof the maintenance of the plug, but not the initial installation? reply fshbbdssbbgdd 18 hours agoparentMore rampant speculation!Some quotes from this article: https:&#x2F;&#x2F;www.reuters.com&#x2F;business&#x2F;aerospace-defense&#x2F;spirit-ae...> As part of the production process, Spirit builds fuselages for 737s and sends them by train with the special door assembly “semi-rigged,” one of the people said.> “They are fitted but not completed,\" the person said.> At its Renton, Washington, plant, Boeing typically removes the pop-out, or non-functioning, door and uses the gap to load interiors. Then, the part is put back and the installation in completed. Finally, the hull is pressurized to 150% to make sure everything is working correctly, the person said.I can imagine a diffusion of responsibility as to whose job it is supposed to be to tighten those hinge bolts. Spirit is installing the plug in a “semi-rigged” state. Boeing is removing the plug to load the interior, then reinstalling it. I’d hazard a guess that Boeing is not removing the hinges, because the plug can be removed without doing so. What if, when reinstalling the plug, Boeing workers just redo the stuff they removed? They tighten the vertical movement arrestor bolt, put the pin through it, and believe they have done their job? If they never messed with those other hinge bolts, they don’t bother tightening them? reply selimnairb 16 hours agorootparentI’m no MBA or aerospace engineer, but why sub-contract the fuselage? I get subbing engines, since engine designs can be used on&#x2F;adapted to other (possibly non-Boeing) airframes, hence opening up economies of scale, etc. But the fuselage is most of the plane by mass and integral to the design of everything else. If you don’t like making fuselages, maybe you should get out of the aircraft business. Was this just a union-busting thing? reply Scoundreller 15 hours agorootparentEngines are weirder. My understanding is that the airline specs out what the engine requirements are, and any engine manufacturer is allowed to try to meet that requirement.Customers get to decide which engine to fit and negotiate for them separately from the aircraft.Sometimes there&#x27;s only one choice, but other times gives you a chance to have the same (or similar) engine to maintain across your fleet (or avoid that to avoid a total grounding) and whatever other reasons to choose one over the other.At least that&#x27;s what the A380 tour in Toulouse said. Kinda makes sense to at least keep the big aircraft builders from throwing too much of their weight around. reply lotsofpulp 15 hours agorootparentprev>Was this just a union-busting thing?Yes, and to lower compensation because Boeing’s benefits are probably better than Spirits, and so if Boeing wants to pay the people that make the fuselage less, then having them be employed by someone else helps them pass non discrimination testing for pre tax benefits offered to Boeing’s higher compensated employees.Also, lower unemployment insurance premiums if they want to reduce the amount of labor they buy, since Spirit would be the one laying people off. reply applied_heat 15 hours agorootparentprevSpirit was spun out of Boeing reply mcbain 15 hours agorootparentI don&#x27;t always love the video format but Mentour talked about Spirit, Boeing, and the 737 MAX a few months ago: https:&#x2F;&#x2F;youtu.be&#x2F;SmJgweFmoxsThe discussion about snowman hole issues and other problems is really alarming. reply thehappypm 17 hours agorootparentprevThere’s no way that this is what happened. They’re not building IKEA furniture, everything is tightly check-listed. reply WheatMillington 16 hours agorootparentEvidently not though.... reply nyokodo 16 hours agorootparent> Evidently not thoughBolts can be loosened by the physical and thermal stresses of use if there is a design flaw. So it’s not evidently an assembly QA problem. reply sp332 15 hours agorootparentThe plane that lost a plug mid-flight was only two months old though. A design problem probably would have shown up in an older one. reply nyokodo 14 hours agorootparent> A design problem probably would have shown up in an older one.Maybe, unless it required really specific conditions that have only occurred for this one or also required some maintenance snafu that also had nothing to do with Boeing assembly QA. We don’t have enough data to establish anything as the most probable explanation yet. reply guax 1 hour agorootparentAccording to the linked article: at least five aircraft. So, not unique to this one. Or the one that blew the door out. reply jojobas 13 hours agorootparentprevSurely you&#x27;ve heard of reliability bath-tub curve. reply Danieru 10 hours agorootparentUh, first part of the bath tub curve is driven by manufacturing defects... That&#x27;s not a counter point at all. reply jojobas 7 hours agorootparentThat curve applies to design issues as well, they are more likely to be found in the very beginning (teething problems) as well. replymynameisnoone 15 hours agorootparentprevYou&#x27;re talking out of your ass. Watch this documentary about whistleblower complaints as far back as the 737 NG line as they observed workers beating structural parts into place with hammers. Clearly, things haven&#x27;t improved since then. https:&#x2F;&#x2F;youtu.be&#x2F;IaWdEtANi-0 reply 1970-01-01 18 hours agoparentprevThe castle nut design requires the use of a cotter or other locking pin.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Castellated_nuthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Positive_locking_device reply Rapzid 17 hours agoparentprev\"Loose bolts\" is not a ton of detail. It could have nothing to do with any of the bolts discussed in that video.I&#x27;m having a hard time imagining how this failure could occur from just those bolts \"needing tightening\". They are lock bolts with pins and appear to take shear forces and provide no clamping functionality. Even if the bolts were \"loose\", or not torqued to spec, how would they come all the way undone? Then the bolts, under shear, work their way out completely? And isn&#x27;t the lift spring forcing the top pins into the upper part of the track? On top of that the curve of the track appears to be such that outward force on the door would actually cause the pins to go into the upper part of the track.IDK, seems like there is something else going on. Different bolts maybe. reply pests 8 hours agorootparentThe bolts themselves don&#x27;t take the entirety of the shear forces. They provide tension and therefore friction between the mounting surfaces which is where the shear is handled. By being loose, there is no friction to handle shear and also the item can gain additional momentum (more distance to travel) during shakes and impacts which might increase the impact force above the rated strengths strength. reply userbinator 14 hours agoparentprevI&#x27;m not an aerospace engineer, but it seems those hinge bolts might be better replaced",
    "originSummary": [
      "United Airlines has discovered loose bolts and other parts on the plug doors of its Boeing 737 Max 9 jets during inspections following a rapid depressurization incident on an Alaska Airlines plane of the same model.",
      "At least five United aircraft have been found to have these loose parts, raising concerns about the assembly and quality checks of the aircraft structure by Boeing and Spirit AeroSystems.",
      "Alaska Airlines has also confirmed issues with its plug doors, and the specific locations of the loose parts vary among the affected aircraft. The FAA must approve inspection processes before inspections can commence."
    ],
    "commentSummary": [
      "United Airlines discovered loose bolts on plug doors of the Boeing 737 Max 9, raising concerns about safety culture and prioritizing profits over safety at Boeing.",
      "The discussion highlights criticism of Boeing's management, quality control issues, and delays in releasing diversity reports.",
      "It emphasizes the importance of proper bolt tightening and inspections in safety-critical areas."
    ],
    "points": 470,
    "commentCount": 673,
    "retryCount": 0,
    "time": 1704746617
  },
  {
    "id": 38921441,
    "title": "Enhancing Key Fob Range: The Science Behind Holding it to Your Head",
    "originLink": "https://physics.stackexchange.com/questions/101913/why-does-a-remote-car-key-work-when-held-to-your-head-body",
    "originBody": "Stack Exchange Network Stack Exchange network consists of 183 Q&A communities including Stack Overflow, the largest, most trusted online community for developers to learn, share their knowledge, and build their careers. Visit Stack Exchange Loading… Tour Start here for a quick overview of the site Help Center Detailed answers to any questions you might have Meta Discuss the workings and policies of this site About Us Learn more about Stack Overflow the company, and our products current community Physics help chat Physics Meta your communities Sign up or log in to customize your list. more stack exchange communities company blog Log in Sign up Physics Stack Exchange is a question and answer site for active researchers, academics and students of physics. It only takes a minute to sign up. Sign up to join this community Anybody can ask a question Anybody can answer The best answers are voted up and rise to the top Home Questions Tags Users Unanswered Teams Stack Overflow for Teams – Start collaborating and sharing organizational knowledge. Create a free Team Why Teams? Teams Create free Team Teams Q&A for work Connect and share knowledge within a single location that is structured and easy to search. Learn more about Teams Why does a remote car key work when held to your head/body? Ask Question Asked 9 years, 10 months ago Modified today Viewed 256k times This question shows research effort; it is useful and clear 128 This question does not show any research effort; it is unclear or not useful Save this question. Show activity on this post. $\\begingroup$ I was trying to unlock my car with a keyfob, but I was out of range. A friend of mine said that I have to hold the transmitter next to my head. It worked, so I tried the following later that day: Walked away from the car until I was out of range Put key next to my head (it worked) Put key on my chest (it worked) Put key on my leg (didn't work) So first I thought it has to do with height of the transmitter. But I am out of range if I use the key at the same height as my head but not right next to my head. Same applies when my key is at the same height as my chest. So it has nothing to do with height (as it appears). Then I thought, my body is acting like an antenna, but how is that possible if I am holding the key? Why would it only amplify the signal if I hold it against my head and not if I simply hold it into my hand? Here's a vid of Top Gear demonstrating it. electromagnetic-radiation everyday-life frequency wavelength Share Cite Improve this question Follow Follow this question to receive notifications edited Apr 23, 2016 at 9:14 SjonTeflon asked Mar 4, 2014 at 15:12 SjonTeflonSjonTeflon 2,06944 gold badges1717 silver badges2323 bronze badges $\\endgroup$ 6 2 $\\begingroup$ here is some sort of explanation. $\\endgroup$ – Wojciech Mar 4, 2014 at 15:22 7 $\\begingroup$ You left your tin foil hat on? :-) $\\endgroup$ – Carl Witthoft Mar 4, 2014 at 15:25 7 $\\begingroup$ Related: skeptics.stackexchange.com/q/5167/16186 $\\endgroup$ – Řídící Mar 4, 2014 at 17:13 4 $\\begingroup$ If you really want an answer to this, you should ask an engineer, not a physicist. $\\endgroup$ – Phil Frost Mar 5, 2014 at 20:02 1 $\\begingroup$ The skeptic answer, in the skeptics SE, is horrible :-( Armchair quoting from internet, plus standard blurb about confirmation bias. Tell about groupthinking to these guys. $\\endgroup$ – arivero Oct 15, 2015 at 5:42Show 1 more comment 9 Answers Sorted by: Reset to default Highest score (default) Date modified (newest first) Date created (oldest first) This answer is useful 114 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ This is a really interesting question. It turns out that your body is reasonably conductive (think salt water, more on that in the answer to this question), and that it can couple to RF sources capacitively. Referring to the Wikipedia article on keyless entry systems; they typically operate at an RF frequency of $315\\text{ MHz}$, the wavelength of which is about $1\\text{ m}$. Effective antennas (ignoring fractal antennas) typically have a length of $\\frac{\\lambda}{2}=\\frac{1}{2}\\text{m}\\approx1.5\\text{ ft}$. So, the effect is probably caused by one or more of the cavities in your body (maybe your head or chest cavity) acting as a resonance chamber for the RF signal from your wireless remote. For another example of how a resonance chamber can amplify waves think about the hollow area below the strings of a guitar. Without the hollow cavity the sound from the guitar would be almost imperceptible. Edit: As elucidated in the comments, a cavity doesn't necessarily need to be an empty space; just a bounded area which partially reflects electromagnetic waves at the boundaries. The area occupied by your brain satisfies these conditions. Edit 2: As pointed out in the comments, a string instrument is significantly louder with just a sounding board behind the strings, so my analogy, though true, is a bit misleading. Edit 3: As promised in the comments, I made some more careful measurements of the effect in question, using a number of different orientations of remote position and pointing. I've posted these as a separate answer to this question. Share Cite Improve this answer Follow Follow this answer to receive notifications edited Apr 13, 2017 at 12:39 CommunityBot 1 answered Mar 4, 2014 at 17:06 Chris MuellerChris Mueller 6,76322 gold badges2828 silver badges5454 bronze badges $\\endgroup$ 19 51 $\\begingroup$ Are you accusing OP of having a hole in his head? $\\endgroup$ – Ross Millikan Mar 4, 2014 at 17:57 2 $\\begingroup$ @RossMillikan As Anna said, a cavity doesn't necessarily need to be a completely empty space in this instance. I edited the post to make it more clear what I meant by a cavity. $\\endgroup$ – Chris Mueller Mar 4, 2014 at 18:29 2 $\\begingroup$ @PhilFrost Valid point. The soundboard makes a string instrument significantly louder with or without a resonance cavity. I therefore admit that my analogy was a bit misleading. However, coloring the sound means precisely making some frequencies louder relative to others, so my analogy is not inaccurate. $\\endgroup$ – Chris Mueller Mar 5, 2014 at 13:54 2 $\\begingroup$ The magnetically coupled \"small-internal-loop-antenna\" and \"head-arm-shoulder-loop\" combination antenna is more efficient. See full response below. $\\endgroup$ – neonzeon Mar 5, 2014 at 15:47 3 $\\begingroup$ @called2voyage Indeed, I had also noticed that. His answer agrees with Phil Perry's answer on this question. The good thing is that these two can be distinguished with a careful experiment. I promise to do the experiment when I get home next week and post the results here by Friday evening (of next week). $\\endgroup$ – Chris Mueller Mar 5, 2014 at 21:34Show 14 more comments This answer is useful 66 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ As promised in the comments to my answer, I went out and measured the effect in a number of different configurations (a couple of days later than promised :-)). For those of you who just want the conclusions, here they are: The remote seems to work better when held to the head though the improvement isn't as marked as one might have expected from a google search of the topic. The best possible orientation seems to be to hold the remote flat against your temple. If you aren't willing to hold it to your head, pointing it at the vehicle seems to work better than pointing it up, and there doesn't seem to be much dependence on how high you hold it. Finally, holding the remote to your chest is worse than just holding it at arm's length. The Experiment I chose six different positions in which to hold the remote, and in each of those positions I held the remote in two different orientations (described in the list below). In each position/orientation I clicked the remote 3 times, waiting a few seconds between clicks. I recorded the number of times out of 3 that the car responded to my click. The car, a 2009 Volkswagen GTI, was parked sideways. Temperature: 70.5$^\\circ$ F; Barometric Pressure: 29.75 inHg; Humidity 86%; Winds: ~5 mph. There were no large structures around accept for the concrete encased stainless steel vacuum tube of the LIGO Livingston Interferometer which runs parallel to the measurement axis and extends for kilometers in both directions. The battery in my remote is a bit old, but I tried to keep my clicks evenly spaced and began with several discarded clicks to try and cancel out battery effects. The different orientations are documented in the picture below, but here is a description Low (Foward/Up): Held down by my leg pointing the remote towards the vehicle or pointing it directly up into the sky. Middle (Forward/Up): Held my arm extended to the right pointing the remote towards the vehicle or pointing it directly up into the sky. High (Forward/Up): Held my arm high above my head pointing the remote towards the vehicle or pointing it directly up into the sky. Chin (Pointed/Flat): Held against my chin either pointed up into my chin or flat against my chin. Temple (Pointed/Flat): Held against my temple either pointed into the temple (like a salute) or held flat against my temple. Chest (Pointed/Flat): Held at the center of my chest pointed towards my chest or held flat against it with the remote pointing up. The Results In table form: and graphically: Share Cite Improve this answer Follow Follow this answer to receive notifications edited 4 hours ago dotancohen 4,53555 gold badges3232 silver badges4646 bronze badges answered Mar 16, 2014 at 17:13 Chris MuellerChris Mueller 6,76322 gold badges2828 silver badges5454 bronze badges $\\endgroup$ 2 2 $\\begingroup$ Good job! Nice experiment and thanks for your effort! $\\endgroup$ – SjonTeflon Mar 16, 2014 at 17:35 5 $\\begingroup$ I sincerely hope that you will find a suitable journal to publish this experiment. My best wishes are with you. The experimental data may be refined by the use of water jars, metal blocks and bricks. $\\endgroup$ – hsinghal Jun 25, 2016 at 13:32 Add a commentThis answer is useful 11 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ Remote \"key fob\" designers intentionally limit size so they conveniently fit in your pocket. However, the convenience comes at a big price - the tiny loop antenna inside is extremely inefficient, transmitting less than 10% of the energy pumped into it, while the rest is simply converted into heat. When holding your remote to your head, your arm, shoulder and head form a much larger \"body loop\" antenna which is almost 100 times more efficient than the remote's antenna. Then, just like in a transformer, the small single \"winding\" of the small loop magnetically couples with the larger, nearby single \"winding\" of your \"body-loop\". The magnetic coupling between these two antennas is not great, but it's good enough to make the combination antenna around 2x to 3x better than the remote alone, resulting in a notable improvement in operating range. Share Cite Improve this answer Follow Follow this answer to receive notifications edited Mar 6, 2014 at 17:01 answered Mar 5, 2014 at 15:21 neonzeonneonzeon 24511 silver badge77 bronze badges $\\endgroup$ 8 $\\begingroup$ The great Alan Bensky has a nice article on magnetically coupled loops. $\\endgroup$ – neonzeon Mar 5, 2014 at 15:27 4 $\\begingroup$ I won't believe that a human head makes a more efficient antenna than the loop in the remote without data to back it up. While a head is much bigger, and if conditions are just right, radiation resistance will be higher, a human head is also much less conductive than copper. Maybe your explanation is correct, but as it stands, with no sources, and no data, -1 for unsubstantiated guessing. $\\endgroup$ – Phil Frost Mar 5, 2014 at 17:58 1 $\\begingroup$ It's also quite possible to make electrically small loops with efficiencies greater than 1%. An efficient antenna isn't at the top list of engineering priorities for a car remote (cost is probably higher), but again, you have cited no sources. $\\endgroup$ – Phil Frost Mar 5, 2014 at 18:01 $\\begingroup$ The key issue is the surprisingly low radiation resistance of a key fob antenna. This article calculates it as 0.0227 Ohm (page 2). The \"body-arm-head\" loop radiation resistance is TENS of ohms - 100x to 1000x larger. $\\endgroup$ – neonzeon Mar 6, 2014 at 2:36 $\\begingroup$ Radiation resistance alone is not a measure of antenna efficiency. Rather, (efficiency) = (radiation resistance) / (radiation resistance + all other losses). A loop of copper is going to have a much lower ohmic loss than a body-arm-head. Water (such as in said body-arm-head) also experiences significant dielectric loss, where the copper antenna does not. Without doing any measurements, it's not hard to imagine losses being 100x to 1000x higher in a human body compared to a copper loop. $\\endgroup$ – Phil Frost Mar 6, 2014 at 12:26Show 3 more comments This answer is useful 9 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ The way it works has nothing to do with your body. Remotes have their antenna as a more or less circular trace on the board (a loop antenna). The strongest signal is when the top or base of the remote is pointed at the receiver. The weakest signal is when the fob is pointed 90 degrees away, such as when pointing it like a TV remote. Guess which way most people point it? Guess which way it's pointing when you hold it to your chin? Share Cite Improve this answer Follow Follow this answer to receive notifications answered Mar 4, 2014 at 23:09 Phil PerryPhil Perry 81966 silver badges99 bronze badges $\\endgroup$ 4 4 $\\begingroup$ I too am curious which explanation is correct. Some experiments are in order. $\\endgroup$ – Chris Mueller Mar 5, 2014 at 13:56 3 $\\begingroup$ You can easily verify it with your own car - simply \"pointing\" the flat side of the remote does not work nearly as well as holding it to your head. $\\endgroup$ – neonzeon Mar 5, 2014 at 15:41 1 $\\begingroup$ @neonzeon If the radiation pattern of the remote is that of an ideal electrically small loop, then maximum gain is in the plane of the loop. Rotating the antenna to achieve the same polarization as the receiving antenna in the car (which could be anything) is also significant. Your fingers, the Earth, the body of the car, and any other conductive objects within sight will cause (probably very significant) deviations from this ideal, simplified model. Fact is, if the remote doesn't work in one orientation, it just might work in some other orientation, like under your chin. $\\endgroup$ – Phil Frost Mar 5, 2014 at 19:45 $\\begingroup$ @neonzeon: Except when the fob is in outstretched hand, it is mostly horizontal and should have decent reception while when it's held to one's head, it is almost certainly pointing the flat side at the car, the worst possible orientation. $\\endgroup$ – Jan Hudec Mar 5, 2014 at 21:12 Add a commentThis answer is useful 2 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ While this may not provide the full answer. This video will help to explain how water acts as an amplifier for the signal. https://www.youtube.com/watch?v=0Uqf71muwWc Share Cite Improve this answer Follow Follow this answer to receive notifications answered May 31, 2014 at 11:41 AndrewAndrew 2111 bronze badge $\\endgroup$ Add a commentThis answer is useful 1 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ I don't think that holding the fob to the head does much good, but what does make a huge difference is holding it high up. The simplest flat plane multipath reflection model predicts that the received power is proportional to $$\\left(\\frac {h_1 h_2}{R^2}\\right)^2$$ where $h_1$ and $h_2$ are the heights of the transmit and receive antennas and $R$ is the distance between them. Antenna height makes an enormous difference in reception quality. (Also at lower heights there is much more scattering from everything around that is ignored in the formula.) Absorption loss is almost nil at usual fob frequencies. A small (relative to wave-length) antenna does get detuned by reflective (metallic) bodies in their neighborhood (within a wavelength, or so, 450MHz ~ 66cm) but the antenna pattern (radiation shape) does not change much by absorbers nearby it except in the direction of the absorbers themselves. A human body being mostly salt water is a lousy radiator and reflector but not the head that is a pretty good dielectric compared to the rest. Share Cite Improve this answer Follow Follow this answer to receive notifications answered Mar 6, 2014 at 15:00 hyportnexhyportnex 18.2k22 gold badges2626 silver badges5757 bronze badges $\\endgroup$ Add a commentThis answer is useful 1 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ The folks at Remcom set out to debunk this myth. https://www.remcom.com/examples/keyless-entry.html They ended up showing why it works. Great software, I've designed a bunch of 2.4 GHz antennas with it that worked quite well in significantly impaired environments. Share Cite Improve this answer Follow Follow this answer to receive notifications answered Nov 1, 2018 at 18:12 user103218user103218 63444 silver badges1111 bronze badges $\\endgroup$ Add a commentThis answer is useful 0 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ Unfortunately I can't remember where I read this, but I recently read a theory/explanation that it's merely because the key is being held higher up. Share Cite Improve this answer Follow Follow this answer to receive notifications answered Mar 6, 2014 at 10:56 shaunebashauneba 10111 bronze badge $\\endgroup$ Add a commentThis answer is useful -2 This answer is not useful Save this answer. Show activity on this post. $\\begingroup$ Are you sure holding it to your head really makes it better? Your experiment is very poorly designed because you have only sampled instances where the remote wasn't working when your head wasn't in the picture. This is blatant selection bias. No doubt, putting the remote near your head (or anything else conductive) will significantly alter the electromagnetic radiations of the remote. But is it better, or just different? If it wasn't working to start, then you changed something, then it worked, that doesn't mean it's better. You need to also try holding it to your head, then find instances where that doesn't work, then try using the remote normally. It's a common flaw in human reasoning at work here. People like to attribute success in some random or complex process to some ritual (in this case, putting the remote on your head) rather than simply realizing the success was due to an unrelated perturbation of the system, or simply another trial. Here's a familiar (at least, to people of the right age) instance of this flaw: The NES had game cartridges that were notoriously unreliable. The culprit was a cheaply designed electrical contact. Child wisdom had it that taking the cartridge out, vigorously blowing into the cartridge, and putting it back in would fix it. Each clan of children probably had some variation on this ritual, with important details, such as pushing the cartridge up and down a couple times, shaking the cartridge, leaving the door open, pressing the reset button multiple times, and so on. In reality, removing and re-inserting the cartridge and rebooting the NES just introduced another trial, and eventually it worked. The rest is insignificant ritual and superstition. (But don't tell any kids from the 80's that -- they won't believe you!) That's not to say it's not possible your head does improve the remote's range. Indeed, your head will be inductively and capacitively coupled to the antenna. Significant RF currents will exist in your head, and some of this energy will be radiated, and your head will radiate differently than the antenna in the remote. Perhaps, by virtue of your head's increased size, it makes a more efficient antenna. It's also possible, by virtue of your head's lower conductivity compared to copper, that it's a less effective antenna. It's also possible your head will act as a reflector, directing more of the radio's energy at the car. It's also possible your head will refract the waves away from the car. The point is we don't know. All the research I've done turns up anecdotal evidence at best, by people who are not RF engineers performing similarly poorly designed experiments, or people who have talked to \"an expert\". I've never seen data collected by a qualified engineer with proper test equipment. Share Cite Improve this answer Follow Follow this answer to receive notifications answered Mar 5, 2014 at 21:37 Phil FrostPhil Frost 4,14133 gold badges2525 silver badges2626 bronze badges $\\endgroup$ 4 3 $\\begingroup$ -1 For an angry rant. Don't you think it would be more productive to go out to your car and test it for yourself? We would be more interested in seeing the results of your own experiment than getting angry rants about how the OP wasn't careful enough with his. $\\endgroup$ – Chris Mueller Mar 5, 2014 at 21:58 1 $\\begingroup$ @ChrisMueller Who said it was angry? Sure, I could test it on my car, but that would be a poor experiment also, due to the extreme lack of precision in measurement, and huge number of uncontrolled variables. There are people who do this sort of thing for a living, and they are called EMC engineers. Unfortunately, unless you know one willing to dedicate some time and a few hundreds of thousands of dollars of test equipment, you may never get a real answer. $\\endgroup$ – Phil Frost Mar 5, 2014 at 22:06 11 $\\begingroup$ Just now tested with Toyota remote, Keithley RF power meter & 1/4-wave antenna at range=1.3 meters: No loop: -59 dBm received. With body loop: -55 dBm. So, 2.5 times more power from the body loop which equates to 1.5 times more range. In line with many similar experiments ran in the past. $\\endgroup$ – neonzeon Mar 6, 2014 at 3:24 1 $\\begingroup$ @neonzeon That's interesting. Perhaps you could elaborate on your test setup in your answer. Or perhaps you could answer the engineering question directly. $\\endgroup$ – Phil Frost Mar 6, 2014 at 12:33 Add a commentHighly active question. Earn 10 reputation (not counting the association bonus) in order to answer this question. The reputation requirement helps protect this question from spam and non-answer activity. Not the answer you're looking for? Browse other questions tagged electromagnetic-radiation everyday-life frequency wavelength or ask your own question. Featured on Meta Update to our Advertising Guidelines Sites can now request to enable a banner to warn about their policy on... Do we want to implement the new AI policy banner on Physics SE? Linked 0 How can a skull/head works as an 'amplifying' antenna? 13 How does my hand amplify an FM radio signal? 11 Why does my body create interference with my clock radio while in bed? Related 7 Why do car keys have longer range when held next to your head? 8 What made the keys in my pocket so hot? 0 Laser vs Transmiting antenna 5 Are cars really Faraday cages: An anomalous observation 2 When you have engine at idle and turn your car, where does the kinetic energy go? 3 Where do the air bubbles inside the pool come from? 2 What is the explanation behind radio shadowing by people? Hot Network Questions Is the speed of Earth's spinning constant over a given 24 hours? Why does the Linux SCSI subsystem drive hardware not obviously related to SCSI? Shortest path to open a letter lock What is the result of extremely over-fermenting bread dough? What are the tradeoffs between NPN vs PNP power transistors? Why do the pieces of breaking objects scatter? Calculate 500 digits of e Counting Collinear Points Safe to travel to Iran in 2024? Book where people live in a city, they are always reborn from a database and regain memories after a certain age? Is \"a Japanese novel\" written in Japanese or can it be a translation? What does \"idle dog\" mean - is it slang or just a regional expression? Checking whether sets of columns are the same, row wise in R, in any order Which US visa do I need as a British citizen who had visited Iraq? Important NPC need to die in fight - narrative or dice Firmware-updater user guide Can the insurrection clause be applied without a conviction by jury? Is there a way to change multiple file extensions at once on Windows 10? What is the limit to which humans can precisely time notes on an instrument or perceive notes as precisely timed? Why doesn't the windshield fog up where my kid drew on it with her fingers? Can there be a case while /proc/cpuinfo file has several different model & model name fields? What is this wrong inscription at the Doors of Durin, the gate of moria? Difference between \"not remembering having said\" and \"never having said\"? Microwave sparks more hot questions Question feed Subscribe to RSS Question feed To subscribe to this RSS feed, copy and paste this URL into your RSS reader. Physics Tour Help Chat Contact Feedback Company Stack Overflow Teams Advertising Collectives Talent About Press Legal Privacy Policy Terms of Service Cookie Settings Cookie Policy Stack Exchange Network Technology Culture & recreation Life & arts Science Professional Business API Data Blog Facebook Twitter LinkedIn Instagram Site design / logo © 2024 Stack Exchange Inc; user contributions licensed under CC BY-SA. rev 2024.1.9.3159 Your privacy By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy. Accept all cookies Necessary cookies only Customize settings",
    "commentLink": "https://news.ycombinator.com/item?id=38921441",
    "commentBody": "Why does holding a key fob to your head increase its range?Hacker NewspastloginWhy does holding a key fob to your head increase its range? (physics.stackexchange.com) 460 points by jasonhansel 14 hours ago| hidepastfavorite121 comments Johnythree 10 hours agoA more likely theory is that the fob transmitter (and antenna) is tuned to put out max signal when near the body. This is it&#x27;s normal use.If however you tested it with the fob somewhat isolated it would then be out of tune.eg in the factory it would be tuned at a set distance from a \"dummy body\".It&#x27;s the same with a walkie-talkie radio. The antenna must be tuned when held in the hand, as your body provides the missing earth or ground-plane.You can easily demonstrate this. Mount an antenna on a ground-plane with a length of coax, a SWR meter and a transmitter. Tune the antenna so the SWR is 1:1 and then move you hand close to the antenna. Once your hand gets withing a wavelength or so, the effect of the \"detuning\" can be readily seen on the SWR meter. reply jpk 9 hours agoparentThis reminds me of a class in college where one project was to make a waveguide WiFi antenna. You know the ones; often built out of a Pringles can.On the day the project was due, we each demo&#x27;d our antennas and the instructor recorded their range, SNR, etc. Most in the class followed the Pringles can tutorials, but I was always kinda extra. So I used some kind of roof flashing coiled into a cylinder to get the length and radius tuned just right, and I fashioned a comfy handle to aim it using some scrap aluminum flat, and round wood stock.Mine did really well, but it also had the widest variance in performance. We figured out that my wood handle could be held in a way in which you didn&#x27;t actually touch any metal, but if you put your thumb up on the aluminum part of the handle, it instantly got way better SNR!The instructor told us that touching the housing improved the quality of the ground because the capacitance of our meat acts like a short at those high frequencies. reply Aloha 3 hours agorootparentYes - and not surprising, it&#x27;s functionally acting like a ground plane. reply wallaBBB 4 hours agoparentprevNot really - antenna is tuned to the maximum allowed emission power per local regulations (e.g. big differences between EU, US and JPN regulations). Certification tests do not include any human handling, since it&#x27;s really unpredictable and varies. Therefore, tests are just the fob with a (per specifications) positioned Rx antenna (highly controlled environment).BTW similar effect is observed with the fob being next to the bottle of water. There are peer reviewed studies on these topics, that my RF engineer shared with me when I asked him way back about it, but are heavy on the RF&#x2F;antenna theory, beyond my understanding. reply greggsy 4 hours agorootparentI read it in the sense that they would retune or reengineer it if it was discovered that holding it in a hand resulted in poorer performance - ie. they need to factor in the environment it operates in (a hand beside a body) after they design it on paper. reply wallaBBB 3 hours agorootparentThere are 2 limiting factors taken into account during design - regulations and peak current that the battery can supply.The battery thing (usually a coin cell CR2032 that can supply ~13mA per spec) can be a bit mitigated with a beefy capacitor (though RF packet length and space in-between have to be appropriate for the capacitor recovery, not to brown out the system).Usually the bigger bottleneck is the regulation, so you tune for best performance in a clean environment. Hand and body during operation are really unpredictable to model in&#x2F;retune, but luckily usually adds for the better. Anyways the range of the classical RF fobs (@3xx-4xx MHz and 8xx-9xx MHZ bands) is well beyond the real world needs that the 10-20% drop of performance due to certain fob positions will make a difference. If it does, you probably have a low battery.Next gen fobs (if they hit the mass market) are BLE and there the range performance is more critical. Dunno what will be the approach there.What can cause problems are ornament and the mechanical key insert. It has to be extensively tested that there is no coupling with those metal parts that are close to the antenna. Problem comes sometimes when they decide to redesign a bit the keyfob without going through the tests internally (e.g. oh it&#x27;s just a minor tweak of the radius of the metal ring around the fob housing...) and then the certification fails and has to be repeated (not just money, but getting the slot for it...). Some OEM might even be inclined to think they don&#x27;t need a certification for such a minor change and push it to the market, making the problem worse if there is an issue.Regarding the ornament things on fobs, there were even instances of them magnetically coupling with the wireless chargers or even immobilizers and that lead to some melting... reply puzzlingcaptcha 7 hours agoparentprevMore likely than what? SE comments provide at least three distinct theories. IMO this one (also provided in the comments) seems fairly conclusive https:&#x2F;&#x2F;www.remcom.com&#x2F;examples&#x2F;keyless-entry.html reply hulitu 1 hour agoparentprev> A more likely theory is that the fob transmitter (and antenna) is tuned to put out max signal when near the body. This is it&#x27;s normal use.This is true. reply DeathArrow 9 hours agoparentprevEven simpler, tune in an FM radio and move your hand near the antenna. It will sound better or worse depending on your hand position and how close it is to the antenna. reply Thlom 8 hours agorootparentBack in the early 00&#x27;s when we still had analogue VHF TV signals, we wanted to watch the football world cup at school. Of course there was no cable or anything at the school and no VHF antenna and streaming was not a possibility yet so we had to be creative. We found an antenna cable and tried to manipulate the cable and use whatever as an antenna. We tried the sheet metal roofing, but that didn&#x27;t work very well, we tried some metal rods and that didn&#x27;t work great either. By chance we found out that if someone held the cable in one hand and leaned out of the window with their other hand stretched out we got a signal that was good enough to watch the game. Well, for everybody except the poor bastard that had to stand behind the TV halfway out the window. reply yrro 7 hours agorootparentFond memories here of watching Babylon 5 on a Performa 5300 with an Apple TV Tuner Card. There was no antenna to the room with the computer, but I found that I was able to get an acceptable picture by holding the coax cable attached to the antenna input in the right way while keeping one hand attached to the central heating radiator... reply ipsum2 7 hours agorootparentprevReminded me of discovering this when I was a kid and thought I was magic. I had forgotten about that. reply matsemann 8 hours agorootparentprevSo a homemade theremin? reply yunohn 6 hours agoparentprevThe scenarios being compared are:- Fob in hand- Fob in hand, held against headBoth of these already fulfill your “near body” requirement. Your point around tuning would not explain the specific difference being questioned. reply beAbU 8 hours agoparentprevYou might be right about this, it makes sense. So standing on your tippytoes with the remote-arm stretched out to try and get better range is actually counter productive. Take 2 steps closer, and hold the remote close to your body. reply andyjohnson0 6 hours agoparentprevHow does it detect the presence of a nearby human body? reply hmottestad 6 hours agorootparentOP means that while developing the radio and antenna part of the fob the engineers have adjusted the radio and antenna to work the best when in close proximity to a body. The human body has a certain effect on the radio signals, so adjusting the radio and antenna to work best while close to the human body will mean that it won&#x27;t work as optimally when further away from a human body.It doesn&#x27;t detect the human body, it is just designed to work the best when it is physically close to the human body. reply bbarnett 2 hours agoparentprevOr pointing it at your head, is the same as holding it up high in the air. reply marcus0x62 1 hour agoprevWhen goofing off while tracing wires with a tone generator[0], we used to press the detector wand into our head, lick our finger tips, then run our fingers along the contacts on the 66 block[1] until we heard the warble from the tone generator.0 - A troubleshooting and wire identification tool consisting of a battery-powered generator that produces a distinctive warbling sound and an inductive detector with a speaker that allows you to hear the warble when placed near the correct wire pair. Most look like this: https:&#x2F;&#x2F;www.grainger.com&#x2F;product&#x2F;EXTECH-Tone-and-Probe-Kit-4...1 - a wiring terminal commonly used in the telephone system. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;66_block reply chaorace 1 hour agoparentThose tone probes are so fun to play with! I highly recommend anyone with a spare $15 to grab a cheapo model and just... run around the home with it. It&#x27;s an enlightening experience to actually perceive with your own ears the normally invisible world of EM radiation reply dicroce 25 minutes agoprevWhen I was a kid I had a tv where the quality of the picture noticeably improved when you touched the antenna... and I had recently heard that humans were mostly water... So I grabbed a glass of water and set it on top of the tv near the antenna and the picture cleared right up. Unfortunately this event made me the IT support guy for the family from then on... reply xp84 10 hours agoprevThe answer posted with all the experiments is conducted with a 2009 GTI, which reminds me of my first car, a Jetta from a generation before that. Its manual included this helpful illustration of the full expected range of the remote:https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;1Pdfyg4Yes, apparently they were only willing to promise it would work within about arm&#x27;s length of the car! It wasn&#x27;t that bad, but also it wasn&#x27;t a heck of a lot better, either! reply eitally 15 minutes agoparentI had a 2001 GTI and it similarly only reliably worked within probably 25&#x27; of the vehicle. In contrast, my 2017 F150 fob works as much as 150-200&#x27; from the vehicle. I tremendously appreciate this, especially with remote start to warm it in the winter. reply mcv 3 hours agoparentprevShort range isn&#x27;t necessarily bad. Modern cars unlock automatically if you try to open the door while the keyfob is in range, so long range could mean someone could unlock your car while you&#x27;re out of sight.I don&#x27;t know if that system uses the same range as when you press the button on the keyfob, but I have read about a hack (probably here) where thieves used a transmitter to extend the range of both the car and the keyfob to unlock the car while the owner is out of sight. That&#x27;s easier to do the longer the range is. reply maccard 8 hours agoparentprevMy first thought was \"I wonder if the car is to scale or the fob\" reply chaorace 1 hour agorootparentWell, it&#x27;s in a 3D perspective so we have the third option of saying that they&#x27;re both to scale and that the perceived size difference is a forced-perspective illusion. In that case you could actually measure the distance depicted in the diagram, though I have my doubts about how accurate they bothered to make it! reply Hamuko 10 hours agoparentprevArm&#x27;s length of the front bumper, but about 1-2 car lengths of the front door. reply avalys 9 hours agoprevThis effect 100% works, I’ve tried it many times over 20 years with many different cars.It is best if you hold the flat side of the remote up against your chin. reply jurassicfoxy 1 hour agoparentIt&#x27;s really funny when people don&#x27;t believe it though. At first glance it looks like such an obvious \"you&#x27;re a gullible idiot\" hoax, haha. reply ipython 1 hour agoparentprevFunny I came here to share the “chin” trick as well. reply aadityaubhat 2 hours agoprevGood explanation I found on YouTube few years back - https:&#x2F;&#x2F;youtu.be&#x2F;0Uqf71muwWc?si=eLDi_zvMtXJeh_WZ reply johnny_canuck 2 hours agoprevI used to use this trick when I worked as a photographer of used cars. You&#x27;d get some 10-20 fobs and be expected to walk a lot of ~300+ cars and take images of them. Holding the fob up to your chin was the trick to finding the right vehicle... assuming the battery wasn&#x27;t dead.I still use this trick today to find my car when I park somewhere I am unfamiliar with. reply nativeit 37 minutes agoparentI just had to tip my cap. I worked as an imaging clerk for Copart Auto Auctions about 18-years ago. My job was more about putting the images on the website (and ordering new photos if they weren’t to-spec, or if there was visible gore—it being an insurance auction), but I have an intimate awareness of your experience. It was an interesting, if poorly paid, job experience. reply mmaunder 8 hours agoprevNot sure I agree with the cavity theory. I suspect it’s you, you big ole bag of salt water, acting as a capacitive ground plane for the antenna. It’s like mounting a ham or CB antenna on a car and having the metal of the car not be in direct contact with the ground, but it acts as a capacitive ground plane. You can do something similar with a vertical antenna using ground radials in a star pattern on the ground. reply Angostura 6 hours agoparentIf that were the case, wouldn&#x27;t simply holding it in your ungloved hand be sufficient? reply teeray 3 hours agorootparentProbably not. Position of the antenna relative to the ground plane alters the radiation pattern. That’s why you’ll see police cruisers mount their antennas dead center on the roof—it creates an omnidirectional pattern. Mounting it to one side or another causes the field to radiate more in the direction with more roof in front of it (kind of the opposite of intuition). So the remote in your hand still likely interacts with your body, but not in a controlled or desirable way. reply gorlilla 3 hours agorootparentprevThe ground plane is typically orthogonal to the antenna. Both TX and Rx antennae will have their own &#x27;effevtive&#x27; ground plane relative to each other at any give point in time that will effect their Tx&#x2F;Rx capabilities. Add into that, parking lots are full of metal objects and typically nearby large buildings. Those, also, will change the propagation characteristics of the general environment.There&#x27;s a lot at play in open-air environments. This does seem quite easy for DIY experiments using RTL-SDRs in varying environments. reply phendrenad2 8 hours agoparentprevI think this is the real answer. reply seeknotfind 10 hours agoprevBecause I saw this headline, I tried to hold my key fob to my head today to lock my car, but it didn&#x27;t work and I had to walk closer. So, there&#x27;s one data point for you. Maybe I&#x27;m doing it wrong reply martin-adams 9 hours agoparentI’ve been using this trick for many years. Things like when in a car park and trying to confirm I’ve locked my car at some distance, this has worked. It’s been pretty reliable for me. reply pbhjpbhj 4 minutes agorootparentMaybe there&#x27;s a difference in resonance of the people reporting their experiences here; also differences in the frequency tuning of the fobs? reply LargeTomato 9 hours agorootparentprevOne more anecdote, this has not consistently worked for me. Raising the height of the receiver may have an effect but I&#x27;m not sure. reply srcreigh 3 hours agorootparentWe need to cross analysis people across the axes of tall&#x2F;short and large&#x2F;small head for posterity reply abrugsch 3 hours agoparentprevI too have been using this trick for many years on many cars since first seeing it done by Clarkson on Top Gear (circa 2006 IIRC and linked in the PSE question). I still baffle people with the considerable amount of extra range it can achieve. Half a football pitch was probably the best example I got on a 2008 Nissan Qashqai. reply redhale 6 hours agoparentprev\"Works on my skull\"I typically press it firmly against my chin, and I have observed increased range many times (including testing this trick explicitly with a few different fobs a few years ago out of curiosity). Try pressing more firmly, or rotating the fob. reply ta8903 9 hours agoparentprevMaybe the one case where \"you&#x27;re holding it wrong\" is valid advice. reply TheWoodsy 12 hours agoprevKeysight Labs did some testing on this a few years ago. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=AjYyjQKW-pU reply nxobject 10 hours agoparentI never expected the sire of HP&#x27;s test and measurement division to be posting entertaining casual YouTube content, but here I am. reply ht85 5 hours agoprevFrom the top answer:> 1&#x2F;2 m ≈ 1.5 ftThanks US units for the quote of the day: \"Meters are for waves, feet are for antennas\" reply jimnotgym 2 hours agoparentExcuse me, feet are US units??? Surely you mean feet are units that were adopted in the US... and then dropped by the rest of the world! reply elzbardico 2 hours agoparentprevFunny how everybody readily accepts the metric system for measuring radio wavelengths without complaints. Even the most hardcore traditionalist ham radio operator in America never complains about naming bands with meters. reply Buttons840 13 hours agoprevIt also works holding it near your torso, don&#x27;t have to use your head.Although, the joke you tell your friends is that it only works if they open their mouth and stick out their tongue like a satellite dish.The fact that it works next to your torso made me think it was just a matter of bouncing half the radio emissions towards the vehicle, thus doubling the signal. Just like someone holding an omni-directional campaign lamp close to their body increases the light headed in a certain directions. reply tempestn 13 hours agoparentThat was my first thought too, but the OPs tests had the range only improving when held to the head. reply Buttons840 12 hours agorootparentI&#x27;ve had my fob fail to work multiple times while walking away from my car, so I take it out of my pocket and put it near my lower back and it works (even though I&#x27;m now even farther away because I&#x27;m walking). reply cstejerean 11 hours agorootparentThat&#x27;s slightly different though, sounds like fob went from being blocked by your body to no longer being blocked by your body. reply chii 12 hours agorootparentprevi suspect the torso&#x27;s cavity isn&#x27;t as amplifying as the liquid in your brain.an interesting test would be to try a full bladder vs empty bladder... reply TeMPOraL 8 hours agorootparentWe could then measure how the signal range changes as you pee, particularly with the length of the urine stream.I&#x27;m serious. This would be an analogue to those navy experiments with shooting streams of sea water to fashion temporary antennas of arbitrary length, instead of having permanent ones that have fixed length and stick out. reply rft 4 hours agorootparentThanks for the liquid antenna pointer, I had no idea this was actually tried! Apparently not only the navy thought about this, but there are idea floating around about using liquid metal for variable length antennas.One of the links I found: https:&#x2F;&#x2F;www.mwrf.com&#x2F;technologies&#x2F;embedded&#x2F;systems&#x2F;article&#x2F;2... reply ratg13 11 hours agoparentprevIt’s just using the water in your body as an antenna.You can see the same effect by holding the car remote to a water bottle.You’ll notice the water bottle gives you about the same extended range as your head. reply eps 6 hours agorootparent> You can see the same effect by holding the car remote to a water bottle.And this ^ doesn&#x27;t actually work.I know it because I specifically tested it. Went from 2L bottles and all the way to 8L jug. Nada. But the head works. reply ratg13 26 minutes agorootparentYou’ve piqued my curiosity.I will have to run more tests. reply eichin 10 minutes agorootparentclean water isn&#x27;t a great conductor - the body is a bag of dirty water... reply ace2358 12 hours agoparentprevI’ve always put the key behind my head when doing this, and can confirm, it extends the range through experimentation.I thought for sure I’d be absorbing it with my head but I definitely get extra range. reply jvanderbot 12 hours agorootparentvs holding it out at arms length but same height? Ground interference is a thing. reply eps 6 hours agorootparentI can confirm that holding the remote next to the head doesn&#x27;t work, but touching chin, temple or the back of the head does extend the range. This works not just with car remotes, but also with garage door openers. reply jimnotgym 2 hours agorootparentHave you tried standing on one leg, and touching your nose with the free hand. Vast improvement over the amatuer technique reply HenryBemis 6 hours agorootparentprevMy favorite place (and yes I do this since I saw the Top Gear) is under the chin, pointing the fob&#x2F;key upwards and opening my mouth. So it doesn&#x27;t use the skull&#x27;s cavity but the mouth&#x27;s (or so I think&#x2F;believe) reply ace2358 9 hours agorootparentprevYes, holding at same height. I did not know about ground interference! Thanks. reply dijksterhuis 13 hours agoprevtop gear (UK) demonstrating this in practice (potato video quality) https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_jACSPipPSE reply MaXtreeM 9 hours agoprevSixty symbols (same author as Numberphile) video on this from 9 yeas ago: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=0Uqf71muwWc reply hprotagonist 2 hours agoprevThere were no large structures around accept for the concrete encased stainless steel vacuum tube of the LIGO Livingston Interferometer which runs parallel to the measurement axis and extends for kilometers in both directions.amazing. reply karol 3 hours agoprevCan we now discuss it in the context of 5g? That would be so much more interesting. reply martijnvds 8 hours agoprevSixty Symbols did a video on this almost a decade ago: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=0Uqf71muwWc reply rabuse 13 hours agoprevMy ex-girlfriend used to do this back in our teens, and I used to think she was crazy... until I started to do it. Blew my mind. reply userbinator 13 hours agoprevI am disappointed to see no mention of \"passive radiator\" nor \"parasitic element\" on that page anywhere: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Driven_and_parasitic_elements#... reply kevin_thibedeau 12 hours agoparentMust have been the log lady&#x27;s secret all along. reply snapetom 8 hours agoprevWow, I first heard about this in the early 90&#x27;s in high school! I was told to hold it under your chin. It seemed to work, but I never formally did any experimentation nor did I have the statistics base back then. I still did it up until I got a proximity fob a few years ago. However, I always felt silly because I thought it was an old wives tail from my childhood. Very cool to learn there&#x27;s actual science behind it. reply cableshaft 13 hours agoprevUsed to have a radio transmitter that plugged into my car lighter, and hook up to an mp3 player (or whatever) and transmit that on a radio frequency that the car could pick up. Often it would be staticky unless I set the device on my leg, and then it got a lot clearer.Always assumed it just kind of turned my body into an extra large antenna. Probably works for a key fob in a similar way. reply gnicholas 13 hours agoprevI’ve found it helps to hold my key with both hands. reply riffraff 9 hours agoparentI can imagine you may also try to raise your hands to get less ground interference, at which point it would not be inappropriate to invoke the power of Greyskull. reply tempestn 13 hours agoparentprevThat would support the head-arm loop theory. reply piskov 12 hours agoprevMakes one wonder about bluetooth headphones reply plugin-baby 11 hours agoparentIME Bluetooth headphone volume increases if you put them near your head reply aqfamnzc 11 hours agorootparentI find this especially true when moving them close to the ears. Could it be the dished shape? reply KeplerBoy 6 hours agorootparentprevbluetooth is a digital transmission. The volume is encoded in the signal, it can&#x27;t get louder just because it receives a clearer signal.Unless the reduced power consumption by the transceiver causes the battery voltage to rise noticeably. reply sgerenser 3 hours agorootparentEmpirical evidence says otherwise. Bluetooth headphones on desk, can hardly hear anything. Touching my head (particularly the ears), loud and clear. reply KeplerBoy 26 minutes agorootparentOhh, I need to work on my sarcasm detector. replyWithinReason 7 hours agoprevAn explanation I read somewhere is that the radio waves reflect from the inside of your skull, the curvature acts as a parabolic antenna. reply eps 6 hours agoparentThat&#x27;s a pretty dumb explanation if you pardon the bluntness. The effects shows itself regardless of how the head is turned reltive to the target. reply willis936 4 hours agoparentprevGiven the conductance of flesh and the frequencies at question the skin depth would only be a few cm at most. The RF energy never makes it through the brain. reply peter_d_sherman 1 hour agoprevInteresting!>\"This is a really interesting question. It turns out that your body is reasonably conductive (think salt water, more on that in the answer to this question), and that it can couple to RF sources capacitively.\"Related: Capacative Coupling: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Capacitive_coupling reply HPsquared 8 hours agoprevThe same reason your phone speaker gets louder when you put it on the table. reply pyinstallwoes 8 hours agoprevI always thought it was because my skull acted as an antenna :P reply K0balt 6 hours agoprevIt’s because the antennas in fobs lack an effective ground and are typically unbalanced. The body acts as an RC choke, creating a short on the ground side of the antenna (a typically intentional part of the design). The closer the fob is to your body mass, the better it will perform. Bone may also act as a reflector to some degree, and height can play a role. reply cranberryturkey 14 hours agoprevyour skull acts as an antenna reply icepat 5 hours agoparentI&#x27;ve started using a HAT running the TINFOIL distribution, then I&#x27;ve configured ingress with request token validation. I bill everyone around me on a per-request basis for UNLOCK calls to their car. I&#x27;ve found the system works pretty well at keeping unwanted GET requests to my MIND database by various bad actors. reply pestatije 13 hours agoparentprevanybody&#x27;s head range increases by holding anything to it...101 physics reply mypgovroom 2 hours agoprevIt doesn&#x27;t reply risfriend 8 hours agoprevFascinated by this, going to dig deep. reply throwaway892238 8 hours agoprevI mean, it&#x27;s electromagnetic waves. The right wavelength will bounce off things and increase likelihood of receiving a coherent signal. Works for a lot of things; RF, sound, light. RF has low energy and huge wavelengths. IIRC keyfobs are in the 200-600MHz range.Ha, found some (kind of) evidence:Radiowave Effects on Humans - March 28, 1980 &#x2F; T. Neil Davis (https:&#x2F;&#x2F;www.gi.alaska.edu&#x2F;alaska-science-forum&#x2F;radiowave-eff...) One reason the question is unanswered is that the energy absorbed by a human from radio waves depends upon the relationship between the size of the human and the frequency of the radio waves. Just as a TV antenna of the right length and orientation picks up the best signal (the most energy) from a transmitted wave, so it is with a human being. It appears that the cranial cavity of a mammal will resonate at specific radio frequencies determined by the size of the brain cavity. At these resonant frequencies the human head will absorb vastly more radiowave energy than it will at other nearby frequencies. An adult&#x27;s head will resonate at a frequency between 350 and 400 MHz (megahertz). Being smaller, a child&#x27;s head will resonate at a higher frequency, somewhere between 600 and 850 MHz. Since each individual may have his or her own resonant frequency, a particular frequency radiowave might affect one person more than another. Consequently, testing on humans--even if people are willing to let this happen--can be rather complicated.Basically the human head is a resonance chamber that probably amplifies the signal. But also your body is made of water, and RF bounces off metal and water. The capacitive coupling of skin probably adds an enhancement to the effect. reply nsonha 12 hours agoprevMy brain could not connect to wifi the other day and the key fob trick worked! reply behnamoh 13 hours agoprevIn the movie LalaLand, they mention that this is dangerous (causing diseases). Is that true? reply drivers99 11 hours agoparenthttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=w5SRH6Ac1LI&t=25s Love that movie. I didn&#x27;t remember that so I found the scene. The character&#x27;s joking &#x2F; trying to mess with the other person. \"You gotta put that thing to your chin. It makes your head into an antenna, so... I think it gives you cancer but you find your car faster. I mean, you don&#x27;t live as long but you get where you&#x27;re going quicker so it all evens out. Just a suggestion.\" At 5:15 in that video she tries it and it works. reply Buttons840 12 hours agoparentprevShould we worry about a radio transmission powered by a 3 volt battery while taking on our phone? reply zontorol 12 hours agorootparentA phone battery is 3.8 volt. No worry, right? reply Buttons840 11 hours agorootparentGood point. I don&#x27;t know much about these things. Are the radio transmissions from a phone stronger? I would expect so, but don&#x27;t know. reply hutzlibu 8 hours agorootparentprevDepends. There is lots of irrational fear with this and as far as I know, no solid proof for harm, but there is extra electricity flowing in your head, because of the transmission of your phone. I don&#x27;t like talking on the phone that much anyway, so I do not care so much, but if I would talk for hours, I would use a headset (also for ergonomic reasons). reply farkanoid 12 hours agorootparentprevBut my remote contains a 12V battery &#x2F;s reply acomjean 13 hours agoparentprevI suspect not. Its a short burst of rf and not done very frequently. (I use this technque with an key fob near an open mouth probably 4 times a year.. Thanks Car talk.https:&#x2F;&#x2F;community.cartalk.com&#x2F;t&#x2F;does-the-remote-entry-work-b...Your phone is probably worse. reply buntz 13 hours agorootparentDuring summer my bald head burns in the 5 minutes it takes to roll garbage to the curb.Really doubt even phones are dosing us the way nature does. reply hammock 12 hours agorootparentprevWhy would the duration or frequency of the burst matter if RF is harmless? reply initplus 12 hours agorootparentRF is harmless below the point where it directly heats tissue.Having a full strength cell tower transmitter inside your home is not safe due to the intensity of the transmission, it will directly heat tissue inside your body. reply Kirby64 10 hours agorootparentI think the distinction&#x2F;point is that it&#x27;s not harmful in the &#x27;this might give you cancer&#x27; way that ionizing radiation sources will. Worst case, you get an RF burn... which is not great, but it&#x27;s effects are immediate and obvious, unlike ionizing radiation which is much more insidious. reply coldtea 8 hours agorootparentprev>RF is harmless below the point where it directly heats tissue.Would it heat tissue anymore than the Sun (in warm places) or your heater or air-conditioner set to heat already does 10x stronger? reply hammock 23 minutes agorootparenthttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yqljaKjKjd4^ this guy literally does nothing more than lay a long wire out on the grass, and touching it instantly smokes and burns his skin reply retrac 8 hours agorootparentprevMicrowave RF that is somewhat directional behaves a lot like laser light.If you were to step into the beam carried by a waveguide for something like a powerful TV transmitter, it will cook you through like a death ray out of science fiction. Fortunately it&#x27;s not actually collimated, so just a few feet away the energy is barely enough to cook your retinas faster than your blood supply can cool them (which can cause blindness). Otherwise, yes, it&#x27;s much like infrared heating effects. If infrared penetrated a few centimetres deep, anyway. reply coldtea 8 hours agorootparent>Microwave RF that is somewhat directional behaves a lot like laser light.While fob frequency is microwave, isn&#x27;t it also much lower energy compared to, say a microwave oven, powered by mains power to cook food?And also the fob operating in the low 100s of Mhz, not GHz, wouldn&#x27;t that make it less dangerous? replyseba_dos1 12 hours agorootparentprevWhy would the amount or the way it gets into your body matter if water is harmless? reply havblue 2 hours agoparentprevI&#x27;m pretty sure that was a \"neg\". reply userbinator 12 hours agoparentprevAs true as the notion that cellphones and microwaves cause cancer. reply entropicgravity 13 hours agoprev [–] It&#x27;s your conductive nervous system (including your brain) that is acting as a directional antenna. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Users on Stack Exchange discuss the effectiveness of holding a remote car key to the head or body to improve its signal strength.",
      "Some users suggest that the body acts as a larger antenna, potentially boosting the signal.",
      "Experiment results and alternative suggestions for improving signal strength are provided in the conversation. There is also mention of the belief that holding a remote key to the head alters electromagnetic radiation, with some users attributing success to trial and error."
    ],
    "commentSummary": [
      "The discussion focuses on different theories and personal experiences regarding improving the signal range of key fobs and radio devices.",
      "Some participants claim that holding the fob near the head or body can extend its range, although this is disputed by others.",
      "There is a debate about the safety implications of radio frequency radiation from devices like phones, with arguments presented for both sides. Further research and experimentation are necessary to gain a better understanding of signal range factors and the potential harm of RF radiation."
    ],
    "points": 462,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1704766995
  },
  {
    "id": 38924300,
    "title": "Google's Search Fails in Firefox due to Bad UA String Sniffing",
    "originLink": "https://github.com/webcompat/web-bugs/issues/131916",
    "originBody": "webcompat / web-bugs Public Notifications Fork 78 Star 700 Code Issues 2k Pull requests Actions Projects 1 Wiki Security Insights New issue Jump to bottom www.google.com - The page is blank when accessed #131916 Open webcompat-bot opened this issue · 6 comments Open www.google.com - The page is blank when accessed #131916 webcompat-bot opened this issue · 6 comments Assignees Labels browser-firefox-mobile diagnosis-priority-p1 engine-gecko priority-normal severity-critical trend-pageload Milestone needsdiagnosis Comments webcompat-bot commented • edited URL: https://www.google.com/ Browser / Version: Firefox Mobile 121.0 Operating System: Android 13 Tested Another Browser: Yes Other Problem type: Site is not usable Description: Page not loading correctly Steps to Reproduce: The page is blank. The page is blank the page is blank. View the screenshot Browser Configuration View console log messages From webcompat.com with ❤ webcompat-bot added the action-needsmoderation label webcompat-bot added this to the needstriage milestone webcompat-bot added the browser-fixme label webcompat-bot changed the title In the moderation queue. www.google.com - site is not usable webcompat-bot added priority-critical browser-focus-geckoview engine-gecko and removed browser-fixme action-needsmoderation labels sv-calin commented • edited Thank you for reporting this issue, I was able to reproduce it. Tested on: • Browser / Version: Firefox Nightly 123.0a1-20240108213208 / Firefox Release 121.0.1-20231230165955 / Chrome 120.0.6099.43 • Operating System: OnePlus 6 A6000 (Android 11) - 1080 x 2280 pixels, 19:9 ratio (~402 ppi pixel density) Notes: Reproducible on both Firefox Release and Nightly Disabling the ETP makes the cookie banner appear but accepting it doesn't result in the page showing, it is still blank Not reproducible on Chrome Moving to Needsdiagnosis. [qa_02/2024] sv-calin added browser-firefox-mobile priority-normal severity-critical trend-pageload and removed priority-critical browser-focus-geckoview labels sv-calin changed the title www.google.com - site is not usable www.google.com - The page is blank when accessed sv-calin modified the milestones: needstriage, needsdiagnosis This was referenced www.google.co.th - site is not usable #131917 Closed www.google.com - design is broken #131982 Closed www.google.com - see bug description #131981 Closed www.google.com - site is not usable #131980 Closed google.com - site is not usable #131979 Closed www.google.co.uk - see bug description #131978 Closed www.google.de - site is not usable #131975 Closed www.google.com - site is not usable #131968 Closed www.google.com - see bug description #131966 Closed www.google.com - site is not usable #131963 Closed www.google.com - site is not usable #131956 Closed 18 hidden items Load more… This was referenced www.google.com - site is not usable #132023 Closed www.google.com - site is not usable #132014 Closed www.google.com - site is not usable #132010 Closed www.google.com - site is not usable #132008 Closed www.google.com - site is not usable #132006 Closed www.google.com - \"Download Chrome\" link fails to open #132005 Open www.google.com - site is not usable #132001 Closed www.google.com - site is not usable #131998 Closed www.google.com - site is not usable #131997 Closed www.google.com - site is not usable #131989 Closed www.google.com - site is not usable #131988 Closed google.com - see bug description #131987 Closed www.google.com - see bug description #131984 Closed Member denschub commented We're investigating. denschub added the diagnosis-priority-p1 label denschub self-assigned this This was referenced www.google.com.br - site is not usable #131986 Closed www.google.co.uk - site is not usable #132033 Closed www.google.com - site is not usable #132032 Closed Member denschub commented This is entirely server-side UA sniffing going wrong. You get an empty HTML doc, only a doctype, with a Firefox Android UA. You can reproduce this with curl, $ curl -H \"User-Agent: Mozilla/5.0 (Android 10; Mobile; rv:123.0) Gecko/123.0 Firefox/123.0\" https://www.google.com % and it seems that this affects all UA strings with versions >= 65. <=64 work. 1 1 This was referenced google.de - design is broken #132036 Closed www.google.com - site is not usable #132035 Closed www.google.co.in - desktop site instead of mobile site #132034 Closed This was referenced www.google.fr - see bug description #132041 Closed www.google.de - site is not usable #132040 Closed www.google.com - site is not usable #132038 Closed This comment was marked as off-topic. Sign in to view Member denschub commented Since this has now been posted to HN, I'll be locking this thread. This bugtracker is a work place, not a discussion forum. webcompat locked and limited conversation to collaborators Member denschub commented Cross-referencing the matching Bugzilla bug: https://bugzilla.mozilla.org/show_bug.cgi?id=1873601 We have a patch ready to deploy in a dot-release if needed, but from what it currently looks like, this hopefully won't be needed. We'll share updates here and on Bugzilla when we have something to share. Sign up for free to subscribe to this conversation on GitHub. Already have an account? Sign in. Assignees denschub Labels browser-firefox-mobile diagnosis-priority-p1 engine-gecko priority-normal severity-critical trend-pageload Projects None yet Milestone needsdiagnosis Development No branches or pull requests 4 participants",
    "commentLink": "https://news.ycombinator.com/item?id=38924300",
    "commentBody": "Google breaks search for Firefox users because of bad UA string sniffingHacker NewspastloginGoogle breaks search for Firefox users because of bad UA string sniffing (github.com/webcompat) 333 points by mozvalentin 6 hours ago| hidepastfavorite166 comments WhackyIdeas 21 minutes agoThis reminds me of a blog post a former exec of Mozilla put out saying Google had been intentionally breaking things to get users to jump ship to Chrome.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38349357 reply kramerger 4 hours agoprevKey part ( from https:&#x2F;&#x2F;github.com&#x2F;webcompat&#x2F;web-bugs&#x2F;issues&#x2F;131916#issuecom...)\"This is entirely server-side UA sniffing going wrong. You get an empty HTML doc, only a doctype, with a Firefox Android UA. You can reproduce this with curl, $ curl -H \"User-Agent: Mozilla&#x2F;5.0 (Android 10; Mobile; rv:123.0) Gecko&#x2F;123.0 Firefox&#x2F;123.0\" https:&#x2F;&#x2F;www.google.com %and it seems that this affects all UA strings with versions >= 65.Kagi (which relies on Brave Search instead of Bing)This is misleading. Kagi uses multiple external sources including Google and Brave as well as their own internal indexeshttps:&#x2F;&#x2F;help.kagi.com&#x2F;kagi&#x2F;search-details&#x2F;search-sources.htm... reply the_snooze 43 minutes agorootparentprev>BingDDG works well enough for me to be my daily driver, but it&#x27;s absolute garbage for any kind of news search. Bing prioritizes MSN repost spam from dubious sources, so I&#x27;m better off going just directly to news sites I trust. reply bad_alloc 2 hours agoparentprevFor people who don&#x27;t know them yet: use DDG bangs. For example \"!m restaurant [citynmae]\" will immediately bring you to Google maps, \"!w chemistry\" will open Wikipedia etc. Super easy and powerful :) reply NekkoDroid 2 hours agorootparentSetting stuff up for that in any browser worth it&#x27;s salt isn&#x27;t too difficult, skipping the entire middleman of any search engine. reply TheCraiggers 2 hours agorootparentBut it&#x27;s already set up for you in DDG, so why not use it?Aside from the fact it&#x27;s another HTTP request, but these days on the majority of computers and connections, that&#x27;s a trivial thing.I&#x27;ll add that !aw to search the Arch Wiki and !aur to search the AUR are my two most favorite commands. reply AdmiralAsshat 16 minutes agorootparent> But it&#x27;s already set up for you in DDG, so why not use it?Because if I wanna search Reddit, I&#x27;d prefer to have &#x27;!r&#x27; search directly within Reddit and not litter my browser history with tons of duckduckgo entries like this:https:&#x2F;&#x2F;duckduckgo.com&#x2F;l&#x2F;?uddg=https%3A%2F%2Fwww.reddit.com%... reply dingnuts 7 minutes agorootparentweird example considering just how bad Reddit&#x27;s internal search is and always has been -- that&#x27;s a site I&#x27;ve always preferred to search with an external search engine, be it Google, DDG, or Kagi loldoesn&#x27;t hurt to have options! to each his own reply plugin-baby 26 minutes agorootparentprev> Aside from the fact it&#x27;s another HTTP requestYou’d think DDG could avoid this via JavaScript if they wanted to. Might be better for privacy, if not for their usage stats. reply eviks 2 hours agorootparentprevIt&#x27;s better to lose the inconvenient ! and use a browser that supports prefixes in the search barThen you can \"w chemistry\" to open Wikipedia with a list of suggestions from the same Wikipedia (\"Chemistry (Girls Aloud album)\") in the same place reply rpdillon 1 hour agorootparentI think everyone in the thread knows about \"search engines\" in Chrome and bookmark keywords in Firefox. The crux of the issue is that there are more than 10,000 bang commands in DDG. Setting up even a popular subset in any given browser is a significant investment. It&#x27;s fine if it&#x27;s the browser you use 99% of the time, but for those spanning multiple computers, phones, and other devices, simply using bang commands is a strict win.https:&#x2F;&#x2F;duckduckgo.com&#x2F;bangs reply eviks 23 minutes agorootparent99% of the time you usesettings -> migration -> importThen set up a gmail forwarding rule.The full documentation is here:https:&#x2F;&#x2F;www.fastmail.help&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;360058752414-Mig... reply Draiken 8 minutes agorootparentprevI am in a similar boat with an ages old Gmail account. My comment was originally intended to be only about Google search (I realize now I didn&#x27;t specify that, lol), but leaving the entire ecosystem is definitely a lot harder... reply cobertos 12 minutes agorootparentprevI migrated about 5 different Gmail accounts off of Gmail to FastMail and it wasn&#x27;t too bad. Though it was at least a day of work across all of them.I honestly spent more time trying to wrangle the data in all of the other numerous Google services those accounts had data with. reply hospitalJail 6 minutes agoparentprevWell I was using firefox and google maps.Apple maps is Yelp spam.What should I be doing? I was doing research reply diggan 3 hours agoparentprevThe only thing that I&#x27;ve found that works properly for my use case (regularly switching between three locales and languages) is Kaggle with the lenses. The only thing missing is disconnecting the locale from the language so I can have proper decimal characters but still search for US-specific things. Right now, I have to chose between having 10,000.10 or 10.000,10 and what language&#x2F;region I&#x27;m searching, together, which is a bit annoying. reply freedomben 2 hours agorootparentI think \"Kaggle\" is supposed to be Kagi but was typoed or autocorrected or something? (If not and you&#x27;re talkign about Kaggle the ML&#x2F;AI company, please disregard)I also use Kagi lenses and it&#x27;s been good, though for me the killer Kagi feature is being able to uprank&#x2F;downrank&#x2F;pin&#x2F;block domains. Such an obvious and simple feature, such a powerful effect.There is a psychological barrier to overcome in paying for searches, but once you get past that, Kagi makes a ton of sense. I suspect the reason Google never implemented personalized search results (like Kagi&#x27;s where you can uprank&#x2F;downrank domains) is because it&#x27;s not about what you see, it&#x27;s about what they show you. i.e. ads. reply diggan 1 hour agorootparentYou&#x27;re right of course, supposed to be Kagi, I blame it on a lack of coffee. reply _jal 1 hour agorootparentprev> the killer Kagi feature is being able to uprank&#x2F;downrank&#x2F;pin&#x2F;block domainsYes! This alone is worth the subscription to me.And I despise and avoid software subscriptions, Kagi is my third. reply devnullbrain 2 hours agorootparentprevDo you mean Kagi? reply pmontra 5 hours agoprev9 minutes ago:> Since this has now been posted to HN, I&#x27;ll be locking this thread. This bugtracker is a work place, not a discussion forum.We have a bad fame. reply latexr 3 hours agoparentLocking the issue after it has been posted to any large community is the right call.The respectful users will look at the thread and not comment to not derail the discussion. The fraction of a percent which may have something relevant to contribute probably already did or will find another way to do so if it’s important.The remaining users will post low quality comments for a while then leave forever. Like a flash mob that invades your home, parties for a few hours, then leaves a mess for the regulars to clean up.Can’t blame the owner for preemptively locking the door. reply lamontcg 3 hours agoparentprev> This bugtracker is a work place, not a discussion forum.that&#x27;s actually an excellent way to frame what a bugtracker is actually for.it is about workers getting shit done and its optimized for the people who work the issues.it isn&#x27;t optimized for the people posting comments on issues.and the fact that a lot of users that have never had to deal with fixing software bugs think it looks like a forum website would explain the impedance mismatch that you often see. reply heresie-dabord 2 hours agorootparent> it is about workers getting shit done and its optimized for the people who work the issues.The above phrase also explains why Social Media is not a bug-tracker. ^_^ reply dylan604 1 hour agorootparentSadly, it seems to be the only bug tracker or method of getting issues noticed by the tech firms with the issues. reply msp26 4 hours agoparentprevWell someone did just write \"&#x27;now you have two problems&#x27; b-bazinga. Software engineering is hard.\"I don&#x27;t blame them for the lock. reply tmtvl 4 hours agoparentprevOur bad reputation is not entirely undeserved, some of us are not as well behaved as others. reply politelemon 4 hours agorootparentIt&#x27;s one of those occasional intersections where we are reminded that our reputation within HN comments does not reflect the outside world. reply pwdisswordfishc 2 hours agorootparentprevNeither is Google’s. reply Uptrenda 4 hours agorootparentprevnext [8 more] [flagged] jgraham 3 hours agorootparent(I work on WebCompat at Mozilla)There are various people whose job involves triaging issues filed on that repo, and communicating with the issue authors where necessary e.g. to figure out additional steps required to reproduce the reported problem. The point of that effort is exactly because we value reports of site breakage so highly, and want to ensure that people reporting them have a good experience.Unfortunately when a bug report (not just this in this repo, but almost anywhere) hits (almost any) social media there&#x27;s a high chance of the suddenly large audience making comments that aren&#x27;t at all actionable in fixing the issue. In this case it seems highly unlikely that anyone can add additional information that will allow a faster resolution, whereas there was already one off-topic&#x2F;unactionable comment at the time the issue was locked.So if we leave the issue open, it has the downside of disrupting our normal workflows, and taking attention away from fixing either the problem at hand, or any other issues that currently require our attention. To me that significantly outweighs the potential upside of leaving it open to \"make people feel welcome\".Of course, like many things in life, it&#x27;s not a mathematical problem where you can derive a correct answer, but a set of tradeoffs based on experience, and therefore reasonable people may come to different conclusions. reply lightedman 1 hour agorootparent\"There are various people whose job involves triaging issues filed on that repo, and communicating with the issue authors where necessary e.g. to figure out additional steps required to reproduce the reported problem.\"And exactly where are the various QUALITY CONTROL testers that should&#x27;ve caught such a dead-simple problem like \"This won&#x27;t work with Google Search\" before it ever happened in the first place? reply jraph 4 hours agorootparentprevOTOH do they need more input from external contributors? They have everything they need. google.com serves &#x27;&#x27; to Firefox and that&#x27;s the end of the webcompat story. Google needs to fix this. Full stop.Given this, I can see how this thing can attract low quality comments and have a very low chance of receiving interesting insight.Now, since we are on HN I&#x27;ll provide my one low quality comment on this: I guess it&#x27;s a silly mistake that&#x27;s not intended, but still feels like another whoops [1].Also: come on Google, seriously? Don&#x27;t you have QA for such things?[1] https:&#x2F;&#x2F;www.zdnet.com&#x2F;article&#x2F;former-mozilla-exec-google-has... reply doix 3 hours agorootparentprevOh come on. As soon as any issue hits any \"social media\" site, the comments turn to shit with people inserting their own clever meme or whatever.The bug is well understood, there&#x27;s nothing to gain from keeping the issue open and a lot to lose. Getting notifications for \"shit posts\" is pretty annoying._Maybe_ they could have avoided explicitly calling out HN and just said \"social media\" or whatever. But you&#x27;re really pulling at straws to get offended here. I don&#x27;t think their an asshole, I think they&#x27;re pragmatic. reply augustohp 4 hours agorootparentprevAlthough I agree his words could&#x27;ve been chosen more carefully, they come from someone used to work with computers. Not his forte. reply bigbillheck 2 hours agorootparentprevA bit of searching suggests that this individual is the same &#x27;robertsdotpm&#x27; who posted that \"b-bazinga\" comment, or at least is closely associated with them. reply striking 2 hours agorootparentGood catch. No wonder their comment sounded so defensive, they&#x27;re the bad guy! reply ben_w 3 hours agoparentprev\"Orange site bad\" is a bit of a meme. I even heard it IRL at a hacker space in the last few weeks. reply avgcorrection 1 hour agoparentprev> This bugtracker is a work place, not a discussion forum.Well, tradeoffs and whatnot with hosting your bugtracker on the most open code platform on the Web. “Conversation limited to contributors until popular site calms down” reply lagniappe 37 minutes agoparentprevat least it wasn&#x27;t a testicle in an egg cup like that other site reply bigbillheck 2 hours agoparentprev> We have a bad fame.But not one undeserved. reply zozbot234 4 hours agoparentprev> ... We have a bad fame.HN is too orange. reply hartator 4 hours agoparentprevMozilla elitism. reply jraph 3 hours agorootparentOr experience with the internet?Of course outrageous GitHub issues get low quality comments from HN.The guy probably reacted like this because of the dummy comment he marked as off topic and probably made the connection.> &#x27;now you have two problems&#x27; b-bazinga. Software engineering is hard.He might have said the same of Reddit, or any social network. It&#x27;s pretty reasonable and I think he made the right call. reply denschub 3 hours agorootparentYou are 100% correct in your assumptions. This isn&#x27;t my first incident, and it won&#x27;t be my last. As much as some folks here want to call me an asshole for that, we have a very good understanding of how this ends if we don&#x27;t lock comments. reply shadowgovt 52 minutes agorootparentFWIW, good on you for managing the signal responsibly.I have to smirk a bit every time I see the public do this to themselves. The public: \"Why are companies never honest? Why is press-release-speak such a space-alien way of communicating?\" Also the public: reacts like this when someone takes a simple, clear action and explains it directly.(And yes, I know I&#x27;m guilty of broad-strokes reasoning lumping everyone in as \"the public\" and anthropomorphizing that entity. In this context, doesn&#x27;t matter. Only takes a few bad actors to wreck the signal). replyandrelaszlo 5 hours agoprevGreat screenshothttps:&#x2F;&#x2F;camo.githubusercontent.com&#x2F;16a554571b3cea973d2b73464... reply Thorrez 2 hours agoprevGoogle is tracking the incident here: https:&#x2F;&#x2F;status.search.google.com&#x2F;incidents&#x2F;hySMmncEDZ7Xpaf9i...Disclosure: I work at Google but not on this. This was linked from the Bugzilla bug. reply robin_reala 2 hours agoparentWhat I don’t understand is why this isn’t just a rollback, or at worst a revert commit and redeploy. I can forgive an issue with a slightly obscure browser, but the fix should be trivial for Google engineers? reply chx 2 hours agorootparentWell, as these things usually go...There&#x27;s a feature important to Middle Manager 32456. You can&#x27;t just revert it for a not-Google browser. That&#x27;s just a no-go.So a fix needs to be developed, QA&#x27;d, rolled. I presume it&#x27;s going to be an out-of-schedule roll so it&#x27;ll probably involve some bureaucracy. (One of my clients is a few thousand people public company and even there a hotfix requires QA lead approval.)Nothing ever is simple. reply egeozcan 1 hour agorootparentprevPerhaps it&#x27;s been a while since it&#x27;s broken? url-bar search works so this seem to only happen if you navigate to google.com directly. How many people navigate to google to search, while using firefox on android? Just a hunch though.OTOH, it&#x27;s amazing that apparently they don&#x27;t have UI tests for FF mobile. reply shadowgovt 50 minutes agorootparent> OTOH, it&#x27;s amazing that apparently they don&#x27;t have UI tests for FF mobile.Why? They don&#x27;t have UI tests for Opera on the Nintendo Wii either, and at this point I bet the install base for Wii-Opera is still larger than the install base for FF mobile.TBH, when I was there it surprised me that Google didn&#x27;t have a dedicated hardware test-bench room with rows upon rows of browser deployments that every UI change needed to be burn-in tested on, but... They don&#x27;t. They never did. In general, their strategy is to be nimble and deploy rapidly (with the expectation they can roll back rapidly). In that context, it actually makes sense why they don&#x27;t have that warehouse of test-bench installations... They&#x27;d slow-down rollbacks as well as rollouts.A handful of projects have dedicated testing targets. They&#x27;re driven mostly by the ideology of individual Googlers (some people really like Firefox) and a handful of high-value users that have specific installs Google isn&#x27;t interested in pissing off. Since they do very little (relatively speaking) B2B business, that&#x27;s a very short list of names. reply kekub 1 hour agorootparentprevIt appears that the problem is related to the version string transmitted by Firefox Mobile. If they were to send an older user agent string, the issue would likely be resolved. However, any rollback would need to be implemented by Firefox, and it seems they are not at fault here.From Google&#x27;s standpoint, this issue may be considered a \"new\" bug, which means they need to conduct an investigation and address it. Consequently, a rollback is not a viable solution for them. reply Moldoteck 2 hours agorootparentprevmaybe not that easy if they use monorepos reply andrelaszlo 5 hours agoprevGoogle partners with Mozilla to deliver a completely ad-free search experience. reply donny2018 4 hours agoparentWhich, coincidentally, happens to be search-free as well. reply dylan604 1 hour agorootparentwhich in turn makes it sound like free money from Googs reply rendaw 4 hours agoprevIs there any legitimate use for UA string sniffing vs feature detection? And what could a search engine possibly do that&#x27;s so bleeding edge it doesn&#x27;t work in all browsers? reply RulerOf 3 hours agoparentThere&#x27;ve been a few, but the first one that impacted me was Chrome&#x27;s switch to requiring the SameSite=None flag on Set-Cookie headers[1] in a third party context.> Warning: A number of older versions of browsers including Chrome, Safari, and UC browser are incompatible with the new None attribute and may ignore or restrict the cookie.This caveat meant that UA sniffing was the only reliable means of setting cookies that were guaranteed to work properly.1: https:&#x2F;&#x2F;web.dev&#x2F;articles&#x2F;samesite-cookies-explained reply dathinab 12 minutes agoparentprevyesn&#x27;tbasically you can send slightly less data by only sending the relevant layout&#x2F;js code etc. with the first request instead of sending some variation which then the browser selects&#x2F;branches onemost likely a terrible optimization for most sides maybe not google search due to how much it&#x27;s calledbut then Google is (as far as I remember) also the company which has tried to push the removal of UA strings (by fixating all UA strings to the same string, or at least a small set of strings)... so quite ironic reply scott_w 3 hours agoparentprevWe’ve seen browsers behave differently in subtle ways. To mitigate impact while we figured out the correct fix, we’ve served different content to them so those users still get a working experience while we figure out and fix the underlying issue.This had nothing to do with feature detection, so the usual suggestions simply won’t work. reply throwaway167 4 hours agoparentprevTrack you in new and exciting ways. reply xcdzvyn 3 hours agoparentprevDetecting the user&#x27;s OS to provide the right binary download link? reply suprfsat 3 hours agorootparentGoogle Earth still asks me to choose \"64 bit .deb (For Debian&#x2F;Ubuntu)\" or \"64 bit .rpm (For Fedora&#x2F;openSUSE)\", but I guess user agent sniffing wouldn&#x27;t help that. reply PlutoIsAPlanet 4 hours agoparentprevGoogle provides a more basic webpage for older browsers. reply Aissen 2 hours agorootparentAnd they often do that wrongly. Try typing \"weather\" in Firefox for Android vs Chrome for Android; a vastly inferior version is shown on Firefox. Changing the UA or using desktop mode makes the page work flawlessly. reply Miner49er 1 hour agorootparentWow, that&#x27;s very anticompetitive. reply klabb3 3 hours agorootparentprevIntroducing ‘about: blank’ by Google. A new way to experience the web. reply djbusby 3 hours agorootparentWill be shuttered in less than 5 years. reply sumtechguy 3 hours agorootparentsuch optimism! reply 1oooqooq 3 hours agoparentprevNo. But you might be misguided if you are incompetent to do it right, with incremental enhancement based on available features&#x2F;resources.But then you will also be incompetent to do it right with UA sniffing, which is even harder and require more maintenance to keep the list up-to-date.That&#x27;s the obtuse thought process on how you get the garbage google just showed us. reply mozvalentin 6 hours agoprevhttps:&#x2F;&#x2F;github.com&#x2F;webcompat&#x2F;web-bugs&#x2F;issues&#x2F;131916#issuecom...This is entirely server-side UA sniffing going wrong. You get an empty HTML doc, only a doctype, with a Firefox Android UA. You can reproduce this with curl and it seems that this affects all UA strings with versions >= 65.Enough friction against Firefox will let the browser still exist (essential for the claim that there is competition) but without actually being able to compete.Interesting theory, but that&#x27;s exactly what M$ got dinged for in the antitrust suit re: Netscape. reply alpaca128 4 hours agorootparentGoogle doesn&#x27;t care, they knowingly implemented the mother of all illegal antipattern cookie banners and only changed it after getting fined over $100M.If the risk is a lawsuit after years of anticompetitive behaviour - if they&#x27;re unlucky - that&#x27;s absolutely worth it for Google. Chrome is now THE web browser platform with the only two remaining notable exceptions being competitors in name only, and no single lawsuit can just reverse that. reply close04 4 hours agorootparentprevMS waged a lot more open war against Netscape, and documented their desire to \"extinguish\", \"smother\", and \"cut off Netscape&#x27;s air supply\".Google is doing more \"eternal irritation by 1000 papercuts\". Never one big blow, never aiming to kill Firefox, they&#x27;re financing it after all. Firefox needs to exist but never be attractive to users, especially on the phone where tracking is next level.I think plausible deniability does a lot of the heavy lifting here. But statistically speaking Firefox being the one browser hit constantly by a stream of random Google issues can&#x27;t be random.The legal and regulatory landscape changed a lot since then too, with Big Tech slowly but constantly lobbying and pushing a lot more than just these tactics into normalcy. A lot of what&#x27;s normal today was outrageous in the &#x27;90s. reply jncfhnb 4 hours agorootparentprevSometimes! And sometimes a middle manager just does what he thinks clears the ticket quickly enough and then someone yells at him.Assuming competence and intention is foolish. reply oblio 3 hours agorootparentprev> Middle management finds a tactic that implements the friction strategy - small \"random\" breaks and persistent performance issues.> An engineer would find the precise measure to implement - break the UA string sniffing targeting a specific browser.You got the strategy right but the implementation is laughable, sorry :-)))The implementation is: \"We have a budget of N story points this sprint to resolve bugs, let&#x27;s prioritize them. Let&#x27;s prioritize by impacted audience size.\"The audience size will make 99% of Firefox specific bugs be deprioritized out of the current sprint. And the next one. And the one after that.And unless a senior engineer stands up to update the prioritization criteria, plausible deniability forever. reply fsflover 3 hours agorootparentprevFormer Mozilla exec: Google has sabotaged Firefox for years (2019) (zdnet.com)304 points by hashhar 49 days ago122 commentshttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38349357 reply boomboomsubban 4 hours agorootparentprevGoogle is currently facing an antitrust suit where their payment to Firefox is a crucial part of the evidence against them. And it&#x27;s over their search engine, which is far more important to them than Chrome.They pay Firefox as they&#x27;re buying a valuable product. Which is why they also pay Safari. reply Fatnino 4 hours agorootparentAre you certain that search is more important than chrome?Sure search was their first product, but they have long since pivoted to being an ad company. And while yes, they can show ads along side search, the real cash cow is all the juicy data they can exclusively hoover up through Chrome to better target ads all across the web not just search. reply disgruntledphd2 3 hours agorootparentNope, search ads are still where they make at least 2&#x2F;3rds of their money. The rest of their ad inventory has substitutes, search really doesn&#x27;t (because they basically invented the category (grumble grumble something Overture)). reply oblio 3 hours agorootparentprevChrome is okish for collecting data. But they have Android which probably provides 100x the data. reply disgruntledphd2 3 hours agorootparentOnly on poor people! (I mostly jest, but having talked to a bunch of former Google ad people, it was a real concern for them that most of their high revenue users were moving to iPhone). replyandyjohnson0 4 hours agorootparentprevIt&#x27;s never been clear to me that Google is actively trying to take-out Firefox. Firefox&#x27;s user base is pretty small - so if they succeed in reducing it they&#x27;d gain very little but lose some shielding from antitrust accusations.I suspect that these problems are more to do with neglecting testing, and just not caring very much about non-Chromium browsers(Disclosure: I&#x27;m a long-time Firefox user) reply bayindirh 4 hours agorootparentThe thing about \"high quality malice\" is it&#x27;s indistinguishable from an error.A bug that breaks others&#x27; tools but not yours is not implemented intentionally, but it&#x27;s not fixed intentionally, so it looks like a benign error.At the end of the day, you use the chance you get, and it makes real damage while you sip your coffee... reply MCUmaster 4 hours agorootparentprevIt’s pretty clear to others. Chrome is supposed to be The Web in the same way that Google is search. reply ranting-moth 4 hours agorootparentprevAntitrust is just money to pay for Google. Firefox is cancer to Google. reply generic92034 4 hours agorootparentI do not know it that is true. Cancer tends to grow... ;) reply pi-e-sigma 1 hour agorootparentwell played, well played :) reply nairboon 5 hours agorootparentprevSimilar to the google image search on Firefox mobile, which has been broken for how many years now? reply guappa 4 hours agorootparentWell image search is broken in general.Reverse search is now completely useless for example. reply shadowgovt 4 hours agorootparentprevThere&#x27;s a much easier explanation.They didn&#x27;t test on it at all. It&#x27;s a browser with sub-5% market share.There are folks in Google who personally test on firefox and believe in it ideologically as an important peace of the web ecosystem, but that&#x27;s not a company policy and detecting Firefox bugs does not gate feature release for most projects. reply pwdisswordfishc 2 hours agorootparentThat&#x27;s just sabotage with extra plausible deniability. reply shadowgovt 1 hour agorootparentIs it \"sabotage\" when you don&#x27;t intentionally devote resources to making some random third party&#x27;s browser work? What obligation do they have?Mozilla has cachet with nerds like us because of its history. Not because it&#x27;s particularly better than alternatives or because it has enough of a user base to throw its weight around.In contrast, they do test on Safari. They&#x27;d lose double-digit percentages of users if they didn&#x27;t.The ecosystem, unfortunately, generally has room for three top browsers. I&#x27;m not even sure Firefox is number four these days. reply yunohn 4 hours agorootparentprevGoogle isn’t sitting around randomly breaking things for Firefox users in this obvious way.I really feel like HNers often forget how minuscule the scale of their usage patterns are. reply alpaca128 3 hours agorootparentGoogle doesn&#x27;t need to intentionally break things, they just have to not test on anything but Chrome and say \"oops\" once a critical mass of complaints come in. Now you could say that they don&#x27;t have to support the competitor, which is fair, but the web is based on standards, and in this case the site breaks based on the user agent and not the lack of some technical capability. reply yard2010 3 hours agorootparentprevHow convenient! reply m45t3r 4 hours agorootparentprevThe title is bad, this only affects Firefox mobile that AFAIK has a really low amount of users (BTW, I am one of them).Not saying that they shouldn&#x27;t have detected this (i.e.: where is the automated testing for those things?), but I don&#x27;t think this is Google screwing up Firefox on purpose.And if Google really wanted to screw up Firefox, they would probably do a better job than User-Agent sniffing. Firefox already has an internal list where it applies fixes for websites (e.g.: setting a custom User-Agent), and the bug report actually comes from it. You can see it by going to `about:compat` page in Firefox. reply lopis 1 hour agoprevGiven Google&#x27;s size and market share, they should be fined whenever they break access to a competitor&#x27;s website (e.g. Chrome update breaks access to DDG) or if their websites break in competitor&#x27;s browser (e.g Google breaks on Firefox). They have more than enough resources to run automated checks on this, so it&#x27;s hard to not see malice instead of incompetence in this case. reply dylan604 1 hour agoparentWhat if it is done during testing as a beta release? If that&#x27;s acceptable, Googs will just turn into one of those companies that never releases full versions and is always just in some form of beta release reply globular-toast 1 hour agorootparentOne of those companies? Google pioneered this. reply fxtentacle 4 hours agoprevThe fact that I didn&#x27;t notice because I&#x27;m using Kagi anyway is probably one of the first hints at Google&#x27;s downfall w.r.t. search dominance. reply adlpz 4 hours agoparentA bit hyperbolic, aren&#x27;t we?Count me in for the destruction of the do-be-evil giant, but we&#x27;re far from it not being absolutely dominant in the space.I didn&#x27;t even know what Kagi was. reply fxtentacle 4 hours agorootparentNo, I actually use Kagi both on my Laptop and on my Firefox on Android.It has one killer feature: you can block Pinterest from spamming your results. reply AH4oFVbPT4f8 3 hours agorootparentBlocking domains is big part of why I use Kagi, I wish they should share their top blocked domains or make it that people can share their blocked domains to help others. They have this https:&#x2F;&#x2F;kagi.com&#x2F;stats, but I&#x27;d like something I can import into my own settings to use. reply jorams 3 hours agorootparentOn the Domain insights tab of that page, the right column is \"Your status\". You can click a status there to instantly apply it to the domain. reply Kuinox 2 hours agorootparentprevYou mean this page ? https:&#x2F;&#x2F;kagi.com&#x2F;stats?stat=leaderboardThe top 7 blocked domain are just pinterest. reply AH4oFVbPT4f8 1 hour agorootparentYes, like that but I&#x27;d like to be able for people to share here is my list of blocks, here is my list of lowers, etc. reply andirk 3 hours agorootparentprevAnd w3schools! reply galangalalgol 4 hours agorootparentprevI think bingchat is more likely to be what eventually supplants google. They funded the ai that created the garbage autogen pages, now they can use more ai to solve it for you in exchange for the low low price of your attention. Tesla will likely supplant google maps any day now when they release an offering. People pay tesla to drive cameras with computer vision around. Google has plenty of altitude and time to correct itself, but probably not as much as it thinks it does. It won&#x27;t die but it might go dormant for a decade or more like MS.Edit: I&#x27;m not saying tesla is building a street view clone. I can&#x27;t imagine they have the bandwidth for that. But the cars recognize construction, speed cameras, police cars, red lights, red light cameras, stop signs and read speed limit signs, which all gets sent back up in real time. They might have to pay to augment their traffic data until enough people without teslas start using the app. reply oblio 3 hours agorootparent> Tesla will likely supplant google maps any day now when they release an offering.An offering of what? reply kup0 50 minutes agoparentprevI&#x27;m a Kagi user myself but I&#x27;m not going to extrapolate that to thinking that because I use something that it points to the downfall of another product&#x27;s dominance.Just because a few techy or aware people use Kagi (or another alternative), is still a drop in the bucket of overall search engine choiceGoogle search is still widely dominant, as much as we might not want it to be. reply boomboomsubban 3 hours agoparentprevI never noticed because I never visit google.com, even when performing a google search. I expect that&#x27;s common. reply anderber 58 minutes agoparentprevKeep in mind that Kagi uses Google Search API. The downfall of Google Search could hurt Kagi. reply Fatnino 4 hours agoprevFirefox should just change its ua to not-chromium. We will all know what it means. reply 1oooqooq 3 hours agoparentyou joke, but microsoft using \"mozilla\" on IE useragent is why to this day every single browser have \"Mozilla&#x2F;5.0\" there.At the time netscape and microsoft were giving out free browsers while fighting for control of the profitable httpd server market, and blocking competitor browsers \"for security\" or something else was the play book of the day. reply joelthelion 36 minutes agoprevThis is going to happen more and more as firefox&#x27;s market share decreases. And then we&#x27;ll be left with chromium-based browsers... reply jraph 3 hours agoprevGoogle deserves Mozilla to send them a UA identical to Chrome. reply lopkeny12ko 2 hours agoprevThe latest comment on the issue states that Mozilla has a patch that can be emergency-deployed as a patch release. The proposed patch literally overrides the UA string for Google.Is it just me, or is this absolutely insane? When Google ships a bug, it&#x27;s suddenly the responsibility of browser vendors to \"fix\" it at the browser level? reply datadrivenangel 2 hours agoparentWe&#x27;re back to the internet explorer days! reply oh_sigh 2 hours agoparentprevIt&#x27;s not the responsibility of the browser vendors. But they have an interest in un-breaking the experience for their users. In a sense, Google is too big to fail, so users want it to work any way possible.It happens all the time, you probably just don&#x27;t realize it. There is special code in Windows for supporting&#x2F;un-breaking popular applications, same with Android and iOS. reply soraminazuki 2 hours agoprevWhy would Google return an empty page based on any UA string? This is such a bizarre bug. reply TonyTrapp 56 minutes agoparentAccording to a comment on the issue, the page output is \"%\", and that suspiciously looks like some template &#x2F; placeholder evaluation might not be doing its jobs properly. reply byteknight 1 hour agoprevMy favorite bug description.\"The page is blank. The page is blank the page is blank.\" reply genevra 5 hours agoprevI wonder how this made it past testing? reply dathinab 4 minutes agoparentsimply: they don&#x27;t testat least not for firefox mobilethey probably test for chrome (desktop+mobile), safari (desktop+mobile), edge(desktop) and maybe Firefox (desktop) but probably no other browser reply ryukoposting 3 hours agoparentprevI have a few guesses:Google has marginal incentive to not kill Firefox (antitrust), they have no incentive to make sure they provide a good experience on Firefox, let alone test with it.The issue seems to be isolated to the search home page, and Google Search hasn&#x27;t exactly been associated with \"quality\" in several years. Internal rot and disinterest gradually chip away at QA. reply _flux 3 hours agoparentprevTesting can never prove something works, only that something doesn&#x27;t. reply ale42 5 hours agoparentprevThey test on version 64 ;) reply shadowgovt 4 hours agoparentprevThey don&#x27;t test on Firefox mobile.Not explicitly anyway. Google&#x27;s testing strategy is as it has always been: do some in-house burn-in testing, then launch to a small number of users and check for unexpected failures, then widen the launch window, then launch to 100%.In this case, the user base in question is so miniscule that no bugs probably showed up at the 1%, 10%, and 50% launch gates. reply exikyut 4 hours agorootparentOr fewer than 20,000 bugs. reply ranting-moth 4 hours agoparentprevTest written according to behaviour? reply conradfr 5 hours agoprevFunny that it works when switching to desktop mode.I never actually looked at what this does. reply andirk 3 hours agoparentI think it changes your user agent string to something that doesn&#x27;t say \"mobile\", and the device \"inner resolution\" or something like that to make it zoom out.https:&#x2F;&#x2F;www.google.com&#x2F;search?q=what+is+my+user+agent+stringhttps:&#x2F;&#x2F;www.whatismyscreenresolution.org&#x2F; reply ziddoap 2 hours agoprevJust another \"oops\" from Google against Firefox.\"Over and over. Oops. Another accident. We&#x27;ll fix it soon. We want the same things. We&#x27;re on the same team. There were dozens of oopses. Hundreds maybe?\"https:&#x2F;&#x2F;www.zdnet.com&#x2F;article&#x2F;former-mozilla-exec-google-has... reply rudasn 4 hours agoprevGoogle search doesn&#x27;t even work on mobile anymore with javascript disabled. reply ravenstine 1 hour agoprevThe user agent header has always been a mistake. I&#x27;m not sure what companies like Google are thinking when they block features from working based on the user agent. In Firefox, I use an add-on that randomizes the user agent string, and I&#x27;ve configured it to use a handful of the most common user agent strings. Occasionally, parts of YouTube will break because of a certain user agent configured, like chats or chat replay, showing nothing but a broken frame with no meaningful information to a non-developer. I guess one could say that it encourages people to update their browsers, or use Chrome which auto-updates, but come on. If a feature legitimately doesn&#x27;t work, then the user still has to update to a modern browser anyway. reply tommica 3 hours agoprevOh, that&#x27;s why the search wasn&#x27;t working earlier - I blamed my phone&#x2F;browser. reply rf15 2 hours agoprevThis is a good reminder that readers of HN should take to heart: Just because a popular github issue gets posted to HN doesn&#x27;t mean that you should head over and do your posting there. Keep it here, usually the associated experts are already on their way or busy working on the problem and you are not helping. reply robblbobbl 41 minutes agoprevHilarious reply lupusreal 2 hours agoprevLast month, Google Maps was completely broken (instant total tab lockup) for all users of a GCC-built Firefox. In that case it was Mozilla&#x27;s fault, Google didn&#x27;t change something to make that happen, but it tells me that Mozilla&#x27;s QA is suffering and probably doesn&#x27;t catch things that are Google&#x27;s fault either.I&#x27;m still using Firefox because I&#x27;m ideologically motivated to, but it&#x27;s no wonder that so many users are dropping the fox for chromium browsers.https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1866409 reply awicz 3 hours agoprev [–] kagi.com reply ravenstine 2 hours agoparent [–] I know that jumping in to mention Kagi has become a meme on HN, but I do think it&#x27;s important to keep encouraging people to move away from Google. The specific search engine barely even matters, as much as I like Kagi. The only way that any of these search engines are going to improve is if more people leave Google in the dust.If people don&#x27;t want to pay for Kagi, then use Brave Search. DuckDuckGo was really gone downhill, so it&#x27;s hard to recommend that. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Users have reported a blank page issue when trying to access www.google.com on Firefox Mobile 121.0 on Android 13.",
      "The problem seems to be a server-side error related to user agent (UA) sniffing, specifically affecting Firefox Android UA versions 65 and above.",
      "Developers are investigating the issue and working on a patch, with updates to be shared on GitHub and Bugzilla."
    ],
    "commentSummary": [
      "The discussion centers around concerns about Google's search practices, including user-agent string sniffing and their dominant position in the search market.",
      "Participants talk about alternative search options such as DuckDuckGo and the convenience of using bang commands.",
      "The conversation touches on topics like bug trackers, software engineer reputation, compatibility issues with Firefox, and speculates on Google's intentions and potential antitrust implications."
    ],
    "points": 334,
    "commentCount": 166,
    "retryCount": 0,
    "time": 1704794689
  },
  {
    "id": 38921668,
    "title": "Mixtral: A Revolutionary Language Model for Diverse Tasks",
    "originLink": "https://arxiv.org/abs/2401.04088",
    "originBody": "Computer Science > Machine Learning arXiv:2401.04088 (cs) [Submitted on 8 Jan 2024] Title:Mixtral of Experts Authors:Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed Download PDF Abstract:We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license. Comments: See more details at this https URL Subjects: Machine Learning (cs.LG); Computation and Language (cs.CL) Cite as: arXiv:2401.04088 [cs.LG](or arXiv:2401.04088v1 [cs.LG] for this version) Submission history From: Devendra Singh Chaplot [view email] [v1] Mon, 8 Jan 2024 18:47:34 UTC (2,811 KB) Full-text links: Access Paper: Download PDF PostScript Other Formats Current browse context: cs.LGnewrecent2401 Change to browse by: cs cs.CL References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) IArxiv recommender toggle IArxiv Recommender (What is IArxiv?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=38921668",
    "commentBody": "Mixtral 8x7B: A sparse Mixture of Experts language modelHacker NewspastloginMixtral 8x7B: A sparse Mixture of Experts language model (arxiv.org) 317 points by ignoramous 13 hours ago| hidepastfavorite125 comments vessenes 12 hours agoThis paper details the model that&#x27;s been in the wild for approximately a month now. Mixtral 8x7B is very, very good. It&#x27;s roughly sized at 13B, and ranked much, much higher than competitively sized models by, e.g. https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;1916896&#x2F;llm_com.... Ravenwolf notes that the model slightly outperforms some of its benchmark testing, and this is my experience. It&#x27;s surprisingly good for a model of its size, and a very capable daily driver on a Mac for chat, code input and other uses.Something that has come to light since the release of the weights, and not mentioned in this paper is that it looks like fairly likely that the 8 experts were all seeded by Mistral 7B and subsequently diverged. This has generated a lot of experimentation in the local LLM community with cloning models as a way to cheaply generate experts.It was generally thought likely that training an 8x7B network would be as much work as training 8 7B networks, but this seems not to have been true for Mistral, which is super interesting.There&#x27;s still a lot of rapid innovation happening in this space, with papers like Calm from DeepMind this week, and a lot of the adhoc experimental layer combining happening in the wild, (see, e.g. Goliath-120b), I think we&#x27;re likely to see some pretty interesting architectural improvements this year in the LLM space.Calm seems to point the way to a next step after MoE, and models like Goliath seem to indicate that even a really really lazy version of Calm (no Linear layer combination, just literally alternating layers at full weights) can be very impactful. Overall I think we will see really, really strong models that are performant on consumer hardware in 2024, likely first half of this year. reply Casteil 12 hours agoparentI&#x27;ve had excellent results with Mixtral too - it&#x27;s genuinely impressive. Only problem is that it&#x27;s a relatively big model that&#x27;s difficult to run with full GPU inference on consumer hardware (vs the 7b&#x2F;13b models people typically use).So far, the main consumer platform capable of running it without &#x27;ruining&#x27; the quality of its output (with high levels of quantization) is the newer Apple Silicon Macs with unified memory - generally >=48GB. It can apparently be done on 32 or 36GB, but there&#x27;s not much headroom.Edit: As coder543 points out, yes - you can run it without more lossy levels of quantization on multi-GPU setups providing those have enough combined vram. reply coder543 12 hours agorootparentMixtral works great at 3-bit quantization. It fits onto a single RTX 3090 and runs at about 50 tokens&#x2F;s. The output quality is not \"ruined\" at all.For the amount of money you&#x27;re talking about, you could also buy two 3090s (~$750 each on eBay) and have 48GB of VRAM to run with less quantization at full speed.M-series Macs are surprisingly flexible platforms, but they&#x27;re not \"the only\" consumer platform that can do Mixtral. reply bekantan 4 hours agorootparent> The output quality is not \"ruined\" at all.That was my experience as well - 3-bit version is pretty good.I also tried 2-bit version, which was disappointing.However, there is a new 2-bit approach in the works[1] (merged yesterday) which performs surprisingly well for Mixtral 8x7B Instruct with 2.10 bits per weight (12.3 GB model size).[1] https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;pull&#x2F;4773 reply mark_l_watson 1 hour agorootparentI could only run 2-bit q2 mode on my 32G M2 Pro. I was a little disappointed, but I look forward to try the new approach you linked. I just use Mistral’s and also a 3rd party hosting service for now.After trying the various options for running locally, I have settled on just using Ollama - really convenient and easy, and the serve APIs let me use various LLMs in several different (mostly Lisp) programming languages.With excellent resources from Hugging Face, tool providers, etc., I hope that the user facing interface for running LLMs is simplified even further: enter your hardware specs and get available models filtered by what runs on a user’s setup. Really, we are close to being there.Off topic: I hope I don’t sound too lazy, but I am retired (in the last 12 years before retirement I managed a deep learning team at Capital One, worked for a while at Google and three other AI companies) and I only allocate about 2 hours a day to experiment with LLMs so I like to be efficient with my time. reply coder543 1 hour agorootparentprevThat is a very interesting discussion. Weird to me that the quantization code wasn’t required to be in the same PR. Ika is also already talking about a slightly higher 2.31bpw quantization, apparently. reply eyegor 10 hours agorootparentprevSo you don&#x27;t see significantly worse performance on 3bit quantized models compared to 4? Every 7&#x2F;13b model I tried quantized gave much worse responses at 3 bit and below, whereas the differences from 4 bit to 6 or even 8 bit is more subtle. reply coder543 9 hours agorootparentMixtral is a larger model, so maybe that makes it more tolerant of that level of quantization? I’ve been impressed with 3-bit Mixtral, but I haven’t done a ton of side by sides against 4-bit because I haven’t felt the need. reply Casteil 11 hours agorootparentprevFair enough. I did put &#x27;ruining&#x27; in quotes for a reason - I haven&#x27;t compared output between Q3 and Q4_K_M that I use, but you do generally sacrifice output quality at higher quantization levels.And you&#x27;re right, you can run it on a multi-GPU setup if you&#x27;re so inclined. reply coder543 11 hours agorootparentYou can also choose to run at 4-bit quantization, offloading ~27 out of 33 layers to the GPU, and that runs at about 25 tokens&#x2F;s for me. I think that&#x27;s about the same speed as you get out of an M1 Max running at 4 bits? Although I&#x27;m not sure about the newer M2 or M3 Max chips. Googling around, I didn&#x27;t immediately see clear benchmarks for those. reply patrakov 9 hours agorootparentJust as another data point, a CPU-only setup with Q5_K_M would give you roughly 4 tokens per second on a Ryzen laptop (Dell Inspiron 7415 upgraded to 64 GB of RAM). reply Casteil 11 hours agorootparentprevNice - that&#x27;s still pretty solid.. although on a more typical 3060 or 3070 with less vram available, I probably wouldn&#x27;t expect numbers quite that good.My 14\" M1 Max does around 30t&#x2F;s on Mixtral Q4_K_M. reply chpatrick 6 hours agorootparentprevCould you share what you use to run it on a single 3090? I&#x27;d love to try it! reply coder543 2 hours agorootparentollama has been by far the easiest way for me, either on Linux directly (as I do now) or WSL2. reply 3abiton 8 hours agorootparentprevHave you tried the 2x 3090 setup? Using nvlink or SLI? reply coder543 2 hours agorootparentI have not personally gotten to test things that way reply lithiumii 11 hours agorootparentprevThree 4060 Ti 16GB (there are single slot models) is around $1500. I think is possible to get a consumer system that&#x27;s cheaper than a 48GB Mac. reply Casteil 11 hours agorootparentYep. Edited my post to reflect as much. The MBP makes a rather nice portable package though. reply ignoramous 12 hours agorootparentprev> the newer Apple Silicon Macs with unified memoryMixtral has been MLXd already? Write ups, if any? reply vessenes 11 hours agorootparentYes it has, actually: https:&#x2F;&#x2F;github.com&#x2F;ml-explore&#x2F;mlx-examples. It&#x27;s right in the main repo. NB, I haven&#x27;t tried this, I&#x27;m using llama.cpp with a non-K-quant quantization on my MBP. reply summarity 6 hours agorootparentI have and don&#x27;t consider MLX to be production ready. I&#x27;ve tested it on M1Max and M1Ultra (128) machines. It&#x27;s completely non-deterministic in its resource consumption, sometimes using the GPU fully, sometimes getting seemingly stuck while processing, sometimes the GPU throttles.However, there&#x27;s one curious thing: llama.cpp _always_ leads to GPU throttling on Apple Silicon (e.g. the M1Max GPU will go from 1200MHz to around 700MHz), and then fully saturates it. In the rare cases I could get MLX to stay on the GPU, it was able to keep it at the maximum clock rate. However the unpredictable pauses and seemingly unoptimized prompt processing makes it hard to pick a winner in end-to-end tokens&#x2F;s reply reexpressionist 2 hours agorootparentprevHere&#x27;s the direct link and I can confirm that Mixtral-8x7B-v0.1 works on M2 Ultra 128GB via MLX and is easy to setup (the longest part is just downloading the weights):https:&#x2F;&#x2F;github.com&#x2F;ml-explore&#x2F;mlx-examples&#x2F;tree&#x2F;main&#x2F;llms&#x2F;mi...We&#x27;ll have a tutorial soon (next week) on combining&#x2F;composing with Reexpress to add uncertainty quantification (and to use it for semantic search). A link will be here: Tutorial 6: https:&#x2F;&#x2F;re.express&#x2F;guide.html reply teilo 2 hours agorootparentI&#x27;m running it on an M2 Max with 96GB, and have plenty of room to spare. And it&#x27;s fast. Faster than I can get responses from ChatGPT. reply coder543 1 hour agorootparentHow many tokens&#x2F;s? Which quantization? If you could test Q4KM and Q3KM, it would be interesting to hear how the M2 Max does! reply Terretta 4 hours agorootparentprevMany options for running Mistral models in your terminal using LLM:https:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Dec&#x2F;18&#x2F;mistral&#x2F;I liked \"Using Llamafile’s OpenAI API endpoint\" described there, using Justine Tunney&#x27;s llamafiles for Mixtral, but the article link is out of date, as the models have been replaced with newer: https:&#x2F;&#x2F;huggingface.co&#x2F;jartine reply LoganDark 12 hours agorootparentprevNot to my knowledge. But because the unified memory doubles as VRAM for the onboard GPU, normal GPU acceleration can access the entire model even if it&#x27;s 50+ GB. That&#x27;s why ASi Macs are currently the holy grail for at-home inferencing, and also why projects like llama.cpp focus so much on ASi above all else, and why so many UIs release for macOS first before other operating systems. Certain Mac models offer up to 192GB of unified memory. reply mkesper 9 hours agorootparentBut that&#x27;s not a Macbook. And a Macbook M3Max with 128GB of RAM is almost 8000€. reply zarzavat 3 hours agorootparentConsidering how inaccessible and expensive 128GB of pro-level cards is, that is believe it or not, a good price. replytracerbulletx 10 hours agoparentprevI&#x27;m looking forward to all the hardware announcements. It&#x27;s certainly looking like intentionally designed on device acceleration of LLMs for consumers is coming. reply pseudosavant 9 hours agoparentprevI&#x27;m really curious if&#x2F;when we&#x27;ll see MoE based on even smaller models like Phi-2? reply bugglebeetle 11 hours agoparentprevMixtral is good but those Ravenwolf benchmarks are meaningless. It’s like some random dude trying to reinvent MMLU without any rigor or consistency and in German. Dataset contamination is a problem, but not one that’s solved by folkloric evaluation of LLMs by people asking for tips on a subreddit. reply vessenes 11 hours agorootparentI don&#x27;t think they&#x27;re meaningless; they have a few benefits:1) He doesn&#x27;t have an ax to grind &#x2F; an LLM to pimp out, so he&#x27;s relatively even-handed2) He uses the same (secret) test data for each model, so his testing is resistant to cherry-picking&#x2F;finetuning on tests3) He likes weirdo role-play prompting, so he has a very good sense of the edges of refusal and alignment tuning4) He picks up stuff well before it hits the only other fair testing I know of, the chat arena5) I think asking stuff in German is at worst neutral, and at best useful for testing capacity in edge cases.Practically speaking, his &#x27;preferred&#x27; non-giant models, Nous-Capybara-34B and Mixtral both are excellent in comparison with some of the others he looks at, and good recommendations.That said, I&#x27;d like to see a test suite that GPT-4 fails at, or struggles at, at least. And, it would save him a lot of time if he could get something automated together, it&#x27;s clearly a lot of effort to hand test all those models. reply audessuscest 7 hours agorootparentI agree with all except using german, because some model might be better at german but it doesn&#x27;t necessarily means they are better overall.For example I&#x27;m pretty sure Mistral models are better at french, so doing a benchmark using french only would be advantageous for them.If you want to compare all models, better use english. Because now his benchmark just show which models is better at german.That being said, it&#x27;s still a very welcomed benchmark. reply bugglebeetle 10 hours agorootparentprevAny tests that are unfalsifiable and can’t be reproduced are meaningless when it comes to gauging the performance of LLMs (and most other things). I could also post on a subreddit and say I have a secret set of German tests that may or may not exist and and I like these models, but that does nothing to advance the science of evaluating these things. If you want to evaluate human preferences, you can use chatbot arena, which can be gamed, but at least reflects more than what one guy says to be true. And this is with me agreeing that Nous-Capybara is also a good model. But don’t take my word for it because it’s not worth very much! reply epups 7 hours agorootparentprevI find it baffling that anyone would take these benchmarks seriously. The methodology is not transparent, and some of the tests completely unfair, like those in German or about specific niche German topics. The author readily acknowledges that these tests are his personal interests, which is totally fair. But that it would rise to the top of that subreddit and now HN as a general measure of quality of any kind is indicative of the lack of reliable benchmarks out there. reply cuuupid 13 hours agoprevI’d like to note that this model’s parameter usage is low enough (13b) to run smoothly at high quality on a 3090 while beating GPT-3.5 on humaneval and sporting 32k context.3090s are consumer grade and common on gaming rigs. I’m hoping game devs start experimenting with locally deployed Mixtral in their games. e.g. something like CIV but with each leader powered via LLM reply snickell 12 hours agoparentYou can also run Mixtral, at a decent token rate, on a post-2020 Apple Macbook Pro M1&#x2F;M2&#x2F;M3 with 32GB+ of RAM. 16GB RAM also works, sort of ok, which I suspect is the same quantization a 3090 is using, but I do notice a difference in the quantization. On my M2 Pro, the token rate and intelligence feels like GPT-3.5turbo. This is the first model I&#x27;ve started actually using (vs playing around with for the love of the tech) instead of GPT-3.5.An Apple M2 Pro with 32GB of RAM is in the same price range as a gaming PC with a 3090, but its another example of normal people with moderately high performance systems \"accidentally\" being able to run a GPT-3.5 comparable model.If you have an Apple meeting these specs and want to play around, LLM Studio is open source and has made it really easy to get started: https:&#x2F;&#x2F;lmstudio.ai&#x2F;I hope to see a LOT more hobby hacking as a result of Mixtral and successors. reply nraford 8 hours agorootparentHow did you get Mixtral to run an a 32gb M1?I tried using Ollama on my machine (same specs as above) and it told me I needed 49gb RAM minimum. reply eurekin 4 hours agorootparentI&#x27;m using: ollama run dolphin-mixtral:8x7b-v2.5-q3_K_S reply mark_l_watson 1 hour agorootparentThat runs on 32G? The original mixtral q3 wouldn’t run for me. Maybe the dolphin tuned version is smaller?EDIT: I just checked, it runs great, thanks. reply barnabee 5 hours agorootparentprevI have so far run it on my M1 MacBook using llamafile [1] and found it to be great.Is there any speed&#x2F;performance&#x2F;quality&#x2F;context size&#x2F;etc. advantage to using LLM Studio or any of the other *llama tools that require more setup than downloading and running a single llamafile executable?[1] https:&#x2F;&#x2F;github.com&#x2F;Mozilla-Ocho&#x2F;llamafile&#x2F; reply cjbprime 11 hours agorootparentprevI don&#x27;t think it&#x27;s true that LM Studio is open source. Maybe I&#x27;m missing something? reply eyegor 9 hours agorootparentLmstudio (that they linked) is definitely not open source, and doesn&#x27;t even offer a pricing model for business use.Llmstudio is, but I suspect that was a typo in their comment. https:&#x2F;&#x2F;github.com&#x2F;TensorOpsAI&#x2F;LLMStudio reply Me1000 4 hours agorootparentprevLM Studio, sadly, is not open source. reply LeoPanthera 13 hours agoparentprevGoogle tells me that the RTX 3090 is priced between US$1,480 and $1,680.You can buy a whole PC for that, I refuse to believe that a GPU priced that highly is \"consumer grade\" and \"common\".Are there any GPUs that are good for LLMs or other genAI that aren&#x27;t absurdly priced? Or ones specifically designed for AI rather than gaming graphics? reply PrayagBhakar 11 hours agorootparent[A used RTX 3090 goes for around $700.](https:&#x2F;&#x2F;prayag.bhakar.org&#x2F;apollo-ai-compute-cluster-for-the-...) reply rfw300 12 hours agorootparentprevI recently purchased a 3090 on Reddit’s hardwareswap community for $550. New GPUs are pricey right now because of shortages, but if you look around a bit it can be affordable. reply alchemist1e9 13 hours agorootparentprevGamers and LLM&#x2F;AI&#x2F;ML GPU users do not find that absurdly priced. Absurdly priced in our world is $15,000 so your perceptions are off by about a order of magnitude. reply __loam 13 hours agorootparentI can assure you a $1,500 graphics card is a big luxury for most gamers.https:&#x2F;&#x2F;store.steampowered.com&#x2F;hwsurvey&#x2F;Steam-Hardware-Softw...3090 isn&#x27;t even in the top 30. reply helloplanets 10 hours agorootparentThen again, the Apple II cost around $6.5k in today&#x27;s dollars. [0] My hunch is that people caring less for tricking out their computers for gaming is about people not being all that interested in being able to have the top of the line graphics settings enabled when playing AAA games. But I think the history of PCs and gaming very much proves that even normal consumers are willing to spend the big bucks on technology when it enables something truly new.[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Apple_II reply MacsHeadroom 10 hours agorootparentprevActually it should be #23 on that list but is split up into two items with roughly 0.6% each. Seems to be a bug.Search the page for 3090 and see for yourself, it&#x27;s on the list twice. reply __loam 10 hours agorootparentTo be honest I didn&#x27;t look that hard reply fbdab103 12 hours agorootparentprevI would go even further - anytime I look at the hardware survey, I am surprised by the anemic and dated hardware people are running. Most people who game are not building a custom box anymore. reply contravariant 5 hours agorootparentI mean I was, but turns out a well built box lasts a while. reply ryanwaggoner 12 hours agorootparentprevAren’t there others in that list above the 3090 that are even more expensive? reply Conasg 13 hours agorootparentprevTo be fair, I got a card second hand to play with, and it was only £700 ($900~) and it came with manufacturer warranty. It was a bit of a gamble, but the 24GB VRAM has been a godsend for experimenting with LLMs. And playing video games at 4K! reply renewiltord 13 hours agorootparentprevNah. It&#x27;s about half that. You can pick up a used 4090 for that much. reply minimaxir 13 hours agorootparentprevtl;dr, no, especially since AMD is lagging behind.Apple is the one doing the best in terms of making consumer-friendly hardware that can perform AI&#x2F;ML tasks...but that involves a different problem regarding video games. reply RandomBK 13 hours agoparentprevIt&#x27;s worth noting that the 4bit quants can run on cpu at ~reading speed, which should unlock many use cases - especially if we can precompute some of the results async. reply minimaxir 13 hours agorootparentThat assumes full CPU utilization, with no other tasks heavily using the CPU.In the case of high-end video games, that&#x27;s unlikely. reply somnic 13 hours agorootparentResource constraints would be a concern, yeah, so if you were developing a game featuring LLMs (which would, at this point in their development and maturity, be a gimmick) you would keep that in mind and keep other demands on resources low. reply RandomBK 13 hours agorootparentprevTrue, yet many games are effectively single-threaded anyways.The bigger problem is memory capacity and bandwidth, but I suspect folks will eventually figure out some sort of QoS setup to let the system crunch LLMs using otherwise unused&#x2F;idle resources. reply ilaksh 12 hours agorootparentprevAlthough in my testing the 4bit reasoning was not nearly as good. reply LanternLight83 10 hours agoparentprevI&#x27;ve been working with local models as agents, and anyone interested in trying this needs to know about llama.ccp&#x27;s \"gammers\" feature. You can force the model&#x27;s output to conform to a specific structure, which is not only useful for ensuring that you recieve eg. valid JSON output but more specific stuff like \"if you choose to do x, you must also provide y\", which can be great for influencing it&#x27;s thinking (eg. an actor who&#x27;s planning ahead might be required to resond with three of any of the five W&#x27;s (it&#x27;s choice which three), but then it get&#x27;s to be free-form inside of the JSON string values, which can be used as context for a following selection from a restricted set of actions; or a model might have option of asking for more time to think at the end if it&#x27;s response, but if it doesn&#x27;t then it needs to specify it&#x27;s next action). This does&#x27;t impact generation speed AFAICT and can be used in vry creative ways, but results can still need re-generated if they&#x27;re truncated and I had to write a function to stop immediately when the valid JSON obj is closed (ie. at the end) or when more that like five newlines are generated it a row. This will vary by model. reply sanjiwatsuki 12 hours agoparentprevThe VRAM usage is closer to a 47B model - although only 2 experts are used at a time for inference, all experts are needed to complete it. reply discordance 11 hours agorootparentConfirmed. Currently running Mixtral 8x7B gguf (Q8_0) on a Macbook Pro M1 Max w 64GB ram, and RAM usage is sitting at 48.8 GB. reply karolist 8 hours agorootparentHow many t&#x2F;s? reply minimaxir 13 hours agoparentprevThe average gamer doesn&#x27;t have a 3090-equivalent, or even an Nvidia GPU.Running LLMs locally to create custom dialogue for games is still years away. reply somnic 13 hours agorootparentVR isn&#x27;t pragmatically accessible to the average gamer due to hardware requirements and the necessity of setting up the right physical environment but there are still VR games. reply __loam 13 hours agorootparentThere&#x27;s a few after almost a decade of vr being a thing. reply Cyphase 7 hours agorootparentHow did you arrive at \"almost a decade\"? There&#x27;s been VR stuff since at least the late 1980s. On the flip side you could say it wasn&#x27;t \"a thing\" until just a few years ago. Or that it isn&#x27;t \"a thing\" yet. reply Mashimo 8 hours agorootparentprev> or even an Nvidia GPU.What do you mean? Most gamers do have an nvidia GPU.Edit: unless you talk about mobile gamers, and not PC gamers? reply michaelmrose 11 hours agorootparentprevWhy couldn&#x27;t this be handled remotely and be handled as part of a subscription to the game? reply fswd 12 hours agoparentprevyou cannot currently run mixtral with a 32k context on a 3090. Unless am I wrong? I think the largest context I was able to reproduce was around 1500 with 2 or 3 bit, I would have to look at my notes. reply noman-land 12 hours agoprevIf anyone wants to try out this model, I believe it&#x27;s one of the ones released as a Llamafile by Mozilla&#x2F;jart[0].1) Download llamafile[1] (30.03 GB): https:&#x2F;&#x2F;huggingface.co&#x2F;jartine&#x2F;Mixtral-8x7B-Instruct-v0.1-ll...2) chmod +x mixtral-8x7b-instruct-v0.1.Q5_K_M.llamafile3) .&#x2F;mixtral-8x7b-instruct-v0.1.Q5_K_M.llamafile[0] https:&#x2F;&#x2F;hacks.mozilla.org&#x2F;2023&#x2F;11&#x2F;introducing-llamafile&#x2F;[1] https:&#x2F;&#x2F;github.com&#x2F;Mozilla-Ocho&#x2F;llamafile#quickstart reply sp332 11 hours agoparentnext [3 more] [flagged] timschmidt 10 hours agorootparentThat&#x27;s easy, just write better software than she does. reply sp332 1 hour agorootparentWe don&#x27;t actually have to let the people who want to disenfranchise others make a play for power. reply aunty_helen 11 hours agoprevOn mac silicon:https:&#x2F;&#x2F;ollama.ai&#x2F;ollama pull mixtralFor a chatgpt-esk web uihttps:&#x2F;&#x2F;github.com&#x2F;ollama-webui&#x2F;ollama-webuidocker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v ollama-webui:&#x2F;app&#x2F;backend&#x2F;data --name ollama-webui --restart always ghcr.io&#x2F;ollama-webui&#x2F;ollama-webui:mainNavigate to http:&#x2F;&#x2F;localhost:3000You can also use ollama in langchain. reply viraptor 11 hours agoparentThere&#x27;s also some unlocked fine tunings available. Dolphin seems to be a very popular one. (Trained on more coding data) If you want to fit under 32gb, there&#x27;s https:&#x2F;&#x2F;ollama.ai&#x2F;library&#x2F;dolphin-mixtral:8x7b-v2.7-q3_K_M reply NwpierratorR 4 hours agorootparentI haven&#x27;t played with dolphin-mixtral, but dolphin-mistral gave me a good impression for generic rag application.There&#x27;s also developments and experimentation in making it more factual via dpo and laser(afaik so far not very unsuccessful). reply vunderba 8 hours agoparentprevI wouldn&#x27;t use Ollama (or any LLM host) through docker on Mac m1 since as far as I&#x27;m aware there&#x27;s still no support for Metal. reply Luc 7 hours agorootparentThe UI is in Docker but the Ollama server isn&#x27;t. reply xrd 13 hours agoprevnext [–]In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarksI&#x27;m interested in seeing how it does with mathematics. That has always seemed like a particular weakness that no one yet has effectively cracked. reply justinl33 13 hours agoparentit&#x27;s sort of a weakness inherent to LLM&#x27;s... next word prediction isn&#x27;t really supposed to be good at math.I doubt it will be ever &#x27;cracked&#x27; with better LLM&#x27;s, only multimodal ones with access to program execution and calculators. reply e12e 1 hour agorootparentSure, llms don&#x27;t do discreet math or logic directly. On the other hand, they write surprisingly good code.I&#x27;m guessing we&#x27;ll see llms that do input>program(s)>run>summarize>outputI&#x27;m not really disagreeing - I just think llms will do \"more of the work\" themselves by way of writing and running prolog programs, symbolic math (Julia etc) and running theorem provers. reply cjbprime 11 hours agorootparentprev> it&#x27;s sort of a weakness inherent to LLM&#x27;s... next word prediction isn&#x27;t really supposed to be good at math.FWIW I don&#x27;t agree with this in a theoretical sense. The reason LLMs can do as much as they can is because next token prediction attempts to infer a world model for the processes that generated each next-token in the training set. I don&#x27;t see a reason that this would preclude learning arithmetic in order to better predict next tokens that require arithmetic.I&#x27;d guess that arithmetic will become suddenly reliable with one of the next significant (e.g. 2-5x) jumps in parameter count. reply justinl33 8 hours agorootparentI disagree; 1. the parameters are there to make the model better at learning textual patterns, not arithmetic patterns. 2. Next token prediction is a terrible way to perform arithmetic. 3. Perhaps most importantly, the loss function does not incentivise being good at arithmetic at all.Any perceived arithmetic ability is just a textual coincidence.I agree that a sufficiently intelligent LLM, like 300+ IQ would have an excellent model of how multiplication works. It may even assist in finding new theorems, but a calculator will always be better at 926*725. reply cjbprime 8 hours agorootparent> 1. the parameters are there to make the model better at learning textual patterns, not arithmetic patterns.There&#x27;s nothing \"textual\" about the tokens. They are arbitrary identifiers. There&#x27;s nothing \"textual\" about transformers! The fact that e.g. GPT-4 can accept images as input, and that its textual performance improved as a result, and that transformers are also being used for text-to-speech models should have already communicated this.> 2. Next token prediction is a terrible way to perform arithmetic.This is just attempting to resolve our disagreement with pure assertion. It&#x27;s certainly less efficient to use an artificial intelligence to do arithmetic. But whether it&#x27;s efficient is a different question than how likely it is to be possible.> 3. Perhaps most importantly, the loss function does not incentivise being good at arithmetic at all.This is blatantly untrue. The same argument would suggest that LLMs can&#x27;t do anything that wasn&#x27;t exactly in their training set already. But they can. reply justinl33 5 hours agorootparent1. this is interesting. tokens are arbitrary identifiers... of text. It&#x27;s called a &#x27;text encoder&#x27; for a reason2. it&#x27;s a strong assertion but it is true. it&#x27;s kind of inherent in the name; next word prediction. Why would you want a calculator to be making predictions? I agree that it&#x27;s worth understanding whether it&#x27;s possible, but your original point was that &#x27;arithmetic will become suddenly reliable&#x27; - this is what I am disagreeing with.3. this links to the above point - you are right: LLM&#x27;s can already perform arithmetic, this could be easily proved by loading up gpt-2. but again, your original point was that LLM&#x27;s will &#x27;figure out&#x27; arithmetic - I don&#x27;t believe they will. The loss function does not incentivize being good at arithmetic, it incentivizes making good predictions that are close to the true value. The loss function will not penalize an LLM who predict &#x27;good&#x27; is the next word when it should have been &#x27;great&#x27;. while it might penalize &#x27;2+2=3; since this sequence would be strongly represented in the training set, it&#x27;s not going to penalize the model getting &#x27;1234*5678&#x27; one digit off - which is the problem. reply eurekin 4 hours agorootparentAbout 3., isn&#x27;t that done specifically in order to not overfit? replyfoota 13 hours agorootparentprevThere&#x27;s been attempts to use different embeddings for numbers, which helps a lot. E.g., https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37936005 reply monkeydust 9 hours agorootparentprevYou don&#x27;t need multimodals to access tools such as calculator. Check out PandasAI or Langchain Agent workflow. Rather than workout 451 * 995 for example the llm constructs the pandas query, runs it, returns result to user. Works pretty well. reply xrd 13 hours agorootparentprevAgreed. But they do call it out here and I&#x27;m interested in understanding why. reply jakderrida 11 hours agorootparentprevAnnoyingly, Bard with Gemini will apparently use coding to answer every logical thinking question and get them all wrong. If you end with \"Do not use code\", it will get them all right. reply Kerbonut 11 hours agorootparentChatGPT-4 is starting to do this now all of the sudden, and it is also annoyingly returning erroneous information. reply dang 10 hours agoprevRecent and related:Mixtral of experts - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38598559 - Dec 2023 (300 comments)Mistral-8x7B-Chat - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38594578 - Dec 2023 (69 comments)Mistral \"Mixtral\" 8x7B 32k model [magnet] - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38570537 - Dec 2023 (239 comments) reply cgeier 8 hours agoprevI haven&#x27;t read a lot of LLM papers, but I believe this is a rather weak paper low on details (note: not the results achieved of the LLM, but the paper itself). If it had landed on my desk for a review, I probably would have sent it back just based on that.For example, they never really say how they trained the experts or which dataset they used.Is this the current standard in the field? reply MichaelRazum 2 hours agoparentExactly, same thought. Actually I would expect, that they trained each expert separately and later together, since you need to train the router network as well. I&#x27;m far from an expert in LLMs. But this would be interesting to know, especially how different training setups influence the performance. reply ShamelessC 8 hours agoparentprev> Is this the current standard in the field?It’s becoming pretty common, yeah. The two things you mentioned: training particulars and dataset mixture are also basically the only competitive advantage companies have. Since the code&#x2F;architecture is trivial to reproduce, anyone with enough money can make a competing model “easily”.OpenAI started this trend and cemented it with GPT4’s “technical report” which didn’t even specify the number of parameters in the model. They’ve been historically vague about their dataset for far longer than that though. reply nl 4 hours agoprevIn their recent interview on the A16Z podcast the Mistral founder said they have multiple internal models between chatGPT and GPT4 level of quality.Given their high quality releases so far they means exciting times for open source LLMs. reply ignoramous 4 hours agoparentExcept there&#x27;s no indication those more powerful Mistral models will also be FOSS. reply nl 2 hours agorootparentWell he said that&#x27;s the plan for the whole company so it&#x27;d be surprising if they aren&#x27;t. reply coder543 1 hour agorootparentMistral Medium is available via their API, but not available for download, for example, so I find that confusing if you’re claiming their CEO claimed the plan is to be open for all models. reply kromem 13 hours agoprevI&#x27;m curious when we&#x27;ll start to see open access multimodal models being released.The advancement in text only models has been amazing, but a lot of the &#x27;emergent&#x27; behavior in GPT-4 may be because of multimodal training and not just MoE or parameter sizes.I&#x27;ll be curious to see if multimodal smaller models see similar leaps. reply minimaxir 12 hours agoparentLLaVA is open, although not the leap you are expecting: https:&#x2F;&#x2F;llava-vl.github.io&#x2F;Meta also released a (non-commercial) multimodal model among 6 modalities: https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;imagebind-six-modalities-binding-ai... reply coder543 12 hours agoparentprevCogVLM is very good in my (brief) testing: https:&#x2F;&#x2F;github.com&#x2F;THUDM&#x2F;CogVLMThe model weights seem to be under a non-commercial license, not true open source, but it is \"open access\" as you requested.It would be nice if someone trained a CogVLM-compatible model from scratch under an open source license. reply beoberha 11 hours agorootparentWhen I tried last, it couldn’t be run on M-series Macs. reply ijustlovemath 13 hours agoparentprevI&#x27;ve heard that Google actually got the jump on OpenAI in this regard (just from people in a FAANG), and they&#x27;re playing a bit of catch-up. OpenAI still has a distinct advantage on the language side, though. This is all hearsay, of course. reply xrd 12 hours agoprevIs this a model that can be run using Simon Wilison&#x27;s LLM tool? I cannot find any mention of Mixtral in the issues nor in the discussions. Is there an easy way to play with this model from the command line other than that? reply gsharma 12 hours agoparentOllama is probably the easiest way. https:&#x2F;&#x2F;ollama.ai&#x2F;library&#x2F;mixtralLM Studio is another option. reply ignoramous 12 hours agoparentprevUnsure what Simon Wilson&#x27;s program does, but you can pull models via many methods.For CLI, Ollama: https:&#x2F;&#x2F;ollama.ai&#x2F;library&#x2F;mixtralWith UI, GPT4All: https:&#x2F;&#x2F;gpt4all.io&#x2F;index.html (doesn&#x27;t yet support Mixtral)In-app, superagent.sh: https:&#x2F;&#x2F;github.com&#x2F;homanp&#x2F;superagent reply xrd 5 hours agoparentprevhttps:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Dec&#x2F;18&#x2F;mistral&#x2F; reply ilaksh 12 hours agoparentprevollama or llama.cpp reply invert_franklin 12 hours agoprevDoes anyone know what Figure 8 at the end shows?It looks like each expert is used interchangeably with no clear pattern. And earlier they say \"Surprisingly, we do not observe obvious patterns in the assignment of experts based on the topic.\"So then, what is the point of the \"expert\"?Could this extra performance just be through the 8 expert architectural design, and not be based on the underlying training material? For example, if all 8 experts were ArXiv papers, would the performance be different? reply jakderrida 11 hours agoparentNot sure if it answers your question, but the expertise of each expert arise from the training process and aren&#x27;t assigned by a human. Thus, they wouldn&#x27;t be discernable to a human. The choice of the model to use, I think, is something called like a \"gating network\". That&#x27;s also trained to favor most appropriate model based on training. reply Mashimo 8 hours agoprevAnyone know of a decent model for coding assistant that can run on a 16GB vram rtx 4060ti? reply gsharma 1 hour agoparentIt will probably require some trial and error, but this leaderboard is a good starting point. https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;HuggingFaceH4&#x2F;open_llm_leaderb...~13B models should work well with plenty of room for other applications. Lately, I’ve heard good things about Solar10B, but new models come in a dozen by day, so it might have already been changed. reply stavros 6 hours agoparentprevThe chatbot arena has tons of good models that can do that, and Mistral, at the very least, isn&#x27;t half bad. reply smcleod 13 hours agoprevWasn’t this what was released at the end of last year? reply simonw 13 hours agoparentYes, the Mixtral magnet link was tweeted on the 8th of December: https:&#x2F;&#x2F;twitter.com&#x2F;mistralai&#x2F;status&#x2F;1733150512395038967The paper just came out today: https:&#x2F;&#x2F;twitter.com&#x2F;dchaplot&#x2F;status&#x2F;1744547220983005478l reply grepfru_it 13 hours agorootparentAlso available on Ollama: https:&#x2F;&#x2F;ollama.ai&#x2F;library&#x2F;mixtral reply IanCal 13 hours agoparentprevThe model itself was, but was the writeup? This submission is from yesterday.I&#x27;ve not been following their releases too well but it seemed they were very much on the side of releasing models asap. reply ricopags 13 hours agoparentprevThe model&#x27;s weights were released in a torrent, but this is the much anticipated paper detailing some of the work. reply SubiculumCode 11 hours agoprevquestions running through my head: Is there some magic with the number 8? Why not 6? 11?Each of these 8 models were 7B models. What about using 80 x tinyllama 1B models? reply justinl33 13 hours agoprev [–] tldr;- &#x27;sparse mixture of experts&#x27; means each layer contains 8 mini-neural-nets (experts), each trained to be good at certain data&#x2F;tasks- a router network passes each token (word) to 2 experts which suit it best- since only 2&#x2F;8 experts are utilized, the model effectively only uses 13&#x2F;47B parameters during inference (text generation)- this expert mechanism makes it very efficient and effective (uses less params, is able to speciailize to tokens)- beats llmana 70b and gpt-3.5, especially at math and coding and language- has fine tuned model able to beat gemini pro, as well as llmana 70b and gpt-3.5 replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper introduces Mixtral, a language model that utilizes a Sparse Mixture of Experts (SMoE) approach.",
      "Mixtral outperforms other language models, including mathematics, code generation, and multilingual tasks, on different benchmarks.",
      "The paper also presents a fine-tuned version of Mixtral for instruction-following tasks, achieving superior performance compared to other models on human benchmarks. The models are available under the Apache 2.0 license."
    ],
    "commentSummary": [
      "The discussions cover various topics, such as the success of the Mixtral 8x7B model and its performance in arithmetic tasks.",
      "There are discussions about the use of quantization and multi-GPU setups, as well as the compatibility of language models with different hardware platforms.",
      "Other topics include the reliability of benchmarks, pricing and availability of GPUs, limitations of current models, and the release of new and more powerful models in the future."
    ],
    "points": 317,
    "commentCount": 125,
    "retryCount": 0,
    "time": 1704768786
  },
  {
    "id": 38917175,
    "title": "The Raspberry Pi Spy: Unveiling a Mysterious Network Intrusion",
    "originLink": "https://blog.haschek.at/2019/the-curious-case-of-the-RasPi-in-our-network.html",
    "originBody": "Last week I got a message from my dad (who works with me at a client) with an image attached. Message from dad I asked him to unplug it, store it in a safe location, take photos of all parts and to make an image from the SD card (since I mostly work remote). I have worked on many Raspberry Pi projects and I felt confident I could find out what it does. At this point nobody thought it was going to be malicious, more like one of our staffers was playing around with something. The parts There were 3 parts: A Raspberry Pi b first generation a mysterious USB dongle a 16GB sd card (a fast one) USB dongle and SD card First thing to do: Ask everybody who can access this network closet The number of people who can access this small cabinet is very limited. Only 4 people have a key for this room: The manager The groundskeeper My co-worker Me None of them knew anything about this so I asked my IT colleagues and they were as baffled as I was. I heard of people getting paid to put things like this in places they shouldn't and for this reason I was very interested in finding out what it actually does. What is that USB dongle though? To help me solve this mistery I asked reddit and surely enough they identified the dongle as a microprocessor, almost as powerful as the Rasberry Pi itself: the nRF52832-MDK. A very powerful wifi, bluetooth and RFID reader. The nRF52832-MDK usb dongle This was - no doubt - to give the old Raspberry Pi a wifi and bluetooth connection. Great so now this thing has wifi too.. Time to dissect the SD card image The SD card has a few partitions. Most ext4 (linux) and one fat16 (boot) GParted view of the image Great, time to mount it. My debian box told me the first big clue: It's a resin installation Resin partitions on the SD Card WTF is Resin? Resin (now renamed to Balena) is a paid IOT web service where you can generate images for IOT devices, deploy those devices and get updates and data from and to resin. Resin also installs a VPN on the device so the collected data is transferred securely. Obviously this device was meant to be picked up again since it leaves a trail as the service is a paid one. Closer look at the partitions First partition is called \"resin-boot\" See something that catches your eye? We got a config.json. Quick jackpot? config.json on the resin-boot partition What we can extract from this file: The application deployed to this resin device is called \"logger\". Not a good sign We got a username. This seems to be the username for the resin account associated with this device Confirmation that the device used a VPN via Port 443 A registration date. It was registered (or first deployed or set up?) on May 13th 2018 About that username.. When I googled the username found in the config.json file I found a person in the same town where this Pi was found. The company then checked their records for this person but found nothing. Oddly enough I found a website from 2001 where parents of \"gifted children\" write articles about them and for some reason sign those articles with their home address and phone numbers. So I have a name and the address of this whole family. Not the actual site but a similar one This could be a wrong lead as usernames tend to be used by multiple people but let's just keep that name in mind. resin-data The data directory didn't have any data stored (as in: collected data) but there was a nodejs app which was heavily obfuscated and to this day I can't tell exactly what it was doing. It seems to talk via a serial connection to the dongle but I can't extract what data is actually collected. I can only assume that it collected movement profiles of bluetooth and wifi devices in the area (around the Managers office) and maybe raw wifi packets. But I found something much more interesting: a LICENSE.md file Screenshot of the LICENSE.md file Odd.. Why would this nodejs app include a confidential piece of software? I googled the company from the copyright header and guess what? The guy from the username I found in the config file is a part owner It is beyond me why a co-founder of a company would distribute these devices around town but well.. Getting the attackers home address Another very interesting thing I found was a file on the third partition (resin-state) in the path /root-overlay/etc/NetworkManager/system-connections/. The file is called resin-wifi-01 and guess what it contains? It contains the wifi credentials to the wifi that was used to set the device up (or to test it). Definitely not the wifi of the company. And what do we do, when we want to find out a location associated with a wifi name? We go to wigle.net, enter the SSID (=wifi name) and it tells us where on the world it is found. not the actual name and not the actual location And guess what? The address we found of that gifted persons parents? That's exactly where our Pi was set up according to Wigle.net Aftermath How and when did the Pi even get there? I checked the DNS logs and found the exact date and time when the Pi was first seen in the network. I checked the RADIUS logs to see which employee was at the premises at that time and I saw multiple error messages that a deactivated account tried to connect to wifi. That deactivated account belongs to an ex employee who (for some reason) made a deal with management that he could still have a key for a few months until he moved all his stuff out of the building (don't ask..). What now Legal has taken over, I did my part and the rest is over my pay grade. For me it was a very interesting challenge and I'd like to thank every person on reddit who helped me with one piece of the puzzle.",
    "commentLink": "https://news.ycombinator.com/item?id=38917175",
    "commentBody": "The curious case of the Raspberry Pi in the network closet (2019)Hacker NewspastloginThe curious case of the Raspberry Pi in the network closet (2019) (blog.haschek.at) 312 points by thunderbong 20 hours ago| hidepastfavorite133 comments liquidgecka 20 hours agoI saw the title and instantly thought of the \"Load bearing mac mini\" at Twitter.In our server closet there was a mac mini sitting on another rack mounted server and plugged directly into a switch. IT found it, asked around and nobody knew what it was, so they unpugged it. Immediately the whole of engineering and support were basically offline.Despite the thing looking suspicious as possible, I had set this thing up as an employee a year before. We were not allowed direct network access to our hosted prod network so as a \"stop gap\" I setup a SSH tunnel that listened on the mini&#x27;s IP. At first we used this for access to the support web interface so it could be taken off the internet. At the time my request for a server was rejected. One by one more things got added to the list of things proxied over the device, eventually including basically all internal pages, git access, and about a dozen other random services. I finally got it moved into the server room, but not to real hardware. Once we built a DC we got peered access and the mini finally died. reply SoftTalker 19 hours agoparentAlso proving yet again that the best way to find out if something is in use is to unplug it and see who complains. reply tengwar2 13 hours agorootparentIt&#x27;s an effective way, but generally a very bad one. I used to work in telecoms, and some idiot took down a tunnel between the UK and Germany carrying 1kB&#x2F;s of RADIUS traffic because someone (the idiot) owned the link it ran on and had failed to record the formal allocation of this tunnel to a production customer-facing public access WiFi service I ran. I on the other had remembered to record his telephone number and his boss&#x27;s telephone number, and a certain amount of screaming went on. Moral: before doing a scream test, make sure your own documentation is watertight. reply gurchik 19 hours agorootparentprevSo-called \"scream test.\" reply csmattryder 18 hours agorootparentChesterton yelling from miles away \"that&#x27;s my damn fence, you moron!\" reply shagie 18 hours agorootparentprevThere was an article by Microsoft back in November about their scream tests - https:&#x2F;&#x2F;www.microsoft.com&#x2F;insidetrack&#x2F;blog&#x2F;microsoft-uses-a-... reply notnaut 10 hours agorootparentThey have about 8 layers of useless customer service acting as ear muffs to deafen the noise, is the problem I’ve had when screaming at them. reply Booourns 18 hours agorootparentprevI once took over a decommissioning project of a DMZ set up for a connection to a third party no longer used. Everything documented showed that all connections were no longer active.Step 1 was to do the ‘scream test’. Some how the enterprise routed the most random traffic through there as we took offline random servers and people’s desktops. Turns out the screaming that happens is at you for making things break instead of a pat on the back for discovering bad networking. reply euroderf 7 hours agorootparentThe information technology equivalent of popping pimples. reply hinkley 17 hours agoparentprevOne of the last contracts I worked, they provided such awful hardware that the company and employees ended up BYOD. Not enough memory for a modern IDE to start up levels of awful.As the project ramped down they ended up having to buy an iMac off of us. Someone stopped using it and before the case even got cold I had installed a CI build agent on it to run Karma tests. Which ended up being invaluable but also never managed to get replaced with a real piece of hardware. So they just dragged that thing around as the project went into maintenance. reply yjftsjthsd-h 19 hours agoparentprev> so as a \"stop gap\"There&#x27;s Nothing as Permanent as a Temporary Solution™:) reply voiceblue 17 hours agorootparentAs immortalized by my favorite case[0] from the codeless code (based on real code [1] from Apollo 11).[0] http:&#x2F;&#x2F;thecodelesscode.com&#x2F;case&#x2F;234[1] https:&#x2F;&#x2F;github.com&#x2F;chrislgarry&#x2F;Apollo-11&#x2F;blob&#x2F;master&#x2F;Luminar... reply luca3v 9 hours agorootparentprevSomewhat relatex XKCD: https:&#x2F;&#x2F;xkcd.com&#x2F;2730&#x2F; reply neilv 14 hours agoparentprevI consider the labelmaker to be a crucial item of sysadmin gear. :) reply davely 12 hours agorootparentTo ensure no one will ever touch it, you can pull the hardware equivalent of adding a comment to a piece of code:&#x2F;&#x2F; AUTOGENERATED DO NOT DELETE reply majewsky 7 hours agorootparentprevWe have a labelmaker in our hackerspace. The box containing it has a label on it \"Please do not print unnecessary labels\". Below it is a label reading \"ok\". :) reply orenlindsey 19 hours agoparentprevI always thought the load bearing Mac mini was a myth, it&#x27;s such an impossible story and it&#x27;s been so widely shared. I guess it&#x27;s just a case of programmers taking the easiest route and having it backfire. reply dijit 19 hours agorootparentThings like this happen all the time.\"Shadow IT\" is the official name for circumstances that lead to this and it&#x27;s the consequence of:A) Deprioritising \"non-urgent\" but \"important\" tasks consistentlyandB) IT being bureaucratic and&#x2F;or unable to allocate budgetI had a Mac Pro (trashcan) at Ubisoft that was the only way people were able to play our studios live game from within the office. (Ubisoft had a \"NO OUTBOUND CONNECTIONS TO INTERNET\" policy for Studios)That same Mac Pro was running our internal slack bot to run Maintenances (and, insult people).I left Ubisoft 5 years ago, as far as I know that Mac Pro is still plugged in on my former desk chugging along, last time I asked my former manager about it was last year.----At another company (now owned by Oracle), we had an internal IRC (this was before Slack) and nobody thought about it.One day it went down, and traceroute had indicated it was in our server room; after checking every single server we could not find it, until someone noticed an ethernet cable that went through a run into the floor but didn&#x27;t come back out.After opening the suspended floor we noticed a laptop running Solaris. That was our IRCd and the OS had an uptime of close to 8 years. reply lostlogin 18 hours agorootparent> Shadow ITUniversities seem to install unlimited hurdles to achieving anything. The stuff staff and students do within the network to make shit work is amazing. reply stefan_ 19 hours agorootparentprevDon’t forget IT ignorance. A lot of places IT is full of Microsoft MVPs that have no understanding of the needs of people developing in and for Linux systems. reply gmfawcett 15 hours agorootparentAh, never attribute to malice or incompetence that which can be attributed to the pain response from trying to secure a heterogeneous OS environment. reply DiggyJohnson 19 hours agorootparentprevDing ding ding. So much friction from this factor alone. reply tomjakubowski 19 hours agorootparentprevI would have thought so too, before I worked on a team where we had our own load-bearing Mac Mini installed at a client site - in that case, load-bearing for A&#x2F;V reasons (no one was able to get PulseAudio working in time).Client&#x27;s IT loved to unplug that thing. reply echohack5 19 hours agorootparentprev> request was denied> mac mini proxy serverI love that the programmer&#x27;s solution is more expensive than doing it the right way had OP&#x27;s request been approved. reply liquidgecka 18 hours agorootparent... At the end of the the deal with had two mac mini&#x27;s with auto fail over configured via health checking. Thank goodness we got rid of the service provider that refused to let us pair with the network. Once that happened the networking team could just do normal peering with a standard router.But yea, in the early days that mac sat on my desk. It only got moved when I pointed out the issue to our new security team and their jaw hit the floor. =) reply NavinF 19 hours agorootparentprevI think it was pretty common in the 2000s when devs could&#x27;t provision machines&#x2F;VMs without asking for permission reply SoftTalker 19 hours agorootparentAlso when you could just plug something into a switch and a) the port is active and b) it goes unnoticed.Probably still the case in a lot of startups. reply liquidgecka 18 hours agorootparentMost startups I deal with these days don&#x27;t even have offices anymore, let alone network ports. =)But yea.. same deal with wifi. Its amazing how often the wifi password is posted on something visible. In fact I have found the password in so many public images which means somebody on the street could just connect to the wifi network fomr the street. reply NavinF 12 hours agorootparentThat&#x27;s only a denial of service issue, not a security issue. Wifi is too cheap to meter reply crtasm 12 hours agorootparentUnknown persons getting onto the company wifi is not a security concern? reply lmm 11 hours agorootparentIt shouldn&#x27;t be. Treat the network as public, require credentials for any access whether it comes from inside or outside. reply woleium 11 hours agorootparentprevWith work from home the security perimeter is the machine. All networks are untrusted. reply NavinF 8 hours agorootparentprevCorrect. Company wifi is just like any other network. Why would there be any services on it that don&#x27;t use encryption and authentication? replystoryinmemo 19 hours agoprevHey friends, use 802.1X for your datacenters and enterprise (certificate) wifi auth so you can audit and rotate credentials to prevent... exactly this problem. Everything else iot-like gets a very limited VLAN &#x2F; alternate WiFi network. reply 63 11 hours agoparentFrom the OP on Reddit at the time:Good points. The problem is, there are over 1000 people coming and going every day, the site has a BYOD strategy and the IT team is 4 people. We tried implementing 802.1X for LAN devices but it was soo much overhead that we dropped that.The thing of this case is that the person was only able to place the Pi there because he had a key to the network closet. That&#x27;s game over no matter how many security protocols you implementWe did change the server passwords though reply geek_at 7 hours agorootparentOP here. What I didn&#x27;t mention in the article is that this actually happened in a public School (small-ish for US standards as there are just ~1000 students and 100 teachers)Hard to get the budget for serious switching hardware, even harder to get people who know how to manage them as I&#x27;m just an external contractor but can&#x27;t exceed the alotted budget for my work there reply atourgates 20 hours agoprevOP posted a bit more info in this Reddit thread for anyone curious:https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;sysadmin&#x2F;comments&#x2F;agij7x&#x2F;remember_t... reply greyface- 20 hours agoparentAnd this HN thread: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29965250 reply asd 20 hours agoprev(2019) Previously: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29965110 reply dang 18 hours agoparentThanks! Macroexpanded:The curious case of the Raspberry Pi in the network closet (2019) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29965110 - Jan 2022 (262 comments)The curious case of the Raspberry Pi in the network closet - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18919129 - Jan 2019 (154 comments) reply BatmansMom 19 hours agoprevIs WiGLE a thing people know about? How does that work, its a service that listens to all publicly available wifis in the country? I understand how it could be possible in theory but how is it actually practical? reply Deathmax 19 hours agoparentData is crowdsourced and contributed by users. On a much larger scale, Apple and Google collect data from iOS and Android devices to power their WiFi&#x2F;mobile tower based geolocation services.Android&#x27;s Location Services: https:&#x2F;&#x2F;support.google.com&#x2F;android&#x2F;answer&#x2F;3467281#location_a...iOS&#x27;s Location Services: https:&#x2F;&#x2F;support.apple.com&#x2F;en-gb&#x2F;102515In fact, Google provides it as a paid API: https:&#x2F;&#x2F;developers.google.com&#x2F;maps&#x2F;documentation&#x2F;geolocation..., but you require BSSID&#x27;s and not just SSID names to try to curb abuse. reply chatmasta 18 hours agorootparentMozilla also has such a service although I believe they&#x27;re deprecating it. You can still query it today, but as a privacy measure you need to include the MAC of 3+ SSIDs to get location info, since otherwise you could check the SSIDs from probe scans of passerby to locate their homes. reply Brybry 8 hours agorootparentprevGoogle street view cars also collect WiFi data (or at least used to): https:&#x2F;&#x2F;europe.googleblog.com&#x2F;2010&#x2F;04&#x2F;data-collected-by-goog... reply ssl-3 4 hours agoparentprevWigle is not a thing that people know about. It isn&#x27;t a secret (at all) -- in fact, it was created in part to raise awareness about the problems associated with open-by-default consumer wireless routers.But, like (say) RIPE Atlas, it just isn&#x27;t very commonly known.Data in Wigle is collected mostly by wardriving, which (in a nutshell) is just driving around and passively recording the information that WiFi access points are shouting about themselves to whoever is listening.The data is collected by volunteers, but it is not strictly free. The way that the project is funded is by selling the data to companies who use it for geolocation services.Regular folks can do some basic searches on the dataset without cost, though, which is what the author has done here. reply SushiHippie 19 hours agoparentprevIt&#x27;s data comes from people who do \"Wardriving\" https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Wardriving reply arcfour 19 hours agoparentprevIt&#x27;s crowdsourced... You drive around and collect data for it and send it in. reply dougdonohoe 19 hours agoparentprevOne of the guys behind the project, bobzilla, worked for me in a previous life. Great guy; fond of tea. reply dzhiurgis 19 hours agoparentprevIt&#x27;s obviously not public data, but satellites have been wardriving WiFi for over a decade. reply podiki 20 hours agoprevFun (or I guess \"fun\" depending on the outcome here) detective story. But would be nice to have the context of what sort of company this Pi was found at. What might be a motive to be tracking devices and be inside the network? reply juliand 5 hours agoparentOP provided a little bit of more context in another comment. It was a public school. reply sitzkrieg 20 hours agoparentprevi have seen redteams do this for persistence reply pnw 3 hours agoprevIf the perp had put this inside something innocuous like a POE injector, and filled it with resin so the SD card could not be easily examined, the device would likely still be there and&#x2F;or they would not have been caught. reply voakbasda 19 hours agoprevWhere’s the follow up? I want to know what happened next with legal…. reply __jonas 14 hours agoparenthere:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29965250 reply exabrial 17 hours agoparentprevcourt records are public. They don&#x27;t mention any names, but I&#x27;d poke around and see what you can find. reply geek_at 7 hours agorootparentOP here. Court records are thankfully not public in europe and it&#x27;s even illegal to name names in public (unless it&#x27;s about a public figure)As far as I know there also were no court proceedings as this was handled internally reply renewiltord 20 hours agoprev> Comment using SSH! Info> ssh rogueraspi@ssh.blog.haschek.atNow that&#x27;s cool haha! reply declan_roberts 20 hours agoprevIt’s still not clear to me whether the pi was malicious or not? reply anakaine 20 hours agoparentDiscreet hacked together device located in comms room, installed by former employee during a time when they were leaving the company.Malicious is implied. reply EricMausler 19 hours agorootparentI think the comment may be implying it isn&#x27;t clear if they were successful in whatever malicious activity they were trying to do or what that activity was.Like were they snooping for something they could whistle-blow, or where they trying to gain access to financial accounts? What was the extent of damage possible by the setup? Are there ways to mitigate such damage now knowing a pi with such loaded software may be in wider distribution and might be installed somewhere on your network? reply HideousKojima 19 hours agorootparentprevAt a previous job we had a Beaglebone mysteriously show up in our DC. We noticed it buried behind some network cables and immediately unplugged it. (Not) Coincidentally, we had gone through a merger a few months prior, and the new corporate IT team had come out (from clear across the country) right after the acquisition to get a feel for how our IT infrastructure was setup. The day after we unplugged the Beaglebone we got a pissed off call from one of the corporate IT guys, turns out he had installed it there to gather some network metrics&#x2F;statistics or something like that when he had come out a few months prior and didn&#x27;t tell any of of our network admins or sysadmins, but somehow it was our fault for not magically knowing what the suspicious SBC in our DC was. reply theamk 15 hours agorootparentThat&#x27;s when you call CISO in, so they can tell: \"No. By our corporate policy, any device not approved by the local IT department is not allowed on our network\"That&#x27;s one of the biggest roles of the CISO, and that&#x27;s why their rank is so high despite often having much fewer direct reports than other CxO&#x27;s - so they can stop crazy stuff from happening, even if it comes from high-ranking people. reply Damogran6 19 hours agorootparentprevThis. The intenet was that the machine COULD be used for ill. Just because it hadn&#x27;t yet doesn&#x27;t absolve the person. reply doublerabbit 19 hours agorootparentprevMaybe they just wanted to keep their Quake3 server running? reply BatmansMom 19 hours agorootparentprevAnd the application was called \"logger\" lol reply AdrianB1 17 hours agoparentprevThis is probably all the author could write without creating a huge legal problem for their employer. The text suggests that clearly. reply lucioperca 7 hours agoprevThey should throw the obfuscated code into chatgpt4 and see if anything meaningful comes up now. reply donatj 19 hours agoprevA number of years ago at a previous job we had building security doing a sweep of our building with a big heavily antenna&#x27;d device because some sort of unauthorized wifi access point showed up.Never found out what came of it, but I wondered then as I do now if someone had just enabled AP mode on their phone. reply lostlogin 18 hours agoparentThis seems weird - most places would have dozens of wifi APs within range of their network unless they were very remote. reply ojbyrne 17 hours agorootparentI don’t think it’s uncommon for people to use their phone AP so as not to use the corporate network. There are even legitimate uses like checking external connectivity. reply WhackyIdeas 19 hours agoprevIt’s almost as if the person didn’t think for a second about someone discovering it… all those traces. Unless it was a set up, fake AP (anyone can create a hotspot quickly on their phone with any SSID). Either a complete reckless amateur or a total set up I am thinking. reply Bluescreenbuddy 20 hours agoprevWhen we fire people we terminate ALL access. Digital and physical. When the call from HR comes in, your keycard is immediately disabled. If you left personal belongings, we&#x27;ll box them up and give them to you. reply skocznymroczny 19 hours agoparentAs an European, I thought that&#x27;s only something people did for movies, I learned not long ago that it&#x27;s actually reality in the US. In Poland you can leave on the spot if you arrange it with the company (e.g. for a severence package). Otherwise by law you are expected to work for a month or two after getting fired (or when changing jobs). This has some benefits for both employer and employee. The employee has time to find a new job and doesn&#x27;t get cut off from income on the spot so he&#x27;s unlikely to burn bridges on his way out. For employer the benefit is the same but also the company gets extra time to prepare a replacement for the fired employee. reply ponector 18 hours agorootparentIt is wild how people in one of the richest and developed country have so little working rights and are ok with it.Especially wild if you consider health insurance is tied to the employment.3-6 months notice period is standard in EU countries. Unless you are sabotaging or always drunk there are no ways they will fire you quickly. reply skinkestek 18 hours agorootparentPeople in leading positions who leave for competitors get told to not show up again, but of course get paid so it is a paid holiday. reply Ductapemaster 17 hours agorootparentprevTo be fair, these rights extend in both directions. This may seem extreme from an employer -> employee direction, but I have the right to do the same in reverse: I could call my manager at 8:30AM tomorrow morning and quit on the spot with no justification.At Will employment cuts both ways. reply ryandrake 17 hours agorootparentExcept the power dynamic and consequences are (usually) totally different:Company fires their employee at 8:30AM on the spot: Employee is now without income and likely health insurance and his ability to pay rent, buy food and merely exist might now be in jeopardy.Employee quits at 8:30AM on the spot: Company is at worst set back a bit until they backfill that job. At best they don&#x27;t even notice. Unless that employee was some keystone that held the whole business together, there is no existential threat to the company. reply PsylentKnight 17 hours agorootparentIn addition to that, it&#x27;s considered \"unprofessional\" to leave without giving at least 2 weeks notice. reply recursive 13 hours agorootparentprevI don&#x27;t think I&#x27;m being arrogant to think that my employer would have a harder time replacing me than I would them. reply lmm 10 hours agorootparentIf that&#x27;s actually the case then you&#x27;re in an extremely fortunate position, and probably something like the top 2% of the income distribution. reply ponector 16 hours agorootparentprevIt is not fair. Fair is when you write resignation letter or receive a termination letter and continue to work for the next 3-6 months. That is fair!Ps: without at will system you can simply stop showing off at work with the same results. reply hinkley 16 hours agorootparentprevWhere things get very strange is when companies enact these same policies on people who give notice.I&#x27;m a software developer. I&#x27;m hired, retained, and often promoted on my ability to look at situations, contemplate actions, and predict their consequences. If I have a piece of paper in hand that announces my resignation, I&#x27;ve been interviewing for weeks, signing acceptance letters, stalking my boss trying to figure out when in the next 36-72 hours I can get him alone and show him the piece of paper.If I can manage all of that without my head catching on fire, then if I meant the company harm it would have already been accomplished prior to cornering my boss. I have probably known for days that my time here is up. We don&#x27;t just wake up one morning to a phone call telling us we have a new job. reply MBCook 19 hours agorootparentprevUnless there is a contract saying otherwise (or union agreement if in a union) you could show up to work at your job tomorrow to be told you’re fired and escorted out of the building.For well paying jobs it’s pretty rare unless you do something bad. Obviously if they just did that to random people it would really hurt morale and other workers may want to leave.But it’s legal. On the other side, with similar exceptions, on any day you can walk into your job and say goodbye forever and never come back. reply alistairSH 19 hours agorootparenton any day you can walk into your job and say goodbye forever and never come backExcept in reality, almost nobody can do that, because they need to eat and pay rent. And if you did, you&#x27;d burn a lot of bridges. reply Verdex 18 hours agorootparentYeah, it&#x27;s not a symmetrical dynamic at all.Leaving without notice is a good way to alienate a lot of contacts that most people will really want to maintain. But even beyond that from what I understand most places have policies in place to prevent employees coming back if they&#x27;ve left without notice.Meanwhile, if my employer fires me without notice and I&#x27;ve got a mortgage, mouths to feed, and&#x2F;or medical bills, then I don&#x27;t really have the leverage to say \"I&#x27;m sorry, by firing me without notice, you are ineligible from asking to rehire me.\" reply codetrotter 18 hours agorootparentprevAt my job they let go of about ~30% of the work force around one year ago. I knew that this theoretically could happen, but this was the first time seeing it myself.And I am left thinking, if in the future I see a coworker leave on the day by his own choice. I wouldn’t hold it against him. The company has shown how easily they are willing to let go of a huge number of people. Why should I be mad at any of my coworkers if they decide to leave on the day? The company already set the bar for how this works. reply SoftTalker 18 hours agorootparentprevThat&#x27;s why it&#x27;s always good to have a few months of essential living expenses in a savings account if you possibly can. More people could do this than actually do it.I&#x27;ve quit without notice once in my career. I already had the next job line up though. reply MBCook 17 hours agorootparentprevRight. I only meant the legality.There are A TON of people people who would probably love to walk in and quit tomorrow if they had another job lined up or the means to go without one for a short while. reply Epa095 18 hours agorootparentprevAnd the health insurance. reply teeray 16 hours agorootparentprevThat’s why they call it FU money. reply dpflug 19 hours agorootparentprev\"Pretty rare unless you do something bad.\"Or there are layoffs. reply MBCook 17 hours agorootparentThat’s fair. I was thinking of when they single out a single person. reply theamk 18 hours agorootparentprev> you can walk into your job and say goodbye forever and never come back.when I was an intern, a person next to me just didn&#x27;t come back one work. And wefound a large-font printout of employment contract with corresponding section highlighted by marker.I still wonder what made him quit, but as an intern I didn&#x27;t talk to to people much and didn&#x27;t care about company politics. reply lostlogin 18 hours agorootparentprev> As an European, I thought that&#x27;s only something people did for movies, I learned not long ago that it&#x27;s actually reality in the USIt’s not quite like this in New Zealand, but wow would an employer be foolish to have an employee leave under a cloud and not immediately block all access.It’s borderline impossible to fire someone here, so it’s not US style lockdown, but cutting access seems basic. reply gumby 19 hours agorootparentprevAt a minimum in the US the company has to pay you for unused vacation days and send you your outstanding pay within 3 days. Also, if you give two weeks notice they might reasonably can you but pay you for the extra two weeks if they are afraid of looking punitive (a smaller company thing — big companies typically don’t worry about being sued for that kind of thing).But not always; my kid resigned from AWS in November and they asked him to work the two weeks, even having him push to prod on the second to last day. reply neuralspark 18 hours agorootparentI&#x27;ve only ever encountered the unused vacation days and outstanding pay by end-of-week in California. It&#x27;s certainly not true in several other states. reply ponector 18 hours agorootparentUnused 7 days of annual PTO. And there are companies with \"unlimited\" vacation which means no unused vacation. reply 20after4 16 hours agorootparentYeah unlimited vacation is nothing more than an excuse to avoid paying for unused vacation time. reply ponector 15 hours agorootparentUnlimited vacation is a marketing bulshit. It is unlimited only if you have really good relationship with your manager.If I have unlimited vacation - I&#x27;ll take 4 weeks every month! reply shagie 18 hours agorootparentprevIt&#x27;s complicated.https:&#x2F;&#x2F;www.helpside.com&#x2F;wp-content&#x2F;uploads&#x2F;2017&#x2F;12&#x2F;Vacation... reply rcxdude 7 hours agorootparentprevIt strongly depends on the circumstances of the firing, but it&#x27;s not uncommon to see &#x27;gardening leave&#x27;: you are technically still employed for an extra month or more, but all your access is revoked and you&#x27;re basically forced to stay home. Generally it&#x27;s a good time to start applying for other jobs. reply herpdyderp 18 hours agorootparentprevKeeping a known-to-be-terminated employee is a huge risk for the employer. People are usually not happy when they lose their jobs which sometimes leads to irrational behaviors (like intentionally sabotaging the no-longer-employer).I&#x27;ve personally been involved on the employer side of such a situation with an irrational person and it&#x27;s a pretty scary deal when you&#x27;re in a small team where each dev has a lot of power. reply chippiewill 17 hours agorootparentprevIt really depends on the job.I think even in Europe it&#x27;s relatively rare to make someone work their notice period if they&#x27;ve been fired due to the risk of retaliation. They just pay them to not work instead. In certain high-risk professions (sales is a big one) you don&#x27;t even work your notice period if you resign. reply whatisyour 17 hours agorootparentprevIt&#x27;s a very different thing between firing an employee immediately and cutting out access. You can still cut out access without firing the employee. And in many case, it could be a wise thing to do. reply justsomehnguy 19 hours agorootparentprevINAPL but I think is what by default both the employee can expect some weeks after the notification (and depending om the circumstances - have an opportunity to move to another job of similar title and&#x2F;or pay in the same company) and employer can expect some weeks if nothing unexpected surface up. But both parties can terminate their relationship in the same dame on a mutual agreement. reply _dain_ 17 hours agorootparentprevI&#x27;ve never met a \"European\" in real life. Frenchmen, Spaniards, Poles, yes, but never a \"European\". They only seem to inhabit internet forums. reply kstrauser 19 hours agoparentprevThe wise will insist that ex-employers do this, if not immediately, then over a very small number of hours. If I&#x27;m to be let go, I want all of my access to go away ASAP. That means they can&#x27;t blame me for things that go missing afterward (minus logic bombs and other kinds of criminality that we do not do, ever, ok?). The last thing I want is for, say, a computer to go missing a week after I left but when I still have an office key, or data to be deleted while I still have AWS access. Take my keys, OK? reply suprjami 20 hours agoparentprevI&#x27;ve always thought such policy heavy handed and unfair. This article proves that&#x27;s not the case. I&#x27;ve heard vague stories of someone doing a malicious delete on the way out, but never seen it myself. reply turtledragonfly 19 hours agorootparentI don&#x27;t think the article proves that. I think these policies can be a bit of a McNamara fallacy[1].When things go wrong, the benefits of aggressive termination are clear. But when things don&#x27;t go wrong (vast majority of time), the alternative&#x27;s benefits are not so clear — employees have more time to hand-off their work, document things that are in their head, better good-will towards the company and its management, etc.So, because one approach has a clear, measurable benefit (avoid some disasters), and the other approach has un-clear hard-to-measure ones, people sometimes dismiss the hard-to-measure side as unimportant. That&#x27;s the fallacy.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;McNamara_fallacy reply AmVess 19 hours agorootparentprevYes. Some people can become very difficult when they&#x27;ve just lost their job. This is the primary reason why firings are done via e-mail so people can flip out and lose their cool at home. reply devmor 19 hours agorootparentprevThings like the occurrence in this article only occur because job termination is so heavy handed here. When people are immediately cut off from their income source without warning, in a society with very little social safety net, they get angry and do drastic things.In many, many other countries, letting someone go is a long process that involves a lot of time for both parties to shore things up and be prepared to move on without incident. reply Johnny555 19 hours agoparentprevThe article doesn&#x27;t say they fired him, it said he&#x27;s an \"ex-employee\". I&#x27;ve stayed on in an hourly role with several companies I&#x27;ve left to be on-call for questions&#x2F;problems for a month or 3 after leaving. reply cortesoft 19 hours agoparentprevIf you are fired, sure, but that usually doesn&#x27;t happen if someone voluntarily leaves. You usually set an end date, and work on transitioning your work during that time. reply SoftTalker 19 hours agorootparentDepends, some places will just pay you to stay home during your notice period and disable all your access and accounts immediately upon you providing your notice. reply johnwalkr 19 hours agoparentprevYou may think so but in IT or especially industries that \"have\" IT but are not IT, who knows what people&#x2F;teams have installed or are using without you knowing. reply aliljet 20 hours agoprevThis is why terminating an employee has to be swift and complete. It&#x27;s just too risky to bet otherwise. reply mytailorisrich 20 hours agoparentNot that complete, hopefully... reply seanw444 19 hours agorootparentUnless you live in the world of Lethal Company. reply teeray 16 hours agorootparentprev“We’re a family in this company… and when you betray the family, there are… consequences…” reply lifestyleguru 19 hours agoprevPlot twist: it was company&#x27;s jenkins and payroll cronjob server. The other \"proper\" CI server was always stuck on some Java+Angular monster pipeline. reply kencausey 20 hours agoprev(2019) reply MOARDONGZPLZ 20 hours agoparentAre raspberry pis in communications closets installed by outgoing employees no longer potential threads five years later? reply scubbo 19 hours agorootparentThat&#x27;s not the implication. It&#x27;s the norm on this site to include the year of an article in the title (if it&#x27;s not from the current year, or very recently in the preceding year if in January). There are _plenty_ of links in the top 100-or-so that follow this pattern - hell, I see one from 1997 in the top 30 right now. They can still be interesting&#x2F;relevant&#x2F;etc. - but it is worthwhile to read them with the knowledge of when they were published, e.g. if you are evaluating technical approaches. reply palemoonale 20 hours agorootparentprevNot if these have been found and removed. reply dmitrygr 19 hours agoprevHard to take the article seriously with so many inaccuracies. I cannot shake the feeling that the writer tried to make more of this than there is by exaggerating.\"almost as powerful as the Rasberry Pi itself: the nRF52832-MDK. A very powerful wifi, bluetooth and RFID reader.\"First of all, the puny little Cortex-M is no where near as powerful as the rPi. Second of all, nRF52 series does not do WiFi, and third of all, RFID will not work without the coil plugged in (which it is not in the picture), and in any case only has a range of an inch at best. reply sylware 19 hours agoprevI have a raspberry PI in my room... but this is my email server, my noscript&#x2F;basic (x)html map server (using OSM tile servers), my web server...:)(next step is RV64 hardware with linux, then this RV64 hardware with an ultra-minimal kernel not using gcc&#x2F;clang compilers). reply born2discover 19 hours agoparentMy apologies for hijacking the thread, but could you please elaborate on your noscript&#x2F;(x)html map setup ?How would one even handle zooming and paning in such a case ? With forms ? reply sylware 19 hours agorootparenthttps:&#x2F;&#x2F;www.rocketgit.com&#x2F;user&#x2F;sylware&#x2F;lnanohtmltiledmapYes, with basic and stupid html forms.Have a look at links web browser. reply fnord77 19 hours agoprevas in most cases like this, the whole thing ended with zero consequences for the perp reply NikkiA 10 hours agoparentI see no sign that that&#x27;s the case, the article ends on:> Legal has taken overWhich would imply there were probably consequences. reply mikelovenotwar 7 hours agorootparentNope https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29965250 reply milliams 20 hours agoprev [–] What I find interesting is the SSH-based comment system (https:&#x2F;&#x2F;blog.haschek.at&#x2F;2023&#x2F;ssh-based-comment-system.html) for their blog. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The writer received a message from their dad containing an image of a Raspberry Pi device found at their workplace.",
      "The device had a powerful microprocessor, wifi and bluetooth capabilities, and was running a paid IOT web service called Resin.",
      "Upon investigation, the writer discovered a configuration file with a username that led them to a person in the same town as the Pi. They also found a heavily obfuscated nodejs app on the device and a file containing wifi credentials which revealed the location where the Pi was set up."
    ],
    "commentSummary": [
      "The collection of discussions and blog posts explores various topics related to company networks, documentation and communication within organizations, IT department challenges, employee termination, and termination procedures in different countries.",
      "Concepts such as \"Shadow IT,\" geolocation services, vacation pay, and power dynamics between employers and employees are also discussed.",
      "The discussions provide insights into the risks and consequences of unauthorized devices in networks and the importance of understanding different systems within an organization."
    ],
    "points": 312,
    "commentCount": 133,
    "retryCount": 0,
    "time": 1704743686
  },
  {
    "id": 38915759,
    "title": "KDE Plasma 5.27 Now Available on OpenBSD: Transition to Qt6 and Future Improvements Planned",
    "originLink": "https://rsadowski.de/posts/2024-01-09-openbsd-kde/",
    "originBody": "rsadowski.de/ Posts/ OpenBSD KDE Plasma Desktop/ OpenBSD KDE Plasma Desktop 7 January 2024·376 words·2 mins· loading · loading · Like Author Rafael Sadowski Shut up and hack Happy New Year, hackers! I started the new year 2024 with a personal milestone of mine. The KDE Plasma 5.27 is available on OpenBSD -current and will be part of the next release 7.5. I’m sure not very many people would understand how large this work. It started so many years ago that I don’t even know how long I’ve been working on it. Definitely years and not just 1 or 2. I remember that before I joined the OpenBSD community, Vadim Zhukov did a lot of work in the Qt/KDE area. In the early days, it was good to have someone to talk to, or just to know “you’re not alone”. This has not been the case for a long time. I’ve been doing it alone for years, just like Vadim did it alone for years. It’s probably the burden of the project, we are a super small team of OpenBSD kernel and ports developers. It should be mentioned that last year kn@ - Klemens Nanni helped with a lot of reviews and thus made it possible that we have KDE as packages. I’m beginning to wonder as I write. What happens now? What happen next? Do I have plans? Sure I could just continue to maintain the whole thing. What will definitely be interesting is the KDE switch from Qt5 to Qt6. This should not be a big challenge for OpenBSD. All dependencies like all Qt6 modules are ported. So this will just be a task of hard work. Here are some thoughts on what we could work on. Fix KWin compositor KDE Wayland NetworkManager (It’s based on glib and GObject. I don’t like it) SDDM - QML based X11 and Wayland display manager - Does that really still make sense? Discover support for pkg_add(1) Perhaps it is normal that after such a big achievement, a period of reflection begins. Let us be surprised what 2024 will bring. OpenBSD KDE Plasma 5.27 Screenshots: Previous Nextsads You can super easy install KDE Plasma and KDE Gear on OpenBSD: Copy # KDE Gear $ pkg_add kde # KDE Plasma $ pkg_add kde-plasma # KDE Plasma extras like power management $ pkg_add kde-plasma-extra A special thanks to all who support my work with a small donation on GitHup. ← → p2k23 - OpenBSD Ports Hackathon Dublin 2023 6 October 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38915759",
    "commentBody": "OpenBSD KDE Plasma DesktopHacker NewspastloginOpenBSD KDE Plasma Desktop (rsadowski.de) 304 points by brynet 22 hours ago| hidepastfavorite127 comments ivan_gammel 21 hours agoThis reminded me of an old meme: https:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;how-does-one-patch-kde2-under... reply sph 20 hours agoparentThis needs its own post. I love that a country&#x27;s president mentioned UNIX in an official address, as well as that #anime IRC channel.EDIT: posted at https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38917307 reply mech422 13 hours agorootparentPersonally, this is my favorite: https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;196&#x2F;comments&#x2F;qgbvah&#x2F;furry_it_sector... reply Apocryphon 21 hours agoparentprevRegional BSD memes, amazing reply rashkov 22 hours agoprevWhat a massive, multi-year effort by one or two individual developers. My utmost respect to this kind of contribution that underpins so much of the software that I use every day reply sho_hn 20 hours agoprevPlasma dev here. Amazing work, this made me smile :-) reply ognarb 19 hours agoparentAlso a KDE dev here and I also love when people port KDE Software to more platforms.Related someone is porting KDE applications to Haiku https:&#x2F;&#x2F;discuss.kde.org&#x2F;t&#x2F;haiku-porting-efforts&#x2F;9032 and someone else is working on gitlab CI&#x2F;CD directly to the Microsoft Store https:&#x2F;&#x2F;blogs.kde.org&#x2F;2023&#x2F;12&#x2F;20&#x2F;gitlab-microsoft-store reply Chanderton 1 hour agorootparentI remember in the early days of Mac OS X when i installed KDE. Was pretty surreal. Then i spent to much time to try create a DarwinBSD distro with KDE. reply unstruktured 19 hours agoparentprevKeep up the good work! I love KDE. reply sho_hn 19 hours agorootparentThanks for using what we make! reply tentacleuno 13 hours agorootparentI&#x27;m very surprised there aren&#x27;t more KDE appreciation posts on here. It&#x27;s such a beautifully round piece of software -- customizable, yet reliable and unassuming.It&#x27;s exactly what the desktop experience, and software in general, should be: there for you when you need it, without making the entire experience about itself.I don&#x27;t have to actively think about my desktop environment when I&#x27;m browsing Hacker News on Firefox, or writing code, or listening to music -- it looks back empathetically when a program goes wrong, or when my workflow changes and it needs tweaking, and everything else.You&#x27;ve made something brilliant, and it&#x27;s definitely positively contributed to Linux&#x27;s increase in market share. reply Ennea 6 hours agorootparentprevThanks for making what I use every single day. reply albertzeyer 18 hours agoparentprevHe said that it took multiple years of work to get this running. I wonder if such effort could be simplified somehow? Maybe from KDE side? reply sho_hn 15 hours agorootparentI&#x27;d love to get an in-depth post-mortem-style experience report from the author on what gave them the most trouble. We regularly invite distribution packagers to give talks at our annual Akademy conference to provide this sort of feedback, I can&#x27;t imagine an OpenBSD talk submission getting turned down! reply rrix2 17 hours agoparentprevhi sho, i hope you&#x27;re well :) reply sho_hn 15 hours agorootparentHeya! Can&#x27;t complain ... :) reply WhackyIdeas 20 hours agoprevFantastic effort! I have such a love for OpenBSD but unfortunately have a system with an Nvidia 4090 which is of course unsupported. Maybe one day I will see if I can dual boot this on my Intel based Mac which has an AMD GPU. reply rubymamis 21 hours agoprevWhat are some pros and cons of using OpenBSD instead of Linux? reply enriquto 20 hours agoparent> What are some pros and cons of using OpenBSD instead of Linux?Pros: htop only fills half of your terminal, and you know exactly what each process does because you put them there. A few well-written man pages are the complete documentation of the system. The whole thing is run by a handful of shell scripts.Cons: exactly the same text, but read with a different tone. reply wharvle 19 hours agorootparentRelaxing. Like back when you could attach WireShark to your local network and not see a single damn thing happen for tens of seconds at a time unless you pressed a button somewhere.... But also when computers wouldn&#x27;t do anything useful unless you pressed a button. Or a bunch of buttons, more likely. reply WhackyIdeas 19 hours agorootparentWhat you describe about WireShark sounds zen. reply randmeerkat 17 hours agorootparent> What you describe about WireShark sounds zen.It was actually ethereal. reply mech422 13 hours agorootparentLOL - made me chuckle reply wharvle 19 hours agorootparentprevIt really was. Just my own machine&#x27;s traffic makes it scroll faster than I can read, these days. Every web page and program constantly phoning home up and and including sending real-time mouse cursor locations, mdns, UDP local-network-device-discovery traffic, all kinds of stuff. reply user3939382 20 hours agorootparentprevYep I love it. ps -ax gives you like 12 processes and the role of each is obvious and essential. The OS isn&#x27;t doing anything you didn&#x27;t ask it to, you can actually understand the OS. Try that on a default Ubuntu install, it&#x27;s like macOS, just totally and literally out of control. reply yeeeloit 19 hours agorootparent> you can actually understand the OS.The way you describe FreeBSD is how I imagine an OS should be. I&#x27;m going to make it a goal this year to get a server up and running. Thanks.-- RantLinux gives me more inferiority complex than any other technology I&#x27;ve ever touched.Sure, something like a database system, or a moderately large code base or framework is complicated, and intimidating, and it might take many years to get a grip on, and understand, let alone master. But Linux? I just don&#x27;t get it. I&#x27;ve tried for years, read books about it, etc. etc.But in the end it&#x27;s voodoo to me, and I&#x27;m always left searching for answers to problems, unable to solve them myself. The answers are always just rote step-by-step; do this and copy this command, problem solved. Why? how? nothing makes sense!!!I always have the sense that somewhere out there is the holy bible of Linux, the missing piece of the puzzle; read this and it will all make sense.Admittedly I&#x27;ve never compiled a distro. So in some respect I&#x27;m guilty of not going into the deep end. I suspect that if I learnt systems programming, and really go into the thick of it... then somewhere I might start to find my feet.But it&#x27;s easier to just believe that I&#x27;m stupid, and Linux is beyond my ability to comprehend. reply exe34 18 hours agorootparentHave you tried LFS? You can copy and paste, but you have to read the commands and figure out what they&#x27;re doing.This will give you an overall theoretical idea of how things are laid out - but you have to realise that every new version of something, there&#x27;s some developer somewhere who wants to exercise their creativity and make something really clever and cool (to them), so it probably won&#x27;t make any sense to you after the upgrade. That&#x27;s the point you realise you&#x27;re on the eternal treadmill of trying to keep your system doing what you need it to do, without freezing in the vulnerabilities. reply cudder 17 hours agorootparentprevI&#x27;d say the Gentoo handbook comes pretty close. You set up everything in the system and all is well explained. Not quite as extreme as LFS but enough to learn and not punish yourself. reply toyg 17 hours agorootparentprev> read this and it will all make sense.Linux is a sprawling metropolis, you have everything and its opposite - a lot of it won&#x27;t make any sense unless you learn who built what, when, and why; and you can have dirty slums right next to well-designed skyscrapers.Trying to find meaning in such a thing is fundamentally a fool&#x27;s errand. reply steve_rambo 10 hours agorootparentprevThe first point equally applies to Alpine and any system built from Debian minimal install (\"built\" is too strong a word, all you need to do is `apt install` several packages). reply cylinder714 9 hours agorootparentThe trick is, figuring out the names of the packages you want. :-\\ Experiment, and take notes, I guess.I had a fun experience playing with `grml-debootstrap&#x27;, GRML¹ being a command-line-oriented LiveCD built upon Debian. Once you’ve booted up, that app installs a minimal Debian instance on your computer. I haven&#x27;t tried using the stock Debian `debootstrap&#x27; utility.1: https:&#x2F;&#x2F;grml.org&#x2F; reply cylinder714 2 hours agorootparentAbout grml-debootstrap:https:&#x2F;&#x2F;grml.org&#x2F;grml-debootstrap&#x2F; reply steve_rambo 5 hours agorootparentprevI meant installing just what you need, like web servers and such. Probably should have written that in the original comment. You need to do that on any other operating system anyway, including any of the BSDs.If you just need a plain system to drop a statically linked binary onto, Debian minimal install is perfectly usable right out of the box, and (IIRC) ships fewer components than OpenBSD. reply technofiend 21 hours agoparentprevIt&#x27;s a legit question, but if you have to ask, then most likely OpenBSD is not for you. I don&#x27;t say that out of some elitist or gatekeeping motive, rather I think most people who use it have a specific need for it, or feel strongly about the principles behind the OS, which are security first and secure-by-default.Here&#x27;s a breakdown of some technical differences between the two, but really if you want to explore alternatives to Linux or even Linux alternatives I highly recommend you do so, even OpenBSD, but I respectfully suggest you have a use case in mind first.https:&#x2F;&#x2F;www.geeksforgeeks.org&#x2F;difference-between-linux-and-o...The security first&#x2F;secure-by-default mindset in OpenBSD means the core distribution is very locked down. By that I mean there&#x27;s very little in the base OS in terms of services. OpenBSD had a robust \"ports\" selection for things you may need to add.My use case for OpenBSD was as a firewall, but it was eventually retired because it just couldn&#x27;t keep up with my network speeds. It still is a secure unix server for things like radius authentication of wireless clients. reply htamas 7 hours agorootparentI respectfully disagree. I have very little Linux&#x2F;Unix&#x2F;xBSD maintenance knowledge, but I started running my own server for my personal email and website. Although I used a script as a crutch to set things up at the beginning (thanks to sive.rs&#x2F;ti), when I started digging in how things work - and when I eventually run into some issues like expired certs - I managed to understand things much faster than when I was trying to run a server before with Ubuntu.For example, Googling things are easier since the tools don&#x27;t change much over the years, so an answer from 10-15 years ago still works. Besides that, I could find most of my answers in the very well written man pages. There&#x27;s also just fewer things happening so there&#x27;s not much clutter to distract me finding the answers I need.I&#x27;m still a beginner of course, but I feel like OpenBSD is good for any application where you need to run something and then \"forget about it\" - be it a server or maybe even a \"kiosk\"&#x2F;informational screen. reply dbolgheroni 21 hours agorootparentprevJust a minor note that you don&#x27;t need a 3rd-party http daemon since there is one in base.https:&#x2F;&#x2F;man.openbsd.org&#x2F;httpd reply technofiend 20 hours agorootparentThank you, I stand corrected: it&#x27;s been a while and my faulty memory had httpd outside of core. I edited my upline comment to remove the erroneous example because I don&#x27;t want to add noise. reply binkHN 16 hours agorootparentprev> My use case for OpenBSD was as a firewall, but it was eventually retired because it just couldn&#x27;t keep up with my network speeds.Are you doing over 10Gbps? A lot has been done in this space. reply technofiend 11 hours agorootparentBased on someone else&#x27;s comment I plan to revisit OpenBSD, because previously I wasn&#x27;t able to get gigabit speeds out of a low-end appliance, even though FreeBSD and Fedora both could. reply binkHN 11 hours agorootparentThings have definitely improved over time, but some of the best improvements are also related to utilizing advanced functionality from hardware that supports it. reply Apocryphon 21 hours agorootparentprevWhat&#x27;s the most casual user-friendly distro of *BSD out there? GhostBSD? reply somat 18 hours agorootparentI would suggest openbsd. it is not user friendly in the \"hide all complexity from the user\" sense but more like \"this system is simple enough to understand yet full featured enough to work in\".The way I like to explain it is. if you like the unix operating environment, It is hard to do better than openbsd for a desktop system. If you are expecting something more like a mac or windows environment, there are options, but I suspect you would be better off with linux(or mac or windows for that matter).Openbsd is comfortable in a way that is hard to explain. While largely this is just what what a person is used to. with obsd I have a good feel on how it works and goes together. something I never really felt with linux. however you do lose a lot of the network effect advantages that linux has. reply artsi0m 4 hours agorootparentprevOpenBSD is in fact already pretty much user-friendly. Installer is simple, althought an a textual interface. It comes with preinstalled X server and window managers fvwm and cwm. In the installer you can choose Xenodm to start automatically after boot, it would be your display manager and you can just simply login through it to fvwm. From here you can edit .xsession and choose any window manager you installed or pre-installed cwm. reply DeathArrow 8 hours agorootparentprevYou can try ravynOS or helloSystem. They are FreeBSD distros made with desktop users and ease of use in mind. reply zilti 20 hours agorootparentprevThey&#x27;re derivatives with their own kernel each, so in that regard the question does not make much sense. Due to its large amount of binary packages though, I&#x27;d say FreeBSD it is out of the big three. reply Apocryphon 20 hours agorootparentJust trying to identify what&#x27;s the Mint&#x2F;Ubuntu&#x2F;Zorin&#x2F;elementary OS equivalent of BSD in terms of ease of use. reply taylortbb 20 hours agorootparentThe point is that they&#x27;re not really comparable. Mint&#x2F;Ubuntu&#x2F;etc all ship the same Linux kernel, that&#x27;s why they&#x27;re called distros. They&#x27;re different distributions (distros) of the same software (Linux kernel, etc).The different BSDs aren&#x27;t distros, they are different kernels that are developed in parallel. Obviously there&#x27;s shared history there, and some shared userspace, but FreeBSD and OpenBSD aren&#x27;t just two different BSD distros of largely the same software. reply parker_mountain 19 hours agorootparentprevI&#x27;d say that if you&#x27;re trying to find the Mint&#x2F;Ubuntu&#x2F;Zorin&#x2F;elementary of BSD, then it&#x27;s not really for you. The BSD ecosystem isn&#x27;t really driven by ease of use, today they&#x27;re more interested in various niches - hardware appliances, OS research, etc.If you&#x27;re curious about what unix is and what a bsd is, I would recommend netbsd or openbsd in a vm. reply Apocryphon 19 hours agorootparentWell of course they&#x27;re not trying to replace macOS, for instance, but when an OS gets big enough to have offshoots and different front-ends and desktop environments and so forth, one would assume there are at least experimental attempts emphasizing ease of use, just like there are experiments to develop offshoots for any other purpose, from power users to pen testers. At least like, someone&#x27;s toy project on GitHub or SourceForge. I just assumed BSD was big and well-established enough to have such efforts.Besides GhostBSD, looks like there&#x27;s also Lumina, MidnightBSD, FuryBSD, and TrueOS&#x2F;Project Trident?https:&#x2F;&#x2F;lumina-desktop.orghttp:&#x2F;&#x2F;www.midnightbsd.orghttps:&#x2F;&#x2F;distrowatch.com&#x2F;table.php?distribution=furybsdhttps:&#x2F;&#x2F;itsfoss.com&#x2F;trueos-bsd-review&#x2F; reply parker_mountain 10 hours agorootparent> experimental attempts emphasizing ease of useyes, i would define them very much as experimental reply stonogo 18 hours agorootparentprevThey&#x27;re definitely trying to replace MacOS: https:&#x2F;&#x2F;hellosystem.github.io&#x2F;docs&#x2F; reply fullstop 15 hours agorootparentprevI installed NetBSD in a VM last week, and it felt like I was using Linux from 20 years ago. reply miah_ 14 hours agorootparentIs that a bad thing? reply fullstop 14 hours agorootparentFor some things I felt a bit nostalgic, but for other things, not so much.It was a neat experience and worth doing. reply zilti 20 hours agorootparentprevProbably still FreeBSD, even though I&#x27;d claim NetBSD&#x27;s documentation is a tad better. (And Ubuntu really does not stand out as beginner-friendly compared to e.g. openSUSE) reply spookie 14 hours agorootparentopenSUSE is a gem.I can&#x27;t even fathom how many times I&#x27;ve made a mess from my impulses to tidy up my system and it just manages to \"fix itself\".There are also a lot of neat things, like being able to use multiple versions of GCC side by side. Not every distro behaves well on that regard. reply CodeCompost 19 hours agorootparentprevWould it be fair to say the Arch Linux users will feel right at home with FreeBSD? They seem to have similar concepts. reply hnlmorg 16 hours agorootparentPre-systemd Arch felt very much like another BSD. At least about as close to one as a Linux could.These days it’s a lot more Linux-y though. reply antiframe 18 hours agorootparentprev> What&#x27;s the most casual user-friendly distro of *BSD out there? GhostBSD?MacOS? reply Y_Y 17 hours agorootparentYmmv, but I found macos might be friendly to the user, but only because it&#x27;s getting to get money out of them. User-(bad)friendly. reply kuon 21 hours agorootparentprevI stil use OpenBSD as firewall as I love PF. But I have the same problem as it cannot easily firewall 10G link. I am curious, what did you migrate to? reply technofiend 21 hours agorootparentI keep switching things around. Virtualization comes with its own limits but is a fast way to prototype things like &#x27;how hard is it to get IPV6 PDUs working in this new os?&#x27;Pfsense is ok, but CE went a year without an update while they worked on other branches. Most recently their switch to kea dhcp broke some minor things like mapping static DHCP addresses to DNS entries. I believe that&#x27;s fixed now, but need to confirm you can also still specify a DHCP option which some network devices need.Opnsense is also decent and has the advantage of a regular update cadence, but I believe the UI is less newbie friendly. Fedora has the advantage of a UI to let you quickly review firewall rules, although the cli is perfectly workable once you get the syntax down.Honestly I like OpenBSD&#x27;s pf too but it couldn&#x27;t keep up with a one gigabit network connection on your typical AliExpress firewall appliance, and I couldn&#x27;t get it there virtually on an HP 360 Gen 8 or Gen 9 with decent Xeon CPUs and network cards. Probably a limitation of the network drivers for the network cards emulated by ESXi. I resisted being nerd sniped by that because my wife needs reliable Internet so there was no time to putter.What are you using that lets OpenBSD achieve better than gigabit speeds?tl;dr: For now I&#x27;m using PFSense because I have a friend I supply with tech support and he uses whatever I use and it&#x27;s safe for him to play around in PFSense on his own. reply rubymamis 21 hours agorootparentprevCompared to a Linux distro, would an end user have much better security out-of-the box, or would one need to be tech-savvy enough for that? reply opencl 21 hours agorootparentOpenBSD out of the box is an extremely minimal setup compared to the default install of most Linux distros.A lot of the security of the default install comes from minimizing the attack surface by having very few services running. So you do not need to be tech-savvy to make it secure, but you might need to be tech-savvy to turn it into a usable system for your use case. reply somat 13 hours agorootparentOpenBSD out of the box is not minimal. As a base install it is more feature full than most linux base installs. It is small yes, but with a lot of high quality network focused services. I could easily run a company backend and network on only what is found in the base install. If I had a good solid group of people I could probably run the frontend on it. (the main thing it lacks is a web browser).mail, web, routing, tunnels, bgp, dns, hell there is even an ldap server in there for some reason. but no ldap client, which kind of sucks. reply seanw444 19 hours agorootparentprevTo add: it&#x27;s not just the fact that it&#x27;s barely running anything that makes it secure, but the things that you do run have effort put into making their codebase secure as well. Such as the various daemons, like httpd. reply miah_ 14 hours agorootparentprevAlso, the code for OpenBSD has been audited for \"common\" security issues, and hardened against various attack types.https:&#x2F;&#x2F;www.openbsd.org&#x2F;security.html reply sneed_chucker 20 hours agoparentprevPros: lightweight, really good docs, security as a design goal, designed from the top down as a complete OS so the userland generally all plays nice together and feels more coherent and less bloated than a typical Linux distroCons: hardware compatibility&#x2F;drivers (especially for WiFi and GPU) is worse than Linux, finding help online is worse than Linux, software availability and compatibility tends to be worse than Linux, but generally you can get everything you need especially if you&#x27;re willing to build from source.Subjective: Lots of Linuxisms that people are used to having aren&#x27;t present on BSD. For example, no docker, no systemd, no Snap&#x2F;AppImage&#x2F;Flatpak, and no eBPF. This is true even on FreeBSD, which is the most Linux-like of the family. BSDs have their own answers to most of the problems that these tools solve, but you&#x27;ll have to learn those tools and your Linux knowledge and muscle memory will be mostly useless. reply Pay08 15 hours agorootparentSince when is an init system or Docker linuxisms? reply sneed_chucker 15 hours agorootparentAn init system isn&#x27;t a Linuxism obviously. Systemd is though.Docker is unambiguously a Linuxism. Docker on MacOS and Windows only works by running a lightweight Linux VM under the hood. Docker does not currently run on any of the BSDs, though you can achieve similar process isolation with jails. reply artsi0m 3 hours agoparentprevIt somehow happens that OpenBSD feels like an whole operating system rather than Linux distro built from various components. For example, when pledge(2) and unveil(2) appeared, many user-space programms got patched as soon as possible. You can see simillar process now, after pinsyscall(2) appeared and syscall(2) was removed.I heard, that there is something simillar in FreeBSD with zstd compression.For me cons is that you can&#x27;t run some programms that depends on Linux kernel insides, like rr debugger, which depends on some specific of linux ptrace(2): https:&#x2F;&#x2F;github.com&#x2F;rr-debugger&#x2F;rr?tab=readme-ov-file#system-... reply radiator 21 hours agoparentprevPro: A website can never steal your SSH keys, because firefox is limited, via unveil(2), to only seeing your ~&#x2F;Downloads folder.Con: Every time you need to upload a file using your browser, you have to move it to this folder first. reply elric 21 hours agorootparentYou can do similar things in Linux with firejail, but there are a lot of folks who feel uneasy about the safety of firejail. reply radiator 21 hours agorootparentBesides firefox, more than 80 userland programs have their access to the filesystem restricted with the use of unveil. reply PrimeMcFly 19 hours agorootparentIf Theo stopped being so resistant to solutions like AppArmor, then OpenBSD could have a real security layer instead of toys like unveil and pledge. reply thewanderer1983 15 hours agorootparentHere is Justine&#x27;s write up on pledge and why he wants to port it to Linux. https:&#x2F;&#x2F;justine.lol&#x2F;pledge&#x2F; reply PrimeMcFly 15 hours agorootparentIt has its uses I guess, but it requires opt-in which is a pretty big disadvantage, and then still can&#x27;t do even a fraction of what SELinux can already do. SELinux isn&#x27;t that hard to learn, and the security benefits are immense. reply okasaki 18 hours agorootparentprevnext [–]2024-01-08 22:34 ubuntu@knope:~$ sudo apparmor_status apparmor module is loaded. 185 profiles are loaded. 104 profiles are in enforce mode. (...) 124 processes have profiles defined. 122 processes are in enforce mode.including firefox and chromium reply artsi0m 4 hours agorootparentBut apparmor is more complex system and in fact is an RBAC. unveil(2) is much more easier in implementation and enforcing. reply bayindirh 21 hours agorootparentprevAlso, there&#x27;s AppArmor which is enabled in Debian and SuSE which transparently limits applications&#x27; reach without they realize. reply belthesar 20 hours agorootparentTransparent limitation is a double-edged sword. From an adversarial perspective, it&#x27;s good since I&#x27;m not advertising what my system can and can&#x27;t do, and poorly written software may get hung up on timeouts waiting for things to happen. On the other hand, those same benefits against an adversary are negative constraints to usability, as now silent failures can happen on a system, requiring you to watch your AppArmor logs like a hawk when using new software.Ultimately, less of a concern for servers that likely have limited scope and use cases, but a significant decrease in usability for workstations. reply bayindirh 20 hours agorootparentYou need to write an AppArmor profile to limit your software. It’s an opt-in system.The workflow is you put a test system to “complain” mode and use your software as intended, and add the required permissions to the profile by looking at the logs to see what your app is doing. Then you put AppArmor to enforcing mode, add the profile to production system and your application is sandboxed. Iteratively refine as necessary.Debian desktop comes with AppArmor enabled. Nothing has been broken so far. reply mike_hock 19 hours agorootparentAnd every time you upgrade to the next major release, you start again from square one because the requirements of your software have changed. You get it to work and things seem to be fine. Over time, you start noticing things that are subtly broken, until something just fails completely and doesn&#x27;t work. The fix turns out to be trivial when you give it another go two days later, but at the time it happened you really didn&#x27;t have the nerve to deal with it right then.After two dist upgrades, you realize that this approach isn&#x27;t workable. reply bayindirh 18 hours agorootparentWell, I have two Debian desktop installations. One is six, the other one is ten years old. I never had a problem with either.This is without adding the numerous servers which I just install and forget, and they work without any problems for years.edit: Yes, they&#x27;re dist-upgraded all the time. reply PrimeMcFly 19 hours agorootparentprev> And every time you upgrade to the next major release, you start again from square one because the requirements of your software have changed.Nah. That&#x27;s a huge exaggeration. Most software doesn&#x27;t change its base behavior like that and certainly not with every new release, and certainly browsers don&#x27;t. replyartsi0m 4 hours agorootparentprevYou can edit &#x2F;etc&#x2F;firefox&#x2F;unveil.main and add string like \"~&#x2F;Documents rwx\" so it would be available from firefox reply codedokode 20 hours agorootparentprevUnveil looks like a hack or a patch. Why do applications have access to whole filesystem by default? reply bayindirh 19 hours agorootparentBecause there&#x27;s already UNIX file permissions which prevent applications to reach places they shouldn&#x27;t. Confine a daemon to its own user, chroot it, and it&#x27;s a sitting duck in its own universe.You add more layers with cgroup&#x2F;AppArmor&#x2F;SELinux in Linux, Jails in FreeBSD, unveil on OpenBSD, etc.You harden as much as necessary. Not \"drowned by default\". reply mike_hock 18 hours agorootparent> Because there&#x27;s already UNIX file permissions which prevent applications to reach places they shouldn&#x27;tRight. Just set up a separate user for Firefox using a single unprivileged command from your user account or a few clicks in your DE, then launch Firefox as that user using another single command or click. Being subordinate to your main user account, the Firefox user&#x27;s files and directories can easily be managed from your main user and you can move files between subordinate users using just an (unprivileged) chown or chgrp. Accidentally launching applications as your main user is not possible and the system strongly encourages you to create separate, subordinate users for all your applications and is designed from the ground up to make this simple and it works out of the box.Oh wait, that&#x27;s not even remotely how any of this works. On a workstation, the \"user account\" is an almost completely useless concept (as set up and implemented in reality). That&#x27;s why we have jails&#x2F;namespaces&#x2F;etc. Hacks that are piled on top of the useless mess of \"user accounts\" (all running as the same user, on workstations) trying to solve the same problems, but ultimately failing at providing any kind of comprehensive solution with a coherent vision. Software cannot take anything for granted anymore. Anything that looks like a writable file could be a read-only bind mount. Any mundane syscall could get it SIGKILLed for no reason other than that somebody forgot to add it to the whitelist. But from the user&#x27;s perspective, there&#x27;s no reasonable level of security by default. reply bayindirh 18 hours agorootparentConsidering how we use jails&#x2F;namespaces and other similar technology, your analogy sounds off. First of all, security is always set up in layers. A different user and chroot doesn&#x27;t exclude the use of jails, or other kernel level security systems like AppArmor&#x2F;SELinux. They are layered on top of each other as necessary.Also, namespaces is not solely a security mechanism. Yes it allows isolation, but it allows resource limitation, too. So you can partition your system to slices and show a particular set of resources to an application (I&#x27;m sure you&#x27;re way more knowledgeable than me in that regard).On the other hand, security starts with application itself. Then you start to add extra containment barriers if you don&#x27;t trust the software in question.What I understand is our realities are completely disparate, and this is not how we hold the mechanisms I talk about. This might be due to the environment each of us live in, or due to our requirements, I don&#x27;t know.But, what I know is, the state of security is not as bleak as you portray, and necessity is mother of invention. Except SELinux, AppArmor, and FireJail all of the technologies we talk here are essentially built as virtualization, or virtualization-like technologies. They bring additional security as a secondary effect, and they&#x27;re good at that.> Software cannot take anything for granted anymore.This is why we have stat calls, defensive programming, APIs and exception handling. The first rule of system programming is to never take anything for granted.I have reached to the end of the time I have for today,Have a nice day and a nice year. reply radiator 19 hours agorootparentprevI guess it has always been like this in Unix, but also in other Operating Systems. reply Am4TIfIsER0ppos 20 hours agorootparentprev\"To upload a file move it to your downloads directory\" lmaoCan you \"unveil\" more places, without recompiling? reply SoftTalker 20 hours agorootparentYes, configurable in &#x2F;etc&#x2F;firefox&#x2F;unveil.main reply codetrotter 20 hours agorootparentprevIt would have cost them nothing to unveil a hypothetical ~&#x2F;Uploads directory in the process of patching it to unveil ~&#x2F;Downloads reply radiator 8 hours agorootparentWith what purpose? Why do you want two different directories? On second thought, maybe you mean ~&#x2F;Uploads could be unveiled read-only, though I still don&#x27;t believe this brings much. reply amatecha 19 hours agorootparentprevYou can trivially-easily add it yourself by editing a text file, unveil is configurable per-process. reply codetrotter 18 hours agorootparentTrue, but defaults are worth a million replyikmckenz 11 hours agoparentprevPros: Secure-by-default, easy to understand your whole system, pledge and unveil are developer-friendly hardening mechanisms, all the answers to your questions are in the (very good) documentationCons: all the answers to your questions are in the documentation, and not in stack overflow. reply PrimeMcFly 19 hours agoparentprevPros: More of the software has been audited. That&#x27;s it really. There&#x27;s nice documentation but that&#x27;s true for many linux distros as well, and much of the security claims are overblown.Cons: Lack of available software and software compatibility. Lack of good security options to restrict software and the system. reply LanzVonL 19 hours agoparentprevnext [4 more] [flagged] yeeeloit 18 hours agorootparent> Indians and Chinese had teamed up to backdoor it.link? reply Pay08 15 hours agorootparentI&#x27;m guessing his own diseased mind. reply MCUmaster 9 hours agorootparentThe only disease here is you and yours.https:&#x2F;&#x2F;cse.umn.edu&#x2F;cs&#x2F;linux-incident reply hospitalJail 21 hours agoparentprevYou join the social club of people who say \"Its not Linux!\"I even had chatgpt try to come up with valid reasons and it struggled. reply codetrotter 20 hours agorootparentEither you are prompting it wrong, or you got unlucky, or you are stuck on GPT3.5 still and it’s less capable compared to GPT4 than I remember.Me:> Give me a short list of five top things that OpenBSD is superior over Linux forChatGPT:> OpenBSD is known for its strong emphasis on security, simplicity, and code correctness. Here&#x27;s a brief list of five aspects where OpenBSD is often considered superior to Linux:> 1. Security by Default: OpenBSD is renowned for its security-oriented design. The system is configured with secure defaults, and security features are integrated directly into the core system, not as add-ons.> 2. Code Quality and Audit: The OpenBSD project places a high priority on clean, readable, and well-documented code. Regular code audits are conducted to identify and fix security vulnerabilities and bugs.> 3. Integrated Cryptography: OpenBSD includes various cryptographic tools and libraries as part of its base system, making it easier to implement secure applications.> 4. Pf (Packet Filter): OpenBSD&#x27;s native firewall, pf, is highly regarded for its flexibility and efficiency. It&#x27;s often considered more straightforward and powerful than iptables, commonly used in Linux.> 5. Documentation and Man Pages: OpenBSD’s documentation, especially its man pages, is extensive and well-maintained. It provides detailed and up-to-date information on system commands, configurations, and daemons.> It&#x27;s important to note that while OpenBSD excels in these areas, the choice between OpenBSD and Linux depends on specific use cases and personal preferences.And then for the cons, flip the question around and ask ChatGPT for a list of five ways in which Linux is superior over OpenBSD. (Left as an exercise for the reader.) reply zilti 20 hours ago[flagged]| rootparentprevIf you are the kind of person who uses ChatGPT for such questions, you wouldn&#x27;t understand it anyway reply gigatexal 17 hours agoprevThe last time I spun up KDE was about two weeks ago on my Fedora 39 system. The tiling was awesome. Coming from i3 and sway it’s pretty good. Not quite keyboard powered everything — maybe it is I’m just a noob — but it was soooo resource heavy. Akonadi was doing too much. And too many things were using compute on my GPU. I went back to sway. reply foresto 19 hours agoprev> A special thanks to all who support my work with a small donation on GitHup.I was hoping the GitHup link was a play on words that would lead to an interesting unix-related project. Alas, it&#x27;s just a typo. Maybe next time. :) reply LAC-Tech 18 hours agoprevLove the man pages, love doas (I use it on my main linux machine), love that it has an HTTP server in the main install. But the filesystem is so basic that people recommend a UPS just so your data doesn&#x27;t get corrupted during a power outage.I hope OpenBSD gets some corporate love one day, because that&#x27;s probably the only way you&#x27;re going to get a modern file system written for it. reply Pay08 15 hours agoparentI tried using doas but I don&#x27;t get it. On the one hand there&#x27;s some inertia with everything on Linux expecting sudo, on the other, the claims about speed, simplicity and simpler configuration rang pretty hollow to me. Especially since I believe doas can&#x27;t do things like custom logging. reply binkHN 13 hours agorootparentIf I recall correctly, the main reason for its existence was due to the recurring security issues with sudo. doas was designed to be a more simple tool with a smaller attack surface. reply LAC-Tech 13 hours agorootparentprevTBH I mainly just like it because the configuration file is a single line. It also never even occured to me for sudo or doas to log anything, so there&#x27;s that.Also, I don&#x27;t have sudo installed at all on my system, and everything seems to work fine with doas. YMMV. reply jmprspret 14 hours agoparentprevRe: fs: Yeah it&#x27;s lacking. But I&#x27;ve never ever had any corruption issues whatsoever running it on (virtual) servers or my laptop for years. reply Erratic6576 22 hours agoprevAlso for arm? reply brynet 19 hours agoparentThe kde-plasma and kde-plasma-extras packages are available in -current aarch64 packages, perhaps you can test it? reply Erratic6576 10 hours agorootparentI’m looking forward to trying it reply pmarreck 20 hours agoprevmeanwhile I swap window managers with a single-line config change on NixOS reply sintax 18 hours agoparentafter googling for 8 hours because the last time you had to do that change was 6 months ago and you forgot all about it. At least, that was my experience. reply rollcat 4 hours agoparentprevInteresting that you bring this up; pkgs&#x2F;desktops&#x2F;plasma-5 in nixpkgs is 3300 LOC (not including helper&#x2F;library code); x11&#x2F;kde-plasma in the ports tree is 1260 LOC. I don&#x27;t think either effort was trivial. reply shmerl 22 hours agoprev [–] What&#x27;s the state of Wayland on *BSDs? reply doublepg23 21 hours agoparentSome notes here on OpenBSD https:&#x2F;&#x2F;xenocara.org&#x2F;Wayland_on_OpenBSD.html reply pimeys 22 hours agoparentprevWorks pretty well on FreeBSD. I think not yet on OpenBSD. reply brynet 21 hours agorootparentThere is experimental support for Wayland&#x2F;sway in OpenBSD -current, with lots of recent ports activity.https:&#x2F;&#x2F;marc.info&#x2F;?l=openbsd-misc&m=170176226313427&w=2 reply LanzVonL 19 hours agoparentprev [–] People have it working OK but it&#x27;ll never be part of the base system. reply bitwize 9 hours agorootparent [–] The BSDs need a Wayland story quick because X is going bye-bye. GNOME and then KDE will probably remove their X code paths before the decade is out. reply NackerHughes 5 hours agorootparent> X is going bye-byeThis has been the &#x27;Wayland story&#x27; for 15 years now. reply ben_bai 5 hours agorootparentprevHAHA, Xorg will always be with us. GNOME and KDE will maybe do something like that, but that&#x27;s no problem. reply LanzVonL 3 hours agorootparentprev [–] X isn&#x27;t going bye-bye. Heck the current \"maintainers,\" who are trying to kill it, don&#x27;t even do anything but merge code given to them by other people.You&#x27;ll never win. At best you can kill it from Red Shat. I find the snarky, hubristic nature of Wayland boosters to be insufferable. Whole thing&#x27;s a huge dumpster fire too. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "KDE Plasma 5.27 is now available on OpenBSD -current and will be included in the next release 7.5.",
      "Development of KDE Plasma for OpenBSD has been a long and independent journey, with some help from other developers.",
      "Future plans include transitioning from Qt5 to Qt6 and potential improvements to various components such as KWin compositor, KDE Wayland, NetworkManager, SDDM, and Discover support."
    ],
    "commentSummary": [
      "The article and comment thread explore the OpenBSD KDE Plasma Desktop and the advantages and disadvantages of using OpenBSD compared to Linux.",
      "The discussion covers topics such as user-friendliness, limitations of different BSD distributions, security features of OpenBSD, and the use of namespaces for security and resource limitation.",
      "The conversation also touches on the state of Wayland on BSD operating systems and the criticism of Xorg."
    ],
    "points": 304,
    "commentCount": 127,
    "retryCount": 0,
    "time": 1704737244
  },
  {
    "id": 38915775,
    "title": "Unlocking the Secrets: Mario Maker 2 API Reveals New Game Insights",
    "originLink": "https://tgrcode.com/posts/mario_maker_2_api",
    "originBody": "TheGreatRambler GitHubTwitterPatreonContact Mario Maker 2 API Created Thursday, Feb 10, 2022 DocumentationGitHub Mario Maker 2 is a game I've played for years, since launch, and I've always been interested in putting my skills in programming to the test here. I've finally done just that. Using the incredible NintendoClients made by Kinnay, I, and individuals from the Ninji Speedrunning discord, 0% discord, and Kinnay himself, we now have an entirely free and public way of accessing data previously only available to the switch itself. Background Nintendo Switch Online games tend to use a specific library with a specific protocol to communicate with Nintendo's servers. Since the WiiU, this protocol has been NEX. NEX, partially due to the incredible success of many of the games using it like Mario Kart 8 and Splatoon 2, has been extensively documented, to the point where it is fully possible to spoof both the client and server. The Pretendo project has been working on a WiiU NEX server for years, and alongside it NintendoClients, a NEX client, has been becoming more stable and safe to run on your personal account. In October 2021 I finally took the plunge and started using NintendoClients for a dream I had years prior: to make all Mario Maker 2 data easily accessible to computers. After watching the project for years, debating whether to purchase a digital copy of the game and put my Switch certificate on the line, Tatiaus, a talented kaizo player, contacted me about using the API for the 0% team as I had mentioned it in passing earlier. Once I realized there was interest past my own goals I bought the game and began working. On the 13th, I released the first build, publicly available with no login required. First release to a small group of Switch modders Word gets out First, the Ninji server used it to round out their leaderboards, making them 100% accurate for the first time ever. The features I considered most important, the level_info and level_data endpoints, went unused. Not many people outside the Ninji Speedrunning discord knew this existed. Slowly, the API got around, but it stayed a novelty. One of the funniest misconceptions I saw was the guess that my switch was running 24/7 and downloading levels for me. The truth is that this was running on a linux server, using a complete recreation of the NEX client. No switch was involved, except for the various credentials the NEX protocol needs to authenticate with the server. Interest peaks In November a kaizo player well known for performing incredibly difficult \"trump jumps\", jumps in the game which were pixel perfect, came to me about using the API for a level viewer he had designed. In time Ji Xiaomai released his viewer, and that was the spark that ignited the entire community. Suddenly now anyone could view any level without the game and even without a switch. Tricky levels that were only possible due to information only the creator could know were exposed. Suddenly now no level could hide secrets. After the release of this viewer, I ported it to C++ and made it portable enough to run in the browser, so now it wasn't even neccesary to download the app to your PC. With time came new incredible viewers, including one that had animated textures. The count of level viewers was now 5, including the continuation of an old level viewer by streamer and programmer Shoujo and one made from the ground up by Ingram. The community had collectively come together to tear the game apart, utterly destroying the roughly 1 level viewer made for the first game. And in another impressive effort, almost every field of every endpoint was determined, so now stats previously thought impossible to obtain, like the boos on a level or the k/d ratio of a player, were accessible. All this hype has generated an impressive amount of traffic as well: Web traffic after release Archival Through all this, the API has stayed public and free. Information should always be as accessible as possible and designed to be as easy to parse as possible by people and computers alike. While I am putting my personal Nintendo Switch Online account on the line, this tool is invaluable to research about the game. So I can proudly say, while Youtube made dislikes private, we made Mario Maker 2 dislikes public. The logical conclusion to this venture is to pull as much data as we can. So I did the only reasonable thing, went out and bought a 14 terabyte hard drive in order to download Mario Maker 2's entire database. Now it might seem impossible to simply download everything, we can request up to 300 random levels at a time through endpoints like search_endless_mode, but statistically we will recieve less and less unique items over time, almost guaranteed to take years to download 100% of available levels. Nintendo, however, made this easy for us: def course_id_to_dataid(id):course_id = id[::-1]charset = \"0123456789BCDFGHJKLMNPQRSTVWXY\"number = 0for char in course_id: number = number * 30 + charset.index(char)left_side = numberleft_side = left_side > 14number = number ^ 0b00010110100000001110000001111100return number Course ids are constructed from a regular algorithm from a consistent incrementing index called a data_id. Internally these ids are used to request many known levels, like a list of your own uploaded levels. Because these data ids increment regularly and we know both the first data id, 3 million, and the last through a call to search_new, we can download every uploaded level by sweeping through all 31 million data ids currently allocated. Because users follow similar rules, downloading every user account is also possible. Running a python program for 4 straight weeks to generate a 2 terabyte database may seem foolish to most, but I'm not putting this perfectly good PC to waste by turning it off. Instead, I did it, ran my computer for all of those 4 weeks, and the resulting data will be a goldmine into how players interact with levels and each other. The resulting database CREATE TABLE level ( data_id INTEGER, -- Data IDs are regularly incrementing values, gaps in the table are due to levels deleted by users or Nintendo name TEXT, -- Course name description TEXT, -- Course description uploaded INTEGER, -- UTC timestamp for when the level was uploaded course_id TEXT, -- Course ID as seen in game gamestyle INTEGER, -- Gamestyle, enum below theme INTEGER, -- Theme, enum below difficulty INTEGER, -- Difficulty, enum below tag1 INTEGER, -- The first tag, if it exists, enum below tag2 INTEGER, -- The second tag, if it exists, enum below world_record INTEGER, -- The world record in milliseconds upload_time INTEGER, -- The upload time in milliseconds num_comments INTEGER, -- Number of comments, may not reflect the archived comments if there were more than 1000 comments clear_condition INTEGER, -- Clear condition, enum below clear_condition_magnitude INTEGER, -- If applicable, the magnitude of the clear condition clears INTEGER, -- Course clears attempts INTEGER, -- Course attempts clear_rate REAL, -- Course clear rate as a float between 0 and 1 plays INTEGER, -- Course plays, or \"footprints\" versus_matches INTEGER, -- Course versus matches coop_matches INTEGER, -- Course coop matches likes INTEGER, -- Course likes boos INTEGER, -- Course boos unique_players_and_versus INTEGER, -- All unique players that have ever played this level, including the number of versus matches weekly_likes INTEGER, -- The weekly likes on this course weekly_plays INTEGER, -- The weekly plays on this course one_screen_thumbnail BLOB, -- The one screen course thumbnail, as a JPEG binary one_screen_thumbnail_url TEXT, -- The old URL of this thumbnail one_screen_thumbnail_size INTEGER, -- The filesize of this thumbnail one_screen_thumbnail_filename TEXT, -- The filename of this thumbnail entire_thumbnail BLOB, -- The entire course thumbnail, as a JPEG binary entire_thumbnail_url TEXT, -- The old URL of this thumbnail entire_thumbnail_size INTEGER, -- The filesize of this thumbnail entire_thumbnail_filename TEXT, -- The filename of this thumbnail uploader_pid TEXT, -- The player ID of the uploader first_completer_pid TEXT, -- The player ID of the user who first cleared this course record_holder_pid TEXT, -- The player ID of the user who held the world record at time of archival level_data BLOB, -- The GZIP compressed decrypted level data, kaitai struct file is provided to read the header unk2 INTEGER, -- Unknown unk3 BLOB, -- Unknown unk9 INTEGER, -- Unknown unk10 INTEGER, -- Unknown unk11 INTEGER, -- Unknown unk12 INTEGER -- Unknown ); CREATE TABLE user ( pid TEXT, -- The player ID of this user, an unsigned 64 bit integer as a string data_id INTEGER, -- The data ID of this user, while not used internally user codes are generated using this code TEXT, -- User code region INTEGER, -- User region, enum below name TEXT, -- User name country TEXT, -- User country as a 2 letter code last_active INTEGER, -- UTC timestamp of when this user was last active, not known what constitutes active mii_data BLOB, -- The CHARINFO blob of this user's mii mii_image TEXT, -- An image of this mii as reported by Nintendo's debug endpoint mii_studio_code TEXT, -- The mii studio code of this user pose INTEGER, -- Pose, enum below hat INTEGER, -- Hat, enum below shirt INTEGER, -- Shirt, enum below pants INTEGER, -- Pants, enum below wearing_outfit INTEGER, -- Whether this user is wearing pants courses_played INTEGER, -- How many courses this user has played courses_cleared INTEGER, -- How many courses this user has cleared courses_attempted INTEGER, -- How many courses this user has attempted courses_deaths INTEGER, -- How many times this user has died likes INTEGER, -- How many likes this user has recieved maker_points INTEGER, -- Maker points easy_highscore INTEGER, -- Easy highscore normal_highscore INTEGER, -- Normal highscore expert_highscore INTEGER, -- Expert highscore super_expert_highscore INTEGER, -- Super expert high score versus_rating INTEGER, -- Versus rating versus_rank INTEGER, -- Versus rank, enum below versus_won INTEGER, -- How many courses this user has won in versus versus_lost INTEGER, -- How many courses this user has lost in versus versus_win_streak INTEGER, -- Versus win streak versus_lose_streak INTEGER, -- Versus lose streak versus_plays INTEGER, -- Versus plays versus_disconnected INTEGER, -- Times user has disconnected in versus coop_clears INTEGER, -- Coop clears coop_plays INTEGER, -- Coop plays recent_performance INTEGER, -- Unknown variable relating to versus performance versus_kills INTEGER, -- Kills in versus, unknown what activities constitute a kill versus_killed_by_others INTEGER, -- Deaths in versus from other users, unknown what activities constitute a death multiplayer_unk13 INTEGER, -- Unknown, relating to multiplayer multiplayer_unk14 INTEGER, -- Unknown, relating to multiplayer first_clears INTEGER, -- First clears world_records INTEGER, -- World records unique_super_world_clears INTEGER, -- Super world clears uploaded_levels INTEGER, -- Number of uploaded levels maximum_uploaded_levels INTEGER, -- Maximum number of levels this user may upload weekly_maker_points INTEGER, -- Weekly maker points last_uploaded_level INTEGER, -- UTC timestamp of when this user last uploaded a level is_nintendo_employee INTEGER, -- Whether this user is an official Nintendo account comments_enabled INTEGER, -- Whether this user has comments enabled on their levels tags_enabled INTEGER, -- Whether this user has tags enabled on their levels super_world_id TEXT, -- The ID of this user's super world, blank if they do not have one unk3 INTEGER, -- Unknown unk12 INTEGER, -- Unknown unk16 INTEGER -- Unknown ); CREATE TABLE user_badges ( pid TEXT, -- Player ID type INTEGER, -- The kind of badge, enum below rank INTEGER -- The rank of badge, enum below ); CREATE TABLE level_comments ( data_id INTEGER, -- The data ID of the level this comment corresponds to comment_id TEXT, -- Comment ID type INTEGER, -- Type of comment, enum below pid TEXT, -- Player ID of the comment creator posted INTEGER, -- UTC timestamp of when this comment was created clear_required INTEGER, -- Whether this comment requires a clear to view text TEXT, -- If the comment type is text, the text of the comment reaction_image_id INTEGER, -- If this comment is a reaction image, the id of the reaction image, enum below custom_image BLOB, -- If this comment is a custom drawing, the custom drawing as a PNG binary custom_image_url TEXT, -- If this comment is a custom drawing, the old url of the drawing custom_image_size INTEGER, -- If this comment is a custom drawing, the filesize of the drawing in its old format custom_image_filename TEXT, -- If this comment is a custom drawing, the filename of the drawing has_beaten INTEGER, -- Whether the user had beaten the level when they created the comment x INTEGER, -- The X position of the comment in game y INTEGER, -- The Y position of the comment in game reaction_face INTEGER, -- The reaction the mii of the user has on this comment unk8 INTEGER, -- Unknown unk10 INTEGER, -- Unknown unk12 INTEGER, -- Unknown unk14 BLOB, -- Unknown unk17 INTEGER -- Unknown ); CREATE TABLE level_played ( data_id INTEGER, -- The data ID of the level this play corresponds to pid TEXT, -- The player ID of the user who made this play cleared INTEGER, -- Whether the user cleared the level liked INTEGER -- Whether the user liked the level ); CREATE TABLE level_deaths ( data_id INTEGER, -- The data ID of the level this death corresponds to x INTEGER, -- The X position of where this death occured y INTEGER, -- The Y position of where this death occured is_subworld INTEGER -- Whether this death occured in the subworld ); CREATE TABLE world ( pid TEXT, -- The player ID of the user who created this super world world_id TEXT, -- World ID worlds INTEGER, -- Number of worlds levels INTEGER, -- Number of levels planet_type INTEGER, -- Planet type, enum below created INTEGER, -- UTC timestamp of when this super world was created unk1 BLOB, -- Unknown unk5 INTEGER, -- Unknown unk6 INTEGER, -- Unknown unk7 INTEGER, -- Unknown thumbnail BLOB, -- The thumbnail, as a JPEG binary thumbnail_url TEXT, -- The old URL of this thumbnail thumbnail_size INTEGER, -- The filesize of this thumbnail thumbnail_filename TEXT -- The filename of this thumbnail ); CREATE TABLE world_levels ( pid TEXT, -- The player ID of the user who created the super world with this level data_id INTEGER, -- The data ID of the level ninjis INTEGER -- Number of ninjis shown on this level ); CREATE TABLE user_posted ( pid TEXT, -- The player ID of the user who posted this data_id INTEGER -- The data ID of the level ); CREATE TABLE user_liked ( pid TEXT, -- The player ID of the user who liked this data_id INTEGER -- The data ID of the level ); CREATE TABLE user_played ( pid TEXT, -- The player ID of the user who played this data_id INTEGER -- The data ID of the level ); CREATE TABLE user_first_cleared ( pid TEXT, -- The player ID of the user who first cleared this data_id INTEGER -- The data ID of the level ); CREATE TABLE user_world_record ( pid TEXT, -- The player ID of the user who got world record on this data_id INTEGER -- The data ID of the level ); CREATE TABLE ninji ( data_id INTEGER, -- The data ID of the level this ninji played on pid TEXT, -- The player ID of the user who made this ninji time INTEGER, -- The time of this ninji in milliseconds replay BLOB, -- The replay binary of this ninji replay_url TEXT, -- The old url of this ninji replay_size INTEGER, -- The filesize of this ninji replay_filename TEXT -- The filename of this ninji ); CREATE TABLE ninji_level ( data_id INTEGER, -- The data ID of this ninji level name TEXT, -- Name description TEXT, -- Description uploaded INTEGER, -- UTC timestamp of when this was uploaded ended INTEGER, -- UTC timestamp of when this event ended gamestyle INTEGER, -- Gamestyle, enum below theme INTEGER, -- Theme, enum below medal_time INTEGER, -- Time to get a medal in milliseconds clear_condition INTEGER, -- Clear condition, enum below clear_condition_magnitude INTEGER, -- If applicable, the magnitude of the clear condition unk3_0 INTEGER, -- Unknown unk3_1 INTEGER, -- Unknown unk3_2 INTEGER, -- Unknown unk5 INTEGER, -- Unknown unk6 INTEGER, -- Unknown unk9 INTEGER, -- Unknown level_data BLOB, -- The GZIP compressed decrypted level data, a kaitai struct file is provided to read this one_screen_thumbnail BLOB, -- The one screen course thumbnail, as a JPEG binary one_screen_thumbnail_url TEXT, -- The old URL of this thumbnail one_screen_thumbnail_size INTEGER, -- The filesize of this thumbnail one_screen_thumbnail_filename TEXT, -- The filename of this thumbnail entire_thumbnail BLOB, -- The entire course thumbnail, as a JPEG binary entire_thumbnail_url TEXT, -- The old URL of this thumbnail entire_thumbnail_size INTEGER, -- The filesize of this thumbnail entire_thumbnail_filename TEXT -- The filename of this thumbnail ); CREATE INDEX idx_level_data_id ON level (data_id); CREATE INDEX idx_level_comments_data_id ON level_comments (data_id); CREATE INDEX idx_level_deaths_data_id ON level_deaths (data_id); CREATE INDEX idx_level_played_data_id ON level_played (data_id); CREATE INDEX idx_ninji_data_id ON ninji (data_id); CREATE INDEX idx_user_pid ON user (pid); CREATE INDEX idx_user_badges_pid ON user_badges (pid); CREATE INDEX idx_user_first_cleared_pid ON user_first_cleared (pid); CREATE INDEX idx_user_liked_pid ON user_liked (pid); CREATE INDEX idx_user_played_pid ON user_played (pid); CREATE INDEX idx_user_posted_pid ON user_posted (pid); CREATE INDEX idx_user_world_record_pid ON user_world_record (pid); CREATE INDEX idx_world_pid ON world (pid); CREATE INDEX idx_world_levels_pid ON world_levels (pid); In an update post I'll cover the data analysis I do on this massive archive, and release it publicly. Make sure to look out for that!",
    "commentLink": "https://news.ycombinator.com/item?id=38915775",
    "commentBody": "Mario Maker 2 APIHacker NewspastloginMario Maker 2 API (tgrcode.com) 263 points by soap- 22 hours ago| hidepastfavorite60 comments rikthevik 21 hours agoLinking to Lunar Magic, the community&#x27;s Super Mario World editor that likely spurred Nintendo to create Mario Maker in the first place.https:&#x2F;&#x2F;fusoya.eludevisibility.org&#x2F;lm&#x2F;Also, go check out the Grand Poo World III videos. Absolutely peak Mario. reply pimeys 19 hours agoparentThe whole release of Grand Poo World III was one of the best things happening in the Internet last year. The chaos that broke smwcentral, how it beat Super Mario RPG in viewers on Twitch for quite a many days and how much fun every streamer seemed to have with it.I can&#x27;t get past the first jump though, but still, thank you barb! reply vga805 13 hours agorootparentAgreed, it was a blast to watch people tackle it. In addition to what you mentioned, I&#x27;d include Barb&#x27;s Lunar Magic streams. They were super chill and it was some of my favorite content of the year, getting to watch him in his creative process working on the hack. reply pimeys 7 hours agorootparentFor sure. And those kaizo block&#x2F;fish snipes that barb uses so masterfully. Good stuff. reply WesSouza 17 hours agorootparentprevI wish I had the skills. reply bradbeam 21 hours agoparentprevAgree, been super fun to watch everyone work through GPW 3. The clip compilations are always fun https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DOpt3DU-16I reply epiccoleman 20 hours agorootparentThe bits where streamers faces show up in the levels are hilarious reply germandiago 20 hours agorootparentprevLololol! I laughed so much watching this. Amazing. The design of that level is the mind of a f*cker. Lol! reply airstrike 21 hours agorootparentprevLMFAO that video is the gift that keeps on giving... I lost my shit at the shark towards the end reply city41 20 hours agoparentprevI made a web based level editor that I was hoping would fill in gaps I perceived in Mario Maker: https:&#x2F;&#x2F;smaghetti.com&#x2F; I no longer work on it and never really filled those gaps, but it was a fun time nonetheless. reply vga805 13 hours agoparentprevBarb (creator of Grand Poo World 3) is my favorite level designer and surely one of the best... But I would say peak Mario might have been the 2022 GDQ Super Mario World romhack race. Some of the stuff in that is truly mind boggling.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UdMR0uMA_2Q reply have_faith 6 hours agoparentprevI spent a lot of time with Super Mario Flash back in the day, has great level editor, you can share levels by copy and pasting a level definition: https:&#x2F;&#x2F;funkypotato.com&#x2F;super-mario-flash&#x2F; reply animal_spirits 20 hours agoparentprevI loved playing with this when I was in high school. This is such a great memory. Thanks! reply CSMastermind 12 hours agoparentprevIs Lunar Magic open source? reply woqe 9 hours agorootparentNo, and it has the single-maintainer problem (buses, lottery, etc.). The tool has a high learning curve and hidden&#x2F;unexplained features that you have to read years-old forum posts to use correctly. Lunar magic is great, but there is tons of room for improvement. There has been at least one attempt to solve this problem, though progress has been slow: https:&#x2F;&#x2F;github.com&#x2F;SMW-Editor&#x2F;smw-editor. reply grose 22 hours agoprevArchive: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240108181325&#x2F;https:&#x2F;&#x2F;tgrcode.c...Followup post: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230811134158&#x2F;https:&#x2F;&#x2F;tgrcode.c... reply WesSouza 16 hours agoparentMore and more hacker news needs a way to pin these kinds of comments due to servers getting overwhelmed. reply mattl 14 hours agorootparentOr just a link for everything at the top which loads from internet archive. It would also help stuff get archived. reply crtasm 12 hours agorootparentSounds like a job for a userscript, or the IA browser extension. reply mattl 57 minutes agorootparentI think it would benefit everyone replynsxwolf 22 hours agoprevI liked the idea of these games and own the 3DS game and 2 on the Switch. I like making levels, but for the most part I haven’t had a lot of fun playing other people’s levels.I gave up on the games because it seemed like most of the user submitted content were weird non playable machines where people bend the rules of the engine to hurl Mario along to the goal automatically.Interesting to see that, but it got to the point where I saw nothing else, and it’s been on the shelf for years. reply GlickWick 21 hours agoparentI still maintain that the Mario Maker series could be absolutely brilliant if Nintendo would invest in better discovery algorithms and searchability. The pool is going to be flooded with garbage, and rightfully so given that kids love to play and make things too. There&#x27;s nothing wrong with that, but in the end it means you&#x27;ve fallen into a tough situation where the internal discovery tools don&#x27;t work, and the only way for a level to be \"discovered\" is for an influencer to find it.I doubt you can ever build a perfect fix for this, but it could be a lot better than it is right now. Unfortunately it&#x27;s just an abandoned project at this point, and the inevitable Mario Maker 3 will likely just have the same issues. reply physicles 21 hours agorootparentIt&#x27;s not a full solution, but there must be lists of good levels out there on the internet. I just found https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;TraditionalMarioMaker&#x2F;.For me, couch multiplayer would make it 10x better. I bought the game and was sorely disappointed to see that this wasn&#x27;t included. reply cubefox 12 hours agorootparentprevActually people on social media sites like Twitter solve a similar discoverability issue by following interesting people. Subscribing to interesting level creators inside the game reduces the problem to finding these creators. reply robrtsql 21 hours agoparentprevSame—unfortunately most of the content that other players produce is either impossible to lose or is specifically designed to be as hard as possible. You can still find levels which are suitable for your skill level, but the “10 mario mode” or whatever is specifically built around selecting the next level FOR you, so that entire game mode is basically a waste. reply wesleychen 21 hours agoparentprevIf you filter levels by a higher difficulty you can get some that require you to actually play. reply rtpg 15 hours agoparentprevKinda weird, I&#x27;ve found that Mario Maker 2, if you queue up on the next-to-hardest difficulty, is basically good? I&#x27;ve encountered plenty of \"top quartile of SMW\" difficulty levels.There&#x27;s some garbage in there too, but that&#x27;s the game! There&#x27;s definitely good sets of levels nowadays IMO. reply nosrepa 17 hours agoparentprevDumbDog&#x27;s levels in Mario maker 2 are fantastic if you like fair but hard levels. reply andrewingram 19 hours agoprevA few years ago I built a level viewer based on this API: https:&#x2F;&#x2F;www.smm2-viewer.com&#x2F;Was quite a fun challenge, some interesting tech at play, and interesting algorithm work to render out the slope tiles. reply declan_roberts 14 hours agoparentYou built this? Well done! I’ve used this several times while watching DGR videos! reply andrewingram 6 hours agorootparentThanks!The original inspiration was a DGR video in late 2021 when he showed the original chinese-language windows-based level viewer. That inspired me (as a Mac user) to seek out the API and level format documentation, then it was a whole load of trial and error to get the rendering working. There are more popular viewers (AFAICT) out there, but I enjoyed the challenge. reply crtasm 12 hours agoparentprevHuge appreciation for both this and the API.I wonder if the API is still running off the developer&#x27;s personal Nintendo account? reply agmater 22 hours agoprevHaving a busy animated background is an awful idea if you want people to read your content. reply tasoeur 9 hours agoparentAnd sadly the reader mode on iOS is also having some trouble :&#x2F; reply amlib 7 hours agoprevI really appreciate this work, thanks to it I was able to recover all my levels I had made for mm2 before I sold my switch years ago. I didn&#x27;t have any level codes, all I had was a screenshot with one of the level names, so I had to filter the whole dataset by level name and luckily that level popped in there (I was afraid Nintendo would have deleted my stuff since my account was inactive for so long...). Then I was also able to get my uploader id from that single level record, which allowed me to filter all other levels I had made. You guys made my day :) reply chilipepperhott 21 hours agoprevWayback machine link: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240108181325&#x2F;https:&#x2F;&#x2F;tgrcode.c... reply noqc 22 hours agoprevit sure would be nice to get the repository of mario maker 1 levels before nintendo burns the library down. reply Y_Y 21 hours agoparenthttps:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;super_mario_maker_courses_202105Typical archive.org to the rescue again. reply echelon 21 hours agorootparentMario is one my favorite platforming series, but I felt that the Mario Maker games never quite reached the level of innovation of LittleBigPlanet. (Both in the tooling and the community.)It looks like some users did the work to archive LittleBigPlanet, too:https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;@littlebigarchiveHopefully it&#x27;s comprehensive.People came up with all kinds of hacks to push the engine to its limits. They made FPS games, top down Zelda dungeons, and all kinds of crazy stuff with LBP. It was awesome.I haven&#x27;t checked out LBP&#x27;s spiritual successor Dreams yet (I don&#x27;t have time to game lately), but I&#x27;ve heard it&#x27;s phenomenal.That said, I do enjoy watching others try to clear some of the diabolically difficult levels that Mario Maker creators design. reply cubefox 11 hours agorootparentI looked into Dreams a while ago. Dreams is more a general game engine than a level editor, including a highly unusual rendering engine that is not based on polygons. But apparently all this innovation hasn&#x27;t translated in much success. reply nothis 22 hours agoparentprevI know Nintendo will never allow it to exist in the open but is this a way to archive the actual levels or just a list of names&#x2F;codes? I&#x27;m genuinely sad thinking about the (very real) possibility of them vanishing forever. reply soap- 21 hours agorootparentThere&#x27;s a dataset on huggingface[0] from this API that has the data, and a decoder on github[1][0] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230811134158&#x2F;https:&#x2F;&#x2F;tgrcode.c... [1] https:&#x2F;&#x2F;github.com&#x2F;JiXiaomai&#x2F;SMM2LevelViewer reply Amigo5862 20 hours agorootparentprevIt includes the levels themselves. However, there&#x27;s not any current way to play them. https:&#x2F;&#x2F;pretendo.network&#x2F; is working on it. reply hospitalJail 21 hours agorootparentprevJust move on. I&#x27;ve realized that Nintendo finds a way to make me suffer in disappointment.Gaming got a lot better when I ripped the Nintendo bandaid off. (And I stopped buying games that are less than 1 year old) reply gjsman-1000 22 hours agorootparentprevMost likely Nintendo (being an extensive AWS user) will just ship the levels to some S3 bucket; never to see the light of day. Even if each level were just 2 MB, that would cost them only $46&#x2F;mo. to keep 1 million levels. reply lofatdairy 21 hours agoparentprevI think pretendo kinda does this? Someone who&#x27;s more familiar should probably confirm&#x2F;give caveats but I believe at the very least there are tools to pull down courses + metadata, but I don&#x27;t known whether a public repository has been established. reply cowsup 22 hours agoparentprevThis already exists online — won&#x27;t link it here but it&#x27;s easy to find if you know where to search. Players have been unable to upload since March 2021, so any archive that&#x27;s a year or two old will still be up-to-date. reply carterschonwald 17 hours agoprevHere’s the hugging face datasets that have some of this data https:&#x2F;&#x2F;huggingface.co&#x2F;TheGreatRambler reply cameronrohani 20 hours agoprevThis is so cool hope to play around with it tonight. I converted the API to a OAS&#x2F;swagger file and temporarily hosted them here to play around with while the site is hugged to death https:&#x2F;&#x2F;mariomaker2api.apidocumentation.com&#x2F; reply reflectiv 22 hours agoprev...and its been hugged to death in minutes. reply barelyauser 22 hours agoparentHow many connections per minute can result from being on HN frontpage? reply pelagicAustral 21 hours agorootparentI had an app on the frontpage for a whole day last year (Show HN) and the server behaved like a champ... a simple 6US&#x2F;month, cloud compute instance on Vultr. It was a Rails app as well.I generally dont understand how some sites go down so quick. reply bagels 21 hours agorootparentHow much traffic was it? reply pelagicAustral 6 hours agorootparent20 GB over 24 hours. reply minimaxir 21 hours agorootparentprevFor an unprepared server, a lot. reply Arbortheus 16 hours agoparentprevNginx 1.18.0 too, oof reply paweladamczuk 9 hours agoprevI find it puzzling that stuff like this is allowed to continue while Nintendo tries to remove gameplay videos on Youtube.I&#x27;m glad people do it. Just curious about the legal considerations. reply Wizulus 9 hours agoparentI think its a combination of A: they don&#x27;t know which credentials are being used; B: While figuring it out would be somewhat trivial, it still requires effort to set up tracking for it; and C: We&#x27;re not doing anything nefarious with it, challenging Nintendo&#x27;s intellectual property, committing piracy, or using it to upload illegal content. As a reminder, Nintendo does not own the copyright on the courses uploaded to its servers. The creators do. By using SMM2, they grant Nintendo a non-exclusive license to use their courses in the game. Non-exclusive reply ChrisArchitect 21 hours agoprev(2022) reply za3faran 16 hours agoprev [–]Size: 1.45MB zipped, 3.10MB unzipped Minimum OS: Win95 (Win98SE if you want to use DirectX 9 option) Version: 3.40 Updated: September 24, 2023.:)) replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author has created an API that enables users to access data from Mario Maker 2 without the game or Nintendo Switch.",
      "The API provides access to a database containing tables with attributes related to user profiles and game interactions.",
      "Tables have been created for super worlds, user activities, ninjis, and ninji levels.",
      "The author plans to share their analysis of the database in a future update."
    ],
    "commentSummary": [
      "The discussion focuses on Mario Maker 2 and its community's engagement with Lunar Magic and Grand Poo World III.",
      "Users share their experiences and favorite moments with the game, while some discuss the limitations of Lunar Magic and suggest improvements.",
      "The thread also highlights the need for better discovery algorithms and searchability for user-created levels, as well as discussions on filtering levels by difficulty and archiving levels in Mario Maker and other games."
    ],
    "points": 263,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1704737310
  },
  {
    "id": 38916663,
    "title": "Golden Rules of Interface Design: Enhancing Users' Productivity and Control",
    "originLink": "https://www.cs.umd.edu/~ben/goldenrules.html",
    "originBody": "Ben Shneiderman Home About Contributions Projects Previous Projects Publications Essays Books Videos Lectures Presentations Photos Links The Eight Golden Rules of Interface Design I have often been asked to distill the vast corpus of user interface design into a few key principles. While I was reluctant to do this, it turned out to be a good exercise to write “Golden Rules,” that are applicable in most interactive systems. These principles, derived from experience and refined over three decades, require validation and tuning for specific design domains. No list such as this can be complete, but even the original list from 1985, has been well received as a useful guide to students and designers. Jakob Nielsen, Jeff Johnson, and others have expanded these rules and included their variations, which enriches the discussion. Each edition of the book produces some changes. This version is from Section 3.3.4 of the Sixth edition: Shneiderman, B., Plaisant, C., Cohen, M., Jacobs, S., and Elmqvist, N., Designing the User Interface: Strategies for Effective Human-Computer Interaction: Sixth Edition, Pearson (May 2016) http://www.cs.umd.edu/hcil/DTUI6 1. Strive for consistency. Consistent sequences of actions should be required in similar situations; identical terminology should be used in prompts, menus, and help screens; and consistent color, layout, capitalization, fonts, and so on, should be employed throughout. Exceptions, such as required confirmation of the delete command or no echoing of passwords, should be comprehensible and limited in number 2. Seek universal usability. Recognize the needs of diverse users and design for plasticity, facilitating transformation of content. Novice to expert differences, age ranges, disabilities, international variations, and technological diversity each enrich the spectrum of requirements that guides design. Adding features for novices, such as explanations, and features for experts, such as shortcuts and faster pacing, enriches the interface design and improves perceived quality. 3. Offer informative feedback. For every user action, there should be an interface feedback. For frequent and minor actions, the response can be modest, whereas for infrequent and major actions, the response should be more substantial. Visual presentation of the objects of interest provides a convenient environment for showing changes explicitly (see the discussion of direct manipulation in Chapter 7). 4. Design dialogs to yield closure. Sequences of actions should be organized into groups with a beginning, middle, and end. Informative feedback at the completion of a group of actions gives users the satisfaction of accomplishment, a sense of relief, a signal to drop contingency plans from their minds, and an indicator to prepare for the next group of actions. For example, e-commerce websites move users from selecting products to the checkout, ending with a clear confirmation page that completes the transaction. 5. Prevent errors. As much as possible, design the interface so that users cannot make serious errors; for example, gray out menu items that are not appropriate and do not allow alphabetic characters in numeric entry fields (Section 3.3.5). If users make an error, the interface should offer simple, constructive, and specific instructions for recovery. For example, users should not have to retype an entire name-address form if they enter an invalid zip code but rather should be guided to repair only the faulty part. Erroneous actions should leave the interface state unchanged, or the interface should give instructions about restoring the state. 6. Permit easy reversal of actions. As much as possible, actions should be reversible. This feature relieves anxiety, since users know that errors can be undone, and encourages exploration of unfamiliar options. The units of reversibility may be a single action, a data-entry task, or a complete group of actions, such as entry of a name-address block. 7. Keep users in control. Experienced users strongly desire the sense that they are in charge of the interface and that the interface responds to their actions. They don’t want surprises or changes in familiar behavior, and they are annoyed by tedious data-entry sequences, difficulty in obtaining necessary information, and inability to produce their desired result. 8. Reduce short-term memory load. Humans’ limited capacity for information processing in short-term memory (the rule of thumb is that people can remember “seven plus or minus two chunks” of information) requires that designers avoid interfaces in which users must remember information from one display and then use that information on another display. It means that cellphones should not require reentry of phone numbers, website locations should remain visible, and lengthy forms should be compacted to fit a single display. These underlying principles must be interpreted, refined, and extended for each environment. They have their limitations, but they provide a good starting point for mobile, desktop, and web designers. The principles presented in the ensuing sections focus on increasing users’ productivity by providing simplified data-entry procedures, comprehensible displays, and rapid informative feedback to increase feelings of competence, mastery, and control over the system. A. V. Williams Building, Department of Computer Science University of Maryland,College Park, MD 20742 Phone: (301) 405-2680 Fax: (301) 405-6707 ben@cs.umd.edu Follow Ben on Twitter: @benbendc",
    "commentLink": "https://news.ycombinator.com/item?id=38916663",
    "commentBody": "Golden Rules of Interface Design (2013)Hacker NewspastloginGolden Rules of Interface Design (2013) (umd.edu) 259 points by luu 19 hours ago| hidepastfavorite126 comments nyreed 9 minutes agoOne golden rule that I learned is that interface elements should not move unexpectedly after the interface has been drawn. Google is particularly bad for buttons which move between you lifting your thumb and pressing the screen, but they&#x27;re not alone. reply jetrink 1 minute agoparentI wish this would be addressed at the OS level. If a target popped into existence less than ~0.25 seconds before it was touched, a touch event shouldn&#x27;t be generated. Humans reaction times aren&#x27;t fast enough to hit a button that quickly anyway. reply bithive123 16 hours agoprevAlthough not really part of a UI&#x27;s \"design\", performance is often overlooked as well. A poorly performing UI violates every single one of these design rules. My sony android smart TV looks amazing but the UI is so slow as to be unusable.An unstable UI that is always changing also violates most of these principles. Smart TVs seem to be exceptionally bad in this area too, with the home screen layout and app icons frequently changing positions for no apparent reason.While I&#x27;m complaining, my other pet peeve, which unfortunately is only getting worse is: unlabeled icons (often without even tooltips). If I have to google for documentation to know what a button is called, your UI design is bad! reply godzillabrennus 16 hours agoparentEver since Snapchat exploded in popularity I’ve decided bad UI is a gen z feature. They flock to difficult to use interfaces that become an insider feature for young folks to keep their parents out. reply weinzierl 2 hours agorootparentOne could say the same thing about the command line and software like vim being made to keep the youngsters out. reply pprotas 8 hours agorootparentprevInteresting, after reading your comment I&#x27;ve decided bad UI is subjective. I&#x27;m gen z, and never found Snapchat&#x27;s UI to be confusing, and none of my gen z friends have ever complained about it, either.> They flock to difficult to use interfaces that become an insider feature for young folks to keep their parents out.This part might be true on a subconscious level (or it might be part of Snapchat&#x27;s design philosophy), but do you think younger generations really choose apps for this reason on purpose? reply beowulfey 4 hours agorootparentBad UI is just one that breaks the patterns we&#x27;re used to. If you&#x27;re young and learning fresh patterns it doesn&#x27;t matter as much reply asoneth 1 hour agorootparentEvery interface convention was novel at some point. Breaking them doesn&#x27;t necessarily make a UI bad, just as following them doesn&#x27;t make it good. It depends on your skill as well as your audience, their expectations, and how experienced they are with the current interface patterns.But certainly the vast majority of products should not create new or novel interface patterns just as they shouldn&#x27;t \"roll their own\" cryptography -- it is almost always unnecessary and unless it is your primary focus it is very likely that what you come up with will be significantly worse than the status quo. reply threethree 14 hours agorootparentprevVery interesting. Yeah I think bad UI could be a way to gatekeep. 4chan for example has its mostly-unchanged now old-school interface, with its own quote&#x2F;reply system, which some call an IQ barrier. That plus all the lingo. It typically gives out outsiders (journalists, govt agents, new users etc) reply bheadmaster 8 hours agorootparent> 4chan for example has its mostly-unchanged now old-school interface, with its own quote&#x2F;reply system, which some call an IQ barrierI doubt it would be an IQ barrier, considering the apparent intelligence of many of the posters there. I would rather call it a \"normie filter\" - the UI is so old-school (\"ugly\") that \"normies\", who usually dwell on fancy UI sites like Facebook, Reddit, etc., will consider it lame and avoid it.I also think this site employs the same filter, whether intentionally or not. reply 98789992165 10 minutes agorootparent4chan - smart people acting dumbHN - dumb people acting smart reply staunton 5 hours agorootparentprev> I also think this site employs the same filter, whether intentionally or not.Definitely intentional. reply busymom0 15 hours agorootparentprevI think this has been observed by others too:> Snapchat’s UI Receives Backlash From Users for being too complicated. However, Snapchat’s user experience is not bad. It’s actually an incredibly smart design. Their challenging user experience is what keeps them relevant to their primary target audience: teenagers and millennials.> It keeps the adults out..Snapchat is a safe place for teens. They intentionally made the user interface challenging to grasp in order to make it difficult for adults to use. Most adults would not bother putting up the effort to learn how to use the app, leading to its abandonment. All content is ephemeral with strict limitations on editing. Most content is sent privately, and no content can be publicly rated or compared. Adults would not bother putting up the effort to learn how to use the app, leading to its abandonment. This limits Snapchat’s user base to teenagers.https:&#x2F;&#x2F;uxmag.com&#x2F;articles&#x2F;how-snapchat-and-netflix-break-ux... reply thworp 7 hours agorootparentprevI think it&#x27;s all just decreasing neural plasticity and having more routine you need to break. reply weinzierl 2 hours agoparentprev\"unlabeled icons (often without even tooltips)\"The worst software I worked with in this regard was CATIA V5. It had not only hundreds of little icons in the UI, but they were also used in the documentation. The manual regularly said things like \"Todo X first click [], then [] and finally go to [] to do [].\"This is from the very first versions of V5, so many years ago, and hopefully has improved. reply albert_e 1 hour agorootparent> ... first versions of V5So \"V5\" is not \"version five\" of something?God. reply mortenjorck 15 hours agoparentprevPerformance is part of design! The best designers will have conversations with developers about the performance implications of the UI they’re proposing, and will help negotiate trade-offs as engineering makes user-facing technical decisions. reply esafak 13 hours agoparentprevHardware companies aren&#x27;t known for their UX chops. reply rubidium 4 hours agorootparentUX started with hardware, it was just called human factors. And most of what they came up with then gets forgotten today. reply throwaway2037 6 hours agorootparentprevIf you strictly mean pure software for \"UX\", then I agree. However, for electronics from the 80s and 90s, Japanese audio&#x2F;visual hardware (especially Sony) was amazing for UX design. Albeit, the screen was limited to a small LED screen, but the combination of buttons and menus was impressively designed. reply graypegg 18 hours agoprevA designer I worked with years ago had a great explanation for why consistency is important.It’s not about a limited colour palette or a careful selection of fonts no one will ever notice. Chasing the specifics makes horrible software. Some people equate less diversity in their UI to more consistency.It’s about letting someone become an expert in your software.Microsoft office was always his example. People pride themselves on “knowing” Microsoft office. They jump between all of the apps because they have a feel for the inertia of “office”. I have the exact same feeling in Vim. I just know how things are expected to be, and new (well made) plugins tend to respect those patterns.Office and (Neo)Vim aren’t exceptional examples of UI, but they are uniquely stable. reply xp84 17 hours agoparentAs a non-\"Designer\" something I never shut up about is how powerful it is to bootstrap that expertness by leveraging the UI elements and concepts your users already know from elsewhere, for instance, literal native UI widgets, and more broadly, highly-recognizable simple fundamental widget types. When you have the opportunity to present 4 options, you could use your brand&#x27;s themed version of [Insert UI Library]&#x27;s searchable combobox with checkable items, or you could show 4 normal labeled radio buttons or checkboxes. The latter beats the former in every way:1. User knows whether they can pick one vs many based on the circles vs squares.2. User can see all four options, even if the widget ends up unfortunately placed in the viewport (I&#x27;ve had to scroll inside these and only be able to see like 2 options at once, so many times).3. No issues with mobile keyboard wanting to open to let you \"search\", further obstructing the tiny viewport.4. Accessibility will always be 100%.Yet this option \"fails\" in the category of \"looks cute with our Design System\" so usually designers choose the first choice, and worse, \"standardize\" on doing that, so that using normal widgets is a \"bug.\"Ultimately too many \"UX designers\" are hacks, who worship and pursue aesthetics and branding at the expense of everything else. A UI widget isn&#x27;t the time or place to assert your brand or creativity, any more than you should design your own font that forces all letters to be shapes from your logo. Your customers don&#x27;t care about your brand more than being able to complete their tasks. reply hutzlibu 9 hours agorootparent\"you could use your brand&#x27;s themed version of [Insert UI Library]&#x27;s searchable combobox with checkable items, or you could show 4 normal labeled radio buttons or checkboxes. \"Ahhh ... that&#x27;s likely a Stilbruch (break of style) my design professor would have exclaimed. Designers hate those and I came to understand why and try to avoid it wherever possible. It is something that can be irritating and bringing in confusion, if suddenly there is a element out of place.But you can have \"highly-recognizable simple fundamental widget types\" without breaking the style. It is just harder and of course, a functional ugly design is in my opinion still way better than a good looking broken design. But the goal should be something consistent - in terms of functionality and style. reply DonHopkins 15 hours agorootparentprevnext [1 more] I had an interesting discussion on Twitter with Michael Darius about this very topic recently. He is an \"Apple pioneer, skeuomorph & protégé of Steve Jobs\" who epitomizes the excesses of aesthetics and branding at the expense of everything else, so I had to call him on his brash claim and ask him some pointed questions, and brought up the User Interface Hall of Shame&#x27;s review of the QuickTime 4.0 player, as an example of the excesses of skeuomorphism.https:&#x2F;&#x2F;twitter.com&#x2F;darius&#x2F;status&#x2F;1741188955985604867Michael Darius @darius 9:06 PM · Dec 30, 2023 22.1K Views:There is just no reason why an interface should be anything but beautiful.Don Hopkins @xardox:Tell that to an airplane pilot who takes the lives of their passengers in their hands every day. Are you really saying that airplane cockpits should be beautiful, at the expense of safe and usable and accessible?Michael Darius:Beauty for the sake of beauty is a mistake but beauty for the sake of user enjoyment reduces cognitive dissonance. Don&#x27;t forget that pilots are people too with emotional needs.Don Hopkins:Beauty should take a back seat when it comes to safety, usability, and accessibility, not only in airline cockpits, but in most other interfaces, too. Your statement that \"there is just no reason an interface should be anything but beautiful\" is extreme and dangerous.Michael Darius:An interface is a habitat for a persons soul to dwell. Some habitats are better than others and there some awfully designed habitats out there.Don Hopkins:There are many reasons why, and many things more important than beauty. A spreadsheet is more beautiful if it hides the ugly truth about the formulas, relationships, numbers, dependencies, and complexities. Its purpose isn&#x27;t to be easy on the eyes, it&#x27;s to be correct.Are your earpods supposed to be beautiful, at the expense of being comfortable and actually fitting in your ears and not itching and poking and flaking paint and decorations into the holes on your head? You don&#x27;t need to see them, just hear them.The shape of your ear canals isn&#x27;t beautiful, but your earpods have to conform to it nonetheless.Michael Darius:I&#x27;d sooner fly a luxury airliner with dashboard complexity that has been thought through for me than assume that safety was the tradeoff for getting to fly with simpler controls.[photos of extremely complex airliner cockpits -- not sure which he&#x27;s claiming are beautiful or ugly though]https:&#x2F;&#x2F;twitter.com&#x2F;darius&#x2F;status&#x2F;1741193514032267758Don Hopkins:Beauty is in the eye of the beholder, but safety and usability and complexity is scientifically measurable, you can&#x27;t claim that thinking through safety and usability and complexity always results in beauty. Most people would consider those examples cluttered, complex, and ugly.ESPECIALLY anyone who subscribes to the school of minimalistic design like iPads exhibit, like hiding scrollbars because they are ugly, even though they tell you how much more there is to scroll, and what to do to scroll to it. Airplanes and spreadsheets need ugly affordances.Michael Darius:You can tell when something has been thought through on the inside, just as much as it has on the outside and most of the people who disagree with me in practice have simply never had the opportunity to work with engineers who care more about what is under the hood than what can be seen by the naked eye.I see no difference between beauty and the reduction in the margin for human error.[Photo of two children piloting an airplane.]https:&#x2F;&#x2F;twitter.com&#x2F;darius&#x2F;status&#x2F;1741195625767772529Don Hopkins:You just have an extreme personal opinion about beauty if you think removing scrollbars and buttons and even cluttered features from iPad interfaces, and making airplane cockpits look like playschool toys, always equals beauty. Your original statement is extreme therefore wrong.It&#x27;s wrong to assume that \"There is just no reason why an interface should be anything but beautiful.\" I&#x27;d rather be lazy and safe than wrong and dead because some interface designer though he was smarter than the FAA.And you&#x27;re also wrong because you&#x27;re presuming there is only one definition of beauty: yours. And that it can be measured. It can&#x27;t. Address that, please.Michael Darius:When effort has been put into an interface to simplify a function, the function itself becomes more beautiful. We see this when writing code. If I can perform an operation by writing 3 lines of code instead of 10, the margin for error decreases.[An image with an example of \"Ugly vs Beautiful\" code claiming that a one-liner is more beautiful than 6 lines of equivalent code.]Don Hopkins:Again, you&#x27;re pretending that beauty is not subjective, and that you know the one universal definition of beauty, and I would have expected better from you, and even more from a first year art student. Would the Mona Lisa be more beautiful with less paint?Would the Sistine Chapel be more beautiful with stick figures like an XKCD comic? Get off your high horse of thinking you can define beauty. Especially after championing the overly minimalistic iPad user interface bereft of scrollbars, buttons with text labels, and even features.Michael Darius:Here&#x27;s a quote that sums up Shaker philosophy:“Don’t make something unless it is both necessary and useful; but if it is both necessary and useful, don’t hesitate to make it beautiful.”[A photo of a \"beautiful\" chair.]Don Hopkins:But for the n&#x27;th time, you&#x27;ve again ignored me when I pointed out you&#x27;re moving the goalposts from your original outrageously extreme and incorrect statement that \"There is just NO REASON why an interface should be ANYTHING BUT beautiful.\"Michael Darius:I&#x27;m not ignoring you, I can&#x27;t keep up with how much you are writing.Don Hopkins:Well at least go back and read the words you wrote in your initial tweet and try defending THOSE, instead of trying to move the goalposts and express the one true definition of beauty. I ask you again: define and defend the words you first chose and wrote yourself.Your original statement is indefensible, so go back and try defending it instead of trying to move the goalposts and pretend you have a monopoly on the definition of beauty.Your original statement didn&#x27;t say anything about necessity or usefulness, as I said before. In fact it PRECLUDED them by claiming interfaces should ONLY be beautiful: \"There is just NO REASON why an interface should be ANYTHING BUT beautiful.\" Stop deflecting. Defend THAT.What exactly do you mean by \"NO REASON\" and \"ANYTHING BUT\". Usability and safety are reasons, and something but.Some random guy:Sorry to interrupt you guys. How about you two actually go to FAA or some shit and consult with them if it&#x27;s possible to make a cockpit more beautiful but retain its practicality. I feel like the argument wouldn&#x27;t go anywhere without trying to do something for real.Don Hopkins:You suggest us just walking in the front door of FAA headquarters, waltzing through security, and insisting on a meeting with the heads of the FAA to redesign their interfaces? Should Darius and I drop all we&#x27;re doing and volunteer our time to do that for free?Michael Darius:The images themself do a better job of communicating what I mean by \"beauty standards for excellence\".I&#x27;ve never met a designer who didn&#x27;t feel that their responsibility was to defend beauty standards for excellence and I&#x27;m not different.The mechanics of a jail door might be functional and usable by a door guard but there is nothing beautiful about building more prisons.Habitats for humanity cares more deeply about the ACTUAL lived experiences people are ACTUALLY having.[... A side discussion about the definition of beauty, in which Darius channels Deepak Chopra, and I try to get him back on track to defend his own original words, and he stands by his statement but doesn&#x27;t justify it: https:&#x2F;&#x2F;twitter.com&#x2F;xardox&#x2F;status&#x2F;1741212753056944187 ]Michael Darius:If beauty were so subjective then walking through a meadow would feel no different than doing jail time.Don Hopkins:Now you&#x27;re sounding like Deepak Chopra and his quantum faith healing mumbo jumbo hand waving woo woo. I would have expected much more from you. You made a clear unambiguous brash statement using the words NO REASON and ANYTHING BUT. Defend those words.Michael Darius:We can agree to disagree.[...]The subjectiveness here may not be around the definition of beauty and more around the ‘definition of an interface’. An interface can be defined as ‘the surface between Air and water’.Don Hopkins:More woo-woo, Deepak. Address points 1 and 2 which are directly about YOUR WORDS: \"There is just NO REASON why an interface should be ANYTHING BUT beautiful.\" (How many times do I have to quote them back to you before you address them? I must be on #10 by now.)[...]Don Hopkins:Of all those cockpits, which fit your definition of beauty and which don&#x27;t, and aren&#x27;t you aware that there are many hard won FAA regulations learned from the study of accidents, mass death, destruction, and human error, that vastly trump your personal opinion of beauty?Or are you arguing that all iPad interfaces should look like 747 cockpits?Or do you believe that beauty automatically implies safety, ergonomics, usability, visual unambiguity and perceptibility? Then how do you measure and prove that beauty is not subjective and not in the eye of the beholder and not just your personal opinion?And what if your personal opinions about beauty happen to require more weight, more expensive, less durable, more bespoke and less modular materials? Do economics not come into the picture, or do you only design interfaces for extremely rich people?Of course Donald Trump thinks that solid gold toilets in his luxury airliner are beautiful. Do you agree, because you think beauty isn&#x27;t in the eye of the beholder and he&#x27;s right, or because you want to make the customer happy no matter how bad their taste and idea of beauty is?Michael Darius:In a field where cognitive safety needs to be the priority and a world where user enjoyment reduces cognitive load, it is intellectually lazy to assume that beauty is the tradeoff for ergonomic safety.Don Hopkins:The UI Hall of Shame&#x27;s review of the notorious QuickTime 4.0 player proves the perilous consequences of a UI designer&#x27;s personal opinions about skeuomorphic beauty trumping usability and ease of use. Were you involved with that, or was it before your time?http:&#x2F;&#x2F;hallofshame.gp.co.at&#x2F;qtime.htmThat article should be required reading for aspiring UI designers. Hacker News discussion:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18212478My comment in that discussion:\"Apple&#x27;s long romance with skeuomorphism peaked with Bob Bishop&#x27;s APPLE-VISION, and went downhill from there.\" I posted several other comments about VLC&#x27;s terrible UI, too.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18219757Bob Bishop&#x27;s Apple Vision:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CU_qKQL5PVk[At this point I took it to private DMs.]Don Hopkins:Are you familiar with that review and the problems that caused the widespread negative response to the QuickTime 4 Player user interface? Have you taken the time to read the whole article? Were you involved with that product, or was it before your time?http:&#x2F;&#x2F;hallofshame.gp.co.at&#x2F;qtime.htmI have written about it on Hacker News, and compared it to the even worse WinAmp user interface. Other commenters compared them to WinAmp, but I don&#x27;t believe WinAmp&#x27;s infinite and easy skinnability is nearly as maliciously terrible or professionally irresponsible as the QuickTime 4 player (I expected SO MUCH MORE from a company like Apple that published Tog&#x27;s original UI guidelines), or VLC (which is an open source project without any money or professional UI designers).HN discussion:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18212478One of my comments (among several), which includes a thread about VLC:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18219757You can see that I actually give a shit enough about VLC to have spend quite a bit of time analyzing the problem and writing up bug reports, but the culture of the project is so insular and \"NIH\" that they don&#x27;t give a shit about user interface design. So I have little hope that VLC will ever improve. But at least Apple finally improved their QuickTime 4 Player in response to acceoss-the-board criticism.A counter example to the rule of thumb that open source user interfaces are terrible is Blender. Especially when you compare it to GIMP (which is like shooting fish in a barrel, but still is an instructive comparison of cultures).Blender was infamous for its complex non-standard confusing user interface design, but they LISTENED TO THEIR USERS and vastly improved it!But of course there is no way of getting around the fact that it&#x27;s an extremely complex tool that&#x27;s used differently by a wide range of people, so a lot of that complexity is necessary, and you can&#x27;t just simplify it away and dumb it down without destroying its usefulness.One thing Blender does have excellent support for is pie menus! And there are some great pie menu editors, which are important because every different Blender user has their own workflow and set of common commands. So Blender users need to customize and define their own pie menus. Just like HyperCard enabled normal users to construct their own task oriented user interfaces.(Of course Steve Jobs hated pie menus, which is a story I can tell you about later, or maybe you can tell me the Apple side of that story: Why didn&#x27;t Apple ever adopt pie menus for MacOS or iOS?)Pie menus have the potential of being both beautiful, efficient, reliable (low error rates), and easy to use, but it takes a lot more design and programming to pull off than a traditional linear menu.Simon Schneegans is a brilliant user interface designer as well as an accomplished programmer, and he has developed not only beautiful pie menus (for example the Coral and Trace menu he did for his Master&#x27;s thesis years ago, and he more recent work on Gnome-Pie, Fly-Pie, and the cross platform Kandu pie menus for desktop app launching, window management, text selection, and many other tasks).The Trace-Menu A short demonstration of a Pie-Menu I developed for my Bachelor thesis.https:&#x2F;&#x2F;vimeo.com&#x2F;51073078The Coral-Menu A short demonstration of a Pie-Menu I developed for my Bachelor thesis.https:&#x2F;&#x2F;vimeo.com&#x2F;51072812The thing about those examples (and his later work) is that the cool graphics don&#x27;t spoil the underlying good Fitts&#x27; Law friendly design -- they actually increase usability and reinforce the gestural navigation user interface metaphor.His most amazing accomplishment is the WYSIWYG drag-and-drop interactive pie menu editor he designed and implemented for Gnome-Pie, that he&#x27;s reimplementing across platforms (Linux X11 Gnome, KDE, Wayland Gnome, etc, Windows, and Mac).Fly-Pie 7: GNOME Shell 40+ and a new WYSIWYG Menu Editor!https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=sRT3O9-H5Xs>Fly-Pie is an attractive marking menu for GNOME Shell. Fly-Pie 7 supports GNOME Shell 40+ and brings a completely rewritten menu editor.I hope this proves to you how important I believe beauty is. but how I also believe it doesn&#x27;t need to sacrifice usability.Here&#x27;s the latest demo of his current project, Kandu: cross platform super customizable pie menus for Linux, Windows, and Mac. I just sent him my old Mac laptop so he can support the Mac desktop well. The way it works is by using Electron with a full screen transparent overlay window, so it can draw the pie menus with html&#x2F;css&#x2F;svg&#x2F;canvas or any other standards based web technologies.Kando becomes useful for the first time!https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=7vVdJ9LORAM>With Kando, I am creating an open-source pie menu which runs on Windows, Linux and (eventually) macOS. In the future, you will be able to create your own men...Michael Darius (excerpts):[...] Tim Wasko was the designer for the initial QT player and still remains one of the best interaction designers I know.\" [...]I don’t consider something unusable or barely usable to be beautiful so if the work hasn’t been put in on the usability side or if something isn’t working it doesn’t matter how beautiful the interface elements themselves are. But in that case what makes it not beautiful is not that the interface elements aren’t beautiful. What makes it not beautiful is that what is under the hood isn’t beautiful and what is under the hood is more often than not not thought through the way it should be.My definition of ‘beauty’ is inseparable from my definition of functional design:An interface should go beyond usable, it should delight, create enjoyment, provide a sense of safety and control over one’s environment, it should be beautifully engineered inside and out and when any one of those pieces go missing beauty itself goes missing. reply Angostura 18 hours agoparentprevIt&#x27;s possibly one of the reasons why so many people were bent out of shape when MS introduced the adaptive ribbon shenanigans that tried to &#x27;help&#x27; by only showing the most likely options. Really knocked my ability to find stuff reply mjevans 15 hours agorootparentI still hate ribbons.MS Office UI peeked around versions 97-2003 or so. Everything in a menu, actions grouped &#x2F; categorized so they were easier to discover. QUICKLY accessible by underlined keyboard combinations (alt+menu letter THEN item in menu letter) and with any actions that had a direct keyboard shortcut annotated. Everything easily discoverable.Ribbons, I&#x27;ve no idea how the categorize what&#x27;s popular or not, but &#x27;related&#x27; things seem weaker to me, and the context switch price is much higher. Plus there&#x27;s a need to hunt and kill with a mouse instead of direct with the keyboard. reply kuchenbecker 14 hours agorootparentMy first job was on a particularly verbose set if software that&#x27;s hard to learn. But, everyone that uses it does so daily and quickly become experts in their workflows.Number of clicks was the #1 metric because a \"pretty\" UI would generally add steps and slow everyone down.Verbose UIs are hard to learn but once learned have much better end-to-end workflows with fewer steps. Simple UIs hide information behind interactive (i.e. slow) workflows and universally hated by customers. reply userbinator 14 hours agorootparentprevYou can still access the items in the ribbons with Alt key sequences (although I agree that they&#x27;ve become far less discoverable), but the full-screen(!) \"file menu\" abomination that they added in later versions is even more hostile and offensive. reply Espressosaurus 11 hours agorootparentEspecially after they made everything cloud-first, making saving my damn documents to my local drive a pain in the ass. reply TaroEld 9 hours agorootparentF12 brings up the old \"Save As\" filebrowser. reply troupo 3 hours agorootparentprevRibbons for Word used to have actual research behind them. Since then it&#x27;s just cargo culting.Sadly, many images are broken, but the blog series \"Why The New UI\" survives on web archive: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20080316101025&#x2F;http:&#x2F;&#x2F;blogs.msdn... reply staplers 18 hours agorootparentprevExpectation should precede consistency in order of importance.Meaning, if a new user is learning your software, how would they expect the next [flow] to go?Consistency often shapes expectations but when things go how you expect them to, you don&#x27;t need to learn new mental models. reply jonshariat 17 hours agorootparentUX designer here. I&#x27;ve learned that these changes are a delicate balance between allowing existing user to remain experts while improving the retention of new users.This can be accomplished by making small changes over time that break up all the new info a user has to learn and avoiding the big UI reveal which people universally hate because all that new learning is required at once and they need to get stuff done.Often times its required because as a product moves into mass market phase of its life cycle, it needs to be simple to use for lots of people, which mean it doenst work great for any specific goup.Which is why I&#x27;m really in favor of allowing customizations to the user where appropriate. It allows experts to have control over their flow and new users can enjoy the UX optimized for them. reply PennRobotics 6 hours agoparentprevI have been screwing around with Microsoft C 3.0 in DOS. What a breath of fresh air it is to install Vim for editing and still have nearly all of its modern functionality (macros, syntax highlighting, folding, splits, regex, visual mode) with absolutely NO keystroke changes. reply throwaway2037 6 hours agoparentprev> It’s about letting someone become an expert in your software.This is brilliantly said. Watching someone, who does not think that they are technical, zoom around Excel is always special to watch.> Microsoft office was always his example.The Microsoft UI design rules are pretty amazing. The consistency over the years allows people to upgrade every 1-2 years and continue to use their software. (I do not write this a Microsoft fanboi.) The key for each upgrade: Incremental changes to improve the UX. One thing I never understood: When Win 95 introduced the concept of \"right click everywhere for properties (and deeper settings&#x2F;details)\", why didn&#x27;t the design team reject it? After all, it is invisible to user (to indicate right click is possible). It seemed like no one understood right click the first few times they used Win 95. reply eviks 7 hours agoparentprevHow can MS Office be this example when shortcut modification is awful there, as well as Ribbon customization??? People pride themselves on all the nonsense they&#x27;ve invested a huge deal of time into, that&#x27;s not an indication of any quality or UI excellence Vim is another prime example of extremely user unfriendly UI design, breaking most of the principles from the linked article (but similarly, with folks who&#x27;ve invested a few metric tons of effort into fixing it will pride themselves) reply DonHopkins 16 hours agoparentprevnext [5 more] I worked with Ben Shneiderman at the UMD Human Computer Interaction Lab developing pie menus, and one of the important principles of pie menus, especially in comparison to both traditional linear menus, and invisible gestures as used by the iPad and mobile apps, is that they smoothly TRAIN novice users to become experts by using \"rehearsal\".Pie menus can lead, follow, or get out of the way. The way a novice uses them is actually rehearsal for how a more experienced and experts use them.Unlike invisible gestures, they can pop up and show users the available items. They also support reselection and browsing, which gestures don&#x27;t. They also utilize 100% of possible \"gesture space\" as meaningful predictable actions, as opposed to gesture recognition which squanders most possible gestures as syntax errors.Gesture Space:https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;gesture-space-842e3cdc7102Unlike pull-down menus that have keyboard shortcuts, pie menu \"shortcuts\" are exactly the same action a novice takes to use them in the first place, only quicker, so using them in the slow way trains you to use them in the fast way. While selecting from a linear menu with the mouse is a totally different action than selecting a menu shortcut with the keyboard.Ben Shneiderman introduces Don Hopkins&#x27; work on pie menus in Spring 1989 on a Sun Workstation, running the NeWS window system:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8Fne3j7cWzgAfter an 1991 intro by Ben Shneiderman we see the older 1989 demo by Don Hopkins showing many examples of pie menus on a Sun Workstation, running the NEWS operating system.This is work done at the Human-Computer Interaction Lab at the University of Maryland.A pie menu is a menu technique where the items are placed along the circumference of a circle at equal radial distance from the center. Several examples are demonstrated on a Sun running NeWS window system, including the use of pie menus and gestures for window management, the simultaneous entry of 2 arguments (by using angle and distance from the center), scrollable pie menus, precision pie menus, etc. We can see that gestures were possible (with what Don call \"mouse ahead\" ) so you could make menu selections without even displaying the menu. Don uses an artifact he calls \"mousee\" so we can see what he is doing but that extra display was only used for the video, i.e. as a user you could make selections with gestures without the menu ever appearing, but the description of those more advanced features was never published.Pretty advance for 1989... i.e. life before the Web, when mice were just starting to spread, and you could graduate from the CS department without ever even using one.This video was published in the 1991 HCIL video but the demo itself - and recording of the video - dates back to 1989 at least, as pictures appear in the handout of the May 1989 HCIL annual Open House.The original Pie Menu paper is Callahan, J., Hopkins, D., Weiser, M., Shneiderman, B., An empirical comparison of pie vs. linear menus; Proc. ACM CHI &#x27;88 (Washington, DC) 95-100.Also Sparks of Innovation in Human-Computer Interaction, Shneiderman, B., Ed., Ablex (June 1993) 79-88. A later paper mentions some of the more advanced features in an history of the HyperTies system: Shneiderman, B., Plaisant, C., Botafogo, R., Hopkins, D., Weiland, W., Designing to facilitate browsing: a look back at the Hyperties work station browser Hypermedia, vol. 3, 2 (1991)101-117.PS: For another fun historic video showing very early embedded graphical links (may be the 1st such link) + revealing all the links&#x2F;menu items + gestures for page navigation• HCIL Demo - HyperTIES Browsinghttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fZi4gUjaGAMhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11319498DonHopkins on March 19, 2016parentcontextfavoriteon: Motion Design Is the Future of UIUser interfaces should always be able to lead, follow, or get out of the way. Animation should never delay interaction, and it should never interfere with gestures and mouse-ahead (or whatever the input device is).The user should never have to wait for animation to finish before they&#x27;re able to do something, and the interface should never be disabled during animation, or ever ignore the user&#x27;s input under any circumstances.User input should always pre-empt and interrupt feedback and animation.The interface should always support quick gestures (mousing ahead, touching ahead, or whatever), without ever requiring the user to pause and wait, or focus their attention on the screen to watch the animation play out before they know it&#x27;s safe to make the next move.I developed a gestural pie menu tabbed window manager for the NeWS window system in 1990, which supported mousing ahead, suppressing the pie menu display and pop-up animation until you stopped moving, showing light weight feedback on the overlay plane, and executing commands instantly without any animation or even popping up the menu, when you make a smooth quick gesture without hesitating.NeWS Tab Window Demo:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=tMcmQk-q0k4https:&#x2F;&#x2F;donhopkins.com&#x2F;home&#x2F;movies&#x2F;TabWindowDemo.movTranscript of the relevant part of the demo:Now you can press the right button to pop up a pie menu on the tab or on the frame itself. And that has commonly used commands like front and back in mnemonic directions. Back is down, and front is up.When you make a menu selection by mousing ahead, it doesn&#x27;t display the menu.As long as you&#x27;re moving, it suppresses the menu display.And it gives you feedback on the overlay plane of the slice that you&#x27;re in, and the label of that slice, so you can actually see what you&#x27;re going to get before you choose it without even seeing the menu itself.And when you wait, it pops up the menu once you stop moving.So if you waste some time by just waiting around, it will waste a bit more time by giving you some stupid animation.And this is meant to be negative reinforcement, to encourage you to mouse ahead.The sub-menu pops up. This is \"move to\" which is unconstrained move.You can always get that from the tab by mousing left and right.That&#x27;s an easy gesture. Just quickly...Or mouse there and wait. There it is. It pops up the one you&#x27;re at first.This is constrained horizontal move.And this is constrained vertical move.So constrained horizontal... We&#x27;ll wait.Constrained vertical...So, I mean, once you&#x27;re there, and you know what you want, why wait?This is \"beam me up\": put it in the next layout position. To tidy the windows.So, if you&#x27;ve clicked the menu up and haven&#x27;t moved, it will just spin it, because it&#x27;s confused, and doesn&#x27;t know what you&#x27;re going to do.----In other words: As it pops up and scales up the round menu, it also tilts it along the axis perpendicular to the direction of movement to reinforce the selected direction, or spins around the center if you haven&#x27;t moved to show no direction is selected.And you only ever see any animation if you actually stop moving -- once you make a selection, the command always executes or the submenu always activates immediately.You can mouse ahead smoothly through multiple levels of sub-menus, without popping any of them up or seeing any animation, as long as you never hesitate.By \"lead, follow, or get out of the way\", I mean that pie menus can lead novice users by giving them feedback and animation when they pause, follow intermediate users who move in the right direction then pause for the feedback to make sure they got it right, and get out of the way of expert users who know the right direction and can quickly articulate gestures without pausing or waiting for feedback.----Here&#x27;s another demo showing pie menus, mouse ahead gestures, and display pre-emption in SimCity:X11 SimCity Demo:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Jvi98wVUmQA----And here&#x27;s a really old demo from June 1986 of the \"uwm\" window manager for the X10 window system, that I hacked to support pie menus with mouse-ahead and display pre-emption.X10 Pie Menu Window Manager:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=IJhvB6kwmog---More info here:The Design and Implementation of Pie Menus -- Dr. Dobb&#x27;s Journal, Dec. 1991:https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;the-design-and-implementation-... reply joeblubaugh 14 hours agorootparentDo you know of any work about how to combine pie menus and keyboard usage? Mousing is very uncomfortable for me, but if a pie menu could be used with a keyboard-attached joystick, it might be a really quick way to work. reply cyberax 8 hours agorootparentBasically, you use cursor keys to select the direction. So you can just memorize the paths to the correct items.Modern console games use the same idea for communication wheels, that are usable from game controllers. reply DonHopkins 13 hours agorootparentprevPie menus work well with trackpads and trackpoints (keyboard clitoris), as well as analog and digital 4- or 8-directional joysticks, and even numeric keypads and arrow keys.If you arrange your menus into 4- and 8-item pie menus, they are uniformly navigable and memorable for many types of input devices including keyboards. Four and eight items are ideal for muscle memory, and also cognitive memory too. So using pie menu layouts that map directly to keyboards and digital joysticks works really well.The ActiveX pie menus I implemented for Internet Explorer a couple decades ago supported full keyboard navigation:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nnC8x9x3Xag reply llanowarelves 13 hours agorootparentprevThanks. A lot of good stuff here that may go overlooked. reply ShadowBanThis01 16 hours agoparentprevI agree with the importance of consistency, but disagree with \"Office and (Neo)Vim aren’t exceptional examples of UI, but they are uniquely stable.\"Office is not stable, at least over the long term. The hated \"ribbon\" marked a sad departure from the \"stable\" and efficient Word UI, and Microsoft&#x27;s clueless regressions across the Windows platform have compounded the problem. For example, the deletion of the menu bar from applications. WTF. reply kemotep 14 hours agorootparentWe are about a year or 2 from the Ribbon interface existing in Office longer than the pre-Ribbon interface.I will agree that the Ribbon and what you can customize or use in it&#x2F;looks has changed drastically since 2007.But the Ribbon “paradigm” will soon have existed longer than the non-Ribbon “stable and efficient” interface so it is more “stable” in one way. reply ShadowBanThis01 12 hours agorootparentStabilizing on shit is a sad thing to double down on. But Microsoft is doing that at every opportunity now. Witness their offensive, relentless hounding to log in, log in, LOG IN WITH YOUR \"MICROSOFT ACCOUNT!!!!!!\"... or you can&#x27;t do anything, including install Windows. reply troupo 3 hours agorootparentprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38925695 reply danielvaughn 17 hours agoparentprevboth vim and neovim are examples of UI, just not (G)UI :) reply andsoitis 1 hour agoprevNielsen&#x27;s 10 usability heuristics for user interface design gives a good north star:1. Visibility of system status2. Match between system and the real world3. User control and freedom4. Consistency and standards5. Error prevention6. Recognition rather than recall7. Flexibility and efficiency of use8. Aesthetic and minimalist design9. Recognize, diagnose, and recover from errors10. Help and documentationhttps:&#x2F;&#x2F;www.nngroup.com&#x2F;articles&#x2F;ten-usability-heuristics&#x2F; reply lcuff 25 minutes agoparentThe contrast between this Nielsen-Norman (NN) page and the OP page is marked. The NN page is much easier to absorb the information. More succinct, way better page layout.Both articles have information&#x2F;direction worth heeding, but there is irony in the fact that the OP page adopts same-text size and paragraphing conventions of yesteryear that the NN page does away with.It&#x27;s also frustrating that Hacker News doesn&#x27;t pay attention to some of the information. In creating an edit to an existing post, the feedback after clicking on the &#x27;update&#x27; button is not as clear as it should be. (It&#x27;s a screen redraw, I guess). reply GMoromisato 11 hours agoprevThe one \"rule\" I wish it covered is about surfacing&#x2F;exposing the conceptual model to the user.If I don&#x27;t understand the conceptual model of the product, I will always be confused, no matter how well-labeled the icons are. For example, imagine a product that has a \"New Configuration\" command. What is a \"Configuration\"? Is it like a template that lets me define other objects? Is it a way to rapidly switch between different sets of options? Is it a container, like a folder?The UI must be designed so that the user can infer the conceptual model just from exploring the interface. This is not always easy. reply Ygg2 10 hours agoparentPoint of good interface is to hide implementation detail while guiding you towards your goal. reply nirimda 7 hours agorootparentTo be clear - the conceptual space the software is built around isn&#x27;t an implementation detail. It&#x27;s the way you reach your goal; it necessarily imposes a burden on the user. A good conceptual space presses less heavily against the user, but you can&#x27;t obscure the notion that there are containers in a file system but not a relational database. reply moring 6 hours agorootparentThere is always the discussion whether the UI should \"hide the implementation details\" (make the internal model, which differs from the conceptual model, invisible -- resulting in hard-to-understand behavior) or \"make the implementation details visible\" (change the conceptual model to be equal to the implementation model, and force the user to adapt to that).But the one option that is rarely used but yields the (IMHO) best results is: design the conceptual model, then build&#x2F;change the implementation model to be equal to it.One example for this strategy that is forever stuck in my head is macOS application folders. The conceptual model is that an application can be moved around like a file, and applications be organized in folders like files. But you also want to run an application by double-clicking it. Instead of what Windows (and then Linux) did with links, menus, installing applications and centrally registering them etc., the implementation was changed to be like the conceptual model. A whole class of errors from inconsistencies just vanished. reply stronglikedan 1 hour agoprev9. Stop popping in something else in place of what I&#x27;m just about to select, causing me to select the wrong thing! (I know this maybe violates or can be mitigated by some of the previous rules, but it is the one thing that drives me absolutely bonkers, and I consider it to be a particularly egregious mistake.) reply tech2 1 hour agoparentJira and the Unassigned&#x2F;Automatic selection when trying to change a story assignment, I&#x27;m looking at YOU in particular! reply joshuaheard 18 hours agoprev\"For example, users should not have to retype an entire name-address form if they enter an invalid zip code but rather should be guided to repair only the faulty part.\"This is my biggest pet peeve, and I still see it. It should also be true for multi-page forms if you are going back and forth between form pages.\"Erroneous actions should leave the interface state unchanged, or the interface should give instructions about restoring the state.\"Designers seeking to save space on small screens like phones and watches are increasingly relying on icons. However, many icons are unfamiliar or hard to decipher. Sometimes, the only way to figure it out is to click on it. Every such icon should have a way to go back to the original state if a mistake is made. reply pugworthy 11 hours agoparentRight. And if I type in \"Corvallis\", ask me \"Oregon or Montana?\" If I type in \"97330\" just skip the rest. reply ShadowBanThis01 16 hours agoparentprevAnnoying as shit. If I&#x27;m trying to log into something with an E-mail address (already a fail, but that&#x27;s another topic) and password, and I click \"forgot password,\" don&#x27;t take me to a form where I have to re-enter the goddamned E-mail address I JUST ENTERED. reply nox101 15 hours agorootparentOr every customer service phone line where the automated system asks for your info (account# or phone#) and then the customer service rep asks again >:( reply bluGill 13 hours agorootparentIn some cases this is a verification and reques, for more information. when doctors reask what the nurse just asked.most of the time it isn&#x27;t. the doctor already knows what you told the nurse. (where the doctor doesn&#x27;t that is bad) reply rrr_oh_man 13 hours agorootparentprevThat is only to keep you busy and engaged reply esafak 13 hours agorootparentI just engaged the close button. reply ShadowBanThis01 10 hours agorootparentprevI actually bring this up when they ask me again. \"Didn&#x27;t I just enter that?\" reply akavi 15 hours agorootparentprevOr its twin cousin: forcing me to login after updating my password. reply Cockbrand 12 hours agorootparentI assume that this is to help the user memorize their new password. I know we on HN all use password managers, but most people out there don’t. reply breadwinner 17 hours agoprev> gray out menu items that are not appropriateDon&#x27;t do this unless it is obvious why it is grayed out. Commands should be left enabled, then an error message should be displayed when the command is clicked and the command is unavailable, and in this case explain why it is presently unavailable. It is frustrating to the user to figure out why a command is disabled. The only time to not leave commands enabled is if the user is likely to end up wasting a lot of time only to be told at the end that the command is unavailable.Update: Read more about this in this article: https:&#x2F;&#x2F;medium.com&#x2F;@vedranio&#x2F;james-bond-and-the-design-of-di... reply moring 6 hours agoparent> Don&#x27;t do this unless it is obvious why it is grayed out. Commands should be left enabled, then an error message should be displayed when the command is clicked and the command is unavailable, and in this case explain why it is presently unavailable.Why not grey out these menu items, but still show the exact same message when you click them? That seems to be the best of both worlds to me. reply breadwinner 2 hours agorootparentBecause users are accustomed to grayed out items not responding to mouse clicks, so they will never click it. reply arcanemachiner 13 hours agoparentprevSure, but there should be some kind of consistent visual affordance that conveys that the action is disabled, before the user clicks on it. reply breadwinner 13 hours agorootparentIf the user is likely to keep clicking the button only to be told that the feature is currently unavailable, then some kind of status indicator would be helpful. In my experience, this situation is very uncommon. reply euroderf 7 hours agoparentprev> Commands should be left enabled, then an error message should be displayed when the command is clicked and the command is unavailable, and in this case explain why it is presently unavailable.An exception to this: premium (for-pay) features.There is a certain To-Do app that does this. Premium commands are visually indistinguishable from freemium commands, so they get clicked a lot and they interrupt the entire experience with nag dialogs.A serious UI error IMO. reply carlosjobim 4 hours agorootparentIt&#x27;s not an error, it&#x27;s deliberate. reply KineticLensman 23 minutes agoparentprev> Update: Read more about this in this articleI read the article (TL;DR it describes a bond car that lets Bond select a weapon only to then give him an error message saying &#x27;ammunition not loaded&#x27;, and then considers how this should be handled from a UI perspective).Thinking about the overall UI guidelines topic, the bond article misses an obvious point - that cars already have familiar mechanisms for displaying the status of consumables such as fuel, oil and battery: gauges on the dashboard. Applying the consistency guideline, Q could have installed an ammo gauge, and the &#x27;backfire&#x27; button would then be permanently available. After all, Bond might still wish to deploy the gun for effect, e.g. to intimidate someone, even if he knows that there isn&#x27;t in fact any ammo. reply verinus 7 hours agoparentprevI disagree. Disabling an action that is not feasible in the current context IS helpful, but ONLY if you provide an explanation on WHY.UIs that simply disable certain actions without telling me why always infuriate me :( reply gpderetta 5 hours agorootparentEven better[1]: GUIs that hide actions that are not feasible.[1] and by better I mean worse. reply nirimda 6 hours agoparentprevI used to use a lot of Gtk+ apps, where the menu item was disabled, but all this meant was that it was shown greyed out. In fact, as far as the toolkit was concerned it was still active and still sent a message to the app, and the app was supposed to respond to the message and inform the user about why the action was presently unavailable. I think that was a good choice at the time, because a menu was a stateful bit of UI (clicking the menu item closes the menu), so a fore-warning that the activity is unavailable might help me remember \"oh, I forgot to ...\" before I see the message, but I can still try anyway and find out what I didn&#x27;t know.Nowadays, I think menu options in user interfaces are much rarer, and complex stateful applications are usually HTML web programs where the disabled flag is a hint to the web browser to reject the interaction. Some of these web programs color submit buttons in a washed-out version of the normal color until the form is fully validated, but they will report the reason (to a greater or lesser utility) when clicked - such a widget is not formally disabled to the computer engineer, it&#x27;s just presented to look like one. I find this subtle distinction frustrating, because it represents an ambiguity of thought that makes precise conversation difficult. Why should a widget ever reject interaction? A widgetset&#x2F;toolkit is just a medium for dialog between a user and the developer, and they should always be allowed to communicate. A software developer should be able to say \"hi widget set, please let the user know this button doesn&#x27;t make sense at the moment\" but they should not be allowed to say \"hi widget set, if the user wants to tell me something - i don&#x27;t want to know it, just throw it away. we&#x27;re not on speaking terms\" (They could, of course, completely ignore the user, but it&#x27;s intuitively obvious that they shouldn&#x27;t completely ignore the user. Most developers intuitively want to communicate the reason for the error if they know it&#x27;s possible for a button to be clicked when they can&#x27;t handle it, but they often get frustrated because the UI designer didn&#x27;t clearly indicate to them how they should communicate errors - but perhaps they them what they shouldn&#x27;t do and now they are stuck).I liked the option 5 mockup in the link, although I&#x27;m not so sure it works for actions (like shooting) so much as state toggles (like activating the weapon). I do strongly disagree with the reasoning at the end of the page \"it&#x27;s okay to break the rules for a piece of software that people often use\", because it&#x27;s 100% a case of \"rules for thee but not for me\". Aside from the fact that I might have been using Outlook until I changed jobs to a new one (and there&#x27;s a lot of people who only use Gmail unwillingly&#x2F;primitively and attempt to use the phone and Teams and Slack and meatspace for their communication needs), it&#x27;s exactly the most commonly used programs that set the norms for users and software developers. We know how to communicate because we imitate previous dialogues. If the most commonly used programs get to break the rules because some of the people who use them use them dozens of times a day whereas others only want to use the features once a week or two and only manage to use them once a month or so, then the members of both parties will come to the view that cryptic software is fine - one because they use it all the time and have no problem, and the other because they see that hard-to-understand software is highly regarded. And so the designer of a widget designing tool will say \"no, it&#x27;s fine for the widget to show only when it&#x27;s available, because the people who use this widget-designing software will almost always be using it daily, and they&#x27;ll only have to learn it once at the beginning of their career\". Are they correct? Who knows. At this point it&#x27;s just a position in the design space by the user interface designer. reply beefield 5 hours agoprevI think it would be important to understand the distinction between two types of applications, I call them \"utilities\" and \"tools\" here.Utilities are things that should be designed with the current typical paradigm of simplicity and discoverability to extreme. I should not need to read user manual for my toaster or microwave.Tools then, should be pretty much the opposite. It should be fine and expected to invest some time to learn the efficient and safe usage of the tool. There is no reason to have a intuitive interface on your tool, as long as it is efficient after you did your training. Vim is way better editor than notepad, but I don&#x27;t think anyone praises it for the intuitively easy to use.And the peeve here is of course that way, way too often these are confused. reply georgeecollins 18 hours agoprevNot sure that Strive for Consistency should be a golden rule of all interface design. Software maybe. But the reality is the world is inconsistent and humans mental model of tasks are inconsistent. Sometimes its better to design an interface that conforms to the world or the mental model.As a random example: You could have an interface on a car that is almost entirely touch screens. You might see replacing the steering wheel with a touch screen interface. That would be consistent but not a good mapping to people&#x27;s mental model. reply ivan_gammel 18 hours agoparent> You could have an interface on a car that is almost entirely touch screens. You might see replacing the steering wheel with a touch screen interface. That would be consistent but not a good mapping to people&#x27;s mental model.Consistency means that users can expect the same behavior from elements with the same specific purpose. When you put steering wheel and infotainment system in the same classification bucket, it is not consistency, it is excessive abstraction. reply projektfu 17 hours agoparentprevWhen I was a kid there were toy RC cars that had two controls, kind of like 1-axis joysticks. The left one pushed upward would cause the car to go forward, possibly with more or less power. The right one pushed to the right allowed turning to the right (but not the left, like Zoolander).A consistent upgrade to this interface would be to allow reversing using the left control in a downward direction and turning left using the right control pushed to the left. An inconsistent application would be to have reverse on the right control pushed to the left and left turning on the left control pushed downward.Inconsistencies across classes are not uncommon and probably understandable given various expectations. For example, the same handlebar steering control behaves very differently on a two-wheeled motorcycle compared to a tricycle. reply p1necone 17 hours agoparentprevI feel like that&#x27;s a bad example because touchscreen controls in cars are just bad in general. Adding a new one makes the car worse because the touchscreen control is bad, not because of anything to do with consistency - all the other touchscreen controls made the car worse too. reply Jtsummers 18 hours agoparentprev> that are applicable in most interactive systems. These principles, derived from experience and refined over three decades, require validation and tuning for specific design domains. No list such as this can be complete, but even the original list from 1985, has been well received as a useful guide to students and designers.The author already caveated that they aren&#x27;t absolutes. That is, they aren&#x27;t declaring you should follow these rules off a figurative cliff. That would be stupid. The presumption is that people would still exercise judgement. reply ebiester 18 hours agoparentprevThink of it more like this.On page A, you have a button. It looks like a button. When you click it, a dialog opens that confirms you want to perform an action.On page B, you click on the button, and it&#x27;s a dropdown. You now have lost a sense of the mental model of the application world.It&#x27;s possible that you may want one of three actions based on your mental model, but the visual should lead you to know \"this is different.\"If you have something that looks like a reply quickthrower2 17 hours agoparentprevIn this case the consistency is between what you learned to drive in, and the car you use now. reply JusticeJuice 12 hours agoparentprev+1, consistency above everything is a very common trap new designers fall into. Humans are messy. reply leetrout 18 hours agoparentprevNot sure that is the best comparison because it removes the mechanical need for leverage, even with power steering.Now that we have more electric steer by wire... maybe. reply pugworthy 11 hours agoprevI inherited an app from someone a few years ago at work, and for whatever reason, the developer loved a gray themed UI. Gray buttons. Gray text entry. You never knew what was disabled and just gray for fun. Needless to say that changed... reply wouldbecouldbe 16 hours agoprevThe Golden Rules of obvious Utopia.I think most of us won&#x27;t disagree with these rules.Yet also most devs will have worked on interfaces that break these rules often. Not because we didn&#x27;t understand or didn&#x27;t want, just that the cost was too high at that point.For instance reversibility is very difficult and only possible if the datastructure under the application is build up with this in mind. Or take preventing errors, often it&#x27;s very difficult and costly to know exactly what errors are, and ever more complicated to provide perfect feedback to a user in their own language. reply ozim 10 hours agoprevOne thing is that some times some things have to be made harder for end users good or for business rules protection.It is sometimes hard to explain but as an example - delete confirmation - it gets in the way of user because user wants to delete stuff and be done with it. Preventing accidental deletes is more important than any specific user convenience.Keep in mind this is most generic example I came up with on the spot. There are more complex scenarios that are complex for the same reasons. But I find people trying to remove such fences even if they don’t know why they’re there. Claiming simplicity and user convenience as golden rule. reply Kranar 9 hours agoparentI really detest that principle. For the design of my software I make almost every action reversible and avoid at all costs confirmation dialogs or anything that makes it seem like the user could be at fault for something if they choose incorrectly.I also work on financial trading software so I do need to think a great deal about user error and the best principle I have found is to never create a situation where a confirmation is needed.Among new users it creates anxiety and indecisiveness, and among experienced users they just ignore it and it&#x27;s noise to them. All confirmation dialogs do is make the developer&#x2F;designer punt responsibility off to the user for what is generally a bad design decision. reply dmalik 15 hours agoprevA lot of these rules are taken care of by design systems these days. If you&#x27;re off developing your own design system or creating custom components the laws of UX are far more useful.https:&#x2F;&#x2F;lawsofux.com&#x2F;Here are a few that relate to laws:Strive for consistency - Jakobs lawReduce short-term memory load - Millers Law reply guardian5x 7 hours agoprevI would like to add: \"Live up to expectations\" in a sense that there are so many Websites or UIs there, that most users have some sort of expectations, on where to find the menu, how to go back etc. How this and that buttons should behave. Even though, you might have a great idea, it might just confuse the user, if it is totally different than what the \"standard\" is. reply whycome 2 hours agoparentEveryone wants to create new expectations and hope they become the new standard reply eviks 7 hours agoprevLooks like a good list, though missing are customization (technically you could tuck customization into \"user control\", but it&#x27;s too important for that) and composability (which also helps with 8 memory load - you can remember &#x27;primitive&#x27; actions that compose well easier, and that memory would be reinforced with repetition) reply dang 16 hours agoprevRelated:Eight golden rules of user interface design - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36652355 - July 2023 (1 comment)8 Golden Rules of Interface Design - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=233654 - July 2008 (7 comments) reply bob1029 16 hours agoprev> Sequences of actions should be organized into groups with a beginning, middle, and end. Informative feedback at the completion of a group of actions gives users the satisfaction of accomplishment, a sense of relief, a signal to drop contingency plans from their minds, and an indicator to prepare for the next group of actions.This is why we built our product around a workflow abstraction. Everything the user can do is some workflow implementation with a # of discrete steps. Our criteria for the scope of a step is guided by a dark and mystical process wherein we all argue about the business for a few hours and then sketch out some prototypes. One trick is to design these with lego-like reuse in mind. Oftentimes, the business will have the exact same view used across a wide range of activities. reply rrr_oh_man 13 hours agoparentCare to share the product? reply infotainment 18 hours agoprevSome good stuff here, but generally I’d disagree with:> Prevent errors: As much as possible, design the interface so that users cannot make serious errors; for example, gray out menu items that are not appropriate and do not allow alphabetic characters in numeric entry fields (Section 3.3.5This sounds nice in theory, but in practice too many guardrails like this will just confuse users. “Why can’t I type text here??” It’s often better to allow mistakes but also offer immediate explanatory feedback if something is incorrect. reply ivan_gammel 18 hours agoparent> It’s often better to allow mistakes but also offer immediate explanatory feedback if something is incorrect.That is just another form of error prevention: in the end erroneous data will not be submitted. reply Jtsummers 18 hours agoparentprev> It&#x27;s often better to allow mistakes but also offer immediate explanatory feedback if something is incorrect.Which is what the rule actually describes.> If users make an error, the interface should offer simple, constructive, and specific instructions for recovery. For example, users should not have to retype an entire name-address form if they enter an invalid zip code but rather should be guided to repair only the faulty part. Erroneous actions should leave the interface state unchanged, or the interface should give instructions about restoring the state.I&#x27;m very confused by some of the attempts at \"gotchas\" in this discussion that are just restating what the list (and context paragraphs) already say as if it didn&#x27;t say it. reply eviks 7 hours agoparentprev> will just confuse users. “Why can’t I type text here??” It’s often better to allow mistakes but also offer immediate explanatory feedback if something is incorrect.No, it&#x27;s better to prevent a mistake and offer immediate explanatory feedback why something is incorrect. For example, the answer to \"why can&#x27;t I type text here??\" would be a message explaining that no text is allowed, only numbers. reply whycome 2 hours agorootparentOr, as is possible on mobile, make the input mode change to numbers-only reply eviks 1 hour agorootparentYes, and make your now useless alpha keys into a perfectly usable numpad so you don&#x27;t have to use the worse horizontal numbers row or shift your hand to the actual numpad!uio 123jkl 456m,. 789 reply naasking 17 hours agoparentprevAdd a tooltip on disabled inputs. reply o11c 11 hours agorootparentTooltips seem to have gone out of style in this touch-first world.Good UIs still use tooltips, you just have to click or drag when in touch mode.There&#x27;s also the awkward problem of most native tooltips being plain-text-only, when text is not actually sufficient for every problem (such as international text). And emulated \"tooltip\" widgets are slow, buggy, etc. reply DonHopkins 16 hours agorootparentprevA thousand times this! All disabled menu items and inputs should always have a tooltip or other means of explaining why they are disabled and what to do to enable them, with no exceptions. reply pvorb 17 hours agoparentprevI can&#x27;t tell which browsers or UI libraries do this, but do you know those date pickers that try to maintain a valid date with every keypress? It&#x27;s such a horrible user experience if you try to type a date by hand. reply stevage 18 hours agoprevThese seem common sense, but it&#x27;s good to see them written down.The one about giving users closure in a sequence of tasks is kind of novel. I like it. reply causality0 14 hours agoprev0. Don&#x27;t change things just for the sake of justifying your employment as a UI designer.The software I use with the best UI is also the software I use with the oldest UI. reply ShadowBanThis01 16 hours agoprevIt&#x27;s missing a critical one, which once seemed obvious: Distinguish between static information and controls.Also, don&#x27;t HIDE inapplicable controls; GREY THEM OUT. That way people learn1. They exist 2. Where they reside 3. There&#x27;s some condition to satisfy before they can be usedRelated: Never, never rely on peek-a-boo UI that hides things unless the user accidentally rolls the cursor over them. I&#x27;m trying to get shit done, not explore an Advent calendar. reply oivviopolite 10 hours agoprev1. Set your page margin to 0px. reply bluSCALE4 15 hours agoprevI think undo and history is vastly underrated. Lots of systems have activity logs but not many associate anything actionable to them. reply Stenzel 17 hours agoprevTitle should say screen design, for general UI these are quite useless, especially if your UI is physical. reply madeofpalk 16 hours agoparentI think these guidelines are pretty translatable for any kind of user interface, including physical.Machines should have consistent physical controls that make it readily apparent whether it&#x27;s a button to press or a knob to turn. They should prevent errors like an exposed blade cutting my hand off. reply tsunamifury 9 hours agoprevThe big one missing is “design symmetrically”. The way you go in is also wheee you go out. Where you turn something on is also where it’s turned off. Swipe up so swipe down and on and on.This is so obvious yet so many completely fail to do it. reply 23B1 16 hours agoprev9. The actual golden rule: don&#x27;t create UX that you yourself would find hostile. reply bbor 18 hours agoprevCan an expert explain some context here?? This seems like a less-well-phrased version of Norman’s principles, which were the ones I was taught in HCI class.The author is clearly some sort of textbook author so they know what they’re talking about, but these principles seem like they were written without considering past work. Like “short term memory load” seems like a phrase that would be replaced by “cognitive load” by most authors, even if it’s technically a little bit less specific. Some of the principles are pretty much identical (consistency), while others seem oddly phrased (like “prevent errors” instead of “constraints”).Obviously these principles are great, just seems like there has to be a story about the academic drama here. reply ivan_gammel 17 hours agoparentI was not familiar with this author, but they mentioned that these principles were defined around 1985 — before Nielsen‘s heuristics. A lot of things were different 40 years ago, so language may indeed seem a bit archaic. reply bbor 17 hours agorootparentAh okay saw the textbook publish date and stupidly assumed that was the overall date. Thanks, makes sense! In that case this is a fascinating look into the past and a testament to how solid these principle are, since they’ve endured and popped up in similar lists. reply sib 17 hours agoparentprevNo drama, just history! Ben Shneiderman&#x27;s been doing \"UX\" research since before it was a defined term (previously called \"Human-Computer Interaction\" or even \"Man-Machine Interfaces\"). He was my thesis advisor in the early 1990&#x27;s and first published these guidelines in the 1980&#x27;s. reply marapuru 7 hours agoparentprevThis post also reminded me of Nielsens&#x27; Heuristics. I can still recall them by heart and never heard of Shneiderman.I can&#x27;t shake the feeling that Nielsen (& Norman) simply marketed and productized their principles way better. reply jonstewart 17 hours agoparentprevBen Schneiderman is an ACM Fellow and CS professor emeritus of the University of Maryland-College Park. These 8 principles are from his 1986 book. He’s done a lot of work in infovis and HCI and is the inventor of the treemap visualization.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Ben_Shneiderman reply DonHopkins 16 hours agoparentprevnext [1 more] Donald Norman and Ben Shneiderman are old friends and colleagues.https:&#x2F;&#x2F;www.nngroup.com&#x2F;news&#x2F;item&#x2F;hci-pioneers-photos&#x2F;NN&#x2F;g News; HCI Pioneers Photos; Announcements; September 8, 2015Professor Ben Shneiderman (University of Maryland) is one of the founders of the discipline of human-computer interaction (HCI) and has produced breakthrough research and influential textbooks since the early 1980s. He is also an accomplished photographer from a family of world-class photographers. Dr. Shneiderman has now released a website that collects many of his photographs from the last 32 years of the field&#x27;s other pioneers, including Jakob Nielsen and Don Norman. It&#x27;s amazing how young they look in the early photos :-)https:&#x2F;&#x2F;hcipioneers.wordpress.com&#x2F;Shneiderman&#x27;s comment on launching this history site: \"My goal is to make HCI more visible and tell our history more widely. I think HCI designs have had as much impact as Moore’s Law in bringing the web and mobile devices to the world.\"Since this is a photohistory, it&#x27;s much more approachable than most history sites. Well worth perusing for anybody with an interest in where we come from.----Ben Shneiderman coined and defined the term \"Direct Manipulation\":http:&#x2F;&#x2F;www.csc.kth.se&#x2F;utbildning&#x2F;kth&#x2F;kurser&#x2F;DH3050&#x2F;hcihist11...https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11365359DonHopkins on March 27, 2016next [–]Wow, Ben Shneiderman looks so young in that photo. He&#x27;s still hard at work making computers easier for people to use, and he just published a major update to his classic book, \"Designing the User Interface: Strategies for Effective Human-Computer Interaction\", which just went to the printers and will be available on April 26. [1]I enjoyed working with him at the University of Maryland Human Computer Interaction Lab, and the experience deeply influenced everything I&#x27;ve done since.Ben is the human who suggested the field be called \"Human Computer Interaction\" instead of \"Computer Human Interaction\", to put humans first.He defined the term Direct Manipulation [2] as:1) continuous representation of the objects and actions,2) rapid, incremental, and reversible actions, and3) physical actions and gestures to replace typed commands.He also came up with the blue underlined hypertext link, as well as embedded graphical links [3] for the \"HyperTIES\" system [4].Here&#x27;s a paper I published when I was at HCIL, about a visual PostScript programming environment that featured \"direct stack manipulation\": \"The Shape of PSIBER Space - October 1989\". [5]Ben&#x27;s an avid photographer, and has published this photo history of SIGCHI conferences. [6][1] http:&#x2F;&#x2F;www.amazon.com&#x2F;Designing-User-Interface-Human-Compute...[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Direct_manipulation_interface[3] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=fZi4gUjaGAM[4] http:&#x2F;&#x2F;www.cs.umd.edu&#x2F;hcil&#x2F;hyperties&#x2F;[5] http:&#x2F;&#x2F;www.donhopkins.com&#x2F;drupal&#x2F;node&#x2F;97[6] http:&#x2F;&#x2F;www.sigchi.org&#x2F;photohistory&#x2F;lib_viewer.jsp?lib=chi----Ben Shneiderman founded the University of Maryland Human Computer Interaction Lab, but instead of calling it \"Computer Human Interaction\" like CHI, he put Humans first instead of Computers.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35736775*4 points by DonHopkins 8 months agorootparentprevnext [–]That&#x27;s a point Ben Shneiderman insisted on making in 1983, when he named his \"Human Computer Interaction Lab\" at the University of Maryland HCIL instead of CHIL, where I worked with him from 1986-1990. Go Terps! ;)Do you have any citations of European or other labs using that human-first convention before 1983?University of Maryland Human–Computer Interaction Lab:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;University_of_Maryland_Human%E...Ben Shneiderman:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ben_ShneidermanBen also coined the term \"Direct Manipulation\", and came up with the design of making links blue for the early HyperTIES hypermedia system we developed at HCIL.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Direct_manipulation_interfaceRevisiting why hyperlinks are blue (blog.mozilla.org):https:&#x2F;&#x2F;blog.mozilla.org&#x2F;en&#x2F;internet-culture&#x2F;why-are-hyperli...https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29897811https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29921532>Ben Shneiderman recalled that \"Tim told me at the time that he was influenced by our design as he saw it in the Hypertext on Hypertext project\".Hypertext on Hypertext CACM1988:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=29b4O2xxeqg30 YEARS AT THE UNIVERSITY OF MARYLAND’S HUMAN-COMPUTER INTERACTION LAB (HCIL). (2013) By Ben Shneiderman, Kent Norman, Catherine Plaisant, Benjamin Bederson, Allison Druin, Jennifer Golbeck:http:&#x2F;&#x2F;interactionsdev.acm.org&#x2F;archive&#x2F;view&#x2F;september-octobe...>One attraction of the University of Maryland was its strong psychology department. My computing colleagues were intrigued by my early attempts to use empirical techniques to study programmers as they wrote, modified, or debugged programs. These crossover ideas caught the attention of Azriel Rosenfeld (1931–2004), a world leader in computer vision, who was forming an interdisciplinary Center for Automation Research (CfAR). He led the Computer Vision Lab and invited me to form a Human-Computer Interaction Lab when he launched CfAR in 1983. In a campus reorganization, HCIL became a unit in the Institute for Advanced Computer Studies and eventually became jointly managed with the iSchool.>Rosenfeld&#x27;s invitation advanced my efforts by at least five years, giving credibility to the \"marriage of computer science and psychology,\" which I described in my 1980 book, Software Psychology. Gaining credibility was important, as this was still a time when many computer scientists were unsure about the value of psychological studies of programmers and database systems&#x27; users, and even the growing field of interactive computer systems. The term human-computer interaction (HCI) was still novel, but I insisted on putting the human first, as opposed to the ACM&#x27;s choice of computer-human interaction to make a more pronounceable name, \"CHI.\"Ken Perlin:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ken_PerlinKen Perlin&#x27;s Blog:http:&#x2F;&#x2F;blog.kenperlin.com&#x2F;?p=237>Human first (May 29th, 2008)>I spent the day today at the annual end-of-year symposium of the Human Computer Interaction Lab (HCIL) at the University of Maryland. All three of the Lab’s successive directors – Ben Shneiderman, Ben Bederson and Allison Druin – were there, and they are all good friends of mine. Ben Shneiderman founded the lab in 1983. He is one of the fathers of the field of HCI research, and is a font of wisdom on many subjects. Ben Bederson, with whom I’ve been friends since he was in grad school, took over the lab directorship in 2000. Allison, who is married to Ben Bederson, became the lab’s director in 2006. I actually know Allison the longest of the three. I have had lots of time to talk with all three of them in the last twenty four hours, which has been great fun.>The wonderful thing about the HCIL, as Allison pointed out today, is that it puts the “human” first. Much of computer science research seems to forget that there are such things as humans. Instead it seems to be a quest for a kind of abstract algorithmic purity, as though computer science were merely a branch of mathematics. The HCIL people have been way ahead of the curve in recognizing that the real power of computers comes when we find ways to interweave that power with the complementary power of the human mind. Computation is indeed enormously powerful, but computation that augments human thought is downright transformative. And to achieve that, you’ve got to understand human thought.>This is rather tricky for many academics, because it requires bridging the large gap in scientific subcultures between computer science on the one hand, and psychology on the other. It’s very hard to get academic recognition when any given reviewer of your manuscript is not going to understand half of what you are saying. To me the people at HCIL are visionary because they recognized, a full quarter of a century ago – long before it was fashionable – the need to reconcile these two parts of the problem.>And they are still at it. Only now the world is starting to catch up.>Ben Shneiderman says on June 3, 2008 at 8:12 pm:>Thanks Ken… for your kind words and thoughtful contribution to the 25th Anniversary events…. it’s great to see that our message was heard and received in a warm human way. Sincerely… Ben ShneidermanDesigning to Facilitate Browsing: A Look Back at the Hyperties Workstation Browser: By Ben Shneiderman, Catherine Plaisant, Rodrigo Botafogo, Don Hopkins, William Weiland. Published in Hypermedia, vol. 3, 2 (1991)101–117.https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;designing-to-facilitate-browsi...HyperTIES Discussions from Hacker News:https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;hyperties-discussions-from-hac...An Empirical Comparison of Pie vs. Linear Menus: Jack Callahan, Don Hopkins, Mark Weiser () and Ben Shneiderman. Computer Science Department University of Maryland College Park, Maryland 20742 () Computer Science Laboratory, Xerox PARC, Palo Alto, Calif. 94303. Presented at ACM CHI’88 Conference, Washington DC, 1988.https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;an-empirical-comparison-of-pie... reply kazinator 16 hours agoprev [–] Where are the apps shipped by umn.edu? reply subroutine 16 hours agoparentUniversities teach students about a lot of things they don&#x27;t actually create themselves. reply DonHopkins 15 hours agoparentprev [2 more] What does the University of Minnesota Twin Cities have to do with this discussion? And why do you care which apps a university research lab shipped? ;)If you want to know about what contributions Ben Shneiderman and his University of Maryland Human Computer Interaction Lab have made, you can read my other post:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38920423Or wikipedia:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ben_Shneidermanhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;University_of_Maryland_Human%E...Or Ben Shneiderman&#x27;s home page:https:&#x2F;&#x2F;www.cs.umd.edu&#x2F;users&#x2F;ben&#x2F;One app that the UMD Human Computer Interaction Lab shipped in several versions was HyperTIES, which was used to implement “Hypertext on Hypertext” that ACM distributed with the articles from the July 1987 Hypertext conference, which influenced Tim Berners-Lee to make hypertext links blue:The Interactive Encyclopedia System:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Interactive_Encyclopedia_S...HyperTIES Discussions from Hacker News:https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;hyperties-discussions-from-hac...>Don Hopkins sent the following message at 10:07 AM, AUG 28, 2021>Why are hyperlinks blue?>Hello Elise. Here is some information about why hyperlinks are blue, from Ben Shneiderman’s answer to a question I asked him about the origin of the term “hyperlink”. I think your belief that HyperTIES was not the first instance of blue hyperlinks because it used cyan links is splitting hairs, and a “No Blue Scotsman” argument, especially since Tim Berners-Lee told Ben Sheniderman at the time that he was influenced by Ben’s design as he saw it in the HyperTIES-based “Hypertext on Hypertext” that ACM distributed with the articles from the July 1987 Hypertext conference at the University of North Carolina. Ben describes the color as “light blue”, which he chose from the limited palette available on PCs at the time, based on controlled experiments he and his students performed comparing user comprehension and recollection.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28317104HI Don (and Jack Gilmore),Thanks for including me in this conversation.I do not have a claim for the term “hyperlinks” and don’t know when it came into use. My claim is for the visual interface for showing highlighted selectable links embedded in paragraphs. This is what we called embedded menu items in that I think is an influential paper on the topic, which was peer-reviewed and published in the CACM in April 1986.https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;5684.5687http:&#x2F;&#x2F;www.cs.umd.edu&#x2F;~ben&#x2F;papers&#x2F;Koved1986Embedded.pdfWhile Engelbart had shown a list that could be selected by pointing and clicking in 1968, I claim the idea of embedded highlighted selectable text in paragraphs. This was implemented by grad student Daniel Ostroff and described in:Ewing J, Mehrabanzad S, Sheck S, Ostroff D and Shneiderman B (1986), \"An experimental comparison of a mouse and arrow-jump keys for an interactive encyclopedia\", International Journal of Man-Machine Studies, Jan., 1986, Vol 24, pp. 29-45.[Abstract] [BibTeX] [DOI]Ostroff D and Shneiderman B (1988), \"Selection devices for users of an electronic encyclopedia: an empirical comparison of four possibilities\", Information Processing and Management, Nov., 1988, Vol 24(6), pp. 665-680.[Abstract] [BibTeX] [DOI]I think the 1988 paper was the earlier study, but the publication took a while.My students conducted more than a dozen experiments (unpublished) on different ways of highlighting and selection using current screens, e.g. green screens only permitted, bold, underscore, blinking, and I think italic(???). When we had a color screen we tried different color highlighted links. While red made the links easier to spot, user comprehension and recollection of the content declined. We chose the light blue, which Tim adopted.His systems with embedded menus (or hot spots), where a significant user interface improvement over early systems such as Gopher. But Tim told me at the time that he was influenced by our design as he saw it in the Hypertext on Hypertext project that we used Hyperties to build for the July 1988 CACM that held the articles from the July 1987 Hypertext conference at the University of North Carolina. The ACM sold 4000 copies of our Hypertext on Hypertext disks.Our history is here:https:&#x2F;&#x2F;www.cs.umd.edu&#x2F;hcil&#x2F;hyperties&#x2F;and the video is very helpful in showing the design we used, which is what I think Tim built on for his WWW prototypes.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=29b4O2xxeqgSo in summary, I don’t know who coined hypertext, but I do think our work visual and interaction design was influential.Our Hyperties system was picked up by Cognetics Corporation (around 1987) who made a modestly successful commercial run with it, doing dozens of corporate projects, most notably the Hewlett-Packard user manual for their Laserjet 4 was distributed as a Hyperties disk.Hyperties was the name we shifted to after we got a stop and desist order from a lawyer because our TIES (The Interactive Encyclopedia System) conflicted with an existing product. By then “hyper” was a growing term.Let me know if this helps, and what other questions you have…. Ben----HCIL also shipped various treemapping applications:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Treemapping>Area-based visualizations have existed for decades. For example, mosaic plots (also known as Marimekko diagrams) use rectangular tilings to show joint distributions (i.e., most commonly they are essentially stacked column plots where the columns are of different widths). The main distinguishing feature of a treemap, however, is the recursive construction that allows it to be extended to hierarchical data with any number of levels. This idea was invented by professor Ben Shneiderman at the University of Maryland Human – Computer Interaction Lab in the early 1990s. [21][22] Shneiderman and his collaborators then deepened the idea by introducing a variety of interactive techniques for filtering and adjusting treemaps.https:&#x2F;&#x2F;www.cs.umd.edu&#x2F;~ben&#x2F;papers&#x2F;Johnson1991Tree.pdfhttps:&#x2F;&#x2F;treemapart.wordpress.com&#x2F; reply bluGill 13 hours agorootparent [–] To someone in Minnesota umd means university of Minnesota Duluth campus. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Ben Shneiderman, an expert in user interface design, has identified eight golden rules for interface design.",
      "These rules encompass principles such as consistency, usability, informative feedback, dialog design, error prevention, action reversal, user control, and reducing memory load.",
      "Following these principles can help designers create effective interfaces that improve user productivity and sense of competence and control."
    ],
    "commentSummary": [
      "The conversation explores various aspects of interface design, including consistency, usability, and aesthetic appeal.",
      "It discusses the use of pie menus, frustrations caused by inconsistent interfaces, and the importance of clear communication and feedback in UI design.",
      "Notable figures in the field of HCI, like Ben Shneiderman, are referenced for their contributions to user interface design."
    ],
    "points": 259,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1704741307
  },
  {
    "id": 38914764,
    "title": "An Overview of Distributed PostgreSQL Architectures",
    "originLink": "https://www.crunchydata.com/blog/an-overview-of-distributed-postgresql-architectures",
    "originBody": "Production Postgres An Overview of Distributed PostgreSQL Architectures Marco Slot Marco Slot Jan 8, 2024·16 min read I've always found distributed systems to be the most fascinating branch of computer science. I think the reason is that distributed systems are subject to the rules of the physical world just like we are. Things are never perfect, you cannot get everything you want, you’re always limited by physics, and often by economics, or by who you can communicate with. Many problems in distributed systems simply do not have a clean solution, instead there are different trade-offs you can make. While at Citus Data, Microsoft, and now Crunchy Data, the focus of my work has been on distributed PostgreSQL architectures. At the last PGConf.EU in December, I gave a talk titled “PostgreSQL Distributed: Architectures & Best Practices” where I went over various kinds of distributed PostgreSQL architectures that I’ve encountered over the years. Many distributed database discussions focus on algorithms for distributed query planning, transactions, etc. These are very interesting topics, but the truth is that only a small part of my time as a distributed database engineer goes into algorithms, and an excessive amount of time goes into making very careful trade-offs at every level (and of course, failure handling, testing, fixing bugs). Similarly, what many users notice within the first few minutes of using a distributed database is how unexpectedly slow they can be, because you quickly start hitting performance trade-offs. There are many types of distributed PostgreSQL architectures, and they each make a different set of trade-offs. Let’s go over some of these architectures. Single machine PostgreSQL To set the stage for discussing distributed PostgreSQL architectures, we first need to understand a bit about the simplest possible architecture: running PostgreSQL on a single machine, or \"node\". PostgreSQL on a single machine can be incredibly fast. There’s virtually no network latency on the database layer and you can even co-locate your application server. Millions of IOPS are available depending on the machine configuration. Disk latency is measured in microseconds. In general, running PostgreSQL on a single machine is a performant and cost-efficient choice. So why doesn’t everyone just use a single machine? Many companies do. However, PostgreSQL on a single machine comes with operational hazards. If the machine fails, there’s inevitably some kind of downtime. If the disk fails, you’re likely facing some data loss. An overloaded system can be difficult to scale. And you’re limited to the storage size of a disk, which when full will cease to process and store data. That very low latency and efficiency clearly comes at a price. Distributed PostgreSQL architectures are ultimately trying to address the operational hazards of a single machine in different ways. In doing so, they do lose some of its efficiency, and especially the low latency. Goals of a Distributed Database Architecture The goal of a distributed database architecture is to try to meet the availability, durability, performance, regulatory, and scale requirements of large organizations, subject the physics. The ultimate goal is to do so with the same rich functionality and precise transactional semantics as a single node RDBMS. There are several mechanisms that distributed database systems employ to achieve this, namely: Replication - Place copies of data on different machines Distribution - Place partitions of data on different machines Decentralization - Place different DBMS activities on different machines In practice, each of these mechanisms inherently comes with concessions in terms of performance, transactional semantics, functionality, and/or operational complexity. To get a nice thing, you’ll have to give up a nice thing, but there are many different combinations of what you can get and what you need to give up. The importance of latency in OLTP systems Of course, distributed systems have already taken over the world, and most of the time we don’t really need to worry a lot about trade-offs when using them. Why would distributed database systems be any different? The difference lies in a combination of storing the authoritative state for the application, the rich functionality that an RDBMS like PostgreSQL offers, and the relatively high impact of latency on client-perceived performance in OLTP systems. PostgreSQL, like most other RDBMSs, uses a synchronous, interactive protocol where transactions are performed step-by-step. The client waits for the database to answer before sending the next command, and the next command might depend on the answer to the previous. Any network latency between client and database server will already be a noticeable factor in the overall duration of a transaction. When PostgreSQL itself is a distributed system that makes internal network round trips (e.g. while waiting for WAL commit), the duration can get many times higher. Why is it bad for transactions to take longer? Surely humans won’t notice if they need to wait 10-20ms? Well, if transactions take on average 20ms, then a single (interactive) session can only do 50 transactions per second. You then need a lot of concurrent sessions to actually achieve high throughput. Having many sessions is not always practical from the application point-of-view, and each session uses significant resources like memory on the database server. Most PostgreSQL set ups limit the maximum number of sessions in the hundreds or low thousands, which puts a hard limit on achievable transaction throughput when network latency is involved. In addition, any operation that is holding locks while waiting for network round trips is also going to affect the achievable concurrency. While in theory, latency does not have to affect performance so much, in practice it almost always does. The CIDR ‘23 paper “Is Scalable OLTP in the Cloud a solved problem?” gives a nice discussion of the issue of latency in section 2.5. PostgreSQL Distributed Architectures PostgreSQL can be distributed at many different layers that hook into different parts of its own architecture and make different trade-offs. In the following sections, we will discuss these well-known architectures: Network-attached block storage (e.g. EBS) Read replicas DBMS-optimized cloud storage (e.g. Aurora) Active-active (e.g. BDR) Transparent Sharding (e.g. Citus) Distributed key-value stores with SQL (e.g. Yugabyte) We will describe the pros and cons of each architecture, relative to running PostgreSQL on a single machine. Note that many of these architectures are orthogonal. For instance, you could have a sharded system with read replicas using network-attached storage, or an active-active system that uses DBMS-optimized cloud storage. Network-attached block storage Network-attached block storage is a common technique in cloud-based architectures where the database files are stored on a different device. The database server typically runs in a virtual machine in a Hypervisor, which exposes a block device to the VM. Any reads and writes to the block device will result in network calls to a block storage API. The block storage service internally replicates the writes to 2-3 storage nodes. Practically all managed PostgreSQL services use network-attached block devices because the benefits are critical to most organizations. The internal replication results in high durability and also allows the block storage service to remain available when a storage node fails. The data is stored separately from the database server, which means the database server can easily be respawned on a different machine in case of failure, or when scaling up/down. Finally, the disk itself is easily resizable and supports snapshots for fast backups and creating replicas. Getting so many nice things does come at a significant performance cost. Where modern Nvme drives generally achieve over >1M IOPS and disk latency in the tens of microseconds, network-attached storage is often below 10K IOPS and >1ms disk latency, especially for writes. That is a ~2 order of magnitude difference. Pros: Higher durability (replication) Higher uptime (replace VM, reattach) Fast backups and replica creation (snapshots) Disk is resizable Cons: Higher disk latency (~20μs -> ~1000μs) Lower IOPS (~1M -> ~10k IOPS) Crash recovery on restart takes time Cost can be high 💡 Guideline: the durability and availability benefits of network-attached storage usually outweigh the performance downsides, but it’s worth keeping in mind that PostgreSQL can be much faster. Read replicas PostgreSQL has built-in support for physical replication to read-only replicas. The most common way of using a replica is to set it up as a hot standby that takes over when the primary fails in a high availability set up. There are many blogs, books, and talks describing the trade-offs of high availability set ups, so in this post I will focus on other architectures. Another common use for read replicas is to help you scale read throughput when reads are CPU or I/O bottlenecked by load balancing queries across replicas, which achieves linear scalability of reads and also offloads the primary, which speeds up writes! A challenge with read replicas is that there is no prescribed way of using them. You have to decide on the topology and how you query them, and in doing so you will be making distributed systems trade-offs yourself. The primary usually does not wait for replication when committing a write, which means read replicas are always slightly behind. That can become an issue when your application does a read that, from the user’s perspective, depends on a write that happened earlier. For example, a user clicks “Add to cart”, which adds the item to the shopping cart and immediately sends the user to the shopping cart page. If reading the shopping cart contents happens on the read replica, the shopping cart might then appear empty. Hence, you need to be very careful about which reads use a read replica. Even if reads do not directly depend on a preceding write, at least from the client perspective, there may still be strange time travel anomalies. When load balancing between different nodes, clients might repeatedly get connected to different replica and see a different state of the database. As distributed systems engineers, we say that there is no “monotonic read consistency”. Another issue with read replicas is that, when queries are load balanced randomly, they will each have similar cache contents. While that is great when there are certain extremely hot queries, it becomes painful when the frequently read data (working set) no longer fits in memory and each read replica will be performing a lot of redundant I/O. In contrast, a sharded architecture would divide the data over the memory and avoid I/O. Read replicas are a powerful tool for scaling reads, but you should consider whether your workload is really appropriate for it. Pros: Read throughput scales linearly Low latency stale reads if read replica is closer than primary Lower load on primary Cons: Eventual read-your-writes consistency No monotonic read consistency Poor cache usage 💡 Guideline: Consider using read replicas when you need >100k reads/sec or observe a CPU bottleneck due to reads, best avoided for dependent transactions and large working sets. DBMS-optimized cloud storage There are a number of cloud services now like Aurora and AlloyDB that provide a network-attached storage layer that is optimized specifically for a DBMS. In particular, a DBMS normally performs every write in two different ways: Immediately to the write-ahead log (WAL), and in the background to a data page (or several pages, when indexes are involved). Normally, PostgreSQL performs both of these writes, but in the DBMS-optimized storage architecture the background pages writes are performed by the storage layer instead, based on the incoming WAL. This reduces the amount of write I/O on the primary node. The WAL is typically replicated directly from the primary node to several availability zones to parallelize the network round trips, which increases I/O again. Always writing to multiple availability zones also increases the write latency, which can result in lower per-session performance. In addition, read latency can be higher because the storage layer does not always materialize pages in memory. Architecturally, PostgreSQL is also not optimized for these storage characteristics. While the theory behind DBMS-optimized storage is sound. In practice, the performance benefits are often not very pronounced (and can be negative), and the cost can be much higher than regular network-attached block storage. It does offer a greater degree of flexibility to the cloud service provider, for instance in terms of attach/detach times, because storage is controlled in the data plane rather than the hypervisor. Pros: Potential performance benefits by avoiding page writes from primary Replicas can reuse storage, incl. hot standby Can do faster reattach, branching than network-attached storage Cons: Write latency is high by default High cost / pricing PostgreSQL is not designed for it, not OSS 💡 Guideline: Can be beneficial for complex workloads, but important to measure whether price-performance under load is actually better than using a bigger machine. Active-active In the active-active architecture any node can locally accept writes without coordination with other nodes. It is typically used with replicas in multiple sites, each of which will then see low read and write latency, and can survive failure of other sites. These benefits are phenomenal, but of course come with a significant downside. First, you have the typical eventual consistency downsides of read replicas. However, the main challenge with an active-active setup is that update conflicts are not resolved upfront. Normally, if two concurrent transactions try to update the same row in PostgreSQL, the first one will take a “row-level lock”. In case of active-active, both updates might be accepted concurrently. For instance, when you perform two simultaneous updates of a counter on different nodes, the nodes might both see 4 as the current value and set the new value to 5. When replication happens, they’ll happily agree that the new value is 5 even though there were two increment operations. Active-active systems do not have a linear history, even at the row level, which makes them very hard to program against. However, if you are very prepared to live with that, the benefits could be attractive especially for very high availability. Pros: Very high read and write availability Low read and write latency Read throughput scales linearly Cons: Eventual read-your-writes consistency No monotonic read consistency No linear history (updates might conflict after commit) 💡 General guideline: Consider only for very simple workloads (e.g. queues) and only if you really need the benefits. Transparent sharding Transparent sharding systems like Citus distribute tables by a shard key and/or replicate tables across multiple primary nodes. Each node shows the distributed tables as if they were regular PostgreSQL tables and queries & transactions are transparently routed or parallelized across nodes. Data is stored in shards, which are regular PostgreSQL tables, which can take advantage of indexes, constraints, etc. In addition, the shards can be co-located by the shard key (in “shard groups”), such that joins and foreign keys that include the shard key can be performed locally. The advantage of distributing the data this way is that you can take advantage of the memory, IO bandwidth, storage, and CPU of all the nodes in an efficient manner. You could even ensure that your data or at least your working set always fits in memory by scaling out. Scaling out transactional workloads is most effective when queries have a filter on the shard key, such that they can be routed to a single shard group (e.g. single tenant in a multi-tenant app). That way, there is only a marginal amount of overhead compared to running a query on a single server, but you have a lot more capacity. Another effective way of scaling out is when you have compute-heavy analytical queries that can be parallelized across the shards (e.g. time series / IoT). However, there is also higher latency, which reduces the per-session throughput compared to a single machine. And, if you have a simple lookup that does not have a shard key filter, you will still experience all the overhead of parallelizing the query across nodes. Finally, there may be restrictions in terms of data model (e.g. unique and foreign constraints must include shard key), SQL (non-co-located correlated subqueries), and transactional guarantees (snapshot isolation only at shard level). Using a sharded system often means that you will need to adjust your application to deal with higher latency and a more rigid data model. For instance, if you are building a multi-tenant application you will need to add tenant ID columns to all your tables to use as a shard key, and if you are currently loading data using INSERT statements then you might want to switch to COPY to avoid waiting for every row. If you are willing to adjust your application, sharding can be one of the most powerful tools in your arsenal for dealing with data-intensive applications. Pros: Scale throughput for reads & writes (CPU & IOPS) Scale memory for large working sets Parallelize analytical queries, batch operations Cons: High read and write latency Data model decisions have high impact on performance Snapshot isolation concessions 💡 General guideline: Use for multi-tenant apps, otherwise use for large working set (>100GB) or compute heavy queries. Distributed key-value storage with SQL About a decade ago, Google Spanner introduced the notion of a distributed key-value store that supports transactions across nodes (key ranges) with snapshot isolation in a scalable manner by using globally synchronized clocks. Subsequent evolutions of Spanner then added a SQL layer on top, and ultimately even a PostgreSQL interface. Open source alternatives like CockroachDB and Yugabyte followed a similar approach without the requirement of synchronized clocks, at the cost of significantly higher latency. These systems have built on top of existing key-value storage techniques for availability and scalability, such as shard-level replication and failover using Paxos or Raft. Tables are then stored in the key-value store, with the key being a combination of the table ID and the primary key. The SQL engine is adjusted accordingly, distributing queries where possible. In my view, the relational data model (or, your typical PostgreSQL app) is not well-served by using a distributed key-value store underneath. Related tables and indexes are not necessarily stored together, meaning typical operations such as joins and evaluating foreign keys or even simple index lookups might incur an excessive number of internal network hops. The relatively strong transactional guarantees that involve additional locks and coordination can also become a drag on performance. In comparison to PostgreSQL or Citus, performance and efficiency are often disappointing. However, these systems offer much richer (PostgreSQL-like) functionality than existing key-value stores, and better scalability than consensus stores like etcd, so they can be a great alternative for those. Pros: Good read and write availability (shard-level failover) Single table, single key operations scale well No additional data modeling steps or snapshot isolation concessions Cons: Many internal operations incur high latency No local joins in current implementations Not actually PostgreSQL, and less mature and optimized 💡 General guideline: Just use PostgreSQL 😉 For simple applications, the availability and scalability benefits can be useful. Conclusion PostgreSQL can be distributed at different layers. Each architecture can introduce severe trade-offs. Almost nothing comes for free. When deciding on the database architecture, keep asking yourself: What do I really want? Which architecture achieves that? What are the downsides? What can my application tolerate? (can I change my application?) Even with state-of-the-art tools, deploying a distributed database system is never a solved problem, and perhaps never will be. You will need to spend some time understanding the trade-offs. I hope this blog post will help. If you’re still feeling a bit lost, our PostgreSQL experts at Crunchy Data will be happy to help you pick the right architecture for your application. Enjoy this article? You will love our newsletter! Do not fill this out please: Do not fill this out please, it will be pre-filled: Email address Join The List Written by Marco Slot January 8, 2024 •More by this author",
    "commentLink": "https://news.ycombinator.com/item?id=38914764",
    "commentBody": "An overview of distributed Postgres architecturesHacker NewspastloginAn overview of distributed Postgres architectures (crunchydata.com) 252 points by eatonphil 18 hours ago| hidepastfavorite39 comments chuckhend 2 minutes ago> Guideline: the durability and availability benefits of network-attached storage usually outweigh the performance downsides, but it’s worth keeping in mind that PostgreSQL can be much faster.I think it often goes overlooked just how slow network attached block storage is though, and some organizations get very surprised when moving from an on-prem data center to cloud. reply magden 11 hours agoprevFirst time seeing someone call Spanner, CockroachDB, and YugabyteDB a \"distributed key-value store with SQL\" :)The cons of the mentioned distributed shared-nothing SQL databases are questionable:- \"Key-value store\" is in fact an LSM-tree-based document store that supports column-level versioning (Postgres supports row-level versioning only).- \"Many internal operations incur high latency.\" - I guess this conclusion is based on the referenced Gigaom benchmark that was paid for by Microsoft to compare apples to oranges.- \"No local joins in current implementations.\" (YugabyteDB certainly has colocated tables that store a whole table on a single node. CockroachDB and Spanner might do this as well.)- \"Not actually PostgreSQL...\" - There is only one 100% compatible database with Postgres...It&#x27;s Postgres itself. Citus, CockroachDB, Aurora, Alloy, YugabyteDB, and others can be classified as \"not actually Postgres.\"- \"And less mature and optimized.\" - Well, both CockroachDB and YugabyteDB are on Gartner&#x27;s Magic Quadrant of the top 20 cloud databases. Toys don&#x27;t get there.It feels like the author joined Crunchy to work on their own distributed version of Postgres. Good move for Crunchy, good luck! reply seedless-sensat 11 hours agoparentI think this con is very real:> Related tables and indexes are not necessarily stored together, meaning typical operations such as joins and evaluating foreign keys or even simple index lookups might incur an excessive number of internal network hops. The relatively strong transactional guarantees that involve additional locks and coordination can also become a drag on performance.You handwaved this away saying you can just store an entire table on a single node, but that defeats many of the benefits of these sharded SQL databases.Edit: Also, before attacking the author&#x27;s biases, it seems fair to disclose you appear to work at Yugabyte reply magden 2 hours agorootparent> You handwaved this away, saying you can just store an entire table on a single node, but that defeats many of the benefits of these sharded SQL databases.I just clarified one-liners listed under the closing \"Cons\" section. My intention was not to say that the author is utterly wrong. Marco is a recognized expert in the Postgres community. It only feels like he was too opinionated about distributed SQL DBs while wearing his Citus hat.> Also, before attacking the author&#x27;s biases, it seems fair to disclose that you appear to work at Yugabyte.I&#x27;m sorry if I sounded biased in my response. I&#x27;m with the YugabyteDB team right now, but that&#x27;s not my first and I bet not the last database company. Thus, when I respond on my personal accounts, I try to be as objective as possible and don&#x27;t bother mentioning my current employment.Anyway, I&#x27;m very positive to see that this article got traction on HN. As a Postgres community member, I truly love what&#x27;s happening with the database and its ecosystem. The healthy competition within the Postgres ecosystem is a big driver for the database growth that&#x27;s becoming the Linux of databases. reply franckpachot 3 hours agorootparentprevIn the case of YugabyteDB, here is how we avoid \"excessive number\" of networks hops- true Index Only Scan. PostgreSQL doesn&#x27;t store the MVCC visibility in indexes and have to look at the table even in case of Index Only Scan. YugabyteDB has a different implementation of MVCC with no bloat, no vacuum and true Index Only Scan. Here is an example: https:&#x2F;&#x2F;dev.to&#x2F;yugabyte&#x2F;boosts-secondary-index-queries-with-... This is also used for reference table (duplicate covering indexes in each regions)- Batching reads and writes. It is not a problem to add 10ms because you join two tables or check a foreign key. What would be problematic is doing that for each rows. YugabyteDB batches the read&#x2F;write operations as much as possible. Here are two examples: https:&#x2F;&#x2F;dev.to&#x2F;franckpachot&#x2F;series&#x2F;25365- Pushdowns to avoid sending rows that are discarded later. Each node can apply PostgreSQL expressions to offload filtering to the storage nodes. Examples: https:&#x2F;&#x2F;dev.to&#x2F;yugabyte&#x2F;yugabytedb-predicate-push-down-pbb- Loose index scan. With YugabyteDB LSM-Tree indexes, one index scan can read multiple ranges, which avoids multiple roundtrips. An example: https:&#x2F;&#x2F;dev.to&#x2F;yugabyte&#x2F;select-distinct-pushdown-to-do-a-loo...- Locality of transaction table. If a transaction touches to only one node, or zone, or region, a local transaction table is used, and is promoted to the right level depending on what the transaction reads and writes.Most of the times when I&#x27;ve seen people asking to store tables together, it was premature optimization, based on opinions rather than facts. When they try (with the right indexes of course) they appreciate that the distribution is an implementation detail that the application doesn&#x27;t have to know. Of course, there are more and more optimizations in each release. If you have a PostgreSQL application and see low performance, please open a git issue.I&#x27;m also working for Yugabyte as Developer Advocate. I don&#x27;t always feel the need to precise it as I&#x27;m writing about facts, not marketing opinions, and who pays my salary has no influence on the response time I see in execution plans ;) reply dikei 6 hours agoparentprev>> First time seeing someone call Spanner, CockroachDB, and YugabyteDB a \"distributed key-value store with SQL\"That was the first thing come to my mind when I read the paper on Spanner and CockroachDB (haven&#x27;t read the paper on YugabyteDB yet) though, and surely I&#x27;m not the only one. reply ManBeardPc 13 hours agoprevVery good overview and easy to read. In recent years I‘ve encountered more and more businesses that use or want to use Postgres instead of other proprietary or NoSQL databases, so this post is very useful. reply franckpachot 9 hours agoparentThe article is a marketing promotion for Citus. They ignore Neon, a major innovation in distributed cloud storage solutions. They reduce Distributed SQL to key-value stores, when it is actually the only distributed architecture that preserves all SQL features (ACID, consistent reads, referential integrity, global indexes).And the only fact about performance is a benchmark comparing elastic and resilient distributed SQL to non-HA Citus running on larger machines. reply ManBeardPc 7 hours agorootparentBig parts of the article are pretty generic concepts and only mention other products as an example. Haven&#x27;t heard of Neon yet. What does Neon do differently? Is there a good introduction&#x2F;overview?Good, fair and reproducible benchmarks are a rarity. Do you have any (independent) benchmarks that compare different distributed PostgreSQL-based solutions? reply tristan957 1 hour agorootparentHere is a blog post that should be a good dive into the Neon storage engine. I work at Neon, and am happy to answer any other questions you might have.https:&#x2F;&#x2F;neon.tech&#x2F;blog&#x2F;get-page-at-lsn reply franckpachot 3 hours agorootparentprevAll benchmarks are biased because nobody does the same level of config tuning on different databases. But this GigaOm&#x2F;Microsoft one is a joke. They run Citus with no replication on 12x16+1x32 vCores and the others on 14x16 vCPU (so 14x8 cores) with replication factor 3. reply ManBeardPc 1 hour agorootparentWithout good benchmarks it&#x27;s hardly possible to compare different products.But I agree that this benchmarks seems questionable at best then. I usually only work with on-premise deployments, so I don&#x27;t know the details of all the cloud offerings. People will probably judge products on what is available on the first few search results though. reply indymike 4 hours agorootparentprevNeon is a very confusing name, and honestly needs to be changed to something that can be distinct in the marketplace. reply franckpachot 3 hours agorootparentI mentioned Neon because it is open source and the article says \"Not OSS\" for \"DBMS-optimized cloud storage\". Think of it as open-source Aurora https:&#x2F;&#x2F;neon.tech&#x2F; reply asah 15 hours agoprevThis is great.One thing I&#x27;d add is a sense of scale - are these architectures for 100 queries per second or 100,000 or 100,000,000 ? reply craigkerstiens 15 hours agoparentMarco (author) is probably asleep at this point and could give a deeper perspective. He sort of hits on this when talking about disk latency... Depending on your setup and well just from some personal experience I know it&#x27;s not crazy for Postgres queries to go at 1ms per query. From there you can start to do some math on how many cores, how many queries per second, etc.Single node Postgres (with a beefy machine) can definitely manage in the 100k transactions per second. When you&#x27;re pushing the high 100k into millions read replicas is a common approach.When we&#x27;re talking transactions, question of is it simply basic queries, bigger aggregations, and is it writes or reads. Writes if you can manage to do any form of multi-line insert or batching with copy you can push basic Postgres really far... From some benchmarks Citus as mentioned can hit millions of records per second safely with those approaches, and even without Citus can get pretty high write throughput. reply franckpachot 10 hours agorootparentThe \"disappointing\" benchmark mentioned in the article is a shame for GigaOm who published it and for Microsoft who paid for it. They compare Citus with no HA to CockroachDB and YugabyteDB with replication factor 3 Multi-AZ, resilient to data center failure. And they run Citus on 16 cores (=32 vCPU) and the others on 16 vCPU. But your point about \"beefy machine\" shows the real advantages of Distributed SQL. PostgreSQL and Citus needs downtime to save cost if you don&#x27;t need that beefy machine all days all year. Scale up and down is downtime, as well as upgrades. Distributed SQL offers elasticity (no downtime to resize the cluster) and high availability (no downtime on failure or maintenance) reply AdamProut 15 minutes agorootparentRE: \"Distributed SQL offers elasticity (no downtime resize\"). I&#x27;m not sure this is as much of an advantage of distributed databases vs single host databases anymore. Some of the tech to move virtual machines between machines quickly (without dropping TCP connections) is pretty neat. Neon has a blog post about it here[1]. Aurora Serverless V2 does the same thing (but I can&#x27;t find a detailed technical blog post talking about how it works). Your still limited by \"one big host\" but its no longer as big of a deal to scale your compute up&#x2F;down within that limit.[1] https:&#x2F;&#x2F;neon.tech&#x2F;blog&#x2F;scaling-serverless-postgres reply mistrial9 14 hours agorootparentprevsecond yes to that - postgresql warm with plenty of RAM can do some fancy things and return an answer sub-millisecond toocache is King reply franckpachot 3 hours agorootparentbut large cache is expensive in the cloud and you cannot scale up&#x2F;down without downtime reply datadrivenangel 1 hour agorootparent4TB of ram is only $71 per hour on AWS RDS. If you&#x27;re at planetary scale that&#x27;s not bad. reply magden 11 hours agoparentprevScalability is not the only reason for jumping on a distributed Postgres version.Some apps might do just 1000 ops&#x2F;second but still run on a distributed database for high availability or data locality reasons. For instance, shared-nothing databases usually guarantee RPO=0 (no data loss, recovery point objective) with RTO (recovery time objective) measured in seconds for zone and region-level outages. As for data locality, think automatic data placement&#x2F;pinning to regions&#x2F;data centers for data regulatory and low latency reasons (serve read&#x2F;write requests equally fast for folks living in NYC, London, Tokyo). reply never_inline 8 hours agorootparentAny reason you can&#x27;t achieve those RPO&#x2F;RTO with straightforward replication? reply magden 4 hours agorootparentYou can achieve RPO=0 with Postgres using synchronous logical replication. You would need to replicate to 2+ standbys because if there is only one standby and it goes down then the primary will stuck. During the failover you would need to have Patroni or comparable tool, but I don’t know what’s the RTO.But once you outgrow the primary&#x2F;standbys severs storage or compute capacity you would need to scale to larger machines that can incur downtimes. With distributed Postgres such as YugabyteDB this is not gonna happen because you can scale horizontally reply feverzsj 10 hours agoprevIn my experience, HA stories of Postgres are always buggy and disappointing for homegrown systems. None of these tools actually gives you a solid HA like proprietary databases do. Managed database services can reduce or eliminate some of the problems, but you can&#x27;t put critical parts of your system on the cloud. reply sargun 7 hours agoparentHaving run Oracle RAC, MySQL circular replication, Postgres replication since 9.X, Amazon RDS, and others in production, I can say that Oracle RAC was the worst experience.We had to provide our own active &#x2F; active storage backend, and fabric. If there were any hiccups, the entire system fell over. The horizontal scalability was nice, but if you caused I&#x2F;O saturation on the backend, you&#x27;d end up knocking over the entire cluster due to shared components. Several times, the entire DB just \"broke\" (this was a couple scenarios, one where the DB was using 100% of CPU, one where the DB was frozen, and not allowing connections, and things like hung queries that couldn&#x27;t be stopped), and it required restarting the whole cluster, for which there was minimal tooling.Perhaps SQL server is better, but that comes with an entirely new ecosystem, and other problems.My biggest thing is being able to crack open the DB, and look at the source code when it breaks. In this, the likes of Datastax Cassandra and Cockroachdb are great, but I wouldn&#x27;t call them \"proprietary\" by any means. reply pi-e-sigma 1 hour agorootparentTo this day only Oracle RAC provides true active-active cluster. All the other things are not real clusters, just replications. reply magden 4 hours agoparentprevThere are good and solid HA options in the Postgres ecosystem that are fully open. You can use Patroni for standard Postgres or YugabyteDB that is fault-tolerant by design.Specifics are here: https:&#x2F;&#x2F;www.yugabyte.com&#x2F;postgresql&#x2F;postgresql-high-availabi... reply jgimenez 7 hours agoparentprevWhat would you recommend instead? reply feverzsj 7 hours agorootparentIf you have enough budget, go for proprietary databases. StackOverflow runs on a single Sql Sever instance with a hot standby. The tooling is just much better and easy to use. The save on maintenance solely is worthy.The free alternative would be Mysql&#x2F;Mariadb + Galera Cluster. Not as solid as proprietary ones, but far easier to use and less buggy than Postgres + tons of tools. reply dikei 6 hours agorootparent>> The free alternative would be Mysql&#x2F;Mariadb + Galera Cluster. Not as solid as proprietary ones, but far easier to use and less buggy than Postgres + tons of tools.Until someone accidentally run an expensive DDL on your Galera Cluster: now your cluster is down for hours without anyway to cancel that query except nuking the entire database and restore from backup. reply teaearlgraycold 9 hours agoparentprev> you can&#x27;t put critical parts of your system on the cloudThis seems highly dependent on how you define “critical”. I think most people’s definition allows for everything to be in the cloud. reply o11c 14 hours agoprevFunny that it mentions Transparent sharding (with the downsides thereof), but not other kinds of sharding. reply franckpachot 3 hours agoparentSharding above is not transparent (the application has to do it) Sharding below is what Distributed SQL does (what they call distributed key-value storage, ignoring that the SQL transactions are also distributed) reply IntrnlCmplrErr 12 hours agoprevUnder the “DBMS-optimized cloud storage” section, won’t replicating the WAL across various different availability zones entail doing an atomic broadcast if you want any isolation?It seems to me that you would need to run some sort of consensus algorithm to ensure the replication is consistent but that’s obviously very expensive in latency. Is it actually done this way? reply franckpachot 3 hours agoparentAurora writes each block to 6 replicas, and waits for a quorum of 4 to acknowledge. This has small impact on commit time which you can see as IO:XactSync (https:&#x2F;&#x2F;dev.to&#x2F;aws-heroes&#x2F;aws-aurora-io-xactsync-is-not-a-po...) but provides good HA reply foota 12 hours agoparentprevThey mention paralleling them, so it&#x27;s only as expensive as the slowest write. reply pama 10 hours agoprev [–] Why not include redshift in the mix? reply dikei 6 hours agoparent [–] Redshift is a data warehouse, it&#x27;s not suitable for OLTP use case. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This article gives an introduction to distributed PostgreSQL architectures and the trade-offs associated with them.",
      "It explores the goals and challenges of distributed database systems, including the impact of network latency.",
      "The article discusses different architectures for distributing PostgreSQL, such as read replicas, DBMS-optimized cloud storage, active-active architecture, and transparent sharding.",
      "It also covers the concept of updating rows in PostgreSQL and the use of sharded systems and distributed key-value storage systems.",
      "Distributed PostgreSQL architectures aim to address operational challenges but may have some efficiency and latency compromises."
    ],
    "commentSummary": [
      "This article analyzes the pros and cons of distributed Postgres architectures, emphasizing the importance of understanding their limitations and benefits.",
      "It discusses the potential performance differences when moving from on-prem data centers to the cloud and the need for unbiased evaluations.",
      "The discussion thread covers various topics, including experiences, preferences, scalability, high availability, and the suggestion of open options like Patroni or YugabyteDB for high availability."
    ],
    "points": 252,
    "commentCount": 39,
    "retryCount": 0,
    "time": 1704732776
  },
  {
    "id": 38917749,
    "title": "Cells Use Communication to Repair and Regulate Aging",
    "originLink": "https://www.quantamagazine.org/cells-across-the-body-talk-to-each-other-about-aging-20240108/",
    "originBody": "Cells Across the Body Talk to Each Other About Aging Read Later Share Copied! Comments Read Later Read Later aging Cells Across the Body Talk to Each Other About Aging By Viviane Callier January 8, 2024 Biologists discovered that mitochondria in different tissues talk to each other to repair injured cells. When their signal fails, the biological clock starts winding down. Read Later Chemical signals released by mitochondria are somehow communicated to mitochondria in other tissues, with consequences for how rapidly organisms age. Kristina Armitage/Quanta Magazine By Viviane Callier Contributing Writer January 8, 2024 View PDF/Print Mode Abstractions blogagingbiologycell biologymitochondriaAll topics Introduction Aging can seem like an unregulated process: As time marches along, our cells and bodies inevitably accumulate dings and dents that cause dysfunctions, failures and ultimately death. However, in 1993 a discovery upended that interpretation of events. Researchers found a mutation in a single gene that doubled a worm’s life span; subsequent work showed that related genes, all involved in the response to insulin, are key regulators of aging in a host of animals, from worms and flies to humans. The discovery suggested that aging is not a random process — indeed, specific genes regulate it — and opened the door to further research into how aging proceeds at a molecular level. Recently, a set of papers documented a new biochemical pathway that regulates aging, one based on signals passed between mitochondria, the organelles best known as the powerhouse of the cell. Working with worms, the researchers found that damage to mitochondria in brain cells triggered a repair response that was then amplified, setting off similar reactions in mitochondria throughout the worm’s body. The effect of this repair activity was to extend the organism’s life span: The worms with repaired mitochondrial damage lived 50% longer. What’s more, cells in the germline — the cells that produce eggs and sperm — were central to this anti-aging communication system. It’s a finding that adds new dimensions to the fertility concerns implied when people talk about aging and their “biological clock.” Some of the findings were reported in Science Advances and others were posted on the scientific preprint server biorxiv.org in the fall. Abstractions navigates promising ideas in science and mathematics. Journey with us and join the conversation. See all Abstractions blog The research builds on a recent body of work that suggests that mitochondria are social organelles that can talk to one another even when they are in different tissues. In essence, the mitochondria function as cellular walkie-talkies, sending messages throughout the body that influence the survival and life span of the entire organism. “The important thing here is that in addition to genetic programs, there is also a very important factor to regulate aging, which is the communication between tissues,” said David Vilchez, who studies aging at the University of Cologne and was not involved in the new research. The cell biologist Andrew Dillin discovered the first hints of this novel pathway that regulates life span about a decade ago. He was hunting for life-extending genes in Caenorhabditis elegans worms when he found that genetically damaging the mitochondria extended the worms’ lives by 50%. That was unexpected. Dillin had assumed that defective mitochondria would hasten death rather than prolong life — after all, mitochondria are central to cell functioning. Yet for some reason, gumming up the smooth functioning of the mitochondria compelled the worms to live longer. More intriguing was the fact that damaged mitochondria in the worms’ nervous system seemed to be driving the effect. “It really says that some mitochondria are more important than others,” said Dillin, who is now a professor at the University of California, Berkeley. “The neurons dictate this over the rest of the organism, and that was really surprising.” Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters Over the past decade, the cell biologist Andrew Dillin has uncovered the biochemical details of a novel pathway that regulates aging, in which mitochondria in cells across the body communicate about cellular health. Courtesy of Andrew Dillin Introduction Now, Dillin and his team have expanded that finding by discovering new details about how mitochondria in the brain communicate with cells across the worm’s body to extend life. First, he had to understand why damage to the brain’s mitochondria could possibly have a beneficial effect on the organism. A mitochondrion’s process for generating energy requires exceedingly complex molecular machinery with dozens of different protein parts. When things go awry, such as when some components are missing or misfolded, mitochondria activate a stress response, known as the unfolded protein response, which delivers repair enzymes to help the complexes assemble properly and restore mitochondrial function. In this way, the unfolded protein response keeps cells healthy. Dillin expected this process to unfold only inside the neurons with damaged mitochondria. Yet he observed that cells in other tissues of the worm’s body also turned on repair responses even though their mitochondria were intact. Like taking a car to a mechanic regularly, the unfolded protein response seemed to keep cells in good running order. It’s this repair activity that helped the worms live longer. Like taking a car to a mechanic regularly, the unfolded protein response seemed to keep cells in good running order and function as anti-aging detailing. What remained mysterious was how this unfolded protein response was communicated to the rest of the organism. After some investigation, Dillin’s team discovered that the mitochondria in stressed neurons were using vesicles — bubblelike containers that move materials around the cell or between cells — to carry a signal called Wnt beyond the nerve cells to other cells in the body. Biologists already knew that Wnt plays a role in setting up the body pattern during early embryonic development, during which it also triggers repair processes like the unfolded protein response. Still, how could Wnt signaling, when turned on in an adult, avoid activating the embryonic program? Dillin suspected that there had to be another signal that Wnt interacted with. After further work, the researchers discovered that a gene expressed in the mitochondria of the germline — and in no other mitochondria — can interrupt Wnt’s developmental processes. That result suggested to him that germline cells play critical roles in relaying the Wnt signal between the nervous system and tissues throughout the rest of the body. “The germline is absolutely essential for this,” Dillin said. It isn’t clear, however, whether the germline mitochondria act as amplifiers, receiving the signal from the brain’s mitochondria and transmitting it to other tissues, or if the receiving tissues are “listening” for signals from both sources. Either way, the strength of the germline signal regulates the organism’s life span, Dillin said. As a worm ages, the quality of its eggs or sperm declines — what we refer to as the ticking of a biological clock. The decline is also reflected in the germ cells’ changing ability to transmit signals from the brain’s mitochondria, he suggested. As the worm grows older, its germline transmits the repair signal less effectively, and so its body declines, too. Related: Why Do We Get Old, and Can Aging Be Reversed? ‘Social’ Mitochondria, Whispering Between Cells, Influence Health Protein Blobs Linked to Alzheimer’s Affect Aging in All Cells What Makes Life Tick? Mitochondria May Keep Time for Cells Scientists don’t yet know whether these findings apply to humans and how we age. Still, the hypothesis makes sense from a broader evolutionary standpoint, Dillin said. As long as the germ cells are healthy, they send pro-survival signals to ensure that their host organism survives to reproduce. But as the quality of the germ cells declines, there is no evolutionary reason to keep extending life span further; from evolution’s perspective, life exists to reproduce itself. The fact that mitochondria can talk among themselves might seem somewhat alarming, but there is an explanation. Long ago, mitochondria were free-living bacteria that joined forces with another type of primitive cell to work together in what became our modern complex cells. So, their ability to communicate is probably a relic from the free-living bacterial ancestor of mitochondria. “This little thing that’s been ticking inside of cells for billions of years still retains its bacterial origins,” Dillin said. And if his research in worms holds up in more complex organisms like humans, it’s possible that your mitochondria are talking right now about your age. By Viviane Callier Contributing Writer January 8, 2024 View PDF/Print Mode Abstractions blogagingbiologycell biologymitochondriaAll topics Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article Mathematicians Identify the Best Versions of Iconic Shapes",
    "commentLink": "https://news.ycombinator.com/item?id=38917749",
    "commentBody": "Cells across the body talk to each other about agingHacker NewspastloginCells across the body talk to each other about aging (quantamagazine.org) 227 points by birriel 20 hours ago| hidepastfavorite148 comments JumpCrisscross 17 hours ago\"As a worm ages, the quality of its eggs or sperm declines — what we refer to as the ticking of a biological clock. The decline is also reflected in the germ cells’ changing ability to transmit signals from the brain’s mitochondria, he suggested. As the worm grows older, its germline transmits the repair signal less effectively, and so its body declines, too.Scientists don’t yet know whether these findings apply to humans and how we age. Still, the hypothesis makes sense from a broader evolutionary standpoint, Dillin said. As long as the germ cells are healthy, they send pro-survival signals to ensure that their host organism survives to reproduce. But as the quality of the germ cells declines, there is no evolutionary reason to keep extending life span further; from evolution’s perspective, life exists to reproduce itself.\"Curious what effect castration has on this mechanism. reply yarg 17 hours agoparent> But as the quality of the germ cells declines, there is no evolutionary reason to keep extending life span further; from evolution’s perspective, life exists to reproduce itself.When the individual&#x27;s survival is the only selection factor, this is true - but it ceases to be the case in social species where reproductively non-viable individuals can still positively influence the reproductive chances of the young.This may be an indirect feedback loop - but a little bit of latency doesn&#x27;t make a huge difference when you&#x27;re dealing with hundreds of thousands of generations of natural selection. reply wcoenen 16 hours agorootparentThe survival of the individual is indeed not what natural selection is selecting for.Otherwise phenomena like eusocial insects with sterile workers would not make sense. What is actually selected for, is genes that somehow promote more copies of themselves. This is the main takeaway from the book \"the selfish gene\".However, the example of ants and bees shows that this doesn&#x27;t exactly promote long lifespan in the sterile workers... Instead, they are mass-produced expendable drones. reply yarg 12 hours agorootparentThe survival of the individual is exactly what is being selected for. The influence of an individual gene is not distinguishable from those that are packaged with it.So what is selected for over any single cycle is sets of sets of genes conveying advantage.Taking half of your genes from each parent could only select whole useful chromosomes from each parent (but is far better than nothing);In order for genes to be selected in their own rights, you need more.Chromosomal crossover copies genes across chromosome pairs - over the course of repeated iterations this allows useful mutations to be more easily distinguished.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chromosomal_crossover reply hgomersall 9 hours agorootparentThere are plenty of ways in which the genes of an individual may survive better when the individual has reduced survival. The individual in this case being the large multicellular organism. Hence we see all sorts of weird strategies in the wild like sexual cannibalism: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Sexual_cannibalism reply wegfawefgawefg 16 hours agorootparentprevI think the common notion is that the survival of the individual is exactly what natural selection is selecting for.However, it seems to me its more selecting for its own particular configuration of genes, that essentially select for a signature of themself.Within a species the configuration between individuals is generally different enough to not ellicit altruistic behaviour.In most animals, the 50% kinship gene relatedness threshold is definitely not enough to instigate self sacrificial behaviour. The children of a usocial species have to be like 11&#x2F;16ths clones of eachother. And the runt suicide mechanism that triggers in rabbits requires a brood of true clones.The reason I think it seems the genes select for individuals is because most circumstances will recquire that the current reproductive unit at the individual level needs to stay alive long enough for a net positive replication contribution to have been made. reply fsckboy 15 hours agorootparent> I think the common notion is that the survival of the individual is exactly what natural selection is selecting for.when we reproduce, do we make copies of ourselves? no we don&#x27;t. It&#x27;s not survival of individuals. Read the Selfish Gene and it will change your thinking. You as an individual are a piece of clothing for your genes. Your genes reproduce, you don&#x27;t. reply AnthonyMouse 14 hours agorootparent> Your genes reproduce, you don&#x27;t.It&#x27;s more complicated than that. Your genes reproduce, but then that child is in your care, and you teach them your values. Then your values reproduce.And then you&#x27;re into nature vs. nurture. Your values can&#x27;t reproduce if you have stupid genes that cause your offspring to die of cystic fibrosis, but your genes can&#x27;t reproduce if you have stupid values that cause your offspring to be self-destructive and sterile.\"You\" are the combination of your genes and your values, and whether there gets to be any more of that depends on whether you, as a whole, are any good at it. reply startupsfail 13 hours agorootparentYep. The immune system is watching for that and killing you off, if you’re being a social reject. That works for any social animal. Plus for humans there’s also a suicide trick. reply d1sxeyes 8 hours agorootparentNot sure if you&#x27;re being facetious or not, but it&#x27;s not the immune system killing you off.That said, you are less likely to reproduce successfully if you are &#x27;a social reject&#x27;.You will meet fewer potential mates, fewer of those will be willing to reproduce with you, etc.Whatever it was that made you a social reject, if it&#x27;s something you can pass on either through nature or nuture, is less likely to be passed on. reply yterdy 12 hours agorootparentprev>when we reproduce, do we make copies of ourselves?You have been blessed not to grow up with a narcissist or vicarious striver as a parent.Technically, cars are a means of transportation for people. However, an honest assessment of the American transit system might lead one to believe that the safety and comfort of cars (or the automotive industry and ecosystem) are more important than the people they&#x27;re supposed to ferry. In reality, the system is complex, incentives and drives are many; a holistic view is more useful than forcing a tortured atomic hierarchy onto that system. reply bryanrasmussen 8 hours agorootparentVicarious striver sounds like you have a psychological diagnosis in mind, but I can&#x27;t find anything on it? reply yterdy 1 hour agorootparentA parent who pushes their child to carry out their own unfulfilled ambitions. The archetypical college athlete who \"coulda gone pro\" dumping tons of time, energy, and money into their kid&#x27;s travel team, or the tiger parent for whom anything less than an A is the end of the world because how else are you going to become a doctor? reply yarg 12 hours agorootparentprevThe individual capable of survival is what survives - he brings with him the genes that conveyed his advantages. reply jacquesm 15 hours agorootparentprev> Otherwise phenomena like eusocial insects with sterile workers would not make sense.These are often genetically identical with the rest of the hive, just on a different diet and with different treatment after the eggs are laid. reply m463 15 hours agoparentprevok probably stupidly curious:A study of 81 historical eunuchs in Korea&#x27;s royal court found a 14- to 19-year increase in lifespan compared to intact men of similar socioeconomic background; these eunuchs had a centenarian rate of over 3%.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Castration#Medical_consequence... reply JPLeRouzic 6 hours agorootparentDoes this observation invalidate the idea that a young germline is associated with overall good health?Yet I wonder if those eunuchs had their testes removed, the WP article tells about removing the penis. If this is the case the eunuchs&#x27; testes were still there. reply onlyrealcuzzo 10 hours agorootparentprevThat seems really statistically significant.It probably can&#x27;t be explained by loss of testosterone alone - since less than 1% of people live to be 100+.It&#x27;d be good to know, though, what the lifespan of women in a similar environment would be. reply I_Am_Nous 14 hours agorootparentprevPets often live longer after being neutered or spayed so it&#x27;s interesting to see a correlation in humans. reply pants2 11 hours agorootparentBased on this observation I posed this question on &#x2F;r&#x2F;AskMen some time ago. \"Would you be castrated to live 15 years longer?\" - overwhelmingly the answer was no. reply jamiek88 8 hours agorootparentIf I could have fake balls like, they let me keep my ballsack and I get a couple marbles in there, I’d take that deal. reply dghughes 4 hours agorootparentYour voice would change though I think that would be more of an issue to most guys.But it may reverse baldness? My guess is it may stop the progression but not reverse it, not regrow lost hair. replydayjaby 8 hours agoparentprev> Scientists don&#x27;t yet know ... how we ageUri Alon[1] argues thar it&#x27;s the exponential growing chance of diseases&#x2F;malfunctions as the amount of senescent cells surpasses certain thresholds.[1] https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;33559235&#x2F; reply phkahler 17 hours agoprevI&#x27;ve come to think mitochondria are somehow fundamental to health in ways we can&#x27;t even see. No sources, but they seem relevant to structure of the overall organism, proper healing of wounds, something in the brain (they can move between neurons), apoptosis, and a few other odd things I&#x27;ve seen talked about. They also come up in any number of diseases and conditions. All far beyond what you&#x27;d expect from \"powerhouse of the cell\" producing ATP. reply aeternum 16 hours agoparentYes, the interesting thing here is that it&#x27;s the germ cell mitochondria that seem to be the originators of the signal.The article&#x27;s findings are also backed by data on Eunuchs who live almost 20 years longer than non-castrated men.Now the real question is: Are Bryan Johnson and his followers willing to take logical next step? reply rco8786 16 hours agorootparentI was not ready for that twist but honestly it wouldn’t completely shock me if he did it. reply qp11 12 hours agorootparentprevWell we need to know what do eunuchs do with the extra 20 years? reply jamiek88 8 hours agorootparentHatch plots against the emperors children mostly. reply mschuster91 15 hours agorootparentprev> The article&#x27;s findings are also backed by data on Eunuchs who live almost 20 years longer than non-castrated men.The question is why this is the case... if it&#x27;s historical data, it may simply be correlation, not causation, as in most societies eunuchs were prized and highly privileged compared to the general populations as the noblemen in power didn&#x27;t see them as a threat to their biological line aka their wives (due to the obvious lack of balls and, in many cases, the penis). And no matter the era, those in privileged positions always enjoyed a longer lifespan due to the accessibility of consistent and higher-quality nutrition as well as healthcare.The only thing coming close that we do have data for (simply out of ethical reasons) is pets and farm animals, and at least for pets there is some reduction in a few reproductive tract-related cancers (well, duh, what&#x27;s taken out can&#x27;t grow a cancer) [1] and higher life expectancy due to less fights.[1] https:&#x2F;&#x2F;www.cats.org.uk&#x2F;farnham&#x2F;news&#x2F;the-importance-of-neute... reply lock-the-spock 14 hours agoparentprevYou would likely enjoy the book \"Power, Sex, Suicide - Mitochondria and the Meaning of Life\" by nick Hall, one of the most insightful books I&#x27;ve read in a while. It is all about the evolutionary history of mitochondria and our complex cells and how it affects our and other animals&#x27; lives. I learned something new on every page. Dense but very well written and clear to follow. reply pineaux 9 hours agorootparentLove this book reply tommychillfiger 16 hours agoparentprevI&#x27;m primed to agree as I like running, and running appears to increase mitochondrial function and density. It also appears to have some anti aging effects, which would track. reply phkahler 4 hours agorootparentBut runners also tend to look more aged, don&#x27;t they? reply TheCoelacanth 1 hour agorootparentProbably not if they take care to protect their skin from sun damage reply grishka 12 hours agoprevThis seems to fit nicely with the other research that explores the rejuvenation effects of \"young blood\", but specifically purified and concentrated extracellular vesicles. Harold Katcher&#x27;s research especially — except he doesn&#x27;t yet know what it is exactly in those EVs that triggers the effect he observed in rats.Here&#x27;s one of those papers: https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2023.08.06.552148v1.... reply LASR 19 hours agoprevYou know, I&#x27;ve recently wondered quite a bit about aging and how any of it makes sense.What has perplexed me is the notion of honest signals[1] in a world governed by natural selection and the survival of the fittest. Why wouldn&#x27;t cheating exclusively emerge as the only strategy? Why wouldn&#x27;t a species evolve a mechanism to survive longer and longer till it completely dominates?Then it dawned on me that the survival of the species is not aligned with the survival of an individual. Cheating maximizes the benefit to that individual. But possibly damages the collective. Why is why honest signals even exist.Aging and death as being pre-programmed is in service of the collective and that&#x27;s why it even exists.A bit of existential dread. But sharing it nonetheless.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Signalling_theory reply bhuga 17 hours agoparent> survival of the species is not aligned with the survival of an individualThe unit of survival is not the individual or the species, but the gene. Genes maximize their survival by combining via sexual reproduction with other genes over time. Any one combination of genes will be out-competed over time.The reason for honest aging signals is that a gene survives longer by getting out of the way of its offspring&#x27;s combinations with other, newer genes. Sexual reproduction is the only way to get access to new phenotype features.It&#x27;s not service for the collective. Hanging around in one individual is the genetic version of vendor lock-in. reply lloeki 6 hours agorootparent> the genetic version of vendor lock-inAll models are wrong but this one is mine, IANA biologist, yadda yadda.- there are only so many resources to sustain individuals- ergo there&#x27;s a cap of the number of individuals- ergo some individuals will die, if not from age, from attrition- if age is not factored in, there are more old individuals, genetic competition between young individuals is reduced as they have to compete for resources with old individuals- ergo age which kills old individuals irrespective of available resources allows more young individuals to exist in such a pool- ergo ageing a) promotes competition between young individuals b) increases mixing of the gene pool- ergo it promotes quicker turnaround on mutations- ergo ageing is a significant asset in species adaptability to changeIOW vendor lock-in sucks in face of changing conditions as one is suddenly stuck with a suboptimal solution and competitors have a harder time emerging to challenge the status quo.conversely the benefits of short term ageing are counterbalanced by social effects, where elders, even when not reproductive anymore but still otherwise in good health and thus autonomous as well as minimally consuming resources, are able to provide support for their chain of descendants, freeing energy for parents-to-be to reproduce, then parents to gather more resources that are then directed to support their younglings. The lack of reproductiveness of elders is advantageous to the species as it removes them from the direct gene mixing pool, instead promoting the younger ones.IOW for its individual lives to be longer, a species goes increasingly social, channeling more support and thus energy towards their younger members, but ageing is still key otherwise the species ability to face quick change (at evolutionary scales) is severely hampered.The deeper question for me is whether ageing is a specific primary process (a literal clock, which a technique such as the paper would attempt to skew backwards) that emerged from evolution or if it is a secondary effect from entropy corrupting other processes (e.g there&#x27;s constant degradation + a ton of error correction but at some point degradation is too high and error correction cannot cope, triggering a catastrophic cascading effect leading to the sudden inability for an organism to sustain its own life, which the paper would delay by introducing younger cells, thus less errors, thus error correction can cope for longer) reply ttoinou 17 hours agorootparentprevWhy would women survive so long after menopause then ? reply mrkstu 16 hours agorootparentHappy accident at first, though there are some possibilities around grandparents increasing survival rates of younger children, so that would ultimately feed back into the gene pool. reply tarkin2 16 hours agorootparentprevTo help her offspring propogate her genes is one theory I&#x27;ve read, coming from observing post menopausal sharkes reply wizzwizz4 16 hours agorootparentprevKin selection. Parents, and community in general, are kinda important for the survival of a child. reply nonameiguess 16 hours agorootparentprevI think it can be instructive to look at other social mammals that range over large areas, like Orca and Elephants. They tend to lean heavily on elder females as the purveyors of tribal knowledge and inter-generational memory to remember where to go and how to get there as environmental conditions vary from year to year and decade to decade. It doesn&#x27;t matter as much in humans since we have writing and maps now, but this kind of wisdom of those who remember similar lean times from 60 years ago could have been very important to the survival of human communities. reply whythre 16 hours agorootparentprevClearly living longer after viable reproductive age offers something. Having grandmothers around to nurture the second generation offspring is certainly a benefit. reply amadeuspagel 18 hours agoparentprevGroup Selection is not a thing[1].There&#x27;s an equilibrium of honesty and dishonesty. If everyone is dishonest, no one trusts, and the dishonesty doesn&#x27;t pay off. If everyone is honest, everyone trusts, and dishonesty pays off all the more.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Group_selection#Criticism reply hot_gril 17 hours agorootparentSo how do group organisms work, there&#x27;s an in-between where they \"trust but verify,\" meaning lifelong cheaters or slackers eventually get screwed anyway? I know bees can kill their own queen under some circumstances. reply atticora 18 hours agoparentprev> Then it dawned on me that the survival of the species is not aligned with the survival of an individual.The selfish genes control, and their survival is not perfectly aligned with either the individual or the species. If aging becomes too slow, adaptation slows, and successful genes become more rare and their propagation slows. Genes are replicators, replicators need turn-over to replicate, and greater age means slower turn-over.It may be that the advent of cultural replicators have decreased the optimal turn-over rate of genetic replicators, but they don&#x27;t know that. reply cma 17 hours agorootparentAt the individual and immediate progeny level, aging doesn&#x27;t affect generation time. If there were group selection it might, as the older people displace resources for the younger, but for an individual that should be dilluted down to no real effect. reply atticora 17 hours agorootparentSince a given niche can only support a given population size, aging reduces generation time by hitting a ceiling on population size. Some organisms get around this by spawning thousands of offspring and all but approximately one fails fast.So that&#x27;s an available trade-off. Increase individual age limits, but maintain adaptation rates by letting many immature individuals compete and die before maturity. Like spermatozoa and tadpoles. reply cma 14 hours agorootparent> aging reduces generation time by hitting a ceiling on population size.That&#x27;s what I meant by \"if there were group selection it might, as the older people displace resources for the younger.\" reply Shorel 17 hours agoparentprevI have believed that to be the case for a while. It&#x27;s perfectly logical, from a species point of view.I also think that we are hardwired not to be able to believe our own lies, because of this. There is (99.9% of the time) a tell, for humans. For someone to effectively lie to us, we need to want to believe the lie, otherwise it fails.The TV show \"Lie to me\" is therefore a fascinating exploration (a bit exaggerated in its effectiveness) of how to detect and point out such tells. reply block_dagger 18 hours agoparentprev> Why wouldn&#x27;t a species evolve a mechanism to survive longer and longer till it completely dominates?Because evolution happens faster with sexually reproducing generations that die out to leave room for the fitter youth. reply taeric 18 hours agorootparentThis is a lot more compelling when you consider what it takes to survive this generation is not the same thing that was needed to survive last generation. This was more obvious with, for example, the peppered moth. reply pmontra 17 hours agorootparentI didn&#x27;t know about it. Thanks.Link to the Wikipedia article https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Peppered_moth_evolution reply alexschnapp 17 hours agoparentprevThere is no more evolutionary pressure on lifespan after you have children since you have successfully passed on the ‘aging’ gene. We used to live much shorter lives, being able to die of old age was rare, therefore, no selection. If we start to have children at 90 years old we may be able to double our lifespans (while the ones that are unable to reproduce earlier will not pass on that inability).There is no cheating, since we could not modify our genomes and give ourselves superpowers. We cannot live forever because there was no need. We won’t die before we can successfully reproduce. reply Terr_ 17 hours agorootparent> There is no more evolutionary pressure on lifespan after you have children since you have successfully passed on the ‘aging’ gene.This assumes, incorrectly, that each generation of children are birthed into a new separate pocket-universe, where absolutely nothing prior generations do next--including suddenly dying--can ever affect their own trajectories.Consider genes Alpha and Beta, where Alpha kills women right after menopause, and the Beta lets them live ably to 120. Do you really think there&#x27;s no difference between the trajectories of clan Alpha and clan Beta?Or perhaps a Cronus gene [0] which increases fitness and lifespan but causes paranoid infanticide. Just because a gene-copy was made doesn&#x27;t mean the gene stops mattering.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Saturn_Devouring_His_Son reply hinkley 16 hours agorootparentElephant matriarchs remember old watering holes that the herd has not visited in decades, and in extreme cases, watering holes that none of the other living members have ever seen.In drought years these backups may end up getting the herd through the worst of it.And it turns out that for elephants, water availability is one of the biggest limitations on reproduction. Provide a population with an artificial water source and it will explode in short order. reply alexschnapp 17 hours agorootparentprevIf your offspring does not survive to reproduce, your genetic lineage disappears, therefore ‘failed’. Others who do not kill their offspring will survive and the species will therefore not exhibit that behavior nor enjoy the benefits of that behavior. reply Terr_ 16 hours agorootparent> If your offspring does not survive to reproduceFirst you declared genes had no evolutionary pressure on longevity after children existed... but now you&#x27;re amending it to grand-children existing?Well, what about great-grandchildren? How many more times must you be forced to move the goalposts before realizing that the logic behind them is simply wrong?You can&#x27;t just ignore stuff like kin-selection, which we&#x27;ve known about for over a hundred years already. reply alexschnapp 16 hours agorootparentThis is just assuming that the offspring survives just like the parent and reproduces.If the offspring requires parenting, the parent, once an offspring, also required parenting and so on.This is not moving the goalpost, it’s doing the similar things adapted in some ways for the environment every generation.I assumed you were talking about humans. For salmon, the definition of a successful reproductive cycle is simply reproducing. For humans, it takes longer and requires parenting. But genes don’t get selected away when it’s passed on to the next generation. reply hwbehrens 16 hours agorootparentprevThat&#x27;s precisely the point the parent was trying to make to your GP post, namely that> \"There is no more evolutionary pressure on lifespan after you have children\"is an inaccurate oversimplification. reply alexschnapp 16 hours agorootparentThe definition of having children varies by species. For humans, it requires parenting and care, for salmon, just the act of reproduction works. reply tommiegannert 8 hours agorootparentprev> If we start to have children at 90 years oldInteresting thought. So if we simply force people to reprocreate later in life, we&#x27;ll select for genes that allow for that, possibly also bringing longer lifespans in general (to protect the early offspring.)I wonder if education, and cultural protection of teenagers has already done that to some extent.In short, the path to immortality is to hold off children longer and longer... Hypothetically. reply jjtheblunt 17 hours agorootparentprev> There is no cheating, since we cannot modify our genomesthat reads like you missed the last 10 years of genomics and the Nobel prizes for Jennifer Doudna and Emmanuelle Charpentier, among other proven DNA&#x2F;RNA manipulations. reply alexschnapp 17 hours agorootparentEdited to past tense ‘could not’ reply jjtheblunt 17 hours agorootparentthat makes sense!your point could turn out true, since edits to genomes AND superpowers resulting is what you said wouldn&#x27;t work. maybe the second half of the conjunctive clause isn&#x27;t possible, but we don&#x27;t know yet.i guess the future will be interesting! reply 3cats-in-a-coat 17 hours agorootparentprevYour brain at 90 is mostly useless even if you&#x27;re not afflicted with a serious condition. You can&#x27;t learn and adapt like you could in your 20s.Being too old is a detriment to both yourself and your community. This is why we die. We stop being ourselves past a certain point. Living to live is such a vapid, pointless goal.People talking about eternal life disgust me. It&#x27;s narcissism or infantilism in disguise. reply JoshTriplett 17 hours agorootparent> Your brain at 90 is mostly useless even if you&#x27;re not afflicted with a serious condition. You can&#x27;t learn and adaptYou are factually incorrect. You can, in fact, learn and adapt in your 90s. Sometimes (not always) the brain has degraded and can&#x27;t do so as well, but that&#x27;s a problem we should work to fix. And there is some evidence to suggest that cause and effect go in both directions there: if you keep learning and adapting your brain remains more capable of doing so.People talking about longevity and improving lifespan are primarily not talking about having people go on for centuries looking and feeling like they&#x27;re 90. They&#x27;re talking about having people go on for centuries or longer looking and feeling like they&#x27;re 50 or better. Many of the same things that make us age and die are also what make us have much worse health (physical and mental) in our 90s than in our 40s or 50s. Fixing those things will both help us live longer and help us be healthier for longer. reply polishdude20 17 hours agorootparentThey won&#x27;t help us change our minds though. The problem with having people in their 90&#x27;s capable of the same things as people in their 30&#x27;s is that they&#x27;d hold positions of power longer. Old ideas would live on much longer reply ben_w 16 hours agorootparentHow can you be so confident about a hypothetical with zero examples? All the 90 year olds today are necessarily stuck with 90 year old brains. reply JoshTriplett 16 hours agorootparentIndeed. And why advocate death as the solution to a problem better handled with term limits and similar mechanisms? reply throw__away7391 14 hours agorootparentBecause right now you don&#x27;t have the option to choose, so you try to convince yourself that the only choice you have is the one you would have picked anyway. It&#x27;s quite a common phenomenon, I guess a sort of survival strategy. reply antihipocrat 15 hours agorootparentprevMany people change their ideas as they age, the ones that don&#x27;t are more noticeable and reinforce the stereotype. reply PeterisP 15 hours agorootparentThere is some truth in saying that science progresses one funeral at a time, and in political structures some of the most effective checks on abuse of power is that even the most shrewd dictator eventually dies.Longevity has its benefits, but if the powerful people can become effectively immortal, then that does have some risks of dystopian stagnation. Like, imagine USSR if Stalin would never die, or Salazar and Franco still holding power in Portugal and Spain, because democracy only became possible when their health failed; and lack of change at top management of megacorporations and major privately held businesses because their owners and CEOs now can be eternal. reply alexschnapp 17 hours agorootparentprevThe idea for eternal life is to live with your 18 year old body at 200 years old, not like your 90 year old body now.I don’t see why we shouldn’t work towards being healthier and younger for longer. The urge to survive is built into us and we can develop the means to achieve it. reply mulmen 17 hours agorootparentMy personal preference is for my 25 year old body but I will settle for 18. reply mulmen 17 hours agorootparentprevThat’s not how evolution works. If you do reproduce at 90 then you are by definition capable and will pass those genes on. If that is beneficial your offspring will out-compete the offspring of others whose brains turn to mush. reply evantbyrne 16 hours agorootparentprevYou sound young. Old folks that are still competitive are a force to be reckoned with. They are rare in part because people die, but also the things people compete over feel less important with age. reply ben_w 17 hours agorootparentprev> People talking about eternal life disgust me. It&#x27;s narcissism or infantilism in disguise.I suspect your disgust has prevented you from actually learning what the positions of these people even are. I mean, we&#x27;ve had the story of \"aging without dying is bad\" since the ancient Greeks and Tithonus, and even for them it was a tragic mistake to forget to ask for the \"no more aging please I&#x27;m fine at XYZ years\" part. reply hot_gril 17 hours agoparentprevI&#x27;m guessing it&#x27;s simpler than that. It&#x27;s hard to keep the seed and mechanisms for reproduction healthy forever. Even if there&#x27;s no harm to the group, anti-aging might have a cost that reduces the individual&#x27;s ability to reproduce at an earlier age, or at least it doesn&#x27;t help. reply kiba 18 hours agoparentprevAging being preprogrammed is only one hypothesis. The other hypothesis is that the evolution only selected for what work and reproduced.Note what work and reproduced is only a minimum bar. reply troupe 17 hours agoparentprev> Cheating maximizes the benefit to that individual. But possibly damages the collective.It would seem like a species that has a language would greatly benefit from having individuals with more years of experience on how to handle infrequent events like droughts, floods, abnormal animal migrations, etc. reply cassepipe 17 hours agorootparentAnd we have. The lifespan of the human individual past its reproductive prime is already impressive. The fact that we take care of our elders instead of just let them die suggest could be a evolutional spandrel but the fact that age and wisdom are associated (at least in \"primitive\" societies) is a testament to how much of cultural species we are, that is with an unprecedented ability to transmit knowledge necessary for our survival. reply pmontra 17 hours agorootparentprevYes, but only as long as they can still communicate and as long as there are no younger experts with comparable experience, if not more up to date, and better motor and communication skills. That puts some limit to useful age. reply kraftman 18 hours agoparentprevit seems like dishonesty, at least in terms of reproduction, would self correct pretty fast? Like if an animal signals that its strong genetically, but it isnt actually, then its offspring wont fair as well and will be less likely to reproduce, so &#x27;lying&#x27; would die off pretty quickly? reply Centigonal 18 hours agorootparentI think it&#x27;s difficult to signal genetic fitness without actually being genetically fit.There are proxies to genetic fitness that are frequently and successfully mimicked, though. See e.g.: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Batesian_mimicry reply lanstin 17 hours agorootparentprevIf your fake out display of fitness is attractive to the other sex, then it is actual reproductive fitness. reply jxy 18 hours agoparentprevIt&#x27;s easier to think all the living things are carriers fabricated and controlled by self-replicating nano-bots. Whatever strategy the nano-bots come up with and eventually successfully allowing them to keep creating more nano-bots is the winning strategy. reply m3kw9 18 hours agoparentprevWith tech these bets are off, what if it can further a collective further? Say making you stronger despite your genes, or using tech to assist us. It’s already happening right now, look at all the tech around us reply hughesjj 17 hours agoparentprevVeratasium just made an approachable video on this subject recently, I definitely recommend. It rebukes the whole &#x27;oh no I just heard what a Nash equilibrium is and now I&#x27;m worried cooperation is impossible long term&#x27; fears some people interpret his thought experiment (prisoners dillema) to have. Tldr it&#x27;s rare that you can&#x27;t coordinate, communicate, or have exactly one trial.https:&#x2F;&#x2F;youtu.be&#x2F;mScpHTIi-kM?si=v8FvrfMCHioLJET5 reply hot_gril 17 hours agorootparentIs the longer tl;dr that with multiple trials and possible miscommunication, the winning individual strategy is tit-for-tat, and the winning group strat is some softer tit-for-tat with one forgivable betrayal? reply JoshTriplett 17 hours agorootparentThe winning multi-round group strategy in a game in which you can identify and remember different people is, roughly, \"cooperate with cooperators, defect with defectors\".https:&#x2F;&#x2F;ncase.me&#x2F;trust&#x2F; is well worth playing to get an idea of how this works.(Also, by way of acknowledging that reality is more complex than simulations like the Prisoner&#x27;s Dilemma, in reality you might also have options like \"stop interacting with defectors in order to avoid lose-lose situations\" or \"warn others about defectors, and listen to others&#x27; warnings but weight them based on whether the entity giving the warning is honest\". And conversely, defectors get more options like \"pretend to be a different entity with no history\" or \"pretend to be a known trusted entity\".) reply hot_gril 17 hours agorootparentYep, I remember playing that minigame a while back, it&#x27;s a nice one. Also the \"wisdom of crowds\" one on that same site. reply qp11 12 hours agoparentprevSame reason everything doesn&#x27;t turn into a predator or a parasite. We get ecosystem collapse as soon as that happens. reply huytersd 18 hours agoparentprevThe longer you live, the less adaptable your species is. The more generations you can have in a shorter amount of time, the faster you can have beneficial mutations that help your species survive changing conditions. reply JumpCrisscross 18 hours agorootparent> longer you live, the less adaptable your species isI live near Yellowstone. There are seasonal hunting grounds the bison, which live a decade or two, won’t cross into. The wolves, meanwhile, don’t live long enough for the lesson to stick. So they continuously cross and get shot.Humans erected an invisible barrier. The bison adapted where the wolves, arguably the more intelligent creature, did not, in part due to the latter’s short lifespan.The best of both worlds would be a long-lived polygamous creature that’s constantly reproducing. Ecology, however, proscribes limits on that approach. reply troupe 18 hours agorootparentprevI&#x27;m not seeing how longevity slows the number of generations you can have per unit of time. That seems like it would be determined by how quickly a species reproduces after being born...not how long they live. reply I_Am_Nous 14 hours agorootparentGenerally, the more individuals you have competing for resources, the more difficult it is to raise viable offspring. If there are far more elderly individuals who cannot reproduce, they are essentially preventing those resources from being used to mature offspring. reply huytersd 15 hours agorootparentprevYes, I thought about that but I went with the general assumption (based on life history theory) that longer lifespans equals longer times to reach sexual maturity. reply Kalanos 17 hours agoparentprevbecause game theory, and we would evolve to recognize cheating reply loceng 17 hours agoparentprevOne interesting thing I had a sense of but only recently could put it into words, in regards to aging-degradation-disease progression, is that there is an inherent mechanism to prune off population that isn&#x27;t emotional (and perhaps including spiritually) healthy, e.g. there is research that shows that if anger (or any emotion) is being suppressed, then the immune system is also suppressed - meaning more likely to succumb to potential harms of various dis-ease states. reply colechristensen 16 hours agoparentprevTwo things:- after you reproduce evolutionary pressures have way less leverage and are limited to how an individual effects the copies of their genes that still might reproduce- excess longevity will result in an older nonreproducing individual competing with copies of its genes leading to evolutionary pressure to die when below a threshold of usefulness to younger generations of your genes reply samstave 18 hours agoparentprevOf note, is that organisms that have a more balanced, symbiotic relationship to their surrounding environment - with shared benefits, live a lot longer. Take thousand year old trees, and millenniums older mycelium networks.However, this doesnt explain tortoise (or 500 year old sharks)The amount of energy required to sustain Human growth and Civilization just grows and grows. If we had a scalable balanced, fully renewable resource in everything, we likely would live longer. reply deadbabe 18 hours agoparentprevCheating could just get you killed off by jealous partners, cutting off your ability to reproduce more. It’s like marking territory. reply speedylight 15 hours agoprevAging should be classified as a disease because there has to be a set of biological levers that we can manipulate with drugs or other forms of medicine which will have an effect on the aging process across the entire. Like using RNA to reprogram the cells in the body to do things outside of what’s encoded in our base DNA.I don’t see why aging can’t be reversible, I’ve heard some people say it’s an impossible task because they equate aging with the fact that time can only move forward and therefore aging must inherit the same property. But aging is just damage that accumulates over time, but damage can be repaired with the right tools.I should say I am not a biologist, I just try to use my imagination to solve problems and this what it’s telling me about aging. reply grishka 10 hours agoparent> But aging is just damage that accumulates over time, but damage can be repaired with the right tools.No, that&#x27;s outdated. Another theory that aging is an intentional, programmed process is gaining more and more traction lately. Damage does accumulate over time, but it&#x27;s not because the cells are incapable of repairing it, it&#x27;s because they deliberately don&#x27;t want to repair it. The developmental program that starts with conception just turns self-destructive at some point. We \"only\" need to reset its state to such that corresponds to a younger age. reply omeid2 15 hours agoparentprev> I don’t see why aging can’t be reversibleAging is loss of information, you can&#x27;t reverse that. You can prevent it though. reply oceanplexian 15 hours agorootparentWhy can’t you reverse loss of information? It’s not like the information is particularly unique, we all have the same blueprints. Copy some DNA from someone younger and fill in the gaps Jurassic Park style. reply omeid2 15 hours agorootparentSubstitution isn&#x27;t reversal. reply verelo 15 hours agorootparentSo take a copy when you’re 21 and store it, re-load it every 10 years? reply speedylight 13 hours agorootparentThat’s the basic idea, the problem is how do you reload it? You would need a mechanism that changes the DNA for every one of the trillions of cells in the body. reply verelo 1 hour agorootparentYeah, thats a good question but i mean, feels like just a matter of time until someone figures that part out. If we can make GTA V load in under 2mins, we can solve human aging... reply ImHereToVote 7 hours agorootparentprevVia a viral vector or liposomal bubble. replyspeedylight 13 hours agorootparentprevI assume by information you’re referring to DNA? If so we can already sequence human DNA from all sorts of samples (so for example we store a copy of it from a young age, like 20), the hard part would be replacing the damaged DNA with the undamaged copy, in every cell of the body—sort of like reinstalling an operating system.It’s interesting to think about the implications of such a technology, if we can swap DNA with another, fresher copy, we should also be able to modify it and make the body do things it wasn’t previously capable of doing. One idea that comes to mind is expanding the range of our senses, or giving our body a better system to repair and regenerate itself beyond what we naturally evolved to able to do so we can have longer life spans with a quality of life that makes it worth it.It sounds like a bad idea to play god like this, and it probably is, but we’ll never know until we give it a serious try. I remember a while ago a scientist in China modified the DNA of human embryos by using Crispr, the goal was to make them resistant to HIV infection and he was jailed and ridiculed for it.The search space for new and improved capabilities is endless once we learn how to program DNA like a computer. We are probably at least a century away from this level of control, and probably another century before it becomes socially acceptable to do it at scale. reply Fbnkigffb66tfbj 15 hours agorootparentprevThe human body has trillions of cells. Surely there are enough copies of our DNA to recover its original form even if individual copies have extensive damage. reply mlyle 15 hours agorootparentYah, I don&#x27;t think it&#x27;s the loss of information, but a related concept: it&#x27;s a decline in order.We have a whole lot of redundancy and mechanisms to restore&#x2F;repair redundancy. But even so, there&#x27;s a march of entropy upwards; oxidation, genetic damage, cell death, tissue damage, neuron loss, etc.We don&#x27;t have repair mechanisms for everything the body knows how to build, and the repair mechanisms that we do have become less effective to use (and often less safe) as the body ages. reply omeid2 15 hours agorootparent> it&#x27;s a decline in order.That is another way of saying loss of information and increase of entropy. reply mlyle 13 hours agorootparentWhile the thermodynamic and the information theoretic concepts of entropy are related, it&#x27;s not really applicable here. All the \"real\" information in the system is highly redundant (except perhaps neurological)-- we have billions of copies of the \"information\". The system&#x27;s ability to restore itself to the order specified in the plan is lacking. reply grishka 10 hours agorootparentprevIf aging is loss of information, then why does reproduction work? How does a non-zero-aged organism, in which some of the information was supposedly lost, give birth to zero-aged offspring with all the same information intact? reply JumpCrisscross 15 hours agorootparentprev> Aging is loss of information, you can&#x27;t reverse that. You can prevent it thoughWe don&#x27;t understand aging well enough to say this with any confidence. reply omeid2 14 hours agorootparentThis is not true. We understand aging enough to confidently say that loss of epigenetic information is correlated to aging.https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;36638792&#x2F; reply JumpCrisscross 12 minutes agorootparent> loss of epigenetic information is correlated to agingVery different from saying “aging is loss of information.” reply Log_out_ 15 hours agoparentprevAging is mamal universal. It&#x27;s a adaption to predation and I think the key would be to find a mammal that was not predated by dinosaurs. Something like whales.But even they have the predation damage. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Blue_whale reply Metacelsus 14 hours agoprev*in C. elegansI&#x27;m glad that the article did say this, though: \"Scientists don’t yet know whether these findings apply to humans and how we age.\" reply windex 13 hours agoprevI wonder when if anytime these results will translate to humans. reply yukkuri 16 hours agoprevCount down to \"prolong\" treatments like in David Weber&#x27;s books? reply dukeofdoom 16 hours agoprevWhat I&#x27;m curious about is how if we are just two cells at one point in our life. Do all the human behaviours and inherent knowledge get transferred. Where is that information kept.Even, uncontacted sentinel island tribes still behave very much like a human.I asked ChatGPT ...\"the rough estimate for the data storage capacity of the human genome in bytes is approximately 6 billion bits .... or equivalently, 750 megabytes.\"That doesn&#x27;t seem like its enough. reply 8organicbits 3 hours agoparentIs it possible to cite a better source than ChatGpt? We have no idea if that&#x27;s nonsense. reply debo_ 17 hours agoprevIn this way, cells are similar to all of my elderly Italian relatives. reply Kalanos 17 hours agoprevreminds me of how stress, especially from exercise is good for you reply fnord77 19 hours agoprevin worms reply tjr 18 hours agoparentTrue. It&#x27;s usually in mice. Nice change of pace! reply redcobra762 18 hours agoparentprevwhich have cells like humans reply fnordpiglet 17 hours agorootparentAll living things have at least one cell, but they do not all operate in the same way. There’s possibility that worm cells and human cells behave similarly in this, but it’s also fully possible they behave in very dissimilar ways. reply redcobra762 17 hours agorootparentWhich is why this is interesting! I just wanted to combat the whole \"this isn&#x27;t relevant to humans\" pushback. There&#x27;s potential value here. reply Affric 16 hours agorootparentprevTrue, and obviously worms and humans aren’t closely related.With that said, this research is about how cells cooperate to form a multicellular animal.I think it would be interesting to use the results to design an experiment that could be applied to animals more closely related to humans (that with these results in hand you could get passed the animal ethics committee). reply fnordpiglet 13 hours agorootparentWell, it’s how mitochondria in cells in worms cooperate. We already know cells cooperate through many channels and some channels we understand quite well. This is truly only about worms right now. Obviously generalizing to other animals will be important next steps. But the title and text of the article implies a much more general understanding than we actually have. It’s not to diminish the results in the least. But science isn’t served by claiming progress we haven’t made, it makes it harder to fund the next step by building an assumption of nonexistent progress. reply shove 18 hours agoparentprevYep, that’s where we all end up! reply jdjdjdkdksmdnd 17 hours agoprevhow does anyone deny the epigenetic model of aging demonstrated by david sinclair? reply grishka 10 hours agoparentDavid Sinclair is a social media influencer more than anything else. His insistence on life extension through lifestyle alone is telling, because it&#x27;s so easy to sell to the general public. Except this doesn&#x27;t work and can&#x27;t work — if an organism has a goal to destroy itself, which it does as part of its aging program, it WILL destroy itself, no matter how much you change its environment. You need to overwrite that internal goal state to truly cure aging which can&#x27;t be done through any manner of lifestyle interventions. reply anigbrowl 16 hours agoparentprevEffective advocacy begins with letting go of the assumption that everyone already knows about the things you know about. I&#x27;m sure this person is well known within the bioscience community, but this is the first time I&#x27;d heard of him or his model.https:&#x2F;&#x2F;www.nad.com&#x2F;news&#x2F;harvard-professor-david-sinclairs-i... reply throw__away7391 14 hours agorootparent> This technique also extended the lifespan of mice with a premature aging condition by about 40%.Why is it always like this? Even \"in mice\" I think they always start with an animal that has been genetically modified to age faster or show some trait of aging and then cure that, as opposed to taking a normal healthy mouse and extending its age by 40%, no? reply JPLeRouzic 5 hours agorootparent> Why is it always like this?Because it is an easy way to write a paper?Even with the genetic line, same chow and environment, it&#x27;s possible to have mice that are ill in one location and healthy in another.https:&#x2F;&#x2F;www.alzforum.org&#x2F;news&#x2F;research-news&#x2F;gut-microbes-dif... reply _ink_ 16 hours agoparentprevCan you ELI5 it? reply andrewstuart 17 hours agoprev [–] As you get older you find it becomes a key topic of conversation not just amongst your cells but amongst friends - the conversation always heads towards whatever ailment or problem your body has recently dealt you. reply lanstin 17 hours agoparent [–] This effect, which I can confirm in more than set of friends, is one of the most annoying aspects of aging. I&#x27;d rather gossip about the cheer leaders or the football players than listen to people talk about procedures. I certain have a lot more aches and pains but I don&#x27;t care to let my attention linger on them. reply otikik 15 hours agorootparent“You know the captain of the cheerleader team? She has arthritis!” reply gverrilla 15 hours agorootparentprev [–] I think it&#x27;s the inverse of an effect. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Biologists have found that mitochondria in various tissues are capable of communication with each other, aiding in the repair of damaged cells.",
      "This communication failure can potentially lead to a decline in the biological clock and aging.",
      "These findings offer new insights into the aging process and highlight the importance of tissue communication in regulating aging. However, it is unclear whether these findings can be directly applied to humans."
    ],
    "commentSummary": [
      "The passage explores various aspects of aging and its impact on organisms, including the role of natural selection, decline of germ cells, and influence of genes on lifespan.",
      "It discusses the concept of cheating and honesty in evolutionary strategies and the ongoing debate regarding the necessity and benefits of aging.",
      "The potential methods for extending lifespan and the importance of genetic fitness and immune system suppression after reproduction are also touched upon. The passage concludes with speculation about the potential reversibility of aging through DNA manipulation."
    ],
    "points": 227,
    "commentCount": 148,
    "retryCount": 0,
    "time": 1704746274
  },
  {
    "id": 38921343,
    "title": "Carta prioritizes trust and exits secondary trading business",
    "originLink": "https://henrysward.medium.com/should-carta-facilitate-secondary-trading-c319e0c9f080",
    "originBody": "Should Carta Facilitate Secondary Trading? Henry Ward · Follow 3 min read · 14 hours ago -- No. Not anymore. Because we have the data, if we are trading secondaries, people will always worry that we are using the data, even if we are not. So we have decided to prioritize trust, and exit the secondary trading business. For those interested, let me provide more context below. Liquidity has been a problem I wanted to solve for almost a decade. From our Series A deck back in 2014. Nasdaq for Private Markets? We started eShares 10 years ago as the “Nasdaq for Private Markets” (we were not “the captable company”) because I wanted to solve the liquidity problem for founders, employees, and angel investors. The percentage of startups that get to IPO is so small that 99% of founders never receive liquidity and spend a decade or more paper rich but cash poor. That seemed a problem worth solving. Fast forward to today, our business is broken down as follows: the captable business is about $250M/year, fund administration is about $100M, private equity is about $20M, and the secondary trading business is about $3M. We have done a decent job at building the captable business, an ok job at fund admin (but feeling the growing pains), and an abysmal job at the secondary business. It is my greatest failure and disappointment. Some of my other ideas have worked — like captables, 409As, fund administration, private equity. But ALL of my ideas around liquidity — auctions, investor matching, secondary trading, open tender offers, have not worked. I might not be the entrepreneur that can solve this problem. Because We Have the Data, We Can’t Use It But I am learning something else — Carta might not be the company that can solve this problem. Many people think we are best poised to solve liquidity because we have captable data. But that same argument is used for data products. People say “You have all the data so you should put Pitchbook out of business!” But it is precisely because we have the data, that we can’t use it. It is our customers’ data, not ours. That’s why in ten years Carta has never released a data product. I use Pitchbook and Techcrunch when I research a company before I meet the CEO. Having ground truth data is not an advantage if we can’t use it. And it is a disadvantage if people think we use it. For example, if we send emails to prospects through publicly available information, how do customers know if we sourced it publicly or internally? Will they believe us if we tell them? And does it matter? Just the appearance of impropriety is damning. Founders Come First From the beginning, we have always built for founders. Even in our liquidity business, the northstar has been to create systematic founder liquidity, that they control, which they can extend to everyone else on the captable. Historically, liquidity has not been founder friendly and our goal was to change that. But we have not succeeded. We won’t do anything that threatens the trust of our founders. And so we will exit the secondary trading business to eliminate any concern that we are not acting in our founders’ best interests. We will focus on what we do best, which is cap table and fund administration software. There are many many talented people working on the private market liquidity problem. We will enthusiastically cheer for them from the sidelines. It is an important problem. I hope someone solves it.",
    "commentLink": "https://news.ycombinator.com/item?id=38921343",
    "commentBody": "Carta to exit secondary trading businessHacker NewspastloginCarta to exit secondary trading business (henrysward.medium.com) 209 points by thewarpaint 14 hours ago| hidepastfavorite104 comments enra 12 hours agoI’m CEO of Linear who raised the alarm on this.I have to commend them for making this decision and removing the conflict of interest.However they didn’t address the fact that sales people had convenient access to data and how long & broadly that access was abused.Edit: fixed “Linear CEO” to “CEO of Linear” reply CityOfThrowaway 11 hours agoparentThey did address it... by completely eliminating the department.They didn&#x27;t deep dive retro it, but in that, we know the answer. reply milkglass 11 hours agorootparentSo strange. What are the data retention requirements for situations such as this?The whole thing just feels so off. Some big moves but very little details from Carta.Commitments just sound like empty promises now, especially when they&#x27;re presented on Medium. Did any customers receive assurance or details of what went down? reply colechristensen 10 hours agorootparentSome financial institutions are basically required to retain everything for years, Carta may or may not be outside some of those stricter requirements.Given their customers are startups, but more specifically founders themselves, and they handle cap tables, I’m sure they’re getting plenty of direct questions from legal departments with the interest of C suites everywhere. Assurances might well be coming in to form of legal agreements and external audits, and possibly SEC investigations and discovery for lawsuits. reply baobun 5 hours agorootparentprevNo, there is no acknowledgement that anything undue ever happened. Only that business in this department hasn&#x27;t been financially successful and that customers could have concerns.Nothing about those concerns actually being valid. This is vague misdirection at best. reply krallja 3 hours agorootparentIt’s in the previous post: https:&#x2F;&#x2F;henrysward.medium.com&#x2F;how-we-handle-captable-informa...> On Friday we had an internal policy violation that affected three companies. I’ve been in touch with the founders and I’m appalled we made that mistake and it should never have happened. It is unacceptable and we’ve dealt with the violation on Saturday morning and are continuing the investigation to make sure it never happens again. reply stuaxo 4 hours agorootparentprevStop doing the possibly illegal thing, and hope that nobody takes it further I guess. reply jjtang1 11 hours agoparentprevAre you leaving Carta for Pulley or other platforms? We&#x27;ve been long time Carta customers at Rootly. reply enra 10 hours agorootparentWe’re starting to evaluate other platforms, Pulley and Angellist. reply choppaface 10 hours agoparentprevI&#x27;m a former employee of a place that did Carta. Employees are already left in the dark about the cap table, liquidity preferences, venture debt, and the C-Suite&#x27;s relationship with the Board. Based on this exchange, I&#x27;d now see usage of Carta as a red flag when looking at any new start-up. Maybe Schwab or Shareworks are ok (Shareworks has been fine in my own experience). The investors are already doing hyper-leveraged arbitrage with my labor, I don&#x27;t need the HR Comp software to do that too (even if they say they don&#x27;t, and even if they say that business is only worth $3m&#x2F;yr vs $250m&#x2F;yr for accounting). If they want to do that, they can pay me directly. reply athoscouto 7 hours agorootparentI&#x27;ve worked on some companies that used Carta. In some of them, I had access to cap table, preferences, total raised debt, etc. In others, I could see only my number of options and their strike price. Is up to the company how much they want to share, Carta can be used on both ways. reply therobots927 4 hours agorootparentprevI worked for a startup where I repeatedly asked basic questions to estimate the value of my shares. I never got a straight answer. So I applied to a FAANG and got in. When I was onboarding the FAANG asked what my shares I was leaving behind were worth (they take this number and use it to calculate starting bonus). I had no idea, gave an honest estimate, and later found out that I had given them a number about 60% lower than the true value. I&#x27;ll never forgive the startup execs for keeping me in the dark, or ever work for a company again that doesn&#x27;t make that information freely available. One of my favorite memories was walking out the door of that place. reply jey 59 minutes agorootparent> asked what my shares I was leaving behind were worthI always decline to answer these questions by saying \"it&#x27;s not relevant; I&#x27;d like to be compensated according to my background&#x2F;experience and the role\". If there&#x27;s a specific number I&#x27;m looking for, I&#x27;ll also ask for that. But I&#x27;d never directly answer the \"what was your last salary&#x2F;comp?\" question. reply fatnoah 3 hours agorootparentprevI flat out never trust any numbers from startups. Some companies are still using the SaaS 10-13x revenue as an estimation, despite the current economic climate and often in spite of a) not reqlly being a SaaS and b) not growing that fast.Throw in liquidation preferences, etc. and it&#x27;s not really possible to know anyway. I&#x27;ve been at three startups. Two were acquired and one is still plateaued over 10 years after I left. Total value of my stock so far? $0.It&#x27;d have to be some rare unicorn for me to treat startup options as anything other than a lottery ticket. reply jjtheblunt 11 hours agoparentprevwhat is \"linear\"? [ edit : thanks below! ] reply temp_praneshp 11 hours agorootparenthttps:&#x2F;&#x2F;linear.app&#x2F;He&#x27;s the CEO \"of\" Linear, not a linear CEO :) reply dboreham 10 hours agorootparentNow planning to re-brand myself as a logarithmic CEO of course. reply jgilias 10 hours agorootparentI’d rather be an exponential one then! reply esafak 9 hours agorootparentExponent, Inc. is already taken... reply bozhark 1 hour agorootparentExponent, Shell. reply Terr_ 10 hours agorootparentprevOr to CS folks, a CEO(n) reply danmur 11 hours agorootparentprevHe could be both, who are we to judge reply jjtang1 10 hours agorootparentprevLinear is the only thing saving startups like ours from using Jira ;) reply dangrossman 11 hours agorootparentprevThe company he&#x27;s CEO of: https:&#x2F;&#x2F;linear.app reply dataflow 10 hours agorootparentOh wow thanks, I just assumed it&#x27;s Linear Technologies. reply elvinyung 9 hours agoparentprevHow was the beef stew? reply smt88 13 hours agoprevThis is the best response, but remember it&#x27;s a response to getting caught. They didn&#x27;t grow a conscience or replace leadership.My company is still taking our business away from Carta, and I don&#x27;t think anyone&#x27;s plans should change because they repented after being caught. Things might be different if the CEO stepped down, but he hasn&#x27;t yet. reply notfried 13 hours agoparentA quick search shows me a number of alternatives to Carta, but none that I have ever heard of or come across. Is there any competitor that is considered the second best? Carta just seems to me what everyone had been using without a second thought. reply threeseed 12 hours agorootparentPulley is what has been recommended in the past. reply earnesti 12 hours agorootparentprevWhat about an excel sheet? reply thebradbain 12 hours agorootparentAs an early employee at a startup from seed through a healthy Series B last year, I would have serious concerns about the company’s bookkeeping and how-up-to-date the shareholder information is if it were kept in an excel spread sheet on Google drive.Carta and Pulley, etc. do a solve a valuable concern here for non-executives who are compensated with stock options and want to keep track of stock vesting, exercises, and shares in a transparent way, I’d say. reply orionsbelt 12 hours agorootparentprevOnce you get past a handful of grants, every Excel cap table I&#x27;ve seen has been an absolute disaster. Use a software product. Both Carta and Pulley offer free versions, until you exceed certain limits (e.g. for Carta Launch, until you exceed $1M raised or 25 stakeholders). If you are over those limits, even more reason to use a software product and not Excel. reply foooorsyth 11 hours agorootparentprevSome VCs will withhold investment until you use a product like Carta or Pulley. Cap table in Excel carries major risk.(And yes, Carta&#x2F;Pulley are often portcos of those VCs pushing you to use them) reply kenneth 7 hours agorootparentAs a seed VC, I still see a majority of Excel cap tables over Carta. (Pulley &#x2F; Shareworks is even rarer). reply o0-0o 12 hours agorootparentprevnext [4 more] [flagged] mkl 11 hours agorootparentHN doesn&#x27;t have DMs, and you don&#x27;t have any contact info in your profile. I agree about just posting a link though - self-promotion is okay if it&#x27;s clearly relevant and up-front. reply smt88 12 hours agorootparentprevJust post a link and tell us why we should trust you. It&#x27;s an appropriate time&#x2F;place for you to self-premote imo. reply o0-0o 8 hours agorootparentHttps:&#x2F;&#x2F;investorportalpro.com reply Matticus_Rex 12 hours agorootparentprevPeople in my network have recommended both Pulley and AngelList. reply orionsbelt 12 hours agorootparentCarta > Pulley >>> AngelList.This is largely a result of how long each product has been available, i.e. the older products are more mature. Hopefully Pulley and AngelList continue to catch up so there is a diversity of good options available. reply choppaface 9 hours agorootparentprevShareworks, Scwhab reply jrflowers 13 hours agoparentprevYou make a good point. This is the best response despite it being in response to getting caught and them but showing any conscience or replacing leadership.If you think about it if a company acts in a way that makes you no longer want anything to do with them, the best thing is a vague blog post bragging about how much money they make doing other stuff reply xyzzy_plugh 13 hours agoparentprevSeconded. While this is a great move, they have yet to provide assurances that this sort of thing won&#x27;t happen in the future. This blog post doesn&#x27;t sufficiently serve as official policy for us. reply __loam 13 hours agoparentprevThis is also the second shady article I&#x27;ve seen from carta this year.https:&#x2F;&#x2F;sfstandard.com&#x2F;2023&#x2F;10&#x2F;25&#x2F;carta-san-francisco-lawsui... reply helloericsf 10 hours agorootparentWow, this is bad. reply bozhark 1 hour agorootparentWhy do people work for such terribleness? reply choppaface 10 hours agoparentprevAnd then oops we&#x27;ll change our mind again in 6 months because it was only $3m&#x2F;yr revenue we lopped off. Especially as investor interest grows with falling fed rates. By the way, to VCs who want to invest in Carta: look it&#x27;s only $3m&#x2F;yr, we&#x27;re saving so much brand by doing this and it&#x27;s not going to hurt our valuation at all. You should probably value us like an OpenAI, we&#x27;re capturing the light cone of cap table info! reply Waterluvian 12 hours agoparentprevThe only people who will ever be caught using Carta are fools, the unaware, or those who have no choice for some reason. You need a base level of trust and that’s gone. reply xyzzy_plugh 13 hours agoprevTo be honest this still seems off.If Carta shows respect for your data and privacy I believe they could still offer an opt-in secondary market, and I can see plenty of companies being interested in participating in it.No one was complaining about the secondary market, they were complaining that Carta was double dipping with their data without consent. This whole post feels like he&#x27;s just trying to move the goalposts.Ultimately it&#x27;s about treating customer data with respect, building trust, and operating with transparency. They can&#x27;t do those things, so they have to shut the whole thing down?Smells funny. reply logiduck 13 hours agoparentThe core issue of the secondaries market is that companies have a conflict of interest not to participate and the control that they want in order to participate essentially violates securities law. Founders want control over the price, who buys the shares, who can sell, etc. Carta and other companies so far haven&#x27;t been able to solve this problem on mass scale of motivating founders to allow all shareholders to sell on an open market. There was weak demand from the company side so it seems like Carta tried to force it by making the market first and then asking for forgiveness because asking for permission wasn&#x27;t working. reply xyzzy_plugh 12 hours agorootparentI agree.My issue with Carta is now the permission vs forgiveness thing. They won&#x27;t get the opportunity to ask for forgiveness again at least in my case. reply yesimahuman 11 hours agoparentprevAgreed. And to make such a seemingly big decision in a matter of a weekend. Respect for being decisive I guess but this seems impulsive and framing the secondary opportunity to conveniently fit the narrative instead of addressing the core issues that, when resolved, might make it viable reply AmericanChopper 9 hours agoparentprevThe comments ITT are a great example of why it’s often a good idea to ignore complaints and do whatever you want anyway. The behaviour that conventionally would be used to build trust, like admitting when you’re wrong and changing what you’re doing (in this case, shutting down an entire division of your company) is simple met with “no not good enough, you were wrong and should be punished more”. reply dbt00 9 hours agorootparentThey didn’t admit they were wrong, they said it was just the appearance of impropriety. reply gruez 13 hours agoprevPrior drama: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38897363Personally I think it&#x27;s great that they removed this potential conflict of interest, but the fact that the announced this while conveniently omitting the events that led up to this makes me still distrust them. reply dang 10 hours agoprevRelated. Others?How We Handle Cap Table Information - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38906749 - Jan 2024 (88 comments)Linear CEO alleges Carta mishandled sensitive cap table data - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38899001 - Jan 2024 (36 comments)Carta CEO&#x27;s response to the unsolicited outreach to their customers&#x27; investors - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38897363 - Jan 2024 (98 comments)Carta doing unsolicited tender offer outreach to their customers&#x27; investors - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38886915 - Jan 2024 (80 comments) reply JCM9 11 hours agoprevThis is a good move, but still an inadequate response to what originally happened. It’s dogging deep questions about who had access to what data and just how bad the security controls were around startups’ sensitive information. Shutting down this bit of the business doesn’t put folks at ease that their information is still safe with Carta.The Carta CEO has botched the response here multiple times now and this latest pass just comes across as an oops sorry we got caught, we won’t do that anymore response… but still dodging the hard questions on how data was being managed. reply ahahahahah 9 hours agoparentName a startup that doesn&#x27;t have shit security or privacy controls (or regulatory, or ... really anything). reply JCM9 3 hours agorootparentIf you’re a fintech startup you very much do or you’re toast. reply hipadev23 11 hours agoprevThey let $3M out of $373M jeopardize the entire company. What incredibly poor foresight and management controls. reply helloericsf 10 hours agoparentIn the beginning, Ward positioned it as an internal process violation. \"Hi Karri and everyone, I’m appalled that this happened. We are still investigating but it appears that Friday morning an employee violated our internal procedures and went out of bounds reaching out to customers they shouldn’t have.Henry\" https:&#x2F;&#x2F;twitter.com&#x2F;henrysward&#x2F;status&#x2F;1743713154721554849 reply blindriver 13 hours agoprevI thought his responses were terrible and worthy of being fired over the weekend, but I am impressed with his quick action on this. I guess you can put me down as “neutral” towards this person. reply ironmagma 13 hours agoparentThey sound like a classic machiavellian, deflecting at the first sign of criticism. reply rrr_oh_man 13 hours agoparentprevCaught with your hand in the cookie jar pre-IPO. Of course you’d want to act quickly. reply dastbe 12 hours agoparentprevdude pretty clearly got his cheeks clapped by everyone around him, presumably including the board&#x2F;vcs who invest in carta. reply lotsofpulp 11 hours agorootparentDidn’t expect to see the use of “cheeks clapped” in this discussion. reply caesil 8 hours agoparentprevHe really comes across as a sociopath. And I don&#x27;t mean that as an insult. I don&#x27;t see any other good explanation for how he can fail, over and over, to foresee that his clearly unempathetic responses will be received poorly. reply relaunched 12 hours agoprevThere is a lot of patting themselves on the back and no acknowledgement of wrongdoing. They got caught violating trust for an inconsequential revenue stream, at the expense of their biggest revenue stream&#x27;s customer - so, we&#x27;ll shut down the conflict.Also, 409a is a conflict of interest, but since it doesn&#x27;t negatively impact our biggest revenue streams, we&#x27;ll keep doing it (at the expense of tax revenue). reply milkglass 12 hours agoprevI do not understand why these have to be done through Medium posts. reply tw04 9 hours agoparentPresumably to make it difficult for any prospective customers to find. Anyone already in the know can rest assured “things have changed” because they’ve been following the news cycle and will readily find the relevant tweets and medium posts. That in theory cause this all to fall out if the spotlight.Any future unwitting potential customer who didn’t think to search for the current CEOs personal medium account to find a damming scandal about the company will be none the wiser. reply caesil 8 hours agorootparentWell uh, he emailed every customer about it. He also emailed every customer about his previous Medium article, about a different controversy, earlier this year (I hadn&#x27;t known about it until seeing the email). reply kyawzazaw 12 hours agoparentprevAnd the CEO’s own medium reply jez 12 hours agoprevWhen a company says something like:“Fast forward to today, our business is broken down as follows: the captable business is about $250M&#x2F;year, fund administration is about $100M, private equity is about $20M, and the secondary trading business is about $3M.”Is that assumed to be yearly revenue? Earnings? Something else? reply tiffanyh 12 hours agoparentI’d assume annual since the first number says “&#x2F;year”, but that blows my mind captable mgmt is $250M in annual revenue. reply altdataseller 11 hours agorootparentIs that too little? Too much? reply ayewo 9 hours agorootparentThat’s a lot.I had no idea that a well-oiled Excel-as-a-Service could be so lucrative. reply motoxpro 8 hours agorootparentI think that&#x27;s pretty much all SaaS; well-oiled Excel-as-a-Service replygranshaw 12 hours agoprevSeparate of what did or didn’t happen here, I hope more companies crack the secondary market puzzle. The current environment really sucks for startup employee liquidity and might be going on for a lot longer. reply jedberg 10 hours agoparent> I hope more companies crack the secondary market puzzle.This feels like the wrong solution. I mean, the reason we need a secondary market is because companies are going public much later than the used to. Why? Because the government made it a lot more onerous to go public. Why? Because companies were abusing the process to enrich insiders.If we make the secondary market easier, we&#x27;ll just be right back where we were, and then the government would probably just step in and make it onerous again.I think the actual solution here is to make going public easier again while addressing the loopholes for abuse so that companies can go public sooner and everyone can get liquidity sooner. reply jgilias 9 hours agorootparentAnd insiders found ways to enrich themselves even while working with the onerous process. Remember the SPAC craze?Another example of where the honest people get penalized with a heavy process in the name of zero fraud. reply granshaw 10 hours agorootparentprevFrom reading your first paragraph I thought you were heading to an opposite conclusion, but yes, completely agree that we should make it easier to go public reply nico 12 hours agoparentprevYes. Btw, what are someone’s potential liquidity alternatives for ISO options in profitable private startups?What’s an alternative to Carta’s solution? reply granshaw 11 hours agorootparentI know there’s equityzen and probably other marketplaces, but I think the main issue is most even late stage startups ban secondary tradingThis knowledge might be outdated, I quit that game and opted to join public companies since a couple years ago.Yes it’s an upfront risk that employees take when joining but man does it not also feel incredibly one sided and smelly, esp the later stage the startup gets reply Animats 12 hours agoprevSo are they spinning the secondary trading business off into a separate company, or shutting it down completely?If they shut it down, their claimed US$8 billion market cap goes poof, doesn&#x27;t it? Maintaining cap tables as a service can&#x27;t be good for more than a few million a year in revenue. reply ipsum2 11 hours agoparent> Fast forward to today, our business is broken down as follows: the captable business is about $250M&#x2F;year, fund administration is about $100M, private equity is about $20M, and the secondary trading business is about $3M.$250M is more than a few million. reply Animats 10 hours agorootparentThe poster with the original complaint said they were paying about US$10,000 a year for their cap table service. Are there 25,000 startups using this service? reply ayewo 8 hours agorootparentSome startups pay Carta more than $10k a year. For instance, in a community I’m in, someone mentioned that they pay Carta $150k&#x2F;yr. It comes down to how many of Carta’s various services startups find worth paying for. reply bix6 13 hours agoprevWhat other ways does Carta share data?That is my fundamental question after all this. reply altdataseller 13 hours agoparentThey sell equity and compensation benchmark data to other startups. That’s one example reply altdataseller 13 hours agoprevWill they still be selling equity and compensation data or getting out of that business? Technically that’s still a data product too. reply simonebrunozzi 8 hours agoparentIt&#x27;s aggregate. reply altdataseller 4 hours agorootparentAnd? That’s still taking customers data and selling it reply RunawayGalaxy 13 hours agoprevDoes that go for Carta Marketplace also? Asking because it seems to be a separate business. reply elefanten 8 hours agoparentYeah, the commitments in this post don’t preclude an entity other than Carta doing the same thing.It seems incredibly risky and foolish to try, to the point that I don’t expect them to. But this post leaves room for other attempts. reply simpleEQ 7 hours agoprevI&#x27;ve heard there are some European companies that started to join the equity management game. products like Nimity are bound to respect the EU data protection regulations, so they might be a solution of how to avoid such data breach issues. reply andrewstuart 12 hours agoprevThis is a business entirely dependent on trust.Trust is quickly lost and hard to win. reply htrp 9 hours agoprevIs there anything more complex to what carta offers to justify the 10k a year price tags ? reply htrp 9 hours agoprevThey&#x27;ll be back in this business again in 2 years. reply o0-0o 12 hours agoprevI run a competitive product if anyone wants an honest run good business alternative reply esafak 9 hours agoparentwhat reply o0-0o 8 hours agorootparentInvestorportalpro.com reply asylteltine 12 hours agoprevWhat does carta do that a spreadsheet can’t? I don’t understand how that can be so hard you pay an entire company to manage it. reply aku286 6 hours agoparentYou know the answer, you just don&#x27;t want to believe it. Something trivial to you might be non-trivial to someone else and vice-versa. reply dboreham 10 hours agoparentprevDoes this question need to be asked when there are countless (even very successful) SaaS companies that do something that can be done with a 100-line bash script. reply refulgentis 14 hours agoprev [–] BRAVO!!!!Edit: we did just spend 2 days pouring over every negative detail, I don&#x27;t think this has to be at -5. I will consider it a karmic offering of the karma I got for being negative replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Carta, a cap table and fund administration software company, is exiting the secondary trading business to prioritize trust and protect the interests of its founders.",
      "Although Carta has data that could be used for liquidity solutions, the company is concerned about potential misuse and believes it has not successfully solved the liquidity problem.",
      "Instead, Carta will be shifting its focus back to its core business and continue to support others working on private market liquidity solutions."
    ],
    "commentSummary": [
      "Carta is leaving the secondary trading business due to concerns about potential conflicts of interest and access to and abuse of data by salespeople.",
      "Customers are dissatisfied with Carta's lack of details and assurance, prompting them to consider alternative platforms such as Pulley and Angellist.",
      "There is skepticism and distrust surrounding the transparency and trustworthiness of Carta's financial software, with discussions about alternative companies for managing stock options and cap tables."
    ],
    "points": 209,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1704766292
  }
]
