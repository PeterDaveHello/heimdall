[
  {
    "id": 39778999,
    "title": "Apple Faces Antitrust Lawsuit Over iPhone Monopoly",
    "originLink": "https://www.nytimes.com/2024/03/21/technology/apple-doj-lawsuit-antitrust.html",
    "originBody": "ADVERTISEMENT SKIP ADVERTISEMENT U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly The lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have fueled its growth into a nearly $3 trillion public company. Share full article 2575 Video TRANSCRIPT 0:00/1:20 Garland Accuses Apple of Violating Federal Antitrust Law Attorney General Merrick B. Garland said that Apple has employed a strategy that relies on exclusionary anti-competitive conduct that hurts both consumers and developers. Over the last two decades, Apple has become one of the most valuable public companies in the world. Today, its net income exceeds the individual gross domestic product of more than 100 countries. That is in large part due to the success of the iPhone, Apple’s signature smartphone product. But as our complaint alleges, Apple has maintained monopoly power in the smartphone market, not simply by staying ahead of the competition on the merits, but by violating federal antitrust law. Consumers should not have to pay higher prices because companies break the law. We allege that Apple has employed a strategy that relies on exclusionary, anticompetitive conduct that hurts both consumers and developers. For consumers, that has meant fewer choices, higher prices and fees, lower quality smartphones, apps and accessories, and less innovation from Apple and its competitors. For developers, that has meant being forced to play by rules that insulate Apple from competition. And as outlined in our complaint, we allege that Apple has consolidated its monopoly power, not by making its own products better, but by making other products worse. Attorney General Merrick B. Garland said that Apple has employed a strategy that relies on exclusionary anti-competitive conduct that hurts both consumers and developers. Credit Credit... Ian C. Bates for The New York Times By David McCabe and Tripp Mickle David McCabe reported from Washington, and Tripp Mickle from San Francisco. March 21, 2024 The federal government’s aggressive crackdown on Big Tech expanded on Thursday to include an antitrust lawsuit by the Justice Department against Apple, one of the world’s best-known and most valuable companies. The department joined 16 states and the District of Columbia to file a significant challenge to the reach and influence of Apple, arguing in an 88-page lawsuit that the company had violated antitrust laws with practices that were intended to keep customers reliant on their iPhones and less likely to switch to a competing device. The tech giant prevented other companies from offering applications that compete with Apple products like its digital wallet, which could diminish the value of the iPhone, and hurts consumers and smaller companies that compete with it, the government said. The Justice Department’s lawsuit is seeking to put an end to those practices. The government even has the right to ask for a breakup of the Silicon Valley icon. Read the Lawsuit Against Apple The antitrust suit is the federal government’s most significant challenge to the reach and influence of the company. READ DOCUMENT 88 PAGES The lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have fueled its growth into a nearly $2.75 trillion public company that was for years the most valuable on the planet. It takes direct aim at the iPhone, Apple’s most popular device and most powerful business, and attacks the way the company has turned the billions of smartphones it has sold since 2007 into the centerpiece of its empire. By tightly controlling the user experience on iPhones and other devices, Apple has created what critics call an uneven playing field, where it grants its own products and services access to core features that it denies rivals. Over the years, it has limited finance companies’ access to the phone’s payment chip and Bluetooth trackers from tapping into its location-service feature. It’s also easier for users to connect Apple products, like smartwatches and laptops, to the iPhone than to those made by other manufacturers. “Each step in Apple’s course of conduct built and reinforced the moat around its smartphone monopoly,” the government said in the lawsuit, which was filed in the U.S. District Court for the District of New Jersey. It added that the company’s practices resulted in “higher prices and less innovation.” Apple says these practices make its iPhones more secure than other smartphones. But app developers and rival device makers say Apple uses its power to crush competition. “This lawsuit threatens who we are and the principles that set Apple products apart in fiercely competitive markets,” an Apple spokeswoman said. “If successful, it would hinder our ability to create the kind of technology people expect from Apple — where hardware, software, and services intersect. It would also set a dangerous precedent, empowering government to take a heavy hand in designing people’s technology.” Apple is the latest company the federal government has tried to rein in under a wave of antitrust pressure in recent years from both the Justice Department and the Federal Trade Commission, to which the Biden administration has appointed heads sharply focused on changing the laws to fit the modern era. Google, Meta and Amazon are all facing similar suits, and companies from Kroger to JetBlue Airways have faced greater scrutiny of potential acquisitions and expansion. The lawsuit asks the court to stop Apple from engaging in current practices, including blocking cloud-streaming apps, undermining messaging across smartphone operating systems and preventing the creation of digital wallet alternatives. The Justice Department has the right under the law to ask for structural changes to Apple’s business — including a breakup, said an agency official, who spoke on condition of anonymity. The official declined to identify what additional action the agency could request in this case but any demands would be tied to how a court rules on the question of whether — and how — Apple broke the law. It’s unclear what implications the suit — which is likely to drag out years before any type of resolution — would have for consumers. Apple plans to file a motion to dismiss the case in the next 60 days. In its filing, the company plans to emphasize that competition laws permit it to adopt policies or designs that its competitors oppose, particularly when those designs would make using an iPhone a better experience. Apple has effectively fought off other antitrust challenges. In a lawsuit over its App Store policies that Epic Games, the maker of Fortnite, brought in 2020, Apple persuaded the judge that customers could easily switch between its iPhone operating system and Google’s Android system. It has presented data showing that the reason few customers change phones is their loyalty to the iPhone. Image The lawsuit takes direct aim at the iPhone and attacks the way Apple has turned the billions of smartphones it has sold since 2007 into the centerpiece of its empire. Credit... George Etheredge for The New York Times It also has defended its business practices in the past by highlighting how the App Store, which it opened in 2008, created millions of new businesses. Over the past decade, the number of paid app makers has increased by 374 percent to 5.2 million, which Apple has said is a testament to a flourishing marketplace. Every modern-day tech giant has faced a major federal antitrust challenge. The Justice Department is also pursuing a case against Google’s search business and another focused on Google’s hold over advertising technology. The Federal Trade Commission filed a lawsuit accusing Meta, which owns Facebook, of thwarting competition when it bought Instagram and WhatsApp and another accusing Amazon of abusing its power over online retail. The F.T.C. also tried unsuccessfully to block Microsoft from acquiring Activision Blizzard, the video game publisher. The lawsuits reflect a push by the regulators to apply greater scrutiny to the companies’ roles as gatekeepers to commerce and communications. In 2019, under President Donald J. Trump, the agencies opened antitrust inquiries into Google, Meta, Amazon and Apple. The Biden administration has put even more energy behind the effort, appointing critics of the tech giants to lead both the F.T.C. and the antitrust division of the Department of Justice. In Europe, regulators recently punished Apple for preventing music streaming competitors from communicating with users about promotions and options to upgrade their subscriptions, levying a 1.8 billion-euro fine. App makers have also appealed to the European Commission, the European Union’s executive arm, to investigate claims that Apple is violating a new law requiring it to open iPhones to third-party app stores. In South Korea and the Netherlands, the company is facing potential fines over the fees it charges app developers to use alternative payment processors. Other countries, including Britain, Australia and Japan, are considering rules that would undercut Apple’s grip on the app economy. The Justice Department, which began its investigation into Apple in 2019, chose to build a broader and more ambitious case than any other regulator has brought against the company. Rather than narrowly focus on the App Store, as European regulators have, it focused on Apple’s entire ecosystem of products and services. The lawsuit filed Thursday focuses on a group of practices that the government said Apple had used to shore up its dominance. The company “undermines” the ability of iPhone users to message with owners of other types of smartphones, like those running the Android operating system, the government said. That divide — epitomized by the green bubbles that show an Android owner’s messages — sent a signal that other smartphones were lower quality than the iPhone, according to the lawsuit. Apple has similarly made it difficult for the iPhone to work with smartwatches other than its own Apple Watch, the government argued. Once an iPhone user owns an Apple Watch, it becomes far more costly for them to ditch the phone. The government also said Apple had tried to maintain its monopoly by not allowing other companies to build their own digital wallets. Apple Wallet is the only app on the iPhone that can use the chip, known as the NFC, that allows a phone to tap-to-pay at checkout. Though Apple encourages banks and credit card companies to allow their products to work inside Apple Wallet, it blocks them from getting access to the chip and creating their own wallets as alternatives for customers. The government said that Apple refuses to allow game streaming apps that could make the iPhone a less valuable piece of hardware or offer “super apps” that let users perform a variety of activities from one application. The government’s complaint uses similar arguments to the claims it made against Microsoft decades ago, in a seminal lawsuit that argued the company was tying its web browser to the Windows operating system, said Colin Kass, an antitrust lawyer at Proskauer Rose. He added that the most compelling allegation — and the one that brings it closest to the Microsoft case — is that Apple could be contractually preventing rivals from developing apps that work with other app providers, as “super apps” could. Other legal experts noted that companies are legally allowed to favor their own products and services, so the government will have to explain why that is a problem with Apple. “This case is about technology,” Mr. Kass said. “Can the antitrust laws force a company to redesign its product to make it more compatible with competitors’ products?” Apple has defended itself against other antitrust challenges by arguing that its policies are critical to make its devices private and secure. In its defense against Epic Games, it argued that restraining the distribution of apps allowed it to protect the iPhone from malware and fraud. The practice benefited customers and made the iPhone more attractive than competing devices with Android’s operating system. The government will try to show that the effect of Apple’s policies was to hurt consumers, not help them. “Competition makes devices more private and more secure,” said Jonathan Kanter, assistant attorney general of the Justice Department’s antitrust division. “In many instances, Apple’s conduct has made its ecosystem less private and less secure.” David McCabe covers tech policy. He joined The Times from Axios in 2019. More about David McCabe Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. More about Tripp Mickle A version of this article appears in print on , Section A, Page 1 of the New York edition with the headline: U.S. Suing Apple, Seeing Monopoly Built on Iphones. Order ReprintsToday’s PaperSubscribe 2575 Share full article 2575 ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=39778999",
    "commentBody": "U.S. sues Apple, accusing it of maintaining an iPhone monopoly (nytimes.com)2215 points by jcfrei 19 hours agohidepastfavorite2114 comments bigtones 19 hours agoHere is the non-paywall link to the full NYT article I shared: https://www.nytimes.com/2024/03/21/technology/apple-doj-laws... Kon-Peki 18 hours agoparentDirect link https://s3.documentcloud.org/documents/24492020/doj-apple-an... dublinben 16 hours agorootparentHere it is from Justice.gov as well: https://www.justice.gov/opa/media/1344546/dl?inline colpabar 19 hours agoparentprevhttps://archive.is/SYlk5 Fripplebubby 18 hours agoprevFor folks who don't have time to read a 90 page document, the case rests on specific claims, not just the general claim that iPhone is a monopoly because it's so big. Here are those claims: 1. \"Super Apps\" Apple has restrictions on what they allow on the App Store as far as \"Super Apps\", which are apps that might offer a wide variety of different services (specifically, an app which has several \"mini programs\" within it, like apps within an app). In China, WeChat does many different things, for example, from messaging to payments. This complaint alleges that Apple makes it difficult or impossible to offer this kind of app on their platform. Apple itself offers a \"super app\" of course, which is the Apple ecosystem of apps. 2. Cloud streaming apps Similar to \"super apps\", the document alleges that Apple restricts apps which might stream different apps directly to the phone (like video games). It seems there are several roadblocks that Apple has added that make these kinds of apps difficult to release and promote - and of course, Apple offers their own gaming subscription service called Apple Arcade which might be threatened by such a service. 3. Messaging interoperability Probably most people are familiar with this already, how messages between (for example) iOS and Android devices do not share the same feature-set. 4. Smartwatches Other smart watches than the Apple Watch exist, but the document alleges that Apple restricts the functionality that these devices have access to so that they are less useful than the Apple Watch. Also, the Apple Watch itself does not offer compatibility with Android. 5. Digital wallets It is claimed that Apple restricts the APIs available so that only Apple Pay can implement \"tap to pay\" on iOS. In addition to lock-in, note that Apple also collects fees from banks for using Apple Pay, so they get direct financial benefit in addition to the more nebulous benefit of enhancing the Apple platform. reply ChuckMcM 16 hours agoparentThis feels like it reflects similar actions taken against companies that are dominant in a market. The first one I heard about[1] was IBM versus Memorex which was making IBM 360 \"compatible\" disk drives. IBM lost and it generated some solid case law that has been relied on in this sort of prosecution. In the IBM case it opened up an entire industry of third party \"compatible\" peripherals and saved consumers a ton of money. [1] I had a summer intern position in Field Engineering Services in 1978 and it was what all the FEs were talking about how it was going to \"destroy\" IBM's field service organization. reply xpe 15 hours agorootparent> This feels like it reflects similar actions taken against companies that are dominant in a market. Not simply that a company is dominant; it is more about how and why they are dominant. Update 2:40 pm ET: After some research, the practices below may capture much (though not necessarily all) of what the Department of Justice views unfavorably: * horizontal agreements between competitors such as price fixing and market allocation * vertical agreements between firms at different levels of the supply chain such as resale price maintenance and exclusive dealing * unilateral exclusionary conduct such as predatory pricing, refusal to deal with competitors, and limiting interoperability * conditional sales practices such as tying and bundling * monopoly leveraging where a firm uses its dominance in one market to gain an unfair advantage in another Any of these behaviors undermines the conditions necessary for a competitive market. I'd be happy to have the list above expanded, contracted, or modified. Let me know. reply bmitc 1 hour agorootparentAnd that is stuff Apple absolutely does. I have been at a company for which Apple was a customer. But you'd think that Apple owned the company the way they through around their power and demands. reply alsetmusic 7 hours agorootparentprevI’ve read a few takes on this from smart people. This is the first time I’ve seen anything that sounds like a real winnable case. Thanks for the distillation. It’s good to know this isn’t as boneheaded as I’d thought (though they still need to go after the App Store). reply joemazerino 7 hours agorootparentprevExcellent breakdown. Much more concise compared to other versions of the story. And, to boot, all entirely true. reply Jagerbizzle 12 hours agorootparentprevThank you reply dmix 16 hours agorootparentprev> In the IBM case it opened up an entire industry of third party \"compatible\" peripherals and saved consumers a ton of money I’m curious what market opportunities the Apple suit could open up. - Xbox cloud game streaming - WeChat like super apps w e-commerce (X wanted to do this play but more likely Facebook Messenger and the like) - iMessage on android - a receipt tracking app or something directly tied into Apple Pay tapping reply ChuckMcM 16 hours agorootparentFrom a hardware standpoint third party fitness trackers with full integration into iHealth and third party ear buds with the same (or better) features than airpods. Part of the IBM settlement required them to document interoperability. That was used by the DoJ to force Microsoft to document their CIFS (distributed storage) and Active Directory (naming/policy) protocols. The latter might be particularly instructive as my experience with CIFS when I worked at NetApp was the different ways that Microsoft worked to be \"precisely\" within the lines but to work against the intent. Documentation like \"this bit of this word must always be '1'\" Which as any engineer knows, if it really was always '1' then that bit didn't have to be in the protocol, so what did it do when it wasn't '1'? reply anonymouse008 13 hours agorootparent> From a hardware standpoint third party fitness trackers with full integration into iHealth and third party ear buds with the same (or better) features than airpods. As someone who makes apps in the health space, I couldn’t care less if other tracker data was integrated into HealthKit. HealthKit honestly sucks - it's some bastard of objc naming schemes and methods jammed into Swift. The async is horrible to debug, too. No one has a good time in HK. The issue with other trackers is that they are more locked down than Apple. You can't just get HR from Oura for instance - and that's not a health kit issue either. reply jimrandomh 8 hours agorootparentThe reason you can't get heart rate data from Oura is that they don't want people looking at it except in aggregate, because then they would notice the accuracy problems and data gaps. reply Thorrez 5 hours agorootparentprev>Documentation like \"this bit of this word must always be '1'\" Which as any engineer knows, if it really was always '1' then that bit didn't have to be in the protocol, so what did it do when it wasn't '1'? Maybe it was a deprecated part of the protocol, and setting it would cause an error or do nothing. reply thaumasiotes 4 hours agorootparentMaybe it's there to prevent desyncing errors that occur for long strings of zeroes. Information theory isn't the only possible consideration. reply cryptonector 11 hours agorootparentprevI had a similar experience with MSFT docs when working at Sun. The docs were not very good, and though they seemed somewhat redacted, it felt like in fact their internal docs probably weren't much better. reply m463 10 hours agorootparentDon't tall into that trap of thinking. Many years ago I knew an ex-microsoft engineer. Microsoft had poor interoperability with something, and I speculated that engineers in microsoft didn't know what 3rd parties were doing and accidentally broke things. He told me, \"don't be naive - microsoft would have meetings saying 'how can we own this?'\" reply throwaway-blaze 5 hours agorootparentNot to cast doubt on your friend's story, I worked on both the SQL Server team and later on the Windows kernel team in the early 2000s (the bad years). I came from \"outside\" meaning I had already had a career at non-Microsoft-related companies (mostly startups using linux on the server). I was continually shocked at how _little_ the MSFT employees seemed to know about the industry, or how their customers used their own products. As an example, this was the era of the J2EE App Server. Almost none of the people I worked with knew what an App Server was, despite the #1 database in use by App Server customers being MSFT SQL Server. reply astrange 44 minutes agorootparentI still don't know what an app server is. Isn't that one of those things from the enterprise programming era where they'd get \"architects\" to design an \"enterprise system\" and it would come with twenty different things with names like \"message bus\" and \"dependency injection\" that no program in history has ever actually needed? reply m463 5 hours agorootparentprevThis was before that, early to mid 90's era reply thaumasiotes 3 hours agorootparentprevMicrosoft's documentation for Microsoft's own technologies (as in, the C# libraries they provide) is terrible. What's the competitive advantage there? reply microtherion 12 hours agorootparentprevI'm not a developer in this space myself, but my impression is that HealthKit is one area where 3rd party apps have access to the same data as 1st party apps. reply heromal 6 hours agorootparentprevReminds me of Bob Colwell's talk, although it's not from the same angle: https://youtu.be/jwzpk__O7uI?si=NZmfU6av_2D-uPgk (around 1:04:10) reply johnnyanmac 15 hours agorootparentprevForget iMessage, I just want media messages from iPhone to not be sub-144p pictures/videos. I know sms is limited but I doubt that's a technical limitation. And yea, Gamepass was an immediate thought of something a company wanted to ship but Apple blocked. Between that and the Epic Games store it looks like there's gonna be a lot more options to game on IOS by the turn of the decade. reply mullingitover 14 hours agorootparentIt's not sms, it's mms, and it is in fact a technical limitation. Honestly we should just sunset MMS entirely. It's like using 56k dialup. reply gryn 14 hours agorootparentyeah, but the one blocking its sun-setting is apple with their artificial barriers. if apple didn't do it's shenanigans, RCS or something similar with a different name would've have replaced MMS by now. reply throwaway-blaze 5 hours agorootparentUm no, if the powers that be who control the LTE and 5G (and soon 6G) standards would improve or replace MMS, apple would be forced to improve their ability to send images/videos because they must comply with the standards to have their phone allowed on the carrier networks. This is a dumb complaint honestly. The carriers and Qualcomm closely control the standards bodies and could address this problem. Instead they focused on the bag-of-garbage that is RCS, which Apple has finally said they will support. But because RCS is a bag-of-garbage, Apple plans to support a different flavor (the basic standard) from Google's. $0.50 says Google will magically start supporting the basic standard too once Apple ships it. reply inferiorhuman 13 hours agorootparentprevif apple didn't do it's shenanigans, RCS or something similar with a different name would've have replaced MMS by now. The only reason there's any RCS interoperability right now is because most carriers have bought into the Google RCS stack. Before that you absolutely had to be aware of which carrier the recipient was using. If memory serves T-Mobile is running both a Google and non-Google RCS stack. RCS is and was a mess. Hell, if you've a rooted Android you can't access Google RCS and any RCS messages sent your way will disappear into the ether. reply simfree 12 hours agorootparentThere are no third party RCS apps outside of hardware manufacturer skins on Google Messages as Google has shut them all out. If you want to interact with the RCS world as a non-wireless carrier, expect to pay upwards of 10 cents a message and have a minimum revenue commit of thousands of dollars a month. Carriers also don't get paid for inbound texts on RCS, creating a huge new cost center instead of symmetrical texting volume resulting in minimal costs like the current SMS/MMS ecosystem. reply throwaway-blaze 5 hours agorootparentThis is untrue, the US carriers had a \"cross-carrier\" consortium that had built most of its own RCS stack, complete with animating dots when the other party was typing, and good image and video support. But Samsung refused to use it (not sure if Google was bribing them in the background) so it got killed in favor of supporting Google's flavor of RCS. reply j16sdiz 4 hours agorootparentAny source for that? Afaict, every Telco now use Google's RCS stack. reply pests 3 hours agorootparentI also can't remember what it was called, but every Telxo uses Google's because of its failure. reply rezonant 1 hour agorootparent> In October 2019, the four major U.S. carriers announced an agreement to form the Cross-Carrier Messaging Initiative to jointly implement RCS using a newly developed app. This service was to be compatible with the Universal Profile.[34] However, this carrier-made app never came to fruition. And later, both T-Mobile and AT&T signed deals with Google to adopt Google's Messages app. https://en.m.wikipedia.org/wiki/Rich_Communication_Services reply mullingitover 14 hours agorootparentprevnext [35 more] [flagged] ygjb 14 hours agorootparentThat is a shockingly user hostile take, especially considering you call out the reason why so many people still use it: it is the only solution for most users that consistently works. The main reason people still use it is despite the issues with MMS (and SMS in general) the reality is that every vendor wants to own the messaging stack to build or strengthen moat, and the regulators who are in a position to enforce standard protocols have incentives in many or all countries to weaken the security of messaging protocols to meet surveillance objectives (whether those objectives are well scrutinized methods with judicial oversight, or blanket surveillance requirements). Blaming the user as lazy or incompetent completely overlooks the significant financial incentives that platform owners and network providers have to maintain the status quo, or force the new status quo to strengthen their moats. reply Karrot_Kream 12 hours agorootparentBoth your post and OP's are confident and emotionally forceful without any reasoning why. On one hand, in most of the world, especially countries less developed than the US, messaging apps are very popular and SMS is either not even provided in the plan or barely used. On the other I do think that at the very least phone manufacturers consider MMS/SMS to be a core functionality because it's built into most phones. As such it does feel user hostile to not care about MMS/SMS. I can see the merits of both but don't know why I'd believe one over the other. I'm curious where y'all's confidence comes from in user hostility or not and what indicators you have to tip your hand one way or the other. That might result in more elucidating conversation too. reply ygjb 9 hours agorootparentSure, I consider calling users lazy and incompetent very hostile because I have spent nearly 22 years building, testing and securing systems starting with ecommerce apps in the early 2000s, through government, finance, browsers and supporting services (Mozilla), internet scale infrastructure at OpenDNS, Cisco, And Fastly, and now at Amazon. All along the way people routinely attack users for making poor decisions when they are simply using defaults, or the easiest to use and most compatible technologies. * Pffft... Of course they got hacked, they used IE * Of course they got hacked, they opened an email attachment * Of course they got hacked, they clicked that homoglyph In this particular case, SMS and MMS are baked into the phone, and delivered by the wireless provider, and for better or worse on the UX front, work with just a phone number and across all mobile OS. For anything other than that, if users have peers using other device or services, the alternative is to use multiple services to communicate with different groups based on which services they use. That means repeating messages across multiple providers, and/or missing folks because all the platform services have actively silo'd their platforms to prevent interoperability. Yeah, SMS and MMS suck, but they suck less for the simple use case of messaging folks with cell phones, because the barrier to messaging those folks is having their phone number. It's lazy and incompetent to attack users when users actually have very little control over the actual security or usability of the services and systems they use, especially as everything is hosted in cloud platforms. reply makapuf 13 hours agorootparentprevMost people couldnt care less with sub par video message security for most (not all) uses. The fact that every vendor want anything but a good standard stack for keeping their users captive is imo a more powerful incentive. reply rezonant 14 hours agorootparentprevPlease don't conflate messaging apps with texting, it's disingenuous. Texting is the feature users expect of any smartphone to be able to send a message to any other user who has a smartphone, regardless of what apps they have installed. reply astrange 12 hours agorootparentMy vague understanding is nobody uses SMS outside America and the entire population is on WhatsApp. reply microtherion 12 hours agorootparentIf only! My wife seems to juggle her friends between SMS, iMessage, WhatsApp, Telegram, and Signal. reply rezonant 11 hours agorootparentSounds complicated. No wonder people in the US don't want to do that when texting is 100% free (with their phone plan) and universal. reply geraldwhen 10 hours agorootparentYeah I’m not installing an app to send a message. I get video and gifs and all sorts of whatever I need with iMessage. Only android people fuss with third party apps because their phones can’t reasonably send messages by default. reply lucasban 7 hours agorootparentAndroid devices can reasonably send messages between each other, by default. The whole issue here is that Apple has been intentionally holding back the cross-platform messaging experience in order to make competitors seem less appealing. reply lynx23 1 hour agorootparentI can easily send SMS to any Android phone from my iPhone. I really dont understand your reasoning. IOW, SMS is cross-platform. Whats the issue? reply lucasban 1 hour agorootparentAs an iOS user myself, SMS is still a low quality messaging experience, cross platform or not. Apple could have taken RCS seriously years ago, raising the standard of cross platform messaging for everyone. This would result in an objectively better experience for users of all platforms, including iOS. reply lynx23 1 hour agorootparentprevThe difference between SMS and iMessage doesn't really count in this context, since usage is largely transparent. Its the same app, and the same contact list. reply mullingitover 14 hours agorootparentprevnext [21 more] [flagged] throwway120385 13 hours agorootparentThe legacy phone system has a lot of features that aren't present in its replacement, such as freedom to connect with anyone who has a phone number, the ability to move your phone number from carrier to carrier, and the knowledge that as an individual the phone company can't block me from contacting its subscribers entirely for free as long as I pay a fee to my own phone company. It's way better than being on Whatsapp or iMessage or Slack or Teams or whatever you're proposing to replace it because I have a lot of control over who can contact me and nobody is using my presence on the phone network as a means to drag all of my friends over to the same phone network. reply mullingitover 13 hours agorootparentThe legacy phone system currently enables breathtaking amounts of abuse and fraud. I know all the benefits you're listing, and I would enthusiastically surrender them just to watch the legacy phone system be decommissioned. If we invented the legacy phone system today, it would be illegal to operate because it's so insecure. We certainly wouldn't dream of forcing everyone to use it. reply simfree 12 hours agorootparentAny replacement would have the same fraudulent traffic migrate to it. You can already see this type of fraudulent traffic occur on Telegram with the constant crypto bots and on Signal with the romance scams. A PSTN sunset would force this fraudulent traffic to migrate to the over the top communications platforms, eliminate many people's ability to access emergency services reliably, destroy reliable voice quality on cellular networks as there's no consistent way to prioritize third party voice and video traffic. reply mullingitover 12 hours agorootparent> Any replacement would have the same fraudulent traffic migrate to it. We've had SSL on the web for 30 years now. We don't visit our bank's web site and wonder if we're really talking to our bank, but we casually accept that of course someone calling from our bank's phone number could be a fraudster. There might be some fraud that is able to migrate, but it wouldn't be the smorgasbord for fraudsters that the legacy phone system has created. > eliminate many people's ability to access emergency services reliably This is like saying that we can't put out the dumpster fire because it provides some people with warmth. The 911 system (at least in the US) is already a travesty. Caller locations are a crapshoot for wireless calls. Call centers aren't centralized, standardized, or coordinated, and they're overloaded. The technology is outdated. Moving it off the phone network and onto a centralized digital platform would be a massive improvement. reply AnthonyMouse 13 hours agorootparentprevAll you would need to replace this is a messaging app that uses email addresses as identifiers and then falls back to sending messages via email if the recipient doesn't have the app. reply throwway120385 13 hours agorootparentWhat organization runs the messaging app? Do we have some kind of consortium of companies? And how do we add or remove companies from that list? There are actually a lot of social problems around this that are already solved by the network of arrangements between the companies that run our phone system and the users of the phone system and so on. You'd likely end up recreating that and at the end of the day you'd have rebuilt the phone system. The technical problems are a very small part of this. reply AnthonyMouse 12 hours agorootparentNo organization runs the messaging app, it's a protocol that anyone can implement. Publish an RFC. The first time you contact someone who uses a different provider, their messaging app or service sends you an email asking you to confirm that you sent the message, after which your app is associated with your email address on their provider. A combined messaging+email app could handle this automatically. At that point you can make calls, video chats, group chats, E2E encrypted direct messaging etc., using an email address as an identifier. In general, solve problems in the same way that email does but add protocol support for realtime direct communications and end-to-end encryption. reply throwway120385 9 hours agorootparentSomebody has to pay for the infrastructure. You can either have a very loose federation of a lot of individuals running their own infrastructure like in the early Internet on one end of the spectrum or a couple of big companies that essentially run everything like we have now with Google and Meta. But someone has to run it. If you rely on a single company to stand up everyone's instance of the application, then you're right back where we are right now. And how do you manage all of the configuration data for all of the users? There are a lot of practicalities here that I worry you don't appreciate when you say \"It's a protocol that anyone can implement.\" Well, so is PSTN. It just so happens that you need a certain amount of infrastructure to implement it, which is true of everything, even email. I'm not convinced that a new protocol gets us anywhere because it doesn't solve the underlying very human tendency to want to pay someone to deal with all the unsightly stuff so you can get on with your life, which is incidentally also the problem we have with email vis a vis Google. reply AnthonyMouse 56 minutes agorootparent> You can either have a very loose federation of a lot of individuals running their own infrastructure like in the early Internet on one end of the spectrum or a couple of big companies that essentially run everything like we have now with Google and Meta. Or you could have thousands of medium-sized companies that each operate nodes that interoperate with each other even though none of them is the size of Google or Meta, and users could choose one based on whether they want to see ads or pay a few bucks a year, or run their own if they're into that sort of thing. > It just so happens that you need a certain amount of infrastructure to implement it, which is true of everything, even email. The infrastructure you need for email is any functioning general purpose computer, including ones you can find in the trash, and a domain name, which you can also get for free if you really want to and in practice costs around $15/year to do it properly. Anyone with the inclination can do this and many solitary individuals actually do. The infrastructure you would need for this thing would be even less, because the premise is that you already have an email address/provider, so all you'd really need is the ability to map a port so you can make a direct connection to the other endpoint -- or IPv6. Whereas the infrastructure you need to participate in the PSTN... I think you're required to be a CLEC to even have a block of numbers assigned. If all you had to do was install Asterisk on the trash PC it would be something else entirely, but the telcos do a lot of regulatory gatekeeping, which is another reason the legacy phone network should be decommissioned and replaced by a modern IETF protocol. reply idle_zealot 10 hours agorootparentprevMy understanding is that used to be how most text messaging was done pre-smartphone in Japan. Currently the only similar thing I'm aware of is https://delta.chat/en/, though I believe it does all of its networking over email, rather than only using it as a fallback. I wonder what the pitfalls of using email this way are; it seems like a great way to get a free backend and growth-hack a chat app, so there must be some reason it's not more common. reply AnthonyMouse 10 hours agorootparentIt's the idealist's solution because it benefits the user. Companies typically want to use phone numbers because they're more expensive for users to maintain separate identities with, which helps when you want to track them. Moreover, companies want lock-in to their own network effect, not a federated network that anybody else can permissionlessly join. It's the sort of thing you get when somebody builds it as a hobby project, or a skunkworks project escapes from a large corporation and is already open source by the time the MBAs get their hands on it. Or, in the old days, DARPA funding. reply rezonant 11 hours agorootparentprev99 standards on the wall, 99 standards... take one down, pass it around, 101 standards on the wall. https://xkcd.com/927/ reply AnthonyMouse 11 hours agorootparentExcept that the popular messaging apps don't have published standards and you can't interoperate with them even if you wanted to. How do you implement the iMessage protocol on Android or Windows? Point me to the existing IETF RFC for e.g. mapping email addresses as identifiers for use in a standard communications protocol for voice and video calls. reply pierat 7 hours agorootparentYou used to be able to, with tools like Trillian and Gaim. Not any more, at least for any semi-popular chat. The throwaway and no-names? Yeah you can, well until IF they get big. And well, they won't. reply theshackleford 12 hours agorootparentprev> I have a lot of control over who can contact me This might be the funniest thing I’ve ever heard. It’s literally legal in my country to spam me on my phone number and there is ZERO I can do to change that. Ergo I have fuck all control over who can contact me. reply Detrytus 13 hours agorootparentprev> freedom to connect with anyone who has a phone number This is actually a bug, not a feature, as it enables all kind of robocalls and sms spam. That's why I love the iPhone feature that allows me to block all the calls from numbers not in my contact list. It does not allow this for SMS though... reply rezonant 13 hours agorootparentIt does allow it for SMS apparently, but the UI is easy to misunderstand. In the \"Unknown & Spam\" settings where you picked \"Filter Unknown Senders\" there is an option below it marked \"SMS Filtering\" and you need to set that to... \"SMS Filter\". https://www.guidingtech.com/how-to-block-text-messages-from-... Even if it couldn't do this, that would just bolster the case that Apple is making SMS worse than it has to be on their platform to promote iMessage and its network effects. EDIT: I booted up my iPhone 14 on the latest iOS and I guess this has changed? There isn't a \"SMS Filtering\" option near the Filter Unknown Senders option which has moved to the top level Messages settings page versus when the guide was written. I'm not sure if that means it always filters SMS or it never does, but again if it doesn't filter SMS at all that's an Apple choice, it doesn't mean you can't do it on SMS. reply throwway120385 13 hours agorootparentprevWhen I was on Android it did allow me to do this for SMS. reply pdntspa 13 hours agorootparentprev> holds us back from adopting modern technology. Where we're all captive subjects of some cloud asshole spoon-feeding us bits of infrastructure we used to be able to run ourselves reply dzhiurgis 13 hours agorootparentprevUS should sue themselves for requiring a phone number for a person to exist to begin with. reply catlikesshrimp 14 hours agorootparentprevTLDR: It has nothing to do with MMS But that didn't address GP's comment. Apple states that green bubbles are pariahs because messages can't be sent to androids so it breaks the system, or something like that [BS] Iphone users think that green bubbles are pariahs because they aren't part of their exclusive group, and because green bubbles turn chat groups into rubbish, because yada yada not iphone. (spoiler alert, apple does it on purpose) https://www.msn.com/en-us/news/technology/android-users-stig... For laughs: Tim Cook telling someone he has to buy her mom an iphone (1hr 0mins 17secs) https://m.youtube.com/watch?t=3615&v=sdvzYtgmIjs&feature=you... reply LorenDB 9 hours agorootparentprevI still want to see Matrix get adopted for messaging by default. Purism actually did it with their Librem 5 (probably one of the few good things about that company, but that's a rant for another day). reply inferiorhuman 13 hours agorootparentprevit is in fact a technical limitation. No, it's not. Carriers limit the attachment sizes quite severely, but that's not an inherent limitation of MMS. reply simfree 12 hours agorootparentThe file size limits on iOS for MMS are far below what most carriers permit, making photos and videos sent from iPhone look much worse when sent via MMS. reply inferiorhuman 11 hours agorootparentDoubt that. AT&T still limits attachments to 1 megabyte for picture, video, and audio files. That's not an iOS limitation. I just sent an animated GIF to a Google Voice number and it was compressed to about 800 kilobytes. I suspect the people whining the most are communicating with folks that have \"Low Quality Image Mode\" enabled on their iPhone. https://www.att.com/support/article/wireless/KM1041906/ reply ipaddr 9 hours agorootparentBelow are the limits per carrier. You are correct AT&T is 1m. The iphone has a limit of 200k which can be raised to 300k. Parent was correct. https://www.infobip.com/docs/mms/message-types reply inferiorhuman 9 hours agorootparentDid you not read what I wrote? There's no 200 kilobyte limit. I literally sent a GIF from my iPhone that was compressed down to 800 kilobytes. Even the JPEG images were compressed to 300+ kilobytes. If you're unable to send files that large from an iPhone there's a carrier issue in play. reply bmitc 1 hour agorootparentAre you sending that to another iPhone? Trt exchanging text messages between an Android phone and an iPhone. It's completely broken. Apple wants to force Android users into iPhones so that their tect messages stop sucking, as if it's and Android issue. reply pests 3 hours agorootparentprevTheir link references MMS not iMessage. How does Apple get around that MMS limitation? reply secondcoming 13 hours agorootparentprevI can count on one hand the number of MMS messages I've ever received. reply starttoaster 10 hours agorootparentMMS was much more common before data messaging apps like Discord or Facebook Messenger became some of the normalized places for cell phone chatter, which anecdotally I think that switch started happening (or at least I began recognizing that switch) around the early 2010's. So I'm guessing you're a very young person based on how little MMS you claim to have received. Which is fine, it's fair to point out that technologies us old folk use may differ slightly from what the whippersnappers are doing. And there are no wrong answers there, except that it's also fair to point out that when you purchase a cell phone, before you install any apps, you have some ingrained cell phone messaging features. One of which is a messenger app built on top of SMS and MMS. I've probably sent and received thousands of MMS messages over the years, because it was the primary method for a cell phone user to send a picture to your friends and family. Back in the day, at least, and still today for some. It was also the way that us old folk were able to send group texts at a time. reply Toutouxc 3 hours agorootparentMust be a regional thing. Where I live in Europe, MMS were just too expensive to use regularly, roughly 5-10x more expensive than SMS, and they came roughly around the time when phones were slowly getting simple email clients and usable data (GPRS and sane pricing). I’m around 30, I grew up with a dad who was a fan of modern phones and technologies (first camera phones, Windows smartphones, PDAs) so I always had fancy phones, and I’ve received\"Copy iCloud Link\" reply jquery 4 hours agorootparentCareful, it will leak your real name. It's no good for anonymous sharing. reply pmarreck 13 hours agorootparentprevMedia messages from Androids to iPhones are in fact technologically-limited by MMS. That's not an Apple-imposed limitation, it's written in stone in the MMS standard. reply akho 1 hour agorootparentWorks fine over WhatsApp/Telegram/…. Not a technological limitation. reply lightedman 9 hours agorootparentprevPlease show me where that's written because iPhones have no problems sending full-resolution images to my droid device but I can't do the same to them. reply astrange 13 hours agorootparentprevSuper apps are a dud. China has them because the regulators want them, not because they're a good business. reply PaulHoule 12 hours agorootparentMy understanding is the reason they are dead in the US is even though the banks might let you build payments into it they will not let you negotiate any discount in fees so you will have to add your own fees on top of their own fees. It begs the question of why a bank or consortium of banks hasn’t developed a super app. When I gave this talk in late 2016 https://www.slideshare.net/paulahoule/chatbots-in-2017-ithac... there was huge interest in messaging-centric apps as this runs around the boondoggle of having even the tiniest patch to your app get reviewed. reply RhodesianHunter 12 hours agorootparentprevExactly. Most people would rather use the best app for the niche thing they want to do rather than the shittier version from some mega-app they happen to have for some other reason. reply unclebucknasty 7 hours agorootparentYes, but don't underestimate the power of convenience. That factor seems to inordinately raise the shittiness toleration threshold these days. reply novok 13 hours agorootparentprevWhy do they show up in other asian markets, like Grab and such? reply astrange 13 hours agorootparentA lot of people are used to WeChat, so it can feel natural to make another one. LINE is also basically WeChat. I don't think that's enough to make them competitive though. For instance, a scandal in one feature of the app (or Facebook being considered lame by kids) will hurt the rest of it. reply bluk 15 hours agorootparentprevCloud game streaming has been recently allowed worldwide under a few conditions ( https://developer.apple.com/news/?id=f1v8pyay ). Forcing Apple to allow third party payments without Apple's cut would improve market opportunities for many businesses. Facebook could have its marketplace conduct peer to peer transactions. Amazon could allow the purchase of digital goods (books, movies, etc.) and put it on more equal footing with Apple itself. While big businesses are best positioned to take advantage today, the effects directly trickle down to small startup businesses. While I personally don't care for it, cryptocurrency use would have more potential. Apple blocked apps for NFT features in the past because they couldn't get their 30%. Having third party marketplaces might make it so that there is some actual curation at the App Store. reply dwaite 3 hours agorootparent> Forcing Apple to allow third party payments without Apple's cut would improve market opportunities for many businesses. It would, but that is how Apple collects their commission. Where regulations where Apple has been forced to provide this separation (such as the US), they have split 3% to cover payment fees out of the commission, and put additional considerations for when leaving the app to make a payment would result in a commission and that Apple may audit that you are properly reporting commissions. The DMA mandated that Apple decouple their commission structure from a single App Store in favor of multiple marketplaces, and they put in a 50 Eurocent core technology fee per user per year (after a margin of free installs). > Amazon could allow the purchase of digital goods (books, movies, etc.) and put it on more equal footing with Apple itself. Amazon does have digital purchasing of Video. Amazon added the ability to subscribe to a limited video version of Prime using in-app purchasing, and that kind of account will bill purchases using in-app purchasing. They likely have razor thin margins for anyone who chooses to do this, but expect customers to either have existing Prime accounts or to want to upgrade from Video to the full Prime account for the other services. I suspect they did the math and think their margins on Kindle wouldn't support this. reply pests 3 hours agorootparent> Amazon does have digital purchasing of Video. Amazon added the ability to subscribe to a limited video version of Prime using in-app purchasing, and that kind of account will bill purchases using in-app purchasing. Sorry, I do not parse this. What did they add? reply CapstanRoller 2 hours agorootparentAmazon Prime was originally an add-on to regular Amazon accounts that provided expedited delivery as a flat rate subscription. Later, Amazon got into the streaming business and bundled access to films and shows into the Prime subscription. For a while it was kind of a useless perk since the available content was old or low quality. Later, as Amazon acquired more popular content and then created an in-house production studio, they added the ability to rent or \"purchase\" (rent) streaming video content on a per-episode/season/film basis without requiring the full Prime subscription service. This was designed to address Amazon customers who were primarily (pun intended) interested in the video content, not the physical goods. reply barkerja 14 hours agorootparentprevI wonder if this will have a trickle down effect on other app stores, specifically gaming consoles. Would XBox Live or Playstation Store, for example, be on the hot seat if they rejected an application or \"game\" that was basically a storefront for streaming other games? reply bluk 13 hours agorootparentI don't think so, at least not as a consequence from this case if Apple loses. Antitrust cases are usually very limited in scope. Microsoft's loss required many actions (documenting Active Directory and other protocols/formats, browser choice screens, etc.), but no one else in tech were required to do so. John Sircacusa (from ATP.fm) pointed out years ago that the heart of Apple's biggest issues is business relationship management. This was when Apple only had a handful of issues with a few companies and made some poorly received statements about developers. Their ability to build mutually agreeable relations has only gotten worse in recent years. Sony and Microsoft have kept their relations with third parties tough but ultimately agreeable. They promote practically all of their third parties (unlike the App Store which has so many apps that its like winning the lottery to be promoted). Consoles have stores which are probably more curated but which third party publishers/developers actually like. IMO, DoJ, EU, etc. are acting primarily because they have received so many complaints from Spotify, Microsoft, Epic Games, Google, Meta, Tile, etc. Governments don't take action for the \"public\" interest on its own. reply bobthepanda 14 hours agorootparentprevFacebook tried this with games and cash transfer within Messenger but it never really took off. Personally, I don’t think Western (or at least American) consumers are all that interested in a super app. Asia has a ton of players in this space like WeChat, QQ, Line and Kaokao but those have never taken off in the West outside of diaspora communities. reply gessha 5 hours agorootparentFacebook’s attempt didn’t work out because they lost the youth market to Snapchat, TikTok, Discord and Instagram(It’s funny, I know). They tried to bring in Instagram users into Facebook but that didn’t(hasn’t) work out yet. reply bobthepanda 5 hours agorootparentI mean even the old people barely play Facebook games or use Messenger money transfer. Western consumers just tend to trust product specialists rather than an all in one app. reply k12sosse 11 hours agorootparentprevKind of sideline here but.. Tim Hortons had gift and loyalty cards (\"every 7th coffee free\"). Then they introduced an app with \"rewards\" as an alternative to loyalty and gift cards. Then the app turned into a bank. Then they stopped the physical loyalty cards. Now you can't \"earn\" free coffee without giving them your personal information and signing up for the bank of Tim Hortons. It's ok though. I stopped being a customer because of it. reply numpad0 14 hours agorootparentprevWhy don't twitter. com just do the super apps w/ e-commerce thing? It's financial regulations, not App Store regulations, isn't that the case? What are challenges for implementing such \"payment\" system on iOS that can transfer, say Monopoly money vs real USD? Aren't those almost entirely legal or compliance matters for very good reasons? The Alaskan 737 MAX 9 landed largely intact thanks to still-working parts of regulations and we all value that. So why not they just do that? Or CAN'T they? reply dragonwriter 14 hours agorootparent> Why don't twitter. com just do the super apps w/ e-commerce X, the company formerly known as twitter, fairly explicitly plans to, they are just taking time to pivot, in part because they don’t seem to have any real clear roadmap from where they are to where they want to be. reply microtherion 12 hours agorootparentWhat you call \"fairly explicitly plans to\" I call \"supposedly is working on, according to statements by its owner, who has a history of vaporware announcements\". reply trothamel 8 hours agorootparentBut also having a history of announcements that take longer than expected, and come true. (Reusable rockets come to mind.) reply dragonwriter 10 hours agorootparentprevFair enough. reply dwighttk 13 hours agorootparentprev>fairly explicitly plans to, >don’t seem to have any real clear roadmap not your fault, but that's pretty funny reply dragonwriter 11 hours agorootparentI see the apparent contradiction, but the goal has been made pretty explicit, but from the outside the plan seems to be missing. reply entropicdrifter 12 hours agorootparentprevAnd also because they're in a technical quagmire of their own creation reply nomel 12 hours agorootparent> And also because they're in a technical quagmire of their own creation Could you expand on that? reply m463 10 hours agorootparentprevI would be happy if iMessage threads could be exported and saved. if I was going to dream big, I would like to point the iCloud hooks to a personal server instead of apple in a meaningful way. reply JimDabell 2 hours agorootparentIf you have a Mac, your messages are stored locally with SQLite, so you can export them that way. reply CapstanRoller 2 hours agorootparentprevIt is possible to export iMessage threads by purchasing an Apple computer and enabling \"iCloud for Messages\", at which point the messages will be synced to the computer and stored locally in an SQLite database then exported using open source tools... unless you sent too many messages or attachments, at which point you also have to purchase an additional iCloud subscription based on how much storage you need. Hopefully you can accomplish all this within the return window of the computer (or purchase a used one). The iCloud subscription fees are non-refundable. You can also just give up, keep the computer, and embrace the Apple ecosystem. Thank you Tim Apple, very cool! Sent from my iPhone reply Reason077 8 hours agorootparentprev- Music Apps (Spotify) that properly integrate with Siri, like on Amazon and Google devices. reply Lio 7 minutes agorootparentI'd just like to be able to get music off my iPhone to my mac without having to buy a third party app or buy a subscription to Apple Music. reply rmbyrro 9 minutes agorootparentprevIronic that Jobs started by fighting the big, fat, corporate IBM, and now they turned the company he founded, Apple, into a big, fat, corporation with despicable practices... When are people going to stop buying Apple? reply scotty79 12 hours agorootparentprev> This feels like it reflects similar actions taken against companies that are dominant in a market. Maybe they should be. Our societies are ostensibly consumer-centric. It's about time our laws and organisations strongly sided with consumers against any opposition, especially against business. reply crabmusket 12 hours agorootparentAs a small business owner, I'm actually keen on the benefits to other businesses that antitrust enforcement and pro-competition enforcement can have. As a really specific example in the case of Apple, I really hope the DMA causes wider availability of browser choice on iOS so that we as a business that ships a web app can offer our customers features like notifications and other PWA benefits. Our customers are somewhat willing to switch browsers to get the best experience when using our app. But switching to Android? Not a reasonable ask from us. Most consumers also have jobs right? Making their lives better and easier at work, increasing competition to give their employers more opportunity to thrive, is just as important as making their groceries cheaper. reply tpmoney 8 hours agorootparentThe flip side of this as a consumer is that I'm happy that mandating safari on iOS means I can be relatively sure any given site is going to work in Safari. I'm glad I don't live in the days where I needed 3 separate browsers on my computer (Safari, Firefox and IE) to ensure that I can use websites when I need to. In \"ye olde days\", even if you were using Safari for most of your browsing because it gave the best battery life on MacOS, you'd run into some sites that wouldn't work with it. You'd try Firefox maybe next, hoping that it was just some site that didn't have any developers who knew what a mac was. But even then, you'd run into sites where, no the problem was the developers just assumed everyone used IE and used a bunch of IE specific stuff. I can't remember the last time I saw a \"this site only works in XYZ\" message. Some of that is a lot of modern sites are all built on big frameworks, but some of that is also because only supporting Safari, or only supporting Chrome or only supporting IE is going to lose you huge swaths of customers. What if I don't want to switch browsers for the \"best experience\" when using your app? What if I want you to make your app the best experience on my browser of choice? As always these things are tradeoffs and balances. reply crabmusket 7 hours agorootparent> What if I don't want to switch browsers for the \"best experience\" when using your app? What if I want you to make your app the best experience on my browser of choice? What if I cannot do that due to there being no incentive for Apple to support web standards in Safari? We don't want our users to have to switch browsers, but that leaves us with no ability to use lots of the features that make modern web apps competitive at all with native apps. reply tpmoney 7 hours agorootparentLike I said, it's all tradeoffs. It's worth noting though that software companies definition of \"best experience\" and the consumer definition of \"best experience\" aren't always in sync, and plenty of Apple's restrictions align more with the consumers version of things. The most obvious example is mandating apps ask for tracking permissions, or location permission or access to photos and calendars. I'm sure Facebook and Google and plenty of other vendors would argue the \"best experience\" is a seamless one where the user doesn't need to be bothered with such minutia. And yet, I for one am quite glad they can't deliver their \"best experience\" to me. reply jquery 4 hours agorootparentprevTrue. On my iPhone, I just did an extremely complicated checkout flow involving registration on multiple websites as well as a credit check, and it worked like a charm. Several years ago I wouldn't have even bothered trying to do that on my phone. There is some benefit to Safari being so ubiquitous. reply rstephenson2 8 hours agorootparentprevIf it goes through, your customers can switch, once, to Chrome. After that, Google leverages its other service monopolies, Chrome goes to 95%+ market share, standards fall by the wayside, and nobody has any choice. I guess the answer to that is antitrust against Google, but I’d rather do that first than go through the Chrome domination phase. reply crabmusket 7 hours agorootparentThe DMA also applies to Chrome, so there'll be some pressure from that direction. reply techpression 6 hours agorootparentNothing in the DMA does anything about Chrome taking over completely. Actually the DMA is more or less a dream come true for Google, Amazon and Meta, it drastically strengthens their market hold at the cost of making the Apple ecosystem more diluted. It will be a sad day in the near future when the web becomes “Chrome”, even on mobile, much as it was “IE” not that long ago, alas, we seem to never learn. reply JimDabell 2 hours agorootparentThe biggest threat to the open web is Chrome’s dominance. Firefox is dwindling away and even Mozilla doesn’t seem to care about it, leaving Safari the only thing stopping Chrome from completely taking over. Google are already executing the Embrace & Extend playbook with non-standard functionality. Everybody who says “Safari is the new IE” seems to be too young to know what IE and front-end web development were really like during the 00s. I’d take WebKit on iOS over a Blink monoculture any day, and so should any web developer. reply techpression 1 hour agorootparentNo argument from me, I disregard anyone who says “Safari is the new IE” as someone who doesn’t know better but claim to do, or someone who is just trolling. I had to work with both IE on Mac and IE6 on Windows, Safari is not even remotely close to the isolated non-conforming nightmare it was back then. It’s also a bit terrifying how many seem to think Chrome gets it right all the time, even when they blatantly ignore standards or leave implementations with bugs for what feels like forever. But they get away with it since they’re so big, just like Microsoft did with IE. I don’t know what the solution would be, not like you can mandate the existence of a web browser engine into existence and making one gets harder for every new thing added. reply astrange 41 minutes agorootparentprevEconomies are producer-centric when you have international competition. An example being Intel, which is currently getting billions in government subsidies via the CHIPS Act, because their business fell behind because it was impeded by the government suing them for antitrust issues. reply ChuckMcM 11 hours agorootparentprevYes, historically the Sherman Antitrust Act (1890) and the Clayton Act (1914) define the roll of \"regulated capitalism\" rather than simply \"free market capitalism\". There has been a continuous battle between people who wanted to get infinitely wealthy by exploiting their dominance and the Government ever since. I've had some great conversations with folks about why this form of \"American Capitalism\" is the most efficient economic engine with regard to an industrial economy. As a system, this, and a graduated taxation that provides a damping function on \"infinite wealth\" and feeds it into government services has the potential to create an economy where everyone has a chance to get rich, and everyone's basic needs are met. That combination maximizes participation in the economy and thus GDP. The macroeconomics class I took spent several weeks on this relationship and the \"Great Courses\" economics class also talks about it. The challenge is that rich men (typically its men) don't like being told they can't do something, or told they have to do something which will reduce their total wealth, and they respond by corrupting legislators into changing the rules. It isn't \"good\" or \"bad\" per se, some people always eat all the cookies if they think they can get away with it. As a systems analyst though the system is an excellent study in 'tuning.' In theory, as a government maximizing GDP is a goal because the more GDP the more gets done the happier people are, etc etc. Technology strongly affected the rate of change of wealth, people who were middle class at a startup suddenly being in the top 10% in terms of wealth over the course of a few years, rather than a life time of work and savings. Others leveraging their wealth in technology startups having it rocket them into the 1%.[1] Something that the US system of laws does not do well is respond to changes \"quickly\" (my lawyer friends tell me that is a design feature not a bug). But as we saw with Microsoft's antitrust case they do respond eventually. [1] Back in the dot com days there was an article in Wired about the \"Billionaire Boys Club\" which talked about members of the several VC firms whose net worth had ballooned to over a billion dollars. reply dclowd9901 3 hours agorootparentprevIronic that the worst business decisions (hardware or software lockdowns that pave the way for antitrust suits) come from the business heads. reply empath-nirvana 15 hours agoparentprevI like the app store, I like the restrictions, I don't want apple to change anything about it. I sort of think apple shouldn't try to comply with these sorts of potential lawsuits by making their app store worse, they should just let people jail break the phone and offer zero support for it. If people want to buy an iphone and shit it up, let them do it. reply bradgessler 15 hours agorootparentI want iOS to be like macOS in that there's one \"blessed\" store, but I can sell, distribute, and install apps outside of it without giving Apple a cut. macOS has proven for decades that a reasonably proprietary OS can be distributed and kept reasonably secure when apps are installed on it outside of an App Store. There's even third-party App Stores on macOS like Steam, Homebrew, and a few more that Indie developers use to distribute apps. reply dmix 14 hours agorootparent> , but I can sell, distribute, and install apps outside of it without giving Apple a cut. I want this personally for me. But I paid extra money to get my mom an iPhone exactly because she won't be able to stuff like this. I used to regularly have to fix her android phone and the last time she was trying to download an app for tracking hours at work, and somehow downloaded the wrong app with a similar name, this app loaded with 3 different pop ups telling her to install other ad filled apps with generic names like \"PDF reader\". OP is right, it should be an explicit jailbreaking process that has a technical barrier to entry where my mom can't be talked into doing it over the phone but an enterprising young person could figure it out. reply bradgessler 13 hours agorootparentApple has a setting in macOS that disables installing apps outside of the App Store. This would be a completely reasonable setting for iOS for less tech savvy people. reply davidd_1004 13 hours agorootparentIt's fine if it's the default honestly, as long as it exists as a setting you can change. reply wiseowise 12 hours agorootparentThis is literally default Android setting, and it even shows scary dialog that sideloading can negatively impact your device. reply judge2020 10 hours agorootparentYet the EU got mad at android for ‘barriers’ to sideloading like this since it ‘unfairly’ makes it harder to install third party App Stores. reply bradgessler 11 hours agorootparentprevAgreed! macOS has really done a fantastic job balancing out the needs of security with usability. reply olyjohn 7 hours agorootparentThey'll lock it down like an iPhone soon enough. The writing has been on the wall for years. Apple and Microsoft are frothing at the mouth to do this. But they have to do slowly boil the frog, because they know it's the only way people will accept these kind of changes. reply umanwizard 6 hours agorootparent> The writing has been on the wall for years People have been saying this for more than a decade, but it still hasn’t happened; there are still zero restrictions about what you can and can’t install on macOS. reply jkestner 14 hours agorootparentprevThere are plenty of junk apps in the App Store now. Apple does a good job marketing trustworthiness, but having competing app stores may at least get them to put more effort into backing it up. reply bamboozled 11 hours agorootparentprevAs a heavy Linux user for most things I feel the same. I love that I have all non tech savvy people in my life are using. Devices that just work, they all seem happy too. I get the idealistic nature of these lawsuits but people buy these phones for the fact they work and for the protected App Store. Including myself. reply strogonoff 2 hours agorootparentI used to regard myself highly as somewhat of an expert in tech, with my relatives and friends as a reference. I would spend days (cumulatively, weeks) customizing and locking down my Windows and Linux machines. I could not imagine paying for a closed product if an open alternative was available, even if it meant more ongoing hassle. At first I got into Apple’s ecosystem because it ticked the boxes of being Unix-compatible yet very capable (perhaps rivaling Windows) of working with multimedia, which I did and do. However, the older I get and the more I lurk here and elsewhere, the more I realize there is another reason: I am not an expert, the aforementioned weeks spent on securing my device are not substantially benefitting my life and are better spent on something else, and while no one should completely give up on keeping up-to-date with modern attack vectors paying someone to do that work more competently is worthwhile. I still go to crazy lengths to avoid closed products in actual work I do, but I consider a base system that is maybe proprietary but just works, and securely enough, to be providing value in that way and enabling me to provide more value in turn. And I still consider myself more knowledgeable than 95% of my friends and relatives, so there’s them to think about. reply Difwif 14 hours agorootparentprevAre you suggesting your Mom has/would have the same experience on macOS? For whatever reason it doesn't seem to be as much of an issue. It probably doesn't need to be as cumbersome as a jailbreak. Maybe it's just a \"Allow apps not approved by Apple\" toggle hidden deep in the settings. I actually would love the ability to set \"IT administrator account\" on device setup. Then mom can't even change the setting without notifying \"dmix\" :) reply cortesoft 12 hours agorootparentprevYour mom would have to go out of her way to find and install a separate app store. You could make it give all sorts of warnings that would scare off a non-tech user like your mom. reply bamboozled 3 hours agorootparentIMO the issue is that people get tricked into doing stuff like this. Elderly people seem even more vulnerable. reply jojobas 7 hours agorootparentprevNow, everyone bow to dmix'es preferences about his mom. If you want to child-lock you mom's phone, you should have the ability to do so. Default for adults getting any sort of hardware should be that they are in charge, and any nanny should be opt-in. reply umanwizard 6 hours agorootparentYou can buy an android if you want. Nothing stops you. I like how iOS works and I would prefer the government does not force Apple to change anything about it. reply paulmd 3 hours agorootparentprevIt’s awful twisted that the people trying to use government fiat to reduce consumer choice and narrow the range of acceptable business models try to cloak themselves in the language of rights and freedoms. Just not the freedom to choose a walled garden (with its own set of - yes - positives). That choice needs to be taken away. For your freedom. One might say - managed freedom. reply jojobas 2 hours agorootparentShould this be judged against Apple, nothing prevents Apple from maintaining their walled garden, and nothing prevents you from staying in it. It's more freedom, not less. reply gardenhedge 13 hours agorootparentprevApple app store has the exact same problems. There was even a post on HN last week about an scam app being the first result in the app store. reply xnx 10 hours agorootparentprevThis seems reasonable and I like the idea of unlocking the capabilities the hardware already has. What makes iPhone different from Xbox, Playstation, Nintendo Switch? reply kibwen 3 hours agorootparentWe should be forcing game consoles to open up as well. As well as every other computing device that you can purchase. This is Hacker News; maximizing the freedom to hack our own property is an inviolable position. reply dzhiurgis 13 hours agorootparentprevOpen source store would be nice. Apple reviews the release ($$$), builds on their server and guarantees it does what it says it does. reply josephg 12 hours agorootparentThis would be lovely. As far as I know, right now its entirely possible for an app developer to show clean, trustworthy code on github. And then ship an app bundle on the app store which contains malware. I'd love it if Apple provided a way to protect against this sort of thing. reply sneak 13 hours agorootparentprev> macOS has proven for decades that a reasonably proprietary OS can be distributed and kept reasonably secure when apps are installed on it outside of an App Store. That’s not really true. Despite the dangers of centralized app censorship, the state of security on iOS is far beyond that of macOS. reply astrange 12 hours agorootparentiOS also has even more security threats, because a phone is in your pocket and has GPS, and your laptop isn't. reply intrasight 5 hours agorootparentAlso, macOS has like 13% market share vs 60% for iOS - in USA. reply scarface_74 14 hours agorootparentprevIt’s reasonably secure because no one has bothered to write malware for it. But there was nothing on the Mac stopping Zoom from putting a backdoor web server on Macs. reply AprilArcus 14 hours agorootparentApple could revoke Zoom's signing certificate, if they were discovered to be doing this. reply andrewaylett 13 hours agorootparentThat's the thing: they were. Apple did act, but not by revoking the certificate. https://www.theverge.com/2019/7/10/20689644/apple-zoom-web-s... reply idle_zealot 15 hours agorootparentprevI am very pro-users-owning-their-computers, which makes me highly critical of Apple's behavior. However, these sorts of lawsuits or regulations that seek to force Apple to change App Store policies feel so wrong-headed and out of touch. The problem with Apple is not that they take a 30% cut of app sales in their store, or that they don't allow alternative browser engines or wallets apps or superapps or whatever in their store. It's their store and they ought to be able to curate it however they like. The problem is that users cannot reasonably install software through any means other than that single store. The problem is that Apple reserves special permissions and system integrations for their own apps and denies them to anyone else. That is not an acceptable way for a computer to work. reply d35007 14 hours agorootparent> That is not an acceptable way for a computer to work. Luckily, you have a choice. Other companies make handheld computers that align better with your definition of ownership. reply AnthonyMouse 13 hours agorootparent> Luckily, you have a choice. Other companies make handheld computers that align better with your definition of ownership. The issue is that your choice is constrained by vertical integration. If you like Apple's hardware, or iOS, or iMessage, or any number of other things, these are all tied together with Apple's app store when they should not be. It's like encountering a retail monopoly in California and someone tells you that you're lucky because you can shop at another store and all you have to do is move to Florida, which also has a retail monopoly, but a different one. Obviously this is not the same thing, and does not have the same benefits, as multiple stores being right next to each other and allowing you to choose the one you want on a per-purchase basis. reply idle_zealot 11 hours agorootparentThe opposing view, in this retail metaphor, is that they like living in a state with this retail monopoly, because the store will not sell them or anyone else... say, bacon. And they find bacon distasteful and like being able to live in a community where nobody eats it. If the retail monopoly were broken, then their neighbors would be able to purchase bacon, and some would have cookouts and they would have to smell it. Perhaps their favorite snack would discontinue its regional bacon-free variant and sell its normal variant in another store now that it is able to. Don't you know that bacon is bad for you? The counterpoint is: if bacon is so bad awful and bad for you we should probably regulate its sale, rather than leave that up to a company bullying other companies. reply AnthonyMouse 11 hours agorootparentThe better counterpoint is, if you don't like bacon, don't buy it, and stop trying to control other people, lest they try and control you. reply iamtedd 7 hours agorootparentCareful. You start applying that to other things like, say birth control or planned parenthood, people lose their minds. reply idle_zealot 13 hours agorootparentprevI am quite aware of the landscape. I use a Pixel phone with GrapheneOS and an iPhone. I prefer many aspects of my iPhone, and can understand why many people choose one as their primary or sole mobile computer. A phone is a very special product category, it's where most users keep their digital lives. As such switching costs are quite high, and user agency is quite important. In general software introduces some very odd dynamics into ownership. If you buy a vacuum cleaner you can take it home, plug it in, and vacuum every room in your house; the vacuum cleaner is yours. If you buy a Roomba and take it home, it demands that you sign a unilateral EULA, then install an app on your phone, and then informs you that it will only clean one room unless you sign up for Roomba Pro for $20/mo[0]. So clearly Roomba still owns the vacuum cleaner they just sold you; they have the final say in what it does or doesn't do. That's ownership. Now, technically, you can legally disassemble your Roomba, and if you manage to dump, modify, and reflash its control software, then you'd be allowed to use your product to clean multiple rooms without paying monthly for the privilege. That would require a lot of effort and specialized skills and tooling, and you would then not be allowed to share your modifications with less skilled Roomba owners because doing so would almost certainly involve trafficking DRM circumvention technology, which is a crime. So in practical terms you only own the Roomba as an inanimate plastic puck. This whole situation maps to iPhones as well. As things stand when you purchase an iPhone you own a glass brick, and Apple owns the phone part. They graciously allow you to use their phone to perform a certain limited set of activities. I am fundamentally opposed to this sort of non-ownership. Whether the buyer had an option to purchase a roughly-equivalent item with different terms is irrelevant; selling someone a product while retaining ownership of it is a mockery of property rights. Some rights are too important to allow people to sign them away with the tap of a button. When the market missteps by rewarding bad behavior like this it is the job of our democratic governments to step in and mandate good behavior. [0]: this is made up to illustrate a point, I don't actually know how Roomba service works reply hparadiz 12 hours agorootparentThis is all so exhausting and goes in circles over and over. I honestly can not believe that there are people on HackerNews of all places that want two companies to control pocket computers and just because one is only marginally better it's totally okay that the first one is draconian. I feel like someone who woke up in the middle ages with a fever and they are trying to cure me with leeches. Yes yes. No need to worry. Let the leech do it's work and you too will be secure from the plague. Does anyone actually know anyone that has gotten hacked on their Android phone? reply jakupovic 4 hours agorootparentPeople like their iPhone and get mad when you point out it is not the best for everyone and go back to I got mine. Really sad to see on HN especially. reply umanwizard 51 minutes agorootparentNo… I like my iPhone and get mad when people want the government to force Apple to change how it works. I like how it works now, which is why I bought it. reply arvinsim 4 hours agorootparentprev\"It is difficult to get a man to understand something when his salary depends on his not understanding it.\" Pretty sure some of the shills here are heavily invested in Apple stocks. reply astrange 37 minutes agorootparentEveryone is, it's the second biggest company in SPY. reply hparadiz 2 hours agorootparentprevApple revenue would likely go up in an open ecosystem. See Microsoft if you don't believe me. reply hilbert42 11 hours agorootparentprev\"...selling someone a product while retaining ownership of it is a mockery of property rights.\" Excellent comment, it sums the situation up very well. And the above extract encapsulates the matter in just a few words. reply megaman821 14 hours agorootparentprevPhones are unique in the consumer space because of how thoroughly they can restrict end user usage. Once you buy an iPhone you can use it physically as a hammer if you wish, but if you want to digitally use a non-Apple wallet then you are restricted. Most consumer goods don't behave this way; my TV lets me watch anything I input into it, my bike lets me ride to wherever a pedal to, my vacuum lets me clean my counter if I want it to. Consumers are choosing a desirable physical good with undesirable digital restrictions. Apple is flexing its hardware power to its advantage and end user's disadvantage in software. reply jjk166 13 hours agorootparent> Consumers are choosing a desirable physical good with undesirable digital restrictions. So long as it is the customers making that choice, and they have access to alternatives, then it's not really a problem. If apple were advertising the iphone as a consumer product that had no such digital restrictions in an effort to hoodwink people into buying them, or if iphone were the only serious game in town, then those restrictions would be an issue, but right now iphones are advertised as being worth more than their competitors specifically because of those restrictions, and people are willing to pay such premiums. That you personally would not make the same decision does not mean they've been manipulated by anti-competitive measures into making theirs. If someone were to make a consumer product that worked better for my use cases at the expense of being worse at or even incapable of doing things I don't intend to use it for, I should have the option to buy it. If you don't like the restrictions, buy something else. That's not anti-competitive, that is exactly how competition is supposed to work. reply megaman821 12 hours agorootparentThere is literally only one other competitor. That is not flourishing, competitive market when consumers can make many different choices. There are two companies that control nearly the entirety of the mobile software market, how can you expect that there would be no oversight to make sure they don't advantage their own software offerings? reply tpmoney 8 hours agorootparentSamsung, Sony, Google, LG, Xiaomi, Motorola, Nokia, TCL, Kyocera, Fairphone, Pine64, Purism, and many others are more than \"literally only one other competitor\". And even if your complaint is that the only other option is \"Android\", there's no reason why those manufacturers couldn't make their own OS if they wanted to. There's no reason why even if they didn't want to, they couldn't make their own custom Android distribution. If the linux community as small as it is can produce multiple varied and unique linux distributions largely on the backs of volunteers, there's no reason why these manufacturers (especially some of the bigger names) couldn't do the same with Android / Linux and their own hardware. And whatever reason is behind the failure of literally the entire cellphone industry to do what they were doing before the advent of iOS and Android, it isn't because Apple is somehow stopping them from making their own OS, and SDKs and app stores. reply dpkonofa 11 hours agorootparentprevBut the reason is there only one other competitor isn't at all because of Apple or the competitor and doesn't have anything to do with their practices. The reason for it is because it's incredibly difficult and complex to put together a device like that and only certain types of companies have the resources and funds to create a product like that. reply ClumsyPilot 9 hours agorootparent> isn't at all because of Apple or the competitor and doesn't have anything to do with their practices. Can you buy the display from a supplier that supplies Apple and put together your own phone? No, they have exclusive agreement with apple. Their anticompetitive practices Make It incredibly difficult and complex to put together a device. That's the whole point! reply astrange 36 minutes agorootparentI think you could buy an OLED display from Samsung if you wanted. reply tpmoney 8 hours agorootparentprevIs the assertion that Apple's supposed monopoly is because they have exclusive agreements on their hardware? reply intrasight 5 hours agorootparentprevExclusive agreements are legal. reply idle_zealot 11 hours agorootparentprev> right now iphones are advertised as being worth more than their competitors specifically because of those restrictions Huh, I must've missed all the iPhone ads touting the device's inability to play Fortnight as a premium feature. reply loup-vaillant 13 hours agorootparentprev> Phones are unique in the consumer space because of how— —they were marketed as phones that can compute, instead of as computers that can phone. That's the crux: people would never have accepted the restrictions on computers like the iPhone, if that thing were instead sold as a general computer called the iPalm or similar. But since it's sold as a phone, any thing else it can do is more easily perceived as a bonus, and we hardly feel the restrictions at the beginning. Only people who see smartphones for what they really are, general purpose palmtops that can make phone calls, can really perceive the egregiousness of those restrictions. The first step then, is generalising this understanding to everyone. A good first step, I think, would be to start naming those things more accurately. I'd personally suggest \"palmtop\". reply AsyncBanana 7 hours agorootparentAt this point, most people likely associated the word \"phone\" with something closer to a modern smartphone than a landline. Language can change. From my point of view, the problem is more that Apple set a precedent of these restrictions due to them being the first mover, and few mainstream phone companies have tried to break out of this idea (even though other phones are technically more flexible if you try hard enough). reply loup-vaillant 2 hours agorootparent> From my point of view, the problem is more that Apple set a precedent of these restrictions due to them being the first mover, and few mainstream phone companies have tried to break out of this idea It's even worse than that: though I stand by what I said, you're correct, people are gradually realising that the difference between their smartphone and laptop/desktop (if any), is one of degree, not kind. But we don't see the push back we would have seen if they had realised right away. Instead, as you rightly point out, companies are building on Apple's precedent to try and expand their model to our good old laptops and desktops. And it looks like they're succeeding. It would seem one has to pay Apple to even get the right to distribute a regular MacOS program regular users can actually execute (no Apple developer plan, no code signing). And newer versions of Windows are displaying increasingly scary warnings for programs telling you they \"protected\" your computer, which are bad enough that we get tutorials about how to get past them. reply paulmd 2 hours agorootparentprevSurely first-mover for smartphones is palm or blackberry or even Windows Mobile. Yes, apple has about half the market today, that’s not the same thing as being first-mover. In fact it’s actually completely different because people had to make the choice to move away from the first-movers to apple. People literally did give up their blackberries and palms and Jornadas for iPhone, consciously and deliberately, because it was a better product. And now you want to change the product and erode the benefits back to the minimum standard defined by android. That’s a taking. reply loup-vaillant 2 hours agorootparentIt was a better product. But it would be quite a take to say their tolling & gate keeping was a significant contributor. It was a better product because of its capacitive multi-touch screen and its overall speed (which I must insist depends more on what apps are installed by default than on the restrictions on third party apps). reply astrange 12 hours agorootparentprevIt isn't a general purpose computer. The form factor is compromised to make it work as a phone and it doesn't matter how good the CPU is. A general purpose computer would be hard to use if it had an OOM killer instead of swap and if running the CPU full speed shut it off because it got too hot inside. (Using it too hard can also drain the battery even if it's on a full strength charger.) reply dvngnt_ 11 hours agorootparentyou can add a keyboard to a phone the same way i can add a keyboard to my desktop to function. phones are actually more general-purpose since they travel with you and know where you are. reply ClumsyPilot 9 hours agorootparentprev> It isn't a general purpose computer. This is straight up lala-land. Phones do banking, browsing, document writing, printing, video editing. Many people don't even have a computer. > OOM killer instead of swap Windows 10 apps work like that. > Running the CPU full speed shut it off because it got too hot inside. Happens to some crappy laptops. These are basically irrelevant details. reply bbradley406 4 hours agorootparent>Happens to some crappy laptops. These are basically irrelevant details. Don't most modern (>2010) CPU's thermal throttle until they are back within operating temps? You'd have to stuff a laptop inside a backpack while maxing it to get it to overheat to the point of resetting reply astrange 9 hours agorootparentprevPhones do browsing only until you switch to another app and it has to kill the tab to save memory. And remember, they don't do Flash ;) It's web pages that changed to fit on phones, more than the other way round. reply zhengyi13 13 hours agorootparentprevLuckily, we have anti-trust and other forms of law and regulation specifically because assuming markets will alway provide meaningful choices has historically proven a bad assumption. reply hightrix 9 hours agorootparentIn this case, we don't have to assume. There is meaningful choice in which platform you use. reply intrasight 5 hours agorootparentWe only have to assume that our legal system will do it's job. Personally, I think the government has a weak case. No customers are being harmed by Apple's restrictions and there is certainly no monopoly. reply kalkr 13 hours agorootparentprevMotor companies should not be able to gate physical features (seat heaters) behind software. My opinion isn't changed by the fact that I can purchase from a company that doesn't do that. reply umanwizard 6 hours agorootparent> Motor companies should not be able to gate physical features (seat heaters) behind software. Why not? If you don’t want a car with this property, don’t buy one — how are you being harmed? reply dlubarov 5 hours agorootparentIt would be fine if companies were extremely clear about it, saying “the car is $30k, but the average customer ends up paying an additional $2k in subscriptions for basic features”. Or “the phone is $1000, but most software will be more expensive due to our 30% tax”. Of course they’re not that clear, and I would argue these business models only make sense when there’s deception involved. reply yibg 5 hours agorootparentprevJust because you aren’t being harmed doesn’t mean you can’t think it’s wrong or try to prevent it. There are lots of things people fight against that doesn’t directly impact them (yet). One good reason in this particular examples is I don’t want subscription based heated seats to become popular, because then I won’t have a choice anymore. reply shiroiushi 53 minutes agorootparentNo, the part that's really bad is that they lock up features behind software locks, but these aren't that hard to break for hackers. But then they get laws passed which make it illegal to change these features on your car, or even to tell other people how to do so. How the DMCA hasn't been struck down by the Supreme Court as an abridgment of the 1st Amendment, I really don't know. reply JoeJonathan 5 hours agorootparentprevBecause its stupid and annoying reply umanwizard 49 minutes agorootparentThen don’t buy one. reply wiseowise 12 hours agorootparentprevLuckily, people can like something despite shortcomings and ask for it to become better. reply Arn_Thor 4 hours agorootparentprev“You can buy this other thing” is not a good defense against antitrust allegations simply because that’s not what it’s about. reply wruza 13 hours agorootparentprevBut these computers are so different… But if Apple does that it would be differently different… /s I mean, what gp wants is literally just there on the shelves and they don’t want it. But they also want it, but in Apple, because it’s nicer when Apple does[n’t] it. Why would they want it after Apple does it? reply Dylan16807 12 hours agorootparentSurprise, people want more than one thing out of a product. Voting with your wallet works very badly when there are two main options. Which anti-consumer behaviors do you pick? When something is bad enough, it's better to make it illegal for all options. reply wruza 11 hours agorootparentI’m all for your device = your control, and I mean your. But allowing software vendors to ignore AppStore will eventually lead to my bank apps, local maps apps, delivery apps etc to go non-AppStore-only route and do whatever they want on my phone, because I have no alternative (except for not using my phone). The first thing one of my bank apps did on my android phone was to install some sort of an “antivirus firewall” which abused every access and semi-exploit to make sure I’m “safe”. Your ideas will affect me, and I can’t see why your (and my) inconvenience is more important than my security. It’s not just “better”. I’m asking to consider this perspective as well. reply Dylan16807 10 hours agorootparentThe controls on apps that prevent them from taking over should be part of the OS, not the app store. reply ladzoppelin 9 hours agorootparentThe controls are in the app store because there is no way of doing it in the OS. reply Dylan16807 9 hours agorootparentWhatever an \"antivirus firewall\" does, it sounds like something that should be tied to permissions or not have an API for it, either way easy to stop all apps from doing. And I'm skeptical that governments would stop Apple from enforcing a rule that says apps have to let you refuse permissions. reply wruza 51 minutes agorootparentThese apps usually simply refuse to work without permissions, so this is not a solution. Empty/fake permissions are easily detectable too. Someone will make a “framework” for that and we’ll see it in most important apps. reply paulmd 2 hours agorootparentprevBy definition apple can’t do anything in that situation, because people don’t want third-party app stores and sideloading to be managed or notarized by apple at all. This is the very definition of bad-faith motte-and-bailey argumentation, and it’s logically incoherent to boot. Get apple out of regulating apps and App Stores, no more telling developers what they can do! Oh and i guess they can tell developers to do one thing… reply tshaddox 6 hours agorootparentprevUnfortunately regulations and lawsuits like this one seek to reduce the amount of meaningful choices consumers have in the smartphone market. reply umanwizard 6 hours agorootparentprevIt is not a “mobile computer”. The fact that it has a CPU and other computer parts is an implementation detail (your dishwasher also probably has a CPU). If you want a mobile computer then buy one, don’t buy an iPhone, and don’t advocate for the government to force Apple to change how iPhones work for those of us who like them. reply alt227 14 hours agorootparentprevYou are exactly describing the recent EU lawsuit reply paulddraper 14 hours agorootparentprevIsn't that exactly what the EU went after? They didn't tell Apple not to charge 30% for their App Store. They can charge 90% for all they care. They told Apple they mustn't block other installation methods. reply idle_zealot 14 hours agorootparentSort of. My reading of the DMA is basically what you're saying; Apple has to let people install what they want on their phones, Apple cannot self-preference with app capabilities. Apple is planning to comply not by allowing users to install what they want on their devices, but instead by offering companies an avenue to enter a business relationship with Apple through which Apple will allow users install that company's applications, provided that Apple has vetted and signed them. That is, all told Apple still has final say over what apps are allowed on peoples' phones. It sounds like the EC is going to nix those app-signing requirements, but the rest of the scheme may or may not be deemed acceptable. So the question remains whether the spirit of the DMA is \"users should be able to install the software they want on their computers\" or \"businesses offering apps and services should be able to compete with Apple on the iPhone\". Is this a fundamentally a pro-user law or a pro-business law? There may be overlap, but they are not the same. reply Hikikomori 11 hours agorootparentprevIf there was alternatives Apple wouldn't be able to charge 30% anymore. reply idle_zealot 10 hours agorootparentWouldn't they? Google gets away with it. reply paulddraper 10 hours agorootparentprevGoogle Play charges 30%, despite F-Droid, Samsung Galaxy, TapTap, Itch.io, Aptoide, Amazon, Aurora, Uptodown, etc. It really is amazing hearing Apple people talk about the world. reply astrange 15 minutes agorootparentThey both charge 15% for most developers. Google charges 15% for the first million for all developers. reply Hikikomori 9 hours agorootparentprevThe preferred alternatives seems to be to charge 30% more when buying things through the app rather than the website or not doing in app purchases at all. Presumably the restrictions or the not user friendly experience Google enforces for users makes it not worth doing it on Android, so the other options are better. reply paulmd 3 hours agorootparentprevSony and Microsoft obviously don’t benefit from opening up the platforms, it’s not just something they don’t care about but something they actively oppose, and they specifically ensured they got legislative exceptions to ensure they would never have to reciprocate under the DMA. Your goals aren’t aligned, you’re just a useful idiot to them and they’ll cast you aside as soon as they no longer need you. The end result of the push isn’t going to be “free as in freedom” for everybody here, just Microsoft capturing 90% of a revenue stream instead of 70%. Classic populism moment - but of course it’s “populism, but on the computer”. Freedoms for users and freedom for business are two fundamentally opposed and conflicting goals, see: GPL vs MIT/BSD. And in their moment of victory, businesses will just steamroll right over you - just like they literally already did with consoles. It’s just crazy that they have these exceptions when their own hardware is very much general-purpose on a technical level, and when they’re actively pushing to use that general-purpose capability to ensnare users with AI features and other crap. Sony and Microsoft are two of the platforms that stand to gain the most from AI adoption literally purely on the basis of being closed platforms with proprietary APIs (plus a minimal amount of interop for embrace-extend-extinguish) with millions of active users and a captive audience of dev studios who have no choice but to use Sony and Microsoft’s closed, gatekept platforms. Somehow the plight of poor little Larian being stepped on by Sony and Microsoft and Epic just doesn’t make the front page of HN like apple hate. reply leptons 12 hours agorootparentprev> The problem with Apple is not that they take a 30% cut of app sales in their store, or that they don't allow alternative browser engines or wallets apps or superapps or whatever in their store. Nope, the problem very much is that they won't allow alternative browser engines, specifically so that they can force a crippled Safari browser with limited APIs to force people to write apps instead of web apps, forcing more traffic to their store. It's explicitly anti-competitive behavior. >It's their store and they ought to be able to curate it however they like. It's kind of forced fraud to call Chrome in iOS as \"Chrome\". It's like trying to sell someone a Ferrari that's just a facade bolted onto 2010 Honda. It's not Chrome, it's actually Safari - and its seems like people are finally starting to wake up to this abusive behavior that Apple has been getting away with for far too long. Microsoft had a famous anti-trust case against them for simply bundling IE with Windows - not from forcing their engine on every other \"browser\" that gets installed. Apple is doing far worse than that and getting away with it for far too long. >The problem is that users cannot reasonably install software through any means other than that single store. That's one of the many other problems outlined by the DOJ today. >The problem is that Apple reserves special permissions and system integrations for their own apps and denies them to anyone else. Also another problem. >However, these sorts of lawsuits or regulations that seek to force Apple to change App Store policies feel so wrong-headed and out of touch. I was clapped out loud when I watched the DOJ announcement today. I cheered. They actually mentioned \"Developers\", which is a group I am part of, and I feel the pain that dealing with Apple and Safari is. Apple absolutely deserves this, and it's about time. reply doctorpangloss 12 hours agorootparentprev> I like the app store, I like the restrictions, I don't want apple to change anything about it. This is basically saying you only use TikTok, Facebook, Instagram, YouTube, Spotify, Tinder, Gmail, Google Maps, and play zero to some handful of mega huge F2P games. Why have an App Store at all then? You don't use it. It's an installation wizard for you, not a store. Don't you see? This stuff doesn't interact with restrictions at all. The problem with the App Store is that it sucks, not that it's restricted. > making their app store worse I've heard this take from so many people. It is already as bad as it gets. The App Store is an utter disaster. They have failed in every aspect to make a thriving ecosystem. It is just the absolute largest, hugest, best capitalized, least innovative apps and games. This doesn't have to be the case at all. Look at Steam. Even Linux package managers have more diversity with more apps that thrive. reply NoPicklez 10 hours agorootparentFor your first point that is a fairly wild accusation of that user. For me, one of the features of a centralised app store is that I buy and subscribe to apps through the app store, which centralises my app subscriptions within my Apple account. I wouldn't have this functionality if I was pulling in apps outside of the app store. I can go into my Apple account and see every subscription I have and cancel it from within. No shoddy dark website behavior that makes it hard to unsubscribe, I can do it all there. This just one feature that I find handy in having a single store. reply idle_zealot 3 hours agorootparentIf Apple had your best interests in mind they would provide a way to integrate third party payment systems into their management interface so all apps could expose their subscriptions to the user in a consistent way regardless of payment backend. Instead they will keep it as an exclusive feature and point to other processors' lack of compatibility as a harm to end-users inflicted by the DMA. They would rather have a talking point in their ongoing temper tantrum than provide a good experience for their users. reply Andrex 14 hours agorootparentprev> If people want to buy an iphone and shit it up, let them do it. The next generation isn't necessarily choosing, though. Their parents are giving into their demands for *an iPhone due to social pressures entirely originated by Apple's monopolistic behavior (iMessage green bubbles). Then, when they're locked into the Apple ecosystem from the start, it's almost impossible to break out -- even if you grow up into a mature adult that doesn't give a shit about bubble colors. Interoperability (being able to exit an ecosystem without massive downsides, specifically) between the only two parties in a de facto duopoly is absolutely necessary and morally right, and it's a shame market failures force the judiciary to intervene. But we are where we are and there's no use putting lipstick on a pig -- the system as it stands is broken, and if left alone will feed on itself and become even more broken. reply thirdsun 1 hour agorootparent> Their parents are giving into their demands for *an iPhone due to social pressures entirely originated by Apple's monopolistic behavior (iMessage green bubbles). First of all, we don't have that problem here in europe. People just use cross-platform messengers. Secondly, I don't understand why a company should be forced to bring its service to a platform it doesn't care about. Apple supports the default carrier messaging standards (SMS/MMS). It's not Apple's fault that they suck. In fact Apple explicitely created iMessage because SMS/MMS were absolutely terrible. If RCS is considered a standard (is it?), then Apple should absolutely support it and apparently they plan to do so. Seems fine to me. While I personally don't use iMessage I'd prefer it if the service was available everywhere, but I don't see why Apple should be forced to support other platforms. Just because iMessage is popular? Imagine a world where WhatsApp was either an iOS- or Android-exclusive app. Should they be forced to develop for a platform they don't care about too? What about popular iOS-exclusive apps like Things? What about Garageband or Logic? Or Super Mario games on Nintendo? reply shultays 22 minutes agorootparent> Their parents are giving into their demands for *an iPhone due to social pressures entirely originated by Apple's monopolistic behavior (iMessage green bubbles). First of all, we don't have that problem here in europe We also have a smaller percentage of iPhone users here in Europe. Apple could have open up their API. Or not try to shut it down so hard when someone finds a way around to use their API reply crmd 15 hours agorootparentprevSame here. I use linux VMs and containers for all my \"hacking\" where I need total control and customizability of the OS. On my workstation and phone, where I do my banking and read emails, I'm willing to trade control and customizability for an extremely locked down high trust operating environment. I feel like Apple's closed ecosystem, despite all its flaws, gets this compromise right. reply kmeisthax 13 hours agorootparentI'd kill for an Apple-sanctioned way to load Linux VMs on my iPad and have them run at full speed. It's got an M1 in it, the virtualization hardware is there, Apple just doesn't want me using it. As it currently stands, the options for Linux VMs on an iPad are: - iSH, a Linux kernel ABI compatible user-mode x86 emulator that uses threaded code (ROP chains) as a substitute for a proper JIT, but doesn't support all x86 applications[0]. - UTM, a port of QEMU that requires JIT (and thus, either an external debugger or a jailbreak) to run a full x86 or ARM OS. - UTM SE (Slow Edition), which is UTM but using the threaded code technique from iSH, which is not only slower than",
    "originSummary": [
      "The U.S. Justice Department and 16 states, including the District of Columbia, have filed an antitrust lawsuit against Apple for allegedly monopolizing the smartphone market.",
      "The lawsuit claims Apple's practices stifle competition and hinder the development of digital wallet alternatives, impacting consumers and developers.",
      "Apple defends its actions by stating they enhance device security and promote consumer benefits, but the lawsuit's resolution could profoundly impact Apple's business and the tech sector overall."
    ],
    "commentSummary": [
      "The discussion focuses on antitrust issues concerning Apple's control over the iPhone ecosystem, App Store, and limitations on third-party apps, impacting consumer choice and market competition.",
      "Debates arise on the pros and cons of Apple's closed ecosystem, monopolistic concerns, and the call for more interoperability and user control in tech platforms.",
      "The conversation delves into alternative messaging standards, decentralized network challenges, and balancing security with openness in app stores, shedding light on Apple's tech dominance and the ongoing antitrust debates."
    ],
    "points": 2215,
    "commentCount": 2115,
    "retryCount": 0,
    "time": 1711031863
  },
  {
    "id": 39778412,
    "title": "Difftastic: Syntax-Aware Structural Diff Tool",
    "originLink": "https://difftastic.wilfred.me.uk/",
    "originBody": "difftastic a structural diff tool that understands syntax GitHub Manual Install Difftastic is a CLI diff tool that compares files based on their syntax, not line-by-line. Difftastic produces accurate diffs that are easier for humans to read. Understand What Actually Changed Difftastic parses your code with tree-sitter. Unlike a line-oriented text diff, difftastic understands that the inner expression hasn't changed here. Ignore Formatting Changes Has your code formatter decided to split something over multiple lines? Difftastic can show what has actually changed. Visualise Wrapping Changes Have you added a wrapper? Difftastic can match the delimiters exactly. Even if you change the inner content, difftastic can still show you the additional wrapper. Real Line Numbers Do you know how to read @@ -5,6 +5,7 @@ syntax? Difftastic shows the actual line numbers from your files, both before and after. 60 Second Demo --:----:-- Programming Languages C++ C# Clojure Dart Erlang Go Haskell Java JavaScript Kotlin Lisp Lua OCaml PHP Python R Ruby Rust Scala TypeScript And more! See the full list of supported languages in the manual. File Formats HCL HTML JSON YAML And even more! See the full list of supported file formats in the manual. Works With Git See the git configuration instructions in the manual. Fully Open Source Difftastic is MIT licensed. Download it, modify it, share it with your friends! Made with Emacs and coffee by Wilfred Hughes.",
    "commentLink": "https://news.ycombinator.com/item?id=39778412",
    "commentBody": "Difftastic, a structural diff tool that understands syntax (wilfred.me.uk)899 points by jiripospisil 20 hours agohidepastfavorite145 comments kstrauser 18 hours agoFor those who don't already know, this is built on tree-sitter (https://tree-sitter.github.io/tree-sitter/) which does for parsing what LSP does for analysis. That is, it provides a standard interface for turning code into an AST and then making that AST available to clients like editors and diff tools. Instead of a neat tool like this having to support dozens of languages, it can just support tree-sitter and automatically work with anything that tree-sitter supports. And if you're developing a new language, you can create a tree-sitter parser for it, and now every tool that speaks tree-sitter knows how to support your language. Those 2 massive innovations are leading to an explosion of tooling improvements like this. Now every editor, diff tool, or whatever can support dozens or hundreds of languages without having to duplicate all the work of every other similar tool. That's freaking amazing. reply ievans 17 hours agoparentAbsolutely agreed, and copying from a comment I wrote last year: I think the fact that tree-sitter is dependency-free is worth highlighting. For context, some of my teammates maintain the OCaml tree-sitter bindings and often contribute to grammars as part of our work on Semgrep (Semgrep uses tree-sitter for searching code and parsing queries that are code snippets themselves into AST matchers). Often when writing a linter, you need to bring along the runtime of the language you're targeting. E.g., in python if you're writing a parser using the builtin `ast` module, you need to match the language version & features. So you can't parse Python 3 code with Pylint running on Python 2.7, for instance. This ends up being more obnoxious than you'd think at first, especially if you're targeting multiple languages. Before tree-sitter, using a language's built-in AST tooling was often the best approach because it is guaranteed to keep up with the latest syntax. IMO the genius of tree-sitter is that it's made it way easier than with traditional grammars to keep the language parsers updated. Highly recommend Max Brunsfield's strange loop talk if you want to learn more about the design choices behind tree-sitter: https://www.youtube.com/watch?v=Jes3bD6P0To And this has resulted in a bunch of new tools built off on tree-sitter, off the top of my head in addition to difftastic: neovim, Zed, Semgrep, and Github code search! reply TeMPOraL 25 minutes agorootparentOkay, but how does that work with language versions? Like, if I get a \"C++ parser\" for tree-sitter, how do I know if it's C++03, C++17, C++21 or what? Last time I checked (which was months ago, to be fair), this wasn't documented anywhere, nor were there apparent any mechanisms to support langauge versions and variants. reply jrave 1 hour agorootparentprevhelix (https://helix-editor.com/) is using treesitter and LSP as well reply ossusermivami 3 hours agorootparentprevdon't forget old man emacs is now using tree sitter reply drcongo 16 hours agorootparentprevDon't forget Zed! https://zed.dev reply germandiago 14 hours agorootparentLooks great! It has lsp support for code completion? Supports C++? reply bfrog 17 hours agoparentprevWhile I agree tree-sitter is an amazing tool, writing the grammar out can be incredibly difficult I found. I tried writing out a grammar and highlighting query set for vhdl with tree-sitter, and found that there were a lot of difficulties in expressing vhdl grammar in tree-sitter. reply kstrauser 17 hours agorootparentNo argument from me on that. The upside is that one person, somewhere, has to get it right one time and then we can all use it. reply grub5000 16 hours agorootparentSeems like something LLMs should be useful for, if not now then soon enough reply HumanOstrich 15 hours agorootparentI think many people are exhausted (at least I am) with the constant irrational exuberance of bolting AI onto every technology, product, and service in existence to end all of humanity's problems. It won't work like that. reply germandiago 13 hours agorootparentIn fact, reminds me of the time at which they used Blockchain for everything. Just a bubble right now. It will come back to its natural uses after it. Everyone is doing AI now and I am pretty sure it is to attract investment even if some might know their product will go nowhere. reply dreamcompiler 11 hours agorootparentCorrection: Everybody says they're doing AI now because that's the magic buzzword for getting money. I spent the 1990s building actual AI software, but we had to call it something else because if you even whispered \"AI\" in the 90s your funding would dry up instantly. reply klabb3 7 hours agorootparentSomeone should build a tool that augments any text with current year tech buzzwords for optimal investor appeal. I wonder what tech could be used for that… wait reply mehdix 20 minutes agorootparentNot quite what you're looking for, but checkout bullshit.js[0]. [0]: https://mourner.github.io/bullshit.js/ reply pizza 3 hours agorootparentprevtree-sitter? reply duped 15 hours agoparentprevI don't believe this is correct - there's no such thing as \"speaking tree-sitter.\" Every tree-sitter parser emits a different concrete syntax tree, not a standard abstract syntax tree. LSP truly solves the M editors to N languages needing M * N many integrations by using a standard interface for a query oriented compiler. Tree sitter doesn't solve this problem, it just makes it way easier to write N many integrations for your editor/tool. reply kstrauser 15 hours agorootparentThat depends on how deep you want to go with the result. I use the Nova editor which uses tree-sitter for syntax highlighting, and I've packaged several languages for it. Each time it goes like this: 1. Clone someone's tree-sitter grammar off GitHub. 2. Build it into a Mac .dylib. 3. Create a Nova extension that says \"use this .dylib to highlight that language.\" 4. Use it. I don't have to make any changes to Nova itself, and the amount of configuration I have to write is so tiny that Nova could have a DIY wizard if they wanted it to. The source for Difftastic discussed here (at https://github.com/Wilfred/difftastic/blob/master/src/parse/...) is also very simple: for each of a list of supported languages, import the tree-sitter parser and wrap a teensy amount of configuration around it. reply duped 15 hours agorootparent> 3. Create a Nova extension that says \"use this .dylib to highlight that language.\" How is that possible if the different tokens emitted by tree sitter don't have standardized names? Isn't there some kind of configuration that maps the rules in the grammar to whatever convention Nova uses for their token names? Now tree sitter does make this super easy, but my point was you still have to have some kind of per-language configuration/logic to work, whereas the entire point of LSP is to have none. reply kstrauser 14 hours agorootparentThat's done with the \"highlights.scm\" query (https://tree-sitter.github.io/tree-sitter/syntax-highlightin...) that maps nodes to their types with lots of standard names (https://github.com/tree-sitter/tree-sitter/blob/master/highl...). The maintainer of the tree-sitter grammar is usually one who maintains that mapping. At least, every time I've wanted to use it, it's been the case that all of that was already done and part of the grammar's repo. reply abdullahkhalids 14 hours agoparentprevCan one write a tree-sitter grammar for English (or any other natural language), that basically labels each sentence as a statement, so I can use difftastic to show changes on sentences rather than visual lines? This is because visual line diffs for an essay is bonkers. Usually the sentence changed starts in the middle of a visual line. reply pxeger1 11 hours agorootparentThe common advice[0] is to just write one sentence per line. I usually split at commas etc as well. Then use editor soft wrapping instead of fixing a maximum line length - but if your lines get longer than the screen width that might be a sign your sentences are too complex. [0]: anyone have a good source for this? I’m not sure where I first encountered it reply rokkitmensch 5 hours agorootparentI will write excessively complex sentences whenever I darn please, and will be hogtied before I stop at the whims of a /diff tool/. Mock outrage aside, whimsy and play in written language is vastly cheaper than in industrial programming environments. Provided, of course, the author can yet communicate while horsing around. reply sovietswag 5 hours agorootparentprevIt turns out that there is a lot of discourse out there about \"semantic newlines\", under a few different names. So far the names I've seen are: - One Sentence Per Line (OSPL) - Semantic Line Breaks (SemBr) - Semantic Linefeeds - Ventilated Prose - Semantic newlines Reading through the pages below was helpful in getting a better idea of what language people use to discuss this. They're mostly historical retrospectives or arguments for the merit of semantic newlines. https://rhodesmill.org/brandon/2012/one-sentence-per-line https://ramshankar.org/blog/posts/2019/semantic-line-breaks https://vanemden.wordpress.com/2009/01/01/ventilated-prose https://discuss.python.org/t/semantic-line-breaks/13874 https://discuss.python.org/t/one-sentence-per-line-for-peps-... https://sembr.org https://asciidoctor.org/docs/asciidoc-recommended-practices/... (Actually I think one-sentence-per-line denotes something slightly different from semantic-line-breaks, not that I know what that difference is). reply abdullahkhalids 7 hours agorootparentprevI am not a slave of the machine. The machine is my tool. The machine will conform to what I want. Not the other way around. There is no philosophy more important in this age. reply antonvs 6 hours agorootparentIn my work I encounter quite a few people beating their heads against walls trying to make the machine \"conform to what they want\". You can often achieve your goals much more quickly by using tools they way they best support being used. reply alpaca128 21 minutes agorootparentAnd often there is a middleground. In this case one could write a script that outputs a reformatted file with one sentence per line. In Vim this could even be a simple macro as the editor already has a key for jumping to the next sentence. reply bpeebles 7 hours agorootparentprevhttps://rhodesmill.org/brandon/2012/one-sentence-per-line/ is one possibility. And discusses a Kernighan Unix memo from 1974 advocating for the practice. \"UNIX for Beginners\" https://web.archive.org/web/20130108163017if_/http://miffy.t... (PDF) reply meatmanek 8 hours agorootparentprevhttps://news.ycombinator.com/item?id=31808093 reply fragmede 13 hours agorootparentprevword diff gets you halfway without that complexity reply abdullahkhalids 13 hours agorootparentDo you mean the diff system inbuilt into Microsoft Word or Google docs etc? reply senknvd 13 hours agorootparentThere is a --word-diff flag in git diff. It can also be customized using --word-diff-regex to possibly match sentences. reply abdullahkhalids 12 hours agorootparentI see. From the docs [1] --word-diff-regex= ... A match that contains a newline is silently truncated(!) at the newline. If I understand this correctly, if you use newlines inside a sentence (if you are writing a fixed width document, for example), this won't work. [1] https://git-scm.com/docs/git-diff reply mzs 12 hours agorootparentpipe through \"fmt -sw999999999999\" first reply emporas 15 hours agoparentprevWas reading about emacs and tree-sitter today [1]. Tree-sitter is a force to be reckoned with. [1] https://www.masteringemacs.org/article/how-to-get-started-tr... reply danielvaughn 8 hours agoparentprevAs soon as you said tree sitter I immediately understood. Yes, I can’t believe I never realized that you could totally build a syntax-aware VCS on top of it. That’s brilliant. I just wrote a language parser a few months ago in tree sitter and it’s probably the most delightful software I’ve used apart from ffmpeg. reply fiddlerwoaroof 7 hours agoparentprevThe main issue I have with tree-sitter is that it’s approach can’t work for many languages I care about: Common Lisp cannot be parsed without a full lisp implementation; Haskell’s syntax is complicated enough that the grammar is incomplete; C/C++ can’t be parsed accurately if only because of the pre-processor; parsing perl is Turing-complete, etc. I think the suggestion elsewhere makes sense: don’t make us write parsers in a new ecosystem, but instead define a format for existing parsers to produce as a side-output. reply chubot 14 hours agoparentprevBTW there is interesting feedback from 4 people on a Treesitter post yesterday: https://news.ycombinator.com/item?id=39762495 (1) The top comment is from the author of difftastic (the subject here), saying that treesitter Nim plugin can't be merged, because it's 60 MB of generated C source code. There's a scalability problem supporting multiple languages. The author of Treesitter proposes using the WASM runtime, which is new. (2) The original blog post concludes with some Treesitter issues, prefering Syntect (a Rust library that accepts Textmate grammars) Because of these issues I’ll evaluate what highlighter to use on a case-by-case basis, with Syntect as the default choice. https://www.jonashietala.se/blog/2024/03/19/lets_create_a_tr... Other feedback: (3) The idea of a uniform api for querying syntax trees is a good one and tree-sitter deserves credit for popularizing it. It's unfortunately not a great implementation of the idea (4) [It] segfaults constantly ... More than any NPM module I've ever used before. Any syntax that doesn't precisely match the grammar is liable to take down your entire thread. --- I think some of the feedback was rude and harsh, and maybe even using Treesitter outside its intended use cases. But as someone who's been interested in Treesitter, but hasn't really used it, it seems real. One problem I see is that Treesitter is meant to be incremental, so it can be used in an editor/IDE. And that's a significantly harder problem than batch syntax highlighting, parsing, semantic understanding. --- That is, difftastic is a batch tool, i.e. you run it with git diff. So to me the obvious thing for difftastic is to throw out the GLR algorithm, and throw out the heinous external lexers written in C that are constrained by it, and just use normal batch parsers written in whatever language, with whatever algorithm. Recursive descent. These parsers can output a CST in the TreeSitter format, which looks pretty simple. They don't even need to be linked into the difftastic binary -- you could emit an CST / S-expression format and match it with the text. Unix style! Parsers can live in different binaries and still be composed. The blog post use case can also just use batch parsers that output a CST. You don't Treesitter's incremental features to render HTML for your blog. reply diffxx 9 hours agorootparentAs one of the harsh and rude commentators, I would say I basically agree with your interpretation. You also correctly inferred that I have experience with working with it in an area that is arguably outside of its true use case. At the same time, I believe that there needs to be a corrective about what tree-sitter should and should not be used for. There are companies building security products on top of tree-sitter which I think is an objectively bad idea given its problems and limitations. Difftastic is to me a grey area because it could lead hypothetically to a security issue if it generates an incorrect diff due to an incorrect tree-sitter grammar. Unlikely but not impossible. Your point about batch vs incremental is spot on, though even for IDEs, I think incremental is usually overkill (I have written a recursive descent parser for a language in c that can do 3million lines per second on a decent laptop which is about 60k lines per 20 ms, which is the window I look to for reactivity). How many non-generated source files exceed say 100k lines? Incremental parsing feels like taking on a lot of complexity for rather limited benefit except in fairly niche use cases (granting that one person's niche is another's common case). That being said, it is impressive that their incremental algorithm works as well as it does but the cost is that grammar writers are forced to mold a language grammar that might not fit into the GLR algorithm. When it doesn't work as expected, which is not uncommon in my experience, the error messages are inscrutable and debugging either the generator or the generated code is nigh impossible. Most of the happy users have no idea how the sausage is made, they just see the prettier syntax highlighting that works with multiple tools. I get that my criticism is as welcome as a wet blanket, but I just think there is something much better possible which your comment hints at. reply kstrauser 9 hours agorootparentFWIW, as a happy user, I'm mainly happy that it exists at all. In the short term, it reduces the work supporting M editors and N languages from to M+N. That's nice. More importantly, it puts a bug in everyone's ear that this is a good and achievable thing. Maybe the next step will be a tree-sitter-API-compatible replacement that fixes some of those problems and we can all migrate onto that. That is, the big win is getting people to buy into the concept of syntax (and analysis) as a library and not as a feature of one specific editor. Once we're all spoiled by that, perhaps a better implementation or an nice API will come along and astound us all. reply porker 3 hours agorootparentprev> Your point about batch vs incremental is spot on, though even for IDEs, I think incremental is usually overkill I'd understood that incremental was used so that as someone writes code the IDE can syntax highlight the incomplete and syntactically incorrect code with better accuracy. Is that not the case? reply joshspankit 12 hours agoparentprevHow close are we to being able to copy a function in to the clipboard, then highlight some lines of code and paste the function around it (like highlight > quote marks)? reply OJFord 9 hours agorootparentWhat does it mean to paste a function around some lines of code? As in what're the manual steps you do because that's not possible today? reply alpaca128 10 minutes agorootparentI assume auto-wrapping a copied function signature around a selecting block as if it was just parentheses or something. I don't think I ever needed that, but a variant of that might be useful for XML where wrapping something in a pair of tags is a common operation. reply epistasis 17 hours agoparentprevI'm imagining what I could have done in my compilers class with something like tree-sitter... It feels kind of as foundational as YACC. reply ivanjermakov 17 hours agorootparentIt is literally an alternative to YACC and other parser generators. reply thaumasiotes 4 hours agoparentprevThis question is coming from a place of total ignorance: One appeal of the general idea of a structural diff tool, for me, is ignoring the ordering of things for which ordering makes no difference. x = 4 y = 7 are independent statements and the code will be no different if I replace those two statements with y = 7 x = 4 However, this information is not actually present in the abstract syntax tree. If I instead consider these two statements: x += 3 x *= 7 it is apparent that reordering them will cause changes to the meaning of the code. But as far as the AST goes, this is the same thing as the example where reordering was fine. What kinds of things are we doing with our new AST tooling? reply etbebl 3 hours agorootparent> x = 4 > y = 7 > >are independent statements and the code will be no different if I replace those two statements with > > y = 7 > x = 4 Not always, e.g. in a multi threaded situation where x and y are shared atomics. Then unless we authorize C++ to take more liberties in reordering, another thread will never see y as 7 while x is not yet 4 in the first example, but not the second. This kind of subtlety can't be determined from syntax alone. reply thaumasiotes 3 hours agorootparentOK, I tended to agree that the AST was inadequate for this task. But what are we doing with it? That's most of what I want from \"structural code diff\". reply bloopernova 19 hours agoprevRelated, updating difftastic and friends if you installed via cargo: cargo install cargo-update cargo install-update --list cargo install-update --all Other fun Rust projects available via cargo: https://mise.jdx.dev/ mise-en-place, a drop-in replacement for asdf https://asdf-vm.com/ that is really fast and flexible. https://github.com/ajeetdsouza/zoxide is a fantastic cd replacement, which stores where you cd to, and you can then do a partial match like \"z hel\" might take you to \"~/projects/helloworld\". https://github.com/bootandy/dust is a compliment to \"du\", shows which directories are using the most disk space. reply arlort 15 hours agoparentAnother three very neat ones are - https://github.com/eza-community/eza (ls with some added visual sugar) - https://github.com/ClementTsang/bottom (htop but with graphs) - https://github.com/sharkdp/bat (cat with syntax highlight) reply kstrauser 19 hours agoparentprevI love zoxide! Also for your list: lsd, a prettier ls. reply bloopernova 18 hours agorootparentso... many... colours! Looks great, thank you for the recommendation. reply letmeinhere 8 hours agoparentprevMy favorite of the new `du`s is dua-cli, an ncdu clone (an interactive TUI). I went hunting because the latter didn't have a light-mode. reply satvikpendem 14 hours agoparentprevAlso, cargo-binstall (cargo binary install) which allows you to not have to compile every single time you cargo install and instead allows you to just install the binaries for a specific program. It also integrates with cargo install-update. reply tomatao 11 hours agoparentprevHow do these compare to https://github.com/moonrepo/proto ? reply qmmmur 17 hours agoparentprevWow, I installed mise-en-place. It's exactly what I wanted asdf to be. reply bloopernova 16 hours agorootparentIt's so much faster than asdf, the dev did a really great job. reply drewbitt 13 hours agorootparentThe rename to mise broke my workflow for a bit and the library is changing fast & adding new features frequently. That's good, but I hope it can stabilize a bit, so things don't get deprecated again. Still love it. reply bloopernova 12 hours agorootparentYeah, the name \"rtx\" was not easy to search for. Mise is a much nicer name too. I am currently using it with direnv, but there's enough functionality in mise to replace that too. I keep meaning to spend some time making mise work without direnv, but it's not been urgent since everything pretty much just works now. I like the active development since the dev really seems to care about doing a great job, and I've been lucky enough so far that my (simple) workflows haven't been impacted. reply prh8 3 hours agorootparentDo you know if there’s a way to do per directory aliases with Mise? Every time I see a tool for directory environment, that’s the one feature in really hoping for reply IshKebab 19 hours agoparentprevncdu is the best du replacement by far. reply polygamous_bat 17 hours agorootparentI've always used dust as a replacement, and so I am curious to know if you have tried both tools: do you have thoughts on what makes ncdu better? reply IshKebab 16 hours agorootparentDust is probably the best you can get without interactivity, so it's good for logs. But ncdu is a fully interactive file browser that lets you navigate through the tree, and crucially it lets you delete things without requiring a full rescan. It's amazing for freeing up disk space by deleting things you don't need anymore, which is probably 95% of the reasons I run `du`. reply mlavrent 19 hours agoprevI’m almost not sure why tools like git don’t ship with this as default. Been using difft for about a year now, and my main complaint is that it makes it hard to go back and use other diff tools when I don’t have difft available :). I am curious if there’s been any work on _semantic_ diff tools as well (for when eg the syntax changes but the meaning is the same). It seems like an intractable problem in the general but maybe it’s doable and/or useful for smaller DSLs or subsets of some languages? reply kstrauser 18 hours agoparentI think shipping good ol' diff as the default makes sense. It's going to be there already on any system you might want to run git on, it's fast, it's tiny, and everyone knows the basics of how to use it. But I'm glad it's easy to change that default. reply DarkPlayer 14 hours agoparentprev> I am curious if there's been any work on _semantic_ diff tools as well (for when eg the syntax changes but the meaning is the same) We are working on https://semanticdiff.com/ which detects basic semantic changes like converting a literal from decimal to hex or reordering keys within JSON objects. It is not a command line utility but a VS Code extension and GitHub App. You can check out https://semanticdiff.com/blog/semanticdiff-vs-difftastic/ if you want to learn more about how it works and how it differs from difftastic. reply Izikiel43 11 hours agorootparentThank you, you just simplified my life greatly, will use it for a demo tomorrow. reply otherjason 19 hours agoparentprevDifftastic is a useful tool, but in my experience, it's far too slow to be suitable as the default selection for a ubiquitous tool like git. reply drcongo 15 hours agorootparentI'm finding it instantaneous here on a large dirty codebase. In what way is it slow for you? reply acdha 13 hours agorootparentDiff a large JSON file - I think it has to do with how large a single structure since I notice it most with static test fixtures. reply ruined 19 hours agoparentprev>I am curious if there’s been any work on _semantic_ diff tools as well (for when eg the syntax changes but the meaning is the same). if you do this your difftool becomes a compiler reply mlavrent 19 hours agorootparentSorry, I should've been clearer. I'm interested if there's any tool that does this kind of thing statically, without running the code. I guess a simple approach is to compile both programs and see if the generated code is the same, but I'd guess reasoning at the generated-code level will probably produce a lot more false positives (i.e. tool will report a change when there isn't one) than if you reason about the original program. reply jerf 17 hours agorootparentThis gets really hard, really fast. That is, yes, reasonably obviously doing this completely 100% accurately requires a solution to the halting problem, but even getting to \"useful\" is really really hard. Even the Haskell world doesn't try to solve the \"equivalence of functions\" problem, and it's even more complicated in imperative languages. You probably have a mental image of catching something really simple, and, yeah, \"1 + 1\" -> \"2\" is reasonably easy, but in reality there aren't a lot of those super easy changes. Most of the time there is something confounding the situation. Truly neutral refactorings are pretty uncommon in their own right. You can see that when someone is discussing semantic versioning and pointing out that if you define a \"major version\" as \"there exists at least one possible use of the code whose behavior will be changed as a result of this library change\", almost any API change is automatically a major version change, which isn't really what anyone wants. E.g., in Python, the mere fact that introspecting on an object's methods will show one more method than it used to isn't really what we want a major version change for. In general, proving refactorings are actually 100% safe is equally difficult; even simple arithmetic changes can result in things overflowing at different times or in different ways, it's virtually impossible to rewrite an expression involving floats without the change being witnessable somehow, extracting a function could make it so that code that previously didn't overflow the stack now does, memory allocation changes can be the difference between OOMing and not and may interact with GC in unpredictable ways if you get really precise, etc. reply kstrauser 16 hours agorootparentHere's a fun related article on Indistinguishability Obfuscation: https://cacm.acm.org/research/indistinguishability-obfuscati... TL;DR verifying that 2 functions have the same output is really freaking hard. reply brabel 16 hours agorootparentprevThe Unison language (https://www.unison-lang.org/) knows how to compute whether the semantic meaning of the code has changed (though I don't think it's possible to get the actual diff to visualize it). You can edit a function you've committed into the Unison code repo, and if you didn't change the semantics of the function, it's actually stored under the exact same hash... All places using the function refer to it by its hash, so nothing needs to be recompiled either, and no tests need to be rerun. Things like renaming variables, reordering code whose order doesn't matter (common in functional programming) and things like that do NOT change the hash. I believe this is only possible because Unison is a Pure Functional Language. If it's not, it becomes a NP problem to decide if two programs are exactly equivalent, probably. I wonder if Unison could provide the actual semantic diff you're thinking of, it's probably not much more complex than actually knowing the meaning of the code did change. Maybe create a Feature Request :) https://github.com/unisonweb/unison reply Chris_Newton 19 hours agorootparentprevif you do this your difftool becomes a compiler Some linters and formatters are effectively compilers already, so that doesn’t seem completely implausible in itself. Finding canonical representations of common coding patterns so you can quickly and reliably determine that they are equivalent is a different question, though. reply hobs 19 hours agorootparentprevThat's exactly what I have done with diffing SQL in lazy mode - just use a server and diff the AST/plan. reply slotrans 19 hours agorootparentTwo semantically equivalent SQL statements can plan differently... reply rrrrrrrrrrrryan 18 hours agorootparentThe exact same SQL statement can plan differently if table statistics change. reply hobs 14 hours agorootparentprevAbsolutely and for this case a different plan mattered. reply rob74 18 hours agoparentprev> I am curious if there’s been any work on _semantic_ diff tools as well (for when eg the syntax changes but the meaning is the same) So when using such a diff tool you can spend hours refactoring something, and then git will refuse to commit your changes because your refactoring was successful in not changing the behavior of the code? I understand what you mean, but if we arrive at that point maybe we should stop calling it \"diff\", to avoid confusion... reply kstrauser 18 hours agorootparentGit doesn't use the output of `diff` to determine whether anything has changed. reply samatman 16 hours agorootparentTrue, although not widely known it would seem. It does use diff to generate patches, however. I know in today's GitHub-dominated landscape, that's considered a bit of a dusty feature, but it would be a pity to break it. reply viraptor 14 hours agorootparentIf you want to generate patches rather than look at local differences, there's a specific command for that - https://git-scm.com/docs/git-format-patch reply pmayrgundter 19 hours agoprev\"Do you know how to read @@ -5,6 +5,7 @@ syntax? Difftastic shows the actual line numbers from your files, both before and after.\" Preach! Just dropped it in and did a git diff.. works like a charm! reply neuromanser 13 hours agoparent> Do you know how to read @@ -5,6 +5,7 @@ syntax? Do you not? reply pmayrgundter 6 hours agorootparent20 years staring at it and no, i don't. i usually have to work it out from context. i think if you have vi or ed sensory organs it might work better for ya. which.. i still chuckle that vi is the visual editor, bc ed lol reply snthpy 3 hours agorootparentprevSame here. If there's a great ELI5 explanation somewhere, please post a link. Thanks reply wffurr 9 hours agorootparentprevNo, I sure don’t. reply teaearlgraycold 5 hours agorootparentprevNever needed to. reply sanity 19 hours agoprevInteresting, I found Semantic Merge [1] years ago but it was never open source. This just does diff but not merge, but at least it's open source - and the diffs look a lot nicer, I've already made it my default. Any plans to extend it to merging? [1] https://docs.plasticscm.com/semanticmerge reply OJFord 9 hours agoparent> Any plans to extend it to merging? The GitHub readme: > Can difftastic do merges? > No. AST merging is a hard problem that difftastic does not address. > AST diffing is a also lossy process from the perspective of a text diff. Difftastic will ignore whitespace that isn't syntactically significant, but merging requires tracking whitespace. reply rideontime 18 hours agoparentprevWas going to suggest this myself, this was a godsend when I was working with a big team on a C# project going through a messy refactor. reply jmholla 16 hours agoprevI tried switching to this, but I found it noisy and use weird formatting for things that didn't change. I went back to using icdiff[0]. [0]: https://github.com/jeffkaufman/icdiff reply pjturpeau 17 hours agoprevIt seems to be a great tool, however on the few checks I did on big XML files, it shows modified lines in normal green and modified attributes in bold green, which makes them difficult to detect visualy. I didn't find in the documentation how it is possible to change the style of the diff, or to ask for another color in the bold case. Any idea? reply jez 14 hours agoparentUnfortunately it doesn't appear to allow customizing colors yet. I chimed in on this issue[1] to express support for that. You may wish to also chime in on that one, or open a new issue if you think that the feature you're looking for is sufficiently different from the one discussed in that thread. [1]: https://github.com/Wilfred/difftastic/issues/611 reply yboris 11 hours agoprevRelated tool: diff2html also as a CLI - with one command opens a browser tab showing HTML diff (side by side or line by line) - a great way to review your work before committing. https://diff2html.xyz/ reply asicsp 18 hours agoprevPrevious discussions: https://news.ycombinator.com/item?id=27768861 (297 points3 years ago61 comments) https://news.ycombinator.com/item?id=32746258 (698 points2 years ago90 comments) https://news.ycombinator.com/item?id=30841244 (983 points2 years ago219 comments) reply jerrygoyal 32 minutes agoprevhow to set it up as the default git diff in vscode? reply Arrgh 13 hours agoprevLong, long ago, I used a library called Augeas (https://augeas.net/) in a drift-detection product*, so that if we detected a difference in config files, either on the same server through time, or on different servers that were supposed to be similar, we could de-noise the diffs, and more importantly, let users write fine-grained, but syntax-tolerant, allow-lists like \"this particular setting is allowed to differ\"... or even \"this particular setting can have one of the following list of values\". :) * the company was acquired by Splunk years after we shelved that product reply domenkozar 6 hours agoprevIn devenv.sh: difftastic.enable = true; reply dsp_person 12 hours agoprevInteresting that while the arch linux the package weighs in a 7MB, it extracts to 80MB installed, and the `difft` binary is a whole 78MB. On a ZFS dataset with LZ4 compression du says it's 17MB. I wonder why not just compress whatever is so compressible in the binary? It would probably even load faster to decompress it in ram. reply jiripospisil 11 hours agoparentJust a data point because you mentioned compression and I got curious - it's about 10MB on btrfs with zstd:1. Processed 1 file, 614 regular extents (614 refs), 0 inline. Type Perc Disk Usage Uncompressed Referenced TOTAL 14% 10M 77M 77M none 100% 1.1M 1.1M 1.1M zstd 12% 9.8M 76M 76M reply dsp_person 10 hours agorootparentApparently ZFS 2.2.0 added an early abort capability for zstd compression. Maybe I'll switch over to it. reply speed_spread 10 hours agoparentprevIts probably related to the comment here about the Nim parser being an unmergable 60mb C file. It looks like TreeSitter requires lots and lots of code, a lot of which must be redundant / compressible. reply replwoacause 12 hours agoprevI want for a nice diff tool on Mac that doesn’t cost an arm and a leg like Kaleidoscope. Right now I am using one called CompareMerge2 from the App Store which is pretty good. reply PlunderBunny 10 hours agoparentI too, settled on CompareMerge2 after casting around fruitlessly, and lusting after Kaleidoscope. reply catlan 41 minutes agorootparentHere a coupon code for 40% off: HN1337 reply ein0p 7 hours agoprevI wish someone would make a console 3 way merge with some rudimentary editing support. I know there’s vimdiff, but I just don’t gel with it. For the lack of a better description I just want a console version of Meld’s 3-pane merge. reply nibab 17 hours agoprevThis is great! I wish my PR review tools allowed me to plug in something like this. Hopefully one day we will go back to the world of customizable/plugin-based software. Most of my web tools are very prescriptive about the user experience and dont let me tailor my tools. reply sanxchit 17 hours agoprevWhat an amazing tool, wish it had a GUI version as well. reply layer8 16 hours agoparentFrom the screenshot examples in the readme, I’m not sure how substantial the benefits are over GUI tools like Kdiff3 or WinMerge that have existed for ages. reply sanxchit 15 hours agorootparentI've used WinMerge, its very different from the above tool because its still a text diff. It often gets the diffs wrong when multiple lines are involved. Take this trivial C# example: https://www.diffchecker.com/gr0H7qA1/ Most diff tools throw out something that is quite difficult to parse, but difftastic gave me the most concise diff so far. reply arcastroe 4 hours agoprevCould this be integrated with something like Gitea or is this purely for CLI based use? reply xyzelement 16 hours agoprevI don't write enough code / write it professionally anymore to integrate it into my life BUT MAN this is a great idea. In general, we're overflowing in TMI which makes it hard to suss out what matters. For example at work I often read docs that describe what we do for customer X vs customer Y and it takes a ton of work to suss out the 1% of text that is different between those two, which is really what you want to understand and validate. So anything that makes just the impactful change stand out is beyond welcome. reply adamc 18 hours agoprevDoesn't seem to have a Debian install. reply pas 18 hours agoparenthttps://github.com/Wilfred/difftastic/issues/560 help wanted :) reply gexla 6 hours agoprevThanks for this. I'll give it a try. And for diffs in a different context, I really like Beyond Compare. reply zokier 18 hours agoprevThere is also gumtree that does ast based diffing https://github.com/GumTreeDiff/gumtree reply blackfawn 17 hours agoprevDifftastic seems really nice! Unfortunately it shows some changed binary files which makes it sort of unusable. `file` reports these files as \"ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, stripped\" and the MIME type/encoding is \"application/x-sharedlib; charset=binary\" so not sure why difftastic is trying to show them as thousands of changed lines of text... reply airstrike 17 hours agoprevFantastic tool. Now we just need the vscode extension ;-) reply modernerd 2 hours agoparentSemanticDiff is probably the closest for now, although I don't think it uses tree-sitter. https://semanticdiff.com/ Found via https://github.com/Wilfred/difftastic/issues/194. reply akkartik 16 hours agoprevIs there a way to make the output more familiar to diff users? I've turned on --inline. I also mostly don't care enough about line numbers to want them on every line, so prefer the '' leaders. Also, on Arch there doesn't seem to be a man page. reply keybored 17 hours agoprevI think I use this indirectly through the git-delta pager which is a great pager replacement for git. reply Aissen 25 minutes agoparentNo, I don't think delta integrates with difftastic: https://github.com/dandavison/delta/issues/535 reply hrdwdmrbl 19 hours agoprevIt seems like a major lapse in product innovation that Github has not come out with something like this. They don't even have something to help you when the indentation changes, they usually just show it as a giant add & remove. Their diff viewer can and should be smarter. reply neuromanser 13 hours agoparentGithub can't even recognize syntax, let alone provide semantic diffs! In fact, Github can't even tell that foo.cpp.in is different from foo.mk.in! Any foo.t is declared to be Perl, with no way to fix it…There are a decade-old tickets! reply bPspGiJT8Y 6 hours agoparentprevTree-sitter optimizes for performance (to use in editors), not for correctness. In fact even TS' core developers advocate for not bothering too much with correctness of grammars[1]. I imagine this constraint would be a deal-breaker for GitHub or anyone else in their position. [1] https://github.com/tree-sitter/tree-sitter/issues/130#issuec... reply sroussey 18 hours agoparentprevGitHub has the option to ignore whitespace in a diff. reply mbork_pl 16 hours agorootparentWhich is useful, but too crude. reply nialv7 12 hours agoprevDifftastic is great, but when I need to create patches I need to go back to good ol' diff... Is there a patching tool that can apply difftastic diffs? reply duncan_britt 5 hours agoprevCan it be made to work with magit in emacs? reply adamtaylor_13 18 hours agoprevDoes anyone know how to enable this for .html.erb files? I found it doesn't work properly in Ruby .erb files which makes it fallback to just regular ol diff behavior. reply coldbrewed 18 hours agoparentThat may require a tree-sitter implementation for erb templated html; it may exist but if so it's less of a mainstream thing. Some quick googling turns up https://github.com/tree-sitter/tree-sitter-embedded-template which may or may not meet your needs. reply markrages 16 hours agoprevDoes the output work with patch(1)? Or does this use a different patch? reply mihaigalos 18 hours agoprevNice tool. Also relevant: https://github.com/dandavison/delta reply mnw21cam 18 hours agoprevNo package for Debian-like systems yet. reply abledon 17 hours agoprevonnly found out about this because it was an option to view diffs when installing git using Nix reply Night_Thastus 18 hours agoprevNo MSYS install, sadly. :( reply quasarj 15 hours agoparentIt's just a cargo package. Is there a working rust/cargo toolchain under MSYS? reply aus10d 18 hours agoprevReally cool idea! reply drcongo 16 hours agoprevI love this so much. I hate reading cli diffs, but this is instantly understandable. reply brainzap 14 hours agoprevfuck yeah finally, I am so sick of text based diff reply throwawaygo 15 hours agoprev [–] How long until this is just a prompt? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Difftastic is a CLI diff tool that compares files based on syntax, not line-by-line, aiding humans in accurately identifying code differences more effectively.",
      "It uses tree-sitter to analyze code, enabling it to recognize alterations in inner expressions while disregarding formatting changes.",
      "Difftastic supports various programming languages and file formats, provides real line numbers, visualizes wrapping modifications, integrates with Git, and is entirely open-source under an MIT license, developed by Wilfred Hughes with Emacs and coffee."
    ],
    "commentSummary": [
      "Users discuss using tree-sitter for syntax parsing in various tools like Difftastic, neovim, and Github code search, highlighting benefits and challenges.",
      "Conversations cover writing grammar for tree-sitter, incremental parsing limitations, diff visualization, and the idea of semantic newlines in programming.",
      "The discussion extends to comparing tools like Difftastic, Semantic Merge, and SemanticDiff for code changes, merging, and customizing colors in diff tools, emphasizing the efficiency and potential advancements in code analysis tools."
    ],
    "points": 899,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1711028566
  },
  {
    "id": 39783223,
    "title": "Memories: Nextcloud-Based FOSS Photo Platform",
    "originLink": "https://memories.gallery/",
    "originBody": "Memories is a FOSS Google Photos alternative that you can self-host (it runs as a Nextcloud plugin).Website: https:&#x2F;&#x2F;memories.gallery&#x2F;GitHub: https:&#x2F;&#x2F;github.com&#x2F;pulsejet&#x2F;memoriesDemo Server: https:&#x2F;&#x2F;demo.memories.gallery&#x2F;apps&#x2F;memories&#x2F; (demo runs in San Francisco on a free-tier cloud vm)Memories has been built ground-up for high performance and is extremely fast when configured correctly. In our testing environment, it can load a timeline view with 100k photos in under 500ms, including query and rendering time!Some features to highlight:* A timeline similar to Google Photos where you can skip to any time in history instantly.* AI-based tagging that runs locally on your server, identifying and tagging people and objects.* Albums and external sharing.* Metadata editing support* A world map of your photos, supported both on mobile and the web* Did I mention it&#x27;s extremely fast?Would love to hear feedback from the HN community! :)",
    "commentLink": "https://news.ycombinator.com/item?id=39783223",
    "commentBody": "Memories – FOSS Google Photos alternative built for high performance (memories.gallery)609 points by radialapps 14 hours agohidepastfavorite188 comments Memories is a FOSS Google Photos alternative that you can self-host (it runs as a Nextcloud plugin). Website: https://memories.gallery/ GitHub: https://github.com/pulsejet/memories Demo Server: https://demo.memories.gallery/apps/memories/ (demo runs in San Francisco on a free-tier cloud vm) Memories has been built ground-up for high performance and is extremely fast when configured correctly. In our testing environment, it can load a timeline view with 100k photos in under 500ms, including query and rendering time! Some features to highlight: * A timeline similar to Google Photos where you can skip to any time in history instantly. * AI-based tagging that runs locally on your server, identifying and tagging people and objects. * Albums and external sharing. * Metadata editing support * A world map of your photos, supported both on mobile and the web * Did I mention it's extremely fast? Would love to hear feedback from the HN community! :) codethief 9 hours agoFantastic project! > No Lock-In > Memories stores most of the metadata in the EXIF headers of your photos, which means that you can easily migrate to other solutions without losing your data. It also utilizes your existing filesystem structure for organization without converting it to any specialized format Given that, would a standalone version be feasible, i.e. one that doesn't rely on Nextcloud and only operates on a folder on disk? I mean, while Memories might not lock you in, Nextcloud can still do so. (No two-way sync etc. etc.) Currently, I just use Syncthing to synchronize all my files across devices (laptop, phone, home server, …) and it works splendidly! Ideally I'd just want to run Memories either locally (on the local copy of my photos folder) or on my home server (on the home server's copy of my photos folder). reply radialapps 9 hours agoparentThank you! I wrote a bit on why Nextcloud a while back, I'll link it here (see point 5 in FAQ): https://memories.gallery/faq/#faq As such, Nextcloud doesn't really lock you in; it just provides a framework for the app. You can, theoretically, continue to use Syncthing to sync files while running Nextcloud on top of it (probably not ideal though) I want to note though, the \"no lock-in\" philosophy refers more to being able to move out of Nextcloud/Memories at any point if you want. Nextcloud still just stores everything on your disk as folders and files, so you can just decide to nuke it one day and still have everything (not fully true yet, you'll still lose some things like tags and albums; exporting these out too is WIP) reply skybrian 8 hours agorootparentAnother question for your FAQ might be \"what is NextCloud?\" reply raybb 9 hours agoparentprevProbably not what you want but I use rclone to mount my hetzner NC instance and have syncthing that points to that mounted folder. It's been pretty hands free solution for me since I don't have a computer at home that's always on. It all started because I didn't want to keep getting sync conflicts with my obsidian notes between laptop and phone. reply BodyCulture 1 minute agorootparentIs that data in the data centre encrypted? reply adrr 8 hours agoprevBiggest missing feature for all these self hosted photo hosting is the lack of a real search. Being able to search for things like \"beach at night\" is a time saver instead of browsing through hundreds or thousands of photos. There are trained neural networks out there like https://github.com/openai/CLIP which are quite good. reply kn100 7 hours agoparentImmich does exactly this with CLIP models, you can even customise which CLIP model it uses and it does a phenomenally good job, I'd personally say surpassing even Google Photos. reply Jnr 2 hours agorootparentImmich is awesome for this and many other things. Automatic facial recognition feature in immich is also great. reply hgomersall 2 hours agorootparentIs there a hosted service of Immich? I'm keen to try it but really don't want the faff of self hosting (happy to pay!). reply Jnr 1 hour agorootparentI don't think they offer hosted solution yet. I self host but donate to the project. Not hard to set up, using docker compose. Just remember to set up automated backups, since there is no company taking care of that. reply vincnetas 2 hours agorootparentprevImmich warning from the home page : \"The project is under very active development. Expect bugs and changes. Do not use it as the only way to store your photos and videos!\" reply dz0ny 1 hour agorootparentAnd PHP project run as extension on Nextcould is not? Cmon. reply ic3man5 7 hours agorootparentprevI can 2nd Immich, nextcloud sync was just terrible for me also. reply dugite-code 6 hours agoparentprevNextcloud has some neural network integrations so implementing something like that might be possible. The Memories app can already use the Recognize app for the smart tags for Photos. Combining it with \"The Search Page\" app makes it a quite comfortable experience as is. reply kzisme 2 hours agorootparentHow easy are these integrations to setup? I use straight up Nextcloud sync and while it works most of the time sometimes it's a little finnicky (when I don't have cell service or something like that) reply schainks 7 hours agoparentprevGoogle Photos can already do this pretty well. I use the feature daily without friction. Sometimes, but not always, it can even pull text from receipts I photograph, which is handy for expense reporting. reply beezle 7 hours agorootparentMakes me wonder whether Google is scanning all photos for text and making use of the data found. reply lrem 2 hours agorootparentWell, the GP comment already pointed out they do use it for Photos search. Generally if someone is paying for the disk space to store your data, that’s with some use in mind, at the very least serving it back. Now, if you worry about some use you wouldn’t like… These are declared in open, if possibly too large, text in all the privacy policies. As a Googler I can tell you the internal bureaucracy for upholding these is dead serious. My product is used only by Google employees in their work duties, yet it took a couple months for us to get access to stats of our own UI. Something like an ads subsystem wanting to read a photos data field is likely to involve quarters of disputes with multiple lawyers. reply KetoManx64 6 hours agorootparentprevConsidering you're not paying for the product.. yes, they totally are. reply adrr 4 hours agorootparentGoogle photos charges if you want more than 15GB of storage. reply mcfedr 2 hours agoprevShout out for photo prism, similar concept, with nice ai search, and doesn't need next cloud, just a folder. https://www.photoprism.app/ No affiliation, just a happy consumer. reply gaazoh 1 hour agoparentStill requires hosting AFAICT. Would you know of a native Windows software alternative, perhaps? I could probably manage to host Photo Prism or Memories, but there's no way my parents would take the time to learn and set up a server, yet they have decades of pictures to sort through. reply noisem4ker 1 hour agorootparentThey offer a hosted service, on PikaPods: https://www.photoprism.app/cloud reply intuxikated 1 hour agoparentprevdoes it do automatic tagging / recognizing faces / scenes / objects? reply noisem4ker 1 hour agorootparentSort of. It uses TensorFlow for object recognition and categorization. I personally wouldn't say it's very reliable. I'm not going to compare it to Google Photos, though, as I never fed my photo library to the latter. reply nolok 1 hour agorootparentprevThey have a features page : https://www.photoprism.app/features reply leononame 13 hours agoprevHi, this looks super polished, congratulations. I've got a couple of questions: - Does the metadata editing allow it to write back to the file, storing the edited metadata in a sidecar or in the EXIF data? - Does it support some kind of auto-stacking? E.g. having raw files alongside exported tiff/jpg and recognizing that they are the same file? Especially for a nextcloud based solution, that'd be awesome reply radialapps 12 hours agoparentYes. Yes. reply gwbrooks 12 hours agorootparentDoes it preserve and/or allow editing of the text metadata (typically, the generative prompt) appended to PNG files created with Stable Diffusion? reply cwillu 10 hours agorootparentThat's exif metadata, so it should Just Work™ reply radialapps 12 hours agorootparentprevNo idea what that is reply tejtm 8 hours agorootparentolder versions of png did not support an exif chunk, so other metadata/property chunks were/are sometimes used reply hunter2_ 3 hours agoprevI need to dig deeper, but for now I just want to say how delightful it is to be able to go to the next/previous photo by swiping even if I've zoomed in. Google Photos makes me zoom all the way back out first with a huge pinch, which leads to a lot of frustration when swipes fail to change the photo. Nice work. reply beAbU 3 hours agoparent\"It's not a bug, it's a feature\". Many rely on this \"issue\" to prevent people from swiping to photos they're not supposed to see - a common enough occurence when showing someone a photo on your phone. reply spurgu 55 minutes agorootparentIndeed. Maybe there should be a setting for this functionality so you can turn it on/off according to your preferences. reply globular-toast 3 hours agorootparentprevReminds me of this: https://javlaskitsystem.se/2012/02/whats-the-waiter-doing-wi... Users will always find a way... reply anigbrowl 8 hours agoprevThis looks promising, plus it won't try to push its idea of my favorite photos at me when my phone detects I'm awake each day - a gPhotos behavior I find increasingly creepy and never asked for. reply mcfedr 2 hours agoparentDisable notifications and it's gone reply spurgu 53 minutes agorootparentNot sure why you're getting downvoted (upvoted to counter). I assume you mean the notifications of Google Photos (and not disabling notifications altogether). I don't see any legitimate use for them so might as well just turn them off. Edit: It doesn't change the fact that the behavior is creepy though. Maybe that's the criticism. reply tamimio 1 hour agoprevCan I search for a text in a photo? Off topic: what’s the best desktop application that allows that? A lot of my pics in my iPhone are still there because of this feature, but if there’s a program that does the same on windows/linux, I will be happy to use instead. reply thih9 1 hour agoprevCongrats on building this, looks great! Minor feedback: could you update the text or image to link to nextcloud? I know nothing about nextcloud, the project mentions it and I wanted to read more. reply bl4kers 13 hours agoprevBasically the last thing keeping me locked into Google Photos is it's social features. I see \"external sharing\" is mentioned but haven't found more information on that. Ideally I'd want the option to share an album with password protection, doesn't require an account to view, and allows comments on photos. Bonus would be to have a running album feed with view receipts per account. I know that's a lot but wanted to be specific. I'm ready to migrate but haven't found a platform that has feature parity on this front. reply collin128 8 hours agoparentThis for me too. The reason I pay for tons of extra Google photos storage is it tags and uploads and pics of my kiddos to an album shared with all the grandparents. It's their favourite app in the world and I'm never allowed to cancel. Could I replicate that here? reply radialapps 12 hours agoparentprevYou can share folders and albums that don't need an account to view. Folders do support password protection as well. reply singhrac 9 hours agorootparentDoes it support allowing others to upload photos as well (eg from a group trip)? If it does I’ll install it today on my homelab. reply radialapps 9 hours agorootparentFolders: this is fully supported. You can share out links of folders that anyone can upload to etc. These get stored in that folder (in your account) then. Albums: partial support. You can share links to albums that are viewable or share albums with others with an account on your nextcloud instance. People who have an account can upload photos to the shared albums. reply magic_hamster 12 hours agoparentprevIt sounds like you can implement this by hosting your photos on a server with password access. You don't even need google for this. reply lytedev 11 hours agorootparent#ThatDropboxComment ;) reply conqrr 12 hours agoprevI will take whatever is the most stable. I don't need a lot of feature, just a timeline and gallery with albums. Immich fits it for now, but it is way too focused on piling features and is bleeding edge. I hope memories has stability as its goal. reply dugite-code 6 hours agoparentI've been using it for quite a while and had no issues with the app at all. Only one hick-up with Nextcloud itself but that was really my fault if I'm honest reply radialapps 12 hours agoparentprevIndeed. Backward compatibility is also a major goal and there have been almost no major breaking changes since v2 (at v7 currently) reply pathsjs 13 hours agoprevHow complex is it to configure? I have an instance of NextCloud from Hetzner, but I would rather not misconfigure it. Also, is there a mobile app? Most of the time when I look at pictures I am on the phone reply talhah 12 hours agoparentAs easy as downloading an app from the store and telling it which directory to work with. If you need the AI features those require separate apps and depending on your deployment it might need some effort. I'm running a docker image and had to ensure I have some of the required libraries for the AI things to work. It isn't too hard to misconfigure though and I believe there's a decent amount of resources for this. As for mobile app, there isn't an explicit one but the webapp interface is mobile friendly and works pretty well. I also use NC photos and it still works with the tags and face recognition things. That app doesn't require \"Memories\" as far as I know. reply radialapps 12 hours agorootparentThere is an Android app, not for iOS yet. https://play.google.com/store/apps/details?id=gallery.memori... reply SushiHippie 10 hours agorootparentAwesome! F-Droid Link: https://f-droid.org/packages/gallery.memories/ GitHub releases: https://github.com/pulsejet/memories/releases?q=android reply XCSme 10 hours agorootparentprevIs there any photo-syncing at play? Or it's just a viewer for the data already on your NextCloud instance. If I take photos with my phone, I have to manually upload them to NextCloud? reply radialapps 10 hours agorootparentJust use the Nextcloud Android / iOS apps for auto upload. Memories automatically picks up everything that's uploaded. reply belinder 13 hours agoprevHow does this compare to immich? I spent a few weekends ago setting that up and it's working great, though it doesn't always detect faces correctly and swiping through images is a bit slower than Google photos reply talhah 12 hours agoparentThe main thing to me was that since this runs on Nextcloud its more extensible as the photos are just stored under the files and you can use various other apps to do what your heart desires. The other aspect is you get your own Gdrive alternative. You may or may not want this. For mobile compatibility Nextcloud is better since you can choose which folder photos go to and you can essentially automatically backup albums whereas with Immich you can't automatically specify which album photos from a directory should go [1]. In addition to this, Immich isn't too stable yet and each time you update the server all clients have to be on the latest version, at least since the last time I used Immich. 1. https://github.com/immich-app/immich/discussions/1678 reply menthe 12 hours agorootparentThis is moot. - Immich supports external libraries - Use docker compose and never worry about versions breaking reply talhah 12 hours agorootparent> This is moot. Immich fully supports external libraries. You're correct, Immich does support external libraries. To be more elaborate with my original comment, I meant inbuilt apps of Nextcloud which integrate well and complement the memories app. An example app would be the Face recognition one or Recognize if you fancy a different implementation. Nextcloud is after all an ecosystem so using memories gains you the other benefits of such an ecosystem. This might be overkill for some so it's upto your usecases. Versions breaking is an issue since both mobile and server clients have to be on the same version. Compared to Nextcloud Memories this is not an issue. This was an issue when I've last used Immich so this may have changed since then. reply Ringz 12 hours agorootparentprevExternal libraries? What do you mean by that? External storage? The last time I looked, Immich can’t work with a existing file and folder structure without importing (copy) everything in his own structure (database). That’s a big no go for me. In Memories, the file structure of your photos is preserved as-is. And you can run it alongside with other solutions that respect your folder structure. EDIT: looks like Immich can work with external folders. But: Does it put pictures from my phone in that external folder or in its own folder? reply menthe 12 hours agorootparentIt absolutely can, and it does not duplicate nor modify the medias. I mount my several TBs large library with the read-only flag in Docker. https://immich.app/docs/features/libraries#external-librarie... reply talhah 11 hours agorootparentprevImmich on mobile doesn't give you much flexibility with where each local folder gets uploaded to yet so it doesn't preserve folder structure. If you're using the CLI you can program the structure and tell it which album a folder can map to. reply Jnr 2 hours agorootparentYou can add any folder to immich as external library. No need to use cli. So if you want custom structure, synchronize files from mobile to server in any way you prefer (Syncthing, PhotoSync, etc.) and add that folder as an external library. reply radialapps 12 hours agoparentprevFace recognition is a hard task but you can manually correct the AI and it learns from that. Performance is the #1 goal here. I actually profiled this side-by-side and it's actually faster than Google Photos for my personal deployment. reply Jnr 2 hours agorootparentHaving tens of thousands of photos in Immich, I am surprised how accurate the model is. It rarely gets it wrong and when it gets it wrong, it usually happens with similar baby faces of close relatives. reply ementally 12 hours agoprevHow is it compared to https://ente.io/ ? reply radialapps 11 hours agoparentDifferent goals. Ente is commercial, Memories is free Ente is focused on E2EE, Memories is focused on self-hosting. reply saddist0 3 hours agorootparentIt has a commercial offering, but it isn't \"commercial\" and provide self hosting fyi. https://github.com/ente-io reply hanniabu 12 hours agoparentprevlooks like memories has auto-categorization reply 28304283409234 2 hours agoprevHave been using it for a couple of months now! Wife and I love the album feature which helps us to maintain photo albums async. It is a huge step up from the default photo's app in Nextcloud. Absolutely wonderful stuff. reply COGlory 10 hours agoprevWhere can I give you money? I see nothing on the support page. reply radialapps 10 hours agoparentThe GitHub has sponsors, thanks! :) https://github.com/sponsors/pulsejet reply stavros 8 hours agoprevThis is fantastic, better photo viewing is the only thing I was missing from Nextcloud, since without this I basically can't see any photos (they're too slow and the UX is bad). I installed this, indexed the photos, etc, but I still get lots of grey boxes (photos not loading) when I browse. Am I missing something, or is my server just too slow for this? EDIT: I think my server is just too slow. The entire machine freezes when loading one of the photos. reply radialapps 8 hours agoparentYou're missing the preview generator, so it's trying to generate them on demand. See https://memories.gallery/config/#recommended-apps Also note there are some extra config steps for the preview app (initial run, cron job). See https://github.com/nextcloud/previewgenerator reply spencerflem 11 hours agoprevI was just setting this up last weekend! Its lovely, really well put together. If this is your project, thank you so much reply radialapps 11 hours agoparentGreat to hear that! It's FOSS and I only work on this in my free time, so please keep the bug reports coming as you run into them! :) reply WhitneyLand 8 hours agoprevGreat work Varun. Doing photos is one thing, but doing it to scale and also with high performance at the client is a very nice accomplishment. reply radialapps 8 hours agoparentThank you! reply muppetman 7 hours agoprevThese are all similar things that Gallery (https://en.wikipedia.org/wiki/Gallery_Project) promised (not the same features because location for example wasn't a thing). And delivered on for a great number of years, really well. It seemed like the future of image hosting. And then it slowly trailed off, v3 of Gallery did get released but to a lukewarm reception (the old plugins/addons didn't work and the cloud was just starting to take over) and then yea, it just died. I have my gallery still online these days, with a fork so that PHP8 still works with it, but I've had to hide it behind an IP Access list now because I don't trust it being public facing anymore. I don't mean to shit on this project, I hope it's massively successful. We need more awesome open source apps like this. But I've been burnt once already pouring my heart and soul into an open source image gallery so I'm not going to do it again. In hindsight I wish I'd put all my photos in Flickr (I thought I was being so clever using Gallery) because it's stood the test of time that Gallery didn't. These days I use Google Photos, I can't see it going away anytime soon (though of course it's Google so who knows) Sorry this rant is probably very offtopic. The product itself looks amazing and I DO hope it achieves the success that Gallery couldn't. reply ksvarma 3 hours agoprevGreat work and finally I could take that step of bringing all the pictures together locally. reply nwbort 7 hours agoprevAny suggestions on the best workflow to export out of Google Photos? I have ~200GB in Google Photos and would need to eg put together the weird Google Photos metadata into usable format for Memories reply radialapps 7 hours agoparentGoogle Takeout. Importing from takeout metadata is supported (at least edits to the images; not albums right now) reply ajtaylor 6 hours agorootparentI tried using Takeout but the exported file structure and various metadata files were almost incomprehensible. This is likely partly my fault because I didn't download the full 100+ zip files, but I suspect there would be so many files scattered in too many directories to be much use. reply exhilaration 5 hours agorootparentI found this in an HN comment https://metadatafixer.com/ I haven't used it but it looks pretty promising reply nwbort 4 hours agorootparentprevYeah this was what my concern was basically reply ggm 12 hours agoprevDoes it have perceptual hash duplicate detection? reply menthe 12 hours agoprevFor having used Memories on Nextcloud, and having spent hours trying to micro optimize the Nginx & PHP configuration, I can safely say that, while it is better than the Nextcloud’s native Photos app, this is absolutely nowhere near to Immich, Filerun, or surprisingly even a dumb SMB share (which doesn’t have thumbnail caching…!). I’ve really tried hard, as Immich’s support for external libraries was still in a PR at that time, and didn’t want to have two separate tools to grab files and grab photos. A big part of the problem, it seems, is that, when you have a large library, and you jump/scroll to a specific year or so, it won’t cancel the previous page(s) worth of thumbnails loading. So as soon as you’re scrolling to search for something, it quickly accumulates hundreds of useless requests that quickly overload the PHP workers, and make everything crawl to a standstill. I personally had to give up. When trying to grab photos from abroad for my shortly upcoming proposal, I’ve literally deleted Nextcloud/Memories, plopped Immich in docker compose, let it index/transcode/generate thumbnails from scratch against my “external library” (so Immich doesn’t duplicate the medias), and that ended up savings me days of buffering, and was able to find the nice pictures for the occasion! (R740xd with 48 cores and 96TB SSD-backed ZFS pool) reply radialapps 12 hours agoparentIt's silly to micro optimize nginx / php when you have docker. Just use the Nextcloud Docker image or AIO and be done with it, everything is pre-optimized. Thumbnail caching exists (it's even highly configurable), there's absolutely zero buffering even with 100k photos+ on a raspberry pi. You obviously did not read the documentation or install the preview generator (which the docs clearly tell you to) Your deployment skills are hot garbage EDIT 3: ^the last line was in response to something that has been edited out of the original comment EDIT: the comment this is in reply to was edited multiple times. This is pointless and a lot of it is just false. EDIT 2: (at least currently the previous comment claims unnecessary PHP requests) this only happens if your configuration is incomplete; you didn't install preview generator as the docs say. Secondly it happens exactly once, the first time you see the image. All other requests are gracefully cancelled. reply menthe 12 hours agorootparentAbsolutely was using the AIO image, with thumbnail generation enabled for every formats of my library (another thing you need to manually edit in Nextcloud’s configuration as by default the format list is limited). And it’s only “pre-optimized” if you are cool with PHP memory limit crashes, PHP operation timeouts, PHP request size limits, and the works. Another joy associated with using Nextcloud sync is that uploads don’t even seem to support multi-part resumable uploads. So not only is it crazy slow, if there’s any error during the auto-upload of a 2G video clip, or the app is temporally backgrounded by iOS, it’ll go into an exponential back off (which you can force start), and eventually just start the upload for that/those file(s) over from scratch - good ways to waste days burning in your screen while in a trip and trying to ensure your medias are backed up in case you lose your phone on a trip. Try uploading raw images & 4k clips shot on iPhone to Nextcloud using the Nextcloud app + the AIO image from abroad. I’m telling you, I’ve tried to use them for quite some time, and I’m far from DevOps-illiterate - I’ve been using k8s since it’s infancy, we wrote the original Operators at CoreOS way back. reply radialapps 11 hours agorootparentI don't know what to say if you think flipping a switch in the admin UI is \"manually\" configuring. Otherwise, mostly all of this is just false. I routinely upload massive files (both RAW and 4K, yes) with almost default configuration and it just works. You also lied with \"no thumbnail caching\" in the first comment, no idea why. reply RockRobotRock 11 hours agorootparentWow, your first comment was completely rude and unnecessary. Why do you feel the need to say, \"you must be lying or you suck at deploying, because it works for me.\" also, they meant that their SMB share didn't have thumbnail caching reply radialapps 11 hours agorootparentHmm I can reply now, strange. That comment was edited multiple times so this is pointless. Also the original commentor started the rude exchange with \"hot garbage\" (wonder if they'll edit that out too now) EDIT: yeah, they edited that out too. reply RockRobotRock 11 hours agorootparentI understand now that you are the developer of this app. I'm sure it doesn't feel very good to have someone criticize it, I get that. But, this person cared enough about the thing you made to use it, troubleshoot it, and post a comment about it on HN. At the end of the day, it's valuable user feedback :) reply radialapps 11 hours agorootparentNo, just no. Valuable user feedback (which I absolutely love) is someone pulling the server logs, filing a bug on GitHub and following through till it gets fixed. Or, even attempting to see what parts are slow and reporting it. Worse but still very helpful, providing a link to an affected instance that might help \"see\" what might be happening. Spending a few hours trying random things and then complaining loudly like a know-it-all is NOT valuable feedback; it's bullshit. Nothing here is helpful, at all. There's absolutely zero indication of what could be fixed and why this particular person's deployment is broken while thousands of others on much slower hardware work just fine. None. reply RockRobotRock 10 hours agorootparentYeah, you're right. You should say \"please file a detailed bug report and consider contributing to the project\", instead of being a dick about it. The other comments you posted are also a bit odd without you disclosing you're the author. just saying reply radialapps 10 hours agorootparent100% agree, generally speaking. In this case I was rather annoyed since the original comment was very offensively worded and the person obviously had zero intention of helping out. Their only goal was to stroke their own ego by shouting out how something they couldn't get to work is crap. This is part of the reason for open source maintainer burnout -- useless comments about how something is broken with zero intention of helping to fix it. Hey, it's free -- if you don't like it then either help, or stop crying and move on to something else. reply 28304283409234 2 hours agorootparentYou asked for feedback in your post. No more, no less. Then you started flaming a person for giving their feedback. And start defending the flaming because you actually wanted feedback _in a certain format and worded nicely_. You are doing great stuff with Memories. Community building skills need some work though. That is my feedback. Which you asked for. reply RockRobotRock 10 hours agorootparentprevTotally understandable sentiment! reply dugite-code 6 hours agorootparentprevWell I for one would like to say I truly appreciate the brilliant work you have done. The app is a joy to use and I have had several coworkers ask what website I was using when I show them something. Your work has given me reminders to memories I long forgot about, and nothing can come close to the importance of recalling good memories. reply PennRobotics 43 minutes agorootparentprevI, for one, am sick of \"just run the Docker image\" as a deployment strategy and the be-all end-all of support. On my last attempt at serving a photo gallery, I deployed Hetzner's PhotoPrism image on a Hetzner server... and it failed. You would think such a thing would be bulletproof! They don't tell you an IPv4 address is needed and the log does not indicate anything is wrong other than Traefik has problems connecting to the certificate server. If something doesn't work—regardless of how unhelpful or oddly configured it is—I would love to hear about it so I temper my own expectations before trying it myself. Also, my Hetzner Photoprism bug report (\"I'm doing my part!\") has been sitting unanswered for two weeks. Getting the log data and trying out different DNS configurations and writing the bug report took a few hours, because I had to SSH into the Docker image and run curl verbosely and figure out which of the five docker-compose elements was causing problems; running Docker and setting up servers isn't my day job. I don't feel like paying 25 bucks a year for an IPv4 address and don't really want to figure out how to get Let's Encrypt to work on Hetzner's IPv6 by manually adjusting the Docker Compose configuration. I thought that's the point of Docker Compose: that you wouldn't need to dick around with it to get it working. I'll probably delete the thing and replace it with something else—potentially Nextcloud as there's no preconfigured Immich image. So, you know... expect my Memories bug report in a few days. While I sympathize with the developer whose product is popular enough to collect 1000 issues as of two days ago, some of your many thousands of users can also get fatigued by spending resources (time, money, mental effort) on deployments that fail because the machine and network running Docker is still different enough from yours that issues arise. I can't imagine this user's complaint was fabricated from thin air. Rude or not, they are having problems with the thing you made. Make a mental note, \"at least some small percent of users are still having issues, probably no clear root cause, probably a small enough population to ignore, maybe one day further reduce the friction for reporting bugs or find a way to gather more detailed info.\" Maybe put them in their place if they attack you personally or actually have no useful information e.g. \"Product Sucks!!\" but beyond that, I (as a potential fellow user) find these not-very-dev-helpful reports insightful, as there are two dozen competing FOSS photo storage programs and I want to efficiently figure out which application has features I prefer, is actually stable and easy to deploy, not likely to switch licenses going forward, has a clear goal and steady progress, documentation is clear and not just a \"Brothers Karamazov\" dump of one developer's stream of consciousness, etc. Otherwise, I start to figure: what is my price point for paying someone else to just do it right? reply menthe 11 hours agorootparentprevThe day SMB supports server-side thumbnail generation/caching, kindly let me know :] reply porphyra 10 hours agoprevDoes it have search by keywords/semantics? That would be my main need. For example if I need to find photos of red algae I could just search for that. OpenAI open sourced CLIP a couple of years ago: https://github.com/openai/CLIP and I was planning to write something myself to index my vast photo library but got too lazy and gave up. reply radialapps 9 hours agoparentNot yet, search is a major planned feature reply tuananh 9 hours agoprevI've been using Synology Photos. Not OSS but they have Android/iOS app so that I can just log in once and enable auto-backup. reply hereme888 11 hours agoprevI tried it a year ago through Nextcloud AIO and it barely worked... Has it had major improvements since? Or is it because I was using the AIO version of Nextcloud? reply radialapps 10 hours agoparentThe project is a little over a year old, so yeah lol reply greatNespresso 11 hours agoprevImpressed by the loading speed of pictures, how does that work? reply radialapps 11 hours agoparentIt uses very complex hand optimized SQL queries to do everything in a single database query. The database is also structured in a way to support this. The result: each request overall only takes a few milliseconds for the hardest part, the rest of the optimization is a game of caching. reply doublesocket 10 hours agoprevI currently use Mylio. The feature I like most is that I can store a compressed version of my entire catalog on my phone so it's very quick to find something and it works offline. I can then download the full res image if I want it. My biggest complaint about Mylio is there is still no automatic synchronisation from Android. You have to leave the app open for it to sync. Wondering if the Memories Android app can handle both of these points? reply radialapps 10 hours agoparentFirst one is interesting, not possible at the moment. The Nextcloud app is used for auto-upload, that does support background upload at least on Android. reply hwbunny 6 hours agoprevIn our testing environment, it can load a timeline view with 100k photos in under 500ms, including query and rendering time! --- Wow, and why is that necessary? reply bogdan 4 hours agoparentBecause we have limited time in this world and waiting for photos to load isn't the best way to spend that time reply aendruk 13 hours agoprevWhat are your thoughts on PhotoPrism? reply candiddevmike 12 hours agoparentIt's nice, but $24/year/forever to have multiple users is a bit much... reply rockooooo 12 hours agorootparent$24 a year is too much? reply candiddevmike 12 hours agorootparentWhen every other aspect of the app is basically free, yes. I would pay once for the functionality, not as a subscription. reply gene91 10 hours agorootparentThey offer a lifetime price of $128. https://www.photoprism.app/membership/faq > Are there alternatives to a recurring subscription? > > Yes, our Plus members automatically receive a free Lifetime Essentials membership after 24 months reply radialapps 12 hours agoparentprevMy thoughts? Too slow. No timeline view. Looks terrible. reply raybb 10 hours agoprevNextcloud itself is a PWA. Did you have to do anything special to make what seems like essentially your own PWA inside another? I ask because I'd love to turn the nextcloud/tasks app into a PWA but was concerned about how it could work. reply radialapps 10 hours agoparentNot much, it works pretty much out of the box. reply adam_gyroscope 12 hours agoprevIs there auto syncing from Apple Photos? That’s the missing feature in Google Photos for me. reply dugite-code 6 hours agoparentThere is an Auto upload function in the Nextcloud APP, I believe it works on IOS reply auscad 8 hours agoprevI would really like to see an integrated camera app that allows me to hide my photos from the OS so that big brother doesn't automatically ingest them reply dugite-code 6 hours agoparentThe Nextcloud App (Not the Memories Nextcloud app) allows taking a photo that goes directly to the server. It's also got a Scan document feature that I use to scan to a Paperless folder for processing. reply lxgr 7 hours agoparentprevIf you don’t trust your OS, how can you trust it to run an app? Apps can’t hide data from the OS that’s running them. reply auscad 5 hours agorootparentI’m concerned about what the OS is doing in accordance with its privacy policy or terms of service. Without having read them (I am only human) I assume the photos in the default location are sent off for analysis to “improve your experience by showing you relevant advertising”. I would be surprised if this above-board surveillance went as far as crawling the filesystem reply pathsjs 13 hours agoprevHow complex is it to configure memories? I own a hosted instance of NextCloud from Hetzner, but I would rather not misconfigure it. Also, is there a mobile app? I think not having one is limiting, since most of the time I want to look at the pictures on the phone reply radialapps 12 hours agoparentEverything can be mostly configured through the admin panel, maybe 15-20 minutes? There's a mobile app for Android: https://play.google.com/store/apps/details?id=gallery.memori... On iOS, you can use the PWA (\"add to homescreen\") and it behaves almost exactly as a native app reply raybb 10 hours agorootparentYou might wanna consider adding a page to your docs about setup on hetzner since it's so popular for NC hosting. Seems that it is possible to get it mostly working based on this issue: https://github.com/pulsejet/memories/issues/110 reply raybb 8 hours agorootparentThey also don't support the recognize app. https://www.reddit.com/r/NextCloud/comments/19acyje/managed_... reply rc_kas 8 hours agoprevOh god. Itranscode... I guess other important point is to store originals as well (or maybe even rendering originals directly). and also RAW format for audio video. then comes question on handling 250GB+ videos and libraries for TBs sizes Apple Photos rocks in all of the above. and it also works excellently offline. to beat it you have to really solve those problems.. reply radialapps 7 hours agorootparentOnly the originals are stored. Transcoding is needed to play any video in browsers, e.g. HEVC isn't supported by most browsers. For this, Memories transcodes your video on the fly and streams it to the browser with HLS. RAW support for photos is easy and already supported, no idea about videos. As far as \"beating\" Apple, I'm ready to bet that'll never happen (not just with this project but any really). A small open source project can't really compete with a $2T company reply nikolayasdf123 7 hours agorootparentprevgot it. guess my point is that excellent support for latest formats are super important for this to be viable for mass user (AFAIK latest browsers still do not support HDR photos.. so guess would be hard to implement in open source those). reply XiS 11 hours agoprevTried this a year ago, it was a real mess, barely worked and broke often. Hopefully it changed a lot in the meantime because I would really like this to be integrated into NextCloud. I the meantime, I'm really happy using Immich reply radialapps 10 hours agoparentUmm the project barely existed a year ago, it was in very early stages. reply Ranmalie 12 minutes agoprev [–] As a matter of fact , I am very impressed with SARAH JEFFREY FX. I just got started with her, within a month I have successfully withdrawn my profit, and believe me I'm still giving her more investment deals. my discussion with her shed enough light on How experienced she is. If you want to invest in Bitcoin and earn decent profits from your investment then choose SARAH JEFFREY FX, she is one of the top notch Bitcoin Expert Trader. Dm her via SARAH JEFFREY FX ON FACEBOOK/INSTAGRAM reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Memories is a free and open-source option similar to Google Photos, self-hosted via Nextcloud, focusing on high performance and various features like timeline view, AI-based tagging, and metadata editing.",
      "It boasts quick loading speeds, displaying a timeline view with 100k photos in less than 500ms, appealing to users seeking efficient photo management.",
      "The developers actively seek community feedback, making it an attractive choice for users interested in contributing to the platform's development."
    ],
    "commentSummary": [
      "Users are comparing alternative photo storage solutions such as Memories, Immich, and Photo Prism to Google Photos, emphasizing features, stability, and privacy, including metadata, search, and facial recognition.",
      "Nextcloud is highly recommended for its versatility, compatibility, ease of use, and AI features in photo storage, sparking discussions among users.",
      "Discussions also cover deployment challenges, pricing, and user feedback, underscoring the complexities and advantages of open-source projects in photography management software."
    ],
    "points": 609,
    "commentCount": 188,
    "retryCount": 0,
    "time": 1711049110
  },
  {
    "id": 39777229,
    "title": "The remarkable intelligence of E. coli: Unraveling chemotaxis",
    "originLink": "https://jsomers.net/e-coli-chemotaxis/",
    "originBody": "I want to tell the story of a beautiful phenomenon in biology. In some sense it’s the prototype of much of the activity of life. The phenomenon is the way in which an individual cell of E. coli forages for nutrients. This process, known as “chemotaxis”—the “chemo-” for chemical and the “taxis” from the Greek τάξις, for tactics—is intelligence in one of its most elemental forms. An individual E. coli has no brain, obviously, and is even many orders of magnitude simpler than a human cell, and yet already it possesses something like a sense of smell, drive, even a memory. Chemotaxis recasts E. coli not as some aimless gut-pest but rather as an exquisitely sophisticated physical computer. I’m also telling this story because I never liked the way biology was taught in high school. It was too much about the names of things. A subject so vast is spoiled by a textbook, which can only point at the endless parade of stuff-there-is-to-know. It’s better approached with questions—like “what’s happening when you smell?” or ”what is a fever, actually?”—that contemplate narrow, deep slices. Chemotaxis is a great slice: it’s a triumph of systems biology—we understand it holistically but also in fine detail at almost every level. It acquaints you with many of the most important motifs in biology, including the way in which protein structure determines function; how membranes control the information flow into cells; and how chemical modifications store and communicate state. It involves one of the most sophisticated and beautiful pieces of molecular nanotechnology, the flagellar motor. And it helps give an intuition for how a bag of unthinking chemicals could possibly give rise to a being. The 30,000-foot view Even with simple rules, the E. coli finds food more often than not The basic idea is this: E. coli “smells” chemicals it’s attracted to with a set of nose-like receptors and decides how to swim. Depending on what it senses, it can either use its flagellar tails to swim forward—this is known as a “run”—or it can spin in a random direction (a “tumble”). By running when the getting is good and tumbling when it isn’t, the E. coli takes a meandering path toward the attractant. A little more detail now: there are half a dozen or so rotors on the E. coli’s body, each controlling a long whip-like tail that flows behind it. When all the rotors are spinning in the same direction, the tails join together into a coil that torques the cell forward into a run. When even one rotor is spinning against the others, the coil unbundles and E. coli spins into a tumble. In a uniform chemical environment, the E. coli swims in a random walk by balancing runs with periodic tumbles. By default, a run lasts about a second, or ten times longer than a tumble. The rate of runs versus tumbles, and their relative duration, is carefully tuned to balance “exploitation” and “exploration”: if runs happened too often or lasted too long, E. coli would range too widely and zip past its food; too seldom or too short, and it’d likely never find food in the first place. But how is this balance achieved? The crux of it is a signaling molecule called CheY (pronounced “KEY-why”). CheY is constantly bouncing around in the cytoplasm of the E. coli, interacting with both the receptor complex (the “nose”) and the rotors, carrying information between them. In the steady state, when CheY encounters the receptor complex, it gets chemically modified, or “phosphorylated,” at a certain rate to become CheY-p. Unlike the unmodified version, CheY-p has a strong affinity for the rotors, and when enough copies bind to one, it reverses its spin, causing a tumble. The trick is that when the nose detects an increase in the concentration of attractant, that steady turning of CheYs into CheY-ps is interrupted. As a result, fewer CheY-ps bind to the rotors; fewer reversals take place; and so the E. coli runs more and tumbles less. In other words, the all-important relative rate of runs versus tumbles is determined entirely by how often the CheY→CheY-p process churns—and this, in turn, is determined by how much attractant is detected by the nose. You can see this process in action in the interactive illustration. Try altering the ratio of CheY-p (white) to CheY (blue) by adding some attractant (pink). You‘ll end up inducing a long run. Less attractant More attractant Why do you need all this complexity? You could imagine a system in which the motors themselves responded directly to attractant. We’ll see later on that the stream of CheY-ps acts as a kind of adaptable, tunable chemical amplifier. “Bacterial cells can amplify signals more than 50-fold; that is to say, a 2% change in receptor occupancy can bring about a 100% change in the output of the system at the flagellar motors. This feature allows cells to sense minute changes in concentration—less than three molecules per cell volume!” The story gets more complicated: adaptation If the system were as described above, then E. coli wouldn’t have much dynamic range. Imagine: if the cell has a huge reaction to just three molecules of attractant, wouldn’t a thousand times as many just completely overwhelm it? In reality, the E. coli is able to respond sensitively across five orders of magnitude of attractant concentration. The cell learns to treat whatever concentration it stumbles into as the new normal, so that the slightest increase triggers the same hypersensitive response as always. The mechanism powering this adaptation is extremely clever. You can think of each receptor as being equipped with “struts” that have pockets in them. When the receptor is bound to attractant, its struts change shape so that these pockets open up, and become the targets for little molecules known as methyl groups. Methyl groups are ubiquitous in biochemistry: for instance, they help determine which parts of your DNA get expressed. Methyl groups bind to the structural proteins your DNA strands coil around, called histones; the “methylated” histone can kink the DNA strand into or out of view of your transcription machinery, turning it on or off. In this case, methylation serves to fill up the strut’s pockets, causing it to become more rigid. (I’m simplifying the actual physical details somewhat, as we’ll see later.) With more rigid struts the receptor’s signaling power is dampened: it takes more attractant to elicit the same response. Because there are many methylation sites per strut and many struts per receptor, there’s a wide range of possible dampening values—as if those pockets were really the holes of an elaborate wind instrument. [Bray] This wide dynamic range is what allows the bacteria not just to find a favorable environment but to keenly and speedily nose its way up a chemical gradient. No wonder a similar mechanism is used by cells in your immune system to track and hunt down invaders. Methylation of the receptors gives E. coli a “simple chemical memory.” This is a powerful and somewhat profound idea: individual bacteria can model their environment and remember important features of it by encoding that information in internal chemical modifications. E. coli “knows” whether attractant has become more or less concentrated in its surroundings going back several seconds; that helps it determine whether it’s swimming in a good or bad direction. Which is not that different in principle from what brains do. In fact one reason that it requires an artificial neural network of about a thousand elements just to model the computational capabilities of a single real neuron is that the real neuron stores so much “state” in its internal chemistry. (Here‘s an aside: should we be surprised at how resilient people can be, given the mechanisms available to a single cell for accepting previously extreme conditions as “a new normal”? No doubt our macro resilience is in some cases actually underwritten by similar cellular mechanisms.) The full picture: a complex signaling network The video above is a very legible overview of E. coli chemotaxis, from a popular textbook. It layers in even more detail, including not just the proteins that phosphorylate CheY but those that dephosphorylate it; and not just the proteins that methylate the receptors but those that demethylate it. What you come to see is that these doers and undoers define a sort of equilibrated circuit whose activity can be conveniently dialed up or down. Dennis Bray describes these sorts of circuits nicely in his book, Wetware: A Computer in Every Living Cell: In a typical signaling pathway, proteins are continually being modified and demodified. Kinases and phosphatases work ceaselessly like ants in a nest, adding phosphate groups to proteins and removing them again. It seems a pointless exercise, especially when you consider that each cycle of addition and removal costs the cell one molecule of ATP—one unit of precious energy. Indeed, cyclic reactions of this kind were originally labeled “futile.” But the adjective is misleading. The addition of phosphate groups to proteins is the single most common reaction in cells and underpins a large proportion of the computations they perform. Far from being futile, this cyclic reaction provides the cell with an essential resource: a flexible and rapidly tunable device. If the cell really needs to change the concentration of the modified protein very quickly, it can. All it has to do is to switch on or shut off the phosphate-adding reaction and the concentration will fall precipitously—at the speed of the spinning cycle. There is no buildup of products or depletion of substrates to slow down the process, as there would be in a linear chain of enzyme reactions. This is a clever way to regulate the level of some protein or metabolite. Rather than producing the thing you want via a lengthy chain reaction, you just have this running cycle that activates and then de-activates it, for example via phosphorylation and de-phosphorylation. When you want more of the active version, you just tamp down the de-activating reaction in the cycle, as if sliding down the volume on a stereo. Regulation in this manner via phosphorylation and dephosphorylation (by “kinases” and “phosphatases” respectively) is an extremely general feature of life. “About 30–50% of human proteins contain covalently attached phosphate. [. . .] A typical mammalian cell makes use of hundreds of distinct types of protein kinases at any moment.” [Alberts] In the interactive figure above, phosphorylation is represented by the blue dots becoming white, and de-phosphorylation happens when they turn blue again. This cycle is constantly running. The speed of the cycle determines how quickly the cell can react to levels of attractant. Notice that when you add some, the blue→white reaction stops happening as much. But the blue←white reaction keeps going at the same rate. So blue CheY proliferates, and the cell runs more. (If the cycle spun more slowly, the blues wouldn‘t take over so quickly.) Down the rabbit-hole… One thing I don’t love in presentations of chemotaxis—and of biological concepts generally—is that they often prominently feature flowcharts and network diagrams. In the case of chemotaxis, as you can gather from the video above, there are many players with nearly indistinguishable names: CheA phosphorylates CheY to become CheY-p, and CheZ dephosphorylates it back to CheY; CheW couples CheA to the receptors, and CheR methylates those receptors’ struts; CheB, meanwhile, “clips off” the methyl groups added to the struts by CheR. A network diagram is no doubt useful for organizing this sea of names but in a sense it foregrounds the most abstract view of the process. I’d rather try to get a sense of the parts as a living whole or in their individual physical detail. When you do that, it’s amazing what you find. What does it mean for a receptor to detect attractant? Almost every action in a cell depends on proteins changing shape and binding to each other. It’s no different in the E. coli receptor complex. The way it works is that there are stimulus-specific proteins embedded in the E. coli’s cell membrane, protruding into what’s known as the periplasm. These proteins are “stimulus-specific” in the literal sense that they are shaped so as to bind favorably with individual molecules of attractant. E. coli has five or six of these, for instance one that detects a crucial amino acid called aspartate. This sensor protein has little clefts in it that are shaped just so for molecules of aspartate to fit snugly into them. [Falke] In schematic form the aspartate receptor looks like this: Source: Falke, “The Two-Component Signaling Pathway of Bacterial Chemotaxis: A Molecular View of Signal Transduction by Receptors, Kinases, and Adaptation Enzymes” You can see that the sensory part—up top, where the aspartate binds—is connected to the signaling proteins CheW and CheA by a columnar structure that straddles the cell’s membrane. What does this protein complex “actually” look like? An individual protein is small enough—like a few nanometers wide—that it can’t really be seen through a regular light microscope. This receptor from top to bottom measures about 350 angstroms, or 35 nanometers. But modern biology is all about seeing the unseeable. Nowadays, we try to find out what nanostructures look like by X-ray diffraction or, more and more often, by cryo-freezing them in an electron microscope. Once we determine a protein’s structure it’s usually rendered using ribbon diagrams, a style invented by the biochemist Jane Richardson in the late 1970s. Here’s a ribbon diagram for the E. coli serine receptor (really it’s a “trimer of dimers,” or a complex of six receptors): Source: Keith Cassidy This whole thing is the receptor. (Those parts just inside the membrane, with little yellow methyl groups lingering stuck to them, are the struts.) How exactly it works is quite complex, and the subject of current research. But in simplified terms it acts like one big piston: when the asparate binds to the part in the periplasm, the columnar structure it’s attached to changes shape—a real biologist would call these subtle allosteric effects; to me it looks like dipping and tilting—in such a way to lock the thing that’s supposed to be phosphorylating CheY, the CheA kinase, into an inactive state. Adapted from: CheA conformation change, posted by Keith Cassidy When I think of a cell I imagine a Rube Goldberg–type contraption where an arm swings here, which drops a ball into a slide there, which rolls down and opens a trap door, which… eventually turns on or off some important cellular function. Indeed, E. coli’s “sense of smell” rests ultimately in a series of physical lock-and-key mechanisms, starting with literal molecules of e.g. aspartate nuzzling into a protein and transmitting that physical shape-change across the membrane. This piston-shaped receptor complex is just one of a huge array arranged near the front of E. coli’s body. In cross section they appear almost to have been laid down through a lithography process, in a neat hexagonal pattern: Source: Theoretical and Computational Biophysics Group, UIUC Source: Direct visualization of Escherichia coli chemotaxis receptor arrays using cryo-electron microscopy Calling E. coli’s receptor complex its “nose” is no mere metaphor. Our own noses operate on a similar principle: when you smell a flower, it means that actual flower-molecules—possibly only a tiny number of them—have reached the inside of your nose and bound to some protein with a specific affinity for that very molecule. This signal is then transmitted via nerves to your brain. The human nose has several hundred receptor proteins for smell; a dog has more than a thousand. Every one of our senses works like this. Touch is underwritten by proteins that get “squished” by tactile forces into cell membranes, triggering a set of downstream responses. Sight is my favorite example. There’s a protein called opsin that lives in the cells of our retina. What’s so cool about it is that the thing that changes its shape is a literal photon. That is, opsin converts the electromagnetic force of an incoming photon into a biomechanical / biochemical signal. This is why I tend to think of molecular biology as the science of shapes bumping into each other. I think of E. coli’s receptor complex as a protoversion of our own sensory apparatus. Its nose has only five or six attractant-specific sensory proteins, but their signals are integrated, as if different sets of receptor-protein activations were playing different “chords” on the E. coli’s sensorium. “In short, the chemosensory array functions as an ultrasensitive, ultrastable biological integrated circuit or sensory chip.” [Falke] How the signal is carried So a bit of attractant binds one of the receptors, and lo, the equilibrium inside the cell begins to shift. Because the CheA kinase is now inactive, CheYs are no longer getting phosphorylated as quickly; the process that de-phosphorylates existing CheY-ps starts winning out. Recall that this is a response that is dynamic, a flow that is tuned. The net number of CheY-ps in the cell is carefully faded down. And then what? The CheY-ps had been binding to the flagellar rotors, flipping them, causing tumbles. That now no longer happens as much, because the unphosphorylated CheY doesn’t have the same affinity for the rotor as CheY-p. As a result, the cell tumbles less, runs more, and biases its random walk toward the attractant. There’s something really important worth dwelling on here. When we say that CheY-p has an “affinity” for the rotor protein, it’s not like it gets directed there; nor does it have some long-acting magnetic attraction for it. What this really means is that it has a strong inclination to bind to the rotor protein when it gets really really close to it. (And CheY, without the -p, doesn't have such an inclination.) Given how small a single CheY-p is in the scheme of the whole cell’s cytoplasm, it might seem improbable that it’ll somehow sidle up right next to one of these rotor proteins somewhere on the other end of the E. coli’s body. But that gets at the heart of the crazy kinetic chaos inside our cells. Source: David Goodsell, The Machinery of Life Cells are dense with stuff, but everything in it is also extremely fast-moving: To get an idea of how fast this motion is, imagine a typical bacterial cell, and place an enzyme at one end and a sugar molecule at the other. They will bump around and wander through the whole cell, encountering many molecules along the way. On average, though, it will only take about a second for those two molecules to bump into each other at least once. This is truly remarkable: this means that any molecule in a typical bacterial cell, during its chaotic journey through the cell, will encounter almost every other molecule in a matter of seconds. [Goodsell] Just to put this in perspective: imagine you took an E. coli cell and scaled it up so that it was the length of a football field. And imagine you kept all the physics the same. A water molecule would be about an inch wide; a protein would be about the size of a basketball. [BioNumbers] The proteins would be juddering violently due to the thermal motion of the water particles bombarding them—so violently in fact that if left unchecked they’d be moving at 500 meters per second. But they aren’t left unchecked: if you were in such an environment it would be so crowded as to be nearly impossible to see. What you really get, then, is an incredible ceaseless shaking and bouncing-into-each-other of all the component parts. This is why shape changes that lead to different bonding affinities are so important in biology. It’s as if inside a cell everyone is constantly going up to everyone else, seeing if they fit together. Proteins sample the space of interactions with other proteins so quickly that for a long time, most biologists didn’t really contemplate where in the cytoplasm two reactants lived; they knew that you never had to wait too long for them to meet each other. In fact it was a relatively recent discovery that inside the cytoplasm certain proteins that share functional relationships do seem to keep especially close together, inside little oil drops known as “phase-separated liquids.” Weak interactive forces between the floppy tails of different proteins cause them to spontaneously “phase separate” into these more viscous pools, and this biases certain proteins to interact more frequently. The rate-limiting step in E. coli’s reaction to attractant is the time it takes for CheY-p to diffuse from the nose to the motor. It takes about a tenth of a second. The journey has actually been tracked on camera, using a fluorescent version of the protein: Source: Single-molecule imaging of electroporated dye-labelled CheY in live Escherichia coli What happens when the signal reaches the motor? Let’s talk about these motors. These things are so intricate and beautiful and seem so reminiscent of machines we’d engineer ourselves that they’re sometimes cited as evidence for intelligent design. The flagellar motor operates with close to 100% energy efficiency. It spins at about 1,500 rotations per second. And the craziest part is that like all molecular nanomachines it is entirely self-assembled. There’s an amazing 30-minute documentary available on YouTube that details the mechanics of the self-assembly process—and, refreshingly, profiles some of the scientists who figured it out, describing the methods they used to make their discoveries. From: Self-Assembling NanoMachine: a film about flagellar biosynthesis My favorite part of the self-assembly process is that after building a base for the rotor, a sort of tunnel is built and the proteins that comprise the whip-like “hook” of the flagellum are extruded through it—as if the flagellum were built by vomiting forth parts of itself. Anyway, at the base of each rotor there are a series of proteins called FliG, FliM, and FliN—pronounced like “Fly G,” “Fly M,” “Fly N”—to which CheY-p, our Frodo-esque bearer of the message from the nose, attaches once it finally arrives. CheY-p has a strong affinity for FliG and will readily glom onto it. We’ll see how that actually affects the flagellum in a second. But for now it’s worth noting that there’s a thresholding mechanism here: just one CheY-p attaching to FliG won’t be enough to flip the motor from counter-clockwise to clockwise (thereby causing a tumble)—it actually takes a handful of CheY-ps conspiring to make that happen. In fact the motor has something like seven states, from rotating quickly counterclockwise at three discrete levels of decreasing speed—as if stepping through three gears on a bike—to stalling entirely, to starting back up again in the clockwise direction, also with three speeds. Even as the motor is in the process of changing direction, any CheY-ps that do attach to FliG are under constant threat of being removed by yet another player, CheZ. That is, the proteins that would reverse the motors are subject to removal by other proteins that un-reverse it. Again we have a responsive regulatory circuit reminiscent of the one that phosphorylated and de-phosphorylated CheY in the first place upstream at the receptor. The idea is that every effect is reversible, and in fact is reversed at a regular rate. This means that in the absence of further signal the cell will quickly return to baseline. How does the motor actually change directions? As a matter of pure mechanics this might be the most ingenious part of the story. It took quite a long time to figure out and even still it seems that we’re not entirely confident with our explanation. But one mechanism that’s been proposed is that CheY-p binds to a protein called FliM (“Fly EM”) embedded in that ring that defines the base of the rotor. This tilts it and causes a 90-degree rotation in an attached protein called FliGc. That protein sits at the interface between the rotating part of the motor and the so-called “stator,” which drives it from the part that’s anchored solidly in the cell membrane. Source: A molecular mechanism of direction switching in the flagellar motor of Escherichia coli When FliGc changes orientation, the stepper-motor-like cycle that normally drives the motor counterclockwise starts driving it clockwise instead. In the illustration below, Figure A shows the stator, i.e., the driving mechanism of the motor. It works by stepping back and forth between the “open” and “closed” states, schematized by the and symbols respectively. In Figure B you can see how, in the normal CCW direction, the repeated cycling between these two states drives the “teeth” of the motor—the crucial FliGc proteins, here tilted left-to-right. Source: Supplementary figure S9, A molecular mechanism of direction switching in the flagellar motor of Escherichia coli When the CheY-p arrives at the rotor it has the effect of flipping the FliGc proteins so that now they tilt right-to-left. In that orientation the step-drive action works the opposite way, and the motor rotates clockwise: You can see this more clearly below in the interactive version of those figures. Click “Step” to drive the motor in one direction, and “Reverse” to flip the orientation of the FliGc proteins; Step again and you’ll see it run in the opposite direction. Reverse Step It would be nice if the original paper presenting this theory included an illustration like this. But even this crude version took me many hours to make. As Bret Victor argues in Stop Drawing Dead Fish, making moving pictures shouldn’t be so hard. If it were easier, such animations would spread everywhere in scientific communication, because so often what a paper describes is some kind of dynamic process. Dynamic illustrations would help readers grasp proposed mechanisms more quickly. As it is, someone who understands a complex mechanism usually has to explain it in patient detail to someone else who’s good at animating; this costs time and money; and most people simply opt not to go through with it. Perhaps someday the process will be democratized by better tools, or by a multimodal AI system. How the motor changing directions causes the E. coli to tumble The final part of the story—for me, anyway; there’s a lot more to explore!—is why exactly the clockwise rotation of just one of the flagellar motors would send the whole cell a-tumbling. It helps to understand how the thing works in “run” mode, when all the flagella are oriented the same way. Traced from: How Escherichia coli MoveNational Science Foundation Even though this bundle of flagella sort of looks like a propeller, when you actually think about it, that’s not really what it is. It’s more like a pig’s curly tail that spins with a whip-y sort of motion. How exactly does that propel the entire cell? A wonderful book called Random Walks in Biology gets into the physics in some detail: Source: Howard C. Berg, Random Walks in Biology. “Fig. 6.3. Analysis of viscous drag on two segments of a flagellar filament moving slowly to the right and turning rapidly counterclockwise. The velocity of each segment, v, is decomposed into velocities normal and parallel to the segment, vn and vp, respectively. The segment shown on the left is moving upward in front of the plane of the paper; the one shown on the right (denoted by primes) is moving downward behind the plane of the paper. The frictional drags normal and parallel to each segment, Fn and Fp, act in directions opposite to vn and vp, respectively. Note that their magnitudes are in the ratio Fn/Fp = 2vn/vp. Fn and Fp are decomposed into components normal and parallel to the helical axis, FΩ and Fv, respectively. FΩ and F'Ω act in opposite directions and form a couple that contributes to the torque. Fv and F'v act in the same direction and contribute to the thrust.” To get a grip on things like this, it helps to have a model of some kind that you can hold in your hand. And actually the question of how separate filaments running in phase near each other would come to bundle was explored nicely in this paper. The authors used physical models of the flagella by wrapping hollow Tygon tubes around a mandrel and filling them with epoxy. They then used a couple stepper motors to drive the counter-clockwise rotation. “The flow field generated by each helix tilts the other helix, causing the helices to roll around each other and form a right-handed wrapping”: From: Macro Scale Model E.Coli Flagella Bundling Individuality in the bacterial population We tend to think of a colony of something like E. coli as an undifferentiated evil goo, each bacterium identical to its neighbors. But people who’ve studied these organisms under the microscope observe a surprising amount of individual personality. A 1976 Nature paper, “Non-genetic individuality: chance in the single cell,” explores variation in the context of chemotaxis using strains of Salmonella and Enterobacter bacteria. The paper came out before the exact mechanism behind chemotactic regulation was well-understood; all the authors knew was that “control of tumbling can be rationalised as caused by changes in the levels of a tumble regulator.” They hypothesized that although bacteria of the same strain would all share the exact same DNA, there might be a relatively small number of copies of that “tumble regulator,” and natural variation in the transcription, translation, and destruction of these regulator proteins could account for differences in behavior. Their experiments were mostly at the behavioral level. They observed how different individuals—including those in a particularly “tumbly” mutant strain (I love that word)—reacted to environments with and without attractant, and found plenty of variance. Their theory was spot-on. We talked above about how E. coli adapt to higher and higher concentrations of attractant via a clever methylation mechanism. Well, it turns out that the methylation of the receptor struts is governed by only about 100 CheR proteins in the cell. The number of those proteins—along with CheB, which un-methylates the struts—determines the speed of the “futile cycle” that reacts to changes in attractant concentration. That is, it affects how quickly the bacterium adapts when the concentration goes up and refracts when it goes down. [Gore 1:06:30] Because 100 copies of CheR is so extraordinarily tiny in the context of the full cell buzzing with something like ten million proteins, variation by just a handful can have a relatively large effect on the cell’s behavior. [Gore 1:13:20] That helps account for why different E. coli with the exact same genetic sequence will tumble and adapt at different frequencies. Recent experiments have used fluorescent microscopy to quantify the individuality of different E. coli cells, individuality that arises not from differences in gene expression but from the dynamics of signaling networks. How did we figure all this stuff out? We don’t yet have the technology to just observe all of the activity inside a living cell. That Goodsell painting above that shows the crowded cytoplasm packed with proteins is an artistic composite—backed by rigorous research to be sure—because there’s no way to capture all the different players in situ at once. And obviously it’s a “still life,” not a video. So how could we possibly know all this detail about what exactly a given protein looks like, and how and when it interacts with others to kick off some particular part of the chemotaxis process? There seem to be three or four major kinds of experiment. Probably the most common is genetic: you can selectively disrupt one gene at a time and, by observing how the mutant E. coli behaves, begin to get a grip on each gene’s function. All of the proteins “CheY,” “CheZ,” “CheW,” and so on are named simply because they are the products of genes that, when excised, “cause a general defect in chemotaxis.” [Blair] As you can imagine, identifying all of these is painstaking work, and involves a considerable amount of clever inference. For instance you might observe that without gene X the bacteria never seems to tumble; is that because that gene is involved in recognizing attractant or in forcing the rotor to run clockwise? Once you have a hypothesis, a second kind of experiment involves purifying some subset of these proteins-of-interest in vitro to see how they work together to form a particular signaling pathway. For example you could put CheA and CheY along with some phosphate groups and other necessary reactants and observe whether and how much phosphorylation takes place. That’s what the authors did in this paper in Cell, in 1990. They used a radioactive version of phosphate as a tracer. “Incorporation of [32P]phosphate into CheA or CheY was determined by excising the radioactive band out of the dried gel and quantitating in scintillation fluid or by analysis of the intact gel using a Phosphorimager (Molecular Dynamics, Sunnyvale, CA) and compare with known radioactive standards.” Another common method for observing in vitro dynamics is to genetically modify proteins to fluoresce; or to “find” a protein in solution using an antibody that recognizes some part of it—you attach that antibody to another protein, and that one you fluoresce, so you can find the hidden one. To understand the literal lock-and-key mechanics at a particular binding site—for instance how exactly a molecule of aspartate causes a receptor to deform, kicking off a signaling cascade—involves “structural” biology work, i.e., taking pictures of individual proteins or, increasingly, ensembles of them in situ. For this you can use X-ray crystallography, nuclear magnetic resonance imaging, cryo-electron microscopy, super-resolution light microscopy, or some combination. A group at University of Illinois at Urbana-Champagne uses atomic-scale molecular dynamics simulations, in software, to understand structural details—like the exact way that CheA changes shape to kick off a downstream signaling process—that wouldn’t be apparent from high-resolution imaging alone. (Keith Cassidy, whose figures appeared above, now has a lab at the University of Missouri-Columbia that’s studying the molecular dynamics of the receptor signaling complex.) Sometimes you can’t get a direct picture. It may require deduction to understand, say, how exactly a protein fits in. One experiment found that CheA didn’t bind to a receptor except in the presence of CheW; that plus the fact that adding too much CheW into the mixture actually led to a decrease in the ability of CheA–CheW complexes to bind receptor suggested that CheW competed with that complex for the binding site on the receptor and that therefore it must sit between the receptor and CheW in the receptor–CheW–CheA trimer [via Blair]. Biology is lousy with heroic inferences like that. It’s a world that’s hard to see; sometimes you just have to imagine what’s going on down there, and back up those imaginings with the right experiments. The very idea that bacteria run and tumble came from experiments published in 1972 by Howard Berg and Douglas Brown, who used a special three-dimensional tracking microscope of their own design to watch the little suckers in action. (A fun fact is that they called the non-runs “twiddles” instead of “tumbles.”) Some of the physics of flagellar propulsion—like how much force the little tails generate—was discovered later by tethering the flagella to a microscope slide: because it’s anchored, the “tail wags the dog“ and you can measure how fast the E. coli’s body spins. We know that bacterial flagellar motors are powered by the proton motive force from a 1977 paper that measured how cells ran or “twiddled” in the presence or absence of an electrical potential. But the research has become even more refined than that. Just by observing the strength of the rotation under various conditions—different viscosities, temperatures, and so on—we know that “rotation is tightly coupled to proton flow, with a fixed number of protons (~500) used to drive each revolution.” [Blair] Think of how detailed an understanding we’ve gotten! One reason I’m particularly attracted to studies of E. coli chemotaxis is that it’s an early star of what’s been called “in silico” biology. It’s been the subject of many computer models. Dennis Bray, the author of that book that put me onto this stuff in the first place, made one of the more popular models. Here’s a nice screenshot of the model in action: Maybe the chief role of a computer model is that to get it working in the first place you have to explicitly articulate every one of your assumptions. In much the same way that writing tends to clarify your thinking (or at least reveal how unclear it really is), a computer model forces you to synthesize what you know. If anything it’s even more exacting than a blank page. Once you have a model, you can use it to explore variations on those assumptions. “The program gives the correct phenotype of over 60 mutants in which chemotaxis-pathway components are deleted or overexpressed,” Bray writes. At best, a good enough model lets you discover things you didn’t already know, or suggests your next experiment. “In order to match the impulse response to a brief stimulus [. . .] we also had to increase the activities of the adaptational enzymes CheR and CheB at least an order of magnitude greater than published values.” So what? Why should you care about E. coli chemotaxis? A typical answer to that sort of question—and I’m sure the answer given in many of the grant applications supporting the work cited here—is that there are medical and practical uses. For instance: if you understand the signaling pathways of bacterial chemotaxis you can disrupt them; that work might lead to a new kind of antibiotic, which, in an era of increasing resistance, is direly needed. Or you might hijack chemotaxis pathways to create “intelligent sniffers” (Keith Cassidy’s phrase) that could home in on cancer cells or environmental waste. More generally you might say—and in fact I led with this up top—that understanding this specific phenomenon equips you to understand all kinds of others. “Bacterial two-component pathways [def’n] control a dazzling array of functions including cell division, virulence, antibiotic resistance, metabolite fixation and utilization, response to environmental stress, sporulation, and taxis.” But I don’t know, to me the real reason is that it’s neat. It’s just fun to find out about. “To learn, and at due times to repeat what one has learnt, is that not after all a pleasure?” Please send feedback or corrections to James.",
    "commentLink": "https://news.ycombinator.com/item?id=39777229",
    "commentBody": "The baffling intelligence of a single cell: The story of E. coli chemotaxis (jsomers.net)440 points by jsomers 22 hours agohidepastfavorite183 comments talkingtab 20 hours agoThe way I think about this comes from reading John Holland's \"Hidden Order\". If you read that book not as a book but as a way to build a Complex Adaptive System, then it comes down to a few essentials. An environment, a bunch of entities, a read/write messaging bus so the entities can interact. The entities need a set of rules and sensors. Put it together and what have you got? Thinking. Or intelligence. Try building one. Is the RIP routing protocol a complex adaptive system? Part of our problem is the way we think. I am a person. I am not a complex adaptive system. And yet I am. I am made of entities. There is a messaging bus, the entities sense, act and interact. But I don't think of myself as a CAS or talk about We. Wecellfs? Perhaps this a Sapir-Whorf thing. Our language limits what we can think. What is the difference between a pile of ants and an ant colony? A colony is collection of entities, but what do we call the entity that is the colony? Are the ants smart or is the colony smart. reply mrkstu 15 hours agoparentAs can be seen by the specializations between human brain hemispheres. There is a bus between them, but when that communication is cut, and you can see that a lot of what we perceive as a single thought process, is a bunch of independent computing entities with an OS layer on top creating the unity that doesn't really exist. reply coldtea 39 minutes agorootparent>a lot of what we perceive as a single thought process, is a bunch of independent computing entities with an OS layer on top creating the unity that doesn't really exist. How else could it be? At some level, it would inevitably be a top-level aggregation \"creating a unity that doesn't really exist\". The alternative would be for the whole brain to be a single elementary particle! reply treprinum 11 hours agorootparentprevWhen Covid hit me, it felt like having a stroke and the effect was that I suddenly perceived that I don't have enough energy to sustain vision, instead I could perceive the delineation between object localization, object recognition, character-to-text conversion etc. It was like the brain was an engine that suddenly lacked fuel (I could force individual parts to \"work\" at the cost of immense pain) and dissolved into individual services competing for resources. The experience was both frightening and awesome. Not sure how I survived that (it took over 3 years to get back to normal). Diffuse MRI didn't find anything anyway. reply anal_reactor 11 hours agorootparent> The experience was both frightening and awesome. Basically LSD. It feels so weird to just... I don't know, have a different personality for a while. And when your normal self clicks back it's so relieving. This made me appreciate what a miracle it is that my brain is fully working most of the time, and realize what a horrible disease dementia is. reply cmrx64 11 hours agorootparentprevhad a relatable but almost opposite experience (no obvious infection, but it was winter 20/21), where I noticed that objects in my visual field seemed to be differentiating themselves away from the background and “competing” for my attention when previously I had to go hunt for them. reply treprinum 7 hours agorootparentOctober 2020 here. I guess you got a boost whereas I got an obstruction of whatever was delivering energy. reply actionfromafar 56 minutes agorootparentprevOr well, it does exist. But maybe more in the \"ant hill\" sense than feels comfortable to admit. reply Balgair 14 hours agorootparentprevJust to be clear here, are you talking about the 'left-brain, right-brain' thing? Because I thought that was pretty well debunked. Also, I think you are talking about the corpus callosum for the 'bus' right? reply coldtea 35 minutes agorootparent>Because I thought that was pretty well debunked. Only when it comes to \"left/right side analytical/creative\" split, and even that mainly based in a single 2013 study, which could have all kinds of issues. Not regarding different functions in general. reply gHA5 14 hours agorootparentprevHe's probably talking about split brain patients. Here's a video by CGP Grey about them: https://www.youtube.com/watch?v=wfYbgdo8e-8 reply mrkstu 14 hours agorootparentYep. reply smaddox 14 hours agorootparentprevAFAIK, the part that's been debunked is that there's a complete separation of concerns between the two hemispheres. From studies on split-brain patients, there does appear to be some specialization, but it's much fuzzier than \"right brain does art, left brain does analysis\" or anything like that. reply patcon 3 hours agoparentprev> But I don't think of myself as a CAS or talk about We. Wecellfs? I am a collector of theories of consciousness :) assuming your quote above is making reference to the \"scale\" at which \"self\" is understood, you might be interested in this theory: Information Closure Theory of Consciousness (2020) https://www.researchgate.net/publication/342956066_Informati... This reddit comment sums it up better than the paper seems to be able to: https://www.reddit.com/r/MachineLearning/comments/dco3t1/com... > Consciousness (at least, consciousness(es) that we are familiar with) seems to occur at a certain scale. Conscious states doesn't seem to significantly covary with noisy schocastic activities of individual cells and such; rather it seems to covary at with macro-level patterns and activities emerging from a population of neurons and stuffs. We are not aware of how we precisely process information (like segmenting images, detecting faces, recognizing speeches), or perform actions (like precise motor controls and everything). We are aware of things at a much higher scale. However, consciousness doesn't seem to exist at an overly macro-level scale either (like, for example, we won't think that USA is conscious). reply qlk1123 2 hours agorootparentThanks for sharing the interesting summary. However I would like to mention that sometimes we do think so, as in \"the will of the party\", at least in some language's context. Fun fact, when I tried to find similar sentence like \"the will of Democratic/Republican Party\", google returns 5 results for the former but followed by voters/members and thus not what I want, for the latter, there is no results at all. But as I find \"the will of the party\", I find an abstract of some paper from my area. Maybe party is too small for this. It seems like \"the will of the nation\" is widely used. reply tshaddox 19 hours agoparentprev> I am a person. I am not a complex adaptive system. And yet I am. Your adaptive system has a very complex model of the environment. You can model yourself as an agent in the environment, and you identify as parts of that agent. I say “parts,” because there is a ton of thinking and actions that your adaptive system performs which you do not identify as you. reply falcor84 18 hours agorootparentIt reminds me of this paper from MIRI a few years ago discussing models which treat themselves as an explicit part of the environment. I think it's a very productive approach - https://arxiv.org/abs/1902.09469 reply medstrom 16 hours agorootparentWow, wish more papers were so well written and pleasing to read! reply nxobject 14 hours agorootparentThis is wild projection, but it reminds me of the good advice I got when writing undergrad philosophy papers – map out your tree of arguments (especially if they're logically complicated), and structure your writing around that; talk in as conversational prose as you can because it mercilessly exposes jargon; highlight when you introduce new concepts. reply aradox66 12 hours agorootparentprevYes - all of our conscious reality, including both the environment and our sense of self, are experiences of perception formed inside the mind by the body and brain. Our sense of an \"external\" world is very much an \"internal\" reality, and the boundary between self and world is a mental construct. reply wslh 19 hours agoparentprev> Part of our problem is the way we think. I am a person. I am not a complex adaptive system. I agree that, in general, we humans, downgrade the importance of external stimulus and interactions with our environment (including other people). My two cents is that this is downplayed where we live in cities and don't move too much, once you move to very distanct places and cultures (and not assuming yours is the best one) more things tick in the brain. reply pas 17 hours agorootparentit's hard to forget about others in a city though. you have neighbors, traffic, etc. that's why the whole 'cabin in the woods' experience can be sold as a relative luxury nowadays. that said, based on the status quo we definitely don't spend enough resources on making sure we can peacefully and sustainably live next to others. reply hosh 13 hours agoparentprevGoing at it a bit sideways, there's also a sense of self that's constructed in which narratives forms around it ... and yet, there's a way of experiencing the world without that separate sense of self. Complex adaptive systems can be nested. Human families, communities, societies, governments all form greater gestalts in which humans, themselves complex adaptive system are a part of. reply swayvil 19 hours agoparentprevSo as we add layers of language, intelligence goes down. (Of course, to the residents of that layer, only the residents of that layer are intelligent. The depths are inscrutable chaos. And further layers are ... Tools? Toys?) Individuals are smart, committees are dumb. Fundamental particles must be geniuses. reply Jensson 19 hours agorootparent> Individuals are smart, committees are dumb. But a human isn't a bunch of individual cells, it is a cell that cloned itself many times. Those cells all have the same base code and can thus become an intelligent committee. reply swayvil 19 hours agorootparentSo the more identical the committee members are, the smarter the committee? reply Jensson 19 hours agorootparentAt least a committee of 10 identical members wont be dumber than a single member most of the time. A committee of clones is just scaling up compute in order to solve larger problems. Imagine if you could clone yourself with your knowledge and mental state, much more useful than trying to cooperate with another human. reply GirkovArpa 19 hours agorootparentAccording to Condorcet's jury theorem, a committee of 10 identical members may be smarter than a single member. reply procgen 17 hours agorootparentThis seems obvious to me, as there'd be ten times more computational resources. reply genman 14 hours agorootparentNo, it is because the probability of arriving to a correct answer increases when there are more members in the group, but only when the individual probability to arrive to a correct conclusion is higher than 50%. Group of smart people is smarter than an individual. The opposite is true too. If the individual probability is less than 50% then the group of people is dumber than the individual. reply svnt 10 hours agorootparentThe answer must also be within all of their domains of expertise for the 50% to have any meaning. You can’t have a “room full of smart people” as you’ll just arrive at suboptimal outcomes because your consensus relies on the lowest common denominator of understanding, which between experts in differing fields can be pretty low. reply inductive_magic 18 hours agorootparentprevI always felt that the decrease in intelligence is a side effect of the necessary consensus mechanisms. 10 genius clones would still take on various roles/positions in the system, requiring some optimization with respect to alignment under time/energy constraints. reply swayvil 19 hours agorootparentprevBut the committee-thinking is still constrained by the language. Any committee-thoughts must be coarser and slower than the member thoughts. We're trading depth for breadth, or something like that. reply fnord77 16 hours agoparentprevSapir-Whorf is bunk reply seatac76 21 hours agoprevFantastic read! If y’all are into this kind of stuff I highly recommend reading “The Song of the cell” by Siddhartha Mukherjee[1], it is one of the best books I’ve read that made the topic of biology approachable. [1] https://www.amazon.com/Song-Cell-Exploration-Medicine-Human/... reply sublimefire 16 hours agoparentHe is a great storyteller, 2 other very successful and interesting books of his: - The emperor of all maladies - about cancer research, for which he got a Pulitzer - The gene - about the evolution of the field and the discoveries and what is the latest thinking reply ramraj07 16 hours agoparentprevWhat does this book talk about that his previous book the Gene doesn’t? reply lmiller1990 6 hours agorootparentI found Song of the Cell a bit underwhelming. The Gene really was fantastic - I think he ran out of steam a bit with Song of the Cell. The majority of the cell related history is also contained in The Gene. reply ta8645 20 hours agoprev> I never liked the way biology was taught in high school. It was too much about the names of things. A subject so vast is spoiled by a textbook, which can only point at the endless parade of stuff-there-is-to-know. Amen. You could easily teach quite intricate biology in grade school, if you focused on a fascinating example or two. How many more people would be inspired, rather than bored? reply atticora 19 hours agoparentThere's a nice discussion of this in Surely You're Joking, Mr. Feynman! > I discovered a very strange phenomenon: I could ask a question, which the students would answer immediately. But the next time I would ask the question – the same subject, and the same question, as far as I could tell – they couldn’t answer it at all! > Then I say, “The main purpose of my talk is to demonstrate to you that no science is being taught in Brazil!” https://v.cx/2010/04/feynman-brazil-education reply magicalhippo 18 hours agorootparentWe had a student in class which was so brilliant at memorizing stuff. But each test had one or two questions where you had to put together the knowledge, not just regurgitate, and that student consistently failed those question on each and every test. Yet the student got top scores on each and every test, because the accumulated number of points was enough to get them into the top bracket. I was so annoyed with that, asking the teacher how they could get top scores while clearly demonstrating they didn't understand the subject matter. Of course, all in vain. edit: Great read BTW reply hahajk 8 hours agorootparentMeasuring student outcomes is hard! For example, do you think we should encourage students to study for tests, or should we encourage them to just show up? After all, if you understand it intuitively why would you need to study the night before? Also, the act of testing changes the students being measured. As does the existence of a test in the future. reply Balgair 14 hours agoparentprevI cannot disagree more here. Biology is just astoundingly complicated, especially micro-bio. Lets look at the 'Central Dogma' of biology as a point to focus on a bit. It's the idea of 'information' transfer. DNA gets decoded into RNA which then gets decoded into Protiens, right? Easy peasy little discussion. You go into how DNA works a bit, it's structure, it's functions. Then you go a bit more into RNA and the various sub types, how the decoding proteins work, Slicer and Dicer, etc. You then talk about how three letter codons work to make amino acids, how you transport the mRNA out of the nucleus, etc. At each step you take a look at how the thing works and you mention some other launching off points for more research if the kids are interested. This is how a lot of education works, things like cooking, math, history, etc. Except nearly none of what I just said about the 'Central Dogma' is considered true anymore. Sure, some of it is, but the vast majority of how proteins get made is not encompassed in it. Nearly the entirety of modern micro-biology is all about the 'exceptions' to the 'Central Dogma'. So much so that you can't really even say that there is any appreciable difference between RNA and proteins anymore. Every week, and I am not joking here, there is at least one new paper detailing some hybrid mess of RNA and proteins that has critical importance in how we understand how even the most common parts of a cell works. It's to the point that I would not call the 'Central Dogma' and outright lie, but more of a useful fiction. Like saying that a 'for loop' is how the internet works. Yes, there are 'for loops' in the internet, yes they are critical, yes, you need to learn about them. But no, you cannot teach someone about the internet via a fascinating example or two about 'for loops'. Understanding biology is Hard, it is the end result of 4+ billion years of literal life and death. It is not something that can be done in a few examples. Even an understanding at a 12 grade level does in fact take a full school year to get to, and even then, it's just the barest launching point into the wider field. The OP s wrong. Full Stop. You do need to learn the names of these things, you do need to get down and do the work of learning all the facts, you do need to fill your brain with these things that are going to affect you as the world gets more and more complicated, you do need to connect this incredibly vast amount of information together. It is going to affect you or the ones you love. Edutaiment is not the way forward here. Hard work is. reply pdm55 10 hours agorootparentOf course, the study of how living cells function is \"hard\". But that doesn't mean it has to be learnt without joy. We tend to explore things we enjoy. A lot of the writer's essays [1] are about finding some aspect of a topic intriguing and following that rabbit hole. My own research centered on one subset of functions within E. coli. I was lucky that I found a carefully engineered subset of plasmids and adaptions of E.coli, that could be mathematically modelled [2] [3]. I didn't have to know the whole functioning of E. coli. I didn't have to use mathematics beyond algebra. That is, no calculus was needed. The key task was to put together the quantitative research of about half a dozen labs. Okay, I had a \"mountain\" of articles to read. And it took 5 years of effort. But it was only doable, because I was modelling a carefully constrained subset of cellular functions. [1] https://jsomers.net/ [2] https://pubmed.ncbi.nlm.nih.gov/8078069/ [3] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5425810/ reply dekhn 11 hours agorootparentprevModern biology is very much not an exception to the central dogma; it still remains central. Don't mistake the vehemence of the RNA biologists (of which I used to be one) for impact or significance (for example, the central dogma had no opinion of whether the ribosome was a protein machine, or an RNA machine, or a protein-RNA machine where RNA formed the critical core components). The only really important detail that wasn't in the original dogma is reverse transcriptase, and they added a dotted line to support that once it was found in physical form. reply kerowak 13 hours agorootparentprevSo, just to simplify your argument, you're saying that grade school students should not be taught biology in a way that GP finds more engaging, because: > You do need to learn the names of these things, you do need to get down and do the work of learning all the facts, you do need to fill your brain with these things that are going to affect you as the world gets more and more complicated, you do need to connect this incredibly vast amount of information together. It is going to affect you or the ones you love. reply gfjx45234 12 hours agorootparentprev> Biology is just astoundingly complicated, especially micro-bio. Do you mean molecular biology instead, which includes the study of central dogma? (That's a common terminology hiccup, lots of people get this wrong) reply m3kw9 19 hours agoparentprevIt turns out the curriculum was made by a bunch of teachers that has been old school taught. Seniority and entrenchment, nobody in that group risking their heads to suggest any deviation from old beliefs reply lostemptations5 14 hours agorootparentOr maybe it wasn't done maliciously -- rather that's the way they thought it should be taught... reply the-mitr 19 hours agoprevI was introduced to the idea of even single cells can exhibit \"learning\" and \"culture\" via John Bonner excellent book The Evolution of Culture in Animals. Instead of thinking in terms of a discontinuity between animals or putting humans categorically different, Bonner builds this idea of a continuum instead for both culture and learning. Of course there are differences, https://press.princeton.edu/books/paperback/9780691023731/th... This post of course goes deep in the rabbit hole so to speak. reply wslh 21 hours agoprevIf you like this, there is a book about the complexity of a single neuron of the brain \"Information Processing in Single Neurons\" [1]. [1] https://www.amazon.com/Biophysics-Computation-Information-Co... reply londons_explore 20 hours agoprev> We don’t yet have the technology to just observe all of the activity inside a living cell. How close are we to being able to make a map of all atoms within a cell? There are 1E23 atoms in 1 ml of water, and an ecoli is about 500nmx500nmx1um. That means there are only about 2E10 atoms in the whole cell! Would it be possible to somehow freeze a whole cell, then use an electron beam to knock off and identify (via mass) every atom there? reply namaria 1 hour agoparentKey word here is activity. Even if you froze a cell and mapped it down to an atom, you'd need to do it again for a cell you somehow managed to freeze in the state immediately after the first one, and so on. What granularity would be significant? What branching of what process would you like to follow? reply koeng 20 hours agoparentprevWe’re pretty close. There’s TEM microscopy tech which basically tilts a sample to get a bunch of lines, which is then reconstructed as a 3d model. It’s stupid expensive though, and you can only really identify whole proteins. But you can do that in context, which is massive reply dbrgn 21 hours agoprevThe random spin followed by a run reminds me a bit of the first-generation Roomba logic... reply 082349872349872 21 hours agoparentor VC's between fads and during fads reply api 20 hours agorootparentEconomies are ecological systems and behave a lot like systems of organisms. reply objektif 18 hours agorootparentprevVCs are pure momentum investors. There is not much intelligence there. reply PcChip 21 hours agoprevExcellent writeup, i love the interactive animation reply ehmorris 20 hours agoparentIf you're interested the code for the simulation all lives here: https://github.com/ehmorris/ecoli-chemotaxis/tree/main/ecoli... reply pmayrgundter 19 hours agoprevIf you do an accounting of all the organ functions, and then ask if the cell has this function independently, nothing is left out... but only if you allow that intelligence arises from the cells. So I believe intelligence arises from the cells and is an essential function of life, not only an emergent phenomena. The organs serve as division of labor amongst the cells in community for what they are already originally capable of themselves. More musings in this direction https://sites.google.com/site/pablomayrgundter/mind reply begueradj 19 hours agoprev> An individual E. coli has no brain, obviously, and is even many orders of magnitude simpler than a human cell, and yet already it possesses something like a sense of smell, drive, even a memory. A person is billions of billions of more effective cells than an E.coli cell: still our sense of smell, drive and memory do not seem to be billions of billions times more efficient. reply oersted 16 hours agoprevThe video embedded in the article is a great and more brief explanation of what's written: https://www.youtube.com/watch?v=LgPDOSou1tw reply swader999 21 hours agoprevIncredible to think how something this intricate with so many interdependent parts and integrated systems could have evolved. reply tasty_freeze 20 hours agoparentThe thing that makes it difficult to imagine is that the large numbers involved are hard to imagine. In a given teaspoon of ocean water in the top layer, there are millions of bacteria (in soil there can be up to 1 billion). Each one lives for a day or two before it either divides or is consumed, with a handful of mutations at each round of division. So ~200 divisions a year, for three billion years, with selection stochastically whittling out the few good mutations the crop up now and then, in a diversity of changing ecosystems and you end up with where we are today. Oh, and the occasional horizontal gene transfer for extra spice. Obviously that is a large hand wave -- the numbers above are from today's environment; early on the biotic density was lower. But the large numbers swamp things. The only real mystery is how things initially got started. But again, it is hard to imagine the time scale involved and the wide variety of environments that exist over the time to imagine the happy accident where the first self-replicating molecule just happen in the right environment that was stable enough for long enough for that self replication to gain traction. reply mrguyorama 14 hours agoparentprevHave you actually seen the results of things made with evolutionary algorithms? They ALWAYS produce \"what the fuck, how could this be good\" outcomes. From antenna that look like scifi props, to a computational system that somehow requires a supposedly unconnected transistor to be activated, evolutionary systems always find their way to a goal in an unimaginable fashion, because \"random\" mutations are basically the direct opposite of engineering something, so why does everyone always expect the outcome to look engineered? Evolution producing a complicated, half non-working, incomprehensible, \"everything interacts with everything else in a chaotic and unpredictable to us way\", is the EXPECTED outcome. It's similar to how many big programming projects become spaghetti messes of half integrations and barely functional parts hooked together half-hazardly where every feature relies on a bit of code nobody understands. It's an \"iterate on the stuff that works\" process, except the machinery inside a cell is way more effective and tolerant of such a regime than our stupidly strict programming languages and computers. reply matthewdgreen 7 hours agorootparentWell, that is true. But presumably selection pressure —- namely, the need for things to work reliably and in an organized fashion —- imposes structure on systems that parallels the kind of organization that engineers use to make complicated systems work reliably. There’s a reason that complex organisms concentrate specific functions into organs with recognizable interfaces rather than scattering those cells widely throughout the body, in the same way that a human-engineered mechanism is usually constructed from parts. The fact that this allows for organ transplants isn’t really by design, but it’s a convenient outcome. reply beders 21 hours agoparentprevI know. But this is very well understood and researched. All it requires is mutations, time and selection pressure. The Blind Watchmaker is still a good read. reply ssener2001 1 hour agorootparentIt is a well-known fact that that well-proportioned, regular, perfect, and beautiful arts are based on a very beautiful program. A perfect and beautiful program, in turn, indicates a perfect and beautiful knowledge, a beautiful mind, and a beautiful spiritual faculty.That is to say, it is the spirit’s immaterial beauty which is manifested in art by means of knowledge. Thus, the universe, with its innumerable material fine qualities, is formed of the distillations of immaterial fine qualities pertaining to knowledge. reply FartyMcFarter 21 hours agorootparentprevIt's still incredible despite all that. Not in the sense that one chooses not to believe it, but in the sense that it's hard to fathom that it actually happened. reply resource0x 10 hours agorootparentprevI'm curious: if tomorrow someone discovers that some parts of the genome are encoded with RSA cryptography, will the argument of \"mutations, time and selection pressure\" still hold? The same handwaving applies :-) reply pixl97 8 hours agorootparentIt 100% still holds. The convergent evolution of pitcher plants is an example of this. There are a number of features that evolve to the same functionality in plants, and many of them have to work together to become fully functional. Yet we see in plants separated by vast distances and millions of years of separation that traits that are useless alone encode themselves and then will will have near spontaneous usefulness when some other gene evolves. The laws of large numbers are not things the human mind really grasps well at all. reply singularity2001 21 hours agorootparentprevFirst you need the incredible machinery to enable mutations in the first place reply prmph 19 hours agorootparentprevSo if a monkeys bangs on keys forever it will eventually produce Shakespeare? I'm quite skeptical reply FartyMcFarter 18 hours agorootparentThere's no selection pressure when a monkey bangs their hands on a keyboard. It's just randomness without any consequence. The letters are not interacting with each other or their environment in any significant way. reply arkey 1 hour agorootparentWhat about offering the monkey some peanuts if he bangs correct words, the more correct words the more peanuts he gets? I understand there would be limitations in the lifespan of the monkey and such, but in a hypothetical case, would that work? reply IncreasePosts 14 hours agorootparentprevEvolution wasn't evolving towards the specific point we are at now. It was just doing its own thing all the time, with no plans for the future. So, a better (but still not great) question, would be, if a monkey bangs on keys forever would they ever produce any kind of story at all? But, that's still not good enough, because evolution is iterative, and would pick out very short stories that worked a bit, and that page kept getting duplicated out to new monkeys who would start typing from the end of that story reply pixl97 8 hours agorootparentprevObviously yes, hence we are the monkeys banging on the keyboard. Evolution just boosted those that made interesting strings because it gave a survival advantage. reply janpmz 21 hours agoprevI would love to understand how individual cells come together to form functioning organs with clear boundaries. reply dustingetz 21 hours agoparentelemental cells also have clear boundaries ie the cell membrane, which evolved as a way to catalyze a chemical reaction by containing all the ingredients in one place. imagine a fatty globule that randomly happens to enclose a set of chemical ingredients that react; that reaction is now far more likely to occur reply janpmz 21 hours agorootparentThats a nice view. Packages of chemical ingredients that react. And they are in an environment together with gradients of molecules that start reactions at specific concentrations. reply swayvil 20 hours agoparentprevSelf-organizing brownie swarms manage the whole process from the ethereal plane. reply yehosef 19 hours agoprevAm I allowed to think this is too complicated to be an accident? reply Jensson 19 hours agoparentYes, but that doesn't mean people will take you seriously. In order to evolve such a system all you need is for the separate components to be useful. A cell laying still and multiplying is useful enough, so that is the baseline. Then adding a flagella to move randomly so it can move away from its waste product and keep hitting new nutrients is also useful. From there it can start to detect waste and move when it is near waste and stop moving when it is near food. Then yo just continue such steps, not very hard to imagine compared to imagining macro evolution. reply arkey 18 hours agorootparentBut doesn't that reduce to a point where something useful becomes from separate useless components? In your case, why would a flagella be useful if it's not propelling something? A flagella is only useful as a component of something, but not by itself. reply jjk166 17 hours agorootparentFlagella only exist as components of something, they do not need to and shouldn't exist by themselves. If flagella spontaneously popped into existence and cells picked them up, that would be quite difficult to explain without design, but cells producing flagella because they are useful components makes perfect sense on its own. reply arkey 1 hour agorootparent> cells producing flagella because they are useful components makes perfect sense on its own. But that's the thing, this sort of implies that a complete flagellum can be spontaneously produced because it's useful, which sort of collides with the parent comment on systems evolving by combining previously useful components. Flagella aren't useful until they are complete. So intermediate forms should be lost, right? Would this leave us in a scenario where a single combination of several mutations at the same time suddenly gives you a complete, functional flagellum? reply lebek 16 hours agorootparentprevI think he's saying, random mutation wouldn't produce all required components at once. One mutation gives you a bit of a flagella, another gives you bit of a nose, but how does the flagella mutation survive to coexist with the nose mutation that makes it useful. I suspect the answer is that having flagella without a nose is still better than having no flagella. If so it suggests evolution isn't good at accessing groups of mutations that aren't individually beneficial. reply jjk166 16 hours agorootparentEvolution doesn't produce 1st part of the flagellum, second part of the flagellum, third part of the flagellum. It produces shitty flagellum, better flagellum, good flagellum. But the problem is we don't see the intermediate forms. So right now you might see a complicated flagellum that has a lot of highly specialized parts that all need eachother, but that is merely a refinement that took place after all the pieces were already there. Like once an arch is complete, all the scaffolding that was holding it up is now vestigial and if it is removed the arch will remain standing. reply crudcodersare 16 hours agorootparentIt seems you may have misunderstood the original argument. The iterative approach suggests increments so minute at each step that they wouldn't significantly impact an organism's survival at any given time. Also given the extremely slow process of evolution and the relatively short number of iterations it is infeasible to suggest such a solution. If a person would like to create an iPhone it's easy to tell them to start with a shitty scrap of metal and work from there. You can make that sort of argument as a solution for creating anything but it is clearly not feasible. reply jjk166 14 hours agorootparentNo, I understand the argument, it is just built on a false assumption about how the iterations work. That a change is small does not make its effects insignificant. A single codon change could profoundly alter the protein it encodes, and even a small change to a protein or its expression can have a massive effect on the organism. It's not the structures of an orgnaism that mutate, it's the instructions that generate those structures which mutate. Imagine for example a typo on a blueprint - where there was supposed to be a \" instead there is a ' and suddenly instead of an 8 inch air vent, now you have an 8 foot door. There is no intermediate step where you have a useless 2 foot hole. Evolution is not a slow process, it is an irregular process. The odds of a useful mutation popping up at any given time is low, but once it pops up it's there immediately. Yes, an evolutionary process could never make an iphone, but no is claiming that evolution produced the iphone. The complex systems evolution produces are things where all the changes are individually useful. reply satvikpendem 14 hours agorootparentprev> significantly Why not? People think in such a short time and amount scale such that we cannot comprehend trillions of cells spending billions of years, iterating. Even a small change can be significant at those scales. reply mrguyorama 14 hours agorootparentprev>so minute at each step that they wouldn't significantly impact an organism's survival at any given time. That's the thing. Evolution isn't \"survival of the fittest\" or even \"driven by more efficient anything\", evolution is simply; if you die before you pass on your genes, you don't pass on your genes. Over long enough time scales, with large enough populations, with tight enough tolerances and strict enough niches, the system roughly approximates a directed iteration of more efficient parts. Nothing about evolution prevents carrying forward explicitly negative mutations! Nothing about evolution prevents carrying completely unused functionality and features! Nothing about evolution guarantees monotonically increasing fitness! The giraffe has a certain nerve that goes from it's brain, all the way down around it's aorta, back up it's neck, to it's tongue. It does this, because in the fish we all evolved from, such a detour was less than a centimeter longer than an \"optimal\" path, and as each next generation went in different directions, it's just not that big a deal. A few hundred extra calories in development, and rare instances of a negative injury outcome are just not going to get fixed, because evolution is almost never vigilant. Most higher level animals have mating behaviors that explicitly favor \"wasted\" energy, including the long neck of giraffes! Sexual selection has a stronger influence on most animals than evolutionary pressure. > Also given the extremely slow process of evolution and the relatively short number of iterations it is infeasible to suggest such a solution This is silly. The vast majority of the ground work for complex life was developed by single celled organisms that produced a new generation every half hour, there were billions of these little creatures experiencing basically any possible mutation all the time, and a water droplet with a billion short lived single cells is exactly the kind of tight tolerance, competitive atmosphere where evolution is most prominent! Evolution is not iteration. Evolution is pruning bad branches in your breadth first tree based algorithm. reply pixl97 8 hours agorootparentprev>Evolution doesn't produce 1st part of the flagellum So this isn't exactly 100% true. Quite often the encoding of these things can sit in our DNA not activated and then pop up out of nowhere. Scishow did an episode on this recently. https://www.youtube.com/watch?v=YzWOjP7hm2w reply lebek 15 hours agorootparentprevI understand that, but it seems like even the MVP \"shitty\" flagellum would require many mutations that individually have no benefit. But I suppose with enough generations/parallelism you get enough stacking of useless mutations to reach the useful ones. reply jjk166 14 hours agorootparentThat's the thing most people have difficulty wrapping their head around. What you need to remember is it's not the structures evolving, it's the instructions evolving. If for example you have a small molecular pump that the cell uses to suck up sodium ions, and a mutation causes the part of the rotor sticking out of the cell to just be longer, which might be due to a single change to the gene controlling the length of the rotor, then congrats, you now have a shitty flagellum. The mutations don't even need to be useful for the eventual purpose. For example the highly dexterous fingers which enable complex tool use that humans used to conquer the world and with which I type this comment now started out as structural reinforcement for fish fins, absolutely useless for object manipulation. And those reinforcements in turn are just extremely bastardized version of a calcite growth which offered some protection to a soft body organism hundreds of millions of years before. reply arkey 1 hour agorootparentBut again you're starting with a fairly complex system already, the molecular pump. And my (limited) understanding is that changes that are not useful or helpful would get lost. And additional to that, if an organism has a pump (which it needs to function properly) and that pump suddenly is no pump, it's a very bad flagellum, that organism has a very big problem. It's like if we swapped our arms for wings. Wings are cool, but we wouldn't be able to fly anyway, and we'd have serious problems as humans with no arms and hands. reply wiz21c 19 hours agoparentprevGiven the size of the universe and its age, I'd say we have waited long enough for probabilities to line up and produce such a complicated design. reply voidmain0001 18 hours agorootparentI read a quote once that said “Simple bacteria can divide about every 20 minutes and have many hundreds of different proteins, each containing 20 types of amino acids arranged in chains that might be several hundred long. For bacteria to evolve by beneficial mutations one at a time would take much, much longer than three or four billion years, the time that many scientists believe life has existed on earth.” I haven't performed the math to back up the quote. As well would it change the time required if the bacteria mutate in parallel rather than in series? reply jjk166 17 hours agorootparentIt's the \"one at a time\" that is the issue here. Evolution is a massively parallel process. If a beneficial mutation happens once every million gnerations, and a generation is 20 minutes, that's a beneficial mutation every 38 years. If you have a million cells, that's a beneficial mutation every 20 minutes. If you have a billion cells, that's 1000 beneficial mutations every 20 minutes. In your body there are around 40 trillion cells. There are something like 10^31 cells on earth. reply pishpash 17 hours agorootparentprevIt's called the plasmid exchange. The search is parallelized to however many individuals there are, which is arbitrarily large, then the result is shared. reply martythemaniak 18 hours agoparentprevI find this to be an incredibly bizarre thing to say. Nobody is stopping you from thinking anything, of course you're allowed and surely you know this very well. I suspect what you're really saying is \"Will you still respect me for being a creationist\". And the answer is, LOL of course not. Nobody is entitled to have their wacky ideas be respected. A lot of the \"free speech\" complaints are really demands that other people treat your bullshit with respect, which is an absurd demand. But if my suspicion above is way off, please tell me. I am curious why anyone would say what you said. reply basil-rash 16 hours agorootparentIt’s funny, because the creationists generally feel the exact same about evolutionists. Both are faith based responses to questions we cannot answer any other way. Getting caught up in absolutes thinking your interpretation is the gold standard is a sign of an unrefined critical thinking process. reply IncreasePosts 14 hours agorootparentNo, evolution is not faith based. If you want something faith based, which creationism purports to resolve, it would be if someone has a strong belief on how abiogenesis actually happened, since that is something that is still not well understood. But, we see evolution happening all around us, all the time. reply basil-rash 12 hours agorootparentIt most certainly is. Evolutionists believe in the time invariance of the laws of physics with no proof, creationists believe the processes by why things have changed in the universe (“physics”, broadly) have changed over time, also with no proof. That there is some external influence that we cannot directly observe that has some massive impact on the development of the universe in ways we cannot explain. (Funnily, physics have come to acknowledge the same, but they call it dark matter and say it’s all very scientific, whatever it is. But this is unknown enough to be not worth much discussion.) Regarding the evolution we see around us all the time, I and many creationists besides me have full confidence in the idea that micro-evolution does occur. That there is a stochastic gradient decent process that hones in on time-varying local maxima over generations cannot really be denied. But that provides absolutely no answer to the questions of abiogenesis and speciation en-masse. reply dekhn 11 hours agorootparentThe reason we believe in time invariance of the laws of physics is based on observation of old structures in the universe (at least we only have to look back about 4 billion years to the beginning of evolution on earth). So far we have not found any convincing evidence that the laws have changed (either new or different interactions, or the strength of the interactions). I will say all of science is based on faith- the faith that the human mind can perceive the universe as it truly is, using rational thought and experimental data collection. For some reason this really bothers some scientists and they like to treat science as an unquestionable objective truth, but realistically, we can't exclude any number of hypotheses, but merely state them as improbable based on our understanding. reply basil-rash 7 hours agorootparentI fear you are failing to comprehend how fundamental the axiom in question (is the universal state influenced by actors beyond our comprehension?) really is. There is no experiment that can answer it, any and all observations must be looked at under a lens that is fundamentally influenced by your answer to the question. We can certainly say that the observations look like they may have progressed at the rate we expect for the past 13 billion years, but that does nothing to exclude the possibility that around 6,000 years ago some actor we do not understand took 1 week to craft everything we observe now to be precisely how it is. Reading your final paragraph, I believe we are more aligned than I previously thought. :) reply burnished 15 hours agorootparentprevOh they really aren't. Its sort of a tired rhetorical ploy pitting them as faith based beliefs on equal intellectual footing though. Both are theories about the world. 'Creationism' as a theory really only became pure faith very recently as most specific claims attributable to it have been disproven or better explanations have been found. For a long time it was a perfectly cogent theory. reply basil-rash 12 hours agorootparentThis is objectively false. Evolution explains absolutely nothing creationism doesn’t, and creationism explains a whole lot that evolution cannot. For instance, universal origins and the formation of cells. reply dekhn 11 hours agorootparentCould you show us an experiment that would demonstrate creationism is a better explanation than evolution (and random chance) for the formation of cells? If you can't come up with an actual experiment, there's really no way to say that creationism \"explains\" something. reply basil-rash 7 hours agorootparentCreationism explains everything very simply: \"X is the way it is because God ordained it to be\". There is no need to experimentally verify, its existence is the proof. In general, the need for experimental evidence is only present when you've accepted the lack of external intervention as axiomatic. When that very axiom is under debate, experimentalism is entirely irrelevant. Not to mention, anything I present as being evidence of intelligence being more able to produce functional complexity than randomness you would reinterpret as \"randomness-that-produced-something-that-look-like-intelligence producing functional complexity better than randomness-that-doesnt-look-like-intelligence\". reply carapace 10 hours agorootparentprevCreationism doesn't explain anything. You don't have to take evolution on faith. You can write a computer program that demonstrates that selection among almost-but-not-quite identical entities with heritable properties generates adaptive forms. Many people have. DNA is real. Reproducing lifeforms are real. We know how they work in some detail. There's no faith required. reply arkey 51 minutes agorootparent> Creationism doesn't explain anything. How so? For that to happen you'd need to have the usual \"evolution-is-science-and-creationism-is-religion-which-denies-science\" stance, no? There are creationist scientists, there is \"creationism-proving\", or at the very least allow \"creationism-compatible\" evidence in science, and so on. Let's reduce it even more, science hasn't been able to disprove Creation. Believing \"God did it\" should not invalidate science, wanting to understand more, and actually making experiments. On the contrary, it should encourage it, as it did with many scientists who, in a way, brought us to where we are. And as other commenters say, your computer program would prove absolutely nothing in the grand scheme of things, primarily because micro-evolution (which can easily be understood as a feature of Creation) does certainly not imply macro-evolution or abiogenesis. reply basil-rash 7 hours agorootparentprevPlease understand the discussion at hand before commenting. Nobody is denying the existence of small-scale \"micro-evolution\" that subtly guides species into local optima. The question is of abiogenesis and mass-speciation, topics evolutionism has been thoroughly unable to explain, despite many attempts. reply carapace 4 hours agorootparentI do understand the discussion. You don't seem to understand what explanation is. Saying \"God did it\" doesn't explain the origin of life. We may never have a scientific explanation for how life arose. It may be that it was an act of God (which, for what it's worth, I personally believe) but that doesn't explain it. There are limits to human knowledge, and faith transcends those limits. You seem to confuse faith and science and put them in some sort of competition with each other, they're not, they are both approaches to the Truth. reply basil-rash 2 hours agorootparentYou are using the evolutionist's definition of \"explain\", which is not applicable to the creationist's interpretation of reality. Under the evolutionists view, there is no actor with the ability to alter universal state besides those physical laws which we currently observe. Thus, any change in universal state that has ever occurred would naturally be able to be \"explained\" by providing a detailed step-by-step rundown of how those laws interacted with universal state S until it reached universal state S'. Under creationism, this definition is nonsense: any change in state can occur at any time based on the whims of the unknown actor, no further rationale is necessary or indeed possible. Accordingly, if we take a definition of \"explain\" which does not assume a particular interpretation of the fundamental axiom (as we should, when that axiom is the very thing under debate), my statement is perfectly valid: That actor which we cannot fathom made it so. Thus, it is. reply samatman 8 hours agorootparentprevDo you believe that the Bible is the literal and inspired word of God, correct in every detail? reply basil-rash 7 hours agorootparentIt's certainly inspired, but it has been subject to the chaotic nature of humanity, as has everything since the fall. reply samatman 7 hours agorootparentClose enough. You're trying to package your religion as something which it isn't. Creationism is Christian theology, not science. People know this. On some level, you know this. reply basil-rash 2 hours agorootparentOf course I know that. And further I know evolutionism is the same. Indeed I opened this entire thread with the statement: \"both are faith based responses to questions we cannot answer any other way.\" It would seem you are not paying attention to what is actually being said. reply Kerb_ 15 hours agorootparentprevThat's cool and all, but do you give an equal amount of credit to Young Earth Creationists and regular creationists? Because both are equally based in faith. It is equally possible some holy being made fake dinosaur bones 6000 years ago to fool us, and no amount of scientific rigor can compete with a being with the foresight to know exactly how we would test the bones. At what point is \"umm we obviously have evidence these bones are over 6000 years old\" thinking in absolutes? In the meantime, I'm willing to be disrespected for thinking both forms of creationism are equally woo-woo in comparison to evolutionary theory. reply basil-rash 12 hours agorootparentIt’s important to understand why we think the bones are over 6,000 years old, and especially consider what assumptions we make in determining that age. Most importantly, the time invariance of physics. Really it boils down to whether you believe the laws of physics we observe now have been constant throughout time. If you do you’re called an evolutionist, if you don’t you’re called a creationist. Neither side has any proof, nor is any proof fundamentally possible. reply pixl97 8 hours agorootparentThen please provide a consistent with observations theory on how physics has changed with time. Or do you have to throw thermodynamics out the window because you've gone and screwed causality? One side has a whole bunch of consistent observational evidence. The other side has a lot of frantic handwaving and inconsistent data points. The point being is, creationists have zero idea why they think 6,000 is some magic number in this case, other than bob said so in a book. But yea, books are written by men and men are liars. Even looking at things like RNA/DNA mutation rates in known species it's pretty damned easy to see that things have been around a whole lot longer than 6k years. reply basil-rash 7 hours agorootparent> looking at things like RNA/DNA mutation rates in known species it's pretty damned easy to see that things have been around a whole lot longer than 6k years Again, please understand the underlying assumptions you are making when you concoct statements like this. Namely: DNA/RNA started as a single form and has mutated at a constant rate since then. You have no evidence to support that, and I disagree with every component of it. reply crudcodersare 15 hours agorootparentprevGod designing us in an emergent manner or through a static blueprint are the same thing. Someone had to create the laws, the genetic algorithm idea itself and all of these components and the environment for it to operate within never mind things like colors, matter etc. Evolutionists cant see the forest for the trees. reply Kerb_ 14 hours agorootparentThen that's not believing in creationism, that's believing in evolution. You wouldn't \"not believe in fusion theory\" because you believe God created the sun through the process of inventing a universe that sustains nuclear reactions. You would just believe in fusion, as a part of God's creation. reply satvikpendem 14 hours agorootparentprev> Someone had to create the laws This is unknown and a quite anthropomorphic view on the universe. Just because we can create things doesn't mean we ourselves were created, even in the way you're talking about in the First Mover argument. reply nyc111 21 hours agoprevThere is a section at the end \"How did we figure all this stuff out?\". Really amazing. And the scale invariance of nature is clearly visible here. The cell is \"small\" compared to human scale but it is as complicated as any machine existing in human scale. There is no absolute small or big in nature. reply roenxi 21 hours agoparentI was about to post a very similar comment. That last section elevates the article from \"interesting\" to \"wow, that was great\". It isn't just revealed wisdom; the gentleman want to show the limits of the knowledge. And the \"in silico\" experiments are probably a bit of a sleeper for people outside the field. It is really obvious how improvements in computing power will have/had a transformative impact on this field. To go from poking out random molecules and growing dangerous things in a pitri dish to fast computer simulations from DNA seems like quite a big jump in how quickly the field can learn. reply beders 21 hours agoparentprevIt is a highly evolved bacterium for sure. It still hasn't figured out how to form multi-cell clusters. And let's hope it stays that way ;) Also scale is subject to physical limitations. Bones can only carry that much weight - chemical processes are limited by - for example - maximum energy dissipation rate. reply fartsucker69 20 hours agoparentprevthere would be an absolute small, at planck scales (from what we know) there's also an absolute big, known in cosmology, far beyond the scales of galaxies, galaxy clusters, etc... it's your mom reply graemep 20 hours agoparentprevIt is a lot more complex than anything made by humans, but it is nothing like as complicated as a human that consists of a huge number of cells. reply dotnet00 20 hours agorootparentTechnically humans are also made by humans :) reply photochemsyn 19 hours agoprevGreat writeup. Here's a full-text review that contains all the math needed to build a model of this process (2013): \"Quantitative modeling of bacterial chemotaxis: Signal amplification and accurate adaptation, Yuhai Tu\" https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3737589/ The main points are: * Both receptor cooperativity and accurate adaptation can be described quantitatively by simple mathematical models. * An integrated model (the “standard model”), which contains both signal amplification and adaptation, is developed to predict responses of it E. coli cells to any time-dependent stimuli quantitatively. * Exponential ramps induce activity shifts, which depend on the ramp rate through the methylation rate function F(a). * Responses to oscillatory signals reveal that E. coli computes time-derivative in the low-frequency regime. * E. coli memorizes the logarithm of the ligand concentration and the Weber-Fetcher law holds in E. coli chemotaxis. It also goes into cooperative phase transitions in the receptor complexes as a means of signal amplification, using the same model as in Ising ferromagnetic spin-spin interactions in physics. reply singularity2001 20 hours agoprevThese ribbons look a bit like wires, transforming the information of an attached molecules through the membrane through physical tension reply gilleain 19 hours agoparentthe red helices? those are transmembrane helices, and i guess yes they can transmit information in some cases. there are receptors in the membrane of our cells that respond to mechanical force reply retskrad 20 hours agoprevFrom a laymans perspective, can human beings create our own version of DNA, let's say with the use of transistors instead of biological cells, long into the future? Or is DNA just magic and we can't recreate it inside solid state objects like a robot made out of transistors? reply dweekly 20 hours agoparentNot sure if it's what you meant, but DNA Computing is a whole field! https://en.m.wikipedia.org/wiki/DNA_computing reply retskrad 20 hours agorootparentThank you, that sounds interesting reply burnished 15 hours agoparentprevDNA sequences are instructions that get printed on the spot and self assemble. This requires a great deal of flexibility so any reproduction would probably look much like what we find in nature. Or did you understand that and were wondering if we'd ever coopt the bodies mechanisms to create familiar logic gate based compute? Personally I doubt that we'd use already familiar transistors because the process requires ultra pure materials that are modified in very thin layers using gasses to scrape or place individual layers, but maybe we'd find a mechanical analogue expressible via protein, or at that point use purpose built neurons instead. reply two_handfuls 20 hours agoparentprevIt’s not magic, we can synthesize DNA. But we don’t yet have the kind of nanotechnology that cells do. reply bell-cot 20 hours agoprevOn the one hand, this is extremely cool science. OTOH, English really needs another word, meaning \"like intelligence, but it could be simulated by an analog computer with a good handful of of discrete components\". reply Jensson 20 hours agoparentYou can't simulate the intelligence of a cell using just a handfull of analogue components. Cell intelligence is still beyond us. People tend to underestimated cells just like you do here. reply bell-cot 20 hours agorootparentArticle subtitle: The story of E. coli chemotaxis I'm not thinking of simulating the whole cell. And last I heard, a DC full of computers can't fully simulate one sucrose molecule. reply dekhn 16 hours agorootparentSure, a DC full of computers can fully simulate a sucrose molecule at a detailed level of description. You wouldn't need a DC- it could be done on a single machine. The real question is, why would you need to model things at the molecular level of detail if that detail is not necessary to recapitulate the behavior of a cell? One thng I've learned from over a decade of simulating proteins and nucleic acids is that those methods, while mathematically interesting, don't provide useful data given the amount of resources they require. Instead, reduced models (effectively embeddings) and careful statistical methods are much, much more productive. reply Jensson 20 hours agorootparentprevE. coli does a lot more things than what is described in the article, the article just gives an extremely simplified view of the cells intelligence. They react to all sorts of substances in reality and decides where to go based on all of those, not just a simple \"go towards good place\" behavior. It is cool that they mapped out how it behaves in a simple environment, but you can do the same thing with humans, if you put a human in a simple experiment you can create similarly simple rules for human behavior. And even if you just look at the behavior described in the article that would still require quite a bit of components since you would need to accumulate signals and normalize them and then turn that to oscillating control signals. Computing via chemical processes like cells do makes the computations a lot simpler. reply bell-cot 19 hours agorootparentUm...I'm suspecting that you want to argue with someone whose worldview is rather unlike mine. And our notions of how many components are in a \"good handful\" may also differ rather widely. Thanks, OO. reply Jensson 19 hours agorootparent> I'm suspecting that you want to argue with someone whose worldview is rather unlike mine. Probably, but I can only respond to the words you write and not your internal thoughts. To me a handful is 10 or less, from fingers, but I guess a handful could also be hundreds like hundreds of rice grains which makes more sense but I haven't seen anyone use handful for more than 10. reply FrustratedMonky 20 hours agorootparentprevThink the issue is what constitutes 'intelligence' at all. Forget computers. This article breaks down how the cell behaves down the the molecules. Once each part is pulled apart and examined, where did the 'intelligence' go. The single cell, looks 'intelligent'. But, when it is all pulled apart we don't find it. It is just chemicals, reactions, physics. Then, scale that up to multi-cellular organism, then human, its all just mechanistic, chemicals, physics. So where did the intelligence come from? Humans are also just twitching flagella. This article just makes it a more stark idea, because a single cell appears 'intelligent', but we can pull it apart and examine the constitutive parts, the chemical, molecules. So there is not much wiggle room for philosophy or souls. It looks intelligent, but look, we can peer under a microscope and don't see the intelligence. reply RetroTechie 18 hours agorootparentThe intelligence is in the parts' interactions. Compare with an OS kernel: individual code snippets are useless / meaningless. Executed by some CPU or VM, each snippet can be seen to modify that machine's state. Snippets put together may be observed, and understood as implementing some specific algorithm. Again: useless / meaningless in isolation. Some snippets may be seen to address I/O, and so it may be assumed to be part of a subsystem that controls (or is controlled by) a peripheral device. Now put all those parts together, and you have an intricate piece of machinery that shows flexible, adaptable, goal-oriented behaviour. Behaves in a 'smart' way (for varying definitions of 'smart'). Where did the intelligence come from? The parts' properties, how they're put together, and their interactions (among themselves & their environment). As science progresses, I think we'll come to realize it's just that: a matter of scale & how the many parts and variables interact with their environment. No magic (but fascinating & wonderful nonetheless). reply Jensson 20 hours agorootparentprev> This article breaks down how the cell behaves down the the molecules No, just for a single molecule. The cell does a lot more than that. Can read this if you want to learn a bit more. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6194112/ > So there is not much wiggle room for philosophy or souls. It looks intelligent, but look, we can peer under a microscope and don't see the intelligence. Sure, but we still can't replicate its behavior in a natural environment, just simple lab environments. reply jvanderbot 20 hours agoparentprevHow does a water droplet \"know\" the path downhill. How does electricity \"know\" the least resistance path. All this language is just confusing. In a chemical gradient sense, molds and yeasts solve tough problems all the time, but it's not much more than physics reply whelp_24 20 hours agorootparentHow many simple physics combinations until you get intelligence? Remember that you are made of cells, and everything you do (probably) can be reduced to a group effect of your cells. reply jvanderbot 20 hours agorootparentComplexity is not magic. It's just a long search for the right combo. In fact we have untold trillions of branching iterations in evolution. reply whelp_24 18 hours agorootparentThis does not answer the question. reply taneq 20 hours agorootparentprevIf it's more than physics at all, what's the extra bit? reply jvanderbot 20 hours agorootparentWell, I guess a fancy narrative. reply a_gnostic 20 hours agorootparentEven that is physics. reply jvanderbot 15 hours agorootparentYou used my own point to \"gotcha\", so I guess that's Hackernews! reply a_gnostic 7 minutes agorootparentA gotcha was not intended. I commented in your support, with mild humor implied. whelp_24 20 hours agoparentprevI think intelligence is the correct word. Why not? reply HarHarVeryFunny 11 hours agorootparentWhy not just use something descriptive like \"food finding mechanism\". It's also seems odd to call it \"baffling\" when they 100% understand how it works! reply bell-cot 20 hours agorootparentprevUseful languages can succinctly distinguish things which are qualitatively quite different. Describing everything in the world as \"intelligent\" sounds kinda cool and Zen, and may reflect some peoples' worldviews - but it also make \"intelligent\" pretty useless as an adjective. reply burnished 15 hours agorootparentIntelligence is not well defined enough for a succinct distinguishment. At least, not colloquially. But also we're in a context where acknowledging the intelligence of other life forms is pretty radical so distinguishing them as 'lesser' than human would be precisely opposite of the point. The baseline world view is that human intelligence is magically different than other animal intelligences. reply whelp_24 18 hours agorootparentprevWhy is intelligence a bad descriptor? reply HarHarVeryFunny 11 hours agorootparentBecause: 1) It's a poorly defined word that means different things to different people 2) The word \"mechanism\" perfectly describes what it is At the end of the day it's just using the detection of food, to switch from \"tumble\" (try a random direction to find food) to \"run\" (assume we're near, or in, a patch of food, and move forward to consume more). reply bell-cot 18 hours agorootparentprevIf \"hot\" described any temperature from \"the dark side of Pluto\" to \"the core of a brand-new neutron star\" - then how useful a word would \"hot\" be, for communication between humans? reply tempaway112751 19 hours agoparentprev\"like intelligence, but it could be simulated by an analog computer with a good handful of of discrete components\" dude, I am an analog computer with a good handful of discrete components and I'm definitely intelligent reply javajosh 19 hours agoprevCheA phosphorylates CheY to become CheY-p, and CheZ dephosphorylates it back to CheY; CheW couples CheA to the receptors, and CheR methylates those receptors’ struts; CheB, meanwhile, “clips off” the methyl groups added to the struts by CheR. I guess 'naming things' isn't just hard in CompSci. reply jmyeet 19 hours agoprevSo I have three thoughts about this. The first is cell specialization, particularly neurons. It seems like nature really came up with a universal neuron. There aren't neurons for eyesight vs thinking, etc. They've experimented with this on frogs where they've reweired the optic nerve to a different part ofd the brain and the frog seems to see just fine. They've even added an eye and the frog seems to cope and use it just fine. The second is the OpenWorm project [1]. This is an attempt to simulate a relatively simple organism with IIRC ~280 neurons. Despite lots of effort, the simulated version just doesn't match up to the real thing. In artificial neural networks we have a stupidly simplified model of neurons that tends to get reduced to a binary signal and an activation function. Thius can do a lot but it's clearly wholly inadequate for any realistic modelling. The protein interactions in a cell are mind-bogglingly complex. The third is the three-body problem. To summarize, we have a general solution for the grvity interactions of two bodies. Add one more and we don't. We have classes of solutions but no general solution. This is why JPL needs to use supercomputers to calculate flight plans with a relatively low number of bodies. We see a relatively simple set of interactions lead to massive complexity with protein folding. I imagine that it just won't be computationally viable to simulate even a single realistic cell given all th einteractions that go on. We're simply left to make estimations. [1]: https://openworm.org/ reply dekhn 16 hours agoparentAre you sure JPL needs supercomputers to calculate flight plans? Please, if you know of more details, I'd like to see them. I was reading the NASA supercomputer complaint and it looks like trajectories can be calculated on extremely conventional small high performance computers now. reply m3kw9 19 hours agoparentprevMy one thought is that at the atomic level it is also “doing calculations” where by the interactions were evolved over eons to work they way it does. It’s like 3 body problem X a million, but it actually have a purpose and not chaos. If you know what I’m getting at reply verisimi 21 hours agoprev> How did we figure all this stuff out? > We don’t yet have the technology to just observe all of the activity inside a living cell. That Goodsell painting above that shows the crowded cytoplasm packed with proteins is an artistic composite—backed by rigorous research to be sure—because there’s no way to capture all the different players in situ at once. > A group at University of Illinois at Urbana-Champagne uses atomic-scale molecular dynamics simulations, in software, to understand structural details > It’s a world that’s hard to see; sometimes you just have to imagine what’s going on down there, and back up those imaginings with the right experiments. > One reason I’m particularly attracted to studies of E. coli chemotaxis is that it’s an early star of what’s been called “in silico” biology. It’s been the subject of many computer models. Honest, at least. reply burnished 15 hours agoparentYeah I always appreciate that, I hate it when people shy away from honesty because they think some heckler won't understand the subtlety of the observations at play. reply verisimi 2 hours agorootparentYou realise of course that models can be wrong. The map is not the terrain. Models are not reality. The observations here are on models. If I knock up something in excel, and other people use that thinking it is how things are, but do not refer to the reality the model represents because there is no way to do that, how useful is the model? Have you ever looked at old medieval beastiaries? Information is being relayed, but how useful is it? https://alexanderadamsart.wordpress.com/2019/07/30/the-besti... Without a means to view the underlying thing the model is meant to represent, to check and correct one's misunderstandings, how useful can the model be? reply stephc_int13 21 hours agoprevImagine a microscopic, fully autonomous and self-replicating Roomba that is also able to adapts at the individual and population levels. We're still quite far from replicating this kind of tech. reply CyberEldrich 14 hours agoparent> Imagine a microscopic, fully autonomous and self-replicating Roomba that is also able to adapts at the individual and population levels. Well, if the Roomba could exchange genetic information with the surrounding population and adapting to a changing environment would give the appearance of intelligence and design. reply agumonkey 21 hours agoparentprevyes evolution/nature .. life .. did a lot with very few long ago, any insect is a technological marvel if you look at it right reply scrubs 10 hours agoprevGood gracious. A fantastic read. Wow. reply chahex 18 hours agoprevHaha. I know you try to persuade me that consciousness as life force intelligence does not exist. But as far as I am concerned, I am and I am sentient and that is the only thing in my life I do not need any proof. reply crudcodersare 15 hours agoprev [–] God designing us in an emergent manner or through a static blueprint are the same thing. Someone had to create the laws, the genetic algorithm idea itself and all of these components and the environment for it to operate within never mind things like colors, matter etc. Evolutionists cant see the forest for the trees. reply pinkmuffinere 13 hours agoparent> “ God designing us in an emergent manner or through a static blueprint are the same thing.” Perhaps I’m misunderstanding you, but to me it seems like you have no argument with evolutionists. Your beliefs seem to permit evolution. I think your disagreement is actually with people that see evolution as evidence for atheism. reply ihumanable 14 hours agoparentprev [–] So your answer to \"where did this complexity come from?\" is to invent an even more complex celestial being that just did it. Creationists can't see the forest for the trees. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The passage explains chemotaxis in E. coli, where cells move towards attractants via a chemical signal, involving proteins like CheY and CheA to control movement and signaling.",
      "The flagellar motor in E. coli is essential for movement, requiring multiple CheY-p proteins to change its direction, and individual bacterial behavior differences stem from protein levels rather than genetics.",
      "Techniques such as fluorescence microscopy and computer modeling are utilized to study bacterial chemotaxis, with possible medical implications in antibiotic development, enhancing comprehension of biological functions."
    ],
    "commentSummary": [
      "The article discusses the intelligence and adaptability of single-celled organisms like E. coli in chemotaxis, along with complex adaptive systems and brain functionality.",
      "It explores the limitations of traditional education methods in comprehending biology, along with the debate between creationism and evolution.",
      "The text highlights advancements in computational power for studying bacterial behavior, emphasizing the complexity of evolution and the boundaries of human knowledge in understanding the natural world."
    ],
    "points": 440,
    "commentCount": 183,
    "retryCount": 0,
    "time": 1711020577
  },
  {
    "id": 39778590,
    "title": "The Reddit Founders' Journey with Y Combinator",
    "originLink": "https://www.ycombinator.com/blog/the-reddits",
    "originBody": "About What Happens at YC?ApplyYC Interview GuideFAQPeopleYC Blog Companies Startup DirectoryTop Companies◦ Revenue◦ ValuationFounder DirectoryLaunch YC Startup Jobs All Jobs◦ Engineering◦ Operations◦ Marketing◦ SalesPioneer Internship Program 2024Startup Job GuideCareer CoachingYC Startup Jobs Blog Find a Co-Founder Library SAFE Resources Startup SchoolNewsletterFor InvestorsHacker NewsBookface Open main menu Apply for S2024 batch.Apply All Posts Founder Stories The Reddits by Paul Graham3/21/2024 I met the Reddits before we even started Y Combinator. In fact they were one of the reasons we started it. YC grew out of a talk I gave to the Harvard Computer Society (the undergrad computer club) about how to start a startup. Everyone else in the audience was probably local, but Steve and Alexis came up on the train from the University of Virginia, where they were seniors. Since they'd come so far I agreed to meet them for coffee. They told me about the startup idea we'd later fund them to drop: a way to order fast food on your cellphone. This was before smartphones. They'd have had to make deals with cell carriers and fast food chains just to get it launched. So it was not going to happen. It still doesn't exist, 19 years later. But I was impressed with their brains and their energy. In fact I was so impressed with them and some of the other people I met at that talk that I decided to start something to fund them. A few days later I told Steve and Alexis that we were starting Y Combinator, and encouraged them to apply. That first batch we didn't have any way to identify applicants, so we made up nicknames for them. The Reddits were the \"Cell food muffins.\" \"Muffin\" is a term of endearment Jessica uses for things like small dogs and two year olds. So that gives you some idea what kind of impression Steve and Alexis made in those days. They had the look of slightly ruffled surprise that baby birds have. Their idea was bad though. And since we thought then that we were funding ideas rather than founders, we rejected them. But we felt bad about it. Jessica was sad that we'd rejected the muffins. And it seemed wrong to me to turn down the people we'd been inspired to start YC to fund. I don't think the startup sense of the word \"pivot\" had been invented yet, but we wanted to fund Steve and Alexis, so if their idea was bad, they'd have to work on something else. And I knew what else. In those days there was a site called Delicious where you could save links. It had a page called del.icio.us/popular that listed the most-saved links, and people were using this page as a de facto Reddit. I knew because a lot of the traffic to my site was coming from it. There needed to be something like del.icio.us/popular, but designed for sharing links instead of being a byproduct of saving them. So I called Steve and Alexis and said that we liked them, just not their idea, so we'd fund them if they'd work on something else. They were on the train home to Virginia at that point. They got off at the next station and got on the next train north, and by the end of the day were committed to working on what's now called Reddit. They would have liked to call it Snoo, as in \"What snoo?\" But snoo.com was too expensive, so they settled for calling the mascot Snoo and picked a name for the site that wasn't registered. Early on Reddit was just a provisional name, or so they told me at least, but it's probably too late to change it now. As with all the really great startups, there's an uncannily close match between the company and the founders. Steve in particular. Reddit has a certain personality — curious, skeptical, ready to be amused — and that personality is Steve's. Steve will roll his eyes at this, but he's an intellectual; he's interested in ideas for their own sake. That was how he came to be in that audience in Cambridge in the first place. He knew me because he was interested in a programming language I've written about called Lisp, and Lisp is one of those languages few people learn except out of intellectual curiosity. Steve's kind of vacuum-cleaner curiosity is exactly what you want when you're starting a site that's a list of links to literally anything interesting. Steve was not a big fan of authority, so he also liked the idea of a site without editors. In those days the top forum for programmers was a site called Slashdot. It was a lot like Reddit, except the stories on the frontpage were chosen by human moderators. And though they did a good job, that one small difference turned out to be a big difference. Being driven by user submissions meant Reddit was fresher than Slashdot. News there was newer, and users will always go where the newest news is. I pushed the Reddits to launch fast. A version one didn't need to be more than a couple hundred lines of code. How could that take more than a week or two to build? And they did launch comparatively fast, about three weeks into the first YC batch. The first users were Steve, Alexis, me, and some of their YC batchmates and college friends. It turns out you don't need that many users to collect a decent list of interesting links, especially if you have multiple accounts per user. Reddit got two more people from their YC batch: Chris Slowe and Aaron Swartz, and they too were unusually smart. Chris was just finishing his PhD in physics at Harvard. Aaron was younger, a college freshman, and even more anti-authority than Steve. It's not exaggerating to describe him as a martyr for what authority later did to him. Slowly but inexorably Reddit's traffic grew. At first the numbers were so small they were hard to distinguish from background noise. But within a few weeks it was clear that there was a core of real users returning regularly to the site. And although all kinds of things have happened to Reddit the company in the years since, Reddit the site never looked back. Reddit the site (and now app) is such a fundamentally useful thing that it's almost unkillable. Which is why, despite a long stretch after Steve left when the management strategy ranged from benign neglect to spectacular blunders, traffic just kept growing. You can't do that with most companies. Most companies you take your eye off the ball for six months and you're in deep trouble. But Reddit was special, and when Steve came back in 2015, I knew the world was in for a surprise. People thought they had Reddit's number: one of the players in Silicon Valley, but not one of the big ones. But those who knew what had been going on behind the scenes knew there was more to the story than this. If Reddit could grow to the size it had with management that was harmless at best, what could it do if Steve came back? We now know the answer to that question. Or at least a lower bound on the answer. Steve is not out of ideas yet. Categories Founder Stories Other Posts YC Founder Firesides: Mutiny on AI and the next era of company growth October 24, 2022 by Y Combinator Read More Same, Same but Different with Vanta and Zapier July 7, 2022 by Y Combinator Read More Learnings of a CEO: Matt Schulman, Pave, on Hiring October 17, 2022 by Lindsay Amos Read More Sign up for weekly updates from Y Combinator Subscribe Author Paul Graham Paul is a cofounder of YC. He is the author of On Lisp, ANSI Common Lisp, and Hackers & Painters. In 1995, he and Robert Morris started Viaweb, the first SaaS company, which became Yahoo Store. Footer Y Combinator Programs YC Program Startup School Work at a Startup Co-Founder Matching Company YC Blog Contact Press People Careers Privacy Policy Notice at Collection Security Terms of Use Resources Startup Directory Startup Library Investors SAFE Hacker News Launch YC YC Deals Make something people want. Apply TwitterFacebookInstagramLinkedInYoutube © 2024 Y Combinator",
    "commentLink": "https://news.ycombinator.com/item?id=39778590",
    "commentBody": "The Reddits (ycombinator.com)418 points by sandslash 20 hours agohidepastfavorite699 comments ChrisArchitect 18 hours agoIt's not fundamental, it's a glorified forum host, not to say that isn't immensely useful in the current landscape. But it's also very much a result of timing that it is still here. The history is often overlooked: when digg imploded/shot itself in the foot, Reddit was in the right place at the right time and got lucky. Somewhere for the exodus to go to. Reddit itself was failing fast and on its last legs at the time held afloat by its core users and that's it. They didn't know what they were going to do and rather than being visionaries in any way really they got lucky hosting everyone with a slew of very standard web 2.0 features. And as with any social site, it's the userbase/community that pulls it thru darkness to the where it is now. reply hn_throwaway_99 6 hours agoparentThis is true, and I was a \"Digg refugee\" who went to Reddit after the Digg 4.0 fiasco. But nearly all successful businesses have a huge amount of lucky timing. Reddit also had the nimbleness to capitalize on Digg's failure. I remember reading a blog post years back about how they were able to do things really quickly (I think the post was about how they changed their alien logo in like a day to something welcoming Digg folks) because they were a small startup back then. reply jascination 11 hours agoparentprevAbsolutely true. Reddit's true success started when Digg failed (remember MrBabyMan??) reply elwell 8 hours agorootparentDigg -> Reddit -> ? MySpace -> Facebook -> ? Yahoo -> Google -> LLM? reply fngjdflmdflg 7 hours agorootparentDigg -> Reddit -> Discord MySpace -> Facebook -> Instagram/Tiktok Yahoo -> Google -> LLM I don't like these developments, but they seem like likely candidates. reply irksomehails 6 hours agorootparentI'm curious why you think, Discord is the replacement for Reddit? Feel like they server different purposes. reply violetthrift 3 hours agorootparentThey function differently, but in terms of what gets communities to actually form and stick around, I think they're very similar: - Making a new space for your community is trivial for anyone; it can be done in seconds with a few clicks and all you have to do is choose a name. - Many people already have an account, so you don't need to convince everyone to sign up for a new platform. (Which scales with the platform's size, like all network effects.) - Communities have their own space they can adjust to their liking, rather than being a vague cluster of nodes with a similar interest like in other social networks. - Owners of those spaces have a lot of leeway to run things as they see fit. Personally, I don't like the growing trend of every community being a Discord server that is going to collect dust in the corner of my chat window unless I commit to keeping up with it every day, but I understand why it's happening. Discord is an adequate social hub for any project or hobby group with a very low barrier to entry, which is more important than the actual functionality being the best IMO. reply mtillman 6 hours agorootparentprevThey might have once but every sub Reddit has at least one, “join my discord server” post a day it seems. People just want browser based BBS but weren’t alive when they were at their best. reply alstonite 6 hours agorootparentprevI think that while Reddit's primary use is link aggregation, there's a secondary use for getting really niche questions answered by members of niche communities.For example, I have questions and answers on subs like r/powershell & r/xcode that still get replies years later because they solve a very specific problem. A lot of communities are choosing Discord for their homebase location rather than Reddit, which really bums me out because I'm not a huge fan of public Discord servers and I miss seeing the posts from all the niche communities I'm in aggregated somewhere. reply swarnie 3 hours agorootparentprevFar easier to manage a focused community, disseminate information rapidly, maintain a history of information. For example im currently playing though a mod pack for a game more that 20 years old; post about it on reddit and you get nothing; post on the discord and 30-40 active people will quickly get you the info you need. Search reddit for info (using google because reddit search has never and will never work) You'll end up with post after post of [Deleted]. Its beyond useless. reply bee_rider 6 hours agorootparentprevMaybe federated networks will catch on reply hayst4ck 4 hours agorootparentprevdigg followed StumbleUpon (https://en.wikipedia.org/wiki/StumbleUpon). StumbleUpon was the source of the vast majority of digg and reddit content before people like Randall Monroe were making high quality comments on reddit. Once every reddit post had a literal expert respond with high quality comments, it dominated the others and content began to be posted on reddit first, rather than the content being found on stumbleupon or digg and ending up on reddit. Eventually things like askreddit became popular and community style content flourished. reply mandevil 7 hours agorootparentprevSlashdot->HN reply ehecatl42 40 minutes agorootparentSlashdot → Kuro5hin reply mandeepj 7 hours agorootparentprev> Yahoo -> Google -> LLM? Yahoo -> Google -> OpenAI -> Microsoft. LLM is a tech stack, not a company. I added MS at the end because OpenAI brought it to forefront of the current wave of computing revolution. reply J_Shelby_J 15 hours agoparentprevBesides general luck and timing, there are two other factors reddit had going for it. 1) It was never the hot social media site, and still to this day it's a dark horse with even some of my peers not \"getting it.\" We're finally seeing it get the user base and mass market usage of other social media platforms. But it's been an extraordinarily long process. So it was never a hot place to work that attracted product managers / MBAs / status seekers that would come in and META the site. And I think even the investors and/or owners didn't know what to do with it, and were kinda content to just ignore it and let it do it's thing. 2) General incompetence. Search broken for decades. Videos broken for decades. Limited features for decades. Inability to make a native app that's usable. Not to say that I mind the UI of old.reddit.com. But that the Reddit team moved so slow to do anything. The only time the acted with expedience was when controversies occurred. Yeah, they're finally rolling out new stuff, but it's only been in the past 2-3 years that dev on the platform has picked up. But the thing is, this is the REASON Reddit has become as important as it is. A \"competent\" startup would of enshitified reddit and it would of died 15 years ago. Just like Digg. Instead we got almost a decade where the site looked like the frontpage of hackernews. And in that time, users kept creating high quality text content. And that content brought other users. And it slowly snowballed to the point where reddit is now the place to get genuine human text content on any topic. This is not something that could of occurred in the sort of time frame most startups or VCs operate in. And now they're trying to play a game that doesn't exist anymore (social media in the 2010s), and destroying the site with bad UI, hostility to the primary content creators, changes to the algorithm to prioritize engagement vs. nurturing quality content. It's sad, but I'm happy Reddit existed for as long as it did. reply mbesto 10 hours agorootparent> But that the Reddit team moved so slow to do anything This is actually the killer feature that has made Reddit so successful - not much has changed and the content keeps coming in. Same reason HN has still continued to do well. reply randycupertino 5 hours agorootparentprev> And it slowly snowballed to the point where reddit is now the place to get genuine human text content on any topic. That's what was interesting about the CEO's statement about their IPO, talking about how the future of Reddit is AI. Umm... I think what makes reddit great is you can actual get genuine humans discussing things they are passionate about. AI generated text seems like the opposite of this. reply valzam 5 hours agorootparentI wouldn't read too much into that, every tech company wanting to IPO in 2024 has to satisfy clueless investors with talk about their AI strategy. If this was 15 years ago they would be talking about investing to 'harness the efficiencies of the cloud' or something... reply akoboldfrying 10 hours agorootparentprev>A \"competent\" startup would of enshitified reddit and it would of died 15 years ago. Germans have a saying for what Reddit has achieved here: \"Falling up the stairs\". reply ForHackernews 8 hours agorootparentprevYeah, it's ironic that they're finally developing new stuff... and it's all absolute user-hostile garbage. My prediction is the IPO bombs hard and they're eventually sold off for scrap as training data for LLMs. reply nextos 8 hours agorootparentprevThe new UI was awful. Recently, they made some changes that IMHO improved it quite substantially. With a bit of work, it could be a good refresh of the original. reply roenxi 7 hours agoparentprevAlthough, in fairness, every business venture depends on timing to some degree. Good luck successfully getting a Google up and insanely profitable in 1900 or 2000. There are specific windows founders need to hit to find a market. Curiously, eyeballing the search engine wiki page [0] for when the engines I know about started it looks like there was a window in the mid 90s (Yandex, Google, MSN Search -> Bing) and another one might have opened in 2010s (DDG, Bing #2, Yandex English). People found these companies continuously, but there is a temporal component to when these companies take off. [0] https://en.wikipedia.org/wiki/Search_engine reply superdisk 15 hours agoprevA few years ago I sent a message to spez on Reddit asking if he'd ever open source the original Lisp version of Reddit. He actually responded and said he couldn't find it, but then a while later it was indeed released. I like to think maybe I contributed to the butterfly effect of that happening. https://github.com/reddit-archive/reddit1.0 reply rhaksw 9 hours agoparentInteresting, it has a del.icio.us scraper. I still don't understand why that site disappeared, it was great. By my recollection, Yahoo bought it and killed it. reply nextos 7 hours agorootparentI wish someone brought back a Delicious clone. I loved its naive Web 2.0 aesthetics. I think it was a really nice service. Right now all similar ones I know of are unpleasant to use and get in your way. It was really minimal and useful to find new things. One particular area where link sharing makes a lot of sense, yet existing services are not very nice, is academic papers. reply pigbearpig 7 hours agorootparentI don’t really remember delicious, but what would the difference be from something like https://pinboard.in/popular/ ? I was under the impression that’s basically a clone. Was it just a different aesthetic? reply jonnytran 5 hours agorootparentPinboard was a clone with a different business model: users actually paid for it. Fast forward, and delicious died, only to be acquired by — you guessed it — Pinboard [1]. Because Pinboard was actually serving its paying customers, it just kept trucking along. [1]: https://blog.pinboard.in/2017/06/pinboard_acquires_delicious... reply pjc50 49 minutes agorootparentprevdelicious launched before Pinboard, IIRC. There were a number of such services. reply bonki 7 hours agorootparentprevThat's exactly what happened and made me hate Yahoo even more than I already had. The day delicious was shut down for good I lost something that I have never managed to replace. Sad times :( reply ahansen 12 hours agoparentprevThat's really cool! Thanks for link. I guess I just never assumed that would be open sourced! reply Antrikshy 5 hours agorootparentOld versions of Reddit (in Python IIRC) were open source. They just stopped updating it. reply seoulmetro 9 hours agoparentprevI once asked a famous biscuit (cookie) factory nearby in a smallish city that never gives tours whether I could tour the factory just as a bucket list check off and never expected to get anywhere. They said they don't do that and will never do that unfortunately. A couple weeks later they auctioned off tickets to the factory tours as a \"special event\". I felt incredibly sour from that. I felt like a little more of humanity had eroded. reply husucueh 9 hours agorootparentYou wanted something from someone for free and then felt sour that they were going to charge for it? Are you friends with these people? Why do they owe you anything reply QuantumG 8 hours agorootparentI think the annoyance is that they weren't interested in giving tours until someone asked, and they figured out they could make a profit. Pretty reasonable to expect a ticket, even if it isn't free. reply j16sdiz 8 hours agorootparentI guess the annoyance is they said never, changed their mind, and auction the ticket off. If I were the factory owner, I would reserve a ticket for him and give a discounted price to thank for his idea. reply flycaliguy 6 hours agorootparentDepending on the trade secrets involved it could be a paranoid choice made in an area that rewards paranoia. Maybe having somebody reach out for a tour was just red flaggy enough. I agree it’s weird and kind of crummy to then offer an auction up. reply seoulmetro 7 hours agorootparentprevYeah I felt sour but I didn't really have any reason to in today's modern world. I shouldn't expect the human I talked with to actually care. reply seoulmetro 8 hours agorootparentprevThat's not why I felt sour. My original request even offered to pay for it. reply ukuina 5 hours agorootparentCould you not participate in the auction? reply seoulmetro 3 hours agorootparentI found out well after unfortunately. And tickets were sold pretty damn fast. reply riwsky 5 hours agorootparentprevThat’s the way the cookie crumbles. reply exreddit 12 hours agoprevFigured I'd share this since its comp info you don't normally see. A lot of people made a lot of money today. I got 150,000 options for Reddit very early after it was spun out. With today's price, that's $7.5M, but I didn't get all 4 years of vesting, the pay was below-average, and my money was tied up. During the same decade, the faangs were up 12x on average, but the pay was better, and my money would have been liquid. Reddit might not hold up for 6 months, either. reply fragmede 8 hours agoparentWhy didn't you take a deal with a secondary market buyer? Quid or SecFi or whatever reply krallja 8 hours agorootparentRegardless of what price they quote in their emails, I’ve heard that Quid will only loan you a quarter of the FMV of your shares, at 15% APR (deferred) — plus 5.5% of your shares outright, which increases annually. It sounds like a horrible deal. reply fragmede 8 hours agorootparent100% of $0 is $0. Even 25% of $7.4m is $1.8m reply mattmanser 3 hours agorootparentDid you miss the key words of LOAN and 15% APR? reply toomuchtodo 7 hours agoparentprevThanks for sharing, always fascinating to see different lottery tickets. reply 8ig8 12 hours agoprevI came to Reddit via Alien Blue and stayed via Apollo. Now I check a few subs periodically in a browser, but my usage has drastically dropped without Apollo. reply Lammy 12 hours agoparentHave you updated past iOS 17.0? If not: — Install AppStore++ for TrollStore: https://github.com/CokePokes/AppStorePlus-TrollStore — Install Apollo from the App Store — Open AppStore++, tap Apollo, tap downgrade, choose 1.15.11 — Go to your home screen and wait for the older Apollo to finish downloading — Install this tweak: https://github.com/JeffreyCA/Apollo-ImprovedCustomApi Open Apollo and it will prompt for your API keys — Stebe Jovs voice “Boom.” reply replwoacause 12 hours agoparentprevSame, I quit using Reddit when they killed Apollo. Their app is terrible. reply alsetmusic 6 hours agorootparentIt’s what pushed me to Lemmy, which feels like Reddit early days. Actual discussion. Names that I recognize from one post to another. It’s worth checking out. For this crowd, you might like my (not my own, but where I joined) instance: lemmy.sdf.org reply hnick 10 hours agoparentprevLargely the same here. Feel like I noticed a further decline in quality on the site after that happened too. It is useful for news aggregation but I don't like the discussion as much. But that could just be the trend continuing. reply SpecialistK 9 hours agorootparentI noticed the \"eternal September\" happening in years prior, as Reddit became more acceptable to the wider public and as a smartphone app rather than a forum host mostly for techies. And with those \"normies\" came the low-effort posts that totally ignored things like stickied posts, subreddit rules, and the overall culture of the community (or site.) Take a look at /r/roms, for example. The sidebar, the top announcement sticky, the rules, and the automod on every single post says \"here is where they are\" and what is most of the subreddit? \"How do I find game\" - same thing for BuildaPC, or Tech Support, or Linux. Then the mods have to remove the low effort posts and get called names, or they get upset that the resources they've taken time to make available to the community are ignored for the 500th time and blow up, just to get called more names or even censured by the admins. The only way to win is to not play. And that's why I use a combination of HN and an RSS reader now. reply hnick 9 hours agorootparentIt definitely started years ago, probably around the time I really started using it. I visit /r/games sometimes and they have stickies around what you have been playing or game suggestions and without fail someone doesn't even read the topic at hand and just posts a random question. Apps were mostly bad at showing sidebars too, they wanted to streamline the main view. They were there but I think a lot of users didn't know. Anecdotally I seem to notice a trend on how grammatical/spelling corrections are received. If people generally accept them in good grace as a chance to improve, discussion quality can be decent. If they take it as a personal attack, or other people pile on (often with the classic \"no one cares\") ... well that's Reddit these days usually. reply Seattle3503 12 hours agoparentprevI used RIF. When that shut down I started checking in on my various accounts much less often. Multiple of my 500k+ user subreddits have been banned for being unmoderated since then. Ah well. reply Fatnino 12 hours agorootparentYou can make RIF work again using vanced. You create your own api key and swap it in to the apk and then it works again. reply Seattle3503 10 hours agorootparentDoes it work now? When I tried that a couple of months ago it was broken. reply Fatnino 7 hours agorootparentI use it all the time now. If you want NSFW to work, you need to be a mod of a subreddit. Any sub, even one you make yourself with no posts ever. reply thrdbndndn 6 hours agorootparentI'm using Vanced-RIF rn, it works fine most of time but has some small problems (e.g. if you open a Reddit link in a comment, it would crash). I don't know if RIF-vanced still gets any \"updates\" to fix these minor issues? I assume not, but never checked. reply zem 7 hours agoparentprevi use old.reddit on both desktop and mobile. if they ever break that i'm gone. reply diggan 19 hours agoprev> Reddit the site (and now app) is such a fundamentally useful thing that it's almost unkillable. Looking forward to see how true this is. The communities I used to frequent, have maybe 20% of the activity they used to, before the API fiasco, even though they're \"back online\". I also stopped using reddit on the phone after my chosen reddit client was closed down (which I'm grateful for, thanks reddit). My reddit activity probably dropped way below half compared to before, as the communities I used to be in are now shells of their former glory. reply bane 12 hours agoparentI think Paul's right in the sense that reddit seems to thrive as a community when the smallest amount of effort is put into running it. The series of leadership horror shows that all mostly left the site alone demonstrates that. The recent very active moves to clean the site up and prep for this IPO have had a detrimental community effect in the sense of disgruntlement, but I would wager have been excellent in making the site more palatable as a business. Virtually none of the reddit-alternatives that all spun up in the wake of this mop job have taken off. So assuming our gut feeling is right that reddit engagement is down, then overall engagement on all reddits is down and users have entirely moved to other social media styles entirely. There's the other angle on this, that engagement is down, but it was calculated to get rid of mostly users who cost reddit things, or are of an undesirable user population (troublesome, illegal, etc.) And what's left is mostly a user class that maximizes the monetary value that can be harvested. There are huge and obvious areas where reddit can better monetize the site if they wished, and I would guess that it's going to happen. Reddit has a very long history of doing a bunch of different experiments with the site, and an influx of investment to properly analyze and then monetize the more successful ones is my guess as to what's going to happen. The recent drive to vacuum up and sell data to LLM companies is serendipitous icing right now. There's also the huge opening that's happening right now with Twitter, where with a few chess moves, Reddit could very easily turn into or pick up the population of exTwitter users who find the current ownership trends so toxic they don't want to be associated with it any longer, but don't have a platform with a built in non-friends public sphere to turn to -- which is why Facebook hasn't been able to really tap into that market gap. reply noobermin 8 hours agorootparent>Virtually none of the reddit-alternatives that all spun up in the wake of this mop job have taken off. You forgot about random discords, which is where they went. reply klabb3 7 hours agorootparentUnderrated observation. Discord has stayed in the shadows to the wider audience but in terms of quality content and community building, from my POV it’s already surpassed Reddit’s peak. I don’t like that it’s yet another proprietary platform, and the ownership/business side is shady to say the least. But man, the product is light years ahead in almost every respect, except (importantly) discoverability. reply klabb3 7 hours agorootparentprev> And what's left is mostly a user class that maximizes the monetary value that can be harvested. Yes, probably, but the user based changed dramatically before this. Since 2019 MAU more than doubled. I deleted my 11y old account after the last debacle. It was in the ~8th percentile of oldest accounts. That’s mind blowing, because I was by no means an early adopter. The drop in signal-to-noise ratio has been dramatic over the years. The interesting, nerdy and quirky is drowned completely by memes, political rage bait, staged sob stories, etc. Which is fine for short term business, but also makes it replaceable. Attention brokerage is “daily fix” business, loyalty is near zero, and competition is fierce. So every time someone argues a decision is good for business, it needs to be qualified by time and risk. If you sell your house to buy Nvidia calls, is that good for your personal finance? reply Eisenstein 8 hours agorootparentprevReddit gets its value from the users that were affected and pissed off by the recent events. Calling the moderators who created and continued to foster communities which exist to farm content for the company 'landed gentry' and telling them that their concerns over being able to work with a broken and incomplete toolset in their terrible app were not worthy of even a good faith conversation caused an irreconcilable awareness of exactly what they meant to in the reddit equation. You don't ever want to do that -- let people who work hard to create value for you live under the illusion (and often reality) that they are doing it for themselves and for their fellow community members, and they will happily break their backs for you and praise your platform. But if you make it obvious what you really want from them, they will realize how much energy it takes to deal with all of the moderation and cultivation and when they reach that point when one too many people called them a Nazi for removing a low effort post they look in the mirror and go 'why am I doing this' and you lose them. Sure, it works to immediately cull a lot of the 'whiners who only cause you problems' but you end up bleeding the people who do irreplaceably valuable work for you for free, and your platform becomes a cesspool of low-effort crap and you can see that happening in real time. They killed their golden goose. But they got their IPO and spez is gonna cash out and wash his hands of all of it and get congrats from his silicon valley buddies and go to sleep at night thinking how much those ungrateful idiots used his platform for free and didn't understand reality and how people like him needed to be rewarded for their work. All the while ignoring the fact that he is actually just a terrible businessman who, if he hadn't met Paul Graham and given free money and an idea and hadn't gotten incredibly lucky that digg imploded at exactly the right time, he would be an upper middle class suburbanite making a living wage working as a salesman for a SaaS company or something. reply gspencley 16 hours agoparentprevI was very late to the Reddit party and created my first account a year or two ago. I posted a little bit and then one day had a big red banner on the top telling me that my account was suspended for violating the TOS (my posts were on a puppetry subreddit about puppets and were very \"normal\" posts... how I could have violated the TOS was beyond me). I immediately appealed and the suspension was lifted (without any explanation as to what caused my account to be suspended in the first place). But even though my account is able to post and do everything a non-suspended account can, there's still that red banner at the top every time I access the website telling me my account was suspended and to check my inbox messages for instructions on how to appeal. That user experience kind of killed any desire of mine to ever use Reddit again. reply Terr_ 15 hours agorootparentI have a similarly buggy experience: My 13-year old account with zero history of problems (and incidentally 500k comment karma) was randomly shadowbanned. I used their appeal page, got a message apologizing and saying my appeal was granted... ... But it's still shadowbanned and everything I ever wrote over those years is still gone, except now the appeals page doesn't even work because it claims my account is in good standing. So I went looking for some kind of human help or support, but another old Reddit account (a resurrected job search throwaway from 5+ years ago) got immediately killed the exact same way, the lying \"granted\" appeal and all! It certainly revitalized my interest in using personal-blogging for information instead of contributing anything to Reddit's decaying ecosystem. reply Max-Ganz-II 12 hours agorootparentRather the same here. A month or two after my main account was banned (see my other post in this thread), I logged into a second account which I'd not logged into for months. Upon logging in, I discovered the account was \"permanently suspended\", and the reason for this was, and I quote; \"Your account has been permanently suspended for .\" reply akoboldfrying 10 hours agorootparentMaybe next time you'll think twice before you . reply zem 7 hours agorootparenti thought it was only a problem if you a coke bottle! reply unshavedyak 19 hours agoparentprevYea, i stopped using it from mobile entirely when that happened. I expect them to kill `old.reddit` soon any that'll be the end of that for me. ATProto is far more interesting to me, if/when someone makes a link aggregator for them rather than the Twitter style UI of Bluesky. ActivityPub will do in a pinch, if needed. (i already tested this idea, for ~60 days with zero Reddit) reply WA9ACE 19 hours agorootparentOld style interface on a development focused lemmy instance has completely replaced reddit usage for me This is the equivalent of /r/all across the lemmy world https://old.programming.dev/?sort=Active&listingType=All reply account42 18 hours agorootparentHow's the built in censorship and cultural bias with Lemmy? reply runjake 18 hours agorootparentIt definitely seems to lean left, from my (American) view. That might be because most of the western world would classify as left by my (American) standards? There have been some right-wing and far-right instances, but they seem to get de-federated by the majority. Hope that helps. reply concordDance 17 hours agorootparent\"Left\" and \"right\" tend to decoher once you move outside a particular political space into another (e.g. one country to another). The UK right wing party introduced gay marriage, but even the most left wing part of the country (Scotland) isn't particularly progressive (e.g. majority disapproval of allowing gender self identification to 16). Similarly, trying to judge the UK on racial issues by US standards gets quite confusing. The common British attitude towards Romani would make even the confederate flag wavers of Texas call them racists. On the other hand, there's full support for plenty of state intervention and state support, e.g. pretty much no one says they want to abolish the NHS. reply antod 12 hours agorootparent> Similarly, trying to judge the UK on racial issues by US standards gets quite confusing. The common British attitude towards Romani would make even the confederate flag wavers of Texas call them racists. Not directly related to Romani treatment in Britain (not familiar enough with that to judge), but sometimes I wonder if the english language needs better words to distinguish between race based bigotry and culture based bigotry. eg often I notice for a person there will be a difference in how they treat/view \"acclimatised\" descendants of immigrants vs new immigrants due to being ostensibly the same race but different culturally. Of course racists will still have bigotry for both groups. reply whatshisface 9 hours agorootparentThe word I think you're searching for is, \"xenophobia.\" reply concordDance 11 hours agorootparentprev> sometimes I wonder if the english language needs better words Words like this are not bad by coincidence, they're bad because they're incredibly politically important words and thus have their meanings and connotations fought over intensely. It doesn't matter what new word or words you try and put in place, if they relate to things people have different strong feelings on then the meanings will become messy over time. reply lazyasciiart 10 hours agorootparentprev> The common British attitude towards Romani would make even the confederate flag wavers of Texas call them racists. I think you are misjudging the confederate flag wavers, what makes you say this? reply 1oooqooq 18 hours agorootparentprevit's awful. it's like a single reddit. the instances are atomic, so you get world-moderators, who are all \"tankies\" in lemmy own parlance (left, communist, heavily sided with russia as ussr continuity) very toxic place. kinda like bizarro TwitterX. reply thereticent 18 hours agorootparentIf you use lemmy.ml, sure. Or if you don't curate a frontpage of your own topics, sure. But I joined through some unaligned Scandinavian instance, found topics I like, and stay away from the /r/all equivalent, and it's just as tolerable as Reddit, if less populous. reply diggan 18 hours agorootparentprevIsn't it federated? How could global moderators decide what's visible on all instances? reply 1oooqooq 18 hours agorootparentfederated is a meaningless word. reply luuurker 9 hours agorootparentprevI joined a instance focused on Android and follow another \"mainstream\" sub, and don't see that. There are some instances that are very \"tankie\" learning though... I avoid them, like I avoid any far right/left subs on reddit. reply huytersd 18 hours agorootparentprevGood, it leans left, but not so far left that it’s just LGBTQ/feminist spam. It doesn’t have a bunch of right wing trolls so far. It’s like the early days of Reddit. reply piaste 18 hours agorootparent> Good, it leans left, but not so far left that it’s just LGBTQ/feminist spam. It's not quite _spam_ but I think it's fair to say it's much more left-leaning than mainstream Reddit. Some of the biggest communities, even non-political ones, are on instances such as Blåhaj (LGBTQ-oriented), Lemmy.ML (Marxist-oriented), Hexbear (Marxists on meth). Short of subscribing to a defederated instance, you need to go out of your way to avoid left-wing content on Lemmy. Whereas on Reddit you could get rid of most of it by unsubscribing from the top 100 subreddits - which is something you wanted to do anyway for the sake of quality, even if you were the world's biggest leftist. reply whatshisface 9 hours agorootparentThere's a really good quip here about how leftwingers are naturally the most likely candidates to give away free web forums instead of trying to run web forum businesses, but I'm keeping it subscribers-only. reply ecshafer 18 hours agorootparentprevThe early days of Reddit was heavily libertarian, if only reddit voted in 2008 and 2012, Ron Paul would have been a two term president. reply thereticent 18 hours agorootparentThat's correct. When people speak of the early days of Reddit it seems like they are talking about whatever time long ago they initially joined. I'm always hesitant to make accounts on new sites, so I thought I had waited a long time to join officially, but I ended up being in the first 500 accounts! From the earliest days (the del.icio.us to Reddit influx) it was a very libertarian place. Sometimes annoyingly so. Reddit has shifted so many times over the nearly 2 decades, but most who stay for a long time have realized that it's great for pocket communities in smaller subreddits, as long as they last and aren't co-opted. The bots are the worst part at the moment. reply crmd 15 hours agorootparentprevI remember in the early days of reddit there was a guy who would post links to his Austrian economics / Murray Rothbard blog every day, and they would end up on the front page because they had like 50 upvotes. reply huytersd 16 hours agorootparentprevIt was a pretty left leaning libertarian though. As soon as those racist papers he authored came out he quickly fell off of Reddit’s radar. Not to mention, he co-opted at lot of the left’s iconography with his re”love”ution campaign. reply europeanNyan 18 hours agorootparentprevIt looks like Old Reddit, but the content is New Reddit. It's just a stream of political dreck and virtue signalling. I really don't need to see Trump in every second post and read about people who hate cars, meat, Twitter, Reddit, etc. reply piaste 18 hours agorootparentYeah, Lemmy is a pretty decent platform but the suggestion of browsing \"All\" is godawful, if one is looking for something closer to pre-smartphone internet. You need to curate your homepage a bit to get a good Lemmy experience. The tech side may be like Reddit, but the human aspect is more like a couple dozen vBulletin forums rolled into one. Some of the instances are (imo) full of straight-up insane and, worse, perpetually angry people. Some instance admins may be power-hungry and prone to drama - but you might not care if the only subreddit you follow from their instance is c/jazz and you just click on Youtube/Spotify links from it. Is it a pain? Yes. But I still prefer to deal with a couple dozen weirdos than with a single billion-dollar company. reply dingnuts 17 hours agorootparent>Some of the instances are (imo) full of straight-up insane and, worse, perpetually angry people This has been true for every instance of every Fedi thing I've ever tried to use or thought of using. And many instances block single-user instances so forget about running your own unless you only want to interact with the absolute fringest nutjob basement-dwellers -- because the \"mainstream\" Fedi is already fringe. I once had the dumb impulse to reply to someone who was mad about fluoride in drinking water with \"you probably get more fluoride from your toothpaste\" and I deleted my account as I started to receive arguments about brushing your teeth, as it made me realize exactly the kind of people I would be interacting with on this network. Honestly I think this is grows out of the incentives for operating a homeserver. There's a negative financial incentive so you must have some other kind of motivator, likely a desire for influence or power. reply mardef 17 hours agorootparentSimilarly, I replied to someone suggesting they pay for a service and I received multiple replies suggesting I kill myself. This wasn't on some random Marxist community, this was on one of the big tech communities. reply bombcar 16 hours agorootparentInternet death threats are so common and boring that I only notice the amusingly new ones, like “I hope you can take advantage of Canadian healthcare.” reply ctrw 17 hours agorootparentprevThe way to save the internet is to force everyone to have a recent picture of themselves next to any post they make. reply chownie 16 hours agorootparentThat would almost certainly end up with the internet becoming one gigantic linkedin and everyone leaving it to flock to whichever underground 4chan-esque service pops up with a promise of pseudonymity. reply karmakurtisaani 13 hours agorootparentprevIs that why Facebook is such a nice and balanced website? reply ctrw 12 hours agorootparentYou uncle McRacy doesn't have 200,000 followers. Your cousin McFatt does. reply rglullis 12 hours agorootparentprevSorry to say \"you are holding it wrong\", but browsing by all is just terrible. Much like reddit, things improve a lot if you subscribe to the communities that interest you and ignore everything else. Granted, Lemmy's issue is that the user base is not large enough to have developed a long tail of interesting communities, but hopefully this will change as it grows. Also, I know that finding the communities is difficult, so I've put together a website to work as a crowdsource of reddit-to-lemmy communities, https://fediverser.network reply dzikimarian 16 hours agorootparentprevHate is keyword here. I really wanted to like Lemmy, but almost all instances are full of frustrated hateful people. Even if sometimes rightfully it's still to toxic. Wild tankies appearing here and there are no help either. reply Goronmon 18 hours agorootparentprevI really don't need to see Trump in every second post and read about people who hate cars, meat, Twitter, Reddit, etc. Exactly. All I see online is people talking about politics, their jobs, their families, their hobbies, the environment, technology, etc. reply jcrash 17 hours agorootparentprevThanks for this link, this is great reply account42 18 hours agorootparentprev> I expect them to kill `old.reddit` soon They have already started to redirect direct image links to the new reddit garbage which has stopped my usage for reddit for entertainment when bored. reply agmater 17 hours agorootparenthttps://addons.mozilla.org/en-US/firefox/addon/load-reddit-i... This solved that for me, but yeah it seems inevitable that all these user hostile decisions make the site unusable. reply giancarlostoro 18 hours agorootparentprevWhat kills me about old vs new reddit is feature parity is just not there. There's also a huge lack of tooling for reddit modding, but what really kills me is how long new reddit has been in development for and still no feature parity. Instead of making old reddit an archive on github, they should have made new reddits front-end open. I'm sure it would be miles ahead if the users were allowed to contribute like they once did with old reddit. I wonder how much money was spent to build new reddit. Feels like a dumpster fire. reply mrmlz 19 hours agorootparentprevModern Reddit is such a broken experience especially on the web. And honestly the community has degraded over the last couple of years. reply pixl97 8 hours agorootparentAnd the number of bots is out of control. I'm guessing they are accounts that pretend to be regular users by copying other user comments on the same topic and posting them days/weeks later when the topic gets brought up again. Then I assume at some point in the future they'll be sold off to spammers or manipulators of some kind. reply mnky9800n 16 hours agoparentprevIt's a great time to do an ipo so people can cash out if they can (or just take a ridiculously sized salary). It's a terrible time to be a Reddit user. It seems like there's almost nothing left of content. And if you look at the front page then you see mostly just rage bait, relationship advice requests that can't possibly be true, and whatever video games are currently the most popular. There's almost no content more engaging then anything in a tiktok or Instagram feed. Nothing is memorable or filled with discussion. It's mostly filler. Sad really. I used to quite enjoy having discussions on various topics there. These days it's all noise. reply dogcomplex 13 hours agorootparentReddit sells the illusion of meaningful discussion in an online forum. Too bad that illusion is transparent, but where else can you get one - besides maybe here? reply Terr_ 8 hours agorootparentIt's not all illusion though, particularly in smaller communities. reply pixl97 8 hours agorootparentThe big subs are seemingly filled to the brim with both post and comment repost bots. It's fun when they mess up and you see a few accounts post the same comments in the same thread then search and the comment was an actual users comment from days earlier. reply swed420 11 hours agorootparentprevAgreed. I only tolerate reddit (for now) because it's always been better than Twitter/X and the alternatives haven't matured yet. reply vanadium 15 hours agoparentprevAfter they killed Apollo, my usage after 15 years went from hours a day and tanked to a few minutes a month at present. They showed their hand, and I showed myself the door for the most part. When the email dropped that I was one of the early users offered entrance into the IPO, I pretty much ignored it. reply 1oooqooq 18 hours agoparentprevshells? they are more likely crap filled boxes of their former glory. communities even remotely related to companies (e.g. r/googlepixel) are run by either fervently crazy zealot fans, or which is more likely, filtered by interns in those companies marketing dept in what seem to be reddit best revenue stream. reply shufflerofrocks 4 hours agoparentprevCompletely agree with you. My circle & I have stopped reddit on phone almost completely. So many active posters have left reddit, that it is a shell of what it previously was. Some of my favorite subreddits have become inactive and shallower, to the point that admins are actively boosting up alternate subreddits From what I can gather, the large majority of the remaining active users in the site are people who use reddit as alternative to 9Gag & Porn sites - prolly hyperbole, but that is what the new r/all felt like reply bun_terminator 16 hours agoparentprev> have maybe 20% of the activity they used to, before the API fiasco Is that really true? I have been on reddit since day 0 and have noticed 0 change, absolutely nothing. Some communities went through a \"we're now on lemmy\" phase. But even that went nowhere. Reddit is still plagued by mods and all the other things, but the userbase is as powerful as ever reply diggan 16 hours agorootparentMaybe it's because my user is \"only\" 12 years old, but there is definitely a big difference in quality of the discussions and the activity today compared to 2-3 years ago, at least in the communities I hang around mostly (music production, 3D, animation and adjacent creative areas). reply rd 16 hours agorootparentQuality discussions and activity don't drive normie usage, and that's what Reddit's optimizing for at this point. Feels like they want to be TikTok, but for links and images, and even the links part is slowly dying. I wouldn't be surprised if you ran an analysis of the makeup of hot-page content across the biggest subs, if links used to make up 90%, that that number has slowly been dropping for the past 5 years to now be mostly images. reply seanhunter 16 hours agorootparentprevAnecdotal of course. I used to read for hours each day and post from time to time - I haven't even looked at it for months except a couple of days ago where I had to prep for a business meeting where reddit was relevant. I had been feeling for a long time that it was declining and also that my social media usage wasn't really adding anything positive so the API thing was just a convenient excuse to rip off the band-aid. reply bombcar 16 hours agorootparentprevI used to be a heavy user, I rarely read it now and then. I certainly never post, and my accounts are deleted or inactive. It still turns up in search results for me but it’s certainly no community I’m using. If there is a stereotypical Reddit user, then they’re stagnating. reply SpecialistK 9 hours agorootparentprevI used to be a mod on a large tech subreddit, and Reddit's mod dashboard actually did show user traffic analytics. In the time between the API meltdown and my finally deleting my account, visits to the sub fell by about 30%. reply pixl97 8 hours agorootparentprev>but the userbase is as powerful as ever Sure about that? Start looking for bots that repost other peoples comments and we may find that questionable. reply bun_terminator 2 hours agorootparentSure the bots are a problem, but that didn't arise with the API changes in my experience. reply quatrefoil 17 hours agoparentprevThe API situation seemed baffling to me at the time. The timing wasn't coincidental and it was clear that they were responding to people training LLMs on the Reddit corpus. But here's the thing: prevailing HN sentiments notwithstanding, your average Redditor leans left and is fairly anti-big-tech, so Reddit could have leveraged this angle. They could've said it's a pro-user move to stop OpenAI and the likes from unfairly profiting off your work. And most users would have applauded. But Reddit didn't say that. They took a PR hit and decided to wait it out. The cynical explanation was that they were actually just trying to get some of that LLM money for themselves. And not long ago, they announced a big deal with Google to give access to user data for training purposes: https://www.reuters.com/technology/reddit-ai-content-licensi... Frankly, I was on the fence about the API access thing until the motivation became clear. reply BHSPitMonkey 16 hours agorootparentThis doesn't track. They spent a lot of time and energy coordinating with the authors of popular mobile clients, and could easily have extended some means of letting them continue to operate given that they were clearly not harvesting content for themselves. Meanwhile, content can still be harvested for LLM training without the API (by using the HTML site). It seems like the real intent was to regain control over the surfaces users use to consume the site, especially on mobile. reply quatrefoil 15 hours agorootparentScraping is a lot more dicey than using an official API. Why did Google enter that partnership? They have the data in their index. The only conceivable reason is that they prefer to pay Reddit to avoid the risk of litigating it and ending up with some unfavorable precedent. reply jtriangle 10 hours agorootparentThere's more than just the data you see remember, the data you don't see is also valuable. The DM's, the deleted posts, advertisingID's that link people to their accounts, and to their alt accounts, etc. reply Ekaros 15 hours agorootparentprevAvoid litigation and possibly of getting some injunction. And on other hand money can go to fund Reddit litigating others. As now they have proven someone paid so they could stop others using data. Slowing them down in process. And the sum is peanuts for Google, they waste that amount regularly... reply Terr_ 8 hours agorootparentprev> The timing wasn't coincidental and it was clear that they were responding to people training LLMs on the Reddit corpus. Hard disagree, they were lying about their motives, plain and simple. Their claimed motiviation doesn't match what they did/didn't actually do. For example, the biggest companies training LLMs could be dissuaded by simply changing the terms-of-service to prohibit that usage (skipping all that developer-labor and community protest) but Reddit didn't do that. (Dodgy companies that don't care aren't relevant since they'll just scrape the website even without API access.) In contrast, \"Reddit arbitrarily killed third-party apps to force their own app\" does match what the company implemented: Abrupt and punishing new fees, mandating that third-party apps can't contain any ads of their own, and making certain categories of content exclusive to their own app. reply segasaturn 17 hours agoparentprevThe site really took a nosedive in about the last 6 months in my experience, I think a combination of the API fiasco + current world events has really done a 1-2 punch on the site. The front page of reddit is a nightmare zone, it's all ragebait, clickbait, shit political memes and posts clearly made by marketing interns and boosted by bot accounts. Every comment section feels intensely ideological and any comment that strays from the majority opinion is downvoted to hell. Also loads of those tacky \"badges\" on comments everywhere making for a lot of visual clutter. Just an all around unpleasant to use site. PG calls the average reddit user \"curious, skeptical, ready to be amused\" which feels almost like the exact opposite of my experience. reply omginternets 11 hours agorootparentI’ve felt it too. I can’t fight the feeling that it happens to attract a certain kind of mentally ill person. Specifically, the preponderance of anxious, neurotic persons, often with a persecution complex and a militant ideology, is enormous. The result is a climate of unbridled vitriol and outright hate for whatever group they hold responsible for their woes. It increasingly feels like Reddit is a breeding ground for various types of extremism (usually left-leaning, with some notable exceptions). reply hnick 10 hours agorootparentPeople who seem to want to be offended. I hate the /s they've adopted. It ruins the joke by explaining it. I dislike the implication sarcasm cannot be conveyed via text. Hundreds of years of authorship and numerous popular works tell otherwise. But people do it to shield themselves from what sometimes feels like intentional misinterpretation. Showing votes is possibly a huge contributing factor. It's well known they gather momentum. reply bonton89 17 hours agorootparentprevI still use some tech subs but I used to dumbscroll the main page for inane things to laugh at. What was on there changed over time and it was well past the high point, but maybe a year or six months ago I just couldn't do it. The stuff you describe was always part of the /r/all mix but now that is all there is. There's nothing fun on there anymore, at all. lemmy is probably to left leaning for my taste but at least the main page still has lots inane and funny things as well as more of a tech focus. reply jeffcox 15 hours agoparentprevI was an active and fairly early Reddit user for many years, but the brutal changes to satisfy financial goals drove me away as well. I think it’s interesting to see a flagging platform with a user base that will consistently post and upvote “fuck spez” celebrated here as a success, but I suppose the only thing that matters at this level of discussion is the almighty dollar. reply majormajor 17 hours agoparentprev\"Killed\"/\"killable\" is one of those terms that changes with age. Was GM unkillable? Well, they aren't dead, but... Was Windows unkillable? Well, it's not dead, but... Is Facebook unkillable? Well, it's not dead, but... So the old fogies who would tell you GE, GM, IBM are all unkillable aren't wrong but neither were the younger folks they were responding to. Lotta zombies hang on long after their relevance fades for the future. \"X is unkillable\" is a good way to reveal a limited imagination for future changes. You go from talking about disruption to talking about how things are now disruption-proof! reply dghlsakjg 15 hours agorootparentYou have a strange definition of dead. I would love to have a company that has 1% the success of just Windows 11 which is estimated to be on 20% of all running PCs, let alone the rest of the MS empire. Selling 6.2 million vehicles in one year (GM) is hardly a zombie company. Meta had 40 billion dollars of net revenue, and 3 billion MAUs, which is a pretty fierce zombie if you ask me. IBM measures their profit in the billions too. Even GE is still spinning off billions in profit. All of the companies you mentioned have grown in the past 10 years. reply majormajor 13 hours agorootparent\"Strange definition\"? Isn't that literally what I said, that it changes definitions with age (and focus)? Which of those companies still have the influence they did at their peak? If you've got a startup, growth mindset, you're growing or you're dying. And even growth in revenue, headcount, profit, etc, can lag growth in relevance by decades. Got any interesting new GE projects on your radar you'd want to work on that you think will be relevant in 20 years? Do you think Paul Graham of twenty years ago would've called GE unkillable? It's the difference in ambition and goals that leads to one person loving to take over today's Microsoft (or Reddit) and another - probably much younger person - wanting to start tomorrow's. reply dghlsakjg 10 hours agorootparent> Which of those companies still have the influence they did at their peak? Facebook is accused of having way too much influence on society as a whole on a constant basis. MS is the money and computing power behind the hottest AI technology on earth. With Azure and AI they are arguably more influential than at any other time. GM runs Cruise, which is busy inventing self driving cars and implementing the rules. They are also the largest manufacturer in the US. Hardly uninfluential. > Got any interesting new GE projects on your radar you'd want to work on that you think will be relevant in 20 years? Floating wind turbines, automated grid controls, efficient jet engines, 3d printed jet engine parts, advanced mobile medical imaging at sports events, modular nuclear reactors all seem like they might be relevant 20 years from now. reply FredPret 17 hours agorootparentprevAll the examples you mention, GM, Facebook, and Windows, pump out a ton of money on the regular. GM made ten billion in profit in the last year reply majormajor 13 hours agorootparentWhich of them would you call unkillable? I think Graham is getting a bit sentimental and overly attached to incumbents in his network. reply FredPret 9 hours agorootparentNothing is completely unkillable, but a company / tech doesn't have to be sexy, new, or fast-growing to be entirely viable or wildly profitable. See: GM, MS Excel, banks. reply spelunker 19 hours agoparentprevAs an opposite anecdote, I probably use it as much now as before the API stuff. reply Workaccount2 19 hours agoparentprevI had (have?) a twelve year account, coming on the tails of the digg fallout. Once they pulled the API I was out. Not terrible since the site's quality has been in steady decline for years. Eventually you realize you are doing the equivalent of having economics discussions in the youtube comments of a taylor swift video. But it seems that lowest common denominator user is who reddit really wants, so good luck to them. reply dotnet00 16 hours agoparentprevAgreed, I was thinking that the API protest and the crackdown Reddit perpetrated wouldn't end up actually doing much (did still delete my account though, partly as an excuse to break the habit), and while to an extent that's true, I've noticed many more deleted or edited comments than I used to pre-crackdown. It really did drive off a lot of positive contributors. reply aerhardt 19 hours agoparentprevI’m on a similar boat, but for all we know, for each of us there might be ten new users who have recently flocked to the site and don’t give a damn. reply jtriangle 18 hours agorootparentNot all users are created equal. Reddit's lost a ton of valuable contributors, via enshitification, and I only expect that to get worse. reply ornornor 17 hours agoparentprev> I also stopped using reddit on the phone after my chosen reddit client was closed down (which I'm grateful for, thanks reddit). Same here, very grateful for Reddit’s API changes. It made me realize how little value Reddit actually provided vs time spent. I refuse to use their dumpster fire of an app so I quit altogether and deleted my very old account + comments. Good riddance after all, for each “niche” subreddit I was on, I have found very active forums and communities to replace these subreddits. And they’re independent forums that are very old (in internet terms) with lots of passionate people sharing very valuable information. Turns out I didn’t really need Reddit at all but it took their shortsighted hara-kiri for me to realize. Oh well, thanks Greeddit! reply omginternets 11 hours agorootparentHave you found any generalizable methods for finding non-Reddit communities for niche interests? reply ornornor 4 hours agorootparentI search for “$topic forum” or “$topic community” and there will typically be something in the first 10 results. There is a little trial and error involved, I check which one of the forums has been around for a while (10+ years works best for me) and still has regular activity (message volume + last posted messages) Sometimes it ends up being a discord chat as this is very popular. Not ideal as I don’t love the discord walled garden but still better than Reddit. And if/when they pull a Reddit in the future, well, I’ll cross that bridge when I get to it. I should add that in getting much better results for these queries since switching to kagi. Ddg and startpage had more spam/SEO/generated junk in the top results. It was more effort to find these communities on those but not impossible either. reply kspacewalk2 18 hours agoparentprevI don't notice this at all. Old communities die off and new ones spring up all the time, and the new ones are still springing up alright. The local subs are doing well, there are still plenty of \"less popular\" subs to have great discussions in. The app is not great not terrible, no biggie. They rather consciously decided that jettisoning some hard-core techies, privacy people and other \"weirdos\" is an acceptable price to pay for more mass appeal and more profitability. Remember, you as a user are not the client of Reddit Inc, you're the product. You or I may not like that direction, but we're not great products anyway. I block ads for Pete's sake, I am literally worthless to them. reply vwoolf 18 hours agoparentprevI liked it better before the modern Reddit censorship machine. At least old.reddit.com still works. For now. reply piva00 19 hours agoparentprevQuite similar experience, the communities for hobbies I used to check out almost daily are quite dead, they've become mostly a gear-showoff or beginner questions forum, the real content in longer form that some old posters used to create is mostly gone. My own activity dropped like a rock after the API changes killed Apollo, the mobile client I used (and before that reddit had already acqui-killed a previous one Alien Blue). I simply check it out of habit, and mostly for news, don't have much of the joy I had when I had started accessing it back in 2009. Probably it's just the natural cycle of profit-driven social media getting swallowed by Eternal Septembers after the initial batches of users posting interesting content and making the platform cool leave the place when the platform inevitably becomes user-hostile. reply jabroni_salad 12 hours agorootparentYou can pretty much graduate yourself beyond the expertise of any outdooring subreddit by walking through a city park and any car-based subreddit by actually owning a car. I've been thinking about this and trad forums witht he ability to bump a topic and keep it going for as long as there is interest really makes it the best venue for hobbies. I spent a good half hour on vwvortex the other day just surfing longer threads and learned more from that than anything reddit can offer. It can be a little annoying when somebody tries to tack on an unrelated question to a thread but apparently the only alternative is to have 15 iterations of 'I just found out outside exist, what do?' every day. reply the_af 18 hours agorootparentprev> Quite similar experience, the communities for hobbies I used to check out almost daily are quite dead I've noticed some of the same for some communities, but where have they gone? Some claim to be migrating to Discord, which in my mind is even worse than Reddit, and to me is a high-stress environment (I simply cannot stand online chat, I've no patience for it, and if you're not constantly online you miss stuff). There are hobby groups in Facebook, which is also disappointing since Facebook groups have terrible UX. reply account42 18 hours agorootparentDiscord is probably the biggest black hole sucking up all kinds of communities right now but that doesn't mean that there aren't others. Old-school forums are still a thing even if less visible these days. reply simonmic 15 hours agorootparentprevSome communities move to discourse forums. reply ProllyInfamous 17 hours agorootparentprev>I simply check it out of habit Adding *.reddit.com to my DNS-blacklist was one of the single-most-productive \"lines of code\" I've ever added to my personal computer. Cold-turkey, I quit. /r/Supermod, 2010-2014, \"the pineapple trees guy; erryday\" reply monkeynotes 17 hours agoparentprevReddit is a cesspit of its former self. The OG reddit is far from what it used to be. It's no longer an innocent link sharing platform, it's a socio-political platform with so much slime in between the subs that I find useful. Try and use Reddit daily and ignore all the drama, political shit, and covert rage click posts. It's emotionally exhausting not to get pulled in and have to constantly triage your home feed. I have deleted my account at least half a dozen times and just tried to use it as a source of useful information, but I inevitably fall into the pit of getting another account because I can't control myself objecting to the nasty stuff on there. I know this is partly my self control problem, but social media in general is just awful. I can get rid of FB easily, there is literally no benefit for me being on there, but Reddit legit has useful content about all of my hobbies and how to do X. It is unkillable but for some pretty rotten reasons. It's a social media platform mixed in with really useful content. Come for the search result, stay for the drama is what happens to me. reply QuantumG 8 hours agorootparentOne thing that happened was the anti-tracking movement provided a better interface. They have their own comment sections that are somewhat better than the actual site. Bifurcation ensues. reply omginternets 11 hours agorootparentprev> socio-political platform with so much slime in between the subs that I find useful. That’s putting it nicely! I’m increasingly seeing it as a breeding ground for fringe-left radicalization. reply threeio 17 hours agoparentprevStopped going to the site/app completely... they were so far off base with the API war it wasn't worth it. reply smackeyacky 12 hours agoparentprevHow much of that is Reddit and how much of it is that all online communities have a definite lifecycle. Either they age out, or they become too popular and become useless. reply dogleash 18 hours agoparentprevIt'll shamble on forever. Look at the front page in a private tab right now. Yeah it's all dogshit content, but this is the product now. All the niche communities that made reddit good were dying a slow death well before any of the API stuff. That old product is dead, the current reddit will live forever as long as they can get costs under control. reply jeffwask 16 hours agoparentprevSame thing as Twitter, they think the power of these sites is the tech. It's not. It's the community and when you turn that into an EBTIDA growth engine it's going to rebel. reply TheIronMark 17 hours agoparentprevWe need something to replace it. Lemmy isn't quite there yet. reply mderazon 16 hours agorootparentIt could already but doesn't have enough users reply jherdman 16 hours agoparentprevI'm in the same boat. I only ever log in periodically to see what's going on with r/AskHistorians, and then promptly run away. reply Pokerface777 16 hours agoparentprev> > Reddit the site (and now app) they have been bugging you with the app for years reply holoduke 18 hours agoparentprevI quit last week with Reddit. I thought it might be a good idea to write a controversial opinion in a sub reddit. Received a perma ban. Well thanks. The content, the way the site works, dark patterns and its just not nice anymore. Happy to be loose. reply omginternets 11 hours agorootparentOut of curiosity, what was this fringe opinion? I think this is the elephant in the room when it comes to Reddit: it’s been captured by a certain kind of radical ideologue. reply holoduke 10 hours agorootparentIt was my opinion on the Russian war in Ukraine in worldnews. My opinion was not in line with the bubble and received a ban for spreading false information. reply swarnie 2 hours agorootparentWorldnews are pretty well known for banning anyone that looks at them funny; you're permitted exactly one correct opinion, deviation will lead to termination Comrade. reply ralfd 12 hours agorootparentprevWas it r/comics? reply mderazon 16 hours agorootparentprevHave you moved somewhere else? reply holoduke 15 hours agorootparentNo not really. Its maybe also a good time to get rid of that annoying addiction. Lots of time is wasted by browsing and using reddit. At least for me. reply Lalabadie 19 hours agoparentprevYeah, that's an affirmation from someone who's in a very pampered US-centric group of Reddit users (if he is that at all). \"My investment is very good!\" In the last year, Reddit has pushed localized home pages across the world, and my own example is the default home page for Canada. It's now exclusively sports and right-wing nuttery. There were good communities, but they were molded by their good moderators, and these moderators are gone. reply Scoundreller 17 hours agorootparent> and my own example is the default home page for Canada. It's now exclusively sports and right-wing nuttery. I think that’s typical for any national sub, because it will be filled with people that live in places that don’t have the critical mass for a local/regional subreddit (or just don’t fit into it). reply Lalabadie 16 hours agorootparentI'm not talking about the /r/Canada subreddit, I'm talking about the complete front page feed for Canadian visitors. There are several \"main\" Canadian subreddits, and the only ones showing up for anon Canadian guests now are the right-wing and far-right subreddits. reply VancouverMan 15 hours agorootparentCan you be specific about these \"right-wing and far-right\" subreddits you're seeing on the front page? I'm not logged in (I don't have a Reddit account), I'm in Canada, and on the Reddit home page I'm currently seeing submissions associated with these Canada-specific subreddits: 6 for r/canada 2 for r/onguardforthee 2 for r/ontario 2 for r/PersonalFinanceCanada 1 for r/alberta 1 for r/vancouver None of those subreddits look \"right-wing\" or \"far-right\" to me in any way. In fact, I'm surprised at how left-leaning they tend to be, especially r/alberta. Of the current top five submissions there, four are for CBC articles, for example, and there are a few other CBC articles on the first page. r/onguardforthee seems to be overtly left wing. The other front page subreddits are broad (like r/AskReddit, r/politics, r/news), or about sports or hobbies (like r/gaming, r/baseball, r/hockey, r/FigureSkating). None the subreddits I'm seeing on the Reddit front page seem to me to even be right-of-centre, let alone \"right-wing\" or \"far-right\". reply omginternets 11 hours agorootparentIt’s quite common for redditors to consider anything short of far-left as being far-right. reply VancouverMan 17 hours agorootparentprev> my own example is the default home page for Canada. It's now exclusively sports and right-wing nuttery. Can you give some concrete examples of this \"right-wing nuttery\" you mention? I've heard other people in Canada make this claim, but whenever I visit the Reddit home page (without logging in; I don't have a Reddit account), I consistently see the opposite. Right now, for example, two of the top five submissions I see are CBC and Toronto Star articles complaining about Ontario's Conservative government's policies. (For those who are unfamiliar with them, CBC and the Toronto Star are among the most left wing of Canada's mainstream media.) Still in the top ten, there's an article complaining about how some corporate layoffs at Bell were conducted. There's an anti-Trump article, a article about Biden cancelling some student loan debt, and a complaint about \"the rich\" (Musk, specifically) in the top fifteen. Beyond that, there's a submission complaining about a landlord's behaviour, an article about urban planning in Vancouver, and the front page ends with a submission that's upset about some munitions company executive cutting down some trees in the US. The rest are about sports, oddities, or otherwise don't seem to be political in nature. I wouldn't consider any of the submissions I'm being shown to be obviously \"right-wing\" in any way. A number of them I'd consider to be centrist or neutral, if not left-of-centre. Several are overtly left wing. reply Lalabadie 15 hours agorootparentMy experience of cookie-less Reddit (and the reason I don't go anymore) is getting served default subreddits like /r/Canada_sub. I'm very open to being wrong or outdated in my impression, however! reply concordDance 17 hours agorootparentprev> In the last year, Reddit has pushed localized home pages across the world, and my own example is the default home page for Canada. I found this quite nice. A lot less American politics on the front page and some fun bits of local news. reply dncornholio 19 hours agoparentprevI would like to see some hard number from people that claim Reddit was hurt from the \"API Fiasco\". My theory is that this is a very small number of users with a very loud voice. Entitled mods were the only people that closed down subs. Most users did not even support this decision. Same is happening again now, entitled moderaters who complain about CEO pay. If anything is destroying Reddit, it's the mods IMO. reply diggan 18 hours agorootparent> I would like to see some hard number from people that claim Reddit was hurt from the \"API Fiasco\". Probably pretty hard to get. Some of the content I found that went away, was quality content. There are still users posting/discussing stuff in the niches I'm interested in, but all the high-quality discussions have gone missing, and the one's who used to engage in it no longer seem to be using reddit at all. But there is no objective way to measure \"high quality content vs low quality\", so it'll be short of impossible to get any objective measures of this, it's just my anecdotal experience with a subset of subreddits. reply Balvarez 18 hours agorootparentprevEntitled mods... you mean the people who work for free to make reddit work? I'm not a mod and I don't have very strong opinion of reddit moderators one way or another (many do), but I think reddit would do well not to make mods angry. They are an unpaid work force. reply hombre_fatal 17 hours agorootparentAnyone who has run a forum knows that mods are paid, usually with ego or duty or power, but they certainly get something from it. Else hundreds of people wouldn't want to be moderators of small phpbb forums much less thousands of people on reddit. Either way, I don't think compensation swivels the \"entitled, power-tripping reddit mod\" trope where they ban from their subreddit if you make a comment they disagree with. It's one of reddit's biggest problems. reply kbolino 12 hours agorootparentprevAs far as I can tell, the business model of modern social media is to make money by selling advertisers access to children, gamblers, addicts, and profligates. The content and moderation that people think is the purpose of social media doesn't actually make any money and never has. reply Seattle3503 12 hours agorootparentprevWell, my experience is only anecdotal, but after the third party apps shut down (RIF in my case) I checked reddit less, maybe once every few days. This wasn't a conscious decision or a protest. I tried the main Reddit app and hated it. One of the key draws to my active participation in Reddit had been killed. A number of subreddits I moderate were shutdown by reddit for being unmoderated. It turns out a lot of mods disengaged. None of the subreddits I was a part of were a part of the protests, but banning communities by moderators that disengaged achieved the same outcome as a protest effectively. Maybe someone has numbers for how many communities were banned for being unmoderated, and did this number increase after the API changes? reply nullindividual 18 hours agorootparentprevThe hypothesis without data is that users [mods/power users] who cared about reddit, who contributed to reddit, have largely left or disengaged to an extent. I would like to see numbers myself, though. However, looking at reddit/r/all, I suspect much of that activity is botting. I mean, no one can seriously post \"my gf cheated, AITAH for breaking up with her?\". Come on... reply badwolf 17 hours agorootparentSo many endless repost-bots :-/ reply piva00 18 hours agorootparentprevAt the same time, good moderation is what made reddit what it is, if there weren't mods doing free work for reddit in 2009 it would be flooded with YouTube comments style of content since that's what low friction posting without moderation achieves. reply dncornholio 18 hours agorootparentYeah but Reddit doesn't owe the mods anything, the users do. reply Starman_Jones 15 hours agorootparentThe dog doesn't owe anything to the hand that feeds it, but it would still do well not to bite it. reply mostlysimilar 18 hours agorootparentprevWhat? Reddit owes their entire platform to their volunteer moderators and users who contribute content. Reddit the company adds almost nothing of value, the tech isn't exactly special -- if anything it's so bad as to be hindrance. reply nazgulsenpai 19 hours agoprev> Aaron was younger, a college freshman, and even more anti-authority than Steve. It's not exaggerating to describe him as a martyr for what authority later did to him. I started reading this cynically curious if Aaron would even be mentioned, but well said. reply abadpoli 19 hours agoparentThe NPR piece on Reddit this morning stated it was founded by Steve Huffman and Alex Ohanian, and didn’t even mention Aaron Swartz. reply doodlebugging 17 hours agorootparentThis is probably because PG encouraged spez and kn0thing to pivot from their original idea and become founders of reddit in June 2005 and Aaron Swartz joined reddit in November 2005 after a conversation with PG, who suggested he work with spez and kn0thing on stabilizing the code since reddit had an early tendency to crash.[0] I found reddit back in 2005 and remember the post announcing that Aaron had joined the team and giving a bit of his background. Reddit was a lot different back then since there were no subreddits. [0]https://www.rollingstone.com/culture/culture-news/the-brilli... reply sparky_z 18 hours agorootparentprevHe wasn't really a founder though. He was brought in months later because his own startup idea hadn't got any traction. He's a founder only in the same way that Elon is a \"founder\" of Tesla - a retroactive title that was the result of a deal. reply rifty 15 hours agorootparentI suppose to make the title legitimate Elon should’ve formally started another company, and then acquired the other? It seems like getting in and operating in a pivotal way within the first 12 months is a valid time frame to still be given a founder title if the other founders agree to it. Since when you decide to incorporate is not consistently/necessarily at the same time for finalizing the foundational team members for a getting a company on its feet. reply FredPret 17 hours agorootparentprevThe Elon-hate is so crazy to me. He pitched in a lot of cash at a do-or-die moment in Tesla's history. He then served as the CEO and driving force through some extremely lean and tough years, including working like hell to raise capital (which isn't optional if you're making cars) Would we have Tesla today without Musk? No. Would electric cars be ubiquitous if it was up to the likes of Ford, GM, Mercedes, Toyota to push the tech? No. It is, of course, entirely OK to dislike him - but at least admit his contributions. reply thefaux 16 hours agorootparentThe whole point is that it isn't enough for him to be recognized for his contributions. He must rewrite history to paint himself as the singular genius while discounting the work of others who were also a part of the story. There is a messianic figure that he presents in his own self-mythologizing that I find dangerous and troubling. It is, of course, entirely OK to admire his contributions - but at least admit the dark side of his persona and the means he's used to achieved his ends. reply TMWNN 15 hours agorootparent>He must rewrite history to paint himself as the singular genius But that's closer to the truth in this case than anything else. It's not an exaggeration to say that all Musk gained when he joined Tesla seven months after the founding—bringing the first substantial amount of outside capital—was the brand name. reply joshmanders 16 hours agorootparentprevI agree with you on your comments about his contributions, but that doesn't mean he deserves the title of Founder of Tesla (Nor does Aaron, RIP). Neither of them FOUNDED the company, they joined in later on. reply jyxent 16 hours agorootparentprevHow is this Elon-hate? Is a founder someone who founded a company or someone who joined it later? Calling someone not a founder doesn't change their contributions to the company. reply jjulius 15 hours agorootparentprevNone of that makes him a founder, simple as that. You're blowing that comment out of proportion. reply FactKnower69 17 hours agorootparentprev>working like hell to raise capital Sounds like some really back breaking labor, was this during his 80 hour work weeks? reply FredPret 16 hours agorootparentYou're right - it's super easy to bounce around from one rich person to the next, trying to get fat cheques from them for your unproven and almost-certainly-going-to-fail hardware startup that would only work if enough other rich people also give you big cheques, based on nothing but a pinky-promise that you'll try your darndest to invent, manufacture, and sell cars well enough to get them their money back, one day, maybe, if all goes perfectly. Why don't you do it too? reply HaZeust 16 hours agorootparentprevRaising capital in a new industry sucks, lol. A cushy job is still a job, and the human brain does a REALLY good job at building the same amount of attrition across roles in relativity - whether you're breaking your back in the mine or cold-calling 400 people a day from a Herman Miller chair. reply babypuncher 15 hours agorootparentprev> Would we have Tesla today without Musk? No. Would electric cars be ubiquitous if it was up to the likes of Ford, GM, Mercedes, Toyota to push the tech? No. These may all be true, but that doesn't make Elon the founder of Tesla. As for the general sentiment of Elon-hate over the last few years, well, he has only himself to blame... The reason people like to point this out is because it highlights the fact that Elon's fragile ego is not a new phenomenon. It was always there, even before he decided to go full crazy. reply sparky_z 13 hours agorootparentprevI'm not on the Elon hate train (not a fanboy either, but I mostly agree with the positive things you said about him.) However, I did think pointing out the comparison would head off any \"how dare you, Aaron deserves to be called a founder\" comments. reply sampo 15 hours agorootparentprev> it was founded by Steve Huffman and Alex Ohanian That is true. But a bit later Reddit was joined with a company Aaron Swartz had founded, so he became a cofounder of this new arrangement of Reddit. https://news.ycombinator.com/item?id=20241 https://en.wikipedia.org/wiki/Aaron_Swartz#Entrepreneurship reply QuantumG 8 hours agoparentprevIt was a bit of a gut punch for me. His is a story of a self-selected marter. This is an unpopular opinion: he broke the law and refused to plead, then jumped on RT and dissed the prosecution for years. There was no chance they were going to back down. Why does this hurt me? Well, Lawrence Lessig and Richard Stallman and the rest of them radicalised me at a young age too. I was their boy. Watching that documentary was like looking into a time-warping mirror! Maybe every hairy nerd my age feels the same way, I don't know. reply avs733 12 hours agoparentprevSame...I honestly am furious at the effort to link Steve and Aaron here. Having known Steve, not well but for a LONG time I would struggle to label him anti-authority in any way. I think he wears many of the trappings of antiauthoritarianism - but only as a path to what he wants. reply jdprgm 14 hours agoprevWhile I still use Reddit often I kind of hope this marks the decline and something new emerges. Pretty much anything and everything their army of devs have built over the past 5+ years has been anti user. I can't even remember the last time a positive new feature was added. (This also kind of feels broadly true for the majority of the consumer apps in recent years -- remember the 2010's when devs actually added new features for users to apps on a regular basis?) There are countless things I assumed would have been fixed years and years ago that never have been. For example the trash search engine where you are better off using google with site:reddit.com. I do wonder if it's incompetence or intentional. Would love to see something in a vein similar to what BlueSky is attempting with twitter clone for reddit. Have a lot of ideas in this area lately. reply anal_reactor 11 hours agoparent> Pretty much anything and everything their army of devs have built over the past 5+ years has been anti user. That's because you're a power user. Reddit owners figured out that even though the service gained popularity as a middle ground between 4chan and Facebook, they can make most money if they kick out weirdos and cater to general audience, so they're consistently making changes to make it appealing to average Joe. You can clearly notice how they're slowly but surely removing controversial content and promoting userbase growth over everything else. My prediction is that Reddit will keep growing, but it's simply going to be \"Facebook, but for people 15 years younger\". reply specialist 11 hours agorootparentWhat are some example \"general audience\" features added these last 5 years? reply hatthew 9 hours agorootparent- Realtime chat - Design that is much less customizable via userscripts/CSS - More emphasis on users rather than communities (enhancements to user pages, profile pictures that are displayed in comments) - Garbage native media hosting alongside worse handling of offsite (youtube/imgur) media hosting - Inline gifs in comments - Algorithms that emphasize clickbait - Algorithms that try to guess what you want to see rather than letting you tell it what you want to see - Suppression of content deemed unsavory by advertisers - Emphasis on mobile design over desktop design - Backward incompatible changes reply rhaksw 9 hours agorootparentprevTons of mod tools built on top of shadow comment removals: crowd control, comment nuke, disruptive comment collapsing, contributor quality score, subreddit shadow bans via automoderator ... Check your account here [1], you probably have removed comments you don't know about. Or comment here [2] to see how it works. [1] https://www.reveddit.com [2] https://www.reddit.com/r/CantSayAnything/about/sticky reply Grimblewald 9 hours agorootparentprevThat obnoxious FB feed style ui they try to force you to use. reply nvr219 10 hours agorootparentprevdark mode reply dotancohen 10 hours agoparentprev> remember the 2010's when devs actually added new features for users to apps on a regular basis AnkiDroid, Telegram, and the Tesla app are the only three applications that I've seen add actual features for end users, in years. Even Firefox has stagnated, and some apps like Google Translate have become difficult to use for anything other than the happy path. I just bought a new phone, a three year old model still in stock, and I'm not even updating the OS as the current OS allows me to record phone calls but the newer ones do not. I am completely off the update treadmill. reply paulryanrogers 10 hours agorootparentDoes Firefox need to be continuously adding features \"for the users\"? I kind of like that their privacy efforts have been trimming back unnecessary features, at least from 3P hosts. reply ryandrake 9 hours agorootparentHonestly, most apps shouldn’t be “adding features.” Simply because of what OP said: the new features are almost always anti-user. Most applications I use today are either as good as or worse than the apps were in 2014. Developers throughout the industry have been furiously developing for ten years and we’re not making anything better. reply pedrogpimenta 11 hours agoparentprevLemmy is to reddit as blue sky is to Twitter and both run on Activity pub, IIRC. reply wlonkly 11 hours agorootparentMastodon instead of Bluesky and you've got it, I think. (Bluesky has its own protocol.) reply spartanatreyu 10 hours agorootparentI've really fallen in love with mastodon. I follow a whole bunch of developers, artists and some writers. It's such a breath of fresh air compared to what twitter ended up being. reply tcmart14 10 hours agorootparentprevYes it does. Bluesky uses the AtProtocol. reply climb_stealth 10 hours agoparentprevInterestingly enough the best kind of development I see happening in the public sector in Australia. For example both the official Bureau of Meteorology weather app and the general car rego / council matter app get regular worthwhile improvements. With actual meaningful changelogs in the play store updates. None of that stupid \"bug fixes and performance improvements\" bullshit that every other popular app puts in there. Still boggles my mind at times. reply DennisP 10 hours agoparentprevAt least they let you keep the old web interface, instead of forcing the new stuff on you. reply 6bb32646d83d 9 hours agorootparentYou have to wonder how long this will last, especially now that they're public. One day, they'll need to squeeze a few extra percentage of revenue to meet their quarterly target and decide that dropping old.reddit.com will move enough people to their revenue optimized new page to get there. Or there will be a breaking change in the API and they'll decide they don't want to bother supporting the old one anymore. In any case, the days of old.reddit.com are counted. I already stopped using Reddit on my phone after they shut down third party app. Just waiting on old reddit to disappear to finally say goodbye to this website reply 6bb32646d83d 9 hours agorootparentprevYou have to wonder how long this will last, especially now that they're public. One day, they'll need to squeeze a few extra percentage of revenue to meet their quarterly target and decide that dropping old.reddit.com will move enough people to their revenue optimized new page to get there. Or there will be a breaking change in the API and they'll decide they don't want to bother supporting the old one anymore. In any case, the days of old.reddit.com are counted. I already stopped using Reddit on my phone after they shut down third party app. Just waiting on old reddit to disappear to finally say goodbye to this website reply jamiequint 10 hours agoparentprevBuilding an actually successful business is the most pro-user thing any company can do. reply rideontime 18 hours agoprev> when Steve came back in 2015, I knew the world was in for a surprise. > If Reddit could grow to the size it had with management that was harmless at best, what could it do if Steve came back? We now know the answer to that question. Or at least a lower bound on the answer. Steve is not out of ideas yet. Does anybody know what \"ideas\" he's talking about? When I think back to recent developments at Reddit, all that comes to mind is the 3rd-party app fiasco and the \"collectible avatars\" and \"Moons\"/\"community points\" nobody but crypto speculators wanted anything to do with (and are now dead). Oh, and the death of celebrity AMAs after they fired Victoria. reply darkhorse222 16 hours agoparentThat's the issue. The thing that made them worthwhile was a very basic set of functionality. Every single other feature they've tried to add was poorly implemented and not picked up by users. It just doesn't make sense as a business. You don't need a million devs to run a forum site, you need them to add more and more bloat to convince investors you're growing. All they have done is pushed ads harder. That is all they really have to offer. reply pipes 13 hours agorootparentI rarely use it now because of the web front end. Yeah old.reddit.com and plugins to redirect to it help a bit. Also why on earth would I want to use an app instead of a web browser for a site that lists wen links. Oh yeah they stopped making the site about links and more about internal content. It really is a pile of shit compared to what it used to be. reply moritzwarhier 13 hours agorootparentprevReddit is the forum to end all forums, with a spice of imageboards. And it is ad-supported. People who have partaken in small PHPbb style forums probably can tell the story - moderation and bandwidth cost time. That's all, a simple, dumb business model based on advertising and market share, or better: mind share. The last part is Reddit's moat, no more, no less. My 2 cents. reply cactusplant7374 16 hours agorootparentprevThey are growing every year. https://www.statista.com/forecasts/1309791/reddit-mau-worldw... reply queuebert 16 hours agorootparentAnd they still have one of the worst apps (and website) in the game. Seems like that would be some low-hanging fruit. reply tempsy 14 hours agorootparenti still use the old version on web and it works great i agree the new version is very busy and buggy on mobile web reply __rito__ 14 hours agorootparentYeah, I have Old Reddit redirect on all of my devices, and I won't touch the official app with a ten foot pole. reply dmix 13 hours agorootparentNever got the complaints with the official app. What's the issue? Last time I asked someone this question they mentioned some power user stuff that didn't really apply to regular Reddit content consumers / casual posters. reply tempsy 11 hours agorootparentimo it's just unnecessarily busy and can be buggy. if you spend some time using the old web version, which feels very HN like, you'll wonder why you'd ever use the new one. reply weaksauce 14 hours agorootparentprevthe app is absolute trash and the new.reddit is almost as bad. if they remove old i'm out reply darkhorse222 13 hours agorootparentprevAh, but I would guess those are low quality users, i.e. they don't vote, they don't comment, they don't post. While that doesn't matter to advertisers, it does matter to the health of your content network. And their features have had zero positive effects on their community health. You can run an ad on a subway and get more users. That doesn't mean you're doing a good job. The only reason those users have something to see is because of community health. reply dageshi 13 hours agorootparentI would guess they're no different to any other users in the past decade. In other words a percentage will comment and a small percentage will post. It's always been that way. reply dwringer 13 hours agorootparentLLM's-at-home are in a vastly different place than they were 10, 5, or even 2 years ago, so I'm not sure the assumptions about typical traffic from then hold true now. reply dmix 13 hours agorootparentprevWhat are you basing this on? reply gustavus 14 hours agorootparentprevNow show us the percentage of those that are real people and not bots, and the number of accounts that are from previously banned users. I mean heck I've gotten to the point where I can only go 2 or 3 months before my account gets banned and then I have to spin up a new one. Come to think of it that might be a reason why their ban happy, more people you ban who come back looks like a new user signup. reply Sohcahtoa82 14 hours agorootparent> I mean heck I've gotten to the point where I can only go 2 or 3 months before my account gets banned and then I have to spin up a new one. User error. It's really not hard to not get banned. Site-wide, at least. I'm pretty active and my account is nearly 13 years old. reply 9991 14 hours agorootparentPretty easy if you have no controversial opinions. reply Sohcahtoa82 11 hours agorootparentThis reeks of \"Oh you know the ones\" https://twitter.com/ndrew_lawrence/status/105039166355267174... Conservative: I have been censored for my conservative views Me: Holy shit! You were censored for wanting lower taxes? Con: LOL no...no not those views Me: So....deregulation? Con: Haha no not those views either Me: Which views, exactly? Con: Oh, you know the ones reply cactusplant7374 11 hours agorootparentThere is a blog post describing the criminal history of a particular mod. If you post that link on Reddit you are automatically banned. reply babypuncher 15 hours agorootparentprevThat growth is predicated on a feature set that has been more or less untouched for over a decade. That core feature set is still very good. I've seen no evidence that anything they've introduced in the last 10 years has contributed to any of that growth, and my evidence is that just about every feature announced or implemented since then is now either gone or largely ignored by the userbase. reply PaulHoule 14 hours agorootparentThere is nothing special about Reddit unless you mean Reddit was in the right place and the right time to establish a two-sided market. It's very hard to kill a two-sided market when it gets established. Look at Craigslist or Twitter. An interesting thing about Reddit to me is many people who look at it see strongly offputting things like being overrun by image memes but when you look at it closely there is so much there about so many subjects. From time to time you find those brilliant social media posts that remind me of some of the emails from the Enron Emails data set where people talk about what they did for training in the army. Perhaps that is what keeps people coming back or maybe they are all about the memes. reply esafak 10 hours agorootparentWhat market are you referring to at Reddit? reply PaulHoule 9 hours agorootparentReaders and writers. reply babypuncher 11 hours agorootparentprevI firmly believe that niche content like what you mention is the life-blood of the site, and the biggest contributor to it's longevity. People come for the memes, but they stay for the litany of small communities that cater to their very specific tastes The fact that people often append \"reddit\" to their Google queries is a testament to this. Even if they aren't active participants in these niche communities, they know that they are the easiest place to find reasonably reliable information from other humans on them. If these types of communities stop flourishing on Reddit for any reason, then the site will become much easier to replace by any other generic meme factory. reply jsheard 14 hours agorootparentprevEven the overhauled UI has gone ignored by many users, thanks to the old UI remaining available as an option, but I imagine it's only a matter of time before they pull the plug on that so they can \"enhance the sponsored post viewing experience\". reply trogdor 14 hours agorootparentI have no evidence for this, but my hunch is that an inconsequentially-small percentage of Reddit users go out of their way to use Reddit’s old UI. reply VHRanger 14 hours agorootparentThose users are disproportionately mods and active users though. Reddit can't easily do away with it. They considered this around the 3rd party app fiasco and it was clear old Reddit has a few years left because mods allhate the new Reddit UI reply throwaway48476 13 hours agorootparentprevYes but what percent of active posters use it? It's going to be much higher and the site will die without new content. reply realusername 14 hours agorootparentprevInteresting, I used to be a member of the French community which peaked around 2017/2018 and kept decreasing ever since. I wouldn't say it's a ghost town now but it became a minor forum. I guess they grew in other countries. reply bevekspldnw 16 hours agoparentprevGetting drunk and editing production database to delete mean comments is certainly innovative CEO behavior. reply brobinson 14 hours agorootparentHah, I saw this: Steve was not a big fan of authority, so he also liked the idea of a site without editors. and remembered him getting prod database access to censor comments criticizing him. I guess it's true what they say about power corrupting you. reply WatchDog 5 hours agorootparentSometimes, those who are most vocal against authority, are projecting their own potential misuse of authority onto others, unable to see someone wielding power differently. reply RSZC 11 hours agorootparentprevThe controversy around this one was always wild to me. Mods editing comments was the most standard behavior on every phpbb/vb board I grew up on. His edits were clearly edited, clearly jokes, and TBH I found them pretty funny. And people were *outraged* that he had the capacity and the temerity to edit their sacrosanct posts... I took it as a sign of the changing times reply jtriangle 10 hours agorootparentThe thing is, when the mods would troll the hell out of users on the old BB's, they were doing it all the time, it was part of the culture. It happening on reddit, where a user's posts were thought to be immutable caused very understandable outrage. reply bevekspldnw 10 hours agorootparentprevIt’s an abuse of power, that’s why. It doesn’t matter if it is or isn’t funny or if anybody was harmed, the act itself was improper for any engineer dealing with other peoples data and egregious lack of judgement by a CEO. reply RSZC 7 hours agorootparentYeah this is the changing times I was talking about reply grepfru_it 15 hours agorootparentprevAnd people want to invest in this IPO? Seems like two trains moving towards each other but can’t tell if they are on the same tra",
    "originSummary": [
      "The article explores the beginning of Reddit founders, Steve and Alexis, and their experience with Y Combinator (YC).",
      "Despite the rejection of their original idea, they received funding to develop Reddit, leading to its subsequent growth and success.",
      "The impact of Steve's comeback to Reddit in 2015 is also discussed, shedding light on the significance of his return to the company."
    ],
    "commentSummary": [
      "The discussion delves into Reddit's evolution from Digg's replacement to potential successor Discord, highlighting user frustrations with content quality decline.",
      "Users are exploring alternatives like Lemmy due to dissatisfaction with Reddit's moderation, censorship, and influx of \"normies,\" affecting the platform's activity and user interest.",
      "Debates include Elon Musk's connection to Tesla and Aaron Swartz's Reddit founding role, alongside concerns about moderators, user engagement, platform features, and the community's health amid Reddit's changes."
    ],
    "points": 418,
    "commentCount": 699,
    "retryCount": 0,
    "time": 1711029604
  },
  {
    "id": 39778570,
    "title": "Dropflow: Advanced CSS Layout Engine for Modern Properties",
    "originLink": "https://github.com/chearon/dropflow",
    "originBody": "For the last 5 years I&#x27;ve been working on a layout engine that targets CSS2 and some more modern properties.Live demo: https:&#x2F;&#x2F;chearon.github.io&#x2F;dropflow&#x2F;It matches browsers in all cases I can find where they agree, and it&#x27;s fast. It supports `position`, `inline-block`, `z-index`, and complex properties like `float` and `vertical-align`. It doesn&#x27;t support high-level layout like flexbox or grid yet, but you can get intrinsics to easily divide space yourself and paint multiple layout trees. It has a great text layout implementation, and supporting non-Latin scripts is a top priority.I&#x27;ve wanted this to exist as far back as 2013, and the desire kept coming up: for a way to get detailed intrinsics, for high quality rich text layout to canvas and SVG, and for server-side rich text. We currently use it in CellEngine for our new canvas-based spreadsheet library to layout text in hundreds of thousands of cells, and will be using it soon to render PDFs with thousands of pages in a few seconds.",
    "commentLink": "https://news.ycombinator.com/item?id=39778570",
    "commentBody": "Dropflow, a CSS layout engine for node or(github.com/chearon)351 points by chearon 19 hours agohidepastfavorite115 comments For the last 5 years I've been working on a layout engine that targets CSS2 and some more modern properties. Live demo: https://chearon.github.io/dropflow/ It matches browsers in all cases I can find where they agree, and it's fast. It supports `position`, `inline-block`, `z-index`, and complex properties like `float` and `vertical-align`. It doesn't support high-level layout like flexbox or grid yet, but you can get intrinsics to easily divide space yourself and paint multiple layout trees. It has a great text layout implementation, and supporting non-Latin scripts is a top priority. I've wanted this to exist as far back as 2013, and the desire kept coming up: for a way to get detailed intrinsics, for high quality rich text layout to canvas and SVG, and for server-side rich text. We currently use it in CellEngine for our new canvas-based spreadsheet library to layout text in hundreds of thousands of cells, and will be using it soon to render PDFs with thousands of pages in a few seconds. atoav 1 hour agoTruly a service to the world. I think this is a classic example of \"somebody ought to do $X\" and nobody ever having done it. Thanks. As someone who loves working with CSS for layout, I am mostly relying on Flexbox and Grids these days — it is totally understandable that these are not supported yet — but do you plan to do so at some point? If so, how can others help? reply lewisjoe 18 hours agoprevThis is an amazing piece of work. Thanks for making this open-source. The default way of generating beautiful PDFs in the backend these days is, running a headless browser and using browser APIs to turn HTML/CSS into PDFs. And apparently, it's a bit costly running instances of browser in the server and scale it properly for huge workloads. This is literally a game changer. Now it's possible to design PDFs using HTML/css and generate them without the browser overhead! reply bawolff 18 hours agoparentAs an aside its amazing how far the web has come, where the best way to make pretty pdf documents is to literally run a web browser on the server. This would have been so unthinkable back in the 90s & 2000s reply rajh 14 hours agorootparentI needed to transform a 12MB HTML file into a PDF document and headless Chrome quickly ran out of memory (4GB+). We are now using a commercial alternative that seems be be using a custom engine that implements the HTML and CSS specs. The result is reduced memory usage (below 512MB during my tests) and the resulting PDF is much smaller, 3.3MB vs 42MB. reply phonon 12 hours agorootparentDid you try Weasyprint? reply ManBeardPc 12 hours agorootparentprevHave you tried Typst? It's like a modern version of LaTeX and allows to generate nice looking documents quickly. Can be called from the console and makes it easy to create templates and import resources like images, fonts and data (csv, json, toml, yaml, raw files, ...). Of course it is its own language instead of HTML/CSS but so far I found it quite pleasant to use. reply sciolistse 12 hours agorootparentprevBack around 2002 at least there were some products, ABCpdf is one I used a lot, which ran Internet Explorer on the server to generate PDFs from HTML. Worked pretty well from what I recall. reply vanderZwan 16 hours agorootparentprevI'm fairly certain that using a headless browser on the server is mainly about sandboxing all the security concerns that PDFs have, not aesthetics, but yes. reply menacingly 15 hours agorootparentit's actually because layout-via-code for arbitrary documents is a humblingly complex problem, so leveraging existing layout engines is preferred. This impressive effort looks far better than what I'd achieve, but when this approach has been tried before, it is eventually discovered that few organizations have the resources to maintain a rendering engine long-term. reply chearon 14 hours agorootparentI do think complexity could be part of why we don't have many options here, but I don't agree that a layout engine is too difficult to maintain. More of the issue is that CSS layout (and maybe layout in general) is not widely well-understood. I've almost _never_ come across people interested in layout because generally it's a few properties to get something working and then you move on. > few organizations have the resources to maintain a rendering engine long-term I'm curious are there other instances of this happening than Edge switching to Blink? That event was one of my main motivators; it felt like further consolidation of obscure knowledge. reply Sesse__ 11 hours agorootparentOpera switched from Presto to Blink, too. Very fun project! Did you ever consider integrating with web-platform-tests? It's shared between all the common browser vendors, and we're always interested in more contributors :-) reply chearon 10 hours agorootparent> Opera switched from Presto to Blink, too True. But I wonder if there are more special-purpose engines similar to Prince that have been abandoned. > Did you ever consider integrating with web-platform-tests? I've run some of the WPT tests manually, but I don't yet havesupport, and some of them use I think? That's a path I'm wary of (eval()?) but I could have a special mode just for tests. I did discover lots of weird corners that would be great to make some WPT tests for. Definitely something I want to do! reply Sesse__ 10 hours agorootparentYes, a _lot_ of WPT tests depend on . But there's also a bunch of ref-tests, where you just check that A and B match pixel for pixel (where B is typically written in the most obvious, dumb way possible). It lets you test advanced features in terms of simple ones. But yes, you'd need selector support in particular. reply nicoburns 6 hours agorootparentI maintain a standalone web layout engine[0] (currently implementing Flexbox and CSS Grid) which has no scripting support. WPT layout tests using is a major blocker to us running WPT tests against our library. Yoga (used by React Native) is in a similar position. Do you think the WPT would accept pull requests replacing such tests with equivalent tests that don't use (perhaps using a build script to generate multiple tests instead - or simply writing out the tests longhand)? I could run against only the ref-tests, but if I can't get full coverage then the WPT seems to provide little value over our own test suite. [0]: https://github.com/DioxusLabs/taffy reply Sesse__ 2 hours agorootparentI don't decide WPT policies (and I honestly don't know who does), but I'm pretty sure using a build script would be right out, as WPT is deeply embedded in a lot of other projects. E.g., if you made a build script, you would need to add support for running that script in Blink and in Gecko and in WebKit, and their multiple different runners, and probably also various CI systems. As for the second option, I don't actually know. If it becomes 10x as long, I would assume you get a no for maintainability and readability reasons. If it's 20% longer and becomes no less clear, I'd say give it a try with a couple tests first? It's possible that the WPT would be interested in expanding its scope to a wider web platform than just browsers. You would probably never get people to stop writing JS-dependent tests, though, so you would need to effectively maintain this yourself. Of course, for a bunch of tests you really can't do without , given that a lot of functionality is either _about_ scripting support (e.g. CSSOM), intimately tied to it (e.g. invalidation) or will be tested only rather indirectly by other forms of tests (e.g. computed values, as opposed to used values or specified values or actual values or …). reply bawolff 16 hours agorootparentprevSecurity of the pdf format is not relavent here. The headless browser outputs a PDF. It is not taking a user controlled pdf as input. reply vanderZwan 14 hours agorootparentAh of course, my apologies. I misread the original post. reply dusanh 1 hour agoparentprevWe did use this approach years back when I worked for on a feature that generated PDF invoices. But I wondered whether using instead something like LaTeX wouldn't be faster and easier to scale. reply thekingshorses 14 hours agoparentprevOne of the benefits of using the browser is that the generated PDF will be using vectors/fonts etc whereas Canvas will be mostly an image in the PDF. Not a big deal for the most use cases. reply aidos 13 hours agorootparentI feel like it’s probably not a leap to go from this to having a PDF renderer as a backend. The trickiness is in the layout, which this is already doing. Looks to be a lower level api and a way to render to absolutely positioned html. That gets you most of the way there. reply Pelerin 14 hours agoparentprevI'm a little confused by your comment. I've been using the Prawn library to generate PDFs on the backend for a side project I am working on for quite sometime https://github.com/prawnpdf/prawn (Admittedly, the PDFs I generate are most certainly not beautiful, so maybe that's the difference) reply Lukas_Skywalker 12 hours agorootparentPrawn really is great. I use it to generate invoices and for exporting a billing overview in client projects. And it’s quite fast as well, since it generates the PDF directly without the need to spin up a browser. reply lukew3 11 hours agorootparentprevLots of people are already really comfortable with html/css, so having the option to avoid learning an entirely new paradigm is helpful. reply ricardobeat 11 hours agorootparentprev> One thing Prawn is not, and will never be, is an HTML to PDF generator reply pmx 17 hours agoparentprevI've used this with good success https://ekoopmans.github.io/html2pdf.js/ reply webprofusion 9 hours agoprevBrilliant! It's super important that stuff like this exists, demystifying the magic boxes of browser rendering engines. It would be great if we could create a full machine readable spec for html and CSS rendering, so that renderers can be generated. Browser quirks could then be extensions to that. Like https://github.com/tawesoft/html5spec but used for real engines. reply internetter 8 hours agoparentSomehow this reminded me that Ladybird is a browser being written by scratch and this has been really useful to actually make sure that there are no bugs in the spec. reply fgutmann 5 hours agoprevGreat achievement, congratulations! This reminds me of flying saucer, a CSS render written in pure Java. Successfully used it in multiple projects for rendering PDFs in the past. It has some great features to handle paged media. For example, it can repeat table headers on a new page, if there is a page-break within the table. Unfortunately, it seems that it doesn't get much active development anymore. https://github.com/flyingsaucerproject/flyingsaucer reply bobajeff 19 hours agoprevThis sounds close to what I've been wondering about lately. I was wondering if css and svg could be used as abstraction over graphics and UI libraries. This is my first time hearing of node-canvas looks like it fills the drawing part of the solution. While this may do the layout portion (which is all I need from a UI library). I wonder how hard it was to implement css. I've heard it can be pretty complex. reply chearon 18 hours agoparent> wondering if css and svg could be used as abstraction over graphics and UI libraries There's another project called Sciter that uses CSS to target native graphics libraries: https://sciter.com > I wonder how hard it was to implement css. I've heard it can be pretty complex. It was hard, but the biggest barrier is the obscurity of the knowledge. Text layout is the hardest, because working with glyphs and iterating them in reverse for RTL is brain-breaking. And line wrapping gets really complicated. It's also the most obscure because nobody has written down everything you need to know in one place. After I finished block layout early on, I had to stop for a couple of years (only working a few hours a week though) and learn all of the ins, outs, dos, and don'ts around shaping and itemizing text. A lot of that I learned by reading Pango's [1] source code, and a lot I pieced together from Google searches. But other than that, the W3C specifications cover almost everything. The CSS2 standard [2] is one of the most beautiful things I've ever read. It's internally consistent, concise, and obviously the result of years of deliberation, trial and error. (CSS3 is great, but CSS2 is the bedrock for everything). [1] https://gitlab.gnome.org/GNOME/pango/ [2] https://www.w3.org/TR/CSS22/ reply jsunderland323 18 hours agorootparentI’m curious if you’ve implemented a rich text editor with this. I think Google Docs uses canvas. I hate the browser APIs for rich text and wonder if this could be more a viable candidate than using contenteditable for future projects reply chearon 17 hours agorootparentGoogle Docs uses canvas, yeah, and last I looked it used an empty contentEditable just to receive [rich text] input. I do think you could use this to write a document editor like Docs and side-step many of the problems with contentEditable, but I haven't tried to. Every time someone releases a new rich text editor I'm disappointed to find that it uses contentEdtiable. Would be very interesting! reply c-smile 16 hours agorootparent> Every time someone releases a new rich text editor ... uses contentEdtiable Sciter is using its own implementation (obviously). contentEdtiable thing is indeed quite limited for general purpose WYSIWYG editor. For example Web platform is missing transactional update [1] mechanism that allows to put custom DOM mutation groups into unified undo/redo stack. Sciter'selement ( implement behavior:richtext - WYSIWYG ) allows to build specialized editors. For example it is used in Sciter.Notes [2]. [1] https://docs.sciter.com/docs/behaviors/behavior-richtext#ric... [2] https://notes.sciter.com/ reply Traubenfuchs 15 hours agorootparentprev> It's also the most obscure because nobody has written down everything you need to know in one place Your work might have been, or maybe still is, the worlds biggest chance for this to change! reply c-smile 8 hours agorootparentThere was a whole team behind Microsoft Trident (IE engine) that was dissolved in favour of third-party (for them) Blink engine. That team was surely knowledgeable, but they had gone. Blink source is de facto current spec. Each function, if not single line, there is a paragraph in spec. I remember at WHATWG / HTML5 WG times when Ian Hickson (Google) was pushing whole SQLite (and its SQL flavour) to be included in HTML5 ... The spec area is so huge and indeed obscure that even Microsoft could not handle it. reply mattmar96 18 hours agoprevOh wonderful. Thank you! I was looking for something like this for my project https://htwins.net/scale2 and others which use svg or canvas reply internetter 7 hours agoparentWoah, I'd love a writeup on how you made this reply webprofusion 9 hours agoparentprevNeat project! reply eob 18 hours agoprevThis is incredible --- @chearon thank you for open sourcing this! I think most folks probably don't realize how difficult it is to go from HTML -> PNG programmatically. You get hit with a thousand papercuts related to either NodeBrowser differences or HTMLCanvas differences. reply lovegrenoble 19 hours agoprevFor anyone struggling with flexbox, you can use this tool to streamline the process of creating responsive layouts, removing the need to focus on multiple properties: https://flexboxcss.com reply techscruggs 12 hours agoparentThis is the first site I've run in to that uses neumorphic design. Love the aesthetic -- just never seen in it the wild before. reply fareesh 5 hours agorootparentCRED had it in their app for a while, their library is open source https://github.com/CRED-CLUB/synth-android reply airstrike 16 hours agoparentprevthank you for this! reply undershirt 16 hours agoparentprevthank you reply big_paps 19 hours agoprevWell this looks like something useful. Can't imaging how much work is needed to first understand css and then to build a layout engine around it. reply troupo 19 hours agoparentThere's also Facebook's Yoga: https://github.com/facebook/yoga reply Rohansi 15 hours agorootparentYoga is great but only really supports flexbox. For most cases that can be enough but inline content (as shown in the Dropflow demo) is difficult with only flexbox layouts available. reply robbiejs 18 hours agoprevThis is a big achievement, congrats! A lot of time must have been put into this I am sure. And you are also making a spreadsheet product AND a PDF (preview?) product? How do you combine it? reply chearon 18 hours agoparentWith this and node-canvas, you have everything you need to generate PDFs. I'll add an example to the examples/ directory for that. The spreadsheet library and PDFs I talked about in OP were examples of how we use this in our application, but are closed-source. reply awesomekling 19 hours agoprevSuper cool! Nice job, chearon :) reply chearon 18 hours agoparentWow thanks! Seeing Ladybird progress kept me motivated! reply LinguaBrowse 17 hours agoprevThanks for sharing this. I’ll be checking its potential as a base element for something like NativeScript or Node.js. Text is about the most complex UI element that a UI framework offers, and if you’ve got Flow Layout working, that’s very encouraging! Will be interested how far along things like gestures (particularly text highlighting) and IME integration are. In any case, kudos for opensourcing this! reply usrusr 18 hours agoprevFeels a bit like history repeating (well, rhyming) with the time back when Java was \"the language of web applets\" and then Sun created the Hotjava browser and confusion reached the point where minds simply blank out. Few technological novelties have been forgotten more decidedly than Hotjava. Despite marking an intersection of two technological fields (browsers and the JVM) that have shown extreme staying power through the last quarter century. But the idea of using html for text styling has stuck, Swing UI do text styling with html (and rudimentary css!) to this day. Html would not be a lingua franca if its use was limited to the equivalent of native speakers (browsers). reply justhw 15 hours agoprevThis looks great. I've been using html2canvas but it doesn't support the 'filter' property yet. This will be an awesome alternative. reply jasonjmcghee 18 hours agoprevAre you planning to add support for the missing standard tags like img and table (both very useful for pdf rendering)? reply chearon 18 hours agoparentYes, definitely. In the meantime, you can still use this to get the intrinsic sizes of cells to create rows and columns, and you can use an empty inline-block and paint the image where it's laid out. I'll put something in the examples/ directory soon. reply vthommeret 14 hours agoprevDoes anyone have a similar solution for drawing graphs / charts in a Node environment without a browser dependency? Last time I explored this I couldn't find any good solutions. reply tills13 13 hours agoparentYou could use https://github.com/vercel/satori which supports Node 16+. reply AaronFriel 12 hours agorootparentUnfortunately not for nested inline nodes, like spans of text with formatting. For a lot of uses, that will be OK - but for rendering say, markdown text, Satori won't work. The upstream layout engine handles flexbox layout, and it's unclear if Facebook needs inline layout or if Vercel would pick it up and close the gap: https://github.com/facebook/yoga Then again, for the main purpose Satori is advertised for - generating URL unfurl previews - Dropflow looks like it might be the answer. reply vthommeret 12 hours agorootparentprevThanks. I've tried using Satori but I'm curious if you've used it to draw graphs specifically. E.g. Satori expects JSX / doesn't support HTML strings from d3-node with dangerouslySetInnerHTML. reply AaronFriel 12 hours agoparentprevDoes this depend on a browser? It looks like it doesn't - which is pretty impressive! reply pier25 10 hours agoparentprevDo you need to create images? It's trivial to create svg in the server. It's like rendering html. reply joelanman 18 hours agoprevthis wouldn't be accessible would it? For example to screen readers, so just wondering what the use case is over accessible tech reply wg0 16 hours agoprevThis is pure craftsmanship. A heavy undertaking TBH, kind of reinventing browser flow on top of browser primitives. reply AndriyKunitsyn 18 hours agoprevI wonder if there’s something opposite — an abstraction for the Web to provide some layout rules that are more sane than CSS. reply moron4hire 14 hours agoprevThis sounds great. In a past role, my job was to develop an immersive, online learning platform. We used Oculus Quest 2s to do foreign language training for DoD personnel. WebXR, Three.js, etc, because I had had enough Unity3D for one lifetime and we didn't want to submit to app store reviews. We had a fleet of our own devices, so it was fine. One of the biggest challenges with the project was creating a workflow for didactic content. By myself. I had an employee who I supervised working for me, but most of the work was of such high technical level that it was way over their head and we couldn't afford to hire anyone else. I eventually landed on having our actual language instructors use PowerPoint to create PDFs, use a bespoke editor I created to upload the PDF into a content database and position them in the training environments, and then used PDFJS to render them to canvas elements to then texture on a 3D quad. Something like this would have made it possible for me to avoid having people go out of band into PowerPoint to make those materials. The PowerPoint route did dramatically improve our workflow speed over a previous attempt to get people to author images in Photoshop. But if I could have built the \"sign\" editor into the app, it would have improved it even more by eliminating the \"guess what will look good in the environment, export to PDF, upload to the database (oh, BTW, not a lot of people know how to keep files well organized), then find out how it really looks\" cycle. Oh well. We didn't have a business development team or market department that knew anything about selling products instead of services, so I guess the point is moot anyway. reply XCSme 18 hours agoprevCould I use this together with Pixi.JS ? reply pietroppeter 18 hours agoprevI would be very much interested in articles on how to write a CSS layout engine from scratch reply nicoburns 11 hours agoparentI've been considering writing such a thing. Although I've only implemented Flexbox and CSS Grid so far. The CSS specifications for those algorithms are worth reading if you're interested in this kind of thing. They're a challenging read, but not an impossible one. reply pietroppeter 56 minutes agorootparentFair advice, thanks reply bawolff 18 hours agoparentprevNot exactly what you are looking for, but if you haven't seen it, firefox has some really interesting blog posts about how their css engine works, e.g. https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-en... that i personally found really enlightening reply pietroppeter 56 minutes agorootparentThis is great, thanks for sharing! reply foreigner 13 hours agoprevWhat is the API to produce SVG? reply Vt71fcAqt7 16 hours agoprevThis looks great. As you mention PDF, do you plan to support the various @page properties that add pagination? For example like pagedjs[0] but native? Major usecases are books and invoices [0] https://pagedjs.org/about/ reply chearon 16 hours agoparentYes, this is pretty high up on my list. I've already done a little bit of work on pagination/fragmentation, but it will take me some time. reply andrewmcwatters 8 hours agoprevThe layout algorithm for CSS 2.1 is not well defined. How did you interpret the algorithm? I may be missing it from a quick glance, but it’s not obvious from your code. reply 1oooqooq 18 hours agoprevwhy not ship a desktop application at this point with support for a special schema? i can understand the abuse for server side rendering, but at this poit you pretty much have a bad browser engine. running inside a 2d hack in a browser engine. sigh. reply Bjartr 18 hours agoparentWhy re-invent the wheel with a special schema when CSS2 is a solid standard and widely understood? Is there no room in the world for rendering implementations between nothing at all and full-spec web browser with all the bells and whistles? reply 1oooqooq 18 hours agorootparentI'm actually advocating against re-inventing the wheel (insider another wheel, no less) you can still follow css spec if you want. just get a better environment than a canvas. reply mwit2023 16 hours agoprevwill give it a try for opengraph images, thank you! reply rrgok 16 hours agoprevPerhaps I'm missing something, but why can't we render HTML directly onto the canvas in the browser? The parser is there, the layout engine is already implemented, and the calculation of box layout is already done. It should be doable without going in circles. If only the browser had a flag indicating which \"surface\" to render on. I was looking at Glide Grid the other day, and it renders so fast, even with 1 million rows; it's somehow responsive. There should be an easier way to render HTML to canvas without resorting to low-level primitives. Why is canvas faster than the \"regular\" DOM renderer? reply duckfruit 16 hours agoparentBut if all you want to do is render HTML then why use ? I'm only speculating, but it doesn't seem surprising that regular DOM rendering logic - which has to handle approximately a bazillion different rules and special cases - is slower than a custom renderer written for a specific subset of HTML. reply hwillis 16 hours agorootparentIf you want to do any kind of text or diegetic UI in webgl, you are begging for DOM rendering to canvas (which is then sent to a texture) reply robbiejs 16 hours agoparentprevGlide Grid is an amazing achievement I have to say! You can have a fast DOM without canvas, but it requires creative thinking. DataGridXL also renders millions of cells, but it does not use canvas as its main renderer (https://www.datagridxl.com/demos/one-million-cells). The way it works: only columns are their own DOM nodes. For browsers it's just too much to ask to re-render let's say (20rows*10cols) 200 DOM nodes while keeping scrolling at 60fps. reply spankalee 15 hours agorootparent> it's just too much to ask to re-render let's say (20rows*10cols) 200 DOM I don't think this is true with modern browsers and CSS. For a table, every cell and parents of the cells as much as possible, should be styled `contain: strict` and if possible, absolutely positioned. reply robbiejs 11 hours agorootparentIt's still true. You might be able to get decent performance on a Macbook 3000 (doubtful even) but anything less than that, nope. That's why many grid components use canvas rendering. It would have been a lot easier for all these grid devs to work with DOM nodes if they could. reply spankalee 10 hours agorootparent> That's why many grid components use canvas rendering Many grid components were developed many years before modern compositors and the `contain` property. reply dtf 16 hours agoparentprevAs far as I remember, it's down to security concerns. You can actually insert your HTML into a SVG foreignObject, and then drawImage() that onto your canvas. But your HTML-in-SVG document will need to load all its own resources, fonts, CSS etc.. which makes this process rather tedious. reply eeiaeaa 16 hours agoparentprevGlide grid renders to canvas also. reply rrgok 15 hours agorootparentPerhaps I worded it wrong: I meant to bring Glide Grid as an example how fast we can render millions of items to canvas. reply spankalee 10 hours agorootparentIt doesn't actually render millions of items though. It renders the visible viewport, something you can also do with pretty standard DOM virtualization techniques. reply shepherdjerred 17 hours agoprevI've used satori [0] on the backend with TypeScript/Deno to render React JSX + tailwind CSS as an SVG (which is then rendered to a PNG). Of course you could use another flavor of JSX (or even plain HTML) or omit tailwind, but it's really cool that you can use the same stack as a typical frontend and render it as an image. Satori is meant for rendering Open Graph images (e.g. the little images that come up when you post a link on Twitter/Slack/Facebook), but I found that it works well for rendering arbitrary images. Satori has no native dependencies, so it kinda \"just works\" on the backend. It supports a subset of modern CSS, including flexbox. My use case is posting match reports for League of Legends into a Discord text channel, e.g. person X just played a match, here are their stats. It's quite nice because there are almost zero server-side native dependencies (the one exception is the library to convert svg -> png requires some native libraries). Here's what a match report looks like: [1] Here's an example of what the JSX looks like: [2] I also built a small project [3] that renders the JSX in a browser to make developing the images just as easy as developing a normal website. If others are interested in this, I would by happy to write a blog post about the process. [0]: https://github.com/vercel/satori [1]: https://github.com/shepherdjerred/glitter/blob/main/assets/p... [2]: https://github.com/shepherdjerred/glitter/blob/main/packages... [3]: https://github.com/shepherdjerred/glitter/tree/main/packages... reply eigenvalue 18 hours agoprevI worry that this sort of technology is going to lead to webapps that aren't really what we've grown to think of as \"the web\" but which will instead be closer to a VNC window where you just see pixels and can't interact with anything or see how stuff works in devtools. reply guhcampos 18 hours agoparentIs it bad though? This is of course a rethoric question, I don't know myself if I think it's good or bad, yet. What I'm thinking is: there's been soo much discussion around \"we have corrupted the Web\", \"Web standards were never made to build apps on\", etc. with sometimes good and sometimes really bad arguments. If we can build viewports in canvas that behave more like just a desktop environment where apps can be built, maybe that could be good? It could mean a split between the informational web and the \"apps on the browser\" paradigm, and in a ideal scenario this could make things simpler and more organized for everyone? Or it could just mean more work, more standards, more rupture and more siloing. Honestly don't know. reply ttepasse 17 hours agorootparentA major point of the web for me back in the 90s was that everything was text. You could inspect it, you could change it, you could curl it. That’s why Java and Flash and Silverlight were so annoying, they were blackboxes inside web pages. I can’t help but see this today like those yesterday. reply littlestymaar 18 hours agorootparentprevIt wouldn't be bad if we were sure it wasn't going to be abused to make apps where ads cannot be blocked, consent extortion pop-up cannot be removed, content cannot be copy-pasted, etc. unfortunately, this is the way this industry is always going, so there's good reason to be scared. (It's also terrible for accessibility, for both disabled people or just regular users who expect to be able to navigate with the keyboard for instance, unless the framework re-implement everything itself, which I doubt) reply wizzwizz4 14 hours agorootparent> unless the framework re-implement everything itself In which case, we're able to make an \"inspect element\" tool, which we could use to copy text out, and at the very least draw black rectangles on top of adverts. https://xkcd.com/2677/ reply jdiff 18 hours agoparentprevAccessibility features would need to be added to canvases before that reality's possible, so we've got a ways to go yet before we need to worry too much about that. reply joelanman 18 hours agorootparenttraditionally, lack of accessibility has unfortunately not held back people's use of tech, see Flash and most SPAs reply jdiff 16 hours agorootparentThe people who would do this canvas trickery are the people that would be held back by the lack of accessibility. reply danielvaughn 18 hours agoparentprevI don't see this, or any other equivalent effort, taking off. It's neat, but CSS layout is a small part of the overall problem. Even setting side accessibility, which is a massive undertaking in and of itself, you have text rendering. To get an idea of what you'd have to emulate, here are some (not even all) issues related to rendering text: https://faultlore.com/blah/text-hates-you/ reply abofh 18 hours agoparentprevEvery snake eats its own tail eventually - we went from bit blasting onto a frame buffer in 320x200 to bit blasting vector graphics onto a virtual frame buffer. (I leave out earlier steps and later steps, but every implementation eventually tries to implement its framework - it seems like the natural flow of things) reply NegativeLatency 10 hours agoparentprevLike flash? Seems like less of a risk than the flash days because browsers are faster and more capable, and stuff like this is currently a subset of what the browser can do, instead of a superset like flash was (or the strong vendor push like microsoft silverlight). Not old enough to have been a dev when flash was in it's prime though so might not have the most accurate view. reply dspillett 18 hours agoparentprevEven without this that is happening in small ways. I've seen a few fairly visual pages (graphs & charts, etc.) where parts that could be done with plain HTML+CSS such as separate tables containing the data (or a subset thereof) displayed in the charts was also rendered on a canvas. reply nickpsecurity 13 hours agoparentprevThat’s what a GUI app is, though. You could say it’s the default way we interact with graphical apps. Web browsers, along with web-enabled platforms, add a bunch of extra stuff to that. Many of us just want good, GUI apps for many things. They were often faster and lighter. VS Code is the exception to the rule which I use regularly. reply zharknado 7 hours agorootparentThis discussion reminds me a bit of the description of Fujitsu trying to implement Habitat in Japan: “…instead of sending a command message to the object on the server, the client would send the X-Y coordinates of your mouse click. The server would then render its own copy of the scene into an internal buffer to figure out what object you had clicked on. Not only was this extremely inefficient, but the race conditions inherent a multi-user environment meant that it also sometimes just got the wrong answer. It was amazing…” http://habitatchronicles.com/2004/04/you-cant-tell-people-an... reply ape4 19 hours agoprevIts too bad browsers don't support this. // Do CSS layout in the regular document const doc = new CssLayout(document); doc.layout(...); // Do CSS layout on your own canvas const mycanvas = new CssLayout(document.getElementById('mycanvas')); mycanvas.layout(...); reply Sesse__ 11 hours agoparentThe security implications would be interesting, unless you tainted the canvas (which makes it instantly less useful). reply adtac 6 hours agorootparentWhat security vulnerability becomes possible with native CSS-in-canvas support that's not already possible today? Or becomes easier? reply Sesse__ 2 hours agorootparentAs I understand the proposal, everything about visited link colors, for instance. Lots of cross-origin leaks. New forms of image leaks. reply peer2pay 15 hours agoprevI have nostalgia for a lot of things in webdev, hacking together floating layouts is not one of them. /s But congrats on the work! I can definitely see this being useful for text formatting and layouting PDFs. Neat! reply lloydatkinson 16 hours agoprev [–] It doesn’t support flex box? I really can’t tell what the purpose of this library is then. reply benatkin 8 hours agoparentI agree, I think there has to be something compilable to WebAssembly. A web search shows something that's written in Rust: https://github.com/DioxusLabs/taffy?tab=readme-ov-file#taffy reply recursive 9 hours agoparentprev [–] The purpose is for documents that don't use flexbox. reply lloydatkinson 1 hour agorootparent [–] Alright so that’s about as useful as saying “I built a word processor without left, right, middle align or tables”. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The speaker has dedicated 5 years to developing a layout engine focusing on CSS2 and modern properties, achieving browser-like speed and supporting features such as `position` and `inline-block`.",
      "However, the engine does not yet support advanced layout features like flexbox or grid, prioritizing text layout and non-Latin script support.",
      "Currently utilized in CellEngine for a canvas spreadsheet library, the engine's future use involves rendering PDFs effectively."
    ],
    "commentSummary": [
      "Dropflow is a CSS layout engine emphasizing CSS2 properties, discussed for its role in generating PDFs, enhancing web layout engines, and leveraging various tools and libraries for rendering.",
      "The conversation covers the challenges and advantages of implementing CSS in UI libraries, producing PDFs with HTML and CSS, and integrating with technologies such as NativeScript and Node.js.",
      "It also examines the risks and rewards of rendering web content on canvases and utilizing CSS within HTML canvas elements."
    ],
    "points": 351,
    "commentCount": 115,
    "retryCount": 0,
    "time": 1711029511
  },
  {
    "id": 39786984,
    "title": "Picotron: Fabulous Workstation for Pixelart Creations",
    "originLink": "https://www.lexaloffle.com/picotron.php",
    "originBody": "Picotron FAQ Submit Forum Carts Log Inv0.1.0b Welcome to Picotron Picotron is a Fantasy Workstation for making pixelart games, animations, music, demos and other curiosities. It has a toy operating system designed to be a cosy creative space, but runs on top of Windows, MacOS or Linux. Picotron apps can be made with built-in tools, and shared with other users in a special 256k png cartridge format. Specifications Display:480x270 / 240x135 64 definable colours Graphics: Blend tables, tline3d, stencil clipping Audio: 64-node synth and 8-channel tracker Code:Lua 5.4 w/ PICO-8 compat features CPU:8M Lua VM insts / second Cart:.p64.png (256k) / .p64 (unlimited) For more technical details and design documents, see the Picotron FAQ Customize your Machine Make your own live wallpapers, screensavers, widgets, custom tools, and set up workflows just the way you like! Or have a look around the BBS to see what other cartridge authors are up to. // Example Wallpaper by castpixel Status: Alpha Picotron is brand new! It is still mostly held together by duct tape, but the runtime and API are fairly complete, and the current binaries allow basic editing code, graphics, maps and sound, and exporting to .p64.png to share on the BBS. Web exporters are coming soon! Picotron Roadmap Get Picotron Until the end of March, Picotron is available for just $11.99. After that it will cost $19.99, or $11.99 when purchased with other fantasy consoles. All future updates are included, and the binaries are DRM-free, for Windows, Mac and Linux. AboutContactUpdatesTerms of UsePicotron Follow Lexaloffle: Generated 2024-03-22 09:42:260.007sQ:0",
    "commentLink": "https://news.ycombinator.com/item?id=39786984",
    "commentBody": "Picotron Is a Fantasy Workstation (lexaloffle.com)273 points by celadevra_ 7 hours agohidepastfavorite70 comments crq-yml 2 hours agoI had a good time with PICO-8 - and I think it retains its core appeal - but I've moved on to \"genuine\" retro hardware with the new crop of machines like CX16, Mega65, or my personal choice, Agon Light. The specification ends up being tighter when there's a board design, chips and I/O ports, and these new machines, like Picotron, are relatively uncompromised in what they can achieve within the I/O spec. You can emulate them, talk to the hardware directly, run BASIC or C or Forth or whatever other language. Lua might be too slow to run interpreted on real 8-bits as in the Pico series, but it can be used as the base for a cross-compiler instead, and that presents a different spin on the specific coding challenge: Why not create an ultimate development environment, something that generates the precise code needed for that type of project? That's the direction that the highly optimized PICO-8 games took, and it is likewise seen in new demos for C64, Spectrum, A800 etc. - the \"big hardware\" is leveraged towards the old stuff in a way that can ignore the assumed paradigms of both. reply kelvinquee 2 hours agoparent+1 My kids and I had a lot of fun with Pico-8, building simple games and learning basic geometry. The community (inherited from Pico-8) is already implementing cat/wget/grep[1] and, of course, Minesweeper[2] in Picotron! Whatever Joseph White/zep is building brings back the early days of Internet and IRC where the everybody builds and shares unashamedly while having a ton of fun! Thank you zep for making computing fun again for more mere mortals! [1]: https://www.lexaloffle.com/bbs/?tid=140771 [2]: https://www.lexaloffle.com/bbs/?tid=140678 reply vintermann 2 hours agoparentprev> Lua might be too slow to run interpreted on real 8-bits as in the Pico series Would it necessarily be all that much slower than Basic? It's a very small and othogonal design. reply benob 2 hours agorootparentThere are efforts to port pico8 to microcontrollers, but the real problem with lua is memory (easily requires 4MB of memory which is only available on high-end microcontrollers). https://github.com/DavidVentura/PicoPico reply vintermann 46 minutes agorootparentOk, but which language feature(s) of Lua is it which inherently requires so much memory? I understand you wouldn't exactly get a 100% standards compliant implementation, but what are the hard parts? reply boffinAudio 59 minutes agorootparentprevAs much as I love Lua its very difficult to shoe-horn into an 8-bit CPU, especially with limited RAM... but there are other efforts to bring more modern languages to these platforms, and one that strikes me as interesting is dflat, from 6502Nerd: https://github.com/6502Nerd/dflat/wiki (See language description here: https://github.com/6502Nerd/dflat/wiki/2.-Language-Descripti...) Maybe something like this could evolve/be adapted for continued modern development needs? reply esbeeb 4 hours agoprevWhen I use Raspberry Pi OS in a Raspberry Pi 4, 8GB of RAM - I feel I already have an excellent, refreshingly stable, late-90s-era experience. It scratches that strange nostalgia itch for that more innocent experience - of early-times WIMP computing. I can surf the web, edit LibreOffice files, record audio in Audacity on my nice Rode microphone, watch video files in VLC, remotely VNC in, transfer files in and out over SSH's SFTP, etc. Pretty much all that's really missing, to fill it out, is Zoom (or some such functional equivalent) with a fast-enough frame rate on video calls. And this is not, strictly speaking, the fault of Raspberry Pi, et al. reply contrarian1234 4 hours agoparentI used 8GB RAM till recently and I've found it more and more untenable. The primary issue is the browser. Even now on 16GB I restart Firefox every couple of days. But other things also eat RAM like crazy Running Emacs/Cider I'd have to kill other apps and reboot my REPL a couple times a day. Emacs would also leak memory and need a restart every couple of days reply prmoustache 1 hour agorootparentI guess the primary issue is the chair-->keyboard interface. The fact that browsers can open unlimited number of tabs doesn't mean you don't have to do a little housekeeping. Plenty of people still use systems with 4GB and lower and it works fine as long as the number of tabs they open is limited. reply contrarian1234 1 hour agorootparentThe primary issue is that browser developers are people that can afford kitted out Macbook pros so the system isn't designed to scale to small/weak systems :)) I don't believe a browser couldn't be designed to have a small RAM footprint. All my tabs could be suspended and saved to disk when in the background (and not spinning any tasks). They can be read back into RAM near instantly when I tab back to them reply nolist_policy 15 minutes agorootparentNo, Firefox and/or raspberryos just not well engineered for this usecase. My Chromebook with 8Gb ram has dozens of tabs and web apps open in Chrome, runs one VM with Android and another VM with Linux in turn running Firefox and more. All without breaking a sweat. reply cabby 2 hours agorootparentprev'Auto Tab Discard' was a game changer for me using firefox. I was about to upgrade to a 64gb laptop. reply contrarian1234 1 hour agorootparentit helps but strangely doesn't eliminate the problem entirely reply cabby 1 hour agorootparentPerhaps I don't see it on 32gb but can relate with cider/emacs. reply grimgrin 4 hours agorootparentprevi wish firefox had more granularity with its tab unloading feature. one method is restarting browser. but by default it’ll unload tabs if you’re low on memory. you can force em in about:unloads (hint- about:about if you ever forget) i wrote a simple firefox extension that unloads em all with a button click, but it’s no different than restarting ff or spamming clicks in :unloads reply sitkack 2 hours agorootparentWe already know the solution. We run the browser in Wasm inside the browser. That way it only has one tab open and that tab is doing 99% of its work inside of a wasm env. I thought firefox would ship new versions of firefox inside of firefox at some point. I guess that point is still in the future. This of course is how electron should work as well. A canvas only frame that loads whatever rendering system you want, which could be a browser, or it could be Unreal engine. reply ale42 1 hour agorootparentIsn't this what SDL (https://www.libsdl.org/) is for? Some cross-platform (and pretty light) hardware abstraction where you can have a canvas, do 3D, audio, whatever... reply adhamsalama 2 hours agorootparentprevTry Sidebery extension. reply persnickety 4 hours agorootparentprev12GiB and copious swap. 4 profiles open with 50-100 tabs loaded at any time. The only problem is the accumulation of CPU use from web apps. Consider adding more swap space so that older tabs have an out-of-the-way place to stay. reply yjftsjthsd-h 4 hours agorootparentprevReally? I can only hold one firefox session at a time in 8GB of RAM, but I've always assumed that's because I keep an unreasonable number of active+background tabs open. reply pjmlp 2 hours agoparentprevNot even close, if you told that about a ESP32 based system then I would have agreed. My 2003 bought multimedia Athlon XP desktop had 512 MB! reply esbeeb 5 minutes agorootparentZoom alone takes 2.4GB of RAM, just after being launched and starting a meeting - and no-one's even joined the meeting yet. reply ale42 1 hour agorootparentprevThe PC I was using in the late 90s had probably 32 MB of RAM after an upgrade... when I built a PC (2001?) with 512 MB it was looking like an infinite amount of RAM... reply rvense 10 minutes agorootparentI remember just laughing when I heard that Adobe had fixed a bug that occurred when running Photoshop in more than 1GB RAM on Mac OS 9. It seemed like such a theoretical thing to have that much memory. reply cxr 3 hours agoparentprev> 8GB of RAM [...] late-90s-era experience Not even close. reply p0w3n3d 1 hour agorootparentI started my studies on 2003 and highest I could do was 768MB of RAM. I remember this amount exactly, because my LL(1) grammar compiler was leaking memory on my pre-presentation test, and I had to present it to pass the course. Every MB of memory counted, and it started swapping. I was praying to make it pass but when the amount of swap increased above the amount of RAM I gave up. However I was last in the queue to present, and the teacher told me he needs to go, as it was too late. I was so happy I barely could hold my laugh. Came to my dorm and fixed it next day. Core memory. That's how I also fell in love with my wife :D She was doing the extreme programming with me reply prmoustache 1 hour agoparentprevYou weren't born in that late 90's era right? :D reply esbeeb 9 minutes agorootparentCorrect. 70's reply mrspeaker 2 hours agoprevI've been playing with this for 30 minutes, and I'm still smiling my head off. It's just so much fun. I have used Pico-8 a bunch in the past (so it was easy to jump into making stuff). Pico-8 is one of four bits of software that I put it in my basket of \"software that sparks joy\" along with Aesprite, Blender, and Propellorhead's Rebirth. Pico-8 had so much care put into its goals and intentional limitations: and so far Picotron seems to have that same level of love and thought. It's delightful, and I don't want to stop making things with it. I've used many of the clones of pico-8 and they all feel like they miss the point. They \"improve\" on the limitations, but are just... not satisfying. Funnily enough, I've tried three times to make my own JavaScript version of what Picotron is (\"what if I made a more feature-rich version of Pico-8 to use for prototyping in game jams?\") and each time abandoned it because it felt like the Pico-8 clones: adequate, functional, but not inspirational. I don't know who makes Pico-8 and Picotron, but hats off to you amazing person/people for making such likable software! reply PostOnce 6 hours agoprevPico-8 was and is one of the most pleasant pieces of software I have used. I can only imagine the wonders the community will produce for this thing. Of course, despite the machine itself (pico 8 that is, and this thing too) being proprietary, all the user-programs are source-available if not open source. It's really educational and I love it. There will be compatible implementations of this thing, but the pico-8 tools were so refined, and pico-8 was so cheap, that I can't imagine not giving the dude 10 bucks. (i.e. the open source implementations might just run the program but not come with all the cute tools like the IDE, the pixel sprite/map/etc editor, or the music tracker), that was well and truly worth the money. Pico-8 is one of the only pieces of paid-for software I haven't hated. Tl;dr: I think pico-8 is wonderful, I think the community and free programs are wonderful, and I think given that, this will also be wonderful. I'm a fan and have been for a while. reply kqr 3 hours agoparentCan you – or someone else – write about why Pico-8 is so much better than other fantasy consoles? In particular, I've been intrigued by WASM-4 recently, and someone else mentioned TIC-80 which also looks good. I remember reading about Pyxel and getting inspired. All three of those have the benefit of being free, so why would I pay for Pico-8? reply tmountain 2 hours agorootparentPay because it’s inexpensive and you are supporting the development of a platform that brings joy to a lot of people (including children). It’s hosted (splore for finding games), a community forum is maintained and is a wealth of knowledge. It’s a hub for learning. Paying for pico-8 is like donating to Wikipedia. Basically, you are putting a few dollars towards a “good thing”. reply kqr 1 hour agorootparentI don't buy that argument – why shouldn't I donate to TIC-80 instead, since it has the potential of reaching also children whose parents don't have $15 burning a hole in their pockets? I'm not trying to be contrary, I'm really just trying to find what the unique thing about PICO-8 is since nobody has been able to articulate it, yet many people appear to feel it. reply tmountain 1 hour agorootparentTIC-80 is heavily inspired by PICO-8. Supporting PICO-8 enables the creator of the original technology to continue producing creative works that seem to inspire a lot of derivative projects. Whatever the case, if you don’t agree, then don’t buy it. It’s pretty simple in that regard. reply Toorkit 4 hours agoparentprevThe Pico-8 is great, but https://tic80.com/ is really cool too. reply PostOnce 4 hours agorootparentTIC-80 is cool, but it's a clone of PICO-8, and like Doom clones, some of them are great, but they're still not Doom. reply blindluke 1 hour agorootparentI wholeheartedly agree with you that TIC-80 is not as great as PICO-8 is, and I would never recommend it over PICO-8 to someone who wants to start their adventure with game development. But it is not a clone of PICO-8. It offers a resolution that's very similar to that of the Game Boy Advance, so it serves as a nice transition stage towards GBA development. You can then enjoy your games on a console like Anbernic RG351P that's optimized for GBA games (2x integer scaling, same screen ratio). It's a specific use case, but one where TIC-80 shines. reply yjftsjthsd-h 4 hours agoprev> CPU: 8M Lua VM insts / second Is that ballpark, or throttled for consistency? The FAQ has a \"How Fast is the CPU?\" item, but that just discusses being fast and faster than PICO-8. reply vinc 42 minutes agoprevIt's not open source but it's really good looking, nice work! reply olivier5199 1 hour agoprevSeems like this would be awesome on one of these Clockwork devices: https://www.clockworkpi.com/shop?page=2 reply exitb 3 hours agoprevIt’s a bit of a shame that it’s apparently not fully compatible with PICO-8. I’d imagine it to be a perfect environment to create PICO-8 games. reply sitkack 2 hours agoparentIn what ways? Maybe there is a chance to change it! reply ggm 4 hours agoprevQR codes on cardboard slid under a cheap reader slot? cannot go past the 8 bit feel demanding some phsicality behind the thing. Lo-fi screen and giant buttons to mash.. reply jimmydoe 5 hours agoprevlooks delicious. just bought one. Mac binary is not signed, is it intentional? (I'm fine w it not signed but just ask reply devjab 1 hour agoparentDon’t you need an Apple developer account to get certificates to sign your stuff? If so that might explain it since that would be… what $300 a year? On top of likely having to go through the whole Apple Store acceptance process. reply jazzyjackson 1 hour agorootparentyou don't have to submit apps for them to be signed by you, but you do need to pay 99$/yr, tbh i think it's fair considering xcode is free reply snvzz 5 hours agoprevI'd rather one of the many open source alternatives to that ecosystem. reply PostOnce 5 hours agoparentHowever, TIC-80 only exists because PICO-8 does, and without money, presumably PICO-8 couldn't've been made, the dude would have had to be doing other work to live. Previously this guy made Voxatron, which I imagine paid for PICO-8, and that presumably paid for Picotron, so if I don't buy Picotron, then perhaps I'll prevent his next work of art from coming to fruition? Yes it bothers me a little bit that PICO-8 itself isn't open source, but I can't see the alternative, otherwise how can the dev afford to be spending time thinking about and working on these new things? It's not as though this is a huge company, or that there are alternative means of generating income from it (no Enterprise wants PICO-8 support, for example). I don't see an alternative to giving the dev a few bucks to keep making art projects that I love. reply noman-land 4 hours agorootparentThe pico-8 is very reasonably priced and for a few extra bucks you get Voxatron. I'm a huge advocate of open source but the pico-8 is just so lovely, and the community so creative and accommodating, that I didn't mind contributing. I have yet to check out the TIC-80 but I plan to after getting a little more fluent on the pico. reply jhbadger 3 hours agorootparentBut TIC-80 just is so much better than PICO-8. Not just the resolutions (which people can argue are an aesthetic choice for PICO-8) but the fact that you aren't limited to lua but have a variety of languages (some Lisp inspired) in TIC-80. reply presbyterian 3 hours agorootparentHaving such specific limits is exactly the point of PICO-8 though. If I wanted a variety of options, I’d be using a more traditional engine or library. reply tomtheelder 5 hours agoparentprevDo you have any examples? I’m pretty curious about Picotron, but would love to try an OSS alternative. reply chawyehsu 5 hours agorootparentThere are plenty of alternatives you could find on [1] in the context of fantasy console, almost all of them, oss or proprietary, active or dormant. And honestly many of them were inspired by PICO-8. Disclaimer: I'm one of the contributors of the list of [2]. [1]: https://github.com/paladin-t/fantasy [2]: https://github.com/pico-8/awesome-PICO-8 reply mostlysimilar 5 hours agorootparentprevTIC-80 https://tic80.com/ reply noman-land 5 hours agorootparentPicotron looks to be a different product from pico-8. reply bitwize 5 hours agoprevIt's a sign of the fact that personal computing has gone way, way off the rails that we make pretend computers to run on our real computers just to have fun ways to compute again. I really really appreciate work like this, but why aren't our actual operating systems \"cozy\" enough to support creative work anymore? reply mike_hearn 19 minutes agoparentWell it's for the same reason that Twitter is popular: intentional limitations that cut everyone down to the same height make something approachable and feel friendly. Nobody can excel on the Picotron, so it's inviting to try because you won't be comparing your work to someone else who did something so much more impressive. Likewise in classical Twitter nobody could write a truly great tweet due to the character length limits, and that set the tone and encouraged everyone to get involved. Compare with blogging on something like Substack where people who might otherwise publish something end up comparing themselves to Scott Alexander or Matt Taibbi and concluding they can't compete. I think in computing there's the other issue that modern programming has a big focus on safety and security which was absent in the 8-bit era. If you sit down to make a Mac app you're not only going to compare your work to Apple's own, but you're also going to be constantly distracted by things that aren't \"fun\" like slow compilers, type systems, notarization and code signing etc. These are all important for people who use computers as end users but if you just want to hack about and make something they suck away the energy. reply rob74 4 hours agoparentprevRemember the days when all home computers came with a BASIC interpreter preinstalled, and that was the first thing you saw when you started the computer? Later generations (Amiga, Atari ST) also had BASIC included with the OS. Not that familiar with the original Apple Macintosh, but from what I read that was the first computer to ship without programming tools. Windows then followed suit, and today all OSes ship without developer tools by default. Of course they're just a download away, but those are mostly tools for professional developers, so not really beginner friendly. Also, the limitations of 8 bit (and 16 bit) computers also made them more approachable. I \"designed\" some cool-looking sprites (actually they were called \"players\") on my Atari 800 back in the day, although I'm not good at drawing, so I would be hopeless at producing something more hi-res... reply otabdeveloper4 3 hours agorootparentLinux comes with Python included. (Python is the new BASIC, and explicitly designed to be so.) reply kqr 1 hour agoparentprevBecause a computer is a general-purpose tool. A computer is not a box made to be cozy and support creative, limited programming work. If you're looking for specific use-cases, that's exactly what userland software is for. Userland software takes the general computer and converts it to something specific. If you are looking for a cozy environment that supports creative, limited programming work, you run userland software for that! It's like software-defined networking except software-defined creative environments. Some people prefer Photoshop, and others Picotron. The computer gives you the choice, and userland software is the mechanism by which it does so. If anything, I'd like to turn your observation around: isn't it marvellous that the same machine allows one person to run Photoshop and another Picotron, with almost no change required to switch between the two environments? reply livrem 2 hours agoparentprevI like to start up Dosbox-X or one of the virtual Amiga environments that comes bundled with Amiga forever. Definitely cozy. More often I use some old application, like the nowadays BSD-licensed ex-Autodesk Animator. It is fun to figure it out and more fun than modern applications in many ways. I even bought an old used book about it and read cover to cover. Limited compared to modern graphics software, but \"cozy\" is a great way to describe the experience. https://github.com/AnimatorPro/Animator-Pro reply tazu 6 hours agoprevThis looks similar to what the cool couple at 100 Rabbits [1] are doing with Uxn. Overall, I love to support anyone producing hobby / cute software (especially with Lua!). [1]: https://100r.co/site/uxn.html reply WD-42 6 hours agoparentThe fact that they seemingly write all this stuff from a sailboat makes it even cooler. reply tazu 5 hours agorootparentLast I checked it was mostly solar-powered too. That's pipe-dream stuff. reply snvzz 5 hours agoparentprevuxn is awesome, and the implementations I have looked at seem to be MIT licensed. reply cubefox 5 hours agoprevDoes anyone also think these \"is a\" headlines violate commonly accepted headline rules? Arguably it should read: \"Picotron, a Fantasy Workstation\" reply pvg 5 hours agoparentIt's 'representative text from the article' in this case plus it probably doesn't matter in most other cases. reply fortyseven 2 hours agoparentprevSlow night? reply ClassyJacket 5 hours agoparentprevWhat rule? reply Ranmalie 18 minutes agoprev [–] Crypto investing has brought me great success!!! Irrespective of economic depression I can boast of over 2BTC every week on my investment. I will have missed a lot if I didn't start investing, it has really help my life and financial status. All thanks to my CRYPTO GURU TRADER Thank you for your focus on quality stocks. Dm SARAH JEFFREY FX ON FACEBOOK/INSTAGRAM reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Picotron is a Fantasy Workstation designed for creating pixel art games, animations, music, and demos with a toy operating system, compatible with Windows, Mac, or Linux.",
      "Users can develop apps using its built-in tools and share them in a unique png cartridge format, featuring a 480x270 display, 64 colors, Lua 5.4 code compatibility, and a 64-node synth.",
      "Currently in alpha stage, Picotron offers basic editing features with upcoming web exporters, priced at $11.99 until March-end, then $19.99."
    ],
    "commentSummary": [
      "The discussion delves into fantasy workstations like Picotron and PICO-8, low-RAM system browser performance, and the advantages of PICO-8 over alternatives such as TIC-80.",
      "It also explores the creativity and restrictions of programming on older computers, supporting hobbyist projects, intentionally limiting computing for accessibility, and successful stories in cryptocurrency investments."
    ],
    "points": 273,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1711075703
  },
  {
    "id": 39779291,
    "title": "Hackers exploit vulnerability in Saflok hotel keycard locks",
    "originLink": "https://www.wired.com/story/saflok-hotel-lock-unsaflok-hack-technique/",
    "originBody": "BY ANDY GREENBERG SECURITYMAR 21, 2024 10:00 AM Hackers Found a Way to Open Any of 3 Million Hotel Keycard Locks in Seconds The company behind the Saflok-brand door locks is offering a fix, but it may take months or years to reach some hotels. PLAY/PAUSE BUTTON PHOTO-ILLUSTRATION: WIRED STAFF; GETTY IMAGES When thousands of security researchers descend on Las Vegas every August for what's come to be known as “hacker summer camp,” the back-to-back Black Hat and Defcon hacker conferences, it's a given that some of them will experiment with hacking the infrastructure of Vegas itself, the city's elaborate array of casino and hospitality technology. But at one private event in 2022, a select group of researchers were actually invited to hack a Vegas hotel room, competing in a suite crowded with their laptops and cans of Red Bull to find digital vulnerabilities in every one of the room's gadgets, from its TV to its bedside VoIP phone. One team of hackers spent those days focused on the lock on the room's door, perhaps its most sensitive piece of technology of all. Now, more than a year and a half later, they're finally bringing to light the results of that work: a technique they discovered that would allow an intruder to open any of millions of hotel rooms worldwide in seconds, with just two taps. Today, Ian Carroll, Lennert Wouters, and a team of other security researchers are revealing a hotel keycard hacking technique they call Unsaflok. The technique is a collection of security vulnerabilities that would allow a hacker to almost instantly open several models of Saflok-brand RFID-based keycard locks sold by the Swiss lock maker Dormakaba. The Saflok systems are installed on 3 million doors worldwide, inside 13,000 properties in 131 countries. By exploiting weaknesses in both Dormakaba's encryption and the underlying RFID system Dormakaba uses, known as MIFARE Classic, Carroll and Wouters have demonstrated just how easily they can open a Saflok keycard lock. Their technique starts with obtaining any keycard from a target hotel—say, by booking a room there or grabbing a keycard out of a box of used ones—then reading a certain code from that card with a $300 RFID read-write device, and finally writing two keycards of their own. When they merely tap those two cards on a lock, the first rewrites a certain piece of the lock's data, and the second opens it. “Two quick taps and we open the door,” says Wouters, a researcher in the Computer Security and Industrial Cryptography group at the KU Leuven University in Belgium. “And that works on every door in the hotel.” A video of the researchers demonstrating their lock-hacking technique. (The pattern of lights shown on the lock is redacted at one point at the researchers’ request to avoid revealing a detail of their technique they agreed with Dormakaba not to make public.)VIDEO: IAN CARROLL Wouters and Carroll, an independent security researcher and founder of travel website Seats.aero, shared the full technical details of their hacking technique with Dormakaba in November 2022. Dormakaba says that it's been working since early last year to make hotels that use Saflok aware of their security flaws and to help them fix or replace the vulnerable locks. For many of the Saflok systems sold in the last eight years, there's no hardware replacement necessary for each individual lock. Instead, hotels will only need to update or replace the front desk management system and have a technician carry out a relatively quick reprogramming of each lock, door by door. Wouters and Carroll say they were nonetheless told by Dormakaba that, as of this month, only 36 percent of installed Safloks have been updated. Given that the locks aren't connected to the internet and some older locks will still need a hardware upgrade, they say the full fix will still likely take months longer to roll out, at the very least. Some older installations may take years. “We have worked closely with our partners to identify and implement an immediate mitigation for this vulnerability, along with a longer-term solution,” Dormakaba wrote to WIRED in a statement, though it declined to detail what that “immediate mitigation” might be. “Our customers and partners all take security very seriously, and we are confident all reasonable steps will be taken to address this matter in a responsible way.” MOST POPULAR SCIENCE Watch Neuralink’s First Human Subject Demonstrate His Brain-Computer Interface EMILY MULLIN BACKCHANNEL 8 Google Employees Invented Modern AI. Here’s the Inside Story STEVEN LEVY GEAR The Omega x Swatch Snoopy MoonSwatch Has Landed JEREMY WHITE SCIENCE The Keys to a Long Life Are Sleep and a Better Diet—and Money MATT REYNOLDS The technique to hack Dormakaba's locks that Wouters and Carroll's research group discovered involves two distinct kinds of vulnerabilities: One that allows them to write to its keycards, and one that allows them to know what data to write to the cards to successfully trick a Saflok lock into opening. When they analyzed Saflok keycards, they saw that they use the MIFARE Classic RFID system, which has been known for more than a decade to have vulnerabilities that allow hackers to write to keycards, though the brute-force process can take as long as 20 seconds. They then cracked a part of Dormakaba's own encryption system, its so-called key derivation function, which allowed them to write to its cards far faster. With either of those tricks, the researchers could then copy a Saflok keycard at will, but still not generate one for a different room. The researchers' more crucial step required them to obtain one of the lock programming devices that Dormakaba distributes to hotels, as well as a copy of its front desk software for managing keycards. By reverse engineering that software, they were able to understand all the data stored on the cards, pulling out a hotel property code as well as a code for each individual room, then create their own values and encrypt them just as Dormakaba's system would, allowing them to spoof a working master key that opens any room on the property. “You can make a card that really looks as if it was created by the software from Dormakaba, essentially,” says Wouters. And how did Carroll and Wouters obtain Dormakaba's front desk software? “We nicely asked a few people,” Wouters says. “Manufacturers assume that no one will sell their equipment on eBay, and that no one will make a copy of their software, and those assumptions, I think everyone knows, are not really valid.” Once they'd managed all that reverse engineering work, the final version of their attack could be pulled off with little more than a $300 Proxmark RFID read-write device and a couple of blank RFID cards, an Android phone, or a Flipper Zero radio hacking tool. A Saflok branded lock. PHOTOGRAPH: DORMAKABA MOST POPULAR SCIENCE Watch Neuralink’s First Human Subject Demonstrate His Brain-Computer Interface EMILY MULLIN BACKCHANNEL 8 Google Employees Invented Modern AI. Here’s the Inside Story STEVEN LEVY GEAR The Omega x Swatch Snoopy MoonSwatch Has Landed JEREMY WHITE SCIENCE The Keys to a Long Life Are Sleep and a Better Diet—and Money MATT REYNOLDS The biggest caveat to the hackers' Unsaflok technique is that it still requires that they have a keycard—even an expired one—for a room somewhere in the same hotel as the room they're targeting. That's because each card has a property-specific code they need to read and then duplicate on their spoofed card, as well as a room-specific one. Once they have that property code, the technique also requires using an RFID read-write device to write two cards—one card that reprograms a target lock as well as the second spoofed card that unlocks it. (An Android phone or a Flipper Zero could also be used to emit one signal after another instead of the two cards, the researchers say.) The researchers hint that the first card allows them to open a target room without guessing its unique identifier in the hotel's system, but declined to say exactly what that first card does. They're holding that element of the technique in confidence to avoid giving too clear a set of instructions to would-be intruders or thieves. By contrast, one security researcher presented a similar hotel keycard hack that opened locks sold by the firm Onity at the Black Hat conference in 2012 with no such obfuscation, and allowed any hacker to build a device that opened any of Onity's 10 million locks worldwide. When Onity refused to pay for the hardware upgrades necessary to solve the problem and instead put the onus on its customers, the issue remained unfixed in many hotels—and eventually was exploited in at least one hacker's cross-country burglary spree. Carroll and Wouters say that they're trying to avoid that scenario by taking a more cautious approach, while still warning the public about their technique, given that hundreds of properties will likely remain vulnerable to it even now that Dormakaba has offered its fix. “We're trying to find the middle ground of helping Dormakaba to fix it quickly, but also telling the guests about it,\" says Carroll. “If someone else reverse engineers this today and starts exploiting it before people are aware, that might be an even bigger problem.” To that end, Carroll and Wouters point out that hotel guests can recognize the vulnerable locks most often—but not always—by their distinct design: a round RFID reader with a wavy line cutting through it. They suggest that if hotel guests do have a Saflok on their door, they can determine if it's been updated by checking their keycard with the NFC Taginfo app by NXP, available for iOS or Android. If the lock is manufactured by Dormakaba, and that app shows that the keycard is still a MIFARE Classic card, it's likely still vulnerable. If that's the case, the two researchers say, there's not much to do other than avoid leaving valuables in the room and, when you're inside, bolt the chain on the door. They warn that the deadbolt on the room is also controlled by the keycard lock, so it doesn't provide an extra safeguard. “If someone locks the deadbolt, they’re still not protected,” says Carroll. Even without a perfect or fully implemented fix, Wouters and Carroll argue, it's better for hotel guests to know the risks than to have a false sense of security. After all, they point out, the Saflok brand has been sold for more than three decades, and may have been vulnerable for much or all of those years. Though Dormakaba says it's not aware of any past use of Wouters and Carroll's technique, the researchers point out that doesn't mean it never happened in secret. “We think the vulnerability has been there for a long time,” says Wouters. “It's unlikely that we are the first to find this.”",
    "commentLink": "https://news.ycombinator.com/item?id=39779291",
    "commentBody": "Hackers found a way to open any of 3M hotel keycard locks (wired.com)271 points by jasoncartwright 18 hours agohidepastfavorite197 comments dmpanch 15 hours agoI work for a company that manufactures access control and communication systems. The readers we develop support a variety of ID standards, from unencrypted EM-Marin and a long time ago cracked Mifare Classic to modern Desfire EVx standards. According to our statistics, more than 95% of customers still continue to use the most insecure identifiers because of their low cost and ease of operation. Many of the installed devices are not properly maintained, even if the manufacturers continue to support them, because you have to pay for maintenance. In addition, not all equipment can be updated remotely over the network or even have a network connection to do so remotely. Even if your cards are encrypted, it still can't guarantee you protection, because in most cases card readers are connected to controllers (not in the case of all-in-one devices like this lock) via Wiegand protocol, which doesn't provide any data encryption, so the identifier ID is transmitted over two wires in the clear form. reply lol768 14 hours agoparentAt some point, isn't there some responsibility that rests with manufacturers for choosing to continue to support known-insecure standards? How many browsers do you think support the TLS_NULL_WITH_NULL_NULL cipher? reply ryandrake 9 hours agorootparent> At some point, isn't there some responsibility that rests with manufacturers for choosing to continue to support known-insecure standards? There should be. Also there should be liability for access control system customers for choosing low cost, insecure solutions. But just like in the InfoSec world, there are simply no consequences to companies that cheap out and fail at security. These companies just issue a press release saying “we take security very seriously” and continue on with their business. reply Nextgrid 14 hours agorootparentprevIt's often a compatibility thing too. Insecure standards can often coexist because they're the lowest common denominator. It's just a \"password\" stored and transmitted as plaintext. A secure system would involve a PKI which increases complexity and management overhead significantly (you won't be able to just copy \"passwords\" from one system to another, etc). reply int_19h 3 hours agorootparentprevI think the only reason why we have the amount of attention to security that we do in the software industry is because Internet enabled cheap automated large-scale attacks - enough so that even very low-value targets are well worth it. reply noselasd 12 hours agorootparentprevBrowser manufacturers normally don't have contracts that binds them to supply product X for Y years. reply pixl97 8 hours agorootparentHeh, You mean IE6 and ActiveX controls :D reply throwway120385 10 hours agoparentprevI'm in a similar space and a lot of our customers continue to use old-school Wiegand low-frequency badges even though they're ridiculously vulnerable to replay attacks to the degree that Flipper Zero has automated it. reply michaelt 12 hours agoparentprevFor a while I've had a question about hotel keycard technology, maybe you can answer. Essentially every time I've stayed in a hotel with contactless keycards (usually in a group needing 3-5 rooms for 2-3 nights) at least one person has needed to get a keycard reissued. What's up with that? My workplace's smartcards and my contactless bank cards keep working for years on end. reply lxgr 12 hours agorootparentHotel keycards usually work by having dynamic data written to them at the front desk (as the locks are often not network connected, at least in older systems, so they write things to the card like \"works for room 123 until March 30th noon and the gym\" or \"works for room 456; sequence number 2, invalidate all prior keys\"). There are two types of magnetic stripe cards available: High-coercivity (HiCo) and low-coercivity (LoCo). The field-rewritable kind used in hotels is usually LoCo, to make the writers smaller and cheaper. But that also makes the cards much more prone to accidental corruption by magnets you might have on you, like earbuds, magnetic wallets etc. Bank cards are usually only ever programmed once (these days), i.e. when they're issued, so they're usually HiCo, making them much more robust against that. In addition to that, magnetic stripe usage has been phased out for payment cards in most countries and is getting rare even in the US, so for all you know, and depending on where you live/shop, your magnetic stripes might have already been demagnetized without any adverse effects! Bonus trivia question: Guess which kind NYC MTA Metrocards are :) Edit: Oh, I just saw that you asked about contactless keycards! For these I actually have no idea, and I haven't had one fail on me yet. I just know that they often use a similar scheme (\"works for rooms x, y, z, until timestamp n\"), sometimes with a bit of cryptography on top (often with a single shared key across all instances of the same lock and even across hotels...) but using non-networked locks, so there can definitely be synchronization/propagation issues too. reply neuralRiot 12 hours agorootparentI used to work as maintenance on a big chain hotel and we had magstripe card locks, I don’t think strong security is their primary goal as in a hotel the staff can enter any room at any time, the cards me and my team had were “god mode” we could open any door at any time even when locked from inside. If the lock didn’t work “firmware problems, dead batteries, stuck mechanism” we had another device that worked by removing a cover and connecting with a wire, this was also used for testing and FW updates. reply baldeagle 9 hours agorootparentWhen I worked mainteince on a big chain hotel in a major college town, we had a mark 2.0 crowbar if the key card didn't work. The real fun one was the flippy locks that you could kinda pop by slapping the non-working key card in, and slamming the door. The card would flex and spring the lock back. Then you could use the crowbar again. It wasn't too slow, but it was very loud. They told me couldn't whistle and spin the crowbar nonchalantly before casually popping open doors that had a dead battery in front of the guest waiting to stay in that same hotel. reply thaumasiotes 1 hour agorootparent> we had a mark 2.0 crowbar What were the improvements over \"crowbar classic\"? reply lotsofpulp 10 hours agorootparentprev> the cards me and my team had were “god mode” we could open any door at any time even when locked from inside. That is just bad management. The whole point of the interior deadbolt lock in a hotel room door is so no one can accidentally walk in on you thinking it is an empty room. An emergency keycard that can open a hotel room locked from the inside is only supposed to be kept at the front desk for use during an emergency, mostly by police or firefighters so they do not break down the door and cause tens of thousands of dollars of damage. And its presence and use should be constantly accounted for. reply pledess 4 hours agorootparentMany U.S. hotels changed that after the Mandalay Bay hotel incident in October 2017. A guest can no longer assume that their deadbolted hotel room door will only be opened in an emergency. Routinely, hotel staff (not accompanied by police) may knock and then immediately open a guest's door for what they consider a \"welfare check\" (e.g., guest has had a Do Not Disturb sign for 2 days). And, yes, guests may be strongly opposed to this for a variety of reasons (in the room but undressed, etc.) but it often is part of a hotel's normal operating practices. One of many references: https://www.reddit.com/r/askhotels/comments/vaxae2/comment/i... reply thaumasiotes 2 hours agorootparent> Many U.S. hotels changed that after the Mandalay Bay hotel incident in October 2017. A guest can no longer assume that their deadbolted hotel room door will only be opened in an emergency. I don't see the connection. The Mandalay Bay incident was an emergency, and the door was forced. What needed to change? reply throwaway2037 8 hours agorootparentprev> cause tens of thousands of dollars of damage This is surely overstated. I am sure firefighters are trained to do the least amount of damage when forcing a hotel door open. I guess a handheld electric saw could do the trick in less than one minute. reply rubidium 7 hours agorootparentUm, no they’re trained to get in as fast as possible. Life >> cost of any door. reply lotsofpulp 6 hours agorootparentprevAny non ancient hotel will have metal fire doors that cost near a thousand themselves, plus the metal framing and whatnot. The cops or firefighters are not going to spend time cutting, they are going to bust it open with a battering ram which will ruin everything, requiring reframing, new door, new thresholds, new frames, new locks ($2k), and maybe flooring too. And then add in opportunity cost from not being able to rent the room during repair, which would take weeks due to those materials not being available at Home Depot. I would budget at least $10k, and I bet it would not exceed $20k, but either way, using a battering ram on a hotel door is very costly. reply julian_t 1 hour agorootparentprevAt least with old fashioned keys you can't easily give out a duplicate. I was once in bed, late at night, lights out, when someone let themselves into my room - a rather drunk guy demanding to know what I was doing in his room. The desk clerk had got his room number wrong and given him another card to mine. It all worked out OK, but under other circumstances I could imagine that it might not. reply mushufasa 9 hours agorootparentprev> Guess which kind NYC MTA Metrocards are :) None anymore! They're being phased out as we speak. They were supposed to be end of life last year, though they pushed back end of life EoY 2024, because the MTA is never on time, all the time. reply lxgr 7 hours agorootparentAnd I’ll be swiping until the day they remove the readers if they don’t introduce monthly capping via OMNY! The Metrocard is actually a quite elegant and resilient/decentralized system, given the technology that was available when it was introduced. OMNY depends on a network connection being (almost) always available. reply drchickensalad 7 hours agorootparentOMNY has had automatic fare cap for 2 years? reply Detrytus 11 hours agorootparentprevShouldn't that be other way around? Keycard only holding the simple numeric id, which is burned into silicone chip on it and impossible to modify, and the reader at the door, connected to hotel central system checks what privileges that particular keycard grants? reply lxgr 7 hours agorootparent> the reader at the door, connected to hotel central system That’s very often not the case, though, especially in retrofitted installations. Locks are sometimes offline and even battery powered (and I suspect they can even report a dying battery to the front desk by setting the appropriate flag on keycards as they’re being read). reply tesseract 11 hours agorootparentprevIn the days before cheap, low-power radio networks a \"central system\" would have meant dedicated wiring to each door lock. So it would have been much more expensive to install than a standalone battery powered unit mounted directly on the door. reply andreareina 8 hours agorootparentprevThat doesn't stop someone else from flashing a reprogrammable keycard with the id. reply maxerickson 10 hours agorootparentprevYou could force or deny service on a lock that just checked a simple ID. reply justinclift 7 hours agorootparentWouldn't that only be for poor implementations? If the reader had a decently secure channel to the central auth piece, then it shouldn't (in theory) matter how simple or complex the id would be. (?) reply vizzah 11 hours agorootparentprevI had the same experience with NFC hotel card failing after being in my pocket (next to other cards and a phone). It had to be re-programmed at the hotel's desk to work again. Puzzled me enough to search net for the answers, but to no avail. reply tonyarkles 9 hours agorootparentIt's the phone. Have had this happen multiple times with just the card and my phone. Not sure if it's doing some kind of NFC ping on the phone or if there's just enough of a magnetic field around it or what, but I reliably locked myself out of my room the first week doing field work this year by putting my phone and my hotel card in the same pocket. reply lotsofpulp 10 hours agorootparentprev> What's up with that? It was programmed incorrectly and expired before it should have. The stay was extended but the key was not updated with the new departure date. A new key was erroneously issued for the room, someone used the new key to go into the room, saw someone was already staying in the room, and had to get keys for a different room. This would cause all old keys to stop working since every time a lock sees a new key used, it assumes a new hotel guest is staying. Or it lost its data for whatever reason. reply hunter2_ 6 hours agorootparentMy brain was ANDing the first three paragraphs until I got to the OR in the last paragraph, wondering why in the world those otherwise discrete scenarios would have a combinatorial effect. I'm wired to look ahead to determine AND versus OR with a comma-delimited series, but not with a paragraph-delimited series. It's a cool pattern but very unexpected, and I'm not sure you could successfully tack on other thoughts before or after the series, because what would delimit those from the series without overloading the meaning of a paragraph separation? Given a need for multi-sentence items within a series, I go for bullet points. Hyphen character to start each point if no rich UL formatting is available. reply hypercube33 4 hours agorootparentprevthere you go. make a fake coil card and tell the door you're staying for 25 years and a new guest ...get in and own the room reply Moru 2 hours agorootparentUntil the next guest arrives, card saying they are staying until next monday and clear all previous keys. reply wnevets 5 hours agoparentprev> so the identifier ID is transmitted over two wires in the clear form. I'm much more worried about someone using to a clothes hanger looking tool [1] to break into my hotel room than someone exposing cables and reading data over the wire to unlock the door. [1] https://www.youtube.com/watch?v=-3G9pyvCBcM reply factormeta 6 hours agoparentprev>Even if your cards are encrypted, it still can't guarantee you protection, because in most cases card readers are connected to controllers (not in the case of all-in-one devices like this lock) via Wiegand protocol, which doesn't provide any data encryption, so the identifier ID is transmitted over two wires in the clear form. It is true, seems like probably better to go back to keys and lock. reply Rebelgecko 6 hours agorootparentUnfortunately most physical keys also transmit their bitting in the clear reply aaronax 7 hours agoparentprevSame as basically any physical lock can be trivially picked. Yet no one is buying office door locks based on pick-resistance. Burglars will smash their way in anyways. reply kawsper 16 hours agoprevThe building where I rent have doorlocks from Scantron ( https://scantron.dk/ ) they use RFID keys to open locks, and last year someone discovered a way of creating masterkeys from any key because of the weak encryption used by MiFare Classic. It took a journalist and a lot of e-mails and calls for my landlord to understand the problem, I suspect that Scantron were also downplaying the issue towards them. They finally budged and upgraded all the locks to use a better encryption scheme and re-issue keys. My building have 197 apartments, each of them have at least 2 keys, I have to trust all of the tenants (and their friends), in order for my apartment not to get burgled, and if I were burgled my insurance wouldn't cover because there's likely no proof of entry. reply wickedsickeune 12 hours agoparentAny chance you could share these e-mails? I also live in such an apartment complex and I was aware that the locks are jokes, but I didn't think it was possible to convince the building's managing company. reply jpk2f2 5 hours agoparentprevI had a similar situation at the apartment I used to rent. Unfortunately they didn't care to correct it, so I removed the battery from my lock and only used the physical key. My fob copy still works there last I checked... reply mdekkers 15 hours agoparentprevI have rented my entire life, and “change all the locks” has always been the very first thing I do. I have a couple of different size high security cylinder locks, and whilst no cylinder lock is unpickable, I’m pretty happy with mine. reply NeoTar 12 hours agorootparentInteresting, because many renters (myself included) would not be permitted to change the locks. reply neilv 8 hours agorootparentOne rental apartment where I'd changed the lock core, one day the nice handyman admired the fancy Mul-T-Lock style key while I was letting him in, and later remarked about it to landlord. So I had to put the old cylinder back in, because of condo rules about the property management company needing keys. (Though I later learned that the property management company might not have been able to find my unit's key if they ever wanted to. One day, the fire department was at the building, trying to get into a different unit, which had an alarm sounding, but they found that the key box was empty. I was there, so I called the management company, but they refused to send a runner with the key. Even after I handed my phone to the firefighter in charge, and he identified himself and asked them again. :) reply Keirmot 10 hours agorootparentprevI’m in Europe, but the first thing I said to the renters of my Grandmother’s house was “here’s the keys, these are all the copies, but feel free to change the lock if it makes you feel more comfortable”. People need to feel safe in their own homes. reply lxgr 12 hours agorootparentprevThis is quite different around the world. I've rented both at places where I could bring my own security locks and others where the landlord pretty much insisted in having a copy of all keys so they could enter in an emergency (e.g. a water leak) without breaking down the front door. reply vizzah 11 hours agorootparentprevChange the cylinder. Put the old one back, when your rental period ends. Takes 10 mins to replace the cylinder. reply hunter2_ 6 hours agorootparentprevWhat about giving a copy of the new key to the landlord? It's not as secure as keeping the key to yourself of course, but at least it eliminates the likelihood of prior tenants having a copy which is usually the primary threat. reply vdqtp3 12 hours agorootparentprevI agree, I have never rented anywhere where I was permitted to change the locks. I have changed the locks everywhere I have rented. reply c0pium 8 hours agorootparentInteresting, when you did so did you know that you were assuming liability for the damage caused by the landlord being unable to access the property in an emergency? reply hunter2_ 6 hours agorootparentprevWhen you say you weren't permitted, are you referring to the absence of any language on the topic, or the presence of language saying that you shall not? Assuming the former, proceeding to do it doesn't seem noteworthy. reply mdekkers 7 hours agorootparentprevPretty much everywhere in Europe it is a legal right to be able to do so. reply ratg13 12 hours agorootparentprev>“Oops forgot to tell you.. was I not allowed to do that?” The only way they would ever find out is if they were trying to enter your place unannounced. reply bigiain 9 hours agorootparentAnd even then \"You had trouble getting in? Oh yeah, the lock is sometimes really sticky. If it's jammed, it helps if you lean on the door while trying to turn the key, then let off the pressure while you're twisting the key. What did you need to get in for? Shouldn't you have called first? I'll be back around {30-60 mins after your excepted arrival time} and can let you in then.\" (meanwhile swap the original barrel back in before they show up again) reply c0pium 8 hours agorootparentNow that busted pipe to the hot water heater has been pumping water into the unit for an extra hour, and you’re on the hook for changing the lock in violation of your lease. But cool story about the cylinder. reply Turing_Machine 12 hours agorootparentprevMaybe operating on the \"easier to ask forgiveness than permission\" principle? I think landlords have to give you notice before entering your unit in most areas. Swapping locks is maybe a ten minute job (probably less if you've done it a lot). There's nothing to stop a tenant from swapping out the locks, then swapping the landlord's locks back in before a scheduled visit. reply iancarroll 17 hours agoprevI worked on this research along with many others, happy to answer any questions! Our disclosure is also available at https://unsaflok.com. reply aftbit 16 hours agoparentWhen do you plan to release technical details on the attack? Surely the long tail of door locks will not be replaced for a decade or more. reply rwmj 14 hours agoparentprevHow did Saflok respond? Were they collaborative or did they try to threaten you / suppress the information? reply iancarroll 8 hours agorootparentThey have been taking it seriously although they didn’t have any sort of formal bug bounty / security disclosure method at the time. The disclosure timeline is in our article as well! reply ildjarn 17 hours agoparentprevDid you set out to find a vulnerability or just stumble on it? If setting out to find a vulnerability, how do you get started? What is the “open ide, write print(“hello world”)” for this kind of work? reply xeornet 8 hours agorootparentThe article explains that they were at a hackathon of sorts, where these 2 were specifically targeting the locks/passes. I would assume reading the cards with a reader would be a great start. reply kidbomb 14 hours agoparentprevThis part caught my eye: \"Note that this information only applies to dormakaba Saflok systems; several other lock manufacturers use MIFARE Classic keycards and are not affected by the Unsaflok vulnerability\" So it is likely they way that Saflok implemented MIFARE Classic. Will start to read about this protocol more. reply lxgr 12 hours agorootparentAt this point, MIFARE Classic can pretty much be considered plaintext. There are very fast card-only cloning attacks against even the newest \"hardened\" cards, and in many of these lock systems (no idea about Saflok in particular though), MIFARE is the only layer of cryptography, and the card only contains a bitmask of locks/doors that it should be able to open. reply zettabomb 10 hours agorootparent>There are very fast card-only cloning attacks against even the newest \"hardened\" cards Do you mean for MIFARE Classic or for all RFID cards? I was not aware of any cloning attacks for types such as HID Seos. reply rwmj 12 hours agorootparentprevI have an original London Underground Oyster Card which still works fine! It's MIFARE Classic according to Wikipedia, and do often wonder when TfL will cancel them. reply lxgr 12 hours agorootparentThey'll probably keep it around either indefinitely, or will replace it with a fully account-based scheme where there's nothing stored on the card itself (i.e. no stored-value balance) other than an authentication key for the card number. That's the model they already use for bank (credit and debit) cards too, so they need the backend to manage a deferred account-based system anyway. That's also what the MTA in New York does: They've never supported stored-value cards, and their new physical OMNY cards are effectively just a weird type of closed-loop EMV payment card. reply sschueller 12 hours agoparentprevIf I stay at a hotel with such a lock how can I tell it's affected? If the hotel hasn't patched it can I patch my rooms door myself without causing issues to the hotel? reply michaelt 12 hours agorootparentYou can generally assume at any hotel with keycards, that any other guest who wants to can get into your room. The only question is whether they do some hacker shit, or whether they just go to reception and say \"My keycard isn't working, I'm in room 123\" and reception gives them a new keycard for room 123, with no ID check and no questions asked. Luckily thieves are relatively rare and 97% of hotel rooms just contain a suitcase of second-hand clothes. reply jules-jules 12 hours agorootparentI locked myself out of the room on several occastions, and at the very least they ask for your name and double check in the system. It's not as easy as you describe. reply blendergeek 10 hours agorootparentI have often either locked myself out of a hotel room or demagnetized my key. I have never been asked my name or been verified in any way (different clerk than the one I checked in with, etc). While I'm sure some hotels (maybe more upscale ones?) do verification, it is far from universal in the USA. reply kadoban 4 hours agorootparentprevNames are not generally considered secret. It will be relatively easy for someone to social engineer the name for a room either with the desk or with you (calling the room). reply c0pium 8 hours agorootparentprevI was traveling a lot for work at one point, and I decided to test this out. I would ask for a new key at every hotel I stayed at, and make a point to not tell them my name unless they asked. They almost never did. reply michaelt 11 hours agorootparentprevPerhaps you're staying at better hotels than I am? In my experience, keycards fail so often that the hotel workers don't bat an eyelid when you say your card has failed, they just make you a new one. reply Retr0id 12 hours agorootparentprevA little social engineering would sort that out reply paulddraper 9 hours agorootparentprevSimilar to the wrench principle. [1] [1] https://xkcd.com/538/ reply iancarroll 9 hours agorootparentprevOur disclosure mentions how to try and detect a vulnerable hotel, but it’s not possible to patch the lock yourself. reply gabrielsroka 12 hours agorootparentprevI think it's in the bottom of the article reply jerpint 16 hours agoprev> An attacker only needs to read one keycard from the property to perform the attack against any door in the property That’s a pretty serious vulnerability, pretty much all it takes is to be a guest at a hotel reply duderific 12 hours agoparentOften times, the hotels don't even require to turn in these cards upon checkout, so they are thrown in the trash. A nefarious actor could just pull one out of the trash and so not even have to be a guest in the hotel. reply neilv 12 hours agoprev> [...] shared the full technical details of their hacking technique with Dormakaba in November 2022. [...] told by Dormakaba that, as of this month, only 36 percent of installed Safloks have been updated. Did Dormakaba not make this a first-priority, all-out effort? Or have 2/3 of the installations been offered a timely free fix, but are dragging their feet for some reason? > “Our customers and partners all take security very seriously, and we are confident all reasonable steps will be taken to address this matter in a responsible way.” That \"reasonable\" in a PR response is suspicious. Wikipedia: > dormakaba Holding AG is a global security group based in Rümlang, Switzerland. It employs more than 15,000 people in over 50 countries. Sounds like they probably have the resources, if they have the will to solve this before potential very bad things happen to some hotel customers. > publicly traded on the SIX Swiss Exchange. https://www.google.com/finance/quote/DOKA:SWX?comparison=IND... https://www.google.com/finance/quote/DOKA:SWX?comparison=IND... reply lazide 12 hours agoparentHotel and hotel safe locks have always been of dubious security. reply LeoPanthera 11 hours agoprevApparently I don't understand how hotel card keys work. I always assumed that keys were manufactured with a random UUID inside them, and then when you checked in, a random card was attached to your room and given to you. When you try to open a door, it compares your card's ID to the room database to see if the door should open. Is that... not how it works? Because that seems simpler than anything that involves encryption, or actually writing shit to the card. reply ahazred8ta 9 hours agoparentThe card machine at the front desk writes a message onto the card, which says: Hey, lock #301, this card is authorised to open you as of timestamp X, and all cards before timestamp X are now invalid. Most older e-locks are powered by a 9V battery and are not wired to a central server. reply jcrawfordor 10 hours agoparentprevThe locks don't have network connectivity, so they have no way to check. Access has to be managed by key expiry and replacement. There are network-connected systems but they can be considerably more expensive to install. reply denysvitali 8 hours agoparentprevUUID can be cloned (with modified cards). This could make a clone attack even easier since you don't need Key A/B to read the contents. reply LeoPanthera 8 hours agorootparentI just imagined that cloning would not be a big deal considering the short life of a typical hotel stay. reply WrongAssumption 9 hours agoparentprevHaving doors not work because the network is unavailable or the database is corrupted sounds neither simpler nor better. reply LeoPanthera 8 hours agorootparentWell, valid key IDs could be pushed to the locks, and remembered for a short time. reply palata 10 hours agoparentprevIt would mean that the door's reader is connected to the network. Is it? reply Kinrany 10 hours agoparentprevI wonder if it's possible to answer pubkey challenges without electricity reply tromp 17 hours agoprevhttps://archive.is/a7ntC reply r3trohack3r 8 hours agoprevI travel with a door jammer. Most hotel door locks I’ve seen are designed to be opened from the outside. A door jammer wedges the door shut. With it, I sleep better at night. reply namaria 1 hour agoparentWhile my instinct is to do the same, depending on what jurisdiction you travel to, you might be liable for damages if staff tries to open the door and decide to break in because you were in the shower or sleeping on ambien or something like that. reply oneplane 12 hours agoprevRFID and NFC are the new Magstripe and Barcodes. People think that they are mysterious things that are secure because they aren't able to see what they mean. But in reality, they are all still just a machine-readable number. (even if a rolling key, challenge-response or pubkey authentication is supported, we're often still just using a single number, but my point is more about the perceived obscurity for the public) reply lxgr 12 hours agoparentIt really depends. There are some contactless tags that really do nothing other than transmit a static identification number which is trivially spoofable, but many systems today use cryptography (again, some long cracked and horribly outdated, but others quite strong). I have a contactless card that runs GPG as a Java Card applet and creates 4096-bit RSA signatures. That's pretty secure! reply hnav 3 hours agoparentprevDESFire based systems, HID iClass SE (properly installed where the reader only accepts the SE credential) are generally pretty secure. reply samcheng 16 hours agoprevSeems like it's only a matter of time before someone writes a Flipper Zero script to do this. reply datameta 15 hours agoparentThe more pertinent matter is that it took this long for RFID exploits to start catching the public eye. RFID is the least secure communication protocol that could be used for locks. At the very least we should have NFC be the standard. Someone with the intent and know-how to crack RFID readers could put together a hardware tool to do so. Does the Flipper Zero provide such a tool? Yeah. Does the responsibility of following ethics fall with the user? Debatable, but I think absolutely yes. If one carries around a lockpicking set and learns how to use it, they can go right ahead, correct? We accept the fact that people exist that can pick locks and yet 80% of states allow possession and use of lockpicking tools in a legal manner. reply vel0city 12 hours agorootparentRFID just means radio frequency identification. It does not imply any particular standard. NFC can be a type of RFID system. Even saying NFC isn't necessarily implying any particular system of protection, basic NFC has no real protection out of the box and would require the higher-level protocols to actually provide any kind of encryption or relay protection or the like. An NFC-based system of RFID can also be incredibly insecure. Saying \"RFID is insecure, use NFC\" is like saying \"radio is insecure, use WiFi.\" NFC is a subset of the concept of RFID, much the same way WiFi is a subset of digital radio protocols. reply datameta 11 hours agorootparentIn my opinion it's clear that NFC is indeed designed with a higher focus on security than general RFID applications. In fact it emphasizes secure data exchange by design. Yes it is a subset of RFID technology operating at 13.56 MHz. Because NFC enables encrypted communication over very short distances (typically less than 4 cm), it is more challenging for unauthorized interception to happen. Also NFC supports two-way communication, which allows for more dynamic and secure interactions between devices, such as payment systems or secure access controls. RFID, while versatile and utilized across a range of applications from inventory management to access control, does not inherently prioritize security to the same extent. Its broader application spectrum means that specific security measures can vary significantly based on the use case and the design of the RFID system. For example, passive RFID tags, which are widely used due to their cost-effectiveness and simplicity, can be read from distances up to several meters, potentially exposing them to unauthorized scans. Active RFID tags offer longer read ranges and can incorporate additional security features, but their cost and complexity limit their use to specific applications. Therefore, when comparing the security aspects directly, NFC's design principles inherently prioritize secure exchanges, leveraging close proximity communication and encryption standards that are well-suited for transactions and sensitive data exchanges. This focus on security, combined with the technology's adaptability for consumer use (e.g., smartphones for payments), underscores NFC's advantage in scenarios where security is paramount. Most hotels use non-NFC RFID and on top of that most use passive tags. So it is certainly an inherent security flaw of hotel door locks. Unfortunately non-meatspace security is also drastically in need of choosing more effective already existing measures. reply vel0city 9 hours agorootparentYou keep suggesting NFC has a lot of security concepts baked in, but it's not really true. The base standards of NFC provide no encryption concepts. It provides no protection against sniffing. It provides no authentication. It provides no relay protection. The only \"security\" you get is it's designed for near communication, but you can absolutely read and write NFC tags from a distance with the right hardware. Base NFC has almost no security and relies on protocols on top to be secure. For example, Amibos use NFC and are trivially duplicated with cheap writable NFC tags. Contactless credit cards aren't secure because they do NFC, they're secure because NFC allows for an EMV transaction, it's the EMV handshake that handles all the security. Once again, suggesting NFC just has a lot of security by default is acting like WiFi is always secure. But even worse, because at least WiFi standards have encryption and what not built in and optional, NFC doesn't even provide that. And then you point out passive tags as if that's a thing that makes RFID less secure (ignoring NFC used for identification is RFID) but then I guess don't realize NFC allows for passive tags as well. I don't need to change batteries on my Amibos or the NFC stickers I put on the Wi-Fi info around the house. You could build a key card system with NFC that has the same or worse system as older key card platforms. It being NFC gives you absolutely no additional benefit. reply wongarsu 14 hours agorootparentprevIt's not just that RFID isn't very secure, it's that a lot of locks are using the worst possible implementations. Just checking the ID of the RFID chip against a whitelist is an astonishingly common method. Not only makes that access cards easy to clone and provides no cryptographic security at all, if you bulk buy access cards you often get sequentially numbered cards ... reply rescbr 13 hours agorootparentOTOH I can use my credit card to open my door - and this is even advertised as a feature by the manufacturer! reply OkGoDoIt 11 hours agorootparentWhich lock do you have? I’ve been wanting to get one with this functionality but I’ve never successfully found a smart lock that works like that. reply Nextgrid 14 hours agorootparentprevRFID is just a bidirectional link between the reader and the card. The security depends on what you send over that link. RFID in itself doesn't imply security or insecurity. reply lmm 11 hours agorootparentprevFeels like a very US-specific mentality. Back in the UK carrying lockpicking tools outside your home without good reason is \"going equipped\" and a crime in itself, and that's generally supported. reply int_19h 2 hours agorootparentUK is notoriously prohibitive of things that could be used in crimes; I mean, we're talking about a country where a screwdriver is potentially an \"offensive weapon\" if carried without a \"legitimate purpose\". However, that is a fairly extreme case, and most countries don't have such laws on the books (or if they do, what's illegal is \"possession with intent\"). reply empathy_m 5 hours agorootparentprevUS lockpicking enthusiasts tend to know their states' laws (see e.g. https://www.toool.us/lockpicking-laws.php) In general it's probably okay to bring your picks somewhere in most parts of the country if you're a hobbyist. In general it's a bad idea to carry picks if you're doing anything that a prosecutor could construe as breaking into a building to steal things. This is an area to be particularly aware of for urban exploration, where trespassing is bad but burglary with burglarious tools is like felony bad. reply datameta 11 hours agorootparentprevI don't have a formed opinion on available lockpicking kits other than if you make them contraband they will still be available in different ways and that measure will have the opposite effect. But a lockpicking kit has one purpose, it's picking locks. A Flipper Zero type device has plenty of legitimate, legal, personal uses in an IoT equipped home. The Flipper Zero being banned will lead to a flood of copies, not to mention black market OEM versions. reply lmm 10 hours agorootparent> if you make them contraband they will still be available in different ways and that measure will have the opposite effect. Banning things doesn't make them impossible to get hold of but it does make it harder/more costly, which is all that any anti-crime measure can hope to achieve. Why do you say the opposite effect? This isn't like alcohol (or even, to an extent, weed) where a majority of ordinary decent people use it occasionally and want it to be available. Most people have never owned or used lockpicks and don't see any reason to have them if you're not a criminal. (And, sadly, that's probably also true of a flipper zero). reply nerevarthelame 16 hours agoprevIt seems irresponsible that it took dormakaba more than a year to fix a single lock. And even now, 1.5 years after the initial disclosure, still only around a third have been updated. reply dpsych 14 hours agoprevhttps://archive.is/gifH6 reply JudasGoat 12 hours agoprevhttps://archive.ph/PypxP reply seplox 11 hours agoprev> Dormakaba started selling Saflok locks in 1988, which means that vulnerable locks have been in use for over 36 years. Ok, my eyebrows are up. Authentication has grown so much as a field since then that I'm having trouble with the idea that this flaw has always been present. In fact, Saflok predates MIFARE Classic by at least five years. Perhaps all will become clear if a full technical disclosure is ever made available, but it seems like the authors are making an overstatement here. https://unsaflok.com/ reply iancarroll 9 hours agoparentOur understanding is that the magnetic stripe version of Saflok (which indeed predates MIFARE Classic) is vulnerable to the same issues, just in a different card format. reply Symbiote 17 hours agoprev> They warn that the deadbolt on the room is also controlled by the keycard lock, so it doesn't provide an extra safeguard. That is the biggest surprise to me. I had assumed getting around the deadbolt would require a locksmith or breaking the door. (What's the point of it otherwise?) reply Cheer2171 16 hours agoparentPeople lock themselves in hotel rooms and refuse to leave more often than you'd think. reply westmeal 17 hours agoparentprevA lot of hotels I've been to also have a latch you can physically lock the door with which would prevent someone from actually entering, but I bet you may be able to slowly pry that open with a jig of some sort. reply Onawa 17 hours agorootparenthttps://foleybelsawlocksmithing.com/products/hotel-door-hing... reply drspacemonkey 17 hours agorootparentprevIt's called a \"swing bar\". It's easy to open from tho2e outside with some duct tape and a rubber band, unfortunately. Plenty of easy instructions on YouTube. reply fitchjo 16 hours agorootparentprevI assume/hope the newer versions in hotels that are a little l bracket that flips are little harder to get open? reply Kye 16 hours agorootparentprevThere are tools specifically designed to open these. At best, they make an attempt to break in more conspicuous. reply sandworm101 17 hours agoparentprev>> I had assumed getting around the deadbolt would require a locksmith or breaking the door. Look into what happens when someone pulls a fire alarm. Some building-wide lock systems will actively unlock doors during a fire scenario. reply swells34 17 hours agoparentprevGood feels and security theater reply dylan604 17 hours agoparentprev> (What's the point of it otherwise?) How else would the hotel staff enter the room when the current occupant is locked in the room, but dead or some lesser medical emergency condition? reply Symbiote 16 hours agorootparentBeing dead isn't urgent, they could call a locksmith. A medical emergency would justify breaking the door. The same applies to my apartment door. reply wongarsu 14 hours agorootparentOnce the hotel is big enough this will occur so frequently that all those locksmith bills and new doors incur a notable cost, enough that for your next lock system you choose something that lets hotel employees override the deadbolt. Most customers won't care or notice, and those that do are offset by those that got inconvenienced by someone breaking down the door next to them. reply urbandw311er 14 hours agorootparentprevIt only becomes non-urgent once you can get in the room to confirm they’re dead. reply shermantanktop 10 hours agorootparentSchrödinger's Hotel Guest. reply dylan604 14 hours agorootparentprevImagine how much faster it would be with an emergency key unlocking the security deadbolt rather than just the door lock. Housekeeping keys do not have the ability to unlock the security bolt, but management does that can used by the appropriate emergency responders. Police doing an investigation with a warrant would be appropriate, but a cop with a hunch would not reply dboreham 17 hours agoprevPresumably with Scotch Tape or Post-it Notes. reply barbazoo 16 hours agoparentNot that kind of \"3M\" :) reply jeffbee 16 hours agoprevI hate to break it to anyone but most locked doors can be opened \"in seconds\" by a variety of means. For the most part the locked state is a signal of prohibition, rather than a meaningful enforcement thereof. reply dhosek 15 hours agoparentI could open any locked door at my high school by slipping my ID in the gap between the door and the frame and wedging the bolt open. I kind of suspect that forty years later, this vulnerability remains. reply pineaux 3 hours agorootparentFormer locksmith here. That is called \"to flipper\" a door. (Guess that is where the flipperzero name comes from) However you can only flipper doors that are held closed by the latch bolt. If the lock deadbolt is engaged, you cannot flipper it, because the deadbolt will not budge when manipulated by a card or piece of plastic. Technically a lock without an engaged deadbolt is not really \"locked\" but \"closed\". That being said, an unbelievable amount of people believe their doors are locked when in fact they are closed. reply SquirrelOnFire 16 hours agoparentprev\"Locked doors only stop honest people\" -Abe Lincoln reply c0pium 8 hours agoparentprevLocks that most people are willing to spend the money to buy are purely there to keep honest people honest. reply jowea 12 hours agoparentprevEven then, some of those means are noisy, require special equipment or skills or make it obvious a break in happened. reply bluGill 14 hours agoparentprevMost locked doors can be bypassed even faster in some other way than unlocking them. A rock through the window... reply cesarb 13 hours agorootparent> Most locked doors can be bypassed even faster in some other way than unlocking them. A rock through the window... This is a bit harder when said window is only reachable from the outside, and is 78m above ground level (and all the walls are brick, so they're stronger than the wooden door). reply shadowgovt 13 hours agoparentprevAnd especially in hotels, locked doors aren't about keeping everyone out forever (there's dozens of reasons that'd be an awful idea, from cleaning staff needing access to medical emergencies). They're about making it inconvenient enough / loud enough to gain unauthorized access that someone is going to notice and complain to the manager. reply asynchronous 13 hours agoprevGoing to go against the grain and say thank you to devices like the Flipper Zero for getting vulnerabilities like this out into the public eye for scrutiny. reply saagarjha 12 hours agoparentNot really against the grain here :) reply pajko 17 hours agoprevJust like microcorruption in real life :) https://microcorruption.com/map reply NooneAtAll3 13 hours agoparentI love these asm hacking challenges reply jdalgetty 15 hours agoprevAnother strike against the Flipper Zero! reply brevitea 12 hours agoparent> \"their attack could be pulled off with little more than a $300 Proxmark RFID read-write device and a couple of blank RFID cards, an Android phone, or a Flipper Zero radio hacking tool.\" And Android, and EBay, and Proxmark... reply CyberDildonics 12 hours agoprevBy exploiting weaknesses in both Dormakaba's encryption and the underlying RFID system Dormakaba uses, known as MIFARE Classic, Carroll and Wouters have demonstrated just how easily they can open a Saflok keycard lock. reply mint2 17 hours agoprev [–] Okay that title was confusing, the 3M is quantity not the company 3M’s locks. The locks are not build by 3M or a subsidiary. reply TylerE 17 hours agoparentIt's especially confusing because 3M does make almost every thing under the sun, from respirators to electrical tape to medical equipment and supplies. No locks as far as I can find though. reply lozf 15 hours agorootparentBut with a roll of 3M Gaffa Tape, you can secure an hotel room door such that those inside inside the room can't open it without help from outside. * other brands of very sticky strong tape are available. reply aqfamnzc 15 hours agorootparentHow? reply lozf 10 hours agorootparentApply tape to the door and frame length-ways at the top and all the way down the opening edge. Layer it up with some overlap to re-enforce both whats on the door, and the door frame. Do likewise at the bottom edge, adding a seal to the floor / carpet. Don't be frugal (these are drunk roadies in full prank mode)... use your imagination ;) reply alephnerd 14 hours agorootparentprevJust tape the victims to a bed and relive Gerald's Game reply golergka 13 hours agorootparentprevYou could, of course, still open it with 3M Glass Bubbles or explosives from other brands. reply ale42 11 hours agorootparentSince when are glass bubbles explosive? reply Arrath 8 hours agorootparent3M product brochure: https://multimedia.3m.com/mws/media/1226911O/glass-bubbles-f... See page 64: https://www.austinpowder.com/wp-content/uploads/2019/01/The-... Not explosive in and of themselves, but a component in modern industrial explosives. As a sensitizer and a density modifier. reply ale42 1 hour agorootparentThanks! I was not aware of their use in explosives, I thought to their use as a filling/density modifier in polymers. reply mikestew 17 hours agoparentprevIt would be nice if the title could get changed, as per below, because it confused me, too: https://corporatefinanceinstitute.com/resources/fixed-income... reply Shog9 17 hours agorootparentThe original title sez \"millions\" and is clearly distinct from both \"Minnesota mining and manufacturing\" and \"millimeters\". reply rad_gruchalski 13 hours agorootparentYes, because the millimeter is “mm”, a meter is “m” and “M” means mega (for example MPa for megapascal) in SI. reply Shog9 9 hours agorootparentThe gp here was referencing a weird little bit of accountant jargon that uses a corruption of roman numerals to indicate million as a product of thousands. It's a terrible idea, but crops up in software circles occasionally due to the number of folks stuck writing financial software. AFAIK, even accountants are slowly moving away from it for ... Obvious reasons. reply ShamelessC 13 hours agoparentprevWhile I agree, I think you underestimated how much this comment thread would wind up somewhat derailing conversation about the actual article. Dear lord people it's a simple disambiguation - there's no need for upwards of 40 comments about it. reply dimask 13 hours agorootparentWell it is apparent that so many people got confused (me included) that it deservedly became part of the conversation. reply dpsych 14 hours agoparentprevDoes 3M stand for 3 musketeers? reply ada1981 13 hours agoparentprevIt should be 3MM reply toss1 17 hours agoparentprev [–] Yes, please change it to 3MM, which also abbreviates to \"3 million\". My first impression was strongly that 3M had some lock system that was now compromised, not that it was referring to 3 million locks in the wild. Also perhaps consider expanding the headline character limit above 80, or maybe not count numbers in the total. reply araes 16 hours agorootparentHow about \"Hackers Found a Way to Open Any of 3 Million Hotel Keycard Locks in Seconds\" its only 75 characters. Nobody has to guess about abbreviations or whether it's really Latin or mm. reply mikewarot 16 hours agorootparentprev3 millimeters is a really small lock. reply amlib 14 hours agorootparentIt's the World's tiniest open-source lock. reply samstave 16 hours agorootparentprevI think its the lock found on most kids' diaries! reply brianleb 17 hours agorootparentprevActually, I believe what you want is 3mm, which I believe they use in accounting. Lowercase m in this instance would stand for milli-, as in thousand. So 3mm would be 3 thousand thousand. 3M is technically correct, though confusing in this specific case. Capital M would indicate Mega, as in the progression from kilobit to megabit to gigabit. reply Yizahi 16 hours agorootparentGamers just write it as 3kk. (PS: never seen MM used as a \"million\" even in my two decades on the internet) reply kukkamario 14 hours agorootparentEh... Haven't seen anyone using 3kk to abbreviate 3M. 3M is common and B for billion. Those are also used in many games to shorten currencies. reply squigz 14 hours agorootparentThis seems to be a (IRL) cultural thing - the vast majority of people I play EVE with use k/m/b/t, but a small percent does use k/kk/kkk reply lowbloodsugar 17 hours agorootparentprev3MM is three million, for US accountants and thus engineers writing docs for VPs. 3mm is three millimeters. reply neilv 17 hours agorootparentprev3mm hotel keycard form factor. reply toss1 15 hours agorootparentprevInteresting, I'd seen it as \"MM\", as in \"Thousand Thousand\" in Roman numerals. Of course lowercase \"mm\" is most recognizable as millimeter, so that would be confusing in a different way. reply dylan604 17 hours agorootparentprevit would take all of about 3 seconds to realize why an unlimited character count would break the site's layout and know that it will never happen. i do agree that the \"don't editorialize\" and strict char count are very contradictory, but suggesting that the site changes because of it is also naive at best. reply stavros 16 hours agorootparentIt took about 1 second to realize that \"80 characters\" and \"unlimited\" aren't the only two options. reply toss1 15 hours agorootparentExactly; thank you. I was definitely NOT thinking of unlimited. I was thinking of 80chars, but excluding numerals (123, etc) and number text (\"thousand\", \"million\" etc.) and maybe a few other items excluded from the count, with a maximum of 100, or whatever number actually will not break the layout. I've found it frustrating trying to fit in 80chars, and e.g., finding that ampersand gets expanded so it actually counts more than \"and\", so it is not a single-rule 80 chars; perhaps a few more sophisticated rules might help. Just a suggestion. reply aqfamnzc 15 hours agorootparentNot that it really matters, but I found it interesting thinking of ways this could be broken... million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million million reply toss1 12 hours agorootparentyou missed the >>\"with a maximum of 100,\" reply swader999 15 hours agorootparentprevMany 3M adhesives would hold the hotel doors closed. reply mindslight 14 hours agorootparentprevOr just drop all the clickbait crap from the headline - \"Hackers\", \"any\", \"3 million\" and \"in seconds\" are all just fluff meant to create an emotional response. Change the subject to where the responsibility lies, the locks themselves or the lock manufacturer, and add \"major brand\" or \"widely deployed\" if it's necessary to separately indicate notoriety. reply hulitu 16 hours agorootparentprevmm is milimeters. MM does not exist. reply samstave 16 hours agorootparentMM = 1,000 * 1,000 == 1,000,000 <- thats where MM comes from Roman numerals. jeasus christ: https://corporatefinanceinstitute.com/resources/fixed-income... Seems like you engineers have been behind code and not having to defend your project budgets to CFOs and stakeholders often. reply devindotcom 16 hours agorootparentMM is 2,000 in Roman numeral notation, not a million. reply wongarsu 14 hours agorootparentYeah, but finance people (way after the roman times) adopted M as a suffix for thousands, and once you treat it as a suffix or prefix it made sense (to them) to use MM for million. You sometimes see the same done in engineering-adjacent contexts with SI prefixes, like using kk for million. reply rescbr 13 hours agorootparentThe finance people that I know uses K for thousands and MM for million. reply yodon 12 hours agorootparentTech and science use K for thousand and M for million. Using K and MM in finance reduces the odds of an incorrect interpretation of a single M. reply maratc 15 hours agorootparentprevSo MMXXIV = 1,000 * 1,000 * 10 * 10 * 1 * 4? reply exe34 17 hours agorootparentprev [–] Maybe 3M should rename themselves to something less confusing. reply landosaari 14 hours agorootparent\"In business news, 3M and M&M have merged to form, get this, Ultradyne Systems.\" Simpsons S14E12 [0] [0] https://www.springfieldspringfield.co.uk/view_episode_script... reply toss1 16 hours agorootparentprev [–] They were originally \"Minnesota Mining and Manufacturing Co.\" Seems the 3M branding has worked quite well... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Hackers have uncovered Unsaflok, a method capable of unlocking any of the 3 million Saflok-brand RFID-based keycard locks found in hotels worldwide rapidly.",
      "Dormakaba, the company behind Saflok, is in the slow process of updating and replacing the vulnerable locks, with only 36% addressed since becoming aware of the problem in 2022.",
      "Researchers advise hotel guests to remain vigilant and assess if their keycard is still at risk by utilizing the NFC Taginfo app due to the persisting dangers associated with these insecure locks."
    ],
    "commentSummary": [
      "Hackers have found vulnerabilities in hotel keycard locks due to outdated systems with low-cost and insecure standards, as well as risks from frequent reissuing of keycards and lack of liability for companies prioritizing cost over security.",
      "Maintenance workers use unconventional methods to open hotel room doors when key card systems fail, sparking debates on emergency keycards and hotel policies, and raising concerns about the security of RFID keys and physical locks in apartment buildings.",
      "Discussions also cover vulnerabilities in Dormakaba Saflok locks, RFID technology issues, and the effectiveness of different locking systems in preventing unauthorized access, alongside suggestions for clearer communication and abbreviation standards."
    ],
    "points": 271,
    "commentCount": 197,
    "retryCount": 0,
    "time": 1711033076
  },
  {
    "id": 39782356,
    "title": "DuckDB: Streamlined JSON Querying with SQL",
    "originLink": "https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/",
    "originBody": "DuckDB as the New jq March 21, 2024 3 minute read Recently, I’ve been interested in the DuckDB project (like a SQLite geared towards data applications). And one of the amazing features is that it has many data importers included without requiring extra dependencies. This means it can natively read and parse JSON as a database table, among many other formats. I work extensively with JSON day to day, and I often reach for jq when exploring documents. I love jq, but I find it hard to use. The syntax is super powerful, but I have to study the docs anytime I want to do anything beyond just selecting fields. Once I learned DuckDB could read JSON files directly into memory, I realized that I could use it for many of the things where I’m currently using jq. In contrast to the complicated and custom jq syntax, I’m very familiar with SQL and use it almost daily. Here’s an example: First, we fetch some sample JSON to play around with. I used the GitHub API to grab the repository information from the golang org: % curl 'https://api.github.com/orgs/golang/repos' > repos.json Now, as a sample question to answer, let’s get some stats on the types of open source licenses used. The JSON structure looks like this: [ { \"id\": 1914329, \"name\": \"gddo\", \"license\": { \"key\": \"bsd-3-clause\", \"name\": \"BSD 3-Clause \\\"New\\\" or \\\"Revised\\\" License\", ... }, ... }, { \"id\": 11440704, \"name\": \"glog\", \"license\": { \"key\": \"apache-2.0\", \"name\": \"Apache License 2.0\", ... }, ... }, ... ] This might not be the best way, but here is what I cobbled together after searching and reading some docs for how to do this in jq: % cat repos.jsonjq \\ 'group_by(.license.key)map({license: .[0].license.key, count: length})sort_by(.count)reverse' [ { \"license\": \"bsd-3-clause\", \"count\": 23 }, { \"license\": \"apache-2.0\", \"count\": 5 }, { \"license\": null, \"count\": 2 } ] And here is what it looks like in DuckDB using SQL: % duckdb -c \\ \"select license->>'key' as license, count(*) as count \\ from 'repos.json' \\ group by 1 \\ order by count desc\" ┌──────────────┬───────┐ │ license │ count │ │ varchar │ int64 │ ├──────────────┼───────┤ │ bsd-3-clause │ 23 │ │ apache-2.0 │ 5 │ │ │ 2 │ └──────────────┴───────┘ For me, this SQL is much simpler and I was able to write it without looking at any docs. The only tricky part is querying nested JSON with the ->> operator. The syntax is the same as the PostgreSQL JSON Functions, however, so I was familiar with it. And if we do need the output in JSON, there’s a DuckDB flag for that: % duckdb -json -c \\ \"select license->>'key' as license, count(*) as count \\ from 'repos.json' \\ group by 1 \\ order by count desc\" [{\"license\":\"bsd-3-clause\",\"count\":23}, {\"license\":\"apache-2.0\",\"count\":5}, {\"license\":null,\"count\":2}] We can still even pretty print with jq at the end, after using DuckDB to do the heavy lifting: % duckdb -json -c \\ \"select license->>'key' as license, count(*) as count \\ from 'repos.json' \\ group by 1 \\ order by count desc\" \\jq [ { \"license\": \"bsd-3-clause\", \"count\": 23 }, { \"license\": \"apache-2.0\", \"count\": 5 }, { \"license\": null, \"count\": 2 } ] JSON is just one of the many ways of importing data into DuckDB. This same approach would work for CSVs, parquet, Excel files, etc. And I could choose to create tables and persist locally, but often I’m just interrogating data and don’t need the persistence. Read more about DuckDB’s great JSON support in this blog post: Shredding Deeply Nested JSON, One Vector at a Time Update: I also learned that DuckDB can read the JSON directly from a URL, not just a local file: % duckdb -c \\ \"select license->>'key' as license, count(*) as count \\ from read_json('https://api.github.com/orgs/golang/repos') \\ group by 1 \\ order by count desc\" Updated: March 21, 2024 Share on Twitter Facebook LinkedIn Previous Next",
    "commentLink": "https://news.ycombinator.com/item?id=39782356",
    "commentBody": "DuckDB as the New jq (pgrs.net)270 points by pgr0ss 15 hours agohidepastfavorite47 comments xg15 10 hours agoThe most effective combination I've found so far is jq + basic shell tools. I still think jq's syntax and data model is unbelievably elegant and powerful once you get the hang of it - but its \"standard library\" is unfortunately sorely lacking in many places and has some awkward design choices in others, which means that a lot of practical everyday tasks - such as aggregations or even just set membership - are a lot more complicated than they ought to be. Luckily, what jq can do really well is bringing data of interest into a line-based text representation, which is ideal for all kinds of standard unix shell tools - so you can just use those to take over the parts of your pipeline that would be hard to do in \"pure\" jq. So I think my solution to the OP's task - get all distinct OSS licenses from the project list and count usages for each one - would be: curl ...jq '.[].license.key'sortuniq -c That's it. reply pcthrowaway 9 hours agoparent> I still think jq's syntax and data model is unbelievably elegant and powerful once you get the hang of it - but its \"standard library\" is unfortunately sorely lacking in many places After a few years of stalled development, jq has been taken over recently by a new team of maintainers and is rapidly working through a lot of longstanding issues (https://github.com/jqlang/jq), so I'm not sure if this is still the case reply xg15 9 hours agorootparentWasn't aware of that, that's great to hear! I think if there is one utility that deserves a great maintainer team then this one. But if we saw some actual improvements in the future, that would be awesome! I have a list of pet peeves that I'd really like to see fixed, so I'm gonna risk a bit of hope. reply mightybyte 49 minutes agoparentprevYour command line solution doesn't give quite the same result as OP. The final output in OP is sorted by the count field, but your command line incantation doesn't do that. One might respond that all you need to do is add a second \"| sort\" at the end, but that doesn't quite do it either. That will use string sorting instead of proper numeric sorting. In this example with only three output rows it's not an issue. But with larger amounts of data it will become a problem. Your fundamental point about the power of basic shell tools is still completely valid. But if I could attempt to summarize OP's point, I think it would be that SQL is more powerful than ad-hoc jq incantations. And in this case, I tend to agree with OP. I've made substantial use of jq and yq over the course of years, as well as other tools for CSVs and other data formats. But every time I reach for them I have to spend a lot of time hunting the docs for just the right syntax to attack my specific problem. I know jq's paradigm draws from functional programming concepts and I have plenty of personal experience with functional programming, but the syntax and still feel very ad hoc and clunky. Modern OLAP DB tools like duckdb, clickhouse, etc that provide really nice ways to get all kinds of data formats into and out of a SQL environment seem dramatically more powerful to me. Then when you add the power of all the basic shell tools on top of that, I think you get a much more powerful combination. I like this example from the clickhouse-local documentation: $ ps auxtail -n +2awk '{ printf(\"%s\\t%s\", $1, $4) }' \\clickhouse-local --structure \"user String, mem Float64\" \\ --query \"SELECT user, round(sum(mem), 2) as memTotal FROM table GROUP BY user ORDER BY memTotal DESC FORMAT Pretty\" reply xg15 6 minutes agorootparentYou can archive that by appending sort -n, so the whole thing becomes: curl ...jq '.[].license.key'sortuniq -csort -n reply tleb_ 44 minutes agorootparentprevFor reference, sort(1) has -n, --numeric-sort: compare according to string numerical value. reply salmo 8 hours agoparentprevAs an old Unix guy this is exactly how I see jq: a gateway to a fantastic library of text processing tools. I see a lot of complicated things done inside the language, which is a valid approach. But I don’t need it to be a programming language itself, just a transform to meet my next command after the pipe. If I want logic beyond that, then I skip the shell and write “real” software. I personally find those both to be more readable and easier to fit in my head than long complex jq expressions. But that’s completely subjective and others may find the jq expression language easier to read than shell or (choose your programming language). reply digdugdirk 7 hours agorootparentYour comment made me go look up jq (even more than the article did) and the first paragraph of the repo [0] feels like a secret club's secret language. I'm very interested, but not a Linux person, do you know of any good resources for learning the Linux shell as a programming language? [0] https://jqlang.github.io/jq/ reply salmo 6 hours agorootparentI’ll say, I did shell scripting for years from copy/paste, cribbing smarter people, and reading online guides. But I didn’t really understand until I read The Unix Programming Environment by Brian Kernighan and Rob Pike. It’s a very old book and the audience was using dumb terminals. But it made me understand why and how. I think I’ve read every Kernighan book at this point and most he was involved in because he is just so amazing and not just conveying facts, but teaching how to think idiomatically in the topic. I also used awk for 2 decades, kind of like how I use jq now. But when I read his memoir I suddenly “got it.” What I make with it now is intentional and not just me banging on the keyboard until it works. A great middle ground for something a little sophisticated, but not worth writing a full program for. Something else that helped me was to install a minimal distro… actually a base FreeBSD install would be great… and read the man pages for all the commands. I don’t remember the details, but I learned that things existed. I have many man pages that I look at the same options on every few months because I’m not positive I remember right. Heck, I ‘man test’ all the time still. (‘test’ and ‘[‘ are the same thing) I also had an advantage of 2 great coworkers. They’d been working on Unix since the 80s and their feedback helped me be more efficient, clean, and avoid “useless use of cat” problems. I also highly recommend using shellcheck. I sometimes disagree with it when I’m intentionally abusing shell behavior, but it’s a great way to train good habits and prevent bugs that only crop up with bad input, scale, etc. I get new devs to use it and it’s helped them “ramp up” quickly, with me explaining the “why” from time to time. But yeah. The biggest problem I see is that people think there is more syntax than there really is (like my test and [ comment). And remember it’s all text, processes, and files. Except when we pretend it’s not ;). reply NortySpock 6 hours agorootparentprevSo, grab yourself a Linux box (I suggest Debian), a large CSV file or JSON lines file you need to slice up, and an hour of time, and start trying out some bash one-liners on your data. Set some goals like \"find the Yahoo email addresses in the data and sort by frequency\" or \"find error messages that look like X\" or \"find how many times Ben Franklin mentions his wife in his autobiography\" Here's the thing. These tools have been used since the '70s to slice, dice and filter log files, CSVs, or other semi-structured data. They can be chained together with the pipe command. Sys admins were going through 100MB logs with these tools before CPUs hit the gigahertz These tools are blisteringly fast, and they are basically installed on every Linux machine. https://github.com/onceupon/Bash-Oneliner And for a different play-by-play example: https://adamdrake.com/command-line-tools-can-be-235x-faster-... reply coldtea 1 hour agorootparentprev>Your comment made me go look up jq (even more than the article did) and the first paragraph of the repo [0] feels like a secret club's secret language. Or one of the most old standing widespread clubs of computing open standard language :) \"jq is like sed for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that sed, awk, grep and friends let you play with text.\" Translation: JQ is like a (UNIX/POSIX staple command line text-manipulation tool) but specialized for text structured in JSON format. You can use it to extract parts of a JSON document (slice), keep nodes based on some criteria (filter), transform each element in a list of structured data to get a new list with the transformed versions (map), and do that as easily as you can with the sed (basic command line text manipulation program), awk (command line text manipulation program with a full featured text-processing oriented language), grep (command line program to search for strings), and other assorted unix userland programs. reply eru 8 hours agoparentprev> I still think jq's syntax and data model is unbelievably elegant and powerful once you get the hang of it [...] It's basically just functional programming. (Or what you would get from a functional programmer given the task of writing such a tool as jq.) That's not to diminish jq, it's a great tool. I love it! reply jimbokun 9 hours agoparentprevThe Unix philosophy continues to pass the test of time. reply ndr 9 hours agoprevIf you like lisp, and especially clojure, check out babashka[0]. This my first attempt but I bet you can do something nicer even if you keep forcing yourself to stay into a single pipe command. cat repos.jsonbb -e ' (->> (-> *in* slurp (json/parse-string true))(group-by #(-> % :license :key))(map #(-> {:license (key %):count (-> % val count)}))json/generate-stringprintln)' [0] https://babashka.org/ reply hu3 11 hours agoprevRelated, clickhouse local cli command is a speed demon to parse and query JSON and other formats such as CSV: - \"The world’s fastest tool for querying JSON files\" https://clickhouse.com/blog/worlds-fastest-json-querying-too... - \"ClickHouse-local – a small tool for serverless data analytics\" https://news.ycombinator.com/item?id=34265206 reply mightybyte 11 hours agoparentI'll second this. Clickhouse is amazing. I was actually using it today to query some CSV files. I had to refresh my memory on the syntax so if anyone is interested: clickhouse local -q \"SELECT foo, sum(bar) FROM file('foobar.csv', CSV) GROUP BY foo FORMAT Pretty\" Way easier than opening in Excel and creating a pivot table which was my previous workflow. Here's a list of the different input and output formats that it supports. https://clickhouse.com/docs/en/interfaces/formats reply gkbrk 1 hour agorootparentYou don't even need to use file() for a lot of things recently. These just work with clickhouse local. Even wildcards work. select * from `foobar.csv` or select * from `monthly-report-*.csv` reply wwader 44 minutes agorootparentJust had to try: $ function _select_aux () { clickhouse local -q \"SELECT $* FORMAT Pretty\" } $ alias SELECT='noglob _select_aux' $ SELECT COUNT(*) as count FROM file('repos.json', JSON) ┏━━━━━━━┓ ┃ count ┃ ┡━━━━━━━┩ │ 30 │ └───────┘ reply mightybyte 45 minutes agorootparentprevOoh very nice, thanks for the tip! reply phmx 32 minutes agoprevThere is also a way to import a table from the STDIN (see also https://duckdb.org/docs/data/json/overview) cat my.jsonduckdb -c \"CREATE TABLE mytbl AS SELECT * FROM read_json_auto('/dev/stdin'); SELECT ... FROM mytbl\" reply sshine 13 hours agoprevVery cool! I am also a big fan of jq. And I think using DuckDB and SQL probably makes a lot of sense in a lot of cases. But I think the examples are very geared towards being better solved in SQL. The ideal jq examples are combinations of filter (select), map (map) and concat (.[]). For example, finding the right download link: $ curl -s https://api.github.com/repos/go-gitea/gitea/releases/latest \\jq -r '.assets[].browser_download_urlselect(endswith(\"linux-amd64\"))' https://github.com/go-gitea/gitea/releases/download/v1.15.7/gitea-1.15.7-linux-amd64 Or extracting the KUBE_CONFIG of a DigitalOcean Kubernetes cluster from Terraform state: $ jq -r '.resources[]select(.type == \"digitalocean_kubernetes_cluster\").instances[].attributes.kube_config[].raw_config' \\ terraform.tfstate apiVersion: v1 kind: Config clusters: - cluster: certificate-authority-data: ... server: https://...k8s.ondigitalocean.com ... reply pgr0ss 12 hours agoparentI think that's a fair point. Unnesting arrays in SQL can be annoying. Here is your first example with duckdb: duckdb -c \\ \"select * from ( \\ select unnest(assets)->>'browser_download_url' as url \\ from read_json('https://api.github.com/repos/go-gitea/gitea/releases/latest') \\ ) \\ where url like '%linux-amd64'\" reply _flux 2 hours agorootparentIn case someone else was wondering, one can get a shell-consumable output from that with duckdb -noheader -list reply mritchie712 11 hours agoprevYou can also query (public) Google Sheets [0] SELECT * FROM read_csv_auto('https://docs.google.com/spreadsheets/export? format=csv&id=1GuEPkwjdICgJ31Ji3iUoarirZNDbPxQj_kf7fd4h4Ro', normalize_names=True); 0 - https://x.com/thisritchie/status/1767922982046015840?s=20 reply NortySpock 12 hours agoprevIn a similar vein, I have found Benthos to be an incredible swiss-army-knife for transforming data and shoving it either into (or out of) a message bus, webhook, or a database. https://www.benthos.dev/ reply esafak 9 hours agoparentI wish it was not based on YAML. Pipelines are code, not configuration!! reply krembo 11 hours agoparentprevHow does this defer from filebeat? reply NortySpock 5 hours agorootparentI don't know which filebeat you are referring to... https://github.com/elastic/beats/tree/master/filebeat This one? I only looked for a moment, but filebeat appears to be ingestion only. Benthos does input, output, side-effects, stream-stream joins, metrics-on-the-side, tiny-json-wrangling-webooks, and more. I find it to be like plumbers putty, closing over tooling gaps and smoothing rough edges where ordinarily you'd have to write 20 lines of stream processing code and 300 lines of error handling, reporting, and performance hacks. reply haradion 12 hours agoprevI've found Nushell (https://www.nushell.sh/) to be really handy for ad-hoc data manipulation (and a decent enough general-purpose shell). reply wraptile 4 hours agoparentNushell is really good but the learning curve is massive. I've been on nushell for almost a year now and still struggle to put more complex commands together. The docs are huge but not very good and the community resources are very limited (it's on Dicord smh) unfortunately. So, if anyone wants to get into it you really need to put down few days to understand the whole syntax suite but it's worth it! reply nf3 3 hours agoprevI run a pretty substantial platform where I implemented structured logging to SQLite databases. Each log event is stored as a JSON object in a row. A separate database is kept for each day. Daily log files are about 35GB, so that's quite a lot of data to go through is you want to look for something specific. Being able to index on specific fields, as well as express searches as SQL queries is a real game changer IMO. reply JeremyNT 10 hours agoprevI have a lot of trouble understanding the benefits of this versus just working with json with a programming language. It seems like you're adding another layer of abstraction versus just dealing with a normal hashmap-like data structure in your language of choice. If you want to work with it interactively, you could use a notebook or REPL. reply WuxiFingerHold 29 minutes agoparentMy thoughts as well: const response = await fetch(\"https://api.github.com/orgs/golang/repos\"); const repos = await response.json(); const groups = Map.groupBy(repos, e => e?.license?.key); ... reply edu_guitar 9 hours agoparentprevif you are used to the command line and knows some basic syntax, it is less verbose then opening a REPL and reading a file. The fact that you can pipe the json data into it is also a plus, making it easier to check quickly if the response of a curl call has the fields/values you were expecting. Of course, if you are more comfortable doing that from the REPL, you get less value from learning jq. If you are fond of one liners, jq offers a lot of potential. reply bdcravens 8 hours agoparentprevPipelining CLI commands or bash scripts. From a security perspective, it may be preferable to not ship with a runtime. reply vips7L 8 hours agorootparentbash and jq are both runtimes. reply bdcravens 8 hours agorootparentVery difficult (or often impractical) to not have a shell at all, and jq is at least limited in scope, and has no dependencies that need to be installed. Far better than a full language with its own standard library and set of dependencies to lock down. reply rpigab 3 hours agoprevI love jq and yq, but sometimes I don't want to invest time in learning new syntax and just fallback to some python one liner, that can if necessary become a small python script. Something like this, I have a version of this in a shell alias: python3 -c \"import json,sys;d=json.load(sys.stdin);print(doStuff(d['path']['etc']))\" Pretty print is done with json.dumps. reply schindlabua 4 hours agoprevShoutout to jqp, an interactive jq explorer. https://github.com/noahgorstein/jqp reply pletnes 12 hours agoprevWorth noting that both jq and duckdb can be used from python and from the command line. Both are very useful data tools! reply hprotagonist 12 hours agoprevi've been using simonw's sqlite-utils (https://sqlite-utils.datasette.io/en/stable/) for this sort of thing; given structured json or jsonl, you can throw data at an in-memory sqlite database and query away: https://sqlite-utils.datasette.io/en/stable/cli.html#queryin... reply ec109685 10 hours agoprevWhile jq’s syntax can be hard to remember, ChatGTP does an excellent job generating jq from an example json file and a description of how you want it parsed. reply HellsMaddy 12 hours agoprevJq tip: Instead of `sort_by(.count)reverse`, you can do `sort_by(-.count)` reply philsnow 11 hours agoparentonly if you're sure that .count is never null: $ echo '[{\"a\": {\"count\": null}}]'jq -c 'sort_by(-.count)' jq: error (at :1): null (null) cannot be negated $ echo '[{\"a\": {\"count\": null}}]'jq -c 'sort_by(.count)reverse' [{\"a\":{\"count\":null}}] reply jeffbee 12 hours agoprevI tried this and it just seems to add bondage and discipline that I don't need on top of what is, in practice, an extremely chaotic format. Example: trying to pick one field out of 20000 large JSON files that represent local property records. % duckdb -json -c \"select apn.apnNumber from read_json('*')\" Invalid Input Error: JSON transform error in file \"052136400500\", in record/value 1: Could not convert string 'fb1b1e68-89ee-11ea-bc55-0242ad1302303' to INT128 Well, I didn't want that converted. I just want to ignore it. This has been my experience overall. DuckDB is great if there is a logical schema, not as good as jq when the corpus is just data soup. reply dudus 11 hours agoprevDuckDB parses JSON using yyjson internally . https://github.com/ibireme/yyjson reply hermitcrab 11 hours agoprev [–] if you want a very visual way to transform JSON/XML/CSV/Excel etc in a pipeline it might also be worth looking at Easy Data Transform. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DuckDB is a database tool akin to SQLite, capable of seamlessly reading and parsing JSON data, making it a valuable tool for data analysis.",
      "The author favors DuckDB over jq for querying JSON data due to the simplicity of SQL syntax compared to the complexity of jq, demonstrating the ease of using SQL for data analysis.",
      "DuckDB stands out for its capability to read JSON data from a URL directly, enhancing its versatility for various data analysis tasks."
    ],
    "commentSummary": [
      "DuckDB is proposed as an alternative to jq for data manipulation, emphasizing the limitations of jq and potential enhancements.",
      "Recommendations include utilizing modern OLAP DB tools, shell scripting, intentional coding, minimal installs, and tools like shellcheck for efficient data processing.",
      "The conversation covers tools like ClickHouse for JSON parsing, Benthos vs. filebeat for data handling, and comparisons of Nushell, jq, and yq, highlighting the impact of individual preferences and familiarity with command-line interfaces."
    ],
    "points": 270,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1711045163
  },
  {
    "id": 39787559,
    "title": "Glassdoor under fire for adding real names to profiles without consent",
    "originLink": "https://techcrunch.com/2024/03/20/glassdoor-added-real-names-profiles-without-consent/",
    "originBody": "(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Link Copied Featured Article Users say Glassdoor added real names to user profiles without their consent Zack Whittaker@zackwhittaker / 9:45 PM UTC•March 20, 2024 Comment Image Credits: Glassdoor / file photo Users of the popular site Glassdoor, which lets anyone anonymously sign up to review companies they have worked for, say Glassdoor collected and added their names to their user profiles without their consent. One user, who goes by Monica, wrote in a post on her personal blog that Glassdoor added her name and the city where she lives to her Glassdoor profile following an email exchange with Glassdoor customer support, despite having never provided her name during the sign-up process some years earlier. Monica, whose last name we’re not publishing to protect her privacy, accused Glassdoor of getting her full name from the email she sent to customer support, which she says they added to her Glassdoor profile. “My email ‘from’ line contains my full name — never thought that would be a problem!” Monica told TechCrunch in an email. “They then added my name to my Glassdoor profile.” Monica repeatedly protested Glassdoor, telling customer support that the company did not have her consent or permission to do this. But Glassdoor said Monica was “required” to have her name added to her profile, adding that this would not compromise her anonymity of past reviews she gave. Monica said that her anonymity might not last if Glassdoor was to experience a hack or a data breach and compromise users’ data. It also means this information can be obtained by legal process, such as a lawsuit or police demanding access to Glassdoor user data. As Monica explained, Glassdoor will add a user’s real name (and potentially other information) to the user’s account without their permission if Glassdoor learns it. And the only other option is to delete your account, Monica said. Glassdoor users expressed alarm at Monica’s story, which has been widely shared on social media and news-sharing sites, for fear that their anonymity could be compromised by having data collected about them and added to their profiles, as well. “It’s not clear to me how they got this information.” Josh Simmons, Glassdoor user Glassdoor has long allowed users to sign up anonymously. In 2021, Glassdoor bought Fishbowl, a semi-anonymous professional social network site that allows users to “ask questions without disclosing your name.” Ars Technica, which first reported Monica’s story, explained that Fishbowl requires users to verify their identities before using the site. As part of the acquisition deal, Glassdoor signed every user up for a Fishbowl account, meaning Glassdoor would have to change its terms of service so that every Glassdoor user could also be verified. Aaron Mackey, an attorney with the digital rights group Electronic Frontier Foundation, told TechCrunch that Glassdoor has been an “industry leader” in defending its users’ anonymity. Mackey previously defended an anonymous Glassdoor user in court whose employer tried to unmask and identify their identity. “We hope that Glassdoor will continue to defend its users’ anonymity in court,” said Mackey. “But the latest news regarding Glassdoor’s policies raises concerns about whether users may be identified even if their information is never sought by an employer or law enforcement. Those policies also appear to conflict with, or at least be in tension with, Glassdoor’s goal of encouraging employees to candidly review their employers.” In some cases, the data added to the user’s profile did not completely line up. Josh Simmons said Glassdoor added information about him to his profile without his consent, describing it as a “breach of trust.” Simmons told TechCrunch that he did not know how Glassdoor got his personal data. “It’s not clear to me how they got this information,” Simmons told TechCrunch. “I didn’t have any social accounts connected to Glassdoor, and I hadn’t used the service in several years,” suggesting that the data may have been scraped or come from a data broker. Simmons said his supplemented Glassdoor profile had an “incoherent mix of details, but each detail was correct in isolation,” describing how Glassdoor got the name of his consultancy correct but jumbled his location in California with his main client based in London. “Taken together, it signaled to me that it was the result of an automated process,” Simmons said. By Glassdoor’s own admission, the company says on its website that it is “unable to fully confirm our users’ identities, the truthfulness of their contributions, or their employment status.” It’s not clear what the goal of Glassdoor’s data collection is if the information is not accurate. When reached for comment, Glassdoor spokesperson Amanda Livingood would not answer TechCrunch’s specific questions, including how — if at all — Glassdoor verifies the accuracy of the information it receives, or how it can be used or obtained. Glassdoor does not publish a transparency report detailing the number of requests for user data it receives from law enforcement. Instead, the company provided a boilerplate statement: Glassdoor is committed to providing a platform for people to share their opinions and experiences about their jobs and companies, anonymously – without fear of intimidation or retaliation. User reviews on Glassdoor have always and will always be anonymous. In the Glassdoor community, users always have the choice to post with their name or post anonymously with their company name or job title. Glassdoor has never and will never reveal a user’s name alongside their content, unless that is what the user chooses. Mackey said that the risk of data breaches or legal demands are magnified because Glassdoor is now collecting more information about users that could identify them. “But because Glassdoor now collects that information, including from email addresses and headers, Glassdoor now has data that directly identifies their users,” Mackey said. That leaves users like Monica with no choice but to delete their account if they are not willing to have their name on their profile. And so Monica did. According to Monica, closing your account just deactivates it. If you want to fully delete your Glassdoor account, you can head over to this specific Glassdoor privacy request page and fill out the data request form with the appropriate selection, such as “Delete my personal data.” To contact this reporter, get in touch on Signal and WhatsApp at +1 646-755-8849, or by email. You can also send files and documents via SecureDrop. Please login to comment Login / Create Account TechCrunch Early Stage 2024 April 25, BostonFounder Summit Register Now Sign up for Newsletters See all newsletters(opens in a new window) Daily News Week in Review Startups Weekly Event Updates Advertising Updates Email Subscribe (opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Copy Tags cybersecurity data protection Glassdoor privacy",
    "commentLink": "https://news.ycombinator.com/item?id=39787559",
    "commentBody": "[dupe] Users say Glassdoor added real names to user profiles without their consent (techcrunch.com)234 points by cgoodmac 5 hours agohidepastfavorite36 comments dang 22 minutes agoEmployer Review Site Glassdoor Deanonymized Users Without Consent - https://news.ycombinator.com/item?id=39785815 - March 2024 (18 comments) Glassdoor added real names to supposedly anonymous profiles - https://news.ycombinator.com/item?id=39777752 - March 2024 (23 comments) Glassdoor is now adding real names to user profiles without consent - https://news.ycombinator.com/item?id=39769166 - March 2024 (40 comments) Users ditch Glassdoor, stunned by site adding real names without consent - https://news.ycombinator.com/item?id=39761176 - March 2024 (31 comments) Glassdoor updated my profile to add my real name and location - https://news.ycombinator.com/item?id=39705788 - March 2024 (310 comments) reply tbdenney 1 hour agoprevAs a marketer who helped manage various companies' reputation online, I can tell you that Glassdoor is pay-to-play. If you pay them the subscription fee, and you get negative reviews, whether \"true\" or not, you can challenge most and get them removed. I thought most people would understand their business model explicitly relies on getting companies to pay a fee to own their page (and in turn they have to keep those customers happy by removing reviews they don't like) but I continue seeing recruits relying on this site as if it's some unbiased source of info. reply Jenk 18 minutes agoparentI can confirm this experience. At a previous job the management team (of which I was a member) would regularly review glassdoor reviews as part of our employee and candidate feedback. We had a healthy attitude toward employee satisfaction, but someone noticed you can flag a review as disputed (or \"under review\" or whatever the term is) and whilst it remains in this state, it is hidden from search results. Even for what I considered a team with a good attitude toward company culture, the temptation was too much and it soon became standard practice to flag every negative review asap. Some were unflagged after we reviewed them and we literally couldn't dispute the review but lots were just left as flagged. The same practice is true of yelp and tripadvisor reviews. They are cyber-racketeers. reply mulmen 1 hour agoprevWhen I logged in on mobile web Glassdoor forced me into a signup flow for something called Communities which included asking for my employment status. I was able to time a stop before the full page load and navigate to the account page. If you log in first you can navigate directly to this URL without answering any questions: https://www.glassdoor.com/member/profile/accountSettings which will allow you to close your account. You then need to request they delete your data which can be done at https://help.glassdoor.com/s/privacyrequest?language=en_US reply hayst4ck 1 hour agoprevGlassdoor is a completely flawed premise. Employers have almost complete compensation data and because we value anonymity more than ability to negotiate, our data is flawed. Employers might well directly know what you got paid at your previous company. Many companies are able to purchase previous employment salary data, which I believe Equifax sells directly: https://news.ycombinator.com/item?id=29834753 Here is a great read about the tools companies have to suppress your wage for anyone who wants to be a little angry: https://www.pave.com/blog-posts/acquiring-option-impact-and-... > At Pave, we spent the last two years building out a suite of 40+ integrations with HRIS, payroll, and equity management systems that connect directly with the source of truth for compensation data. We are thrilled to bring this technology to the Option Impact customer base and ensure that our combined customers will never have to fill out a manual survey again while gaining access to a persistent real-time network of compensation data. [pdf] https://advisor.morganstanley.com/the-hamilton-retirement-pl... > Option Impact is free to eligible and participating companies through our give-to-get model. So if I understand correctly, almost all of our employers are providing our real time compensation data to an entity that then allows all other participant companies to graph and query. I find it outrageous that my employer could tell my compensation data to other companies, while simultaneously we live in a culture of \"we shouldn't talk about compensation.\" reply Sardtok 1 hour agoparentIn Norway you can lookup anyone's tax information. You can see who looks up your tax information, though, it is publicly available as long as you log on to government sites. So basically everyone's salary from two years back is public information. It is often used by the press to check how much the richest people pay in taxes (or rather how badly they contribute by dodging taxes). I've never heard of employers using it to check candidates' salaries, though. They usually just ask as part of the interview process. reply earnesti 52 minutes agorootparent> I've never heard of employers using it to check candidates' salaries, though. They usually just ask as part of the interview process. As a Scandinavian employer, I can tell you that the tax records are very useful. Especially for higher-end roles it is very nice being able to check how much people have been earning from a reliable data source. I'm pretty sure many are using that a lot. reply doktrin 1 hour agorootparentprevNorwegian tech salaries are relatively standardised and skew low (sometimes very low) by US standards, so certainly in a decent to good market there isn’t that much burning incentive for a company to volunteer themselves to the front page of VG just to save a handful of crowns. reply mcculley 48 minutes agoparentprevIt isn’t just your employers that are selling your compensation. Many give copies of W-2 and paystubs to companies that loan them money (e.g., for mortgages and auto loans). Some of these companies then sell this data to aggregators. reply klabb3 1 hour agoparentprevIsn’t it illegal in the US for an employer to share your compensation data with third parties? Or do they skirt the rules by “anonymizing” it? > we live in a culture of \"we shouldn't talk about compensation.\" Yeah especially now that the cat is out of the bag, but restricted to employers. Such a data set should absolutely be made available to workers. Information symmetry is critical for a functioning market. And capitalists love markets, right? reply aerhardt 1 hour agorootparentWhether it’s anonymized or not, if this is real, it’s fucking dystopian. reply klabb3 1 hour agorootparentYes, but merely a reflection and reminder of a dystopian reality that already permeated society long ago. It’s obvious that if they are allowed they would. The faster people drop the illusion that corporations[1] have emotions and “care” and such, the better people can protect themselves, organize and rebalance the scales I guess. [1]: A generalization. There are more amoral, faceless self-perpetuating machines than just corporations, and there are many small- and medium sized companies that may be incorporated while maintaining human decency. reply randomcarbloke 1 hour agorootparentprevIf I think I get paid more than you in the same role it's absolutely in my interest to keep that information from you. With departmental budgets in mind, you receiving a raise may limit the total compensation available to me when I negotiate my own. reply eecc 1 hour agorootparentEver heard of the allegory “I capponi di Renzo” from the Promessi Sposi novel by Alessandro Manzoni? Look it up reply hayst4ck 42 minutes agorootparent> “i capponi di Renzo”, has become a proverbial admonition in Italian culture > Renzo is carrying these poor capons (castrated male chicken) as his only means of payment to a well-off city lawyer, whom Renzo intends to hire... Manzoni (the author) notes that, had the capons been a little more intelligent, they would have started picking the hand that kept them captive, therefore regaining their freedom. Instead, the capons fought among themselves and ended up being delivered with great ease to their recipient. reply klabb3 1 hour agoprevAren’t all the Yelps, Glassdoors and Trustpilots of the world all accepting money from companies to take down bad reviews and/or promote good-looking content? To the point of that being the main business model? I remember there used to be a lot of those claims coming up a few years ago, from credible sources. I don’t trust any review sites these days, especially star ratings. At most I’ll skim through and look for what appears to be authentic reviews with quirky writing, shitty photos and such. However, that’s going away soon too, thanks to AI. reply tbdenney 1 hour agoparentYes, that is their business model -- it's surprising more people don't understand this. I know from experience regarding Trustpilot and Glassdoor specifically. FWIW, in my personal experience TrustPilot seemed to be a touch more interested in accuracy on managing the reviews, but that was a few years back. reply type_Ben_struct 2 hours agoprevThat is really shitty behaviour, and bizarre. Glassdoor is only feasible if users can have trust that their feedback is anonymous. I really hope this has not harmed anyone, I'd imagine the lower rated companies are most likely to retaliate. reply prmoustache 2 hours agoparentThe risk is not only retaliation by lower rated companies. It may make users virtually unemployable if HR starts using Glassdoor as a database of publicly critical people. Given the choice between engineer 1 who never posted anything bad against a company, and engineer 2 who posted critical comments, who would you hire? reply type_Ben_struct 1 hour agorootparentAgreed, but my point was that those that are lowest rated will likely have the worst cultures, and so would be *most likely* to retaliate. A company with a good culture would in theory be more likely to take any constructive feedback on board. reply techcode 1 hour agorootparentBeing surrounded by \"yes\" people can only get you so far. Although it probably gets you further than the opposite extreme where everyone disagrees all the time. Personally having such info (critical reviews on previous employers) for a candidate, would be close to already having their answer for \"Tell me about a time you had a challenge/problem/conflict at work\" type of interview questions. reply mulmen 1 hour agorootparentprevIt’s more dangerous than that. Even “good” companies use third party data and HR services to rank and disqualify applicants. If one of those services uses Glassdoor reviews as a signal even “good” employers could be unintentionally discriminating against applicants based on Glassdoor history. reply e40 1 hour agoprevFounder of small company. Of 16 reviews, only 1 is not fake. Really hard to believe they are mistakenly attached to my company. Many are negative, too. Glassdoor seems like a complete scam to me. reply Sparkyte 1 hour agoprevGlassdoor also doesn't report actual income and wages in the field as a way to help lowball the brackets. I once saw it say a Senior Backend Developer was only worth 120K... I was shocked considering I know Amazon will pay you up to 250 with bonus. reply ChrisArchitect 4 hours agoprev[dupe] More discussion: https://news.ycombinator.com/item?id=39705788 https://news.ycombinator.com/item?id=39761176 reply teekert 2 hours agoprevWhy would add your real name on such a website? I couldn’t read the article when rejecting the cookies (or it took very long) so maybe the answer is in there… reply thih9 2 hours agoparentThe answer is in there: > One user, who goes by Monica, wrote in a post on her personal blog that Glassdoor added her name and the city where she lives to her Glassdoor profile following an email exchange with Glassdoor customer support, despite having never provided her name during the sign-up process some years earlier. Monica, whose last name we’re not publishing to protect her privacy, accused Glassdoor of getting her full name from the email she sent to customer support, which she says they added to her Glassdoor profile. reply genewitch 1 hour agorootparentStraight Talk wireless tirelessly attempted to get your mailing info and other such; any time you called them for any reason. It only took 2 questions before i went \"do you need this? because you're not verifying anything i gave you before, since i didn't\" I have no idea if it's still that anonymous. reply jonathanstrange 21 minutes agoprevLOL, for a moment I thought this was about a new office glass door with built-in semitransparent smart display. reply elsadek 2 hours agoprevI have just deleted my account. reply yinser 3 hours agoprevWhere there’s smoke there’s fire and I’m sure they are also purchasing gigabytes of data from vendors as well reply wisienkas 1 hour agoprevCan anyone summarize how this breaks or does not break european GDPR? reply misja111 53 minutes agoparentExcellent question. I would say that this breaks GDPR principle #2, 'purpose limitation'. See e.g. https://www.cyberpilot.io/cyberpilot-blog/data-protection-pr.... reply a_gnostic 4 hours agoprevPosted previously https://news.ycombinator.com/item?id=39785815 reply stanislavb 4 hours agoparentThanks. reply AlienRobot 24 minutes agoprev [–] Classic mistake. This is why you should never type your real name into a website that you don't wan >One user, who goes by Monica, wrote in a post on her personal blog that Glassdoor added her name and the city where she lives to her Glassdoor profile following an email exchange with Glassdoor customer support, despite having never provided her name during the sign-up process some years earlier Wait, what. This is just grotesque and unethical. You do NOT go around fixing other people's profiles. You do NOT edit other people's posts. This is a huge breach of trust for any platform that handles user inputted information. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Glassdoor users are reporting that the company added their real names to profiles without consent, raising worries about anonymity and privacy.",
      "Data collection practices causing concerns about anonymity compromise and potential exposure to data breaches or legal requests express alarm among users.",
      "Questions on the accuracy and use of information collected due to Glassdoor's user identity verification policies have been brought up, highlighting concerns about transparency and the necessity for users to delete accounts for privacy maintenance."
    ],
    "commentSummary": [
      "Glassdoor users raised concerns about the site adding real names to user profiles without consent and the pay-to-play model allowing companies to challenge negative reviews.",
      "Participants discussed the credibility of review sites, privacy violations, and doubts about the accuracy of income/wage reports on Glassdoor.",
      "Skepticism was expressed regarding the ethics of data sharing and the implications of relying on review sites for crucial decisions."
    ],
    "points": 234,
    "commentCount": 36,
    "retryCount": 0,
    "time": 1711082881
  },
  {
    "id": 39779195,
    "title": "GoFetch: New side-channel attack targets Apple CPUs",
    "originLink": "https://gofetch.fail",
    "originBody": "GoFetch Breaking Constant-Time Cryptographic Implementations Using Data Memory-Dependent Prefetchers Overview of GoFetch Attack GoFetch is a microarchitectural side-channel attack that can extract secret keys from constant-time cryptographic implementations via data memory-dependent prefetchers (DMPs). We show that DMPs are present in many Apple CPUs and pose a real threat to multiple cryptographic implementations, allowing us to extract keys from OpenSSL Diffie-Hellman, Go RSA, as well as CRYSTALS Kyber and Dilithium. Paper Cite Tools Cite GoFetch Copy to Clipboard Close Demo Videos. Go's RSA-2048 Key Extraction on Apple m1 People Behind GoFetch Boru Chen University of Illinois Urbana-Champaign Yingchen Wang University of Texas at Austin Pradyumna Shome Georgia Institute of Technology Christopher W. Fletcher University of California, Berkeley David Kohlbrenner University of Washington Riccardo Paccagnella Carnegie Mellon University Daniel Genkin Georgia Institute of Technology Contact us at info@gofetch.fail Frequently Asked Questions What is the mechanism behind GoFetch? The GoFetch attack is based on a CPU feature called data memory-dependent prefetcher (DMP), which is present in the latest Apple processors. We reverse-engineered DMPs on Apple m-series CPUs and found that the DMP activates (and attempts to dereference) data loaded from memory that \"looks like\" a pointer. This explicitly violates a requirement of the constant-time programming paradigm, which forbids mixing data and memory access patterns. To exploit the DMP, we craft chosen inputs to cryptographic operations, in a way where pointer-like values only appear if we have correctly guessed some bits of the secret key. We verify these guesses by monitoring whether the DMP performs a dereference through cache-timing analysis. Once we make a correct guess, we proceed to guess the next batch of key bits. Using this approach, we show end-to-end key extraction attacks on popular constant-time implementations of classical (OpenSSL Diffie-Hellman Key Exchange, Go RSA decryption) and post-quantum cryptography (CRYSTALS-Kyber and CRYSTALS-Dilithium). What processors have DMPs and are affected by GoFetch? We have mounted end-to-end GoFetch attacks on Apple hardware equipped with m1 processors. We also tested DMP activation patterns on other Apple processors and found that m2 and m3 CPUs also exhibit similar exploitable DMP behavior. While we have not tested other m-series variants (e.g., m2 Pro, etc), we hypothesize that since these parts have the same microarchitecture as their simpler counterparts, they are likewise equipped with exploitable DMPs. Finally, we found that Intel's 13th Gen Raptor Lake microarchitecture also features a DMP. However, its activation criteria are more restrictive, making it robust to our attacks. What is the difference between GoFetch and Augury? The Apple m-series DMP was first discovered by Augury, which suggested that DMPs might mix data and addresses under some conditions. However, we found that the DMP activation criteria outlined by Augury are overly restrictive. This prevents Augury's findings from being sufficient to mount attacks on real-world constant-time cryptography. GoFetch shows that the DMP is significantly more aggressive than previously thought, and thus poses a much greater security risk. Specifically, we find that any value loaded from memory is a candidate for being dereferenced (literally!). This allows us to sidestep many of Augury's limitations and demonstrate end-to-end attacks on real constant-time code. What is a Cache Side-Channel Attack? Modern processors use caches to reduce a program's memory access latency. If data has been accessed before, it gets cached, which makes subsequent accesses to it faster. Since the cache is shared by processes running on the same machine, attackers co-located to the same machine can monitor the cache's state to deduce a victim's access pattern. What is constant-time programming? Constant-time programming is a paradigm that aims to harden code against side-channel attacks by ensuring that all operations take the same amount of time, regardless of their operands. In particular, constant-time code cannot contain secret-dependent branches, loops, or other control structures. Moreover, as the CPU caches different addresses with attacker-observable latency, constant-time code cannot mix data and addresses in any way and prohibits the use of secret-dependent memory accesses or array indices. We show that even if a victim correctly separates data from addresses by following the constant-time paradigm, the DMP will generate secret-dependent memory access on the victim's behalf, resulting in variable-time code susceptible to our key-extraction attacks. What is a data memory-dependent prefetcher? Prefetchers are a hardware optimization that predicts memory addresses to be accessed in the near future and fetches the data into the cache accordingly from the main memory. To make a prediction, classical prefetchers use the address trace of previous demand accesses. This strategy performs poorly when it comes to irregular access patterns like linked-list traversals. Aiming to handle such irregular patterns, data memory-dependent prefetchers (DMPs) also consider the content of memory to determine what to fetch, which is capable of capturing those indirect access patterns. Unfortunately, this behavior inherently mixes data and memory addresses at the hardware level, making the entire compute stack non-constant-time, enabling our attack. Are there other DMP-vulnerable cryptographic implementations? We don't know. Our attack relies on the fact that it is possible to craft inputs to control specific intermediate states, making them contain memory addresses in a key-dependent way. The DMP then serves as an oracle, allowing us to learn if the intermediate state indeed looks like a pointer and thus leaks secret key bits. Unfortunately, to assess if an implementation is vulnerable, cryptanalysis and code inspection are required to understand when and how intermediate values can be made to look like pointers in a way that leaks secrets. This process is manual and slow and does not rule out other attack approaches. Can the DMP be disabled? Yes, but only on some processors. We observe that the DIT bit set on m3 CPUs effectively disables the DMP. This is not the case for the m1 and m2. Also, Intel's counterpart, DOIT bit, can be used to disable DMP on the Raptor Lake processors. What can I do to protect myself against this attack? For users, we recommend using the latest versions of software, as well as performing updates regularly. Developers of cryptographic libraries can either set the DOIT bit and DIT bit bits, which disable the DMP on some CPUs. Additionally, input blinding can help some cryptographic schemes avoid having attacker-controlled intermediate values, avoiding key-dependent DMP activation. Finally, preventing attackers from measuring DMP activation in the first place, for example by avoiding hardware sharing, can further enhance the security of cryptographic protocols. Is there a proof-of-concept code? Yes, we will release it soon. Can I use the logo? Yes, SVG and PNG versions of GoFetch logo are free to use under a CC0 licence. When did you notify Apple? We disclosed our findings to Apple on December 5, 2023 (107 days before public release). GoFetch in the News Unpatchable vulnerability in Apple chip leaks secret encryption keys Apple Silicon vulnerability leaks encryption keys, and can't be patched easily GoFetch Flaw Exposes Cryptographic Key Leakage Risk in Apple's M-Series Chips New chip flaw hits Apple Silicon and steals cryptographic keys from system cache — 'GoFetch' vulnerability attacks Apple M1, M2, M3 processors, can't be fixed in hardware Researchers uncover unfixable vulnerability in Apple CPUs affecting cryptographic security It turns out that it is possible to steal private keys with the \"GoFetch\" attack that exploits the vulnerability of Apple silicon that cannot be patched GoFetch: Critical Vulnerability in Apple's M-Series Chips Apple M-series chips found to leak secret encryption keys Acknowledgments This work was partially supported by the Air Force Office of Scientific Research (AFOSR) under award number FA9550-20-1-0425; the Defense Advanced Research Projects Agency (DARPA) under contract numbers W912CG-23-C-0022 and HR00112390029; the National Science Foundation (NSF) under grant numbers 1954712, 1954521, 2154183, 2153388, and 1942888; the Alfred P. Sloan Research Fellowship; and gifts from Intel, Qualcomm, and Cisco. Copyright © 2024 Georgia Institute of Technology. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=39779195",
    "commentBody": "GoFetch: New side-channel attack using data memory-dependent prefetchers (gofetch.fail)202 points by kingsleyopara 19 hours agohidepastfavorite53 comments jerf 17 hours agoAs long as we're getting efficiency cores and such, maybe we need some \"crypto cores\" added to modern architectures, that make promises specifically related to constant time algorithms like this and promise not to prefetch, branch predict, etc. Sort of like the Itanium, but confined to a \"crypto processor\". Given how many features these things wouldn't have, they wouldn't be much silicon for the cores themselves, in principle. This is the sort of thing that would metaphorically drive me to drink if I were implementing crypto code. It's an uphill battle at the best of times, but even if I finally get it all right, there's dozens of processor features both current and future ready to blow my code up at any time. reply FiloSottile 16 hours agoparentSpeaking as a cryptography implementer, yes, these drive us up the wall. However, crypto coprocessors would be a tremendously disruptive solution: we'd need to build mountains of scaffolding to allow switching to and off these cores, and to share memory with them, etc. Even more critically, you can't just move the RSA multiplication to those cores and call it a day. The key is probably parsed from somewhere, right? Does the parser need to run on a crypto core? What if it comes over the network? And if you even manage to protect all the keys, what if a CPU side channel leaks the message you encrypted? Are you ok with it just because it's not a key? The only reason we don't see these attacks against non-crypto code is that finding targets is very application specific, while in crypto libraries everyone can agree leaking a key is bad. No, processor designers \"just\" need to stop violating assumptions, or at least talk to us before doing it. reply saagarjha 13 hours agorootparentProcessor designers are very unlikely to do that for you, because everyone not working on constant time crypto gives them a whole lot of money to keep doing this. The best you might get is a mode where the set of assumptions they violate is reduced. reply bee_rider 15 hours agorootparentprevI don’t think the security community is also going to become experts in chip design, these are two full skill sets that are already very difficult to obtain. We must stop running untrustworthy code on modern full-performance chips. The feedback loop that powers everything is: faster chips allow better engineering and science, creating faster chips. We’re not inserting the security community into that loop and slowing things down just so people can download random programs onto their computers and run them at random. That’s just a stupid thing to do, there’s no way to make it safe, and there never will be. I mean we’re talking about prefetching. If there was a way to give ram cache-like latencies why wouldn’t the hardware folks already have done it? reply FiloSottile 15 hours agorootparent> download random programs onto their computers and run them at random To be clear that includes what we're all doing by downloading and running Javascript to read HN. Maybe I can say \"don't run adversarial code on my same CPU\" and only care about over-the-network CPU side-channels (of which there are still some), because I write Go crypto, but it doesn't sound like something my colleagues writing browser code can do. reply csande17 14 hours agorootparentSpeak for yourself; I've got JavaScript disabled on news.ycombinator.com and it works just fine. reply arp242 14 hours agorootparentprevIs this exploitable through JavaScript? In general from what I've seen, most of these JS-based CPU exploits didn't strike me as all that practical in real world conditions. I mean, it is a problem, but not really all that worrying. reply cryptonector 10 hours agorootparent> Is this exploitable through JavaScript? Why wouldn't it be? reply samatman 4 hours agorootparentHow is JavaScript going to run a chosen-input attack against one of your cores for an hour? reply bee_rider 15 hours agorootparentprevUnfortunately somebody has tricked users to leaving JavaScript on for every site, it is a really bad situation. reply anonymous-panda 14 hours agorootparentSecurity and utility are in opposing balances often. The safest possible computer is one buried far underground without any cables in a faraday cage. Not very useful. > We’re not inserting the security community into that loop and slowing things down just so people can download random programs onto their computers and run them at random. That’s just a stupid thing to do, there’s no way to make it safe, and there never will be. Setting aside JavaScript, you can see this today with cloud computers which have largely displaced private clouds. These run untrusted code on shared computers. Fundamentally that’s what they’re doing because that’s what you need for economies of scale, durability, availability, etc. So figuring out a way to run untrusted code on another machine safely is fundamentally a desirable goal. That’s why people are trying to do homomorphic encryption - so that the “safely” part can go both ways and both the HW owner and the “untrusted” SW don’t need to trust each other to execute said code. reply titzer 15 hours agorootparentprevI almost gave you up an upvote until your third paragraph, but I have to now give a hard disagree. We're running more untrusted code than ever, and we absolutely should trust it less than ever and have hardware and software designed with security in mind. Security should be priority #1 from here on out. We are absolutely awash in performance and memory capacity but keep getting surprised by bad security outcomes because it's been second fiddle for too long. Software is now critical infrastructure in modern society, akin to the power grid and telephone lines. It's a strategic vulnerability to neglect security, and it must happen at all levels of the software and hardware stack. Meaning, trying to crash an enemy's entire society by bricking all of its computers and send them back to the dark ages in milliseconds. I fundamentally don't understand the mindset of people who want to take that kind of risk for a 10% boost in their games' FPS[1]. Part of that is paying back the debt that decades of cutting corners has yielded us. In reality, the vast majority of the 1000x increase in performance and memory capacity over the past four decades has come from shrinking transistors and increasing clockspeeds and memory density--the 1 or 5 or 10% gains from turning off bounds checks or prefetching aren't the lion's share. And for the record, turning off bounds checks is monumentally stupid, and people should be jailed for it. [1] I'm exaggerating to make a point here. What we trade for a little desktop or server performance is an enormous, pervasive risk. Not just melting down in a cyberwar, but the constant barrage of intrusion and leaks that costs the economy billions upon billions of dollars per year. We're paying for security, just at the wrong end. reply saagarjha 13 hours agorootparentTurning off bounds checks is like a 5% performance penalty. Turning off prefetching is like using a computer from twenty years ago. reply crest 7 hours agorootparentTurning off prefetching while running crypto code would be a performance gain before you can implement the algorithms safely without even more expensive and fragile software mitigations. Just give me the option of configuring parts of the caches (at least data + instructions + TLBs) as scratchpad and and a \"run without timing side-channels pretty please\" bit with a clearly defined API contract and accessible (by default) to unprivileged userspace code. Lots of cryptographic algorithms have such small working sets that they would profit from a constant-time accessible scratchpad in the L1d cache if they get to use data dependent addresses into it again. reply aseipp 11 hours agorootparentprevI agree that hardware/software codesign are critical to solving things like this, but features like prefetching, speculation, and prediction are absolutely critical to modern pipelines and broadly speaking are what enable what we think of as \"modern computer performance.\" This has been true for over 20 years now. In terms of \"overhead\" it's not in the same ballpark -- or even the same sport, frankly -- as something like bounds checking or even garbage collection. Hell, if the difference was within even one order magnitude, they'd have done it already. reply bee_rider 14 hours agorootparentprev> I fundamentally don't understand the mindset of people who want to take that kind of risk for a 10% boost in their games' FPS[1] Me either. But, lots of engineers are out there just writing single threaded matlab and python codes with lots of data-dependencies and just hoping the system manages to do a good job (for those operations that can’t be offloaded to BLAS). So I'm glad gamer dollars subsidize the development of fast single threaded chips that handle branchy codes well. > In reality, the vast majority of the 1000x increase in performance and memory capacity over the past four decades has come from shrinking transistors and increasing clockspeeds and memory density I disagree, modern designs include deep pipelines, lots of speculation, and complex caches because that’s the only way to spend that higher transistor budget for higher clocks and compensate for the fact that memory latencies haven’t kept up. > Part of that is paying back the debt that decades of cutting corners has yielded us. It will be tough, but yeah, server and mainframe users need to roll back the decision to repurpose consumer focus chips like the x86 and arm families. RISC-V is looking good though and seems open enough that maybe they can pick-and-choose which features they take. > I almost gave you up an upvote until your third paragraph, but I have to now give a hard disagree. I’m not too worried about votes on this post; this site has lots of web devs and cloud users, pointing out that the ecosystem they rely on is impossible to secure is destined to get lots of downvotes-to-disagree. reply saagarjha 13 hours agorootparentHow is RISC-V going to solve anything here? reply snvzz 2 hours agorootparentIt is significantly less complex yet without compromising anything. This means a larger portion of a chip's design effort can be put elsewhere such as into preventing side channel attacks. reply saagarjha 1 hour agorootparentI don't really see how the design of RISC-V avoids the need to have a DMP reply bee_rider 12 hours agorootparentprevIt isn’t a sure thing. Just, since it is a more open ecosystem, maybe the designers of chips that need to be able to safely run untrusted code can still borrow some features from the general population. I think it is basically impossible to run untrusted code safely or to build sand-proof sandboxes, but I thought the rest of my post was too pessimistic. reply tadfisher 14 hours agorootparentprev> The feedback loop that powers everything is: faster chips allow better engineering and science, creating faster chips. We’re not inserting the security community into that loop and slowing things down just so people can download random programs onto their computers and run them at random. That’s just a stupid thing to do, there’s no way to make it safe, and there never will be. Note that in the vast majority of cases, crypto-related code isn't what we spend compute cycles on. If there was a straightforward, cross-architecture mechanism to say, \"run this code on a single physical core with no branch prediction, no shared caches, and using in-order execution\" then the real-world performance impact would be minimal, but the security benefits would be huge. reply bee_rider 13 hours agorootparentI’m in favor of adding some horrible in-order, no speculation, no prefetching, 5 stage pipeline architectures 101 core which can be completely verified and bulletproof to chips. But the presence of this bulletproof core would not solve the problem of running bad code on modern hardware, unless all untrusted code is run on it. reply Kluggy 4 hours agoparentprevIsn't that the entire point of the secure enclave[1]? https://support.apple.com/guide/security/secure-enclave-sec5... reply sargun 16 hours agoparentprevI think what's more likely is \"mode switching\" in which you can disable these components of the CPU for a certain section of executing code (the abstraction would probably be at the thread level). reply a-dub 1 hour agoparentprevsee DIT and DOIT flags referenced in the paper and in the faq question about mitigations. newer CPUs apparently provide functions to do just that. reply gabrielhidasy 16 hours agoparentprevMany modern architectures have crypto extensions, usually to accelerate a few common algorithms, maybe it would be good to add a few crypto-primitives instructions to allow new algorithms? reply Joel_Mckay 15 hours agoparentprevEncrypted bus mmu have existed since the 1990's. However, the trend to consumer-grade hardware for cost-optimized cloud architecture ate the CPU market. Thus, the only real choice now is consumer CPUs even in scaled applications. reply bee_rider 15 hours agoparentprevOne option would be for people to stop downloading viruses and then running them. reply xiconfjs 17 hours agoprevFrom the paper: \"OpenSSL reported that local side-channel attacks (...) fall outside of their threat model. The Go Crypto team considers this attack to be low severity\". reply saagarjha 13 hours agoprev> Can the DMP be disabled? > Yes, but only on some processors. We observe that the DIT bit set on m3 CPUs effectively disables the DMP. This is not the case for the m1 and m2. Surely there is a chicken bit somewhere to do this? reply theobservor 17 hours agoprevThe end result of these side channel attacks would be to have CPUs that perform no optimizations at all and all opcodes would run in the same number of cycles in all situations. But that will never happen. No one wants a slow CPU. As long as these effects cannot be exploited remotely, it's not a concern. Of course multi-tenant cloud-based virtualization would be a no go. reply bee_rider 15 hours agoparentWe need to drop all the untrusted code on some horrible in-order, no speculative execution, no prefetching, 5 stage pipeline from architectures 101 class core. reply wmf 10 hours agorootparentIf untrusted code includes JavaScript that would make Web apps ridiculously slow. (I know what you're thinking...) reply bee_rider 10 hours agorootparentOh no, a totally unexpected side effect, less complex webpages. reply graemep 14 hours agorootparentprevIt might be preferable. We have ridiculously fast hardware. In many use cases (client machines in particular) we do not usually really need that. I would gladly drop features for security. reply bee_rider 14 hours agorootparentIt will also be good because users will become more annoyed when people try to sneak full programs into their websites, hopefully resulting in a generally less bloated internet. reply _factor 14 hours agoparentprevThis is why high core counts and isolation matter. Isolate the code to a specific core. Assuming everything is working as intended, an exploit won’t compromise other tenants. reply woadwarrior01 18 hours agoprevReminded me of the Augury attack[1] from 2022, which also exploits the DMP prefetcher on Apple Silicon CPUs. [1]: https://www.prefetchers.info reply Findecanor 17 hours agoparentBTW. Three of the authors of GoFetch where also behind Augury. reply loeg 17 hours agoparentprevYes, they specifically mention that in the article and FAQ. reply Shtirlic 12 hours agoprevIs it naive to ask whether implementing this mitigation would impact performance and memory interaction speed? reply d-z-m 7 hours agoprevwhat's the attack vector here? access to an encrypt oracle and co-location on the target machine? reply john_alan 13 hours agoprevOn reading it seems a lib like libsodium can simply set the disable bit prior to cryptographic operations that are sensitive on M3 and above. Also looks like they need to predetermine aspects of the key. Very cool but I don’t think it looks particularly practical. reply martinky24 17 hours agoprev [–] Why does every attack needs its own branding, marketing page, etc...? Genuine question. reply modeless 17 hours agoparentScience isn't just about discovering information. Dissemination is critical. Communicating ideas is just as important as discovering them and promotion is part of effective communication. It's natural and healthy for researchers to promote their ideas. reply FiloSottile 16 hours agoparentprevNames are critical to enable discussion. The \"marketing\" page is where documentation is. Summaries that don't require reading a whole academic papers are a good thing, and they are the place where all the different links are collected. Same reason software has READMEs. Logos... are cute and take 10-60 minutes? If you spend months on some research might as well take the satisfaction of giving it a cute logo, why not. reply saagarjha 13 hours agoparentprevWhy does the comments of every such attack need a question about why it has its own branding, marketing page, etc…? Genuine question. (Seriously, this comes up every time, just do a search for it if you actually want to figure out why.) reply xena 17 hours agoparentprevSo people talk about it reply sapiogram 17 hours agoparentprevWell, names are useful for the same reason people's names are useful. The rest just kinda happens naturally, I think. reply yborg 17 hours agorootparentYes, it saves time vs. starting a discussion on \"that crypto cache sidechannel attack that one team in China found\". reply martinky24 17 hours agorootparentprevName makes enough sense. \"Branding, marketing page, etc...\" was my question. \"Happens naturally\" isn't really an answer. reply ziddoap 11 hours agorootparentIs your position that any write-up about an attack must be plain text only, and must not use its own URL? I truly cannot understand why this is brought up so often. You aren't paying for it, it doesn't hurt you in any way, it detracts nothing from the findings (in fact, it makes the findings easier to discuss), etc. There is no downside I can think of. Can you share what the downsides of a picture of a puppy and a $5 domain are? Sorry, \"branding\" and \"marketing page\"? Or at least, maybe you can share what you think would be a more preferable way? reply fruktmix 17 hours agoparentprev [–] It's science these days. They need funding, one way is to get people to recognize the importance of their work reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "GoFetch is a side-channel attack targeting Apple CPUs with data memory-dependent prefetchers, enabling attackers to retrieve secret keys from constant-time cryptographic implementations.",
      "The vulnerability impacts Apple M1, M2, and M3 processors, along with Intel's 13th Gen Raptor Lake microarchitecture, through exploiting the DMP feature for cache-timing analysis.",
      "Users can safeguard their systems by applying the latest updates, deactivating DMP on susceptible CPUs, and integrating input blinding in cryptographic protocols to mitigate the risks posed by the GoFetch attack."
    ],
    "commentSummary": [
      "The conversation underscores the significance of security in contemporary hardware and software development, especially regarding vulnerabilities to side-channel attacks.",
      "Recommendations are proposed for incorporating secure cores and cryptographic extensions to manage risks, although there are concerns about balancing security with performance optimization.",
      "Emphasizing the prioritization of security measures, like securely running untrusted code, is crucial to thwart breaches in confidentiality and financial losses due to cyber intrusions."
    ],
    "points": 202,
    "commentCount": 53,
    "retryCount": 0,
    "time": 1711032678
  },
  {
    "id": 39777223,
    "title": "Navigating a FinTech Startup: Marketing Specialist's Guide",
    "originLink": "https://news.ycombinator.com/item?id=39777223",
    "originBody": "E.g. I&#x27;ve never been strong at finance (always at the bottom of the class) but I&#x27;ve joined a startup 2 months back that makes a b2b saas fintech product, to lead marketing (first mktg hire in in a total 12 member team). I&#x27;ve worked with the founder before and I like the company. The founder has mentioned that it&#x27;ll take time to learn the nuances of the product&#x2F;industry but since I&#x27;m a somewhat senior person (9 years exp.), I wanted to see if there are any best practices out there to increase the speed of knowledge transfer&#x2F;onboarding so that I can connect the dots faster, so to speak.We do have a set of required reading material that I&#x27;ve gone through, along with product demos, and even 2 VC books that have been recommended on the subject. But unfortunately, I still feel left behind. I need repetition to understand something deeply. Kind of like rote.The lack of knowledge is obviously going to affect my growth somewhere down the line as well as in identifying opportunities for the company&#x27;s growth.I&#x27;m looking for advice on what can I do more from folks who joined a company&#x2F;product&#x2F;industry that they knew nothing about and how long it took you to get comfortable with it?",
    "commentLink": "https://news.ycombinator.com/item?id=39777223",
    "commentBody": "How to onboard yourself to a new product/industry in a new job?190 points by sujdes 22 hours agohidepastfavorite67 comments E.g. I've never been strong at finance (always at the bottom of the class) but I've joined a startup 2 months back that makes a b2b saas fintech product, to lead marketing (first mktg hire in in a total 12 member team). I've worked with the founder before and I like the company. The founder has mentioned that it'll take time to learn the nuances of the product/industry but since I'm a somewhat senior person (9 years exp.), I wanted to see if there are any best practices out there to increase the speed of knowledge transfer/onboarding so that I can connect the dots faster, so to speak. We do have a set of required reading material that I've gone through, along with product demos, and even 2 VC books that have been recommended on the subject. But unfortunately, I still feel left behind. I need repetition to understand something deeply. Kind of like rote. The lack of knowledge is obviously going to affect my growth somewhere down the line as well as in identifying opportunities for the company's growth. I'm looking for advice on what can I do more from folks who joined a company/product/industry that they knew nothing about and how long it took you to get comfortable with it? rco8786 21 hours agoI have a very specific (and pretty easy) strategy for this when I join a new org. Technically you could do this at any time, but you generally have a \"grace window\" when you're new where people are happy to go out of their way to meet you and teach you. First, meet 1 on 1 with every member of your immediate team. This of course serves as a \"get to know you\" meet, but your real goal is to get them to explain their work to you. Have them go into as much detail as time allows on whatever they're currently working on. Ask followup questions that start with \"why\" on everything. Have them show you their part(s) of the product, have them share as many docs as they're willing to (for you to read async later), etc. Put aside whatever ego you may have, and just get into a beginner's/learning mindset. Ask all the stupid questions. Then, at the end, ask them who else they're working with from other teams. Put those names on a list, and rinse and repeat with them. This way you'll start local to your role and work your way outward in the company. Eventually you'll find people that are doing nothing particularly relevant to you and you can decide to stop. If it's a larger company, this is also where you establish your understanding of the org chart and who does what in it, and also makes you known to a ton of folks who may want or need to work with you in the future - which is invaluable in and of itself. reply DavidPeiffer 18 hours agoparentThis process was mandatory at my last company, and it was really helpful. People are way more likely to respond to your email or do something for you as a newer employee if they've met you, particularly so if you can meet in person. Taking notes during or immediately after the meeting, then synthesizing them to form a narrative is also helpful when you're meeting so many people. The other thing I do is start a file literally titled \"Everything I know about \" and just write everything down. I make diagrams, write sentences with highlighted blank spaces for gaps in knowledge, etc. As you get to the 10th meeting, you have a decent mental model of how things are intended to work, and have probably heard about some of the systems the 11th person works with. When you communicate some of your understanding of the system to them, they can fill in gaps or correct misunderstandings. The other thing I always ask about is what a cadence or work looks like? Is there seasonality in their availability? Finance/accounting are best left alone the first week of the month as they're dealing with month end. Some people are slammed Monday and Tuesday, catching up from things that happened over the weekend. If an entire business is seasonal, it makes sense to prioritize heavy lift projects to the off-season. reply KineticLensman 18 hours agorootparent> If an entire business is seasonal, it makes sense to prioritize heavy lift projects to the off-season One form of seasonality is associated with financial years, in some industries. I found this working on contracts for UK govt agencies, where the FY runs from April to March. The customers usually procrastinated about letting contracts, which sometimes wouldn't appear until after the summer or even just before Christmas. Then there was a mad panic from Jan to March to actually spend the money and submit those deliverables. It followed that the time to do training, internal projects, housekeeping etc, was in April and May. reply jimberlage 20 hours agoparentprevThis is fantastic advice! One additional thing I do is Identify people they don’t work with, that you would naturally assume they would. Typically this means: Your understanding of how processes flow in this industry has some gaps, or some thing you thought was crucial is a solved problem that people don’t think about; or There is tension and some history here, tread lightly while you figure out the office politics; or You’ve identified a legitimate opportunity! Be careful here though, you need to understand if some higher ups have misaligned incentives to keep the status quo before you suggest changes. reply b-karl 21 hours agoparentprevI have not done the 1 on 1 method before, it sounds interesting and will try it in the future, but I agree with utilizing the grace period to explore, ask and learn as much as possible about the organization and industry. My additional recommendation would be to try to identify limited-scope projects that contribute to your role and where you can start delivering some value. For me this helps set a clear goal and it is usually easier to identify the specific skills/knowledge/information/contacts I need to complete the task. It also usually feels motivating to check off those early projects. reply gamepsys 20 hours agorootparent> My additional recommendation would be to try to identify limited-scope projects that contribute to your role and where you can start delivering some value. If you are in a leadership role over a team then having a pre-chewed problem ready for new members of your team is a very useful thing you can do. I'm talking well defined problem with a clear path towards success. This helps the new member become use to the team and processes, and gives them an easy win to put some wind in their sails. Also, this can serve as a litmus test to their on the job performance. reply PaulHoule 20 hours agorootparentprevIt can work really well but you can sometimes find individuals who won't play along. reply maroonblazer 20 hours agorootparentIn which case that's good feedback to give to management. Unless they have very good reasons and offer an alternative (\"I'm on deadline so can't talk now, but after this sprint I'll have time.\") those individuals are actively sabotaging the team and should be dealt with accordingly. reply PaulHoule 19 hours agorootparentOften management knows all about it and does nothing for one reason or another. I had two cases of having a toxic coworker and only being able to get them fired after leaving myself. (Step 1 is “oh shit, we lost an important team member”, Step 2 is “aha! we haven’t been able to replace that team member in six months because of the behavior of the toxic employee”). Next thing I see the person is on LinkedIn looking for a new job. reply robviren 17 hours agoparentprev100% support this approach. My knowledge of product has always been less important than my knowledge of the people, resources, and structure of my organization. I don't need to know things, I need to know who knows things. At least at the start. reply epolanski 13 hours agoparentprev> Put aside whatever ego you may have, and just get into a beginner's/learning mindset. Ask all the stupid questions. This so much. Play fool to catch wise sung Bob Marley and it works wonders. reply mannycalavera42 20 hours agoparentprevsubscribing to everything, rco8786 let me know if you are hiring anytime soon :rotfl: reply efxhoy 21 hours agoparentprevCompletely agree. It’s also a fantastic way to get to know how the org is doing, many people will be happy to share what parts of the product they’re happy with and where the dumpster fires are. I also think it’s useful for the people you’re talking to as they get an opportunity to reflect on what they’re doing and if it makes any sense. It’s like an external auditor or reviewer coming in. Just pronouncing what you’re doing in a way that’s understandable to an outsider can be very helpful in building your in understanding imo. reply rco8786 21 hours agorootparent> Just pronouncing what you’re doing in a way that’s understandable to an outsider can be very helpful in building your in understanding imo. Totally. It's the same idea around rubber ducking! reply samstave 17 hours agoparentprevI've always done this as well! Another strategem is to ask the people you meet with 1:1 how they feel you may help them be more successful. What can you do in their current workflow that will spread load, help you learn, help them succeed. Most times you get \"just happy to have you on board\" but you can get valuable feedback as well as an understanding of stress levels of others on and off team. reply j45 17 hours agoparentprevThis is a nice summary. Being an innocent beginner helps convey your ability to lead yourself and work with a team at the same time. One tweak I do is assume your grace window is half the length you're told or believe. Building up a bit of momentum in case it's needed if something comes up is helpful. reply kerkeslager 21 hours agoprevAs a freelance software developer, I've worked in finance, law, logistics, pharmaceuticals, cable TV, food sales, and probably a few more I'm not remembering off the top of my head over the years. I provide the best service to my clients when I understand the domain well enough to make suggestions that marry the capability of the computer and the web to their domain. It helps that I have repeat clients often, and referrals within the same industry so I can re-use knowledge from previous contracts, but often I'm working on software for a domain I have no prior knowledge for. So it's a high priority for me to be able to obtain a lot of information about the domain quickly. Here are my tips: 1. Schedule time to ask questions. Domain experts' time is valuable, and you don't want to be interrupting their other work, so if you can build up a list of questions and schedule a 30 minute period to ask all your questions, that uses their time more effectively, and also gives them the opportunity to take the time to answer the questions you didn't ask. (OP doesn't appear to be a freelancer, but for any freelancers reading this, I don't bill for this time, which helps clients to feel they're getting something worthwhile from it). 2. Ignore \"rank\". The people on the bottom of the totem pole are often the people who know the most about the domain because they are actually working waist-deep in the domain. There have been cases where I have used my seniority to escalate problems or promote ideas from, say, an intern or junior, that were likely more valuable than the development work I was getting paid for. When you do this, be sure to give credit where it's due--people remember that sort of thing. 3. There comes a point somewhere in the 3-6 month mark at a job, where I start getting a lot of anxiety because I feel like I should understand the domain better than I do. This has never, in my experience, been anyone else's expectation. It's just impostor syndrome. reply tedhallez 21 hours agoprevI'm facing a similar challenge, but for Sales within the defense industry. I've approached it by reading and thinking about the company's relationship to it's stakeholders. Understanding and writing mini-essays on the current customers and their pain points, the main competitors and their products, the history of the industry/segment and more. Information sources include YouTube, podcasts, press releases, news articles from niche sites, research paper summaries and various websites. Networking of course plays a role, where I've sought out friendly people a few years ahead of me when it comes to industry knowledge. Mostly through existing contacts I'd do this again if I needed to, and would make sure to leverage each new contact to introduce me to further relevant people. I've asked ChatGPT specifically to detail out how a MBB-consultant would approach the knowledge acquisition challenge, as they are adept at quickly navigating and learning a new field in a short amount of time. This has helped somewhat and suggested I'd sit down a perform a few different types of analyses. As for rote learning, I've bought into the Anki flashcard system where i study acronyms, enemy materiel NATO designations, specifications and more. To wrap up, I've studied finance myself and I have a strong feeling that there's a low correlation between financial-academic success and proficiency in marketing in the industry... Best of luck! reply wikidani 19 hours agoparentIf you don't mind me asking, what does a sales role within the defense industry entails? I am only familiar with the big expos and (sort of) public tenders for specific things like PPE reply qznc 18 hours agoparentprevSecond Anki! Joining an industry/domain/organization also means learning the language there. The acronyms are vocabulary. reply omarhaneef 20 hours agoprevAll these suggestions are great but I would add two more: 1. find a good text book in the field as narrowly construed as possible, and just browse the table of contents. This will give you a quick map of the field, and a place to put all the info you gain. 2. Read the management discussion in the 10k of a public version of the company you work at and 2 leading customers, and the transcript from the earnings call. Fastest way to get up to date on challenges. reply galdosdi 17 hours agoparent> 2. Read the management discussion in the 10k of a public version of the company you work YES! Management's Discussion of Risks section of 10ks is amazing, and really easy to read. I think it's nuts to work at a public company and NOT follow your employer's 10ks and earnings calls (at least on and off, or at least when newly hired as well as for context any time there's Big Corporate News) It really helps cut through management's BS when you can just read how they're describing the situation to the shareholders rather than the spin for internal audiences. It's the One Secret Trick that will give you an idea of what the motivations and interests of your company's leaders are, as opposed to what they claim or you guess that they are, which then ends up being super useful for say, judging which project has a better likelihood of becoming important, how to sell things internally, etc reply bzmrgonz 19 hours agoparentprevNice, we are going macro now. This is often overlooked, if you did a lateral industry shift, you have to get conversant in the industry lingo asap, so don't forget the jargon and concepts. Most standard industries are well documented, even though the documentation may be less than stellar (I'm personally looking for IP industry material to binge on, nevertheless, because it's IP(intellectual property), they don't publish much training/guide material). I tend to do the book thing but on subreddits of the particular sector/industry, I think that browsing topics on reddit is the fastest way to get conversant and begin to absorb knowledge, or more specific, awareness of existence of knowledge. reply decafninja 20 hours agoprevControversial take from me. Also this was more in the context of legacy finance tech whereas you are in fintech. I used to work in tech at an investment bank. When I first joined I was all starry eyed and eager to learn about the business, even to the point of trying to get a CFA (which some of my colleagues apparently had done). Fast forward many years, I came to the conclusion that the limited time I had was best spent becoming a better technologist/engineer instead of a halfassed banker/trader/investment professional. Of course it’s still useful to know the basics of the industry and anything specific to your role, but beyond that the returns diminish sharply. FWIW most of my engineer colleagues that spent all that grueling time and effort to get a CFA no longer work in the finance industry, so it’s arguably all down the toilet unless they ever go back. AFAIK none of them want to reply eitally 12 hours agoparentI think this isn't controversial on the tech side, but on the business side it is absolutely 100% more important to deeply understand the business and build a meaningful, useful network than it is to half-ass your way on the tech side. As careers advance in business, doors to new opportunities open primarily based on one's reputation & network, so it pays dividends to focus on cultivating those starting as early as possible. \"Managing up\" should not be an epithet, but a way of life. reply rohanm93 20 hours agoprevI covered this in a recent issue of a career newsletter I write [1]. Some snippets from it that I think would help new joiners (not only those joining a new industry): 1. No-one’s going to go out of their way to guide you. Esp at smaller companies, the fact that you’ve been hired means you’re joining a time-poor company, and there likely won’t be a formal onboarding process. So...you’ve got to onboard yourself. 2. Adopt a mindset of personal responsibility. This isn’t going to be a passive process, but an active one. 3. Don't meet everyone for the sake of it. The goal isn't to set-up endless meetings and become a burden. Limit yourself to a few, and make the most out of them. Make your ask clear when you ask someone for their time — e.g. 'I'd like context on X and what's been done so far' 4. Get some small wins on the scoreboard. Although your priority is to learn the key skills of the job, you also want to make a great impression during your first 60 days by showing you’ve made an impact. To do that, identify some smaller projects you can knock out to get a few small wins under your belt. 5. Be ‘seen’. Make your presence known. And communicate upwards so people know you’re busy. How? Tell your manager, “Can I send you a list of 5 things I think I need to hit the ground running? I’ll then set up a 1-1 and we could go through that.” the full essay's here [2] (and plug: the newsletter I write is called Coached. If occasional career strategy is your thing, feel free to check it out) [1] https://coached.com [2] https://careersupplement.beehiiv.com/p/cs233-onboarding-hard... reply UncleEntity 20 hours agoparentThis is also sound advice for someone wanting to join an established open source project. Pluck some of the low-hanging fruit so they can get to know you and try not to be a burden on the core maintainers. And...have fun? reply sevagh 19 hours agorootparentI think starting off with the impression of being a small wins person sticks, and people will think of you as \"does small tasks well.\" No promos and whatnot. It's why being a loud jackass that deploys something horrendous has better outcomes for your career. reply spacecadet 21 hours agoprevTalk to people. Interview your entire team, with detailed questions, avoid solutioning out of context, just listen. Next extend those interviews to stakeholders your team supports- go as deep or as high as you can, adjust questions for context, execs? business/strategy questions, the janitor? the dirt questions... yes interview the cleaning crew... Ive done these rounds at every job and 2 times I left that job immediately after the interviews. reply jstanley 21 hours agoparent> I left that job immediately after the interviews. Why? reply omarhaneef 20 hours agorootparentIf you read between the lines, it would seem no one was keeping the place clean. reply koliber 21 hours agoprevIn addition to the 1:1 suggestion that rco8786 wrote ( https://news.ycombinator.com/item?id=39777488 ), immerse yourself in conversations. Watch recordings of standups, all-hands, sales calls, and whatever you can get your hands on. Attend meetings and sit quietly in the corner. Listen. Much of it will be foreign. Over time, more and more will make sense. It will begin to gel. Take notes on words and phrases that are unclear. Google them. See who you can ask about help (see the 1:1s strategy). Repetition is important in learning. Everyone learns differently. I like multi-modal reinforcement. Listen in groups, QA in 1:1s, read books, search Google, try by doing. It all somehow comes together and all of a sudden you're riding the bike without paying attention to your feet and hands. reply infamia 20 hours agoprevYour lack of experience and absence of preconceptions is a golden time. First, interview your customers (internal and external), to see how the team/company are perceived and what is important to them. Explain to them that you are talking to them first to avoid forming any preconceptions. Spend a bit of time organizing and summarizing your findings before moving on to interviewing your team. By interviewing your team last, you will be able to ask better questions and avoid being locked in to your company/Dept's group think and culture. reply cableshaft 17 hours agoprevI work in consulting and have been working for a client in finance for the past two years working on greenfield applications for them. I haven't gone too far out of the way to learn aspects of finance other than through exposure and osmosis. As long as there's someone on the team that really understands it on a deep level, you don't have to be that person to be effective, at least on the frontend (which has been my focus for this client, although I am doing a bit more backend now). Hasn't stopped me from implementing complicated features as requested and discussed, just asking questions for what's expected, what the data should look like when it's done correctly, etc, but now I do understand it a lot better and I can mostly follow along during deep discussions (some of it still goes over my head though). That being said, you can pick up books on finance to help you understand things better. For me, I discovered recently (stumbled upon it at a used bookstore, actually), that I should probably pick up textbooks on Quantitative Investment Analysis and Portfolio Management in order to understand those deeper discussions better, but the focus of your startup might be different. reply alephnerd 15 hours agoprevAre you Product Marketing or Content Marketing/Demand Gen? First - recognize that there is a significant difference between the two. Second - chat with peer PMMs, Field Marketers, Growth PMs, etc to get good tips and advice. Finally, I recommend reading Monetizing Innovation [0] in order to understand the Packaging and Pricing portion of Product Marketing. For Content Marketing/Demand Gen, I found Hacking Growth to be useful, but honestly there are a number of YC and adjacent podcasts that are fairly useful for that. Finally - if you feel you don't like the role or the space, make sure to let you CEO know ASAP and make a transition plan with them. In my younger days I burnt a bridge with a good friend when I became an inexperienced VP Marketing/Demand Gen at their startup. [0] - https://www.simon-kucher.com/en/insights/monetizing-innovati... reply toddmorey 14 hours agoparentOP isn’t new to marketing, just this particular industry. reply austin-cheney 12 hours agoprevYou should always be aligned to the revenue mission of the company. The mission is to earn money AND enhance the reputation of the company. Scenario 1: My first job out of college was developing automated pretty HTML for emails for this marketing company in the hospitality industry. It was still start-upish at that time, so the business was centered around account management and business relations. I was hired to be a developer, so I found problems to solve. When those solutions saved business relationships I could walk on water. I got good at task lists and account management even though account management was handled elsewhere. Scenario 2: I once did cyber defense for the US Army back before Army cyber was a thing. I started getting pretty good at it until I was promoted out of that organization into a logistics organization. All that cyber expertise didn't matter so much anymore, I had to be a manager in a group that different things. I was basically a people manager of a help desk plus other stuff. In order to protect my staff I had to learn logistics. I had to know how to do other people's jobs so that I could push back with better answers when leadership made decisions or other managers tried to poach my people. I have now been in logistics long enough I know the management of logistics operations better than many of the logistics managers even though I am just the IT guy. This provides me a lot of pull. Scenario 3: I spent a lot of time as a developer in the online travel agency space. I learned a lot about the retail side of e-commerce and the behavior of travel planning. As a junior developer I was promoted to a senior in about 2 years because I the A/B test guy for this major .com brand. I learned to master DOM traversal without abstraction layers so I could write tests really fast that did amazing things and were often more durable than the actual real code later released to production. Because I had also learned the business of e-commerce and the travel industry I could also design better tests and than many of the business owners recommended. So long as velocity, durability, and quality of test remained high I could walk on water. reply ipnon 21 hours agoprevI have a simple method that worked well for me in my last job, where I switched industries completely and was definitely underwater. First I became friends with everyone I could. Then identified the most mature teammate with the most tenure, and the smartest teammate who clearly generated the most value for the company. Anytime I got stuck on a problem for more than a few hours, I asked the greybeard for a quick chat. He was pretty always willing to hear me out, let me break down my understanding, then rebuild all my faulty assumptions. His time was relatively cheap but his knowledge base relatively valuable, so with him I did deep dives. The smart hacker guy I watched from a distance. Any time I saw him merge some ludicrous Rube Goldberg type commit I’d send him a quick DM, knowing his time was precious. I’d fire off a few quick questions and try to glean as much insight into his critical work before he scurried off to the next apparently invaluable task. I think approaching the problem this way, leveraging the “implicit theories” embedded in the teammates heads, is the surest and most efficient way to ramp up, besides the obvious advice like RTFM and gloss over the relevant textbooks. Always remember to make yourself useful first. No accomplished engineer will ever turn down a well intentioned and friendly favor! “Team work makes the dream work,” as they say. Good luck! reply sebstefan 21 hours agoprevI've found that these two tips help * Putting in time to learn the product as a user of it before trying to develop for it is time well spent. In my experience it makes it easier to read the code afterwards * When a codebase is old and you're reading a file where 10 to 20 developers have done a pass of bugfixes on it, it may not immediately be obvious what everything does and why some checks are being done. Going through the history and checking earlier versions of the file sometimes helps me getting the basics of it down reply epr 21 hours agoparent> Putting in time to learn the product as a user of it before trying to develop for it is time well spent This should always be priority #1 when you first arrive. Not only is it beneficial for understanding your work, but you can never get back that opportunity to see through the eyes of a real user. Once you get used to a product, the warts will be less apparent. Put the product through it's paces, and take notes on what's confusing or unintuitive. You don't want to tell everyone their baby is ugly immediately, but you can slowly address at least some of the issues over time. reply tetris11 21 hours agoparentprevThe first point is one I strongly agree with. It is bewildering, trying to understand a codebase from the bottom up. The best part of learning it as a user, is that you can also make meaningful edits to the product page or user documentation that is often completely overlooked by devs. reply rco8786 21 hours agoparentprevOP is in marketing, not eng, FWIW. reply sebstefan 21 hours agorootparentOop, nevermind then reply Roelven 21 hours agoprevRegardless of your job or responsibilities, if you are new to a certain domain, find users or customers to talk to. If you can't talk to them directly, find colleagues who do, and ask to be a fly on the wall. Meet at least 10. Write down their day to day jobs, their challenges and their frustrations. Even from just listening to others talk, you will get a good perspective. To speed it up, write an interview script with a set of questions. Use an LLM to make the questions non-leading if you want, but point is to show colleagues who have customer contact your script. If you manage to do the interviews, record them, transcribe them and share them around. You are now a customer advocate who knows the customer's needs and wants. Don't wait with doing this only after you've met the team, start immediately. Let this be your driving force to meet colleagues. It's useful, offer to share the results, or ask for question ideas to whoever wants to listen to you. You now have laid the groundwork for your success. Now you can focus on the organisation, the team, the mission, the proposition, etc. Everyone you now meet, talk about how customers want to do A or B but can't, or about their challenges. People will appreciate your insight and you're off to a great start! reply vipshek 19 hours agoprevIn the past year, I've gone from near-zero understanding to pretty deep expertise in the domain of electrical grid interconnection as a product engineer. Here's how I went about it. I think all the other comments saying \"read a lot\" and \"talk to everyone\" are correct first steps, but for me, consuming information has diminishing returns after a short while. After you've reached a point where your brain feels like it's exploding, you should switch your focus to outputting information. If you're a \"write things down\" person, then write a synthesized document explaining everything you've learned, and then ask a few trusted coworkers to tear it apart. If you're a \"talk out loud\" person, schedule time with coworkers to have a \"teachback session\" where you give a presentation about everything you've learned. Again, ask them to tear it apart. It's crucial to build trust with a few coworkers who are willing to critique your output. Get them to rip everything you've created to shreds. Whenever you write or say something that's even slightly off compared to how someone in the industry would say it, make sure you learn about that, and learn how someone in the industry would say it. This focus on getting the language right - especially the colloquial language of how people actually describe things day-to-day - is important for every role, but I assume it's especially important in marketing, where you need to be able to use the precise language that your customers use. tl;dr: Read/talk to people at first, but switch to writing/presenting ASAP. Solicit and internalize as much critical feedback as you possibly can. reply epolanski 13 hours agoprevI start taking notes and have endless questions for everyone. By the end of the first days it is clear to me that most people there, even some veteran product managers have a very incomplete ideas. By the end of the first few weeks I generally end up being the most knowledgeable person in the team (or at least among the top) because generally most people don't give two damns and are there for the paycheck so I'm reminded of how low the bar is in pretty much any environment. A nice side effect of my approach is that you end up learning a terrific amount about the other team mates and you force people into questioning their knowledge themselves. reply scyzoryk_xyz 10 hours agoprev9 years and you consider yourself a „senior” and you still think about how you „feel” left behind? What do you expect? Processes take time - all of them. I ventured into a new domain 3 years ago and got comfortable within one year. Then found out I know nothing around year two. Then again. Back and forth. True seniors, experts, whatever you call them - they don’t get comfortable. reply scyzoryk_xyz 1 hour agoparentJust realizing the above comes off super grumpy. To clarify, sometimes I get the sense that the sort of people, also like myself, who come on here, have this delusion that this tech stuff will cheat reality. That you do this and that, you play your cards well and you will skip ahead of everyone else in all the other professions in society. A sort of technocratic megalomania. I absolutely do not know that the OP is like this. My experience „switching” domains is that it can help to find the common familiar denominators with what you know in the new thing. And then, like an anthropologist, to develop a respectful understanding of the people who are experts in this domain. You keep it respectful by recognizing that you’re not going to catch up with them. It’ll be their job to convey to you what their problems are, and yours to listen carefully. You might be good with that hammer you’re holding from your earlier experiences, but they might not even have nails for you to bang on. That’s where the discomfort comes in. reply hn72774 19 hours agoprev> We do have a set of required reading material that I've gone through, along with product demos, and even 2 VC books that have been recommended on the subject. What were some of the reading material and books? What area of fintech? I went the other way, from finance into non-finance. And from bigco to smallco. It took a solid 6-12 months to start feeling competent. It was worth it. I now have a lot more breadth on the business side, and technical depth from having to read code to learn a bunch of new stacks and end to end integration flows. At the smallco there wasn't much for docs to read, and the ones they had were out of date. reply h0bb3z 15 hours agoprevAs a new engineer (engineer #2) at a startup decades ago, I was asked to teach the new incoming engineers about the company product.. Next week. Forcing myself into the mindset that I had to explain it to others in a meaningful and comprehensive way - AND to be prepared to answer questions - I learned and understood the product in record time. It wasn't perfect, but holy moly was I motivated to know it well enough to explain it. reply newsclues 21 hours agoprevRead. Trade publications, textbooks, news. Ingest everything, take notes and ask questions. Showing an interest is important, learning the lingo is important but it will be a learning curve and it’s important not to expect too much from yourself too soon. reply attah_ 13 hours agoprevWhen i have joined a new project, i have asked for a \"safari\" from one or a few senior people. Show me \"the big five\" of your area. Pretty simple to find time and willingness for generally, and it's been a good amount of info to digest at once. reply ilc 19 hours agoprevI've done this a few times. 1. Immersion. I learn more German in Germany when I visit for a week than I do in months of study. Why? Because I can see it all context. I can guess what a Hauptbahnhof is context, and other words. You start to see the patterns. Work is much the same. Get in there and learn! There is a reason why the first thing every software developer should do is fix a pretty easy bug. It gets them to do so many essential things they will need to do day to day as part of their job. 2. There are no dumb questions. \"What is Alpha?\" \"What are the Greeks?\" etc. All VERY valid questions. If in Star Trek parlance if someone says to \"Tech, tech the tech.\" ask some questions. :) (Tech was used by the writers as a stand in to allow them to write the script without looking everything up.) 3. You have time. Nobody expects you to know anything. Ramp up for an industry to basic levels is usually about 6 months. 4. Suffer. Try to learn the concepts. This won't always work, but it'll teach you tons of extra concepts you will need later. Time spent learning is rarely totally wasted. It just may be the knowledge you need to cross a gap later. Also it makes it obvious to the people around you, you are trying, thus you are more likely to get help. 5. Don't be afraid to be stupid. When I used to work with TLAs a wise boss once told me if he didn't know what some word/acronym meant. He'd just ask. It was amazing how many times nobody in the room could expand it. Despite us all working with it ;) I've picked up this habit from him. It hasn't hurt me... But it can be a great way to rattle people. reply slotrans 19 hours agoprevIf you're curious, you'll learn. If you're not, you won't. Nothing else to it. reply volkk 16 hours agoprevctrl-f \"use the product\" -- and haven't seen one mention of this. dogfood your product. shadow people using it if you're not the target demographic, understand it inside out, and you will catch up very quickly. reply joby_surge 21 hours agoprevYou should join the product marketing alliance which has frameworks & an active slack community that can help you out. reply joloooo 17 hours agoparentI'm assuming you're a member; what is the value you enjoy most from PMA? I've been on the fence. reply VladimirGolovin 21 hours agoprevTake my advice with a grain of salt, but: Get a ChatGPT4 subscription and ask away. It may hallucinate, but it lets you ask questions and immediately clarify points you don't understand. When you get the basic understanding, check it against a more reputable source (e.g. Investopedia?) Here's an example question (which I obviously made up): \"Hi! I'm about to get a job in finance but I feel that I don't fully understand some of the important concepts, such as compound interest. Can you explain compound interest to me?\" reply Kon-Peki 20 hours agoparentThese books, which are expensive because I don't think they're printed anymore, are going to be far more useful than GPT: https://www.amazon.com/Dictionary-Finance-Investment-Busines... And since the resale value is extremely high, so you can always resell if/when you don't need them anymore, possibly for a profit. reply DontchaKnowit 14 hours agoprevHonestly, define key terms and make anki flashcards. Not gonna give you deep understanding BUT will make the roadmap lf terminology and probably thw structure of the company and the product very concrete very quick and so the nuance will come much faster. reply itqwertz 20 hours agoprevMake friends with the people around you. You’ll pick up things by osmosis, be able to ask “stupid” questions without revealing your lack of knowledge to anyone who might see this as weakness. whenever you see a term or concept you don’t understand, WRITE it down. The brain-body connection works well for your memory. I’m gonna get flak for this, but going out drinking and to the smoking area will give you an inside track to how the company operates. reply enjoyitasus 20 hours agoprevLLM Agent support reply j45 17 hours agoprevI've learned to work in multiple industries and verticals and transferring what I know that can. Generally, there's no hack around learning, other than learning more efficiently. The faster you dive in, the sooner you'll have a sense of what you know (more than you think) and where to actually focus in the next 3-6-9-12 months. There is a course called learning how to learn that focuses on how adults learn differently that's worth checking out before going into fintech or other topics. Highly recommend checking it out as a first stop. Fintech is a broad and vague category, not specific. In this case if it's new to you, focus on first principles learning whether it's in finance, banking. If you can saturate your time, consciousness with meaning full content, there is a good amount of passive spaced repetition from hearing different explanations of concepts. Podcasts can be helpful, but for learning you will probably find some things on youtube to subscribe to and work through. Have a playlist ready to go, whether it's in your ears, or on a speaker while getting ready in the mornings. First principles learning means learning the basics and using that to build up to the other concepts. Luckily it also can mean learn it like you're 5 and don't expect to learn it as quickly as something that is partially familiar or similar. When you do this, your brain will point out what's familiar or similar anyways. What's nice is if you're not great at math, there's still a lot of people and process interactions that can have value added too. The math can be learned too. reply RecycledEle 21 hours agoprevLook at the training materials, and look up every word in them. research until you can give an example of how everything is used. There are probably old time finance people running the company ir advising it. Find out what they did back in the day and look at things from that point of view. reply zabzonk 21 hours agoprev [–] to be honest, if you are in marketing and you don't understand the market you are trying to sell into i don't see this going too well. reply chasd00 20 hours agoparentIt can if they have time to get up to speed but if they're thrown right at clients/customers probably not. I consult and develop on a very complex platform, both in breadth and depth. I routinely have to correct their sales/marketing people and account executives on platform capabilities and even pricing/licensing. I try not to do it in front of clients but sometimes have to. You're right in that it doesn't go well. edit: actually, i've seen this work. The marketing person has to be honest and upfront about being new and take down any questions they can't answer and then follow-up. I've found clients/customers to be sympathetic, everyone has been thrown into the deep end at some point in their career. A humble and honest approach can even endear them to the customer. So, it can work but the you have to upfront, honest, and absolutely follow-up. reply esafak 16 hours agoparentprev [–] You'd learn, wouldn't you? Other marketers were not born with the knowledge either. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A marketing specialist, new to a startup providing a b2b Software as a Service (SaaS) financial technology product, is facing challenges understanding the intricacies of the product and industry.",
      "Despite having nine years of experience, the individual seeks advice on expediting the onboarding process to contribute effectively to the company's growth."
    ],
    "commentSummary": [
      "The post provides advice on quickly adapting to a new product and industry in a new job, including meeting team members, documenting information, understanding work dynamics, and identifying areas for improvement.",
      "It emphasizes networking, staying updated on company challenges, building relationships, and understanding the business aspects, while highlighting the importance of remaining humble, seeking feedback, and continuous learning.",
      "Additional suggestions involve learning finance, industry terminology, improving technical skills, and networking, as well as utilizing AI tools, reputable sources, and first principles learning for industries like finance and fintech."
    ],
    "points": 190,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1711020525
  },
  {
    "id": 39777896,
    "title": "Ikigai: Finding Meaning and Happiness in Life",
    "originLink": "https://nesslabs.com/ikigai",
    "originBody": "I lived in Japan for seven months when I was younger. For all of the challenges I faced there as a woman and a foreigner, I still learned a lot from Japanese culture. Because Japan experienced a long period of relative isolation from the outside world — caused by sakoku (literally “closed country”), the isolationist foreign policy of the military government during the Edo period — Japanese people have developed their own unique set of values and beliefs. One unique Japanese concept is the idea of ikigai, which can be roughly translated to reason for being (or “raison d’être” in my native French) . Each person’s ikigai is personal to them, reflective of their inner self, and creating a mental state in which they feel at ease. What makes it such a powerful idea in today’s age of constant change and uncertainty is that ikigai doesn’t limit someone’s value in life to career and financial status. In fact, in a survey of 2,000 Japanese people conducted by Central Research Services, only a third of respondents considered work as their ikigai. Rather, ikigai is about feeling your life makes a difference in people’s lives — the idea that you can contribute to other people’s lives simply by living a fulfilling life. And this idea can unlock many benefits. The Health Benefits of Ikigai Because your ikigai is less of a theory and more of a way of living, it can have a profound impact on your mental and physical health. Ikigai reduces anxiety. Research shows that the feeling of ikigai contributes to a well-balanced secretion of neurotransmitters such as serotonin, dopamine, and endorphins, which in turn reduces the feeling of stress. Ikigai is good for your heart. A seven-year long study with more than 40,000 Japanese adults found evidence that people with a low sense of ikigai had a higher overall mortality risk, mostly due to higher cardiovascular disease. Ikigai increases your self-authorship. Research suggests that people without ikigai have a strong need for approval from others, while those with ikigai tend to perform tasks for their own satisfaction. Ikigai makes you more resilient. There’s evidence that ikigai may help you go through times of hardship more easily, making you feel like it’s worthwhile to continue living. For example, it helped many Japanese people cope during the earthquake that occurred in Japan in March 2011 and during the COVID-19 pandemic. Ikigai helps you live longer. Another study identified ikigai as a positive psychological factor contributing to longevity, with men and women with a sense of ikigai showing decreased risks of mortality from all causes. In short, there’s quite a bit of research suggesting that a sense of ikigai will contribute to your overall well-being. So, how can you leverage the power of ikigai? Leverage the Actual Power of Ikigai The concept of ikigai has often been misunderstood in the Western world largely due to the popularity of the below Venn diagram: This diagram was created in 2011 by astrologer Andres Zuzunaga, who designed it to help people find their purpose in life, and was then adapted by blogger Marc Winn, who replaced the word “purpose” with “ikigai” (you can read the whole story here). However, the concept of ikigai is not about finding the intersection of what you love, what you’re good at, what the world needs, and what you can get paid for. It’s just about finding pleasure in life and being happy to get up in the morning. “Japanese people don’t view ikigai as a lofty goal, a destination, or something to achieve,” explains Nicholas Kemp, author of the book Ikigai-Kan. Similarly, in The Little Book of Ikigai, Ken Mogi wrote: “Japanese do not need grandiose motivational frameworks to keep going, but rely more on the little rituals in their daily routines.” Your ikigai can be found in small daily rituals, side projects, and deep conversations. It can be found in moments of silence and idleness, or in moments of creative flow. To find your ikigai, forget about the westernized version and instead follow these principles: Stop seeking your One True Passion. Many of us think that finding our passion will magically give our life a purpose. Instead, find meaning in your daily experiences and interactions. Explore the world around and inside you. Learn something new everyday, including about yourself. Play with uncertainty instead of chasing the next milestone. Embrace lifelong learning. The concept of ikigai never mentions being good at what you do. There is joy in being a beginner all over again, learning through mistakes, and growing outside of your comfort zone. Don’t try to be the expert in the room. Keep asking questions. Never stop learning. Let go of lofty financial goals. Ikigai also doesn’t have anything to do with money. Of course, we all need enough money to live a comfortable life, and money can help explore projects and ideas that bring you pleasure in life, but beyond the point of comfort, financial success should be seen as a potential byproduct of living a meaningful life. Don’t try to save the world. Instead, focus on the positive impact you can have on your friends, family, colleagues, and community. Ask yourself how you can connect with people in meaningful ways and which changes you want to bring to life. This is how we save the world — when everyone contributes at their own human scale. As psychiatrist Mieko Kamiya puts it, ikigai is closer in Japanese to the “power necessary to live in this world” or the “happiness to be alive”, which unfortunately is often translated to “a life worth living” in English, when the original concept doesn’t ascribe measurable value to our lives. Instead of pursuing a grand life purpose, optimize for wanting to wake up in the morning. Live a life of curiosity and connection. Trust that success will be a byproduct of the meaning you find in daily experiences. Join 80,000 mindful makers! Maker Mind is a weekly newsletter with science-based insights on creativity, mindful productivity, better thinking and lifelong learning. One email a week, no spam, ever. See our Privacy policy. Categories ⛰ Meaningful Living Tags happiness, life, meaning The Triple Take: How to Balance Your Mental, Emotional, and Physical Health",
    "commentLink": "https://news.ycombinator.com/item?id=39777896",
    "commentBody": "Ikigai: What We Got Wrong and How to Find Meaning in Life (nesslabs.com)186 points by pmzy 21 hours agohidepastfavorite73 comments graemep 20 hours agoThis is hardly a novel idea in the rest of the world. It is an ancient one and widespread. It is discussed by many philosophers and is discussed in many religions. It strikes me that westerners have lost the roots of their culture and are having to relearn it from elsewhere. \"ikigai doesn’t limit someone’s value in life to career and financial status\" Ancient Greek philosophers and their successors frequently discussed happiness and how to live life. Assuming it is being explained correctly here, that is less anti-wealth than Christianity (\"it is easier for a camel to pass through the eye of a needle\" etc) but similar in rejecting financial status. Buddhism regards wealth as an attachment so I would have expected a slightly different attitude. From middle eastern (possibly Hellenised) culture before Christianity read the book of Ecclesiastes. \"What does a man acquire from all his labor and from the anxiety that accompanies his toil on earth? For all day long his work produces pain and frustration,) and even at night his mind cannot relax! This also is futile! There is nothing better for people than to eat and drink, and to find enjoyment in their work.\" reply Oioioioiio 17 hours agoparentThats a very hard simplification in a complex modern world. A world like now never existed before: Millions of people living in cities were they are not able at all to live in nature or can't afford to move away or into the cities. A world with high speed communication. A world with unlimited possibilities. A world were you grew up without ever having to learn were your water comes from and how your food is made. The world doesn't need most of us, this was never the case in the past. I'm a smart person, i'm not needed because there are still enough even smarter people. And regarding your quote of the Christians: They don't live it either or never lived. The dark ages produced a lot of christian focused 'art' full of gold. And in the past, if you had any mental illness, you just might have been killed or put in shackles. reply hosh 17 hours agorootparent> Thats a very hard simplification in a complex modern world. Although I think the issues are complex, I disagree that the complexity of the modern world itself leads to this. One of the core features of modernization has to do with the substitution of local communities with regional and global institutions. That alone changed many things. It also does not help that our civilization keeps making this mistake: https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-call... ... that is, the effort by modern institutions to make sense of the world in a legible way leads to imposing simplification on the world. The world was already complex, even in pre-modern times. > The world doesn't need most of us, this was never the case in the past. I'm a smart person, i'm not needed because there are still enough even smarter people. If we take a person's worth as a _quantity_, sure. We can reduce every person into a set of stats, similar to D&D character sheets, and every person fits into roles based upon those stats. Those stats make things more legible. Each person, however, has a _quality_, and it is here one's unique purpose and contribution can be discovered. I didn't learn this from ikigai specifically; as one of the comments talked about, some form of this was widely known in pre-modernized cultures. Carol Sanford has been writing, talking, and practicing this as applied to the modern world for decades. There's also the work of Christopher Alexander. His writings and work convinced me that modernity did not have to be designed this way. reply UncleOxidant 16 hours agorootparentI don't think that Oioioioiio was saying that each person doesn't have intrinsic worth (quality, as you put it), more like that each of us has such a small piece of the puzzle now. In the past if you lost a community member who had critical knowledge and skills it would endanger the survival of the community. Now there aren't a lot of communities where that would be the case. reply hosh 15 hours agorootparentI wasn't talking about intrinsic worth at all. That kind of framing is still looking at things in terms of quantity rather than quality. I'm talking about the difference in the very worldview and paradigm. I am certainly not just talking about the material production someone can contribute. The unique contribution someone can make isn't necessarily about the survival of the community. When I say unique, it means once that person has passed, there will never be again that particular contribution -- at the very minimum, the environment, relationship, and moment is unique, as is the person. As such, the community also grows and changes over time, a living system as much as the individual people within the community are themselves living systems. reply graemep 15 hours agorootparentprevSo why were people considering these questions so long ago? It s not the modern world that is the only problem. > And regarding your quote of the Christians: They don't live it either or never lived. Lots of people have. Not everyone was perfect, but it was an aspiration, and there are whole traditions of monasticism and other service based on it. It is no accident that the word organisations that help others is derived from a Christian theological term, charity. > The dark ages produced a lot of christian focused 'art' full of gold. The dark ages were not dark. Art is one of the things that contribute to the community, and its creation leads the artist to fulfilment. Public art (which is what religious art usually is) is the opposite of hoarding private art. > A world with unlimited possibilities. Very few people have access \"unlimited possibilities\". Financial constraints, legal constraints, personal constraints.. reply a_bonobo 7 hours agorootparent>Very few people have access \"Man is born free and everywhere is in chains\" - as Rousseau said 300 years ago. reply UncleOxidant 16 hours agorootparentprev> And regarding your quote of the Christians: They don't live it either or never lived. The dark ages produced a lot of christian focused 'art' full of gold. There have always been Christians who at least tried to live it. They're in the minority and they weren't and aren't the ones you hear much about (or from) but that's kind of the point. reply woliveirajr 13 hours agorootparentprev> The world doesn't need most of us Perfect. It isn't even a matter of being replaceable: it's just that so many people might die, anywhere in the world, and you don't even notice it. reply nathan_compton 12 hours agorootparentThe world has never needed us, in my opinion. Other human beings may find you useful, love you, whatever, and you may find some kind justification for your own existence, but the world itself has never cared about people. reply mihaic 19 hours agoparentprevSometimes truths have to come from the outside for them to be accepted by the closed minded. As the Enlightenment already absorbed eastern concepts into the western plane to some degree already (see the roots in Hume for instance), the relationship of westerners with eastern concepts as like hiring a consultant to tell you all the things that your employees were already saying, but which were ignored since they were merely grunts. reply geye1234 13 hours agorootparentIs the history of the Enlightenment's link with eastern concepts documented anywhere? Clearly Hume uses eastern concepts (\"I\" am just a bundle of thoughts; causality is just a projection; etc). And the anti-Aristotelianism of the Enlightenment (hostility to concepts such as substantial form) could be seen as eastern too. I'm not sure if this history has ever been documented though. The Enlightenment is seen as paradigmatically western, and in a way it is, and yet it tried to reject pretty much the entirety of western philosophy that came before it -- perhaps even under eastern influence. Stuff is never simple, is it? reply mihaic 3 hours agorootparentYeah, the story is always more complicated than what you generally hear. I've never read about the eastern connection to the Enlightenment in any place, but lots of references pop up. A translation of the play Shakuntala by Kalidasa seems to have created a bit of stir for instance, even inspiring some of the structure in Faust by Goethe. reply MenhirMike 13 hours agoparentprev> It strikes me that westerners have lost the roots of their culture and are having to relearn it from elsewhere. Rome defeating Carthage was legitimately one of the worst things that ever happened in history. reply UncleOxidant 16 hours agoparentprevEcclesiastes, probably the first existential text that we have. In a lot of ways it seems really contemporary. reply graemep 15 hours agorootparentThere was a question some months ago on the Academic Bibical Reddit asking what religious text non-religious people there liked the most and it was by far the most popular with them. I read a bit again recently because someone quoted part of what I quoted with regard to work and education, and it really does feel contemporary. That said, it is not that uncommon for ancient texts to feel relevant. I do not read a lot of ancient texts but one I did recently, pseudo-Xenophon's Constitution of the Athenians had several things, including a great passage about the rich and democracy. There is a lovely reading of it by David Suchet that is on Youtube. reply mistermann 19 hours agoparentprev> This is hardly a novel idea in the rest of the world. It is an ancient one and widespread. This (like so many other things) is a very ontologically tricky proposition due to the deceptive distinction between abstract and concrete \"is-ness\". It is true that at least one Human in each country possesses at least some knowledge of such things, but how well distributed is the knowledge? The so casually deployed symbol \"is\" makes no distinction, and Humans generally do not have the ability to consider such things. Even weirder: Hard Whorfism \"is\" \"false\". > It strikes me that westerners have lost the roots of their culture and are having to relearn it from elsewhere. Absolutely agree....perhaps this is (at least in part) because we never learned in the first place (other than abstractly, and even there only for a small percentage of the population) the difference between abstract and concrete \"reality\", because such things are not taught in standard curriculum in school (see also: financial planning, how to be nice, categorization in general (ontology/taxonomy), etc). I often wonder if all of the sub-optimalities in our \"advanced, 'scientific' culture\" are purely coincidences / oversights. That people seem to so reliably (in frequency, and form) have an innate and very strong aversion (a lot like how religious or anti-religious people get nervous/agitated if one is to call into question the truth of scripture) to discussing such matters in the context of concrete reality makes me more than a little suspicious. reply graemep 15 hours agorootparent> I often wonder if all of the sub-optimalities in our \"advanced, 'scientific' culture\" are purely coincidences / oversights. That people seem to so reliably (in frequency, and form) have an innate and very strong aversion (a lot like how religious or anti-religious people get nervous/agitated if one is to call into question the truth of scripture) to discussing such matters in the context of concrete reality makes me more than a little suspicious. I think you are right, but I am not sure what the underlying problem is. I wonder whether there is a bit of cowardice there and a fear of where the line of thought will lead - not wanting to turn the stone over for fear of what you will find. Our scientific culture is afraid of facing facts. reply divinie 19 hours agorootparentprev> a lot like how religious or anti-religious people get nervous/agitated if one is to call into question the truth. You're recognizing the same bias. It's not that there are oversights so much as there are widespread ideas believed to be definitive. Rather than teaching people the \"right ideas,\" at this point I feel it's critical that people learn how cognitive biases work, namely, authority bias. On the matter of beliefs, Crony Beliefs is a gem https://meltingasphalt.com/crony-beliefs/ reply graemep 18 hours agorootparentI agree it is a problem, but I do not think teaching people about cognitive biases will solve it. It is very hard to apply it to yourself, and any kind of critical thinking is hard. A lot of people will not even make the effort. The motivation comes from existing values and beliefs, which will have been subject to biases themselves! reply divinie 11 hours agorootparentNot claiming this is ethical, but the biases can be used on the person to generate the motivation and emotional response to recognize that they don’t want to suffer from exploitation of the biases As for the reason it would help the issue, if the person is not susceptible to these, they will not be susceptible to the industries, governments, teachers that exploit these. They’ll recognize it before falling for it. As for the difficulty level, it could be made simple. They aren’t complex, they are just unknown reply FrustratedMonky 18 hours agoparentprevYes. With all of these examples. The trick seems to be in 'how'. Everyone can read this article, or a Buddhist text, or some Stoic essays, and agree and think it would be a good idea. The 'how' to get there, seems to be the gap. Everyone agrees having 'purpose' is great. The 'how to find a purpose' is the problem. Not just intellectually 'decide on a purpose', but 'believe in a purpose'. reply hosh 16 hours agorootparentThere is no procedural method or recipe in which would lead to someone finding their purpose like that. This purpose isn't a purely objective and externalized thing. To do otherwise, it would be no different than partaking in one of those FB quizzes that would, based upon some input, spit out which Harry Potter House you belong to, or what kind of D&D class you have. You have to take the time to allow yourself to be aware of what's going on within yourself, and what's going on in the community around you. This \"awareness\" isn't the same as collecting data, or constructing thoughts that interpret things. It's not an easy thing to convey, since many people will take what I'm saying here and turn it into yet another recipe. And if I then say, it's more like mindfulness meditation, then all sorts of ideas and interpretation gets added to that, making it far away from I'm saying here. I'm not very articulate about this. But maybe Carol Sanford's _Regenerative Life_ would better able to convey just how to find your unique contribution to that which is greater than yourself. reply divinie 10 hours agorootparentprevFor years I denied all self-help books for missing the \"how\" part of the equation, this is now my main focus. All things considered, even if you have the intentions, the goals, the how to, I feel that most people do not have the consistency of themselves or a clear enough mind free from changing moods to pursue a purpose. [Another major part is not knowing how to listen to or access the Intuition regularly]. For me something like looking at life from a constant meditation on your future self [Alex Harmozi] or Gurdjieff's Self-Remembering or Vigyan Bhairav Tantra: Meditation Technique No. 33 allows this kind of consistent clarity. reply chasd00 13 hours agorootparentprev> The 'how to find a purpose' is the problem. zen would say the harder you try the further away you'll be. You do have a purpose only as much as you don't. ...\"sense\" isn't the right word but it makes sense to me, it's more like just something you realize. reply jmbwell 16 hours agoparentprevSure, but it's not like humans in all parts of the world haven't been proposing models for understanding happiness in some form or another since before the written word. If it were possible to compare every model for happiness ever conceived, they'll likely have a few things in common. Mostly, they will propose factors that are familiar within a group's common frame of reference, those factors will address that group's common experiences and habits, and the formula will project a roadmap for making changes in those habits to realign the experiences with \"happiness.\" In other words, \"we all tend to do one thing, but doing another is probably better, and it's easy to forget, so here's way to remember.\" If it's useful to anyone at all, it's of value. If it's useful to larger group, then a utilitarian might say it has greater value. But even the assessment of value is culturally-dependent, so it's kind of pointless to argue about the virtues of different models on the basis of their cultures of origin. So of course different cultures present things differently. It doesn't have to mean anyone is losing the roots of their own culture. Foucault would argue that being anything other than a part of your own culture is impossible. Even if you reject your own culture, you're rejecting the culture you're a part of, and that becomes a part of that culture. You just can't _not_ be who you are, where you are, and a product of your experiences. If the differences in habits among various cultures become more apparent in a direct comparison, that's mostly down to the different frames of reference that determine the signs and signifiers used to express and internalize the models. But within each culture, the mechanisms themselves are often fundamentally the same. We manage resources as a group, we figure out who's us and who's them, we defend the group against threats, and we generally aim to reproduce. Whatever else goes on, our culture is how we communicate among ourselves what to expect from each other as we all go about those activities. It gives us the language we use, which Pinkerton et al might go so far as to say shapes the very ideas we have about ourselves and each other, including our \"secrets to happiness.\" The point is, there are many models for understanding happiness. Some we know more about because they've established a large socio-economic footprint, like the major religions, and some are more academic thought experiments, like what the ancient greeks tended to get up to. Others are more directly products of and by their host culture. Ikigai is this. If people find it accessible and useful, that's nothing but great. Is it a very Japanese way of looking at it? Sure. Is it some innate universal truth and wisdom? I dunno, but I bet someone pushing that narrative has a book or a seminar to sell. In any case, for most purposes, the meme is probably enough. Do what you can to do what you love, that you're good at, that helps you survive, that helps your group survive. In \"westerner\" kindergarten, they simplify it even further: do only what is necessary, helpful, and/or kind. Don't even need a graduate philosophy degree for that. reply autumnstwilight 6 hours agoprevWhile I'm not a native Japanese speaker, I've lived here for a decade and communicate in Japanese 98% of the time at work. \"Ikigai\" is just a combination of \"ikiru\" (live) and \"kai\" (worth doing). The existence of such a word does not imply any more of a coherent or commonly followed philosophy than the existence of the English phrase \"purpose in life\" or the loanword \"raison d’être\" does. Pretty much everything I've seen about the \"unique Japanese concept of ikigai\" appears to be almost entirely made up by non-Japanese people. Not that it's necessarily a bad or useless concept, but claiming this particular formulation of it is ancient Japanese wisdom appears to be a marketing effort. reply raskelll 3 hours agoparentI would posit that the ability to distil complex concepts into concise phrases is prevalent across various cultures and languages. Isn't it true for our Western idioms, like the popular 'YOLO' or 'Carpe Diem' (or even the very French 'raison d'être' itself)? These terms, mostly void of any formal philosophical roots, are ways of defining and affirming the value of life within our linguistic and cultural contexts. Who's to say that future generations, whether foreign or native, won't feel a sense of novelty or exoticism in analysing these phrases of old, much like the discussion surrounding 'ikigai' today? reply rramadass 5 hours agoparentprevQuite right. I have a longstanding interest in Japanese Budo and hence count myself as somewhat knowledgeable on certain ancient aspects of that culture. There is always a tendency by westerners to read/invent more than what is in the culture itself. And then the charlatans/hucksters/shysters (both japanese and non-japanese) get on the act and ruin everything. This \"Ikigai\" hype reminds me of the earlier hype about \"Naikan Therapy\", \"Morita Therapy\" etc. reply koliber 20 hours agoprevI have not understood the need of a purpose in life until I found myself in situations where direction evaporated. It is discomforting, surprising, and enlightening. This happened a few times, and I learned something new each time. It's a journey of self-discovery. Thinking of it both in grandiose terms as well as in the little habits was helpful. It's also helpful to see what others do in such situations. Some common situations where the purpose in life changes: - retirement - kids moving out of the house - hitting a grand goal (i.e. buying a house, trip of a lifetime) - financial sufficiency or independence - finishing college Ikigai is a neat lens for exploring this part of self. reply ivankuz 1 hour agoparentWhile not exhausting nor practical in its absolute, I frequently return to a phrase from The Brothers Karamazov by Dostoevsky: > You need to love the life more than its meaning. Purpose in life is important, but for a healthy mind being lost is fine. It's \"the next step\", something you will inevitably face again. reply lucidrains 13 hours agoparentprev\"There are only two tragedies in life: one is not getting what one wants, and the other is getting it.\" - Oscar Wilde reply beryilma 9 hours agorootparentThere are three. The third one being \"one not knowing what one wants\". reply divinie 10 hours agorootparentprevOsho [or Watts?] once noted that men die at 50 from heart attacks because they get all the things society asked them to get, the external pressure of society is no longer pushing them, and they are no longer running from themselves, iirc. reply chasd00 13 hours agoparentprev> - kids moving out of the house I've been starting to think about this as i've got maybe 4-5 years left to prepare, it's not that comfortable of a thought. I read an article in the WSJ about new empty nesters and one guy described it as similar to getting fired. Like he had worked so hard for 18 years and then one day he gets \"by dad, see you at Thanksgiving\" and it was over. haha (but not really haha) reply e40 10 minutes agorootparentThese days, with a record number of post-graduates living with their part, empty nesting is probably a hope for many. For me, I want my son to be successful and happy, for any definition of the former he wishes. I would not compare it to being fired. It’s unsettling to wait while they figure out life, because you know you cannot short circuit experience by living and failing and succeeding. I never realized how hard being an empty nester would be, I just thought it would be hard for different reasons. reply oldstrangers 18 hours agoparentprev\"until I found myself in situations where direction evaporated.\" This is the important part. Most people simply work themselves to death and never find the time to ask these kinds of questions. Or, they did ask themselves these questions at one point and realized working themselves to death was a more pleasant route than struggling with such existential problems. reply natmaka 8 hours agorootparentInertia ('habits') \"at work\". reply balfirevic 13 hours agorootparentprevMost people work themselves to death? reply oldstrangers 12 hours agorootparentCorrect. reply ProllyInfamous 17 hours agoparentprev>Some common situations where the purpose in life changes: I have best heard these moments called \"now what? moments.\" reply koliber 4 hours agorootparentThat captures the essence perfectly. reply nox101 17 hours agoprevI lived in Japan for 18 years. Japan is not known for people following any of the advice in this article > Stop seeking your One True Passion 1000s of examples of Japanese people following their passion to extremes exceeding most non-Japanese expectations. A famous example would be Jiro from \"Jiro Dreams of Sushi\" Japan is a place where lots people give their lives to their company. I've met plenty of Japanese who work 10am with 90 minute commute (so 8:30am) to 10pm (and 90 mins back) 5 days a week, all year. These people have families but they readily admit they spend more time with coworkers than family and are in many ways closer to them. reply geraldhh 16 hours agoparent> These people have families but they readily admit they spend more time with coworkers than family and are in many ways closer to them. baring the closeness part, this seems rather ubiquitous reply agumonkey 20 hours agoprevWarning: depending on your life, the first reading about ikigai might make you even more depressed (cause it may reopen wounds) reply mattgreenrocks 18 hours agoprevFor most of my life I kept thinking I was looking for financial independence, knowing full well I’d continue to work if I hit it. But this posed a problem: why work hard toward that if the day-to-day wouldn’t change much? Eventually I reconciled this when I encountered Epictetus: I was actually looking for a mental freedom to find my own meaning, identity, and grow my capacity to choose the good on a daily basis. It was less about the total dollar amount and more about the perception of my own agency. In fact, I’d much rather grow the meta-skills that let me flourish in life across multiple dimensions than have a bunch of cash land on my doorstep. This is either wise or the type of thing you tell yourself when you haven't had outsized success. But, I also realize the former is 100% more resilient even if it is much harder. From here, the fog has started to lift, and I can continue the work of uncovering my resilient core of personality. reply theonething 10 hours agoparentI'd rather have a bunch of cash. Then I wouldn't need to work and could do want I want. So many things I'd rather do than work, e.g. spend more time with my family, take classes, read more, exercise more, etc. reply dhosek 16 hours agoprevThere’s a recent (2023) novel translated from Japanese for which this is a central concept in the plot (since I read it in translation, I don’t know if Ikigai is mentioned in the original). It’s entitled What You Are Looking For Is In The Library by Michiko Aoyama. http://www.amazon.com/exec/obidos/ASIN/1335005625/donhosek I first learned of it thanks to reading all the shortlist books from this year’s Tournament of Books https://www.tournamentofbooks.com reply JohnMakin 18 hours agoprevDealing with this kind of angst most of my life, I've found great value in this and similar philosophies. However, it should also be noted that Japan has one of the highest suicide rates in the world (not that far ahead of the US though). reply ed_mercer 11 hours agoparentJapan's suicide rate is significant but not among the highest in the world when compared with other countries https://worldpopulationreview.com/country-rankings/suicide-r... reply JohnMakin 9 hours agorootparent“One of the highest in the world” IS comparing it to other countries. It is in the top 20 and towards the top in the developed world. Hardly an inaccurate or false statement. reply ljoshua 20 hours agoprevThis was a nice reframing of the concept of ikigai as I've heard it, and a quick consult of Wikipedia for ikigai [0] shows that it's largely accurate. I'd also throw out there that one can derive a lot of purpose and meaning in life from religion as well. I certainly do. There are many motivating factors in life, and some core religious beliefs can do this quite effectively, in a positive manner. [0]: https://en.wikipedia.org/wiki/Ikigai reply 47282847 19 hours agoparentSpirituality != Religion reply schneebyte 14 hours agoprevI prefer \"flexible\" stoicism, like Seneca. In the scale of the universe (time and space) we are all insignificant, like tiny ants. One ant has more money than the others. Another ant is famous. Don't be afraid of death. Enjoy living in the present. Try to do good. Of course easier said than done. reply hayst4ck 10 hours agoprevI've found if you substitute the word meaning with the word feeling, almost all content about meaning makes a lot more sense. The purpose of life is to live a life full of feeling. > Many of us think that finding our passion will magically give our life a purpose. Instead, find feeling in your daily experiences and interactions. > Embrace lifelong learning. -> Conduct yourself in a way that gives you the feeling of self esteem. > beyond the point of comfort, financial success should be seen as a potential byproduct of living a life full of feeling. > Instead of pursuing a grand life purpose, optimize for wanting to wake up in the morning. Live a life of curiosity and connection. Trust that success will be a byproduct of the feeling you find in daily experiences. reply blueyes 16 hours agoprevI like the idea of finding micro-habits, activities and relationships that are fulfilling. While Ikigai may have been repurposed by the West, its new incarnation and Venn diagram seems like a pretty valuable tool for young people to navigate life, even if it's a radical semantic shift from the original Japanese. It also has the merit of trying to awaken peoples' ambition, to raise the ceiling on what they think they might achieve, and how to get there, which Anne-Marie's originalism lacks. reply knightoffaith 18 hours agoprevI don't really understand. Is the article saying that how to find meaning in life is by rejecting grand narratives and finding meaning in small things? That sounds to me like saying that how to find meaning in life is by... finding meaning in it. Don't get me wrong, it does seem correct to stop seeking your one true passion, embrace lifelong learning, letting go of lofty financial goals, and stop feeling like your only goal should be saving the world. But I'm not clear on why or how we should, in the \"ikigai worldview\", find meaning in doing these things. Really, it seems to me that the implication in the article is that the question \"how do I find meaning in life?\" is basically the wrong question to ask, that life is not the kind of thing that has meaning, and that we should instead just focus on being happy, which can be accomplished by small things. That would make sense to me. Though I prefer the western idea that there is a grand life purpose. The 4 \"ikigai principles\" are perfectly compatible with there being a grand life purpose - that there is a grand narrative in which we are partaking doesn't mean that every individual person has be some world-renowned entrepreneur or something. An analogy - a team of stonemasons working on building a cathedral may each individually be working on a small piece of the final building that, to the individual, doesn't appear very meaningful or important. But the sum total of the work of all the stonemasons culminates in something grand and beautiful. reply xyzelement 16 hours agoprevThis deeply resonates, but I am also inherently biased towards seeking meaning and long-run impact. There are various western schools of thought that add up to the same thing, eg Viktor Frankl's Man's Search for Meaning. Sometimes I see posts on HN and elsewhere that seem to be divorced from a \"meaning\"-full perspective. I don't mean someone who finds different meaning than I do, but someone who doesn't think meaning matters at all. Sometimes it comes out as \"I don't understand why anyone would have kids when it's much easier to just get brunch\" or \"I don't understand why work that impacts people is more valuable than one that doesn't\" etc. FWIW, I sometimes check those folks comment history and they don't seem to be particularly happy despite (or maybe because of) the fact that they removed all onus of meaning from themselves. reply sevagh 9 hours agoparentHere's my sticking point with this: >Sometimes it comes out as \"I don't understand why anyone would have kids when it's much easier to just get brunch\" If I have kids, I derive meaning from providing _them_ with the ability to derive pleasure from brunch. Then, they have kids and those kids go derive pleasure from their kids having brunch. It's brunch all the way down. reply ajkjk 18 hours agoprevIt is amusing that the arguments for this are like \"it reduces anxiety\" and \"it's good for your heart\". Like... yes... in that it makes you happier or more fulfilled or whatever, and therefore it has those effects? But if what draws you to a philosophy is the health benefits... you're fucked. reply tmountain 13 hours agoparentSeems like the health benefits would typically be viewed as the byproduct of the practice. I doubt many people explore philosophy directly for their health. reply ajkjk 10 hours agorootparentYeah that's my point, it's weird that those are on the article's list, and at the top of it Oo reply freemanon 17 hours agoprevLooking at the term \"Ikigai\" as if it's some sort of dogma or a way to improve one's life sorts of defeats the point. East Asian philosophies are not for achieving \"meaning of life\" and other mundane goals. reply ojo-rojo 19 hours agoprevThis kind of reminds me of something Mariko told the Anjin in the show Shōgun. He wanted to leave Japan and be free of rituals and she said something like \"If you're always chasing freedom you'll never find yourself.\" reply _tk_ 13 hours agoprevIkigai is one of these concepts, that I suspect to be mostly substituted by western life coach BS, which mostly means common sense application of modern-ish western philosophy to daily life including work. Unfortunately, when it is presented through the lens of someone who has lived in Japan for 7 months, this hardly changes my biased view. reply phkahler 19 hours agoprevThere are 4 regions in the diagram that have no labels. These are all one step away from the Ikigai. Each of these would be \"close but not quite\" for a different reason. Edit: Haha, as I read on it's not necessary to find the \"one thing\". reply irq-1 17 hours agoparenthttps://management30.com/wp-content/uploads/2020/07/IKIGAI--... They're labeled on the linked image. reply sevagh 12 hours agoprevAnybody else feel like you enjoy the feeling of \"having had done a thing\" more than doing the thing? reply aradox66 12 hours agoparentType 2 fun reply Zufriedenheit 16 hours agoprevThis reminds me of the recent movie “Perfect Days”. It’s about a japanese man who lives his ikigai cleaning Tokyo toilets. reply ChidiKajal 17 hours agoprevstill not sure what to think about the popularized ikigai venn diagram but thought this talk by Everything Everywhere All at once directors at SXSW recently covered some interesting and entertaining perspectives on the idea https://www.youtube.com/watch?v=nBANXz79fDg reply throwaway_08932 20 hours agoprev> Japanese do not need grandiose motivational frameworks to keep going, but rely more on the little rituals in their daily routines. reply photochemsyn 17 hours agoprev [–] Reminiscent of the Akira Kurosawa film 'Ikiru' (1952): https://en.wikipedia.org/wiki/Ikiru reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text explores the Japanese concept of ikigai, which focuses on finding purpose and fulfillment in life, leading to improved mental and physical well-being, resilience, and longevity.",
      "Ikigai is not solely about passion or financial success but centers around deriving joy from daily life and creating meaningful relationships with others.",
      "It offers principles for discovering one's ikigai, such as staying curious, learning from failures, and making a positive impact on a personal level, promoting happiness and meaningful connections as key priorities for overall success."
    ],
    "commentSummary": [
      "The post explores the Japanese concept of ikigai, focusing on finding purpose and fulfillment beyond career and finances, rooted in various philosophies and religions.",
      "It discusses modern challenges in seeking meaning, the influence of Christianity, the significance of community and art, and cultural variations in defining happiness.",
      "Emphasizing self-awareness, mindfulness, and balance, it questions the historical accuracy of ikigai as a distinct philosophy, promoting happiness in daily moments over a singular purpose."
    ],
    "points": 186,
    "commentCount": 73,
    "retryCount": 0,
    "time": 1711025452
  },
  {
    "id": 39777898,
    "title": "Plant-Based Polymers Biodegrade in 7 Months, Offering Eco-Friendly Solution",
    "originLink": "https://today.ucsd.edu/story/biodegradable-microplastics",
    "originBody": "Say Hello to Biodegradable Microplastics Research shows plant-based polymers can disappear within seven months Microplastics can take anywhere from 100 to 1,000 years to break down. Much is still unknown about their impacts on the environment and human health. (cr: Whitehoune/iStock) By: Michelle Franklin - m1franklin@ucsd.edu Media Contact: Michelle Franklin - m1franklin@ucsd.edu Mario Aguilera - maguilera@ucsd.edu Published Date March 21, 2024 By: Michelle Franklin - m1franklin@ucsd.edu Media Contact: Michelle Franklin - m1franklin@ucsd.edu Mario Aguilera - maguilera@ucsd.edu Share This: Article Content Microplastics are tiny, nearly indestructible fragments shed from everyday plastic products. As we learn more about microplastics, the news keeps getting worse. Already well-documented in our oceans and soil, we’re now discovering them in the unlikeliest of places: our arteries, lungs and even placentas. Microplastics can take anywhere from 100 to 1,000 years to break down and, in the meantime, our planet and bodies are becoming more polluted with these materials every day. Finding viable alternatives to traditional petroleum-based plastics and microplastics has never been more important. New research from scientists at the University of California San Diego and materials-science company Algenesis shows that their plant-based polymers biodegrade — even at the microplastic level — in under seven months. The paper, whose authors are all UC San Diego professors, alumni or former research scientists, appears in Nature Scientific Reports. “We're just starting to understand the implications of microplastics. We've only scratched the surface of knowing the environmental and health impacts,” stated Professor of Chemistry and Biochemistry Michael Burkart, one of the paper’s authors and an Algenesis co-founder. “We're trying to find replacements for materials that already exist, and make sure these replacements will biodegrade at the end of their useful life instead of collecting in the environment. That's not easy.” “When we first created these algae-based polymers about six years ago, our intention was always that it be completely biodegradable,” said another of the paper’s authors, Robert Pomeroy, who is also a professor of chemistry and biochemistry and an Algenesis co-founder. “We had plenty of data to suggest that our material was disappearing in the compost, but this is the first time we’ve measured it at the microparticle level.” Putting it to the test To test its biodegradability, the team ground their product into fine microparticles, and used three different measurement tools to confirm that, when placed in a compost, the material was being digested by microbes. The first tool was a respirometer. When the microbes break down compost material, they release carbon dioxide (CO2), which the respirometer measures. These results were compared to the breakdown of cellulose, which is considered the industry standard of 100% biodegradability. The plant-based polymer matched the cellulose at almost one hundred percent. Definitions Biodegradable: Able to be broken down (decomposed) rapidly by the action of living organisms. If something is labeled biodegradable, that doesn’t mean it will do so in a reasonable amount of time, or in all environments. Microplastics: Plastic debris measuring between 500 micrometers – 5 millimeters in length. Much is unknown about microplastics and their impacts on the environment and human health. Polymer: Large molecules made of smaller, repeating molecules called monomers. All plastics are polymers, but not all polymers are plastics. Particle counts of petroleum-based (EVA) and plant-based (TPU-FC1) microplastics show that, over time, EVAs exhibit virtually no biodegradation, while the TPUs have mostly disappeared by day 200. Next the team used water flotation. Since plastics are not water soluble and they float, they can easily be scooped off the surface of water. At intervals of 90 and 200 days, almost 100% of the petroleum-based microplastics were recovered, meaning none of it had biodegraded. On the other hand, after 90 days, only 32% of the algae-based microplastics were recovered, showing that more than two thirds of it had biodegraded. After 200 days, only 3% was recovered indicating that 97% of it had disappeared. The last measurement involved chemical analysis via gas chromatography/mass spectrometry (GCMS), which detected the presence of the monomers used to make the plastic, indicating that the polymer was being broken to its starting plant materials. Scanning-electron microscopy further showed how microorganisms colonize the biodegradable microplastics during composting. “This material is the first plastic demonstrated to not create microplastics as we use it,” said Stephen Mayfield, a paper coauthor, School of Biological Sciences professor and co-founder of Algenesis. “This is more than just a sustainable solution for the end-of-product life cycle and our crowded landfills. This is actually plastic that is not going to make us sick.” Creating an eco-friendly alternative to petroleum-based plastics is only one part of the long road to viability. The ongoing challenge is to be able to use the new material on pre-existing manufacturing equipment that was originally built for traditional plastic, and here Algenesis is making progress. They have partnered with several companies to make products that use the plant-based polymers developed at UC San Diego, including Trelleborg for use in coated fabrics and RhinoShield for use in the production of cell phone cases. “When we started this work, we were told it was impossible,” stated Burkart. “Now we see a different reality. There's a lot of work to be done, but we want to give people hope. It is possible.” Full list of authors: Robert S. Pomeroy, Michael D. Burkart, Steven P. Mayfield (all UC San Diego), Marco N. Allemann, Marissa Tessman, Jaysen Reindel, Gordon B. Scofield, Payton Evans, Ryan Simkovsky (all Algenesis). This research was supported by funding from the Department of Energy (DE-SC0019986 and DE-EE0009295). Disclosure: Burkart, Mayfield and Pomeroy are co-founders of and hold equity positions in Algenesis Corporation. Share This: You May Also Like San Diego Supercomputer Center Interns Create App for UC San Diego’s Stuart Collection The Arts Say Hello to Biodegradable Microplastics Science & Environment Focus on South Asia Giving UC San Diego Professor Awarded Signal Processing Society’s Highest Honor Technology & Engineering Say Hello to Biodegradable Microplastics Science & Environment Focus on South Asia Giving UC San Diego Professor Awarded Signal Processing Society’s Highest Honor Technology & Engineering San Diego Supercomputer Center Interns Create App for UC San Diego’s Stuart Collection The Arts Stay in the Know Keep up with all the latest from UC San Diego. Subscribe to the newsletter today. Email Please provide a valid email address. Subscribe Subscription Notification Close Confirmation Thank you! You have been successfully subscribed to the UC San Diego Today Newsletter.",
    "commentLink": "https://news.ycombinator.com/item?id=39777898",
    "commentBody": "Research shows plant-based polymers can disappear within seven months (ucsd.edu)180 points by geox 21 hours agohidepastfavorite104 comments culi 16 hours agoJust so anyone doesn't get the wrong idea, this is about a specific algae-based polymer being developed by UCSD. > Microplastics can take anywhere from 100 to 1,000 years to break down and, in the meantime, our planet and bodies are becoming more polluted with these materials every day In general \"biodegradable plastics\" currently on the market should still be heavily scrutinized. So far it mostly has just meant it gets to the microplastics stage faster than other plastics. Not only does this have negative health consequences for us and fish, but it also makes it much more difficult to ever recycle and re-use these plastics https://www.biopak.com/au/resources/biodegradable-plastic-pr... Still, it's exciting to see progress on the possibility of an actually sustainable version of biodegradable plastic. Hopefully it can scale and doesn't lead to other micro pollutants reply kleton 10 hours agoparentPLA etc are just fine, they might not biodegrade quickly outside of a compost pile, but they are not making indefinitely persistent microplastics. Indeed, medical implants made of PLA are reabsorbed in mammals. The same cannot be said of PETE fibers accumulating in various tissues. reply Kerb_ 6 hours agorootparentJust a note, PLA is industrially compostable, but it won't biodegrade quickly if at all in your backyard compost pile reply Brian_K_White 3 hours agorootparentIt will biodegrade just laying around anywhere, with not even a backyard composter, 1000x sooner than all the normal plastics. Some other things can even go faster and easier, but you can use pla without feeling guilty of anything. It doesn't do the world any good to make anyone wary of such a huge improvement. reply colechristensen 15 hours agoparentprev>Not only does this have negative health consequences for us and fish, but it also makes it much more difficult to ever recycle and re-use these plastics Are there any actual concerns with pure PLA? reply WhatIsDukkha 15 hours agorootparent\"Environments without the necessary conditions will see very slow decomposition akin to that of non-bioplastics, not fully decomposing for hundreds or thousands of years.[59]\" https://en.wikipedia.org/wiki/Polylactic_acid#Degradation No mention of its actual life cycle as it turns into a microplastic ie so it should be presumed dangerous in the same ways. reply zik 10 hours agorootparentprevPLA pretty much just breaks down into microplastics unless it's decomposed in an industrial composting facility. reply mypalmike 14 hours agorootparentprevI suspect they are referring specifically to PLA. reply huytersd 13 hours agoparentprevWhen they say break down they just mean even more micro than microplastics right? It’s not truly breaking down right? reply sfink 12 hours agorootparentNope, truly breaking down and digested by bacteria. > The last measurement involved chemical analysis via gas chromatography/mass spectrometry (GCMS), which detected the presence of the monomers used to make the plastic, indicating that the polymer was being broken to its starting plant materials. Scanning-electron microscopy further showed how microorganisms colonize the biodegradable microplastics during composting. reply huytersd 12 hours agorootparentNo I mean regular plastics. They’re not truly going to get broken down in a 100 years, they’re just going to be really tiny. reply numpad0 9 hours agorootparentIf you like set it on fire it decomposes into gas to the point they're not the same compound, they don't come back down into micro-particle slug of same thing like gaseous gold would, and there is always that bacteria known to scientists that can break down certain kind of plastics in that manner for almost all common plastics reply philipkglass 10 hours agorootparentprevRegular plastics are truly broken down over the long term by environmental bacteria. \"Degradation and metabolism of synthetic plastics and associated products by Pseudomonas sp.: capabilities and challenges\" https://enviromicro-journals.onlinelibrary.wiley.com/doi/pdf... Long-term exposure to sunlight and physical abrasion contributes to the formation of microplastics ( These effects consist of oxidative stress, DNA damage, organ dysfunction, metabolic disorder, immune response, neurotoxicity, as well as reproductive and developmental toxicity. In addition, the epidemiological evidence suggests that a variety of chronic diseases may be related to microplastics exposure. https://pubs.acs.org/doi/10.1021/envhealth.3c00052 reply prmph 18 hours agorootparentprevhttps://www.theguardian.com/environment/2024/mar/06/microsco... reply tiagod 18 hours agorootparentprevI can think of a few confounding factors for that... reply pinkmuffinere 12 hours agoprevAs far as I can tell, the company with the IP is making individual consumer products, like shoes and surfboard parts [1]. I wish I could buy the material, to make my own biodegradable parts. It would also be nice to see packaging materials in their lineup [1] https://www.algenesismaterials.com/algenesis-products reply Havoc 16 hours agoprevI suspect the sweet spot actually lies a bit higher than 7 months. You don't want stuff disintegrating while in use. ...call it 5 or 10 years. But anything that gets us away from the functionally \"forever\" of current plastics would be a win reply jtsiskin 11 hours agoparent7 months in industrial compost, not 7 months in use! Hopefully under 'normal conditions' it does already last 5 or 10 years... reply H8crilA 12 hours agoprevI think that we've know that for a very, very long time: cellulose, i.e. wood or paper, is an example. reply 1letterunixname 8 hours agoprevOh boy, not this trope again. The so-called \"biodegradable\" plastics that weren't (Fuck the plastics industry and their greenwashing). I'm suspicious every time this is raised because mostly the starch-based single use items have been shown to degrade in a reasonable timeframe. reply thrawn0r 19 hours agoprevit doesnt seem like `the market` will fix this abhorrent use of plastic for packaging and other fast moving consumer goods. This is where states have to interfere and ban plastic usage. How can it be allowed to package 80g of food (like ham, cheese etc.) that has a shelf-life of max. 14 days in 10g+ of plastic that will be around for hundreds of years? If you go to any super market there is no consumer choice but to buy most of your food wrapped in plastic, amounting to kilos of plastic per family and month :( reply BenFranklin100 19 hours agoparentThis seems like an appropriate place for the government to step in and price negative externalities in the form of taxes. Taxes are effective as bans but they better handle edge cases where plastic may still be required for whatever reason. reply sph 19 hours agorootparentWhere do you account for lobbying from the oil industry and corruption? reply sph 19 hours agoparentprevIn a perfect world where governments are competent, I would love a law stating that packaging must not last more than 10x times the shelf life of the product itself. Ham expires after 3 days? Put it in packaging that lasts no more than 30 days when left outside. reply zik 10 hours agorootparent\"Last no more than 30 days\" with currently available degradable plastics just means it breaks down into microplastics really quickly and pollutes the environment with them. reply peteradio 19 hours agorootparentprevSomething that only lasts 30 days is going to partially start breaking down on day 1, I don't think people want that touching their meat. reply sph 19 hours agorootparentJust brainstorming here: anything temperature-based? Starts degrading above 10C for example. In your fridge it's no problem, chuck it out of the window like a savage and it will eventually degrade, unless you live on the poles. Sounds like a good avenue for (organic) material science research. reply bluGill 19 hours agorootparentDoes something like that exist? Can something like that exist? don't forget it needs to be food safe - including whatever it breaks down to, and whatever bacteria might grow on it - so long as the food itself is safe to eat. Materials science has come a long way, but some problems still are not solved and it isn't always clear if the problem can be solved. reply BurningFrog 18 hours agorootparentWater ice fits the description, but it's hard to see how that would be practical. reply sph 18 hours agorootparentWe need Ice 9: https://en.m.wikipedia.org/wiki/Ice-nine reply Projectiboga 18 hours agorootparentprevOk 100, or 500, both way below the hundreds of years they now last. reply verisimi 18 hours agorootparentYou know, this is simply not true. I have found old buried plastic bags, from supermarkets - I remember the bag style from just a few years ago. The bags had severely degraded. When I tried to pick one up, it fell apart into small pieces, what integrity it had was gone. I've had the same experience with bags left in lofts - they degrade. From my personal experience, I therefore assume that plastics already disintegrate after about 10 years, not 100 or 500 years, as you state. reply hombre_fatal 17 hours agorootparentYou're just talking about a bag degrading into smaller and smaller plastic particles (microplastics) while the people above are talking about biodegrading into natural elements. reply verisimi 17 hours agorootparentYou think I'm unfair in comparing a plastic bag to plastic packaging? If you follow this particular thread, they were talking about packaging. reply littlestymaar 11 hours agorootparentNo, you're just confusing macroscopic level of degradation (the whole structure degrades) and microscopic degradation (molecules are being degraded). The problem with plastic is that while the macroscopic structure can be altered in just a few years (depending on the conditions), the resulting parts aren't being metabolized away by micro-organisms and they remain as small plastic chunks, and then micro-plastic, then nano plastic, until they eventually break down entirely after decades, which is very unlike what happens with what we call biodegradable materials. reply verisimi 10 hours agorootparentSo, in your view, although the bag I see is breaking up into small brittle pieces, there are even smaller pieces that are not been degraded? Is that a theory to you, or do you have first hand knowledge? If I have understood your position correctly, this is certainly counterintuitive... because if there is not much plastic bag left, you'd think that whatever broke down the bag, would also be able to break down these smaller bits (microplastics). But you are saying that small bits of the bag remain for decades, even though I can't see them.. I just don't see why small bits of plastic bag would remain, when it is evident that something in the ground already degraded the plastic bag as a whole. reply littlestymaar 3 hours agorootparent> So, in your view, although the bag I see is breaking up into small brittle pieces, there are even smaller pieces that are not been degraded? They are being degraded, just slowly. > Is that a theory to you, or do you have first hand knowledge? It's not a theory of mine, you can find the explanation in practically any explanation of what \"microplastics\" are. > If I have understood your position correctly, this is certainly counterintuitive... because if there is not much plastic bag left, you'd think that whatever broke down the bag, would also be able to break down these smaller bits (microplastics) That's correct, and it eventually happens, the process is just very slow, let me try explaining it to you: Plastics are made of very long polymer chains, composed of the same small molecule (monomer) chained together millions of times. Let's assume we have a plastic for which half[1] of the connections break down in 50 years. If I'm not messing the math up, it means that every year you lose roughly 1% of the connections between the molecule. So, after one year, your chain of 1 million molecules have been cut in 10,000 smaller piece of 100 monomers. Then the next year, there's again 10,000 connections that will break (~1% of the remaining 990,000 connections), but this time it will just double the number of pieces (if you cut a piece 10 times, you and up with 11 pieces, if you have again 10 scissor hits on the next 11 pieces, you'll end up with 21 pieces). Of course my model is not entirely accurate because I looked only at the 1D molecular structure, when plastics are actually 3D meshes of these chains, so multiple chains are holding one another and it slows down the macroscopic effect, but you should get the idea of why it first degrades relatively quickly at macro scale and then slower at smaller scale. [1] half times are a good way to model degradations of chemical compounds, at least the “spontaneous” ones, but keep in mind it's a model: it's not flawless and it's not able to describe every degradation phenomenon (for instance it fails to describe degradation from microorganisms that can grow on a substrate they are degrading hence the “spontaneous” qualifier above). reply verisimi 2 hours agorootparentThank you for taking the time to explain. I get how these connections are meant to break down, though not to the detail you provided. It could be like you say, though I don't why the degradation wouldn't be concurrent - ie I don't get why half times are a good way to model plastic degradation, when all of the plastic is exposed to 'scissor hits' all of the times. Ie, once the scissor hits start to impact the bag, I would think the bag would soon fully disintegrate. Assuming it is like you say, if a plastic bag is brittle, going to dust after just 10 years after being in the ground, (I'm using supermarket bag design as a means to figure out the age of the bag,) that is far from 50 years to break down half the connections. This is too say the metric to measure degradation seems wrong to me... Or perhaps the metric is the case in artificial, sterile conditions, which the ground is not. reply littlestymaar 2 hours agorootparent> ie I don't get why half times are a good way to model plastic degradation, when all of the plastic is exposed to 'scissor hits' all of the times. They are all exposed to scissor hits all the time, but it's a stochastic scissor. You can think of every connection rolling many dices every second, and whenever they all land on 1 the molecule breaks. This kind of behavior leads to exponential decay, which is subject to half life. > Assuming it is like you say, if a plastic bag is brittle, going to dust after just 10 years after being in the ground, (I'm using supermarket bag design as a means to figure out the age of the bag,) that is far from 50 years to break down half the connections. Why? You don't need to break all connections to break to dust. They are trillions of connections to break if you want to degrade the compound to its primitive molecule, but only thousands if you want to shred it to pieces. Keep in mind that if the monomer measures 1nm, a piece of plastic of 10um still has 10,000 connections. And if at the beginning you have a piece of plastic that's 10cm long (all reasoning are 1D here for simplicity), you just need to cut it 1000 times to get to 10um (so at 10um you're still much closer to the beginning than to the end, even though the plastic is now invisible). > Or perhaps the metric is the case in artificial, sterile conditions, which the ground is not. As I said before, it's a model and you're right it's not entirely accurate. Yet plastic doesn't have much enemies living in the ground, so it's pretty close to being sterile from the perspective of the plastic. And that's actually the problem we're facing right now. reply verisimi 1 hour agorootparentI still don't see why microbes or UV light or salt work in this linear process, where half lives come into play. > Yet plastic doesn't have much enemies living in the ground But this is the very point I'm making in my first post in this thread - that I found a fairly recent plastic bag (~10 years old) that was badly degraded. Perhaps there aren't adverse conditions in the lab. Or perhaps the measurements are wrong? Perhaps these micro plastics are too small to see... But the info we are given should correlate with one's personal verification, I hope you agree. reply logtempo 19 hours agorootparentprevAdjust the variable in consequence, we're talking about a fictional material. You're using a strawman there, just to be in contradiction. reply randomdata 17 hours agorootparentprev> In a perfect world where governments are competent Yet the general consensus seems to be that in a perfect world governments are democratic, and therefore beholden to the will of the people, not authoritarian like you suggest. But if the will of the people wants to see a change in the use of plastic, they don't need it to flow through government, they can simply change their buying habits. reply AstralStorm 17 hours agorootparentYou cannot buy something that doesn't exist or is otherwise unavailable. And good packaging materials rarely make for good marketing. reply randomdata 17 hours agorootparent> You cannot buy something that doesn't exist or is otherwise unavailable. Of course you can. Facilitating such a thing is Kickstarter's entire business model, as an example. You can also refrain from buying, communicating to other people that \"I'm not buying your product unless you...\" which gives really strong incentive to do things differently. It's not like government is some kind of magical thing. It's just people. And in the case of democratic government, it's the very same people. reply littlestymaar 13 hours agorootparent> You can also refrain from buying Day 56 after I refrained from buying food: I'm now dead. reply randomdata 13 hours agorootparentIf only the people had chosen to enact a law that made it illegal to sell you food packaged in harmful packaging that you had already decided not to buy. I mean, you'd still be dead, but you'd have 56 days of satisfaction knowing that your voice was heard. reply comicjk 14 hours agorootparentprevWe're talking about negative externalities, of which pollution is a perfect example: the effects of pollution are spread across everyone, no matter who emits it, so no one has an individual incentive to change their buying habits. It's a coordination problem, which can be solved democratically by the voters demanding an overall change in incentives (such as an appropriate tax on single-use non-biodegradable plastics). reply randomdata 14 hours agorootparent> We're talking about negative externalities No. Not sure why would you would choose to reply before reading the comments, but since you have... we are quite explicitly talking about at least one consumer expecting food packaging to degrade within a similar period as the food contained within, with a suggestion that an authoritarian government in a perfect world would recognize that as a good idea and force it upon the people. But the general consensus seems to be that, in a perfect world, governments are democratic – a notion you do not seem to discount. Under a democracy, if he stands alone in that desire of short-life packaging, nothing is going to change. No business is going to cater to his unique want (well, maybe if he's exceedingly rich and is willing to pay disproportionally for it) and government is not going to act on the wishes of one person (that would be undemocratic). If a majority of people share in that desire, though, then businesses would face pressure to provide when consumers make that choice clear. Any business that fails to comply will suffer the consequences of lost profits. The people can enact a law that prevents themselves from buying the product they already don't want to buy, but that doesn't accomplish anything. They've already decided they don't want to buy it! Democratic government is useful for cleaning up minority groups who try to act against the wishes of the majority, but in this particular case you have not even made clear why the minority would be stuck on buying 'forever' packaging or what businesses would gain from catering to the minority. People don't care about food packaging that much. Once the majority are buying short-life packaging, the small number of people who want to watch the world burn will be priced out of the market anyway. As such, there is no need for government. The people can just do it... ...and if they don't, that's the end of it. Magic isn't going to swoop in and save the day. The democratic government is nothing other than the very same people who have already decided that, in this scenario, they don't want to do anything. But maybe what you're really struggling to say is that democracy wouldn't be found in a perfect world? Fair enough, but I'm still not sure that's the general consensus. reply littlestymaar 13 hours agorootparentprev> they can simply change their buying habits. Sure. And where am I supposed to find affordable food not wrapped in plastic? Ideally in my city and not 100kms away, and not 10 times the price. And now that you're at it, please tell me where I can buy food that is not already polluted by microplastics? This kind of argument is a just a “blaming the victim” kind of reasoning. reply randomdata 12 hours agorootparent> And where am I supposed to find affordable food not wrapped in plastic? The same place you expect to find it when you outlaw food wrapped in plastic. It's not going to disappear until people stop buying it. You can create a law to remind you to not buy food wrapped in plastic, or you can just not buy food wrapped in plastic. So long as the population is on board with the idea of not buying food wrapped in plastic, there is absolutely no difference. If you are suggesting that the population isn't on board and everyone other than you is quite happy to keep buying food wrapped in plastic then a democratic government would never create such a law in the first place, rendering the entire discussion moot. That would not be in alignment with the will of the people. Democracy does not serve individual whims. reply littlestymaar 12 hours agorootparent> The same place you expect to find it when you outlaw food wrapped in plastic. It's not going to disappear until people stop buying it. People aren't going to stop buying it as long as it's the only option! > You can create a law to remind you to not buy food wrapped in plastic, It's not about reminding you not to buy, it's about banning people from selling. You know, as they already do for dangerous stuff like Kinder Suprise in the US… > or you can just not buy food wrapped in plastic. You cannot because nobody is selling it. > If you're suggesting that the population isn't on board, then a democratic government would never create such a law in the first place. It would not be the will of the people. The population is on board, but population-wide synchronization don't happen for free you know. Here's a fun example: here in Europe the majority of people is against daylight saving time. Yet there is one. That's stupid you'd say, because they could actually collectively decide not to change their clocks' time and call it a day, DST is gone. But in fact, doing so would require an enormous amount of coordination, and this kind of amount of coordination is the exact reason why we've created the State in the first place! And it's actually its only power! (armed force: literally started as just a well synchronized militia, same for law enforcement, collecting taxes: just make sure to get a big enough group to raid the house of the people who refuse to pay, etc.) reply randomdata 12 hours agorootparent> People aren't going to stop buying it as long as it's the only option! Then that's it. Game over. Until buyers stop buying what's already out there, vendors don't have an avenue to sell any kind of replacement. Fortunately, your view is quite disconnected from reality. In the real world people talk, negotiate, and work to satisfy the buyer's wants and needs. > It's not about reminding you not to buy, it's about banning people from selling. You know, as they already do for dangerous stuff like Kinder Suprise in the US… Not to mention illicit drugs. They, of course, straight up vanished from the US as soon as it became illegal to sell them. Oh wait. Let's be real: If someone is buying, there will be someone ready to sell. The law ultimately has to compel the buyer to back away. You can say the onus is on the seller, but you're just looking at the opposite side of the same coin. > Yet there is one. Meaning that if I decide to keep my clocks on a constant schedule it's straight to jail for me? If not, how does that relate to a law that would penalize you if you sell (or buy) plastic-wrapped food? In this part of the world, at least, if you want to ignore DST, go nuts. DST only exists because the people just do it, not because there is some legal threat that keeps them on the straight and narrow. > and this kind of amount of coordination is the exact reason why we've created the State in the first place! If the state is democratic, the people have to coordinate first. Without such coordination, there is no way for democracy to take place. Once the people have coordinated their will, they can just do it. Like you point out with DST – at least to the extent of its existence in my part of the world – you don't need a law to force people to do what they've already decided to do. They can just do it. Simple as that. Such laws are useful for keeping the minority dissenters in line with the will of the majority, but in this case once the majority has stopped buying plastic-wrapped food, it is highly unlikely there will be a compelling business case to serve the small handful of people who want to see the world burn. I mean, even if you don't give a rat's ass about the environment, are you really going to go well out of your way to buy plastic-wrapped food? Not likely. You're just going to buy the food the same way everyone else is. It will be cheaper and much, much, much more convenient. The previous commenter's idea of an authoritative higher power forcing the people to bend to his will is great and all, but doesn't work with democracy. If a perfect world sees that government be a democracy, as the prevailing consensus seems to indicate, then that idea is out the window in said perfect world. reply littlestymaar 11 hours agorootparent> Then that's it. Game over. Until buyers stop buying what's already out there, vendors don't have an avenue to sell anything else. That's pretty fascinating to see that you're reading literally everything backward, like not only the real world around you but even what I'm writing! I'm talking about the fact that nobody is offering the possibility to buy stuff that's not wrapped (and for legit business reasons, it's much easier on their supply-chain management to do so this way), and you're interpreting as if the problem was on the demand side. And everything is in the same vein: I'm talking about a situation where the supply side is definitely not providing what the consumer want, at least a significant fraction of the population, and you insist in arguing as if plastic packaging was driven by consumer demand: it is not it's cost saving and supply chain ease of use on the supply side, not demand. And that's why you can't find any: why would a business bother doing what the customer want when they can get away with costs savings because customers have nowhere to go. > Meaning that if I decide to keep my clocks on a constant schedule, it's straight to jail for me? Chances are that you'll straight up lose your job after a couple days. Then you'll see how your freedom not to change your clock time is respected when you're being evicted because you could not pay your rents due to lack of revenue. By the way that's a good illustration of the difference between freedom in a vacuum, and the actual exercise of freedom in a socially interconnected world where your agency is in fact very constrained by material factors. > If the state is democratic, the people have to coordinate first. Without such coordination, there is no way for democracy to take place. Fascinatingly steady with backward-driven thinking indeed! You can't have democracy if you don't have a state entity that's able to run the elections and enforce them. The democratic character of the state comes later, once the people already in charge have been confirmed through the election, or when they decided to step down if they lose. Coordination comes from the state, which can then replicate itself thanks to this coordination. No state started with an election, at the very beginning was always somebody getting power through other means (be it a foreign invader, a previously ruling king, or a group of insurrectionist). > Laws are useful for keeping the minority dissenters in line with the will of the majority, but in this case once the majority has stopped buying plastic-wrapped food, it is highly unlikely there will be a compelling business case to serve the small handful of people who want to see the world burn. But without enforcement, nobody will ever be able to buy such food, because nobody has an incentive to sell it in the first place. It's cheaper to sell plastic wrapped food, and because the externalities come for free, the business isn't paying the cost of their behavior. Buyers, or at least a significant fraction of it, realize the cost, but they don't have any leverage on the business because there's nowhere to go. The same way I'm not buying a smartphone that's being manufactured in my country, because there isn't any. > Laws are useful for keeping the minority dissenters in line with the will of the majority Not only. Laws are also setting the state budget, the tax levels or food and drugs safety standards, your interpretation of what law is supposed to do is indeed very limited in comparison to what it actually is in the real world. > he previous commenter's idea of a higher power forcing the people to bend to his will is great and all, but doesn't work with democracy. No, there's no non-democratic high power in charge up there, it's just a matter of democratic state intervening to fix a market imperfection (negative externalities), but in your now infamous skill to misinterpret everything, you managed somehow invented some authoritarian power in the discussion. Well done. Maybe you could try reading what other people are writing twice before commenting, or maybe three or four times, just to be sure you're not making things up in your head, because that's a recurring theme at that point. Edit: oh I found this gem in another comment of yours (https://news.ycombinator.com/item?id=39783570) Not sure why would you would choose to reply before reading the comments The irony is absolutely delicious. reply megaman821 15 hours agoparentprevI am seeing lots of problems with your argument here: * One, the amount of carbon that get wasted if that sandwich goes bad is immense compared to the small amount of carbon it takes to make the plastic. * Two, in places with decent waste management, what is wrong with the plastic sitting in a landfill. * Three, assuming you are still going to protect food items, the alternatives are all heavier materials that will increase transportation costs and pollution. reply sargun 18 hours agoparentprevI can see this playing out in one of two ways: 1. Suddenly shelf lives are massively extended. I think this would be a good thing. 2. Shelf lives are decreased to accommodate degradable packaging. Given the people who are in the food supply chain are probably going to be sourcing the same packaging from maybe 2-3 vendors, I don’t see anyone able to differentiate themselves on packaging tech. reply fy20 6 hours agorootparent> shelf lives are massively extended. I think this would be a good thing. 50 years ago many fruits and vegetables had a lot shorter shelf life, however that has been greatly extended due to selected breeding. For example tomatoes used to have a shelf life of around 3 days, but now it's 3 weeks or more. The disadvantage of this is that now there are a few varieties that dominate what you can buy in supermarkets, and they are optimized for economic features. This means other features like taste and nutrient content are a lot worse than it was 50 years ago. reply verisimi 17 hours agoparentprev> If you go to any super market there is no consumer choice but to buy most of your food wrapped in plastic, amounting to kilos of plastic per family and month This is corporations 'socialising' the expense of their decisions via writing laws. Why should they pay? reply userbinator 20 hours agoprev [–] ...enabling more planned obsolescence than ever thought possible. Why make things last when you can have them \"naturally\" self-destruct and force you to buy again, under the guise of greenwashing? reply jvanderbot 20 hours agoparentThe use of degradable polymers is for things that are single use. Plastic bags, straws, etc. nobody is trying to replace your iPad with a compostable version that disolves in humidity. It's cynical bordering on humor to look at the accumulation of forever trash in our oceans and blood and say \"well at least we can build something that may last with all this poison\". Nobody does that anyway. reply Filligree 18 hours agorootparentIt's also commonly used in 3D printing, i.e. PLA. PLA is stable enough in normal circumstances -- you need specific equipment to make it degrade -- but once broken down to microplastics it doesn't last long. Otherwise it's nearly an ideal plastic for printing; brittle, but strong and incredibly easy to print. With some additives you can get rid of the brittleness, though I'm not sure how those would degrade. I see no reason you couldn't make plastic straws from PLA. Clothing might not last as long, but plastic clothing never lasts that long in any case; I prefer cotton. reply delecti 13 hours agorootparentA lot of commercially available \"biodegradable\"/\"compostable\" plastic is already made out of PLA. reply graemep 18 hours agorootparentprev> nobody is trying to replace your iPad with a compostable version that disolves in humidity. Ssh - you will give the electronics industry ideas :) reply userbinator 20 hours agorootparentprevPlastic bags, straws, etc Those are the least likely to degrade into microplastics anyway, unlike clothing fibers and the like, and that is already assuming you believe that microplastics have any actual effects. nobody is trying to replace your iPad with a compostable version that disolves in humidity. The article talks about phone cases and clothing. reply woodruffw 19 hours agorootparentThis comment contradicts itself: if microplastics in clothing are a serious issue, then we should be looking seriously at clothes that degrade without producing microplastics. (All clothing degrades; presumably you don’t object to wool or accuse wool sweaters of planned obsolescence.) reply jeltz 19 hours agorootparentOr we can just burn the clothes. Almost no clothing in Europe, biodegradable or not, ends up in the ocean. reply woodruffw 19 hours agorootparentMy understanding is that much of the West’s second-hand and overstock clothes ends up in countries like Ghana, where it does end up in waterways[1]. This has presumably increased over time due to fast fashion, which is a large market in Europe (like in the US). [1]: https://www.theguardian.com/global-development/2023/jun/05/y... reply graemep 18 hours agorootparentFast fashion is horrible. That article really shows on aspect of it. It has turned a large chunk of a recycling process into dumping. reply piaglfgp 15 hours agorootparentprevMicroplastics are emitted from clothing and flushed into the waste water system, and from there to oceans, every time you do laundry. This is considered to be the main source of microplastic pollution, including in the EU unless they managed something revolutionary that I'm not aware of. https://www.nature.com/articles/s41598-019-43023-x reply logtempo 19 hours agorootparentprevYou really need to cite a source on this subject, measuring the industrial waste is very difficult and any articles state that \"we found this but anyway, it's difficult to track efficiently the industry wastes\". reply throwaway22032 14 hours agorootparentprevAbsolutely shit tons of fluff comes off off polyester clothes and ends up in the drain. We could probably design washing machines to filter it better, granted. reply pfdietz 17 hours agorootparentprevSo, like ... cotton? reply woodruffw 17 hours agorootparentSure. But the reality is that cotton is expensive and resource intensive compared to other materials; absent a global effort to ban plastic clothes, it seems worthwhile to make those clothes less environmentally damaging. reply IntrepidWorm 16 hours agorootparentCotton also shrinks when wet and has poor thermal properties - polymer blend fabrics perform better in the cold, and are lighter and cheaper than wool. Goretex is wonderful stuff, but its also made of '\"forever-plastics\" and is known to slowly leach into runoff. Finding a polymer that can be cleanly manufactured for a competitive price with similar properties would be wonderful, as long as theres also a method for it to degrade safely when discarded. reply bee_rider 19 hours agorootparentprevMicroplastics are accumulating at pretty high levels all over the food chain, right? The burden of proof should be on the folks who want to run the “let’s all eat this new thing in great quantities” experiment. reply jeltz 19 hours agorootparentNo the burden of proof is on people who claim this will reduce the release of microplastics. Most plastic pollution comes from a few countries in Asia and from fishing. https://ourworldindata.org/ocean-plastics What we need to do is assist these few countries with better waste management, that is what by far would have the biggest impact. Not saying we shouldn't do other things too like trying to find new materials for fishing nets or reducing fishing but plastic bags in the west is not a significant source. reply bcrosby95 18 hours agorootparentWe should also lead by example by not just exporting our plastic trash to other countries. reply bee_rider 19 hours agorootparentprevThat’s a related but different issue, we should figure out if they are safe, help other countries deal with them, and stop producing as many ourselves, at the same time. reply Zach_the_Lizard 19 hours agorootparentprevThe story of humanity can be summed up as: \"what if we changed our environment without understanding it?\" with both wonderful and wretched consequences. The same fires that poison the air we breathe also power life saving medical equipment so that we can keep breathing. Micro plastics, endocrine disrupters and more have been unleashed. I am sure their effects will prove to be less than positive on both humans and wildlife. But in trying to snuff out the next great environmental crisis, will we account for the benefits we've derived from the use of these materials when we do our cost-benefit analysis? The effects on innovation? Did curiosity kill the cat, but save cats? reply bee_rider 18 hours agorootparentWe have think of it differently now, stuff like lead and asbestos were bad, but localized mostly. We’re running the microplastic experiment on everybody simultaneously. reply techdmn 20 hours agorootparentprevThe phone cases made by RhinoShield are the aftermarket kind that fit over the phone, not the integrated case. reply BurningFrog 18 hours agorootparentprevAmerican plastic trash does not end up in the ocean. reply Projectiboga 18 hours agorootparentHave you spent time in any major American coastal city or one with an ocean bound river. There is so much plastic litter. I'm in Manhattan and I see plastic litter every day. If even some of it doesn't get swept up it's a short trip to the East River, a tidal estuary of the Atlantic Ocean. This isn't a theory these things are gathering into the oceans and in our bodies. reply bordercases 20 hours agoparentprevThe arguments against planned obsolescence are partially environmental. If planned obsolescence isn't going away, at least this aspect is improved. Consider medical disposables, or one-time packaging that still requires medium term storage survivability. reply mechanicalpulse 19 hours agoparentprev [–] I'll take environmentally responsible planned obsolescence over the current situation. Nothing lasts. Durable plastic and metal goods become damaged or worn. What then? When repair, reuse, or recycling is not socioeconomically attractive, having some sort of naturally sustainable cycle would be nice, wouldn't it? Even if I have to buy a new phone case every seven months, if it's part of a sustainable cycle that becomes quite economical due to the massive scale -- wouldn't that be better than maintaining the current production of long-lived plastics? This strikes me as an example of capitalism learning something from biology. reply kmeisthax 17 hours agorootparentThe problem with \"environmentally responsible\" planned obsolescence is that it's never environmentally responsible to throw out what would otherwise be a functional device but for the fact that it was made to break down on a specific timetable. The three Rs are \"reduce, reuse, recycle\", not \"recycle, recycle, recycle\". Making the product degrade prematurely means you can't reuse, and by proxy, having to buy a new one means you're not reducing. Degradable devices sounds like the sort of thing intended to assuage the consciences of very rich people who buy the newest iPhone every year. reply CamperBob2 18 hours agorootparentprev [–] Meanwhile, a lot of people end up buying cars sooner than they would have had to otherwise, because someone thought it was a good, environmentally-sound idea to make electrical wiring out of tasty, tasty soybeans. That's capitalism taking a lesson from nature. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Microplastics, tiny plastic fragments, can take up to 1,000 years to decompose, posing an environmental hazard.",
      "Scientists at the University of California San Diego and Algenesis have created plant-based polymers biodegrading in under seven months, offering a sustainable solution.",
      "These biodegradable microplastics, free of harmful fragments, have the potential to combat environmental pollution, with ongoing efforts to make them viable for broad manufacturing applications."
    ],
    "commentSummary": [
      "Plant-based polymers, especially algae-based ones from UCSD, can biodegrade within seven months, unlike traditional plastics, which may take hundreds to thousands of years to decompose.",
      "Debate surrounds biodegradable plastics concerning their impact on microplastic pollution and the conditions required for effective degradation.",
      "Discussions involve the roles of democratic governments, individual decisions, and businesses in combating plastic pollution, promoting sustainability, addressing the environmental consequences of plastic, planned obsolescence, and finding alternatives to tackle plastic waste accumulation."
    ],
    "points": 180,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1711025458
  },
  {
    "id": 39777528,
    "title": "Introducing QuickWP: AI-Powered WordPress Site Builder",
    "originLink": "https://themeisle.com/blog/we-are-open-sourcing-our-ai-site-builder/",
    "originBody": "A couple of weeks back, we released the prototype of QuickWP, an AI-powered WordPress site builder that uses OpenAI, an FSE theme, and WordPress Playground to generate a personalized theme for the user based on the topic and description of your website. If you haven’t checked it out yet, you can see the preview of QuickWP on Twitter (aka X). Building QuickWP has been a challenging and learning experience for us, and today, we are open-sourcing the code base for the project so you can also learn from it and maybe even build something awesome upon it. In this article, I will discuss the ideas, challenges, and things we learned by working on QuickWP. I hope this helps you if you ever face similar challenges. Check out Quick-WP, an open-source #AI-powered #WordPress site builder CLICK TO TWEET The idea While we have thought of experimenting with AI and OpenAI APIs for a while, we never planned to create an AI website builder. Previously, we tried integrating AI with the Otter Blocks plugin to generate layouts from available patterns using AI prompt, but that implementation was quite primitive. The results were very generic and did not consider user context much in the provided result. Given that patterns in Block Editor are easy to break even with minor changes, we could not simply ask GPT to create patterns on the fly or even ask it to replace content. It all changed when we thought of this idea based on wireframes. It is simple: we create an FSE theme with wireframes and extensive color palettes. And then, with AI, we pick the patterns based on user prompts. In FSE themes, using the theme.json file properties, we can easily modify the styling of the entire website from one place. And the same is applied to our patterns so that we have uniformity across the website without worrying about different patterns having different settings that need to be modified separately. Here, we also use a CC0 image directory to populate the website with images to give a better starting point to the user. While the idea sounds simple enough, it required some trials and errors for us to reach the point where it could generate results that were good enough for the user. The goal was to spend as little time as possible to create a prototype that users can use as a SaSS from the product website. Overview of project stack The project required more than one part, so we used a number of stacks, i.e., whatever made it easier for us to prototype as quickly as possible. Here are the various parts of the project: FSE Theme: The base of the project. It includes various patterns and a comprehensive theme.json file. Base Plugin: This plugin has all the functionality and UI required to make the project work. API Endpoint: An API endpoint communicating between the user website and OpenAI API. Here is a simplified diagram to show the entire workflow. FSE theme The FSE theme works as the base of the entire project. To make prototyping easier, we started with a fork of the Twenty Twenty-Four theme. We pretty much removed all the patterns and customized the theme.json properties as per our needs. FSE theme best practices are changing very quickly, and with each version of WordPress, we have a new way of doing things. Starting with the fork of the default theme allows us to build upon a solid foundation with minimal work. In terms of code, most of the things are as you would expect in an FSE theme. The only difference you will notice is how we use strings and images in patterns. Here, we add default text, template-specific namespace for the strings, and a default preview namespace to each string. The default text is the text that will appear in the patterns when used normally, in case someone is adding a pattern inside the editor or using the theme without QuickWP AI. The template-specific namespace is an identifier for that particular string. And the default preview namespace is a shared namespace that we use for all the strings in context. We will come back to this later. AI prompt generation As it was a quick prototype, we wanted to explore easier testing and implementation methods. We experimented with various AI models but ended up with the most popular option, which is OpenAI. During the development phase, we used GPT-4 as the results were much better with OpenAI’s latest model offering, but it was too costly, so we decided to shift to using GPT-3.5 Turbo for most tasks. I say most of the tasks as we are still using GPT-4 for color palette generation as the color variety was not great with GPT-3.5 For making requests, we tried different options that OpenAI offers but found the Assistant API best suited for our needs. To avoid some bad-faith actors, we also used OpenAI’s Moderation API to prevent processing the requests if they do not align with OpenAI’s content policies. As we can see after the release, people have tried to experiment with all sorts of prompts that could have landed our OpenAI account in trouble, so adding the moderation was worth the time. And yes, it is free to use! Image generation When we were imagining this project, one of the issues was how to generate images. We could, of course, use Dall-E or other models to do it, but they’re slow, low-quality, and quite expensive. It turned out that we were thinking in the wrong direction. Why generate images when there are millions and millions of CC0 images available on the internet? After some consideration, we chose Pexels. The reason behind choosing Pexels was that it has more liberal request limits and a good catalog of images. And, of course, we link back to the original image on our app. How do you maintain context site-wide? The first problem we needed to solve to make this project work was to see how we could maintain context site-wide when generating content for the user. Different patterns have different numbers and types of strings, and we can’t just randomly add content there and hope it will be relevant for the website. And this is where our great friend JSON came to the rescue. With some creative prompts (found in the source code) and a consistent JSON schema, we could maintain context throughout the website and have strings that complement each other, rather than random gibberish. If you look at one of our templates, you will see how we list each pattern with a description to let the API know its purpose and what strings it contains. For example, here’s the first pattern from that template: { \"order\": 1, \"slug\": \"quickwp/hero-centered\", \"name\": \"Hero Centered\", \"description\": \"Hero sections are used to introduce the product or service. They are the first and primary section of the website. This is a centered hero section with a large title, a subtitle and two buttons.\", \"category\": \"heroes_page_titles\", \"strings\": [ { \"slug\": \"hero-centered/title\", \"description\": \"Main title of the hero section\" }, { \"slug\": \"hero-centered/subtitle\", \"description\": \"Subtitle of the hero section\" }, { \"slug\": \"hero-centered/button-primary\", \"description\": \"Primary button text of the hero section\" }, { \"slug\": \"hero-centered/button-secondary\", \"description\": \"Secondary button text of the hero section\" } ], \"images\": [ { \"slug\": \"hero-centered/image\", \"description\": \"Background image of the hero section\" } ] } Each string, along with the namespace, also describes its connection to the rest of the pattern. This allows us to make sure that GPT does not repeat the same thing in multiple places and, for example, keeps the subtitle related to the title of the pattern. When we get the request back on the site, we use the string slug to replace it in the pattern. While our current implementation is primitive, you can use this approach to give even more context to the string, such as the length and tone of the string. This way, we only exchange the data and not the markup. We need WordPress instances for each user Another problem we needed to solve was to have an instance of WordPress for each user session. In our implementation, we are making changes live on the WordPress instance of the current user and then using existing WordPress functionality to export the FSE theme. Only if there was a solution to create WordPress instances without pretty much building a small web hosting solution… Let me introduce you to WordPress Playground. Playground allows you to run WordPress in your browser with zero clicks. If you have not used the WP Playground, you will be surprised at how awesome it is! What will you be building with WordPress? Now that we have walked you through some of the challenges we faced, what will you be building with these tools? We hope the article inspired you to use some of the tools we discussed, like OpenAI API, FSE themes, and WordPress Playground, and build something awesome. If you do, let us know because we would love to try it! Once again, all the source code is available on our GitHub, so feel free to use it in any way it can help you! FREE GUIDE 4 Essential Steps to Speed Up Your WordPress Website Follow the simple steps in our 4-part mini series and reduce your loading times by 50-80%. 🚀 FREE ACCESS Was this article helpful? Yes No",
    "commentLink": "https://news.ycombinator.com/item?id=39777528",
    "commentBody": "An AI-Powered WordPress Site Builder That We Are Open-Sourcing Today (themeisle.com)173 points by selul 21 hours agohidepastfavorite65 comments nibab 17 hours agoI commend you for plugging AI into a commonly used tool in this space vs creating your own platform for building websites with AI. It's refreshing to see someone working back from a great user experience and meeting the users where they are today. This requires focus in the face of constant integration challenges and lots of design restrictions/limitations. Best of luck going forward! reply nkko 13 hours agoprevWordPress has become an unwieldy mess of plugins and licensing nightmares. Until Automattic addresses the core technical debt, WordPress will continue disappointing developers seeking a clean, modern CMS foundation. reply vouaobrasil 13 hours agoparentThat is absolutely true. But if you're just blogging and only need the base install with Classic Editor and Akisment, it's actually quite nice and still better than most other platforms for self-hosting. reply keane 9 hours agorootparentI appreciated this plugin inventory by Nick Simson: https://nicksimson.com/posts/plugin-inventory-2023/ There are some high-quality GPL-spirited plugins and themes (like those by Anders Norén https://andersnoren.se/teman/ or Oliver Juhas https://www.webmandesign.eu) amid an utter avalanche of SEO cruft so you have to know where to look. reply boznz 9 hours agoparentprevluckily there is an AI-Powered WordPress Site Builder you can use :-) reply j45 12 hours agoparentprevWordpress has been plugin integration brick wall city for a long time. reply CharlesW 10 hours agoparentprevIt's not disappointing them now. Given the continuous improvements in every release, that seems unlikely to change any time soon. https://w3techs.com/technologies/history_overview/content_ma... reply pbowyer 21 hours agoprevFor those of us who haven't recently used WordPress it would be really helpful if you define what a FSE theme is. For others, it's \"Full Site Editing\" themes, which means... I guess you can edit anything in the theme customizer? reply selul 21 hours agoparentHi there, That's a very good question. In WordPress, Full Site Editing (FSE) allows you to design your entire site—including the header, footer, and everything in between—using blocks. Blocks are the components for adding content in the new WordPress block editor, enabling you to easily incorporate text, images, videos, and more. For this new approach, your site will require a Block theme, designed specifically for compatibility with this new editor. Also, one thing to note here is that the traditional theme customizer is no longer present in this environment. Instead, FSE allows direct manipulation of site elements within the WordPress Block Editor interface. reply interestica 20 hours agoparentprevThe full site editing thing really changes the wordpress paradigm. It's a different mental model. I've had people reach out for help because it ends up being a wall for them. The communication/education aspect of it needs work. reply aussieguy1234 8 hours agoprevAs long as WordPress is around, PHP will never die. Great for me with my 15 years of PHP experience. Once upon a time, I was involved in creating the largest WordPress media platform in the world with WordPress. You can view it at news.com.au, but there are about 20 other publications hosted on the same platform. reply rodolphoarruda 21 hours agoprevSounds interesting and promising, I just hope it doesn't fall into the WP pricing trap that I have seen becoming the norm lately. The extreme case was this theme I downloaded for free, but later found out that in order to make all functionality work as I've seen in the demo, I would have to subscribe to an X number of paid plugins, something around a thousand dollars per year. This has nothing to do with the WP mentality from years ago. reply josefresco 21 hours agoparentVeteran of WordPress here: Pretty much every theme on Envato Marketplace comes bundled with plugins that at some point will create a licensing nightmare. It's been this way for years, and is not a recent development. The problem is in order to \"bundle\" these premium plugins (think Slider Revolution) the theme authors often devise their own propriety update mechanism that after a few years becomes...wonky at best. Separate licensing that relies on \"native\" update processes would actually be ideal. The process goes like this: 1. Login to update plugins. 2. Some plugins don't auto update because they require licenses. 3. Search for the theme's proprietary update process or plugin. 4. Discover that the Envato support license is expired. 5. Renew license (typically 6 months). 6. Update plugins again and... pray that it works because support is always a gamble. We stay away from Envato and the like if we can, but inevitably we acquire clients with themes purchased this way. reply konfusinomicon 20 hours agorootparenthey now, when using terms like 'Slider Revolution' always remember to include a trigger warning to avoid sending all the salty wordpress webdevs into fits of insurmountable rage reply josefresco 19 hours agorootparentI hear you, just yesterday I was telling someone in my office how that plugin just gives me the sweats. I can stumble around sure but woah is that UI a beast. Very capable but not for the faint of heart. reply rodolphoarruda 20 hours agorootparentprevYes, I began to work with Envato back in 2008 and saw this licensing tsunami coming. I have canceled my subscription with them last November. I couldn't find a single theme without Elementor bundled up. I feel sorry for those many unadvised people who actually bought the theme to later had to open the wallet again to pay Elementor for a subscription. reply RobotToaster 18 hours agoparentprevI made a website for a small non profit I'm a member of recently, wordpress seemed like the natural fit but wading through the hive of scum and freemium that is wordpress plugins made me feel dirty. With all the awesome open source self hosted apps these days I'm surprised there's nothing better for generic websites. reply fhd2 16 hours agorootparentI'm working on a WordPress site for a test campaign right now, and pretty much came to the conclusion that most themes/plugins send me down two rabbit holes: 1) Licensing / security issues 2) Getting them beyond 80% of what I need. Ended up using only a single third party plugin (Polylang), and doing the other stuff we need in a custom theme based on Automattic's (possibly a bit unmaintained) _s base theme. Feels like a good decision, only took me about a day more to fiddle with the CSS to make things look right and write a bit of PHP code for some functional requirements we had. Seems way more economical than dealing with a soup of plugins and some shady theme. Since you can nowadays just create custom blocks for all the site elements, it's a pretty OK development experience. But I also can't quite believe this is the state of the art... I use static site generators whenever I can, but for a bit more dynamic websites, it seems WordPress is one of the best out of what seems like only bad options. Also an interesting case: Automattic seems like a company that's set up to resist enshittification. But all those theme and plugin authors with profit motives are not, which has about the same effect as if Automattic was ruining the platform for short term profits. reply Beijinger 20 hours agoparentprevWhat was the theme? reply ckluis 19 hours agoprevI wish they had a better demo video of it in action. reply imnotgpt 20 hours agoprevAnyone know of any good multi site options other than Wordpress? Say you were running 300+ sites by your lonesome, what would you pick, Wordpress or something else? I’m asking because for this use-case Wordpress Multisite seems to be the only option, but I’ve also always despised its structure and inner-workings. reply mickeyfrac 13 hours agoparentWe've got a hundred tenant multisite running on WP and have been looking at other options over the last couple of weeks. I am most interested by PayloadCMS https://payloadcms.com/blog/how-to-build-a-multi-tenant-app-... . However our CMS needs, for this product, are very simple, so Payload suits. We've also been looking at a multitenancy option for WordPress, in particular using Gridpave https://gridpane.com/kb/using-gridpane-multitenancy/ but you need the $5000 annual dev pro plan (annual for unlimited sites). We use Gridpane already on their lower cost plan and have found it excellent value for money. We will probably go with Payload. WP is getting messier by the day. With the AI coding tools getting better and better it feels like having as much flexibility as possible will have a huge benefit down the line. reply 1123581321 20 hours agoparentprevLook at Craft CMS multi site for a better implementation. It’s also multi-lingual, e.g. you can maintain Spanish and French translations for your global elements and then designate language for each of your sites and it’ll translate any shared content. However, for 300 sites, anything but a custom web app will get out of hand because that’s too many to manage in a UI that’s primarily meant for a handful of sites. reply esquire_900 13 hours agoparentprevI'm using it for a 10.000+ multisite installation (quite simple personal blogs), and even though it has it quirks it works quite well. Almost nothing is best in class and a slight pain to get it working, but the sheer size of the ecosystem is still it's biggest plus. In general every problem or feature you can imagine already exists or is easy to bolt on. reply rroose 14 hours agoparentprevDrupal has an excellent multi site solution with the domain access module with which you can share content between multiple domains/sites. reply iamacyborg 11 hours agorootparentI'll never understand why Drupal never became as popular as WP. reply rroose 4 hours agorootparentYeah, it's weird. All the modules (plugins) are free and open source as well so it looks like a no brainer. It probably has something to do with the steep learning curve which can be intimidating. reply rovr138 20 hours agoparentprevWhat’s shared between these 300 sites? reply selul 20 hours agoparentprevI don't think there is any other option. If those are very simple websites, there are some wp plugins that allow you to map them to domains, i.e you can use a single instance of WordPress and map the content to different domains. One plugin for this use case is WP Landing Kit. reply ec109685 10 hours agoprevIs the tldr; having open ai generate json config files that are parameters to a Wordpress template? reply hnrodey 21 hours agoprevCommenting w/o reading the article. WordPress triggered me. Last month I created a brand new site using WordPress. I followed a 90 minute video on YouTube where I was instructed step-by-step on what to do. The result is that I'm happy with the finished product and learned a lot about WordPress along the way. However, I would have NEVER got there on my own absent this remarkable YT video. WordPress is too complex, too bloated, too filled with messages from plugins, too reliant on magic, too reliant on plugins to do anything advanced beyond setup a post or page. I hate WordPress so much. I'll still use it because it's entrenched, and because it's less time that coding a Jekyll site to equivalent functionality. But I hate it. Thoroughly. reply tutfbhuf 20 hours agoparent> I'll still use it because it's entrenched, and because it takes less time than coding a Jekyll site with equivalent functionality. I wouldn't count on that. It required a 90-minute video for you to get going with Wordpress. I would say, if you know some basic stuff (e.g., know how to install gem, how to write markdown/html), you can set up Jekyll in under 90 minutes: gem install jekyll bundler; jekyll new myblog; cd myblog; bundle exec jekyll serve Now, you have a server up and running. You can start creating a post by creating a markdown file in the _posts folder. For me personally, it would be faster to learn any easy-to-use static site generator than Wordpress. reply debesyla 11 hours agorootparentOnly if you already know how to, well, do programming and writing commands to terminal. For a lot of people clicking pretty buttons is easier to understand. reply slim 4 hours agorootparentprevit's 30 seconds to do that in wordpress. I think what GP meant by setup is advanced setup reply berkes 20 hours agoparentprev> that coding a Jekyll site to equivalent functionality. With me it's the exact opposite. Jekyll, a GH actions, deploy to a static site hosting takes under an hour. I know Jekyll, so it's a bit cheating, but yesterday I did the same with hugo, that I never used before and within 1:30 I had a site running on Digital Ocean. And It's also not because I don't know WP. I've build and scaled a dedicated WP hosting company so I know quite a bit about setting it up :) In my case it's always because I know the primitives of the web very well: HTML, CSS, JavaScript (and the JS/HTML Web APIs). WP has layers upon layers upon layers between me and these primitives. Hugo or Jekyll don't: they are as close to these primitives as possible. I know the primitives, I never know these layers upon layers upon layers. They are shifting targets, poorly documented and often horribly executed. So instead of \"just using flexbox for this thingy\", In WP I need to learn yet another \"site builder\", or \"theme framework\", or, worse but rather common: all combinations of all options; infinite amount of permutations that interact, or conflict, or both. (And yes, I know I can build a WP theme from scratch, staying close to the primitives. But that's far, far more work than 1:30h) This is just the startup cost. Which is, in my experience, rather high with WP. The real cost comes at maintaining and future development and scaling. reply bevekspldnw 18 hours agorootparentI’m building pretty complex stuff with just Flask and Jinja, and as somebody who also has deep fundamentals it’s so much easier than wading through layers of useless crap these frameworks de jour push in your face. reply marc_io 20 hours agorootparentprevThe problem is that right now the pathways to quickly bootstrap a WordPress site with a good enough, customized theme are hidden under SaaS providers, like hosting companies. Use InstaWP or ZipWP, for example, and you can start in just minutes. reply berkes 16 hours agorootparent> and you can start in just minutes. Like I said: I built and scaled such a hosting. But while you can start in just minutes, you don't have that publishable site that you have in your mind, in minutes. It takes hours to learn where to find what. To select a good theme. To find the right plugins. To remove the wrong plugins. To then fix some error that comes from removing the plugin. Or to fix an error from installing the wrong one. Experienced WP devs even ask hours for this: people who do this all day, for a living, will charge you hours to build this for you. Sure, you may be lucky and have some goal in mind that happens to be ridiculous easy with WP. Or you may not have something in mind and just go-with-the-flow to end somewhere that happens to be easy with WP (a good strategy really). But, in general, I have something in mind. A landing page for a startup. Or the outlines of a webshop, or a simple blog even, and it will take me hours or days banging against WP to get there, whereas with hugo or jekyll that's less than a few hours of banging. reply whatamidoingyo 20 hours agoparentprev> But I hate it. Thoroughly. I had this mindset for years. \"It's not real programming. It's for people with no brain\", I would tell myself. A lot of other developers share this idea, I think. However, I currently am in the plan of launching a series of blogs, somewhat related to each other. I figured I'd try out wordpress, just to see what it's like, and also because I plan on having other people working on these blogs. Whoah! Completely blown away by wordpress and how quickly I can set things up. PHP is quite simple, and the built-in functions are very helpful. If you plan on just launching some products, learn wordpress. If you want to learn a programming language, go ahead and write the entirety of the code base yourself - that's the only reason I can think of to not use wordpress (for myself). reply sgc 19 hours agorootparentI recently was forced to use WP for a site due to third party constraints. It simply wreaks of being a swiss cheese of security vulnerabilities once you start adding plugins - so that would be my main reason for staying away from it for a simpler site. For a more complex site you will wind up with so many plugins you are better off custom since something will definitely break from an update down the road. My favorite thing was how easy it was to create a simple plugin from where I could inject my own php / html / js/ css at just about any stage of the pipeline, and crazily enough, I tried too many cms that would not allow me to override and direct edit the html on a page. It does win in the \"easy to deploy but fully customizable\" category, just because of that. But my thought when using it was sometimes \"they made this more complicated and difficult than doing it directly, because they managed to convince people the direct programming was out of reach\". But that is how I feel about most frameworks, so I might not be objective on that one. Overall it was faster, but the tradeoff was massive opacity. I recently noticed a tracking pixel on my site and have to figure out which a**hole plugin dev is injecting it, then find a different plugin or write my own. I have always been vanilla for my other sites, so learning to combat other vendors and having an adversarial relationship with my own site really breaks the mental model for me. reply Tijdreiziger 19 hours agorootparentWordPress is best viewed as a framework for people who don’t want to touch code. The reason it feels more difficult to ‘do it directly’ is because most WP users really aren’t expected to do so; they’d be using plugins rather than writing their own code. reply sgc 18 hours agorootparentI completely understand that, but in the real world, you will need to get your hands dirty with a bit of code because no matter how complete, there will be an edge case where you need to jump outside the box. reply jurimasa 15 hours agorootparentprevWP is still popular as it is for two reasons: 1. You can install it in a toaster. The cheapest hosting service will offer PHP and MySQL. It will run slow, but it will run. It will be easy to install and start working right away. 2. You can train anyone to use it and put content on it in an hour. reply abhiyerra 15 hours agorootparentprevI’ve built my own websites running on NextJS, Django, Rails, Jekyll, and Hugo and it was great as a developer getting exactly what you want. Recently we brought on some marketing people and trying to get things out on a custom Django app was blocking them because of a lack of engineering resources. Their campaigns were delayed and they were getting frustrated. We moved to Wordpress and have setup a vetting process for plugins which they just need 2-3. Marketing can update the website as needed and don’t need engineering time. Most of what they create are forms, blog posts, and pages. So nothing super complex anyways. As an entrepreneur I see why WordPress has such a large command. Plenty of people who can work on it. If you are nontechnical and use a hosted solution you can create a good enough MVP with all of these plugins. As an engineer everything about it is annoying but it commands 42% of the web so it must be doing something right. reply 8338550bff96 20 hours agoparentprevMind sharing that video? I have a friend that set himself up on a WordPress site because he wants to be able to have control over his very small private training business. I'm a full-stack dev, but don't know anything about how WordPress does things to be able to help him out. reply codegeek 20 hours agoparentprev\" followed a 90 minute video on YouTube where I was instructed step-by-step on what to do. The result is that I'm happy with the finished product\" Now try doing that as a non technical person with anything else and report to us if you succeeded. You won't. This is why WordPress is popular. Liking or hating doesn't matter. No one has been able to build something that can replace WordPress. reply spiderfarmer 20 hours agoparentprevSame. I tried many times in the last 10 years to see if it improved, but every time it got worse. Especially the plugins. Automattic should have killed many of them by integrating the functionality, but they have seem to have stagnated years ago. reply RobotToaster 18 hours agorootparentAutomattic are one of the worst offenders when it comes to plugins, a bunch of features that should be in core are in their jetpack plugin that integrates with their proprietary SaaS. reply Tijdreiziger 19 hours agoparentprevBackground: I got my start dabbling in WP around 10 years ago, and still maintain a few WP sites. If you needed a 90-minute video — I daresay you either did it wrong, bit off too much to chew, or were better off using a high-code framework instead. One of the reasons WordPress got popular is its at-the-time famed ‘five-minute install’. [1] You just throw the files on a server with PHP, give it a MySQL database and that’s it. (Nowadays, even this five-minute process is usually abstracted away behind a mouse click.) With that, you get the core WP functionality, i.e. a modern theme, the ability to create blog posts, pages, and have visitors leave comments. For many people who just want to get a relatively simple website, this is quite enough, and IMO there is still no comparable no-code site engine. Want a different look? Just search on the official theme directory (quality varies, but there are decent ones — just try not to get forced into the old ‘classic’ editor), use one of the first-party themes, or write your own. Want to extend the core functionality? Just search on the official plugin directory (again, quality varies, so exercise judgment) or write your own. Now, is it possible to blindly throw a cocktail of plugins at the wall, resulting in an unmaintainable abomination? Yes, it is — but as you’ve already discovered, you won’t necessarily like the result. [1] https://developer.wordpress.org/advanced-administration/befo... reply robtherobber 15 hours agorootparentSomething similar I said in 2021, glad to see it still applies: https://news.ycombinator.com/item?id=26540187 reply bevekspldnw 18 hours agoparentprevThe problem with Wordpress is it doesn’t follow MVC and mixes application logic with presentation which is a mess. reply quesera 20 hours agoparentprevI'd love to share the link to that video with someone who will benefit as much as you have, so that I can continue to never think about WordPress myself. reply rodolphoarruda 20 hours agorootparentFolks here are commenting about this FSE feature that allows you to build a full site starting from a block theme. I did a quick search on YT for 'FSE full course' and found some. I think it's worth the time checking out. reply dageshi 20 hours agoparentprevAre you mad at wordpress or the fact you had to build the site in the first place? Cause it seems like building any site with a tool you don't understand and don't particularly want to understand is going to be a bad experience? reply hdlothia 20 hours agoparentprevWhat's the video? reply lovegrenoble 19 hours agoparentprevCan you share the link with this tutorial? reply stevenicr 18 hours agorootparentNot OP - but I have found a few like this that are good - and I posted a few under 'wordpress stuff' https://steveiscritical.com/learn-websites-and-coding/ - to teach my teams more modern wordpress ways recently. I warn people that even though a good and easy to use tutorial like XYorZ may help teach, be wary that if they are teaching using elementor, bricks or similar page builder (added plugins), that it may be good knowledge, but that's not really wordpress per se. Anyhow, with the new FSE editing options, I will say that I finally feel we can put the separate page builders to pasture for the most part, and all the bloat that comes with them for most use cases. Super Appreciate the vids that Jamie Marsland has been releasing - many showing how to do nice designs with base WP, watching the process is helpful getting up to speed with current options - and shows how modern stuff can be crafted without tons of fancy addons these days. Navigating the new FSE stuff is very different than previous WP ways like the customizer or 'additional css' blocks, it's finally getting noob friendly again. reply lovegrenoble 17 hours agorootparentThank you, Sir reply Brajeshwar 20 hours agoparentprevOnce upon a time, you have to have a second installation of WordPress just to get an \"About\" page along with the main Blog. reply iamacyborg 11 hours agorootparentI first used WordPress in ~2008 and that wasn't the case then, you must have been a real early adopter for that to have been true, or have done something seriously wrong during the install. reply Brajeshwar 8 hours agorootparentTried and used WordPress since its beta or early release 2003-ish. If I remember correctly, it has no option to have multiple pages, hence the need to install another instance for Pages. (I see, my original comment was downvoted -- I've no idea. We started WordPress with no option to have multiple pages and now see where we are and what we can do with it. Isn't that an interesting titbit.) :-) reply rodolphoarruda 20 hours agorootparentprevI reached a point where I had to install Bludit in ./blog in order to add a decent blog to a Wordpress website. I'm serious. reply tbwriting 20 hours agoprev [–] No shade to the creators as I'm sure the tool is great but if I didn't know better I'd say this seems like an astroturfed effort by WordPress to stay relevant. Existing AI tools alongside other open-source builders (Puck for React, Primo for Svelte, etc.) equals all the good things about WordPress's \"WYSIWYG-ness\" minus all the unnecessary bloat that's piled up over the years. reply dmurko 18 hours agoparentWP is still by far the most popular CMS [1] and runs a large part of the internet. So I'm pretty sure it's still relevant. [1] https://kinsta.com/wordpress-market-share/ or https://trends.builtwith.com/cms reply marc_io 20 hours agoparentprev [–] The power of WordPress lies in its community, branding, and marketplace. The options you mentioned simply don't compete in these areas. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "QuickWP is an AI-driven WordPress site builder leveraging OpenAI, an FSE theme, and WordPress Playground for creating custom themes from user inputs.",
      "The project, recently made open-source, explores AI models, image generation, and consistent context management across the site.",
      "The codebase is accessible on GitHub, offering a learning resource and foundation for further development by the community."
    ],
    "commentSummary": [
      "Themeisle.com has launched an AI-powered WordPress site builder, revolutionizing site design with block-based editing, challenging the traditional WordPress approach.",
      "Despite concerns over WordPress's technical debt and plugin issues, utilizing FSE themes and quality plugins can enhance the user experience positively.",
      "Users are debating WordPress's evolving landscape, pricing and licensing challenges, reliance on proprietary updates, satisfaction with themes and plugins, and considering alternatives like Craft CMS and Drupal."
    ],
    "points": 173,
    "commentCount": 65,
    "retryCount": 0,
    "time": 1711023103
  }
]
