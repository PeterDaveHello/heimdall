[
  {
    "id": 36380711,
    "timestamp": 1687099367,
    "title": "Imaginary problems are the root of bad software",
    "url": "https://cerebralab.com/Imaginary_Problems_Are_the_Root_of_Bad_Software",
    "hn_url": "http://news.ycombinator.com/item?id=36380711",
    "content": "Subscribe Audio version (read by a tts bot)Imaginary Problems Are the Root of Bad SoftwareThere are many factors which can be a catalyst for bad software: from the tools being used, to team communication, to the personal stake developers have in its success, to the testing methodology.I propose that there is one problem chief among them, an impetus for bad software from which almost all others take root: imaginary problems.Most complicated or broken software is not designed to be overly complex or dysfunctional. It\u2019s just designed to do something other than its intended purpose.Let\u2019s say you\u2019re a podcast host who wants a custom website where you can sell your promotional products, make advertising money without a third party cutting in, and, most importantly, deliver podcasts, videos, and blogs to your audience.The requirements for your little web-app might look something like this:Fast load time in North America, with real-time podcast streaming and downloadsDoesn\u2019t crash or freeze in the first 15 minutes for 99.99 percent of users, preferably never crashes or freezesIntegrates well with Google Adwords and maybe some other third-party ad providers as well, if there\u2019s timeDynamically links to the latest products in my Zazzle shop and, if possible, gives recommendations to users based on the content they\u2019ve consumedIntegrates with Facebook live player. If it\u2019s easy to create an alternative solution for streaming that doesn\u2019t require Facebook, even betterYou give these specs to a team of contractors, and you chat about them a bit. It seems that everyone is on the same page. Yet, when they return with the Minimum Viable Product two months later, your face turns red. You\u2019ve just wasted $15,000 on a piece of garbage; you want your money back.The first time you open the app, the screen freezes. You ask how to select what kind of ads should be allowed to run on the site and are pointed to an ugly, hard-to-understand custom user interface (UI). Half the links to your merchandise on Zazzle are broken or missing images, and the Facebook livestream is laggy!But the development team is confused at your anger\u200a\u2014\u200arightfully so, from their point of view\u200a\u2014\u200abecause they\u2019ve gone to hell and back for you.They\u2019ve put their heart and soul into creating this app, and it has some amazing features:A state of the art recommendation systemAn algorithm generating the transcript of all your streams, in real timeYour front page loads in sub 200ms times all over the worldA streaming protocol and client build almost from scratch, in case you don\u2019t want to rely on Facebook liveA service that allows you to easily integrate over 20 ad exchangesThe problem is that you thought you requested a core product with a couple of extra features, if they were easy enough to implement. Meanwhile, the dev team heard something else. They heard about some exciting challenges they could tackle\u2026 and a slew of boring, basic features they couldn\u2019t be bothered to test properly or care about.Even worse, you didn\u2019t communicate directly with the devs\u200a\u2014\u200ayou communicated through a game of Telephone. You spoke to a sales guy, who held a meeting with some middle management chap, who wrote some business specs and gave those to a PM, who wrote some technical specs and gave those to a team lead or architect, who then, at last, began to design the product with his team\u200a\u2014\u200aeach one of them putting a bit of his own twist on it along the way.Imaginary problems are often more fun to solve than real ones. Extremely intelligent people play competitive games, construct and solve math problems, and write books that aim to answer abstract questions about the human condition, all of them for free. A mediocre programmer, however, will probably charge you a fair amount to build a simple Android app. That\u2019s not because mediocre programmers are harder to find than geniuses, but because the former activities are all fun, while the latter can be quite boring.Most programmers want to get paid and have fun at the same time. Of course, the definition of \u201cfun\u201d is different for everyone, but for many engineers, it boils down to tackling interesting and challenging problems that are within the realm of solvability.Give a somewhat intelligent person too many boring tasks that are impossible to automate and you will eventually drive him mad. The human brain however, after billions of years of evolution, is quite talented at keeping its sanity. Much like victims of childhood hardship or abuse can find escape in fantasy books, victims of enterprise programming or freelance web development can find their escape in solving imaginary problems.The amount of imaginary problems a software engineer can create for themselves is a function of their imagination and of the difficulty of the real problems they\u2019re supposed to solve.It should be noted that this issue isn\u2019t unique to developers. Management, sales, HR, support, legal, and even accounting departments have their own unique ways of creating imaginary problems. They try to involve themselves too much in a decision, when their presence at a meeting is just a formality or wasn\u2019t requested at all. They overemphasize a minute problem that is related to their role, or hire teams much larger than necessary to illustrate their importance.When problems are dumb, intelligent individuals will find a way of coping.But imaginary problems aren\u2019t just the result of bored developers. They\u2019re also the result of long chains of communication.When I first began taking on freelance clients, I couldn\u2019t afford to be particular. This means I\u2019ve had email chains lasting for over a 100 exchanges, discussing insignificant details about internal MVPs. I\u2019ve had people change every single requirement on a project within the span of a week. I\u2019ve had clients ask questions such as \u201cCould this be ICO-ed?\u201d or \u201cCan we add some A.I. in here?\u201dGranted, most clients are savvier than that, but, even still, they often lack a bit of the knowledge necessary to articulate or construct some of their requirements. That is fine, as part of my job as \u201cthe computer guy\u201d is to help people figure out what they do and don\u2019t need based on their use cases. But it can become much harder to determine what\u2019s needed when there are a few layers between you and the client.Requirements get changed because someone either misunderstood an intention or because someone was trying to cope with that aforementioned boredomMost companies like having a sales guy who pitches potential customers, negotiates prices, and outlines possible features. They also have a people person to discuss more in-depth requirements and details with the customer, usually another sales guy, but with a slightly different title. Then there\u2019s the internal chain of command, various levels of management, and possibly some hierarchy, within the technical team.When a list of client requirements goes through so many people, even if those people have the best of intentions, some things will inevitably get lost in translation. Sometimes that change happens because the original requirement made no sense, or sometimes requirements need to be redefined. The sales guy might have told the client, \u201cfor only 39,999 extra we can do this on the Blockchain.\u201d But that leaves everyone who encounters the requirements down the line wondering what the definition is of \u201cdoing it on the Blockchain.\u201dMore often than not, requirements get changed because someone either misunderstood an intention or because someone was trying to cope with that aforementioned boredom, trying to make his job or the work of his team more interesting and impressive.Through all of this, the original requirements\u200a\u2014\u200athe real problems that have to be solved\u200a\u2014\u200aget lost. They are replaced with imaginary problems and with voids, and you\u2019ve got plenty of people ready and willing to fill those voids with their own imaginary problems, because the problems they have to solve are boring, and filling the voids gives them a way of coping.Overcomplexity and natural selectionThere can often be an even darker reason for the existence of imaginary problems: problems can help a team or a company grow, and can even become an integral part of its function.\u201cPeople who are bred, selected, and compensated to find complicated solutions do not have an incentive to implement simplified ones.\u201d\u2014 Nassim Nicholas TalebHave you ever heard about those three web engineers who figured out that secure online banking is actually quite an easy problem to solve? They developed some flawless banking software from scratch, using a functional design methodology and memory safe languages, then started migrating major banks to their amazing infrastructure.Probably you haven\u2019t heard of them, because they don\u2019t exist. There are, however, plenty of teams of thousands of developers, who are unable to grasp simple concepts such \u201crollbacks,\u201d perpetually creating banking software.The storage and transfer of numbers is not a particularly hard problem. Indexing the whole content of the internet and providing relevant results to natural language queries, in sub second times, is a hard problem. But just a few smart guys managed to solve that problem.The persistent problem for online banking is that the banking ecosystem has become really good at preserving its own money-grabbing hierarchy. Its leaders are corrupt leeches who prey on society\u200a\u2014\u200abut the leaders in an organization are just a symptom of its members.I wouldn\u2019t suggest that most underling workers for banks are evil or malicious in any way. Far from it. They are usually friendly lads, working to provide food, shelter, and an education for their families. But their chief incentive is not to fix the banking software, it is to stay employed. Losing your job in today\u2019s economy is no joking matter for some; in the banking industry, a big mouth or too much initiative is an easy way find yourself in front of a disciplinary committee.So banking systems remain the same\u200a\u2014\u200anot because the systems are efficient, but because of inertia. This inertia comes in the form of working on imaginary problems in order to avoid fixing real problems\u200a\u2014\u200areal problems which, once pointed out, would threaten the jobs of other people. To focus on these real problems could lead to getting fired, or, in the case of some particularly nasty \u201cinstitutions\u201d like Goldman Sachs, getting a few life-ruining brown envelopes sent to a few FBI officers and prompting a strange suicide.\u201cIt is difficult to get a man to understand something, when his salary depends upon his not understanding it!\u201d\u2014 Upton SinclairThe C-suite ignores the fact that their upper management workers spend 90 percent of their time on \u201cclient meetings\u201d that involve tropical islands and million-dollar budgets for \u201cother expenses.\u201d Upper management, in return, turns a blind eye to corruption in C-suite.Because middle management encourages them to live in their Wolf of Wall Street fantasies, upper management ignores middle managers who buy eccentric offices and hire themselves three secretaries and a dozen interns.Because line management doesn\u2019t complain about their dictatorial power fantasies, middle management ignores the fact that line managers, instead of cutting costs, spend their time working on PowerPoint presentations about \u201cImproving our Agile Methodology.\u201dBecause the team leaders don\u2019t seem to notice the fact that their superiors can\u2019t even use Excel properly and only hit the office every few weeks, line managers ignore the team leaders and architects talking about \u201cnext generation interfacing between our systems using JRPC and microserviceization using Hibernate and Spring\u201d when they should be getting those bloody Mysql queries to take less than a day.Because the developers don\u2019t seem to notice that their leaders don\u2019t really write any code except DOT diagrams, team leaders don\u2019t complain about their developers, instead of looking at an EXPLAIN for the aforementioned slow query, re-designing the UI for the tenth time that year using a new JavaScript framework.It\u2019s a vicious cycle of solving imaginary problems, from the CEO who doesn\u2019t realize that stealing another 30 million won\u2019t make his dad love him to the user-experience intern who doesn\u2019t realize that redesigning the \u201csubmit\u201d button using Angular-Material-Bootstrap 19.13.5 won\u2019t make the fact that they store passwords in plain text (and use them as part of the auth cookie) go away.But everyone needs to keep solving the imaginary problems, because if they stop creating and solving these problems, if they start focusing on the real problems, they might realize the whole system is broken. They might realize Debra has been sitting in that corner, staring at uptime graphs of the internal server farm for 10 years, despite the fact that the company moved to AWS five years ago. They might realize 99 percent of their job is to perpetuate the existence of someone else\u2019s job. And that\u2019s a hard realization to digest\u2014impossible for most, I dare say. So, instead, most find a way of coping.If you enjoyed this article you may also like:The Red QueenStop future proofing softwarePublished on: 2019-04-29SubscribeReactions:",
    "summary": "- Imaginary problems can often be the root cause of bad software.\n- Miscommunications and long chains of communication can contribute to the creation of imaginary problems.\n- The persistence of imaginary problems can be driven by incentives to maintain job security and avoid fixing real problems.",
    "hn_title": "Imaginary problems are the root of bad software",
    "original_title": "Imaginary problems are the root of bad software",
    "score": 778,
    "hn_content": "- The software industry's incentive system is often to blame for producing bad software.\n- Designers, engineers, product managers, and managers are rewarded for creating more solutions, rather than focusing on what is actually needed.\n- The industry prioritizes features and innovation over stability and usability, leading to a proliferation of complex and unnecessary designs.\n- The web has contributed to the decline of good industry practices and standard UI guidelines.\n- The lack of consistency in design across different apps and platforms has worsened over time, leading to confusion among users.\n- The emphasis on speed and new features can result in poor code quality, technical debt, and a lack of attention to user needs.\n- The desire to solve imaginary problems can be more exciting than tackling real problems and finding practical solutions.\n- There is a need for alignment between the incentives of everyone involved in software development and what is actually needed.\n- Some companies and individuals prioritize stability, minimalism, and usability, and are rewarded for their efforts.\n- Overcomplicating software and pursuing unnecessary complexity can lead to negative consequences.\n- Solving real problems for real users can be highly rewarding and provide a competitive advantage.\n- There is value in simple, reliable solutions that efficiently address user needs.\n- The mindset that \"bigger is better\" and prioritizing the pursuit of growth can undermine the effectiveness of software development.\n- Imaginary problems often distract from the necessary focus on delivering functional and practical solutions.\n- There can be a disconnect between what is taught in educational programs and the practical realities of software development.\n- It is important to align incentives and prioritize practical solutions over technical complexity and feature bloat.\n- Solving real problems and making users' lives easier can be a highly satisfying experience for developers.\n- There is value in focusing on user needs and delivering stable, efficient, and usable software.\n\nOverall, the post highlights the need for a shift in the software industry's focus towards practical problem-solving, stability, and usability, while aligning the incentives of all involved parties. It emphasizes the importance of avoiding unnecessary complexity and pursuing minimal, reliable solutions that address real user needs.- Scaling up can be cost-prohibitive, but now there are fast, high productivity languages/runtime that allow for scaling out.\n- Choosing a language you're comfortable with and then scaling is a valid approach.\n- The economics of writing, running, and distributing software have changed dramatically.\n- Pick technologies that you can optimize, but don't over-optimize.\n- Optimization is more about the overall stack, not just the language.\n- PHP was the right tool for Facebook because it was easy for them to use.\n- Facebook's success was not solely dependent on the choice of PHP.\n- The language you choose does matter, and knowing multiple languages is important.\n- Unnecessary optimizations and over-engineering can hinder progress.\n- Sometimes people focus on imaginary problems rather than solving real ones.\n- The future of software development lies in solving real problems and delivering value.\n- Balance simplicity and complexity in software design.\n- Don't dismiss simple solutions to complex problems.\n- The way organizations are run can impact the quality of software.\n- Enterprise architecture teams can introduce complexity and unnecessary solutions.\n- Be wary of the resume-driven development and the fear of missing out on trendy technologies.\n- The article points out the importance of focusing on real problems and avoiding unnecessary complexity in software development.",
    "hn_summary": "- The software industry's incentive system often prioritizes creating more solutions rather than focusing on what is actually needed, leading to bad software.\n- The industry's emphasis on features and innovation over stability and usability has resulted in complex and unnecessary designs, contributing to confusion among users.\n- Solving real problems for users and delivering stable, efficient, and usable software is important, and there is value in focusing on practical solutions rather than technical complexity."
  },
  {
    "id": 36382700,
    "timestamp": 1687111777,
    "title": "Swing VPN app is a DDoS botnet",
    "url": "https://lecromee.github.io/posts/swing_vpn_ddosing_sites/",
    "hn_url": "http://news.ycombinator.com/item?id=36382700",
    "content": "POSTSSwing VPN app is a DDOS botnetJune 4, 2023tldr: Swing VPN is using its user base to DDOS sites using its users as a an attack botnet.new: Some people wrote me saying that the DDOS is not happening on ios devices. Just did a quick check and you guys are right. iOS app is using different way to do VPN and also does not do anything suspicious. I should appologize to you and to Appstore team for my lazy extrapolation without actually checking it. Unfortunately I don\u2019t have much time to fix the article right now, so please just ignore anything ios related below this line.IntroductionIt all started with a friend of mine complaining that his phone was doing a request to a specific app every few seconds. Initial assumption was that the phone was infected with a virus but a 2 minute investigation showed that all requests went from \u2018Swing VPN\u2019 app which were legitimately installed on the phone as VPN service. It was making requests to specific website that my friend never used and had specific data inside request payload indicating its intent send requests to an endpoint that would be heavily demanding on resources of that site.The site that was targeted on my friends phone and later on my phones was https://turkmenistanairlines.tm. Request was sent about every 10 seconds and was sent specifically to this search endpoint:https://turkmenistanairlines.tm/tm/flights/search?_token=J8SxUX2Qwzltw4LiHsRHTCtfthgBYxf4hyI8oNly&search_type=internal&departPort=TAZ&arrivalPort=CRZ&tripType=rt&departDate=4%2F22%2F2023&arrivalDate=5%2F4%2F2023&adult=1&child=0&infant=0&is_cship=onThe specificity of this URL clearly indicates that this is not a mistake nor is it method to ping a site to check for errors with internet connection. Later in this document I will show and hopefully prove malicious intent of the creator of this application by inspecting how it all works and infrastructure behind it.RequestsLet\u2019s start with examining requests and see what exactly is happening when we run Swing VPN on our phone. I am using a physical phone connected to a computer using a usb wire and a program named \u2018scrcpy\u2019 to mirror screen of my phone to the screen of my computer. This is done just simplify screenshot taking and is not required for the analysis.First let\u2019s start with simple inspection and verification that the request made to airlines website is done by the \u2018Swing VPN\u2019 app. For this I will use an android app pcapdroid to capture all requests by the apps and see who is responsible for which request. There is no need for additional plugins or apps to see the details about the requests as I will use different tools for those tasks. Current goal is to link each request with specific app. I want to mention that this phone have only standard android apps and swing. In this video pcapdroid has been just installed and I waited some time for google play to finish with all of its statics and other request so that they will be less non related requests in the log.Your browser does not support the video tag.From the video we can clearly see that this \u2018Swing VPN\u2019 app does some type of request to the site https://turkmenairlines.tm. From it we cannot clearly conclude that the app does something malicious but this is left for later analysis. For now the proof that the request are originated from the app that I am inspecting is good enough. Now we can safely proceed to a deeper dive into functionality of the app.Your browser does not support the video tag.The next step is to figure out what exactly Swing VPN is trying to do by sending these requests. For these I will use mitmproxy to capture all data sent and see what the purpose of those requests.In this video \u2018Swing VPN\u2019 is just freshly installed from the Play Store and being monitored by mitmproxy. After app startup, language selection and acceptance of privacy policy the app starts to figure out \u2018real IP address\u2019 by doing a request to both google and bing with query \u201cwhat+is+my+ip\u201d. My guess is that the app just parses the returned HTML and figures IP from those responses.These ip request needed, as we will see later, to figure out which config files to load. The app loads different configs and does different actions based on not only country or region of the user but also on the internet provider within the region.After the required config type is identified in this video the Swing VPN does a couple of requests to 2 different config files stored in personal google drive account of the app creator. The config files are requested from specific personal servers, a few github repositories or a couple google drive accounts. My guess is that config file location could be determined by daytime but I have not spent any time to verify that as it is not important. As soon as configs are retrieved the app connects to ad network to load ads. This concludes the app initialization process. After this app stores data into a local cache and proceeds to DDOS a site returned from the config.And this is how the app behaves over time after being close. Hint it still tries to do it DDOS even though it is not being used.From this log we can see that the app is requesting a specific endpoint of \u2019tm/flights/search\u2019. Since flight search is quite intensive tasks that requires a lot of databases and server resources then it is clear that that the goal is to stress server out of resources so that normal users won\u2019t be able to acess it when needed. And even though 1 request per 10 seconds might seem that it does not doing DDOS the problem is in amount of install base. Currently in the beginning of June 2023 it has over 5 million install base on android and even if you split it by 10 it has a potention of 500k RPS. Which is quite impressive to be able to handle for a small site written probably in PHP.Sidenote: The app does not respect privacyYour browser does not support the video tag.While doing this little investigation I found out that the app does not care about privacy. It probably added the button \u2018I Accept the privacy policy\u2019 just to make appstore and playstore accept the app but in reality it is just a button that does not do anything. In the video above I installed a fresh version of Swing VPN from playstore and then instead of pressing \u2018I Accept the privacy policy\u2019 button I pressed which leads to \u2018Privacy Policy\u2019 screen. And while I was skimming though the policy the app already started sending my data to ad network. At the same time it was downloading configurations with information about which site to DDOS and started executing the DDOS routine while I as reading the \u2018Privacy Policy\u2019. After I was done reading I just pressed back a couple time thus informing the app that I am not agreeing to the term but it is already late. The act of opening the app is enough for it start it\u2019s DDOS actions.The functionality of the configurationsSo we just went through outer look of how the app app does it actions related to DDOS\u2019ing other sites. But I could have installed some other app in the background maybe with similar icon which did all the nasty stuff just to fool you. So now let\u2019s dive deeper inside the app and the actual configurations stored in the app which you can do yourself to verify that it is indeed the \u2018Swing VPN - Fast VPN Proxy\u2019 that is responsible for all this actions.Some general information about android apk:VERSION USED: swing-vpn-1-8-4.apkAPK SIZE: 32.5 MiBINSTALL BASE ON PLAY STORE: 5+ million usersLINK TO PLAY STORE: https://play.google.com/store/apps/details?id=com.switchvpn.app&hl=en_USANDROID APP CREATOR: Limestone Software SolutionsLAUNCH DATE: 2020-10-06The app uses 2 custom native libraries to just obfuscate it\u2019s function and complicate the reverse engineering process. This files are libnativelib.so and libbony.so. We will use libnativelib.so as it will be enough to decrypt and deobfuscate the data.Configuration is downloaded from github, google drive or a custom host. In my research I checked only github and google drive since it was enough to check the hypothesis.GithubLet\u2019s start with github. First of all there are at least 2 different github accounts used to store the configurations for the app. I cloned both the repositories just in case somebody needs the historical data if they are modified or deleted. It looks like both repositories are about 6 month old so it won\u2019t be something unexpected if new repositories are created soon. These repositories are:https://github.com/Javaidakhtar576/swinglite_newhttps://github.com/githubfunc/cocomoThe general format of the message is some encoded string surrounded by curly braces. You could have seen one example of these in the second video. Here is how it looks like.And here is a the text version of one of the configs requested during startup.{{{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}}}The decoding code is located in the native libs directory with the name libnativelib.so. I reverse engineered the decoding algorithm and wrote is the python code that does the reversing. You can download it here: decode.pyIn order to decode that message store it into a file, let\u2019s say \u2018data.txt\u2019 and just run that file on it like this:python decode.py data.txtThe decoding string string will be put into stdout of the terminal and you if you want to save it to a file just redirect the output to the output file. For example:python decode.py data.txt > data.decoded.txtIf we run this decoder on the encoded message provided above the output of it will be:{ \"adsMode\": \"Remote\", \"adsSingleIdMode\": \"1\", \"summaryAdLocal\": \"0\", \"timeLimitedMode\": \"1\", \"timeLimitedConnection\": \"0\", \"defaultTimeLimit\": \"5\", \"minTimeLimit\": \"3\", \"extendTimeSmall\": \"15\", \"extendTimeBig\": \"30\", \"report\": \"1\", \"fixedServer\": \"1\", \"repair\": \"0\", \"summary\": \"0\", \"adsTest\": \"0\", \"screenMirroring\": \"1\", \"hotspot\": \"1\", \"adsDisabledFirst\": \"0\", \"adsDisabledPeriod\": \"0\", \"drawerCodeItemEnabled\": \"0\", \"disconnectDialogEnabled\": \"0\", \"summaryScreenEnabled\": \"0\", \"reportScreenEnabled\": \"0\", \"youtubeChan\": \"\", \"telegramChan\": \"\", \"livechat\": \"https://demolivechat.com/\", \"email\": \"\", \"telegram\": \"\", \"whatsapp\": \"\", \"facebook\": \"\", \"instagram\": \"\", \"twitter\": \"\", \"tiktok\": \"\", \"fakeServerList\": \"1\", \"fakeServerListP\": \"1\", \"fakeServerListPP\": \"1\", \"fakeServerListPPS\": \"0\", \"fakeServerListVIP\": \"0\", \"fakeServerListGP\": \"0\", \"gdServers\": \"1Wg3kZfrbbZxNz3BX1faZ1UQwPR3I3sVC\", \"gdServersTP\": \"1AjsNBfyj5asMmagR2JDwKDYF9jdvTgMu\", \"gdServersPP\": \"142dHQVc_Bmt3Cs_AZ8wZ90e54TdXQCzr\", \"gdServersPPS\": \"14ExZ2TZLzkfLEZSum-RkXrl8nCVSGkeO\", \"gdServersVIP\": \"1QkzwRzVFeYoL1vPZxn5gm4_VPAxaZbX3\", \"gdServersGP\": \"1SxfivoSYgBwIiLyRD8bR0Kfjy2f-lCrw\", \"ghServers\": \"B2_s\", \"ghServersTP\": \"B2_sp\", \"ghServersPP\": \"B2_spp\", \"ghServersPPS\": \"B2_spps\", \"ghServersVIP\": \"B2_svip\", \"ghServersGP\": \"B2_sgp\", \"update\": {  \"enabled\": \"0\",  \"updateVersionName\": \"\",  \"updateForcedCode\": \"\",  \"updateAbout\": \"\",  \"updateMirror1\": \"\",  \"updateMirror2\": \"\" }, \"urls\": {  \"enabled\": \"1\",  \"minTime\": \"10\",  \"maxTime\": \"10\",  \"randCi\": \"1\",  \"urlList\": [   {    \"url\": \"https://turkmenistanairlines.tm/tm/flights/search?_token=J8SxUX2Qwzltw4LiHsRHTCtfthgBYxf4hyI8oNly&search_type=internal&departPort=TAZ&arrivalPort=CRZ&tripType=rt&departDate=4%2F22%2F2023&arrivalDate=5%2F4%2F2023&adult=1&child=0&infant=0&is_cship=on\",    \"method\": \"GET\"   },   {    \"url\": \"https://turkmenistanairlines.tm/tm/flights/search?_token=J8SxUX2Qwzltw4LiHsRHTCtfthgBYxf4hyI8oNly&search_type=internal&departPort=TAZ&arrivalPort=CRZ&tripType=rt&departDate=4%2F22%2F2023&arrivalDate=5%2F4%2F2023&adult=1&child=0&infant=0&is_cship=on\",    \"method\": \"GET\"   },   {    \"url\": \"https://turkmenistanairlines.tm/tm/flights/search?_token=J8SxUX2Qwzltw4LiHsRHTCtfthgBYxf4hyI8oNly&search_type=internal&departPort=TAZ&arrivalPort=CRZ&tripType=rt&departDate=4%2F22%2F2023&arrivalDate=5%2F4%2F2023&adult=1&child=0&infant=0&is_cship=on\",    \"method\": \"GET\"   }  ],  \"uaList\": [   \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\",   \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\",   \"Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36\",   \"Mozilla/5.0 (Linux; Android 10) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.5563.116 Mobile Safari/537.36\"  ] }}If we scroll down to the \u2018urls\u2019 section we could easily find the link to the https://turkmenairlines.tm and the time required between requiests of 10 seconds. Which clearly lines up with our earlier observations.But there are quite a few files in the github repository and a lot of different configurations. Here are the files found in the repository:A1_c  A1_spp  A2_s  A2_spps B1_sgp  B1_svip B2_sp  B3_c  B3_spp  GLOBAL_s  GLOBAL_spps IRANMCI_sgp  IRANMCI_svip  IRANTELCOM_sp  IRNCELL_c  IRNCELL_spp  RU_s  RU_spps TEST_sgp  TEST_svipA1_s  A1_spps A2_sgp A2_svip B1_sp  B2_c   B2_spp  B3_s  B3_spps  GLOBAL_sgp GLOBAL_svip IRANMCI_sp  IRANTELCOM_c  IRANTELCOM_spp  IRNCELL_s  IRNCELL_spps RU_sgp RU_svip TEST_sp  backupA1_sgp A1_svip A2_sp  B1_c   B1_spp  B2_s   B2_spps B3_sgp B3_svip  GLOBAL_sp  IRANMCI_c  IRANMCI_spp  IRANTELCOM_s  IRANTELCOM_spps IRNCELL_sgp IRNCELL_svip RU_sp  TEST_c  TEST_spp  mainA1_sp  A2_c   A2_spp B1_s   B1_spps B2_sgp  B2_svip B3_sp  GLOBAL_c GLOBAL_spp IRANMCI_s  IRANMCI_spps IRANTELCOM_sgp IRANTELCOM_svip IRNCELL_sp  RU_c     RU_spp TEST_s  TEST_sppsThese filenames are constructed in specific order. First of all the a files has a prefix like A1, B1, \u2026, GLOBAL these is their way to split configurations into ISP related configurations. And here is how it is split:\"B1\"     | \"tm\"   | \"State Company of Electro Communications Turkmentelecom\"     |\"B2\"     | \"tm\"   | \"Telephone Network of Ashgabat CJSC;AGTS CDMA Mobile Department\" |\"B3\"     | \"tm\"   | \"Altyn Asyr CJSC\"                        |\"GLOBAL\"   | \"default\" | \"\"                                |\"RU\"     | \"ru\"   | \"\"                                |\"IRANTELCOM\" | \"ir\"   | \"\"                                |\"IRNCELL\"  | \"ir\"   | \"Iran Cell Service and Communication Company\"          |\"A1\"     | \"ae\"   | \"\"                                |\"A2\"     | \"ae\"   | \"Emirates Integrated Telecommunications Company PJSC\"      |\"IRANMCI\"  | \"ir\"   | \"Mobile Communication Company of Iran PLC\"            |with \u2019tm\u2019 -> Turkmenistan, \u2018ru\u2019 -> Russia, \u2018ir\u2019 -> Iran, \u2018ae\u2019 -> Unitaed Arab Emirates. We are interested in configurations that end with \u2019_c\u2019 which is proably a way to identify \u2018configurations\u2019.So if we walk over all the configuration files and collection all the urls the app is DDOS\u2019ing then we will get a list of these urls:https://www.science.gov.tm/news/20230112news-2023-01-12/https://www.science.gov.tm/organisations/classifier/reseach_institutes/https://www.science.gov.tm/library/articles/article-asirow-25/https://www.science.gov.tm/news/~Page34/https://railway.gov.tm/https://turkmenistanairlines.tm/tm/flights/search?_token=J8SxUX2Qwzltw4LiHsRHTCtfthgBYxf4hyI8oNly&search_type=internal&departPort=TAZ&arrivalPort=CRZ&tripType=rt&departDate=4%2F22%2F2023&arrivalDate=5%2F4%2F2023&adult=1&child=0&infant=0&is_cship=onhttps://www.science.gov.tm/news/~Page25/https://www.science.gov.tm/news/~Page9/https://www.science.gov.tm/news/~Page36/https://www.science.gov.tm/sci_periodicals/https://www.science.gov.tm/anounce/https://www.science.gov.tm/projects/mietc1/https://www.science.gov.tm/projects/APCICT1/https://www.science.gov.tm/projects/caren/https://www.science.gov.tm/events/https://www.science.gov.tm/organisations/chemical_institute/https://www.science.gov.tm/en/news/~Page11/https://www.science.gov.tm/en/news/20220329news-2022-03-28-1/https://www.science.gov.tm/en/news/20220310news-2022-03-09-1/https://www.science.gov.tm/en/news/20220123news-2022-01-22-1/https://www.science.gov.tm/news/20230112news-2023-01-12/If we look in this list we can see already familiar link to turkmenistanairlines. But other urls are all look similar to each other and all end with \u2019.gov.tm\u2019 which we probably can assume that this app is trying to attack some government sites of Turkmenistan. It is hard for me to imagine why would anybody do that but that is not what were are here for. My interest is in technical explorations.Configurations stored in the apkAll those previous explorations could be easily removed and then there would be no way to prove that this app is actually doing that. So let\u2019s deep a bit more deeper and actually find evidence that is baked inside the apk and cryptographically signed.It turns out not that hard of a task. If you decompile the by unzipping it or with a tool like apktool, there would be a file at the locationres/raw/rc_g.rawthis file is also encrypted and could be decrypted with the \u2018decode.py\u2019 script but this files does not contain enclosing {{{ and }}} marks. So in order to decode that file we just need to add \u2018-n\u2019 to end of our as second argument for \u2018decode.py\u2019 script. It is not the nicest solution but gets the job done for the this task:python decode.py cr_g.raw.txt -nSo after you run this command you should get a file similar to this:{  \"configResources\": [    {      \"type\": \"git\",      \"purpose\": \"config\",      \"url\": \"https://github.com/githubfunc/cocomo/blob/main/\",      \"urlExt\": \"\",      \"entry\": \"green\"    },    {      \"type\": \"git\",      \"purpose\": \"config\",      \"url\": \"https://github.com/javaidakhtar576/swinglite_new/blob/main/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://arpqpedacr.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://atrytgoi.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://bdefsr.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://cornchance.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://dreoapms.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://freekept.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://gquyidezfixp.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://haptpydligyh.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://hcvxm.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://hgvcp.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://jhgvu.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://mqurstd.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://mraznakgde.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://mwuth.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"host\",      \"purpose\": \"config\",      \"url\": \"https://net-vm-games.com/\",      \"urlExt\": \"\",      \"entry\": \"main\"    },    {      \"type\": \"google\",      \"purpose\": \"config\",      \"url\": \"https://www.googleapis.com/drive/v3/files/\",      \"urlExt\": \"?alt=media\",      \"entry\": \"15_T7IYmov1A7Ar3jFe4SkZ4dKFpbomTf\",      \"credentials\": \"...\"    },    {      \"type\": \"google\",      \"purpose\": \"config\",      \"url\": \"https://www.googleapis.com/drive/v3/files/\",      \"urlExt\": \"?alt=media\",      \"entry\": \"13R-GC8jtz4XB-xl_IQUeL8BiS32pXB03\",      \"credentials\": \"...\"    },    {      \"type\": \"google\",      \"purpose\": \"config\",      \"url\": \"https://www.googleapis.com/drive/v3/files/\",      \"urlExt\": \"?alt=media\",      \"entry\": \"13B5sCioRZCGfBx13b9K2sRoo2XEEst0B\",      \"credentials\": \"...\"    },    {      \"type\": \"google\",      \"purpose\": \"pin\",      \"url\": \"https://www.googleapis.com/drive/v3/files/\",      \"urlExt\": \"?alt=media\",      \"entry\": \"\",      \"credentials\": \"...\"    }  ]}I edited the output to remove \u2018credentials\u2019 value and replaced it with \u2019\u2026\u2019. If you really want to get that data just run the script yourself on the file and you could get the original value.So if you look at the last output you will find familiar github and goodle drive links that the app used to download additional settings. That settings files apart from being a real settings configuration is used as C&C (Command and Control) mechanism to secretly deliver targets for the Swing VPN to do DDOS attacks.Related filesswinglite_new.zip - latest commit for swinglite_new repository.cocomo.zip - latest commit for cocomo repositorygoogle_drive.zip - decrypted config files from one of the google drive accountsdecode.py - file to decrypt encrypted config stored in github and google driveswing-vpn-1-8-4.apk - a Swing VPN apk file version 1.8.4, downloaded from play storeI provided only single commit for github repositories as they are quite large (over 100 MB). If for some reason you need whole repository you can contact me by email and I will send a link to download whole repositories with history of more than half a year of commits.ConclusionFrom the provided evidence I think it is undeniable that creator of the app has malicious intent in denying services to regular people by DDOS\u2019ing those services. They use different techniques to obfuscate and hide their malicious actions in order to try to go undetected. That is main reason for why they send the request every few seconds as with the amount of install base they have it is enough to bring the services down but still not fire security alarms in appstore and playstore security teams. But if for some reason they decide that the pressure on the service is not enough they could easily send command to their apps and force the to storm those services with useless requests.Apart from malicious actions toward some innocent services I think it is really dishonest behavior toward regular users that download the app from stores. They do not respect their privacy and use users phones as a botnet. The reason it is very shady is that they already collect money from users by either show them ads or by selling monthly VIP services. It is from pure greed they also want use innocent users phones as a tool in their criminal actions.I have to give props for Swing VPN teams creativity to bypass security measure of Apple appstore and Google PlayStore but it is sad that Apple/Google security systems does not have some automated ways to detect these types of actions.If you have any questions about my methods, if you found any factual errors (don\u2019t send me typography corrections) or if I missed something important please contact me at via email. My login is lecromee and my mail hosting of choice is proton.me. I hope if you read these type of posts then you know how basic concatenation works.",
    "summary": "- The Swing VPN app has been found to be a DDoS botnet, using its user base to launch distributed denial-of-service attacks on specific websites.\n- The app sends requests to targeted websites at a rate of about one request every 10 seconds, aiming to overwhelm the servers and deny service to legitimate users.\n- The app also raises concerns about privacy, as it collects user data and sends it to an ad network without users' consent.",
    "hn_title": "Swing VPN app is a DDoS botnet",
    "original_title": "Swing VPN app is a DDoS botnet",
    "score": 625,
    "hn_content": "- The Swing VPN app has been identified as a DDoS botnet, operating in a command and control fashion.\n- Free VPN software, such as Hola VPN, has been known to abuse client trust and resources.\n- The Swing VPN app pulls lists of URLs from control sites and sends requests to them, potentially causing malicious traffic.\n- The app has over 5 million installations on Android.\n- The author of the post discovered this suspicious behavior by analyzing the app's traffic using Proxyman.\n- It is important to be cautious about the VPN providers you choose, as many engage in questionable practices.\n- Mullvad and ProtonVPN are popular VPN services that have a good reputation in the industry.\n- Using a VPS and setting up your own VPN can be a more secure alternative to using free VPN services.\n- VPNs can be used to bypass geo-blocking and protect privacy, but it is crucial to choose a trustworthy provider.\n- VPN services should not be used as a substitute for good cybersecurity practices and should not be relied upon to protect against malware.- The post discusses the use of tools like Frida and mitmproxy for reverse engineering and inspecting apps.\n- It includes a link to a blog post about reverse engineering a Norton VPN.\n- A recommendation is given to watch YouTube channel liveoverflow for beginner-friendly videos on reverse engineering.\n- The commenter mentions using chatGPT and phind for self-education on a topic.\n- Another commenter discusses their clientless tunneling service called Pinggy.io.\n- A discussion ensues about the possibility of the Swing VPN service operating a botnet.\n- Possible motivations for DDoS attacks are discussed, including extortion and petty revenge.\n- A debate occurs about whether DoS attacks should be legalized, with arguments for and against.\n- It is mentioned that legalizing DDoS attacks could enable protection racket schemes and harm small businesses.\n- The commenter expresses a preference for a system of vigilante justice based on moral justification.",
    "hn_summary": "- The Swing VPN app has been identified as a DDoS botnet, operating in a command and control fashion.\n- Free VPN software, such as Hola VPN, has been known to abuse client trust and resources.\n- The app has over 5 million installations on Android."
  },
  {
    "id": 36377875,
    "timestamp": 1687070151,
    "title": "Sennheiser HD 555 to HD 595 Mod",
    "url": "http://mikebeauchamp.com/misc/sennheiser-hd-555-to-hd-595-mod/",
    "hn_url": "http://news.ycombinator.com/item?id=36377875",
    "content": "aboutprojectsphotographythe cross canada projectmiscellaneousgiveaway: time fades awaysennheiser hd 555 to hd 595 modThis page will show you how to turn a $199.95 (Canadian \u2013 Suggested Retail) pair of Sennheiser HD 555 headphones into a pair of Sennheiser HD 595\u2018s that cost $349.95. And all you need is a screwdriver.IntroInstead of designing a completely new product to fit a certain price range, large scale manufacturing dictates that it is often cheaper to simply \u201ccripple\u201d an existing high-end product. This way the manufacturer can use existing molds, parts, assembly lines and training, etc. In electronic products, firmware is usually crippled to omit/hide certain features. For example, digital camera companies reserve functions (like RAW output, exposure and white balance bracketing, long exposures, etc.) for their higher priced cameras, even though their cheapest camera has the same capabilities (See the CHDK project for more info).Comparing HD555 to HD595Thanks to the people at head-fi.org, I was able to find someone willing to take apart their expensive HD595 headphones so I could compare them to my moderately priced HD 555 headphones. Here are the photos:What are the differences?Aside from the aesthetic differences, the only physical difference was an additional piece of foam inside the cheaper HD555 headphones, blocking about 50% of the outside-facing vents. Since both the HD 555 and HD 595 are designed to be \u201copen\u201d headphones, reducing the vent with this foam would alter the frequency response slightly. So to save yourself $150, open your HD 555\u2019s up and remove the foam. Done.How to do the modThe foam cushions are removed simply by pulling on them. From there, use a screwdriver to remove the driver assembly. Once open, remove the black foam stuck onto the back of the outside-facing vents and put everything back together. While you have the foam cushions off, it\u2019s a good time to give them a cleaning (damp cloth).Is that it?Yes. The actual sound difference is very slight, but it is noticeable. My guess is that the foam is there only to slightly alter the frequency response of the headphones so that the two models have their own \u201ccharacter\u201d and response curve when tested (some web sites actually graph this as part of their reviews, such as headphone.com). While both headphones sound good, the HD 595\u2019s preserve their more desirable flatter frequency response curve. It\u2019s this flatter frequency response curve that some people are willing to spend the extra money on, and Sennheiser know this.Quite a few people speculated in my Original thread that the more expensive HD595 headphones must also be using a more expensive driver. However, Head-fi member MCC posted the smoking gun; a picture of the original Sennheiser replacement driver labelled \u201cHD 555 / HD 595\u201d.Contact me if you can help compare other products. Thanks to \u201cIvant\u201d, \u201cMCC\u201d and others for all their help!Design & content by Mike Beauchamp. RSS",
    "summary": "- This post explains how to modify a pair of Sennheiser HD 555 headphones to have the same sound quality as the more expensive HD 595 headphones, saving $150.\n- The only physical difference between the two headphone models is an additional piece of foam inside the HD 555 headphones, which slightly alters the frequency response.\n- By removing this foam and cleaning the cushions, users can achieve a sound quality similar to that of the more expensive HD 595 headphones without the extra cost.",
    "hn_title": "Sennheiser HD 555 to HD 595 Mod",
    "original_title": "Sennheiser HD 555 to HD 595 Mod",
    "score": 584,
    "hn_content": "- The post discusses the difference between Sennheiser HD 555 and HD 595 headphones.\n- Some users speculate that the HD 555 received rejected drivers from the HD 595, while others argue that they could simply be drivers that didn't meet the same quality standard.\n- The discussion also mentions \"binning\" in the electronics industry, where processors and other electronics are categorized based on their quality.\n- The post references how AMD CPUs and graphics cards have been overclocked or unlocked through modifications.\n- The comment thread also includes discussions on product binning and matched pairs in the audio industry.\n- Some users express their preference for other headphone brands like Beyerdynamic and Audio Technica.\n- Others mention that the mentioned Sennheiser models are no longer being produced and suggest looking into other brands for headphones.\n- Some users discuss the concept of market pricing and how companies set prices based on what customers are willing to pay.\n- The topic of the Chi-fi (Chinese hifi) market is brought up and how it may influence the headphone industry in the future.- Some users are discussing the comfort of Sony MDR-7506 headphones.\n- Different users have different preferences for headphone brands and models.\n- Some users prefer wireless and noise-canceling headphones for certain activities.\n- A user recommends closed-back headphones for noisy environments and open-back headphones for studio mixing.\n- Some users share their experiences with expensive headphone setups.\n- Users discuss the benefits of AirPods and the convenience of wireless headphones.\n- Different users have different opinions about headphone brands and their quality.\n- Some users discuss the differences between open-back and closed-back headphones.\n- Users share their experiences with different headphone models and brands.\n- A user mentions the durability of Sennheiser headphones.\n- Some users have experienced sound leakage after removing the foam from headphones.\n- Users discuss the differences in sound quality between different headphone models.\n- Some users suggest conducting scientific headphone studies to evaluate sound quality objectively.\n- Users discuss the importance of considering individual ear shape and size when evaluating sound quality.\n- Some users recommend measuring frequency response to accurately assess headphone sound quality.\n- Users mention Linus Tech Tips as a reliable source for headphone testing.\n- A user recommends a specific headphone brand and model with a cheap USB DAC and equalizer for good sound quality without breaking the bank.",
    "hn_summary": "- The post discusses the difference between Sennheiser HD 555 and HD 595 headphones, with speculation on the origin of the drivers used.\n- The discussion includes mentions of product binning, market pricing, and the Chi-fi market's potential impact on the headphone industry.\n- Users share their experiences and preferences for different headphone brands, models, and features like wireless and noise-canceling capabilities."
  },
  {
    "id": 36378689,
    "timestamp": 1687081404,
    "title": "Jellyfin: Free software media system",
    "url": "https://github.com/jellyfin/jellyfin",
    "hn_url": "http://news.ycombinator.com/item?id=36378689",
    "content": "JellyfinThe Free Software Media SystemJellyfin is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it. We welcome anyone who is interested in joining us in our quest!For further details, please see our documentation page. To receive the latest updates, get help with Jellyfin, and join the community, please visit one of our communication channels. For more information about the project, please see our about page.Want to get started?Check out our downloads page or our installation guide, then see our quick start guide. You can also build from source.Something not working right?Open an Issue on GitHub.Want to contribute?Check out our contributing choose-your-own-adventure to see where you can help, then see our contributing guide and our community standards.New idea or improvement?Check out our feature request hub.Don't see Jellyfin in your language?Check out our Weblate instance to help translate Jellyfin and its subprojects.Jellyfin ServerThis repository contains the code for Jellyfin's backend server. Note that this is only one of many projects under the Jellyfin GitHub organization on GitHub. If you want to contribute, you can start by checking out our documentation to see what to work on.Server DevelopmentThese instructions will help you get set up with a local development environment in order to contribute to this repository. Before you start, please be sure to completely read our guidelines on development contributions. Note that this project is supported on all major operating systems except FreeBSD, which is still incompatible.PrerequisitesBefore the project can be built, you must first install the .NET 7.0 SDK on your system.Instructions to run this project from the command line are included here, but you will also need to install an IDE if you want to debug the server while it is running. Any IDE that supports .NET 6 development will work, but two options are recent versions of Visual Studio (at least 2022) and Visual Studio Code.ffmpeg will also need to be installed.Cloning the RepositoryAfter dependencies are installed you will need to clone a local copy of this repository. If you just want to run the server from source you can clone this repository directly, but if you are intending to contribute code changes to the project, you should set up your own fork of the repository. The following example shows how you can clone the repository directly over HTTPS.git clone https://github.com/jellyfin/jellyfin.gitInstalling the Web ClientThe server is configured to host the static files required for the web client in addition to serving the backend by default. Before you can run the server, you will need to get a copy of the web client since they are not included in this repository directly.Note that it is also possible to host the web client separately from the web server with some additional configuration, in which case you can skip this step.There are three options to get the files for the web client.Download one of the finished builds from the Azure DevOps pipeline. You can download the build for a specific release by looking at the branches tab of the pipelines page.Build them from source following the instructions on the jellyfin-web repositoryGet the pre-built files from an existing installation of the server. For example, with a Windows server installation the client files are located at C:\\Program Files\\Jellyfin\\Server\\jellyfin-webRunning The ServerThe following instructions will help you get the project up and running via the command line, or your preferred IDE.Running With Visual StudioTo run the project with Visual Studio you can open the Solution (.sln) file and then press F5 to run the server.Running With Visual Studio CodeTo run the project with Visual Studio Code you will first need to open the repository directory with Visual Studio Code using the Open Folder... option.Second, you need to install the recommended extensions for the workspace. Note that extension recommendations are classified as either \"Workspace Recommendations\" or \"Other Recommendations\", but only the \"Workspace Recommendations\" are required.After the required extensions are installed, you can run the server by pressing F5.Running From The Command LineTo run the server from the command line you can use the dotnet run command. The example below shows how to do this if you have cloned the repository into a directory named jellyfin (the default directory name) and should work on all operating systems.cd jellyfin             # Move into the repository directorydotnet run --project Jellyfin.Server --webdir /absolute/path/to/jellyfin-web/dist # Run the server startup projectA second option is to build the project and then run the resulting executable file directly. When running the executable directly you can easily add command line options. Add the --help flag to list details on all the supported command line options.Build the projectdotnet build            # Build the projectcd Jellyfin.Server/bin/Debug/net7.0 # Change into the build output directoryExecute the build output. On Linux, Mac, etc. use ./jellyfin and on Windows use jellyfin.exe.Running The TestsThis repository also includes unit tests that are used to validate functionality as part of a CI pipeline on Azure. There are several ways to run these tests.Run tests from the command line using dotnet testRun tests in Visual Studio using the Test ExplorerRun individual tests in Visual Studio Code using the associated CodeLens annotationAdvanced ConfigurationThe following sections describe some more advanced scenarios for running the server from source that build upon the standard instructions above.Hosting The Web Client SeparatelyIt is not necessary to host the frontend web client as part of the backend server. Hosting these two components separately may be useful for frontend developers who would prefer to host the client in a separate webpack development server for a tighter development loop. See the jellyfin-web repo for instructions on how to do this.To instruct the server not to host the web content, there is a nowebclient configuration flag that must be set. This can specified using the command line switch --nowebclient or the environment variable JELLYFIN_NOWEBCONTENT=true.Since this is a common scenario, there is also a separate launch profile defined for Visual Studio called Jellyfin.Server (nowebcontent) that can be selected from the 'Start Debugging' dropdown in the main toolbar.NOTE: The setup wizard can not be run if the web client is hosted separately.This project is supported by:",
    "summary": "- Jellyfin is a free software media system that allows you to manage and stream your media.\n- It is an alternative to proprietary platforms like Emby and Plex.\n- Jellyfin is built on the .NET Core framework, enabling cross-platform support and there are no premium licenses or hidden fees.",
    "hn_title": "Jellyfin: Free software media system",
    "original_title": "Jellyfin: Free software media system",
    "score": 559,
    "hn_content": "- Jellyfin is a free and open-source media system software that allows users to manage and stream their media files.\n- Users have praised Jellyfin for its ease of use and compatibility with various devices.\n- Some users have mentioned that Jellyfin lacks support for parsing Scene release names, but overall it does a good job recognizing media files.\n- Jellyfin has been compared to other media center options like Plex and Emby, with some users preferring Jellyfin for its open-source nature.\n- Users have recommended using additional tools like Sonarr, Radarr, Lidarr, and Prowlarr for automation and enhanced functionality.\n- There is ongoing development and improvement of Jellyfin, including the upcoming Jellyfin Vue, a new web interface.\n- Users have shared their experiences of migrating to Jellyfin from other media servers, citing reasons such as better control, open-source nature, and support for AMD/VA-API transcoding.\n- Some users have highlighted the challenges of running Jellyfin on certain operating systems, such as FreeBSD, but alternatives like Docker can mitigate these issues.\n- Individuals looking for an alternative to commercial media servers and seeking a customizable and open-source solution have shown interest in Jellyfin.- Kodi is a free, old-school media player that runs on multiple platforms.\n- Kodi and other media players have a library concept that duplicates files in your filesystem.\n- Fixing and cleaning file tags improves the user experience and makes it more like Netflix.\n- Windows has a file limitation issue with colons in filenames due to compatibility with old Microsoft protocols.\n- Jellyfin is a media server alternative to Plex, but users encountered some quirks and issues.\n- Some users find Jellyfin better than Plex, while others prefer the polished features of Plex.\n- There are some limitations with Jellyfin, such as no offline downloading on iPad and occasional logouts on the Apple TV app.\n- Plex offers additional features like intro skipping and better media organization.\n- Jellyfin does not require an account or subscription and does not have ads.\n- Jellyfin is open-source, which means users can customize and contribute to its development.\n- Jellyfin is a good alternative for those who prioritize freedom and open-source software.\n- Commercial software like Plex offers a higher quality experience and ongoing development with a lifetime pass option.\n- Some users prefer open-source software due to concerns about commercial software being abandoned or changing for financial reasons.\n- There is no screenshot of Jellyfin running on the GitHub page, but there is a demo available on the official website.\n- The demo requires the username \"demo\" and no password.",
    "hn_summary": "- Jellyfin is a free and open-source media system software that allows users to manage and stream their media files.\n- Users have praised Jellyfin for its ease of use and compatibility with various devices.\n- Jellyfin has been compared to other media center options like Plex and Emby, with some users preferring Jellyfin for its open-source nature."
  },
  {
    "id": 36377805,
    "timestamp": 1687069284,
    "title": "I have received a $100k sponsorship for Ladybird browser",
    "url": "https://twitter.com/awesomekling/status/1670298370550779905",
    "hn_url": "http://news.ycombinator.com/item?id=36377805",
    "content": "Thread ReaderOne-click sign-up and loginSign up or login to access your unrolled and bookmarked threads (or PDF archives if you are a Premium member!)Login with TwitterLogin with EmailLogin above to accept Thread Reader App'sTerms of Service and Privacy PolicyHelp | About | TOS | Privacy | Twitter Files",
    "summary": "- The article discusses the receipt of a $100k sponsorship for the Ladybird browser.\n- The Ladybird browser is a web browser that has recently gained popularity.\n- The sponsorship represents a significant financial contribution that will likely support the development and improvement of the Ladybird browser.",
    "hn_title": "I have received a $100k sponsorship for Ladybird browser",
    "original_title": "I have received a $100k sponsorship for Ladybird browser",
    "score": 520,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginI have received a $100k sponsorship for Ladybird browser (twitter.com/awesomekling)520 points by samwillis 1 day ago | hide | past | favorite | 154 commentsakling 1 day ago | next [\u2013]Hello friends! I am very excited about this indeed :)If you\u2019d like to know more about Ladybird, I did a presentation about it at the Web Engines Hackfest in Spain just two weeks ago: https://youtu.be/De8N1zrQwRsreplysamwillis 19 hours ago | parent | next [\u2013]Andreas has just had a second one!> In a surprising twist, I have just received a second $100,000 sponsorship for Ladybird development!> This one came in the form of an anonymous cryptocurrency donation, so now I need to talk to my tax accountant ASAP and figure out what to do..https://twitter.com/awesomekling/status/1670440822129532928replymarginalia_nu 12 hours ago | root | parent | next [\u2013]I guess it has to be the same guy feeling generous, but I just got a driveby dono of $100,000 in crypto as well :Oreplyeep_social 10 hours ago | root | parent | next [\u2013]!!Congrats! Sounds pretty amazing coming right on the heels of your decision to go full time. I have so many questions \u2014 hope you\u2019ll put out an update when you\u2019re done celebrating ;)replymarginalia_nu 20 minutes ago | root | parent | next [\u2013]Yeah it's very generous and amazing. ... although, like Andreas I have some things to figure out in terms of how to liquidate the asset.Swedish banks really don't like crypto, to the point where I've had trouble charging for API access because I couldn't prove the money wasn't from crypto :-/I have some old friends who are deep into that world, gonna have to see what advice they have. Still, as far as problems go, it's a nice problem to have I guess.replyIntermernet 18 hours ago | parent | prev | next [\u2013]Congrats Andreas! I'm hoping that we see Ladybird become a contender in the browser space and in 10 years the browser landscape is once again diverse!Of course this means that in 20 years we will probably have another stagnated monoculture based on some weird 3rd party, hostile corporate fork of Ladybird, but by that time you will hopefully own a venture capital firm and will be happily sipping mojitos in the Bahamas, and the cycle shall begin again ;-)replyDANmode 15 hours ago | root | parent | next [\u2013]> you will hopefully own a venture capital firm and will be happily sipping mojitos in the Bahamas, and the cycle shall begin again ;-)Or he could just be comfortable, and the product could keep delivering the same thing, with incentives mostly aligned on all sides.Not to bring negativity to the thread, but it's certainly possibly to do better than what you've described as a tongue-in-cheek norm.replyuserbinator 1 day ago | parent | prev | next [\u2013]As someone who has also been attempting to write a minimal browser in my free time, and so far has made much less progress, I fully support your fight against Big Browser.replyNovaDudely 1 day ago | parent | prev | next [\u2013]Whenever I see your stuff it is always so cool. Im also glad to see everyone still going at it years down the line. Now that there is decent money to back it up it so much better!Party on!replybArray 19 hours ago | parent | prev | next [\u2013]Hello there, great work! I have been following since a long time, back when you were on Freenode IRC. If you do bridge your Discord to IRC, please do announce it somewhere.One suggestion: maintain your compatibility with Linux, as this would likely bring more people to your browser and lower the barrier to work on the browser.replysamwillis 1 day ago | parent | prev | next [\u2013]Congrats Andreas. What you are building is incredible, both from a technological point of view but also for education and inspiration. That influence you can spread for me is the thing that is most exciting about the project!replyChickeNES 23 hours ago | parent | prev | next [\u2013]Is there a chance of an embeddedable/library version in the future? I think there are a lot of places where it would be useful, plus it would allow ports to more esoteric systemsreplyroetlich 23 hours ago | root | parent | next [\u2013]I guess the library part is LibWeb: https://github.com/SerenityOS/serenity/tree/master/Userland/...replyyafetn 23 hours ago | parent | prev | next [\u2013]Hi Andreas, when are we getting the next batch of \u201cFIXME Roulette\u201d videos? They\u2019re the most entertaining yet educational debugging videos out there.replylemper 1 day ago | parent | prev | next [\u2013]Andreas my guy! congrats! and I'm sure many people have asked this request: please integrate adblocking to Ladybird.replyvkoskiv 18 hours ago | root | parent | next [\u2013]Basic pattern-based content filtering is already built right into LibWeb[1]. I spot 851 patterns that get filtered currently [2].1: https://github.com/SerenityOS/serenity/blob/master/Userland/... 2: https://github.com/SerenityOS/serenity/blob/master/Base/home...replyDexesTTP 18 hours ago | root | parent | prev | next [\u2013]Well, good news about that, a simplified version of adblocking through content filtering[0] is already part of Ladybird (and has been part of Browser[1], the version of Ladybird integrated in Serenity, for a while). There is even a video[2] where Andreas implemented it![0] https://github.com/SerenityOS/serenity/blob/master/Ladybird/...[1] https://github.com/SerenityOS/serenity/blob/master/Userland/...[2] https://www.youtube.com/watch?v=Jc22wPqpaBQreplydeoxxa 1 day ago | parent | prev | next [\u2013]I just want a browser that tastes like a real browser!replySahAssar 17 hours ago | parent | prev | next [\u2013]Hey, I tried to contact you (via twitter since I couldn't find an email) about if you would be interested in doing a talk at \u00f6redev about ladybird a few months back. I assume the lack of a reply meant you weren't interested, but if that wasn't the case and it was just drowned out in your notifications let me know :)replymatheusmoreira 18 hours ago | parent | prev | next [\u2013]Congratulations, I wish you massive success.replymysterydip 22 hours ago | parent | prev | next [\u2013]Awesome and well deserved! One of my favorite projects.replywila 22 hours ago | parent | prev | next [\u2013]That was a great presentation. Now I'm going to have to try Ladybird :DreplyLeFantome 23 hours ago | parent | prev | next [\u2013]Huge thank you for SerenityOS, Ladybird, and maybe Jakt at some point.Did this sponsorship result from your presentation?replyprox 1 day ago | parent | prev | next [\u2013]Akling, I hope you keep doing inspiring work! Thank you for your contributions!replyRiverheart 20 hours ago | parent | prev | next [\u2013]Hey akling, since you\u2019re building a browser I\u2019ve got to ask, do you have any thoughts on https://htmx.org/ or whether it could be supported as part of some extension to Ladybird?replyrmuratov 20 hours ago | root | parent | next [\u2013]I thought htmx is just a library, does it need support by the browser?replyRiverheart 14 hours ago | root | parent | next [\u2013]The htmx library emulates what would be possible if browsers supported gets/posts on other html elements like buttons. It\u2019s a library because no browser supports this natively.replyDANmode 15 hours ago | root | parent | prev | next [\u2013]Make it natively supported, watch it catch on like wildfire if the browser gets any traction with devs.replyrecursivedoubts 11 hours ago | root | parent | next [\u2013]@akling i'd be happy to chat about this if you are interested in extending HTML as a hypermedia. I'm the creator of htmx, and I don't think it should have to exist: it's what HTML should have evolved into.replyjraph 1 day ago | prev | next [\u2013]Ladybird looks amazing. Just as I was losing faith that building a browser from scratch today was an almost impossible task that only a big company could pull off, they proved otherwise.I compiled it and added packages to install on openSUSE for this in the readme... which was easy because you don't need much to build this browser! And it builds in a few minutes.I wish Discord was not mandatory to interact with the community (because I strongly believe in [1]). I will not use Discord so interacting with the community might be complicated if I ever want to work on it.Anyway, may Ladybird thrive.[1] https://drewdevault.com/2022/03/29/free-software-free-infras...replysimonw 23 hours ago | parent | next [\u2013]I resisted starting a Discord for my open source projects for years.With hindsight that was a mistake. I finally created one a year ago and it had a huge impact on the velocity of the project - I now have active engagement with users and a growing pool of contributors and collaborators, all thanks to that group.I think often it's important to prioritize reducing friction to getting involved over (very rational) reservations about the platforms themselves.replyandybak 23 hours ago | root | parent | next [\u2013]How do you feel about the fact that all your institutional knowledge is now not visible outside of Discord, not indexed and barely searchable?How do you feel about the fact that the long-term survival of this knowledge is at the whim of a company that is mostly focused on the gaming community and has no vested interest in preservation over longer time periods?When was the last time you found an answer to a question from an ancient newsgroup or mailing list that's archived on the open web? It happens to me fairly regularly.(for context, I help maintain a Discord for an open source project and I feel like I'm betraying the web as an ideal - and constanty wish we had chosen differently)EDIT - I didn't look to see who I was replying to. Simon -not you of all people! I'm less concerned about your specific community than I am about the example you're setting and the the fact you're lending your voice to support a worrying trend that affects the long-term health of open source.replymarcinzm 21 hours ago | root | parent | next [\u2013]My experience with semi-private chats in modern times is that it encourages more conversation that are visible to more people since everything people say is not going to be trivially searchable for all time by anyone. In the age where the media and those with an axe to grind (and frankly the person interviewing you for a job in 10 years) have figured out how to dig up anything you ever said in under 10 minutes the web ideal is less than ideal. Part of learning is saying stupid things and semi-private forums makes that easier I feel.replyavian 19 hours ago | root | parent | next [\u2013]> it encourages more conversation that are visible to more people since everything people say is not going to be trivially searchable for all time by anyone.It also encourages more people to be assholes in my experience. I'm sure there are well moderated chats out there associated with open source projects, but I had several such abysmal experiences with Discord in the past that I'm completely done with it.replyandybak 19 hours ago | root | parent | prev | next [\u2013]I'm more concerned about the people that need help with something, but don't ask on Discord for any number of reasons.I suspect 1000 people use Google to solve a problem for every 1 that joins a Discord and asks.replymarcinzm 18 hours ago | root | parent | next [\u2013]That depends. Would you take a public forum where no one ever answers questions and fixes are never implemented and the contributors feel burned out, or a Discord where questions do get answered? The OP clearly said their project got significantly more involvement since moving to Discord. The problem with lack of community involvement is that it puts more work on the contributors which means less questions are answered and burnout is much more likely.replyandybak 17 hours ago | root | parent | next [\u2013]> Would you take a public forum where no one ever answers questions and fixes are never implemented and the contributors feel burned out, or a Discord where questions do get answered?I don't understand why these are the only choices offered. In fact - they feel fairly orthogonal. There's nothing about Discord that makes supporting a community easier - in fact I would argue it's demonstrably worse than many alternatives. It feels like an accident of history that's led to it's ascendency.As someone that does maintain a community. I'd much prefer to have something Reddit-like (structured around topics, asynchronous). I find chat-style to be good for... well... chatting. And worse for everything else.replyeropple 17 hours ago | root | parent | next [\u2013]> There's nothing about Discord that makes supporting a community easierIt exists, it requires minimal competence or attention to technically administer, and it provides adequate (though not great) tooling for moderation (which is then significantly improved at scale with third-party tools). It also provides a unifying umbrella with a single set of affordances where everything is, from shitposting friend groups to technical projects.IRC exists, at least in a technically-correct-is-the-best-kind-of-correct sense. It requires nontrivial competence and attention to technically administer (and like, I wrote an IRC server once and still don't ask me to tell you, or to give a damn, what the alphabet soup of flags does). Moderation is actively bad, helped only by it being sufficiently annoying to get onto IRC that you probably are putting up a \"you must be this tall to ride\" gate.It also just sucks to use. Phones exist and supporting them adequately is not optional in 2023. Bouncers are not a solution, they are an additional problem.There's also limited space in people's brains for all the alternatives. Most people seem to find that That One Friend Who Uses Telegram (or Signal, or WhatsApp) when everybody else you know is on the Signal (or Telegram, or WhatsApp) island to be drifting away--it's not dissimilar. This also ejects Zulip--which is quite nice, IMO--and Mattermost-- which is not--and similar because when you've already got Slack and Discord fighting for cognitive space, a third option had better be step-change better, and they're not.> It feels like an accident of history that's led to it's ascendency.Sure? It was good enough, soon enough. Other things weren't good enough or soon enough.> I'd much prefer to have something Reddit-like (structured around topics, asynchronous). I find chat-style to be good for... well... chatting. And worse for everything else.Great, but most people...don't, and it's not hard to understand why. Chat has won because the world is an increasingly frustrating place and people have steadily decreasing ability to care about fucking with stuff. Forums are, for the most part, fucking with stuff. And worse: it's fucking with stuff for an unclear payout with regards to the thing that the prospective visitor cares about.Other people don't care about your stuff as much as you care about your stuff, and that's not a dig, that's just how people's brains work. You can go stand alone, and appeal to the sliver who want to deal with creating an account and validating an email address and figuring out where the reply button is (oops it was the post button, now I created a new thread and people think I'm a rude jerk)...or you can use the thing everybody already does use, understands, and at least is willing to tolerate.Unless you have a forum that has a genuine raison d'etre to stand alone as a thing, and are willing to consider a low-cut filter a feature of your community, it's a bad choice. And if you do qualify for those maybe it's a great choice, but most things simply do not.Something Awful provides a real reason to be a distinct thing. Most other attempts at forums don't, regardless of topic.replyfragmede 13 hours ago | root | parent | prev | next [\u2013]That's a helluva false dichotomy you've got going on there. How about a forum that shows up in the search results in Google when I ask it about my problem? Without me needing to bother or wait for someone else to respond, especially if it's the middle of the night.My kingdom for a Discord bot to slurp up all the messages and LLM me an FAQ.replyskinnymuch 19 hours ago | root | parent | prev | next [\u2013]Discord servers aren\u2019t fully private. Messages can be extracted. Neither Google nor Discord need to officially do anything. The people of Discord servers can decide how info can be publicly shared. There are nuances to care about like people\u2019s privacy and comfort.replyandybak 19 hours ago | root | parent | next [\u2013]It's worth repeating the maxim \"Defaults Matter\". It's a fair bit of effort to mirror Discord to the web, and it's unclear whether it's officially frowned upon. Add to that the nuances you refer to and the end result is lots of valuable knowledge that will never be preserved, will rarely be found and will one day disappear.replyskinnymuch 15 hours ago | root | parent | next [\u2013]Those all seem like good things to me. Not the loss of knowledge being mainstreamed but the trade offs. An ultimate goal for knowledge doesn\u2019t usually go well from my limited experience.replymid-kid 13 hours ago | root | parent | prev | next [\u2013]Running a discord server for an open source project, I very much echo this feeling. I came after the discord server's creation, and the best I can do is help keep the IRC open and advocate that we keep the server on the lowest security level so people without accounts can join (in the odd case that feature actually works - it's very strictly behind captchas and IP rangebans, and desktop-only). Getting people off the platform and moving elsewhere is not an option, even if I had full decision-making power.But it's a question that constantly weighs on my mind. There's a lot of knowledge and information archived in the server, and it's really not easily findable without knowing to look in the discord server. Opening a second Q&A site would mean nobody would ask there, as the barrier to entry and use would be too high (even if it had a discord login). Using github discussions binds us even closer to github (they can't be exported), and I'm not comfortable with that either.I would love to see a service appear that allows us to publish discord forums on the net. I feel this is the closest thing we can do to something that would actually spark change. Discord's forum system is absolutely rancid compared to everything else, but my biggest priority is getting the information out there and at least slightly ordered. I feel this would encourage the most people to actually use it.replyyrro 22 hours ago | root | parent | prev | next [\u2013]Have you considered logging what's said in each channel and publishing it to your project's web site?replymoneywoes 20 hours ago | root | parent | next [\u2013]i have a rough prototype of this if anyone with a Discord is interested in trying it out email in bioreplykeb_ 22 hours ago | root | parent | prev | next [\u2013]That makes me think, has anyone created a Discord bot that automatically archives chats? Preferably as HTML files similar to Pidgin? That would be great.replypocketarc 21 hours ago | root | parent | next [\u2013]I've thought about this in the past, it's not difficult to do. I've used the Discord API in the past, you can listen to literally all messages that happen in the server. Streaming those into a DB and displaying them in a web-based UI (with Pidgin-like HTML export) would be straightforward. Maybe that'll be my next weekend's project.Edit: My sibling mentions the appropriateness of such a thing, and I do think letting users know that their messages will be posted on the web is important, but either way, if it's a public channel of a FOSS project's Discord server, surely people understand that those messages aren't private to begin with, right?replymid-kid 13 hours ago | root | parent | next [\u2013]> surely people understand that those messages aren't private to begin with, right?For some reason, this is really hard for people to get. The discord company is super paranoid about scraper bots joining through public links, and people themselves are continuously in awe when someone digs up an old message about whatever, asking the mods to ban them for doxing.I completely agree with the sentiment, however, and I think it should become more socially acceptable for some chats to be viewable online, like forums used to be back in the day. Even then, people would close certain subforums off from appearing for people without an account (e.g. in public searches). As it stands, however, people are not comfortable with this because nobody is doing it.replyyrro 13 hours ago | root | parent | next [\u2013]It would be wise to disclose that messages are archived publicly. But you also don't need to archive the identity of everyone in the chats, you can replace their usernames with generic identifiers in the public archive.replymid-kid 13 hours ago | root | parent | next [\u2013]Well, yeah. I wouldn't do it behind people's backs, but I'm pretty sure people would protest, and new people would miss the message no matter how big you make it in the introduction channel.replyandybak 21 hours ago | root | parent | prev | next [\u2013]I suspect it's against the Discord TOS - but even if it's not there's a bunch of community expectations to manage. For recent forums we've added a disclaimer to the channel discription notifying people that we might make the contents web public at some point.Discord also encourages certain usage patterns that are unhealthy. Threads are rarely used and have poor discoverability, search is incredibly limited etc.replyFrotag 18 hours ago | root | parent | next [\u2013]Someone stirred up a bit of drama doing something similar a few years ago. The biggest difference is that they were selling it and harvesting it without any consent from users or server admins.https://web.archive.org/web/20221205181242/https://www.reddi...replypabs3 4 hours ago | root | parent | prev | next [\u2013]Pidgin supports Discord, so you could simply republish Pidgin HTML log files.replySecretDreams 22 hours ago | root | parent | prev | next [\u2013]> How do you feel about the fact that all your institutional knowledge is now not visible outside of Discord, not indexed and barely searchable?No different than an office workspace no?replyandybak 21 hours ago | root | parent | next [\u2013]Discord is a replacement for IRC, forums and mailing lists - not for hanging out in meat-space.replySecretDreams 19 hours ago | root | parent | next [\u2013]The Internet is moving towards a meat place replacement.replytharne 18 hours ago | root | parent | next [\u2013]Pretty sure that COVID showed the exact opposite. Our brains evolved in the meatspace and won't be happy anywhere else.Even the success of remote work shows this. People want to avoid the office (and the commute) to get more time with friends, family, and their hobbies. The internet is most successful when it helps people live the life they want in the meatspace, not when it tries to replace it.replyhardware2win 21 hours ago | root | parent | prev | next [\u2013]Is IRC google searchable?replyharrisi 20 hours ago | root | parent | next [\u2013]In my experience, there is usually some percentage of people that archive whatever channels they use. Sometimes they will put them up on a website.There's also nothing stopping anyone from doing that, and it's quite easy. I've always just had irssi running on some server that archives everything and I ssh into the server when I want to chat.replycalvinmorrison 20 hours ago | root | parent | prev | next [\u2013]if you hung out in channels there would often be a log botIf it was a channel with a lot of users, also a general bot would often exist.For example you could call up faqs easily on say systemd in Debian by just hitting !systemdYou could add to the faqs on the flyAll faqs were synced back to the website.So we're just reinventing the wheel herereply3np 20 hours ago | root | parent | prev | next [\u2013]In case you're not aware, as an operator/mod/admin it's fairly straight-forward to bridge a Discord channel to Matrix (and, if one so desires, from there to IRC), allowing users not on Discord to participate. Conservative mods concerned about spam can start with an allowlist for which servers can join.https://github.com/matrix-org/matrix-appservice-discordreplyheywoodlh 17 hours ago | root | parent | next [\u2013]In addition, it's also easy to use something like Matterbridge[0] to bridge Discord to other apps!I do this for one of my projects as I find that Discord is where a lot of people are, and people find it accessible. But for those of us who do not love the closed ecosystem, it's nice to have alternatives.[0] https://github.com/42wim/matterbridgereplylazylion2 20 hours ago | root | parent | prev | next [\u2013]Andreas had a similar situation. its just really practicalreplytroad 1 day ago | parent | prev | next [\u2013]Very strong agree re Discord. Quite apart from Drew's ideological reasons to oppose Discord, with which I quite agree, I also tend to find that (a) busy group chats are not a great way to coordinate software development, and (b) the kinds of communities Discord is structurally designed to foster really don't tend to be communities I wish to be part of.I am a big fan of kling and his work on Ladybird though, and I wish the project the absolute best.replydurandal1 23 hours ago | root | parent | next [\u2013]Andreas seems like a guy that is more interesting in building stuff than ceremony/principles around how to build stuff. Which is probably why he has founded a highly productive community.replytester756 1 day ago | parent | prev | next [\u2013]>Just as I lost faith that building a browser from scratch today was an almost impossible task that only a big company could pull off, they proved otherwise.I feel like just intersection of people who know how web / webbrowser works and know how to write compilers is relatively lowlike both of those independently are rarereplyeropple 17 hours ago | parent | prev | next [\u2013]> I wish Discord was not mandatory to interact with the community (because I strongly believe in [1]).While I understand this preference and am sympathetic to it, I hope this means that you're doing the (heavy, thankless) work to make IRC or mailing lists more reasonably usable for a modern audience on modern devices.Email's problem is mostly just that email has been rendered almost useless by bad affordances across the board and the general disregard for signal-to-noise, but IRC manages to even be worse. I have a phone in my pocket; I expect continuous connection and history. No, I'm not going to start a bouncer. No, I'm not going to pay somebody else to do it. And no, I'm not going to start a history-archive bot so I can see what I missed.People moved because these tools are inadequate. Maybe somebody wants to make those tools better, but I don't see it happening at the scales necessary to make these more than but-for complaints.replychubot 16 hours ago | root | parent | next [\u2013]Zulip has a better and faster interface than Discord IMO, and it's published under the Apache 2 license, making it free software:https://github.com/zulip/zulipI've been using it at https://oilshell.zulipchat.com/ for over 5 years now, it's greatreplyeropple 16 hours ago | root | parent | next [\u2013]As I mentioned in a sibling, I quite like Zulip. But its problem is pretty simply that people have limited attention span, willingness to change, and most people in the tech space already have Slack on the brain and Discord is probably at least passingly familiar.Asking people to put up with a third thing--a third set of ways to do things, a third app on the taskbar or on the phone--is asking a lot of people in the current hellscape. (It's a lot like how most groups just quietly let that one person who only uses Telegram and won't use Signal/WhatsApp/the group preference du jour...drift away.) That's not Zulip's fault, but also kind of disqualifying unless you consider that filter a feature. And if that's a feature to you, your desire for a community is probably nontrivially smaller and stubbier than that of folks who are using Discord in the first place.replychubot 13 hours ago | root | parent | next [\u2013]FWIW I worked in software for 14 years, and never used Slack or Discord, so I wouldn't be so quick to generalize\"Everybody else is doing it\" is a weak argument\"Everyone else\" isn't building a browser from scratch -- it's more important what those people are doing and usingreplyuserbinator 1 day ago | parent | prev | next [\u2013]I compiled it and added packages to install on openSUSE for this in the readme... which was easy because you don't need much to build this browser! And it builds in a few minutes.Did you also make this post from it?I wish Discord was not mandatory to interact with the communityAgreed. My preference is IRC or even mailing lists.replyjraph 23 hours ago | root | parent | next [\u2013]> Did you also make this post from it?Nope! Apparently it does not like the textarea used to reply to a comment on HN.replydougall 22 hours ago | parent | prev | next [\u2013]Is there a reason you call out Discord and not GitHub?replyjraph 13 hours ago | root | parent | next [\u2013]The reason is that I'm trying to keep my messages effective. If I complain against everything at the same time, I risk being ignored.I don't like the closed nature of GitHub neither. I hope the free software world move away at some point.The open source world can't seem to avoid locking itself in those closed tools, I would really like if we stopped doing this.I chose Discord because I see it as a bigger issue than GitHub, with which one can interact with standard tools like emails and git, and basic stuff work without JS. So one can both refuse to run non-free code and interact with GitHub. Still not ideal and concerning.Try to go back to the early 2000s and tell someone that the open source world is going to trust MS to host all their stuff. You would probably have difficulties to be taken seriously.(Although it is to be noted that back then many people used SourceForge which was also proprietary)replytoastal 18 hours ago | root | parent | prev | next [\u2013]Absolutely fair to call out both on similar grounds on openness and privacy being proprietary (publicly-traded megacorp vs. VC funded). One difference would be at least GitHub results can be found with a search engine and without authentication (though you cannot use the search for \u201cCode\u201d without an account).replythih9 1 day ago | prev | next [\u2013]More information about the Ladybird browser:https://awesomekling.github.io/Ladybird-a-new-cross-platform...Github repo:https://github.com/SerenityOS/serenity/tree/master/Ladybirdreplymarginalia_nu 1 day ago | prev | next [\u2013]Fantastic! Well deserved!It's the exactly right type of project. High profile and high impact. The status quo of the software industry needs to be shaken up, and this has the potential to be exact right sort of rude awakening.The fact that solo devs or small teams on a shoestring budget are time and time again shown to be surprisingly competitive with billion dollar companies retaining supposedly the best and brightest in the world is undeniably egg on their face.It raises concerning questions about the entire industry, how we do things when we build software, where money is flowing.replybadpun 1 day ago | parent | next [\u2013]Ladybird is currently far from competetive. Andreas himself told that his loose goal for Ladybird is to be able to render YouTube page correctly and play video with sound - 5 years from now.replymarginalia_nu 1 day ago | root | parent | next [\u2013]I'm looking mostly at what it could be. Ladybird has every potential of becoming the Linux of web browsers. And it took Linux what, over a decade to mostly displace the competition in the server space.These types of projects are long term, but public perception matters. Making waves matters. The audacious possibility that it might just succeed matters.replynicoburns 1 day ago | root | parent | next [\u2013]Isn't Firefox already the Linux of web browsers?replyLeFantome 23 hours ago | root | parent | next [\u2013]As a multi-decade long Firefox user, I am going to say no.Firefox is produced by a single company and its users are completely beholden to the choices that the company makes.In some ways, Chromium is closer to being the Linux of browsers. There are multiple \u201cdistributions\u201d or instances of the technology ( Chrome, Edge, Brave, and others ). There is at least some collaboration on the core.Chromium is not developed nearly as collaboratively as Linux though and certainly it is dominated by Google.What we need is something like Ladybird which is community driven prior to corporate involvement and that is led by that community and not by a company.Not that we have not lost this opportunity before. KHTML was community driven before Apple co-opted it for WebKit which Google later forked to Blink.Ladybird is perhaps already in a better spot being cross-platform vs only the browser in SerenityOS. It is also a \u201ccomplete\u201d project with JavaScript and multimedia already built in. Let\u2019s work to keep the project together as a browser and not chase bits of it getting ripped off and taken elsewhere.replySakos 23 hours ago | root | parent | next [\u2013]Agreed. There are far more differences/changes between Chromium-based browsers than Firefox ones (which just remove Mozilla telemetry or provide a way to use old-style extensions). It really was a huge shame that they chose to base Edge on Chromium instead and I feel it points to clear issues in Firefox that prevent it from being the Linux of browsers.I do wonder what's so wrong with FF that nobody wants to base their fork on it.replyY_Y 21 hours ago | root | parent | next [\u2013]> I do wonder what's so wrong with FF that nobody wants to base their fork on it.It's compatibility. I use Firefox now it less exclusively, and sometimes I'll need to go on some \"normie\" website to book a flight or something and the Continue button will be broken or some shit. Seems like lots of web devs will just make the sure works in Chrome and call it a day.replytharne 18 hours ago | root | parent | next [\u2013]> sometimes I'll need to go on some \"normie\" website to book a flight or somethingI have ungoogled chromium installed alongside firefox for exactly this reason. A lot of mainstream sites clearly do not care about supporting other engines.replyYoshiRulz 12 hours ago | root | parent | prev | next [\u2013]I find that faking a Chrome User-Agent works in half of those cases, YMMV.replyDANmode 13 hours ago | root | parent | prev | next [\u2013]If you're going to start less secure than state of the art, why not fork state of the art, or start your own?This appears to be the mindset, anyway.replycalvinmorrison 20 hours ago | root | parent | prev | next [\u2013]Nobody cares there's only one implementation that's really used widely for Java. I don't see why I should care what VM is used for the web. Chromium can be that and you can build whatever tooling on top to interact with that VMreplymarginalia_nu 19 hours ago | root | parent | next [\u2013]I think this argument would have credibility if it wasn't for the fact that Google is ostensibly waging a war against the ability to extend the browser in any way that harms their ads business (with Manifest v3).Google has a massive conflict of interest with the free and independent web in a way that Oracle does not have with the ability to build and run arbitrary Java applications.replymarginalia_nu 1 day ago | root | parent | prev | next [\u2013]Given Firefox is primarily funded by Google handouts ostensibly as token competition to keep antitrust suits off their ass, I wouldn't say so.replytannhaeuser 22 hours ago | root | parent | next [\u2013]I'd say to keep antitrust suits off their ass is even too strong a formulation ;) considering US antitrust is what has led the acquisition of DoubleClick and YouTube by Google happen (and that of WhatsApp by Facebook). Time to hold those responsible for this ... responsible.replymarginalia_nu 22 hours ago | root | parent | next [\u2013]Keep in mind Microsoft was a legal technicality away from being broken up. Lessons were learned from that.replydmytrish 23 hours ago | root | parent | prev | next [\u2013]It's the SunOS of webbrowsers. Chrome is technically opensource too.replybadpun 1 day ago | root | parent | prev | next [\u2013]Linux is Linux thanks to large involvement of big tech. It remains to be seen if any Big Tech companies would be interested in seriously supporting development of an open source browser.replymarginalia_nu 23 hours ago | root | parent | next [\u2013]Big tech used Linux to wage a proxy war against Microsoft from a safe distance without needing to actually commit to anything.Linus Torvalds had nothing to his name when he started working on Linux. He was just some kid from Finland, but the audacity the project gave it attention and visibility, and visibility came with funding.I think in general a hint of audacity along with being able to demonstrate capabilities to follow through is a great recipe for having people throw money at you, and the more money you have to work with, the more options you have to keep demonstrating what you can do.A lot of people have a vested interest in shaking up the tech world. It's just a matter of finding the right fuses to light.replyabnercoimbre 20 hours ago | root | parent | next [\u2013]> A lot of people have a vested interest in shaking up the tech world.I'd imagine you're one of us, considering you went full-time on your search engine :)We had Andreas demo his OS / browser [0] at Handmade Cities [1]. These conferences are what I run full-time independently. I'm excited to see a flourishing of audacity, so to speak![0] https://vimeo.com/641406697[1] https://handmadecities.comreplymarginalia_nu 19 hours ago | root | parent | next [\u2013]Yeah. Andreas is an inspiration and a trailblazer, and although we're on slightly different journeys, we have similar ambitions I think :DIt's weird, it's become this truth in software development that one should lower their ambitions, try to do something small and not overextend. Don't try to reinvent the wheel, stay in your lane.Which I guess is sage advice for a beginner, but I think it sort of stuck with the developer hive mind and as a result, what you get is these small low-impact projects instead of this kind of a moonshot.While I don't think just anyone could make a browser or a search engine, I also don't think most who could would ever think to try because of these self-imposed limitations.replysamwillis 1 day ago | root | parent | prev | next [\u2013]> It remains to be seen if any Big Tech companies would be interested in seriously supporting development of an open source browser.You're missing a \"new\" or \"another\" in that sentence.replyblinkingled 18 hours ago | prev | next [\u2013]I have been following Andreas' YT channel for ~8 months now and it's been fun - miss the Car talk ones lately but the live bug fixing, the updates and how he has pulled himself out of some dark times - it's all very inspiring. IOW 2x100k would not possibly have gone to a better guy!He does this all for fun and even if Ladybird doesn't become the #1 browser the learnings in developing a x-platform browser in themselves would make this all worthwhile!replyBiteCode_dev 1 day ago | prev | next [\u2013]An actual new browser engine that is not based on Chrome. Wow.And now with money. That's something I really didn't expect to see anymore.replyducktective 1 day ago | prev | next [\u2013]The more browser engines, the better. It doesn't use neither Chromium nor Gecko.replysilisili 1 day ago | parent | next [\u2013]Small nit: this reads in English as a double negative. It's easier to picture if you think of neither as 'not either.'Perhaps 'it uses neither' or 'doesn't use either.'replystjohnswarts 18 hours ago | root | parent | next [\u2013]You don't need either or neither to get the same point across. \"It doesn't use Chrome or Gecko\" works just fine :)replytannhaeuser 1 day ago | prev | next [\u2013]Congrats! Considering HTML but mostly CSS complexity is expanding all the time as we speak (discussed on the HN front page right now [1]), are there points to be addressed at the likes of W3C, Inc and github.com/whatwg to make your work easier or even possible? Such as versioned CSS specs/CSS profiles (subsets), test suites aligned with CSS or HTML versions, test suites usable without JS (eg web-platform-test for CSS requires in-browser scripting last I checked), formal specifications/better algorithmical layout descriptions, etc? Are you targetting specific HTML versions such as WHATWG's preview drafts/snapshots?Good luck with your project! Maybe naming your sponsors can help to get even more contributions and contributors?I can offer some help/advice with HTML parsing, but I guess you have figured that one out and are following the procedural parsing description, whereas my expertise would be the SGMLisms on which it is based (and its minute re-construction from the HTML5 spec).[1]: https://news.ycombinator.com/item?id=36375582replyuserbinator 1 day ago | parent | next [\u2013]but mostly CSS complexity is expanding all the time as we speakThat's the biggest problem facing new browser implementations, and IMHO it's deliberate. Probably 99% of sites out there do not need any of the new crap that gets constantly added to the \"standard\", but continued propaganda by those constantly in power will practically guarantee that they will, under some guise of \"progress\" or \"modernity\". WHATWG is basically controlled by Big Tech (and was created because they didn't like the W3C's approach to stability) and popularised the idiotic oxymoron \"living standard\". Constant churn is how they're trying to maintain their monopoly, because they have the sheer manpower to outrun competitors.replytannhaeuser 23 hours ago | root | parent | next [\u2013]I agree in principle; a reasonable spec that doesn't change all the time is what's needed for supporting next-gen browser development (as in inspire a new generation). But that's not what's happening at all; collaborators of github.com/whatwg even welcomed the rejection of HTML profiles/subsets and target device classes when the idea was brought up by MS (to save IE, but still ;)But the ones responsible for the piece of shit that is CSS are actually W3C, Inc. Not that the bad looks of Google having them by the balls is better than your scenario eg the impression W3C on its last legs receiving money to keep the illusion of a multi-party effort of web standards.replyjeroenhd 18 hours ago | root | parent | prev | next [\u2013]A lot of CSS seems excessive but I, for one, am glad with a lot of the additions over the years. CSS tables are great (better than flexbox for many layouts IMO), CSS masks combined with gradients and other background tricks save us from manually positioned SVGs that have to be just the right size.Recent additions include the :has pseudo class, which I've wanted for a while, a subgrid layout to alleviate the problems nesting grids can cause, scroll snapping should make those annoying Apple style scrolling web pages less of a problem to deal with, and there are tons of other great features out there as well.With these, we can finally get rid of the janky mess that we needed 10 years ago. No more magical \"width: auto auto\" for centering text. No more lists of \"display: float\" to get dynamic sizing.The newer the standards are, the better the documentation is in my experience. Older CSS had a lot of shitty implementation defined behavior that has since been documented to correspond to what most browsers seemed to do anyway. The newer standards seem to be written with an actual intend to be implemented consistently.You could build almost any modern web page in Microsoft FrontPage twenty years ago with enough carefully crafted GIFs, but I think we all agree that CSS has improved for the better since then. If it weren't for all these \"living standards\", you would barely be able to use the web on your phone. I remember the PDA internet era, back before the iPhone made showing real websites on your smartphone a thing developers became aware of. It was not good.replylosvedir 21 hours ago | prev | next [\u2013]Wow, congrats!Does this change anything about the feel of working on it, I wonder? Until now, it has been a real passion project. I wonder if this will make working on it more of a chore, or if it will affect the \"roadmap\".I hope someone donates $100k to the programming language project of theirs next.And lastly, the most important thing is for him to stay sober. My understanding of the whole \"serenity\" project was as an alternative to drinking that was fun and fulfilling. I hope the money doesn't cause stress, or otherwise change what the project is or how it works, such that it no longer works for its original and primary function.replyxvilka 1 day ago | prev | next [\u2013]Congratulations! I wish someone would sponsor completing Servo as fast as possible, or completing rewriting of Firefox in Rust.replysamwillis 1 day ago | parent | next [\u2013]Servo was moved to the Linux Foundation in 2019, and earlier this year Igalia (an open source consulting company) contributed funds and developer time to advance the project. I believe they have a small team full time on it. You can read more here:https://servo.org/blog/2023/01/16/servo-2023/https://people.igalia.com/mrego/servo/igalia-servo-tsc-2022/https://news.ycombinator.com/item?id=34400214So, your \"wish someone would sponsor completing Servo as fast as possible\", is looking like it's coming true.Note though that Servo and Ladybird have vary different motivations and objectives.replyintelVISA 19 hours ago | root | parent | next [\u2013]> an open source consulting companyNot sure how to feel about this combination, are they any good?replyMatthiasPortzel 19 hours ago | root | parent | next [\u2013]Igalia is responsible for a lot of open source contributions to web browsers. Here\u2019s an article about them.=> https://thenewstack.io/igalia-the-open-source-powerhouse-you...replycyberpunk 1 day ago | parent | prev | next [\u2013]If only there was some kind of foundation which could choose where to spend the many millions of funding it receives each year...replygrey_earthling 1 day ago | root | parent | next [\u2013]Of course the wisest thing to spend it on would be integrating a proprietary competitor to Wallabag. That's exactly what the open web needs most.replyintelVISA 19 hours ago | root | parent | prev | next [\u2013]Then who is going to fund market disruptors such as Pocket?replyest31 1 day ago | parent | prev | next [\u2013]FTR, Servo has received funding by Mozilla by having their engineers work on it that amounts to way way more than 100k USD.replyjedisct1 17 hours ago | parent | prev | next [\u2013]Have you actually looked at it/tried to contribute to it?Servo was a promising experiment, but it eventually became a massive, complicated, unmaintainable mess.replyevnix 1 day ago | prev | next [\u2013]Please go through his YouTube videos, he records a good portion of his work.I personally learnt a lot more from his videos than from any book.replyhosteur 1 day ago | prev | next [\u2013]This is great news. Congratulations Andreas. I am very impressed by your work.Can you shed some light on who\u2019s sponsoring? Any strings attached?replyakling 1 day ago | parent | next [\u2013]Thank you! The sponsor has asked to remain anonymous for now. There are no strings attached, although we do stay in touch. :)replyellis0n 12 hours ago | root | parent | next [\u2013]Have a project. Tweeted to youreplySakos 23 hours ago | root | parent | prev | next [\u2013]What are the chances it's Google or Apple?replybadocr 16 hours ago | root | parent | next [\u2013]Maybe it's Notch. It'd make sense to me.replySakos 17 hours ago | root | parent | prev | next [\u2013]Scratch that. My current guess is Valve.replydizhn 20 hours ago | prev | next [\u2013]There's an opensuse package (unofficial) if anybody is interested in checking it out today. https://build.opensuse.org/package/show/home:xpufx/ladybirdreplyPCP7 1 day ago | prev | next [\u2013]Really nice to hear and here's hoping that he uses it well, we need more than 2 web engines.replyvimsee 1 day ago | prev | next [\u2013]That is so cool. Been watching some of the youtube videos where Andreas is working on the browser and it is a joy to watch. Congrats to you Andreas!replyhahhahanananana 1 day ago | prev | next [\u2013]I'm curious about how the funds can be used. Is it treated like a personal donation to the developers?replyjdthedisciple 21 hours ago | prev | next [\u2013]Great to see this! However, I see Windows is supported only via WSL. If this is to be adopted by the mainstream then perhaps native Windows support becomes paramount at some point.replydiath 21 hours ago | parent | next [\u2013]This is mostly because Ladybird is just a way to test LibWeb and other components outside of SerenityOS, it also purposefully doesn't have a lot of usability features and instead is packed with debug features. I assume that in the future somebody will build a proper browser UI with native support for Windows.replyrhdunn 18 hours ago | root | parent | next [\u2013]The various components need porting to Windows. Several attempts have been made, but thus far none have done al that is needed to make it work.replyNayamAmarshe 16 hours ago | prev | next [\u2013]Awesome! Congratulations, Andreas!replyhfo 1 day ago | prev | next [\u2013]It worked, I checked out what that browser is.replyquew 23 hours ago | prev | next [\u2013]Why don't people fork Chromium instead? License issues? Why reinvent?replySakos 22 hours ago | parent | next [\u2013]Because Google retains tight control over Chromium and outsiders generally have no say in important decisions/changes. If Google kills support for one image format in favor of their own, that basically means every Chromium fork doesn't support that format.That said, most modern browsers already are forks of Chromium. It'd be nice to have a third option that isn't just Google or Google-funded.replybunga-bunga 18 hours ago | root | parent | next [\u2013]\u201cChromium browsers\u201d are not actual forks, they\u2019re still the same Chrome.What they could do, as GP suggested, is actually fork an existing engine and start with a working foundation that\u2019s already compatible with the existing web.Note: Google did it, they forked WebKit and now nobody calls Edge a \u201cWebKit browser\u201dToday people complain that Safari and Firefox are \u201cthe new IE\u201d because they don\u2019t keep up with the slew of updates Chrome pushes out. Nobody wants to support a third, brand-new super-buggy-forever engine.It\u2019s an interesting bet, but incredibly high-risk or relegate to obscurity.replySakos 17 hours ago | root | parent | next [\u2013]Oh, right. Didn't see it from that angle, my bad.All the current \"forks\" of Chromium basically rely on continued development by Google, saving them from having to invest in all the engineers necessary to work on, maintain and develop a proper fork. So they can limit the size of their engineering teams to what's necessary for developing surface-level features like vertical tabs (Edge) or built-in adblocking and ... uh ... crypto (Brave).I'd say Microsoft throwing in the towel and building a flavour of Chromium instead shows that there's no corporation out there that's going to be willing to make a real fork.The only reason why Ladybird exists at all is because it's a part of SerenityOS, which was started because the founder wanted to make his own OS for daily use. Like, of course the guy's gonna write his own browser instead of just forking Chromium.replydarthrupert 21 hours ago | prev | next [\u2013]Why twitter?replyFpUser 1 day ago | prev | next [\u2013]Congrats for such a nice acknowledgement of your work. While looking at their other project I am curious that the author has decided to invent their own memory safe language currently implemented as transpiler to C++ written in Rust. Why not to just use Rust as their system language. I can imagine potential nightmares when debugging such concoction.replytimschumi 23 hours ago | parent | next [\u2013]> While looking at their other project I am curious that the author has decided to invent their own memory safe language currently implemented as transpiler to C++ written in Rust. [...] I can imagine potential nightmares when debugging such concoction.Compatibility with C++ is required at this point in time to interface with the thousands of lines of C++ code that have already been written. Assuming that everything will be written in Jakt at some point, then one could look into making more grave changes without having to care about compatibility (including maybe skipping the C++ part alltogether).> Why not to just use Rust as their system language.Rust has been evaluated, but discarded (mainly, iirc) due to it's approach (or lack thereof) for OOP. Also, the whole \"we want to make things ourselves\" thing.replyjeroenhd 18 hours ago | parent | prev | next [\u2013]There was a video in which Andreas explained in detail what problems he had with Rust. I agreed with a lot of them.It should be noted that most of the SerenityOS umbrella is written in modern C++ (modern enough that you may very well need to compile a compiler to build the project). Rust and C++ can interoperate, but the process isn't exactly user friendly.The goal of the language, as I understand it, was to make working on the rest of the Serenity projects more pleasant and safe. Even modern C++ has some annoying footguns but rewriting the entire system simply wasn't an option.As such, jakt compiles to C++, specially C++ that interoperates with a lot of SerenityOS code, and doing that from Rust code would probably be a much worse experience.replydiath 21 hours ago | parent | prev | next [\u2013]IIRC it was just the bootstrap compiler that was written in Rust, these days Jakt is written in Jakt.replydmytrish 18 hours ago | parent | prev | next [\u2013]The jakt compiler has been rewritten in jakt.Rewriting it in jakt is now a thing!replynpn 21 hours ago | parent | prev | next [\u2013]> written in RustWhat? From my knowledge Jakt is written in C++ and Jakt itself, not Rust.Sure the first implementation was written in Rust but it was quickly replaced when Adreas took over the project.replyFpUser 9 hours ago | root | parent | next [\u2013]How do they debug Jakt code? I mean other than dumping things to screen which is not very pleasant experience.replybruce511 1 day ago | prev [\u2013]For more context see [1].At first glance I felt that 100k wasn't really going to move the needle in creating a new browser engine but in fact (after reading the link below) it's not insignificant. There are a lot of contributers to this project, and funding the project lead is a big step in the right direction.Realistically another browser engine really isn't needed. 2 is enough. Given the scale of the work involved it'll take a lot more than money to make this mainstream.Bur that doesn't mean it's not important. These sorts of projects have value beyond main-stream use cases. While those uses are small, they can end up being significant.[1] https://awesomekling.github.io/Ladybird-a-new-cross-platform...replynot_your_vase 1 day ago | parent | next [\u2013]> Realistically another browser engine really isn't needed. 2 is enough.Currently the internet is what Chrome is - if Google decides that they don't like something on the internet, they can just wipe it. Firefox is dying. (And Safari is... well... it does things). The internet has been rotting away for good part of the last decade. We definitely don't have enough browser engines, we are in dire need of more.replyRaz2 1 day ago | root | parent | next [\u2013]> Firefox is dyingThen I don\u2019t understand how this new thing will not be stillborn. It is years before becoming usable and even then it will be worse than Firefox.replynot_your_vase 21 hours ago | root | parent | next [\u2013]Google definitely did everything they could to marginalize Firefox, but Firefox's position isn't entirely the making of Google. Mozilla was also busy messing things up, and alienate not only their adhoc users, but many of their diehard fanatics also.Firefox isn't dying because it's a bad browser or because it has no place on the market. It is dying because of mismanagement, mostly for not knowing what their users really want and need. They have no idea why their current users are using their browser, instead of Chrome. They just go with the stream, and seemingly are content that Google is keeping them on life support.But it doesn't mean that new browsers will make the same mistakes, or that there is no need for new ones at all.With that said, I would be lying if I would say that you are completely wrong. I just don't want you to be right, regardless how slim of a chance it is, because the state of internet is not getting any better that way.replyyekoc 19 hours ago | root | parent | prev | next [\u2013]Firefox dying is not because it's lacking in any form of quality. Firefox is dying because mozilla exists only as a tiny sheet of cloth over the dummy that google brings out whenever they need to dismiss antitrust/monopoly concerns.replymcherm 1 day ago | parent | prev | next [\u2013]> another browser engine really isn't needed. 2 is enough.I profoundly disagree with this statement. 2 is too few.replyTade0 1 day ago | parent | prev [\u2013]Two competitors in anything is too few.Look at the mess any two-party system is comparing to where there are at least three, each keeping the others in check.replybruce511 19 hours ago | root | parent [\u2013]Tell that to MS Phone. Tell that to Desktop Linux. Or OS/2. Or BeOS. Etc.A browser is a consumer product. As such the public will gravitate between two choices. 3rd place is no-where land.Sure 3rd place can exist, but its always a distant 3rd. Trident got canned for a reason. MS phone was a good OS, but sales offered iOS and Android.We need a stronger second option, not another option. Mozilla at least starts at parity. A new engine now is do far behind, that without Google scales of cash (which is what it took for Chrome to even join the fray) this project cannot go anywhere material.I'm not a fan of monopolies, but all markets have a leader a follower, and a bunch of minor placings.replyrprospero 18 hours ago | root | parent [\u2013]As a counter-point, I remember people making the same argument when Google announced Chrome. Browsers would always be a battle between two contenders and it would be better for Google to focus on helping Firefox in its fight against Internet Explorer than creating a third browser that could never hope to scrape a meaningful market share from the existing behemoths.It\u2019s a long road for Ladybird to be a real competitor to Chromium. However, the road to overtaking Firefox is much shorter and I\u2019m less hopeful that Mozilla has a road to overtake Chromium.replybruce511 14 hours ago | root | parent [\u2013]Chrome had two benefits over IE that Ladybird doesn't have today. The first was budget, and the second was that IE development had basically stopped.By contrast Chrome today is perhaps Google's most active development team, and has more or less an unlimited budget.MS saw IE as a nice-to-have, Google sees Chrome as existential.Also, while IE was very closed source, Chromium (and Mozilla) are open. That means Ladybird is competing with Brave et al for mind share, and can't play the \"we're better cause Open Source \" card.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Andreas has received a $100k sponsorship for Ladybird browser development.\n- Ladybird is a new cross-platform browser project with its own engine called LibWeb.\n- The sponsorship will support the project and its goal of creating a competitive alternative to existing browsers."
  },
  {
    "id": 36376669,
    "timestamp": 1687054090,
    "title": "A single line of code made a 24-core server slower than a laptop (2021)",
    "url": "https://pkolaczk.github.io/server-slower-than-a-laptop/",
    "hn_url": "http://news.ycombinator.com/item?id=36376669",
    "content": "How a Single Line of Code Made a 24-core Server Slower Than a LaptopDecember 31, 2021Imagine you wrote a program for a pleasingly parallel problem, where each thread does its own independent piece of work, and the threads don\u2019t need to coordinate except joining the results at the end. Obviously you\u2019d expect the more cores it runs on, the faster it is. You benchmark it on a laptop first and indeed you find out it scales nearly perfectly on all of the 4 available cores. Then you run it on a big, fancy, multiprocessor machine, expecting even better performance, only to see it actually runs slowerthan the laptop, no matter how many cores you give it. Uh. That has just happened to me recently.I\u2019ve been working recently on a Cassandra benchmarking tool Latte which is probably the most efficient Cassandra benchmarking tool you can get, both in terms of CPU use and memory use. The whole idea is very simple: a small piece of code generates data and executes a bunch of asynchronous CQL statements against Cassandra. Latte calls that code in a loop and records how long each iteration took. Finally, it makes a statistical analysis and displays it in various forms.Benchmarking seems to be a very pleasant problem to parallelize. As long as the code under benchmark is stateless, it can be fairly trivially called from multiple threads. I\u2019ve blogged about how to achieve that in Rust already here and here.However, at the time I wrote those earlier blog posts, Latte\u2019s workload definition capabilities were nonexistent quite limited. It came with only two predefined, hardcoded workloads, one for reading and another one for writing. There were a few things you could parameterize, e.g. the number or the sizes of table columns, but nothing really fancy. No secondary indexes. No custom filtering clauses. No control over the CQL text. Really nothing. So, overall, Latte at that time was more of a proof-of-concept rather than a universal tool for doing real work. Surely, you could fork it and write a new workload in Rust, then compile everything from source. But who wants to waste time on learning the internals of a niche benchmarking tool?Rune scriptingSo the last year, in order to be able to measure the performance of storage attached indexes in Cassandra, I decided to integrate Latte with a scripting engine that would allow me to easily define workloads without recompiling the whole program. After playing a bit with embedding CQL statements in TOML config files (which turned out to be both messy and limited at the same time), through having some fun with embedding Lua (which is probably great in C world, but didn\u2019t play so nice with Rust as I expected, although it kinda worked), I eventually ended up with a design similar to that of sysbench but with an embedded Rune interpreter instead of Lua.The main selling points of Rune that convinced me were painless Rust integration and support for async code. Thanks to async support, the user can execute CQL statements directly in the workload scripts, leveraging the asynchronous nature of the Cassandra driver. Additionally, the Rune team is amazingly helpful and removed anything that blocked me in virtually no time.Here is an example of a complete workload that measures performance of selecting rows by random keys:const ROW_COUNT = latte::param!(\"rows\", 100000);const KEYSPACE = \"latte\";const TABLE = \"basic\";pub async fn schema(ctx) {  ctx.execute(`CREATE KEYSPACE IF NOT EXISTS ${KEYSPACE} \\          WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }`).await?;  ctx.execute(`CREATE TABLE IF NOT EXISTS ${KEYSPACE}.${TABLE}(id bigint PRIMARY KEY)`).await?;}pub async fn erase(ctx) {  ctx.execute(`TRUNCATE TABLE ${KEYSPACE}.${TABLE}`).await?;}pub async fn prepare(ctx) {  ctx.load_cycle_count = ROW_COUNT;  ctx.prepare(\"insert\", `INSERT INTO ${KEYSPACE}.${TABLE}(id) VALUES (:id)`).await?;  ctx.prepare(\"select\", `SELECT * FROM ${KEYSPACE}.${TABLE} WHERE id = :id`).await?;}pub async fn load(ctx, i) {  ctx.execute_prepared(\"insert\", [i]).await?;}pub async fn run(ctx, i) {  ctx.execute_prepared(\"select\", [latte::hash(i) % ROW_COUNT]).await?;}You can find more info on how to write those scripts in the README.Benchmarking the benchmarking programAlthough the scripts are not JIT-compiled to native code yet, they are acceptably fast, and thanks to the limited amount of code they typically contain, they don\u2019t show up at the top of the profile. I\u2019ve empirically found that the overhead of Rust-Rune FFI was lower than that of Rust-Lua provided by mlua, probably due to the safety checks employed by mlua.Initially, to assess the performance of the benchmarking loop, I created an empty script:pub async fn run(ctx, i) {}Even though there is no function body there, the benchmarking program needs to do some work to actually run it:schedule N parallel asynchronous invocations using buffer_unorderedsetup a fresh local state (e.g. stack) for the Rune VMinvoke the Rune function, passing the parameters from the Rust sidemeasure the time it took to complete each returned futurecollect logs, update HDR histograms and compute other statisticsand run all of that on M threads using Tokio threaded schedulerThe results on my old 4-core laptop with Intel Xeon E3-1505M v6 locked at 3 GHz looked very promising:Because there are 4 cores, the throughput increases linearly up to 4 threads. Then it increases slightly more up to 8 threads, thanks to hyper-threading that squeezes a bit more performance out of each core. Obviously there is no performance improvement beyond 8 threads, because all CPU resources are saturated at this point.I was also satisfied with the absolute numbers I got. A few million of empty calls per second on a laptop sounds like the benchmarking loop is lightweight enough to not cause significant overhead in real measurements. A local Cassandra server launched on the same laptop can only do about 200k requests per second when fully loaded and that only if those requests are stupidly simple and all the data fits in memory.By the way, after adding some real code for data generation in the body, but with no calls to the database, as expected everything got proportionally slower, but not more than 2x slower, so it was still in a \u201cmillions ops per second\u201d range.That was easy. I could have stopped here and announce victory. However, I was curious how fast it could go if tried on a bigger machine with more cores.Running an empty loop on 24 coresA server with two Intel Xeon CPU E5-2650L v3 processors, each with 12 cores running at 1.8 GHz should be obviously a lot faster than an old 4-core laptop, shouldn\u2019t it? Well, maybe with 1 thread it would be slower because of lower CPU frequency (3 GHz vs 1.8 GHz), but it should make up for that by having many more cores.Let the numbers speak for themselves:You\u2019ll agree there is something wrong here. Two threads are better than one\u2026 and that\u2019s basically it. I couldn\u2019t squeeze more throughput than about 2 million calls per second, which was about 4x worse than the throughput I got on the laptop. Either the server was a lemon or my program had a serious scalability issue.InvestigationWhen you hit a performance problem, the most common way of investigating it is to run the code under profiler. In Rust, it is very easy to generate flamegraphs with cargo flamegraph. Let\u2019s compare the flamegraphs collected when running the benchmark with 1 thread vs 12 threads:I was expecting to find a single thing that was a bottleneck, e.g. a contended mutex or something similar, but to my surprise, there was nothing obvious there. There wasn\u2019t even a single bottleneck! Rune\u2019s VM::run code seemed to take about 1/3 of the time, but the rest was simply taken by polling futures and quite likely the culprit got inlined and disappeared from the profile.Anyway, because of VM::run and the path rune::shared::assert_send::AssertSend leading also to Rune, I decided to disable the code responsible for calling the Rune function, and I reran the experiment with just a loop running an empty future, albeit with timing and statistics code still enabled:// Executes a single iteration of a workload.// This should be idempotent \u2013// the generated action should be a function of the iteration number.// Returns the end time of the query.pub async fn run(&self, iteration: i64) -> Result<Instant, LatteError> {  let start_time = Instant::now();  let session = SessionRef::new(&self.session);  // let result = self  //   .program  //   .async_call(self.function, (session, iteration))  //   .await  //   .map(|_| ()); // erase Value, because Value is !Send  let end_time = Instant::now();  let mut state = self.state.try_lock().unwrap();  state.fn_stats.operation_completed(end_time - start_time);  // ...   Ok(end_time)  }That scaled fine to over 100M calls per second on 48 threads! So the problem must be somewhere below the Program::async_call function:// Compiled workload programpub struct Program {  sources: Sources,  context: Arc<RuntimeContext>,   unit: Arc<Unit>,}// Executes given async function with args.// If execution fails, emits diagnostic messages, e.g. stacktrace to standard error stream.// Also signals an error if the function execution succeeds, but the function returns// an error value.  pub async fn async_call(  &self,  fun: FnRef,  args: impl Args + Send,) -> Result<Value, LatteError> {  let handle_err = |e: VmError| {    let mut out = StandardStream::stderr(ColorChoice::Auto);    let _ = e.emit(&mut out, &self.sources);    LatteError::ScriptExecError(fun.name, e)  };  let execution = self.vm().send_execute(fun.hash, args).map_err(handle_err)?;  let result = execution.async_complete().await.map_err(handle_err)?;  self.convert_error(fun.name, result)}// Initializes a fresh virtual machine needed to execute this program.// This is extremely lightweight.fn vm(&self) -> Vm {  Vm::new(self.context.clone(), self.unit.clone())}The async_call function does a few things:it prepares a fresh Rune VM \u2013 this is supposed to be a very lightweight operation that basically prepares a fresh stack; the VMs are not shared between calls nor threads so they can run totally independentlyit invokes a function by passing its identifier and parametersfinally it receives the result and converts some errors; we can safely assume that in an empty benchmark this is a no-opMy next idea was to just remove the send_execute and async_complete calls and leave just the VM preparation. So basically I wanted to benchmark that line:Vm::new(self.context.clone(), self.unit.clone())The code looks fairly innocent. No locks, no mutexes, no syscalls, no shared mutable data here. There are some read-only structures context and unit shared behind an Arc, but read-only sharing shouldn\u2019t be a problem.VM::new is also trivial:impl Vm {  // Construct a new virtual machine.  pub const fn new(context: Arc<RuntimeContext>, unit: Arc<Unit>) -> Self {    Self::with_stack(context, unit, Stack::new())  }  // Construct a new virtual machine with a custom stack.  pub const fn with_stack(context: Arc<RuntimeContext>, unit: Arc<Unit>, stack: Stack) -> Self {    Self {      context,      unit,      ip: 0,      stack,      call_frames: vec::Vec::new(),    }  }However, not matter how innocent the code looks, I like to double check my assumptions. I ran that with different numbers of threads and, although it was now faster than before, it didn\u2019t scale at all again \u2013 it hit a throughput ceiling of about 4 million calls per second!The problemAlthough at first it doesn\u2019t look like there is any sharing of mutable data in the code above, actually there is something slightly hidden that\u2019s shared and mutated: the Arc reference counters themselves. Those counters are shared between all the invocations, performed from many threads, and they are the source of the congestion here.Some may argue that atomically increasing or decreasing a shared atomic counter shouldn\u2019t be a problem because those are \u201clockless\u201d operations. They even translate to single assembly instructions (e.g. lock xadd)! If something is a single assembly instruction, it is not slow, isn\u2019t it? That reasoning is unfortunately flawed.The root of the problem is not really the computation, but the cost of maintaining the shared state.The amount of time required to read or write data is mostly influenced by how far the CPU core needs to reach out for the data. Here are the typical latencies for the Intel Haswell Xeon CPUs according to this site:L1 cache: 4 cyclesL2 cache: 12 cyclesL3 cache: 43 cyclesRAM: 62 cycles + 100 nsL1 and L2 caches are typically local to a core (L2 may be shared by two cores). L3 cache is shared by all cores of a CPU. There is also a direct interconnect between L3 caches of different processors on the main board for managing L3 cache coherency, so L3 is logically shared between all processors.As long as you don\u2019t update the cache line and only read it from multiple threads, the line will be loaded by multiple cores and marked as shared. It is likely that frequent accesses to such data would be served from L1 cache, which is very fast. Therefore sharing read-only data is perfectly fine and scales well. Even using atomics for only reading will be plenty fast in that case.However, once we introduce updates to the shared cache line, things start to complicate. The x86-amd64 architecture has coherent data caches. This means basically that what you write on one core, you can read back on another one. It is not possible to store a cache line with conflicting data in multiple cores. Once a thread decides to update a shared cache line, that line gets invalidated on all the other cores, so subsequent loads on those cores would have to fetch the data from at least L3. That is obviously a lot slower, and even slower if there are more processors than one on the main board.The fact that our reference counters are atomic is an additional problem that makes things even more complex for the processor. Although using atomic instructions is often referred to as \u201clockless programming\u201d, this is slightly misleading \u2013 in fact, atomic operations require some locking to happen at the hardware level. This locking is very fine-grained and cheap as long as there is no congestion, but as usual with locking, you may expect very poor performance if many things try to fight for the same lock at the same time. And it is of course much worse if those \u201cthings\u201d are whole CPUs and not just single cores that are close to each other.The fixThe obvious fix is to avoid sharing the reference counters. Latte has a very simple, hierarchical lifecycle structure, so all those Arc updates looked like an overkill to me and they could probably be replaced with simpler references and Rust lifetimes. However, this is easier said than done. Unfortunately Rune requires the references to the Unit and RuntimeContext to be passed wrapped in Arc for managing the lifetime (in probably more complex scenarios) and it also uses some Arc-wrapped values internally as part of those structures. Rewriting Rune just for my tiny use case was out of the question.Therefore the Arc had to stay. Instead of using a single Arc value we can use one Arc per thread. That requires also separating the Unit and RuntimeContext values, so each thread would get their own. As a side effect, this guarantees there is no sharing at all, so even if Rune clones an Arc stored internally as a part of those values, that problem would be also fixed. The downside of this solution is higher memory use. Fortunately . Latte workload scripts are usually tiny, so higher memory use is likely not a big problem.To be able to use separate Unit and RuntimeContext I submitted a patch to Rune to make them Clone. Then, on the Latte side, the whole fix was actually introducing a new function for \u201cdeep\u201d cloning the Program struct and then making sure each thread gets its own copy:  // Makes a deep copy of context and unit.  // Calling this method instead of `clone` ensures that Rune runtime structures  // are separate and can be moved to different CPU cores efficiently without accidental  // sharing of Arc references.  fn unshare(&self) -> Program {    Program {      sources: self.sources.clone(),      context: Arc::new(self.context.as_ref().clone()),  // clones the value under Arc and wraps it in a new counter      unit: Arc::new(self.unit.as_ref().clone()),     // clones the value under Arc and wraps it in a new counter    }  }BTW: The sources field is not used during the execution, except for emitting diagnostics, so it could be left shared.Note that the original line where I originally found the slowdown did not need any changes!Vm::new(self.context.clone(), self.unit.clone())This is because self.context and self.unit are not shared between threads anymore. Atomic updates to non-shared counters are fortunately very fast.Final resultsNow the throughput scales linearly up to 24 threads, as expected:TakeawaysThe cost of a shared Arc might be absurdly high on some hardware configurations if it is updated frequently on many threads.Don\u2019t assume that a single assembly instruction cannot become a performance problem.Don\u2019t assume that if something scales fine on a single-CPU computer, it would still scale on a multi-CPU computer.Share on:",
    "summary": "- The performance of a benchmarking tool called Latte was unexpectedly slower on a 24-core server compared to a laptop, despite having more cores available.\n- After investigation, it was discovered that the issue was caused by the use of shared reference counters (Arc) in the tool's code, which led to congestion and poor performance on the server.\n- The problem was addressed by implementing separate reference counters for each thread, resulting in improved scalability and linear performance scaling on the server.",
    "hn_title": "A single line of code made a 24-core server slower than a laptop (2021)",
    "original_title": "A single line of code made a 24-core server slower than a laptop (2021)",
    "score": 497,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginA single line of code made a 24-core server slower than a laptop (2021) (pkolaczk.github.io)497 points by xk3 1 day ago | hide | past | favorite | 161 commentssamsquire 1 day ago | next [\u2013]This is really good. Thank you for this blog post.Asynchronous code, coroutines, async/await, parallelising problems is my deep interest and I blog about it everyday.I think the easiest way to parallelise is to shard your data per thread and treat your multithreaded (or multimachine) architecture as a tree - not a graph - where dataflow doesn't need to pass between tree branches. This is similar to the Rust's \"no interior mutabiliy\" and Rust data structures pattern.My machine can lock and unlock 61570760 times a second. But it can count to 2 billion in 1 second. So locks are expensive.I recently worked at parallelising the A* graph search algorithm that I'm using for code generation/program synthesis.For 16 processes it takes 35 seconds to synthesise a program but with 3 processes it takes 21 seconds. I think my approach to parallelising A* needs a redesign.We hit Amdahl's law when it comes to parallelising. I need to split up my problem into spaces that don't require synchronization/serialisation.EDIT: I've mentioned this whitepaper before (\"Scalability! But at what COST?\") but this whitepaper would be useful reading of anybody working on multithreaded or distributed systems. In summary: single threaded programs can easily be faster and more performant (wall clock time) than multithreaded/multimachine distributed machines, but they don't scale.https://www.usenix.org/system/files/conference/hotos15/hotos...replyasimpletune 1 day ago | parent | next [\u2013]This is in a nutshell the moral of the performance story. I took a graduate level class in performance computing that was basically all lab based. In the end what I learned, overwhelmingly, first hand, is that in the performance computing world, what wins is what exploits the hardware intelligently.Theoretical advancements matter too but usually only in so much as they can translate to hardware. Although, there are some special case where even a slight theoretical gain matters even more than how it translates to hardware, but they're limited.Anyways, to that end, everything becomes about dividing work in a way that parallelizes nicely, exploits cache well, reduces the need to share information between threads, etc... and this ultimately comes down to data structures. However, these aren't your normal, fundamental data structures. Instead each problem sort of has some kind of exotic, hypothetically ideal data structure, that is fine tuned to exploit the machine's resources to the max for just that problem. By the time you're done they rarely resemble anything intelligible, let alone wha the whiteboard version of the algorithm was.In that vein, there are a few general trends that appear over and over again. Trees vs graphs is definitely one of of those trends, although that's more of a general theme and not a literal rule.replycgio 23 hours ago | root | parent | next [\u2013]That sounds very interesting. Would you be able to reference any such exotic data structure and maybe the process of getting to defining it?replyasimpletune 22 hours ago | root | parent | next [\u2013]I don't know any of their names, or if they even have names. My TA for that class had, at the time, one of the world's fastest SSSP implementations, and our last class was basically just spending the whole lab time understanding his personal implementation. It was really in that moment that it clicked for me that the more you come to understanding a problem in CS the more your code morphs from something general into becoming one big, bespoke data structure. Almost his entire program was just one giant data structure. So, I don't think this kind of thing has a name, nor can I say I really even understood it, but I do remember he used a lot of bags.For reference, we spent the whole class doing SSSP on a graph representing every road in the United States. The naive A*/Dijkstra implementation took like 45 min, and naive bellman-ford never finished (probably days/weeks). By the end of the class I was so proud to have parallelized Bellman-Ford to the point where it took like 30s or something. And my TA's record breaking implementation was <1s. All of this was on a normal university linux desktop.It's kind of like programming = logic + data. However, there's a continuum between the two, and on the far, extreme end of that spectrum, the structured access of the data can be the program itself.replydlisboa 22 hours ago | root | parent | next [\u2013]These stories really expose how fast and efficient computers can actually be. I remember a post (don\u2019t have the link) where someone sped up a Python script by 3000x or something crazy like that with C++. A script anyone would\u2019ve been fine running, but it was just so much slower than what was possible.Sometimes I wonder whether we should not focus more on these micro adjustments. We usually have this \u201cit\u2019s fast enough\u201d attitude, but probably everything we use today (including web services) could be instant if focus was given to optimization (although yes, I understand the drawbacks of focusing solely on that).replytharkun__ 19 hours ago | root | parent | next [\u2013]We as in the general every day programmer especially your web services example should definitely not focus on these micro adjustments I would say. Sure it's fun. If you make library type code, yes please do focus on them! If you're a run of the mill corporate dev, very rarely I would think.Other much simpler optimizations are usually possible in \"corporate code\". Lots of stupid things being done. To use your python script example, proba ly you could've gotten 2950x improvement rewriting the bad parts better but still in python :)Do you remember what the python script did/was for? How much time was spent building the original script? What was the guy that built it paid?How long did it take to build the C++ version and how much was that guy paid?If these were all open source/unpaid, what would it cost for these different types of people and could the company conceivably pay those salaries/keep the guy happy and busy enough to stay around?replydlisboa 15 hours ago | root | parent | next [\u2013]I understand all that and apply that day to day. But my thought here is more to think of the possibilities if the performance of most things was brought to its absolute best. There\u2019s a company that went from 30 servers to 2 just by rewriting from Ruby to Go (I can find the link later if interested). Even if they had kept Ruby and achieved a speed up, there was something just massively inefficient and they didn\u2019t really care as they were in \u201cwe're shipping fast\u201d mode and were making money. Which I understand perfectly but that\u2019s a big waste of energy and resources.Not that I think that should be priority #1 but it\u2019s staggering how much more efficient things can be than the \u201cnaive\u201d approach.replyeterm 16 hours ago | root | parent | prev | next [\u2013]Perhaps you're thinking of Matt Parker's (of standup maths and numberphile fame) video:https://m.youtube.com/watch?v=c33AZBnRHksreplydlisboa 15 hours ago | root | parent | next [\u2013]I think that\u2019s it! Really shows my point: the first code was already ok and solved the problem in a reasonable amount of time, in a normal \u201clet\u2019s ship faster\u201d setup the ridiculous speed up achievable would\u2019ve never even be considered. 4 million percent faster! A whole class of possibilities open up at that point.replycgio 19 hours ago | root | parent | prev | next [\u2013]Thank you for the detailed answer. I am looking into a risk management system and valuation also seems to be an area where data structures can significantly improve calculation time. Also on my end looking into the role of data structure into enabling two separate optimisation paths, one being the real time latency oriented and the other being the batch throughout oriented. If anyone has seen any work on data structures with focus on this kind of optimisations it would be great. A bit related to the parent discussion, I am looking at graphs with tree views if that makes sense.replysobkas 21 hours ago | root | parent | prev | next [\u2013]For me it sounds a lot like data-driven programming or data-oriented programming.replyZephyrBlu 21 hours ago | root | parent | prev | next [\u2013]The point is that these data structures are highly dependent on the problem you're trying to scale.I don't think an example of one and the process taken to define it is that helpful, since the skill is about being able to do this for an arbitrary problem. It also probably requires a lot of trial and error.replymagicalhippo 20 hours ago | parent | prev | next [\u2013]> I need to split up my problem into spaces that don't require synchronization/serialisation.When I first got a dual CPU (before \"cores\" were a thing) computer, I decided I'd try dipping my feet in some \"proper\" parallel coding.I started with something simple, parallelizing a quicksort routine. This seemed quite trivial: instead of recursing, add the spans to be sorted to a list. I then spawned a thread per CPU, which fetched a span from the list, did a single quicksort pass on it and added up to two new spans to the list. Rinse repeat until list was empty.Since each span was non-overlapping, the threads only had to synchronize while accessing the list of tasks.When benchmarking it became clear that while there was a good performance win for large arrays, for short arrays the multithreaded code was much slower than the non-multithreaded version. At my hardware the threshold was around 50k items for integer elements and 20k or so for string elements, IIRC.I added a threshold detection, where the thread would do a regular recursive quicksort on the span if the length was below the threshold, and this yielded significantly better results.And with that the harsh reality of multithreading hit me: no free lunch. It was clear the threshold varies not just with element type (slow/complex comparators would reduce the threshold, and vice versa) but with the details of the hardware. So a hardcoded threshold was out of the picture, and it would have to be dynamically determined at runtime.Was a great learning experience though.replymagicalhippo 15 hours ago | root | parent | next [\u2013]For those who might wonder why, the quicksort splits the array into half and then repeats on the two halves.Thus the majority of spans are small and quickly processed, and hence the naive multithreaded version leads to lock contention as the threads fight to access the shared list of spans.replytgv 1 day ago | parent | prev | next [\u2013]The basic algorithm of A* is very sequential, isn't it? It works by taking the best scoring unexpanded node and expand that. Most of the time, there's only one such node. When expansion has finished, you need to re-sort the queue/heap of unexpanded nodes. All those steps are sequential. So I guess the only gain is when the node expansion can be done in parallel; expanding the top-N nodes probably is counterproductive for many problems. How much you gain then depends on the time expansion takes. The advantage of parallelism then depends on how much time one step \"down\" takes.replysamsquire 22 hours ago | root | parent | next [\u2013]Yes, I think I can take advantage of my particular problem to parallelise, which I'm still trying to work out.My neighbour scanning is dynamic and my neighbours and all neighbours from a node is independent from that point forwards, it shall not visit the exact same node. In essence my problem is kind of a tree.I am trying to infer data flow between two states including hidden states such as functions calls. My dream is that I can provide a start state and end state and the computer writes itself based on type information and data flow analysis of values.Here's my input data - which is what memory is set to and what registers are set to. start_state = {  \"memory\": [0, 0, 0, 0],  \"rax\": 0,  \"rbx\": 1,  \"rcx\": 2,  \"rdx\": 3,  \"rsp\": -1,  \"rdi\": -1,  \"rbp\": -1 } end_state = {  \"memory\": [3, 1, 2, -1],  \"rax\": 3,  \"rbx\": 2,  \"rcx\": 1,  \"rdx\": 0,  \"rsp\": 6,  \"rdi\": -1,  \"rbp\": -1 } # these functions take in a value and return another value minus_1_to_four = Function(\"minus1\", -1, 4) four_to_five = Function(\"fourtofive\", 4, 5) five_to_six = Function(\"fivetosix\", 5, 6)This synthesises the following program in 16 seconds (I improved the heuristic function). Function values input and output can be in any register, but in my example they are all in the same register. With 3 processes it synthesises in 0.6 seconds. [start, mov %rax, (%rdx), mov %rbx, (%rbx), mov %rcx, (%rcx), mov %rdx, (%rsp), mov %rax, %rbp, mov %rdx, %rax, mov %rbp, %rdx, mov %rcx, %rbp, mov %rbx, %rcx, mov %rbp, %rbx, call minus1(rsp=-1) -> rsp=4, mov $-1, %rbp, call fourtofive(rsp=4) -> rsp=5, call fivetosix(rsp=5) -> rsp=6]replyasimpletune 1 day ago | root | parent | prev | next [\u2013]This is correct, and Bellman-Ford, while naive compared to A*, actually parallelizes much better. That said, an optimized Bellman-Ford doesn't even resemble the original, naive version of the algorithm.replylelanthran 21 hours ago | root | parent | prev | next [\u2013]I wouldn't say sequential. Maybe at implementations are sequential and state based because games need to pause the process on a frame refresh.A* is naturally recursive [1] and so can be parallelized as you go further.[1] unless I'm mistaking some other algorithm for A*, each new recursive call of all the neighbours can be started on a different thread or node.replyrkuska 2 hours ago | parent | prev | next [\u2013]This is exactly a reason why I like Scylla as a database. One shard per CPU. Each shard owning different partition of data. Great performance.replyhinkley 21 hours ago | parent | prev | next [\u2013]When I was noodling with the Traveling Salesman problem, I was sure that what I really needed was to spend X% of available resources on the Big Gamble (a low probability algorithm with fast results), Y% on a common heuristic and the rest on the honest work of plowing through the linear equations progressively culling the remaining scenarios that need to be tested. I had limited success with this though. I just haven\u2019t done enough LP to make anything noteworthy, and it was a tool sharpening exercise, which made me a little more effective at more mundane batch processing tasks, not a great mind of NP-completeness.reply_hl_ 23 hours ago | parent | prev | next [\u2013]FYI, there are lots of papers on parallel shortest path algorithms. If an approximate solution suffices, there\u2019s also a lot of research available on that, often with some parameter that lets you trade more computation for a tighter approximation. It's not a problem that parallelises particularly well though, so not sure if you'll see good gains in practice.If you can restrict the structure of your graphs (e.g. planar) then some very efficient methods exist.replyOoooooooO 20 hours ago | parent | prev | next [\u2013]Isn't a tree just a graph that is directed and acyclic (DAG)?So a tree is just a subtype of a graph?replyironSkillet 20 hours ago | root | parent | next [\u2013]A tree is a subtype of graph. However, a DAG is not a tree if it has cycles once you forget direction, meaning paths can join up again after splitting. This distinction matters because when different paths \"join up\" again, there is often complicated data duplication/integration that is necessary in order order to combine the results. On a distributed system, it may mean data passing over a network, which you want to avoid.replypxc 17 hours ago | root | parent | prev | next [\u2013]In graph theory, trees are undirected. In computing, trees usually have two features that differentiate them from their more minimal graph theoretical cousins: they are (a) directed and (b) rooted (a particular vertex is designated as the root, and every vertex can be walked to from that vertex).But yeah. Some graphs are trees. And you can construct trees within graphs for efficiently navigating connected graphs, which is done in various important and famous algorithms.replyRuphin 19 hours ago | root | parent | prev | next [\u2013]A tree is a subtype of a graph, but it is not the same as a DAG. A diamond-shaped directed graph (edges A->B, A->C, B->D, C->D) is a DAG, but not a tree.replyjasfi 16 hours ago | parent | prev | next [\u2013]I'd like your opinion: channels or locks?This is really for a program I'm writing in Nim, so perhaps it depends on how channels are implemented?replybrutusborn 1 day ago | parent | prev | next [\u2013]Can you share any of the parallel A* code? I\u2019m currently looking at using A* for use in generative design and am pretty ignorant about parallelising code. Would love to learn more!replysamsquire 22 hours ago | root | parent | next [\u2013]I've taken a very naive approach and it does NOT scale. It uses python multiprocessing. I think the fScore updates pickling and serialization - communication and synchronization lock overhead is slowing it down. It simply does not parallelise.This is my code generator/program synthesiser, it synthesises assembly instructions from two given states of memory and registers to take it from one to the other, including hidden states such as functions.https://replit.com/@Chronological/SlidingPuzzle3#main.pyreplybrutusborn 20 hours ago | root | parent | next [\u2013]Thanks, regardless of ability to parallelise it looks interesting.replyjeffbee 1 day ago | prev | next [\u2013]Atomics don\u2019t scale. In this age that needs to be widespread elementary knowledge. They are particularly bad on armv8 without atomic extensions because that platform has no equivalent to \u201clock; xadd\u201d and an atomic increment could theoretically become an infinite loop.replytrws 1 day ago | parent | next [\u2013]Let\u2019s be clear here, while you are 100% right that armv8 atomics kinda suck by default, neither compare and swap nor load linked store conditional scale but some atomics can scale if implemented and used appropriately. As parent points out, an atomic increment can scale, we proved they could scale to the performance of a load in the 80s for goodness sake. The fact that arm, ppc, and some others tend to implement these in the absolute worst way possible for performance doesn\u2019t mean atomics can\u2019t scale.replytemac 21 hours ago | root | parent | next [\u2013]I'm not sure about how atomics having the performance of loads mean they will scale (and to be honest i doubt they could have the perf of loads on modern architecture, otherwise why would e.g. Intel not implement them to be faster - but lets pretend it is possible)The fine article shows that a single lock xadd can destroy perfs on some x86 systems and explain that it is due to cache line bouncing. You would get the same effect with loads: if the loaded data is RO or mostly RO it will of course scale fine. It won't scale as soon as it starts bouncing too much.replytrws 13 hours ago | root | parent | next [\u2013]Then why keep bouncing it? Leaving it managed by a known single user in a cache architecture like on x86 means that latency goes up, but the overall throughput of the operation goes up drastically. That\u2019s why flat combining data structures are so popular there despite their absolute maximum throughput being bounded by sequential performance.Also, FWIW, intel largely does implement operations closer to that way on single socket parts, if you want to see it for real look at on-device atomics on a GPU. Ironically an average laptop chip handles atomics much faster than most servers as a result.replyghusbands 1 day ago | root | parent | prev | next [\u2013]You're not being clear - are you claiming that they do scale well on ARM/PPC, despite the \"absolute worst\" implementation or that they don't?replybonzini 1 day ago | root | parent | next [\u2013]He means that locks anyway have the same problems as atomics on platforms with load locked/store conditional. Therefore yes, that's a problem of the platform, but even on arm/ppc atomics scale better than locks.Which is true, but eliminating sharing works even better if possible as proved by the article.replymoonchild 22 hours ago | root | parent | prev | next [\u2013]> an atomic increment can scale, we proved they could scale to the performance of a load in the 80sInteresting--can you link a reference for this?replytrws 12 hours ago | root | parent | next [\u2013]This is the citation I most often use from that time, though the primary source is probably another reference down the line: https://dl.acm.org/doi/10.1145/69624.357206The short version is that if atomics are implemented as part of the memory network, common cache, or memory controller, then atomics of the form \u201cfetch-and-X\u201d can be implemented in roughly equivalent complexity to a load of the current value (plus an instruction for the op, give it take) with the cost only scaling past that as op queues or other implementation-specific limits fire. It\u2019s the infinite consensus ops that just can\u2019t scale no matter what you do. The coherence and memory model matter a lot too of course, which is part of why x86 tends to be slow for atomics, while arm and ppc (with fetch-and-X extensions) or GPUs tend to do much better.replymoonchild 22 hours ago | parent | prev | next [\u2013]Contended atomics don't scale. It is possible to construct concurrent structures which contend rarely (but which must still use atomics to guard against the rare case when mediation is required). There was also an interesting paper from a few years ago about using HTM to detect contention in a scalable fashion. I will aver that such code may be difficult to reason about\u2014shared-nothing has far more obvious correctness and performance properties. (Queueing/amortisation also works, and lands somewhere in the middle wrt ease of reasoning.)Riscv has an interesting compromise, which is to delineate a subset of ll/sc loops which is guaranteed to eventually make global progress. I do agree that it is better to include real wait-free primitives like cas and faa; but I wish that such guarantees of global progress would be provided to HTM.replyiaaan 1 day ago | parent | prev | next [\u2013]Ignorant question: what's the alternative? A normal mutex? I just sort of assumed atomics were abstractions around some type and a mutex.replykccqzy 1 day ago | root | parent | next [\u2013]Partition your data structure to be per-CPU and get rid of any sharing.replyotabdeveloper4 1 day ago | root | parent | next [\u2013]> Just don't use any shared state, broThank you, Sherlock.But for the rest of us: when you need shared state, lockfree atomic spinlocks are roughly 1000 times more performant than mutexes. (Not a scientific estimate, numbers taken from real-word experience.)replycyberax 1 day ago | root | parent | next [\u2013]No, they are not.The slow part of locking is invalidation of cache lines, and this has to happen with spinlocks anyway. Modern mutex implementations also first try to acquire the lock optimistically, so in the uncontended case they are as fast as userspace spinlocks (modulo inlining).And if you have a contended lock, then userspace spinlocks are a PITA. You need to take care of fairness, ideally deal with the scheduler (yield to a thread that is not spinning on the same spinlock), and so on.You can do all of that properly, but even then, you're looking at maaaaybe 10-20% performance increase in real-world applications.Pure spinlocks can win only in contrived cases, like only having exactly two threads contending for the lock, with short locked sections.replymangamadaiyan 21 hours ago | root | parent | next [\u2013]>userspace spinlocks are a PITA ... >ideally deal with the schedulerDon't you anyway need to drop the scheduler a hint so that the thread holding the spinlock doesn't get scheduled off the CPU, making the contenders wait longer than they ideally should? (Or is this what you meant by your \"fairness\" reference?)In my limited understanding, this was the no. 1 reason why userspace spinlocks were discouraged -- because pretty much no scheduler accepted a hint from userspace to not kick a thread off the CPU -- modulo jumping through hoops with priority, et cetera.If I'm missing something (and I likely am), I would be glad to be educated.replycyberax 13 hours ago | root | parent | next [\u2013]> Don't you anyway need to drop the scheduler a hint so that the thread holding the spinlock doesn't get scheduled off the CPU, making the contenders wait longer than they ideally should?How would you do it? You can change the thread's priority to realtime to prevent the scheduler from pre-empting it while holding the lock, but this requires a kernel roundtrip and several scheduler locks anyway.You can have a worker thread pool, with individual threads hard-pinned to specific CPUs. Then you can dispatch your work into these threads. This in practice will guarantee that they are not pre-emptied except for occasional kernel housekeeping needs.But this will make it impossible to use the kernel-level mutexes because they can block your worker threads. So you'll have to reimplement waiting mutexes in userspace, along with a scheduler to intelligently switch to a work item that is not blocked on waiting for something else to complete.Long story short, you're eventually going to reimplement the kernel in userspace. This can be done, and you can get some performance improvements out of it because you can avoid relatively slow kernel-userspace transitions. DPDK is a good example of this, but at that point you're not just using spinlocks, you're writing software for essentially a custom operating system with its own IO, locking, memory management, etc.replymangamadaiyan 10 hours ago | root | parent | next [\u2013]Yes indeed -- all of these reasons make userspace spinlocks undesirable in the general case, which is pretty much the point I was trying to make :)(Edit:) Arguably, I could've been less obtuse in what I wrote.replyloeg 16 hours ago | root | parent | prev | next [\u2013]You're correct -- the problem with userspace spinlocks is that the holding thread can be scheduled off. You can prevent this to some degree (probabilistically) with isolcpus and thread pinning, but that usually doesn't prevent hardware interrupts from running on those cores (which kernel spinlocks can avoid!). This isn't really solvable without running in kernel context (to have the elevated permissions necessary to mask interrupts).replysaagarjha 1 day ago | root | parent | prev | next [\u2013]Pure spin locks will always win for uncontended locks.replyNobodyNada 1 day ago | root | parent | next [\u2013]Without any contention at all, a spinlock and a mutex are identical: a single compare-and-swap.replygpderetta 1 day ago | root | parent | next [\u2013]Technically you can use a release-store on a spinlock unlock path, but you need a CAS for a mutex.replypetters 1 day ago | root | parent | prev | next [\u2013]> spinlocks are roughly 1000 times more performant than mutexesThat is absolutely not universal. See e.g. but there are of course many places discussing this: https://news.ycombinator.com/item?id=21970050replyhappymellon 1 day ago | root | parent | next [\u2013]This immediately popped into my head too when I saw the comment.Spinlocks are terrible, and written by people who are trying to do quick hacks because they work in terrible environments and are taught to do bad things.There is a reason that most GPU drivers are just lists of hacks to get games working correctly.replyimtringued 1 day ago | root | parent | next [\u2013]Yeah, spinlocks sound cool but actually they are terrible. Hybrid locks are generally quite good. The only way to get better is to pin cores and let nothing else run on them. Only then will spinlocks have a chance to increase performance by a tiny bit.replysaagarjha 1 day ago | root | parent | prev | next [\u2013]Locking is hard in general. Don\u2019t do an unbounded spin in userspace is typically good advice though. The typical mutex construction these days will spin for a little while in an attempt to take advantage of mostly uncontended locks and then yield to the kernel.replyOno-Sendai 1 day ago | root | parent | prev | next [\u2013]mutexes are not that slow.Uncontested (single thread): incrementing using atomics took 0.002011 s (0.2513 ns / increment) incrementing using mutex took  0.005515 s (0.6894 ns / increment)Contested (8 threads trying to increment a single protected integer): incrementing using atomics took 0.1069 s (13.36 ns / increment) incrementing using mutex took  1.970 s (246.3 ns / increment)So mutexes are roughly the same speed in the uncontested case, and about 20x slower in this heavily contested case. This is on Windows.replymjan22640 1 day ago | root | parent | next [\u2013]Is that AMD or Intel? Intel ivalidates the other CPU's cache line on write. AMD sends an update to the other CPU's cache line. AMD is supposed to be significantly faster than Intel on a \"real\" multiprocessor workload.replyComputerGuru 17 hours ago | root | parent | next [\u2013]Don\u2019t know why you were downvoted but yes, AMD uses MOESI and Intel uses MESI.replyOno-Sendai 17 hours ago | root | parent | prev | next [\u2013]AMD Ryzen 9.replycyberax 1 day ago | root | parent | prev | next [\u2013]I guess you have more than 8 physical CPUs?replyOno-Sendai 17 hours ago | root | parent | next [\u2013]16 coresreplygnulinux 1 day ago | root | parent | prev | next [\u2013]This is not true, you should never use spinlocks in userspace unless you know exactly what you're doing. Using spinlocks well requires scheduling, which you have no control over in userspace, this is why it makes more sense for kernel to use spinlocks. Without scheduling, with spinlocks, random threads can starve for no reason.replyotabdeveloper4 1 day ago | root | parent | next [\u2013]You are right, theoretically.Unfortunately, the userspace part of pthreads is not tuned for performance and does a lot of ridiculous things if you care about parallelism.(Mostly I was complaining about the poor quality of userspace system libraries.)replyMuffinFlavored 1 day ago | root | parent | prev | next [\u2013]how is this done in rust or c?replybottled_poe 1 day ago | root | parent | next [\u2013]This is not a language problem. It\u2019s an algorithm design problem. There\u2019s no silver bullet. The basic principle is to divide the problem space into independent blocks of work. How to achieve that depends on the problem.replycyber_kinetist 1 day ago | root | parent | next [\u2013]For a good example, there's a tricky parallelization problem in physical simulation, which you have update edge/triangle/bending wing forces in a mesh structure without any race conditions. (This becomes especially thorny if you want to parallelize your algorithm to the GPU.) A surprising solution for this is graph coloring, where you \"color\" each element without having two elements that interfere with each other the same color. Then you can safely parellelize the updates of all elements inside each color group, since the same color guarantees absolutely no interference.replyfooker 1 day ago | root | parent | prev | next [\u2013]Algorithm design problems, when general enough, warrant being treated as language problems!Every feature of programming languages started in this fashion.replybottled_poe 1 day ago | root | parent | next [\u2013]Indeed, the holy grail (or perhaps the rapture) of programming languages is a compiler which generates the entire program with zero human-written code. I fear it may be on the horizon.replyinopinatus 1 day ago | root | parent | prev | next [\u2013]There are programming languages e.g. occam designed with the intention of exposing parallelism algebraically, but I wouldn't call them a silver bullet either.replyj16sdiz 1 day ago | root | parent | next [\u2013]They are great in theory, but sucks in practice.We don't have good optimising compiler for thatreplyinopinatus 1 day ago | root | parent | prev | next [\u2013]For something small like a counter you can use thread_local since C11, but for substantial parallelized computation, designing the division of work to avoid shared writes typically entails a scheduling function that parcels up the work, sets up memory allocation in advance to avoid conflict, and then hands an entirely unshared execution context for each thread to the thread start function, most likely as a pointer to a app-specific struct (since that is what pthread_create allows for), and then subsequently applies a combination operation in the thread reaper loop to collate results (extra brownie points accrue when a reduce function is written to vectorize).The memory allocator plays a significant role, since allocation strategy needs to be per-thread-/per-CPU-cache-aware. Choosing and then tuning a different malloc (e.g. tcmalloc, jemalloc) to the one in your platform's default library is a non-trivial matter but may have enormous impact both on overall performance and memory demand.In addition, when you design computation this way it is relatively easy to hadoopify it later, since it's basically map-reduce writ small.replyflatline 1 day ago | root | parent | prev | next [\u2013]MPI partitioning by rank? I\u2019m curious what other solutions there may be.replypitaj 1 day ago | root | parent | prev | next [\u2013]In rust, you can usually use the rayon library which handles partitioning and scheduling for you.replyMuffinFlavored 16 hours ago | root | parent | next [\u2013]that's just multi-threading in generali feel like the post i was responding to was talking about handling/pinning a thread to a specific CPU core?replystevefan1999 1 day ago | root | parent | prev | next [\u2013]aka share-nothing architecturereplyjeffbee 1 day ago | root | parent | prev | next [\u2013]It's the other way around. Mutex is an abstraction over atomics.replyrramadass 20 hours ago | root | parent | prev | next [\u2013]Not ignorant at all, You have actually pointed to the core of the problem.IMO It is not enough to know the logical constructs used for synchronization in parallel programs, you have to know the hardware too.A little bit of everything from high-level parallel algorithms/data structures through memory consistency models, compiler optimizations to processor micro-architecture (cache coherency protocols, atomic instructions, NoC overhead etc.) is needed. Basically we need to be aware of the overheads for contention at every level in the system.replybbatha 1 day ago | root | parent | prev | next [\u2013]Other way around mutexes abstract around atomics but in typical implementations will yield to the kernel scheduler fairly. That system is called futexes on Linux. The kernel will also use atomics on its end.replythrowdbaaway 1 day ago | root | parent | prev | next [\u2013]Don't share atomics among threads. For example, envoy proxy mostly doesn't share atomics among threads, and can scale nicely on arm64 without requiring the atomic extensions.replycdogl 1 day ago | root | parent | next [\u2013]Honest question: why would atomics be necessary or useful if data isn\u2019t shared between threads?replyNL807 1 day ago | root | parent | next [\u2013]Because at some point data has to be exchanged across threads. For example a task queue might have tasks that can independently executed in a thread pool, but the queue index has to be atomically modified when some other thread emplaced a new task. Or if you want to transfer ownership of a heap allocated object between threads, you need to atomically transfer the pointer, or modify the reference count of that pointer. Things like that.replytormeh 1 day ago | root | parent | prev | next [\u2013]You can and should use atomics, just not in any kind of hot loop. Using atomics is fine but expensive.replyloeg 17 hours ago | root | parent | prev | next [\u2013]You can reduce sharing probabilistically, for example -- because contention is an N-squared problem, reducing sharing by some linear factor is enough for a large reduction in contention. You aren't eliminating contested atomics entirely, just making them low-contention rather than highly contended.replyfulafel 1 day ago | root | parent | prev | next [\u2013]Reference counting (the use of std::sync::Arc covered in the article) is a parallelism unfriendly type of garbage collection algorithm - so use a better one. But might be that Rust doesn't make that easy.replysaagarjha 1 day ago | parent | prev | next [\u2013]It\u2019s not just theoretical. In bad situations (many cores, heavy contention\u2026) you can get cores to starve each other as they try to each poke the monitor and fail continuously. I know of at least one platform which moved to LSE immediately partly because it fixed stuff like this. LL/SC is nice from some perspectives but it fails if you scale it up and also can be difficult to reason about (cough, cough, Linux getting their cmpxchg implementation wrong for years\u2026)replyjlokier 12 hours ago | root | parent | next [\u2013]Can you say a bit more about what Linux got wrong in cmpxchg or provide a link?replysaagarjha 7 hours ago | root | parent | next [\u2013]https://github.com/torvalds/linux/commit/8e86f0b409a44193f15... was the commit that fixed this IIRCreplyjlokier 1 hour ago | root | parent | next [\u2013]Thanks.replyeldenring 1 day ago | parent | prev | next [\u2013]Atomics scale very well if you are reading often and writing rarely.replygpderetta 1 day ago | root | parent | next [\u2013]Exactly. Atomics are a red herring. The single writer principle should be the fundamental guideline.replymagicalhippo 19 hours ago | root | parent | prev | next [\u2013]I was optimizing some code where, for reasons, many threads had to aggregate data in a shared data structure. Each thread would have a small buffer, and when full it would acquire a lock and aggregate.While fooling around I had the idea to exploit that not all atomic operations are equal. So I added an additional \"contention\" flag. When a thread wanted to aggregate it would do an atomic read of the flag, if it was set it would bail[1] and continue to accumulate to the local buffer. Once done aggregating the flag would be reset after unlocking.Effectively this was adding a single-iteration spinlock before the \"heavy\" lock, but even using CriticalSections for the lock on Windows (which does spin before acquiring a mutex lock) it resulted in clear improvements, especially when running on machines with more than 8 cores.[1]: It would bail unless the local buffer grew too large, so slight memory vs perf tradeoff there.replyloeg 17 hours ago | root | parent | next [\u2013]This is more or less equivalent to a try_lock() operation, yeah? And continuing to collect to the local buffer if try_lock fails, up to some limit.replymagicalhippo 15 hours ago | root | parent | next [\u2013]Yeah I suppose. One limitation we had was cross-compiling on Windows, Linux and OSX so available locking primitivea differed, so was easier to just do it via atomics.replyanaisbetts 1 day ago | root | parent | prev | next [\u2013]Yep, uncontended atomics are quite fast. When they're contended is when things start to slow down like OP has seenreplyklabb3 23 hours ago | root | parent | next [\u2013]Sorry to nit, but this is important. Parent was saying that reads are cheap, which is true. Writes can be expensive even if uncontended, because they invalidate cache lines. I guess you could say they contend with unrelated data but that would stretch the definition a bit.So what does this mean in practice? In my view, the way to think about it is that atomic writes have non-local side effects. But since atomics are necessary for synchronization, and involves both reads and writes, we should compartmentalize and minimize synchronization as much as possible, to avoid these gnarly issues creeping up and tanking real world performance.Arc<T> (and it\u2019s relatives in other languages) constitute textbook violations of this rule. In Rust they are everywhere in non-trivial code, including in the async runtimes themselves. Of course, they also violate (or evade if you\u2019re generous) ownership principles of idiomatic Rust, (or \u201chello world-Rust\u201d, if you will). I think we need to take a hard look as an industry at ref counting as a silver bullet escape hatch to shared data.replyanaisbetts 2 hours ago | root | parent | next [\u2013]It's a good point, it's easy to cause contention and not realize it because of cache linesreplyloeg 16 hours ago | root | parent | prev | next [\u2013]> Writes can be expensive even if uncontended, because they invalidate cache lines.This isn't expensive if cache lines are uncontended, though.> I guess you could say they contend with unrelated data but that would stretch the definition a bit.I think you might be talking about \"false sharing.\" This is real contention on the cache line due to co-location of apparently unrelated variables.> Arc<T> (and it\u2019s relatives in other languages) constitute textbook violations of this rule.Definitely!> In Rust they are everywhere in non-trivial codeEhh.. only the hot ones matter. Most are not actually contended much, and the article's solution (unshared clone) is a very reasonable approach to scale these without an API change.replyklabb3 13 hours ago | root | parent | next [\u2013]> I think you might be talking about \"false sharing.\" This is real contention on the cache line due to co-location of apparently unrelated variables.You\u2019re right. And cache lines are quite small, so this is probably less common. Yet, it\u2019s another potential source of perf regressions in concurrent code, as if it wasn\u2019t incredibly complex already.> Ehh.. only the hot ones matter.Well.. first atomics have even more non-local effects, such as barriers on instruction reordering. So Arcs that are cloned willy nilly can still be significant, with no contention.But let\u2019s ignore that and focus on the contended case: when you hear \u201cuncontended X are basically free\u201d it (subjectively, imo) downplays the issue, like contention is some special case that you can compartmentalize and only worry about when you consciously decide to write contended code. The blog post demonstrates exactly how this is so easy for contention to creep in, that you have to be superhuman levels of vigilant and paranoid to spot these issues upfront. Extremely easy to miss in eg code review.I think both compile- and runtime tooling could help at least partly here. I\u2019d also give rust some credit for having explicit clone instead of hiding it.replyLiquid_Fire 21 hours ago | parent | prev | next [\u2013]> an atomic increment could theoretically become an infinite loopOnly if your software is badly implemented. If you follow the requirements specified by the architecture, forward progress is guaranteed. Of course there is no guarantee how long it will take, but the things that make it slow are essentially the same things that make atomics slow.replymjan22640 1 day ago | parent | prev | next [\u2013]the x86 lock prefix does the same loop, this is the best performant and scaling way to do itreplythrowawaylinux 1 day ago | parent | prev | next [\u2013]`lock ; xadd` isn't really fundamentally different than `ll ; add ; sc; b again`The latter is a bit clunky but the core more or less implements them in the same way. Acquire a line exclusive, load value, increment it, write it back. And you can hold the line exclusive such that the conditional store failure cause is mostly a formality, and can't actually become an infinite loop.No general purpose atomics are done by shipping the operation to the cache or to memory controllers, it just doesn't work[*]. So even if they look slightly different in the core, they all end up looking exactly the same at the caches and coherency protocols, and that is where atomics are slow. Well any sharing of cache lines updates really.[*] EDIT: That is to say it doesn't work for performance, for many reasons. Some CPUs do have \"remote atomics\" something like that which does exactly this, but they are not intended to be broadly used.replygpderetta 23 hours ago | root | parent | next [\u2013]Yes, AFAIK in practice many architectures special case some ll/sc sequences to guarantee forward progress and fairness.replyTedDoesntTalk 1 day ago | parent | prev | next [\u2013]What about variables locked with mutexes or semaphores?replysweetjuly 1 day ago | root | parent | next [\u2013]locks and mutexes will perform worse than things like atomic increment.replybluGill 1 day ago | root | parent | next [\u2013]Maybe. It depends on the algorithm. If you share a lot of data than a mutex, update it all then unlock is fastest. If you share little data atomics can be faster. This is case be case on both the algorithm and hardware, so nobody can say which is better.Of course not sharing at all is of course best, but often you have no choice in that.replyloeg 17 hours ago | root | parent | prev | next [\u2013]The significant cost comes from contending on memory. Changing the synchronization primitive doesn't help much. You have to change your algorithm not to contend.This is significant because if you profile your code and find that a mutex is expensive, you should change your algorithm to avoid contention rather than blindly trying to change the code to use atomics instead of mutexes.replyAnimats 1 day ago | prev | next [\u2013]Ouch. I had no idea that contended Arc could be that expensive.I found a contention bug inside of Wine a few weeks ago. Something that is supposed to be \"lockless\" really had three nested spinlocks. With many threads contending for a lock, performance would drop to about 1% of normal.[1][1] https://bugs.winehq.org/show_bug.cgi?id=54979replyeldenring 1 day ago | parent | next [\u2013]Lockless is not the same as lock-free, which is not the same as wait-free which seems to be what you are describingreplypiyh 21 hours ago | root | parent | next [\u2013]>Lockless is not the same as lock-freeCan I get the HN comment length explanation of what this means?replygpderetta 20 hours ago | root | parent | next [\u2013]Lock-free is a term of art with a formally defined meaning (at least one thread makes forward progress at any time). Lock-less doesn't really have a well defined meaning (first you would have to define what a lock is).replyMichaelZuo 18 hours ago | root | parent | next [\u2013]Sometimes I wish HN would have a term-of-art dictionary built in so users can check if there's a special meaning to reduce the chance of misinterpretation.replylionkor 1 day ago | parent | prev | next [\u2013]lockless is often the wrong term, goal, idea and solution. mutexes/futexes do very well, almost zero cost when not contended.replyasicsp 1 day ago | prev | next [\u2013]Previous discussion: https://news.ycombinator.com/item?id=29747921 (617 points | Dec 31, 2021 | 195 comments)replyhinkley 20 hours ago | parent | next [\u2013]> Therefore the Arc had to stay. Instead of using a single Arc value we can use one Arc per thread.I thought the title sounded familiar, and the culprit is more or less the same (false or in this case unnecessary sharing). But I didn\u2019t think it was quite that long ago, so maybe it\u2019s two articles about the same classic blunder.replylll-o-lll 1 day ago | prev | next [\u2013]Same problem occurs with c++ std::shared_ptr. I guess all reference counting has this inherent scaling issue due to contention ruining cache lines. Makes me wonder how/if you get linear parallelism in Swift.replymalkia 1 day ago | parent | next [\u2013]Not sure what is currently in swift, but this paper described biased reference counting approach - e.g. in way two counters - one non-atomic to be used only by specific thread (supposed owner?), and another (atomic) by all other threads - so the sum of these two shows the real reference count (somewhat). Paper here - https://dl.acm.org/doi/pdf/10.1145/3243176.3243195(Before reading the paper I was expecting that the additional bytes were put for the split counter, plus thread id - but it actually packs them using lower bits for reference counting).I wonder what abseil/folly/tbb do - need to check (we are heavy std::shared_ptr users, but I don't think 14 bits as described in the paper above would be enough for our use case)replyot 23 hours ago | root | parent | next [\u2013]Can't speak for abseil and tbb, but in folly there are a few solutions for the common problem of sharing state between a writer that updates it very infrequently and concurrent readers that read it very frequently (typical use case is configs).The most performant solutions are RCU (https://github.com/facebook/folly/blob/main/folly/synchroniz...) and hazard pointers (https://github.com/facebook/folly/blob/main/folly/synchroniz...), but they're not quite as easy to use as a shared_ptr [1].Then there is simil-shared_ptr implemented with thread-local counters (https://github.com/facebook/folly/blob/main/folly/experiment...).If you absolutely need a std::shared_ptr (which can be the case if you're working with pre-existing interfaces) there is CoreCachedSharedPtr (https://github.com/facebook/folly/blob/main/folly/concurrenc...), which uses an aliasing trick to transparently maintain per-core reference counts, and scales linearly, but it works only when acquiring the shared_ptr, any subsequent copies of that would still cause contention if passed around in threads.[1] Google has a proposal to make a smart pointer based on RCU/hazptr, but I'm not a fan of it because generally RCU/hazptr guards need to be released in the same thread that acquired them, and hiding them in a freely movable object looks like a recipe for disaster to me, especially if paired with coroutines https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p05...replymenaerus 20 hours ago | root | parent | next [\u2013]I think RW locks are also worth a mention in this problem space, and folly has them. Actually several implementations.replyot 18 hours ago | root | parent | next [\u2013]Yes, though note that RW locks need to maintain the count of readers, and most implementations just use use a single counter in the lock state word, which makes them as subject to contention as a reference count.folly::SharedMutex, the main RW lock in folly, tries to shard them by core when it detects contention (in fact it is the OG core-sharded primitive in folly) and when that works it is virtually linearly scalable, but the detection is a heuristic (which also has to minimize memory and writer cost) so there are still access patterns that can be pathological.replyloeg 17 hours ago | root | parent | prev | next [\u2013]RW locks have a pretty limited space where they're useful (because readers are still contending on a cache line to update the reader count). They're similar to a mutex + ref count. They pretty much only work well in situations where there aren't many readers and they hold the lock for a relatively long amount of time. (Ok, there are sharded reader count variants that reduce the cost of the reader count, but they're still only useful for relatively long reader lock sections.)Instead, if a mutex showed up as hot in a profile, I'd look at things like RCU/hazard pointers for read-biased data structures in most situations, or trying to shard or otherwise split data between cores such that there isn't much contention on the boring, vanilla mutex.replyot 16 hours ago | root | parent | next [\u2013]> because readers are still contending on a cache line to update the reader countThey don't have to, see my sibling comment about folly::SharedMutex.replyloeg 13 hours ago | root | parent | next [\u2013]I preemptively attempted to respond to this:> (Ok, there are sharded reader count variants that reduce the cost of the reader count, but they're still only useful for relatively long reader lock sections.)RW locks are a code/design smell, even with a cheap reader count.replyot 9 hours ago | root | parent | next [\u2013]Was that a later edit? I didn't see it when I read the comment. Also what's the point of saying that something is not possible and then \"actually it's possible, but I don't like it anyway\" in parentheses?What you're saying is wrong: if the reader section is long, you have no problem amortizing the cache invalidation. Sharded counts are useful when the reader section is small, and the cache miss becomes dominant.Also I don't get this \"RW locks are code smell\" dogma, not having RW mutexes forces you to design the shared state in a way that readers can assume immutability of the portion of the state they acquire, which usually means heavily pointer-based data structures with terrible cache locality for readers. That is, in order to solve a non-problem, you sacrifice the thing that really matters, that is read performance.I've heard this thing from Googlers, who didn't have a default RW mutex for a while, then figured out that they could add support for shared sections for free and suddenly RW mutexes are great.replyhayley-patton 1 day ago | parent | prev | next [\u2013]Coalescing reference counting [0] avoids almost all synchronisation. n.b. The abstract says they do \"not require any synchronized operation in its write barrier\" but they rely on a micro-architectural hack; in practice I'd expect one atomic test-and-set per modified object per collection.[0] https://sites.cs.ucsb.edu/~ckrintz/racelab/gc/papers/levanon...replyeldenring 1 day ago | parent | prev | next [\u2013]This is one of the most common arguments for non reference counted GCsreplyFpUser 1 day ago | parent | prev | next [\u2013]There are no miracles here because it is not a language \"feature\". It is a property of algorithms. When you divide your large task into parts and schedule execution of those on multiple threads make absolutely sure that there is no locking (atomics are locking) happening inside each individual task.replyFeepingCreature 22 hours ago | prev | next [\u2013]Small note:> In Rust, it is very easy to generate flamegraphs with `cargo flamegraph`.... Also in pretty much every other language that can generate perf stacktraces, because this is just a wrapper around Brendan Gregg's FlameGraph visualizer: https://github.com/brendangregg/FlameGraphreplyemi2k01 20 hours ago | parent | next [\u2013]`cargo-flamegraph` uses a port of FlameGraph written in Rust and handles the \"capture\" and \"fold\" steps so I'd say it's at least a bit easierreplyFeepingCreature 13 hours ago | root | parent | next [\u2013]Oh, I see! Well then, almost-full credit to them.replymalkia 1 day ago | prev | next [\u2013]in C++ std::shared_ptr (similar story) has similar effect. One of our applications (3D editor) went way slower when an artist were given a server-class machine (NUMA) and we had to ensure that all threads would run on a single CPU socket (yes they were still accessing the \"other\" memory, but it was better somehow).replyBazookaMusic 1 day ago | parent | next [\u2013]I might be wrong on this explanation, but the reason why it was faster might have been the following:During execution you had two kinds of memory locations, some in CPU caches and some in RAM. By running all the threads on one socket, everything accessed from the cache was just a fast cache access. Everything accessed from the memory was a slower memory load. Frequently loaded/stored locations will tend to go to the cache.In the NUMA setup, you would have a larger cache (more than one socket) which would mean that more locations were likely to be in the cache. However, if a core on a socket tries to access a location which is on another socket's cache, it will use the interconnect between them to access it.If you have an unfortunate memory layout, this can make it so that you end up having a large percentage of the accesses using the interconnect (slower than cache access) and values get swapped between the caches constantly, which forces subsequent accesses to also use the interconnect.Another way to avoid this except using just one socket is for the designer of a program to consider NUMA nodes as separate processing units and design around that. Both should be processing separate data and they should only share small amounts of data for synchronization/communication. Then the caches will be much less affected.replymalkia 1 day ago | root | parent | next [\u2013]That's a pretty reasonable explanation, and one day I should sit down and write some artifical test/bench to get more details.replyTwirrim 17 hours ago | parent | prev | next [\u2013]NUMA can be such a pain, especially because it's really difficult to account for in code, and all sorts of stuff you'd never think of can end up impacting your performance too, that usually you'd never even think of, e.g. the linux page cache.With the way that processors are going, with this focus on increased core counts etc, NUMA is increasingly being important to understand and account for, as processors are getting more \"NUMA-ish\" (to borrow a co-workers apt description). Especially Neoverse/Arm CPUs, etc.replyloeg 17 hours ago | parent | prev | next [\u2013]Cache synchronization operations between CPU cores (MOESI) is cheaper (lower latency) between cores in the same socket than across sockets, often by a factor of 2x or more. But also limiting the program to one socket would reduce contention significantly. Both help.replyvlovich123 1 day ago | prev | next [\u2013]I feel like using hybrid-rc [1] (biased reference counting [2]) instead of Arc should be more popular. You rarely need to send data between threads so when you do you pay the atomic cost but otherwise you\u2019re doing normal super fast arithmetic.[1] https://docs.rs/hybrid-rc/latest/hybrid_rc/[2] https://dl.acm.org/doi/10.1145/3243176.3243195replykzrdude 23 hours ago | parent | next [\u2013]Thanks for the link. Biased reference counting is a topic I've heard of in Python now too (the Nogil discussions).However, HybridRc would still be as contended in the scenario in the blog post, wouldn't it (before the fix that solved it)? Just checking my understanding.replyvlovich123 16 hours ago | root | parent | next [\u2013]That\u2019s a good question and I\u2019m not sure but I think so? The unit and RuntimeContext would be sent once to each thread and Rune would take the RC variant everywhere and only upgrade to ARC when they actually need \u2018Send (which you don\u2019t use). It requires changes to Rune obviously but I think just converting Arc into HybridRc types.replylionkor 1 day ago | prev | next [\u2013]Arc and shared_ptr should be used sparingly - especially in languages with more or less real ownership semantics, sharing ownership of state seems like a hack job.replyeldenring 1 day ago | prev | next [\u2013]Good article, but if i had to guess the subsequent L3 cache access after an increment is likely far overshadowed by the overhead of coherence messages, or the cores communicating between each other.replyfulafel 1 day ago | prev | next [\u2013]Reminder: refcounting is garbage collection. There are parallelism friendly GCs too. I wonder if the same interface in Rust could accommodate them.replyalexott 1 day ago | prev | next [\u2013]Not directly related, but https://github.com/nosqlbench/nosqlbench is very flexible benchmark tool for Cassandra and other distributed systemsreplyextasia 11 hours ago | prev | next [\u2013]I like the writing style of this post, it doesn't gloss over the details and conveys a lot of information from first principles. Good work pkolaczk.replyVectorLock 1 day ago | prev | next [\u2013]This is what I'd describe as the deepest of the deep magic.replysaagarjha 1 day ago | parent | next [\u2013]Oh, the rabbit hole goes far deeper than this.replyhahhahanananana 1 day ago | parent | prev | next [\u2013]Would love to see someone recommend some beginner-friendly books to learn more about the theory behind this blogpost. Seems like a CS degree is the only straightforward way.replymetaphor 21 hours ago | root | parent | next [\u2013]Patterson/Hennessy on Computer Organization and Hennessy/Patterson on Computer Architecture are considered foundational canon.The implied expectation underlying \"beginner-friendly\" seems naively misguided; it's an advanced undergrad computer/software engineering topic in the most permissive sense, and the blog's prose appears to have been tailored with that minimum target audience in mind.replyOscarTheGrinch 1 day ago | prev | next [\u2013]Hey, noob question guy here. Can anyone explain why the last graph shows a slight performance drop going from 48 to 96 threads?replyfrankreyes 1 day ago | parent | next [\u2013]It can be many things, my guess is likely memory bandwidth. There's so much MB/s the RAM can handle. Also, above 48 cores, those are hyper threading and for CPU bound tasks, hyper threading is known to be slower.Example: https://ieeexplore.ieee.org/document/7804711Edit: looks like there's only 12 cores per CPU so that's 24 physical cores. 48 HT cores. So the drop must be cache trashing?replyhinkley 20 hours ago | root | parent | next [\u2013]Higher parallelism is usually about timeliness for interactive workloads, not throughput. Unless it\u2019s just the classic fallacy that parallelism = speed.For throughput tasks it\u2019s often the case that you go with less parallelism to reduce Amdahl\u2019s law a few percent, and instead investing in keeping the pipeline saturated, so that the variance in concurrent tasks is lower. Work stealing being one of the more notable tricks.replykovacs_x 1 day ago | parent | prev | next [\u2013]96 processes on 24 cores, not 96 cores.apparently 2 process per core is more efficient than 4.replywilltemperley 20 hours ago | prev | next [\u2013]Pleasingly parallel is a far better term than \u201cembarrassingly parallel\u201c - it was a poor description and I never understood why people liked using a pejorative for an elegant solution.replybirdyrooster 20 hours ago | parent | next [\u2013]Some people like to be embarrassed? It\u2019s that kind of community.replysandworm101 22 hours ago | prev | next [\u2013]Let me guess: someone dared to right-click a pdf in windows explorer? My computer at work locks up every time i do that. It takes exactly 24 seconds for the server to respond. I think i could physically run back and forth to the server room in less time.(Started last month after an update. They are still trying to figure it out. I instead not use ctrl-c to copy files as that doesnt need the little menu to load. I kick myself every time i forget and accidentally right-click.)replyjcparkyn 21 hours ago | parent | next [\u2013]Just in case you haven't already done this:Try using ShellExView to disable all 3rd party shell extensions. There's a good chance that something like Acrobat is running some code that doesn't play nice with your windows version (or hardware etc).replysandworm101 21 hours ago | root | parent | next [\u2013]Ive done nothing. I can do nothing. On this network i am a simple end user, unable to change even basic settings let alone install extra software. I can only submit a work ticket and wait for our support staff to address my issue.replynottorp 1 day ago | prev | next [\u2013]Hmm so the embarrassingly parallel task wasn't embarrassingly parallel because of an implementation detail, basically?replyklabb3 23 hours ago | parent | next [\u2013]The issue with Rust in particular is that the zero-cost fearless yadda yadda is real, but often not feasible in practice. Arc is this magical escape hatch which always appears like an uninvited guest in all non-trivial real-world programs. Heck, Arc is even part of the async specification itself.It\u2019s very complicated and I don\u2019t blame anyone in particular. It\u2019s an ok solution, but it\u2019s definitely not in the zero-cost category. I\u2019d rather accept that this is the state of things and working towards systemic solutions in allowing borrowing in more situations, but that requires a compile-time verifiable hierarchical thread- and task model.Fun fact: Arc was partially the reason Rust disallowed borrowing across threads. Arc had already become popular and combined with thread borrowing someone demonstrated use-after-free. Borrowing across threads seemed less important at the time, so Arc was kept. This led to the famous \u201cleaks are safe\u201d rule, which was sold as a mere clarification of an inherent truth.It\u2019s possible that all that was inevitable and correct, but I was never convinced by the arguments made in those old threads or the subsequent writings about it. To me, it looked like details were glossed over in order to get to a swift resolution. I\u2019m quite content waiting for someone else to figure out whether Rust could have gone down a different path. Worst case, I\u2019ll come down peacefully from this tiny hill. Best case, there\u2019s an alternate timeline where Rust could live out its full potential in concurrent environments.replyfulafel 1 day ago | prev | next [\u2013]Also 24-core servers from cloud services usually run your app slower than a laptop anyway.replyandrepd 1 day ago | prev | next [\u2013]>Although using atomic instructions is often referred to as \u201clockless programming\u201d, this is slightly misleading \u2013 in fact, atomic operations require some locking to happen at the hardware level.Lockless/lockfree refers to the fact that there are no deadlocks.replydist1ll 22 hours ago | parent | next [\u2013]That's not entirely correct. Deadlock-freedom means that at least one thread will make progress in the absence of failures.Lock-freedom is a much stronger statement. It guarantees progress of at least on thread in finite time, regardless of failures.Source: Dan Alistarh, Keren Censor-Hillel, and Nir Shavit. \"Are lock-free concurrent algorithms practically wait-free?\" December 2013replySniffnoy 1 day ago | prev | next [\u2013](2021)replysaagarjha 1 day ago | parent | next [\u2013]Updatedreplysalawat 21 hours ago | prev [\u2013]The joys of parallelism. Communication/signal propagation is hard, yet extremely rewarding once you nail it. You've really gotta be willing to dig into the guts of what you're doing though.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The use of asynchronous code, coroutines, and parallelization techniques in programming.\n- The importance of dividing work in a way that maximizes parallelism and minimizes contention.\n- The impact of data structures and algorithms on parallel performance.\n- The challenges and trade-offs in scaling parallel programs.\n- The potential performance gains in optimizing code for parallel execution."
  },
  {
    "id": 36382361,
    "timestamp": 1687109641,
    "title": "Goodbye, Twilio",
    "url": "https://blog.miguelgrinberg.com/post/goodbye-twilio",
    "hn_url": "http://news.ycombinator.com/item?id=36382361",
    "content": "miguelgrinberg.comHomeMy Courses and BooksConsultingAbout MeGoodbye, TwilioPosted by on June 18, 2023 underAs of this week and after almost four years, I'm not a Twilio employee anymore. I'm writing this while I work through a range of conflicting emotions, and try to adapt to new daily routines without Twilio in my life. Before you jump to conclusions let me clarify that I have not been laid off. The decision to leave the company was mine alone.When I joined Twilio in 2019, this is how the company presented itself to the world, as seen through the famous billboard on the 101 freeway in San Francisco:The three words in this billboard are possibly one of the best marketing campaigns of all times (I'm not the only one who thinks so). With such a simple message, Twilio established itself as a company for and by developers. Even though I never lived in San Francisco, I visited for work and pleasure countless times, and have always considered the Twilio billboard a welcoming landmark as I drove from the airport to the city. When I eventually joined Twilio, it was a dream come true for me.You can see in the picture above that there is some additional text in small print to the right of the Twilio logo. Through the years this billboard has been up, a few different messages appeared in that part of the sign. The two most used were:Voice, SMS, and Video APIsThe Cloud Communications PlatformThese complemented the three-word shout-out to developers, and helped cement Twilio's position as the leader in developer-friendly communication APIs.Early in 2023, the billboard was given a full redesign. This is how it looks today:I'd risk that now most travelers on the 101 are confused by this sign and forget they saw it a second or two after passing it by. The message in the bottom right of the billboard, which now reads Customer Engagement Platform is also, in my opinion, too vague and less indicative of what the company stands for.The changes made to the billboard are actually a reflection of the internal changes that are ongoing inside Twilio. Before, the company was laser-focused on helping developers become the heroes of their companies by equipping them with best-in-class APIs to solve their communication problems. Now, the goals have shifted and the vision is not as clear as it used to be, so much that the new billboard needs an explanatory blog post.Sadly, us developers are not at the center of everything anymore at Twilio. The new Twilio wants to help companies collect, use and even make up customer data, all with the goal to drive more sales. For me it was easy to identify with a company that helps people communicate. My views on online privacy, however, make it difficult to find alignment anymore.So this is it for me, then. Goodbye, Twilio. And thank you.In spite of two rounds of mass layoffs and some attrition, many of my friends and colleagues are still employed and continue to be awesome as they adapt to new company goals. I have no idea what's going to happen in the future, but my hope is that those who are staying are able to help Twilio find its way back to greatness.What's Next?I'm sure you want to know what the future has in store for me. The short answer is I don't know yet. My plan is to take my time to look for a new great company with a developer-first culture that wants to have me. Do you have any leads? Be sure to let me know!In the meantime, I'll have some extra time to dedicate to my open source projects. I'm also making some time to work on short or medium-term projects on a contract basis, so if you or your company have something you think I can help you with, I'll be more than happy to chat with you. See my Consulting page for details.Become a Patron!Hello, and thank you for visiting my blog! If you enjoyed this article, please consider supporting my work on this blog on Patreon!Share this post:Hacker NewsRedditTwitterLinkedInFacebookE-MailNo comments yetLeave a CommentNameEmailCommentCaptchaFlask Web Development, 2nd EditionIf you want to learn modern web development techniques with Python and Flask, you may find the second edition of my O'Reilly book useful.Click here to get this Book!About MiguelWelcome to my blog!I'm a software engineer and technical writer, currently living in Drogheda, Ireland.You can also find me on Twitter, Mastodon, Github, LinkedIn, YouTube, Facebook and Patreon.Thank you for visiting!Categories179158184610011183082513721571138617186112231\u00a9 2012-2023 by Miguel Grinberg. All rights reserved. Questions?",
    "summary": "- The author is no longer an employee at Twilio after almost four years. Their decision to leave the company was voluntary.\n- The author reflects on the changes that have occurred at Twilio, including a shift towards a goal of collecting and using customer data to drive sales, which no longer aligns with the author's views on online privacy.\n- The author plans to take their time to find a new company with a developer-first culture and is open to consulting and contract opportunities in the meantime.",
    "hn_title": "Goodbye, Twilio",
    "original_title": "Goodbye, Twilio",
    "score": 494,
    "hn_content": "- Twilio, a communications platform, has undergone significant changes as it shifted its focus from a developer-centric company to a customer engagement platform.\n- The change in focus reflects the evolving needs of the company and the industry, and the importance of sales, marketing, and business aspects in driving growth.\n- Twilio's billboard messaging showcases its shift in focus, with the previous \"Ask your developer\" tagline being replaced by more business-oriented messaging.\n- The change has sparked discussions about the role of developers in the company and the impact of shifting priorities.\n- Twilio's decision to acquire Segment, a customer data platform, aligns with its new focus on customer engagement and the integration of data and communication services.\n- Some people view Twilio's shift as a necessary step for the company's growth and success, while others express concern about losing its developer-centric approach.\n- Twilio faces challenges related to maintaining profitability, addressing fraud and scam vectors, and the increasing costs associated with providing its services.\n- The company's shift highlights the importance of finding a balance between technical excellence and sales and marketing efforts in order to succeed in the industry.- Twilio's shift in focus towards marketing and customer engagement has disappointed some developers.\n- The company's acquisition of SendGrid and introduction of new products like Twilio Flex are seen as moves away from its developer-centric roots.\n- Developers are concerned that Twilio is prioritizing high-margin business over providing expanded technical services to its existing customers.\n- Some users have experienced frustrating issues with Twilio, such as account suspensions and lackluster support.\n- Twilio's recent layoffs and the changes in its direction have raised questions about the company's long-term vision.\n- Alternatives to Twilio, such as Voximplant, Plivo, and Bandwidth, are mentioned, but their suitability varies depending on individual needs.\n- The impact of Twilio's changes on developers and the potential implications for the future of programmable messaging are discussed.",
    "hn_summary": "- Twilio has shifted its focus from a developer-centric company to a customer engagement platform, sparking discussions about the role of developers and the impact of shifting priorities.\n- The company's decision to acquire Segment and its introduction of new products like Twilio Flex are seen as a move away from its developer-centric roots, disappointing some developers.\n- Twilio's changes have raised questions about the company's long-term vision and the potential implications for the future of programmable messaging."
  },
  {
    "id": 36379615,
    "timestamp": 1687091169,
    "title": "Follow up to \"I booted Linux 293k times\"",
    "url": "https://rwmj.wordpress.com/2023/06/18/follow-up-to-i-booted-linux-292612-times/",
    "hn_url": "http://news.ycombinator.com/item?id=36379615",
    "content": "Richard WM JonesHOMEABOUT\u2190 I booted Linux 292,612 timesJUNE 18, 2023 \u00b7 10:35 AM\u2193 Jump to CommentsFollow up to \u201cI booted Linux 292,612 times\u201dWell that blew up. It was supposed to be just a silly off-the-cuff comment about how some bugs are very tedious to bisect.To answer a few questions people had, here\u2019s what actually happened. As they say, don\u2019t believe everything you read in the press.A few weeks ago I noticed that some nbdkit tests which work by booting a Linux appliance under qemu were randomly hanging. I ignored it to start off with, but it got annoying so I decided to try to track down what was going on. Initially we thought it might be a qemu bug so I started by filing a bug there and writing my thoughts as I went to investigate. After swapping qemu, Linux guest and Linux host versions around it became clear that the problem was probably in the Linux guest kernel (although I didn\u2019t rule out an issue with KVM emulation which might have implicated either qemu or the host kvm.ko module).Initially I just had a hang, and because getting to that hang involved booting Linux hundreds or thousands of times it wasn\u2019t feasible to attach gdb at the start to trace through the hang. Instead I had to connect gdb after observing the hang. It turns out that when the Linux guest was \u201changing\u201d it really was just missing a timer event so the kernel was still running albeit making no progress. But the upshot is that the stack trace you see is not of the hang itself, but of an idle, slightly confused kernel. gdb was out of the picture.But since guest kernel 6.0 seemed to work and 6.4rc seemed to hang, I had a path to bisecting the bug.Well, a very slow path. You see there are 52,363 commits between those two kernels, which means at least 15 or 16 bisect steps. Each step was going to involve booting the kernel at least thousands times to prove it was working (if it hung before then I\u2019d observe that).I made the mistake here of not first working on a good test, instead just running \u201cwhile guestfish \u2026 ; echo -n . ; done\u201d and watching until I\u2019d seen a page of dots to judge the kernel \u201cgood\u201d. Yeah, that didn\u2019t work. It turns out the hang was made more likely by slightly loading the test machine (or running the tests in parallel which is the same thing). As a result my first bisection that took several days got the wrong commit.Back to the drawing board. This time I wrote a proper test. It booted the kernel 10,000 times using 8 threads, and checked the qemu output to see if the boot had hung, stop the test and print a diagnostic, or print \u201ctest ok\u201d if it got through all iterations. This time my bisection was better but that still took a couple of days.At that point I thought I had the right commit, but Paolo Bonzini suggested to me that I boot the kernel in parallel, in a loop, for 24 hours at the point immediately before the commit, to try to show that there was no latent issue in the kernel before. (As it turns out while this is a good idea, this analysis is subtly flawed as we\u2019ll see).So I did just that. After 21 hours I got bored (plus this is using a lot of electricity and generating huge amounts of heat, and we\u2019re in the middle of a heatwave here in the UK). I killed the test after 292,612 successful boots.I had a commit that looked suspicious, but what to do now? I posted my findings on LKML.We still didn\u2019t fully understand how to trigger the hang, except it was annoying and rare, seemed to happen with different frequencies on AMD and Intel, could be reproduced by several independent people, but crucially kernel developer Peter Zijlstra could not reproduce it.[For the record, the bug is a load and hardware-speed dependent race condition. It will particularly affect qemu virtual machines, but at least in theory it could happen on baremetal. It\u2019s not AMD or Intel specific, that\u2019s just a timing issue.]By this point several other people had observed the hang including CoreOS developers and Rishabh Bhatnagar at Amazon.A commenter on Hacker News pointed out that simply inserting a sleep into the problematic code path caused the same hang (and I verified that). So the commit I had bisected to was the wrong one again \u2013 it exposed a latent bug simply because it ran the same code as a sleep. It was introducing the sleep which exposed the bug, not the commit I\u2019d spent a week bisecting. And the 262K boots didn\u2019t in fact prove there was no latent bug. You live and learn \u2026Eventually the Amazon thread led to Thomas Gleixner suggesting a fix.I tested the fix and \u2026 it worked!Unfortunately the patch that introduced the bug has already gone into several stable trees meaning that many more people will likely be hitting the problem in future, but thanks to a heroic effort of many people (and not me, really) the bug has been fixed now.Share this:RedditTwitterEmailPrintLoading...RelatedBooting Fedora 19 ppc64 netinst under qemu on x86-64August 27, 2013In \"fedora\"How many disks can you add to a (virtual) Linux machine? (contd)April 28, 2017In \"hard drives\"Booting RISC-V Linux with qemuJune 11, 2015In \"ISAs\"Leave a commentFiled under UncategorizedTagged as debugging, kernelLeave a ReplyThis site uses Akismet to reduce spam. Learn how your comment data is processed.Recent PostsFollow up to \u201cI booted Linux 292,612 times\u201dI booted Linux 292,612 timesNBD-backed qemu guest RAMnbdkit\u2019s evil filterFrame pointers vs DWARF \u2013 my verdictSmithForthFrame pointers \u2013 an important updatenbdkit + libblkioCreating a modifiable gzipped disk imageAn NBD block device written using Linux ublk (user block device)nbdkit for macOSSSH from RHEL 9 to RHEL 5 or RHEL 6Composable tools for disk imagesnbdkit now supports LUKS encryptionInstalling Fedora 34 on my Turing Pi 7 node clusterInterview for Red Hat BlogHiFive UnmatchedBeagleVTuring Pi 1nbdkit 1.24 & libnbd 1.6, new copying toolRecent CommentsEhud Gavron on I booted Linux 292,612 ti\u2026Ehud Gavron on I booted Linux 292,612 ti\u2026robi on I booted Linux 292,612 ti\u2026Oscar Henr\u00edquez on I booted Linux 292,612 ti\u2026Alaafia on I booted Linux 292,612 ti\u2026Tim on I booted Linux 292,612 ti\u2026valdikss on I booted Linux 292,612 ti\u2026rich on I booted Linux 292,612 ti\u2026valdikss on I booted Linux 292,612 ti\u2026valdikss on I booted Linux 292,612 ti\u2026About the authorI am Richard W.M. Jones, a computer programmer. I have strong opinions on how we write software, about Reason and the scientific method. Consequently I am an atheist [To nutcases: Please stop emailing me about this, I'm not interested in your views on it] By day I work for Red Hat on all things to do with virtualization. I am a \"citizen of the world\".My motto is \"often wrong\". I don't mind being wrong (I'm often wrong), and I don't mind changing my mind.This blog is not affiliated or endorsed by Red Hat and all views are entirely my own.aarch64 AMD ARM bbc c++ centos cluster cron debian disk image disk images febootstrap fedora filesystems fosdem fpga FUSE git guestfish guestfs-browser guestmount hardware hivex ideas kernel kvm kvm forum libguestfs libguestfs-1.12 libnbd libvirt linux lvm nbd nbdkit ocaml odroid openstack performance perl programming python qemu rants red hat registry rhel risc-v rpm security ssh tip ubuntu v2v video virt-builder virt-cat virt-df virt-edit virt-inspector virt-install virt-manager virt-p2v virt-rescue virt-resize virt-sysprep virt-tools virt-v2v virt-win-reg virtualization virtual machine vmware whenjobs windows windows registry RSS - Posts RSS - CommentsRichard WM Jones \u00b7 Virtualization, tools and tipsCreate a free website or blog at WordPress.com.FollowPrivacy & Cookies: This site uses cookies. By continuing to use this website, you agree to their use.To find out more, including how to control cookies, see here: Cookie Policy",
    "summary": "- The writer experienced a bug in Linux that caused the system to hang randomly, and decided to track down the issue.\n- They performed extensive testing and bisection to identify the specific commit that introduced the bug.\n- The bug has been fixed thanks to the efforts of various developers, but it may still affect users who have already installed the patch.",
    "hn_title": "Follow up to \u201cI booted Linux 293k times\u201d",
    "original_title": "Follow up to \u201cI booted Linux 293k times\u201d",
    "score": 304,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginFollow up to \u201cI booted Linux 293k times\u201d (rwmj.wordpress.com)304 points by pabs3 21 hours ago | hide | past | favorite | 31 commentsmcdonje 20 hours ago | next [\u2013]>but thanks to a heroic effort of many people (and not me, really)...That's funny because when I was reading through this I kept thinking, \"Wow, this is a heroic effort.\"It was a heroic individual effort that led to a heroic team effort. The team wouldn't have been assembled had the individual not raised the alarm and focused the attention. Then the team was able to handle it through their collective efforts. Doubly inspiring.replynoir_lord 19 hours ago | parent | next [\u2013]I've observed this many times over my career, a thorny problem that no-one wants to touch or look at sits there for ages until I take a run at it, as soon as I do everyone piles in and helps.It's the Bystander Effect in code.replyaendruk 15 hours ago | root | parent | next [\u2013]Reminds me of the psychology behind crowdmatching a la Snowdrift.coop. If no one else is working on the problem I also don\u2019t feel inclined to; it doesn\u2019t seem worth it because the chance of success is low. But if I know that other people are in it with me I\u2019m suddenly motivated because I can expect my contributions to help actually solve the problem.replyrattray 20 hours ago | prev | next [\u2013]Bit of a spoiler, but I did find this a fun followup worth skimming:> So the commit I had bisected to was the wrong one again \u2013 it exposed a latent bug simply because it ran the same code as a sleep.The fix was by someone else, and is here: https://lore.kernel.org/stable/20230615091830.RxMV2xf_@linut...replymitko 17 hours ago | parent | next [\u2013]It is not that the commit was wrong. It was the right commit, in the sense that it did expose and trigger the bug. OP is being too modest :)But the root cause of the bug was in another earlier commit. In a complex system such as the linux kernel, there could be multiple contributing factors. Both the \"introducing a sleep\" and the \"root bug\" are contributing factors, but we as engineers tend to think of the \"root bug\" as the actual problem, because we like more elegant explanations. Also, the \"root bug\" is likely something that goes against the ethos of the software project, and \"common sense best practices\", to a much larger degree than \"introducing a sleep\" is.replysamwillis 21 hours ago | prev | next [\u2013]Previous thread from original post: https://news.ycombinator.com/item?id=36325986808 points, 3 days ago, 266 comments.replyMR4D 20 hours ago | prev | next [\u2013]\u201cAfter 21 hours I got bored\u2026\u201dThere are devs and then there are kernel devs.The relentless pursuit of bugs is truly impressive.replyvasco 20 hours ago | parent | next [\u2013]Bored of waiting for the parallel run, I don't think they were investigating for 21h straight. Previous paragragh:> Paolo Bonzini suggested to me that I boot the kernel in parallel, in a loop, for 24 hours at the point immediately before the commitOtherwise I don't disagree that perseverance is important to get to the bottom of this stuff.replykneebonian 13 hours ago | parent | prev | next [\u2013]A great article by James Mickens entitled \"The night watch\" explains what it really means to be a kernel dev.https://scholar.harvard.edu/files/mickens/files/thenightwatc...replyMR4D 6 hours ago | root | parent | next [\u2013]\u201czombies who say \u201csir\u201d and \u201cma\u2019am\u201d but then try to eat your brain\u201dAwesome read! Thanks for sharing.replyplq 12 hours ago | root | parent | prev | next [\u2013]Man, what a masterpiece, even the title gives me chuckles :) Thanks for bringing it upreplyweinzierl 20 hours ago | prev | next [\u2013]Not surprised Thomas Gleixner ultimately found the root cause. He did a lot of real time work and this bug was a timer related bug.replyx86x87 19 hours ago | prev | next [\u2013]I think that the author is too modest. Refreshing to see.The amount of attention this received probably led to a way faster fix.replyasylteltine 20 hours ago | prev | next [\u2013]Can someone explain the problem and fix in plain Englishreplydelecti 17 hours ago | parent | next [\u2013]There was a rare race condition [1] bug in the linux kernel, and they didn't know precisely where it was introduced (which made it difficult to know what to change to fix it). They knew it was introduced at some point between two versions, but there were 52,363 code changes between those two versions. Because the bug was rare, you would have to test any given code change multiple times (thousands of times, in their case) to be confident that the bug was still present (if working backwards), or still absent (if working forwards). A way to do that faster is a binary search [2], or commit bisection.Basically, you know commit 0 is fine, and change 52,363 is bad, so you run 1000 tests on change 26,180 to cut in half the number of commits that could have introduced the problem. If the bug is still there, then you run 1000 tests on change 13,090; if the bug is not in change 26,180, then you run 1000 tests on change 39,270. Eventually (after 15 or 16 iterations) you'll narrow down the problem to a single change which introduced the problem. Unfortunately code is complicated, so the first time they ran that procedure, their tests didn't find the right bug, so they did it again but slightly differently.(many details omitted for simplicity)[1] https://en.wikipedia.org/wiki/Race_condition[2] https://en.wikipedia.org/wiki/Binary_search_algorithm?replyufo 13 hours ago | root | parent | next [\u2013]Furthermore, in this case there were actually two commits related to the bug. An older commit that introduced the race condition, and a second commit that triggered it (by subtly changing how long a certain function took to run).The long bisection process identified the second commit but it took further work to identify the true cause of the bug.replysh34r 15 hours ago | root | parent | prev | next [\u2013]It's worth mentioning that this generalized problem in user space can often be solved much more easily using concurrent fuzz testing (ex: https://www.microsoft.com/en-us/research/project/cuzz-concur...).Unfortunately, when the problem is in kernel boot software, that is not a practical solution for obvious reasons, and you're left using more basic techniques like running a binary search on the commit history.replysmaddox 17 hours ago | parent | prev | next [\u2013]Based on my reading, under some circumstances the scheduler wasn't dedicating large enough chunks of time to a particular boot process for it actually make progress. The fix appears to have been to change how the time chunk size was calculated.replydev_tty01 16 hours ago | root | parent | next [\u2013]As a curious onlooker, was the calculated time below a reasonable minimum?replyjseutter 14 hours ago | root | parent | next [\u2013]In retrospect you could say yes, but it was hard to tell. It ended up being either okay or not okay depending on Intel vs AMD and clock speed.replypaulclinger 15 hours ago | root | parent | prev | next [\u2013]Based on my reading it looks like the accuracy wasn't enough, so they switched it to a bit later time when hires timer was already available.replyamtamt 19 hours ago | prev | next [\u2013]> You see there are 52,363 commits between those two kernels,Would it have been possible to generate a list of commits on timeline and perform bisects in a method similar to binary search? Or that was already done and still 293k boots were needed? I am genuinely curious.replydetaro 19 hours ago | parent | next [\u2013]> in a method similar to binary search?That's what bisect means. You do a binary search for the breaking commitreplykangalioo 18 hours ago | root | parent | next [\u2013]Exactly, and the reason 293k boots were needed anyways is because the bug was hard to reproduce and needed thousands of boots to potentially triggerreplyhinkley 16 hours ago | root | parent | next [\u2013]That\u2019s why I always push telemetry onto a team. Concurrency and resource bugs are extremely expensive per iteration. Anything that can hint that the problem you are certain happened somewhere in a two month period was more likely to have happened in a particular week saves you a ton of work.The human brain struggles when it has to execute almost, but not quite, the same exercises over and over again. It becomes a blur and after a while you can\u2019t recall if you ran all of the steps this cycle (if you can\u2019t automate the test well) and all it takes is typing \u201cbad\u201d when you meant \u201cgood\u201d to end in failure. Which doesn\u2019t sound like a big likelihood but when you\u2019re testing a negative it\u2019s much easier to get your wires crossed.replycwillu 16 hours ago | parent | prev | next [\u2013]Expanding on other comments: binary search is extremely sensitive to false positives and false negatives\u2026 false information generally. While other approaches will still put you in the right ballpark even with some amount of incorrect information, a binary search with a single flipped bit will consistently land you in entirely unrelated areas, so you need to be _damn_ sure your \u201cgit bisect good/bad\u201d is correct.replywging 13 hours ago | root | parent | next [\u2013]There is `git bisect skip` (https://git-scm.com/docs/git-bisect#_bisect_skip), which lets you cope with a testing process that sometimes doesn't yield a true/false result. But it's more useful for untestable commits than for inconclusive results like you'd get from a single boot here.replyrwmj 15 hours ago | root | parent | prev | next [\u2013]In the other post there was an interesting discussion about different approaches to searching for a bug (other than straight bisection) when your test is unreliable: https://news.ycombinator.com/item?id=36327263replyalsetmusic 17 hours ago | prev | next [\u2013]Previous discussion: https://news.ycombinator.com/item?id=36325986replyswordbeta 12 hours ago | prev [\u2013]I am unfamiliar with kernel dev but shouldn't that commit also need to add some kind of unit test?replykevans91 6 hours ago | parent [\u2013]Race conditions in places like this are exceedingly hard to write reliable tests for. It may take one, two boots; dozens, or thousands, or you may just get insanely lucky and whatever arbitrary # boots you do to try and reproduce it was still simply not enough. It's hard to have any level of confidence, in many cases.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- The process of identifying and fixing a rare race condition bug in the Linux kernel is discussed in the article\n- The bug was introduced between two versions of the kernel, and there were over 52,000 code changes to consider\n- The author used a binary search approach, running tests on different code changes to narrow down the bug's source"
  },
  {
    "id": 36376875,
    "timestamp": 1687056568,
    "title": "Scientists create contained ball of turbulence in a tank",
    "url": "https://news.uchicago.edu/story/tempest-teacup-uchicago-physicists-make-breakthrough-creating-turbulence",
    "hn_url": "http://news.ycombinator.com/item?id=36376875",
    "content": "Tempest in a teacup: UChicago physicists make breakthrough in creating turbulenceUniversity of Chicago scientists pioneered a way to create a contained \u201cball\u201d of turbulence in a tank of water, which has never been done before. Above, a visualization shows the average energy density of the ball over time.Image courtesy Takumi MatsuzawaScientists create contained ball of turbulence in a tank that could help answer longstanding questionsTurbulence is all around us. It\u2019s in the swirl of coffee and milk in a latte, unfurling along the wings of airplanes and the sides of cars, churning the blood in your heart after the valve snaps closed. Yet we still don\u2019t fully grasp all of its rules. Part of the challenge is that physicists typically start by isolating the phenomenon from its environment to study it \u2013 but stirring a cup means the spoon is always still inside it, affecting the movement of the liquid. There hasn\u2019t been a way to separate the turbulence out by itself.A group of University of Chicago scientists, however, have pioneered a way to create contained turbulence in a tank of water. They use a ring of jets to blow loops until an isolated \u201cball\u201d of turbulence forms and lingers.\u201cIt was a surprise to us,\u201d said physicist Takumi Matsuzawa, the first author on a study describing the findings, published in Nature Physics. \u201cIt\u2019d be like calmly sitting in a field with a picnic and watching a storm raging 50 feet away,\u201d said Prof. William Irvine, the corresponding author on the study.They hope the breakthrough opens a new avenue of study to better understand turbulence. \u2018No one knew this was even possible\u2019Turbulence\u2014the chaotic flow in an unevenly mixed substance\u2014is an old problem. \u201cIt\u2019s often quoted as one of the big open questions in physics,\u201d said Irvine. In the past decades, scientists have made progress in describing the behavior of an \u201cidealized\u201d state of turbulence. That is, turbulence without confounding variables like boundaries, or variations in strength and time. But when it comes to real-world turbulence, there is much left to understand. \u201cTurbulence appears everywhere around us, but it keeps eluding what physicists consider a satisfying description,\u201d said Irvine. \u201cFor example, if you ask, can I predict what happens next when I poke this region of turbulence? The answer is no. Not even really with a supercomputer.\u201d One of the big problems was the presence of confounding variables in experiments. You can make turbulence by shooting a fast jet of water through a pipe or by stirring a paddle in a tank of water, but the turbulence is always brushing up against the container walls and the stirrer, which affects the results.Matsuzawa, Irvine, and their collaborators had been running experiments with tanks of water to make \u201cvortex rings\u201d \u2013 like smoke rings, but in water. When they tried to combine them to make turbulence, the energy usually bounced right back at them before dissipating. By Louise LernerJun 15, 2023FacebookTwitterLinkedInEmailPrintTOP STORIESDigital artwork blooms endlessly on campusMagic words: Can what you say help you get your way? with Jonah Berger (Ep. 114)Argonne, UChicago scientists create low-cost way to make clean hydrogen fuelNEWSLETTERGet more with UChicago News delivered to your inbox.RECOMMENDEDScientists create tiny capsules that can vacuum up or deliver cargo\u2026UChicago physicist selected for $2 million Brown Investigator AwardA high-speed photograph shows the vortex rings as they are fired from the sides of the tank. The bubbles show the outline of the ring.Image courtesy Dustin KlecknerBut once they hit upon a particular configuration \u2013 a box with eight corners, each containing a vortex ring generator \u2013 something odd happened. When they repeatedly fired rings that met in the center, they watched as a ball of turbulence formed that was self-contained \u2013 away from the walls of the tank. This itself was a breakthrough: \u201cNo one knew this was even possible,\u201d said Matsuzawa, who is a graduate student in physics. \u201cTurbulence is very good at mixing things; if you mix your milk into your coffee, you can only get one or two swirls in before it becomes completely mixed. The fact we can contain it in place is very surprising.\u201d A visualization of the experiment setup. The central tank is filled with water, and eight vortex rings (shown here in blue) are fired from the corners. Where they meet in the center, a ball of turbulence forms.Image courtesy Takumi MatsuzawaMatsuzawa explained that a freestanding ball of turbulence allows scientists, using lasers and multiple fast cameras, to track its parameters much more precisely. This includes its energy and its helicity (a measure of how tangled or \u201cknotty\u201d the loops are) as well as the impulse and angular impulse (the fluid equivalent of momentum and angular momentum).What\u2019s more, they could play with it by varying the parameters. They could change whether the loops they sent in were helices spinning clockwise or counterclockwise. They could change the amount of energy going in, or stop adding rings and watch the turbulence dissipate, or vary the helicity of the rings and see how the turbulence evolved over time. \u201cHow does turbulence dissipate? How does it expand? What does it \u201cremember\u201d? How does the energy spread across scales? Are there different types of turbulence? There are all kinds of questions we could ask, and this is a unique setting with which to ask them,\u201d Irvine said. \u201cI really hope this can help open up a new playground in the field.\u201dThe researchers track the turbulence with lasers and high-speed cameras.Image courtesy Takumi MatsuzawaA visualization from the experiment was awarded the 2022 APS/DFD Gallery of Fluid Motion Award, from the American Physical Society. Noah P. Mitchell (Ph.D.\u201918, now with the Kavli Institute for Theoretical Physics at UC-Santa Barbara) and St\u00e9phane Perrard (formerly a UChicago postdoctoral researcher, now with ESPCI Paris) were also co-authors on the paper. The research used the National Science Foundation-supported Materials Research Science and Engineering Center and the Research Computing Center at the University of Chicago.Citation: \u201cCreation of an isolated turbulent blob fed by vortex rings.\u201d Matsuzawa, Mitchell, Perrard, and Irvine, Nature Physics, May 11, 2023. FacebookTwitterLinkedInEmailPrintRELATED TOPICSDivision of the Physical Sciences , James Franck Institute , Physics , Research Computing Center , William Irvine",
    "summary": "- Scientists at the University of Chicago have created a contained \"ball\" of turbulence in a tank of water, which has never been done before.\n- This breakthrough could help researchers better understand turbulence, which is still not fully understood in physics.\n- The researchers were able to track the parameters of the turbulence more precisely using lasers and high-speed cameras, opening up new avenues for study in the field.",
    "hn_title": "Scientists create contained ball of turbulence in a tank",
    "original_title": "Scientists create contained ball of turbulence in a tank",
    "score": 287,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginScientists create contained ball of turbulence in a tank (uchicago.edu)287 points by gmays 1 day ago | hide | past | favorite | 44 commentsmotohagiography 1 day ago | next [\u2013]The visualization of the experiment is amazing, they got an award for it. What a great data visualization does is scale your ability to use other minds to reason about a problem. https://gfm.aps.org/meetings/dfd-2022/62ea9a06199e4c2da9a944...replylukko 17 hours ago | parent | next [\u2013]Thanks for sharing! Amazing video...Also reminds me of this classic - Schrodinger's smoke from SIGGRAPH 2016: https://www.youtube.com/watch?v=5C9BLAXCe1IreplyjimmySixDOF 1 day ago | parent | prev | next [\u2013]Amazing demonstration of yet another example of things that just work better in 3D. Seeing the 3D simulation through a 2D video on a 2D screen works to get the point across but it's so much better with the affordances of XR. I am hopeful it will become standard to publish to that medium in the near future so you can just click on a web link to see this whole system floating around you at whatever scale and perspective you choose. That to me would really help your ability to use others minds to reason about a problem, as you put it so well.replyontowelton 1 day ago | parent | prev | next [\u2013]The visualization of the paths of the vortex rings looks mimetically like electron orbitalsreplygoldenkey 1 day ago | root | parent | next [\u2013]That's because the orbitals are the consequence of spherical harmonic interference.https://en.wikipedia.org/wiki/Spherical_harmonicsreplyrrobukef 22 hours ago | root | parent | next [\u2013]Does that mean you can shoot 8 electrons and create a contained ball of electromagnetic turbulence?replymecsred 19 hours ago | root | parent | next [\u2013]Electrons would just strongly scatter. You would probably need a charge distribution that produces an EM field which looks like the vortex rings. I forget how the analogy for fluid systems works, I think you have to make Poynting vector <-> pressure vector for the math to look similar? Not sure if that would work exactly but you can definitely make a ball of EM turbulence.replyreaperman 1 day ago | parent | prev | next [\u2013]Thank you, this video made it instantly understandable.replydownboots 14 hours ago | parent | prev | next [\u2013]Did they also try repeatedly colliding 2 vortex rings? That may make more sense of what parameter changes do (?)replymock-possum 16 hours ago | parent | prev | next [\u2013]\u201cA steady, tunable, isolated turbulent blob!\u201dreplynewZWhoDis 20 hours ago | parent | prev | next [\u2013]Fascinating! I wonder if this explains ball lightning?replykoolba 1 day ago | prev | next [\u2013]> A group of University of Chicago scientists, however, have pioneered a way to create contained turbulence in a tank of water. They use a ring of jets to blow loops until an isolated \u201cball\u201d of turbulence forms and lingers.So they invented a real world Rasengan?replyH4rryp0tt3r 18 hours ago | parent | next [\u2013]You just summarised the whole thing in a sentence! (Of course one needs to know at least a few 100 episodes of Naruto)replyhackernewds 1 day ago | parent | prev | next [\u2013]Now to devise a way for a Susano'o next.replykoliber 1 day ago | prev | next [\u2013]I love all the things that people said that this reminds them of in this comment thread.The first thing that came to mind is the game of life simulations people make using walker guns. This is a 3D 8-gun game-of-real-life simulation.replyChuckMcM 1 day ago | prev | next [\u2013]This is a pretty neat result. I wonder if it could be used to study plasma and/or fusion.replymumumu 1 day ago | parent | next [\u2013]Also detonation. It Could make Rotation Detonation Engines possible.replynomel 1 day ago | root | parent | next [\u2013]Could you expand on that? I know just a little about detonation engines, and can\u2019t fathom how this is related.replymumumu 12 hours ago | root | parent | next [\u2013]Flow instability is one of the biggest challenges to get them to operate for long time without blowing up. Of course, there are others.Any progress on the control of chaotic flow is great news. Even at subsonic speed.replyChuckMcM 1 day ago | root | parent | prev | next [\u2013]A very good point.replynomel 1 day ago | parent | prev | next [\u2013]Isn\u2019t it inertial? What would the equivalent be with plasma/fusion?replywillis936 1 day ago | root | parent | next [\u2013]Shooting rings of plasma. Forming a ring of hot dense plasma moving quickly is an exercise for the reader.It's alluring because turbulent modes are one of the leakier parts of magnetic confinement fusion devices. \"Confining turbulence\" is a thing that makes plasma physicists sit up in their chair.replyDrBazza 23 hours ago | root | parent | next [\u2013]> \"Confining turbulence\" is a thing that makes plasma physicists sit up in their chair.Self-confined, doubly so.replynomel 4 hours ago | root | parent | prev | next [\u2013]But does this inertial phenomenon somehow translate to plasma? Is there some analog in the physics, or are these comments speculation?replywillis936 35 minutes ago | root | parent | next [\u2013]Bulk plasmas behave as fluids as described by magnetohydronamic theory. If you observe a behavior in fluids there is a good chance that behavior will exist in plasmas if scaled correctly in size and time. Plasmas are, obviously, much more complicated. This warrants experimentation though because no one has ever tested something like this.replyzmgsabst 21 hours ago | root | parent | prev | next [\u2013]We have that part covered; though unclear that we could get four systems into close enough proximity without negatively impacting each other.https://www.youtube.com/watch?v=_bDXXWQxK38Still, if it allowed for more complete burning and/or less power input per axis\u2026replylost_tourist 19 hours ago | parent | prev | next [\u2013]I was wondering the same. I know very little about either, but it reminds me of the containment issues that plasma fusion has, and I wondered if they could do something similar and make a controlled turbulence.replyGravityloss 1 day ago | prev | next [\u2013]If this gives us better fluid dynamic models and better designs, it could be huge. Better ship propellers and hulls, cars, trucks, airplanes, jet engines. Wind turbines and gas turbines. Also combustion and all kinds of chemical reactions that need mixing.replysemi-extrinsic 1 day ago | parent | next [\u2013]My understanding is that this will not give us any breakthroughs in fluid dynamic modelling capabilities for real life applications.The main challenge for turbulence modelling in applications is to accurately represent the boundary layers around walls, especially where you have transitions and separation. Isotropic turbulence like they have here is well resolved by existing models.Nevertheless it is very cool stuff that you can do this. Although if I am to play devil's advocate, I do wonder at how \"isolated\" this turbulence actually is, since it's continuously being pumped by eight vortex ring generators.replyteekert 22 hours ago | prev | next [\u2013]A layman like myself would perhaps think that this may have applications in nuclear fusion plasma containment. Or am I way off?replyelil17 21 hours ago | parent | next [\u2013]Yeah, nothing really like that. That\u2019s about containing a ball (/other shape) of gas in a vacuum. This is about creating a turbulent system that doesn\u2019t propagate into nearby fluid.It\u2019s as if you stirred up a bathtub, but there were only waves in half the bathtub, with a fairly clear line between waves and still water.That said, it\u2019s related to the general problem of co trolling chaotic systems, so it\u2019s possible that there might be theoretical insights which apply across that domain.replyzmgsabst 21 hours ago | root | parent | next [\u2013]I\u2019m not sure this is unrelated:Naively, this idea would allow for turbulent \u201cburning\u201d regions within an otherwise smooth flow around a ring. The idea of a smooth boundary on your plasma constrained by magnets which has turbulent interior regions may turn out to be useful.replygreggsy 21 hours ago | root | parent | prev | next [\u2013]So, silent propellers?replymensetmanusman 10 hours ago | parent | prev | next [\u2013]The strange thing about the unreasonable effectiveness of mathematics in this universe of ours is that almost everything is related.replyh2odragon 22 hours ago | parent | prev | next [\u2013]I think the big problem there is neutrons that we can't contain or influence much.replyBubbleRings 22 hours ago | prev | next [\u2013]So cool. But come on, call it what it is! I know they're scientists trying not to look like they were playing with a great toy, but really now.They created a bubble ring rat king!Search for \"bubble rings\" on YouTube for lots more fun.And watch this space, one day I will finish my engineering work and then start working on my web site:Https://bubblerings.comreplyThouYS 1 day ago | prev | next [\u2013]Instantly reminds me of \"La Horde du Contrevent\" a magical adventure on a planet with constant wind, and wind-scholarsreplyswayvil 1 day ago | prev | next [\u2013]Is this how we get ball lightning or plasma balls in microwaves? Or a whole class of other discreet spherical material thingys?I mean, maybe the generator doesn't have to be a precise thing. Maybe a mess of waves randomly bouncing around can do it too.It's suggestive.replyakomtu 1 day ago | parent | next [\u2013]A ball lightning needs a blob of charged particles and a powerful magnetron nearby to keep that blob spinning.replybjelkeman-again 1 day ago | parent | prev | next [\u2013]It makes me, naively, think of applications in fusion plasma.replysomeweirdperson 1 day ago | root | parent | next [\u2013]One step closer to lightsabers.replydavidmurdoch 18 hours ago | root | parent | next [\u2013]Relevant: https://youtu.be/8qtUzxU8-6creplyFpUser 1 day ago | prev [\u2013]Is this any different than smoke rings [0]?[0] - https://youtu.be/-VL0M0jmu7kreplyred_trumpet 1 day ago | parent [\u2013]They study what happens when 8 smoke rings collide!replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Scientists have created a controlled ball of turbulence in a tank of water using a ring of jets to blow loops.\n- The experiment visualizes the paths of vortex rings, which resemble electron orbitals.\n- This breakthrough in controlling turbulent flow has potential applications in fluid dynamics, such as improving designs for ships, cars, turbines, and chemical reactions."
  },
  {
    "id": 36376071,
    "timestamp": 1687047098,
    "title": "Infinite Photorealistic Worlds Using Procedural Generation",
    "url": "https://arxiv.org/abs/2306.09310",
    "hn_url": "http://news.ycombinator.com/item?id=36376071",
    "content": "",
    "summary": "- 'The Tech Times' article discusses the concept of infinite photorealistic worlds created through procedural generation in the field of technology and gaming. \n- The article explains that procedural generation is a method used by game developers to generate an infinite number of unique worlds without having to manually design each one. \n- It highlights the benefits of procedural generation, such as saving time and resources for developers, providing endless exploration opportunities for gamers, and creating dynamic and immersive gaming experiences.",
    "hn_title": "Infinite Photorealistic Worlds Using Procedural Generation",
    "original_title": "Infinite Photorealistic Worlds Using Procedural Generation",
    "score": 287,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginInfinite Photorealistic Worlds Using Procedural Generation (arxiv.org)287 points by cpeterso 1 day ago | hide | past | favorite | 75 commentsuserbinator 1 day ago | next [\u2013]Procedural generation is something the demoscene has essentially specialised in for several decades, but I see no mention of it in the article. The demoscene has also done so using several orders of magnitude less computing resources than mentioned here, so I think everyone else has a lot to learn from them.Here's a memorable intro, from 2009: https://news.ycombinator.com/item?id=31636482Earlier than that, another famous 64k from 2000:http://www.theproduct.de/index.htmlreplyelif 1 day ago | parent | next [\u2013]This is an academic paper not an article. Generously 0.01% of demos generate landscape scenes, photorealistic or not.. so it is clear why the paper would not rely upon them for inspiration.replylaurentlb 22 hours ago | root | parent | next [\u2013]What they are doing has clear overlap with what we've seen in the demoscene. On a technical point of view, they generate all meshes and textures from formulas, using the same kinds of algorithms.See for example some 64kB demos that have landscapes / nature:- Paradise by Rgba, 2004 https://www.pouet.net/prod.php?which=12821- Gaia Machina by Approximate, 2012 (https://www.pouet.net/prod.php?which=59107)- Turtles all the way down by Brain Control, 2013 (https://www.pouet.net/prod.php?which=61204)Of course, it's not exactly the same, the demoscene tends to focus on a few carefully crafted scenes and do everything in real-time (with up to 30s of precalc), but I think there's a lot of similarity.replyvirtualritz 21 hours ago | root | parent | prev | next [\u2013]Procedural generation in computer graphics starts in the 70s.The demo scene was already standing on the shoulders of giants.replynickdothutton 21 hours ago | root | parent | next [\u2013]Many hours wasted playing Rescue on Fractalus, Koronis Rift, and The Eidolon.replyricardobeat 23 hours ago | parent | prev | next [\u2013]The novelty in this paper is generating photorealistic textures and scenes without using any assets.replyvanderZwan 23 hours ago | root | parent | next [\u2013]Could you define \"assets\", please? What would you consider the assets in these videos by Inigo Quillez, for example?https://www.youtube.com/watch?v=BFld4EBO2REhttps://www.youtube.com/watch?v=8--5LwHRhjkEDIT: To be clear, I was not being flippant, I was assuming that there is some nuance to how \"assets\" is used here that I'm not aware of since I'm not a 3D artist which would make this work novel compared to the work in the demoscene. Beyond being a general purpose asset generator, which is indeed very impressive but not what is being argued here.replyricardobeat 20 hours ago | root | parent | next [\u2013]The emphasis is on photorealistic.What is being argued here? I don\u2019t see where this turned into a competition.It\u2019s a paper presenting a system of new algorithms that can generate geometry, textures and lighting with extreme photorealism. It seems to do that very well. It\u2019s not a study of the procedural 3D graphics evolution, pretending to be an entirely new technique or the first to do it.replyvanderZwan 3 hours ago | root | parent | next [\u2013]It's not a competition, except it sort of is: claiming to be the first as well as acknowledging previous is serious business in academia, and in an indirect way also an indicator of how much people did their homework or how willing they are to play nice with others.So if they don't view the demoscene as relevant previous work to their paper then I want to understand why they think their work falls under a different kind of procgen.replyAbrahamParangi 18 hours ago | root | parent | prev | next [\u2013]It\u2019s not photorealistic though. It\u2019s not even close to a modern standard of realism. Compare to an indie game https://m.youtube.com/watch?v=IK76q13Aqt0&pp=ygUIdW5yZWNvcmQ...replyricardobeat 13 hours ago | root | parent | next [\u2013]You\u2019re comparing it to what is probably the most realistic game since the PT Silent Hill demo came out, and heavily based on photogrammetry. The paper also focuses on natural textures, not built up environments, so it\u2019s a pointless comparison in multiple ways.Again, not a contest. The paper is exploring new techniques for generating content. Why all the negativity?replyAbrahamParangi 11 hours ago | root | parent | next [\u2013]The negativity is because the claim is strong \"Infinite *Photorealistic* Worlds Using Procedural Generation\" while the approach is probably a dead end and does not improve performance in any of the relevant directions.No new ground is broken here in rendering techniques, nor in procedural generation, nor in actual content. AI is generating actually photorealistic content today, AI-adjacent techniques such as NERFs as well as traditional but sophisticated rendering like UE5 are the leading edge of rendering. If you're going to make a strong claim, you should deliver something.replyuserbinator 14 hours ago | root | parent | prev | next [\u2013]Inigo has a bunch of photorealistic scenes here too:https://iquilezles.org/demoscene/reply_a_a_a_ 22 hours ago | root | parent | prev | next [\u2013]The paper does not say that AFAICS \"Ours is entirely procedural, relying on no external assets\"replyrevertmean 22 hours ago | root | parent | next [\u2013]I'm not sure how you missed it, it's right there in the summary: \"Infinigen is entirely procedural: every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source...\"replyvanderZwan 21 hours ago | root | parent | next [\u2013]This is not a critique of what they achieved, but that is not an innovation over existing procgen techniques. Generating assets from maths is basically what the demoscene has been all about for decades.The sheer scale of what this does, how general it seems to be (instead of a single special-purpose animation like in the demoscene), as well as the fact that the output is structured and labeled assets I would consider novel, and very impressive.reply_a_a_a_ 22 hours ago | root | parent | prev | next [\u2013]\"without using any assets\" vs \"relying on no external assets\" but it's not my area so I may be misunderstanding.replyrevertmean 20 hours ago | root | parent | next [\u2013]Ok, to clear it up:\"Ours is entirely procedural\" == \"\"Infinigen is entirely procedural\"\"relying on no external assets\" == \"every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source\"If that doesn't make it make it clear, could you elaborate on the part that doesn't click and I'll try and explain further.reply_a_a_a_ 20 hours ago | root | parent | next [\u2013]Don't worry, I'm out of my depth and I know it, I shouldn't have put my oar in :)replyavaer 1 day ago | prev | next [\u2013]I ran this for most of today in the background and I have some thoughts:The quality is good and it's giving you all of the maps (as well as the .blends!). It seems great for its stated goal of generating ground truth for training.However, it's very slow/CPU bound (go get lunch) so probably doesn't make sense for applications with users behind the computer in the current state.Additionally, the .blend files are so unoptimized that you can't even edit them on a laptop with texturing on. The larger generations will OOM a single run on a reasonably beefy server. To be fair, these warnings are in the documentation.With some optimization (of the output) you could probably do some cool things with the resulting assets, but I would agree with the authors the best use case is where you need a full image set (diffuse, depth, segmentation) for training, where you can run this for a week on a cluster.To hype this up as No Man's Sky is a stretch (NMS is a marvel in its own right, but has a completely different set of tradeoffs).EDIT: Although there are configuration files you can use to create your own \"biomes\", there is no easy way to control this with an LLM. Maybe you might be able to hack GPT-4 functions to get the right format for it to be accepted, but I wouldn't expect great results from that technique.replyjustinclift 1 day ago | parent | next [\u2013]> ... on a reasonably beefy server.Out of curiosity, what kind of cpu / ram are you meaning here?Asking because I have some spare hardware just sitting around, so am thinking... :)replyp1esk 1 day ago | root | parent | next [\u2013]A typical server would be 8xA100 with a dual CPU (128 cores total), 2TB of RAM. I doubt you have something like this sitting around.replyjustinclift 1 day ago | root | parent | next [\u2013]That's only a \"typical server\" for some companies with specialised needs.Lots of places have servers with 128-256GB of ram around though.replybragr 1 day ago | root | parent | next [\u2013]That doesn't track in my experience, but that depends heavily on how you define typical. Just going off total servers installed, what I see getting racked are typically 1+TB RAM, and anything less would be seen as low density (i.e. cost inefficient). We've got a whole batch in the 512GB range that are coming up on EOL. Dual socket is definitely less common, but not rare either.reply_delirium 1 day ago | root | parent | next [\u2013]In my corner of academia, 128gb is by far the most common RAM per node on something billed as a compute cluster (on random desktops and laptops it\u2019s of course much lower than 128gb). I have seen a few 1tb+ nodes but they are rare.replyCSMastermind 1 day ago | root | parent | prev | next [\u2013]I know nothing about server hardware but I'm curious how that works.I have a decent PC (AMD 3990X 64-Core Processor with 256 GB of RAM), I'd have installed better/more components but that seemed to be the best you could do on the consumer market a few years ago when I was building it.Are they using the same RAM I'm using with a different motherboard that just supports more of it? Or are they using different components entirely?Apologies for what I'm sure is a very basic question but it would be interesting to learn about.replyelif 1 day ago | root | parent | next [\u2013]It's the same RAM chips (though error tolerance features are prioritized over pure speed). You would just need a server motherboard to support that many sockets, and a server chassis to support that motherboard, and a rack to support the cooling needs of that chassis.Here's what a lowly 256GB server looks like. For a TB just imagine even more sticks:https://i.ebayimg.com/images/g/dnIAAOSwcy1kFNqq/s-l1200.jpgreplydur-randir 1 day ago | root | parent | prev | next [\u2013]Typical Intel offering is 1.5-2TB per socket. Socket scales up to 8 (though the price increase 2->4 is very steep). Memory itself is registered ECC DIMMs (which is even lower cost than consumer DIMMs/unbuffered ECCs), but to get to 1.5TB density you need low-rank (LRDIMM) modules, which gives x2 capacity but at a higher price.replyjustinclift 1 day ago | root | parent | prev | next [\u2013]Interesting. The servers at places I work with are in the 128-256GB ram range.The only real exception to that would be for database or reporting servers, which sometimes might have higher ram requirement (eg 384GB).That's pretty much it though.replymelagonster 20 hours ago | root | parent | prev | next [\u2013]but there aren't many people can use these servers for amusement.replyfnordpiglet 13 hours ago | parent | prev | next [\u2013]Proof of concepts don\u2019t have to be optimized. That\u2019s an exercise for the reader. ;-)replydmarchand90 1 day ago | prev | next [\u2013]https://infinigen.org/replydmarchand90 1 day ago | parent | next [\u2013]Demo video is very impressive. I thought it was yet another GAN, but, no. It's something \"mathy\". I'll need to read the paper for sure!replymnky9800n 1 day ago | root | parent | next [\u2013]> Zero aiI gave a standing ovation when that popped up in the video.replynine_k 1 day ago | parent | prev | next [\u2013]\"Infinigen is free and open source\".What a gift. Gotta love it.replyschemescape 1 day ago | root | parent | next [\u2013]Now we just need to make a No Man\u2019s Sky-style\u2014but open source\u2014universe with this.replyelif 1 day ago | root | parent | next [\u2013]I think no man's sky proved conclusively that we don't need more no man's sky. One was already too much no man's sky.replydgellow 17 hours ago | root | parent | next [\u2013]What do you mean? The release didn\u2019t go too well (mainly due to unrealistic expectations) but the game is still updated and has a healthy community.replyschemescape 15 hours ago | root | parent | prev | next [\u2013]As in the universe was too big or as in the game was no good?I think one could make a case for the former, but the latter is subjective (I liked the game, although it is a bit shallow).replymalermeister 21 hours ago | root | parent | prev | next [\u2013]Well there's a second one coming soon with Starfieldreplyprox 1 day ago | root | parent | prev | next [\u2013]How about a planet that runs on a server and is part of a federated universe basically. Each server has a solar system to play with.Then add spaceships so you can actually travel between them.Godot runs in the browser these days, so that could work.replyaddandsubtract 1 day ago | root | parent | prev | next [\u2013]No Man's LicensereplydopidopHN 1 day ago | root | parent | prev | next [\u2013]It\u2019s random, sorry. But I looked at it briefly and I saw jargon that I had difficulty picking up. What\u2019s baseline is needed to operate that stuff with meaningful control. ( I\u2019m confident any dev can run it and have fun )replymadacol 20 hours ago | parent | prev | next [\u2013]https://www.youtube.com/watch?v=6tgspeI-GHYreplyHellDunkel 1 day ago | prev | next [\u2013]None of this looks \"photorealistic\". The creatures look hilarious and the paper is not well written either.\"Each part generator is either a transpiled node-graph, or a non-uniform rational basis spline (NURBS). NURBS parameter-space is high-dimensional, so we randomize NURBS parameters under a factorization inspired by lofting, composed of deviations from a center curve. To tune the random distribution, we modelled 30 example heads and bodies, and ensured that our distribution supports them.\"This strikes me as a fairly random approach. No wonder why those creatures look the way they do. I fail to see why this is worth a scientific paper as it appears to be no more than a student project with a number of contributors across different fields. Building a (somewhat) procedually based asset library has been done countless times before by game dev studios big and small.replyprox 1 day ago | parent | next [\u2013]Spore, No Man\u2019s Sky, Elite Dangerous all do galaxy generation to good effect. Elite is probably the most realistic. No Man\u2019s Sky has creatures like Spore.replygrumbel 23 hours ago | root | parent | next [\u2013]Space Engine[1] is another popular one[1] https://spaceengine.org/replythumbuddy 23 hours ago | parent | prev | next [\u2013]Complete opposite reaction for me here. Interesting to see how two people can see the same thing and think polar opposites.replyAnimats 1 day ago | prev | next [\u2013]This is great. Terrain generators have been around for decades, but this is a nice open-source one.\" The wall time to produce a pair of 1080p images is 3.5 hours.\"Ouch. It's in Python, but still...replyoersted 23 hours ago | parent | next [\u2013]They Python part just generates Blender procgen specifications (compute graphs), that is probably relatively fast. But apparently the output graphs are huge and unoptimized, so generating the geometry takes a lot of resources (CPU bound). Rendering might also take a while if they don't have good ways to limit detail (something like Nanite would come in very handy here).replyAnimats 15 hours ago | root | parent | next [\u2013]With Nanite, if you have a sidewalk with occasional cracks, and all the cracks are the same, those get combined into a single submesh. This is recursive; if you have multiple instances of that sidewalk, those get combined at a higher level. It's a form of compression for mesh data with redundancy.This only works if the data contains such redundancy. That depends on how it's generated. Not clear if this type of generator creates such redundancy. Something using random processes for content generation won't do that.Nanite is optimized for large areas of content generated by a team of people working together, as in a major game project. There's a lot of asset reuse. Nanite exploits that. It's not a good fit for randomly generated assets, or for assets generated by a large community, as in a serious metaverse. The redundancy isn't there to be exploited.replyoersted 14 hours ago | root | parent | next [\u2013]You seem to know more about it than I do. But isn't Nanite also about automatic and continuous LOD adjustment? A big selling point is to be able to drop-in extremely detailed unoptimized meshes made by artists, and have it perform well by dynamically reducing the polygon count based on the screen real-state they take up. I guess you could call this compression too, but it is lossy compression (automatic mesh downscaling) and doesn't depend on redundancy that much.Many of these artist-made high-fidelity meshes make heavy use of Z-brush style sculpting and procedural materials, which have similar characteristics to these randomly generated assets.replyjustinclift 1 day ago | parent | prev | next [\u2013]Yeah, it's not clear if the wall time needed is due to Python being slow or not. eg could it be redone in a compiled language for a better resultI'd kind of expect that most of the core stuff is being done in C++ or similar behind the scenes though. Maybe (haven't looked). :)replyAnimats 15 hours ago | root | parent | next [\u2013]Considering that part of the code is in CUDA and part is in C/C++, there's already been some optimization.replyukuina 1 day ago | prev | next [\u2013]\"Zero AI\" will likely become a selling point.replyomoikane 1 day ago | parent | next [\u2013]I worked on a thing many years ago that involved machine learning, which usually produced reasonable results but all users hated it nonetheless, because machine learning made it completely opaque. The correct predictions it made were mostly acceptable, but the incorrect predictions it made were hilariously bad, and in both cases nobody could explain why it generated those outputs.Eventually we concluded that machine learning wasn't a good fit for our problem, and our users were very keen to maintain that conclusion.replynoduerme 1 day ago | root | parent | next [\u2013]I'm thinking of a very complex logistics system I wrote, that had to trace millions of possible paths to optimize a route. Even when the range of choices is too extensive to present to the user directly, and you need to resort to a list of best choices, it's indispensable to show somehow how the logic was arrived at and present ways of disabling portions of what went into the deductive process. That's something machine learning simply isn't geared towards, because the reasoning doesn't rest on reproducible sets of hierarchical rules.replylaurentlb 22 hours ago | prev | next [\u2013]Interesting - they've just changed the license from GPL to BSD: https://github.com/princeton-vl/infinigen/commit/258cf38e860...This makes the repo much more useful to me.replyvsskanth 1 day ago | prev | next [\u2013]Something feels odd about the fire animation. Water flowing also feels a bit odd but I am not able to say how.replykstrauser 1 day ago | parent | next [\u2013]The banks of the creek didn\u2019t darken when water splashed on them.replyshahar2k 1 day ago | parent | prev | next [\u2013]it's an offline fluid simulation, it's a pretty identifiable look once you've seen a fewreplyacutesoftware 1 day ago | prev | next [\u2013]This is really impressive, even the trees look pretty good which appears to be tricky to do with procgen stuff.A nice next step or addition would be to take the results and remesh them to lower poly models so it can be used in a game engine to walk around in.replyjcelerier 18 hours ago | prev | next [\u2013]I can't help but find this so much more interesting and fun to use than anything AI-basedreplyjumpkick 1 day ago | prev | next [\u2013]Love the \"Matrix\" zoom-in on the green terminal text.replyChrisMarshallNY 23 hours ago | prev | next [\u2013]Reminds me of the Mac Aquarium SereneScreen screensaver.That was around for decades.https://m.youtube.com/watch?v=Ws1zpk9GWkkMuch, MUCH more limited, but pretty cool.replypk-protect-ai 19 hours ago | prev | next [\u2013]Absolutely amazing. The holly grail of shaders.replyterrycody 1 day ago | prev | next [\u2013]Think of a real world scale sandbox gaming with Pok\u00e9mon elements...must be a crazy game.replyXen9 1 day ago | prev | next [\u2013]Procedural generation, not transformers\u2014truly infinite!Of course AI input would work well with this...replybeaker52 1 day ago | prev | next [\u2013]The infinite virtual reality escape comes nearerreplyilrwbwrkhv 1 day ago | prev | next [\u2013]Can't wait for my vision proreplypeter_d_sherman 1 day ago | prev | next [\u2013]\"Introducing Infinigen\":https://www.youtube.com/watch?v=6tgspeI-GHYreplyanthk 21 hours ago | prev | next [\u2013]I'd love this generating images for a Don Woods' Adventure version. Or for Nethack/Slashem.replytaneq 1 day ago | prev | next [\u2013]The name\u2019s reminiscent of Terragen, I wonder if the author is involved in any way?replyFpUser 1 day ago | prev | next [\u2013]This is very nice. Thinking of playing with itreplyjohnea 1 day ago | prev [\u2013]\"Worlds\"...Interesting delusion...replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Procedural generation for creating photorealistic worlds has been a focus of the demoscene community for decades.\n- The paper presents a system that generates geometry, textures, and lighting without using any external assets.\n- The output of the system is free and open source and can be used for training neural networks or creating full image sets for various applications."
  }
]
