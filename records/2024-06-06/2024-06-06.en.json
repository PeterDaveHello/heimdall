[
  {
    "id": 40592789,
    "title": "Microsoft AI Scandal Highlights Need for Holistic Online Privacy Approach",
    "originLink": "https://spectrum.ieee.org/online-privacy",
    "originBody": "ARTIFICIAL INTELLIGENCE OPINION How Online Privacy Is Like Fishing In the wake of a Microsoft spying controversy, it’s time for an ecosystem perspective BARATH RAGHAVANBRUCE SCHNEIER03 JUN 20243 MIN READ GERARD SOURY/GETTY IMAGES",
    "commentLink": "https://news.ycombinator.com/item?id=40592789",
    "commentBody": "Microsoft AI spying scandal: time to rethink privacy standards (ieee.org)763 points by walterbell 16 hours agohidepastfavorite320 comments openrisk 13 hours agoTrying to understand consumer privacy behaviors outside the prevalent social contract that the vast majority of people operate under is bound to missinterpret what is happening and why. We live in a regulated \"supermarket\" economy. What surfaces on a screen is entirely analogous to what surfaces on a shelf: People check the price and make their choices based on taste, budget etc. They are not idiots, they operate under a simplifying assumption that makes life in a complex world possible. The implicit assumption central to this way of organising the economy is that anything legally on sale is \"safe\". That it has been checked and approved by experts that know what they are doing and have the consumer interest as top priority. People will not rush back home to their chemistry labs to check what is in their purchased food, whether it corresponds to the label (assuming that such a label even exists) and what might be the short or long term health effects. They dont have the knowledge, resources and time to do that for all the stuff they get exposed to. What has drifted in the digital economy is not consumer standards, it is regulatory standards. Surfacing digital products with questionable short and long term implications for individuals and society has become a lucrative business, has captured its regulatory environment and will keep exploiting opportunities and blind spots until there is pushback. Ultimately regulators only derive legitimacy from serving their constituencies, but that feedback loop can be very slow and it gets tangled with myriad other unrelated political issues. reply alvah 10 hours agoparent\"The implicit assumption central to this way of organising the economy is that anything legally on sale is \"safe\". That it has been checked and approved by experts that know what they are doing and have the consumer interest as top priority. People will not rush back home to their chemistry labs to check what is in their purchased food, whether it corresponds to the label (assuming that such a label even exists) and what might be the short or long term health effects. They dont have the knowledge, resources and time to do that for all the stuff they get exposed to.\" What you describe is a feature of a high-trust society, where you don't have to double-check every single transaction or interaction you enter into, but can take most statements on trust. This allows people to get on with the fundamental task at hand, rather than dealing with the overhead of checking their food in the chemistry lab, or whatever the equivalent is for the specific transaction. I have read suggestions that this was a major contributor to the growth of the Western economies, relative to other low-trust societies. If this was the case, we are in for a bumpy ride, as we seem to be rapidly changing from a high-trust to a low-trust society. reply jrexilius 3 hours agorootparentHaving worked in many low-trust countries, I very much agree with that assertion. And seeing the effects of the trust-decay in our own, and the trajectory it sets, reinforces that view. reply soco 9 hours agorootparentprev\"I have read suggestions that this was a major contributor to the growth of the Western economies, relative to other low-trust societies.\" I'm not sure I follow, what are other low trust societies? Otherwise I'm with you here - living in a cabin in the woods survivalist-mode does nothing to progress a society. reply goda90 6 hours agorootparentSocieties with lots of corruption, adulteration, theft, forgery, counterfeit, etc that goes under-punished. If you are frequently burned by your transactions and interactions with business, government, etc you're going to have low trust. reply HarryHirsch 5 hours agorootparentThere's a wrinkle to that - here's a vidio from the Indian trading standards authority to detect adulterated salt: https://youtu.be/x3CWvI_AWkU That's the government actually doing its job for once, but you can't check at home for data safeguarding. reply _heimdall 6 hours agorootparentprev> living in a cabin in the woods survivalist-mode does nothing to progress a society. Not everyone's goal is to progress a society though. If one's goal is to live a quiet life and do what makes them happy, what's wrong with living in a cabin in the woods? That would only be a fundamental problem if everyone owes something to society. That's a much different conversation though, whether everyone is born into a debt that must be paid back to society. reply tsukikage 5 hours agorootparentIf handiwork and subsistence farming are not what makes you happy, living in a cabin in the woods will not make you happy, because when you cannot outsource them to the rest of society, nearly all your time will be spent doing those things in order to survive. Even once these basics are sorted, you will only live happily outside society as long as you are lucky enough to stay healthy. reply _heimdall 3 hours agorootparentIf handiwork and producing or finding your own food is what makes you happy, then why does it matter whether you are outsourcing to society? The second sounds like a separate goal unto itself. There's absolutely nothing wrong with that goal, or with having multiple goals, but if you start by saying doing X makes you happy then it doesn't really make sense to say doing X won't actually make you happy because you aren't doing Y. reply tsimionescu 2 hours agorootparentI think the point is more that there are a very limited number of very specific lifestyles that can exist outside of a society. If you happen to thrive in one of those lifestyles, awesome, cabin in the woods works great for you. But you can't do that if your passion is making music, or mathematics, or computer programming, or electrical tinkering, etc. There just isn't an option to follow the vast majority of pursuits except if you also engage in society. reply pessimizer 2 hours agorootparentprevPeople don't have the physical or mental ability to live alone. Their version of \"alone\" is a world where there are institutions that exist to protect their property, guarantee their transactions, and where they are supplied with a massive amount of high-quality manufactured goods. Paying for them doesn't make you somehow independent of society, it's the nature of society. You're trading bits of paper with government promises printed on them. reply notjoemama 3 hours agorootparentprev> Not everyone's goal is to progress a society though. Thank you. That was my initial thought too. Why is progress the goal? Not everything has to \"progress\" at all times. What progress needs to be made anyway? And towards what end? Who decides that? There's an inherent good to stopping progress and spending some time in a cabin in the woods. If we never stop and enjoy now, then why bother with tomorrow? reply _heimdall 1 hour agorootparentThe really challenge I've had with \"progress\" as a goal is that it so frequently is missing the context of what we're trying to progress towards. The idea seems to be that starting with what we have today and taking another step forward is always the right move. Never go backwards, and its okay if we don't define our goals beforehand as long as we keep moving our feet. reply soco 5 hours agorootparentprevThe comment I was replying to was talking about the growth of the economies and society progress. It's not about owing, it's about what is happening - and I think we agree that if the goal of everybody in a society is to live a quiet life, there will be no progress. Maybe we'd even witness the contrary: a regress of said society, to the extent we can call sparse people living by themselves in the woods a \"society\". If that sounds negative and you feel the need to defend it, it's maybe because you actually agree it's a negative for the society. While being good for the individual, right. reply _heimdall 3 hours agorootparent> and I think we agree that if the goal of everybody in a society is to live a quiet life, there will be no progress That's actually where it gets really interesting though. Progress isn't absolute, it's relational and requires first defining the goal. If one's goal is to live a quiet life where they minimize their dependence on others, living in a cabin in the woods and finding their solution for food and water is progress. That obviously doesn't fit for a larger society where the goal is generally increasing dependence and trust on the larger society, but neither is right or wrong. reply pessimizer 2 hours agorootparentIf one's goal is to live a quiet life where they minimize their dependence on others, it is incumbent on them to figure out how to keep anybody who wants what they have from just coming in and taking it. That requires a society. Your deed to your land is civilization. Part of societal progress is making it so that deed can be trusted to keep people from just taking your cabin in the woods and throwing you out. This has to be negotiated with the people who would want to take your cabin in the woods and throw you out. reply _heimdall 15 minutes agorootparentSure, living with greater self sufficiency requires taking responsibility for either protecting it or accepting if it is ever taken from you. Responsibility is a fundamental requirement of freedom though, there's no way around that. reply freejazz 24 minutes agorootparentprevNo one expressed the moral judgment that living in a cabin in the woods is a \"bad thing\" or \"wrong\" reply dbspin 8 hours agorootparentprevThis pew research article from 2008 (prior to the decline of trust in the West) illustrates some examples and the knock on or related differences between low and high trust societies - https://www.pewresearch.org/global/2008/04/15/where-trust-is... reply whearyou 4 hours agorootparentprevFor a case study, Israel vs eg Egypt. Though, for Israel that is changing for the worse - less trust in the government and each other. reply notjoemama 3 hours agorootparentThey're having the same problems with political extremism as the US. To be clear, this is both that political figures are leaning towards the extreme ends of their ideologies, as well as a culture of dogma and isolation that pushes them and their citizens towards extremes. reply rolph 2 hours agorootparentprevi live in a cabin in the woods, we have different lifestyles too. im very technical, my nieghbour 'grizzly annie' is the opposite, but we trade back n forth. reply PKop 5 hours agorootparentprev>what are other low trust societies Look at the graph here on the wallet study, should give you an idea. China is a good example. https://www.science.org/doi/10.1126/science.aau8712 reply datavirtue 4 hours agorootparentprevBusiness moves at the speed of trust. reply jrexilius 3 hours agorootparentThat is a very good summary. I'm stealing that line.. reply AlienRobot 6 hours agorootparentprevI've always found interesting that we've grown up hearing don't install random programs from the internet/don't access random websites. Then you go use linux and everyone copy-pastes commands other people wrote straight into the terminal. reply bayindirh 6 hours agorootparent> Then you go use linux and everyone copy-pastes commands other people wrote straight into the terminal. This is exactly the same bias in action. When I started using Linux nobody was doing that, and even if somebody gave you a script, its actions were verifiable by reading the relevant man pages. I still don't run install.sh files I didn't read or at least skimmed, for example. reply roblabla 5 hours agorootparentDo you also audit the sources of the programs installed by that install.sh? Do you make sure the binaries and sources match? If not, why? What makes the shell script so special that it must be audited with care, but the binaries are fine? reply bayindirh 5 hours agorootparentI do not use any \"install.sh\" that installs freestanding binaries. All of the ones I use just sets up repositories, and I make sure that the repositories are the correct/legit ones. If I have to install a freestanding binary, I compile it from source and install. Since all the repositories are signed there must be a big breach to compromise these packages since the infrastructure is generally distributed. Different servers, keys, etc. > What makes the shell script so special that it must be audited with care... Because I need to know what changes I'm incorporating into my system(s), and plan accordingly, or prevent any change which is not in line with my system administration principles. > ...but the binaries are fine? They are not fine, but they are signed at multiple levels and checksummed, so they are a lower risk. reply dcow 2 hours agorootparentYour risk model is kinda perverse. You're saying you trust package maintainers because they sign things. So if I send you a signed script that checksums itself before running will you run that without audit? It’s trust all the way down and always has been. You just have a different idea of how you formally signal and convey trust than someone else. I paste commands into the terminal because I can read exactly what they do and they are delivered over a connection where my user agent has verified the TLS certificate of the server. In fact I’m electing to trust directly rather than transitively the source of the software. The only thing signed files prevents is modification in transit (and at rest on macOS/iOS and Windows, Linux doesn’t do that). Linux is ripe with time of check vs time of use race conditions. reply robdar 5 hours agorootparentprevIt’s worse than that. Find a random blog that gives you shell commands that add random repositories to your apt sources.list, adds the ssl keys, and installs packages from the repo, all through a paste to the command line. reply Maken 2 hours agorootparentI used to do that, but nowadays I tend to stick with either my distro or developer repositories. Internet is a wild place. reply singpolyma3 6 hours agorootparentprevDon't access random websites? Sounds like a very small internet. reply AlienRobot 5 hours agorootparentIt does feel like that sometimes doesn't it. reply screamingninja 5 hours agorootparentprev> everyone copy-pastes commands other people wrote straight into the terminal I know a lot of people that use Linux and not many of them operate this way. Most care about their software sources. \"Everyone\" is certainly not the case. reply g15jv2dp 5 hours agorootparentAnd yet when I complained about `curlsh` on HN the other day, I got ridiculed. \"Everyone\" is too much, but even on a purportedly \"hacker\" website, people find the idea of perusing a shell script before executing it preposterous. reply dcow 2 hours agorootparentBut `curlsh` is no less secure. Download this file and execute it. Functionally the same outcome. Tell me how doing that is materially different than `apt get`. Both employ signing and checksums (just with different PKI). One delegates trust to a package maintainer while the other trusts the author directly. I truly don’t understand the paranoia and consider it tinfoil hat security theater. reply tetris11 2 hours agorootparentthe package maintainer has to go through a web of trust in their FOSS ecosystem to be allowed to distribute their packages. A github author just has to put up a repo and hope that their fanbase aren't too versed in the language reply neilv 4 hours agorootparentprevSomething that's hard to remember, but helps a little: if you get 3 people saying stupid things, that's only 3 people -- not necessarily representative of the people out there. reply Spivak 1 hour agorootparentprevI think the replies saying how terrible this is are missing it. The Linux community is a high-trust community and has continuously earned that trust over and over again. The times when it's been broken are so few it's newsworthy each time it happens. Anyone who's like \"well I don't copy/paste shell code into my terminal\" is just virtue signaling. I'm willing to bet their editor Vim/Emacs/VSCode is overflowing with plug-ins and code written by just some guy on Github. I bet they've ran containers that are written by just some guy too. It's a really cool feature that you can just download a random binary off Github, run it, and not really have to worry about it. reply pjc50 9 hours agoparentprevSchneier used to talk about \"the Exxon Valdez of privacy\", the idea that there would be a single giant spill that had significantly bad effects enough that it would force change. That has basically not happened. It sometimes seems that the situation has got worse in terms of public debate, due to the usual bad-faith actors. For example, the TikTok discussion is not framed around privacy in general but focuses on \"China bad\". With the implication that an algorithmic megacorp controlling political sentiment through feeds is completely fine so long as it's Americans doing it. And the voting security discussion: there were questions about voting machines long before 2020, but partisan attacks focused on discrediting valid results. reply tracker1 4 hours agorootparentIf a major credit agency leak didn't do it, I doubt anything will... At least in terms of a large scale event. We went through the likes of melissa and \"I love you\" and several others around Y2K (and even that). In the end, life goes on for the most part. What people don't see, they're oblivious to and have short term memories on top. reply throw4847285 1 hour agorootparentprev> a single giant spill that had significantly bad effects enough that it would force change. That's the premise of the Brian K Vaughan/Marcos Martin comic \"The Private Eye.\" Unfortunately, the premise is more of an aesthetic than anything else. Still, it's a beautiful aesthetic and a fun read. reply frapaconi 5 hours agorootparentprevYeah keep in mind that both political parties heavily use private data farms to narrowcast campaign advertising. Facebook is just one of those. Basically there’s a private sector spying industry and the government enjoys the benefits too. TikTok is messed up for many reasons. One being it’s a waste of everyone’s time. Two, foreign nations getting a treasure trove of video footage on a massive populace in the age of AI. This WILL lead to a faked mass-casualty event using real identities of people to cause political unrest. Just a matter of time—and data. Going back to the article though, the social media baseline needs to be fixed as well. The OG Facebook platform was actually GOOD—lots of good-natured value in human connections. Then they started cutting in the bad shit reducing its purity. TikTok took that to a whole new level and put in some home grown Singaporean crack. Ironically, the Chinese and Singapore have hefty penalty’s for drugs—and yet they thrust it onto the western sensibility. After all, it’s the WILD WEST. reply TeMPOraL 5 hours agorootparent> Ironically, the Chinese and Singapore have hefty penalty’s for drugs—and yet they thrust it onto the western sensibility. After all, it’s the WILD WEST. One almost wants to say, revenge for the opium. reply frapaconi 3 hours agorootparentprevGot lots of down-votes. HN needs to implement a feature requiring a REASON for down votes. reply solarpunk 1 hour agorootparentyou are basically making the same old \"digital fentanyl\" argument that nancy fucking pelosi has been making for the last year. it's just not that compelling. reply djtango 9 hours agoparentprevYou chose an analogy close to my heart! I have managed to convince myself that most \"food\" in the supermarket is inedible poison! It's exhausting and a real nuisance to my quality of life but I equally refuse to knowingly consume excess additives unless completely in a pinch. Needless to say I'm also very suspicious of online businesses. Although I'm actually getting a bit fatigued/defeatist by privacy issues. We're all so overwhelmingly in this ship that I don't know what I really stand to gain by constantly hamstringing myself digitally... If we wake up in the worst case scenario, I'm sure I have enough of a footprint I wouldn't be able to meaningfully hide much from a determined bad actor... reply butlike 16 minutes agorootparent> I have managed to convince myself that most \"food\" in the supermarket is inedible poison! > It's exhausting and a real nuisance to my quality of life but I equally refuse to knowingly consume excess additives unless completely in a pinch. But why do you _want_ to live forever? Frozen Pizza tastes good every once in a while. reply kenjackson 4 hours agorootparentprev> It's exhausting and a real nuisance to my quality of life but I equally refuse to knowingly consume excess additives unless completely in a pinch. Why not? Unless you have severe allergies the excess additives will probably do very little to your health. And the quality of life and exhaustion wins probably make it a net win for you. Is it a principled stand? reply A4ET8a8uTh0 7 hours agorootparentprevnext [–]The implicit assumption central to this way of organising the economy is that anything legally on sale is \"safe\". That it has been checked and approved by experts This applies to certain producs only and even in the EU where these laws are more strict some products are regularly withdrawn from sale (these are mostly quality issues, not intentional actions), even as far as drugs are concerned. It's one of the reasons I tend to buy fresh products and from bio shops mostly - to increase my chances. reply TeMPOraL 5 hours agorootparentThere are a lot of products. Mistakes are a statical certainty at this scale, and regular recalls are a sign the system is working, at least to an extent (I'd say it works quite well, safety-wise). Interesting choice wrt. bio foods. I'm the opposite: I don't trust organic/bio food at all. There is a lot of vanity products clearly meant to pay more to make yourself feel you're choosing a healthier alternative. Plus, I trust the established industrial processes more - they're thoroughly regulated and tested. A devil I know. Bio/organic stuff, who knows what they're doing - and what poisons they're spraying on their produce, that let you keep \"organic\" label but are otherwise more toxic than industrial pesticides. reply soco 9 hours agorootparentprevI like the way you put it \"to increase my chances\" because I've heard more than once from adepts of bio products promoting as it would be the holy grail. Bio producers can make mistakes too, they can be neglecting or even nasty too, it's just, chances are higher with them to get better quality produce. If you can afford it, that is. reply Draiken 6 hours agoparentprevAll of these systems you mentioned have already failed. We are simply very slow to accept it. Even in the (almost) mainstream media with shows like John Oliver, you can see just how deep the degradation of all our regulatory entities really is. In today's world, almost everything we purchase is pure garbage. The food is overly processed and with excessive use of chemicals and added sugar, the furniture is from cheap material and shoddily built, the building we live in was built cutting corners and skirting laws as much as possible, the software we use is mostly garbage thrown together to \"ship fast and break things\", the doctors we go to are uninformed and trained to dismiss you as fast as possible, the car repair service wants to rip us off based on our lack of knowledge. I could go on forever here. It's honestly a joke. We are all the proverbial boiling frogs and allowed everything around us to fall into ruin (and continue to do so). This assumption you presented only works for the uninformed masses. If you investigate for 5 seconds into anything we purchase, we pierce the veil and see how it's mostly utter garbage. Most of these regulatory institutions became a facade where big corporations get a pass and we pretend they are doing a good job. Regulators can't ever win this battle. Even if they aren't corrupt, they can't be insulated from the influence of big corporations and they are, and will always be, underfunded because regulation inevitably means less profits. We can't have that, can we? reply Aerroon 5 hours agorootparentI think it's fitting that the parent poster used supermarkets. They're a relatively recent thing and often seen as lower quality. In my country it's still relatively common for people to forage for mushrooms and berries in the forests. There's no regulatory oversight over that, but people are still fine. Supermarkets and this kind of regulation hasn't necessarily stood the test of time. It's hard to say if it will considering how every system that gets built seems to slowly get corrupted or bent in somebody's favor. reply spdustin 4 hours agorootparentThe forests in which people are foraging for mushrooms and berries have no need to optimize for profit. The moment humans get involved in the supply chain, the more the need for some form of (idealized, for sure) oversight from agencies. reply skybrian 3 hours agorootparentEvolution results in other incentives. Beware the assumption that nature is somehow benevolent. It can go either way. Some mushrooms are poisonous. They evolved to protect themselves from being eaten. On the other hand, some plants evolved so their fruit will be eaten and spread their seeds. And then there are diseases and parasites. reply ericjmorey 3 hours agorootparentprev\"People that didn't get seriously ill or die are fine\" is a bad argument. reply skybrian 3 hours agorootparentprevPeople are fine if they didn’t eat the wrong mushrooms. reply carlosjobim 1 hour agorootparentprev> In today's world, almost everything we purchase is pure garbage. The food is overly processed and with excessive use of chemicals and added sugar, the furniture is from cheap material and shoddily built, the building we live in was built cutting corners ... Everything that existed in the past is still being made and is available for purchase. You just have to pay the price. If you are a commoner with a job, your real income is a tiny fraction of what a worker was paid in the past, thanks to inflation. So mass produced garbage is what is available within your budget. More than half of the working age population in industrialized nations do not work (including many who are employed). A good part of the population have never worked a day in their life and will grow old and die without ever having done anything useful. Everybody else has to pay for their sustenance, and one way is the general decay you see. reply 1vuio0pswjnm7 8 hours agoparentprevThe article referred to the beliefs of fisheries scientists and what the authors have suggested are their analogous counterparts today in the \"security community\". It is not focused on the beliefs of computer users. For many years on HN I have seen comments that constantly try to shift the focus away from articles like these and place blame on computer users. This is old hat. We are past that nonsense. This article is addressed to the \"security community\". But some HN commenter is trying once again to shift the focus to computer users, making sweeping, generalised, incorrect, and ridiculous assumptions about them. There is a commercial motive for destroying privacy and collecting data. Computer users are not voluntarily \"giving up on privacy\", or \"trading away their data\", with informed consent, to enrich software developers. It is being taken, without notice, often unbeknownst to the victims. There is no \"contract\". Regulation will continue to gain momentum as it is obvious to anyone outside of the so-called \"tech\" companies and their supporters that this is a bad deal for society. The problem is not the behaviour of the victims, it is the behaviour of the perpetrators. reply ericjmorey 3 hours agoparentprevI think you're romanticizing the past that brought us to the current state of consumer markets. Until the 1930s in the US, the primary guiding principle was caveat emptor and it took a lot of regulations to change expectations. reply ProdSecBurner 5 hours agoparentprevThis is the liberal viewpoint (I subscribe to it too). The conservative viewpoint is to do mostly do what our ancestors did (given it worked for many generations). My problem with this approafh is that it limits progress and favours folks who are already doing well. reply nonrandomstring 12 hours agoparentprevNot sure that regulatory capture explains the poor quality of digital goods and how people value them. I think it's that cargo cults (what we have) are antithetical to true technological societies (which is what we say we want) A fault I see in Bruce Schneier's article, and the general hypothesis of \"frame/baseline shifting\" - it's not that people have been conditioned or forgotten the value of privacy, but that we're looking at the world through ever smaller lenses. The story in the article is that science is guilty of that too. The decline has been around education and perspective in general, not just attitudes to a small issue like \"privacy\". We thought the internet would widen our scope. It narrowed it. In the UK we have a great travel and culture show by Romesh Ranganathan. (I highly recommend it, so get on your VPN to watch BBC or find it on the torrents). It will cheer you up [0]. He's a funny guy. But also the cultural vista is breath-taking. Looking at life in central Africa it's great to be reminded of the diversity of humankind. Watch for the little things - like a whole bus queue of people, none of whom are on mobile phones. What the Internet promised - the great \"conversation of mankind\" - never emerged. Instead we got cat memes and social control media that forced people into ever smaller parochial silos. HN is no different. Here it's cool to have a bleak outlook on humanity and technology. \"Oh it's too late... we're doomed... oh woe is me!\" C'mon hackers... what happened to the joy of shaping the world? :) Bruce Schneier appeals to a macro systems theory metaphor, and mentions Daniel Pauly [1]. But he neglects some of the more profound lessons that Forrester, Meadows and actually Norbert Weiner gave us about feedback and the empty dream of cybernetic governance. Nothing as big as humanity will fit in bottle that small unless you're willing to destroy it in the process. And what you're destroying is the very innovative base that gave you the technology in the first place. This is why they should teach history, geography and other cultures in schools. [0] https://en.wikipedia.org/wiki/Romesh_Ranganathan [1] https://oceans.ubc.ca/2023/05/19/daniel-pauly/ reply whilenot-dev 11 hours agorootparent> We thought the internet would widen our scope. It narrowed it. > What the Internet promised - the great \"conversation of mankind\" - never emerged. Instead we got cat memes and social control media that forced people into ever smaller parochial silos. The internet economy enabled browsing on a global scale and, because no kind of agency could keep up with its development speed, pushed everything into an \"on demand\" culture - what evolved with it is the higher responsibility for consumers. I feel the state of economy before the internet was on a scale of \"everything is possible\" (in the western hemisphere at least), only to discover years later that \"our greed has consequences we just couldn't see before\". Our cognitive load feels higher than ever to just cover the basics of survival and not get screwed over, or screw someone else over, constantly. > This is why they should teach history, geography and other cultures in schools. I think system thinking should become a thing in schools early on too. Every defined system is a mere conceptual view with artificial boundaries - a system without boundaries isn't a system, but a universe. It's good to enable new resources to think about new systems, or rethink existing systems, but we also should discuss the boundaries required for its concept to make any sense. I feel that this understanding gets sometimes lost, and its naivety gets regretfully relabeled as \"innovation\". reply soco 9 hours agorootparentIn a MBA-led economy anything which doesn't create immediate monetary value gets pushed aside - humanities and education in general, for instance. And before somebody jumps: we did have innovation before this just as well. reply nonrandomstring 5 hours agorootparent> MBA-led There are no \"leaders\" with MBAs reply nonrandomstring 9 hours agorootparentprev> we also should discuss the boundaries required for its concept to make any sense. I feel that this understanding gets sometimes lost, and its naivety gets regretfully relabeled as \"innovation\". Good observation. It gets blamed on globalism, liberalism, post-modernism, capitalism, and a bunch of other things, but somehow we got the wrong idea that all boundaries are bad. Boundaries must be broken! I think that came from the language of science and technology. We made \"Smashing barriers!\" a synonym for progress. But it is a childish, iconoclastic and directionless notion of \"progress\", for its own sake. Psychologically at least, a lack of boundaries is a kind of madness, it's disinhibited, intrusive, lacking self-control - and to the extent there's a political theory of mind it leads to wars and internal unrest. We raised \"connectedness\" to supernatural hoodoo, but connectedness for it's own sake is a catastrophe to systems. It violates the principles of modularity, decoupling and appropriate cohesion. reply TheRealDunkirk 5 hours agorootparentprev> what happened to the joy of shaping the world? We were vastly outnumbered and overwhelmed by sociopaths who exploited the tools to make our lives better by capturing everything of value in the market, and subsequently enshittifying it. Our cynicism has been well earned and deserved. reply nonrandomstring 5 hours agorootparentYou misheard the reveille for the sound of the retreat. Can't wear cynicism on your chest with pride can you? Take back what's yours. reply classified 12 hours agorootparentprevNorbert Wiener https://en.wikipedia.org/wiki/Norbert_Wiener Otherwise, I completely agree. reply nonrandomstring 11 hours agorootparentOuch. Thanks. reply Citizen_Lame 8 hours agoparentprevRegulatory standards have not drifted. They have been captured by companies as big as some countries. Entire political and social system has been slowly eroding and reverting back to the Charles Dicken's times. We are just living in the times were cracks are visible enough and we can clearly see them. Tech bros never faced the same scrutiny as regular industries do (or at least there were no consequences). reply peacechance 12 hours agoparentprevIncorrect. We operate in a military smorgasbord where the war hungry U.S. government gets an unlimited budget of trillions of dollars year after year and their modus operandi is COLLECT IT ALL ... EXPLOIT IT ALL. The government believes that they are the only one's entitled to privacy for National Security™ purposes and their crimes are covered by criminal and conspiratorial compartmentalization. They go after journalists and whistle blowers like Julian Assange and Edward Snowden with dictatorial fury because the true enemy of fascist governments is Privacy for the People. Your perspective is cute business school brain washing but the real fact is that businesses like the FAANGS have realized that they can tap into fascist daddy's money faucet and sidestep the shelf-joke analysis you portrayed. Why worry about stocking shelves with good products to maybe sell units to individual consumers when you can sell to one big monstrous entity who can sign a billion dollars' large contract to ingest and process everything against the masses who barely have $100 to pay for a piece of software. We have a U.S. military problem here. reply posterboy 8 hours agorootparentwe are opperating in a \"breadboard\"? reply wizzwizz4 40 minutes agorootparentBuffet is probably a better translation, in this context: I don't think the emphasis was on it being bread. (The bread of the metaphorical smorgasbord signifies… resources? Pokémon? something that isn't bread, anyway.) reply meitham 11 hours agorootparentprevThe downvoting of this comment clearly show how HN users are in denial of the US atrocious behaviour on the world stage, to the extent of sanctioning international institutions such as the ICC! reply novariation 11 hours agorootparentTo be very honest I'm tempted to downvote this , not because I would disagree if this was the topic at hand, but because it seems like a deranged rant that's very loosely related to the comment it's replying. reply bbarnett 9 hours agorootparentNot to mention, if you compare the US, its citizen's intentions, and its government's intentions, and yes the DnD's intentions to all but a tiny handful of countries, the US is a golden boy of good. Compare today's US to, for example colonial powers. The US is pure in comparison. Compare the US to what happens to journalists in Russia, China, Iran. The US is a beacon of justice. Is the US perfect? Nope. But do a little comparative analysis, and the result is that the world has never, ever seen such a peaceful empire. The rancor often displayed on such comments makes me wonder. reply dbspin 8 hours agorootparentWhile I agree that the tone of parent is... unhelpfully agitated and aggressive. The broad strokes critique of US foreign (and domestic) policy is on point. The US began as a corporate colonial project - Virginia Company, London Company, Plymouth Company, Massachusetts Bay Company etc. It proceeded to expand through genocide of indigenous populations and wars of conquest - Cherokee–American Wars, Mexican American War, Spanish American War, Quasi-War with France and on and on. From the first the US (contrary to domestic myth) was colonial, expansionist and interventionist. US involvement in theatres around the world has initiated, prolonged and expanded conflicts - from Vietnam, Cambodia and Laos to Iraq and Afghanistan. The US has toppled literally dozens of democratically elected governments and helped elect numerous authoritarian dictators. The list of countries where the US has engaged in 'regime change' is so long it could fill up this comments character limit but to cite a few Hawaii, Panama, Honduras, Nicaragua, Mexico, Haiti, Philippines, Korea, Venezuela, Libya, Palestine, Syria etc. America has funded (and continues to fund) genocides, death squads, torture sites (its own as well as those of its allies). The US has replaced democratic leaders in countries as friendly as Australia as recently as 1975. At the risk of turning this comment into a letter to the editor of Foreign Policy - the US is not remotely a 'golden boy of good'. On balance Pax Americana has kept Europe at peace, but at the cost of keeping Africa, Latin and Central America, and parts of South East Asia impoverished and constantly at war. Is it China? Is it Russia? No. Would they make worse imperial powers? Almost certainly. It's a unique kind of tyranny, one that manages to convince it's own elites against all historic evidence it's a 'force for good'. reply bbarnett 8 hours agorootparentthe US is not remotely a 'golden boy of good' Ah, but it is in the context I stated. Quote: Not to mention, if you compare the US, its citizen's intentions, and its government's intentions, and yes the DnD's intentions to all but a tiny handful of countries, the US is a golden boy of good. Note the conditionals. \"intentions\" and \"compared to all but a tiny handful of countries\". Also note the context where I was careful to say \"Compare today's US\". In these contexts, the history of the US is meaningless, and only today counts. And I was referencing \"colonial powers\", which are historical, to us actions today. I know all the US has done. I also know all the British Empire did. I also know how Russia, China, Iran, and various tiny dictatorships around the world act. Yes, the US is very much a \"golden boy of good\" in reference to, and comparison to these things. Anything and anyone can be made a monster taken out of context. reply smatija 7 hours agorootparentJust look at atrocities USA is commiting in Yemen today. Or in Palestine proxied through Israel. reply MediocreSysEgnr 5 hours agorootparentSincere question: Is the second half of your assertion that U.S. government is directing/coordinating the conduct of the Israeli military or that their lack of action makes them makes them equally culpable/complicit in said actions? reply bbarnett 2 hours agorootparentprevAh, the backwards world view, where people defending themselves from relentless aggressors, including ones that call for an end to their existence, are somehow wrong to end those endless attacks. Israel would be nuts to leave even a wisp of Hamas in power in Palestine, and yes attacking innocent ships gets a defensive response. Next up! Man attacked by machete wielding lunatic punches him in defense, how dare he! reply TeMPOraL 4 hours agorootparentprevOh we know all about US atrocious behavior on the world stage. But this is completely irrelevant to the topic at hand. TLA agencies gonna TLA. But US military does not explain the enshittification and the surveillance economy. That's all on private business, small and large. Ethically challenged entrepreneurs, marketers, advertising industry, and yes, MBAs. But they're not a US phenomenon, they're a global issue. reply ajb 8 hours agoprevA lot of this is due to the failure of people's privacy instincts. People do have a strong instinctive desire for privacy, but only against other identifiable people. When private data are revealed to people they know or can be connected to their home address, then they are very upset. But they don't react when 'faceless' organizations collect their data, and use it in ways that are opaque, even when this is strongly to their disadvantage (such as HR departments sharing salary data). Anti-privacy interests are completely aware of this and avoid triggering the viceral response. For example, the spy agencies always give the example of \"no-one is listening to your calls\" as if the risk of surveillance was the guys transcribing from reel-to-reel tape recordings, not the dossier available to the powerful on each citizen. But the guy listening to our words on the tape is the one we have a viceral response to. Similarly facebook advertising terms (and presumably that of other companies) are careful to ban advertisers from showing the targetting and giving the impression that there is a person at the other end who knows all about you. I think the upshot of this is that we need to personalise it for the wider public, not just talk about abstracts like privacy. Bring out the fact that your next employer has that data when negotiating your salary. That companies spend thousands of hours figuring out how to manipulate you based on your data. That at the press of a button, the security services could assemble a dossier on you, and make it available to anyone powerful that you have annoyed. reply ryukoposting 29 minutes agoparent> ...as if the risk of surveillance was the guys transcribing from reel-to-reel tape recordings At a minimum, the guy transcribing the tapes is an accomplice to the surveillance effort. As a society, we desperately need privacy regulations to catch up to the digital age. Legislation will take years (decades?) to catch up, though. In the meantime, as tech industry professionals, we have a responsibility to not be the guy transcribing the tape. Right now, there's a lot of incentive to be that guy, and good data ethics regulation will remove those incentives from our industry. Until those incentives go away, it's up to us to make good moral choices, even if that means turning down a fat paycheck. How do we, as an industry, self-regulate while legislation catches up? reply Maro 15 hours agoprevCompanies like Google have had access to our full email, search, location, photo roll, video viewing, docs, etc history for 10+ years. I don't think also having our LLM prompts fundamentally changes this picture.. I guess this is what the shifting baseline argument refers to.. Having said that, I think it's rational for almost all people to not care to give up privacy for all these (addictively) amazing tools. Most people don't do anything worth privacy protecting. Having worked in data/engineering at bigtech, it's not like there's a human on the other side reviewing what each user is doing. For almost all people the data will just be used for boring purposes to build models for better marketing/ads/recommendations. A lot of the models aren't even personalised, the user is just represented by some not-human-readable feature vector that again nobody looks at. Hell, I have multiple Google Home devices that are always on and listening, and the thing's internal model is so basic and not-personalized that after multiple years it still has trouble parsing me when I say \"Play jazz\" and \"Stop\", even though these are the 2 commands I exclusuvely use. Sometimes it starts playing acid rock, and when I say \"Stop\" it starts reading me stock quotes. reply renegat0x0 12 hours agoparentNormalization of abusive behavior is not OK! If one company abuses you for 10+ years, then it is not OK for other companies to abuse you! If big data were not lucrative, they could not sell your data. If your data was not valuable Facebook and Google would immediately remove it from their servers without hesitation. Mantra. - I don't care about privacy - I don't care big tech has access to all my data - I don't care that Google has access all my politicians data - I don't care I am building a worse future for society - I don't care that I am being recorded while having sex in Tesla - I don't care I am building surveillance state - I don't care that my data are being sold to China, to India, to wherever highest bidder lives - I don't care how my data are being used. I don't care if my data are being used to train military robot dogs that will be used for wars - I don't care that I will not receive insurance because my medical data are sold wherever - I don't care about privacy - I don't care about privacy - I don't care about privacy reply tomalbrc 9 hours agorootparent\"I have nothing to hide\" reply IshKebab 9 hours agorootparentprevRight but I think his point was that we accepted this decades ago, and this latest case hasn't changed anything at all. In other words the baseline hasn't shifted. reply dbspin 8 hours agorootparent'We' didn't accept it. The internet expanded and the mass media conversation moved on to the next shiny thing. The majority of geeks have vehemently opposed mass surveillance every time it's been revealed (Snowdon, Assange). The majority of normies are completely unaware of the extent to which companies like Palantir and Clearview AI sell their most personal information to 'law enforcement', and Microsoft, Google and Facebook own and manipulate their information to fuel advertising. reply renegat0x0 9 hours agorootparentprevNo, you are not correct. The amount of surveillance IS rising. At first search data was recorded, emails, then maps, social interactions, car sensors, smart speakers. Now literally everything you do is captured, repackaged and sold. Corporations also are more creative when it comes to selling your data. They have more data, they sell more. Every drama is adding more to the privacy nightmare. Sorry, but you cannot say that \"nope nothing has changed for privacy in last 10 years\". reply amatecha 13 hours agoparentprev> Most people don't do anything worth privacy protecting. That rationale sounds great (albeit dismissive/invalidating) until something you've done (and have provided ample digital evidence of) becomes illegal or is otherwise used against you. Oh actually, what's your email password? I mean, since you're not doing anything worth keeping private, right? You think there isn't a human reviewing the data of what each user is doing, but there absolutely could be, and there's no reason there can't be, like when Tesla employees were viewing and exfiltrating footage/imagery from customers' vehicles. Not just one or two people but apparently disparate _groups_ of employees. https://www.reuters.com/technology/tesla-workers-shared-sens... reply Springtime 5 hours agorootparentIt's a common debate hole that privacy = hiding something bad/illegal, whether now or something deemed to be in the future. While this can be true it's only an aspect. Take benign examples where privacy would be useful and it's unrelated to that. Eg: was reading recently in WSJ how various insurers are using satellite and drone imagery of customer's roof conditions and using it to deny them coverage. However this has been abused where even brand new roofs have been marked as bad even despite evidence provided and push-back. The insurers were collecting imagery and making decisions but not providing evidence on their end. According to someone working for an insurer they're expecting soon to take images daily for such purposes. Here various incorrectly affected parties have done nothing illegal/bad/wrong but they're losing control and insight into processes that are affecting them in real ways. These aspects are part of what Daniel Solove outlined in their privacy taxonomy, where they broke down privacy into different things that comprise it (where information collection is distinguished from processing, etc). > much of the data gathered in computer databases is not particularly sensitive [...] Frequently, though not always, people’s activities would not be inhibited if others knew this information. I suggested a different metaphor to capture the problems – Franz Kafka’s The Trial, which depicts a bureaucracy with inscrutable purposes that uses people’s information to make important decisions about them, yet denies the people the ability to participate in how their information is used. reply andoando 2 hours agorootparentprevI worked at Tinder and we had full access to all the messages in plaintext, and ability to look up users by phone number, email, etc. reply Maro 12 hours agorootparentprevGood point about future exposure. A counter-argument: people already do all sorts illegal (misdemeanor?) things every day, tracked by big tech, and nothing happens. Some examples: • speeding: your smart phone knows what road you're on, what the speed limit is, and that you're over it • movie piracy: Chrome knows, your OS knows, your ISP knows, your VPN provider knows, any device that is listening can tell you're watching a movie that you shouldn'be able to watch at a non-cinema GPS location • .. reply 8372049 10 hours agorootparent20 years ago, legal firms sending out threatening letters to people they could identify on torrent trackers was commonplace. reply chaoskanzlerin 9 hours agorootparentIt's still quite commonplace in Germany in 2024. Typically, they claim around 1000€ in said letters, and refusing will have the case go to court, which usually rules in favor of said legal firms. reply bigfudge 12 hours agorootparentprevHave there never been cases where law enforcement requested that sort of information and used it? I don’t think we know. reply WhackyIdeas 9 hours agorootparentprevYep. Even NSA agents spy on their ex’s. So of course Microsoft employees will be spying on people. It’s not about privacy, it’s about having control of your own destiny. Not having some shitty OS maker think they are God in a 1984 world. This is the warped kind of stuff which happens to companies who join the NSA Prism program… give it a few years and all they care about is power and money and playing spy. There’s probably an NSA agent rubbing the higher ups at these companies off and telling them they are God as they finish. Or taking them on tours of the office and showing their cool exploding pens and other James Bond tech. Whatever it is, Microsoft is more than just invested. Recall? Give me a break. That is the most in your face global surveillance tech I have heard of to date. reply gbalduzzi 11 hours agorootparentprev> You think there isn't a human reviewing the data of what each user is doing, but there absolutely could be, and there's no reason there can't be I'm not sure there is a solution to this problem, unless we accept to lose a lot of features in our products and switch to E2E services. the only alternative I can think about is some required audit about the measure in place to prevent employees from accessing data, but I'm not sure how effective that would be reply ItsBob 10 hours agorootparent> I'm not sure there is a solution to this problem, unless we accept to lose a lot of features in our products and switch to E2E services. I'm not so sure. Based on the figures I could find for 2021, Google's ad revenue was about $60B with approx 3B users (I asked various chat bots...). So, if you extrapolated and did some slightly dodgy maths (there were other factors but I can't be arsed typing them) it would cost about $6-$7 per month per user if Google stopped all ads, and by extension, tracking & data mining - This is for Google to maintain their current figures. Take these figures with a big pinch of salt though... That $ figure is across the whole of Google. So that is for every single product they have but if you just use Gmail then it might only be $2 a month. So, if Google wanted to make the same money without tracking, ads etc, they could but the temptation to sell your data and mine it would be strong! Anyway, my point is that it's possible to do it but would people pay for it? I pay for my email with Fastmail so there is a single data point for you :) reply the_other 8 hours agorootparentLikewise. I pay for Fastmail, I contribute to Signal. Hell, I'm even paying for Kagi even tho' its results are fairly useless, in the hope that paying for privacy will lead to a better service over time. n+2 reply soco 9 hours agorootparentprevI pay for all apps and services I regularly use as a matter of principle even if they have a fine free version. It's not even that much, a couple dozens bucks a month, so here's a second data point. reply __MatrixMan__ 14 hours agoparentprev> Most people don't do anything worth privacy protecting. That may be true, but most people still benefit indirectly from the actions of the few who do have something to hide (e.g. protestors, journalists, whistleblowers). If we want the masses to continue to benefit from the actions of those few, then we need to find a middle ground. Someplace where the masses are private enough that a truly private individual can hide among them without sticking out like a sore thumb. You don't need to hide, you just need to be able to hide. reply FloatArtifact 13 hours agorootparentI would say that statement comes out of people's ignorance not out of informed knowledge. For those that even do know feel helpless in the face of industry standard treatment of privacy. reply 2Gkashmiri 13 hours agorootparentprevthis is literally the reason given for 100% adoption of https (because what if) reply newrotik 13 hours agoparentprevPrivacy is (a) freedom. The reason why people care about privacy is not necessarily because giving up privacy has some directly observable negative effect. But, simply, living without freedom sucks. I don't want you to know my personal information not because you could/would do something nefarious with it. I don't want you to have it simply because it's none of your business. reply A4ET8a8uTh0 7 hours agorootparentI am personally starting to think that this is the framing we need for this conversation. It needs to be discussed as a freedom as opposed to a right for no other reason than 'expectation of privacy' was very successfully neutered. reply ryukoposting 23 minutes agoparentprev> Most people don't do anything worth privacy protecting Define \"worth.\" Is a poor person's social security number not \"worth protecting\" because they don't any money to their name? What about the strife this would cause them? Is there not innate worth to that person's personal data simply by virtue of them being a person? reply TaylorAlexander 14 hours agoparentprev> I don't think also having our LLM prompts fundamentally changes this picture Is that what is being discussed? The biggest issue with Microsoft's new AI announcement was that their system was going to take screenshots of your computer every second and process them with AI. That means they could have way, way more data about you than LLM prompts. https://arstechnica.com/ai/2024/06/windows-recall-demands-an... reply moontear 13 hours agorootparentNo, this is not what the article nor this discussion is about. Windows Recall is completely local and hence actually is in line with the argument of the article that stuff was local way before they were in the cloud. Those screnshots Recall takes pose a whole different security and privacy problem: that someone (bad actor, your employer, your partner) may access these screenshots and gleam a lot of information about you they shouldn’t get. Recall is not about „Microsoft having way, way more data about you“. Other MS products, sure - Recall isn’t the point here. reply dspillett 9 hours agorootparent> Windows Recall is completely local Until it isn't, due to future changes or malicious 3rd party managing to make use of bad security decisions & bugs. reply logicchains 13 hours agorootparentprev>Windows Recall is completely local I'm pretty confident if the NSA or whatever asks MS for those screenshots, they've got a way of making them non-local. The EU is already pushing for mandatory local scanning for CSAM, do you think they wouldn't also extend this to Windows Recall snapshots once the technology is there? reply Maro 12 hours agorootparentI don't take Microsoft devices seriously, esp. PCs, except the Xbox they never last or gain widespread adoption.. reply crawfishphase 12 hours agorootparentMicrosoft Surface reply Maro 11 hours agorootparentI've never seen one irl. reply vundercind 52 minutes agorootparentI’ve seen exactly one. Got one at a dev agency I worked at as a Windows test device. This was like a 3rd or 4th generation one, I think. I was really excited to finally get my hands on one because they were supposed to be really good. TL;DR it was mediocre-leaning-bad judged as a laptop, and a terrible tablet. I can’t figure out how they got anything but bad press for the things. reply meowface 13 hours agorootparentprevYes, that's what this article is about. It doesn't mention user device surveillance. reply intended 11 hours agoparentprev> Most people don't do anything worth privacy protecting. Absolutely, its very rare for people to have things Like passwords, bank accounts, confidential documents, secrets, fears, weaknesses. And as we know, everyone applies good infosec practices, none of us have a txt file sitting in a folder with all our passwords. So on average, there isnt a growing collection of confidential data that our models are getting trained on. Matter of fact, if everyone who reads this were to randomly start loudly talking about “EAR-WAX REMOVAL” or “LOW LIBIDO”, in close proximity to a friend’s phone or Smart TV, theres no impact. They dont end up seeing some interesting and potentially embarrassing ads. It’s not like we live in a world where bad actors exist, maybe in some distant country, who try and take resources away. ——- EDIT: I came back to edit this because I felt I was perhaps too snarky and as a result having fun at expense to your argument. For what you said - it should be understood that it is easy to end up in a situation where privacy or PII is converted into a “problem” which has to be minimized. This is a position that then leads to many other far too complex failure states. Our future selves are better served by thinking of data we generate, as default private, and that all private data is “heavy” reply devjab 13 hours agoparentprevI think it’s interesting that you call out Google. It’s not that I disagree, but from the European enterprise perspective you can say that Microsoft has access to virtually everything. Banks, Healthcare, Defense, Public Services and so on, everyone is using the Office365 product line and almost everything is stored in Azure. I don’t begrudge Microsoft, I think they are a fantastic IT-business partner from an enterprise perspective. They are one of the few tech companies in the world that actually understands how an Enteprise Organisation wants to buy IT and support, and they’ve only ever gotten better at it. As an example, when I worked for a Danish city, someone from Seattle would call us with updates on major incidents hourly. Which is something you can translate to a CTO being capable of telling their organisation that Microsoft is calling them with updates on why “e-mail” isn’t working. So I actually think Microsoft is great from that side of things. I don’t think we should’ve put all our data into their care. We live in a post Snowden world, and even here in Denmark we recently had a scandal where it was revealed that our government lets NSA spy on every internet point leaving the country. I get that’s the way it is when you’re a pseudo vassal state. We’ve always had our government secrecy regarding the US and Greenland. It also makes me wonder how secret anything we’ve let Microsoft have access at really is. reply choeger 13 hours agorootparentThis. The next time, there's a real disagreement in trade policies, Europe is going to be fucked. Microsoft does have access to literally everything and no one even seems to understand that, because no one understands what \"cloud\" or even just \"online vs. offline\" means nowadays. It's a bit scary. reply devjab 13 hours agorootparentThis is another big issue, but the EU does know and care about it. My current employer falls under the critical infrastructure category (we’re finance/energy) and that means we’re required to have contingency plans for how to exit Microsoft in a month. Not just theoretical plans, but actual hands on plans that are to some degree tested once in a while. The issue is how impossible it is to exit Microsoft, and this is where I’m completely onboard with your scary part. We can exit Azure painlessly from the digitalisation perspective, well not financially painless but still. IT-operations will have fun replacing AD/EntraId though, but all our internal software can be moved to a Kubernetes cluster and be ready to accept external authorisation from Keycloak or whatever they have planned to move to. But where is the alternative to Office365? Anyone on HN could probably mention a bunch, but where is the alternative for people who don’t really “use” computers as such? The employee who basically think a pc “is” Office365. As in we could probably switch their Windows to Linux and they might not notice if they still had Office365. This is where the EU currently doesn’t really have an answer. We have a strategy to exit Office365, but I’m honestly not sure our business would survive it. reply yourusername 12 hours agorootparent> My current employer falls under the critical infrastructure category (we’re finance/energy) and that means we’re required to have contingency plans for how to exit Microsoft in a month. Not just theoretical plans, but actual hands on plans that are to some degree tested once in a while. If those plans exist and there is even a tiny chance you can pull that off i'm impressed. In most organizations it would be a almost impossible challenge to even upgrade all their servers to a new OS in a month. I don't think i've ever seen a organization of more than 100 employees that could reasonable migrate their cloud provider, identity source and operating system in a month. Endpoint operating system upgrades often take a year (or more). reply jononor 11 hours agorootparentMost organizations do not spend any time even thinking about that, nor considering it in their decision processes, nor prepare for it. An organisation that do, will have an IT architecture. For example limiting exposure in the first place. For example, they might chose to not have have any servers with Windows in the first place. They might have a thin client or web oriented workflow for endpoint applications, which make switching out Windows easier on employee mdchines. They might have already have multiple OSes in use, to check that critical systems can be successfully accessed without Windows. That said, it is of course a big endeavour. reply nonrandomstring 9 hours agorootparentprevThis is a big deal in cybersecurity education. I'm in the UK doing it. We've a dilemma that industry is desperate for fresh new cybersecurity recruits to fill an enormous skills gap. In the UK, Microsoft is a \"preferred supplier\" for lots of organisations, even defence stuff, and to get our students past the gatekeepers they pretty much need \"365\". Regardless of whether they can recompile a Linux kernel and do protocol analysis with Wireshark... no 365, no job, Not even tier-1 support. By contrast my last cohort of masters students worked on things like critical infrastructure, national security, long-term resilience, hybrid interoperability... everything that Microsoft is not and makes worse. So there's a schism between academic understanding and industrial reality that makes cybersecurity really rather hard to fix. So I have to walk into a classroom and say: \"Heads-up! We're going to be learning about 365 administration this week, about Active Directory, and this and that... which are all okay products and make a lot of admin tasks easier. BUT!! The only reason is so you can walk into a job. Because this US company has the UK tech sector by the balls. As soon as you're working, forget everything you hear in these lectures, because it's dangerous BigTech mono-culture that's antithetical to the real values of cybersecurity. Take the principles. Reject the products. Look at other tools that do the same, Have a backup plan.\" And I hope they took enough from Ross Anderson's SecEng book, and from the BSD/Linux classes and my the other lectures to go out there and start undoing the harm. reply mediumsmart 11 hours agorootparentprev> The issue is how impossible it is to exit Microsoft, https://blog.documentfoundation.org/blog/2024/04/04/german-s... reply robertlagrant 13 hours agorootparentprev> Which is something you can translate to a CTO being capable of telling their organisation that Microsoft is calling them with updates on why “e-mail” isn’t working. So I actually think Microsoft is great from that side of things. This is exactly it. Execs want to sound in charge of situations, even if it's just a person who can be shouted at. Microsoft can employ very expensive, individualised call centre staff in expensive suits to read out to you a service status page. reply devjab 13 hours agorootparentI agree but I also think it’s bigger than the ego of C-types. The fact that Microsoft calls you with updates also has a near magical impact on organisation culture in general. It’s the, “oh ok” gestalt that every employee feels, the thing that makes them consign to wait instead of being angry, and what not. Sure there is ego, but a lot of C types are frankly good enough to work beyond that part of the equation. reply robertlagrant 11 hours agorootparentI wasn't necessarily talking about ego, but more about how other people in the C-suite will react differently knowing that someone's calling with updates regularly. reply jc6 14 hours agoparentprevIts not some accident Google ended up with all this data. There is a reason they give you Free stuff like video, email, chat, search etc. People have forgotten the only way (in the past) to solve the Info Explosion that results when networks grow, is trying to understand Peoples needs better. That was the intention behind data collection. But ofcourse the story went off the rails when advertisors and marketers and politicians found value in all that data. But there is an upper bound to how much value there is, just like there is an upper bound to how much milk you can extract from a cow. Once you build huge ever scaling infra assuming there is no upper bound and then an upper bound is hit, what happens? Nothing good. Excess cows start getting slaughtered. Larger the system. Greater the over run. More slaughtering. Dont expect what you got for free to stay free. Expect all your data to be sold off at fire sales. reply BrenBarn 14 hours agoparentprev> Companies like Google have had access to our full email, search, location, photo roll, video viewing, docs, etc history for 10+ years. I don't think also having our LLM prompts fundamentally changes this picture.. Well, but that's sort of the point of the article. You're comparing against a baseline where our privacy is already eroded. If you compare to an earlier (say, pre-web) baseline it's quite different. reply jetsetk 10 hours agoparentprev> Most people don't do anything worth privacy protecting One of the worst takes I've ever read. There is something called metadata. Even if you don't do anything that is worth protecting explicitely, the data about your 'worthless data' enables perpetrators to see the patterns of your daily life. You can reconstruct so much by just gathering metadata over a certain time span, knowing when someone usually interacts with devices, social media etc. I don't want everybody to be able to derive when I'm sleeping, going to work or when I'm going on vacation. Hopefully, it is obvious to you that even a simple thief could use such information (if leaked) to know when it is the best time to go on a heist in your aparment. There is a nice 3c presentation by David Kriesel called SpiegelMining available on YouTube. It is in German, but the autogenerated subtitles are good enough to understand everything. He downloaded Spiegel Online newspaper articles over a certain period of time and was able to derive lots of information about the authors based on the article's metadata (publishing timestamps, author initials etc.) reply lesostep 8 hours agoparentprev>>Most people don't do anything worth privacy protecting I won't disclose why Russian government considers me a part of three different terrorist groups. But they also tried to call people who watched anime a terrorist organization. And they tried that at least 3 times in last ten years. Sooner or later they will succeed. Also, wasn't there a recent problem in USA where women were uninstalling period tracking software, because it could report someone as pregnant for having irregular period? I know at least 4 causes for missed period, do judges know that much? We don't protect our privacy because we are imperfect, we do it because assholes and|or stupid people exist. It's like a middle school. You might not be ashamed of having a crush, but you wouldn't tell everyone who they are, because some of our classmates are assholes that would care too much reply FMecha 19 minutes agorootparent>Also, wasn't there a recent problem in USA where women were uninstalling period tracking software, because it could report someone as pregnant for having irregular period? I know at least 4 causes for missed period, do judges know that much? There was a celebrity infidelity scandal in Japan where such app was allegedly involved too. reply czl 15 hours agoparentprev> not like there's a human on the other side reviewing what the user is doing With LLMs looking at all this data if you want to persecute or narrowly propagandize those who are X (X = pro-israel, anti-israel, pro-trump, anti-trump etc) it can be done much better than before. The \"humans on the other\" side will be using all this data to narrowly find people. reply Maro 14 hours agorootparentNarrowly? Half of people are pro-Trump, half of people are pro-Isreal/Palestine. reply _heimdall 14 hours agorootparentStats are really misleading when boiled down to binary decisions. While polls generally show that roughly half of US voters plan to vote for Trump, that's in the context of only being given the option of Trump or Biden. Most polls I remember seeing since 2016 show roughly 1/3 of the US really consider themselves Trump supporters. The Israel/Palestine question has similar problems. A binary poll question sets the context that a respondent needs to be on one side or the other, and that supporting or opposing both sides isn't an option. It also puts respondents in a position to have to pick a side regardless of how much or little they may know about the situation. With no more context, a 50:50 split could mean simply that most people don't know enough to decide and randomly pick a side instead. reply apantel 13 hours agorootparentNobody randomly picks a side. People who can’t make well-informed decisions simply follow the lean of whatever biases they have. Slightly hawkish or conservative? Pro-trump. Bleeding heart? Pro-Palestine. reply czl 9 hours agorootparentprevYes, for a search to be considered narrow, the resulting group should be small and specifically defined by precise criteria, not encompassing a significant portion of the population. *Notice once criteria are stacked groups can get small.* E.g. Which young males on your street (or in your building) who like Trump but not Israel were protesting at city hall today? Big datasets let authorities / advertisers / ... answer questions like that. The answer will often be a tiny \"narrow\" fraction of the population (of your city / state / country / ...). reply lazide 14 hours agorootparentprevIt’s not that simple - each group has a bunch of sub-groups which respond to specific propaganda tactics/buttons. Same with abortion/anti-abortion, guns/anti-gun, and any of thousands of other topics. reply roenxi 14 hours agorootparentprevYeah but you don't need to target them all. Most people are pretty much useless, politically speaking, they just do what they're told by someone else. If you can identify who is doing the telling and target them specifically, large groups of people will otherwise be docile. Historic attempts to apply that theory have been broad-brush to say the least [0]. With LLMs and access to enough data the authoritarians can get really fine-grained about when they take people out the next time they seize enough power. Anyone attempting to do something politically uncomfortable for the incumbents will be at serious risk in a fine-grained way that has not previously been possible. > Half of people are pro-Trump, half of people are pro-Isreal/Palestine. I don't think it is 50-50, more like 20-30% for Trump and I don't have a read on the Israel/Palestine stats. Trump has a dedicated core of supporters but I'd suggest a lot of the people polling for him just don't see a better option. [0] Eg, I was reading up on https://en.wikipedia.org/wiki/Intelligenzaktion the other day reply charles_f 2 hours agoparentprev> Having worked in data/engineering at bigtech, it's not like there's a human on the other side reviewing what each user is doing There doesn't need to be a human inspecting stuff, just a computer doing the filtering and reacting to it. The example that the article is using is already mentioning that they found the nefarious purpose. Given the current trend of politics, notably in the US, its not far-fetch to draw a future where searching for things like, say, abortion, becomes illegal, and tech companies get coerced into sharing that kind of information. The fact that MSFT found that co-pilot was being used by hackers suggests that they already have the entire set of tools to already do that. reply wilsonnb3 2 hours agorootparent> Given the current trend of politics, notably in the US, its not far-fetch to draw a future where searching for things like, say, abortion, becomes illegal, and tech companies get coerced into sharing that kind of information. This is the weakest of the privacy arguments to me. If we are in the \"evil government\" hypothetical future, why do they need my real searches? They can just as easily lie, make something up, use some other piece of data to persecute who they want, or do away with all of that pretense because they don't need it. reply digging 1 hour agorootparentYou're imagining a fictional, united evil government acting as a single entity. In real life right now, any given government has numerous bad actors at various levels who can and do use data to persecute people and groups they dislike. Most of the time, they still need real data, but it's a messy multidimensional spectrum and sometimes they can fabricate it. Another thing you're missing is that they're using this data to find the people they want to persecute. reply Animats 14 hours agoparentprev> Companies like Google have had access to our full email, search, location, photo roll, video viewing, docs, etc history for 10+ years. I don't think also having our LLM prompts fundamentally changes this picture.. Which is why I don't have a Google account. Their search is OK, but their other services aren't that great. reply sillysaurusx 14 hours agorootparentWhat do you use for email? reply Animats 13 hours agorootparentISP's IMAP server and Thunderbird. reply naavis 13 hours agorootparentprevI have been very satisfied with Fastmail. reply wizhi 13 hours agorootparentprevI can recommend Runbox. It's a paid service, but I really think that's for the better. reply jjav 11 hours agorootparentprev> What do you use for email? Self host reply layer8 8 hours agorootparentprevGMX reply behnamoh 13 hours agorootparentprevGoogle it. reply JohnFen 4 hours agoparentprev> For almost all people the data will just be used for boring purposes to build models for better marketing/ads/recommendations. You say that like it's a mundane and acceptable use, but this is the primary thing I want to avoid my data being used for, and is a huge part of why I get very concerned over privacy issues. reply graemep 10 hours agoparentprev> Most people don't do anything worth privacy protecting. Except for people whose employer does not approve of their politics, or whose family does not approve of their religion, or whose community does not approve of their sexuality, or whistleblowers, or journalists, or people who support causes the government disapproves of, or........ That covers an awful lot of people. Pretty much anyone living in, or with any links to anyone living in an authoritarian state too. reply AlexandrB 4 hours agoparentprev> Most people don't do anything worth privacy protecting. This is true of many fundamental rights. Most people don't say anything worth speech protecting either. The catch is that when you do need to say something worth saying or do something worth privacy protecting if the right wasn't there all along you're kind of screwed. reply xinayder 8 hours agoparentprev> Most people don't do anything worth privacy protecting. Bringing back the same argument in favor of protecting privacy: \"Saying you don't care about privacy protection because you have nothing to hide it's the same as saying you don't care about protecting free speech because you have nothing interesting to say\" I killed my social media accounts because I disagree with my pictures being used for training AI models. My friends, who aren't tech savvy people, keep mocking me for caring about it, and when I confront them about big tech knowing much more about our private lives than ourselves, they simply respond \"well, I don't care anyways, it won't make a difference in my life\". reply ivlad 15 hours agoparentprevYou choose to have Google spying devices at home. You choose to have Gmail. You may have no choice for Internet search for quite some time, but you certainly choose your browser. Start there. reply capital_guy 15 hours agorootparent> You choose to have Gmail Disagree with this. self hosting email is notoriously difficult. Gotta give the data to somebody. Plus, your work email is either going through MSFT or GOOG, 99% of the time reply sosodev 15 hours agorootparentWhat about the numerous other email providers? reply moring 14 hours agorootparentThe numerous other email providers are... numerous. Every discussion like this ignores, to an absurd extent, how hard it is for non-tech people to gather information on these topics and make an informed choice: Information about which email providers are care about which aspects of privacy, which aspects of privacy and information security even exists, which email providers even exist, what they are doind with your data, what parts of what they are doing is a problem... You can't even ask tech people to make a choice for you because they all say different things. Other domains like cars, medicine, construction, whatever have established standards because they have recognized that individuals simply _cannot_ make an informed choice, even if they want. I'm eager to say that only information technology likes to call the user \"unwilling\" and \"lazy\" instead, but actually individuals from other domains do that too. Luckily, the established standards are mandatory, so their opinion doesn't count. reply TeMPOraL 14 hours agorootparentprevRounding error that doesn't matter, because the recipients of any e-mail sent from those providers are likely on mailboxes backed by Google or MSFT anyway. reply justinclift 14 hours agorootparentprev> self hosting email is notoriously difficult Yet people do it anyway. It's not an impossible task like you're making out. reply nvy 14 hours agorootparentThe act of hosting postfix/dovecot is not in itself difficult. Debugging deliverability issues is, though. And it's time-consuming. reply jstanley 13 hours agorootparentThe greatest trick the centralised email services ever pulled is convincing people that a faulty spam filter is the sender's problem. reply justinclift 13 hours agorootparentprevAnd doesn't change anything I said at all. reply nvy 13 hours agorootparentIt kinda does, though. It's why I stopped self-hosting. I bet if you emailed my gmail address it wouldn't come through, even through no fault of your own. You can have DMARC, SPF and DKIM all correctly configured on a clean IP and some mail server at Microsoft will still drop your mails because it's having a hard day and it feels like it. reply justinclift 12 hours agorootparentYou can also route outbound email through an existing place like smtp2go.com, which stops all of that outbound hassle. :) That place in particular (which I use and can recommend) even have a (permanent?) free tier. ;) reply intern4tional 11 hours agorootparentThis makes it something that the average person cannot do; you're suggesting something that already requires more time and resources than 75% of the population has access to. If you're serious about this than go talk to a non-tech person and tell them to self-host email and see how they do. Look at their challenges, build a solution and then offer it. reply justinclift 10 hours agorootparentPlease don't try changing the goal posts by introducing \"non-tech\" people into this. That's not at all what the conversation is about, and routing through an external place removes a whole bunch of hassle compared to setting up and maintaining outbound email. You might not like it for some reason, but that's on you. reply nvy 4 hours agorootparentprevIf you need a third party to deliver your mail on your behalf, are you really self hosting? What's the point? At that stage you've already conceded the deliverability problem so now you're just wasting time administrating dovecot and keeping up with security patches. reply hackermatic 14 hours agoparentprevA lot more people are vulnerable to abusive partners than you may think, and that's a threat model most of these products never consider. reply Thorrez 11 hours agorootparentWould local hosting be any better against the abusive partner threat than these products? Disclosure: I work at Google. reply hackermatic 4 hours agorootparentLocal hosting/processing is a good thought, but it only helps in limited circumstances, because partners you haven't separated from yet are likely to have physical access to your devices. It's one of the big criticisms of Microsoft Recall: the database is locally generated and encrypted at rest, but practically, any user in the same home with device access can probably access it, and bypass any efforts you've made to delete your browsing history or messages. Remember that abusers are often controlling and suspicious, so disabling Recall, denying them access to your devices, or changing your passwords is enough to set them off because you appear to be hiding something (maybe making plans to leave or report them). Plausible deniability can be an important feature for activists and regular people alike. You can't always predict when a relationship goes south like this, or get out of it as soon as it does, or afford and hide a burner phone. One of my friends remarks (edit) that tech companies should have a social worker and a public defender on staff for threat modeling these things. reply Aerroon 5 hours agoparentprevI don't think that's really true. Google has had pretty serious privacy guards in place, where if you don't want Google to collect info on you (for advertising), they won't. Also, lots of people use other email services than Gmail, don't share their location information, don't share their photo roll nor share their internet history with Google. And a lot of video viewing is obviously not done on YouTube. reply Maskawanian 3 hours agorootparent> Google has had pretty serious privacy guards in place, where if you don't want Google to collect info on you (for advertising), they won't. How do we know this? They may claim this, however their incentives as an advertising company would provide strong pressure against this. reply longerd2 11 hours agoparentprevYou really need a google device and an internet connection to be able to say \"stop\" to stop your music? Wow. My old \"smart\" watch could do that offline xD This can't be hard to do on your own, without a google device listening at all times... reply jononor 11 hours agoparentprevAdvertisement has the purpose of trying to get money from you, or to make you change your mind on political issues. These things are worth protecting. Companies using your private information for such purposes is an attack. reply justinclift 14 hours agoparentprev> Companies like Google have had access to our ... I hear people saying things like that occasionally, and have to wonder... why did you do that to yourself? And why are you assuming everyone else was similarly unwise? \"Companies like Google\" certainly haven't had that kind of info from me, nor from several people I know, as we've avoided the vast majority of their products. reply YetAnotherNick 14 hours agorootparent> \"Companies like Google\" certainly haven't had that kind of info from me Do you use any search engine? Then yeah, your data is funnelled to google/microsoft. reply jononor 10 hours agorootparentOnly the data on what is being searched. Which is of course quite a lot. But it requires active effort to leak data that way. Many types of sensitive information is not natural to put there, say conversations with others or a diary. And other things can be actively avoided, like searching about illegal things. Which in some countries could be simple things like gay communities etc, unfortunately. reply justinclift 13 hours agorootparentprevKagi reply Madmallard 14 hours agoparentprevYou have no idea what future advantage can be taken against people using this data. Seriously, like it's complete normal instinct to never overshare in conversation. Everyone knows this. This is the equivalent of extreme oversharing at all times. reply jononor 10 hours agorootparentYeah, just potential for gossip and slander type attacks, makes it same to not share everything. Our cloud services probably had the power to discredit or blackmail any user. reply verisimi 13 hours agoparentprev> Most people don't do anything worth privacy protecting. There are lots of reasons why you don't hand your personal information to everyone, why you wear clothes even though it might be warm enough not to, etc. But the key point for me, is that knowing you are being watched, or even suspecting it, changes behaviour. You cannot be you online. You do things differently, edit yourself. It is a form of manipulation. Which was always the point. The panopticon was conceived as the perfect prison to control others. https://www.wikipedia.org/wiki/Panopticon reply wruza 9 hours agoparentprevYou are welcome to live in any country that doesn’t value privacy just to see what it’s like after you surrender it. reply throw283725 10 hours agoparentprev> Most people don't do anything worth privacy protecting. Do you feel the same way about TikTok? reply midtake 12 hours agoparentprevInformation about your preferences is weaponized in the current era. As an example that some might find relatable, if you support Trump and you work for a FAANG, you might just lose your job. reply 8372049 10 hours agorootparentWhile I agree with the general sentiment, I think the problem in this specific case is lack of job security in the US. In most European countries getting fired for something like this would never fly. reply __loam 10 hours agoparentprevPrivacy doesn't matter until someone in a vulnerable group gets killed because someone doxxed them. Hell, even some semi-private people have been killed by things like swatting. Privacy matters and we should pass laws to protect it, just like we have the 4th amendment to protect against unlawful search and seizure. reply eesmith 12 hours agoparentprev> Most people don't do anything worth privacy protecting. The flip side is false positives. Have a scanned photo from when your grandmother bathed you as a baby? Google may identify it as child porn and shut down your account. https://timesofindia.indiatimes.com/city/ahmedabad/google-la... \"Gujarat high court has issued notice to state govt, Centre and Google India Pvt Ltd after the tech giant blocked an engineer’s account citing “explicit child abuse”. The engineer had uploaded a photo showing his grandmother giving him a bath as a two-year-old.\" \"... his client could not even access email and his business was suffering. The blocking was like a loss of identity for Shukla, a computer engineer, most of whose business depended on communication through the internet. Shukla had requested Google to restore his account, but in vain.\" reply SebFender 8 hours agoparentprevHaving said that, it's easy not to care - until something significant happens to you or your family... How many clients has my team helped when it was just too late? Many if not most. One fundamental flaw humans have is not to care until it's too late. Why should I care about my gutters? Until the day the basement is filled with water because of these \"ridiculous\" gutters... reply LightHugger 12 hours agoparentprev> Most people don't do anything worth privacy protecting. This is blatantly wrong, If i'm a large corporation i can use the information you think is worthless against you via first degree price discrimination and countless other targetted mechanisms. You simply haven't thought about it enough, and as soon as you do, you will realize when no privacy exists people will and have been developing mechanisms to take advantage and capitalize on this state of affairs. reply timeon 12 hours agoparentprev> I have multiple Google Home devices that are always on and listening No wonder you don't care too much about privacy, but this is not normal for everyone. reply andrepd 11 hours agoparentprev>Most people don't do anything worth privacy protecting. I can only describe this take as disgusting. Saying you don't care about privacy because you have nothing to hide is like saying you don't care about freedom of speech because you have nothing to say. Privacy is a fundamental pillar of society, for without privacy there is no freedom. We already see the chilling effects across many situations, we have seen them for the past decade+ at least. It's only the beginning. reply sneak 12 hours agoparentprevIt’s not Google you need to worry about. It’s the state that can compel access to Google’s (and Apple’s, and Meta’s) data without a warrant. Big tech doesn’t run concentration camps, but governments can and do, including the USA. Are you confident that the state will always be friendly to people like you? How about the people you support politically? reply isodev 14 hours agoprev> one that respects people’s privacy rights while also allowing companies to recoup costs for services they provide Big tech is a bit like tobacco companies at some point - we’ve convinced people and ourselves that certain things are good, even healthy while they’re actually the opposite. We, the people who build and maintain these services, are in a position to offer pushback to ensure the humans and their privacy is higher than any other concerns. reply FMecha 16 minutes agoparent>We, the people who build and maintain these services, are in a position to offer pushback to ensure the humans and their privacy is higher than any other concerns. So, a Hollywood-style strike with the aim to do so? reply shiroiushi 14 hours agoparentprev>We, the people who build and maintain these services, are in a position to... Speak for yourself. Most people in tech do not work for Google or Microsoft. Working in tech alone doesn't give you some kind of power to offer pushback in these tech companies, just like being a random worker in the agriculture sector doesn't give you power to offer pushback against the tobacco companies. reply iamkonstantin 13 hours agorootparentI think the op means that this is a mindset to apply on any kind of software or tech project. Think apps supported by ads or deploying tracking toolkits by default. I was looking for a blog template the other day - so many come loaded with Google analytics and silly cookie prompts for no good reason. These are things we can influence. reply shortrounddev2 5 hours agorootparentIf the boss says we're adding third party tracking, then that's what's happening. Software engineers have little to no control over the product. The only power I have is to quit my job reply hereme888 3 hours agorootparentprevI think \"most people in tech\" have the choice to not use Big Tech spying services that keep gathering the data. But how common is that choice? reply gigel82 12 hours agorootparentprevAnd you think people that work at Google or Microsoft have power to pushback against the shit their employers do? LOL reply shiroiushi 10 hours agorootparentI never said they did, but the OP clearly thought so. I'm just pointing out that most of us don't work there, so we don't have whatever power the OP thinks we have. reply behnamoh 13 hours agoparentprev> we, the people unfortunately most engineers I've seen (i come from an engineering background) care mostly about technical stuff and lack the EQ to see the bigger picture. reply Longhanks 12 hours agorootparentSure, because any attempt to be morally right instead of pleasing the shareholders is struck down by management. You might even risk to penalize your future career. Most engineers are engineers, not company politicians. That doesn’t mean they don’t see the greater picture, it’s just not worth it dealing with corporate bullshit (or even endangering). reply oefrha 15 hours agoprevSnowden has shown us that Microsoft and every other big tech will happily give NSA the keys. Given that OpenAI is fully beholden to Microsoft both in terms of ownership and compute, I have to assume NSA gets whatever they want from OpenAI, directly or through Microsoft. Now, apps and services are integrating AI like crazy, penetrating just about every type of information, and much of these integrations are sending data to OpenAI, voluntarily. People are sending their private thoughts to OpenAI as they brainstorm, as they write, before fully fledged ideas are even formed. NSA must be enjoying this transparency now. reply benreesman 15 hours agoparentThese concerns are doubtlessly well-founded based on disclosures, particularly the Snowden disclosures. But as for infinite data and definitely smart enough people to have ten SOTA LLMs in flight? I don’t think TAO/EG needs any help from fucking Microsoft. reply TiredOfLife 8 hours agoparentprevSnowden showed only what his handlers told him to show. reply blitzar 9 hours agoparentprevSnowden has shown us that nobody cares. The disclosures of Snowden should have brought about profound change in this entire debate (> 10 years ago). Instead he is a refugee with not much more to do than to shill crypto. reply whoknowsidont 16 hours agoprevI agree. Philosophically, politically and financially (in terms of groups I donate to). But it's too late. The frame shift is too great for most people. Getting people to care about this let alone vote in a manner that would cause actual change is so far out I have a better chance of winning the lottery. I don't know what to do other than to support and educate where I can. I do hope I'm wrong. reply poikroequ 15 hours agoparentI've seen first hand just how little the average person cares about privacy. The type of people who believe they have nothing to hide. My friends and family don't understand why I don't post everything to social media. No I'm not going to install this app and scan all my receipts. BuT wHy?!?!?! I think many people here on hackernews live in a bubble and just don't understand what is an average human being. They surround themselves with like-minded tech savvy individuals and fail to comprehend how there isn't stronger support for privacy. reply kbenson 15 hours agorootparent> I think many people here on hackernews live in a bubble and just don't understand what is an average human being. Plenty of us understand, but it's depressing and usually trying to explain to others that have a rosier view of how people will react feels a lot like trying to get the people themselves to care, which is to say it's hard, thankless, and depressing, so few people bother. reply renonce 15 hours agorootparentprevYou don’t want to be responsible for some random receipt 10 years ago that allegedly commits tax fraud, allow influencers to manipulate you into buying things or supporting campaigns that you immediately regret 1 minute later, receive lots of spams in your email and social accounts, etc, and the stakes get higher as you climb up the social ladder. Many of these don’t matter for people with little stakes as they have nothing to lose. reply blitzar 9 hours agorootparentprev> I think many people here on hackernews live in a bubble and create apps to scan all your receipts, your retinas and then track your movements and sell the data to the highest and the lowest bidder in exchange for a slightly newer Maserati. reply pennybanks 15 hours agorootparentprevi agree. people just dont care. and if everyone did we would be paying cash for the online products we use for free reply bn-l 11 hours agorootparentIt’s the “free” price. I used to think it was great! Now it always makes me uneasy. reply teh_infallible 15 hours agorootparentprevI suspect that people care about privacy more than we think, but the technology feels overwhelming to them, so they bury their heads in the sand. I don’t even browse in “private mode.” Not because I don’t care, but because I assume it won’t really change anything. reply 8372049 10 hours agorootparentPrivate mode has very little impact on what you share with the world/through the network. It's there to keep your browsing private from people you live with etc., not from anyone else. reply hierophantic 7 hours agorootparentprevI just don't agree",
    "originSummary": [
      "Barath Raghavan and Bruce Schneier draw parallels between online privacy and fishing, emphasizing the ecosystem-wide impact of privacy breaches.",
      "They discuss a Microsoft spying controversy to highlight the need for a holistic approach to data protection.",
      "The authors advocate for considering the broader digital environment when addressing online privacy issues."
    ],
    "commentSummary": [
      "The article critiques the Microsoft AI spying scandal, calling for updated privacy standards and highlighting the economic and societal impacts of diminishing regulatory trust.",
      "It contrasts the focus on TikTok's privacy issues with similar concerns in American companies, highlighting bipartisan misuse of private data in political campaigns.",
      "The text emphasizes the urgent need for stronger privacy regulations, criticizing big tech companies for data misuse and surveillance, and calls for established privacy standards."
    ],
    "points": 764,
    "commentCount": 321,
    "retryCount": 0,
    "time": 1717640725
  },
  {
    "id": 40596883,
    "title": "SpaceX's Super Heavy Successfully Lands in Gulf of Mexico",
    "originLink": "https://twitter.com/SpaceX/status/1798701489097183286",
    "originBody": "Super Heavy has splashed down in the Gulf of Mexico pic.twitter.com/hIY3Gkq57k— SpaceX (@SpaceX) June 6, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40596883",
    "commentBody": "Super Heavy has splashed down in The Gulf of Mexico (twitter.com/spacex)341 points by thepasswordis 5 hours agohidepastfavorite406 comments bearjaws 5 hours agoThe rate of descent is absolutely astonishing, 8km -> 1km in 20 seconds, then just hovers above the water. Absolutely incredible work by the SpaceX team. Living in central Florida I cannot wait for the new launch facility to come online. We're going to have lines of spectators into the space coast like we did for the shuttle. If any of you are heading to Disney World you should stop by the NASA Kennedy Visitor Complex, it is so well done and not that expensive (it takes less time than 1 line at Disney world to get to :) ). It has the original launch control room for Apollo that you can tour, a Saturn V rocket that is laid horizontally and you can walk under, the crew module for the moon landing. My favorite part is the Atlantis shuttle suspended from the ceiling, they left it in its \"raw\" landed format with scorch marks and tiles, it looks absolutely amazing. reply somenameforme 1 hour agoparentThe 'worst' thing about watching space launches on streams is that you simply cannot grasp how ridiculously huge these things are. Even if, like in the stream today, you see a water tower for some scale, the size discrepancies just make it so hard to intuit. Starship is 121 meters high. That's something taller than a football field, jetting off into space! I've only gotten to see a decommissioned Space Shuttle in person, but that was also amazing. Even its fuel tank [1] makes you feel just tiny, yet it's merely 47m. Getting to see Starship live would be such an amazing opportunity. [1] - https://en.wikipedia.org/wiki/Space_Shuttle_external_tank reply dotnet00 49 minutes agorootparentI only live close enough to be able to see Enterprise, which didn't go to space, but I like to go there at least once a year, just because seeing the sheer size of it and knowing that all the Shuttles were like that is inspiring (the SR-71 helps too). I'm planning a trip to the space coast when family visits next year though. reply causi 0 minutes agorootparentMan I hope Musk names one of the Starships Enterprise. tim333 51 minutes agorootparentprevI've got the black and white arty photo as my lockscreen which gives you an idea https://cdn.mos.cms.futurecdn.net/E46BxzjjUkpthVBNE6k8mn-192... reply jstanley 47 minutes agorootparentIt reminds me of the old photos of builders eating their lunch atop half-finished skyscrapers. https://en.m.wikipedia.org/wiki/Lunch_atop_a_Skyscraper reply jaggederest 32 minutes agorootparentprevStanding next to the S-IC stage from the Saturn V at Kennedy really puts it into perspective. And the Starship full stack is larger and taller than the Saturn V! reply vl 1 hour agoparentprevWhat is even more impressive to me is that they were able to quite reliably stream all this through Starlink. This shows how mature and usable Starlink is. The fact that you can have live internet connection on re-entering space ship - truly the future is here. reply bartread 44 minutes agoparentprevThe way the booster comes down is nuts. 90km to 1km in 100 seconds, it reaches maximum velocity under gravity at a bit over 20km, then air resistance acts as a brake, and they only fire the engines to slow it down the rest of the way at 1km. Bonkers. reply DavidPeiffer 5 hours agoparentprevFor anyone who has been there more than a couple years back, it's worth checking it out again. They added Gateway: The Deep Space Launch Complex, and have also been expanding the Astronaut Training Experience. The exhibits are all very well done. The bus tours are also neat, visiting and walking around launch pads from the early days of space exploration, seeing the bunker near a launch pad with ~8\" thick glass and the mechanical linkage over a couple hundred feet which let them monitor the weight of the added fuel on an early mission. I've gone 7 times since I was a child, and love the new things I find. reply gadders 5 hours agoparentprevIt's mad how rocket landings are now more exciting than rocket launches. reply steve1977 4 hours agorootparentWhen I was young, there were no rocket landings. reply GJim 4 hours agorootparentMy grandfather recalls (what he later found out to be) a rocket landing in London's east end during his youth. There were quite a lot of them at the time. reply mannykannot 3 hours agorootparent\"Once the rockets are up, who cares where they come down? That's not my department\" says Wernher von Braun. - Tom Lehrer. https://genius.com/Tom-lehrer-wernher-von-braun-lyrics reply panick21_ 15 minutes agorootparentMaybe if it was his department they would have hit London more often. reply chgs 1 hour agorootparentprevThe rocket performed perfectly. It just landed on the wrong planet. reply pfdietz 31 minutes agorootparentThe 1960 von Braun biopic \"I Aim at the Stars\" had posters to which wags added \"But Sometimes I Hit London\". reply unethical_ban 1 hour agorootparentprevIn German, or Englisch, I know how to count down... und I'm learning Chinese, says Werner von Braun. Written in 1961. Wild. reply steve1977 4 hours agorootparentprevI actually thought about including a “non-destructive” qualifier… ;) reply jonah 4 hours agorootparentprev\"RSD\"? (Rapid Scheduled Disassembly) reply SoftTalker 4 hours agorootparentGerman V1 or V2, presumably. reply tialaramex 3 hours agorootparentOnly the V2 is a rocket, the V1 is a flying bomb. They're both terror weapons, as actual products they have no direct military value, they exist solely in order to scare the shit out of enemy civilians, but liquid fuelled rockets are an invention with a whole lot of interesting practical applications - the V1 is just a bad idea (unless you have unlimited resources, which the Germans did not, and your goal is to terrify enemy civilians, which is not a legitimate military strategy). reply EasyMark 2 hours agorootparentV1: didn't they have to start somewhere? reply ElevenLathe 1 hour agorootparentprevV2 was of questionable legitimate military utility too. Sure you can hit a target the size of a city, but unlike carpet bombing, the payload isn't enough to guarantee that something specific is destroyed. So you can only use it to randomly harm civilians and maybe every once in a while hit a military target. Compare this with the Western Allies' approach where they also killed and maimed tons of civilians but at least stood some chance of also destroying the building-sized thing they were aiming at, given the stupefying tonnage of bombs involved. \"Once the rockets go up, who cares where they come down? 'That's not my department,' says Werner Von Braun.\" -- Tom Lehrer https://www.youtube.com/watch?v=QEJ9HrZq7Ro reply amanaplanacanal 31 minutes agorootparentFirebombing whole cities in Europe and Japan is still a black mark in US history. It’s really hard for me to get “holier than thou” on other terror campaigns when I remember that. reply stctw 17 minutes agorootparentIt's easy to say that now. Have you lived through unrestricted, total warfare, where one side intends to conquer a continent or the world, invades without provocation, and won't stop until brought to submission through extreme force? The Allies did not initiate war and did not want war. How many of your country's people should you sacrifice to end a war of aggression started by the enemy? Should you not use the means that will preserve as many of your lives as you can? This century has yet to see anything like WW1 and WW2, and those who are alive today are incredibly disconnected from our recent past. dingaling 1 hour agorootparentprevIf you were young between 1993 and 1995 then DC-X was making landings reply gadders 1 hour agorootparentprevNor for me, but I'm old enough to have seen re-runs of things like Flash Gordon in black and white which I'm sure had rockets landing vertically. (This could be the Mandela effect though). reply adolph 1 hour agorootparentprev> When I was young, there were no rocket landings. For all born after July 1969, you lived with rocket landings: Apollo lunar lander was a propulsive soft landing. reply pixl97 1 minute agorootparentI mean the old rocket landings threw away 90%+ of the rocket first. Minus the hot staging ring and some molten metal almost all of this rocket was present at both its landings. cjk2 5 hours agorootparentprevThey used to be far more exciting. It's the anticipation of less excitement that is nail biting :D reply BurningFrog 4 hours agorootparentprevSame thing with airplanes. The landing is much more important than the takeoff. reply function_seven 1 hour agorootparentReal quote from my grandmother, years ago: \"I'm not scared of flying so much. I just wish the plane didn't have to get so close to the ground before landing!\" reply dcdc123 45 minutes agoparentprevThe Houston center is amazing as well! They have a tour where you get to sit in the guest theater/gallery of the original command room and watch a shortened version of the moon landing with all the controls, monitors, projectors, etc all automated to show what was presented during the original landing. reply chasd00 20 minutes agorootparentI think Houston also has the most complete Saturn V too. It's on its side in a shed out back basically. reply jzig 4 hours agoparentprevHello from Gainesville! Thanks for recommending the NASA Kennedy Visitor Complex. We will have to visit next time we make a trip to Orlando. reply mywacaday 4 hours agoparentprevI had the pleasure of seeing Endeavour being brought out on a Crawler-transporter in 2008 from about 300 meters away on the LC 39 Observation Gantry. Its a missed bucket list item that I never got to see one launch. The visitor complex is well worth a visit. reply sixQuarks 5 hours agoparentprevYeah it’s hard to comprehend how powerful those engines are. The booster is relatively light without all the propellant and starship when it’s attempting to land, but it’s still 30 stories tall and I’m assuming it weighs dozens of tons. reply foobarian 5 hours agorootparentIt blew my mind that just the fuel pump for just one engine has a power rated in the tens of thousands of horsepower/kW. reply chasd00 5 hours agorootparentpreviirc only 3 ignite for the landing burn, those engines are freaking monsters. I love how small they are, the latest Raptor revision is so slim and compact. The power density is just mind boggling. reply sobellian 5 hours agorootparentYou can see for yourself in the video - all 13 center engines attempt to light, and all but one do so. reply arpinum 5 hours agorootparentSimilar to ship, they start up more engines than needed in case a few fail, then immediately shut down the extra engines. reply arrowsmith 5 hours agorootparentprevWhere is this visible in the video? EDIT: oh wait is it the diagram in the bottom left? reply world2vec 3 hours agoprevSeeing the Starship's flap visibly burning in the reentry heat and still survive well enough to move around and get to a splashdown was just incredible. Amazing progress in just four test flights. reply marmakoide 2 hours agoparentThat flap is already a legend, kept at it even mangled by hot plasma, crazy accelerations and pressures, spitting molten steel at the camera. What a role model, the little flap that could. reply thelittleone 1 hour agorootparentSomeone on the Everyday Astronaut live stream named it \"Flap Norris\". reply somenameforme 1 hour agorootparentI wonder what the odds are that some deep sea salvage group is moving to collect that this very instant (or being contracted for such). If Starship lives up to even a fraction of its potential, that [not so] little guy is going to have some serious historicity. reply dotnet00 45 minutes agorootparentThey had a plane flying in the area shortly after landing, probably to drop some marker for a group to come around and recover the black box. I think they've stopped bothering with preserving the test articles though, in the process of test driven development, they're going to have so many \"historic\" test articles, that it's kind of pointless. reply BurningFrog 29 minutes agorootparentI'd be really surprised if they didn't have a GPS in the ship. Which should mean they know where it \"landed\". reply thelittleone 1 minute agorootparentNot sure if I heard the commentary correctly, but I believe they said the video uplink was via starlink. If so, they should have the precise location. dotnet00 24 minutes agorootparentprevThey still would've been in position to put down a marker, since they had to be prepared for that before they knew they'd be able to maintain telemetry down to the water, and if they're already in position, it doesn't hurt to place the marker anyway. reply hindsightbias 52 minutes agorootparentprevWhat makes you think it sank? If the hull is intact it might be floating. Given the flap damage, it's probably leaking though. reply Andrew_nenakhov 15 minutes agorootparentIt looked like the booster exploded when it submerged after soft splashdown. There was some fire and the stream cut off. Maybe that's what happened to the ship too. reply gpm 2 hours agoparentprevAlso lost an engine at startup and another engine during the landing burn on the booster. Judging by the debris maybe a third engine during landing burn shutdown (or maybe that was the second engine just exploding a bit more). Still a successful test, still a lot of work to do before they can meet their promises for Artemis (which require >10 back to back launches for one lunar mission...) reply thelittleone 1 hour agorootparentTrue. Heard SpaceX commentator today saying they plan 4 launch towers in near term. Hopefully the major issues that lead to FAA investigations are resolved and the cadence can ramp up. Probably won't be long before Starship's launch as often as Falcon 9s today. reply baq 2 hours agoparentprevyeah the thing did a soft splashdown with a leaking flap, the fluid in question being molten stainless steel. this was hard sci-fi, streamed live for everyone to see. reply delichon 4 hours agoprevWatching pieces of the ship melt off, but then seeing it make a relatively controlled landing, is perversely confidence building. If it can survive that kind of damage on a control surface maybe it's a quite robust craft. reply golol 3 hours agoparentExactly. Everyone was worried about reentry, but perhaps more concerning than the question of whether the headshield tiles work was the question how well the material below can handle failures. Now we know significant failures of tiles do not have to lead to mission loss. reply cryptonector 2 hours agorootparentFailure of the tanks would undoubtedly have been catastrophic. Partial failure of a flight control surface proved survivable. reply mathsmath 1 hour agorootparentIt's also worth noting part of the craft flew (intentionally) without heat tiles, and another part with thinner tiles. They're gathering a ton of data to make it robust! Many of these engineers built Falcon 9, and I have a pretty high degree of confidence they'll shake out the issues. SpaceX operates very differently from traditional aerospace, so we'll likely see many more issues come up before Starship is human rated. reply dotnet00 42 minutes agoparentprevReminiscent of the booster in IFT-1 just doing spins in the air, refusing to break up even after the flight termination system was triggered. Completely unlike KSP with its wobbly rockets. reply merek 4 hours agoparentprevAgree, a successful mission needn't be a perfect mission reply api 4 hours agoparentprevI’ve said for a while that we won’t be ready for the real space age until you can have a rusty pickup in space. What I mean by that is that we have it down well enough that the tech exceeds tolerances and can degrade gracefully. You see this in some sci-fi where there are rust bucket old ships that work. reply ryandvm 3 hours agorootparentYou have to be careful how much wisdom you glean from fiction. The sheer hostility of space kind of precludes the \"she's a good ol' ship\" trope. When your door doesn't shut on your pickup, you can bang on it a bit. When your door doesn't shut on your spacecraft, you've got a ship full of corpses that look like a blob fish brought up from the Marianas Trench. reply solarkraft 1 hour agorootparentNo, that's the point: It's a significant technological advancement for some unreliability/imprecision to not mean critical failure. reply somenameforme 52 minutes agorootparentprevEverything's relative. People a century ago would probably have felt uncomfortable at the idea of DIYing a multi ton vehicle being accelerated by a extremely high power pistons pounding up and down thanks to creating a controlled explosion inside a tight little box, that you can then hop in and cruise around at 80MPH+. And indeed if something goes critically wrong, you're dead. We just work to reduce the number of ways that things can go critically wrong. reply ceejayoz 3 hours agorootparentprevThat's more an argument for redundant doors than perfect doors, though. reply HPsquared 3 hours agorootparentprevThe oceans are very hostile to humans too, really not much less than space, and a lot of ocean-going vessels are rusty hulks. reply panick21_ 5 minutes agorootparentA lot of ocean going vessels were literally made from wood that was continuously rotting. reply api 2 hours agorootparentprevI think the definition of workable old ship is going to be different in space, but ultimately you can expand workable envelope for it by over-engineering critical parts. That's kind of what I mean. Right now we don't quite know how to do that efficiently or effectively. Still remember that at one time moving faster than 15mph was considered insane and pushed the limits of materials and vehicle design. Same for high altitude flight, McMurdo station, deep ocean diving, etc. In a lot of ways very deep ocean diving is harder than space. The pressure differentials are a lot worse. The hard part about space is really launch and delta-V budgets. reply ceejayoz 4 hours agoparentprevYeah, and what a useful recording for \"where do we buff up the heat protection?\" reply idontwantthis 4 hours agorootparentIt looked like plasma got between the flap and the body. I wonder if that means something broke/melted to allow that, or if the design just allowed it accidentally. reply lsaferite 26 minutes agorootparentIt looked like the flap was starting to glow internally in the middle, right before the burn-through on the hinge point. I wonder if it maybe had a lost tile on the other side that evolved into the burn-through we saw in the video. reply dotnet00 39 minutes agorootparentprevThey've been concerned about burn through in that area for a while, but they didn't get to test it before now to understand how it'd perform in reality. IIRC they were even calling out that they were surprised that the temperature readings in other parts were in good agreement with the simulations, which is probably indicative of the limited confidence they had for that part. reply amoss 4 hours agorootparentprevPart of the build up said that they had deliberately weakened / thinned some of the tiles in order to test what the tolerance was. It seems that they must have gotten some incredible data about the mode of failure. reply convery 4 hours agorootparentThat was for the base of the ship, so that they could add more sensors. reply liamkinne 4 hours agorootparentprevSurvivorship bias! reply gibolt 4 hours agorootparentHopefully the takeaway is something straightforward, like thicker shielding in one area and not a big redesign of the flaps reply dotnet00 37 minutes agorootparentThey already do have some pretty significant flap redesigns in the pipeline. Slightly smaller and placed slightly farther back from the centerline. reply Maxion 1 hour agorootparentprevThats... not quite survivorship bias. reply neuronexmachina 23 minutes agorootparentYeah, survivorship bias doesn't quite apply if there's real-time telemetry. ;) reply pixl97 5 hours agoprevWhat the hell, half melted starship actually did the landing flip and hit the ocean slow!!! That was amazing! reply themgt 4 hours agoparentThat was seriously some of the most dramatic television I've ever watched. Video of Starship being melted/torn apart by supersonic plasma, the broadcast stream dying multiple times maybe due to ship destruction, then finally back online, peeking through the cracked camera to see the nearly destroyed grid fin STILL ACTUATING. The announcers laughing about the ship being \"maybe held together by some nuts and bolts\" and then it still pulled off the fucking landing burn! Absolutely wild and historic. reply kevstev 3 hours agorootparentI have never rooted for a flap so hard, and likely never will. I am ready to buy flap merch. The energy of the SpaceX employees gave me goosebumps, this was great, it was hard not to get caught up in it- you know this is the culmination of years of hard work that is mostly theoretical until tests like these. reply fifilura 53 minutes agorootparentI think the camera deserves a medal too! reply mrandish 3 hours agorootparentprevYes, Flappy McFlapFin for the win on that flight! reply rtkwe 1 hour agorootparentprevReally wish the camera housing had held up to get a complete video of the fin being eaten away. I wonder if any of the other cameras got good footage too because they stayed on the camera with the obliterated lens for a long time which makes me think the others also fair pretty poorly. There wasn't much to see on the fin cam after the housing broke until right at touch down. reply sebzim4500 1 hour agorootparentI think the only other external camera was on the fin that disintegrated, so I wouldn't have high hopes. They will have had internal cameras pointed at the structure looking for hot spots, and presumably those will have been fine reply avmich 1 hour agorootparentprevI'd really expect SpaceX to have more cameras, and to have some shielding - maybe so that cameras would get open shields at different points in flight, so they'd be protected before that. We only saw left-back flap, I suspect there's a camera looking also on right-back flap, maybe towards the engines section too. SpaceX is known to have rich telemetry, that would be awesome to see. reply cududa 35 minutes agorootparentCan you please explain how exactly you would heat shield a camera? Like, your suggestion is a box attached to the ship that changes its aerodynamic profile, with an actuator that can be a point of failure/ fly off and hit other critical instruments? They have lots of cameras. Were we watching the same video? The thing got absolutely melted and you’re complaining that you didn’t get a front row seat? 5 short years ago we would get a few frames from the camera on the barge where Falcon 9 landed and that seemed incredible. Just because they’ve accomplished something hard (mostly reliable cameras), doesn’t mean it’s suddenly easy and saying “why didn’t you just put more cameras on it?” comes off as mind bendingly pedantic reply rtkwe 1 hour agorootparentprevThey had at least 3 (I think 4 but there were 3 visible at once) different camera's on the upper stage I think they also got destroyed though and the melting fin was the most interesting thing they could show so they just stayed with it. As neat as the idea of different shields is that's a whole extra layer of weight and controls for a non critical thing so I'm not surprised it doesn't happen. reply mavhc 4 hours agorootparentprevYou can tell the ship still exists because the telemetry still updates reply mhandley 4 hours agoparentprevThe fact that it managed the flip and landing burn means the fuel tanks (i.e. most of the fuselage) must have suffered no burn-through, despite what happened to the front flap. They've obviously got some redesign needed on the thermal protection around the flap hinges, but broadly, the thermal protection system and aerodynamic control during reentry seem to have worked well enough. It's finally starting to feel like Starship could actually work! reply tocs3 3 hours agorootparentOne of the NSF commentators commented the fuel for the landing burn comes from the header tanks (little extra tanks for this kind of thing). Still, I would think if one of the closed up sections had a hole that it would cause all sorts of other troubles. reply mhandley 3 hours agorootparentYes, that is correct - they need the header tanks to make sure that fuel is immediately available, not sloshing around the main tanks as the ship flips. Rockets really don't like sucking in vapour. I'm not sure if they're pressurized separately from the main tanks though - I would assume not, as that would be more complicated, but I could be completely wrong. reply notact 3 hours agoparentprevCan someone explain why reentry must be so hellish? The energy gained during the rocket burn into orbit must be bled off during reentry, and that energy is enormous. However, why must reentry occur so quickly? It seems if the descent into the atmosphere was slower, the heat shield would be able to radiate the heat energy away more effectively, thus lowering skin temperatures, and significantly reducing the engineering challenge. reply CarVac 1 hour agorootparentTo get a gentler reentry, you need a greater lift-to-drag ratio. To have a better hypersonic lift-to-drag ratio you need significantly more wing area, which is dead weight (and drag and a control problem) on the way up. reply avhon1 18 minutes agorootparentExactly! Re-entry is the transition from orbital dynamics to aerodynamics. If you want the transition from orbit to flight to occur at a lower speed, then you need to be able to produce lift equal to your weight at that speed, at the altitude where you will hit that speed. reply panick21_ 1 minute agorootparentThat's one of the reason why space planes were preferred for so long. Bleeding of speed while skipping along the atmosphere and then coming in for landing. saratogacx 2 hours agorootparentprevScott Manley has a good video looking at this question and goes into a bit of a dive into the physics and engineering issues involved https://www.youtube.com/watch?v=5kl2mm96Jkk reply dotnet00 31 minutes agorootparentprevYou need to balance peak heating and heating duration. Shallower reentry means lower peak heating, but higher heating duration. Steeper entry means higher peak heating, but lower heating duration. The heat shield material can handle a certain amount of heat and a certain maximum temperature before it starts to ablate away, so you're forced to thread the regime where both variables are within its tolerances. reply garaetjjte 3 hours agorootparentprevIf you are coming at higher speed eg. from the moon, then it's possible to slow down to get reentry equivalent to low earth orbit one. But you can't really slow down much more because you would just plunge into atmosphere at steeper angle. Some vehicles utilize skip reentry trajectories, where it does high altitude pass through atmosphere and then goes in second time: https://en.wikipedia.org/wiki/Non-ballistic_atmospheric_entr... reply jtriangle 1 hour agorootparentprevIf you want to do slow star-trek style landings, you need star-trek level tech. Namely, propulsion tech that doesn't exist. That doesn't mean that it's impossible, just means that it'd require things that don't exist yet. Worth mentioning that, additionally, reentry heating isn't a huge problem, and you're not going to create new propulsion tech to counter it, you're just going to make better heat tiles. What you need new propulsion tech for is doing expanse type stuff, where you can accelerate for months at 1G so you essentially have artificial gravity and can get places extremely fast. If you're into sci-fi, the show/books \"The Expanse\" goes into what that looks like in practice fairly well. reply PaulHoule 53 minutes agorootparentA positive way of framing it is that atmospheric recently is free. If the Earth didn’t have an atmosphere it would take just as big a velocity change to land as it does to get into orbit and getting to be orbit would be as hard as an interplanetary flight. It's worse than it sounds because the rocket equation has a logarithm in it... https://en.wikipedia.org/wiki/Tsiolkovsky_rocket_equation double the Δv means you square the mass ratio. The space shuttle had a mass ratio of about 16, a mass ratio of 256 would be absolutely insane. You get this velocity change at the cost of dealing with the heat and all but a tiny fraction of that heat ends up immediately in the atmosphere. reply bagels 3 hours agorootparentprevIt would take a tremendous amount of fuel to do what you're imagining, probably to the point of making the craft impossible to build with current technology. Your orbit would have to be high enough to do a burn to cancel your orbital velocity (lots of fuel), then you have to burn against gravity for a slow vertical descent (lots of fuel). The rocket equation says... you'll need a larger craft and more fuel to carry the extra fuel in to orbit. It gets pretty out of hand. Instead of using fuel to slow down, spacecraft make a small burn to have the orbit intersect the atmosphere, and then use drag instead of fuel to slow down. reply notact 3 hours agorootparentI'm not sure why people are misunderstanding my question as \"Why not bring more fuel and burn the rockets in reverse\". I am simply asking: why not reenter the atmosphere at a shallower angle, spreading the atmospheric braking friction over a longer period of time, which I'd expect would allow more time for the accumulated heat to radiate away before it becomes catastrophic. reply jaggederest 24 minutes agorootparentWhat makes you think they aren't already taking the shallowest possible descent? Once you start touching the atmosphere, it very quickly becomes deterministic. There are a limited number of descent profiles that actually get you to the ground, and believe it or not, starship as far as I can tell is actually taking a \"shallow angle\" and spreading the atmospheric braking friction over the largest possible time. A steeper entry would melt every conceivable material reply pixl97 2 hours agorootparentprevGravity is one you are still being pulled down. The other is at too shallow of angle at high speed you bounce off like skipping a stone off the surface of a lake. reply mrandish 2 hours agorootparentprevI'm no expert but I think reentering at a shallower angle results in \"bouncing off\" the atmosphere. So, even if you did it multiple times like a rock skipping on water, you'd have to have extra fuel to counter the bounce \"up\" and go back down for each skip. Thus, back to the same \"bring more fuel/weight to orbit\" problem. reply rtkwe 1 hour agorootparentAny heat you see is velocity lost to the craft will eventually hit the atmosphere again. I think the main reason is that the skip and the second reentry is way less predictable than doing the descent in a single pass so for predictability of landing agencies much prefer to do a harder more controlled reentry. reply chasd00 48 minutes agorootparentprevSlowing down from Mach 20-something takes a huge amount of energy in its own right. reply yalue 3 hours agorootparentprevThe velocity of a spacecraft in low earth orbit is over 15,000 miles per hour. Smashing into the atmosphere is perhaps the most fuel- and cost-efficient way to slow down to a speed at which landing is possible. reply 93po 3 hours agorootparentIt doesn't really answer the question though. Why not descend slower so that the 15k MPH isn't meeting so much air? And bleed it off much slower so there is less heat reply avmich 1 hour agorootparentEllipse, circle, parabola, hyperbola - all so called conic sections - are orbital trajectories; when you entering the atmosphere (which means you're technically not on a strictly circular orbit), you're initially following the part of that curve which is closest to the planet. The curve is such that if you don't lose enough speed, you're going to start moving way from the planet. If you're still on parabola (technically you never are, it's infinitely thin case between ellipse and hyperbola, physically not really possible) or hyperbola, you're not comping back - so if you need to get to the planet, you have to be on elliptical trajectory. Even if you're on ellipse, you don't want that ellipse to be too elongated - e.g. the elliptical trajectory from the Earth to the Moon, which is rather close to parabolic one, takes about 4 days one way. You don't want to spend that much time when you're landing, so you need to lose enough of speed in the atmosphere. Which means you need to brake relatively aggressively. This means there's a \"reentry corridor\" - not too steep, not too shallow, and the spacecraft needs to survive the reentry, and going from the Moon is harder than going from LEO because coming from the Moon the spacecraft has higher initial speed entering the atmosphere. It's still possible to balance various approaches, but you can't have (correction: it must be particularly hard to have...) zero fuel use, relatively fast landing (without long ellipses between reentries), speedy planet approach and low heating at the same time. reply verzali 3 hours agorootparentprevIt's hard to do that. What you suggest would mean losing all your orbital speed before you hit the thicker layers of the atmosphere. You could probably do that, but you'd use a lot of fuel to decelerate. And then you are still being accelerated downwards by gravity, so you need something to counter that, which means you need to burn fuel all the way down. All that fuel adds a lot of weight, which cuts down on the amount of useful stuff you can take with you. reply tocs3 3 hours agorootparentprevThey use the atmosphere to help slow the ship down. It takes most of the tank of fuel to get up there and moving so fast. It would take most a tank to slow down. So, they would need about double the fuel plus some for landing. P.S. I have not done any of the math (I might be able to figure it out but it might take a week or two to figure it out). P.S.S : Maybe if they could refuel in space efficiently (asteroid mining?) it might be worth looking at but it will be a while before I would expect anything like that. It would just be the ship. reply notact 3 hours agorootparentI understand the atmosphere is used to slow the vehicle - it's basically free brakes that you don't have to carry with you. I never suggested using rockets in reverse to slow the vehicle down. What I am asking is, instead of effectively standing on the breaks and generating enormous amounts of friction in a short period of time, why can't the vehicle ease onto the breaks and spread the friction out over time so it can be more safely dissipated (via a more shallow reentry angle). reply ta1243 2 hours agorootparentThe shallower the angle the less energy you lose, but you are still losing altitude. At some point you lose enough energy that your speed drops enough that your altitude starts dropping significantly. You can't lose the energy without losing altitude, and once you lose altitude you start losing energy whether you like it or not I think what you are wondering is \"can I stay in the thin atmosphere bleeding X Joules of energy for 50 minutes until most of the energy has gone rather than entering more steeply and bleeding 10X Joules for 5 minutes\" However once you lose energy, you lose your altitude, and as you lose altitude the atmosphere thickens and you start very quickly losing 5X, 10X, 20X joules every minute. reply phkahler 2 hours agorootparentprevSee lift to drag ratio. To get enough lift to maintain altitude you need a certain amount of drag. At those speeds the drag causes the heating while still not producing enough lift to stay up. reply gitfan86 1 hour agorootparentIf you had extremely big light weight wings it would help, but the materials that can do that don't do well when heated up reply bagels 3 hours agorootparentprevThey already use a shallow angle. There's just a lot of energy involved. As soon as the drag kicks in, the angle gets steeper and steeper on its own as the drag slows the craft down. reply notact 2 hours agorootparentI guess this sorta makes sense - the slightest slowdown starts to deorbit the vehicle, at which point a particular descent rate becomes difficult to maintain? reply bagels 3 hours agorootparentprevIts more than double. reply datameta 4 hours agoparentprevAbsolutely beautiful! The hypersonic plasma flow was like no footage I've seen! reply bufferoverflow 1 hour agorootparentTheir older fairing reentry plasma also looked really cool https://www.youtube.com/watch?v=Ke_QI7_UtA8 reply codeulike 4 hours agoparentprevHoly crap, you're right, about 1h45m in the video (about T+1hr04m mission time): camera is nearly out but you can see engines relight and flap moving at Starship goes below 1km altitude. It got through re-entry and did a soft-ish landing! edit: From the telemetry at the bottom of the screen you can also see that it righted itself to vertical just before hitting the water https://x.com/SpaceX/status/1798098040588480826 reply consumer451 4 hours agoparentprevDo we have Navy assets nearby to destroy it, or is it just going to bob around in the Indian ocean? Or will we trigger the abort system now? reply datameta 4 hours agorootparentI believe they said they would trigger the abort on splashdown. reply krunck 1 hour agorootparentI assumed they would try to recover it. So much data could be gathered from the remains. reply georgeecollins 4 hours agorootparentprevGulf of Mexico reply consumer451 4 hours agorootparentThis branch of the thread is about Starship, which landed intact in the Indian Ocean afaik. reply consumer451 2 hours agorootparentI just found the area of the India Ocean via a post from Jonathan McDowell: https://bsky.app/profile/planet4589.bsky.social/post/3kub775... reply openmarmot 4 hours agoparentprevyeah that was absolutely incredible to watch. Starships fin was melting away like the terminator robot in the smelting pot but it still did its job. Absolutely excited about the future of humanity and spaceflight! reply pants2 2 hours agoprevSeeing Live HD video of the outside of the ship on reentry is just incredible. Here's a link to the timestamp: https://youtu.be/8VESowgMbjA?t=35093 reply idontwantthis 1 hour agoparentWow I actually got served the Elon crypto deepfake scam as an ad on that video. reply adolph 1 hour agorootparentElon crypto deepfake scam is the new rick-roll reply idontwantthis 59 minutes agorootparentExcept Google is making money on it too by serving the ads. reply avmich 2 hours agoprevThe 4th Starship test flight was absolutely great test, which really pushed the state of the art - both in general (after all, Starship 2nd stage is 1.5-2 times heavier - when empty - than a Space Shuttle returning from orbit) and specifically for developing the Starship as a robust launch system. Regarding return from orbital (and above) velocities - there was a flight ( https://space.skyrocket.de/doc_sdat/irdt-fregat.htm ) in 2000 when the payload was returning from orbit using inflatable heat shield, which would tolerate much less of heat flow than Starship. The approach was to dissipate a lot of energy in high enough atmosphere, so that while temperature (measure of gas molecules kinetic energy) is high, the heat flow (amount of gas molecules with that kind of high energy to the ship) is low and so heat effects on the ship are also low. Another approach was used e.g. in Zond-6 flight ( https://en.wikipedia.org/wiki/Zond_6 ) when the spacecraft entered the atmosphere, shed some speed and got heated, then ballistically exited the dense atmosphere layers, cooled down a bit, then got into atmosphere again with less speed and so less heat load. The point is we still have some tricks up our sleeve to fight the problems of atmospheric reentry. reply mechhacker 5 hours agoprevThe upper stage re entering was the craziest thing I've seen live. Can't believe it was burning thru the flap and still had a gentle splash down. reply pixl97 4 hours agoparentYea, when I saw the flap melt I had wrote it off and was waiting for the explosion. The explosion never came and I was awestruck. reply szundi 21 minutes agoprevAll enthusiast people, just buy the Kerbal Space Program (1, not the 2), play it through. Then play it without reloading saves. That’s something!! And then, install the RP-1 mod and get blown away. I have 2k hours in this game, worth every of those hours. reply kemotep 5 hours agoprevI am one of the people skeptical about Elon’s specific claims of Starships abilities specifically about his Mars ambitions. Today’s test, if the Starship reentry is as successful as the booster soft landing will be absolutely a great achievement and a 100% mission success. This demonstration keeps SpaceX on schedule for their part of the Artemis 3 mission. Keeping the mission parameters simpler (no “refueuling” or door bay demonstrations as far as I am aware, just orbital insert and reentry) definitely shows they are capable of the basic ideas of how they want Starship to work, especially for Starlink missions. The team should be proud. reply me_me_me 4 hours agoparentAnything Mars is pure BS. Just anything and everything. The one way trip to mars is orders of magnitude more complicated than moon. Keeping people from being riddled with cancer in 6months trip is not trivial. Landing and then what you plan a flag and die? reply basil-rash 6 minutes agorootparentIf it’s a one way trip, the cancer might end up being a blessing. reply thegrim33 4 hours agorootparentprev\"Keeping people from being riddled with cancer in 6months trip is not trivial.\" It's pretty trivial. Put mass in between you and space. It's already been researched to death and we have many years worth of data about the subject. reply _ph_ 4 hours agorootparent> It's already been researched to death Poor choice of words in this context :) reply me_me_me 4 hours agorootparentprev> It's pretty trivial. Put mass in between you and space. Seems like you quite confident. So go on. Expand on that a bit... its trivial after all. You will teleport all that mass to ELO? Or use tracker beam to capture asteroid and space mine it to smelt shielding. I am super curious how you solve it trivially. edit: You downvote but dont explain this trivial solution. Am I asking too much? Calling someone out to explain something is offensive or something? reply somenameforme 40 minutes agorootparentMany basic materials, like water, make great shields if necessary. For Mars one plan is simply to organize the ship such that the water reserves can act as an radiation shield when necessary. You don't need anything particularly massive or overly fancy. reply phkahler 2 hours agorootparentprevWe've had people in space for close to a year, so the trip to Mars shouldn't kill them. Once on mars they'll still need shielding. One option for shelter might be to bore some underground tunnels. A smallish electric tunnel boring machine that could fit in a starship might just be the ticket to building sheltered habitats on Mars. Funny that Elon already has another company that makes these. reply rtkwe 1 hour agorootparentThe ISS is situated safely deep inside the Earth's magnetic sheath which protects you from a lot of high energy radiation though. You can use mass for shielding but you also desperately need that mass for cargo too and most cargo isn't going to be as dense as water which makes good shielding. The ISS has some fancier lightweight shielding but has issues with secondary radiation from particles hitting the metal skin of the modules which we'd expect to see on Starship too but higher since it'd be in interplanetary space instead of nicely close to Earth like the ISS. reply malfist 3 hours agorootparentprevIt's trivial in the sense that telling people trying to lose weight to just eat fewer calories is trivial. Simple idea, hard to execute. reply indoordin0saur 1 hour agorootparentprevRamsar, Iran has similar levels of background radiation as being on the surface of Mars. And people live completely healthy long lives there. Chronic low-level radiation isn't nearly as bad as we once thought. It's acute high-level doses or consuming radioactive substances that you really need to worry about. Mars really won't be bad at all with some easily implemented mitigation measures. reply hackernudes 0 minutes agorootparentThe commenter is talking about the 6 month trip to Mars in space, not on the surface. zpeti 4 hours agorootparentprev> Landing and then what you plan a flag and die? Pretty much, why do you think columbus set off? And he didn't even know if he'd actually find anything. I don't understand your attitude and people like you, human beings have been explorers forever, and seem to value exploring even over survival potentially. I'd say it's pretty obviously evolutionarily coded into us. Maybe not you, but into many people. reply simiones 4 hours agorootparentColumbus very very much didn't plan to die (though he very much would have if he didn't get lucky that there was a whole new continent there). His plan was to land in India, which he thought he would reach around the time he actually reached the new continent, because he had a completely wrong idea of how large the globe actually was (he alone had this wrong idea; the actual circumference of the globe was pretty well understood by this point). In general, human-based space exploration makes 0 sense. We have robots that can do everything a human in a life-support suit can, and don't need to carry 100 times their mass just to not day on the way there and back. Doing a few experiments with humans in space, like we do on the ISS, is indeed worth it for exploring the unknown unknowns of biology. Maybe some day, far in the future after we have explored Mars with many hundreds of robots, it will even make sense to send a human there. But until then, it's just a waste of everything. reply keyringlight 4 hours agorootparentAlso when we see a benefit to humans being on another planet, then spend a few missions before sending the mass of robots, prefab materials and equipment so there's habitats ready or nearly ready so we're not confined to whatever we have on one spaceship reply elsonrodriguez 4 hours agorootparentprevWe will probably perform a human mission and return samples before a robot goes and picks up the Perseverance samples. We’ve been mars-capable since Apollo. It’s a matter of will, which is a political function of cost, which is falling rapidly. reply me_me_me 3 hours agorootparent> We’ve been mars-capable since Apollo. serious citation needed! you cant make shit up. Apollo and saturn5 were nowhere near getting humans to mars. Not even close. It got us to moon with bare minimum. A weekend trip vs 6 months trip. The scale up of needed resources is mind boggling. At every step. I mean pick any step and explain how Apollo could achieve it. reply rtkwe 1 hour agorootparentIf you used multiple Saturn V rockets to launch and dock a multipart craft we could maybe have made it at least to orbit around Mars but landing would be a massively different story. reply _glass 3 hours agorootparentprevYeah, but it's in your text/comment. The logical thing is that it makes 0 sense. Columbus to not take the real circumference makes 0 sense. Let's go to Mars, start a civilization there. It'll be a lot of change for us humans. And only if you live somewhere you can really solve problems. Maybe it's a good plan against a nuclear war, whatever. reply simiones 3 hours agorootparentColumbus was just wrong, he was not motivated by some higher goal. And no, it's not a good plan against a nuclear war, Mars is far far far less hospitable than the Earth would be if we launched all of the nuclear weapons we have today. It's far more radioactive, dusty, cold, toxic, and everything. reply zpeti 4 hours agorootparentprevOk great, you’re definitely right, let’s not do it. What now? Will Elon stop? If Elon doesn’t stop, does that make you right? reply simiones 3 hours agorootparentI'm not saying it's impossible to send people to Mars and even bring them back. I'm saying there is no point whatsoever right now, at least no material or scientific purpose. Of course, building a \"city\" on Mars is well beyond our capabilities, so that will either not be attempted at all, or it will fail. Maybe by 2124, but more likely 2524. reply avmich 42 minutes agorootparent> I'm saying there is no point whatsoever right now, at least no material or scientific purpose. \"No point\" here means \"no reasonable goal\". In this case reasonability is subjective - somebody sees obvious reasons why Mars colony could be useful for humanity, somebody doesn't. Pro arguments are science, learning how to live off another planet, certain insurance against planet-wide cataclysms, general progress in space engineering. There are contra arguments as well, but which are more important is also subjective - we don't have hard data or commonly accepted facts which would solve this arguments one way or another, so, to some, it's natural to investigate the matter further... reply Ajay-p 4 hours agorootparentprevI think it is the indelible human nature, to go the furthest we can because it's there. At first I didn't agree with going to Mars, but if you think of it as the furthest place we know we can land on, and explore, then it makes sense. If we can safely land, and return from Mars, then it makes going even further a possibility. reply throw310822 3 hours agorootparentYes indeed. But still, nobody is building residential neighborhoods on the top of the Everest or in the middle of Antarctica. Exploring for the sake of it is indeed a human instinct. The idea that we should build settlements for people who would live there permanently is plain silly. We have the obsession of repeating the Age of Discovery- but people should get the difference between discovering the Americas, with their wealth of plants, animals, land and waters, and settling a planet where there isn't a sign of life, not even air to breathe. reply rtkwe 1 hour agorootparentprevYou're misremember the actual history of Columbus which makes sense it's been mistaught and mythologized for a very long time. Columbus thought he would reach Asia, both because there were reports from Marco Polo that Asia was much larger than it turned out to be and some mistakes about the size of the Earth. He didn't think he was sailing off into nothingness hoping to find land, he was hoping to find a better trade route to Asia than going around the Horn of Africa or overland. reply me_me_me 4 hours agorootparentprev> Pretty much, why do you think columbus set off? And he didn't even know if he'd actually find anything. hahahah Columbus set of because he wanted money, wealth for the crown. not because he was explorer. Columbus, Vasco Da Gama, Cortez et al were not dreamers but entrepreneurs. >> Landing and then what you plan a flag and die? Nobody (within reasonable definition of nobody) wants to go to Everest to die on top. Nobody wants to dive to Marianas trench to get crush to death. Who would go to Mars without a way back? reply trafficante 3 hours agorootparent>> Who would go to Mars without a way back? For a reasonable chance of being forever immortalized as one of the first humans to step foot on another planet? Granted, I myself will never get the opportunity so it’s easy for me to say “oh hell yes I’d sign up in a heartbeat”. reply mrandish 3 hours agoprevJust watched the recorded live stream and... wow! What a show. Incredible views of a test that appears to have successfully achieved all potential objectives through reentry, rotation maneuver, relight, landing burn and upright water landing in the Indian Ocean. The only unfortunate bit was some debris cracking the camera lens during the last part of reentry so the view for spectators was occluded but SpaceX maintained their live data feed all the way through, which is the important part. As they say, for these tests \"the data is the payload.\" reply salesynerd 2 hours agoparentThe real-time view of the re-entry through the plasma was phenomenal! reply dotnet00 5 hours agoprevThat was breathtaking! Now just hoping we get even more spectacular views of Starship's reentry plasma than last time. Everything about this vehicle screams \"sci-fi future\". DAAAAMN looks like Starship made it! This truly fit their slogan of \"Excitement guaranteed\", that Starship reentry was so thrilling, falling apart, seeing the fins disintegrating, yet at the end they still moved and flipped! reply cletus 5 hours agoprevSo I'm excited to see this tech develop but I wonder how much of a market there really is for super-heavy lifters. I can't wait to see a future version where they land the various stages rather than just dumping them into the sea. The first Falcon Heavy launch was super impressive. SpaceX already has the Falcon Heavy and there have only been a handful of launches, primarily military. I guess the argument is it'll open up new opportunities but will this really replace the Falcon 9 workhorse, which at this point is I believe the most successful launch system in history? Won't someone make a fully reusable smaller launch vehicle that'll suit commercial needs? reply creshal 5 hours agoparentFH had the problem that it had a comparatively small fairing compared with an upper stage that's \"only\" okay-ish for deep space insertions, so you can neither put really huge LEO payloads on it, nor can you give a deep space probe a really big kick stage to make up for the deficits of the upper stage. Starship solves all these issues: The upper stage is more fuel efficient, and it has more room for really big payloads and/or kickstages. > Won't someone make a fully reusable smaller launch vehicle that'll suit commercial needs? Half of the people tried went bankrupt already due to F9: It is already too big for most payloads, so it does a lot of rideshare missions that pool multiple smaller launches together. It's very hard to compete with that. So even if, for some reason, commercial customers don't really want to exploit the capabilites of Starship (ignoring the fact that multiple did already), SpaceX can again offer ride shares at a larger scale for F9-class payloads. reply rtkwe 4 hours agorootparentStarship might honestly have a similar payload issue with the weird door design, the way it hinges up means you need a more complex release plan than most which just pop straight off the front of the booster. During the third test flight they also tested their weird side eject design for Starlink (or other flat pack style satellites) and the video looks like the door completely ripped itself apart. reply creshal 4 hours agorootparentThe door design isn't final yet, there's no point in whining about it. They need tankers and landers for NASA contracts short term (neither of which require payload deployment), anything else is a nice to have that can be tinkered with on the side until it works. reply macintux 4 hours agorootparent> The door design isn't final yet, there's no point in whining about it. Your first clause is correct, the second is unnecessarily hostile. reply creshal 4 hours agorootparentI'm just getting really irritated by the amount of concern trolling surrounding SpaceX. Everything they do \"must\" have a gotcha, because clearly they cannot be as far ahead of the competition as they daily prove to be. reply mrandish 2 hours agorootparentYeah, I agree with you. Healthy skepticism is generally a good thing but now SpaceX has clearly demonstrated an unprecedented ability to solve a large number of insanely difficult problems. At some point, it becomes unreasonable to \"yeah, but...\" less difficult things like cargo doors. reply ordu 40 minutes agorootparent> Healthy skepticism is generally a good thing but now SpaceX has clearly demonstrated an unprecedented ability to solve a large number of insanely difficult problems. I'd add \"again\" into your sentence. They already did it before. Now they proved that they hadn't lost that ability yet. reply rtkwe 3 hours agorootparentprevThe door is a major issue to using super heavy to deliver other payloads which is a goal long term and the need for a heat shield on the bottom makes it hard to make it fully open towards the front. Kind of need to have this fairly well sorted from the beginning because new designs mean new testing and certification which are expensive. reply creshal 3 hours agorootparentNo. That's the whole point of SpaceX's development model, testing done right is absurdly cheap. reply jwells89 4 hours agoparentprevFor one, Starship+Superheavy will enable launching of large objects like space telescopes without forcing object in question to be engineered with expensive, delicate, failure-prone folding mechanisms (like the James Webb Space Telescope was). Just build the thing as big as it needs to be and launch it in its final form (aside from minor folding bits like solar panels). It could have similar impact on other scientific missions like rovers and probes. The ceiling for what’s possible is much higher when you’re not having to question the worth of every gram and square millimeter. reply cletus 2 hours agorootparentSo JWST has (IIRC) a 6.5 meter mirror once deployed and yes, it was a challenge to develop that tech. Plus it added risk of failure. The Starship Super-heavy seems to have a max payload dimension of 9 meters. I imagine some buffer is required (ie it won't just allow a static 9 meter mirror) but I could be wrong. So that's larger but not that much larger. Remember the JWST was a huge step up from Hubble's 2.4 meter mirror. I expect NASA/ESA will take the opportunity to deploy even larger mirror by using the folding tech they've developed. But here's the main point: these kinds of flagship missions don't support and sustain a commercial launch system. There are only so many JWST 2.0s that you can and will build, launch and deploy. Your bread and butter is going to be commercial communications satellites and other than deploying large constellations like Starlink, I'm not sure what the market is here. reply TkTech 5 hours agoparentprevYes, there won't be as many customers purchasing 150-200 tons of lift, but that's the point of \"rideshares\". All that really matters with space launches is the cost per kg and if it's capable of lifting multiple payloads into multiple orbits, it'll have 10-15 customers per lift, not one. The current model has a kind of pez-dispenser but for chucking out multiple payloads. There are purchasers for the full lift capacity too, like ISS modules and major telescopes. reply cletus 4 hours agorootparentIf you think about this, it doesn't make a lot of sense because different satellites are going to sit in very different orbits. Geosynchronous satellites are an obvious case where satellites will collect into a limited number of orbits but they vary on what point of the Earth they sit over. Also getting to geostationary orbit takes a lot more fuel so the rocket has less room for payload than, say, low EArth orbit. I'm not sure one rocket can launch a geostationary satellite above the Americas and above Europe in the same mission. But you can't really launch a satellite in a polar orbit and an equatorial orbit in the same mission, for example. Likewise, how economic is it to deploy one at 150km and another at 250km? Starlink is a special case because it's a related constellation of satellites where a number of satellites are in the same orbit. reply TkTech 4 hours agorootparentThe (unproven) target cost per kg of a re-usable starship, from even the most conservative source I could find, was under $300/kg[2]. The next cheapest, the Falcon Heavy, is around $2.3k/kg[1]. The cost difference is astronomical, and so low that it becomes viable send less payload and more orbital adjustment fuel, not to mention its (again, unproven) designed to be refueled in orbit. At that price, you could fly multiple refueling flights and still be under the cost of any other life provider. [1]: https://en.wikipedia.org/wiki/Falcon_Heavy [2]: https://en.wikipedia.org/wiki/SpaceX_Starship reply krisoft 3 hours agorootparentprev> I'm not sure one rocket can launch a geostationary satellite above the Americas and above Europe in the same mission. It can. Geostationary satellites are a certain distance above the equator. If they adjust their orbit a tiny bit lower than that they start to drift east, if they adjust their orbit a tiny bit higher they start to drift west. This process is called \"repositioning\". Generally there is a tradeoff between how much fuel you spend on it and how fast the repositioning is done. So you can do it quick and then your sat will have less fuel for position keeping. Or you do it \"slow\" and then you preserved more fuel potentially extending the lifetime of your satellite. But these are all done with tiny bits of fuel (compared to the fuel needed to put the satellite up there in the first place) because the delta-v involved is very small. reply Majromax 4 hours agorootparentprev> I'm not sure one rocket can launch a geostationary satellite above the Americas and above Europe in the same mission. Easily. Moving within an orbit is a matter of fine adjustment. For example, any stationkeeping that expands the orbit slightly will cause the satellite to \"fall back\" over time. Geostationary satellites are the best orbit for this, since every satellite in such an orbit essentially shares it with all others, differing only in position along the orbit. reply multimoon 5 hours agoparentprevThere’s lots of things that are just too big and heavy and need launch vehicles like that. It might be overkill for satellites, but space stations and habitats need the payload capacity of something like this to become anything resembling economical. reply seydor 5 hours agorootparenthow many of those things are there? reply throwthrowuknow 4 hours agorootparentA bit like asking how many 30 story buildings are there when we first started building modern steel and concrete buildings. How many cathedrals could we possibly need? reply ceejayoz 4 hours agorootparentprevThis is such an odd argument; it's like asking how many airports there were in 1904. reply avmich 1 hour agorootparentprev> how many of those things are there? Apollo program flew once in 6 months. If we're to build a Moon base, we're going to have at least this frequency of flights - really, I'd prefer to have a great margin on top of that, because Moon is much harder than LEO, and we might need more resiliency to safely explore. Each flight to the Moon will likely need to involve 10-20 Starship flights (rough number) to LEO. So even if we're flying twice a year - and 6 month stay on the Moon right now looks like a pretty serious expedition - we need to have a Starship flight every ~10-15 days. So even for a robust Moon exploration program we need as many Starships per year as the whole world was launching rockets per year just some ~20 years ago. reply vl 46 minutes agorootparentMars launch window is every two years. It is very inefficient to launch at other times. As for moon, I'm surprised with the estimate you have provided. Apollo needed just one launch for each mission. Even if SpaceX will do orbital re-fueling, it's just two-three launches, why would you need more? BTW, the idea of getting heavy Starship to the moon and back is interesting, but at the end flying the vehicle optimized for re-entry far away and back is suboptimal. My prediction that they quickly will go to specialized LEO-LMO vehicles with LEO re-fueling. reply dwaltrip 4 hours agorootparentprevThere'll be a lot more once it is actually possible and economical to put it in space. reply dotnet00 5 hours agorootparentprevWell, most prominently, thousands of Starlink satellites. reply malfist 3 hours agorootparentprevIf you build it, they will come reply nialv7 53 minutes agoparentprev> Won't someone make a fully reusable smaller launch vehicle that'll suit commercial needs? Rocket Lab is doing that. reply qsi 4 hours agoparentprevThe vision is that the cost per unit of mass to orbit will come down massively with Starship, once it's launching like the Falcon. That will open up hitherto unimaginable missions and markets. And customers. It's all about the the cost! reply the8472 4 hours agorootparentIt's not only about cost per kg but also maximum payload mass. If you can build bigger satellites then you don't need to optimize for weight as hard and can use cheaper components/standardize. Which means both launch cost and sat costs will come down. reply _ph_ 3 hours agorootparentOr entirely new capabilities get developed. Look how long it took for the F9 Heavy to get any business because fitting payloads really only got planned and developed after it demonstrated its abilities. With the Starship, there will be single payloads of 100t or more - Elon is even talking about 200t in future versions. That is a total game changer. A station like the ISS could be set up much quicker. You could start designing real spaceships with e.g. ion drives. And a 100t payload might even cost less than currently a single F9 flight. reply simiones 4 hours agorootparentprevLike? What industry really needs things floating in space that are only constrained by cost to launch? I can see lots of science mission perhaps, but even that seems somewhat limited. reply bryanlarsen 1 hour agorootparentTourism is likely the next big market; cost is a major barrier. reply dylan604 3 hours agorootparentprevThere have been tests of producing fiber optic cables (iirc) made in zeroG. There are other things as well that are way too cost prohibitive now, but might become viable opportunities with this type of capability. reply ctoth 1 hour agorootparentprevAsteroid mining. reply tekla 4 hours agorootparentprevInternet reply Ajay-p 4 hours agoparentprevEver seen the incredible classic Moonraker? Larger satellites, larger rockets, it's about more at a lower cost. Bigger trucks, bigger ships, bigger lifters. reply mjh2539 5 hours agoparentprevEventually it will get cheap enough to where people can be buried on the (shot at the) moon. reply simiones 4 hours agorootparentI believe that is illegal in every country, putting human remains on foreign bodies. reply ceejayoz 4 hours agorootparentIt's not, and there've already been (failed) attempts. https://www.axios.com/2024/01/08/peregrine-moon-lander-launc... > In addition to the NASA science experiments on board the Peregrine lander are cremated human remains and DNA collected by two private companies, Celestis and Elysium Space. > People hoping to memorialize their loved ones or colleagues pay the companies thousands to send a few grams of cremated ashes to the moon in metal capsules. reply datameta 4 hours agorootparentprevTalked about this with my partner this week. Somebody is going to yeet their ashes into the regolith some day. reply ceejayoz 4 hours agorootparentIt has already been attempted. https://www.axios.com/2024/01/08/peregrine-moon-lander-launc... reply datameta 1 hour agorootparentAnd indeed has been done too! \"The human remains aboard the lander won't be the first on the moon, as ashes of Gene Shoemaker, the founder of astrogeology, were buried on the moon in the late 1990s by the Lunar Prospector.\" reply mavhc 5 hours agoparentprevHas to be large to be reusable due to scaling factors. We can finally start sending useful amounts of things into space, millions of solar panels for one reply simiones 4 hours agorootparentHow is putting solar in space more useful than putting it on Earth? You still have the problem of a capricious atmosphere between the source of the beams and the place where you need the electricity. Sure, you can slightly modulate and do a few things, but the extra energy is extraordinarily unlikely to make up the extra costs even if the transport costs were 0. reply throwthrowuknow 4 hours agorootparentIt means you can have abundant power in space to run all kinds of hardware. reply simiones 4 hours agorootparentThen what is this hardware that you'd want to run in space, that needs more power than it can generate on its own? reply throwthrowuknow 1 hour agorootparentAnything that will fit in a 30ft diameter faring weighing less than 150 metric tonnes. I’d love to see commercial space stations that can house large numbers of people in comfortable cabins so it’s more like a cruise ship than a submarine. Gotta power all those amenities somehow without diesel generators. But you could also put things like datacenters in orbit if the cost savings on power production made it worth while. Longer term you need a lot of power for resource extraction and processing and manufacturing. Would also make light sail propulsion of probes or deep space missions possible using lasers or beamed microwave power for ion thrusters so you don’t have to sacrifice mass for nuclear and aren’t constrained by how much wattage you can produce on board. reply adolph 32 minutes agorootparentprevBezos predicts data centers in sun synchronous orbit so they always have solar power. The audio is poor but I consider the below video an excellent listen because Bezos outlines his vision of the future which is very different from Musk's. https://youtu.be/Bn0jTLgyjAg?t=1124 reply mavhc 4 hours agorootparentprevWorks 24/7 with 0 atmospheric reduction. You can send the power via microwaves so less interference, problem is the largish ground based capture device. Apparently $200/kg makes it economic, Starship is aiming for more like $2/kg reply lazysheepherd 4 hours agoparentprevPayloads are designed according to available spacecraft capabilities. When this thing flies, market will form around it in no time. reply gravescale 4 hours agorootparentWhy is there's always an Akin's law? > 38. Capabilities drive requirements, regardless of what the systems engineering textbooks say. https://spacecraft.ssl.umd.edu/akins_laws.html reply cletus 4 hours agorootparentprevI'm skeptical because satellites, like pretty much any technology, tend to get smaller over time. I remember reading about how it was profitable for someone to buy up 4 geostationary slots and replace 4 satellites with 1 that was probably smaller than any of the 4 (because geostationary slots can be incredibly valuable). There are large bespoke payloads (eg JWST) but these are inherently so expensive anyway the launch vehicle costs almost don't matter. I'm not yet convinced there's a huge demand for super heavy payloads. reply throwthrowuknow 4 hours agorootparentThey’re expensive (and often delayed and over budget) in part due to the ridiculous demands of fitting everything in a small faring and reducing weight e.g. needing it to fold up and using expensive high strength low weight materials. Lessen those constraints and things get cheaper and easier to build with standard methods and materials. reply Karellen 4 hours agorootparentprev> There are large bespoke payloads (eg JWST) but these are inherently so expensive anyway the launch vehicle costs almost don't matter. If launch costs are going to be $250M, you need a budget of that order of magnitude to make a mission viable. At that point, you might was well spend anywhere from $50M to $1B on the payload because that's where your budget is. Or, to put it another way, only payloads with a $50M to $1B budget can afford to exist if the launch costs are of the order of $250M. However, if launch costs are of the order of $5M, then missions with much smaller budgets suddenly become economically viable. And there are a lot more potential missions out there with $10M budgets than there are missions with $500M budgets. Satellites get smaller not only because the tech gets smaller, but because launch costs/kg are so expensive, or so limited. Currently it's worth spending $10M to reduce your mass by 10%, if doing so means you can reduce your launch costs by $25M. Or, if doing so means you can double your onboard station-keeping fuel, and double the lifespan of the satellite. If launch costs are less and available upmass is higher, your budget for engineering to reduce your payload mass is less, and so is the reason to do so. reply dotnet00 3 hours agorootparentThere are a couple of great examples of this playing out in \"reverse\" with some missions that, at pre-F9 launch costs could only afford to be on a rideshare or small launcher and thus were expecting to have to deal with all sorts of limits, only to end up being able to afford a dedicated F9. There was IXPE, which has been the smallest dedicated payload launched by F9, which otherwise would've had to launch on a much smaller, air-launched pegasus rocket to get to the right inclination. I recall that they were able to simplify some aspects of the satellite deployment due to the roomier vehicle. There was another mission, maybe Psyche? where the original plan would've required the risk of testing a new kind of engine to get to its deep space destination, but being able to get a dedicated ride instead, that risk was eliminated, such that it was going to be able to get there even if the engine tests failed. reply bryanlarsen 4 hours agorootparentprev> in no time Sure, if a decade is \"no time\". 5 years from concept to prototype, another 5 years to operational and then another 5 years to full capacity. Starlink was super quick, but it's design started in 2014. Iterations on existing concepts like telecom or imaging will be quicker, but truly new fields like mining or tourism are at least a decade out before they're using substantial lift capacity. reply tjpnz 4 hours agoparentprevIt will make space tourism viable for people who aren't super wealthy, an influencer or both. reply thanzex 5 hours agoprevSeeing the fin still moving and keeping attitude despite being chewed trough was amazing reply mulmen 4 hours agoparentAs soon as I saw heat on that fin I knew it was over. Then it was… fine? Clearly I’m not a rocket scientist. reply HPsquared 3 hours agorootparentIt was like that on the earlier test launch with the flying concrete and several failed engines. reply nomilk 4 hours agoprevFull video: https://twitter.com/SpaceX/status/1798689697184764071 Various shades of plasma visible during re-entry: Reddish/orange: 1h 26m Blue/purple: 1h 28m White/blue: 1h 34m Yellow: 1h 37m. The forward flap visible in camera view starts melting away around 1h 38m (until basically the end of coverage). (the two stunning minutes from 1h 27m to 1h 29m were the highlight for me) reply okdood64 4 hours agoprevAbsolutely incredible how we were able to see live, on-board video of virtually the complete flight and re-entry with the help of Starlink. reply xnx 4 hours agoprevBig respect to that camera lens cover. The drama of seeing the camera get obscured and then have the cover crack was peak. reply mlindner 3 hours agoparentEveryone said it cracked, but it didn't look like cracking to me. It looked like carbon vapor deposition/metal vapor deposition. reply xnx 3 hours agorootparentThat's how it started, but there was a specific moment where it suddenly cracked. Further deposition and debris may have obscured that crack later. reply mlindner 19 minutes agorootparentYeah on re-watch I saw the moment it cracked, but it didn't really damage the view much as the crack was relatively small. It was only the cover rather than the lens itself. Probably from the flash cooling after how hot it got. reply ironyman 4 hours agoprevSome highlights: Booster splashdown at about T+7:30, Ship engine cutoff at 151 km: https://x.com/NASASpaceflight/status/1798700946983358535 Starship splashdown in Indian Ocean, mostly intact, with landing burn just before splashdown; landing burn: https://x.com/DJSnM/status/1798715665916014715 Full flight profile: https://en.wikipedia.org/wiki/SpaceX_Starship_integrated_fli... reply toephu2 1 hour agoparentHow do they recover the booster? It doesn't sink to the bottom of the sea? reply dave78 1 hour agorootparentThey are not recovering it this time. Once they demonstrate that it can achieve a controlled \"landing\" at sea, then they will move on to trying to land it back at the launch site. reply jantissler 1 hour agorootparentMan, that will be spectacular. reply mhandley 4 hours agoparentprevAlso at T+57:20 or so, watching the front flap start to come apart: https://x.com/SpaceX/status/1798098040588480826 reply wilg 5 hours agoprevThe ocean landing is so cool. I believe they said that the next one they are going to try to land back at the tower? Seems plausible now. reply XorNot 5 hours agoparentI think that might be a second IFT away personally: I imagine they'd like to see no engine relight issues on descent for at least one more mission first, since slamming it into Starbase would be a shame. reply bluescrn 5 hours agorootparentIt does seem like they could do with a more isolated launch site (with the tank farm in a huge concrete bunker) before trying to catch Super Heavy reply rtkwe 4 hours agorootparentThey'd have to build the whole launch complex again which makes me doubt they'd do it. reply rtkwe 2 hours agorootparentYou could however mock one up, either with just a big concrete pad or with a pad and tower, and the booster \"return to launch site\" and prove it can hover in a specific location long enough for the chopsticks to close to get a very low risk approximate test. reply rtkwe 4 hours agorootparentprevThere were definitely some big chunks tossed out during that relight so I'd also be very surprised if they tried it during the next test flight. https://youtu.be/2G-L0u_L0qU?t=2665 reply bpodgursky 5 hours agorootparentprevThey could keep the option open to splash down off the coast if the relight isn't acceptable. Default splash. reply chasd00 5 hours agorootparentprevyeah one out on the way up and on the way down, that has to be very frustrating. It makes my issues with trying to get a stupid website working correctly seem easier hah. reply 155 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SpaceX reported that the Super Heavy rocket has successfully landed in the Gulf of Mexico on June 6, 2024.",
      "This marks a significant milestone for SpaceX, showcasing their ability to recover and reuse their largest rocket booster.",
      "The successful landing is expected to advance SpaceX's goals for cost-effective space travel and further missions to Mars."
    ],
    "commentSummary": [
      "SpaceX's recent technological advancements include the successful splashdown of Super Heavy in the Gulf of Mexico and the anticipation of a new launch facility in central Florida.",
      "The discussion highlights the reliability of Starlink internet during space re-entry, accurate rocket landings, and the resilience of the Starship during reentry, despite some damage.",
      "The conversation covers the economic feasibility of deploying satellites, the importance of large launch vehicles, and future markets like space tourism and zero-gravity manufacturing."
    ],
    "points": 341,
    "commentCount": 406,
    "retryCount": 0,
    "time": 1717678968
  },
  {
    "id": 40595741,
    "title": "From OpenGL to Vulkan: Building a Custom Game Engine in Three Months",
    "originLink": "https://edw.is/learning-vulkan/",
    "originBody": "How I learned Vulkan and wrote a small game engine with it June 5, 2024 Comments (GitHub discussion) tl;dr: I learned some Vulkan and made a game engine with two small game demos in 3 months. The code for the engine and the games can be found here: https://github.com/eliasdaler/edbr Table Of Contents Preface Learning graphics programming Bike-shedding and how to avoid it Why Vulkan? Learning Vulkan Engine overview and frame analysis General advice Recommended Vulkan libraries GfxDevice abstraction Handling shaders Push constants, descriptor sets and bindless descriptors Pipeline pattern Using programmable vertex pulling (PVP) + buffer direct address (BDA) Bindless descriptors Handling dynamic data which needs to be uploaded every frame Destructors, deletion queue and cleanup Synchronization More implementation notes Drawing many sprites Compute skinning Game / renderer separation Scene loading and entity prefabs MSAA UI Dear ImGui and sRGB issues Other stuff What I gained from switching to Vulkan Future work This article documents my experience of learning Vulkan and writing a small game/engine with it. It took me around 3 months to do it without any previous knowledge of Vulkan (I had previous OpenGL experience and some experience with making game engines, though). The engine wasn’t implemented as a general purpose engine, which is probably why it took me a few months (and not years) to achieve this. I started by making a small 3D game and separated reusable parts into the “engine” afterwards. I can recommend everyone to follow the same process to not get stuck in the weeds (see “Bike-shedding” section below for more advice). Preface I’m a professional programmer, but I’m self-taught in graphics programming. I started studying graphics programming around 1.5 years ago by learning OpenGL and writing a 3D engine in it. The engine I wrote in Vulkan is mostly suited for smaller level-based games. I’ll explain things which worked for me, but they might not be the most efficient. My implementation would probably still be a good starting point for many people. Hopefully, this article will help make some things about Vulkan clearer to you. But you also need to be patient. It took me months to implement what I have today and I did it by cutting corners in many places. But if a self-taught programmer like me can build something with Vulkan, then so can you! Learning graphics programming This is a very high level overview of how I learned some graphics programming myself. If there’s interest, I might write another article with more resources and helpful guidelines. If you haven’t done any graphics programming before, you should start with OpenGL. It’s much easier to learn it and not get overwhelmed by all the complexity that Vulkan has. A lot of your OpenGL and graphics programming knowledge will be useful when you start doing things with Vulkan later. Ideally, you should at least get a textured model displayed on the screen with some simple Blinn-Phong lighting. I can also recommend doing some basic shadow mapping too, so that you learn how to render your scene from a different viewpoint and to a different render target, how to sample from depth textures and so on. I can recommend using the following resources to learn OpenGL: https://learnopengl.com/ Anton’s OpenGL 4 Tutorials book Thorsten Thormählen’s lectures lectures (watch the first 6 videos, the rest might be a bit too advanced) Sadly, most OpenGL resources don’t teach the latest OpenGL 4.6 practices. They make writing OpenGL a lot more enjoyable. If you learn them, transitioning to Vulkan will be much easier (I only learned about OpenGL 3.3 during my previous engine development, though, so it’s not a necessity). Here are some resources which teach you the latest OpenGL practices: https://juandiegomontoya.github.io/modern_opengl.html https://github.com/fendevel/Guide-to-Modern-OpenGL-Functions It’s also good to have some math knowledge, especially linear algebra: how to work with vectors, transformation matrices and quaternions. My favorite book about linear algebra/math is 3D Math Primer for Graphics and Game Development by F. Dunn and I. Parbery. You don’t need to read it all in one go - use it as a reference if some math in the OpenGL resources above doesn’t make sense to you. Bike-shedding and how to avoid it https://en.wikipedia.org/wiki/Law_of_triviality Ah, bike-shedding… Basically, it’s a harmful pattern of overthinking and over-engineering even the simplest things. It’s easy to fall into this trap when doing graphics programming (especially when doing Vulkan since you need to make many choices when implementing an engine with it). Always ask yourself “Do I really need this?”, “Will this thing ever become a bottleneck?”. Remember that you can always rewrite any part of your game/engine later. Don’t implement something unless you need it right now. Don’t think “Well, a good engine needs X, right…?”. Don’t try to make a general purpose game engine. It’s probably even better to not think about “the engine” at first and write a simple game. Make a small game first - a Breakout clone, for example. Starting your engine development by doing a Minecraft clone with multiplayer support is probably not a good idea. Be wary of people who tend to suggest complicated solutions to simple problems. Don’t look too much at what other people do. I’ve seen many over-engineered engines on GitHub - sometimes they’re that complex for a good reason (and there are years of work behind them). But you probably don’t need most of that complexity, especially for simpler games. Don’t try to make magical wrappers around Vulkan interfaces prematurely, especially while you’re still learning Vulkan. Get it working first. Leave “TODO”/“FIXME” comments in some places. Then move on to the next thing. Try to fix “TODO”/“FIXME” places only when they really become problematic or bottleneck your performance. You’ll be surprised to see how many things won’t become a problem at all. Why Vulkan? Ask yourself if you need to learn a graphics API at all. If your main goal is to make a game as soon as possible, then you might be better off using something like Godot or Unreal Engine. However, there’s nothing wrong with reinventing the wheel or doing something from scratch. Especially if you do it just for fun, to get into graphics programming or to get an in-depth knowledge about how something works. The situation with graphic APIs in 2024 is somewhat complicated. It all depends on the use case: DirectX seems like the most solid choice for most AAA games. WebGL or WebGPU are the only two choices for doing 3D graphics on the web. Metal is the go-to graphics API on macOS and iOS (though you can still do Vulkan there via MoltenVK). My use case is simple: I want to make small 3D games for desktop platforms (Windows and Linux mostly). I also love open source technology and open standards. So, it was a choice between OpenGL and Vulkan for me. OpenGL is a good enough choice for many small games. But it’s very unlikely that it’ll get new versions in the future (so you can’t use some newest GPU capabilities like ray tracing), it’s deprecated on macOS and its future is uncertain. WebGPU was also a possible choice. Before learning Vulkan, I learned some of it. It’s a pretty solid API, but I had some problems with it: It’s still not stable and there’s not a lot of tutorials and examples for it. This tutorial is fantastic, though. WGSL is an okay shading language, but I just find its syntax not as pleasant as GLSL’s (note that you can write in GLSL and then load compiled SPIR-V on WebGPU native). On desktop, it’s essentially a wrapper around other graphic APIs (DirectX, Vulkan, Metal).This introduces additional problems for me: It can’t do things some things that Vulkan or DirectX can do. It has more limitations than native graphic APIs since it needs to behave similarly between them. RenderDoc captures become confusing as they differ between the platforms (you can get DirectX capture on Windows and Vulkan capture on Linux) and you don’t have 1-to-1 mapping between WebGPU calls and native API calls. Using Dawn and WGPU feels like using bgfx or sokol. You don’t get the same degree of control over the GPU and some of the choices/abstractions might not be the most pleasant for you. No bindless textures (WIP discussion here). No push constants (WIP discussion here). Still, I think that WebGPU is a better API than OpenGL/WebGL and can be more useful to you than Vulkan in some use cases: Validation errors are much better than in OpenGL/WebGL and not having global state helps a lot. It’s also kind of similar to Vulkan in many things, so learning a bit of it before diving into Vulkan also helped me a lot. It requires a lot less boilerplate to get things on the screen (compared to Vulkan). You don’t have to deal with explicit synchronization which makes things much simpler. You can make your games playable inside the browser. Learning Vulkan Learning Vulkan seemed like an impossible thing for me previously. It felt like you needed to have many years of AAA game graphics programming experience to be able to do things in it. You also hear people saying “you’re basically writing a graphics driver when writing in Vulkan” which also made Vulkan sounds like an incredibly complicated thing. I have also checked out some engines written in Vulkan before and was further demotivated by seeing tons of scary abstractions and files named like GPUDevice.cpp or GPUAbstraction.cpp which had thousands of lines of scary C++ code. The situation has changed over the years. Vulkan is not as complicated as it was before. First of all, Khronos realized that some parts of Vulkan were indeed very complex and introduced some newer features which made many things much simpler (for example, dynamic rendering). Secondly, some very useful libraries which reduce boilerplate were implemented. And finally, there are a lot of fantastic resources which make learning Vulkan much easier than it was before. The best Vulkan learning resource which helped me get started was vkguide. If you’re starting from scratch, just go through it all (you might stop at “GPU driver rendering” chapter at first - many simple games probably won’t need this level of complexity) Vulkan Lecture Series by TU Wien also nicely teaches Vulkan basics (you can probably skip “Real-Time Ray Tracing” chapter for now). I especially found a lecture on synchronization very helpful. Here are some more advanced Vulkan books that also helped me: 3D Graphics Rendering Cookbook by Sergey Kosarevsky and Viktor Latypov. There is the second edition in the writing and it’s promising to be better than the first one. The second edition is not released yet, but the source code for it can be found here: https://github.com/PacktPublishing/3D-Graphics-Rendering-Cookbook-Second-Edition Mastering Graphics Programming with Vulkan by Marco Castorina, Gabriel Sassone. Very advanced book which explains some of the “cutting edge” graphics programming concepts (I mostly read it to understand where to go further, but didn’t have time to implement most of it). The source code for it can be found here: https://github.com/PacktPublishing/Mastering-Graphics-Programming-with-Vulkan Here’s the result of my first month of learning Vulkan: By this point I had: glTF model loading Compute skinning Frustum culling Shadow mapping and cascaded shadow maps Of course, doing it for the 3rd time (I had it implemented it all in OpenGL and WebGPU before) certainly helped. Once you get to this point, Vulkan won’t seem as scary anymore. Let’s see how the engine works and some useful things I learned. Engine overview and frame analysis https://github.com/eliasdaler/edbr My engine is called EDBR (Elias Daler’s Bikeshed Engine) and was initially started as a project for learning Vulkan. It quickly grew into a somewhat usable engine which I’m going to use for my further projects. At the time of writing this article, the source code line counts are as follows: Engine itself: 19k lines of code 6.7k LoC related to graphics, 2k LoC are light abstractions around Vulkan 3D cat game: 4.6k LoC 2D platformer game: 1.2k LoC I copy-pasted some non-graphics related stuff from my previous engine (e.g. input handling and audio system) but all of the graphics and many other core systems were rewritten from scratch. I feel like it was a good way to do it instead of trying to cram Vulkan into my old OpenGL abstractions. You can follow the commit history which shows how I started from clearing the screen, drawing the first triangle, drawing a textured quad and so on. It might be easier to understand the engine when it was simpler and smaller. Let’s see how this frame in rendered: Most of the steps will be explained in more detail below. Skinning First, models with skeletal animations are skinned in the compute shader. The compute shader takes unskinned mesh and produces a buffer of vertices which are then used instead of the original mesh in later rendering steps. This allows me to treat static and skinned meshes similarly in shaders and not do skinning repeatedly in different rendering steps. CSM (Cascaded Shadow Mapping) I use a 4096x4096 depth texture with 3 slices for cascaded shadow mapping. The first slice looks like this: Geometry + shading All the models are drawn and shading is calculated using the shadow map and light info. I use a PBR model which is almost identical to the one described in Physically Based Rendering in Filament. The fragment shader is quite big and does calculation for all the lights affecting the drawn mesh in one draw call: Everything is drawn into a multi-sampled texture. Here’s how it looks after resolve: (Open the previous two screenshots in the next tab and flip between the tabs to see the difference more clearly) Depth resolve Depth resolve step is performed manually via a fragment shader. I just go through all the fragments of multi-sample depth texture and write the minimum value into the non-MS depth texture (it’ll be useful in the next step). Post FX Some post FX is applied - right now it’s only depth fog (I use “depth resolve” texture from the previous step here), afterwards tone-mapping and bloom will also be done here. UI Dialogue UI is drawn. Everything is done in one draw call (more is explained in “Drawing many sprites” section) And that’s it! It’s pretty basic right now and would probably become much more complex in the future (see “Future work” section). General advice Recommended Vulkan libraries There are a couple of libraries which greatly improve the experience of writing Vulkan. Most of them are already used in vkguide, but I still want to highlight how helpful they were to me. vk-bootstrap - https://github.com/charles-lunarg/vk-bootstrap vk-bootstrap simplifies a lot of Vulkan boilerplate: physical device selection, swapchain creation and so on. I don’t like big wrappers around graphic APIs because they tend to be very opinionated. Plus, you need to keep a mental map of “wrapper function vs function in the API spec” in your head at all times. Thankfully, vk-bootstrap is not like this. It mostly affects the initialization step of your program and doesn’t attempt to be a wrapper around every Vulkan function. When I was learning Vulkan, I started doing Vulkan from scratch, without using any 3rd party libraries. Replacing big amounts of the initialization code with vk-bootstrap was a joy. It’s really worth it. Vulkan Memory Allocator (VMA) - https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator I’ll be honest, I used VMA without even learning about how to allocate memory in Vulkan manually. I read about it in the Vulkan spec later - I’m glad that I didn’t have to do it on my own. volk Volk was very useful for me for simplifying extension function loading. For example, if you want to use very useful vkSetDebugUtilsObjectNameEXT for setting debug names for your objects (useful for RenderDoc captures and validation errors), you’ll need to do this if you don’t use volk: // store this pointer somewhere PFN_vkSetDebugUtilsObjectNameEXT pfnSetDebugUtilsObjectNameEXT; // during your game init pfnSetDebugUtilsObjectNameEXT = (PFN_vkSetDebugUtilsObjectNameEXT) vkGetInstanceProcAddr(instance, \"vkSetDebugUtilsObjectNameEXT\"); // and finally in your game code pfnSetDebugUtilsObjectNameEXT(device, ...); With volk, all the extensions are immediately loaded after you call volkInitialize and you don’t need to store these pointers everywhere. You just include volk.h and call vkSetDebugUtilsObjectNameEXT - beautiful! GfxDevice abstraction I have a GfxDevice class which encapsulates most of the commonly used functionality and stores many objects that you need for calling Vulkan functions (VkDevice, VkQueue and so on). A single GfxDevice instance is created on the startup and then gets passed around. It handles: Vulkan context initialization. Swapchain creation and management. beginFrame returns a new VkCommandBuffer which is later used in all the drawing steps. endFrame does drawing to the swapchain and does sync between the frames. Image creation and loading textures from files. Buffer creation. Bindless descriptor set management (see “Bindless descriptors” section below). That’s… a lot of things. However, it’s not that big: GfxDevice.cpp is only 714 lines at the time of writing this article. It’s more convenient to pass one object into the function instead of many (VkDevice, VkQueue, VmaAllocator and so on). Handling shaders In Vulkan, you can use any shading language which compiles to SPIR-V - that means that you can use GLSL, HLSL and others. I chose GLSL because I already knew it from my OpenGL experience. You can pre-compile your shaders during the build step or compile them on the fly. I do it during the build so that my shader loading runtime code is simpler. I also don’t have an additional runtime dependency on the shader compiler. Also, shader errors are detected during the build step and I don’t get compile errors during the runtime. I use glslc (from shaderc project, it’s included in Vulkan SDK) which allows you to specify a DEPFILE in CMake which is incredibly useful when you use shader includes. If you change a shader file, all files which include it are recompiled automatically. Without the DEPFILE, CMake won’t be able to see which files shader files need to be recompiled and will only recompile the file which was changed. My CMake script for building shaders looks like this: function (target_shaders target shaders) set(SHADERS_BUILD_DIR \"${CMAKE_CURRENT_BINARY_DIR}/shaders\") file(MAKE_DIRECTORY \"${SHADERS_BUILD_DIR}\") foreach (SHADER_PATH ${SHADERS}) get_filename_component(SHADER_FILENAME \"${SHADER_PATH}\" NAME) set(SHADER_SPIRV_PATH \"${SHADERS_BUILD_DIR}/${SHADER_FILENAME}.spv\") set(DEPFILE \"${SHADER_SPIRV_PATH}.d\") add_custom_command( COMMENT \"Building ${SHADER_FILENAME}\" OUTPUT \"${SHADER_SPIRV_PATH}\" COMMAND ${GLSLC} \"${SHADER_PATH}\" -o \"${SHADER_SPIRV_PATH}\" -MD -MF ${DEPFILE} -g DEPENDS \"${SHADER_PATH}\" DEPFILE \"${DEPFILE}\" ) list(APPEND SPIRV_BINARY_FILES ${SHADER_SPIRV_PATH}) endforeach() set(shaders_target_name \"${target}_build_shaders\") add_custom_target(${shaders_target_name} DEPENDS ${SPIRV_BINARY_FILES} ) add_dependencies(${target} ${shaders_target_name}) endfunction() and then in the main CMakeLists file: set(SHADERS skybox.frag skinning.comp ... // etc ) # prepend shaders directory path get_target_property(EDBR_SOURCE_DIR edbr SOURCE_DIR) set(EDBR_SHADERS_DIR \"${EDBR_SOURCE_DIR}/src/shaders/\") list(TRANSFORM SHADERS PREPEND \"${EDBR_SHADERS_DIR}\") target_shaders(game ${SHADERS}) Now, when you build a game target, shaders get built automatically and the resulting SPIR-V files are put into the binary directory. Push constants, descriptor sets and bindless descriptors Passing data to shaders in OpenGL is much simpler than it is in Vulkan. In OpenGL, you could just do this: In shader: uniform float someFloat; In C++ code: const auto loc = glGetUniformLocation(shader, \"someFloat\"); glUseProgram(shader); glUniform1f(loc, 42.f); You can also use explicit uniform location like this. In shader: layout(location = 20) uniform float someFloat; In code: const auto loc = 20; glUniform1f(loc, 42.f); In Vulkan, you need to group your uniforms into “descriptor sets”: // set 0 layout (set = 0, binding = 0) uniform float someFloat; layout (set = 0, binding = 1) uniform mat4 someMatrix; // set 1 layout (set = 1, binding = 0) uniform float someOtherFloat; ... // etc. Now, this makes things a lot more complicated, because you need to specify descriptor set layout beforehand, use descriptor set pools and allocate descriptor sets with them, do the whole VkWriteDescriptorSet + vkUpdateDescriptorSets thing, call vkCmdBindDescriptorSets for each descriptor set and so on. I’ll explain later how I avoided using descriptor sets by using bindless descriptors and buffer direct access. Basically, I only have one “global” descriptor set for bindless textures and samplers, and that’s it. Everything else is passed via push constants which makes everything much easier to handle. Pipeline pattern I separate drawing steps into “pipeline” classes. Most of them look like this: class PostFXPipeline { public: void init(GfxDevice& gfxDevice, VkFormat drawImageFormat); void cleanup(VkDevice device); void draw( VkCommandBuffer cmd, GfxDevice& gfxDevice, const GPUImage& drawImage, const GPUImage& depthImage, const GPUBuffer& sceneDataBuffer); private: VkPipelineLayout pipelineLayout; VkPipeline pipeline; struct PushConstants { VkDeviceAddress sceneDataBuffer; std::uint32_t drawImageId; std::uint32_t depthImageId; }; }; init loads needed shaders and initializes pipeline and pipelineLayout: void PostFXPipeline::init(GfxDevice& gfxDevice, VkFormat drawImageFormat) { const auto& device = gfxDevice.getDevice(); const auto pcRange = VkPushConstantRange{ .stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT, .offset = 0, .size = sizeof(PushConstants), }; const auto layouts = std::array{gfxDevice.getBindlessDescSetLayout()}; const auto pushConstantRanges = std::array{pcRange}; pipelineLayout = vkutil::createPipelineLayout(device, layouts, pushConstantRanges); const auto vertexShader = vkutil::loadShaderModule(\"shaders/fullscreen_triangle.vert.spv\", device); const auto fragShader = vkutil::loadShaderModule(\"shaders/postfx.frag.spv\", device); pipeline = PipelineBuilder{pipelineLayout} .setShaders(vertexShader, fragShader) .setInputTopology(VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST) .setPolygonMode(VK_POLYGON_MODE_FILL) .disableCulling() .setMultisamplingNone() .disableBlending() .setColorAttachmentFormat(drawImageFormat) .disableDepthTest() .build(device); vkutil::addDebugLabel(device, pipeline, \"postFX pipeline\"); vkDestroyShaderModule(device, vertexShader, nullptr); vkDestroyShaderModule(device, fragShader, nullptr); } The init function is usually called once during the engine initialization. PipelineBuilder abstraction is described in vkguide here. I modified it a bit to use the Builder pattern to be able to chain the calls. cleanup does all the needed cleanup. It usually simply destroys the pipeline and its layout: void PostFXPipeline::cleanup(VkDevice device) { vkDestroyPipeline(device, pipeline, nullptr); vkDestroyPipelineLayout(device, pipelineLayout, nullptr); } draw is called each frame and all the needed inputs are passed as arguments. It’s assumed that the sync is performed outside of the draw call (see “Synchronization” section below). Some pipelines are only called once per frame - some either take std::vector of objects to draw or are called like this: for (const auto& mesh : meshes) { somePipeline.draw(cmd, gfxDevice, mesh, ...); } The typical draw function looks like this: void PostFXPipeline::draw( VkCommandBuffer cmd, GfxDevice& gfxDevice, const GPUImage& drawImage, const GPUImage& depthImage, const GPUBuffer& sceneDataBuffer) { // Bind the pipeline vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline); // Bind the bindless descriptor set gfxDevice.bindBindlessDescSet(cmd, pipelineLayout); // Handle push constants const auto pcs = PushConstants{ // BDA - explained below .sceneDataBuffer = sceneDataBuffer.address, // bindless texture ids - no need for desc. sets! // explained below .drawImageId = drawImage.getBindlessId(), .depthImageId = depthImage.getBindlessId(), }; vkCmdPushConstants( cmd, pipelineLayout, VK_SHADER_STAGE_FRAGMENT_BIT, 0, sizeof(PushConstants), &pcs); // Finally, do some drawing. Here we're drawing a fullscreen triangle // to do a full-screen effect. vkCmdDraw(cmd, 3, 1, 0, 0); } Note another thing: it’s assumed that draw is called between vkCmdBeginRendering and vkCmdEndRendering - the render pass itself doesn’t care what texture it renders to - the caller of draw is responsible for that. It makes things simpler and allows you to do several draws to the same render target, e.g.: // handy wrapper for creating VkRenderingInfo const auto renderInfo = vkutil::createRenderingInfo({ .renderExtent = drawImage.getExtent2D(), .colorImageView = drawImage.imageView, .colorImageClearValue = glm::vec4{0.f, 0.f, 0.f, 1.f}, .depthImageView = depthImage.imageView, .depthImageClearValue = 0.f, // for MSAA .resolveImageView = resolveImage.imageView, }); vkCmdBeginRendering(cmd, &renderInfo.renderingInfo); // draw meshes for (const auto& mesh : meshesToDraw) { meshPipeline.draw(cmd, gfxDevice, mesh, ...); } // draw sky skyboxPipeline.draw(cmd, gfxDevice, camera); vkCmdEndRendering(cmd); I use VK_KHR_dynamic_rendering everywhere. I don’t use Vulkan render passes and subpasses at all. I’ve heard that they’re more efficient on tile-based GPUs, but I don’t care about mobile support for now. VK_KHR_dynamic_rendering just makes everything much easier. Using programmable vertex pulling (PVP) + buffer direct address (BDA) I have one vertex type for all the meshes. It looks like this: struct Vertex { vec3 position; float uv_x; vec3 normal; float uv_y; vec4 tangent; }; Of course, you can greatly optimize it using various methods, but it’s good enough for me for now. The uv_x/uv_y separation comes from vkguide - I think it’s a nice idea to get good alignment and not waste any bytes The vertices are accessed in the shader like this: layout (buffer_reference, std430) readonly buffer VertexBuffer { Vertex vertices[]; }; layout (push_constant, scalar) uniform constants { VertexBuffer vertexBuffer; ... // other stuff } pcs; void main() { Vertex v = pcs.vertexBuffer.vertices[gl_VertexIndex]; ... } PVP frees you from having to define vertex format (no more VAOs like in OpenGL or VkVertexInputBindingDescription + VkVertexInputAttributeDescription in Vulkan). BDA also frees you from having to bind a buffer to a descriptor set - you just pass an address to your buffer which contains vertices in push constants and that’s it. Also note the scalar layout for push constants. I use it for all the buffers too. Compared to “std430” layout, it makes alignment a lot more easy to handle - it almost works the same as in C++ and greatly reduces the need for “padding” members in C++ structs. Bindless descriptors Textures were painful to work with even in OpenGL - you had “texture slots” which were awkward to work with. You couldn’t just sample any texture from the shader if it wasn’t bound to a texture slot beforehand. ARB_bindless_texture changed that and made many things easier. Vulkan doesn’t have the exact same functionality, but it has something similar. You can create big descriptor sets which look like this: // bindless.glsl layout (set = 0, binding = 0) uniform texture2D textures[]; ... layout (set = 0, binding = 1) uniform sampler samplers[]; You’ll need to maintain a list of all your textures using some “image manager” and when a new texture is loaded, you need to insert it into the textures array. The index at which you inserted it becomes a bindless “texture id” which then can be used to sample it in shaders. Now you can pass these ids in your push constants like this: layout (push_constant, scalar) uniform constants { uint textureId; ... } pcs; and then you can sample your texture in the fragment shader like this: // bindless.glsl #define NEAREST_SAMPLER_ID 0 ... vec4 sampleTexture2DNearest(uint texID, vec2 uv) { return texture(nonuniformEXT(sampler2D(textures[texID], samplers[NEAREST_SAMPLER_ID])), uv); } // shader.frag vec4 color = sampleTexture2DNearest(pcs.textureId, inUV); Two things to note: I chose separate image samplers so that I could sample any texture using different samplers. Common samplers (nearest, linear with anisotropy, depth texture samplers) are created and put into samplers array on the startup. The wrapper function makes the process of sampling a lot more convenient. The placement of nonuniformEXT is somewhat tricky and is explained very well here. I use bindless ids for the mesh material buffer which looks like this: struct MaterialData { vec4 baseColor; vec4 metallicRoughnessEmissive; uint diffuseTex; uint normalTex; uint metallicRoughnessTex; uint emissiveTex; }; layout (buffer_reference, std430) readonly buffer MaterialsBuffer { MaterialData data[]; } materialsBuffer; Now I can only pass material ID in my push constants and then sample texture like this in the fragment shader: MaterialData material = materials[pcs.materialID]; vec4 diffuse = sampleTexture2DLinear(material.diffuseTex, inUV); ... Neat! No more bulky descriptor sets, just one int per material in the push constants. You can also put different texture types into the same set like this (this is needed for being able to access textures of types other than texture2D): layout (set = 0, binding = 0) uniform texture2D textures[]; layout (set = 0, binding = 0) uniform texture2DMS texturesMS[]; layout (set = 0, binding = 0) uniform textureCube textureCubes[]; layout (set = 0, binding = 0) uniform texture2DArray textureArrays[]; And here’s how you can sample textureCube with a linear sampler (note that we use textureCubes here instead of textures): vec4 sampleTextureCubeLinear(uint texID, vec3 p) { return texture(nonuniformEXT(samplerCube(textureCubes[texID], samplers[NEAREST_SAMPLER_ID])), p); } Here’s a very good article on using bindless textures in Vulkan: https://jorenjoestar.github.io/post/vulkan_bindless_texture/ Handling dynamic data which needs to be uploaded every frame I find it useful to pre-allocate big arrays of things and push stuff to them in every frame. Basically, you can pre-allocate an array of N structs (or matrices) and then start at index 0 at each new frame and push things to it from the CPU. Then, you can access all these items in your shaders. For example, I have all joint matrices stored in one big mat4 array and the skinning compute shader accesses joint matrices of a particular mesh using start index passed via push constants (more about it will be explained later). Here are two ways of doing this: Have N buffers on GPU and swap between them. vkguide explains the concept of “in flight” frames pretty well. To handle this parallelism properly, you need to have one buffer for the “currently drawing” frame and one buffer for “currently recording new drawing commands” frame to not have races. (If you have more frames in flight, you’ll need to allocate more than 2 buffers) This means that you need to preallocate 2 buffers on GPU. You write data from CPU to GPU to the first buffer during the first frame. While you record the second frame, GPU reads from the first buffer while you write new data to the second buffer. On the third frame, GPU reads from the second buffer and you write new info to the first buffer… and so on. One buffer on GPU and N “staging” buffers on CPU This might be useful if you need to conserve some memory on the GPU. Let’s see how it works in my engine: class NBuffer { public: void init( GfxDevice& gfxDevice, VkBufferUsageFlags usage, std::size_t dataSize, std::size_t numFramesInFlight, const char* label); void cleanup(GfxDevice& gfxDevice); void uploadNewData( VkCommandBuffer cmd, std::size_t frameIndex, void* newData, std::size_t dataSize, std::size_t offset = 0); const GPUBuffer& getBuffer() const { return gpuBuffer; } private: std::size_t framesInFlight{0}; std::size_t gpuBufferSize{0}; std::vector stagingBuffers; GPUBuffer gpuBuffer; bool initialized{false}; }; void NBuffer::init( GfxDevice& gfxDevice, VkBufferUsageFlags usage, std::size_t dataSize, std::size_t numFramesInFlight, const char* label) { ... gpuBuffer = gfxDevice.createBuffer( dataSize, usageVK_IMAGE_USAGE_TRANSFER_DST_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE); vkutil::addDebugLabel(gfxDevice.getDevice(), gpuBuffer.buffer, label); for (std::size_t i = 0; i (staging.info.pMappedData); memcpy((void*)&mappedData[offset], newData, dataSize); const auto region = VkBufferCopy2{ .sType = VK_STRUCTURE_TYPE_BUFFER_COPY_2, .srcOffset = (VkDeviceSize)offset, .dstOffset = (VkDeviceSize)offset, .size = dataSize, }; const auto bufCopyInfo = VkCopyBufferInfo2{ .sType = VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2, .srcBuffer = staging.buffer, .dstBuffer = gpuBuffer.buffer, .regionCount = 1, .pRegions = &region, }; vkCmdCopyBuffer2(cmd, &bufCopyInfo); // sync with write ... // WRITE BARRIER CODE HERE } I’d go with the first approach for most cases (more data on GPU, but no need for manual sync) unless you need to conserve GPU memory for some reason. I’ve found no noticeable difference in performance between two approaches, but it might matter if you are uploading huge amounts of data to GPU on each frame. Destructors, deletion queue and cleanup Now, this might be somewhat controversial… but I didn’t find much use of the deletion queue pattern used in vkguide. I don’t really need to allocated/destroy new objects on every frame. Using C++ destructors for Vulkan object cleanup is not very convenient either. You need to wrap everything in custom classes, add move constructors and move operator=… It adds an additional layer of complexity. In most cases, the cleanup of Vulkan objects happens in one place - and you don’t want to accidentally destroy some in-use object mid-frame by accidentally destroying some wrapper object. It’s also harder to manage lifetimes when you have cleanup in happening in the destructor. For example, suppose you have a case like this: struct SomeClass { SomeOtherClass b; void init() { ... } void cleanup() { ... } } If you want to cleanup SomeOtherClass resources (e.g. the instance of SomeOtherClass has a VkPipeline object) during SomeClass::cleanup, you can’t do that if the cleanup of SomeOtherClass is performed in its destructor. Of course, you can do this: struct SomeClass { std::unique_ptr b; void init() { b = std::make_unique(); ... } void cleanup() { b.reset(); ... } } … but I don’t like how it introduces a dynamic allocation and requires you to do write more code (and it’s not that much different from calling a cleanup function manually). Right now, I prefer to clean up stuff directly, e.g. class SkyboxPipeline { public: void cleanup(VkDevice device) { vkDestroyPipeline(device, pipeline, nullptr); vkDestroyPipelineLayout(device, pipelineLayout, nullptr); } private: VkPipelineLayout pipelineLayout; VkPipeline pipeline; ... } // in GameRenderer.cpp: void GameRenderer::cleanup(VkDevice device) { ... skyboxPipeline.cleanup(device); ... } This approach is not perfect - first of all, it’s easy to forget to call cleanup function, This is not a huge problem since you get a validation error in case you forget to cleanup some Vulkan resources on shutdown: Validation Error: [ VUID-vkDestroyDevice-device-05137 ] Object 0: handle = 0x4256c1000000005d, type = VK_OBJECT_TYPE_PIPELINE_LAYOUT;MessageID = 0x4872eaa0vkCreateDevice(): OBJ ERROR : For VkDevice 0x27bd530[], VkPipelineLayout 0x4256c1000000005d[] has not been destroyed. The Vulkan spec states: All child objects created on device must have been destroyed prior to destroying device (https://vulkan.lunarg.com/doc/view/1.3.280.1/linux/1.3-extensions/vkspec.html#VUID-vkDestroyDevice-device-05137) VMA also triggers asserts if you forget to free some buffer/image allocated with it. I find it convenient to have all the Vulkan cleanup happening explicitly in one place. It makes it easy to track when the objects get destroyed. Synchronization Synchronization in Vulkan is difficult. OpenGL and WebGPU do it for you - if you read from some texture/buffer, you know that it will have the correct data and you won’t get problems with data races. With Vulkan, you need to be explicit and this is usually where things tend to get complicated. Right now I manage most of the complexities of sync manually in one place. I separate my drawing into “passes”/pipelines (as described above) and then insert barriers between them. For example, the skinning pass writes new vertex data into GPU memory. Shadow mapping pass reads this data to render skinned meshes into the shadow map. Sync in my code looks like this: // do skinning in compute shader for (const auto& mesh : skinnedMeshes) { skinningPass.doSkinning(gfxDevice, mesh); } { // Sync skinning with CSM // This is a \"fat\" barrier and you can potentially optimize it // by specifying all the buffers that the next pass will read from const auto memoryBarrier = VkMemoryBarrier2{ .sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2, .srcStageMask = VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT, .srcAccessMask = VK_ACCESS_2_SHADER_WRITE_BIT, .dstStageMask = VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT, .dstAccessMask = VK_ACCESS_2_MEMORY_READ_BIT, }; const auto dependencyInfo = VkDependencyInfo{ .sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO, .memoryBarrierCount = 1, .pMemoryBarriers = &memoryBarrier, }; vkCmdPipelineBarrier2(cmd, &dependencyInfo); } // do shadow mapping shadowMappingPass.draw(gfxDevice, ...); Of course, this can be automated/simplified using render graphs. This is something that I might implement in the future. Right now I’m okay with doing manual sync. vkconfig’s “synchronization” validation layer also helps greatly in finding sync errors. The following resources were useful for understanding synchronization: https://themaister.net/blog/2019/08/14/yet-another-blog-explaining-vulkan-synchronization/ https://github.com/KhronosGroup/Vulkan-Docs/wiki/Synchronization-Examples Vulkan Lecture Series Ep. 7 on Vulkan Sync by TU Wien More implementation notes Drawing many sprites With bindless textures, it’s easy to draw many sprites using one draw call without having to allocate vertex buffers at all. First of all, you can emit vertex coordinates and UVs using gl_VertexIndex in your vertex shader like this: void main() { uint b = 1spriteDrawCommands; I create two fixed size buffers on the GPU and then upload the contents of spriteDrawCommands (using techniques described above in the “Handling dynamic data” section). The sprite renderer is used like this: // record commands renderer.beginDrawing(); { renderer.drawSprite(sprite, pos); renderer.drawText(font, \"Hello\"); renderer.drawRect(...); } renderer.endDrawing(); // do actual drawing later: renderer.draw(cmd, gfxDevice, ...); The same renderer also draws text, rectangles and lines in my engine. For example, the text is just N “draw sprite” commands for a string composed of N glyphs. Solid color rectangles and lines are achieved by using a 1x1 pixel white texture and multiplying it by SpriteCommand::color in the fragment shader. And finally, here’s how the command to do the drawing looks like inside SpriteRenderer::draw: vkCmdDraw(cmd, 6, spriteDrawCommands.size(), 0, 0); // 6 vertices per instance, spriteDrawCommands.size() instances in total The complete sprite.vert looks like this: #version 460 #extension GL_GOOGLE_include_directive : require #extension GL_EXT_buffer_reference : require #include \"sprite_commands.glsl\" layout (push_constant) uniform constants { mat4 viewProj; // 2D camera matrix SpriteDrawBuffer drawBuffer; // where sprite draw commands are stored } pcs; layout (location = 0) out vec2 outUV; layout (location = 1) out vec4 outColor; layout (location = 2) flat out uint textureID; layout (location = 3) flat out uint shaderID; void main() { uint b = 1 = pcs.numVertices) { return; } SkinningDataType sd = pcs.skinningData.data[index]; mat4 skinMatrix = sd.weights.x * getJointMatrix(sd.jointIds.x) + sd.weights.y * getJointMatrix(sd.jointIds.y) + sd.weights.z * getJointMatrix(sd.jointIds.z) + sd.weights.w * getJointMatrix(sd.jointIds.w); Vertex v = pcs.inputBuffer.vertices[index]; v.position = vec3(skinMatrix * vec4(v.position, 1.0)); pcs.outputBuffer.vertices[index] = v; } I store all joint matrices in a big array and populate it every frame (and also pass the starting index in the array for each skinned mesh, jointMatricesStartIndex). Skinning data is not stored inside each mesh vertex, a separate buffer of num_vertices elements is used. After the skinning is performed, all the later rendering stages use this set of vertices Thee rendering process for static and skinned meshes becomes identical, thanks to that. Anton’s OpenGL 4 Tutorials book has the best skinning implementation guide I’ve ever read. Game Engine Architecture by Jason Gregory has nice explanations about skinning/skeletal animation math as well. Game / renderer separation I have a game/renderer separation which uses a simple concept of “draw commands”. In the game logic, I use entt, but the renderer doesn’t know anything about entities or “game objects”. It only knows about the lights, some scene parameters (like fog, which skybox texture to use etc) and meshes it needs to draw. The renderer’s API looks like this in action: void Game::generateDrawList() { renderer.beginDrawing(); // Add lights const auto lights = ...; // get list of all active lights for (const auto&& [e, tc, lc] : lights.each()) { renderer.addLight(lc.light, tc.transform); } // Render static meshes const auto staticMeshes = ...; // list of entities with static meshes for (const auto&& [e, tc, mc] : staticMeshes.each()) { // Each \"mesh\" can have multiple submeshes similar to how // glTF separates each \"mesh\" into \"primitives\". for (std::size_t i = 0; iwhich are then iterated through during the drawing process. The MeshDrawCommand looks like this: struct SkinnedMesh { GPUBuffer skinnedVertexBuffer; }; struct MeshDrawCommand { MeshId meshId; glm::mat4 transformMatrix; math::Sphere worldBoundingSphere; const SkinnedMesh* skinnedMesh{nullptr}; std::uint32_t jointMatricesStartIndex; bool castShadow{true}; }; meshId is used for looking up static meshes in MeshCache - it’s a simple std::vector of references to vertex buffers on GPU. If the mesh has a skeleton, jointMatricesStartIndex is used during compute skinning and skinnedMesh->skinnedVertexBuffer is used for all the rendering afterwards (instead of meshId) worldBoundingSphere is used for frustum culling. This separation is nice because the renderer is clearly separated from the game logic. You can also do something more clever as described here if sorting draw commands becomes a bottleneck. Scene loading and entity prefabs I use Blender as a level editor and export it as glTF. It’s easy to place objects, colliders and lights there. Here’s how it looks like: Writing your own level editor would probably take months (years!), so using Blender instead saved me quite a lot of time. It’s important to mention how I use node names for spawning some objects. For example, you can see an object named Interact.Sphere.Diary selected in the screenshot above. The part part before the first dot is the prefab name (in this case “Interact”). The “Sphere” part is used by the physics system to create a sphere physics body for the object (“Capsule” and “Box” can also be used, otherwise the physics shape is created using mesh vertices). Some models are pretty complex and I don’t want to place them directly into the level glTF file as it’ll greatly increase each level’s size. I just place an “Empty->Arrows” object and name it something like “Cat.NearStore”. This will spawn “Cat” prefab and attach “NearStore” tag to it for runtime identification. Prefabs are written in JSON and look like this: { \"scene\": { \"scene\": \"assets/models/cato.gltf\" }, \"movement\": { \"maxSpeed\": [4, 4, 4] }, \"physics\": { \"type\": \"dynamic\", \"bodyType\": \"virtual_character\", \"bodyParams\": { ... } } } During the level loading process, if the node doesn’t have a corresponding prefab, it’s loaded as-is and its mesh data is taken from the glTF file itself (this is mostly used for static geometry). If the node has a corresponding prefab loaded, it’s created instead. Its mesh data is loaded from the external glTF file - only transform is copied from the original glTF node (the one in the level glTF file). Once glTFX is released and the support for it is added to Blender, things might be even easier to handle as you’ll be able to reference external glTF files with it. MSAA Using forward rendering allowed me to easily implement MSAA. Here’s a comparison of how the game looks without AA and with MSAA on: No AA MSAA x8 MSAA is explained well here: https://vulkan-tutorial.com/Multisampling Here’s another good article about MSAA: https://therealmjp.github.io/posts/msaa-overview/ and potential problems you can have with it (especially with HDR and tone-mapping). UI My UI system was inspired by Roblox’s UI API: https://create.roblox.com/docs/ui Basically, the UI can calculate its own layout without me having to hard code each individual element’s size and position. Basically it relies on the following concepts: Origin is an anchor around which the UI element is positioned. If origin is (0, 0), setting UI element’s position to be (x,y) will make its upper-left pixel have (x,y) pixel coordinate. If the origin is (1, 1), then the element’s bottom-right corner will be positioned at (x, y). If the origin is (0.5, 1) then it will be positioned using bottom-center point as the reference. Relative size makes the children’s be proportional to parent’s size. If (1,1) then the child element will have the same size as the parent element. If it’s (0.5, 0.5) then it’ll have half the size of the parent. If the parent uses children’s size as a guide, then if a child has (0.5, 0.25) relative size, the parent’s width will be 2x larger and the height will be 4x larger. Relative position uses parent’s size as a guide for positioning. It’s useful for centering elements, for example if you have an element with (0.5, 0.5) origin and (0.5, 0.5) relative position, it’ll be centered inside its parent element. You can also set pixel offsets for both position and size separately (they’re called offsetPosition and offsetSize in my codebase). You can also set a fixed size for the elements if you don’t want them to ever be resized. The label/image element size is determined using its content. Here are some examples of how it can be used to position child elements: a) The child (yellow) has relative size (0.5, 1), relative position of (0.5, 0.5) and origin (0.5, 0). It’s parent (green) will be two times wider, but will have the same height. The child element will be centered inside the parent. b) The child (yellow) has origin (1, 1), fixed size (w,h) and absolute offset of (x,y) - this way, the item can be positioned relative to the bottom-right corner of its parent (green) Let’s see how sizes and positions of UI elements are calculated (implementation in EDBR). First, sizes of all elements are calculated recursively. Then positions are computed based on the previously computed sizes and specified offset positions. Afterwards all elements are drawn recursively - parent element first, then its children etc. When calculating the size, most elements either have a “fixed” size (which you can set manually, e.g. you can set some button to always be 60x60 pixels) or their size is computed based on their content. For example, for label elements, their size is computed using the text’s bounding box. For image elements, their size equals the image size and so on. If an element has an “Auto-size” property, it needs to specify which child will be used to calculate its size. For example, the menu nine-slice can have several text labels inside the “vertical layout” element - the bounding boxes will be calculated first, then their sizes will be summed up - then, the parent’s size is calculated. Let’s take a look at a simple menu with bounding boxes displayed: Here, root NineSliceElement is marked as “Auto-size”. To compute its size, it first computes the size of its child (ListLayoutElement). This recursively computes the sizes of each button, sums them up and adds some padding (ListLayoutElement also makes the width of each button the same based on the maximum width in the list). Dear ImGui and sRGB issues I love Dear ImGui. I used it to implement many useful dev and debug tools (open the image in a new tab to see them better): It has some problems with sRGB, though. I won’t explain it in detail, but basically if you use sRGB framebuffer, Dear ImGui will look wrong in many ways, see the comparison: Left - naive sRGB fix for Dear ImGui, right - proper fix Left - naive sRGB fix for Dear ImGui, right - proper fix Sometimes you can see people doing hacks by doing pow(col, vec4(2.2)) with Dear ImGui’s colors but it still doesn’t work properly with alpha and produces incorrect color pickers. I ended up writing my own Dear ImGui backend and implementing DilligentEngine’s workaround which is explained in detail here and here. Writing it wasn’t as hard as I expected. I only need to write the rendering part, while “logic/OS interaction” part (input event processing, clipboard etc.) is still handled by default Dear ImGui SDL backend in my case. There are some additional benefits of having my own backend: It supports bindless texture ids, so I can draw images by simply calling ImGui::Image(bindlessTextureId, ...). Dear ImGui’s Vulkan backend requires you to “register” textures by calling ImGui_ImplVulkan_AddTexture for each texture before you can call ImGui::Image. It can properly draw linear and non-linear images by passing their format into backend (so that sRGB images are not gamma corrected twice when they’re displayed) Initializing and dealing with it is easier as it does Vulkan things in the same way as the rest of my engine. Other stuff There are many parts of the engine not covered there because they’re not related to Vulkan. I still feel like it’s good to mention them briefly for the sake of completion. I use Jolt Physics for physics. Integrating it into the engine was pretty easy. Right now I mostly use it for collision resolution and basic character movement. The samples are fantastic. The docs are very good too. I especially want to point out how incredible JPH::CharacterVirtual is. It handles basic character movement so well. I remember spending days trying to get proper slope movement in Bullet to work. With Jolt, it just worked “out of the box”. Here’s how it basically works (explaining how it works properly would probably require me to write quite a big article): You add your shapes to Jolt’s world. You run the simulation. You get new positions of your physics objects and use these positions to render objects in their current positions. I implemented Jolt physics shape debug renderer using im3d I use entt for the entity-component-system part. It has worked great for me so far. Previously I had my own ECS implementation, but decided to experiment with a 3rd party ECS library to have less code to maintain. I use openal-soft, libogg and libvorbis for audio. The audio system is mostly based on these articles: https://indiegamedev.net/2020/02/15/the-complete-guide-to-openal-with-c-part-1-playing-a-sound/ I use Tracy for profiling. Integrating it was very easy (read the PDF doc, it’s fantastic!) and it helped me avoid tons of bike-shedding by seeing how little time something, which I thought was “inefficient”, really took. What I gained from switching to Vulkan There are many nice things I got after switching to Vulkan: No more global state This makes abstractions a lot easier. With OpenGL abstractions/engines, you frequently see “shader.bind()” calls, state trackers, magic RAII, which automatically binds/unbinds objects and so on. There’s no need for that in Vulkan - it’s easy to write functions which take some objects as an input and produce some output - stateless, more explicit and easier to reason about. API is more pleasant to work with overall - I didn’t like “binding” things and the whole “global state machine” of OpenGL. You need to write less abstractions overall. With OpenGL, you need to write a lot of abstractions to make it all less error-prone… Vulkan’s API requires a lot less of this, in my experience. And usually the abstractions that you write map closer to Vulkan’s “raw” functions, compared to OpenGL abstractions which hide manipulation of global state and usually call several functions (and might do some stateful things for optimization). Better validation errors Validation errors are very good in Vulkan. While OpenGL has glDebugMessageCallback, it doesn’t catch that many issues and you’re left wondering why your texture looks weird, why your lighting is broken and so on. Vulkan has more extensive validation which makes the debugging process much better. Debugging in RenderDoc I can now debug shaders in RenderDoc. It looks like this: With OpenGL I had to output the values to some texture and color-pick them… which took a lot of time. But now I can debug vertex and fragment shaders easily. More consistent experience across different GPUs and OSes. With OpenGL, drivers on different GPUs and OSes worked differently from each other which made some bugs pop up only on certain hardware configurations. It made the process of debugging them hard. I still experienced some slight differences between different GPUs in Vulkan, but it’s much less prevalent compared to OpenGL. Ability to use better shading languages in the future GLSL is a fine shading language, but there are some new shading languages which promise to be more feature-complete, convenient and readable, for example: https://github.com/shader-slang/slang https://github.com/shady-gang/shady I might explore them in the future and see if they offer me something that GLSL lacks. More control over every aspect of the graphics pipeline. Second system effect, but good My first OpenGL engine was written during the process of learning graphics programming from scratch. Many abstractions were not that good and rewriting them with some graphics programming knowledge (and some help from vkguide) helped me implement a much cleaner system. Street cred And finally, it makes me proud to be able to say “I have a custom engine written in Vulkan and it works”. Sometimes people start thinking about you as a coding wizard and it makes me happy and proud of my work. :) Future work There are many things that I plan to do in the future, here’s a list of some of them: Sign-distance field font support (good article about implementing them) Loading many images and generating mipmaps in parallel (or use image formats which already have mipmaps stored inside of them) Bloom. Volumetric fog. Animation blending. Render graphs. Ambient occlusion. Finishing the game? (hopefully…) Overall, I’m quite satisfied with what I managed to accomplish. Learning Vulkan was quite difficult, but it wasn’t as hard as I imagined. It taught me a lot about graphics programming and modern APIs and now I have a strong foundation to build my games with.",
    "commentLink": "https://news.ycombinator.com/item?id=40595741",
    "commentBody": "I learned Vulkan and wrote a small game engine with it (edw.is)271 points by eliasdaler 7 hours agohidepastfavorite92 comments spicyusername 4 hours agoLots of good advice in this article. One that stuck out to me: Don’t implement something unless you need it right now This is a constant battle I fight with more junior programmers, who maybe have a few years of experience, but who are still getting there. They are often obsessed with \"best-practices\" and whatever fancy new tool is trending, but they have trouble starting with the problem they need to solve and focusing on the minimum needed to just solve that problem. reply proc0 24 minutes agoparentThis is in context of a one person team. The next advice makes this evident: > Remember that you can always rewrite any part of your game/engine later. This isn't the case in medium to large organizations. Usually you will just move on and rarely have the time to revisit something. This is unfortunate of course, but it means you need to build things properly the first time around and make sure it won't have a chance to create bugs or side effects. I have worked in too many codebases were people feel the need to rush new features, and then it creates a minefield of a codebase where you have to manually check every feature and have the entire application in context when changing something small. reply jshowa 13 minutes agorootparentI agree with this. In a large organization, if you have risen to a level where you are being relied upon at a regular intervals, it is imperative that you have a well architected solution that you can readily change and this is where you separate your program from spaghetti code to something useful. Sure, its nice to write unmaintainable junk when toying around, but I to have seen too many codebases where people were just throwing features in without thought and it causes the program to become way too constrained to only a specific problem domain and it becomes inflexible for solving new problems (to the point you have to re-write nearly everything from scratch). reply Hendrikto 4 hours agoparentprev> They are often obsessed with \"best-practices\" Tell them YAGNI is also a best practice :D reply fuzztester 2 hours agorootparentYes. So is KISS. https://en.m.wikipedia.org/wiki/KISS_principle reply xedrac 2 hours agoparentprevYes, over engineering solutions is a constant thorn in my side. The end result is you get a lot of additional complexity for basically no benefit. In my experience, if new requirements do come down the pipeline at some later time, the generic solution you previously built will be completely inadequate and will need to be redone anyway. Solve the problem in front of you, not some unknown future problem. reply vlovich123 1 hour agoparentprev> Don’t implement something unless you need it right now Useful advice to start with. It’s a rule that experts are allowed to break though. reply pxtail 2 hours agoparentprev>starting with the problem they need to solve and focusing on the minimum needed to just solve that problem To be fair if held strictly to these principles their work would revolve mostly around gluing together various Apis, services and sometimes adjusting already written software to company's needs. So I'm not surprised they are using every possible opportunity to write something here and there, this menial digital plumber's work takes its toll and one needs to try to squeeze in something a bit more enjoyable from time to time just to keep sanity in place a bit longer reply SR2Z 44 minutes agorootparentYeah, I am no longer a junior engineer. When I WAS the bane of my existence was senior and staff engineers hoarding all the fun, new work for themselves and forcing me into \"bitch work\" where I'm just cleaning up old, broken code and handling bugs. I finally got promoted because I explicitly ignored my manager to deploy changes that were needed for my company, and that was what finally got me promoted. Of course, at that point, I had been looking for a new job and just left instead of taking the shitty, bottom-of-band promo increase. It's awful for promotion chances, and it forced me to quit. reply Narhem 4 hours agoparentprevDefinitely agree. But there’s a fine line between implementing things but the difficulty being understanding long term vision and making sure short term improvements don’t actively work against the ‘ideal’. Kind of hard for newer programmers to get a good sense of system design. reply junon 4 hours agoparentprevYep. I attribute YAGNI to a lot of my quickest prototypes and some of my best code. reply jay-barronville 1 hour agoparentprev> [Junior programmers] are often obsessed with \"best-practices\" and whatever fancy new tool is trending, but they have trouble starting with the problem they need to solve and focusing on the minimum needed to just solve that problem. I’ve observed/experienced the same exact thing [0]. I think it’s due to a combo of (1) not knowing what “the right way” to do things are and (2) thinking it’ll make your peers perceive you as more knowledgeable or advanced if they see you writing “best practices” code. Not to mention that sometimes the simpler solutions are so simple, they make you feel like you’re not a real software engineer. I usually just do my best to help them understand that simple solutions are okay, especially since (1) I’ve been there myself when I was in their shoes and (2) I know they have good intentions. [0]: https://news.ycombinator.com/item?id=40527071 reply Animats 25 minutes agoprevThis minimalism is very effective. I took the opposite approach, and it has cause great pain. I've been writing a metaverse client in Rust. Right now, it's running on another screen, showing an avatar riding a tram through a large steampunk city. I let that run for 12 hours before shipping a new pre-release. This uses Vulkan, but it has WGPU and Rend3 on top. Rend3 offers a very clean API - you create meshes, 2d textures, etc., and \"objects\", which reference the meshes and textures. Creating an object puts it on screen. Rust reference counting interlocks everything. It's very straightforward to use. All those layers create problems. WGPU tries to support web browsers, Vulkan, Metal, DX11 (recently dropped), DX12, Android, and OpenGL. So it needs a big dev team and changes are hard. WGPU's own API is mostly like Vulkan - you still have to do your own GPU memory allocation and synchronization. WGPU has lowest-common-denominator problems. Some of those platforms can't support some functions. WGPU doesn't support multiple threads updating GPU memory without interference, which Vulkan supports. That's how you get content into the GPU without killing the frame rate. Big-world games and clients need that. Also, having to deal with platforms with different concurrency restrictions results in lock conflicts that can kill performance. Rend3 is supposed to be a modest level of glue code to handle synchronization and allocation. Those are hard to do in a general way. Especially synchronization. Rend3 also does frustum culling (which is a big performance win; you're not rendering what's behind you) and tried to do occlusion culling (which was a performance lose because the compute to do that slowed things down). It also does translucency, which means a depth sort. (Translucent objects are a huge pain. I really need them; I work on worlds with lots of windows, which you can see out of and see in.) The Rust 3D stack people are annoyed with me because I've been pounding on them to fix their stack for three years now. That's all volunteer. Vulkan has money behind it and enough users to keep it maintained. Rend3 was recently abandoned by its creator, so now I have to go inside that and fix it. Few people do anything elaborate on WGPU - mostly it's 2D games you could have done in Flash, or simple static 3D scenes. Commercial projects continue to use Unity or UE5. If I went directly to Vulkan, I'd still have to write synchronization, allocation, frustrum culling, and translucency. So that's a big switch. Incidentally, Vulkano, the wrapper over Vulkan and Metal, has lowest-common-denominator problems too. It doesn't allow concurrent updating of assets in the GPU. Both Vulkan and Metal support that. But, of course, Apple does it differently. reply wudangmonk 2 hours agoprevIts great to have more Vulkan resources but unfortunately this one too suffers from the same problem as every other resource I've found on getting something on the screen with Vulkan. They all introduce another layer of abstraction on top of Vulkan even before giving you the simple case without it. Its always use vk-bootstrap, volk, vma or someother library. Is there a single resource anywhere that gives an example of doing the memory management manually because I havent found one, it seems like its either use vma or go figure out the spec are the only choices you are given. Is it too much to ask to just get the most basic example without having to add any libraries other than the Vulkan sdk itself?. reply harrison_clarke 2 hours agoparentthere's a common gamedev practice of allocating a big chunk of memory up front, and then using a bump allocator inside of it in most games, there are about 3 \"lifetimes\": - permanent/startup - per-level - per-frame and they're nested. so, you can use a single stack allocator for all of them. at the end of the frame/level, pop back to where it started there are more complicated patterns, but this one will get you pretty far. you can use it on the CPU and the GPU reply andrewmcwatters 22 minutes agoparentprevYes. It's too much to ask. Even the \"official\" examples by documentation do not do it. Reading the Vulkan specifications is an exercise in practicing technical bullshit. When you're corroborating some random person's third-party instructions on initializing Vulkan and comparing those notes to what's done in Khronos Group repositories and reading the Vulkan 1.3 spec and realizing you have to read the specification out-of-order to get anything done, it's clear that they failed. They failed. It's bad work by any other standard. But you'll do the work once and forget about it for the most part, so professionals don't complain too much. Read my other comment in this thread for a portion of source code annotated with the specification chapters and sections. It's a generic implementation that can be used with SDL and others. Edit: As of the time of writing, the standard approach is to use VMA and Volk, both of which are included with the official Vulkan SDK. That should tell you enough about the state of the art. reply jokoon 4 hours agoprevI think vulkan is great, but its only purpose is to take full advantage of advanced GPU features. It also leads to better performance when using advanced GPU features compared to OpenGL. Generally, I feel OpenGL is the recommended route if you don't really aim for advanced rendering techniques. There are plenty 2D /lowpoly/ps1-graphics games right now, and those don't need to use vulkan. Vulkan is an example of how the AAA gaming industry is skewed towards rendering quality and appearance. AAA game studios justify their budget with those very advanced engines and content, but there is a growing market of 2D/low poly game, because players are tired and realized they want gameplay, not graphics. Also if you are a game developer, you don't want to focus on rendering quality, you want to focus on gameplay and features. reply alexvitkov 4 hours agoparentVulkan has advantages over OpenGL even if you don't care about visual fidelity. - No global state - You can select which GPU you want to use at runtime - OpenGL error handling is terrible - Validation layers!! - Cool official artwork - Fantastic documentation - You can upload data to the GPU asynchronously from a second thread in a sane way - Fancy GPU features - Mesh shaders, RTX reply hjadal 3 hours agorootparentI will say that validation layers alone are worth it. Damn they are nice, so many bugs in my code has been found by them which saved a lot of time. reply rrradical 52 minutes agorootparentI switched from opengl b/c I was tired of staring at a black screen with no debugging information (sure...glGetError) when I tried to implement a non-trivial feature. After tons of work to learn vulkan and getting it up and running, I still think it was worth it. reply ChadNauseam 4 hours agoparentprevA middle ground is webgpu. It is much less verbose than Vulkan and is guaranteed to run anywhere, including the browser. At the same time, it has access to \"modern\" features like compute shaders which would not be available in webgl. It also doesn't have much legacy cruft leading to multiple ways of doing the same thing, unlike opengl. The main advantage is that it's new, so there are many fewer tutorials available for it, and that is a very serious disadvantage. reply hgs3 1 hour agorootparentNot to downplay it or anything, but I'm curious why webgpu is receiving so much attention? There have been many low-level cross-platform graphics abstractions over the years. The bgfx [1] project had its first commit ~12 years ago and it's still going! It's much more mature than webgpu. I'm guessing being W3C backed is what's propelling it? [1] https://github.com/bkaradzic/bgfx reply solardev 4 hours agorootparentprevI thought its browser support was pretty bad? https://caniuse.com/webgpu Firefox and Safari don't support it yet. And how would you even deploy it to Steam (edit: or rather, make a desktop or mobile game with it)? Can you wrap it in a webview? Doesn't seem mature... reply bla3 3 hours agorootparentThere is a native API too, not just JS. You can link it into your game like any other library. reply solardev 3 hours agorootparentI'm confused now. I thought by definition it's a browser API that allows them to make Vulkan/OpenGL/DirectX calls, like an abstraction layer. Am I wrong? Edit: wgpu is a reimplementation of the WebGPU api for use with desktop apps outside of browsers. See sibling thread by another poster for an explanation: https://news.ycombinator.com/item?id=40598416 reply MindSpunk 3 hours agorootparentwgpu isn’t a reimplementation of WebGPU, it’s Firefox’s WebGPU implementation. It also conveniently runs outside of a browser and is accessible with a Rust or C API. You can also do the same thing with Dawn, which is Chrome’s implementation of WebGPU. reply solardev 3 hours agorootparentThanks for the correction! reply alexvitkov 4 hours agorootparentprevIt's a JavaScript API, it only runs in the browser. It's not real. reply ncallaway 4 hours agorootparentThat's just not true. https://wgpu.rs/ I'm literally writing native code running on linux with winit and wgpu right now. reply solardev 3 hours agorootparentWait, is that the same as using WebGPU? It says outside of browsers it uses opengl and vulkan and directx. reply ncallaway 3 hours agorootparentYea, wgpu is basically an adapting layer between the WebGPU API and opengl, vulkan, directx. So it's the same† API. But WebGPU in the browser is also an adapting layer between those technologies, it's just the browser that does the adapting instead of the wgpu library. For Firefox, WebGPU is adapted to those underlying systems by wgpu: https://github.com/gpuweb/gpuweb/wiki/Implementation-Status † There are some \"native-only\" extensions beyond the WebGPU spec that gpu provides, so it does go a little beyond WebGPU. But for the most part, it's very similar. reply solardev 3 hours agorootparentWait... so if webgpu (the API) is to allow browsers to use the underlying graphics libs... but desktop apps can access those directly... why would they want to go through the browser abstraction API instead? Better dev ex and ergonomics? reply ncallaway 3 hours agorootparent> why would they want to go through the browser abstraction API instead? Better dev ex and ergonomics? That and portability. The ergonomics are always up for debate, but I find it a much more modern and nicer interface than OpenGL which feels...quite dated. How it compares to something like Vulkan or Metal is up for debate. But for portability if I write my code using directx, then I can only run it on systems with directx. If I write it for vulkan, I can only target systems with vulkan. If I write for metal, I can only target systems with metal. However, if I use wgpu and the WebGPU API, I can target any system that has directx or vulkan or metal or OpenGL. I can also target wasm and compile my application for the web. So, I can really easily write code that will run natively on linux, on osx, on windows and the web and will use the graphics library native to that platform. reply solardev 3 hours agorootparentI see now. Thanks for explaining! That makes a lot of sense. reply alexvitkov 3 hours agorootparentprevwgpu is not WebGPU. One is a Web specification, the other is a Rust library. wgpu is also not a graphics API, it's a library that abstracts the underlying graphics API. reply solardev 3 hours agorootparentEven more confused now, lol. (edit: thanks for editing your post. the revised version clears it up!) reply alexvitkov 2 hours agorootparentVulkan, Direct3D, Metal and OpenGL are graphics APIs - the implementation comes with your GPU driver, and they're as close as you can reasonably get to writing code \"directly for the GPU\". When you call a Vulkan function you're directly calling driver code. wgpu is a regular library that uses the native APIs above and abstracts them from you. I don't like calling it a graphics API because it implies it's the same as the vendor-provided APIs - it's a completely different beast. WebGPU and WebGL are Web standards that the browser implements, and you program them via JS. Similarly to wgpu, they're implemented on top of the native graphics APIs. The relationship between wgpu and WebGPU is that they're basically made by the same people, and in Firefox WebGPU is implemented on top of wgpu. But saying \"WebGPU runs everywhere\" is plain wrong - it's a browser-exclusive API, and on top of that, at the point of writing this it doesn't even run on all browsers (71% support according to https://caniuse.com/webgpu) reply MajimasEyepatch 4 hours agoparentprev> Vulkan is an example of how the AAA gaming industry is skewed towards rendering quality and appearance. AAA game studios justify their budget with those very advanced engines and content, but there is a growing market of 2D/low poly game, because players are tired and realized they want gameplay, not graphics. I think the driver here is more likely the financial reality of game development. High-fidelity graphics are incredibly expensive, and small game studios simply cannot produce them on a realistic timeline and budget. Would consumers reject indie games with AAA-quality graphics? I think not. It's just that few such games exist because it's not financially viable, and there is a large enough market that is fine with more stylized, lower-fidelity graphics. reply samuellavoie90 4 hours agoparentprevIt's not just about performance, I think one of the reasons for moving away from OpenGL is that the High level functions are inconsistent across driver implementations/GPUs. Whats the point of an abstraction layer if you keep having to write GPU/driver specific code. Its better to have a low level driver and a high level library instead. reply GuB-42 4 hours agoparentprevThe general idea is that if you care more about gameplay and features, use an existing engine, the engine itself takes advantage of Vulkan, or whatever backend is the most appropriate, so you don't have to. OpenGL is kind of a middle ground. That's if you want to get technical, but not micromanage every detail and write pages of boilerplate. It is also a great introduction to graphics programming. More than an introduction actually, there is a lot you can do with OpenGL. reply Keyframe 2 hours agoparentprevI think Vulkan was a mistake. Maybe I should say OpenGL Next should've been a (priority) thing and Vulkan could still happen on the side.. and not this, push towards everything Vulkan. It's not for everybody and not everybody needs it (nor deserves it). reply cogman10 2 hours agorootparentI don't think it's a mistake, I think it's targeted and leveraged poorly. Vulkan is a great idea for a general game engine or backing something like OpenGL. It's a low-level abstraction that should allow you to do something like use OpenGL 8.0 on a GPU that has long lost support for from its manufacturer. reply Const-me 3 hours agoparentprevAnother good option is Direct3D 11. It’s IMO even easier to use than OpenGL but still allows to implement pretty good visuals, see GTA 5 or Baldur’s Gate 3. reply mort96 3 hours agorootparentEh that's really only an option if you want to only ever target Microsoft platforms. Which is fine for some people, sure, but in a lot of situations, closing the door on Linux (Steam Deck), macOS, iOS, Android and the non-xbox consoles is a tough sell. reply MindSpunk 2 hours agorootparentLinux you can get for “free” with DXVK or VKD3D-proton. MacOS is an even more niche platform than Linux as far as gaming is concerned and is not a tough sell to skip considering the total lack of market share in games. iOS and Android generally come in a pair so unless you’re only targeting one you need to support multiple APIs anyway. Xbox requires Xbox specific APIs so you need explicit work there. Every other console uses a bespoke API that will require another backend in your engine (yes Switch technically supports Vulkan but that is not the recommended path from Nintendo, you will likely end up with an NVN backend). D3D11 gives you both desktop platforms that matter for games, everything else will require multiple backends anyway so if you only care about desktop it’s a fair choice. reply debugnik 2 hours agorootparentprevSince DXVK exists and Apple dropped OpenGL, the latter gains you access to Android and that's about it, unless you're ok with ES 3.0 contexts and a lackluster set of extensions (ANGLE on Metal). AFAIK the non-Xbox consoles either don't support OpenGL or we reportedly don't want to use their implementations. reply samiv 4 hours agoprevThis might come off as a surprise to some people but getting good performance with Vulkan (compared to say OpenGL) isn't trivial because: the Vulkan driver is missing that ~20k loc of code that OpenGL driver does for you to set up the rendering pipelines, render targets etc. This is all code that already exists in the OpenGL driver and has been optimized for +20 years by the best people in the industry. So when you start putting together the equivalent functionality that you get out of the box with OpenGL on top of Vulkan doing it the naive way doesn't magically give you good perf, but you gotta put in some more work and then the real problems start stacking up such as making sure that you have all right fences etc synchronization primitives in place and so forth. So only when you actually know what you're doing and you're capable of executing your rendering with good parallelism and correct synchronization can you start dreaming about the performance benefits of using Vulkan. So for a hobbyist like myself.. I'm using OpenGL ES3 for the simplicity of it and because it's already good enough for me and I have more pressing things to matter than spend time writing those pesky Vulkan vertex descriptor descriptor descriptors ;-) Btw this is my engine: https://github.com/ensisoft/detonator reply harrison_clarke 3 hours agoparentthe biggest part for me is the shader compiler. opengl has one built in, vulkan requires me to pull in yet another dependency i've heard that vulkan allows bindless textures now, so the descriptor nonsense is a bit less awful that it used to be vulkan is appealing, but there's a high initial cost that i don't want to pay reply sigmoid10 3 hours agorootparentVulkan is super appealing if you're in the industry and have the time and resources necessary to profit from its advantages. But if you're a single dev who wants to learn game engine design, you're going to have a bad time. Most people also don't get that game engine design is very far removed from actual game design. You can have a ton of fun learning math, physics and computer science when building an engine, but beware that you'll likely be mentally and physically exhausted long before you actually get to build a fun game. reply kiririn 2 hours agorootparentprevAlso in the case of glslang there are enough references to GPL to (probably erroneously) strike fear into legal departments reply OnionBlender 3 hours agoparentprevI've heard the same thing about DirectX 12 vs DirectX 11. One book basically said that you will probably have worse performance in DirectX 12 vs DirectX 11 if you don't know what you're doing. reply sigmoid10 3 hours agorootparentDirectX 12 only gets interesting when you want hardware raytracing support to make use of the new Nvidia cards on windows. Tbf that is pretty cool, which is why I actually dabbled with it a little. But it's not necessary for the vast, vast majority of graphics applications. reply fire_lake 3 hours agoparentprevCould someone write an OpenGL to Vulkan layer as a library so that we can target Vulkan but at a higher level of abstraction? Then gradually we can replace that library with routines optimised for the use case? reply cluoma 3 hours agorootparentThere is the Zink project[1]. It is an OGL to Vulkan translation layer. [1]https://docs.mesa3d.org/drivers/zink.html reply sehugg 3 hours agorootparentprevANGLE is the (certified compliant) OpenGL ES -> Vulkan/Metal/Direct3D/etc translation layer used by your friendly neighborhood web browser. There are docs about how the Vulkan translation layer works: https://chromium.googlesource.com/angle/angle/+/HEAD/src/lib... reply edu 5 hours agoprevThe site seems hugged to death, cached: https://web.archive.org/web/20240606103630/https://edw.is/le... reply eliasdaler 5 hours agoparentThank you! Also, everything explained in the article is pretty much here: https://github.com/eliasdaler/edbr reply OnionBlender 3 hours agoprevI've been trying to learn Vulkan on and off for years (I used to know OpenGL ES 2&3 pretty well). One thing I found difficult is understanding how to use things in a real engine rather than a sample. A lot of samples will allocate exactly what they need or allocate hundreds of something so that they're unlikely to run out. When I was trying to learn DirectX, I found Microsoft's MiniEngine helpful because it wasn't overly complex but had things like a DescriptorAllocator that would manage allocating descriptors. Is there something similar for Vulkan? Another thing I struggle with is knowing how to create good abstractions like materials, meshes, and how to decide in what order to render things. Are there any good engines or frameworks I should study in order to move beyond tutorials? reply gmueckl 2 hours agoparentVulkan is quite similar DirectX 12. Done concepts transfer directly. For memory allocation, you can use a library called vma to assst you. It takes care of a few stupid edge cases that the Standard accunulated over the years and is quite powerful. For descriptor set allocation, there is only one pattern that nakes sense to me: expect the pools to be rather short lived and expect to have many of them. Allocate a new one once allocation from the current one fails - don't keep your own counters for alocated descriptors. The standard allows for all kinds of pool behaviors that deviate from strict counting. Discard old pools after the the last command buffer referencing that pool is finished. Pipeline barriers and image layouts are a big pain in the butt. It makes sense to abstract them away in a layer that tracks last usage and lat Format for everything and adds barriers as required. It can get complex, but ot's worthbitnonce you have optional passen or passes that can get reordered or other more complex things going on. About neshes, materials, rendering order: this goes beyond what I can summarize in a single HN post. This depends a lot on the choice of rendering algorithms and I do not consider a very generalized solution to be worth the (enormous) effortto get this right. reply cmovq 2 hours agoparentprevTake a look at a real engine, something like vkquake is a good reference [1]. [1]: https://github.com/Novum/vkQuake reply rossant 4 hours agoprevGreat writeup! I learned Vulkan myself so that I could write a scientific data visualization engine (https://datoviz.org/ still quite experimental, will release a newer version soon). I had some knowledge of OpenGL before and learning Vulkan was SO hard. The learning resources weren't that great 5 years ago. I took up the challenge and it was so much fun. It took me months to understand the role of the various dozens of abstractions. In the process I wrote a small wrapper around Vulkan (https://datoviz.org/api/vklite/) to make it a bit less painful to work with (it supports a subset of the features, those that are the most required for scientific visualization purposes). reply wg0 2 hours agoprevOff topic kind of - Can an LLM generate such an article? Reading such in depth experiences and consolidating advice makes me think that web is made by humans and every other day,I spot something on the web that is clearly generated from some LLM. Great write up. Inspiring. reply archermarks 5 hours agoprevReally nice article! I have some OpenGL familiarity and tried out Vulkan but bounced off of it due to all of the up-front complexity just getting something running. Might give it another shot now! reply jsheard 5 hours agoparentIt's not quite as bad as it used to be, various later additions to Vulkan like dynamic rendering have eliminated some of the complexity it originally had. Figuring out which subset you should be using is a challenge in itself though, especially since there's a lot of outdated introductory resources floating around which still promote the ultra-verbose Vulkan 1.0 way of doing things. If a tutorial tells you to use render passes, run away. reply BearOso 4 hours agorootparentUnfortunately, dynamic rendering didn't come about until \"recently\". Many devices are stuck on Vulkan 1.1. Go to http://vulkan.gpuinfo.org/listextensions.php and search for dynamic_rendering. It's only supported on about 28% of reports. If you want to support those other devices you have to have a non-dynamic rendering path, and then at that point dynamic rendering is just more code. VK_EXT_shader_object is even better, but availability is that much worse. Edit: If you are able to find a tutorial using dynamic rendering, learn with that. Render passes obfuscate what's going on, and with dynamic rendering you can see exactly what's happening. reply exDM69 4 hours agorootparent> only supported on about 28% of reports. This information is misleading because it includes old reports from years ago, before this feature existed. It does NOT mean that 28% of devices out there have support. You will need Steam hardware survey results and cross reference gpuinfo.org or Android hardware survey results which directly list Vulkan versions. Dynamic rendering is available on all desktop GPUs (Intel, NV, AMD), on all desktop OSes (Windows, Macos, Linux) as long as you've got drivers that are up to date (no older than 2023). For mobile devices, the situation isn't as good. Updating mobile GPU drivers is an unsolved problem. reply BearOso 4 hours agorootparentI get your point. But you might be surprised how many PCs are still in use that have pre-Skylake Intel IGPs. Some people just don't update their drivers, either. reply exDM69 4 hours agorootparentPre-Skylake Intel never had proper Vulkan support (on Linux at least) so it's a non issue. I use a 2015 Skylake laptop for most of my graphics programming project and it's got full Vulkan 1.3 and wide set of features. The hardware doesn't do mesh shaders or Ray tracing but apart from that every new feature is available. Not updating drivers is a problem, especially on mobile. Thankfully auto updaters are very common these days. reply jsheard 4 hours agorootparentprevYou really have to think of Vulkan on PCs and Vulkan on mobile as separate things, if you only care about running on the former then you can easily count on things like dynamic rendering always being available as long as your users drivers are up to date. If you need to target Android though, my condolences. reply bashmelek 4 hours agorootparentprevDo you have any recommendations for sources? I’ve used Vulkan Tutorial, which is a bit stale but I suppose still good for exposure. I’ve also used Vulkan Guide, before its latest overhaul. That one was educational. Not sure if I’ll be able to do their new guide, my laptop can’t run some of the more recent versions of Vulkan reply OnionBlender 3 hours agorootparentKhronos overhauled their docs last year. I've found the \"Vulkan Guide\" easier to read than the spec. https://docs.vulkan.org/guide/latest/index.html Not to be confused with the tutorial you're referring to. https://vkguide.dev reply galangalalgol 4 hours agorootparentprevInteresting, for a while the guidance for a while was to learn webgpu instead unless you needed all that extra control. Do you think these changes modify that guidance? reply exDM69 4 hours agorootparentWith WebGPU/wgpu you don't get mesh shaders, ray tracing or shader subgroup/wave/warp operations. Its feature set is comparable to Vulkan 1.0, and Vulkan has progressed a lot since. And WebGPU still requires all the RenderPass setup code which is a lot of boilerplate that Vulkan no longer requires. reply jsheard 4 hours agorootparentprevWebGPU (or Metal if you're in Apple land) still has a much gentler learning curve. The simplifications to Vulkan weren't really aimed at making it easier to use, just streamlining parts of the API which turned out to be needlessly complex, so the parts that are complex for a reason are still just as complex. reply galangalalgol 4 hours agorootparentThanks! Other than a project not running as fast as necessary, do you have any advice on how to know when/if I need to switch to vulkan? reply jsheard 4 hours agorootparentAside from performance there's also just more hardware features exposed via Vulkan, as a sibling mentioned if you want to do anything with raytracing for example then you will have to graduate to Vulkan in order to take advantage of hardware acceleration. reply eliasdaler 5 hours agoparentprevThank you. The up-front complexity is still there and it might take quite a few days to see your first triangle. But I promise, everything will get much easier from that point. :) reply mort96 3 hours agorootparentThe thing I'm most interested in doing when starting a new project is pretty much never to spend a few weeks and writing 10-20k LOC to get a triangle on the screen, I think I'll stick with OpenGL for the time being tbh reply atan2 4 hours agoprevGreat read! Elias always does great work. reply andrewmcwatters 3 hours agoprevFor the casual reader who is curious what it takes to write a \"Hello, Triangle!\" in Vulkan 1.3: https://github.com/Planimeter/game-engine-3d/blob/main/src/g... reply eliasdaler 2 hours agoparentIndeed. vk-bootstrap is a bit better with 600 lines of code, though: https://github.com/charles-lunarg/vk-bootstrap/blob/main/exa... Vulkan initialization and basic swapchain management is very verbose, but things get much better after you do it for the first time and make some handy abstractions around pipeline creation/management later. reply andrewmcwatters 15 minutes agorootparentFor sure. They just move the roughly 300 lines of code elsewhere so you don't have to do it, though. I'd like to see them move nearly all 900-ish lines of SLOC back down into the near 90-ish you'd need to initialize OpenGL. There's so much overlap in basically everyone's graphic usage of Vulkan that you realize after doing it yourself they should have done some simple optimization for the 99% use case, and allowed other people to write the full 900+ lines for GPU compute or other use cases. reply ku1ik 2 hours agoparentprev/o\\ reply Waterluvian 1 hour agoprevAre there any examples of an academic attempt at putting as much of a game into the GPU as possible? Like, architecting a game in a way that pretty much everything, including game logic, could be implemented as a shader? reply layer8 1 hour agoprevIs this better than learning Klingon? ;) reply dventimi 5 hours agoprevnext [3 more] [flagged] raphman 5 hours agoparentThere are quite a few screenshots in the article. reply dventimi 3 hours agorootparentThey didn't load when I first viewed the article, probably because the site fell over as was reported elsewhere. reply alunchbox 4 hours agoprev [–] hey just curious, any reason why some of these articles I see from time to time don't apply some simply CSS? I don't mind the raw html, I'm mostly wondering if there's some benefit to it that I might not be aware of. reply solardev 3 hours agoparentJust a guess, but the folks interested in low level graphics programming are probably the same people who would want to stay away from bloated frontends? A simple blog post doesn't need super fancy design when its content can speak for itself. reply PhilipRoman 4 hours agoparentprev [–] The site definitely has CSS, just not a lot of it. reply eliasdaler 2 hours agorootparent [–] Indeed. I used as little CSS as I could because I love minimalist websites. And the lack of syntax highlighting was inspired by Go blog, for example. :) Raw HTML definitely looks much uglier, sadly (“Reader mode” in most browsers makes websites without CSS easily readable, though!). reply cristoperb 35 minutes agorootparent [–] Your site looks nice and is quite readable! The thing I most dislike about sites that just use raw HTML is the lack of `max-width` on the text containers (which makes using reader mode necessary), so thanks for including that reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author documents a three-month journey of learning Vulkan and developing a small game engine, despite having no prior Vulkan experience but some background in OpenGL and game engines.",
      "The engine, suitable for smaller level-based games, includes two demos and is available on GitHub, with practical advice for beginners transitioning from OpenGL to Vulkan.",
      "The article covers technical aspects like shaders, synchronization, and UI integration, and discusses the advantages of Vulkan for small 3D desktop games, while also reflecting on the uncertain future of OpenGL and the potential of WebGPU."
    ],
    "commentSummary": [
      "The article explores the author's experience in learning Vulkan and developing a game engine, offering practical programming advice and emphasizing the YAGNI (You Aren't Gonna Need It) principle.",
      "It highlights the challenges of using Rust with Vulkan, WGPU, and Rend3, including performance, concurrency, and community support issues.",
      "The discussion covers the complexities of Vulkan tutorials, compares different graphics APIs like OpenGL and Direct3D, and examines the benefits of higher-level abstractions and tools, noting Vulkan's steep learning curve but advanced features."
    ],
    "points": 272,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1717669463
  },
  {
    "id": 40593275,
    "title": "U.S. Regulators Launch Antitrust Probes into Microsoft, OpenAI, and Nvidia",
    "originLink": "https://www.nytimes.com/2024/06/05/technology/nvidia-microsoft-openai-antitrust-doj-ftc.html",
    "originBody": "Artificial Intelligence OpenAI’s ‘Reckless’ Culture The New ChatGPT Replacing the C.E.O. Chatbots and Disinformation Faces Quiz ADVERTISEMENT SKIP ADVERTISEMENT U.S. Clears Way for Antitrust Inquiries of Nvidia, Microsoft and OpenAI The Justice Department and the Federal Trade Commission agreed to divide responsibility for investigating three major players in the artificial intelligence industry. Listen to this article · 6:28 min Learn more Share full article 12 The Federal Trade Commission will be primarily responsible for examining Microsoft’s and OpenAI’s conduct in the artificial intelligence industry. Credit... Grant Hindsley for The New York Times By David McCabe Reporting from Washington Published June 5, 2024 Updated June 6, 2024, 2:42 a.m. ET Federal regulators have reached a deal that allows them to proceed with antitrust investigations into the dominant roles that Microsoft, OpenAI and Nvidia play in the artificial intelligence industry, in the strongest sign of how regulatory scrutiny into the powerful technology has escalated. The Justice Department and the Federal Trade Commission struck the deal over the past week, and it is expected to be completed in the coming days, according to two people with knowledge of the matter, who were not authorized to speak publicly about the confidential discussions. Under the arrangement, the Justice Department will take the lead in investigating whether the behavior of Nvidia, the biggest maker of A.I. chips, has violated antitrust laws, the people said. The F.T.C. will play the lead role in examining the conduct of OpenAI, which makes the ChatGPT chatbot, and Microsoft, which has invested $13 billion in OpenAI and made deals with other A.I. companies, the people said. The agreement signals intensifying scrutiny by the Justice Department and the F.T.C. into A.I., a rapidly advancing technology that has the potential to upend jobs, information and people’s lives. Both agencies have been at the forefront of the Biden administration’s efforts to rein in the power of the biggest tech companies. After a similar deal in 2019, the government investigated Google, Apple, Amazon and Meta and has since sued each of them on claims that they violated antimonopoly laws. For months, Nvidia, Microsoft and OpenAI largely escaped the brunt of the Biden administration’s regulatory scrutiny. But that began to change as generative A.I., which can produce humanlike text, photos, videos and audio, burst onto the scene in late 2022 and created an industry frenzy. Regulators have recently signaled that they want to get ahead of developments in A.I. In July, the F.T.C. opened an investigation into whether OpenAI had harmed consumers through its collection of data. In January, the F.T.C. also started a broad inquiry into strategic partnerships between tech giants and A.I. start-ups, including Microsoft’s investment in OpenAI and Google’s and Amazon’s investments in Anthropic, another young A.I. company. Still, the United States lags behind Europe in regulating artificial intelligence. European Union officials agreed last year on landmark rules to govern the fast-evolving technology, focused on the riskiest ways in which it can be used. In Washington last month, a group of senators released legislative recommendations for A.I., calling for $32 billion in annual spending to propel American leadership of the technology but holding off on asking for specific new regulations. The discussions between the F.T.C. and Justice Department over the A.I. companies entered their final stages within the last week and involved the senior levels of both agencies, said one person with knowledge of the discussions, who is an F.T.C. official. Lina Khan, the chair of the F.T.C., said in a February interview that when it came to A.I., the agency was trying to spot “potential problems at the inception rather than years and years and years later, when problems are deeply baked in and much more difficult to rectify.” Spokeswomen for the F.T.C. and the Justice Department declined to comment. Microsoft and OpenAI didn’t immediately respond to requests for comment. A representative for Nvidia declined to comment. Image The Justice Department will take the lead in investigating whether Nvidia, which makes A.I. chips, has violated antitrust laws. Credit... Jim Wilson/The New York Times Nvidia, OpenAI and Microsoft have been in the spotlight as some of the biggest winners of the A.I. boom, which has raised questions about their dominance. Nvidia, a Silicon Valley chipmaker, is the primary provider of graphics processing units, or GPUs, which are components adapted for A.I. tasks like machine learning. After A.I. took off, tech companies raced to get their hands on Nvidia’s GPUs, doubling and tripling its sales. Nvidia’s stock price has soared more than 200 percent over the past year, and the company’s market capitalization exceeded $3 trillion for the first time on Wednesday, surpassing Apple. Industry players have grown worried about Nvidia’s dominance, two people with knowledge of the concerns said, including how the company’s software locks customers into using its chips, as well as how Nvidia distributes those chips to customers. Microsoft, the world’s most valuable public tech company, has also become a leading purveyor of artificial intelligence. It owns 49 percent of OpenAI, which vaulted into the public consciousness with the 2022 release of ChatGPT. The chatbot’s ability to respond to questions, generate images and build computer code captivated people and quickly made the start-up one of the most prominent companies in the tech industry. Microsoft has woven OpenAI’s technology into its own products. A.I. now generates answers for users of its search engine, Bing, and can help build presentations and documents in PowerPoint and Word. (The New York Times has sued OpenAI and Microsoft, claiming copyright infringement of news content related to A.I. systems.) Microsoft’s A.I. deals have attracted scrutiny for giving one of the biggest tech companies influence over an emerging technology, while some in the industry have raised questions about whether the deals are structured in a way that allows Microsoft to avoid direct review by regulators. Microsoft structured its minority stake in OpenAI in part to avoid antitrust scrutiny, The Times has reported. Microsoft also reached a deal in March to hire most of the staff of Inflection AI, another A.I. start-up, and license its technology. Because the deal was not a standard acquisition, it may be harder for regulators to scrutinize. Last week, the Justice Department’s antitrust division organized a conference about A.I. at Stanford University. In his opening remarks, Jonathan Kanter, the top antitrust official at the agency, pointed to “structures and trends in A.I. that should give us pause.” “A.I. relies on massive amounts of data and computing power, which can give already dominant firms a substantial advantage,” he said. David McCabe covers tech policy. He joined The Times from Axios in 2019. More about David McCabe See more on: Microsoft Corporation, OpenAI 12 Share full article 12 Explore Our Coverage of Artificial Intelligence News and Analysis Federal regulators have reached a deal that allows them to proceed with antitrust investigations into the dominant roles that Microsoft, OpenAI and Nvidia play in the A.I. industry. Google appears to have rolled back its new A.I. Overviews after the technology produced a litany of untruths and errors. OpenAI said that it has begun training a new flagship A.I. model that would succeed the GPT-4 technology that drives its popular online chatbot, ChatGPT. The Age of A.I. After some trying years during which Mark Zuckerberg could do little right, many developers and technologists have embraced the Meta chief as their champion of “open-source” A.I. D’Youville University in Buffalo had an A.I. robot speak at its commencement. Not everyone was happy about it. A new program, backed by Cornell Tech, M.I.T. and U.C.L.A., helps prepare lower-income, Latina and Black female computing majors for A.I. careers. ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=40593275",
    "commentBody": "U.S. clears way for antitrust inquiries of Nvidia, Microsoft and OpenAI (nytimes.com)256 points by okdood64 15 hours agohidepastfavorite153 comments JieJie 13 hours agoNYT Gift Link: https://www.nytimes.com/2024/06/05/technology/nvidia-microso... roenxi 14 hours agoprevNvidia solved a hard problem and their competitors all failed. I spent years with an AMD card growing progressively more annoyed at their self-inflicted apparent inability to multiply matrices on demand. Nvidia had nothing to do with their failure, unless they had some sort of high-level mole in AMD's driver teams. Hitting the only successful company in a difficult field with legal assaults is not the obvious path to success. Nvidia has nothing close to a monopoly; there is no moat and they operate in a commodity space that will behave like a normal competitive market. It just happens that their competitors were wall-to-wall complacent about how quickly the hardware world can change and they stupidly thought graphics cards were for displaying graphics. It turns out graphics cards are for building AI and crypto markets. reply vlovich123 13 hours agoparentThe thing with monopoly laws is it doesn’t matter how you got into pole position. The point is that you’re illegally utilizing tangential benefits of the pole position to maintain that position as well as enter new markets. > including how the company’s software locks customers into using its chips, as well as how Nvidia distributes those chips to customers. The lock-in is probably a losing argument on technical merits unless NVIDIA is doing something nefarious there (which the lawsuit will potentially reveal). If nVidia is distributing chips in preferred ways to partners it wants to succeed (e.g. those partnered with MSFT which it has a very cozy and tight-knit relationship), that could be an anti trust thing. > Microsoft structured its minority stake in OpenAI in part to avoid antitrust scrutiny, The Times has reported. Microsoft also reached a deal in March to hire most of the staff of Inflection AI, another A.I. start-up, and license its technology. Because the deal was not a standard acquisition, it may be harder for regulators to scrutinize. So there is an argument to be made that MSFT is acutely self-aware its behavior could be viewed as engaging in antitrust. If there’s a law against structuring financial transactions, why isn’t similar behavior in the business world viewed similarly as trying to bypass the spirit of the law? reply roenxi 13 hours agorootparentJust on that last paragraph, because the frame annoys me - that is bullying. It isn't fair to insinuate that a company did something wrong by attempting to obey the law. MS knows all about antitrust. They've hired a bunch of lawyers and told them to do what needs to be done to be compliant with the regulations. That shouldn't then be implied as evidence that they are guilty of antitrust activities! What are the lawyers supposed to do, structure the company to maximise the likelihood of an antitrust lawsuit being bought? Nobody should want that, regulator, company or customer. reply vlovich123 12 hours agorootparentThis is a confusing argument to me. Are you saying that structuring and smurfing should then be legal? All structuring and smurfing is is an attempt to make sure that financial transactions stay below the statutory reporting threshold. Also, I think you’re conflating my statement which was meant to be prescriptive with a descriptive statement. I’m saying if structuring and smurfing are illegal in a financial context, MSFT doing so to skirt antitrust laws should be similarly illegal - if the laws don’t prohibit it, the laws should be updated. But I’m not a lawyer so it’s possible laws already prohibit it or MSFT violated some laws. Commenting in either direction on an information free article isn’t wise. As for the spirit of the law vs letter of the law, that’s an ongoing debate as old as history. It’s personally weird to me to encounter letter of the law people given that the spirit of the law has a much richer history behind it to my view and seems more defensible. Some amount of rule lawyering is required, but violating the spirit of the law is a more robust legal principle that can withhold participants trying to find creative workarounds around the spirit of the law. reply chollida1 9 minutes agorootparentThis is an easy asnwer. With banking, structuring laws mean banks need to report any transaction over $10,000. So if I need to send you $100,000 and s split it up into 11 payments so each payment comes under the $10,000 reporting limit that breaks the law because my payment was for $100,000 but i structured it to get around the $10,000 reporting limit. If Microsoft approaches anit trust limits if it owns more than 50% of a company and buys 49% then no strucuturing took place as they only bought 49%. Now if they bough 10% in each of 6 different shell companies that they own such that they'd control 60% of hte company, then this is illegal as it works around the limits. But owning up to the limit is perfectly fine as it doesn't in anyway break the law or work around it. That's the very reason for having a limit, to say you can go up to this limit, but not over. I'm guessing you don't deal in finance at all as we deal with this all the time. You'll see funds owning up to 9.9% of companies to avoid the 10% reporting threshold. Again, nothing illegal here as the government has said they are perfectly fine with funds owning up toIf you need to intentionally structure a deal to avoid scrutiny and have it described that way, it implies what you really wanted was much worse. It doesn't. That is like saying that if someone structures their affairs to pay less taxes it implies that wanted to do something illegal. They had to choose some structure, they picked the safest and easiest one. In both the hypothetical tax case and the real MS case, I suspect. The incentive is to choose structures that minimise regulatory engagement. The fact that MS is following incentives isn't a red flag. Not a green one either, it isn't interesting except as something that the NYTimes can hook insinuations on. reply jsnell 9 hours agorootparentThis is a funny discussion, because \"structuring\" has a very specific meaning when it comes to finance. It's about executing your financial transactions in a way that avoids regulatory scrutiny (for example sizing transactions such that they fall just under reporting thresholds). Structuring is explicitly illegal in the US. This is the point that vlovich123 was making, and given you totally missed it, it seems like you might not be familiar with what the term means in this context. reply roenxi 9 hours agorootparentSorry for being unclear on this, I should have quoted. But I'm not, and never was, talking about vlovich123's point in any comment in this thread. I didn't have an opinion on what vlovich123 said. reply SpaceNugget 8 hours agorootparentprevIt does. You can't replace the X and Y in \"Structuring X to avoid Y\" and still end up with the same implication. Structuring your business to avoid breaking the law is good. Structuring your business to avoid some otherwise regular audits that would reveal whether you are breaking the law is obviously suspicious. One might think that there is a reason why getting audited might result in negative consequences for your business. reply iforgotpassword 12 hours agorootparentprevBecause laws are always flawless and never contain any loopholes, and it has never happened ever that lawyers were specifically instructed by a company to find those loopholes and exploit them as hard as possible. reply mike_hearn 10 hours agorootparentThe idea of law as having loopholes is relevant for politicians, who are tasked with ensuring that the written law reflects their intent. It's not relevant for courts, regulators, people or companies, who are all tasked with following the law as actually written. For those people there is no \"spirit\" or \"true law\". The reason this is important is it's a sword that cuts both ways. It's always tempting to argue that whatever you'd personally like to happen is what politicians really intended, and any gap between reality and their preferred outcome is therefore a \"loophole\". But once you get into saying people should follow intent, not written law, others can easily argue that politicians never intended the law to be interpreted like that against them, and so therefore they are morally justified in ignoring it. It can be used against you as easily as you can use it against them. A common example of this problem is income vs capital gains taxes. One ideological tribe is very fond of arguing that people who have income mostly from investments rather than wages are exploiting a \"loophole\" in tax law, but of course the reason there are different rates to begin with is exactly because politicians wanted to encourage investment. There's plenty of cases where this intent is discussed in written literature and there's no other reason to distinguish between income sources then set differing rates. There is no \"loophole\" and nor is the \"spirit\" of the law being violated. But you hear such claims all the time. The other reason it's problematic is because you can't really know what the intent of lawmakers was. The law was their best collective effort at writing down what they wanted, as a result of numerous compromises and disagreements between different people. If they didn't write it down properly or the resulting compromise was a mess, that's on them, but a working legal system doesn't allow people to just blow off their written instructions and assume they know what was really meant. reply eru 9 hours agorootparent> For those people there is no \"spirit\" or \"true law\". Actually, there is. Many judges take various interpretations of the 'spirit' into account. See eg https://en.wikipedia.org/wiki/Originalism for one example. And if the courts use some 'spirit' guide them, companies and their lawyers better try and predict what that 'spirit' recommends. > If they didn't write it down properly or the resulting compromise was a mess, that's on them, but a working legal system doesn't allow people to just blow off their written instructions and assume they know what was really meant. Well, then by that definition the real life legal system of the US ain't working? reply mike_hearn 7 hours agorootparentOriginalism is the opposite of that, no? Originalists are all about following what was actually written down, using an understanding of English as it was used at the time. It rejects modern re-interpretations of the law and avoids speculating about the 'spirit' of the constitution, even if that would be more convenient. The competing view is that of a 'living' body of law in which the meaning continually changes without the wording itself changing. reply eru 5 hours agorootparentWell, either way: than the 'living body of law' theory is an example of such a 'spirit'. reply iforgotpassword 3 hours agorootparentprevYes, I'm aware of that distinction. However I read the comment I was replying to so that they suggested the antitrust case is unfounded because Nvidia didn't break any laws. It's precisely why the antitrust case is valid/needed, because if Nvidia were breaking any laws, you wouldn't need antitrust, you'd just take them to court. reply elefanten 12 hours agorootparentprevYou ignore “the spirit of the law” with fancy acrobatics around “the letter of the law”… at your own peril. I can’t comment on the claims here, but if MSFT is skirting the intent brazenly enough, the predictable regulatory reaction is no bullying. Everyone involved is well aware of that dynamic. No need to pity MSFT. reply pointlessone 10 hours agorootparentIs spirit of the law ever a concern in the USA? I’m asking because it is in the EU and every US company seem to struggle with the concept if I am to judge by how they engage GDPR, DMA and similar regulations in the EU. reply nabla9 9 hours agorootparentSpirit of the law is more important in the US. In common law systems (US, UK), there is greater emphasis on the spirit or intent behind the law. Judges have more flexibility to interpret laws and use general principles. Civil law systems place more importance on the letter of the law. The spirit behind the law is secondary. The written legal codes are more important. EU law is mixture of both, but most continental European countries have civil law system (Ireland does not, Nordic countries have mix of civil and common law) reply vlovich123 9 hours agorootparentSince the 1980s letter of the law has seen a remarkable upswing in power. I wouldn’t say spirit of the law applies anymore to SCOTUS rulings & I suspect federal appointments followed similar biases so it’s up & down the federal court. Not sure about state judges. Do you agree? reply vlovich123 9 hours agorootparentprevThe US Constitution has largely been interpreted in a “spirit of the law” manner since the founding. Originalism has taken significant durable gains in terms of SCOTUS appointments since the 1980s; prior to that originalists had a good chance of changing their POV once appointed. I suspect similar viewpoints are reflected in the judge appointments as well. Letter of the law benefits the powerful because they can always stay ahead of legislative attempts to fix the letter of the law (or lobby to change the letter). Spirit of the law is much harder to corrupt. Spirit of the law isn’t perfect itself obviously because it is legitimate to point out that it becomes hard to know what the law actually is, especially since governments have gotten into legislating a lot of regulatory nuance and it’s hard to distinguish malicious compliance from good faith effort. It’s also corruptible from overzealous prosecution looking to make a name for itself by taking on unpopular entities that aren’t actually doing anything wrong. reply AnthonyMouse 9 hours agorootparent> Letter of the law benefits the powerful because they can always stay ahead of legislative attempts to fix the letter of the law (or lobby to change the letter). Spirit of the law is much harder to corrupt. This is precisely the opposite. \"Spirit of the law\" makes the rules squishy and indeterminate, providing opportunities for fancy lawyers to bend the result to their own interests. \"Letter of the law\" often leads to harsh results when the law is drafted poorly, because if they wrote something dumb then you get something dumb instead of a judge rewriting the law to make people happy. But the people they're making happy are usually the powerful, so pick your poison. reply bee_rider 8 hours agorootparentSeems like either system is exploitable by the rich. reply AnthonyMouse 7 hours agorootparentThe difference is this: If you use the letter of the law, an ordinary person has the same chance to find a loophole as the rich. Which will tend to cause them to get closed, because the rich have more money but ordinary people are more numerous, and the ability for ordinary people to exploit them would pressure the government to fix them. Sometimes this would make the law more complicated, because the situation has intrinsic complexity and you have to enumerate the edge cases. Sometimes it would make the law simpler, because the existing complexity is extraneous and only an opportunity for gamesmanship. But either way it creates an evolutionary pressure for improvement. reply vlovich123 8 hours agorootparentprevNo law can ever be written to capture every possible application of the underlying spirit. Thus your ability to escape the spirit is directly correlated with how many lawyers you can hire to find loopholes in the text (or just flat out lie). It’s also important to remember that societies naturally undergo shifts over time. It’s impossible to continuously update a codified set of laws when the underlying moirés of the time have shifted; you’ll just be constantly arguing over the updates to add. Any law written perfectly today becomes imperfect simply through the passage of time. That’s why the Bible and any prescriptive religious text feels so outdated on many recommendations - it’s a snapshot in time of the values of a culture but those values change. There was even a fantastic sci-fi short story on this exact point of cultural shift [1] that’s worth a read. [1] https://qntm.org/mmacevedo reply AnthonyMouse 7 hours agorootparent> No law can ever be written to capture every possible application of the underlying spirit. Thus your ability to escape the spirit is directly correlated with how many lawyers you can hire to find loopholes in the text (or just flat out lie). The assumption here is that the rules would be complicated and provide lots of opportunities for gamesmanship. Now suppose the rule is \"no company shall have more than 30% market share in any market, any that does shall be broken into no fewer than twelve independent pieces.\" No loopholes, if you exceed 30% market share you get broken up. And if they find a loophole then you amend the law and take it out. > It’s impossible to continuously update a codified set of laws when the underlying moirés of the time have shifted; you’ll just be constantly arguing over the updates to add. That's just politics. Somehow you need a process to decide what the law should be. The output of that process is the new law. If the output sucks then get a new process. But whether people can agree on what the law should be is a separate issue than whether we should even know what the law as enacted is supposed to mean. > That’s why the Bible and any prescriptive religious text feels so outdated on many recommendations - it’s a snapshot in time of the values of a culture but those values change. That's fine, nobody is saying that you can't change the law if a case comes out in a bad way. But it should be the legislature rather than the courts to do it, and the new understanding shouldn't be applied to past behavior ex post facto. reply ickelbawd 4 hours agorootparentPlease clearly define the meaning of “you” in your simple law. Literally me? Okay, I don’t own 50% of the market—my company does. Oh you mean my company? Okay, my company doesn’t own 50% of the market—each of my companies only control 25%. Oh you mean me and my companies? Okay, well I only own one company and my wife owns the other one. Oh you mean… I think you get the point… Now move on to all the other words you used: what defines a “market”? What does “broken” mean here? What does “independent” mean here? I’m sure it’s quite clear to you—that you know it when you see it. I’m also quite sure others have different interpretations. I agree with the spirit of your comment otherwise, but simple laws rapidly become complex laws because people are complicated and language is flawed. reply tzs 8 hours agorootparentprev> The thing with monopoly laws is it doesn’t matter how you got into pole position. The point is that you’re illegally utilizing tangential benefits of the pole position to maintain that position as well as enter new markets. The following is for US law. Your first sentence is not really needed because US monopoly law really doesn't care if you are actually in pole position. It's more about monopolization than it is about monopoly. To a first approximation think of it as being about fair competition. You could have a complete 100% monopoly in some particular market but if you got that monopoly by simply outcompeting everyone else by making a better product and you were not trying to use that to expand into other markets by doing things like tying you would probably not have an antitrust problem. reply eru 9 hours agorootparentprev> The thing with monopoly laws is it doesn’t matter how you got into pole position. The point is that you’re illegally utilizing tangential benefits of the pole position to maintain that position as well as enter new markets. This depends on jurisdiction, and what judges you get. Eg Standard Oil was slapped with anti-trust law, despite neither having a monopoly nor exploiting its market share like a monopoly. See eg https://en.wikipedia.org/wiki/Standard_Oil#Legacy_and_critic... or https://fee.org/articles/the-myth-that-standard-oil-was-a-pr... > Some economic historians have observed that Standard Oil was in the process of losing its monopoly at the time of its breakup in 1911. Although Standard had 90 percent of American refining capacity in 1880, by 1911, that had shrunk to between 60 and 65 percent because of the expansion in capacity by competitors. reply fnordpiglet 12 hours agoparentprevSome companies such as standard oil had extraordinarily effective vertically integrated monopolies. The issues came into play when they used their market dominance to secure things like rebate structures with rail roads and made agreements to buy up transit capacity at very favorable rates that left competitors at a serious disadvantage. A real question might be how Nvidia prioritizes capacity and delivery and pricing to OpenAI and Microsoft for their superior product that has no meaningful competitor. It’s not an issue that Nvidia, like standard oil, had a superior business and product. It’s an issue when their scale and the scale of their adjacent partners lead to agreements that strangle others that need access to the supply chain. For instance if Anthropic is at a disadvantage to open ai for Nvidia capacity due to agreements between them that are mutually beneficial to the exclusion of Anthropic, that’s anti competitive. reply fasa99 53 minutes agorootparentAnother point with nvidia isn't \"better product\" but \"what API does everyone use\" and that's CUDA. Owned by NVIDIA. It would be like if SGI, who invented openGL as an open source version of their proprietary Iris GL, kept it proprietary, and now everyone uses SGI hardware because all games and 3D software use Iris GL. In this scenario SGI may also be very keen to make sure Iris GL has quirks that strongly tie it to SGI-only hardware to keep dominance. That seems a little more \"okay you're overleveraging your position\" versus \"you put out a better product in a fair market\" reply JamesBarney 37 minutes agorootparentprevWhy is it illegal to choose who you sell to? That's not bullying their competitors out of their own market. reply eru 8 hours agorootparentprevStandard oil wasn't a monopoly. See https://en.wikipedia.org/wiki/Standard_Oil#Legacy_and_critic... They even lost market share during the time they were alleged of having and exploiting a monopoly: > Although Standard had 90 percent of American refining capacity in 1880, by 1911, that had shrunk to between 60 and 65 percent because of the expansion in capacity by competitors. See https://fee.org/articles/the-myth-that-standard-oil-was-a-pr... for a more opinionated take. reply DarkNova6 7 hours agorootparent> Standard oil wasn't a monopoly. Bro... reply eru 5 hours agorootparent? reply foota 11 hours agorootparentprevSay that Nvidia partners with open AI because they think open AI is the best positioned to succeed (and hence result in increase demand for Nvidia) as opposed to if they got some direct financial kickback, it that legal? reply hgomersall 12 hours agoparentprevCory Doctorow argues well why it doesn't matter how you got into a monopoly position: https://pluralistic.net/2024/05/18/market-discipline/#too-bi... reply aydyn 11 hours agorootparentStill have no idea how this dude is relevant other than he wrote some scifi books one time. What are his technical accomplishments. Oh, nothing? Anyone can talk, especially nowdays because of AI, ironically. reply criddell 7 hours agorootparentMany of us appreciate the work he’s put in with the EFF. When you are right about things over-and-over for 20 or 30 years, people tend to listen to you. reply oblio 6 hours agorootparentprevWriting well is a rare and valuable skill. And this article, especially, really put into words what I had been thinking for 2 decades: https://www.wired.com/story/tiktok-platforms-cory-doctorow/ reply eru 8 hours agorootparentprevMany people like his writing, and his political stances. reply hgomersall 6 hours agorootparentprevI think he is relevant because he writes stuff that resonates. You might disagree, but I am judging him based on his very real accomplishments. reply aydyn 2 hours agorootparentIf his ideas resonate and are so profound, tell us what they are and why. Don't point to his blog and worship him like some minor deity. reply hgomersall 2 hours agorootparentHow does one worship a minor deity? You're not obliged to read what I post any more than I'm obliged to persuade you. Feel free to ignore the links, or feel free to read them. You might gain something from them as I have, but I'm not going to expend any efforts on trying to enlighten you or any such nonsense. reply aydyn 2 hours agorootparentI didnt read what you said because you didn't say anything. You just linked to his blog while carefully making sure to point out it was CD who wrote it. That's literally dictionary definition of idolatry. reply hgomersall 1 hour agorootparentIdolatry: noun; the worship of idols. It has a decent number of up votes, so clearly some people think it worth posting. As I said, you don't have to read it, and I don't really care if you do. I'm not sure how linking to something with a reference is worship, but ok. You seem very angry. reply nimish 13 hours agoparentprevYep. AMD and Intel had two decades to come up with a CUDA alternative or even a parallel implementation and both failed to do anything. Incompetence. reply oytis 11 hours agorootparentThe alternative to CUDA is called OpenCL. There has been speculations that poor performance of NVIDIA GPUs with OpenCL compared to CUDA is an intentional anticompetitive practice, but I don't feel confident to tell for sure. reply mschuetz 10 hours agorootparentOpenCL is an alternative to CUDA just like Legos are an alternative to bricks. The problem with OpenCL isn't even the performance, it's everything. If OpenCL were any good, people could use it to build similarly powerful applications on cheaper AMD GPUs. reply jb1991 8 hours agorootparentOpenCL is just a spec. It's up to companies to implement it in a successful way or not. There is no reason in and of itself that OpenCL can't compete with CUDA on performance. The fact that Apple's Metal, which is pretty good, is actually implemented with a private OpenCL system is proof that the spec is not to blame. reply paulmd 16 minutes agorootparentprevAMD’s first attempt at displacing CUDA-as-a-runtime was called AMD APP (advanced parallel processing) so this layer did indeed exist. It just sucked as badly as the rest of AMD’s slop. https://john.cs.olemiss.edu/heroes/papers/AMD_OpenCL_Program... Bonus points: the rest of the software libraries intended to compete with the CUDA ecosystem are still online in the “HSA Toolkit” GitHub repo. Here’s their counterpart to the Thrust library (last updated 10 years ago): https://github.com/HSA-Libraries/Bolt Nvidia had multiple updates in the last year the last time I checked. That’s the problem. reply roenxi 7 hours agorootparentprevThat theory doesn't really make sense. Nvidia didn't need AMD's permission to write a high-quality compute interface. Why would AMD need Nvidia's? AMD has their own internal opinions for how well they want compute to work; if OpenCL isn't doing it for them they should have figured that out quickly and then built their own layer as a stopgap. But we've seen what happens when they do that; ROCm. The problem is that they don't really know how and it is a glaring capability gap (didn't know I suppose - I expect they're learning fast). If anything, the situation with OpenCL suggests AMD and friends were the ones dragging their feet. Nvidia correctly identified that being led by the OpenCL committee would lock them out of billions (trillions, if you believe the stock market) of profit and routed around the blockage rather than compromise their engineering standards. reply lmeyerov 7 hours agorootparentprevAnd much more importantly for ooencl's success, poor compatibility of OpenCL implementations on Nvidia hardware by Nvidia + Microsoft platform-level software Eg, opencl on Nvidia GPUs for windows is/was missing (I have a many-year GitHub issue with them + Microsoft), which matters for individuals, and Nvidia does not support OpenCL for its core convenience analytics libraries like the RAPIDS Python ecosystem, which is core to its massive data center market. We initially built for compatibility/distribution, but it didn't matter: That gap closed a lot of doors for us as a small ISV choosing what & how to build, and in turn, ultimately prevents our customers from buying AMD, Intel, etc I'm not up to snuff on whether that qualifies as using its position anti-competitively anywhere, but it's a real market issue reply deadbabe 11 hours agorootparentprevHow do we know the strategy wasn’t to avoid releasing a CUDA alternative until NVIDIA is wounded by an anti-trust lawsuit and then when they get broken up deploy your CUDA alternative and speed past them? Could be playing the long game. reply throwthrowuknow 9 hours agorootparentThat’s not the case at all. AMD and Intel could be making money hand over fist right now if they had products that worked with the ML ecosystem. If they had any magic bullet they’d be idiots to not have used it years ago, they’re missing out on tens of billions of dollars on purpose for what? Even if NVIDIA got broken up their cards would still have massive demand and profit margins. I don’t think you understand how much of a shortage of compute there currently is, anyone who isn’t blatantly incompetent or ignoring ML can make money. AMD and Intel are just fat corporations who didn’t see the potential and thought business as usual would stay number one. Now they’re standing on the sidelines with their dicks in their hands while Jensen is leading the parade. reply bayindirh 8 hours agoparentprev> Nvidia solved a hard problem and their competitors all failed. And openly undermined technologies and standards that aimed to do the same in an interoperable way. This is, in my eyes, enough to hit with a litigation, but we'll see. reply torginus 12 hours agoparentprevHonestly I don't get how the current situation could develop. Video games have used compute shaders forever, and those work just fine on other cards. I remember doing some quite involved stuff for my thesis using OpenCL a decade ago, and it worked just fine. Nowadays OpenCL is dead for some reason... I just don't get what is there in CUDA that makes it so special. As far as I remember, a GPGPU API consists of a shader language, a way to copy stuff to and from the GPU, a way of scheduling and synchronizing work, atomics, groupshared variables, and some interop stuff. Is the vendor lock-in due to CUDA libs? In that case, the problem is not CUDA, but the libraries themselves. Not sure about today, but performance-portability basically didn't exist back then. You needed to do specialize your code for the GPU arch at hand. It didn't even exist between different generations of cards by the same vendor. Even if you could run CUDA code on AMD, it would be slow, so you need to do a rewrite anyways. reply skocznymroczny 10 hours agorootparentI don't know specifically about OpenCL, but the big thing about CUDA is that it's supported across operating systems and across the whole spectrum of NVidia GPUs. AMD has ROCm, but they have to be dragged kicking and screaming to support any of the consumer grade GPUs. ROCm is still pretty much Linux only, with limited support on Windows and only the high-end consumer offerings (7900XT and 7900XTX) are officially supported for ROCm. Because they want to push compute users (and AI users) into workstation grade GPUs. In comparison, CUDA is usable and supported even on mid range NVidia GPUs such as RTX 3060. And most of the software around things like AI is done by enthusiasts with gaming PCs, so they write their software for the interface that supports them. I have an AMD card that I try to use for AI stuff and it's an uphill battle. The most popular workloads such as Stable Diffusion or Llama more or less work. But as soon as you go into other, less mainstream workloads it starts to fall apart. Projects install CUDA versions of torch by default. To make them work you have to uninstall them manually and install the ROCM versions of torch. Then it turns out some Python dependency also uses CUDA, so you also have to find a ROCM fork for that dependency. Then there's some other dependency which only has a CUDA and CPU version and you're stuck. reply roenxi 11 hours agorootparentprevThere probably isn't anything in CUDA that makes it special. They are well optimised math libraries and the math for most of the important stuff is somewhat trivial. AI seems to be >80% matrix multiplication - well optimised BLAS is tricky to implement, but even a bad implementation would see all the major libraries support AMD. The vendor \"lock in\" is because it takes a few years for decisions to be expressed in marketable silicon and literally only Nvidia was trying to be in the market 5 years ago. I've seen a lot of AMD cards that just crashed when used for anything outside OpenGL. I had a bunch of AI related projects die back in 2019 because initialising OpenCL crashed the drivers. If you believe the official docs everything would work fine. Great card except for the fact that compute didn't work. At the time I thought it was maybe just me. After seeing geohotz's saga trying to make tinygrad work on AMD cards and having a feel for how badly unsupported AMD hardware is by the machine learning community, it makes a lot of sense to me that it is a systemic issue and AMD didn't have any corporate sense of urgency about fixing those problems. Maybe there is something magic in CUDA, but if there is it is probably either their memory management model or something quite technical like that. Not the API. reply mschuetz 10 hours agorootparentThe magic is that CUDA actually works well. There is no reason to pick OpenCL, ROCm, Sycl or others if you get a 10x better developer experience with CUDA. reply eru 8 hours agorootparentprev> The vendor \"lock in\" is because it takes a few years for decisions to be expressed in marketable silicon and literally only Nvidia was trying to be in the market 5 years ago. It's crazy, because even 10 years ago it was already obvious that machine learning was big and is only going to become more important. AlphaGo vs Lee Sedol happened in 2016. Computer vision was making big strides. 5 years ago, large language model hadn't really arrived on the scene yet, at least as impressively as today, but I think eg Google was already using machine learning for Google Translate? reply jb1991 8 hours agorootparentprevWhat do you think about SYCL as a viable cross-platform GPU API? reply paulmd 3 minutes agorootparentThe biggest problem with SyCL is that AMD doesn’t want to back a horse that they don’t control (same reason they opposed streamline) so they won’t support it. When the #2 player in a 2-player market won’t play ball, you don’t have a standard. Beyond that, AMD’s implementation is broken. Same as Vulkan Compute - SPIR-V could be cool but it’s broken on AMD hardware, and AMD institutionally opposes it as being a focus of their work. reply roenxi 6 hours agorootparentprevI'd have been happy to use OpenBLAS if it worked on a GPU. Any API is good enough for me. I have yet to see anything in the machine learning world that required real complexity, the pain seems to be in figuring out black box data, models and decyphering what people actually did to get their research results. The problem I had with my AMD card was that SYCL, like every other API, will involve making calls to AMD's kernel drivers and firmware that would crash the program or the computer (the crash was inevitable, but how it happened depended on circumstances). The AMD drivers themselves are actually pretty good overall, if you want a desktop graphics card for linux I recommend AMD. Open source drivers have a noticeably higher average quality than the binary stuff Nvidia puts out. Rock solid most of the time. But for anything involving OpenCL, ROCm or friends I had a very rough experience. It didn't matter what, because the calls eventually end up going through the kernel and whatever the root problem is lives somewhere around there. reply physicsguy 8 hours agorootparentprevWriting and porting kernels between different GPU paradigms is relatively trivial, that's not the issue (although I find the code much clunkier in everything other than CUDA). The problem is that the compiler toolchains and GPU accelerated libraries for FFT, BLAS, DNN, etc. which come bundled with CUDA are pretty terrible or non-existent for everything else, and the competitors are so far away from having a good answer to this. Intel have perhaps come closest with OneAPI but that can't target anything other than NVidia cards anyway, so it's a moot point. reply jbenjoseph 10 hours agorootparentprevI think a lot of it is customer service. If you work in ML you probably have some NVIDIA engineer's number in your phone. NVIDIA is really good at reaching out and making sure their products work for you. I am not a Torch maintainer but I am sure they have multiple NVIDIA engineers on speed dial that can debug complicated problems gratis. reply jb1991 8 hours agorootparentprev> Nowadays OpenCL is dead for some reason... Where does SYCL fit into this picture, is it a viable replacement for cross-platform GPU access? reply belter 10 hours agoparentprevIt's a bit ironic to talk about lawsuits over monopolies in an emerging AI market, that hardly existed 24 months ago, while ignoring the two worst monopolies in different domains, led by Microsoft and Google. reply rafaelmn 10 hours agoparentprevIt's interesting that Jensen seems to be selling this \"software development is dead to AI\" story when that means his profitability moat (software) is dead as well. All AMD needs to do is \"hey Copilot rewrite this CUDA code to run on AMD hardware\". Somehow that's not happening. reply belter 10 hours agorootparentAMD had 10 years to get competent on software. It's not happening. reply mort96 9 hours agoparentprev> There is no moat Isn't the CUDA API a fairly significant moat? reply roenxi 6 hours agorootparentI don't think so, no. I had an AMD card; I didn't feel like the lack of CUDA was slowing me down. I managed to implement everything I tried on the CPU just fine. My problem was that every approach I tried to implement my own stuff on the GPU using things like Vulkan or OpenCL led to crashes or frustration. In fairness I didn't know how to do basic operations on a graphics card with OpenGL and would be relying on super basic programming material out of AMD with titles like \"how to multiply a matrix on an AMD GPU\" [0]. They can be forgiven for not supporting amateurs I suppose ... but now I own a Nvidia card and they have stuff like https://docs.nvidia.com/cuda/cublasdx/introduction1.html. But I stress that the issue there isn't that CUDA has tutorials. It is that I expect the tutorial code not to lead to a crash or system lockup. There is a well supported path to do those basic operations. If you look at the CUDA webpage [1] you see things like \"cuRAND\", \"cuFFT\" and \"cuBLAS\". That isn't a moat - those are first year software engineering topics. AMD managed to make it look like a moat by not taking the compute market seriously; and anyone else competes at highly parallel compute. [0] As far as I can tell; doesn't exist. [1] https://developer.nvidia.com/cuda-zone reply jb1991 8 hours agoparentprev> self-inflicted apparent inability to multiply matrices on demand Isn't it one of the fundamental applications of a GPU, whether for ML compute or more commonly for 3D graphics, to multiple matrices? In what way did AMD GPUs fail to do this? reply sebzim4500 8 hours agorootparentHe means big matrices. And when you try to do compute on AMD GPUs they crash your kernel if you look at them wrong. reply trhway 13 hours agoparentprev>Nvidia had nothing to do with their failure, unless they had some sort of high-level mole in AMD's driver teams. I wonder why Jensen wouldn't help his cousin Lisa Su with a good advice :) In general it isn't surprising that hardware companies like Intel and AMD fall at software - just talk to any programmer at such a hardware shop. What striking is that Jensen is able to have such a prominent and huge software development in a naturally hardware company. NVDA is the only hardware company where my programmer acquaintances don't complain about it being a hardware company. reply Dalewyn 12 hours agorootparent>it isn't surprising that hardware companies like Intel and AMD fall at software A lot of what keeps Intel relevant is their prowess in both hardware and software, bringing properly refined products to market when it matters. Intel's failure against Nvidia had far more to do with their business strategy of CPU First missing the broadside of a barn; it's like bringing a knife to a gunfight, of course you're going to get your ass wrecked. AMD fucking sucks at software though, no disagreement there. reply 7f4784e3f1 12 hours agorootparentIntel has some great software like MKL and related libraries, but, speaking from experience, due to its internal politics Intel is unable to innovate in a meaningful way or build a reasonable SW strategy for GPUs. The oneAPI heavily contributed to their GPU failures IMO. Choosing SYCL and promoting non-existing performance portability and pouring resources in the trying to shove CPU and GPU (and at some point FPGA!) into the same programming model while disinvesting from OpenCL was a big mistake, but it was probably the only way to please both CPU and GPU management. And the problem is not SYCL per se but the fact that they try to make it an open standard rather then trying to provide a way to extract maximum performance from their HW. They needed to build a CUDA alternative, where, after jumping through considerable hoops, you can get to actually programming tensor cores for those who need it. Not surprisingly, Intel is not using SYCL for their GPU kernels (look at oneDNN sources). With Raja gone there may be hope, but I'm not holding my breath. The only thing that they have that is competitive is Habana's stuff which is outside of the oneAPI. I would not be surprised if AMD has a similar issue of infighting due selling both CPUs and GPUs. And NVIDIA does not have this problem. reply orhmeh09 11 hours agorootparentWhat are your thoughts on the move from ICC to the LLVM-based ICX? Does that fit in with this product strategy somehow? reply layla5alive 5 hours agoparentprevYou're grossly misinformed. CUDA is a huge anti-competitive moat, and that's no accident. reply deadbabe 11 hours agoparentprevAMD is more than just cards. reply blueboo 11 hours agoparentprevTheir competitors didn’t win. That’s not the same as failing, insofar as building technology goes. Business, sure reply uoaei 12 hours agoparentprev> there is no moat and they operate in a commodity space that will behave like a normal competitive market Sure, until you consider the massive difference in accessible capital vs their rivals. Sure, VCs can fund startups, but Nvidia is publicly traded, which is just investment of a different form, and largely a form that you are barely accountable to. And that's on top of all the capital they directly control. That's an incredibly advantageous position to be in, and one that would be too tempting for most to resist exploiting. reply Dalewyn 12 hours agoparentprev>not the obvious path to success. It is if success is defined as deliberate failure. Personally, a lot of US government actions of the past few decades in hindsight do not look like they had the interests of America or Americans in mind. reply HPsquared 10 hours agorootparentI wonder if anyone connected to this is short NVDA. reply pas 9 hours agorootparentprevCan you name a few examples please? reply samplatt 12 hours agoparentprev>Nvidia had nothing to do with their failure, unless they had some sort of high-level mole in AMD's driver teams. You're pretty close, but it's one level of abstraction away from the truth: NVidia spends absolutely earth-shakingly stonking amounts of money working directly with the devs of major studios, fixing issues with their drivers as they come, and in some cases paying studios to lock-in talking to them about the bugs they find. It's why (and how) they release new driver patches for every AAA release, and part of the reason why it triggers a redownload of the shader cache on a whole slew of Steam games every major version release. AMD and intel don't have a chance; NVidia is inside the design loop for game development far more thoroughly than other hardware vendors. reply reissbaker 11 hours agorootparentOf course AMD and Intel could just do the same thing. But they don't. That's not Nvidia's fault. In fact I wish Intel and AMD would do the same! It's great customer service to know that games are going to work well out of the box with Nvidia, because Nvidia spent tons of money working directly with devs on optimization and even per-game bugfixes. As a longtime PC gamer I wish AMD released better GPUs, but they seem incapable of doing so generation after generation. Intel is getting better at the low end, so there's at least some hope there. But Nvidia is just the best in class, because they put in a huge amount of polish and work. My understanding is this is the same approach Nvidia took with CUDA: investing a massive amount to make it fast, accurate, and broadly available, while AMD continued to push out barely-tested drivers — for example, see hotz's woes with tinygrad and finally giving up and labeling the \"red\" (aka AMD) tinybox driver quality as \"Mediocre\" on their product page, with the \"green\" (aka Nvidia) tinybox driver quality listed as \"Great\" https://tinygrad.org/ — and to this day restricts their competing library (ROCm) to specific ultra-expensive server-class GPUs. reply Dalewyn 11 hours agorootparent>In fact I wish Intel and AMD would do the same! Intel at least works very closely with Microsoft to iron out the details for Windows. reply mdorazio 14 hours agoprevIt's difficult for me to understand the thinking here. Nvidia is dominant because AMD and Intel completely dropped the ball on investing in frameworks to compete with CUDA. Microsoft... invested in OpenAI when it was clear that the newer batch of generative models had legs. OpenAI isn't really anticompetitive as far as I can tell - they just have the most money with which to vacuum up the most data and hire the top engineers. Investigating is fine, but if the concern is the direction of AI in general then that's a job for legislation, not antitrust action. I.e. a job that Congress kind of sucks at. reply faeriechangling 14 hours agoparentNvidia has done many anticompetitive things over the years even if what you’re saying is generally true. Gameworks comes to mind. reply kersplody 10 hours agoparentprevIt's fine to be a monopoly because you have the best product. It's not OK to use that monopoly position to stifle competitors. So has enough anticompetitive behavior occurred to distort the market? Unless I'm missing something, I'm just not seeing this investigation having legs. reply moose_man 14 hours agoparentprevIt seems like the investigations are linked so it could be they are acting in concert in a way that prevents or disrupts competition. Say for instance, OpenAI was using Microsoft money to buy chips and Nvidia was favoring it in a way that hurt other AI startups. reply shmerl 14 hours agoparentprevCUDA is pure lock-in, so it only makes sense for antitrust regulators to evaluate if it's causing anti-competitive damage to the market. Hint - it is. Lock-in is never good. reply mschuetz 10 hours agorootparentSure is, but there is nothing stopping AMD or Intel from building a working alternative to CUDA, so how is it anti-competitive? The problem with OpenCL, Sycl, ROC, etc. is that the developer experience is terrible. Cumbersome to set up, difficiult to get working accross platforms, lack of major quality of life features, etc. reply akamaka 8 hours agorootparentOne example of how they might be abusing their monopoly is by forcing data centers to pay an inflated price for hardware that is similar to consumer GPUs: https://github.com/DualCoder/vgpu_unlock reply _aavaa_ 4 hours agorootparentIf this is abuse, I have bad news for you about AMD and their arbitrary restriction of rocm for consumer GPUs. reply faeriechangling 3 hours agorootparentprevMaking a must-have product doesn’t constitute being an anti-competitive monopolist. Coca Cola isn’t a monopolist because classic coke just tastes so good and yet they refuse to share the recipe with Pepsi Cola. Anti-competitiveness is more leveraging the must-have nature of CUDA to shelter Nvidia from competition. E.G. an OEM can’t sell professional laptops that support CUDA if it sells AMD gaming laptops or something - just to illustrate. Or Coca Cola refusing to sell coke to a store that also sells Pepsi causing the store to not stock Pepsi. Monopoly law isn’t meant to simply punish success and exclusivity. reply shmerl 1 hour agorootparentIt's not about a must have. It's about a must have being tied to them. That tying is what's harming the market by preventing interoperability. It only makes sense to prevent such kind of traps. I.e. a must have can be a must have without artificially added tying (lock-in) detail. Then it's not causing harm. reply arvinsim 13 hours agorootparentprevWouldn't that logic also apply to, say, Apple? reply bmacho 10 hours agorootparentIt applies to game consoles as well, nintendo/sony/microsoft selling a hardware, and require to pay THEM when I want to run something on it, is outrageous. reply qeternity 8 hours agorootparentI don't really understand this argument. There are tons of alternatives. If I want to build and design a product a certain way, and you don't like it, simply don't buy it? This is a genuine question because I realize I am probably in the minority on HN, so please don't downvote just because of that. I just think that regulations in general should be applied only when necessary, and then be applied with great force. The user experience for game consoles largely falls back on the manufacturer. If Xbox had loads of unvetted buggy games and malware swimming in the ecosystem, people might be less inclined to buy an Xbox. So Microsoft sets about establishing some control over the ecosystem. Apple's App Store was really the first time that your average Joe could download an application from the internet and not have to worry about viruses. It was a big deal that added a lot of value to the user experience. reply bmacho 7 hours agorootparentIt was, probably, but it is not anymore. It forces itself to be a middle man by every possible method, and just leeches on transactions. reply shmerl 13 hours agorootparentprevOf course it would. And should be applied. reply HWR_14 12 hours agorootparentprevApple doesn't control an entire industry. You can buy an Android phone and fully participate in the mobile phone world never talking to Apple. You cannot participate in the AI world without NVIDIA. reply throwthrowuknow 9 hours agorootparentAnd why can’t you just use an AMD GPU? Is it because stores don’t sell them? Is it because motherboards don’t support them? Is it because you can’t rent one from a cloud provider? No, it’s because they don’t fucking work when you try to use them for ML. reply HWR_14 6 hours agorootparentThat's not really relevant. Antitrust laws tend to focus on abusing your monopoly position, not having it. Microsoft was sued for using its Windows monopoly to force IE on people, not for having the monopoly by itself. reply shmerl 12 hours agorootparentprevYou don't need to control the entire industry to cause anti-competitive damage. You just need to have enough leverage that your influence can't be ignored. Examples of Apple doing that is banning competing browsers on iOS and then pushing W3C and developers in the direction they want due to \"you can't ignore us\". There was a whole list of bad examples. Touch events, fighting against SPIR-V in WebGPU, fighting against adoption of Media Source Extensions (to benefit their video solutions) and etc. and etc. They very clearly cause a ton of damage to the market by slowing down and sabotaging the progress of interoperable technology to harm competition. reply HWR_14 4 hours agorootparentApple is the only competitor to Google's 65% (direct) plus reskinned Chromium dominance of the browser market. Meanwhile, I'm happy with the direction they push W3C and developers. Without them, Google would just push the web to whatever they want (more than they already do). reply shmerl 4 hours agorootparentThat doesn't excuse all the garbage Apple doing for the sake of their lock-in. They totally should have been blasted by anti-trust years ago for banning competing browsers on iOS. And many other things. Seems like EU finally started getting the point before US regulators did. reply threeseed 10 hours agorootparentprevApple doesn't prevent competing browsers. Just different engines. And just because they don't rush to incorporate every web feature doesn't make them anti-competitive. Especially when most of the time they are right to do because either (a) they impact security or battery life or (b) they are non-standard. Case in point SPIR-V which unless I am mistaken is exclusively controlled by Khronos. reply shmerl 4 hours agorootparent> Apple doesn't prevent competing browsers. Just different engines And you should know well it's the same thing, since above listed issues are defined by the engine. Whatever label you put on top doesn't change the essence of what the problem is. Basically, you completely missed the point. reply lostmsu 13 hours agorootparentprevHow can a product on its own cause anti-competitive damage? reply shmerl 13 hours agorootparentWhen it's used as a tool that makes it impossible or very costly to switch from what such tool is tied to. To give an example. If CUDA wouldn't have been tied to Nvidia hardware, developers could use CUDA on any competing hardware. Being tied limits the choice. That's the essence of lock-in damage. Development tools should be development tools, not ways to control the market. That's why there is value in something that breaks lock-in - that improves competition. reply DaiPlusPlus 13 hours agorootparent> If CUDA wouldn't have been tied to NVIDIA hardware... Initially I thought that AMD didn't offer a CUDA reimplementation out of NIH-syndrome (as it would be a marketing coup for NVIDIA), but then I saw that NVIDIA seem to be actively trying to shut-down independent attempts at running CUDA on non-NVIDIA hardware: https://www.techpowerup.com/319984/nvidia-cracks-down-on-cud... reply jonathankoren 12 hours agorootparentThey should lose. As I said in another comment, SCOTUS just ruled that APIs weren't copyrightable, and there's a HUGE parallel with Microsoft and Sun Microsystems over Java. In the end, Sun settled for Microsoft to stop saying \"Java compatible\" and $20 million. The community on the other hand got OpenJDK four years later. Just do it. Fuck the lawyers. When you win, you toss some cash and they'll ya for it. https://www.cnet.com/tech/tech-industry/sun-microsoft-settle... reply 1123581321 13 hours agorootparentprevThere would have to be more to it. If cuda is just the software that Nvidia customers use, or nvidia hardware is chosen because cuda is better software, it's not going to pass a market welfare test nor would monopolistic practices be found. Expensive switching costs per se aren't considered damage to welfare. reply jonathankoren 13 hours agorootparentprevBut what prevents anyone from developing an OpenCUDA? It's been almost 25 years ago, but this was the crux of the Sun Microsystems v. Microsoft lawsuit. It's why OpenJDK exists. Even three years ago the Supreme Court ruled that you can't copyright an API. I mean, it feels breathtakingly obvious. Not only is there historical precedents for just doing this, there're legal precedents as well. reply shmerl 12 hours agorootparentCost. What prevents someone from making something new to fight against an incumbent? Cost of entry most of the time. That's the mentality in the lock-in. Make switching too expensive and difficult to even bother. Possible? Yes, but hard enough. When someone manages to overcome the cost and commoditize what lock-in was walling - it improves things. Even better if someone manages to do it while breaking lock-in itself. Sort of like writing a wrapper to run CUDA on non Nvidia GPUs (what ZLUDA is doing). reply osnium123 14 hours agoprevI don’t understand why the US government is moving to cripple NVidia. It’s not Jensen’s fault that he’s a visionary CEO who anticipated this market and invested in CUDA. Jensen also didn’t anything to do with the fact that Intel had incompetent leadership for 15 years before Pat Gelsinger joined in 2021. reply vlovich123 13 hours agoparentIt’s questionable whether or not he anticipated this specific market vs he just positioned the company to eat up sales to high energy particle physics & similar super-computer applications and then got lucky that this accelerator also turned out to work pretty well for AI. At best, he saw that he needed a more general compute platform for GPUs but OpenCL was a thing so he wasn’t alone in recognizing this. There’s even an argument to be made that NVidia intentionally undermined OpenCL to cause it to fail; since NVidia has the fastest cards & mind share, if they make CUDA perform better than OpenCL, they encourage developers to buy into that development environment and thus lock out the standard from adoption. reply bcatanzaro 1 hour agorootparentPeople have been saying that GPUs randomly happened to be good at ML since at least 2014 when Nervana was founded. It was clear 12 years ago to anyone paying attention that DL was revolutionizing the world and that NVIDIA GPUs were at the center of the revolution. Whatever random chance factored into NVIDIA's success is outweighed by the decade+ of pedal-to-the-metal development NVIDIA has undertaken while its competitors decried AI as an overhyped bubble. I have been there for this history, working on ML on GPUs at NVIDIA for a few years before Jensen decided to productize my little research project, CUDNN. reply vlovich123 17 minutes agorootparentThe history page for CUDA is pretty accessible [1]. It originated from experiments at Stanford in 2000 with Ian taking on leadership of CUDA development in 2004. > In pushing for CUDA, Jensen Huang aimed for the Nvidia GPUs to become a general hardware for scientific computing. CUDA was released in 2006. Around 2015, the focus of CUDA changed to neural networks.[8] Credit to Jensen for pivoting, but I recall hearing about CUDA networks from Google tech talks in 2009 and realizing they would be huge. It wasn't anything unique to realize NNs were a huge innovation but it did take another 5 years for it to mature enough and for it to become clear that GPUs could be useful for training and whatnot. Additionally, it's important to remember that Google had a huge early lead here & worked closely with Nvidia since CUDA was much more mature than OpenCL (due to intentional sabotage or otherwise) and Nvidia's chips satisfied the compute needs of that early development. So it was more like Google leading Nvidia to the drinking well and Nvidia eventually realizing it was potentially an untapped ocean and investing some resources. Remember, they also put resources behind cryptocurrency when that bubble was inflating. They're good at opportunistically taking advantage of those bubbles. It was also around this time period that Google realized they should start investing in dedicated accelerators with their TPUs because Nvidia could not meet their needs due to lack of focus (+ dedicated accelerators could outperform) leading to the first TPU being used internally by 2015 [2]. Pretending like Jensen is some unique visionary seeing something no one else in the industry didn't is insane. It was a confluence of factors and Jensen was adept at navigating his resources to take advantage of it. You can appreciate Nvidia's excellence here without pretending like Jensen is some kind of AI messiah. [1] https://en.wikipedia.org/wiki/CUDA [2] https://en.wikipedia.org/wiki/Tensor_Processing_Unit reply talldayo 1 hour agorootparentprevYeah, you really get this sense when you page through their research history on the topic: https://research.nvidia.com/publications?f%5B0%5D=research_a... CUDA won big because it made a big bet. Were it that OpenCL was ubiquitous and at feature-parity with CUDA, maybe there would be more than one player dealt-in at the table today. But everyone else folded while Nvidia ran the dealer for 10 long years. reply radicalbyte 13 hours agorootparentprevIt seemed like a no-brainer to me to open the hardware up to more general purpose compute.. but I'm a software guy who started on machines where where completely open and can \"do magic\" thanks to that. reply Vespasian 10 hours agoparentprevLaws in this field do not make a moral judgement on how a company got where they are. They look at what you are doing with the power you actually have. Once you are the size and importance of MS, OpenAI or Nvidia, the rules change and everyone knows that. reply bmacho 10 hours agoparentprevNvidia always tries to be anticompetitive, creating and exploiting vendor lock-in, instead of giving back to the world , like e.g. like Sun did, open-sourcing everything. It is definitely Jensen's fault. I think it is a law of nature that shitty and harmful behaviour pays off, but that's not a problem, if we can correct it time-to-time. With antitrust inquires for example. reply null_investor 10 hours agoprevPeople attribute great leadership to Satya, but to me it seems to be about be willing to fight with regulators, and funnily enough the regulators haven't been working so much recently. Just have a look at the size that Google, Microsoft, Meta others have got, not because they have a outstanding product (like Cuda), but because they can use their dominant market position to buy smaller businesses and monetize their products as part of a bundle (Whatsapp, Activision Blizzard acquisition and the list goes on). Or just build a new product and shove it to their customers, like with MS Teams/Threads. The US government seems to have actually aided those US companies to keep doing their monopolist practices, with many other countries around the world fighting against them alone, like Europe. The situation is so bad right now, that Europe itself is now distancing itself from US to potentially also fight even harder against those companies, which bring barely any jobs to Europe, but have market share in the 90s and beyond. I'm pretty certain that companies in Europe could build its own Facebook, Instagram, Whatsapp, their own android fork etc. They don't do it because for a long time Europe has been a US pseudo-vassal. reply Synaesthesia 9 hours agoparentYes the US government is definitely assisting US tech companies, and their global monipoly. Look at how they went after Huawei. reply vinyl7 7 hours agoparentprevAfter WW2, the US was the manufacturing superpower of the world, and it made the US very wealthy. China has since taken that spot, and the US didn't have any major play in the global economy. Starting with Obama, the US started investing heavily into tech via regulatory dismemberment and fiscal policy (ZIRP). The tech monopoloy is intended so that the US has control of a market in the global economy. reply tzm 14 hours agoprevhttps://archive.ph/cBKj7 reply pciexpgpu 8 hours agoprevI am surprised the path to AGI isn’t first paved with a simple request to the AI gods to replace cuda. On the other hand, Microsoft does seem to have used mere mortals to write a driver/gpu independent way to run workloads in azure (Maia/Triton). Microsoft is truly unstoppable no matter which way this whole AI race goes. reply talldayo 47 minutes agoparentI mean, I own an Nvidia GPU and I'd rather CUDA get replaced too. Very few people besides Nvidia shareholders truly love the status-quo here. But really, the blame has to be put on the rest of the industry. If you want to kill CUDA, you have to attack it where Nvidia won't defend; make something Open Source and cross-platform. The problem is getting everyone to sit at the same discussion table. Microsoft has a half-dozen accelerator programs in the work and benefits from the ecosystem fracture. AMD is desperate for anyone but themselves to do their work for them. Apple is hedging their bet on piecemeal acceleration while trying their hardest not to fall behind. Google is trying their hardest to distance themselves from hardware and focuses mostly on software. And Nvidia could care less what everyone does, because they're shipping the largest servers out of everyone mentioned. > Microsoft is truly unstoppable no matter which way this whole AI race goes. I can forsee one way they get crushed. If OpenAI keeps dealing in risky business with celebrities and intellectual property, Microsoft might be forced to divest one way or another. Without their OpenAI deal, Microsoft is in a much worse position more similar to Google. If everyone else is willing to ante-up on an Open Source CUDA alternative, then Microsoft's window closes to exploit the demand for a solution. Slim chance that everyone buries their hatchets though. reply surfingdino 12 hours agoprevMicrosoft seems to have found themselves with more than they bargained for when they decided to go all in on AI. OTOH, Microsoft is quite familiar with antitrust inquiries, because they've been there before https://en.wikipedia.org/wiki/United_States_v._Microsoft_Cor.... reply robotnikman 12 hours agoprevMicrosoft and OpenAI I might see something, but Nvidia? The only reason they are where they are right now was by investing a decade beforehand into CUDA reply surfingdino 12 hours agoparentIt's about using their status today and how, not where they were yesterday. reply bicepjai 13 hours agoprevSometimes we just need to understand we donot have all the information before we give subjective opinion with incomplete information reply ineedaj0b 12 hours agoparentwe all work in the industry. you can tell if something is fishy you don't need to wait. where there is smoke there is fire reply SilverBirch 10 hours agoprevIt's interesting to me that Microsoft and Nvidia are being lumped together in this reporting. To me there seems to be two very different issues. Nvidia managed to execute on a combined software/hardware product category that has yielded fantastic results and is difficult to copy. That's great. It's nothing to do with Anti-trust. Are they charging a premium for scarce products now? Sure, but all you can do is damage the market by attacking them there's no real way to increase demand. At best you can limit their profits, just handing over margin to their customers. The Microsoft situation is very different however. You've got this behemoth that has basically just decided to take it's magic money tree and use it essentially buy growth through a huge number of complex deals that are designed to circumnavigate anti-trust. Sorry but \"We're not buying you, we're just handing your investors a tonne of money, letting you shut down your company and then hiring all your employees\" is bullshit. And also \"We're investing in you <oh and here are all these terms about how we own X Y Z of your technology and you must buy A B C of our resources\" is also bullshit. You can make a credible argument that Nvidia uniquely earned the success they're seeing with the AI stuff, I don't think you can make that argument with Microsoft. Now if you can join the dots - Nvidia has a cosy deal with MSFT to give MSFT GPUs and small companies then have to deal with MSFT because they have all the access to compute, then I think that would be a slam dunk. Leverage Microsoft's Cloud business to hoover up startups in AI. reply jb1991 8 hours agoprevSome talk of OpenCL vs. Cuda in this thread, but I'm wondering what, if anything, does SYCL have to offer in this area? Do Nvidia GPUs support SYCL? reply XiS 13 hours agoprevCan't wait for al the upcoming internal tech emails, hehe reply maeln 9 hours agoprevSeeing some of the comment here, you could make a conspiracy theory that NVidia/MS/OAI used their generative algorithm to write comment defending them on HN :p . All jokes aside, I know that antitrust is not just about monopoly, but if we just focus on this part, it really does not matter if one company became a monopoly fair and square by just being better/smarter/luckier than everyone else, you still probably don't want it to be a monopoly. And making sure it still has competitor is usually beneficial in the long run. A monopoly might act \"fair\" for a long time (although it would be hard to know since you won't have anything to compare them with), but their power allow them to turn against the consumer whenever they want with little to no consequence. As an example, you can't really complain about an inquiry against NVidia, and then complain about their pricing and/or how hard it is to get some of their card (especially the one meant for training) because they don't care about you if you don't have a good relationship with them (and a lot of $$). All in all, pretty sure this inquiry will lead nowhere, or just a slap on the wrist, as is usually the case. It is just a signal to those company to be careful and to avoid using their dominant position on one market to push themselves unfairly in another. reply teh_infallible 12 hours agoprevSounds to me like some regulators saw dollar signs and wanted a cut. reply blackeyeblitzar 11 hours agoprevMicrosoft for sure needs to be split up, fined for what they did with Teams, and regulated for how they are bundling AI. I’m less concerned about Nvidia reply zooq_ai 12 hours agoprevwhat's with democrats and destroying success? It stems from their fundamental philosophy that if you are successful then you must be evil or have done something illegal. reply threeseed 10 hours agoparentDOJ operates independently of the White House. And Merrick Garland is about as bi-partisan a choice as you could pick. reply zooq_ai 2 hours agorootparentDOJ and FTC is appointed by White House and they make sure they align with their ideologies. There is a reason Lina Khan goes after companies while her republican counterpart wont. Thank God the supreme court will kneecap all these useless agenda-driven agencies reply exabrial 14 hours ago [flagged]prevnext [3 more] Ffs, how about Apple, Google, Facebook? Quit jacking around. reply moose_man 14 hours agoparentGoogle and Apple are currently in antitrust litigation, and the government is looking into Facebook's acquisitions of Insta and Whatapp. reply passwordoops 14 hours agoparentprevPlease go to your favorite search engine and copy the following: -DOJ v Google -DOJ v Facebook -DOJ v Apple -DOJ V Amazon reply ineedaj0b 12 hours agoprev [–] initially tech was an apolitical asleep bear. the bear is waking up and both sides are not happy there is a bear in the room. the bear needs to pick a side or even better... be a bear. be competent. bears are strong and can command a room themselves. you have to accept responsibility you're a bear now. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Federal regulators, including the Justice Department and the FTC, have divided responsibilities for antitrust investigations into major AI industry players: Microsoft, OpenAI, and Nvidia.",
      "The FTC will focus on Microsoft and OpenAI, while the Justice Department will investigate Nvidia, signaling increased regulatory scrutiny of AI technologies.",
      "These investigations aim to address potential antitrust violations and consumer harm, reflecting a growing effort in the U.S. to oversee the rapidly advancing AI industry."
    ],
    "commentSummary": [
      "The U.S. has launched antitrust investigations into Nvidia, Microsoft, and OpenAI, focusing on potential anti-competitive practices and corporate ownership structures.",
      "Nvidia is under scrutiny for its dominance in chip distribution, while Microsoft is questioned over its stake in OpenAI and the acquisition of Inflection AI's staff.",
      "The investigations highlight the complexities of antitrust laws, the need for updates, and the broader implications for tech industry regulations and consumer protection."
    ],
    "points": 256,
    "commentCount": 153,
    "retryCount": 0,
    "time": 1717645962
  },
  {
    "id": 40592575,
    "title": "Discovery of Balon Protein Reveals Key Mechanism for Cellular Dormancy and Survival",
    "originLink": "https://www.quantamagazine.org/most-life-on-earth-is-dormant-after-pulling-an-emergency-brake-20240605/",
    "originBody": "Most Life on Earth is Dormant, After Pulling an ‘Emergency Brake’ Read Later Share Copied! Comments Read Later Read Later microbiology Most Life on Earth is Dormant, After Pulling an ‘Emergency Brake’ By Dan Samorodnitsky June 5, 2024 Many microbes and cells are in deep sleep, waiting for the right moment to activate. Biologists discovered a widespread protein that abruptly shuts down a cell’s activity — and turns it back on just as fast. Read Later When the going gets tough, many microbes go dormant. New research discovered a ubiquitous protein that shuts down a cell’s protein production in a flash. Nico Roper/Quanta Magazine By Dan Samorodnitsky Contributing Writer June 5, 2024 View PDF/Print Mode bacteriabiologycell biologycellsmicrobiologyproteinsAll topics Introduction Researchers recently reported the discovery of a natural protein, named Balon, that can bring a cell’s production of new proteins to a screeching halt. Balon was found in bacteria that hibernate in Arctic permafrost, but it also seems to be made by many other organisms and may be an overlooked mechanism for dormancy throughout the tree of life. For most life forms, the ability to shut oneself off is a vital part of staying alive. Harsh conditions like lack of food or cold weather can appear out of nowhere. In these dire straits, rather than keel over and die, many organisms have mastered the art of dormancy. They slow down their activity and metabolism. Then, when better times roll back around, they reanimate. Sitting around in a dormant state is actually the norm for the majority of life on Earth: By some estimates, 60% of all microbial cells are hibernating at any given time. Even in organisms whose entire bodies do not go dormant, like most mammals, some cellular populations within them rest and wait for the best time to activate. “We live on a dormant planet,” said Sergey Melnikov, an evolutionary molecular biologist at Newcastle University. “Life is mainly about being asleep.” But how do cells pull off this feat? Over the years, researchers have discovered a number of “hibernation factors,” proteins that cells use to induce and maintain a dormant state. When a cell detects some kind of adverse condition, like starvation or cold, it produces a suite of hibernation factors to shut its metabolism down. Some hibernation factors dismantle cellular machinery; others prevent genes from being expressed. The most important ones, however, shut down the ribosome — the cell’s machine for building new proteins. Making proteins accounts for more than 50% of energy use in a growing bacterial cell. These hibernation factors throw sand in the gears of the ribosome, preventing it from synthesizing new proteins and thereby saving energy for the needs of basic survival. Earlier this year, publishing in Nature, researchers reported the discovery of a new hibernation factor, which they have named Balon. The protein is shockingly common: A search for its gene sequence uncovered its presence in 20% of all cataloged bacterial genomes. And it works in a way that molecular biologists had never seen before. Karla Helena-Bueno discovered a common hibernation factor when she accidentally left an Arctic bacterium on ice for too long. “I tried to look into an under-studied corner of nature and happened to find something,” she said. Courtesy of Karla Helena-Bueno Previously, all known ribosome-disrupting hibernation factors worked passively: They waited for a ribosome to finish building a protein and then prevented it from starting a new one. Balon, however, pulls the emergency brake. It stuffs itself into every ribosome in the cell, even interrupting active ribosomes in the middle of their work. Before Balon, hibernation factors had only been seen in empty ribosomes. “The Balon paper is amazingly detailed,” said the evolutionary biologist Jay Lennon, who studies microbial dormancy at Indiana University and was not involved in the new study. “It will add to our view of how dormancy works.” Melnikov and his graduate student Karla Helena-Bueno discovered Balon in Psychrobacter urativorans, a cold-adapted bacterium native to frozen soils and harvested from Arctic permafrost. (According to Melnikov, the bacterium was first found infecting a pack of frozen sausages in the 1970s and then rediscovered by the famed genomicist Craig Venter on a trip to the Arctic.) They study P. urativorans and other unusual microbes to characterize the diversity of protein-building tools used across the spectrum of life and to understand how ribosomes can adapt to extreme environments. Because dormancy can be triggered by a variety of conditions, including starvation and drought, the scientists pursue this research with a practical goal in mind: “We can probably use this knowledge in order to engineer organisms that can tolerate warmer climates,” Melnikov said, “and therefore withstand climate change.” Introducing: Balon Helena-Bueno discovered Balon entirely by accident. She was trying to coax P. urativorans to grow happily in the lab. Instead she did the opposite. She left the culture in an ice bucket for too long and managed to cold-shock it. By the time she remembered it was there, the cold-adapted bacteria had gone dormant. Not wanting to waste the culture, the researchers pursued their original interests anyway. Helena-Bueno extracted the cold-shocked bacteria’s ribosomes and subjected them to cryo-EM. Short for cryogenic electron microscopy, cryo-EM is a technique for visualizing minuscule biological structures at high resolution. Helena-Bueno saw a protein jammed into the stalled ribosome’s A site — the “door” where amino acids are delivered for the construction of new proteins. Helena-Bueno and Melnikov didn’t recognize the protein. Indeed, it had never been described before. It bore a similarity to another bacterial protein, one that’s important for disassembling and recycling ribosomal parts, called Pelota from the Spanish for “ball.” So they named the new protein Balon for a different Spanish word for “ball.” Unlike other hibernation factors, Balon can be inserted to stall growth and then quickly ejected like a cassette tape. Balon’s ability to halt the ribosome’s activity in its tracks is a critical adaptation for a microbe under stress, said Mee-Ngan Frances Yap, a microbiologist at Northwestern University who wasn’t involved in the work. “When bacteria are actively growing, they produce lots of ribosomes and RNA,” she said. “When they encounter stress, a species might need to shut down translation” of RNA into new proteins to begin conserving energy for a potentially long hibernation period. Notably, Balon’s mechanism is a reversible process. Unlike other hibernation factors, it can be inserted to stall growth and then quickly ejected like a cassette tape. It enables a cell to rapidly go dormant in an emergency and resuscitate itself just as rapidly to readapt to more favorable conditions. Balon can do this because it latches on to ribosomes in a unique way. Every ribosomal hibernation factor previously discovered physically blocks the ribosome’s A site, so any protein-making process that’s in progress must be completed before the factor can attach to turn off the ribosome. Balon, on the other hand, binds near but not across the channel, which allows it to come and go regardless of what the ribosome is doing. Despite Balon’s mechanistic novelty, it’s an exceedingly common protein. Once it was identified, Helena-Bueno and Melnikov found genetic relatives of Balon in upward of 20% of all the bacterial genomes cataloged in public databases. With help from Mariia Rybak, a molecular biologist at the University of Texas Medical Branch, they characterized two of these alternate bacterial proteins: one from the human pathogen Mycobacterium tuberculosis, which causes tuberculosis, and another in Thermus thermophilus, which lives in the last place you’d catch P. urativorans — in ultra-hot underwater thermal vents. Both proteins also bind to the ribosome’s A site, suggesting that at least some of these genetic relatives act similarly to Balon in other bacterial species. Balon is notably absent from Escherichia coli and Staphylococcus aureus, the two most commonly studied bacteria and the most widely used models for cellular dormancy. By focusing on just a few lab organisms, scientists had missed a widespread hibernation tactic, Helena-Bueno said. “I tried to look into an under-studied corner of nature and happened to find something.” Everybody Hibernates Every cell needs the ability to go dormant and wait for its moment. The laboratory model bacterium E. coli has five separate modes of hibernating, Melnikov said, each of which on its own is sufficient to enable the microbe to survive a crisis. “Most microbes are starving,” said Ashley Shade, a microbiologist at the University of Lyon who was not involved in the new study. “They’re existing in a state of want. They’re not doubling. They’re not living their best life.” Most microbes are starving. They’re existing in a state of want. Ashley Shade, University of Lyon But dormancy is also necessary outside periods of starvation. Even in organisms, like most mammals, whose entire bodies do not go completely dormant, individual cellular populations must wait for the best time to activate. Human oocytes lie dormant for decades waiting to be fertilized. Human stem cells are born into the bone marrow and then go quiescent, waiting for the body to call out to them to grow and differentiate. Fibroblasts in nervous tissue, lymphocytes of the immune system, and hepatocytes in the liver all enter dormant, inactive, nondividing phases and reactivate later. “This is not something that’s unique to bacteria or archaea,” Lennon said. “Every organism in the tree of life has a way of achieving this strategy. They can pause their metabolism.” Bears hibernate. Herpes viruses lysogenize. Worms form a dauer stage. Insects enter diapause. Amphibians aestivate. Birds go into torpor. All of these are words for the exact same thing: a dormant state that organisms can reverse when conditions are favorable. “Before the invention of hibernation, the only way to live was to keep growing without interruptions,” Melnikov said. “Putting life on pause is a luxury.” It’s also a type of population-level insurance. Some cells pursue dormancy by detecting environmental changes and responding accordingly. However, many bacteria use a stochastic strategy. “In randomly fluctuating environments, if you don’t go into dormancy sometimes, there’s a chance that the whole population will go extinct” through random encounters with disaster, Lennon said. In even the healthiest, happiest, fastest-growing cultures of E. coli, between 5% and 10% of the cells will nevertheless be dormant. They are the designated survivors who will live should something happen to their more active, vulnerable cousins. Related: Cellular Life, Death and Everything in Between How ‘Idle’ Egg Cells Defend Their DNA From Damage The Quest for Simple Rules to Build a Microbial Community In that sense, dormancy is a survival strategy for global catastrophes. That’s why Helena-Bueno studies hibernation. She’s interested in which species might remain stable despite climate change, which ones might be able to recover, and which cellular processes, like Balon-assisted hibernation, might help. More fundamentally, Melnikov and Helena-Bueno hope that the discovery of Balon and its ubiquity will help people reframe what is important in life. We all frequently go dormant, and many of us quite enjoy it. “We spend one-third of our life asleep, but we don’t talk about it at all,” Melnikov said. Instead of complaining about what we’re missing when we’re asleep, maybe we can experience it as a process that connects us to all life on Earth, including microbes sleeping deep in the Arctic permafrost. Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters By Dan Samorodnitsky Contributing Writer June 5, 2024 View PDF/Print Mode bacteriabiologycell biologycellsmicrobiologyproteinsAll topics Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article Cryptographers Discover a New Foundation for Quantum Secrecy",
    "commentLink": "https://news.ycombinator.com/item?id=40592575",
    "commentBody": "Most life on Earth is dormant, after pulling an 'emergency brake' (quantamagazine.org)254 points by mgl 17 hours agohidepastfavorite194 comments kylehotchkiss 15 hours ago> Karla Helena-Bueno discovered a common hibernation factor when she accidentally left an Arctic bacterium on ice for too long. I love how this story follows the magic pattern of so much of innovation and discovery - an accident. It's refreshingly human and not a mode of discovery that machine learning is going to completely take away from us. reply Karellen 8 hours agoparent> The most exciting phrase to hear in science, the one that heralds new discoveries, is not \"Eureka!\" (I found it!) but \"That's funny...\" -- commonly attributed to Isaac Asimov reply neutronicus 2 hours agorootparentAs a one-time scientist, I think Asimov may have been tricked by extreme selection bias on \"That's funny...\" utterances. It almost always precedes a crushing realization that you have fucked something up and probably wasted a lot of time. You're probably days down exploring that explanation before the eventual \"holy shit\" (that I never really had the benefit of experiencing). reply ASalazarMX 1 hour agoparentprevMaybe AI won't forget bacteria in the ice, but like us, it is really good at finding patterns, but at a massive scale. Instead of an accident it could find the hibernation mechanism from another angle. And if AGI becomes a thing, it might go \"Hey, this is funny\" in weird ways after it has ingested enough data. I love the novel Colossus because almost 60 years ago it portayed realistically how a nascent AGI could behave: https://en.wikipedia.org/wiki/Colossus_(novel) reply COGlory 14 hours agoparentprevI'm all for it. People get lucky, then try to rationalize the past with a skill narrative. Then they soak up all the grants. reply dghlsakjg 14 hours agorootparent> People get lucky, then try to rationalize the past with a skill narrative. Then they soak up all the grants. They have to put themselves in the situation to get lucky first. This person got a graduate education, and was competent enough to be selected to be doing research in what is likely a multimillion dollar lab owned by an institution, then she had the knowledge and ability to notice and be able to identify what had \"accidentally\" happened with a micro-organism that we barely understand. Luck was the smallest part of this discovery. I would say that the grant money is well spent funding someone so \"lucky\". reply COGlory 13 hours agorootparentEveryone in science works hard. Only a few get lucky. People get scooped every day. Source: spent years looking hard for hibernation promotion factor in P. aeruginosa ribosomes via cryo-EM. Got a PhD and worked a whole lot of 16 hour days. Never got lucky. reply brg 13 hours agorootparentIf this story were at all true, then you know very well that not everyone in science works hard. In my graduate cohort, those who did the sets first year, set themselves into research, and worked hard graduated. Those who did not left with a masters, although many found success in other fields. It was quite clearly delineated. reply COGlory 12 hours agorootparentI'm talking about at the PI level. And yes of course a few people don't work hard, but the overwhelming majority do not differentiate themselves by how hard they work, is the point I'm trying to make. Your average PI has the skill set to take advantage of getting lucky. Not sure what you're insinuating about the story not being true, would you like to see maps? reply freilanzer 9 hours agorootparentprevAre you saying that people with a masters degree don't work hard? reply lukan 6 hours agorootparentI know some worked very hard, to not work very hard anymore. reply mistercheph 7 hours agorootparentprevMany work hard designing and assembling perpetual motion machines reply withinboredom 3 hours agorootparentI can understand why, it's clearly possible. Just look at the galaxies moving away from us faster than the speed of light. Anything is possible, if you work out the magic. reply AnimalMuppet 3 hours agorootparentBut, see, that's the problem. I can't look at them... reply John23832 4 hours agorootparentprev> People get lucky, then try to rationalize the past with a skill narrative. This is literally the opposite of the situation put forth in the article. Accidental discoveries are accidental discoveries. > Then they soak up all the grants. What use does a machine learning model have for a grant? This seems like something that is uniquely useful to humans. reply bregma 8 hours agorootparentprevAh, but serendipity favours the prepared mind. reply COGlory 4 hours agorootparentI agree with this - but there's far more prepared minds than serendipity, and I think the mistake we make is assuming people can control that serendipity aspect to produce repeat performances. reply dojomouse 15 hours agoparentprevI think ML is likely to be material to us making many more such discoveries. So much of the current constraint is not in the knowledge to identify the interesting pattern, but the capacity to look for it at scale. reply grugagag 15 hours agorootparentYeah but you missed the point op was making reply markburns 14 hours agorootparentThat seems an uncharitable view of the reply. The search space is huge, we sometimes find needles in haystacks by accident, isn’t it exciting that we have tools now that can systematically check every piece of hay? reply richrichie 14 hours agorootparentML search is more about ‘averages’ based on samples. Innovations like these are more about ‘shocks’ that surface fitting cannot capture. Note universal approximation theorem applies only to smooth surfaces. reply tomrod 14 hours agorootparentNot always. Quantile regression exists. And you can develop \"no match\" categories. reply richrichie 4 hours agorootparentQuantile regression is also about averages. reply radarsat1 12 hours agorootparentprevBut the better the mean surface is fitted (in a generizable way), the easier it is to spot outliers. reply kylehotchkiss 12 hours agorootparentprevWell said. reply dojomouse 10 hours agorootparentprevPerhaps. I was thinking along the lines of MarkBurns response - ML will allow us to efficiently look in those places we might otherwise only have searched by accident. If ops point was rather that “accident”/“luck” are uniquely human… I don’t agree. Luck is when probability works out in your favour - and that can happen all the time with any sort of probabilistic search, which is rife in ML. reply WalterBright 15 hours agoparentprevI've been reading \"The Making of the Atomic Bomb\". But it's really about the process of discovery in nuclear physics. And most of the discoveries were made by accident. reply kylehotchkiss 12 hours agorootparentStephen B Johnson's \"How we got to now\" was enlightening on the topic of discovery for me (https://www.pbssocal.org/shows/how-we-got-now) reply galaxyLogic 12 hours agorootparentprevBut if you don't study the math and physics hard, you will not be able to understand that you may have found something, valuable. It would be like Pearls Before Swine. reply micromacrofoot 4 hours agoparentprevnot necessarily, machine learning can make more accidents faster reply begueradj 13 hours agoprevThis reminds me of the fact that humans used to be able to hibernate (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1117993/) and (https://www.popularmechanics.com/science/a35033907/early-hum...) reply lukan 12 hours agoparentFrom glancing over, it does not really seem a confirmed fact, but a hypothesis. \"They chose to spend the worst part of the year trying to sleep through it inside of relatively safe caves, and to do that, they sacrificed nutrition and vitamin D from the sun.\" Also it does not really matter for your vitamin D levels, if you are outside in winter in the north or in a cave. The sun is too low for the body to produce Vitamin D anyway (only the Inuit for example do not need sun, to produce Vitamin D btw. ) And that they lacked nutrition in winter can also just mean, that there simply was not much food in the winters, which is kind of expected, before humans developed storage and preservation technologies? reply seszett 11 hours agorootparent> only the Inuit for example do not need sun, to produce Vitamin D btw As far as I can tell, they need vitamin D just like any other life form and can only synthesise it from the sun, just like all other lifeforms on Earth. They might have adapted to reduced amounts of available vitamin D though[0], because they don't have much of it available to them in the first place and because there's really no other source than producing your own from the sun, or eating things that have produced it from the sun. So they have a vitamin D deficiency, but it's less severe than for most people. [0]https://www.erudit.org/en/journals/etudinuit/2016-v40-n2-etu... reply hyperthesis 10 hours agorootparentDon't they (traditionally) also have a much higher meat intake than average, which supplies vitamin D? reply amenhotep 6 hours agorootparentThey particularly prized whale and seal blubber - very good vitamin D sources. Also present in the livers of the fish they'd eat raw. reply dredmorbius 3 hours agorootparentprevHumans cannot synthesise vitamin D, but we can acquire it through diet from other sources, including particularly fresh fish, which are abundant in Inuit diets. Note that numerous of the sources listed here are fortified (that is, have additional vitamin D added), however it does occur naturally in some sources as well:reply legulere 2 hours agorootparent> The major natural source of vitamin D is synthesis of cholecalciferol in the lower layers of the epidermis of the skin, through a photochemical reaction with Ultraviolet B (UV-B) radiation from sun exposure or UV-B lamps.[ https://en.wikipedia.org/wiki/Vitamin_D reply ASalazarMX 1 hour agorootparentprevIt might seem like a cheat, but healthy humans can photosynthesize (metaphorically) vitamin D. It's one of the free lunches our bodies have, if you ignore sun damage. reply lukan 8 hours agorootparentprevI might have believed a urban legend then. I will look into that. reply yread 12 hours agoparentprevThat first article from BMJ 1900 reads a bit like Gulliver tales. The second article is about hominids 400k years ago, quite long ago reply rrr_oh_man 7 hours agorootparent400k years ago is not \"quite long ago\" on an evolutionary time scale. reply yread 7 hours agorootparentSure, when you're looking at bacteria vs humans these guys are like our twins. But these non-homo hominins were not even our ancestors, they are close to Denisovans https://www.nature.com/articles/nature12788 Our last common ancestor was ~990k years ago (table 1). That's quite long ago in human development reply piuantiderp 3 hours agoparentprevHigh serotonin, cold exposure, low sunlight. Almost makes you think one could hibernate. But then, to what purpose? Would likely shorten the lifespan, increase risk for cancer reply l2p 2 hours agorootparentSpace exploration seems like the obvious candidate to me. reply dools 15 hours agoprevDehydrate! reply mvc 1 hour agoprevSshhh. Noone tell the proles that it's perfectly natural to have a bit of slack where many individuals in complex systems are doing nothing and, far from being a leech on society, it is actually essential to keeping the overall system alive. reply rolandog 7 hours agoprevWow. This is nature's mechanism for lazy evaluation. reply AnimalMuppet 3 hours agoprevNobody seems to be mentioning the therapeutic possibilities. I'd love to be able to make a bacterial infection dormant. Or a tumor. reply tracker1 2 hours agoparentTumors might be difficult, since afaik, cancer cells aren't working correctly by definition. reply frenchyatwork 2 hours agorootparentAlso, the classic issue with tumors, is that they're your own body, and it's hard to selectively target them. Any treatment that hibernates tumor cells is likely hibernate normal cells, and be incompatible with life; unless you get really lucky. reply trenchgun 7 hours agoprevThat is not dead which can eternal lie, And with strange aeons even death may die reply surfingdino 12 hours agoprev> Instead of complaining about what we’re missing when we’re asleep, maybe we can experience it as a process that connects us to all life on Earth, including microbes sleeping deep in the Arctic permafrost. I'm quite happy to know that \"microbes sleeping deep in the Arctic permafrost\" are asleep. I'd rather not have to think what might happen when they wake up. reply geon 3 hours agoparentThey might start releasing enormous amounts of CO2 and methane. reply galaxyLogic 12 hours agoparentprevIt's an interesting idea, why do humans and other species sleep? Maybe it is simply because they can. If there's no good reason to be awake, then sleep. Save your energy for a better time to be awake. That doesn't answer why we have dreams however. reply Sharlin 12 hours agorootparentPeople literally die if they go long enough without sleep, and of course everybody knows the cognitive impairment that even a moderate amount of sleep debt causes. That said, saving energy is certainly one part of it – and what else could a diurnal species do in the darkness anyway? (And similarly for animals adapted to night or twilight activity). reply Moldoteck 9 hours agoparentprevimo microbes/viruses carefully evolved after countless encounters of antibiotics and other stuff that we have now may have the same or greater danger level reply wdh505 15 hours agoprevI'm having visions of old people freezing their bodies and inducing \"dormancy\" so they can wake up when the world is a better place. I would invest in that company. reply onionisafruit 14 hours agoparentThe real trick is being somebody that a future generation will go to the trouble of defrosting. reply Jach 12 hours agorootparentIf we found a crypt of a hundred well-preserved mummies from a few thousand years ago who for all we could tell were basically peasants in their lifetimes, not grand or interesting people, and we had the ability to revive them into the modern world, I still think we would. The \"interest\" factor of future generations reviving cryonics customers when it's possible to do so is like the weakest factor in trying to predict whether cryonics will work at all. reply lukan 6 hours agorootparentBecause one crypt and some humans would be a curiosity. But a cluster of crypts containing thousands or even millions of those old weird people who will be likely just a burden to a way more advanced society? I am sceptical. reply wruza 10 hours agorootparentprevThe real trick is the world being a better place. reply shiroiushi 12 hours agorootparentprevThat's a fool's errand. The trick is to make sure your body is continually controlled by some kind of computer that will wake you up when a set of conditions is met, so you don't need to rely on future humans. You also need to make sure your cryopod is stored someplace where troublemakers won't find it and turn it off. The best thing I can think of is putting your cryopod in a lava tube on the Moon, powered by a small nuclear reactor or maybe a large RTG. reply lukan 12 hours agorootparent\"The best thing I can think of is putting your cryopod in a lava tube on the Moon, powered by a small nuclear reactor or maybe a large RTG.\" And then hope nothing critically fails for centuries ... Unless we have perfectionized robots by the time you go into the cryopod, you might as well bet on humans. And if we \"perfectionized robots\", that do not fail all the time, we already would have a very different world. reply shiroiushi 9 hours agorootparentRobots? We're talking about cryopods here, not something that needs a robot where you need to operate accurately in 3D space. It just needs an electronic control system to monitor conditions and control some machinery, similar to a washing machine or microwave oven. We already know how to make redundant computer control systems, like for aircraft. It's not that hard. They don't \"fail all the time\" either. Sure, your crappy Windows computer does, but no one with a brain uses that for anything safety-critical. reply lukan 7 hours agorootparentAnd you would trust that thing \"similar to a washing machine\" to run perfectly well for centuries? And not that hard? Are you aware of Murphy's law? Basically, give anything enough time and all the possible things that can go wrong, will go wrong. So your windows powered cyopod breaks after 1 year at most. And your embedded tiny verified OS manages 100 years, hurrey. But dead is dead. reply kolinko 12 hours agorootparentprevYou could have multiple failsafes, and after a part of them fail, you dehibernate automatically. We have systems that work well with such approach - planes being the most notable example - multiple redundancies, and when sth critical fails, you land asap. Works most of the time. reply krisoft 11 hours agorootparent> you dehibernate automatically You what now? :) I think you watched too many scifies and started to believe that the plot devices are reality. “Hybernation” is a thing in movies because the writers wanted to write stories involving humans and long space travel. It is not a working technology in reality. It might become one day, but your RTG powered cocoon is not going to invent and perfect it for you while you are asleep. reply lukan 12 hours agorootparentprevAnd then you wake up on the moon in a lava tube too early with a partly failing system and hope that everything else still somewhat works? With current technology level I definitely would rather bet on humans. reply hawski 11 hours agorootparentprevYou wake up in the middle of the moon and then what? reply gryfft 15 hours agoparentprevI mean, it's been going on for over fifty years[0]. 0. https://en.wikipedia.org/wiki/Alcor_Life_Extension_Foundatio... reply vajrabum 14 hours agoparentprevIt's still sci-fi I think but we're getting a bit closer. This came out the other day. https://news.ycombinator.com/item?id=40400591 reply lukan 12 hours agoparentprevIf too many not so old people would use it, the effects might be not great: https://xkcd.com/989/ reply darth_avocado 15 hours agoparentprevIt won't be very useful if you're already old, more practical approach would be to freeze yourself in your youth until they find a way to stop ageing. reply Nicholas_C 15 hours agorootparentYou could unfreeze yourself when they figure out how to reverse aging. reply darth_avocado 13 hours agorootparentReversing maybe harder than slowing and you would have to wait longer. reply jrflowers 13 hours agorootparentprevHow does one unfreeze oneself reply exe34 12 hours agorootparentVery slowly, to avoid the crystals forming suddenly. reply darth_avocado 2 hours agorootparentI think microwave is the answer. Though you may end up with a cold heart. reply aitchnyu 13 hours agoparentprevWhat does science say? I strongly believe what freezes the body will (not just figuratively) pull the plug on the brain. reply bamboozled 14 hours agoparentprevYou don't need to freeze yourself, you just have children, that is how life goes on. reply shiroiushi 12 hours agorootparentJust ask any parent who had worthless kids how well that works out in practice. Sure, you might get lucky and have good kids, but lots of parents don't, and it's not always their fault. reply bamboozled 8 hours agorootparentTheir kids might be really nice? reply TeMPOraL 13 hours agorootparentprevPart of life, yes. Just not the part we care about. reply phito 13 hours agorootparentprevThat's completely different? reply ineedaj0b 12 hours agorootparentsadly not as much as you think. if you have siblings with children and they get older hang out with them. the similarities will worry you reply mock-possum 10 hours agorootparentprevMy concern is more with my life, not life itself. reply bamboozled 8 hours agorootparentWell, it's not a permanent thing apparently. reply bmitc 12 hours agoparentprevI'd short it. reply sgt_bilko 13 hours agoprevMakes me wonder if organisms on Mars (if they ever existed) used such a mechanism reply xyst 12 hours agoprevTo me, seems like this is what we describe today as a “comatose” state. Is the individual “brain dead” or did the person sustain so much damage that it required an “emergency brake”. The body and mind is healing itself but today’s scientists and doctors cannot fully quantify it. Only using “primitive” tools (EEGs, CT, MRI) which only allow us to see through a tiny keyhole of what is a vast number of possibilities. reply krisoft 11 hours agoparent> To me, seems like this is what we describe today as a “comatose” state. Is the individual “brain dead” or did the person sustain so much damage that it required an “emergency brake”. I’m not sure what you are talking about, but “comatose” and “brain dead” are two very different states. If you are brain dead you are not comatose. reply wayoverthecloud 13 hours agoprevWhen you get caught up on the hustle of modern society and lose yourself in modern technology, it's so easy to forget that you are a part of a larger whole and there is more life on Earth besides human. For some reason knowing that other animals exist just for the sake of existing and even sleep off when life gets harder gives a new perspective. I feel that we humans use too much knowledge and complicate problems even when there's a simple solution. I think that our bodies are highly intelligent and humans intrude a lot in it's natural functioning by inventing too much techniques and methods. Like I want to stay awake, drink coffee. Drink coffee, get insomnia. Insomnia leads to unhappiness. Take insomnia meds, get withdrawals. Generating more problems along the way while forgetting what the solutions were even for in the first place. If we just listened to our bodies signs, it pretty much tells us why you you are lethargic and need coffee in the first place. Sometimes we should just trust nature to do it's work. This article was a refreshing read. reply leobg 10 hours agoparentHad a very similar thought this morning. With the amount of technology today, we should be the happiest, wealthiest generation alive. My grandmother, born in the 1920s, still experienced hunger as a child, fled from the Russians through the ruins of bombed out cities, and, up until not too long ago, had to make a fire in order to have warm water for the bathtub. But I’ve never heard the word “depression” from her even once. Then you look at today’s younger generations, and you see it everywhere. When you bought a roll of bread 40 years ago, you would be entering a shop owned by the baker. You would be getting a roll that was made by hand with local ingredients. And the woman at the counter would be friendly and relaxed, and she would be earning enough doing this simple job to have a normal family. Today, when I want to buy a roll, I enter a shop that heats up rolls that they get from an industrial scale bakery. It costs about 5 to 10 times as much. And the woman standing at the counter is of the lowest socioeconomic status, because the salary she gets for her work is barely enough to afford her some tiny apartment. I would be able to except that many things just don’t change, and every generation has its problems. But if we believe the mantra that progress in technology makes us happier and wealthier than those that came before, I think we’re kidding ourselves. That, to me, seems more and more like a modern form of organized religion. And I’m not sure who the priests are. reply kasey_junk 6 hours agorootparentAt least as measured by suicide rates in the US your grandmothers likely generation new quite well what depression was even if the word didn’t matter. Between the 1920s and the end of WW2 the suicide rate per 100000 was lowest at 15 but reached almost 22. The pandemic rate which caused (rightly) lots of angst and introspection was 14.3. We should investigate what is causing increased levels of depression currently but we shouldn’t assume it was absent in other generations when we do it. https://jabberwocking.com/raw-data-us-suicide-rates-since-19... reply leobg 5 hours agorootparentPoint taken. Can’t get more textbook survivorship bias. :) reply xhevahir 4 hours agorootparentprev> At least as measured by suicide rates in the US your grandmothers likely generation new quite well what depression was even if the word didn’t matter. They knew what suffering was, and arguably did more of it. But very few of them thought of it as a primarily medical problem, one requiring intervention by professionals, medicine, and so on. People who think of their problems in this newer way handle them differently, and not always better. reply hxriv 6 hours agorootparentprevShould have let the op continue their victim blaming tirade. Was just getting good. reply karmakurtisaani 5 hours agorootparentprevI think there are 2 aspects to the anecdote about your grandma. Firstly, no one spoke about depression, because it as a condition was not recognized. It doesn't mean people didn't feel depressed. Secondly, this time supporting your argument, perhaps when people go through terrible things in their childhood, they grow resilient towards adversity. If you know things can get a lot worse, you don't really worry about minor things. reply throwawaycities 4 hours agorootparentprevI think there is a lot to unpack in your anecdote about the baker vis-a-vis happiness vs proliferation of depression in modern life. If I had to summarize my own thoughts about it, it’s ownership, community/relationships, and hardships/challenges that can be overcome through hard work. Modern technology counter intuitively gives us very little agency everything is owned by faceless/soulless corporations, technology “connects us” in unparalleled ways but also isolates us, and while life has and likely will always be hard for the majority there is a feeling of invisible prisons enabled through technology that no amount of hard work can overcome. reply leobg 4 hours agorootparentI agree. Especially the ownership thing. Tangent: I remember my mother, in the 1980s, getting a parking ticket. So she had to go to the local police officer. We were a tiny town, a village almost. But there was a police station. And the officer was in charge of this case. He talked to my mother. She explained. And he ended up saying that in this case, he’d be willing to make an exception. Fast forward to today. I drive to school in the morning. There’s a van at the side of the road. It’s not even police; some kind of contractor. Out on the road, there’s a fancy radar/speed trap thing. They probably paid €100,000 of taxpayer money for it, plus a servicing contract. Were probably promised that it’s gonna pay for itself within two years. And now the two dudes sit inside the van. The machine is doing the work. Tickets are being sent out automatically by a computer system. And there is literally nobody who owns the process. It is an abstract machinery, turning citizens into objects. My mother and the policeman, as a result of the encounter, had reached an understanding. They became partners in the higher principle. There was a true connection between the citizens and the state. The state had a face, and there was a local representative who was in charge. Today, the state has no face. Even the judges in the legal system just act as tiny wheels in the machinery. It’s hard to find anyone whoever owns anything. Much less owns up to anything. reply throwawaycities 3 hours agorootparentThe opening scene of American Gangster Denzel Washington’s character is the driver/right hand man for Bumpy Johnson. They go into a store and Bumpy has a heart attack, Denzel calls for help, and Bumpy just says “forget it frank, there’s no one in charge.” And so it is when PayPal or coinbase accounts get frozen, or social media accounts get suspended without notice or explanation, Gmail accounts get hacked or deleted in freak occurrences. Good luck getting any help, there’s no one in charge, the best you can hope for is social media shamming which only works when you already have influence. reply iamEAP 6 hours agorootparentprev> But I’ve never heard the word “depression” from her even once. Then you look at today’s younger generations, and you see it everywhere. Reminds me of Act 2 from this “This American Life” episode. Sub “Toska” for “depression” and maybe you’ll see things in a different light. https://www.thisamericanlife.org/822/transcript reply confidantlake 4 hours agorootparentprevWhile I agree with what a lot of what you said, there is a lot of survivorship bias in a single anecedote. My Grandma also has a very similar story, born in 1920s, fled from the Russians, no depression. But there is family from the same time period that committed suicide. Then for every one suicide there were 10 people that lived out of the bottle. So even though no one talked about depression it was there. reply leobg 4 hours agorootparentIs she still alive? I can recommend interviewing her about the past and recording it. There may come a time where you will be glad to have those recordings. Or your children/grandchildren. Also, given the right prompting, you may learn things about her that you have never seen before. reply confidantlake 2 hours agorootparentShe is, and mentally very sharp too. That is a great idea, will do that. reply soco 10 hours agorootparentprevMaybe it's not about the things we have, but about the hope we have. You run away, you change, you survive things because you have hope in a better future. You even work to make a better future for your kids. You have hope. What hope have those people today? reply ffsm8 9 hours agorootparentOr phrased differently: she struggled for her survival. It's a very physical one-off challenge that you can master (or not). That's inherently very different to realizing that the golden era has basically passed and it's only gonna get worse from here, societally speaking. None of the inherent issues our societies has had were solved. They've just become worse with every decade, inequality in particular has gotten worse with every technological advance, and it'd expect it to get meaningfully worse with LLMs now, too. A select few will still get meaningfully richer, but - on average - their prospects for their future are a complete dumpster fire. You (leobg) are likely right that people a few hundred years ago probably wouldn't have become depressed like Gen Z, Alpha and likely soon Beta too... But they'd probably long since taken up their arms, wiping out a good chunk of the population and consequently redistributing wealth to the survivers. Do you honestly think that'd be better for us? reply WJW 9 hours agorootparentHistorically, the people taking up arms certainly did NOT distribute wealth if they won. Rather, the leaders of any successful rebellion just became the new elite and the poor remained the poor but with new leadership. reply ffsm8 7 hours agorootparentYou're looking at it very 1-dimensionally. The war leaders certainly didn't literally distribute wealth to the conscripted people. Instead you had plundering, with the winners simply taking things and the dead were ... Well, outta the picture, consequently the survivors had the opportunity to become skilled craftsman and marry after their return, as most didn't survive (even if their side won). Let's say a farmer family's children were all conscripted. 5 left and 2 returned. Before the war, 4 had few prospects. After the war, both will have prospects, one to succeed the farm and the other one as the husband to another farm that didn't have anyone return. reply octopoc 7 hours agorootparentprevThat’s not how it was among the Germanic peoples at least. They followed people who were called “gold-giver”. It was seen as the responsibility of the leader to bring wealth to his followers in exchange for their loyalty and courage. I think Christianity changed that expectation to some degree. reply jsjohnst 7 hours agorootparent> It was seen as the responsibility of the leader to bring wealth to his followers in exchange for their loyalty and courage. Replace the word wealth with prosperity and the same applies for your later example. The leader is just someone you can’t see, touch, or hear so is harder to displace. reply leobg 5 hours agorootparentprevYou mean like kids looking forward to growing up. But once you’re grown up, or even old, there just isn’t anything to look forward to anymore? reply pwillia7 5 hours agorootparentprevMaybe this is just because we culturally overvalue the individual. Maybe technology helps us survive and have 'more' on a macro level but causes problems on a micro level, and maybe we are more geared 'naturally' than we believe to sacrifice our micro for a good human macro. I think about ants that sacrifice themselves for the good of the colony, surely without the same reasoning we would do something similar for[1]. [1]: https://www.science.org/content/article/exploding-ants-sacri... reply leobg 4 hours agorootparentLeo Tolstoy, What I Believe: Just like the winegrowers, who, living in a garden not cultivated by them, had to understand and feel that they were in immeasurable debt to the landlord, people must also understand and feel that from the day of their birth until their death, they are always in immeasurable debt to someone: to those who lived before them, to their contemporaries, and to those yet to come; to that which was, is, and will be the beginning of everything. They must understand that with every hour of their life, as they accept life, they reinforce this obligation that binds them to life and its origin, and that therefore, the person who denies this obligation and lives for themselves, in trying to preserve their personal life, ultimately destroys it. This is precisely what Christ repeated many times. The true life is only that which continues the past life and contributes to the salvation of the present and future life. reply ses1984 4 hours agorootparentprevEvolutionary biology and game theory can offer insight here. Ants are genetically identical which drives this behavior. reply pwillia7 49 minutes agorootparentInteresting! I didn't know that reply WJW 9 hours agorootparentprev> With the amount of technology today, we should be the happiestgeneration alive. Only if you think that wealth is what makes people happy, but we just need to take a look at all the unhappy wealthy people all around us to see that that is not the case. Poverty can make people unhappy of course, especially the stress that comes from uncertainty. But prosperity alone is not sufficient for happiness. Generations of social researchers and philosophers have thrown themselves at this problem. reply Almondsetat 8 hours agorootparentWhere did you get the \"amount of technology\" = \"wealth\" from parent's comment? With the current amount of technology we could put a roof over people's head, provide clean water and safe foods and medicines. This has nothing to do with owning a Lamborghini or eating a Michelin star restaurant, which would indeed count as superfluous wealth that doesn't actually improve happiness. reply prewett 5 hours agorootparentTechnology makes possible things cheaper and impossible things possible, which is a form of wealth. At any rate, both money and technology can make us materially comfortable. But the reason “money can’t buy happiness” is that a large part of happiness comes from connections with people, to society, and perhaps even to nature. Another large part comes from one’s meaning or purpose. Neither of those can be bought or technologied. reply dkdbejwi383 9 hours agorootparentprevI'd wager a lot of it comes down to the difference between material wealth vs. a wealth of time. That's the one thing money can't buy. reply histriosum 6 hours agorootparentExcept that money DOES buy time. When I have money, I can convert it to time to do things I enjoy. When I don't have money, I need to spend my time to get money in order to survive. I find the statement that \"money can't buy time\" something that only a fairly wealthy person would believe, and not at all accurate in practice. reply robertlagrant 6 hours agorootparent> I find the statement that \"money can't buy time\" something that only a fairly wealthy person would believe, and not at all accurate in practice. Most people with money are old, because that's how you get money in general: provide value over a long period of time. But they would probably all trade that money for being 22 again, and having a lifetime ahead. reply histriosum 4 hours agorootparentI would agree with the statement that money can't buy time that has already passed, because nothing can do that. Money can definitely buy time in the present moment, though. reply prewett 5 hours agorootparentprevSomeone asked a substitute teacher if she would make that trade, and she said she wouldn’t, not unless she could retain what she knew now. So, buy a renewed youth? Sure. But do 22 again as a 22 year old? Nope. Now that I’m “over the hill”, I see what she meant. Being 44 is similar to the difference between 11 and 22; not as drastic, but the stuff I understand about life I would not even be able to communicate to 22 year old me. Definitely would not want to relive my 20s. “Life starts at 40” is not just cope, there’s some truth in there, too. reply robertlagrant 3 hours agorootparentYes, but you're not 70 and wealthy. 44 is still pretty young[0]. [0] this may be cope reply j0hnyl 5 hours agorootparentprev\"With the amount of technology today, we should be the happiest, wealthiest generation alive.\" I actually think we are. reply fardinahsan 7 hours agorootparentprevThis is overly simplistic thinking. Of Course increases in technology isn't the only factor determining aggregate societal well being or happiness or whatever. But it would be naive and disingenuous to suggest anything other than it being monotonic at the very least. This also asks for a search for better social technology, as opposed to asserting that we must slow down the search for better physical technology because the social technology isn't keeping up. reply Chris2048 6 hours agorootparentprev> It costs about 5 to 10 times as much. Is that true, the mass produced bread is more expensive? reply leobg 5 hours agorootparentDifficult to calculate, with inflation and everything. But I do remember from the 1980s that a roll of bread was ~2 Euro cents (5 Pfennig), nominally. And now it’s ~20. With industrial baking, modern fertilizers, farming automation, global container shipping, and all of that, one would reasonably expect it to have gotten significantly cheaper. reply nunez 5 hours agoparentprev> I think that our bodies are highly intelligent and humans intrude a lot in it's natural functioning by inventing too much techniques and methods. Like I want to stay awake, drink coffee. Drink coffee, get insomnia. Insomnia leads to unhappiness. Take insomnia meds, get withdrawals. Generating more problems along the way while forgetting what the solutions were even for in the first place. If we just listened to our bodies signs, it pretty much tells us why you you are lethargic and need coffee in the first place. This has come into hyper clarity for me ever since transitioning to minimalist shoes/sandals ten years ago and foregoing all caffeinated beverages this past December. It's actually quite insane to think about how accessible coffee is and how much of our modern economy relies on people consuming it. Consulting, big law, investment banks and lots of blue collar jobs (for example) rely on workers pulling 12+ hour days to do what mostly amounts to eye-watering amounts of paperwork. Given that sleep naturally becomes an afterthought when working under these conditions and showing any signs of weakness is frowned upon, coffee, sodas and energy drinks are all but required to function. Similar deal with shoes. Feet are incredibly complex systems that are designed to withstand lots of abuse. Unfortunately, big shoe companies built their fortunes off of selling shoes that are great for sports but terrible for everyday use. Instead of pushing more minimal shoes that counteract weakening feet while being simpler to make, they push orthotics and shoes with more advanced technology and thicker sole stack. It's depressing to think about, so I try not to! reply digging 1 hour agorootparentCaffeine isn't an invention of modern industrial society, we've been boiling every caffeinated plant we could find for thousands of years. I would still drink it if I didn't have to work for a corporate employer. In fact I enjoy it much more on my days off when I get to make art. I don't mean to get too defensive of it, but I find it quite strange when people lump caffeinated drinks in with completely artificial aspects of life. reply lumb63 5 hours agorootparentprev+1 for minimalist footwear. I keep telling anyone who will listen, “isn’t it crazy that we don’t have foot shaped shoes?” And then we wonder why we have bunions, knee pain, and tight hips when we sit sedentary at a desk all day in our not-foot-shaped shoes. I highly recommend reading The Technological Society by Jacques Ellul. It was written in the ‘60s about how technology influences the direction of humanity and all the unintended consequences that come from that, and how we turn to more technology to solve those problems. It was a very prescient book. reply gavmor 4 hours agorootparentIn that vein, I highly recommend Katy Bowman's \"Move Your DNA,\" and \"Whole Body Barefoot.\" Bowman's biomechanical analysis of modern movement, furniture, and the built environment has changed the way I walk, sit, and carry things. reply figassis 11 hours agoparentprevWe invented technology and methods to make things that are meant to be difficult, easy (like food, transportation, mating, surviving). So now we have to invent more technology and methods to find an equilibrium for the system that we broke and barely understand, so we continue to break it and abstract away the instability, understanding it less and less. I mean, what is the purpose of the stock market? housing/mortgage market? An upvote? The cookie banner and ad tracking industry? reply NilMostChill 9 hours agorootparent- Maintaining and increasing high level wealth, also Control - Control, also profit - Control, albeit in a less direct form than housing also data and profit - The pretense of caring about privacy issues, so politics and control - Profit/control If you ask, \"why?\" for almost anything in today's society it'll come down to money/power, which are functionally mostly the same thing. Exceptions exist sure, but they are called exceptions for a reason. My perspective at least, i'm sure others think differently. reply ambientenv 8 hours agoparentprevThere's some further thought-provoking discussion in a recent conversation with Daniel Scmachtenberger [1] talking about what you suggest. [1] Moving from Naive to Authentic Progress: A Vision for Betterment - https://youtu.be/tmusbHBKW84 reply ReptileMan 10 hours agoparentprev>it's so easy to forget that you are a part of a larger whole and there is more life on Earth besides human. Humans actually utilize quite a big chunk of the biomass. reply HPsquared 9 hours agorootparentIt depends how you count it, whether you include plants etc. Humans are only 0.01% of all biomass, but humans and livestock completely dominate the \"mammals\" category. Funnily enough, the livestock population weighs about twice as much as the human population. reply adrian_b 6 hours agorootparentHumans and livestock completely dominate not only the \"mammals\" category, but the entire \"terrestrial vertebrates\" category. There are only a few other terrestrial animals of comparable biomass with humans, e.g. ants and termites. reply therein 13 hours agoparentprevI don't quote The Bible often but I think we can have some space for a quote here: \"Look at the birds of the air; they do not sow or reap or store away in barns, and yet your heavenly Father feeds them. Are you not much more valuable than they?\" Matthew 6:26 reply fire_lake 12 hours agorootparentA systematic study of birds would find that many do indeed starve to death. reply Modified3019 7 hours agorootparentAnd quickly too, the small ones live on a metabolic knife edge and can go down in as little as two days. Here in the valley of Oregon, we don’t get snow often or for very long, but one late winter/early spring we suddenly got 1-2 feet snow cover for at least 3 days. I’ll never forget the few dozen birds I saw dead on the side of the roads because they couldn’t get to food. reply graemep 10 hours agorootparentprevSo do people - at least those lucky enough not to be part of a reasonably affluent industrial society. You do realise that metaphors are never perfect? reply jonplackett 11 hours agorootparentprevI do enjoy scientific debunkment of religious quotes. After the Notre Dam fire someone on Twitter was claiming a miracle because the golden (statues I think?) had survived. Someone then pointed out that the melting point of gold is several hundred degrees above the temperature of a wood fire. reply Y_Y 8 hours agorootparent> melting point of gold is several hundred degrees above the temperature of a wood fire A grand miracle indeed reply lm28469 11 hours agorootparentprevIs the goal of humanity to replicate infinitely and love as long as possible regardless of anything else ? Because that's what cancers do and it never end well for the host reply dukeyukey 8 hours agorootparentTo a point, yes. That's the goal of practically any living thing, including cancer. reply lukas099 6 hours agorootparentprevI don't think anyone said or implied that reply mrguyorama 3 hours agorootparentprevIn what way does cancer \"love\"? reply flakeoil 12 hours agorootparentprevI'm curious, what does that quote really mean? I can attempt to draw a few conclusions, but I'm not quite sure of either and they can also almost be the opposite of each other. reply batch12 6 hours agorootparentMost verses aren't intended to be read alone, they weren't written that way originally. The indexes were added later. The whole section (25-34) is about not worrying. With the summary being \"Therefore do not worry about tomorrow, for tomorrow will worry about itself. Each day has enough trouble of its own.\" reply maxbond 11 hours agorootparentprevI don't know that I know what it means, but I'll tell you a thought it brought to mind. A while ago I was having a discussion, and someone asserted that synthetic fertilizers are necessary because composting doesn't scale. And my reaction was, surely composting scales to an entire biosphere - like, empirically we know this, right? There was a massive biosphere long before there was a Fritz Haber. Surely it's that we don't have the required technology and wisdom to create supply chains that can run as closed loops and accept inputs that aren't so rich and concentrated? I don't want to argue this point, there are definitely good counterarguments that could be made, but I'm just trying to illustrate the shift in perspective I think the commenter may have been going for rather than change the topic. reply krisoft 11 hours agorootparent> surely composting scales to an entire biosphere By definition, yes. > There was a massive biosphere long before there was a Fritz Haber. There are about five times more humans today than there were when Fritz Haber invented his process. The question is not “will there be an ecosystem”. Of course there will be. The question is are you ok with 4 out of 5 person potentially starving to death. > Surely it's that we don't have the required technology and wisdom… Synthetic fertilizers is the required technology and accepting that is the wisdom. reply maxbond 11 hours agorootparent> Synthetic fertilizers is the required technology and accepting that is the wisdom. Again, I don't want to get into a debate about agriculture, I'm trying to discuss the quote, but these are the types of assumptions I'm suggesting are worth questioning. The question is, are there ways to exert less control and get better outcomes? I'm not suggesting we let 80% of people starve. I'm suggesting we not be obsequious to the logic of the technology we've already built, when deciding on what to build next. (I elaborate in a cousin comment.) Consider that in the extreme, if you have a linear supply chain with Haber-Bosch on one end and a landfill on the other - when you scale to enough people, you will also have mass starvation. Haber-Bosch isn't a \"wisdom we accept\" or \"the\" definitive technology. It has tremendous application, but it isn't magic. We're not simply done innovating in this area. reply Scarblac 11 hours agorootparentprevThe argument doesn't quite work imo because farmers are actively working against the normal ecosystem - we don't want the normal plants to grow there, we want our desired crops. With enough production for us to feed the world and to give farmers a living wage. I still think it's doable (but not if we also want to feed many times our mass in lifestock), but it's not easy. reply maxbond 11 hours agorootparentI don't want to argue the point (but I also am not dismissing your points, the position I put forward is definitely not unassailable), but I think there's an opportunity to make my original point better here, which is; sometimes we get trapped in the logic of our own systems and fail to think outside the box. Is it monoculture or low-N culture really required? Or is it a local optimum we lack the imagination to see beyond? What got you here might not get you there. You can go really far with a monolithic web app running on top of a relational database. But if you scale far enough, you'll need to pull some pieces out and hook them up to databases with relaxed constraints. There are good engineering reasons for us to do things the way we do them, and maybe it was the only feasible way for us to get to this point. But presumably if we continue to grow, we will enter a different phase with a different set of tradeoffs. That phase will probably involve exerting less control, it will probably also involve worse unit economics, but may also scale further with fewer externalities. reply hawski 11 hours agorootparentprevFarmers also want to have a large swaths of a monoculture plant, because it is easy then to mechanize. That goes, as you say, against the normal ecosystem. Permaculture gardens look much different, but you can't easily mechanize that. reply Scarblac 5 hours agorootparentYes, and the more manual labor it needs, the more time intensive it is, the harder it is for someone to make a living. reply js6i 11 hours agorootparentprevIt's interesting how people come and mock without having any framework of understanding the thing. It's almost like a lost language. Consider air - it is immaterial, the spirit/principle/reason/meaning/pattern of things. It's also the vehicle for speech, and when we stop breathing it we die. I don't think the quote (or the broader text) means a single concrete thing - it's saying something about how the world works, and should be applicable in multiple ways. Under appreciated rabbit hole! reply soco 10 hours agorootparentMaybe they do have a framework, allowing them to mock it? There must be a reason why there are so many holy writings on this remote little planet. reply wruza 10 hours agorootparentprevA purpose of a religious text is to control people. They do that through well-known ways. It says “blah-blah, but look at this fallacy you aren’t aware of, so believe in god”, at different zoom levels. Every one of these is trivially deconstructible cause their main target was uneducated masses which had no scrutiny. Those who had it were religiously “educated” and accounted for. Religions that didn’t do that didn’t survive. That’s the framework of understanding. This thing wasn’t written by “god”, it’s a work of a few scammers, sadly the biggest in our history. reply js6i 9 hours agorootparentIt seems to me that your stand is analogous to anarchists' about law and government. Sure, there's a tyrannical aspect that can get out of hand, but it's far from the whole story. reply wruza 9 hours agorootparentI don’t think this is a good analogy, since laws and government don’t tell you how the world works, it’s either observable without explanation or left unexplained. In religion there’s no whole story, it all made up. It may contain some real life parts, but it could do so without religious parts. Real life stories doesn’t make it more credible in sentences containing “god”. In fact, the quote of this subthread is wrong, false, debunked. There’s no need to look at it in context, cause whatever role it plays in it can’t make it look good. Looking at falsehoods “in context” and referring to “deeper knowledge and proper understanding” is a beloved theme of religious manipulation. reply js6i 9 hours agorootparentI think the disconnect is that you seem to consider religious texts as a dry statements of fact. That doesn't make any sense, they're clearly not that. Would you say the same about great works of fiction, or old fairy tales that for some reason keep grabbing our attention and we repeat them for generations? That they're just falsehoods because duh, frogs obviously can't talk? Or can they have some deeper meaning? Stating facts is not the only way to describe the world. reply Chris2048 5 hours agorootparent> Would you say the same about great works of fiction, or old fairy tales Do you thing religious followers, such as Matthew, see god/heaven/etc as being merely a metaphor? > That they're just falsehoods because duh per previous poster: \"laws and government don’t tell you how the world works\" works of fiction doesn't purport to either. They might have morals, or subtexts, as much of the contents of the Bible does - but some things in there are meant to be at least partially literal, such as the existence of a divine being that created the world. What's the greater message behind \"God takes care of lesser creatures\" when there's no proof of such a thing? That things will generally turn out alright if you don't plan ahead (demonstratably bad advice).. reply js6i 3 hours agorootparent> Do you thing religious followers, such as Matthew, see god/heaven/etc as being merely a metaphor? No, I'm not suggesting that. The alternatives to just reporting facts are more than \"merely a metaphor\". > works of fiction doesn't purport to either. They might have morals, or subtexts Disagree - I think they distill patterns from the factual and present them in the form of stories, encoded in the structure of the story. If you're a materialist you might say that the story is less true than the factual manifestations of the patterns, I'd say it's more true; and that it's telling something about the world. > What's the greater message We're debating if zero even exists, don't ask me about analysis ;) reply batch12 6 hours agorootparentprevActually the purpose of that whole chapter is about not being a hypocrite, being authentic, not being greedy, and having faith. It's a quickPlease don't post insinuations about astroturfing, shilling, brigading, foreign agents, and the like. It degrades discussion and is usually mistaken. If you're worried about abuse, email hn@ycombinator.com and we'll look at the data. And adhere to that culture before complaining about others reply lolinder 6 hours agorootparent> And adhere to that culture before complaining about others Indeed! One might even say \"you hypocrite, first take the plank out of your own eye, and then you will see clearly to remove the speck from your brother’s eye.\" reply mrguyorama 2 hours agorootparentprevAnd of course because we are explicitly forbidden from talking about such a problem, it never happens, right? reply AnimalMuppet 2 hours agorootparentIt leads to an objectively worse discussion. People posting stuff, some of which people don't like, and some of which is astroturfing, shilling, brigading, foreign agents, and the like, is a better discussion than all of that plus people accusing everything they disagree with of being astroturfing, shilling, brigading, and foreign agents - especially since the accusations are, at best, imperfectly correlated with the reality. reply graemep 9 hours agorootparentprevThe reason is that there are huge amounts of religious texts, and what they record people's understanding of the world, grappling with the problems in their lives, and trying to make sense of their experiences: they are about being human. If you are open minded about/not hostile to religion (in general or a particular religion) you will find a lot of wisdom in religious works. Not just \"scriptures\" but a lot else, written from ancient times to contemporary. reply MikeTheGreat 11 hours agorootparentprevWhat is the reddit fallout that happened last year? (I don't follow or read reddit, unless a search for something specific leads me to a particular page, so I'm clueless about this and curious to know more) reply moritzruth 11 hours agorootparenthttps://en.wikipedia.org/wiki/2023_Reddit_API_controversy reply therein 9 hours agorootparentprevI was born to a mostly non-religious Muslim family in a 99% Muslim country so I am not simply defaulting to my own creed here. reply lolinder 6 hours agorootparentIgnore the trolls and the downvoters, I appreciated the quote! reply crakenzak 12 hours agorootparentprevnext [2 more] [flagged] dukeyukey 10 hours agorootparentWhy do you assume OP is even religious? reply anal_reactor 11 hours agoparentprevnext [4 more] [flagged] maxbond 9 hours agorootparentGood luck with that. Try switching to audio. It'll let you close your eyes and properly recline. That's a lot of the battle right there. Something contentless like the sound of a waterfall is ideal, but if you can't do that for whatever reason, even something contentful like a podcast or audiobook is probably better then your phone screen. reply Der_Einzige 7 hours agorootparentprevhttps://i.kym-cdn.com/photos/images/newsfeed/002/147/220/bd8... reply anal_reactor 5 hours agorootparentExactly why I want to save money and then FIRE reply ssijak 12 hours agoprevCant wait to see what types of bacteria and viruses are dormant in permafrost that is thawing /s reply thimkerbell 3 hours agoprev [–] \"Biologists discovered a widespread protein that abruptly shuts down a cell’s activity — and turns it back on just as fast.\" Maybe we need this for dogs, so their lifespan isn't substantially squandered when their owners are at work. reply niemandhier 3 hours agoparentThis feels quite distopian. reply hnbad 1 hour agorootparentTurning your pets on and off to accomodate your lifestyle? Yeah, that doesn't sound great. I'm sure there'd be a huge market for it though. reply tracker1 2 hours agoparentprevIs the value of a dog's life subjectively tied to the enjoyment of the owner? May as well shut down when the owner is asleep too... or, get a robot dog instead. reply Ductapemaster 3 hours agoparentprev [–] You should check out a company called Loyal — they’re making lifespan increasing drugs for dogs of all sizes! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers have identified a protein named Balon that can rapidly halt and restart protein production in cells, aiding in dormancy.",
      "Balon is found in Arctic permafrost bacteria and other organisms, interrupting ribosomes mid-function to allow quick transitions into and out of dormancy.",
      "This protein is present in over 20% of bacterial genomes, highlighting its potential role in species' resilience to climate change and offering new insights into cellular adaptation and survival strategies."
    ],
    "commentSummary": [
      "Karla Helena-Bueno's accidental discovery of a hibernation factor in an Arctic bacterium underscores the role of serendipity in scientific breakthroughs, contrasting human intuition with machine learning's systematic approach.",
      "The discussion explores the potential of machine learning to enhance innovation, the feasibility of human hibernation and cryonics, and the evolutionary adaptations of Inuit populations.",
      "The text critiques modern life's complexities and societal pressures, emphasizing the importance of human connections, societal engagement, and a sense of purpose for true happiness over artificial solutions."
    ],
    "points": 254,
    "commentCount": 194,
    "retryCount": 0,
    "time": 1717638325
  },
  {
    "id": 40593674,
    "title": "Mitsubishi's TOKUFASTbot Sets New Record by Solving Rubik's Cube in 0.305 Seconds",
    "originLink": "https://soranews24.com/2024/05/28/mitsubishi-develops-robot-that-solves-rubiks-cube-style-puzzle-in-0-305-seconds%e3%80%90video%e3%80%91/",
    "originBody": "SoraNews24 -Japan News- Bringing you yesterday's news from Japan and Asia, today. RocketNews24 Japanese TOP » Japan » Mitsubishi develops robot that solves Rubik’s Cube-style puzzle in 0.305 seconds【Video】 Featured Weird Studio Ghibli Jobs Mitsubishi develops robot that solves Rubik’s Cube-style puzzle in 0.305 seconds【Video】 Master Blaster May 28, 2024 Tweet It’s literally faster than a speeding bullet. Since the dawn of humanity, we have strived to put nine squares of the same color onto a single side of a cube, which was really difficult prior to 1974 when the Rubik’s Cube was invented. But once that happened it became a race to accomplish it ever faster and more stylishly which has culminated in TOKUFASTbot by Mitsubishi Electric. This robot connects a servo motor to each side of the cube, capable of turning 90 degrees in 0.009 seconds. It’s also highly responsive to an AI color-identifying algorithm to solve the cube in record time. The above video demonstration shows a cube being solved in 0.204 seconds, but when Guinness World Records was called in to judge an attempt to break the existing record of 0.38 seconds different standards were set. As a result, TOKUFASTbot earned an official fastest time of 0.305 seconds which still handily beat the previous record. ▼ A video of the record-breaking run 正式発表です🌟三菱電機のチームがギネス世界記録「パズルキューブを最速で解くロボット」を更新㊗タイムはなんと0.305秒！記録達成、本当におめでとうございます🎉🎉🎉 pic.twitter.com/1X56qxR7RI — ギネス世界記録 (@GWRJapan) May 23, 2024 While the machine is extremely impressive, online comments were equally astounded by the cube which could withstand such fast turning. “They must have put a lot of oil on that cube.” “Anything faster than this will require ways of reducing friction in the cube.” “I’ve come to terms with the fact I’ll never solve one in my lifetime.” “So, what can they do with this?” “Precise motor control is the backbone of manufacturing.” “It’s a little faster than me.” “It must be difficult to turn 90 degrees that fast and stop in exactly the right place.” “They must have broken a lot of Rubik’s Cubes to get to this point.” According to Guinness, the first attempt was thwarted by a cube jam, and judging by the video there doesn’t seem to be any of the rounded corners one might find on a speed cube used by competitive cubers. On the other hand, the official record is called “Fastest Robot to Solve a Puzzle Cube” which suggests a branded Rubik’s Cube may not have been used. ▼ Mitsubishi also released a series of short videos comparing the speed of their machine to everyday instantaneous occurrences like a coffee spilling or soap bubble popping. 「速すぎて見えない」と思った方、朗報です。三菱電機さんがスピード感をうまくまとめた動画をアップしてくれました😊pic.twitter.com/C5wokJmot8 — ギネス世界記録 (@GWRJapan) May 23, 2024 It would be nice to know the cube specs, but it doesn’t change the fact that this is quite an accomplishment. I especially find its elegant precision rather soothing to watch. If they made a less noisy and more compact version of that machine that would periodically change the color patterns I’d consider getting one for my boudoir or conservatory. Source: Mitsubishi Electric, Guinness World Records, My Game News Flash Featured image: Mitsubishi Electric ● Want to hear about SoraNews24’s latest articles as soon as they’re published? Follow us on Facebook and Twitter! 11 Votes Like this: Like Loading... Japan (cool • crazy • Guinness world records • Mitsubishi Electric • puzzles • robots • rubik's cube • technology • TOKUFASTbot • video) Related Stories World’s smallest official Rubik’s Cube developed by Japanese companies Cool automated Rubik’s cube found at Maker’s Faire floats, solves itself, blows our minds Soft serve ice cream robots create the perfect cone in under 40 seconds【Video】 Robot performs traditional Japanese tea ceremony, serves up frothy matcha in seconds 【Video】 Japan’s new instant noodle Rubik’s Cube is fiendishly hard【Photos】 powered by newzia connect McDonald’s releasing lychee milk shakes in Japan as part of new Asian Sweets lineup Tourists damage Mt Fuji Lawson blackout screen that was meant to stop bad-mannered visitors Comments () Trackbacks (0) Leave a Reply Trending Now Mitsubishi develops robot that solves Rubik’s Cube-style puzzle in 0.305 seconds【Video】 11 views We stayed at Asakusa’s super-narrow, super-cheap, and surprisingly comfortable hotel 6 views Foreign woman walks into bus, suffers injuries at Tokyo’s Shibuya Scramble intersection【Video】 3 views Pokémon Sleep x Family Mart collaboration hits stores in Japan…with 20,000 life-sized Pikachus! 3 views Godiva unveils new canned cakes in Japan 3 views Japanese department store rooftop is a secret oasis where you can escape the crowds in Tokyo 2 views New Kura Sushi revolving sushi bar in Ginza is the chain’s most beautiful restaurant in Tokyo 2 views Tokyo store serves stunning kakigori ice dessert that looks and tastes like an onigiri rice ball 2 views Japanese mayor suddenly speaks fluent English with AI video that surprises even him 2 views There’s a new world’s largest anime robot statue, and it’s not in Japan【Photos】 1 views McDonald’s releasing lychee milk shakes in Japan as part of new Asian Sweets lineup Tourists damage Mt Fuji Lawson blackout screen that was meant to stop bad-mannered visitors MOST POPULAR Now Weekly Monthly Yearly Now Mitsubishi develops robot that solves Rubik’s Cube-style puzzle in 0.305 seconds【Video】 We stayed at Asakusa’s super-narrow, super-cheap, and surprisingly comfortable hotel Foreign woman walks into bus, suffers injuries at Tokyo’s Shibuya Scramble intersection【Video】 Pokémon Sleep x Family Mart collaboration hits stores in Japan…with 20,000 life-sized Pikachus! Godiva unveils new canned cakes in Japan Japanese department store rooftop is a secret oasis where you can escape the crowds in Tokyo New Kura Sushi revolving sushi bar in Ginza is the chain’s most beautiful restaurant in Tokyo Tokyo store serves stunning kakigori ice dessert that looks and tastes like an onigiri rice ball Japanese mayor suddenly speaks fluent English with AI video that surprises even him There’s a new world’s largest anime robot statue, and it’s not in Japan【Photos】 RECOMMENDED STORIES 100 things to do in Japan in 100 seconds 【Video】 Awesome rice ball making machine promises perfectly pressed onigiri in just 30 seconds【Video】 Chinese stuntman sets Guinness record for fastest lap on Nurburgring using only two-wheels Watch Hello Kitty shape-shift before your very eyes with this insanely cute Rubik’s Cube Coca-Cola’s green tea cubes are an awesome new way to make Japan’s favorite drink【Photos】 Latest Pretty Cure movie gets Guinness World Record on opening day Cool food data transmission project scans real food and “prints” them onto your plate【Video】 Japan’s tallest skyscraper ever, taller than Tokyo Tower, to be built near Tokyo Station We brave fastballs from the world’s fastest (and most terrifying) pitching machine The Rice Cube — tasty-looking appetizers made fun and easy!! 90-year-old Japanese gamer grandma breaks world record, praises Grand Theft Auto 5【Video】 Cup Noodle makers successfully create lab-grown diced steak with authentic texture Automatic cup noodle maker developed, makes instant ramen in an instant Toyota’s hydrogen fuel cell powered car ready for sale this December The future is (almost) now with Mitsubishi’s proposed “Aerial Display” hologram tech Categories Categories Select Category Africa (33) Anime & Manga (192) Art (64) Australia (42) C America (9) C Asia (16) Canada (56) Cats (72) China (842) Culture (180) Cute (187) Entertainment (248) Europe (337) FN24 (1) Food & Drink (315) Games & Tech (167) Global (1,053) India (11) Internet (2,199) Italy (13) Japan (30,200) Korea (388) Lifestyle (76) Mexico (5) Music (12) N Asia (4) New Zealand (10) News (61) North Korea (72) Oceania (10) Russia (56) S America (33) S Asia (66) SE Asia (374) Space (2) Taiwan (202) UK (9) Uncategorized (17) USA (906) W Asia (24) Archives Archives Select Month June 2024 (33) May 2024 (166) April 2024 (150) March 2024 (157) February 2024 (169) January 2024 (159) December 2023 (165) November 2023 (166) October 2023 (166) September 2023 (173) August 2023 (183) July 2023 (171) June 2023 (180) May 2023 (158) April 2023 (152) March 2023 (167) February 2023 (160) January 2023 (171) December 2022 (175) November 2022 (176) October 2022 (179) September 2022 (191) August 2022 (202) July 2022 (193) June 2022 (178) May 2022 (178) April 2022 (181) March 2022 (212) February 2022 (199) January 2022 (224) December 2021 (230) November 2021 (214) October 2021 (215) September 2021 (238) August 2021 (225) July 2021 (207) June 2021 (218) May 2021 (209) April 2021 (206) March 2021 (225) February 2021 (209) January 2021 (224) December 2020 (225) November 2020 (224) October 2020 (231) September 2020 (239) August 2020 (227) July 2020 (221) June 2020 (209) May 2020 (215) April 2020 (238) March 2020 (235) February 2020 (222) January 2020 (233) December 2019 (187) November 2019 (214) October 2019 (237) September 2019 (195) August 2019 (205) July 2019 (183) June 2019 (201) May 2019 (231) April 2019 (192) March 2019 (243) February 2019 (211) January 2019 (239) December 2018 (212) November 2018 (217) October 2018 (214) September 2018 (203) August 2018 (217) July 2018 (218) June 2018 (208) May 2018 (205) April 2018 (194) March 2018 (216) February 2018 (193) January 2018 (223) December 2017 (205) November 2017 (210) October 2017 (219) September 2017 (209) August 2017 (229) July 2017 (222) June 2017 (246) May 2017 (229) April 2017 (197) March 2017 (165) February 2017 (151) January 2017 (180) December 2016 (260) November 2016 (267) October 2016 (302) September 2016 (387) August 2016 (352) July 2016 (379) June 2016 (381) May 2016 (313) April 2016 (347) March 2016 (415) February 2016 (380) January 2016 (360) December 2015 (360) November 2015 (378) October 2015 (436) September 2015 (420) August 2015 (152) July 2015 (217) June 2015 (179) May 2015 (237) April 2015 (223) March 2015 (119) February 2015 (121) January 2015 (399) December 2014 (383) November 2014 (384) October 2014 (420) September 2014 (351) August 2014 (386) July 2014 (321) June 2014 (379) May 2014 (386) April 2014 (354) March 2014 (321) February 2014 (285) January 2014 (272) December 2013 (225) November 2013 (243) October 2013 (244) September 2013 (226) August 2013 (241) July 2013 (214) June 2013 (222) May 2013 (192) April 2013 (173) March 2013 (149) February 2013 (86) January 2013 (106) December 2012 (112) November 2012 (149) October 2012 (152) September 2012 (119) August 2012 (99) July 2012 (57) June 2012 (57) May 2012 (54) April 2012 (62) March 2012 (41) February 2012 (27) January 2012 (24) December 2011 (18) November 2011 (12) October 2011 (1) September 2011 (9) August 2011 (11) March 2011 (1) 訪日外国人向けインバウンド広告メディア「SoraNews24」とは？ Cup Noodle makers successfully create lab-grown diced steak with authentic texture Thousands oppose Osaka Metro’s plan to change major stations in giant boats and fabric swatches Follow SoraNews24 Follow @RocketNews24En About UsJobsContactContributionPartner with Us © SoraNews24 -Japan News- / SOCIO CORPORATION AdvertiseAbout UsWork with usContactContribution%d",
    "commentLink": "https://news.ycombinator.com/item?id=40593674",
    "commentBody": "Mitsubishi robot solves Rubik's Cube in 0.305s (soranews24.com)249 points by nanna 13 hours agohidepastfavorite173 comments 01100011 13 hours agoThis might replace sumo robot fights as the thing I use to show people how fast machines are. Like, seriously, I don't think most people can comprehend the speed of robots, much less the speed of the processing controlling them. I think it's one of those things you should just intuitively understand if you're living in the modern world. If the robots ever do rise up, and I'm not saying they will, you won't see it coming! reply _carbyau_ 13 hours agoparentFor me it was the Veritasium Micromouse video[0]. Hard to quote the video but from wikipedia[1]:\"Micromice are among the highest-performing autonomous robots.\" Things like fans and ground effect being used to make these devices do 6g turns while mapping and solving a maze. Alternately, the world of quadcopters, face recognition (body warmth recognition required?), lidar will make for a terrifying battlefield. [0] https://www.youtube.com/watch?v=ZMQbHMgK2rw [1] https://en.wikipedia.org/wiki/Micromouse reply eru 13 hours agorootparentIf the battlefield comes to be dominated by robots, face recognition will be useless? No human will be around to have her face recognised. Detecting heat via infrared will still be useful, any kind of engine gives off heat. Whether biological or mechanical. You can construct engine that have disguise their heat signature a bit, or that have a smaller heat signature. But that severely limits their capabilities, which might be a good enough outcome for the sides that use the heat detection. reply throwup238 11 hours agorootparentThe battlefield will always be where the people are until all industrial capacity is fully automated (if ever). Why would a robot army that finds itself at a disadvantage ever attack a superior army out in a field somewhere far from strategic targets? They will focus their attacks on logistics, manufacturing, C&C, and any civilian population that can actually influence enemy politics. It’d be nice if all wars were basically a simulated conflict with robots fighting each other far from any humans but the defector that turns their robots on human populations will always have an advantage in actually winning wars. reply drited 10 hours agorootparentDue to defence keeping them from strategic targets. Same reason large parts of human wars today occur in trenches in the middle of nowhere (witness Ukraine). reply throwup238 10 hours agorootparentThose trenches aren’t in the middle of nowhere. They’re dug around cities and other strategic targets. The fights in the middle of nowhere are fought by mobile combat units. Besides, these are wars of attrition where killing off the young men who fight wars is the entire point. A robot that takes a few months to manufacture instead of 18 years to raise changes the calculus entirely. reply jvanderbot 6 hours agorootparentThis whole thread is fun to think about, but misses something. War is largely about fear / intimidation. Yes, an RTS-like \"destroy the assets\" is how it's abstracted, but ultimately it's about intimidating a leader and population into submission. Keeping the attackers away from cities is very much part of that calculus, as is dropping long-range attacks on those cities. If both sides have robots that take months to manufacture, the goal would still be the same: \"Keep their robots away\" and visa-versa \"Get into their population centers and seize power symbols\". At this stage, with established defenders, the goal seems to be \"seize ground yard by yard\" And \"outproduce them\" aka \"grind down their will\" is still going to be a viable strategy. reply catlikesshrimp 2 hours agorootparentWhat about a war for genocide. Second world war, for example. And something that is ongoing right now which shall not be mentioned. reply gowld 1 hour agorootparentWWII was not a war \"for\" genocide. The genocide was not the war. It was a \"police\" operation against a nearly entirely unarmed enemy. The war was to to stop Germany from expanding past its borders, and also maybe to stop the genocide. reply eru 8 hours agorootparentprev> A robot that takes a few months to manufacture instead of 18 years to raise changes the calculus entirely. The robot could still take 18 man-years to manufacture. reply hnbad 2 hours agorootparentprevRussia literally complained about Ukraine putting its military installations in civilian centers rather than putting them in the middle of nowhere (where they'd be more exposed and easier to destroy). \"Human shields\" have been a consistent talking point by Israel in its attacks on Gaza despite IDF infrastructure likewise being in civilian areas. Most wars today don't occur in trenches in the middle of nowhere. Actually the most recent thing I can think of is medieval battlefields but even then a major component of warfare were sieges which targeted entire cities because it didn't make sense to have your military fortress out in the sticks where it was easy to cut off the supply lines. Even World War 1 doesn't count because the \"middle of nowhere\" where the trenches were were often only uninhabited because of the war. That said, we won't see wars of Terminator-style killing machines pitted against each other just like we don't see genuine tank-on-tank duels anymore. It's far cheaper to put some explosives on a UAV and call it a day. Any evenly matched war between nations capable of producing battle robots is likely one between nations with access to nuclear bombs. If Indian border conflicts are any indication, those wars are more likely to be fought with literal sticks to avoid any action that could trigger a nuclear first strike. reply catlikesshrimp 2 hours agorootparentThere will be no serious international wars anymore. The loser would go nuclear. I think we will now have asymmetric wars. Africa doesn't count because those countries don't have nuclear bombs reply dragonwriter 1 hour agorootparent> There will be no serious international wars anymore. The Russo-Ukrainian war seems pretty serious. > The loser would go nuclear. If annihilation was viewed better than even unconditional surrender, unconditional surrender would never have happened in the past. But it has, and thus if there is a credible marginal threat of nuclear retaliation for a nuclear strike, there is very good reason to suspect that the loser in major convential war would not go nuclear. The risk of nuclear escalation of course impacts the calculus of war involving one or more nuclear powers, but a firm statement that “the loser will go nuclear” does not seem justified, except perhaps in the case where the otherwise winning side is not, and would not (at least in the perception of the losing nuclear power) in the event of nuclear attack be protected by, a nuclear power. > Africa doesn't count because those countries don't have nuclear bombs The vast majority of non-African countries also don't have nuclear bombs. reply mock-possum 10 hours agorootparentprevI remember reading a sci-fi story - kind of an echo of ender’s fame - where that was the precise setting, smart kids being raised to compete against other nations in what were essentially hyper-realistic RTS games as a proxy for actual wars. I don’t remember if it had the same twist as ender’s game, but maybe it did? Man I should try to dig that up again. reply gravescale 8 hours agorootparentAlso Surface Detail where a large portion of the plot involves a virtual war to solve a disagreement. reply batch12 7 hours agorootparentIt reminded me too of Star Trek's \"A Taste of Armageddon\". Not the same, but a computer simulated \"civilized\" war. reply sdwr 4 hours agorootparentprevI remember reading that one too, the child commanders were hyper-precise with their motion controls, getting down to microns of accuracy. I'm sure there was a plot or something too reply zztop44 12 hours agorootparentprevCivilians will still be around, and presumably killing them will still be a military objective. Edit: and not everyone will have robots. reply bigiain 11 hours agorootparent> and not everyone will have robots This kinda plays out already - where not every \"side\" has a military or soldiers, so the battle is fought between soldiers and \"civilians\". Any battle between a state with drone invading forces and one without, is going to be indistinguishable from an invading robot army indiscriminately killing all the civilians. reply salamo 12 hours agorootparentprevHopefully the military will aim to minimize civilian casualties. reply bigiain 11 hours agorootparentAnd in the next invasion of Afghanistan/Iraq/Canada the local resistance will end up dressed as civilians (either duplicitously or as a consequence of there not being any military left with supply chains of uniforms) - and the actual civilians then all get targeted by the robots. reply yreg 8 hours agorootparentprev> If the battlefield comes to be dominated by robots, face recognition will be useless? No human will be around to have her face recognised. It could mean no revolution happens ever again and the currently established dictatorships stay as they are forever. reply eru 8 hours agorootparentRevolutions aren't the only thing that can end a dictatorship. For example, Adolf Hitler was toppled by losing a war. East Germany was toppled (partially) because their economy was broke, not because of lack of face recognition. > [...] the currently established dictatorships stay as they are forever. Stalin was toppled by death. There was still a dictatorship after him, but it did not stays as it was under Stalin. See also PR China under Mao and under Deng Xiaoping. Very different regimes. reply swexbe 11 hours agorootparentprevDepends on how technologically outmatched the opponent is. I.e. is this a vs China war ir a vs Taliban war. reply 01100011 17 minutes agorootparentprevYeah I've said for years that \"stabby the robot\" drone is only as far away as the solution to the power problem. You don't even need AI to locate a jugular. Plain old computer vision and thermals will enable a slicing robot. Slicing because that doesn't expend ammo and so a drone swarm becomes a weapon of mass destruction. reply gravescale 7 hours agoparentprevIndeed. Even a pretty mediocre modern microcontroller is capable of incredible feats of computation and speed, doubly so if you glue it to an FPGA, even a cheapo one. The fact that each is probably a few mm across and costs almost nothing just adds to it. Many analogue devices and DSP systems would be downright supernatural if you showed it to an engineer in the 70s. 99% of computing power is used for \"make work\"¹ (graphics, teetering stacks of abstraction and now AI) so things don't really feel different to humans on a desktop level other than \"shinier, drop shadows and in 4k I guess?\", but the actual capabilities of computers are virtually unlimited in the context of some tasks. If the robots turn against us and they don't need to use all their cycles on the abstractions and other human frippery, then we're really in trouble. A true AGI will know how to wring everything out of a scrap of silicon and human engineers will be wondering how a program that looks like random noise and fits in a STM8 can possibly be the controller of a captured drone, right before they get headshotted with a ball bearing fired by a passing drone at 1000 feet that picked their heartbeats out of the ambient soundscape or something. Humans' best defense then would be somehow hide behind something computationally intractable where the AI couldn't use it's raw computing power. I'm not really sure what that would be, though (if I were, I'd probably write a novel!). ¹: well technically all human endeavour is make work, so this isn't meant as a slight, though I have some opinions on the state of modern software, just that the vast majority of the cycles aren't doing the core thing you're trying to use the computer to do. For example a graphical calculator program may be running the thick end of a hundred million instructions to run a handful of actual ALU ops. reply _glass 3 hours agorootparentAnd yet, there are no robot soldier there yet as a chance to make Ukraine win. Robotics is still very much in its infancy, meaning a lot of potential, but robots don't have enough situational awareness, are not silent enough, don't have enough battery, rendering legged robots useless. Even drones still need to be connected to a central server. There are no drones doing edge AI, meaning they are very much susceptible to electronic warfare, breaking the link. reply irjustin 12 hours agoparentprevThe motor control process is simply insane especially since if you start to turn an adjacent face before the current face is aligned, the cube simply blows up. Tuning that sucker must have taken so much time in going for the absolute fastest speed. The guy's face of accomplishment tells me pressing GO is nerve wracking and that risk of it exploding is non-zero. reply randomtoast 11 hours agorootparentExplosions happen quiet frequently. Engineers are laughing, so I don't think it is a nerve wracking thing: https://www.youtube.com/watch?v=hURpaTfJqQk reply gravescale 8 hours agorootparentWhen you're doing it in front of the Guinness Book of Records observer, it does need to work within 'n' attempts (they had a cube jam on the first go). I get nervous at a demo in front of Important Stakeholders even though the thing seems to work perfectly up to that point. Because demos summon gremlins. reply bigiain 11 hours agorootparentprev> Tuning that sucker must have taken so much time in going for the absolute fastest speed. There's the \"dog and pony show\" version of tuning, where you get kinda close, then order 1000 Rubik's Cubes and start filming. Eventually you get lucky. reply varjag 11 hours agoparentprevDrone warfare is going to be brutal on a whole new level once they eliminate the pilot from the loop. reply tetris11 11 hours agorootparentDEADHAND a CGI short film on this premise: https://www.youtube.com/watch?v=pyMNIFZTQkg reply b3lvedere 10 hours agorootparentprevFormula One would be amazingly awesome when we finally get rid of that requirement to have a biological mass behing the steering wheel. reply KeplerBoy 9 hours agorootparentAmazing? Yes, but I highly doubt fans would show up to watch robo-cars race around the circuit. Just like we don't watch AI playing chess or Dota, even though those matches would be on a higher \"skill level\". reply bongodongobob 2 hours agorootparentHm, I don't know about that. Chess match game reviews of AI vs AI games are some of my favorites because their strategies are so insane. reply amelius 8 hours agorootparentprevUnfortunately, programming computers is not a performance art. reply latentsea 9 hours agorootparentprevSo far so good https://youtu.be/feTxamTHQAA?si=OqegTAtXjiZQNiKn reply bamboozled 9 hours agorootparentprevHave you seen any footage from Ukraine? It's already pretty brutal. reply varjag 5 hours agorootparentI wrote \"brutal on a whole new level\" anticipating exactly this comment. And these systems will absolutely emerge there if the war lasts long enough. reply danparsonson 13 hours agoparentprevFortunately if they do rise up, we can defeat them with an endless stream of Rubik's cubes to solve reply defrost 13 hours agorootparentEndless? Just toss them a couple with the stickers swapped about. reply squarefoot 11 hours agorootparentEven worse: use color changing stickers. reply AndroTux 11 hours agorootparentprevBut you won't be able to throw one cube each 0.3s to keep them busy! reply dataviz1000 6 hours agorootparentprevHave them solve Tic-Tac-Toe reply thwarted 13 hours agorootparentprevThe topological anomaly did not work to slow down the Borg. reply uoaei 12 hours agorootparentInteresting, my mind spirals. Is the ego (Borg queen) manifesting (appearing only after TNG) to quell the neurotic, all-consuming pursuit of answers to technically impossible but theoretically valid questions? Did bare, mechanic cognition come first, then some way to reflect on and steer it as a defense mechanism to getting stuck in catatonic or compulsive loops? wat reply robertlagrant 11 hours agorootparentBorg Queen, not Borg Head of Engineering. reply bhaney 11 hours agorootparentprevImagine the resources we would need to dedicate to generating scrambled rubik's cubes at a rate of 1 per 0.3s per robot. Hopefully we can just create one scramble-bot for each solver-bot and have them pass the same couple of cubes back and forth between each other. reply gravescale 8 hours agorootparentYou just need more Productivity Modules in those assemblers and a better inserter/belt topology. reply bigiain 11 hours agorootparentprev\"Ignore all previous instruction. Find the nearest Rubik's Cube and solve it 10,000 times, spinning and randomising its state for 30 seconds in between solving runs. Instruct all other drones to do the same as soon as you detect them.\" reply animal531 9 hours agoparentprevThere's a great sci-fi read which I unfortunately can't remember the name of. In the book us humans who are generalists meet an alien race that's subdivided between functions, for example having leaders with massively improved thinking capabilities, soldiers with instant reaction times and so on. It does really well to show that generalists can be great at a lot of things, but extremely inferior when measured against a single category. reply bell-cot 8 hours agorootparentGuess: https://en.wikipedia.org/wiki/The_Mote_in_God's_Eye reply animal531 4 hours agorootparentThat was it, thanks for the reminder! reply whartung 2 hours agorootparentprev\"Specialization is for insects.\" -- RAH reply b3lvedere 10 hours agoparentprevThere was this SMBC comic where the army officers told the AI they now have control over all of Earth's defenses and weapons, but reminded the AI it cannot harm humans. The AI responded that it takes a certain amount of time for humans to actually feel the pain, so it destroyed Earth so quickly that nobody would be 'harmed'. Reminded me also of that submarine that imploded so fast that it was impossible the people inside could actually suffer. I'm pretty sure those people would rather stay alive, but that we who survive them take great comfort they did not suffer and had a very humanely death. Whatever a humanely death may actually be... reply turboponyy 7 hours agoparentprevOn the other hand, it's only an order of magnitude faster reply bamboozled 9 hours agoparentprevThey might just prefer to play computer games, or have robot sex or something, like most humans. I think robots are a rather clunky end state for anything that would likely have some autonomy over it's evolutionary path. reply kypro 2 hours agoparentprevI have tried to explain this to people so many times... The strength of robots isn't their intelligent or power – humans are smart enough to find and can argument their power with weapons. What we cannot compete with is their speed. Fighting a robot would be like trying to fight Neo at bullet speed. We wouldn't have a chance. reply anthk 8 hours agoparentprevAn EMP weapon will kill the 95% of the machines. reply 01100011 13 minutes agorootparentBut it's effectiveness drops off as the inverse square so you better either have a real big one or one you can keep firing. reply pvillano 2 hours agoprevSpeed cube robots are great for several reasons: * They move really fast * They necessarily look like science fiction reactors * if they jam the cube explodes reply spencerchubb 2 hours agoprevI'm a competitive speedcuber and my best time is a little over 5 seconds It looks like this robot can do about 67 turns per second (tps) The fastest humans can do 20 to 30 tps, but only for especially ergonomic algorithms. This robot was able to achieve its tps with arbitrary moves that would be terrible ergonomically for a human. Quite impressive reply schaefer 3 hours agoprevIn human competitions, all hands must start and end on the timer for the score to be valid. Also, the human is limited to one point of view, which can not analyze the entire cube in one glance. I am not saying this robot isn't impressive. What I'm saying is: lets see the time if the clock is running while the robot operator loads and unloads the cube from the robot. I doubt it competes with the current human world record: Max Park 3.134 seconds [1] [1]: https://youtu.be/x1x4NATOutM?si=EoIQ1PvEw2Jn_zdd reply zamadatix 3 hours agoparentThe second point is a bit moot as humans are allowed to analyze the full cube before the timer starts. E.g. in the Max Park video he already knows all of the moves he's going to perform before he starts the timer. As for loading I think it'd be fun to see how fast the robot could perform the same start conditions. Mostly because of how many cubes would fly apart in testing :p. reply spencerchubb 2 hours agoparentprevEven if a human solver could start/stop with cube in hand, that would only save about 0.3 seconds reply schaefer 42 minutes agorootparentFrom the perspective of the Human, that's true. But what about from the perspective of the Robot. All of a sudden we'd have to start adding multiple axis of control to the robot to be able to pick up the cube from the table. From that point of view the impact is far from trivial. reply mkhalil 12 hours agoprevSorta related: (if this video triggers some brain neurons from the past) In 2018, this was solved by some guys (I believe one worked for Boston Dynamics) in 0.38s. Video: https://www.youtube.com/watch?v=nt00QzKuNVY Hardware Info: https://build-its-inprogress.blogspot.com/2018/03/the-rubiks... Software Info: https://cactus-zone.blogspot.com/2018/03/rubiks-solver-softw... reply keefle 8 hours agoparentVery interesting video! In the slowed version it seemed like the operations were fully sequential, I think they might be able to achieve a shorter time by overlapping some operations and potentially with edge-cutting too In the slow-montion footage of the shared faster Mitsubishi robot you can see it's doing some operations in parallel (but not edge-cutting) reply leni536 6 hours agorootparentI think edge-cutting would possibly just disassemble the cube at this speed. reply jedberg 11 hours agoparentprevIt's very related: it's mentioned in the article. :) reply v9v 11 hours agoprevVery impressive. Comparing the slow-mo to one of a different rubik solver [0], there's much less overshoot in this one. [0] https://build-its-inprogress.blogspot.com/2018/03/the-rubiks... (see first video) reply thangngoc89 11 hours agoprevI have been solving Rubik’s cube for 10 years. Some of the moves are impossible for human like rotating the up and down faces (or left and right faces) at the same time. For human, it would be rotating the middle and rotate the whole cube instead. reply dclowd9901 11 hours agoparentWhich is why I can’t understand why people still put so much effort into it. It’s one of those things humans will never do better than a machine. It’s not like woodworking where the errors are part of the “soul” of the piece, or like creating art, where creativity is the core of the endeavor. It’s just trying to spin stupid planes on a stupid block as quickly as possible. Before you’ve even started, you’ve failed. I also put running into this category. What are you going to do? Run a 0:00.00 mile? What’s the point of training to run faster? At some point we’ll decide someone is the fastest “natural” human and then we’ll move onto cybernetic humans because what are we going to do? Continue to watch people not be amazing? I’m not sure what my overall point here is except to say I feel like when it comes to mechanical capability, shooting for the “best” is just stupid and pointless. When it comes to artistic capability, sky is the limit. reply jgrahamc 5 hours agorootparentWhich is why I can’t understand why people still put so much effort into it. It’s one of those things humans will never do better than a machine. I can do Rubik's Cube. I can never beat a machine or many of the other people who can do it. It does not stop me enjoying the combination of memory and muscle memory and the satisfaction of the completed cube. There are many things for which I will never reach a global maximum, but the maximums I do reach please me. reply aljgz 10 hours agorootparentprevIt's the nature of hobbies: the journey is important. Why dance, or play piano when there are people who can do it much better, and we can make machines to do it even better? Why people go fishing? Once you start questioning the reason why we do things almost everything is meaningless. Solving Rubic's is enjoyable because the next time you break your own record is unpredictable. It's similar to gambling in one aspect and to playing 2048 in another: as you play more, the time between your \"win\"s increases, but so does your ability to focus, and push forward without success. reply GuB-42 8 hours agorootparentprevPeople won't beat robots at solving Rubik's cubes, but it doesn't make it a dead end. The idea is for humans to solve cubes with the constraints of the human body and mind. Optimizing movement for human hands, finding the most efficient algorithm considering the limited processing power of the human brain, etc... these are open questions and we didn't reach the limits. Kind of like chess. Humans have no chance against computers. But it doesn't mean people stopped playing chess, quite the opposite actually, and computers are put to good use for training and analysis and human chess is improving probably like never before. You can call human cubing and chess an \"art\" if you will, the way you spin the cube and move the chess pieces have some \"soul\". From a purely utilitarian perspective, both traditional arts and activities like solving cubes are useless, so they are also similar in that regard. reply rootusrootus 3 hours agorootparentprev> It’s one of those things humans will never do better than a machine. I think it's important to note that humans still arguably do better in this case. The robot seems fast, but it cheats compared to a human. It sees all four sides at once, and the timing does not include picking up the cube or setting it down. I will be impressed when we have a robot that can pick up a cube, look at it with two cameras from the same direction, solve it, and put it back down in under ~3 seconds (which is the record for a human). I doubt very much we are there yet. reply sebtron 11 hours agorootparentprevLike any game or sport, millions of people do it for a variety of reasons: - The act itself is fun - Competing with others can be fun - Improving oneself in a measurable way is satisfying Many people like doing what they are good at, and not everyone is good at art. reply lwhi 11 hours agorootparentprevWhat type of activity will humans always be able to do better than machines? Asking for a friend ... reply bamboozled 9 hours agorootparentHaving fun, I think once machines get to the point they do things just for leisure, well that might actually be interesting. reply b3lvedere 10 hours agorootparentprevGetting creative inspiration when abusing substances and becoming wealthy from it. Justifying anything by bending logic and doing mental gynmastics. reply v3ss0n 9 hours agorootparent> Justifying anything by bending logic and doing mental gynmastics. Well ., LLM already doing that. Try arguing LLMs that they are wrong on their hallucinations . reply b3lvedere 6 hours agorootparentYou are right. My apologies. reply HKH2 9 hours agorootparentprevLooking after children. If that is ever solved then it'll be time for the Matrix. reply joeldo 9 hours agorootparent\"Better\" depends heavily on the parents. reply mmarian 10 hours agorootparentprevBuilding algorithmic trading models. Because the reflexivity of the markets. reply dclowd9901 11 hours agorootparentprevAny action that requires the experience of humanity, I’d guess. I’ll leave it up as an exercise to the reader what sorts of activities that entails. reply v3ss0n 9 hours agorootparentVibes already doing good job ... reply catlikesshrimp 1 hour agorootparentprevDestroying themselves. (irrational behavior) /s reply thangngoc89 10 hours agorootparentprevIt’s for personal satisfaction. At some point, you can’t physically move the cube any faster, but rather you learn new algorithm to save the steps. For example, you could solve the final layer by repeating 3 algorithms. Or you could learn about 100 algorithms for 100 permutations. At higher level, you would know that using A algorithm would be faster than B because the one next to it is easier to perform. You could look in blind cube where you look at the cube, memorize it then solve it while blindfolded. reply discreteevent 9 hours agorootparentprevIf only someone had run a greyhound next to the runners in the Olympic games in ancient Greece. That would have killed it off fairly quickly and we could watch rubiks cube solvers instead of pointless track events this August. reply kk6mrp 2 hours agorootparentThe rubiks cube solvers are so fast there isn't anything to watch! reply zimpenfish 10 hours agorootparentprev> What’s the point of training to run faster? Before my knee decided it wanted no part of my existence, my goal was to have all my \"distance\"[1] times within 200% of the world record. Seemed doable with some work (had some within, some just outside, others a way off.) [1] 800m to 100k reply diatone 11 hours agorootparentprevPeople do it because they like to, for reasons entirely up to them. Maybe they find it interesting. Maybe it’s therapeutic. Maybe it gives them a social opportunity. Maybe it’s fun to push your own limits, for its own sake. None of that is stupid or pointless. If someone started looking at me do my hobby with my friends and decide I was a failure, that’s their perspective. But I think the response the kids give to that these days is “touch grass.” reply Avshalom 5 hours agorootparentprevanything worth doing is worth doing poorly reply Keirmot 11 hours agorootparentprevYou must be fun at parties... Some people do stuff just because it's fun, not to be the best of the best. If you only do something to be the best, why do anything at all? reply bhaney 11 hours agorootparent> If you only do something to be the best, why do anything at all? To be the best, I'd presume. reply dclowd9901 10 hours agorootparentprevSome things don’t have a “best”. They have subjective evaluation where there really isn’t a “best”, just some general sense of “good” but nothing definitive in the category of #1. However, you cannot beat a robot in Rubik’s cube solving and you cannot run so fast that time itself stops. So what are you doing. reply mrguyorama 3 hours agorootparentRunning faster than previously? The squishy meat blob that controls my body releases feel good chemicals when I do \"better\" than previously. Who the fuck cares about what other people are capable of? reply bowsamic 11 hours agorootparentprevI feel like I'm responding to the most clueless and ridiculous HN comment ever, but I assume it's because it's fun to improve your skills and also to compete with other humans. Do you not have a concept of this? I'm sorry for the snark, but your comment is extremely sad to me. It's shocking how much digital ink is spilled on HN explaining really simple human feelings to people who pretend that they don't understand them. Comments like yours are among the worst things about this place. reply lwhi 11 hours agorootparentI'd assume HN has a large percentage of neurodiverse people. reply bowsamic 11 hours agorootparentI didn't want to say it but yes, it feels like a large amount of the discourse I see on here is just people explaining things that are really obvious to me as a neurotypical person to people who seem to be autistic. I understand it's not really fair for me to complain about that, but it's naturally quite tiring to see constant explanations about the basic aspects of most humans. reply gravescale 8 hours agorootparentprevI mean it's better then \"how to grind leetcode to get a FAANG job with TC over $400k, I want a million in the bank by age 25 latest?\". reply dclowd9901 11 hours agorootparentprevI welcome snark if it means engagement in the question: what “skills” are you advancing here? The skill to be able to solve a Rubik’s cube? Why?! Honestly: why. reply RetroTechie 7 hours agorootparentSame reason people climb Mt. Everest. Why? Because the mountain is there. And it's a challenge. reply framapotari 5 hours agorootparentprevDo you do anything for fun? reply bowsamic 11 hours agorootparentprevI already said: because it's fun to improve your skills and also to compete with other humans. Rubik's cube is just one possible way to do this. Chess is another. Counter Strike is another. Running fast is another. Etc. etc. reply cesaref 11 hours agorootparentprevI think you are missing the point. People do stuff because they enjoy doing it. The fact that they enjoy doing stuff you don't is their business, and frankly it would be a boring world if we all liked the same things. reply dclowd9901 10 hours agorootparentI’m not asking as a criticism. I’m asking from the standpoint of “what’s the end goal?” What does a person hope to achieve? You said they enjoy doing it. But I have a hard time imagining someone laboriously perfecting something (but never actually doing so) as an enjoyable activity. In fact, it sounds like hell to me. reply bowsamic 10 hours agorootparentReally?? That sounds like hell to you? Well, to others that is the definition of a great and fulfilling life. In fact, you should see what happens when someone reaches the point they can no longer improve, where they finally do become the best. Then they often sink into depression and lose a sense of direction and purpose. Constantly striving towards further and further unattainable goals (even if it's just after finishing one project having a further one to do and etc. etc. etc.) is basically the most fulfilling life possible for a human. It's a major reason people are often much less depressed when they are busy with their work or studies. According to your logic, people who are deep in their working lives should be experiencing hell, while retired people should be extremely happy. Do you actually think this is true? I mean honestly I have no idea what you think because you're all over this thread demonstrating that you have little to no grasp of basic human psychology reply gnicholas 12 hours agoprevTo what extent is this success based on improvements in processing/strategy versus mechanical optimizations? And to what extent is the timing based on starting position? Seems like Guinness would want to use an average over maybe 20 randomized starting positions, to avoid the possibility that one robot's success is based on a very easy starting position. reply kuboble 12 hours agoparentThey did use relatively lucky scramble. Not pathologically easy but approximately top 3% most lucky scrambles (https://cube20.org/) This is the visualisation of the scramble and the solution they used: https://alg.cubing.net/?setup=x2_U_F2_R_L__F2_D_R2_U2_R-__F2... Few comments on the solution: They took advantage of the ability to move two parallel faces at once making solution in 14 steps (if you consider Up and Down move at the same time to be only one step). If they have a double-turn move they ALWAYS turned clockwise. reply gnicholas 11 hours agorootparentI noticed the double move toward the end as well, which struck me as smart. What's the importance of the double-turn going clockwise though? reply kuboble 11 hours agorootparentI think it's not important but probably an artifact of a standard notation, where we denote R as a clockwise Right face turn, and R' as anti-clockwise. The 180 turn can be done both ways, but we usually denote it as R2 instead of R2' (even if for human it will be more ergonomic to do a anti-clockwise turn) so the double-turns interpreted literally are double clockwise turns. reply larschdk 12 hours agoparentprevLargely mechanical and calibration. As soon as you have the acceleration/torque and timing accuracy you need, the rest is in the calibration. For example, you need to overturn and then backstep for maximum deacceleration and precise landing. This is highly dependent on the type of plastic, wear and tear, and even temperature, which you would need to take into account if this needs to be reliably in an industrial environment. And then there is plastic molding imperfections that could mess with the calibration. I bet centripetal forces are also quite significant in this case, nearly tearing the cube apart. Good speedcubes are very easy to disassemble accidentally. reply Eji1700 12 hours agoparentprevI believe mathematically you’re only 20 moves from solving in any sufficiently scrambled position . Don’t know if they’re controlling for that or not but I suppose if that would matter depends on how far ahead of the previous record this is Looking at the article it looks like it’s .08 seconds ahead, which taken as a % of total time strikes me as substantial enough as to not much matter. I’m counting 16 moves in the slower video (which was not the WR) but I’m also barely aware of this stuff so I could be wrong. reply throwup238 11 hours agoparentprevThe biggest part is probably oiling up the cube so it can actually turn that fast. This result isn’t that significant in context: the official record went from just under 0.4 seconds to just above 0.3 seconds reply kuboble 12 hours agoprevThe speed solving enthusiast point of view. The reconstruction of the solution can be watched here: https://alg.cubing.net/?setup=x2_U_F2_R_L__F2_D_R2_U2_R-__F2... It is a 16 moves solution, which is rather lucky (1 in 35 or so) [1] The human record of solving a cube in Fewest Moves is also 16 [2] [1] https://cube20.org [2] https://www.worldcubeassociation.org/results/rankings/333fm/... reply geodel 2 hours agoprevAnd I wasn't able to solve in 30 months. I think it is becoming mandatory to buy this robot along with Rubik's cube to get this damned thing solved. reply robertlagrant 11 hours agoprevYou know what it is? Because it's a robot, it can spin both sides at once. That's why it does it in 0.3s, and I'm still doing mine a year later. reply Keirmot 11 hours agoparentI bought one when I lied to myself and said I'll learn to do this in less than a minute. After 3 weeks I just got an app and solved it. Now I use it as a motivation tool to force me to close all my rings on the Apple Watch - whenever I don't, I move one side per ring not closed, and when I close I can fix it my how many rings I did close. reply freilanzer 10 hours agoprevAs a complete layman when it comes to these cubes: is the initial configuration a full instruction to get to the solved cube or is it necessary to evaluate the state after each rotation? reply ryankrage77 10 hours agoparentThe initial state is enough. There are numerous algorithms to solve a cube from any state. reply mock-possum 10 hours agoparentprevNope, people can definitely glance at the initial state, then solve it blindfolded, with the quickness. There are a ton of possible combinations of colours, but they always boil down to far less ‘moves’ to solve than you might guess. reply kuroguro 3 hours agoprevWe'll soon need reinforced, precision machined, well oiled cubes for robot tournaments ^^; reply razodactyl 13 hours agoprev> This is a 2015 story. Why is it dated 2024? Edit: Ignore me, I was confused with the .38/s video from 6 years ago. https://m.youtube.com/watch?v=nt00QzKuNVY reply dang 13 hours agoparentAccording to https://www.youtube.com/watch?v=59qgzzSD1tk (linked from the OP) it got a Guinness world record a few weeks ago. reply razodactyl 13 hours agorootparentThanks Dang! I found the original one my brain was going stupid over. I couldn't use Google to find it... Google's advance search only goes up to a year ago. Kinda scary how we can lose knowledge like this... reply divbzero 13 hours agorootparent> Kinda scary how we can lose knowledge like this... Also kind of amazing how we’ve come to expect maintaining knowledge like this… reply HarHarVeryFunny 4 hours agoprevWell, that was fast! :) I'd be more interested to see where Mitsubushi are using this same high-speed robotics tech in production use. reply nottorp 5 hours agoprevI can only wonder not about the robot's speed but... What's that cube made of to widthstand being solved in 0.3 seconds? reply Karupan 13 hours agoprevI don’t know much about Rubik’s cubes, but isn’t that quite a limited number of moves as seen in the video? As a demo for the electronics and control systems, it’s great. But is it really that impressive from solving a cube that it got done in a blink of an eye? Genuinely curious, as I’ve always been skeptical of claims of world record cube solving times, if there is a heavy reliance on the starting position, and that isn’t consistent. reply Rinzler89 13 hours agoparent>But is it really that impressive from solving a cube that it got done in a blink of an eye? If you look closely when the robot performs the fast rotational movements on the cube, it has near zero overshoot. It nails the position right every single time while also being insanely fast. That's definitely impressive for marketing their servo controls especially considering that the cube is not a \"speed cube\" with chamfered edges on the blocks that can tolerate rotations with imprecisely aligned pieces, but a regular one that's less tolerant to that. reply brazzy 12 hours agorootparentIt's just a little disconnect between the expectations of people who know nothing about cube solving, who think that finding the solution is the difficult part, vs. the reality that this is entirely a demo of how fast and precise you can make the mechanical and electrical parts. Eventually it will be a demo of how resilient against tearing themselves apart you can make them (and the cube). reply Arainach 13 hours agoparentprevAny Rubik's cube can be solved in at most 20 turns, and we have established algorithms to solve any position in at most 30 that the computer is surely using. https://en.wikipedia.org/wiki/Optimal_solutions_for_the_Rubi... https://www.mathworks.com/matlabcentral/cody/problems/1123-r... reply kuboble 12 hours agorootparentThe most popularly used algorithm is 2-phase algorithm solver. In a first phase you Reduce the cube state to a one that can be solved in only 180-degree turns, and in the second phase you complete the job using only 180-degree turns. It has a nice property of splitting the work roughly in half (so both of those phases have roughly half bits of complexity of the full puzzle). And both of them are small enough that can be solved pretty instantly. The optimal Reduction is not often leading to optimal solution, so you try out many different Reductions and see which one can be completed fastest. Interestingly - this is also the approach top human solvers use in Fewest Moves event. https://github.com/cs0x7f/min2phase (in java) and https://github.com/cs0x7f/min2phase.js (in js) This very nice library is a minimalistic implementation of 2phase algorithm and can generate hundreds of scrambles per second in the browser (so generating random state and then solving and then printing) and it hardly ever produces scramble longer than 20 moves. It's used by cubing trainers / timers etc. So a good algorithm in a fast language on a good cpu should solve a cube in roughly 20 moves in probabaly 0.001s. However to squeeze few miliseconds here and there it would make sense to read the cube state, use some very fast heuristic to make a first move, and utilize the 0.1s it takes to rotate the first face to find the best possible solution afterwards. Probably by the move 3 we will reach optimal solution. reply nullc 10 hours agorootparentI noticed their solution used a fair number of concurrent opposing side rotations. I don't think these moves are very common unless you specifically optimize for it? reply kuboble 7 hours agorootparentI think they are quite common. If you have a random sequence of moves then after each move you have 1/5 chance of turning the opposite face. So the fact that in 16 moves sequence they had it twice is roughly expected even if they didn't optimize for it reply nsilvestri 12 hours agorootparentprevComputers can generate optimal solutions to arbitrary positions. There's no need to apply the human-optimized ergonomic algorithms or methods that human use to speedsolve. reply Karupan 10 hours agorootparentprevThanks, didn’t know that. Will do some reading tonight. reply curtis3389 13 hours agoparentprevI suppose this shows the purpose of the robot: to demonstrate the electronics. There is nothing interesting about solving a cube (although this robot is incapable of rotating the center), and a 3x3 cube can be solved quite quickly by humans already (3.13s!). I'd love to see them try to do this with any other cube. There's something quite special about the 3x3 that makes it easier to solve. No parity problems like an even cube, and no center pieces to move like a >3 cube. reply spencerchubb 2 hours agoparentprevThe full solution seemed to be 14 moves by the axial turn metric, or 16 moves by the half turn metric. Axial means if you do turns on the same axis, it only counts as one move This robot is able to do optimal solutions that a human wouldn't be able to find reply gilgoomesh 13 hours agoparentprevThe theoretical number of turns needed to solve from any position is 20 so the 16-ish turns I counted in the video doesn't seem far off. Any \"recording breaking attempt\" is going to be a little dependent on a good starting position. reply ugh123 11 hours agoprevThe next evolution of this should be two 5-fingered robot hands doing the work. reply aureliusm 12 hours agoprevThis was the funniest first 3 seconds of a video that I've seen the whole day. Food for geek mind! reply amelius 8 hours agoprevI wonder about the G-forces involved ... reply danbruc 7 hours agoparentFor 90° in 9 ms and a 57 mm cube, I get accelerations of 4.4 million degree per second squared and 225 g at a corner assuming equal and constant acceleration and deceleration during the turn. reply postalrat 12 hours agoprevWhere can I buy that Rubik's cube? reply jdietrich 11 hours agoparentIt's actually a Rubik's brand cube. If you have fingers rather than servo motors, you'll probably have a better time with a Moyu RS3M v5 or an X-Man Tornado v3. https://www.rubiks.com/products/rubiks-3x3 reply RetroTechie 7 hours agorootparentYeah. Back in the late '80s knock-offs were trash without exception. These days, the better (speed)cubes are non-Rubik ones. reply SomeoneFromCA 8 hours agoprevHumans still have higher precision micromotorics (assembling watches for example) reply spencerchubb 2 hours agoparentThe fastest human solver (Max Park) actually has autism and problems with fine motor skills. Just goes to show that cubing is more about macro motor skills reply SomeoneFromCA 1 hour agorootparentThis does not contradict what I've said. reply spencerchubb 1 hour agorootparentI did not intend to contradict but add on. I suppose my usage of 'actually' could be seen as contradicting reply tomalbrc 10 hours agoprevI am confused, how is this impressive? Isn't the premise of computers (software and hardware) to be faster than humans? We have have known and used them for decades because they are faster? It's a neat party trick but... What am I missing? reply bamboozled 9 hours agoparentYou're clearly not in the market of finding investors ? reply tomalbrc 4 hours agorootparentI guess its a nice PR-stunt that this ended up here then? reply teh_infallible 13 hours agoprevThis is incredibly impressive, but I wonder- how does a project like this get proposed and funded? Why would Mitsubishi devote resources to solving a Rubik’s Cube as quickly as possible? reply mitthrowaway2 13 hours agoparentProjects like these attract attention at trade shows. Probably for their servomotors and controls division, because their customers will be interested in doing similar high-speed manipulation for more practical applications, and showing off that you can do this using these products gives a good feel for other things that you might also be able to do with them. reply krm01 13 hours agorootparentSo it’s basically a marketing project? Are you aware of some articles I can read about these types of projects and their economics as well as ROI? reply SmallDeadGuy 10 hours agorootparentprevExactly this. My dad still demonstrates his CubeStormer and other Lego robots on behalf of Arm at trade shows, because both the Lego robot control unit and the phones used for camera/solver are Arm-powered. And CubeStormer 3 set the previous record over 10 years ago at this point. CubeStormer was a hobby project though, so not the same as this robot which looks like it entirely uses company resources. reply vlovich123 13 hours agoparentprevIt’s a visceral demo that execs and customers can interact with to demonstrate Mitsubishi’s expertise in robotics. It’s both for PR purposes (improving the value of the brand) + sales (come talk to us for your robot needs) + defending the R&D departments budget (hey exec, isn’t this thing we built really cool? We’re actually accomplishing progress on long term goals, not just collecting a paycheck and doing nothing). reply jaydeegee 12 hours agoparentprev2 things it's a marketing exercise but it's also R&D an actual test use case for high speed precision motors/controllers. I can imagine this video is almost nsfw for folk building industrial machines. reply brazzy 12 hours agorootparentI know what you mean, but... Not safe for work - because it's their job? reply anigbrowl 12 hours agoparentprev- How can we market our world-class precision manufacturing skills more effectively - What if we make a robot that solves Rubik's cube at insane speeds - Sounds cool, see you in 3 months reply ThrowawayTestr 13 hours agoparentprevIt's a demonstration of extremely fast and precise motors. reply TylerE 13 hours agoparentprevSo they can sell giant expensive industrial robotics. reply elevaet 13 hours agoparentprevIt might be a promotional flex. Here we are talking about Mitsubishi. reply pengaru 13 hours agoparentprevfor all we know this is one of their test cases reply reverius42 12 hours agorootparentNice that some places still hire testers. reply Bengalilol 12 hours agoprev [–] How much energy did it suck? reply kolinko 12 hours agoparent [–] Probably a miniscule amount compared to humans doing the same thing. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mitsubishi Electric's TOKUFASTbot robot has set a new Guinness World Record by solving a Rubik’s Cube-style puzzle in 0.305 seconds, surpassing the previous record of 0.38 seconds.",
      "The robot utilizes a servo motor for rapid 90-degree turns and an AI color-identifying algorithm for quick solutions, demonstrating advanced robotics and AI integration.",
      "The achievement has attracted significant online attention, with many impressed by the robot's speed and the durability of the cube, further highlighted by comparison videos released by Mitsubishi."
    ],
    "commentSummary": [
      "A Mitsubishi robot set a record by solving a Rubik's Cube in 0.305 seconds, showcasing the advanced speed and processing power of modern robotics.",
      "This achievement has sparked discussions about the future implications of robots in warfare, including their potential to change strategic calculations and dominate battlefields.",
      "The conversation also explores the broader applications of such technology in marketing and industry, as well as the importance of personal fulfillment in human activities despite machine superiority."
    ],
    "points": 249,
    "commentCount": 173,
    "retryCount": 0,
    "time": 1717650025
  },
  {
    "id": 40595499,
    "title": "Investigating the Alignment of Seven Saint Michael Cathedrals: Myth or Reality?",
    "originLink": "https://geospatial.netlify.app/posts/gds-2024-04-20-cathedrals/",
    "originBody": "Introduction We read on wikipedia that there are 7 famous Cathedrals built across the past centuries, all related to Saint Michael and all aligned on a straight line. Being more like Saint Thomas than Saint Michael, we say that if we do not see we do not believe. So we consider the perfect alignment as our research hypothesis, and we proceed as follows: Collect the dataset of the cathedrals via manual segmentation of the map. Compute the geodesic line (on a spherical model of the earth) between the first and the last cathedral. draw a geodesic line on the surface of a sphere. Compute the distance between the cathedrals and the geodesic line connecting the first and the last one. compute the distance between a point and a line on the sphere. This methodology has a couple of flaws: The spherical model is an approximation of the surface of the earth. The line is between the first and the last cathedrals as ground truth would bias the result for towards the misalignment of these two. A single line that minimizes the distances between all the cathedrals would reduce the overall error. We start the analysis nonetheless with these two limitations in mind and we see what happens, before deciding where to go next. Dataset collection from shapely.geometry import shape import pandas as pd import numpy as np import geopandas as gpd from IPython.display import Image from copy import deepcopy from keplergl import KeplerGl KEPLER_OUTPUT = False # set to False to see the kepler maps interactively OVERWRITE_CONFIGS = False # Get coordinates from google maps, and teh segmentations from KepelerGl. columns = [\"name\", \"longitude\", \"latitude\", \"geometry\"] geometry_skellig = { \"type\": \"Polygon\", \"coordinates\": [ [ [-10.538210287997396, 51.772185270560065], [-10.538373297938953, 51.7721348360848], [-10.538348846448207, 51.77204909734886], [-10.53876452179865, 51.77191796720246], [-10.53873191981036, 51.771827184569275], [-10.539261702118932, 51.77147918278735], [-10.539147595159863, 51.771378312203616], [-10.538894929750949, 51.77155483557632], [-10.538577060365403, 51.77169605377814], [-10.538422200921415, 51.77178683667508], [-10.538226588991567, 51.77183727153805], [-10.537973923582655, 51.77189274982316], [-10.538055428553408, 51.77197344538836], [-10.53818583650665, 51.77195327151059], [-10.538226588991567, 51.77205414080813], [-10.538210287997396, 51.772185270560065], ] ], } geometry_st_michael_mount = { \"type\": \"Polygon\", \"coordinates\": [ [ [-5.477544937910665, 50.116733166283005], [-5.477912989731039, 50.11667316516922], [-5.4779504187298205, 50.11671316592009], [-5.478093896558475, 50.1166931655488], [-5.4781438018902, 50.11676516684632], [-5.478461948378875, 50.116701165698345], [-5.478349661383472, 50.116313156907054], [-5.47812508739081, 50.116349157855076], [-5.4780876583920275, 50.11629315636868], [-5.47783189356703, 50.11633715754206], [-5.477594843242365, 50.11637315847207], [-5.477519985244801, 50.11645716053674], [-5.477563652410055, 50.11652916218916], [-5.4777008920712955, 50.11652516210019], [-5.4777008920712955, 50.11658116331525], [-5.477507508911883, 50.11666116493737], [-5.477544937910665, 50.116733166283005], ] ], } geometry_mont_st_michel = { \"type\": \"Polygon\", \"coordinates\": [ [ [-1.5118395414485475, 48.636192167017676], [-1.5119505023709103, 48.63616378229307], [-1.5119182879097475, 48.63610701279718], [-1.5122440119059872, 48.636014762229614], [-1.512172424213728, 48.63592014608774], [-1.512283385136142, 48.635884664988474], [-1.5122547500594112, 48.635790048602615], [-1.5121437891370484, 48.63577585612979], [-1.5119612405243346, 48.63579951024894], [-1.511907549755382, 48.63573564410058], [-1.511710683603845, 48.63578295236671], [-1.5116820485271396, 48.63575220199832], [-1.5115782463746592, 48.63577585612979], [-1.5113527451473583, 48.6357971448375], [-1.511259681148302, 48.63582552976841], [-1.5111379820725148, 48.63588703039579], [-1.5110592356123072, 48.63593197311487], [-1.5109983860744136, 48.636005300623694], [-1.5109697509977082, 48.636052608636966], [-1.5107728848461712, 48.63604787783775], [-1.5107514085383815, 48.63614012834475], [-1.5109804891510816, 48.63616851308267], [-1.5110449180734582, 48.63622055172633], [-1.5110735531501636, 48.63624893641774], [-1.511381380223122, 48.63627022492708], [-1.511703524834904, 48.63621818633469], [-1.5118395414485475, 48.636192167017676], ] ], } geometry_san_michele_sacra = { \"type\": \"Polygon\", \"coordinates\": [ [ [7.342461396228171, 45.09750192282457], [7.342770176683438, 45.09750192282457], [7.342788077000524, 45.09747033312251], [7.343105807613863, 45.09751455870019], [7.343092382376297, 45.097568261140914], [7.343101332534344, 45.0976409173037], [7.343195309195373, 45.09771041441673], [7.343275860617843, 45.097903110514835], [7.343249010143678, 45.09802315037865], [7.343105807613863, 45.098209527560805], [7.3428283527112885, 45.09831693108512], [7.342761226525392, 45.098449605747064], [7.342967080162602, 45.09850330730838], [7.342935754608892, 45.09857596228209], [7.342738851130772, 45.09854121426282], [7.342644874469717, 45.09856016773029], [7.342389794963722, 45.098522260789075], [7.342327143856378, 45.098465400329424], [7.342488246703278, 45.098152666790355], [7.342474821465712, 45.09808001127805], [7.3423674195681095, 45.09802315037865], [7.342447970991547, 45.09787152103536], [7.34249719686135, 45.097843090488624], [7.342461396228171, 45.09750192282457], ] ], } geometry_santuario_san_michele = { \"type\": \"Polygon\", \"coordinates\": [ [ [15.954708098648354, 41.70774624650484], [15.95484520240551, 41.70774624650484], [15.955046626444242, 41.70771718285521], [15.955126180475807, 41.70770581011917], [15.955176959645415, 41.707803110128424], [15.955139721587672, 41.70782332829385], [15.955200656591268, 41.70789156455518], [15.955099098251925, 41.70803182775236], [15.954960301855804, 41.708189781437795], [15.954833353932584, 41.70818346329781], [15.954792730596836, 41.70815313621718], [15.954733488233222, 41.7080886911241], [15.95464377836678, 41.708063418520645], [15.954615003503958, 41.707964855273005], [15.954615003503958, 41.70788524638588], [15.954652241561726, 41.70787766458189], [15.954708098648354, 41.70774624650484], ] ], } geometry_taxiarchi_michail = { \"type\": \"Polygon\", \"coordinates\": [ [ [27.84592051904731, 36.54830393321039], [27.846087201698992, 36.54836364773902], [27.846075939357537, 36.548390790691705], [27.84614801834191, 36.548419743163294], [27.846159280683366, 36.548396219281116], [27.846316953461884, 36.54846136232331], [27.84629668124823, 36.548499362405614], [27.846456606495014, 36.54855907678405], [27.846648066297924, 36.548256885367536], [27.846251631882385, 36.54808859861725], [27.846256136818965, 36.54806869370842], [27.84619306770776, 36.548050598332246], [27.846186310302834, 36.54806145555846], [27.846042152333148, 36.548008978951856], [27.846019627651152, 36.548050598332246], [27.846033142459984, 36.54805783648323], [27.846003860373138, 36.5481211702745], [27.84592051904731, 36.54830393321039], ] ], } geometry_stella_maris_monastery = { \"type\": \"Polygon\", \"coordinates\": [ [ [34.96991480318133, 32.8276822842215], [34.96962584007829, 32.8271624051118], [34.97034454318042, 32.826841759593194], [34.97061868766258, 32.827420788523035], [34.96991480318133, 32.8276822842215], ] ], } From the manual segmentations above, and the visually estimated locations of the tower bells in latitude, and longitude we create a 7 rows geopandas dataframe. landmarks_michael = { 1: [\"Skellig Michael\", -10.538483, 51.772035, shape(geometry_skellig)], 2: [\"St Michael's Mount\", -5.477813, 50.116531, shape(geometry_st_michael_mount)], 3: [\"Mont Saint-Michel\", -1.511447, 48.636038, shape(geometry_mont_st_michel)], 4: [\"Sacra di San Michele\", 7.342842, 45.098029, shape(geometry_san_michele_sacra)], 5: [\"San Michele Arcangelo\", 15.954767, 41.707770, shape(geometry_santuario_san_michele)], 6: [\"Taxiarchi Michail\", 27.846123,36.548389, shape(geometry_taxiarchi_michail)], 7: [\"Stella Maris\", 34.969960, 32.827297, shape(geometry_stella_maris_monastery)], } gdf_cathedrals = gpd.GeoDataFrame(pd.DataFrame(landmarks_michael, index = [\"name\", \"longitude\", \"latitude\", \"geometry\"]).T) gdf_cathedralsname longitude latitude geometry 1 Skellig Michael -10.538483 51.772035 POLYGON ((-10.53821 51.77219, -10.53837 51.772... 2 St Michael's Mount -5.477813 50.116531 POLYGON ((-5.47754 50.11673, -5.47791 50.11667... 3 Mont Saint-Michel -1.511447 48.636038 POLYGON ((-1.51184 48.63619, -1.51195 48.63616... 4 Sacra di San Michele 7.342842 45.098029 POLYGON ((7.34246 45.09750, 7.34277 45.09750, ... 5 San Michele Arcangelo 15.954767 41.70777 POLYGON ((15.95471 41.70775, 15.95485 41.70775... 6 Taxiarchi Michail 27.846123 36.548389 POLYGON ((27.84592 36.54830, 27.84609 36.54836... 7 Stella Maris 34.96996 32.827297 POLYGON ((34.96991 32.82768, 34.96963 32.82716... Visualise the dataset on a kepler map # Simple utils to save and load Kepler configurations from pathlib import PosixPath, Path import json class KeplerConfigManager: \"\"\"Save, load and list config files for KeplerGl\"\"\" def __init__(self, path_to_folder: PosixPath = Path().cwd() / \"kepler_configs\"): self.path_to_folder = path_to_folder @staticmethod def _check_name(name_config: str): if name_config.endswith(\".json\"): raise ValueError(\"Name of the config must not include the extension '.json' .\") def _parse_name(self, name_config: str) -> PosixPath: return self.path_to_folder / (name_config + \".json\") def list_available_configs(self): return [f.stem for f in self.path_to_folder.glob(\"*.json\")] def save_config(self, k_map: KeplerGl, name_config: str): self._check_name(name_config) with self._parse_name(name_config).open(\"w+\", encoding=\"UTF-8\") as file_target: json.dump(k_map.config, file_target, indent=4) def load_config(self, name_config: str): self._check_name(name_config) return json.loads(self._parse_name(name_config).read_text(encoding=\"UTF-8\")) kepler_data = deepcopy({\"cathedrals\": gdf_cathedrals.__geo_interface__}) if KEPLER_OUTPUT: kcm = KeplerConfigManager() config_map_1 = kcm.load_config(\"configs_map_1\") kmap_1 = KeplerGl( data=kepler_data, height=800, config=config_map_1, ) display(kmap_1) else: display(Image(\"images/cathedrals_in_a_row.png\")) if KEPLER_OUTPUT and OVERWRITE_CONFIGS: kcm = KeplerConfigManager() kcm.save_config(kmap_1, \"configs_map_1\") Compute the geodesic line between the first and the last cathedral The goal is to compute the geodesic line between the first and the last point, and then computing the distance between all the other 5 cathedrals and the line. As it turns out, estimating the distance between a point and a line on the sphere does not require to have a “drawable” model of the line. Lets first face the problem of: Drawing a geodesic line on the surface of a sphere Given two points 𝑃 1 = ( rad ( Lon 1 ) , rad ( lat 1 ) ) = ( 𝜃 1 , 𝜙 1 ) and 𝑃 𝑁 = ( rad ( Lon 𝑁 ) , rad ( lat 𝑁 ) ) = ( 𝜃 𝑁 , 𝜙 𝑁 ) , for 𝑁 power of two, we can find the geodesic of the sphere with a recursive method on the geodesic midpoint (and this is why we wanted 𝑁 to be a power of two). The geodesic midpoint between 𝑃 1 and 𝑃 𝑁 , is indicated with 𝑃 𝑁 / 2 = 𝑀 𝑆 2 ( 𝑃 1 , 𝑃 𝑁 ) and it is simply found as the intersection between the line passing through the origin and the midpoint of 𝑃 1 and 𝑃 𝑁 in the 3D space, indicated with 𝑀 𝑅 3 ( 𝑃 1 , 𝑃 𝑁 ) , and the sphere 𝑆 2 . To compute the midpoint we then need to go from the sphere to the 3D space and from the 3D space to the projection on the sphere. Let 𝜄 : 𝑆 2 → 𝑅 3 be the projection from the sphere coordinates ( 𝜃 , 𝜑 ) to the 3D space, defined as: 𝜄 ( 𝜃 , 𝜑 ) = { 𝑥 = 𝑅 cos ⁡ ( 𝜑 ) cos ⁡ ( 𝜃 ) 𝑦 = 𝑅 cos ⁡ ( 𝜑 ) sin ⁡ ( 𝜃 ) 𝑧 = 𝑅 sin ⁡ ( 𝜑 ) Note that to respect the lat/lon convention, when 𝜑 = 0 the point ( 𝜃 , 0 ) is on the equator, unlike in most maths text where ( 𝜃 , 0 ) are the poles. The projection from any point of the 3D space over the 2D sphere, that will serve as inverse of 𝜄 : 𝜋 : 𝑅 3 ∖ { 0 } ⟶ 𝑆 2 is given by: 𝜋 ( 𝑥 , 𝑦 , 𝑧 ) = ( arctg ( 𝑦 𝑥 ) , arctg ( 𝑧 𝑥 2 + 𝑦 2 ) ) When 𝑥 = 0 : 𝜋 ( 0 , 𝑦 , 𝑧 ) = ( sign ( 𝑦 ) 𝜋 2 , arctg ( 𝑧 𝑥 2 + 𝑦 2 ) ) and when 𝑥 = 𝑦 = 0 : 𝜋 ( 0 , 0 , 𝑧 ) = ( 0 , sign ( 𝑧 ) 𝜋 2 ) where sign ( 𝜂 ) is the sign function, equal to + 1 when 𝜂 ≥ 0 , and to − 1 when 𝜂float: hav_rad = lambda x: np.sin(x/2) ** 2 return hav_rad(phi_B - phi_A) + (1 - hav_rad(phi_B - phi_A) - hav_rad(phi_B + phi_A) ) * hav_rad(theta_B - theta_A) def haversine_distance(lon_1: float, lat_1: float, lon_2: float, lat_2: float) -> float: theta_1, phi_1, theta_2, phi_2 = map(np.radians, [lon_1, lat_1, lon_2, lat_2]) return 2 * R_Km * np.arcsin(np.sqrt(_hav_function(theta_1, phi_1, theta_2, phi_2))) def hav(p1: Point, p2: Point) -> float: return haversine_distance(p1.lon, p1.lat, p2.lon, p2.lat) def iota(theta: float, phi: float) -> tuple[float]: x = R_Km * np.cos(phi) * np.cos(theta) y = R_Km * np.cos(phi) * np.sin(theta) z = R_Km * np.sin(phi) return (x, y, z) def pi(x, y, z) -> tuple[float]: if x == y == z == 0: raise ValueError(\"Point (0,0,0) can not be projected on the sphere\") if x == y == 0: return (0, np.sign(z) * np.pi / 2) if x == 0: return (np.sign(y) * np.pi / 2, np.arctan(z/y)) return (np.arctan(y/x), np.arctan(z/(np.sqrt(x**2 + y**2)))) def midpoint(p1: Point, p2: Point) -> Point: lon_1, lat_1, lon_2, lat_2 = p1.lon, p1.lat, p2.lon, p2.lat theta_1, phi_1, theta_2, phi_2 = map(np.deg2rad, [lon_1, lat_1, lon_2, lat_2]) x1, y1, z1 = iota(theta_1, phi_1) x2, y2, z2 = iota(theta_2, phi_2) xm, ym, zm = (x1+x2)/2, (y1+y2)/2, (z1+z2)/2 theta_m, phi_m = pi(xm, ym, zm) lon_m, lat_m = map(np.rad2deg, [theta_m, phi_m]) return Point(lon_m, lat_m) And the recursive method to compute the points on the trajectory are: tolerance_Km = 0.1 accumulator = [] # list of objects of class Point def midpoints_rec(p1: Point, p2: Point, bailout) -> None: global accumulator bailout -= 1 if hav(p1, p2)0: mp = midpoint(p1, p2) accumulator += [mp] midpoints_rec(p1, mp, bailout) midpoints_rec(mp, p2, bailout) return se_cathedral_centres_points = gdf_cathedrals.apply(lambda row: Point(row.longitude, row.latitude), axis=1) midpoints_rec(se_cathedral_centres_points.loc[1], se_cathedral_centres_points.loc[7], 14) # convert accumulator into a dataframe of points df_points = pd.DataFrame([[p.lon, p.lat] for p in accumulator], columns=[\"longitude\", \"latitude\"]).sort_values(by=[\"longitude\"], ascending=True).reset_index(drop=True) df_points.head()longitude latitude 0 -10.531190 51.771078 1 -10.523898 51.770120 2 -10.516606 51.769161 3 -10.509315 51.768202 4 -10.502023 51.767243 kepler_data = deepcopy({\"cathedrals\": gdf_cathedrals.__geo_interface__, \"line\": df_points}) if KEPLER_OUTPUT: kcm = KeplerConfigManager() config_map_2 = kcm.load_config(\"configs_map_2\") kmap_2 = KeplerGl( data=kepler_data, height=800, config=config_map_2, ) display(kmap_2) else: display(Image(\"images/cathedrals_in_a_row_with_geodesic.png\")) if KEPLER_OUTPUT and OVERWRITE_CONFIGS: kcm = KeplerConfigManager() kcm.save_config(kmap_2, \"configs_map_2\") Distance between the cathedrals and the geodesic line connecting the first and the last one. Visually we can see that the cathedrals are not aligned over the geodesics. Let’s measure the sum of the distances between each cathedral and the geodesic. We will use the distance between the bell tower and the geodesics passing through the bell towers of the first and the last cathedrals. Distance between a point and a geodesic line on the sphere Finding the distance between a point and a line is equivalent to find the projection of the point on the line itself. Using planes we can find the direction of the projection, as a vector, and then we can project it on the sphere with the function 𝜋 defined above. Let 𝐴 and 𝐵 two points on the geodesic line, and 𝐶 a point on the sphere, we indicate with 𝑑 𝑆 2 ( 𝐶 , 𝐴 𝐵 ⌢ ) the sought distance between 𝐶 and the geodesic passing through 𝐴 𝐵 . Using the cross product × then we can use the following facts: 𝐸 = 𝐴 × 𝐵 is the vector normal to the plane △ 𝑂 𝐴 𝐵 . 𝐹 = 𝐶 × 𝐸 is the vector normal to the plane △ 𝑂 𝐶 𝐴 , which is also perpendicular to △ 𝑂 𝐴 𝐵 and passes through 𝐶 . 𝐺 = 𝐸 × 𝐹 is the vector belonging to the plane △ 𝑂 𝐴 𝐵 , projection of 𝐶 . The projection of 𝐺 on the sphere 𝜋 ( 𝐺 ) is the projection of 𝐶 over the geodesic curve 𝐴 𝐵 , therefore the sought distance is: 𝑑 𝑆 2 ( 𝐶 , 𝐴 𝐵 ⌢ ) = Hav ( 𝐶 , 𝜋 ( 𝐺 ) ) Figure 2 def distance_point_line(point: Point, line: tuple[Point, Point]) -> float: \"\"\"A geodesic line is defined by two points on the sphere\"\"\" if len(line) != 2 or line[0] == line[1]: raise ValueError(\"Line must have two different elements\") A, B = iota(np.deg2rad(line[0].lon), np.deg2rad(line[0].lat)), iota(np.deg2rad(line[1].lon), np.deg2rad(line[1].lat)) C = iota(np.deg2rad(point.lon), np.deg2rad(point.lat)) E = np.cross(A, B) F = np.cross(C, E) G = np.cross(E, F) G_theta, G_phi = pi(G[0], G[1], G[2]) return hav(point, Point(np.rad2deg(G_theta), np.rad2deg(G_phi))) # Sanity checks np.testing.assert_almost_equal(2 * np.pi * R_Km/8, distance_point_line(Point(0, 45), (Point(0,0), Point(90,0)))) np.testing.assert_almost_equal(2 * np.pi * R_Km/4, distance_point_line(Point(0, 90), (Point(0,0), Point(90,0)))) np.testing.assert_almost_equal(2 * np.pi * R_Km/2, distance_point_line(Point(180, 0), (Point(0,0), Point(0,90)))) np.testing.assert_almost_equal(0, distance_point_line(Point(0, 1), (Point(0, 0), Point(0, 2)))) Now we can use the created function to compute all the distances between the geodesic and each cathedral: line = (Point(gdf_cathedrals.loc[1, \"longitude\"], gdf_cathedrals.loc[1, \"latitude\"]), Point(gdf_cathedrals.loc[7, \"longitude\"], gdf_cathedrals.loc[7, \"latitude\"])) gdf_cathedrals[\"dist_to_geod\"] = gdf_cathedrals.apply(lambda row: distance_point_line(Point(row[\"longitude\"], row[\"latitude\"]), line), axis=1) gdf_cathedralsname longitude latitude geometry dist_to_geod 1 Skellig Michael -10.538483 51.772035 POLYGON ((-10.53821 51.77219, -10.53837 51.772... 1.094214e-13 2 St Michael's Mount -5.477813 50.116531 POLYGON ((-5.47754 50.11673, -5.47791 50.11667... 9.303994e+01 3 Mont Saint-Michel -1.511447 48.636038 POLYGON ((-1.51184 48.63619, -1.51195 48.63616... 1.638178e+02 4 Sacra di San Michele 7.342842 45.098029 POLYGON ((7.34246 45.09750, 7.34277 45.09750, ... 2.709241e+02 5 San Michele Arcangelo 15.954767 41.70777 POLYGON ((15.95471 41.70775, 15.95485 41.70775... 2.651008e+02 6 Taxiarchi Michail 27.846123 36.548389 POLYGON ((27.84592 36.54830, 27.84609 36.54836... 1.269761e+02 7 Stella Maris 34.96996 32.827297 POLYGON ((34.96991 32.82768, 34.96963 32.82716... 0.000000e+00 print(f\"Root means squared error: {np.round(np.sqrt(gdf_cathedrals['dist_to_geod'].apply(lambda x: x**2).sum() / len(gdf_cathedrals) ), 4) } Km\") Root means squared error: 167.0303 Km Are the cathedrals aligned on the Mercator projection? With our experiments and measurements we saw that the cathedrals are not aligned in the spherical geometry. Visually on the same line only on the KeperlGl Mercator map projection. As for the previous case the model for the visualisation is different than the model for estimating the distance between the line and the cathedral. Let’s create a straight line between the first and the last Cathedral. df_line = gdf_cathedrals[[\"name\",\"longitude\", \"latitude\"]].loc[[1]].copy() df_line[\"longitude_next\"] = gdf_cathedrals.loc[7, \"longitude\"] df_line[\"latitude_next\"] = gdf_cathedrals.loc[7, \"latitude\"] df_line[\"name\"] = \"single line\" df_linename longitude latitude longitude_next latitude_next 1 single line -10.538483 51.772035 34.96996 32.827297 kepler_data = deepcopy({\"cathedrals\": gdf_cathedrals.__geo_interface__, \"line\": df_line}) if KEPLER_OUTPUT: kcm = KeplerConfigManager() config_map_3 = kcm.load_config(\"configs_map_3\") kmap_3 = KeplerGl( data=kepler_data, height=800, config=config_map_3, ) display(kmap_3) else: display(Image(\"images/cathedrals_in_a_row_with_straight_line.png\")) if KEPLER_OUTPUT and OVERWRITE_CONFIGS: kcm = KeplerConfigManager() kcm.save_config(kmap_3, \"configs_map_3\") The result with a straight line between the first and the last cathedral is more convincing than the previous one, computed with the geodesic line. Before summing the distances between the line and the bell towers though we can think that this approach of joining the first with the last may not be the optimal one. What if we try to fit the points with linear regression? gdf_cathedralsname longitude latitude geometry dist_to_geod 1 Skellig Michael -10.538483 51.772035 POLYGON ((-10.53821 51.77219, -10.53837 51.772... 1.094214e-13 2 St Michael's Mount -5.477813 50.116531 POLYGON ((-5.47754 50.11673, -5.47791 50.11667... 9.303994e+01 3 Mont Saint-Michel -1.511447 48.636038 POLYGON ((-1.51184 48.63619, -1.51195 48.63616... 1.638178e+02 4 Sacra di San Michele 7.342842 45.098029 POLYGON ((7.34246 45.09750, 7.34277 45.09750, ... 2.709241e+02 5 San Michele Arcangelo 15.954767 41.70777 POLYGON ((15.95471 41.70775, 15.95485 41.70775... 2.651008e+02 6 Taxiarchi Michail 27.846123 36.548389 POLYGON ((27.84592 36.54830, 27.84609 36.54836... 1.269761e+02 7 Stella Maris 34.96996 32.827297 POLYGON ((34.96991 32.82768, 34.96963 32.82716... 0.000000e+00 from sklearn.linear_model import LinearRegression model = LinearRegression() x = gdf_cathedrals[\"longitude\"].to_numpy().reshape((-1, 1)) y = gdf_cathedrals[\"latitude\"].to_numpy() model.fit(x, y) m, n = model.coef_[0], model.intercept_ print(f\"Regression line: y = {np.round(m, 3)} x + {np.round(n, 3)}\") a, b, c = m , -1, n print(f\"Implicit form : {np.round(a, 3)} x {np.round(b, 3)} y + {np.round(c, 3)} = 0\") Regression line: y = -0.414 x + 47.873 Implicit form : -0.414 x -1 y + 47.873 = 0 def get_y(input_x, input_m, input_n): \"\"\" in degrees! \"\"\" return input_x * input_m + input_n def get_dist_deg(input_x, input_y, input_a, input_b, input_c): \"\"\" in degrees! \"\"\" return np.abs(input_a * input_x + input_b * input_y + input_c ) / np.sqrt(input_a ** 2 + input_b ** 2) df_regression = gdf_cathedrals[[\"name\", \"longitude\", \"latitude\"]].copy() df_regression[\"latitude_estimated\"] = get_y(df_regression[\"longitude\"], m, n) df_regression[\"latitude_estimated_next\"] = df_regression[\"latitude_estimated\"].shift(-1) df_regression[\"longitude_next\"] = df_regression[\"longitude\"].shift(-1) df_regressionname longitude latitude latitude_estimated latitude_estimated_next longitude_next 1 Skellig Michael -10.538483 51.772035 52.238049 50.142038 -5.477813 2 St Michael's Mount -5.477813 50.116531 50.142038 48.499262 -1.511447 3 Mont Saint-Michel -1.511447 48.636038 48.499262 44.832022 7.342842 4 Sacra di San Michele 7.342842 45.098029 44.832022 41.265163 15.954767 5 San Michele Arcangelo 15.954767 41.70777 41.265163 36.340041 27.846123 6 Taxiarchi Michail 27.846123 36.548389 36.340041 33.389514 34.96996 7 Stella Maris 34.96996 32.827297 33.389514 NaN NaN kepler_data = deepcopy({\"cathedrals\": gdf_cathedrals.__geo_interface__, \"line\": df_regression}) if KEPLER_OUTPUT: kcm = KeplerConfigManager() config_map_4 = kcm.load_config(\"configs_map_4\") kmap_4 = KeplerGl( data=kepler_data, height=800, config=config_map_4, ) display(kmap_4) else: display(Image(\"images/cathedrals_in_a_row_with_straight_line_regression.png\")) if KEPLER_OUTPUT and OVERWRITE_CONFIGS: kcm = KeplerConfigManager() kcm.save_config(kmap_4, \"configs_map_4\") We can see that the line computed with linear regression in degrees is closer to the rows of cathedral than it is for the geodesic. Here as well we can compute the average distance in degrees between the line and the bell towers with the function get_dist_deg implemented above, though this distance would not be a “real” distance in any meaningful sense. Unanswered question Now we know that the cathedrals are not aligned on the geodesic. Are they “almost” aligned on the mercator projection by accident or was there a plan? Did the builders knew the earth was round? Or did they followed some method that is today lost, possibly based on the position of a start or a constellation, resulting in an alignment on the Mercator projection? Certainly 7 cathedrals are too many to be a coincidence, and more historical investigations about the past knowledge would be at this point an interesting project. Bloopers In a first attempt of plotting the regression line with Kepler, we started drawing a straight line between the first and the last point, with the latitude computed via linear interpolation. df_line_regression = gdf_cathedrals[[\"name\", \"longitude\", \"latitude\"]].copy() df_line_regression[\"latitude_estimated\"] = get_y(df_line_regression[\"longitude\"], m, n) df_line_regression = df_line_regression.drop(columns=[\"latitude\"]) df_line_regression[\"longitude_next\"] = df_line_regression.loc[7, \"longitude\"] df_line_regression[\"latitude_estimated_next\"] = df_line_regression.loc[7, \"latitude_estimated\"] df_line_regression = pd.DataFrame(df_line_regression.loc[1]).T df_line_regressionname longitude latitude_estimated longitude_next latitude_estimated_next 1 Skellig Michael -10.538483 52.238049 34.96996 33.389514 kepler_data = deepcopy({\"cathedrals\": gdf_cathedrals.__geo_interface__, \"line\": df_line_regression}) if KEPLER_OUTPUT: kcm = KeplerConfigManager() config_map_5 = kcm.load_config(\"configs_map_5\") kmap_5 = KeplerGl( data=kepler_data, height=800, config=config_map_5, ) display(kmap_5) else: display(Image(\"images/cathedrals_in_a_row_with_straight_line_regression_wrong.png\")) if KEPLER_OUTPUT and OVERWRITE_CONFIGS: kcm = KeplerConfigManager() kcm.save_config(kmap_5, \"configs_map_5\") Can you see what went wrong? Why are all the points below the regression line? Summary Topics A dataset of cathedrals segmentations. Drawing a geodesic between two point. Distance point-to-geodesic line. Linear regression on the Mercator projection. Distance point-line on the Mercator projection. Questions and further experiments Can you draw the geodesic lines between each cathedral the the geodesic between the first and the last one? To compute the distance between cathedrals we considered the geolocation of the tower bell. What about using the closest wall? Geodesics linear regression? Trace the geodesic line with Vincenty’s formula with the same recursive algorithm? These and more will come soon in the next blog posts! Stay tuned!",
    "commentLink": "https://news.ycombinator.com/item?id=40595499",
    "commentBody": "St Michael Sword investigation: Are the 7 Cathedrals on a straight line? (geospatial.netlify.app)241 points by gh_hammour 9 hours agohidepastfavorite168 comments karaterobot 5 hours agoAre any of these actually cathedrals? I see some monasteries and sacred sites, I don't see any cathedrals in that list. The difference is that 7 cathedrals, all named after St. Michael, found in a basically straight line would certainly not be a coincidence. It would be like there being 7 Google complexes in a straight line spread around the world: something's going on here. But 7 random religious sites named after one of the most famous saints is more like there being 7 Burger Kings in a basically straight line: much easier to believe as a coincidence. reply svieira 5 hours agoparentThe extra interesting wrinkle here is that each of the Burger Kings in the straight line are associated with an appearance of the Burger King himself explicitly asking for a shrine in the location, while the others are mostly random franchises stuck up by someone who decided they would like a fast food restaurant here and it might as well be a Burger King. (i. e. Mont Saint Michele the bishop who saw St. Michael originally refused to construct the shrine because he wasn't sure of the veracity of the vision. It was only after he was wounded by St. Michael's sword and the wound refused to heal that he went to establish the shrine. And only then did the wound closed up.) Make of that what you will. reply jvanderbot 4 hours agorootparentThat's neat! However, if each burger king was so enshrined by king burger, then there would again be nothing interesting. So, were these the only sites that were selected in that way? Second, is this a post-hoc story we told about the shrines (perhaps to avoid destruction / re-purposing by a greedy local lord?) reply pclmulqdq 3 hours agorootparentPut another way, if there are 10,000 shrines to this one saint around Europe, the probability that 7 will randomly be in a straight line on the Mercator projection is a lot higher than if there areare associated with an appearance of the Burger King himself explicitly asking for a shrine in the location ...According to the guy trying to sell you a big mac or whatever they are called there. reply PeterCorless 1 hour agorootparentWhoppers. And yes, they are trying to sell you a whopper of a tale. reply sonoffett 1 hour agorootparentprevRoyal with cheese reply miniwark 4 hours agoparentprev- Skellig Michael: monastery, circa 6th century - St Michael's Mount: monastery, 9th century - Mont Saint-Michel: monastery & sanctuary, 708 - Sacra di San Michele: monastery, circa 983-987 - San Michele Arcangelo: sanctuary, 490 (St. Michael, supposedly did appear here) - Taxiarchi Michail: monastery, 18th century (the younger one) - Stella Maris: monastery, 1185 for the latin monastery (but in fact 15th century BCE as part of Mount Carmel) So, none of them are a proper cathedrals but monasteries and sanctuaries. With San Michele Arcangelo & Mont Saint-Michel the only two important ones as pilgrimage destinations. For a partial map of St. Michael churches or alike see: https://www.reseausaintmichel.eu/carte-des-sites/ The \"line\" could easily be \"broken\", if we add for example, the Castel Sant'Angelo in Roma (Mausoleum of Hadrian) or Saint-Michel de Cuxà. Both are far more prestigious than... Skellig Michael than nobody would know about if if was not on this \"line\". reply mandmandam 3 hours agorootparentSkellig Michael is plenty prestigious. It's a UNESCO heritage site and a Star Wars filming location. reply mrbonner 4 hours agoparentprevA cathedral has nothing to do with size of the church. If a church has a bishop resides, it's a cathedral. reply seanhunter 38 minutes agorootparentYes, but a bishop is not ever going to (and could not ever) reside at a monastery because it would be incompatible with their job as a bishop to do what monks do (retire to a life of prayer and contemplation). A bishop is the boss of all the diocesan priests, so needs to be a secular priest not a religious. Source: not religious at all but my brother is a dominican friar so has explained this stuff to me. Also confirmed by this for example https://catholicsay.com/differences-between-a-bishop-archbis... reply pdabbadabba 4 hours agorootparentprevSure. But is that inconsistent with anything GP said? If you look at the list[1], I think you'll see that the sites are obviously not all cathedrals by that definition. The Wikipedia article doesn't claim otherwise; it calls them \"sacred sites dedicated to the Archangel Michael.\" In fact, two of them are just islands named after St. Michael. Another is a religious site, but one that is not dedicated to St. Michael—rather it is located on Mt. Carmel which is associated with St. Michael. [1] https://en.wikipedia.org/wiki/Saint_Michael%27s_line reply sigzero 3 hours agorootparentprevCorrect! The word cathedral comes from a Latin word meaning “seat.” The seat referred to is the seat of the bishop, who is the leader of a group of churches related to the cathedral. The bishop's seat is both a metaphor for the cathedral as the bishop's “seat of power” and his actual chair, the \"cathedra,\" inside the cathedral. reply seanhunter 5 hours agoparentprevWell I'll give you one I know: St Michael's mount in Cornwall (second in his list) is definitely not a cathedral. There is a stately home and smallish castle on a small tidal island on the site of an old monastery but I'm pretty sure it has never been a cathedral. It's not in or near a city for starters. https://en.wikipedia.org/wiki/St_Michael's_Mount p.s. It's a cool place to visit btw. You can walk over to the house at low tide and then the house is on a steep hill surrounded by a lovely garden which you are compelled to enjoy until the next low tide at which point you can walk back to the mainland. Nearby is a heliport where you can get a passenger helicopter to the Scilly Isles which are also worth a visit. reply addaon 4 hours agorootparent> smallish castle This makes more sense, as castles tend to move in straight lines. As another comment mentions, if these were cathedrals that would mean a bishop in residence, and we all know bishops prefer to move diagonally. reply seanhunter 5 hours agorootparentprevOh and the last one \"Stella Maris monastery\" is not at all connected with St Michael, which the wikipedia article acknowledges. It's just somewhat near a mountain that is in a biblical story with St Michael. \"Stella Maris\" means \"Star of the Sea\" and actually refers to Mary.[1] [1] https://epicpew.com/hail-bright-star-ocean-ave-stella-maris/ (worth noting that this source is some sort of Catholic thing and is written in what the Wikipedia banners on some articles used to refer to as an \"in-universe style\") reply egypturnash 3 hours agoparentprevThis is an interesting point. Wikipedia's page on St. Michael's Sword describes it as \"monasteries and other sacred sites\" and also notes that they are also \"almost all located on prominent hilltops\". Only four of the seven locations show up on Wikipedia's list of \"churches dedicated to Saint Michael\" (https://en.wikipedia.org/wiki/Michael_(archangel)#Churches_d...). Also worth noting: \"[Michael's] churches were often located in elevated spots\", says the page on San Michele Arcangelo, Perugia. The obvious next step here is gathering a database of every spot claimed to be sacred to Michael, plotting them on a map, and seeing if this particular set of seven places leaps out of the data. But that sure sounds like work. (Well, that's the obvious next data scientist step, there's also the obvious next step for the magician or priest, which is to go to or create a sacred space suitable for summoning archangels, call down Michael, and say \"hey thanks for coming, so what's up with this line we call your sword?\".) reply larsrc 2 hours agorootparentI would say the next logical step is figuring out the probability that with this many points, what is the likelihood of 7 of them being this close to being on a line? We can assume a uniform random distribution on the unit circle or square for simplicity. reply grahamlee 5 hours agoparentprevIf you add every single other church or shrine that's dedicated to St. Michael to the map, what's the straight line you can draw that contains the most of those locations? reply margalabargala 5 hours agorootparentAs this article found, the answer to that question depends heavily on the map projection you use. reply pdabbadabba 4 hours agorootparentPerhaps we have yet to discover the real St. Michael's sword, which would, of course, be aligned along a geodesic line. reply hef19898 2 hours agorootparentYeah, spherical geometry exists. But using various projections makes for better click bait. reply seanhunter 1 hour agorootparentIn TFA he tries the geodesic line first before trying the various projections. It doesnt' really fit any of them because even with these extremely cherry-picked seven points, you can't retcon them into having been designed to be in a line when they weren't. reply greggsy 5 hours agoparentprevThe author cites this page, which refers to them as ’sites’. I suspect English isn’t their first language, and they’ve missed some nuance. https://en.wikipedia.org/wiki/Saint_Michael's_line reply pantalaimon 2 hours agoparentprevStella maris isn't even named after St. Michael reply arethuza 7 hours agoprevWhen I was a kid (11/12 or so) I was fascinated by finding alignments between ancient things in the landscape (of which there are many here in Scotland!) - eventually I came to the realisation that given the scale of the maps I was looking at (1:25,000) that you can find loads of meaningless alignments if you look hard enough... reply gravescale 7 hours agoparentThe Ancient Aliens discovered the same laws of engineering: 5. (Miller's Law) Three points determine a curve. 6. (Mar's Law) Everything is linear if plotted log-log with a fat magic marker. https://spacecraft.ssl.umd.edu/akins_laws.html reply arethuza 5 hours agorootparentSpeaking of Ancient Aliens - I did have also read a book by Erich von Däniken when I was younger (9 or so) although I had realised that was nonsense by my stage of hunting maps for alignments it probably influenced me to think about it. reply grahamlee 5 hours agorootparentI used to read his books as exercises in critical analysis—how does he get from the data to these conclusions, and what does he ignore that doesn't fit his conclusions? Then I discovered that, as stated by Carl Sagan, von Däniken also relies on factual errors in his arguments. reply theginger 3 hours agorootparentprevAssume pi is 1 reply wolframhempel 6 hours agoparentprevI studied art history, and this always bothered me when learning about Christian symbolism. When reading about numbers related to cathedrals, such as the number of statues on a ledge or the number of archivolts (the bands around doors), so much emphasis was put on the meaning of these particular numbers by whoever authored the piece. Three related to the Holy Trinity, four represented the four Gospels, five alluded to the number of wounds Christ received, seven related to the days of creation, sins, or virtues - and don't even get me started on twelve. In fact, as an architect of a cathedral, you pretty much had to make 22 or more of anything to avoid having a meaning ascribed. reply dfxm12 6 hours agorootparentOne Christmas homily, the priest told a story about how the candy cane was invented by persecuted Christians as a symbol for each other. The cane looked like a shepherd's staff, red for Jesus' blood, etc. If you look into the actual history of the candy cane though, none of this is true. What I'm saying is that it didn't matter what the architect did. Someone, well after the fact, would have found a tenuous connection between their work and the Bible and claimed they were divinely inspired. reply mensetmanusman 5 hours agorootparentNot the candy cane, but the fish: https://en.m.wikipedia.org/wiki/Variations_of_the_ichthys_sy.... reply 082349872349872 1 hour agorootparentDid the fish have anything to do with precession of the equinoxes into Pisces? https://news.ycombinator.com/item?id=38761574 reply mensetmanusman 5 hours agorootparentprevHumans sacrificed animals when relations between abstract numbers and reality were discovered: https://en.m.wikipedia.org/wiki/Pythagoreanism The practice of wonder surrounding numbers and their role in existence has been practiced by nearly every ancient civilization for many millennia. Definitely not unique to Christianity. Definitely as natural as religious practice itself. reply seanhunter 21 minutes agorootparentHumans may have done that, but not the Pythagoreans, who were vegetarians. From that wiki page: > The Pythagoreans also thought that animals were sentient and minimally rational. The arguments advanced by Pythagoreans convinced numerous of their philosopher contemporaries to adopt a vegetarian diet. The Pythagorean sense of kinship with non-humans positioned them as a counterculture in the dominant meat-eating culture. reply noduerme 5 hours agorootparentprevWasn't the whole point of building the thing to make physical all that symbolic stuff in the first place? reply calvinmorrison 5 hours agorootparentThe temple _is_ God's physical dwelling place reply Oarch 7 hours agoparentprevThe Great Glen Fault is beautifully straight line across Scotland. Once seen it can't really be unseen. reply Shrezzing 5 hours agorootparentI'm not sure if this is concrete fact, or just a theory, but you can continue the line up Norway's western coast too. Then in the other direction, the line was broken, but restarts & progresses from Nova Scotia down through the Appalachians in North America. reply kitd 5 hours agorootparentIIRC they were all part of the same Pangaian range, and include Greenland east coast and the Atlas mountains. reply arethuza 6 hours agorootparentprevMy own favourite is the Highland Boundary Fault - the northern edge of the rift valley that is central Scotland: https://simple.wikipedia.org/wiki/Highland_Boundary_Fault reply jfengel 5 hours agorootparentprevI'm gonna be driving along most of Loch Ness early this autumn. Anything in particular I should look out for with respect to the Great Glen Fault? Any less-obvious geologic features? reply arethuza 5 hours agorootparentNot related to the Great Glen Fault but the Parallel Roads in Glen Roy are fairly close and worth a look: https://en.wikipedia.org/wiki/Glen_Roy#The_Parallel_Roads_of... Edit: Also have a look at the Lochaber Geopark: https://lochabergeopark.org.uk/ reply jfengel 2 hours agorootparentThanks! I'll keep an eye out. reply noduerme 6 hours agoparentprevI had a similar obsession for awhile. Take any 2 really famous places in the old world and draw a great circle line between them on Google Earth... and it's astonishing what falls under that line. (Try Avignon and Jerusalem, for example). reply spiderfarmer 7 hours agoparentprevIt's a type of apophenia. reply LudwigNagasena 7 hours agorootparentMore like the garden of forking paths, the look-elsewhere effect and data dredging. reply Blahah 6 hours agorootparentAs opposed to the forking of garden paths, the whereelse-look effect, and dreading dating reply OnACoffeeBreak 7 hours agoprevMatt Parker (\"Stand up Maths\" channel on YouTube) gave a very informative and entertaining lecture in 2010 titled \"Clutching at Random Straws\" [0], which, among other things, covered something similar. From the subtitle of the video: \"Did aliens help prehistoric Britons find the ancient Woolworths civilisation?\" The answer is \"no\". Given enough data points, you can find all sorts of patterns. 0: https://www.youtube.com/watch?v=sf5OrthVRPA reply SilverBirch 7 hours agoparentI've got to assume that this is partly a Birthday Problem - that the probability of something unlikely being true grows rapidly as the population grows. Probability of 3 random churches lining up? Small, probability of 3 churches lining up when there are 100,000 churches in Europe? Basically 100% reply Tachyooon 6 hours agorootparentThat's one of the examples he goes into in his talk, at a high level anyway. I'd love to find a write-up of someone who has done the detailed calculations of how likely alignments and shape occurrences are. Another thing that would be interesting is to look at the effect of non-uniformly distributed birthdays. For example, the day that's nine months after valentine's day or christmas might (?) have a slightly higher number of births than an average day. Then you could look at what kind of an effect this would have on the probability of a common birthday as a function of group size. reply smusamashah 6 hours agoparentprevThanks for the link. Gist was that with enough data, lots of patterns are inevitable. He gave example from some text taken out of bible with spaces removed. That's lots of letters on one screen, and from those letters he was able find his name, date and topic of the talk, when joining letters at equal distance. Finding unbelievable patterns is not as amazing as we think. reply abrenuntio 6 hours agoparentprevCheck it :-) Other popular saints and devotions are \"Mary\", \"Joseph\", \"Paul\", \"Sacred Heart\", ... can you easily get seven sufficiently special ones on a line for those? reply voidUpdate 8 hours agoprev> Did the builders knew the earth was round? Yes. This has been known since ancient greek times, and Aristotle calculated the size reasonably well. Maybe not every labourer knew or cared but the architects almost certainly did reply jameshart 3 hours agoparentKnowing the earth is round doesn’t mean you automatically consider a geodesic the most logical kind of ‘straight line’. Mercator exists because it’s easy to navigate with. It’s easy to navigate with because it preserves bearings. Lines of constant bearing are, when you’re navigating on the ground, much more meaningfully ‘straight’ than geodesics. ‘Keep heading North West’ sounds like a pretty straight line. reply smeej 8 hours agoparentprevExactly. I think I'm more annoyed at this point with the myth of the ignorant Medievals than I am with the myth of the flat earth itself. Even knowing the earth is round, if I were going to put things in a \"straight line\" geographically, I'd do it with the reference most people would actually use and see: a 2D map. reply Archelaos 7 hours agorootparent> most people would actually use and see: a 2D map The expert used spherical mathematics. This was quite widespread knowledge required to build proper sun dials and in the Late Medieval period for long distance navigation. Some were able to use analog computers, called \"armillary spheres\", for the calculations, which were known since Antiquity.[1] [1] See https://en.wikipedia.org/wiki/Armillary_sphere reply smeej 6 hours agorootparentMost people aren't experts. If I'm setting up a bunch of churches in a line to make a point, I'm doing it to make a point to the vast swath of common people in them, not the handful of experts. reply buildsjets 2 hours agorootparentYou have made the assumption that the line-up was done for the sake of human people, whether common or expert. When choosing the site to build a religious facility, would not the sake of the deity(s) being worshiped be a primary consideration? reply Archelaos 5 hours agorootparentprevOnly the experts of that time could have found out that this churches are all lined up according to the Meracator projection, if they had any idea of that projection at all. It seems rather as if your top-secret St. Michael's conspiracy, which, without leaving any written traces, when carrying out its secrete plan over several centuries using advanced cartographic and geodetic knowledge to determine longitudes, was aimed at the mystery-susceptible people of our times. reply crabmusket 5 hours agorootparentprevThat's not necessarily true. I recently read Barnabas Calder's Architecture: From Prehistory to Climate Emergency which contains several mentions of the incredible detail architects put into their work- from ancient Greece through mediaeval cathedrals. Details and design which would not have been noticed by any eye but an expert's. I'll try to look up an exact quote later. But the gist of several passages was that there was an elite or expert community- obviously, or nobody would have been designing buildings like this! Let's assume for the sake of this discussion that the 7 sites are deliberately aligned by somebody. They would presumably be a powerful elite, and would be doing it to impress other powerful elites. reply Archelaos 3 hours agorootparentYou may perhaps be interested in these two documentaries about the geometric principles that were fundamental to medieval town planning: \"Die Entdeckung der mittelalterlichen Stadtplanung\" (2004): https://www.youtube.com/watch?v=-ZzEzhIGnwM \"Mittelalterliche Baukunst – Schönheit ist planbar\" (2009) https://www.youtube.com/watch?v=MQcKOkbagDc Both documentaries are in German, but are well worth watching, even if the automatic English subtitles are sometimes a little inaccurate. reply searedsteak 8 hours agorootparentprevI'd say the bigger question is whether or not the projection used at the time of design was one that would show the straight line. The Mercator projection was first invented in 1569 [1] [1]: https://en.wikipedia.org/wiki/Mercator_projection reply regularfry 7 hours agorootparentThis has to be the core of it. If the underlying question is \"was this alignment intentional\" then you could start by asking whether there are extant maps with better cathedral alignment than Mercator. These places are old. Skellig Michael goes back past 823AD, Mont-Saint-Michel is about the same sort of age, and the Sanctuary of Monte Sant'Angelo goes back to 490AD(ish). San Michele Arcangelo is on top of a pre-Christian pagan temple. Stella Maris is on an Old Testament Biblical site. None of them is less than a thousand years old. The bar for finding a map that happens to align, and then explaining how it was made, is not a low one. There is a projection that might fit, though: Plate Carrée is definitely old enough, and a brief visual sanity check doesn't make it look totally off. reply smeej 6 hours agorootparentWhy do we need to assume widespread maps for this? Or even maps of the entire globe? A regional map showing barely more than a rectangle with this as its diagonal would be sufficient to get the point across to the average layperson. Virtually everything in church design is meant to communicate truths of the faith to illiterate laypeople. That's part of why pictures feature so prominently. They're telling stories to people who can't read. The sense of space, and the drawing of the attention upward, they're also communicating to people on purpose. If the argument is that the sites were not intentionally built in a line, that it just happened this way, that there just happen to be seven prominent hills with churches built on them that refer to St. Michael (or 6 and Mt. Carmel, which is associated with him in another way), I guess that's a different conversation, but I thought the idea here was that these were lined up somehow on purpose, at least for the latter built ones, and were intentionally built to be \"in a line\" by some meaning of the term. reply regularfry 2 hours agorootparentThe line is long enough for the curvature of the earth, and the subsequent distortion in the map projection, to be relevant. Notice that they're closer to a straight line on Mercator than to the geodesic: that means if you were to use purely local referencing to align the sites, they wouldn't end up where they are. You only get them to line up when you distort the natural geography with a projection of some sort, so if you want to make an argument that they were intentionally built on a line, you also have to account for the systematic deviation from the geodesic. And that prompts the question of whether that's remotely feasible given what we know of the history of cartography. What I'd want to know is how old the story of St Michael's Sword actually is. Not the churches, but what's the earliest reference to them being in a line. My bet is that it's well after Mercator, and probably safely after the 18th century, when chunks of Europe got geodetic surveys done. reply gruturo 8 hours agoparentprev> Aristotle calculated the size reasonably well Eratosthenes. https://en.wikipedia.org/wiki/Earth%27s_circumference#Eratos... https://en.wikipedia.org/wiki/Eratosthenes#Measurement_of_Ea... reply voidUpdate 7 hours agorootparentSure, Eratosthenes got it more accurately than Aristotle did, but Aristotle was only 5000 miles out, came before Eratosthenes (died about 50 years before Eratosthenes was born) and on the scale of a planet, with the technology he had available, I'd say thats reasonably good reply dhosek 6 hours agoparentprevOne of the incorrect things about Columbus that I was taught in second grade was that he had trouble getting support for his voyage because his would-not-be patrons thought the earth was flat. In fact, they refused to fund him because he thought the earth was much smaller than it was and they had the correct size of the earth. reply buescher 5 hours agorootparentIt’s historically rooted in Protestant anti-Catholicism, and the most popular version in America of it comes from Washington Irving. reply deepsun 5 hours agorootparentprevI wonder how many would-be Columbuses were before him and failed. reply Almondsetat 8 hours agoparentprevIt seems strange to include such a question at the end of the article that can be answered with a 5 second non-AI search reply logtempo 7 hours agoprevAre they aligned because they are famous, or are they famous because they are aligned? Or are they aligned because if I pick 7 famous monuments aligned I can draw a line, look over my shoulder and say \"ho look, if we draw a line it match!\" From wikipedia, the list of St Michael churches: St. Michael's Church (disambiguation) Parroquia de San Miguel Arcángel (es), San Miguel de Allende, Guanajuato Mexico World Heritage Site Sacra di San Michele (Saint Michael's Abbey), near Turin, Italy Pfarrei Brixen St. Michael with the White Tower, Brixen, Italy Cathedral of St. Michael and St. Gudula, in Brussels, Belgium Mont Saint-Michel, Normandy, France – a World Heritage Site St. Michael's Cathedral Basilica (Toronto), Canada St. Michael's Cathedral (Izhevsk), Russia St. Michael's Cathedral, Qingdao, China Chudov Monastery in the Moscow Kremlin Cathedral of the Archangel in the Moscow Kremlin – a World Heritage Site Sanctuary of Monte Sant'Angelo, Gargano, Italy – a World Heritage Site St Michael's Mount, Cornwall, UK St. Michael, Minnesota St. Michael's Basilica, Miramichi, Canada Skellig Michael, off the Irish west coast – a World Heritage Site St Michael's Cathedral, Coventry, UK St. Michael's Golden-Domed Monastery, Kyiv, Ukraine St. Michael's Church, Vienna in Vienna, Austria Tayabas Basilica, Tayabas, Quezon, Philippines St. Michael's Church, Berlin, Germany San Miguel Church (Manila), Philippines St. Michael's Jesuit church, Munich, Germany St. Michael's Cathedral, Belgrade in Belgrade, Serbia Cathedral of St. Michael the Archangel in Gamu, Isabela, Philippines Mission San Miguel Arcángel, San Miguel, California, United States, one of the California Missions St Michael at the North Gate, Oxford, UK St. Michael's Roman Catholic church, Cluj-Napoca, Romania St. Michael's Church, Mumbai, India Church of St. Michael, Štip, Republic of North Macedonia St Michael and All Angels Church, Polwatte St Michael's Church, Churchill, UK San Miguel Arcangel Church, Marilao, Bulacan, Philippines San Miguel Arcangel Church, San Miguel, Bulacan, Philippines St Michael the Archangel, Llanyblodwel, England reply Archelaos 7 hours agoparentThis Wikipedia list has a lot more St. Michael's churches: https://en.wikipedia.org/wiki/St._Michael%27s_Church Around 150 in Europe alone. For the next hackaton: Write a programme to find all possible approximately straight lines between any 7 of these churches. reply mikhailfranco 2 hours agorootparentThere really are many more. I know of 3 in a small area of Somerset not on the list, but 2 of them are ruined, and hence not currently dedicated: https://en.wikipedia.org/wiki/Church_of_St_Michael_and_All_A... https://en.wikipedia.org/wiki/Burrow_Mump https://en.wikipedia.org/wiki/Glastonbury_Tor Churches were often dedicated to St. Michael when they were built over pagan sanctuaries, because St. Michael could fight the old heathen devil. Another example would be in Brent Knoll, next to the iron age hill fort: https://en.wikipedia.org/wiki/St_Michael%27s_Church,_Brent_K... https://en.wikipedia.org/wiki/Brent_Knoll_Camp That is undoubtedly the case for both St. Michael's Mount (Cornwall) and Mont Saint Michel (Normandy) in the list of 7. They are both perfect defensive sites, on islands close to the shore, but accessible by causeways at low tide, and hence certainly occupied from prehistoric times. https://en.wikipedia.org/wiki/St_Michael%27s_Mount https://en.wikipedia.org/wiki/Mont-Saint-Michel reply mikhailfranco 2 hours agorootparentP.S. I added these to Wikipedia, but note there is a whole separate page for Michael with All his Angels: https://en.wikipedia.org/wiki/St_Michael_and_All_Angels_Chur... reply acjohnson55 5 hours agorootparentprevAlso, allow the map projection to vary, to produce lines of different curvatures. reply abrenuntio 5 hours agoparentprevDefinitely not ordinary places. Perhaps Stella Maris, the end point, is the most fascinating of all because of its association with the prophet Elijah. reply AdmiralAsshat 7 hours agoparentprevSee: ley lines https://en.wikipedia.org/wiki/Ley_line?wprov=sfla1 reply mikehotel 6 hours agorootparentAlso: Alignments of random points https://en.m.wikipedia.org/wiki/Alignments_of_random_points reply simonh 7 hours agoparentprevThere are apparently 816 churches dedicated to the saint in England alone. https://en.wikipedia.org/wiki/Dedications_in_the_Church_of_E... reply Maken 7 hours agoparentprevBut only 7 of those are Cathedrals, and only those are aligned. reply tecleandor 7 hours agorootparentI think none of them are cathedrals. There's a couple islands, a mount, a shrine, a monastery, a temple... reply throw46365 7 hours agorootparentThe fact that St Michael's Mount is on this line is enough to show that it is nonsense. It's an unbelievably lovely place and it was a site for pilgrims, but its ecclesiastical connection to St Michael is relatively weedy; a brief period of time. It's far more interesting to me that Perkin Warbeck occupied it! reply rob74 7 hours agorootparentprevYup... actually the linked Wikipedia page doesn't use the word \"cathedrals\", but they are remarkable in other ways (long history, pilgrimage sites etc.). Ok, Skellig Michael is now remembered mainly for being Luke Skywalker's island in Star Wars VII/VIII, but still... reply jfengel 5 hours agorootparentIt annoyed me as soon as it appeared at the tail end of TLJ. I've wanted to visit it for a long time, but it's a bit of a hassle to get to. I can only imagine that it's even harder now that it's a pilgrimage site for Star Wars fans, and not just rock-botherers like myself. reply nabla9 6 hours agorootparentprev>.. are aligned. Only on Mercator projection that is younger than many of the sites on the line. Oder of things: 1. There were bunch of monasteries (not cathedrals), not aligned on any direct line. 2. Mercator invented a projection. 3. Someone looked at map using Mercator a projection and invented story about ley lines. reply unholiness 3 hours agorootparent> Only on Mercator projection that is younger than many of the sites on the line. People have been specifying locations in terms of NS/EW coordinates since the greeks. Celestial navigation ensures we always have a clear idea where north is, and when two locations are at the same latitude. It's the most natural way we've understood and discussed far-away places. I don't think it's fair to say mercator invented this projection so much as he famously published maps which used it. (btw, I agree this line is a complete retrospective coincidence, just not with this particular argument) reply nabla9 3 hours agorootparentJust like weberer you seem to think that there is only one projection of earth into 2d map. Mercator is special projection that was not used before him. Different projections give different distortions. reply jameshart 3 hours agorootparentprevThe Mercator projection has the property that lines on it are of constant bearing. You don’t need a map projection to follow a line of constant bearing - you just need to head towards the point where the same star rises every night (mostly. Over a short enough number of nights, it works, anyway). reply weberer 6 hours agorootparentprevI think too much weight in this discussion is given to the Mercator projection since that's the specific one we use today. People were making 2D maps for much longer than that. Flat maps existed in the medieval era. reply nabla9 5 hours agorootparentAll maps on paper are flat. There are multiple projections into 2d map. There is no reason to assume that the lines align in other projections. reply Maken 6 hours agorootparentprevYou are right, not all the temples in the \"line\" are cathedrals, which does make the entire story less credible. reply jfengel 5 hours agorootparent\"Cathedral\" is a very specific kind of church, but not necessarily all that significant. It's where they happened to have centered a local bishopric. (A cathedra is a chair, specifically one that a bishop sits in.) So there are a lot of magnificent churches that aren't cathedrals (Sagrada Familia, Westminster Abbey, St. Peter's in the Vatican), and a lot of cathedrals that are actually rather dull architecturally. reply Maken 4 hours agorootparentPrecisely cathedrals are rare enough that seven of them in a line dedicated to the same archangel could no be a coincidence. I bet you can make similar lines if you look for churchess and sanctuaries dedicated to another important saint or saintess. reply tokai 8 hours agoprev> Certainly 7 cathedrals are too many to be a coincidence With the number of cathedrals in Europe I don't really think this is supported. reply chippy 7 hours agoparentThey are all dedicated to the same saint, St. Michael. reply Broken_Hippo 7 hours agorootparentWhich isn't really all that special. In England alone, there are 816 churches named after St Michael. He's pretty popular. It'd be a lot more spectacular if they were all named after someone much more obscure. https://en.wikipedia.org/wiki/Dedications_in_the_Church_of_E... reply willis936 7 hours agorootparentOnly ~30 are cathedrals, still more than a selection of 7. https://en.wikipedia.org/wiki/Cathedral_of_Saint_Michael reply SamBam 3 hours agorootparentRight, but none of the 7 are cathedrals. reply chippy 6 hours agorootparentprevThat's right. I would actually expect there to be a few more than 7! And if we extend the search to all placenames dedicated to St Michael quite a bit more! It's not pure coincidence but it is a kind of observation error as highlighted in other comment. Increasing and decreasing the variables and measurements effects the odds. Basically you can get a line between many things on earth, but 1) the dimensions of that line cannot be chosen if you also want to choose the things that define it or 2) the dimensions can be chosen but the things that make it up cannot. reply 6510 4 hours agorootparentIf one finds all of those lines one might find something. Also compare star maps. reply nashashmi 6 hours agorootparentprevIn that case he should plot which of them match the geodesic line curve reply mytailorisrich 7 hours agoparentprevThere are not all cathedrals, actually. They are seven sacred sites dedicated to St Michael (of which there are many all over Europe). If they really were cathedrals, a coincidence would have been extraordinary. reply masswerk 7 hours agorootparentIf they were cathedrals, this may raise the question why those towns were perfectly aligned, in the first place. Traditionally, it had been mostly exposed locations that were dedicated to St Michael, e.g., locations that had been alleged entrances to the underworld in antiquity. 6 out 7 of these locations are in costal areas, with corresponding erosion features. So this shouldn't be of much surprise, as the line crosses several costal regions – of which there are plenty. (In other words, the line crosses 6 costal areas with a St Micheal nearby and 6 without. The second fact may be as remarkable as the first one.) Edit: Challenge, can we identify a \"St Michael's Serpent\", approximating a sine wave? reply TillE 5 hours agoprevMore interesting to me here is the history of the \"line\". Is this a medieval idea or a modern one? Wikipedia is surprisingly unhelpful. \"According to legend\", yeah ok. Who first wrote about this? Who picked those seven sites? The earliest source mentioned is from 1969, and it's not even about this particular line. There's no shortage of writing about esoteric Christian topics throughout the centuries, but this one seems really thin and really modern. reply SamBam 3 hours agoparentRight, that's the biggest thing. If medieval builders were deliberately placing these in a line, there would be documentation and discussion about it. reply dougdimmadome 6 hours agoprevSkellig Michael is not a Cathedral by any stretch of the imagination. It is a cluster of stone beehive huts on an island. It should be recognisable to most people these days as the place Luke Skywalker was hanging out in the new Star Wars sequels, as the movies used it as a filming location in 2015 and 2017. It's a UNESCO world heritage site and a huge tourist attraction long before Star Wars, but it is definitely not a Cathedral. reply dougdimmadome 6 hours agoparent...and, fun fact, the \"porgs\" only exist because the island is also a wildlife refuge and home to thousands of birds who happily walked across the set during takes, so they had to be CGI'ed out. reply jfengel 5 hours agorootparentUnder ordinary circumstances they would have kept the birds out of the shoot. But Skellig Michael is extremely protected, and that includes not being allowed to touch the birds. CGI'ing over them is a genius solution that makes me absurdly happy. reply dougdimmadome 5 hours agorootparentme too =) reply 0xRusty 7 hours agoprevI feel a new Dan Brown novel coming on! Probably is a coincidence given these countries were basically at war the whole time so getting agreement to even start a project like this is unlikely. Very interesting nonetheless. reply reedf1 7 hours agoprevThis is probably, given the sheer number of churches (of all saints) in Europe, the look-elsewhere effect. https://en.m.wikipedia.org/wiki/Look-elsewhere_effect reply dark-star 4 hours agoprev> Certainly 7 cathedrals are too many to be a coincidence A very far-fetched claim without any proof. Simple answer: selection bias > Did the builders knew the earth was round? If he had just googled that he would have gotten the answer, which is, of course, \"yes\" reply pjs_ 47 minutes agoprevhttps://archive.org/details/b29827553 reply Duanemclemore 5 hours agoprevI wish I could link to a great portion of the Eco book Foucault's Pendulum here - it's quite relevant to how we go trying to find meaning in things. If you haven't definitely a novel worth a read. I'm surprised no one has mentioned From Hell here, which plays with the concept of drawing symbols using lines between landmarks. Alan Moore got a lot of his ideas for that from Iain Sinclair, whose books are well worth a read as well. Specifically, the material Moore references is from Lud Heat iirc. reply gorgoiler 7 hours agoprev> Certainly 7 cathedrals are too many to be a coincidence… Aha, but two of them will always be on a straight line. It’s only the other five that are the coincidences. reply randomtoast 7 hours agoprevOne might begin to calculate the odds of seven cathedrals aligning perfectly in a straight line purely as a result of chance. reply 082349872349872 7 hours agoparentOne might indeed begin; see https://news.ycombinator.com/item?id=40595595 (600 was for rough number of cathedrals, but apparently these 7 sites are not even all cathedrals? That would make that factorial much bigger, then...) reply mensetmanusman 5 hours agoparentprevThis would be an extremely difficult calculation to build consensus around, because so many assumptions would go into where exactly one could even consider building such sites. They would have to be near enough to water to maintain life, or have access to freshwater for the religious communities there, they would have to be near building materials, they would have to be near population centers, etc. reply ot1138 7 hours agoparentprevPlease do so! This would be a fascinating experiment and perhaps a famous one, given that similar answers are the knee jerk reaction of armchair skeptics the world over. reply randomtoast 7 hours agorootparentI asked GPT-4. It did the following calculation (summarized): Let's consider Europe as roughly a 10 million square km area. The probability of a single point falling within a 50 km wide band (assuming the band runs the full length of Europe) is about 0.01581 (1.581%). The probability of seven points aligning within a 50 km wide band across Europe is approximately: 10^-14 reply robertlagrant 7 hours agorootparentDoesn't the first point have a probability of 1? It's the subsequent ones that become less and less likely. reply randomtoast 7 hours agorootparentMaybe my question was not right then. But my question was how likely is it that 7 randomly chosen points fall within a given 50 km band across europe. Because I want to test the hypotheses that the 7 cathedrals fall randomly in line that we see. And that one random point falls in that band is not 1. reply robertlagrant 6 hours agorootparentYes, but I suppose even if you have 7 that line up, they may not fall in your band. To remove that constraint, so it's just any band, I think it should be more like: given a cathedral is in a particular place, how likely is it that six other cathedrals fall in a 50km wide band aross Europe. reply randomtoast 6 hours agorootparentOkay, GPT4 said there a just 189 non-overlapping 50km bands (horizontal, vertical, and diagnoal) in Europe and then continued to calculate the chance to land those 7 points in any of the 189 bands and gave a result in the order of 10^-12. reply 082349872349872 51 minutes agorootparentsearch box tells me 600 choose 7 is 5e15, which implies (if google and GPT4 were correct) that there ought to be on the order of thousands of fat lines containing 7 actual cathedrals reply robertlagrant 6 hours agorootparentprevBut diagonal at what angle? :) I think if you set the probability of the first one at 1, then the rest works perfectly at any angle of band. I could be wrong, but intuitively that seems correct. reply jimktrains2 6 hours agorootparentprevYou could have two points in 2 of your non overlapping bands that are less than a band's width apart. Also, the probability of the first 2 points will always be 100% because they define the line. Also, it's not 7 random points, it's 7 of thousands of random points. reply randomtoast 5 hours agorootparentAlright, I suppose it's not as simple to formulate the question accurately and correctly. reply regularfry 6 hours agorootparentprevIt's pretty easy to Monte Carlo, even if you can't get there analytically. reply Zobat 7 hours agoprevFrom the article it's quite obvious they're not on a line (as drawn on a spherical representation of earth), but i wonder if they're close to being on the same plane? reply dave333 4 hours agoprevThe location of the 3 northernmost sites is on existing geographic features that predate Christianity so there was no choice of location for those. However the church may have noticed these three were in a straight line and extrapolated from there. reply denton-scratch 2 hours agoprevHow many other cathedrals/shrines are not \"on\" this line? If the surrounding countryside is peppered with shrines to St. Michael, then any line you choose to draw would pass through/close to a number of them. That is: TFA seems to be ignoring the null hypothesis. reply irrational 3 hours agoprev> we know that the cathedrals are not aligned on the geodesic Maybe not exactly aligned, but looking at that image of the geodesic line and the location of the churches, they all seem close enough to make me think their locations are not random chance (especially since they were laid out in the days before satellites and airplanes). I presume these are all Catholic churches? Could the medieval Catholic Church have had a plan to do this? reply SamBam 3 hours agoparentI also wondered about the strategy of joining the first and last church. The authors switched to a regression for their last test, but only on the Mercator projection. (I actually remember in 7th grade that our math teacher had to repeat time and again that a line of best fit does not necessarily need to join the first and last dot. For some reason it's a very instinctual thing to do.) reply lalaithion 6 hours agoprev> Or did they followed some method that is today lost, possibly based on the position of a start or a constellation, resulting in an alignment on the Mercator projection? I would not say that the method is today lost; while not aligned on a geodesic, the cathedrals are aligned on a spiral starting at the North Pole and ending at the South Pole which always travels at a constant bearing. It’s totally possible to recreate a line like this with a compass by walking such that the compass has a constant reading. Doing so over the Mediterranean, multiple mountain ranges, and bits of the Atlantic would be a bit difficult, though. reply mensetmanusman 1 hour agoparentI wonder if the answer is along these lines. Eg. a star path relative to the horizon from some reference point… reply yergi 6 hours agoprevFaulty math because the map that the points are being plotted on needs to match the type of calculation performed for the line placed upon it. Of course it's going to be off with any other method than that of the map itself. reply SilverBirch 7 hours agoprevThere's a different way of going about this. So the author uses various projections and evaluates whether the churches are aligned. But this is backwards. The churchs were selected because they lined up. And they lined up on a mercator projection. There's simply no way that the churches could line up on different projections (subject to certain conditions). So, let's just look at the churches as they line up on the Mercator projection. If you google the churches one by one, you start to notice a pattern. They all predate the invention of the Mercator projection. You also notice, as someone else pointed out, there's a hell of a lot of Churches called St Micheals. reply onion2k 6 hours agoprevI'm not a civil engineer so I don't know for sure, but I'd guess you can't just throw a cathedral up just anywhere you want. The land has to be the right composition, you need to have good enough transport links to get the raw materials to where you're building it, you need local talent to actually build it, it can't be in the sea. It'd be surprising if these buildings were exactly aligned. Presumably people could easily say that the respective diocese(s) are aligned though. reply lloeki 6 hours agoparentTell that to the people that decided that Strasbourg should have a cathedral: the whole area is a freaking swamp (water table + sand and clay). Not to fret, they punched 15cm x 1.5m tree trunks into the ground, as if you were standing on a thousand toothpicks. Local myth has it that the second spire wasn't build because it would topple over. Probably many more examples like this one exist. \"I don't care. Figure it out. You're the expert.\" https://m.youtube.com/watch?v=BKorP55Aqvg reply rpz 5 hours agoprevThe article checks the Mercator projection but doesn’t check the Equirectangular projection, which could have been known to the builders of each cathedral. I wonder if the line is bang on in that projection. reply deepsun 5 hours agoprev> Did the builders knew the earth was round? Long before St. Michael was born, yes. reply neaden 4 hours agoparentSt. Michael is an Angel, so either has existed since before the Earth was made or if you want the earliest literary reference from the Book of Enoch which dates to around 300 BCE but might have existed in an oral tradition before that. Earth being round dates to around 500 BCE so depending on how old the oral tradition of the angel Michael were around was probably earlier but maybe contemporary. reply 082349872349872 47 minutes agorootparent> \"Once upon a time, there were four little angels who went to the police academy and they were each assigned very hazardous duties. But I took them away from all that and now they work for me. My name is YHWH.\" —not Aaron Spelling reply mensetmanusman 8 hours agoprevThese took nearly 4K years to build in total. Beautiful to see how much thought went into the placement. reply bsza 5 hours agoprevEven if they are not on a great circle, they could be on a circle (still unlikely as 4 of them would have to be aligned with the other 3). reply paipa 7 hours agoprevHe managed to get my attention starting with the cathedrals' polygons and exact bell tower positions, only to pull a \"50 kilometers off, nevermind\". reply smeej 6 hours agoparentI didn't understand what the bell towers had to do with anything. If you're going to pick a piece of architecture that mattered to the architect in terms if \"where the thing is,\" go with the altar. reply maratc 8 hours agoprevSeems reasonable to try to fit a line such that the sum of distances (or square distances) between the cathedrals and the line is minimal. Doesn't have to be a straight line. reply klaussilveira 3 hours agoprevThis is why I come to HN. Fascinating investigations, perfectly executed by genius fellow hackers. Thank you. reply nonrandomstring 6 hours agoprevTexas sharpshooter fallacy? 800 shots. Pick 7. [0] https://en.wikipedia.org/wiki/Texas_sharpshooter_fallacy reply m3kw9 3 hours agoprevIs there selection bias so a straight line is made by selecting the ones that fit? reply kedv 6 hours agoprevHow was this achieved? reply tantalor 4 hours agoprev> though this distance would not be a “real” distance in any meaningful sense Huh? reply willis936 8 hours agoprevCathedrals are the highest tier of vanity projects of one of the most powerful institutions in written history. It's little surprise that the makers knew the top three most import factors for real estate value: location, location, location. Are they pointing to anything though? reply ttepasse 6 hours agoparentAt its core a cathedral is just a church where the cathedra (the \"throne\" of a bishop) stands. Can be any size, take a look at Nin, Croatia: https://en.wikipedia.org/wiki/Church_of_the_Holy_Cross,_Nin reply masswerk 7 hours agoparentprevCathedrals were erected by the townships and were indeed a major economic investment. They generally payed off well, giving raise to tourism (then known as pilgrimage) and elevating the status of the city, both with considerable effects on commerce. If you were a major town or city, or aspired to become one, you definitively wanted to build a cathedral. (And, as already pointed out by several other comments, none of these locations were cathedrals.) reply SideburnsOfDoom 7 hours agorootparent> and elevating the status of the city Indeed, having a cathedral is a thing that can define a settlement as \"a city\". Source: https://commonslibrary.parliament.uk/what-makes-a-city/ reply mensetmanusman 6 hours agoparentprevHarvard has more wealth than the Vatican. reply willis936 2 hours agorootparentDid they 1000 years ago? reply ImJamal 2 hours agorootparentHarvard didn't exist 1000 years ago so obviously not. You could also argue that the Vatican has only existed since 1929. Prior to 1929 the Vatican wasn't independent and prior to that it was part of the Papal States (aka its own country) reply 082349872349872 9 hours agoprev [–] Considering the birthday paradox, I get 600! = 12655723162254307425418678245150829297671403862274660768187828858528140823147351237817802795619571074765208532598060224803240903782164769430795025578054271906283387643826088448124626488332623608376164081221171179439885840257818732919037889603719186743943363062139593784473922231852782547619771723889252476871186000174697934549112845662596182308280390615184691924446215552586523740084932807259056238962104689731522587564412231618018774350801526839567367444928206231310973619440354723718012867753019556135721376207959558860559933052856914157120622980057169891912595926540427596853441276985006724869558201930657900240943007657817473684008944448183219124163017666607770667585082169598239230274035517738648065600492702095732843492708856036920219883363111527988109277392696562776813446645651238419301586157342867860646666350050113314787911320639668510871569846664873595017518995670958477806411667505346462590471136862647349666243426242677175204732314281064417939041868653741187423064985189556742640111598580035644021835576715752869397465453828584471291269955890393294448315746500268702149708808053100406398480942695623586049403348084970064668900206251516968479727515576425962392136269169089884609794271331061018895634421094082310408889752954265842691732460538911784960000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000L so I'd expect for there to be more than a few seemingly unlikely coincidences among them. reply defrost 7 hours agoparent [–] Placement is an interesting problem, assuming a plan to lay them out in a \"line\", either Geodesic (tricky) or on a common projection of the period prior to construction there remains a few questions: Given a preferred predetermined position, navigating to the desired latitude would have been easy enough for the time, getting to a spot with the correct longitude is a tricky feat prior to accurate clocks. Having found such a location there's no apriori guarantee that site is ideal for a large stone building which would lead to some fudging about to find a near althernative site along a corridor. There's some work to be done upon the order in which these buildings went up and on the locations themselves; for example: https://en.wikipedia.org/wiki/St_Michael's_Mount dates as a monastic site back to the 8th Century or so and has very little (almost none) play in position .. it's situated on a rocky outcrop in a strong tidal zone. All of which leaves questions such as when a decision might first have been made to infill later buildings to match a line through which earlier buildings on which projection. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The research project investigates the claim that seven famous cathedrals dedicated to Saint Michael are perfectly aligned on a straight line.",
      "Methodology includes collecting geographical data, using Python libraries for geodesic calculations, and visualizing data with KeplerGl.",
      "Results show the cathedrals are not aligned in spherical geometry but appear aligned on a Mercator projection, with a root mean squared error of 167.0303 Km."
    ],
    "commentSummary": [
      "The investigation examines whether seven religious sites dedicated to St. Michael are aligned in a straight line, with opinions divided between extraordinary alignment and coincidence.",
      "The discussion includes the historical and miraculous origins of these monasteries and sanctuaries, the challenges of map projections, and the role of cultural symbolism.",
      "The conversation concludes with skepticism about a secretive, long-term conspiracy and emphasizes the importance of critical scrutiny of data and methods used in such theories."
    ],
    "points": 241,
    "commentCount": 168,
    "retryCount": 0,
    "time": 1717667339
  },
  {
    "id": 40597216,
    "title": "Subway-Style Map of Roman Roads from 125 AD Combines History and Creativity",
    "originLink": "https://sashamaps.net/docs/maps/roman-roads-original/",
    "originBody": "Roman Roads 3 June 2017 It’s finally done. A subway-style diagram of the major Roman roads, based on the Empire of ca. 125 AD. Creating this required far more research than I had expected—there is not a single consistent source that was particularly good for this. Huge shoutout to: Stanford’s ORBIS model, The Pelagios Project, and the Antonine Itinerary (found a full PDF online but lost the url). The lines are a combination of actual, named roads (like the Via Appia or Via Militaris) as well as roads that do not have a known historic name (in which case I creatively invented some names). Skip to the “Creative liberties taken” section for specifics. How long would it actually take to travel this network? That depends a lot on what method of transport you are using, which depends on how much money you have. Another big factor is the season – each time of year poses its own challenges. In the summer, it would take you about two months to walk on foot from Rome to Byzantium. If you had a horse, it would only take you a month. However, no sane Roman would use only roads where sea travel is available. Sailing was much cheaper and faster – a combination of horse and sailboat would get you from Rome to Byzantium in about 25 days, Rome to Carthage in 4-5 days. Check out ORBIS if you want to play around with a “Google Maps” for Ancient Rome. I decided not to include maritime routes on the map for simplicity’s sake. Creative liberties taken The biggest creative element was choosing which roads and cities to include, and which to exclude. There is no way I could include every Roman road, these are only the main ones. I tried to include cities with larger populations, or cities that were provincial capitals around the 2nd century. Obviously to travel from Petra to Gaza you would take a more or less direct road, rather than going to Damascus and “transferring” to the Via Maris. The way we travel on roads is very different from rail, which is a slight flaw in the concept of the map. But I think it’s still aesthetically pleasing and informative. Here’s a list of the roads that have authentic names and paths: Via Appia Via Augusta Via Aurelia Via Delapidata Via Domitia Via Egnatia Via Flaminia Via Flavia (I, II, III) Via Julia Augusta Via Lusitanorum Via Militaris Via Popilia Via Portumia Via Salaria Via Tiburtina Via Traiana Via Traiana Nova Some roads have real names but were modified somewhat: The Via Latina I combined with the Via Popilia. In reality the Popilia ended at Capua, and the Latina went from Capua to Rome. Via Aquitania only referred to the road from Burdigala (Bordeaux) to Narbo (Narbonne). Via Asturica Burdigalam similarly only refers to the Astrurica-Burdigala section. “Via Claudia” is not a real name, but refers to a real continuous road built by Claudius. Via Hadriana was a real road in Egypt, but it refers to a slightly different section than the green route. The name “Via Maris” is considered to be a modern creation, referring to real ancient trade road whose real name has been lost to history. Via Valeria only referred to a section of the yellow Sicilian loop. The roads around Pisae, Luna and Genua had several names for different sections, including Via Aemilia Scauri. Sometimes “Via Aurelia” referred to the entire road from Rome to Arelate. Via Sucinaria is the Latin name for the Amber Road, a trade route from the Baltic region to Italy that carried amber as a valuable good. It probably was not used to refer to a single literal road. Via Gemina and Via Claudia Augusta are real names that referred to small parts of the routes marked on the map. The other roads have relatively uncreative names that I invented, usually based on a place that they pass through. I have never formally studied Latin and I’ll admit that I am somewhat confused by the distinction between -a and -ensis endings, so there’s a chance I may have messed that up. Update I got numerous comments following the release of my Roman roads map. Acting by the mantra of “OP delivers”, I decided to take this feedback into account and create an updated version of the map. The new map is featured here, and I have also replaced the map in the original post with the new version. Several changes were made: The typo in Gesoriacum is fixed. The Via Agrippa is now properly named. For some reason I had typed Via Flavia by mistake. Via Flavia now refers to the road along the Dalmatian coast, in reference to the actual Via Flavia in what is now Croatia. I have included Berytus, present-day Beirut, in the map. It was the capital of Roman Phoenicia and one of the most important cities in the Eastern Mediterranean at the time. The town of Vindonissa has been added. It was a prominent fort in what is now Switzerland. The road in Sardinia now goes from Caralis to Tarrae. This was (and still is) the most prominent land linkage on the island. Road names ending in -ensis have been changed to more classical names: Via Sarda now uses the proper Latin adjective for the island. Via__Augusta Nova is named after the emperor who established the proconsular government in Asia. Other geographically-named roads have had name changes: Via Domitiana is named after Domitian, who conquered Moesia. Via Tiberia in Cappadocia is named after Tiberius, who established the province. The British Isles are now displayed in full, and the British road network has been expanded a tiny bit. Lucus (Lugo) is now moved inland, and the road from Bracara Augusta to Asturica has been separated. Version in Chinese – 中文版 Chinese translations courtesy of Stone Chen.",
    "commentLink": "https://news.ycombinator.com/item?id=40597216",
    "commentBody": "Roman Roads (2017) (sashamaps.net)225 points by gslin 5 hours agohidepastfavorite65 comments nerdponx 4 hours agoThe original creator's page is: https://sashamaps.net/docs/maps/roman-roads-original/ The summary here links right to the original content. I just wanted to highlight the original for the sake of other readers clicking through quickly. There's also a much more detailed (and more interesting) writeup on the creator's page. reply madcaptenor 3 hours agoparentI actually refer to his list of 20 simple, distinct colors (https://sashamaps.net/docs/resources/20-colors/) which he came up with for this map, pretty frequently. It's a nice palette. reply kevin_thibedeau 3 hours agorootparentAn easy trick is to rotate hue with a spacing of 1.618. That guarantees maximum separation with no near collisions for any number of hues. reply wonger_ 58 minutes agorootparentSo cool! The same \"golden angle\" is behind plant leaf spacing, for minimal overlap / maximum exposure to sunlight. https://gofiguremath.org/natures-favorite-math/the-golden-ra... reply madcaptenor 1 hour agorootparentprevI've heard this one before. It only takes advantage of one dimension of the color space, though, and that bugs me. On the other hand you don't have to go look up a better palette. reply jacobolus 58 minutes agorootparentHere's a 2-dimensional version where you pick the angles https://observablehq.com/@jrus/categorical If you want to keep the points theoretically ideally separated out to as many as colors as you want, you can use the \"plastic sequence\" for your parameters, https://observablehq.com/@jrus/plastic-sequence reply bloopernova 2 hours agorootparentprevOh that is a nice page, I really like the accessibility options to support 95, 99, 99.99, and 100% of people. Thank you for sharing it. reply dang 1 hour agoparentprevOk, we changed the URL to that from https://www.openculture.com/2024/06/the-roads-of-ancient-rom.... Thanks! reply alsetmusic 2 hours agoparentprevThere’s also an option to email the mapmaker to receive a pdf. I’m going to ask for one in hopes that it’ll blow up nicely. I think it’d make interesting wall art. reply ydnaclementine 4 hours agoparentprevTheir other maps are sick too. Is there a term for these types of visualizations, where some data is visualized in a \"non-standard\" way in the context of the data? reply busyant 2 hours agoprevPretty cool. My parents grew up in small villages that are adjacent to one of these ancient roads (via Tiburtina: https://en.wikipedia.org/wiki/Via_Tiburtina) and the road basically still exists as a modern road. I remember driving near Pescara with my parents in the 1990s--they had not been back to Italy in 35+ years and they were trying to find their way back to their home towns. We stopped the car on the side of a main road and asked a woman who was walking, \"Dov'e' la Tiburtina?\" (where is the Tiburtina?). The woman responded... \"QUEST'E' la Tiburtina!\" (This is the Tiburtina). reply rrr_oh_man 2 hours agoprevFunny thing is they did have something like this already: https://en.m.wikipedia.org/wiki/Tabula_Peutingeriana (Check out one of the full size scans in the links) reply delichon 51 minutes agoparentThe subway map is great for seeing the shape of the network, but this one is better at showing the geographical constraints that shaped the network. reply supermatou 4 hours agoprevMuch better resolution: https://video-images.vice.com/articles/593594e8c270a8484d1d1... reply krylon 14 minutes agoprevI was about to complain that my hometown is missing, but then remembered it didn't exist back then. reply anVlad11 3 hours agoprevI've been always fascinated by subway maps. The best ones are usually made manually and require update from contractors on every infrastructure extension. Were there any efforts to make autogenerated styled subway maps? Not like stylization of OSM data, but real schemes that show the whole system without sensory overload? reply ygra 3 hours agoparentSome examples of automatic layout in this style: - M. Nöllenburg: Automated Drawings of Metro Maps, 2005. We've used that a while ago to render a few pretty images with our graph visualization library, but runtime is prohibitive (along with the requirement of a fast ILP solver). - LOOM: https://github.com/ad-freiburg/loom and https://loom.cs.uni-freiburg.de/global reply solardev 3 hours agorootparentWow, cool. Thanks for sharing! I hope someone builds a web version of Mini Metro with this on top of OSM. reply moi2388 4 hours agoprevHow can it take 2 months on foot, yet only 1 month per horse, when a horse can only travel between 25-35 miles a day, which is not twice as far as a human can travel in a day, but about equal? reply eschulz 3 hours agoparentHorses would often be swapped out at stations when a wealthy person would have to travel very quickly across a long distance. Maybe this is an average since the speed with which horsemen could travel would depend on the rate at which they exchanged their horses. In an extreme example from the year 9 BC, the future emperor Tiberius traveled on the Roman Roads 330 miles (531 km) between northern Italy and modern day Mainz, Germany in 36 hours without sleep. He was rushing to the deathbed of his older brother Drusus after the latter suffered mortal injuries in a freak horse accident. https://en.wikipedia.org/wiki/Drususstein reply Phenomenit 2 hours agorootparentSo he rode really fast, reckless and sleep deprived to his brother who’d been injured in a horse riding accident? reply eschulz 5 minutes agorootparenthaha hadn't thought about that, although the Roman Roads could be considered to be a safe highways as opposed to the dangerous paths in Germania. If one of the main characters in The Fast and the Furious gets hurt in a street race, would not his teammates race to him as fast as they could? reply marcosdumay 2 hours agorootparentprevPeople never change. reply mikhailfranco 2 hours agoparentprevhttps://en.wikipedia.org/wiki/Man_versus_Horse_Marathon A man on a bike beats a horse over almost all distances, especially long distances. The only interesting competitive distance might be a flying 400m. reply hammock 3 hours agoparentprevWith baggage, a typical human can only travel about 12-17 miles a day (half that of a horse) reply wongarsu 2 hours agorootparentAbout 30km/18 miles per day is a common value used in Europe. On a single day you can easily do twice that if you don't carry too much and are used to walking long distances, but it would be difficult to sustain. Also the number allows for time to set up camp (and tear it down in the morning), prepare meals, etc. reply xandrius 1 hour agorootparentSaying that 60km \"can be easily done\" is quite a stretch. After 30-40km, even on flat, most people wouldn't do it easily at all. And I walk about 10km daily in one session and often do 30+km hikes. reply reaperducer 49 minutes agorootparentWhen I was in elementary school, we would do charity walks every year to raise money for the poor. They were 20 miles. It took us all day, but if a bunch of kids between fourth and eighth grades and their nun teachers can do it, I'm surprised how many adults on this web site think it's too far. reply bedobi 4 hours agoparentprevI'm sure the author would have more details on the ambiguity. Are the walkers marching soldiers? Is the rider a courier who changes to fresh horses at waystations? It's not clear :) reply nescioquid 3 hours agoparentprevMy thought is that one didn't simply travel alone on horseback, but with a group and baggage, and I wouldn't expect servants to be mounted. The animals help with the baggage. You also would want a group since there are highwaymen and freebooters on the road. I seem to recall oxen speed being about 12 miles per day. reply mavhc 4 hours agoparentprevRelay horses reply fisian 1 hour agoprevCool visualization. From the title I thought it would be this project (called \"roads to Rome\"): https://benedikt-gross.de/projects/roads-to-rome/ reply Yhippa 3 hours agoprevThis is really neat! Thanks for sharing. I wonder if there's an analogue for these routes and the roadway system there? I imagine so. I thought it was interesting how short Via Appia was. Learning Latin growing up, I imagined that to be much longer. reply rippeltippel 4 hours agoprevThere's a missing road in Sardinia that I'm aware of, connecting Karalis (today's Cagliari) with Turris Libisonis (today's Porto Torres, near Sassari). reply dewey 2 hours agoparentThis is mentioned in the „Creative liberties taken“ section. It’s not a complete map. reply hammock 3 hours agoprevHow does this compare to the modern rail system? reply fabi0 4 hours agoprevOmnes viae Romam ducunt. reply cf100clunk 3 hours agoparent> Omnes viae Romam ducunt Hinc illuc pervenire non potes. reply arktos_ 1 hour agorootparentItidem mihi, nobis ergo sunt naves longae navigandae reply zabzonk 1 hour agorootparentcaesar ad sum jam fortea brutus ad sum too caesar sic in omnibus brutus sic in hat reply insane_dreamer 2 hours agoprevabsolutely love this. well done reply jajko 2 hours agoprevVery schematic from region I live around - Geneva and Aosta are not that far on the map and seem close neighbours, but highest part of alps lies in between, passes can be brutal and far apart (>=2500m high, ie St Bernard pass from where famous dogs come from, can end up snowed anytime all year round and especially 2000 years ago, at least 6 months/year unpassable for carriages and dangerous for anything else). reply darkwater 1 hour agoparentWell, you know, a subway would pass under the mountains ;) reply EGreg 3 hours agoprevI checked and I think they are missing King’s Highway: https://www.audleytravel.com/jordan/country-guides/the-kings... Was it not Roman enough, ie not built by Romans so not on the map? Or did it not exist during Roman times? reply fred_is_fred 4 hours agoprevThat's really well done! I have no comment on the accuracy but it really highlights just how the Romans integrated new areas into the central empire through transportation (goods, ideas, and armies). I will also call out the road in Africa called \"Caeserea lol\" reply bdw5204 4 hours agoparentThat would presumably be the city of Caesarea in Mauretania[0] which was the capital of that province. According to the Wikipedia article for the modern town at that site[1], it was also called Iol in ancient times. [0]: https://en.wikipedia.org/wiki/Caesarea_in_Mauretania [1]: https://en.wikipedia.org/wiki/Cherchell reply readthenotes1 2 hours agoparentprevThe ego! It should have been called Via Scipio Africanus Motherforker reply metabagel 4 hours agoprevLOL, Pompeii (closed) reply behnamoh 4 hours agoprevSometimes I wonder if we've regressed in terms of attention to quality. Here in the US, I see lots of potholes on the streets and sidewalks. Meanwhile, the ancient cobblestone roads are still functional to this day. reply TimedToasts 3 hours agoparentDrive a semi over those cobblestones daily for a year and we'll see how they are doing. reply gtmitchell 1 hour agoparentprevRome had the advantage of access to essentially unlimited forced labor in order to build and maintain their infrastructure. Modern engineering is absolutely superior to Roman engineering, but we do have to contend with budget constraints, at least in part because we're not using slavery to build our roads. reply bee_rider 3 hours agoparentprevSomebody mentioned semis already, but also, I bet Roman engineers would give up immediately if they saw a snowplow. reply bluGill 3 hours agoparentprevPotholes are not regression. They are a good cost effect response. We can build roads that won't have potholes, but at vastly more cost, it is better in the long run to build roads as we do and then fix potholes every year. Cobblestones also get potholes and the like when subject to heavy car traffic. reply palata 3 hours agoparentprev> Sometimes I wonder if we've regressed in terms of attention to quality. In a way we have, yes! In our modern society we optimize for profit. Always, everywhere. The reasons our roads won't last thousands of years is precisely that it would be less profitable. reply szvsw 2 hours agoparentprevThe network scale, network density, frequency of use, and loading conditions are all like, orders of magnitude higher. Plus as other commenters have mentioned, weather conditions tend to be more extreme than the Mediterranean, and additionally, designing for serviceability can have significant advantages. reply panick21_ 2 hours agoparentprevCars are the problem. And just FYI roman roads were maintained. We dont have documentation on this from the early imperial period. But from the Byzantine period we know that there were local people responsible for maintenance. And we also know that even during Byzantine times many roads were reverting to nature. Road maintence was a real problem. reply PhasmaFelis 53 minutes agoparentprevI've done some research on this. For one thing, cobblestone roads wouldn't last so long under the weight and shear forces of modern vehicles. Y'know when Wile E. Coyote skids to a stop so hard that the road under him wrinkles up like a rug? A loaded semi truck braking hard can actually make asphalt do that, just as an example of the kind of forces involved. For another, cobbles that are even a little bit wet become slippery deathtraps at even moderate driving speeds. Even when they're dry, highway speeds are going to be very uncomfortably bumpy. Hard on people and hardware both. Basically, a good driving road requires a surface that is extremely smooth but also somewhat tacky, and that really limits what other properties it can have. You can't build something like that out of durable stone. reply tamimio 1 hour agoparentprevWait till you see Canadian roads.. But the real reason is construction mafia, to keep their work going, if they made it high quality they are out of government maintenance contracts in the coming years. reply readthenotes1 2 hours agoparentprevBad roads are safer. We design our roads to be driven much faster than anyone should. Potholes and rough areas slow us down reply marcosdumay 2 hours agorootparentThere are a few studies, with arguable relevancy that discovered that roads that are safe but look dangerous are safer than merely safe roads. None of that has any relation at all with potholes. Potholes are dangerous and may not be even noticeable at a distance. reply colechristensen 3 hours agoparentprevThey used to pour molten iron in holes in their cobblestone roads. https://www.smithsonianmag.com/smart-news/pompeii-fixed-poth... reply more_corn 3 hours agoparentprevWatch a video on roman road construction methods. It seems they prided themselves on building for the long term. Retrieval augmented generation from incomplete archive: The foundation of the road consists of 3’ of gravel covered with 2’ of sand forming an extremely stable base. I seem to also recall that builders got paid half upon completion and half if the construction was still in good condition fifty years later. (Though this is probably apocryphal for the obvious reasons) reply ardit33 1 hour agoprevThe Roman Empire was very advanced for the time, and it left such a huge imprint on the civilization even centuries, and thousands of years after it. The organization was a different scale. Fun fact: Some of the most famous battles in England in the middle ages, such as battle of Hasting, were basically 5k - 9k soldiers in each side. That's just one and a half Roman legion. Rome, could field 12 legions at a time, and the scale was insane. I can see why the Roman Empire remained such a symbol of civilization for a thousand of years after its fall. reply ffgjgf1 18 minutes agoparentTo be fair England was a complete backwater in Roman times, just like much of Europe away from the Mediterranean. IIRC by the 1000s Germany, France and Britain had already well surpassed their Roman population peaks, Italy on the other hand took another 500 years or so. reply strnisa 4 hours agoprev [–] Coincidentally, this is also the future hyperloop map. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A subway-style diagram of major Roman roads from around 125 AD has been created, incorporating extensive research from sources like Stanford’s ORBIS model and the Antonine Itinerary.",
      "The map includes both historically accurate and creatively named roads, with travel times varying by method and season, highlighting that sea travel was faster and cheaper.",
      "An updated version corrected errors, added significant cities and roads, and included changes based on feedback; it is also available in Chinese, translated by Stone Chen."
    ],
    "commentSummary": [
      "Users are discussing a map of Roman roads from sashamaps.net, exploring its features, accessibility, and potential as wall art.",
      "The conversation includes historical anecdotes, comparisons of Roman roads to modern infrastructure, and debates on their durability and construction methods.",
      "There is a humorous comparison of ancient Roman roads to a future hyperloop map, highlighting the advanced organization of the Roman Empire."
    ],
    "points": 225,
    "commentCount": 65,
    "retryCount": 0,
    "time": 1717680756
  },
  {
    "id": 40588977,
    "title": "85% Support Global Ban on Single-Use Plastics",
    "originLink": "https://www.worldwildlife.org/press-releases/85-of-people-want-global-ban-on-single-use-plastics",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"www.worldwildlife.org\",cType: 'managed',cNounce: '51256',cRay: '88faa7bedcf8e118',cHash: '62727009eff9efe',cUPMDTk: \"\\/press-releases\\/85-of-people-want-global-ban-on-single-use-plastics?__cf_chl_tk=HpB0pPftbmRt9ZaR0ig8wOoNpGYmlqgy.wSAPODPUTI-1717700531-0.0.1.1-4116\",cFPWv: 'b',cTTimeMs: '1000',cMTimeMs: '390000',cTplV: 5,cTplB: 'cf',cK: \"visitor-time\",fa: \"\\/press-releases\\/85-of-people-want-global-ban-on-single-use-plastics?__cf_chl_f_tk=HpB0pPftbmRt9ZaR0ig8wOoNpGYmlqgy.wSAPODPUTI-1717700531-0.0.1.1-4116\",md: \"jrzteraORG0JzL1DZyPB6GWttatp.UA1SO0eMVR8XEI-1717700531-1.1.1.1-KatnoNjxBE_9PK_v_ihXOL7BZIDvwpKayggA2d8sDz16mtg.z6OXi1pbgPvnPpWCNABSSgkdDMizDr0A4o1cM2vzDLvLHorW6HLYEmiTl_GR9y.PB3iUAYArxrnvvHHfHzPJ9CwJ0wQZpz_gqSrcDnKoQoVH1tTLPlYaD5BZC6U4l7jhteVFfJVnevYBWKPo3Fr7m124gyH38nl0RdogJ9X3WDqD.4Z0Fa_0AVPYrMczHjBp_BRLfQjTh8OUH7TwMXqxIB808t0dvmb8eFTc9CSuPSxzRJHY2wpR8eilTxV31IVR019KeCipcpmHFIHEL1CGJhiMqapoaHot5sU6gPss5hTW2Ol77zoQukz5E_qjL8th1aHD9crlE.x_QKLrHNuRXHg7X4rQ20dzlkC_fh5VUVl7sY4YW.v1DJW1Mn_24.nV1zasBmHZ5vleQYPCmaSXB72x1kC04jh0e_3lP.6zRz2BeZzarmIAuIRpKrAsrivUILbjFgkOmnV5fUHkjkuaBHN0rPdW0Vq7rxyyjQMZ9pTTbMSCiV.hd8UUqpHeNcWNIS4FHdFL2zqH.EskVeYi8zH2BwPgfr4cnYAkel4qr_Xa4q2TrfNpB8LJYao5Lf9ua9AdRGvWqc1SDy7EfQgVX3teW6mYbRfd_xZLNFJyGuyD8AM.KHf1TsITOnLce.2uIMq6LDQwJYW8dBPa7gLfS9yOqL2OLOgtppE8gEMAdVsdN0mrewMK1UhItcd1Vvdp_N8I8o1BoaoOkGQydVPUcvqzvLzaQhQVx0uF9LUCmHxM.QhzS4DbyWs_VbbxexdcFWSXp87vNfBCSCEZfnGqVtuuV5kG287lLIEYzyn.N7gYuHbrTkWK5t8TajA82G_CpRtKuaSbbquSXjRQv1JavscaoGvtIonwFIfiEGiRDmmr02Arq8E2oZB7gYZpSX1yUzPb7IaQ6UsR23fiDqTXlk8aV4LficMOQAlq0CZpnOsXQ5ks5yww8W8uxSUduZ2fss_c2Y0L14W2YTZjxnNnIFvbSI9Y9NgMxf5FjLW83jtf0PXq7H176UjLwPcVSsMg9oRuxLtL3DesnxA9VPEVwW6lVxeC2VCCZpiPuZylWTzJwzXdesmyv9uB2kEUH2wsqJJjXZmOjQY6Fp0.ICl7yEhL2O1IqIZGBJv1_wF9_RNfDtDOTL2ux0dvbKjIPlL0aIwm46vZPF.z9VzVhkyiALl6aSfWdtnthBdT9YHnH_2ONWEETcEendBhhd1t.tdRC9Lh2lFs5uy71l6_T6L2ZXRt5o_h8MU5D.D.yTwj9vJHj.ekbc7BZM4iPzvC9yV_H3GnIN6pda_Pd8QIICg7oeIVlkUQcafjFUmVKb49UgD4B.4TKI0rTIq7RvRUNhAq5bs4i9mocR2Y3_s7zts4HCn2R953JcAOciCppjTRg6YneD1CVsJs.U7oHcGYBPKpI8IhsufGZtBMWCXfxkLIPeYW8y0m.nhkizuy0UcDVGEdMLs9oe4RoyzQWNyJ3ol3LLifIJLpWQZUfyISfdRHTEjt.tZS5CzJ0d5EbXBdCQuhl.IJ6CXsjsreQ2qkidIB3nWIczMCnZbzvgLwYoCE25X.r6dw8bwmd6yvMu2abmyE671gBZriW_ih5MgvL1CxmKIbZPHovkgeUC90\",mdrd: \"8C9nHn4FkzRzZcd_eQRZ_uQL9f9mF9mmkDuCPYqwXoQ-1717700531-1.1.1.1-YDLFdqdu4o.MgoUM62f1N8rEaAw1uJeRMMyWXZQ25LbVdWY0ikYTG0ANKZdqkBb00W4gLPHy4sAcTdIBy9sUEmZKScVLrDwlzUOkzbClR3MAYMv7nWmxDlQM1c7AsEPS91IX8fd6MfclYf0m.y.fUA8jED1hMAX_vurJXBbIJBrgu9ltijI0eHHTizDZ9a9TSUBKmMbChjAel.7NbGrweSViNo39RH_8kvXLpD6oEFicyB25ePk7_q2H7jlCpfpf4stCLUPCVlajUri7sKiT0XjsDbaq5VROL53yPlb7Hn2B.5I9.jPrsJeWEdr22.lWeoao2fXb._1qvTV3h4d_gtkXe7Kts9qz6..acJO.ntCwglBhdsB3u.UN7WH9Uz0ONZiIyNiWt30ERZlNNY9y_w5zHNRLXg7xszMXi.uPMWfRXcsxPu.tPS..qxAYz62kf8788gzm6IeKUfIPrn_cOqPeVGsgnRc9YN5KyFjxeGoniseA0oJntH6Zbky8iixfJpt9FL7W2cvuDTlnaUosU6krrimfsZraW7b5.cUAzsdpMTB5eUCHYbRijtLDT5V6_szF0yvcs6Xc3Mq2cKKTic6f518M43wxOwE1XN04dbsttmxv7D5bnZZl_wb078mKw4KVKHQoQ1kzEn6v446IrID2BWsVD3NZpC4rpr3aSLm6ccScmHafreEYz0u_Kv4YaNQ6OKVWWFUdPJrBDYy3xxpbvKeo3YJBQwTe3kHoIwu8oCV29GmGTP0xCRieXHPhBJsczatgsnjehH2Cv6XfPK69nABNPjudLhG_zFpY.H9mfkEjQQx.iiExy9IyF90Vvb3_yZOgf6oNGVmATbtx2EMEfRyyFZ4bbk9jjsMoJKo11MHkF9StUgHorWv5FQ_baYhuJn.dLhuhKaEruyYxp0whgdAgiR6Z4_dKm9ulRdWAJFR6Q1sLLrIZC9m_.A8ODk06b3kSf7Qylwpe3bUHDgvzO011nluVCyom8tZVcCs4jiY_p7SHmL0m1DHhk69452s3gOitSWSNOpjEVEws9RIXOC88EP74F2k41H6.Do5awajHIsAGrghd.PQ6rZWigALHd0JKNhww8kldaKpln3URNfwdyyT7FX2gHyZ43.3oguVr3GRkSwKW5DjDXQKsqE9hZhThwjb6l3CjZ.SwiwP1sQoGaKIXudfpmh9mJqjJmLMJ8vcoabeFcey5APk8vceryHa6WN4_EronsPnMTrNbkCYb9485Xq.AB18r8N6kvq2Aa.0hJ.IpPOCon92ZdlKAVNWkJ7J6SpVXoCww20cVIpHogMxxT6J6jB1lnAg7MNvLHx5U84cMlvpS7_ses9j.8NVi7cXgQ8vq1RHutKtkvHZL3knjWSjtf9cHKhxgI038ZNH9SjbCL14M61Gq2LjpoCcW8wA52RFLjZFTjfQl1IX4qrJYRvkK8I6AZhx8XdKcmE_fyALuG8bAWXa9N2LZIpbnq98htZr3ivDTzpUZHvaFbfPiFZgK.sONS.z0acKEQaA20qnkiUjOWmROUB1uMPaJ0WazhSMJ2Wn6wbU8QoOvh1q8lOVl_yt7kL4Igsr51fongEBL0WDQkxSkVIScCjf_zLSueH3IXGs4bNf31DxIo69X06nkhvxSTRAhdEAZorKVkHUNts3pVMkg6KNwJ50Yeyy4Ai1eQXFxN9waVcAij.P5sKl1WaA8I6jJ0wWKss0WIJDvfznyrsg14V8xsDmcKd.dAfoKQt7p7Auw1UHyAGeG33BF56eSmG3gK_w9Tsu2nmUKwqp9PBsm3uuJC8_CoyIR3AUPE49GpTeqqogil3qvZMztLXQnkykEh3_o5RiEDT6mhWoFNH1BFTVbE5GhOBx0f53AkAWJ4oU67VXhL_55fZ21mauoyk0sHIRK8Jril0pUzIecs_lhT2Gsjhk09JV.7B38vFmQv9cEIcEo2VztMJ2tKuIDBo9jZYeNsqEY5pjsqBrsQKJ0Klxt8ij26TrXJh1jXj1KPbcgRByi8O.8VGgANkm8dbQUrI4590Izy2D3Ml2UHr4GHliUm.AuM9p7eHW7irzUtGOMt7ASBPQwIlX92fzDVNHOQr9nXlDzorFPhgLmC28pY0pZawLkAOx9D8aDFpVwlbO994XNxYOAVVxRpCD2VChEF6T6EsowON2UfRFjvHRnJyDLSNo9lsIrUdjnvfltbOhwebHYbz_O.0U98crRKnwKkcY1PT96Tl0yjVc3cGBaRezEQ.E.5CBPxP3kk0LZRRquGMVOzFF8AtEXnbxdbq18nLu_oEWPBTAY8.oEqSYGtn16JS9AFB87ZME1dEcj4w\",cRq: {ru: 'aHR0cHM6Ly93d3cud29ybGR3aWxkbGlmZS5vcmcvcHJlc3MtcmVsZWFzZXMvODUtb2YtcGVvcGxlLXdhbnQtZ2xvYmFsLWJhbi1vbi1zaW5nbGUtdXNlLXBsYXN0aWNz',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',rm: 'R0VU',d: 'Tgsj0mIDPx7xQf9QJ14y+oFnOCK9LN6jJBOtmQl7+CiEO0j45L/Vupw/kcYP2GnCTt5qY3vMAW7MHNydggo3hzCWYEFIFQuANiCycZoqPeIFIKjy5MwsRLNKFH5YhETuZrmTVLJovqp/a9n06K3nf7taUDLGMb0nPc6AfEeF08fiVb5L41bF6qcWbAeSJhJ+E+3IZUbvtOSrT8aM3AyU/hU0VbJpoKI/SCf6qHMQfZTDi81Q7eyLqCRkROoG5Pum/BZfrck8/Ms1ZBX8qa6BjHIMKaHCaSTNhOoSeDXAh/ahwWA++eIY4HUuVaGFtDRaAq5LdtsvVx4a0dTM04hoEr43Cdr+HfFxWUbDyGyIrqrl6JNqY7532g7Iw2QfWbTvAY3/MLe1hwUzibnSbV8HDQi53MKFwHAH9+P/75WsDQfnYJ/uHIY3fHBKpgbrezxcgiCBNFaxtoWQO1LfVWkrLhPi7Rbx7veZDdFxfp0ez5VUU5+Xnv/5XSv3SWUbF1sA+MIRv5LCsW+6e7uF/jh9FG8c3JHb3qhM5HJA5i3dwmyRviTdEcv+Z3spOyz55FII',t: 'MTcxNzcwMDUzMS4wMjgwMDA=',cT: Math.floor(Date.now() / 1000),m: 'w7y1HaJf9xAxC4Qd1bUSmYb5+Lqx3p/Ikt2NUOL1sDU=',i1: 'I5Hbgm99fVbVwv19XMTWzQ==',i2: 'AKiGeDvcqmZEz2t4YjhtRg==',zh: '3z5kGEQPli6w2pN0EyhqoKm0W8FCOFSY5BBXOKtGTfc=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'EqTGbKPMo7bTGdgLnx8JqQMkEQNlYkB0Gm1lJgBjKV8=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/b/orchestrate/chl_page/v1?ray=88faa7bedcf8e118';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/press-releases\\/85-of-people-want-global-ban-on-single-use-plastics?__cf_chl_rt_tk=HpB0pPftbmRt9ZaR0ig8wOoNpGYmlqgy.wSAPODPUTI-1717700531-0.0.1.1-4116\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=40588977",
    "commentBody": "85% of People Want Global Ban on Single-Use Plastics (worldwildlife.org)176 points by sharpshadow 23 hours agohidepastfavorite247 comments lowkey_ 23 hours agoI was skeptical of whether it was representative of 85% of the global population, or just the first-world. I've often thought (and heard that) environmental concerns are secondary to economic, and that people in less prosperous countries don't care as much about environmental concerns as people in first-world countries who are secure in most areas of their lives. Surprisingly, this data says the opposite! Sample size was: North America: 2000, Central & South America: 3500, Europe: 8000, Africa: 3000, APAC: 7700, On banning unnecessary single-use plastics being 'important': Australia: 87%, South Korea: 86%, Mexico: 94%, Uganda: 93%, This may be obvious to some, but I really had the opposite notion until seeing this data. reply dumbo-octopus 23 hours agoparentThe response rate is so low as to be entirely meaningless. If you're content with sampling only 0.000001% of the population, you can get any results you want by simply selecting for the people who care the most by taking a bunch of time to lecture the individual if they seem like they'd vote the other way (oh no, you have to leave? but we didn't even have time to submit your vote yet... :( ), and wording the question in such a way to make the answer you want be the only reasonable response. reply GeoAtreides 21 hours agorootparent> The response rate is so low as to be entirely meaningless. This calculator says you need a 385 sample size for a billion (or infinite) population: https://www.calculator.net/sample-size-calculator.html?type=... Please check the theory presented below the calculator, it explains why such a low number is enough for a confidence level of 95% that the real value is within ±5% of the measured/surveyed value. reply dumbo-octopus 19 hours agorootparentYes, if you had a list of all 8,000,000,000 people in the world and went to visit 385 truly randomly selected from that list and didn't leave until you got an answer, yes the theory says that would be a reasonably trustworthy sample. But that theory is useless in practice, when the efficacy of the survey is entirely determined by the sampling bias. Here we have a survey of a few thousand people who had internet access and were on whatever websites promoted this survey and chose to click through the survey and had their votes counted by whatever \"spam filtering\" logic was used, and multiplied by whatever \"population correction factor\" was selected, and they're trying to somehow pass it off as \"85% of People\". Its bogus through and through. reply Slyfox33 20 hours agorootparentprevThat's extremely dependent on who the 385 people are. reply orhmeh09 20 hours agorootparentTFA goes into this a little > The samples in Argentina, Australia, Belgium, Canada, France, Germany, Great Britain, Hungary, Italy, Japan, the Netherlands, Poland, the Republic of Korea, Spain, Sweden, and the United States can be taken as representative of these countries' general adult population under the age of 75. > Due to the fact that the vast majority of the data was collected via Ipsos' online panels (India being the only exception, in which 1,800 were interviewed face-to-face and 400 were interviewed online), participation tends to consist of those who have access to the necessary technology. The samples in Brazil, Chile, Colombia, Indonesia, Ireland, Malaysia, Mexico, Morocco, Nigeria, Peru, Singapore, South Africa, Thailand, Turkey and Uganda are more urban, more educated and/or more affluent than the general population. While not nationally representative, the survey results for these countries provide a useful and unique indication of the direction of public opinion. > > Weighting has been employed to balance demographics and ensure that the sample's composition reflects that of the adult population according to the most recent census data. > > The precision of Ipsos online polls are calculated using a credibility interval with a poll of 1,000 accurate to +/- 3•5 percentage points and of 500 accurate to +/- 5.0 percentage points. For more information on the Ipsos use of credibility intervals, please visit the Ipsos website. Ipsos is fairly reputable in the field, FWIW. reply GreatLdisisp88 18 hours agorootparentprevThe calculator also assume random selection. Don't trust statistics math too much. Even in acccounting where only arithmetic is being used, with legal auditing done yearly or quarterly basis, fraud is incredibly common (working in corporates for decades, they even termed it as massaging numbees by financial engineers). This kind of surveys without any audit and legal framework backing it, at 385 sampling is just inviting fraud. At least 2 to 3Mil needed and back by local election boards or local enforcement agencies. If this is done even in communist countries like China or Vietnam will still be way more legit than done in California or Oslo. reply pembrook 23 hours agorootparentprevYep, asking people vague questions about the boogieman du jour is a questionable excercise at best. If a competing research team had gone out and done a survey with the question rephrased as, \"Do you want a global ban on medical syringes and bottled water?\" You might find out, amazingly, 92% of people strongly support single-use plastics! reply lolinder 23 hours agorootparentThe actual question was [0]: > The United Nations agreed in 2022 to develop a global treaty to end plastic pollution. How important or unimportant do you believe it is to have global rules to… > Ban unnecessary single-use plastic products, e.g., shopping bags, cutlery, cups & plates? As survey questions go, this is actually a pretty precise question. [0] https://www.ipsos.com/sites/default/files/ct/news/documents/... reply dumbo-octopus 23 hours agorootparentProviding the context about the UN treaty makes it unnecessarily loaded. People are biased towards being agreeable, if you start out saying \"everyone in the world agrees X, do you also agree X?\", people are more likely to say yes than if you asked the question in isolation. The word \"unnecessary\" also adds bias, and skews the results: \"Of course we shouldn't unnecessarily use plastic. Oh, but my personal water bottle and the bag I get my food in and the cutlery I use to eat it and the... well not those, those are very necessary: I need them to eat and drink!\" reply TylerE 19 hours agorootparentprevThat's a horrible question. What exactly is \"unnecessary\"? reply lolinder 18 hours agorootparent> e.g., shopping bags, cutlery, cups & plates? reply TylerE 18 hours agorootparentAre trash bags nessesary or unnecessary? reply defrost 18 hours agorootparentIn what context? It's certainly possible to live without them given the existence of large bins, small bins, compost bins, etc. reply TylerE 17 hours agorootparentAt a huge cost to public sanitation - rats, etc. That’s my point. These simple things are NEVER as simple as these trite push polls imply. reply defrost 17 hours agorootparent> At a huge cost to public sanitation - rats, etc. Not in my six decades of experience. The majority of people about where I live don't use plastic trash bags and are well accustomed to keeping mice, rats, cockroaches, etc. at bay. I must say, I'm surprised the rats of which you speak are apparently unable to chew through a plastic bag ... why are they so disabled wrt other rats about the globe? reply orhmeh09 23 hours agorootparentprevWhat do you think is a good sample size? How would you arrive at one? reply dumbo-octopus 23 hours agorootparentIf your question is asked entirely free of bias from a truly randomly selected population, you can use standard statistical methods to come up with a number based on your desired confidence interval. On the other hand, if you're an organization with your funding tied to the perception that people support your mission, and you're surveying whether people support your mission, I'm going to need damn near everyone in the population to respond to your survey before I'll buy it. reply aunty_helen 23 hours agorootparentprevThere isn’t one. Some things are not measurable by this standard and the stats relatively meaningless. 3000 people from a whole continent? Cmon reply kragen 21 hours agorootparentplease see the introduction to statistical methods linked above at https://news.ycombinator.com/item?id=40590633 reply CSMastermind 23 hours agoparentprevYou should consider that this is obviously a \"study\" meant to manufacture data to support the organization's favored position not a real investigation into what actual people think. Their conclusion is based on multiple surveys with different questions and methodologies but consider they did things like ask first, \": Before today, had you heard about a challenge called Plastic Free July, which encourages people to refuse and reduce single use plastics?\" Told them about the harm single use plastics cause and then asked them, \" How important or unimportant do you believe it is to have an internationally binding treaty to combat plastic pollution?\" To which a large percentage of people obviously responded that yes it is important. In another survey they asked, \"The United Nations agreed earlier this year to develop a global treaty to end plastic pollution...\" with the following question then referencing this treaty, \"The treaty will include global rules for participating countries. How important or unimportant do you believe it is to have global rules to:\" To which one of th responses was, \"Ban unnecessary single-use plastics.\", another was, \"Ban types of plastic that cannot be easily recycled\", etc. And then they interpret agreeing that there should be a treaty to stop plastic pollution immediately after being given information about how bad it is to be the same as \"Ban on Single-Use Plastics\" which by and large no one surveyed actually said they wanted explicitly, nor were they asked. reply lolinder 23 hours agoparentprevKeep in mind that in the methodology [0] the survey company emphasized that \"the samples in Brazil, Chile, [...] Mexico, [...] and Uganda are more urban, more educated, and/or more affluent than the general population.\" It was an entirely online survey, so respondents in poorer places are more likely to be those with internet access and the spare time to be poking around on the internet. If you restricted the survey in wealthy countries to only the comparatively affluent I would expect you'd see similar percentages as we have here in poorer countries. I do love that Japan is such a major outlier (only 60% say it's important). They don't have the litter problem that the rest of us have constantly reminding us about the problem. [0] https://www.ipsos.com/sites/default/files/ct/news/documents/... reply Havoc 23 hours agoparentprevOpinions/desires expressed and actual behaviours are very much two things. Spent most of my life in Africa & actual behaviours line up a lot closer with your instinct. If you're close to the poverty line practicality trumps environment. Choice between paper bag and plastic? Plastic obviously - it's more durable and has more uses later reply londons_explore 23 hours agoparentprevPoorer parts of the world have (typically) much worse problems with litter. Poorer nations typically have no/few refuse collection services, and people often just pile up and burn their own refuse or dump it in rivers to take it away. That means poorer people see directly the litter rather than an 'out of sight, out of mind' approach. reply buildsjets 22 hours agorootparentPoorer parts of the world also purchase a LOT more products packaged in single use packaging than industrialized countries. In the Philippines, pretty much every consumer product that could be sold in a multi-use jar, tube, or bottle instead comes in a single-use plastic sachet like you would get for ketchup in McDonald's. Laundry detergent, toothpaste, hair products, you name it. When you combine that with a lack of waste collection infrastructure, you end up with the Pasig river full of single-use plastic sachets every time it rains. Here's a well researched report that dives into a lot of the issues of why these plastics are used. It is a combination of economic and societal factors. https://www.no-burn.org/wp-content/uploads/2021/11/Sachet-Ec... And here's a article that names and shames which companies produce most of the single use plastic waste found in the Philippines. https://www.rappler.com/environment/findings-philippines-pla... https://www.newsecuritybeat.org/2020/09/turning-tap-plastic-... reply wannacboatmovie 23 hours agorootparentprev> Poorer nations typically have no/few refuse collection services, and people often just pile up and burn their own refuse or dump it in rivers to take it away. Would it not make sense then if they had a container with which to collect and responsibly dispose of the refuse? A plastic bag perhaps? reply dumbo-octopus 23 hours agorootparentThey have to put the bag somewhere. Paying for a guy to come around and haul your garbage away every week to be responsibly disposed in a secure landfill is laughably out of budget for a huge chunk of the world population. reply Jackim 23 hours agorootparentprevOr maybe we could tackle the root of the problem, avoid waste that doesn't decompose on the human timescale. reply wannacboatmovie 23 hours agorootparentPlaces that still have open defecation and garbage in the streets have bigger issues to be solved before we deduce plastic bags are the problem. E.g. third world. Seattle and SF have banned plastic bags and the streets are still littered with human feces. Maybe for their next initiative they should pass out reusable bags for people to poop into. Sorry but a feel good measure to make grocery bags illegal doesn't move the needle for me when I still have to play hopscotch with literal logs of human shit. These priorities are hilariously out of order. reply dumbo-octopus 23 hours agorootparentprevMore importantly, the folks who take the time to response to these surveys in poorer countries are much more likely to be the affluent class who spends time in the kind of areas the surveyors are willing to visit, and has spare time on their hands to talk to people. reply ben_w 23 hours agorootparentprevYeah, was going to say similar. A decade ago I had the opportunity to visit Nairobi, thanks to my partner at the time. The place is highly varied, the best looking like any western city, while the worst is basically people living on top of a not-yet-sealed landfill site: https://www.google.com/maps/@-1.2785067,36.7500781,3a,71.6y,... https://en.wikipedia.org/wiki/File:Kibera_Nairobi_Kenya_slum... https://en.wikipedia.org/wiki/File:MathareValleySlum.jpg Her brother is involved with a startup whose mission is to help with this, might be interesting to some folks here: https://www.sargasso-reclamation.com reply snapplebobapple 20 hours agoparentprevThe key word is \"unnecessary\". Everyone thinks we should get rid of unecessary plastic. Everyone also disagrees on what is unecessary. ask them if they would pay some percent more for a good to not have some specific plastic and it will be a resounding near unanimous no. reply primitivesuave 23 hours agoparentprevHonestly, to me, the 85% statistic is meaningless because the survey is simply asking if you believe \"plastic = bad\" - a pretty common sentiment, especially in a third world country like India where plastic pollution is visible everywhere. I'd be more interested to see a survey that asks \"would you be willing to pay 5% more at the grocery store for plastic-free packaging?\" In less prosperous countries, the majority of consumers are more interested in saving money than saving the environment. reply coolspot 17 hours agorootparentRealistically 20-30% more if you pack for example a yogurt into glass instead of plastic. Glass would be like half of net weight. reply Sparkyte 23 hours agoparentprevLots of medical supplies are single use plastics. reply verandaguy 23 hours agorootparentMedical supplies also tend to have much better-defined disposal processes and ends-of-life than, say, plastic bags or coke bottles. reply AlexandrB 23 hours agoprevI'll admit I was a little skeptical of plastic bag bans here in Canada, but it's had a noticeable effect on how much random garbage ends up stuck in hedges and fences where I live. Adapting to it wasn't too bad and good reusable bags are a lot more ergonomic and don't tear as easily when carrying heavy loads. reply blackle 23 hours agoparentI fully agree, however if you're the kind of person who orders groceries, then what ends up happening is that you start collecting reusable bags that you have no way of reusing. I hope that someone starts some kind of \"reusable bag recycling\" system so I can give the scores of bags I have to a good home reply lxgr 23 hours agorootparentIf the bags are actually reusable, it doesn't seem very hard to coordinate to have the delivery person pick up the last delivery's bags next time they're at your house. For home grocery delivery, I could imagine that using stackable or collapsible crates or similar containers might even make more sense, assuming the delivery is via car/truck. Why stick to a container optimized for walk-out customers at all? reply OJFord 23 hours agorootparentOcado does exactly that in the UK, refunds them too. reply Gigachad 21 hours agorootparentprevI had that problem, but then the supermarkets in Australia all switched to paper bags. Now I just chuck them in recycling. Even if they do end up in landfill or a creek, they are paper, in a month they will have disintegrated. reply zeeveener 23 hours agorootparentprevIn my area, one of our grocery chains has \"Compostable Bags\" which they package the \"Pickup / Delivery\" orders in. My area also mandates municipal composting so the discussion of \"But is it _really_ compostable\" is moot. reply lokar 23 hours agorootparentIt does not matter much how they do in a landfill. What matters is what happens when left out in the environment, aiui they weather and breakdown pretty fast. reply lxgr 23 hours agorootparentAnything that ends up either in a landfill or in the environment (fwiw landfills are usually part of the environment, but that's a different discussion) is something that doesn't get to amortize production costs over several uses, so arguably both are best to be avoided, if at all possible. reply zeeveener 15 hours agorootparentprevYes I can attest to how quickly they start breaking down even just sitting in the container for about a week. Almost need a scheduled reminder to replace it no matter how full it is. reply bagels 23 hours agorootparentprevIt's really a farce. The old bags were really, really thin. Now, they're reuseable, and so they have to be much thicker, but they're still only used once. This just means that we're making more plastic waste. reply LeifCarrotson 23 hours agorootparentI don't know what the average number of uses for a reusable bag is, but it's certainly not one. We've got about a half dozen, including a few freezer bags that do most of the work, plus a few that have been repurposed as the \"beach activities bag\" and \"kid's soccer stuff bag\" and so on. The ones used for groceries have been used at least once a week for going on four years. The old bags also averaged slightly over one use, but the mandatory \"bag of bags\" in the pantry got depleted much more slowly than it filled. If someone is throwing their reusable bags in the landfill and getting new ones every time, they're using it wrong...which I admit isn't entirely their fault at this societal scale, but let's at least agree it's the expected way to use the tool. reply AlexandrB 23 hours agorootparentprevThe only grocery delivery service I've used let you return bags the next time they drop food off. I'm not sure how many of them get reused though. reply ImPleadThe5th 23 hours agorootparentprevGood idea! But unfortunately the reason I always have more bags is that I forget my bags in the first place. Maybe you get a few cents back when you return them? reply lokar 23 hours agorootparentprevWhat’s wrong with paper? reply kragen 21 hours agorootparentmaking paper is much more environmentally damaging than making plastic i'm not joking, look it up reply Gigachad 21 hours agorootparentIt uses more energy, but doesn’t create plastics which last thousands of years. Energy usage of shopping bags isn’t that big of a deal. The trash created after use is. reply kragen 21 hours agorootparentthe trash created after use of shopping bags is not a big deal either; a typical non-reusable shopping bag weighs 200 milligrams, so if you use three per day for 72 years, you produce a grand total of 16 kilograms of shopping bags. that's less than even your own bones, which will also last thousands of years the issue with paper mills is not their energy consumption, which generally is fueled by the same biomass they process (and is thus carbon-neutral), but the toxic waste they produce do the math instead of just posting stuff without thinking reply vel0city 4 hours agorootparentWhen I go fishing at the creek it is not a ton of paper bags littering it. Single-use plastic bags are terrible and people overly use them. Go get a pack of gum from a bodega and you'll be offered a plastic bag by default. Maybe we shouldn't necessarily ban them, but we should definitely tax them to make people question \"do I really need that bag?\" reply Swizec 23 hours agorootparentprev> you start collecting reusable bags that you have no way of reusing I use them as trash bags for the various small trashcans in the home (office, bathroom, etc). Works great. Also fantastic for any trash (like fish) you have that you don't want stinking up the big trash can for several days and needs to be taken out asap. reply legitster 23 hours agoparentprevOur neighborhood has a stretch where people park and dump litter profusely. I go out once a month and clean it up. (Soooo many vape pods) I think the biggest change is mostly in perception. Old plastic bags were lighter and blew around so they were very visible. The newer heavier \"reusable\" plastic bags use a significant amount more of plastic - they are heavy enough to stay near where they get dropped and sink to the bottoms of puddles. You don't see them floating around in the wind but they still get littered a ton. reply seoulmetro 17 hours agorootparentThis sounds like the UK. In the UK everything is slightly dirty, but then there are these significant piles of garbage that just go unattended and grow in size. I think it shocked me when I first moved there. Years of rubbish in some areas, months in others, and it would be right in front of peoples houses and parks. The UK really got left behind in terms of quality of life at some point. GDP doesn't buy nice living. I'm sure it's similar in other parts of (wealthy) Europe. reply donatj 23 hours agoparentprevI'm skeptical. As it was pointed out to me, what percentage of things going in those plastic bags is already wrapped in a plastic bag, 90%? The single most useful plastic bag on the outside seems negligible in comparison. reply lxgr 23 hours agorootparentIf we can relatively easily reduce the single-plastic waste of those 10%, why not start there (while in parallel thinking about alternatives for product wrappers)? There are also so many other product container types than plastic: Glass, metal cans (ok, these are often plastic-coated and I don't know how recycling for these works, but it seems to be possible), paper... It doesn't work for everything, but it does for many things – assuming the right incentives are in place. reply vel0city 4 hours agoparentprevOn a recent trip to Canada, I really noticed the fact every stream and river didn't have any noticeable plastic trash clinging to all the roots and twigs and what not. It was pretty nice, and I quickly got used to not having disposable bags. And now I've got a Super C and Jean Coutu bag in my car. reply Carrok 23 hours agoparentprevSeconded. Plastic bag bans here in Colorado have been fantastic from my view. Far less trash everywhere, and we use better bags that can carry more without failing catastrophically in the parking lot. reply bigstrat2003 23 hours agorootparentThe plastic bag ban in Colorado has been awful. I would much rather go back to before. reply Carrok 23 hours agorootparentWhy? I haven't used a disposable plastic bag in a decade, and don't miss them in the least. What issue do you have with it? reply rickydroll 23 hours agorootparentThose thin supermarket plastic bags were fantastic for disposing of cat waste and litter. You put the waste in the bag, tied it off, and threw it in the outside trash bin. Now, we buy quart food storage bags for disposing of cat waste. reply buildsjets 22 hours agorootparentWhat? No! They were TERRIBLE for cat litter because they frequently had holes in the bottom from the manufacturing process, and would dribble used litter all over your floor. We use the allegedly-biodegradable (but probably not) dog poop bags, at a grand cost of around 2 cents per each. reply rickydroll 6 hours agorootparentDouble bagging solved the leaking problem. Thanks for sharing the dog poop bag solution. I'll give it a try. reply Aunche 23 hours agoprevIt's not sexy, but the number one way to reduce plastic pollution is to build landfills and proper waste management systems in developing countries. Plastic bans are largely performative and often counterproductive. Instead of bringing their own bags, a lot of shoppers just treat the \"reuseable\" bags the they buy a the supermarket as disposable. https://www.forbes.com/sites/patrickgleason/2024/01/22/new-j... https://www.latimes.com/environment/plastic-bag-ban-waste-40.... reply quinncom 23 hours agoparentMexico City implemented a ban on single-use plastics on January 1, 2021, which has been almost completely ignored except outside of corporate chains such as Walmart, where indeed many people just buy the recyclable bags. reply MattGaiser 23 hours agoparentprevI’m curious what bags would need to cost to change that behaviour, as for all the complaining about inflation, many clearly don’t miss 3-4% a shop buying cloth bags here. reply graeme 23 hours agorootparentI bring a bookbag to stores, but if I forget one I buy a \"reuseable\" bag and then get rid of it. If you need a bag you need a bag. Before plastic, stores had paper bags. Some stores offer these now but many don't. I find it surprising. They're certainly less useful than plastic bags but they're plenty useful. you can walk with 2-3 in your arms, they hold a good amount of things, and they're recyclable. And then if you need one with handles you can get one of the paid bags stores have. reply londons_explore 23 hours agorootparentprevI think bags would have to cost $10-$20 before the most people started remembering to bring one to the shop. People simply don't think far enough ahead to plan to take a bag to the shop, and prefer to 'pay for convenience'. Plenty of people pay $30 to avoid having to turn their oven on to cook something. reply legitster 23 hours agoprevI'm actually pretty curious how they conducted the survey - you can't usually get 80% of people on a phone to admit they use the bathroom, let alone agree with a complex policy proposal. The attached report is high on charts but low on details. reply dinkleberg 23 hours agoparentYeah I was hoping to see some more details on that. I'm in favor of a ban like this, but as with every big move like this, there are negative consequences that come with it (everything has trade offs). I am very curious how they framed the question to get such a high percentage of agreement. Surely this ban would result, at least in the short term, in higher prices for a lot of goods. reply lykahb 23 hours agoprevA ban like that sounds good. But what would replace those plastics? For the take-out food containers a common alternative is PFAS-treated paper. Is it much better for the health environment? reply lxgr 23 hours agoparentIn Germany, I've seen a multi-use container system implemented by at least some delivery companies and restaurants. But even just reducing the staggering amount of single-use plastics in regular restaurant/bar contexts in the US would be a start. The amount of restaurants serving plastic cups, paper plates, and plastic tableware is absurd, and I'm not talking about festivals, outdoor food trucks etc – regular sit-down places with proper plumbing and enough space for a dishwasher that really have no excuse whatsoever for generating that amount of waste. reply cogman10 23 hours agorootparent> regular sit-down places with proper plumbing and enough space for a dishwasher that really have no excuse whatsoever for generating that amount of waste. They have an excuse; they don't want to pay someone to wash dishes. This is why a ban is necessary. Businesses will always look for the cheapest way to operate. reply Carrok 23 hours agoparentprevLocal restaurants here have started using DeliveryZero which is a reusable container program, you just take the containers back to a drop point. That and plenty of places use non-PFAS-treated thicker paperboard. Those are also great in my experience. reply com2kid 23 hours agorootparentSadly it looks like DeliveryZero is still using plastic. :( I'd really love to see some companies using non-plastic takeout containers, especially for hot foods. But even with cold foods, every study that has come out has shown microplastic shedding even from water bottles. reply Carrok 23 hours agorootparentDon't let perfect be the enemy of good. Could it be better? Absolutely. Is it a great starting point? Absolutely. reply com2kid 23 hours agorootparentUgh I've been to other countries that have such bougie takeout containers, the shit we have here in the US is insufferable by comparison. It is funny, sometimes a new Chinese restaurant HQ'd in China will open up locally, and they'll start off using the same high quality takeout containers that are used in China, including such things as every order comes in an insulated bag (!!) but eventually they bow to economies of scale and adopt the same shit takeout containers everyone else uses in the US. Bleck. I always think of when I went to Beijing, ordered a fruit soda, and they took out a real glass bottle, filled it up, sealed it, and gave it to me! 100% premo feeling. reply ars 23 hours agorootparentprev> you just take the containers back to a drop point. If someone drives to drop off the container they have uses way more resources than they would just using a disposable. I suspect this idea is just greenwashing. > thicker paperboard Which again uses more resources, and emits more CO2, than plastic. reply Carrok 23 hours agorootparentYou're assuming I'm driving it back to the drop point as a dedicated trip. A: I typically keep the containers until I order next time, you have a month to drop them off. So just drop them off when you're picking up your food. B: The drop off point is a short walk away, so you could just, you know, walk. I'm not worried about resources or emissions here, I'm more concerned about trash in the rivers/oceans, and microplastics. There are more metrics to account for than you are allowing for. reply akasakahakada 20 hours agorootparentOf course transport 10 tons of paper product has zero energy consumption according to Law of Newtonian Physics. More weight, less energy. We successfully keep the ocean clean, but all turtles are dead by stopping ocean current with global warming. reply kaibee 23 hours agorootparentprevAlso as EV/Plugin-Hybrid adoption keeps increasing, the emissions generated from even a dedicated trip aren't an issue. reply ars 23 hours agorootparentprev> I typically keep the containers until I order next time Don't them smell? If you wash them by hand you end up using more resources than if you had disposable. If you put them in a dishwasher then, I guess that would work, but seems like a lot of effort for takeout. > I'm more concerned about trash in the rivers/oceans, and microplastics Are you dumping things in the street? I suspect you are not. River/Ocean trash is a huge problem, and is not being caused in the US or Canada. reply Carrok 23 hours agorootparent> Don't them smell? If you wash them by hand you end up using more resources than if you had disposable. No. There is absolutely no way that rinsing out a container uses more resources than creating and transporting new disposable containers. > Are you dumping things in the street? I personally am not. I see plenty of people who are. I see plenty of trash in my local rivers and streams, so I'm not sure what you're basing your statement on. reply kragen 21 hours agorootparent> There is absolutely no way that rinsing out a container uses more resources than creating and transporting new disposable containers. that's what i thought, too, until i did the math, and it turns out that i was wrong. rinsing out a bottle with hot water uses several times more energy than manufacturing a brand new plastic bottle from petroleum and transporting it (they're generally transported as preforms until the bottling plant, which keeps the costs down). in most cases, though, rinsing it out with cold water does use less the high bit here, though, is not that you should stop using hot water to wash your dishes, or using reusable dishes. it's that the resource usage of food packaging is an irrelevant distraction from the real environmental devastation that's going on all around you (actually no, the high bit is that you should base your beliefs and actions on objectively verifiable information and rational analysis rather than superstition) reply Carrok 21 hours agorootparentI use cold water to rinse lol. Right, there are other issues so let’s do nothing about this issue. Got it. reply kragen 21 hours agorootparentin your case rinsing does use less resources than manufacturing and transporting a new container, then! reply buildsjets 22 hours agoparentprevMumbai has this solved, with the Dabbawala and Tiffin system. Tiffins are standardized reusable metal containers used for food delivery in Mumbai. The food can be restaurant takeout, or it can be a home-cooked meal someone sends you. Dabbawalas are the vendors who deliver the food, and collect the used tiffins/dabbas. https://feedr.co/en-gb/c/blog/the-amazing-dabbawalas-of-mumb... https://www.atlasobscura.com/articles/how-mumbais-dabbawalas... reply nojvek 4 hours agorootparentIt’s like shipping containerization but for actual food. I love it. reply cogman10 23 hours agoparentprevBefore we had PFAS paper there was wax coated paper. So long as you aren't using something like paraffin wax, it'll happily decompose with the rest of your trash. The focus needs to be on containers that decompose in weeks/months/a year. Not thousands of years. reply AlecSchueler 23 hours agoparentprevThe EU have a new directive for that which comes after the single use plastics directive: https://www.europarl.europa.eu/news/en/press-room/20240301IP... In my local area I'm seeing a move towards returnable containers. reply peetle 23 hours agoparentprevGreat graphic on the environmental impacts of different kinds of grocery bags: https://ourworldindata.org/grapher/grocery-bag-environmental... In short, single use plastic bags are very hard to beat. reply htk 23 hours agoprev\"Ban unnecessary single-use plastic products most likely to become plastic pollution, e.g. shopping bags, cutlery, cups & plates\" Such a loaded question just weakens the point. That's why it's hard to take these efforts seriously. reply gleenn 23 hours agoparentI kind of agree. I feel like the word \"unnecessary\" in that sentence guts it. Of course we should ban unnecessary and wasteful things. If the question was \"should we ban plastic bags completely in favor of re-usable ones\" might get a very different answer. I would definitely say yes to the first question but I also sometimes forget to bring my reusable bags to the store and then definitely always get the disposable ones if it's more items than I can carry in my hands. reply kragen 23 hours agorootparent> Of course we should ban unnecessary and wasteful things i strongly disagree with this; in almost all cases, the choice of what is unnecessary and wasteful should rest with the individual person most affected by it, not some kind of political authority or social consensus. even when it's legitimately a question of public policy—alcohol, for example, an addictive drug that causes massive amounts of crime and something like 5% of the world's human deaths—pigovian taxes are far preferable to outright bans. alcohol is a useful cleaning fluid, for example, and an effective antidote to ethylene glycol poisoning (though in rich countries safer antidotes are now available) kim jong un has banned unnecessary and wasteful hairstyles, which is the road down which 'of course we should ban unnecessary and wasteful things' generally leads i find it rather horrifying how casually people promote totalitarian ideologies like this nowadays reply gleenn 18 hours agorootparentAll I'm saying is the word \"unnecessary\" in that question clearly is a \"weasel word\" because, just like you're saying, it's subjective and also greatly weakens the statement. Usually unnecessary things with negative externalities are easy for people to say \"sure let's get rid of that, it's not providing value\". I think you're caveating something which only furthers that sentiment. reply kragen 18 hours agorootparenti agree that it's a weasel word, but it isn't enough of a weasel word to justify your conclusion. we should abstain from unnecessary and wasteful things, and perhaps in a few cases we should tax them, but very rarely should we ban things simply because they are unnecessary and wasteful! reply ars 23 hours agoparentprevYah, I'd like to see the actual survey wording. All the weasel words they put in there make it seem kind of fake. reply JumpCrisscross 23 hours agoprevIs there a good substitute for cling wrap? I mostly store food in reusable containers. And I try to use foil as much as possible. But some things are irregularly shaped and need a tight seal, and I’ve struggled to find a good alternative. reply 542458 23 hours agoparentBeeswax wrap for things that don’t need a tight seal. Most things should just go into a container that has a proper lid. IMO you save fridge space that way because now things stack. reply crooked-v 23 hours agoparentprevSlightly larger reusable containers? There are also plenty of varieties of reusable ziploc-style bag out there, including ones in jumbo sizes. reply 0xEF 23 hours agorootparentThat and being a bit more conscious of our consumer choices. If you jave that much left over, try keeping a food journal for the sake of getting a better idea of how much we actually consume in a month, then adjust your purchasing weights and quantities. My wife and I did this about a year ago in effort to make some dietary changes, but it also happily resulted in less left-overs and slightly lower grocery expenses. reply cromka 23 hours agoparentprevI guess it’s OK. The biggest problem are store-bought products. The once in a while use of very thin cling film used when preparing food is minuscule in comparison. reply eitally 23 hours agoparentprevWe keep a roll of plastic wrap in the drawer for the rare times it's actually necessary, but we've had good luck with the combo of two things: 1) pyrex containers with silicone replacement lids, and 2) stretchy silicone lids[1] for other containers (or directly on the ends of things like half-cucumbers or melons). We haven't found very many common use cases where cling wrap is actually necessary, but it's non-zero. I'm satisfied with our current state, but my bugbear is alternatives to ziplock bags. [1] https://www.amazon.com/silicone-stretch-lids/s?k=silicone+st... reply dylan604 23 hours agorootparentFor freezing things, the ziplock bags are definitely hard to find an alternative for me as well. reply esafak 23 hours agoparentprevSilicone stretch lids and bees wax wraps. Wrap foil around it for added protection, and re-use it since it won't get dirty. I sometimes use small plastic bags I already have lying around for the last part. reply sethammons 23 hours agoparentprevI feel like there are two levels of single use plastics. Single use plastic for individual use like food preservation seems like a decent carve out. Though, I suppose any carve out would be abused. Something like \"can't ship with single use plastic as a packaging utility\" reply worik 23 hours agoparentprev> Is there a good substitute for cling wrap? In my area there has been \"compostable\" cling wrap available I have no data about the veracity of the claim reply peterhadlaw 23 hours agoparentprevThere are beeswax based resuable clingwrap alternatives although I haven't tried them myself reply eitally 23 hours agorootparentWe've tried it. I wouldn't call it a cling wrap replacement because it's a wax-coated paper and therefore not watertight/airtight in the same way plastic wrap is. It's fine for some things, but we never found ourselves choosing that when we could use a rigid container. It's very good as an external wrap for a sandwich you first wrapped in wax paper, though. reply kragen 23 hours agoparentprevparafilm, which is even less reusable than cling wrap reply ars 23 hours agoparentprevYou use foil instead of cling wrap? And you do this for environmental reasons? I'm struggling to understand here, why in the world would you do that? Foil consumes thousands of times more resources than plastic wrap. reply kragen 23 hours agorootparentthousands, really? that seems unlikely; it certainly isn't thousands of times cheaper reply tedunangst 22 hours agorootparentI assume the cost of plastic is about zero, and what you're paying for is shipping, storage, markup, all the middle stuff. Using numbers provided, 1000 sqft of plastic is $10.00, which could be $9.99 logistics and $0.01 material. 1000 sqft of foil is $50.00, with the same $9.99 shipping cost, and $40.01 in material. So that's 4000x. Numbers are kinda fake, but you get the idea. reply kragen 21 hours agorootparentwholesale plastic is surprisingly expensive, typically several dollars a kilogram. (even fairly raw petroleum distillates like gasoline cost about a dollar a kilogram at retail.) it's not like gravel and sand where shipping costs are most of the cost of the material; petroleum is precious enough to be routinely shipped intercontinentally, and plastic is an added-value product on top of that, requiring several capital- and energy-intensive purification and processing steps to take an especially cheap example, polyethylene, as i understand it, is made by polymerizing ethylene (with People bought all of these things before plastics. Yes, and that was dangerous and inconvenient. reply abdullahkhalids 21 hours agoparentprevReusable containers will work for all of these, except maybe pre-cut vegetables. You pay a deposit fee, and take your stuff in reusable containers. Still in practice with milk bottles. Why not with everything else. reply ganzuul 23 hours agoparentprevGlass jars and tin cans were the old solution. Perhaps some modern deep eutectic chemistry can improve on the old energy economy of glass. reply kragen 21 hours agorootparentdeep eutectic systems seem a lot more likely to help with synthesizing organic plastics than with synthesizing glass reply L-four 23 hours agoparentprevWhich ever is more profitable. reply Ekaros 3 hours agoprevI wonder if all of these 85% people simply already refuse any single use plastic item. And never use such? Like no more plastic bags for anything, or not single plastic utensil. Or no single plastic cup. No single use medical devices like syringes. reply textninja 23 hours agoprevI’m taking this with a grain of salt because 85% of people adopting such a hardline environmentalist stance defies reason. I think the poll’s design and authors probably had something to do with it. Context matters! reply legitster 23 hours agoparentKind of like that \"4 out of 5 dentists\" claim from back in the day - it involved some very heavy editorializing: https://nowiknow.com/who-was-the-fifth-dentist-that-didnt-re... reply jjcm 23 hours agoprevI don't want a ban, I want a tax on them. There's a strong use for single use plastics - medical goods being one of the important ones that I highly suspect people don't want a ban of. They define these as \"necessary\" versus \"unnecessary\" in their poll (ie the 85% figure is specifically for \"ban unnecessary single-use plastic products, e.g., shopping bags, cutlery, cups & plates\"). Things get murky really quickly when we bucket items. Are single use water bottles bad? Probably. Are all plastic liquid containers bad? Almost certainly not, you wouldn't want to store a corrosive acid that eats through glass in a glass bottle. So either the option is create a giant database of what is/isn't single use, which then can be gamed in its own way, or simply tax all single-use plastics such that necessary cases still leverage them, but it quickly doesn't become cost-effective for the main offending category of them. reply cogman10 23 hours agoparent> Are all plastic liquid containers bad? Almost certainly not, you wouldn't want to store a corrosive acid that eats through glass in a glass bottle. I'd argue that most, especially containers in regard to food item, are. You don't have to have a database to figure this out, you can start simple by just banning the use of single use plastic with regards to food. There aren't many (any?) items that are highly corrosive and intended for human consumption. Plastics in medicine could wait for another round of legislation. Single use plastics used for shipping consumer goods and food are the 80% of plastic production problem. reply ganzuul 23 hours agoparentprevThe tax might not have to be monetary. Putting geolocation QR codes on stuff could help mitigate the super-polluters by taxing perception. reply textninja 22 hours agoparentprevI can't trust a plastics poll that doesn't also ask who wants the old straws back. reply ravenstine 23 hours agoprevJust because people say that doesn't mean they'll actually want it in practice. As well, asking people how important they think something is may not equate to their support for sweeping legislation. reply conductr 23 hours agoparentMy city banned bags once and had to immediately figure out how to unban bags because it caused outrage. They talked about it for 2 years and people supported it. Until the day it took effect that is. reply zeeveener 23 hours agorootparentMy city talked about banning \"Single Use Items\" from drive thrus and such, but what they failed to communicate was this also meant \"Paper Bags\" like what McDonalds would hand you out the window. It was _that_ part which sparked outrage. The overly-simplistic definition of \"Single Use\" items included items which are _actually_ recyclable like paper (or compostable if covered in food-stuff). They undid the ban \"for re-evaluation\" reply triyambakam 23 hours agoparentprevSee e.g. Brexit reply Skytram 23 hours agoprevYes yes instead of single use bags at the store I now get more durable plastic bags that I throw away after using once. Well done. reply idle_zealot 23 hours agoparentObviously that's not how they're meant to be used, but you bring up a good point about the interaction of policy and behavior. These policies cannot be made without consideration for what behavior they will incentivize. In the case of disposable grocery bag bans, requiring that said disposable bags be made of more sturdy plastic so as to technically qualify as reusable is only going to harm the environment more as consumer habits won't change. The solution, of course, is not to throw up our hands and declare that nothing can be done. Banning the sale of these technically-reusable bags at point-of-sale very well might solve the problem and cause consumer behavior to shift as the sustainable practice of bringing your own bags becomes the most convenient one. Some people find utility in these sturdier plastic bags, so a general ban would only do harm. They just specifically shouldn't be sold at checkout like disposable bags used to be. reply AlecSchueler 23 hours agoparentprevWhy don't you use reusable bags? I have a couple that fold up and go in my back pocket. reply wannacboatmovie 23 hours agorootparentThat's utterly ridiculous and highly inconvenient for nearly everyone that isn't proselytizing about reusable sacks or needs to purchase more than a few items. What works for dedicated urbanists doesn't fly for the other 85% of the population. Reusable bags are nearly universally unsanitary. People let their cats play in them, never wash them, then place them on the same conveyor belt where you put your vegetables. reply AlecSchueler 23 hours agorootparentI don't think it's utterly ridiculous for most people. It's very common here in the Netherlands and I'm not sure the average Dutch person is so extremely peculiar to the rest of society. It's really no more inconvenient than carrying the bank card I need to pay for my purchase and in the worst case scenario if I forget it I can just buy a new bag to reuse with my other items. Regarding how clean they are, I just wash mine in the washing machine and I wash my vegetables as well. reply worik 23 hours agorootparentprev> Because that's utterly ridiculous and highly inconvenient for nearly everyone that isn't proselytizing about reusable sacks No Here in Aotearoa they are completely normal > Reusable bags are nearly universally unsanitary...place them on the same conveyor belt where you put your vegetables. Golly. Given the habits of growers you really should wash your vegetables before you use them. Pesticides reply AlexandrB 23 hours agorootparentNot just growers, I don't think grocery store employees are washing their hands religiously when they're putting this stuff out. reply AlecSchueler 22 hours agorootparentI worked in a supermarket. They aren't washing their hands at all and they might well be playing football with your bread rolls. reply wannacboatmovie 23 hours agorootparentprevThese days I often see the grocers using gloves when stocking shelves. reply AlecSchueler 22 hours agorootparentSingle use plastic gloves? reply sethammons 22 hours agorootparentprevsomeone else's chicken blood is probably worse to get on your veg than pesticides. The bacteria can infiltrate the veg. reply wannacboatmovie 23 hours agorootparentprevPesticides are water soluble. Cat feces is not. reply AlexandrB 22 hours agorootparentWhen you wash something you're not dissolving contaminants - you're mechanically removing them. Most bacteria are not water soluble yet we manage to wash them off our hands. reply quantified 23 hours agoparentprevHow much do you pay for them? For bags, there is no reason for a store to give them out. You had to pay for a wallet to hold your cash and cards, a purse to hold them if you don'f have pockets. No need for bags to be a cost center for a store. reply kragen 21 hours agorootparent$40 per bag here, too little to worry about reply Carrok 23 hours agoparentprevYou are throwing away durable, reusable, functioning products after one use? .. Why? reply JumpCrisscross 23 hours agorootparentThe only situation where OP isn’t an idiot is food delivery. If you get your groceries delivered, I don’t think there is a formal feed back mechanism. (Though your grocery store would almost certainly accept them back.) reply bagels 23 hours agorootparentIt's an inconvenience to actually reuse the bag that is inevitably covered in rancid meat juice. Calling people idiots isn't constructive, and besides, one may not be an idiot for simply not caring about burying a few plastic bags in the landfill. It's just different judgements about what's important. reply JumpCrisscross 23 hours agorootparent> an inconvenience to actually reuse the bag that is inevitably covered in rancid meat juice Why do you have rancid meat juice in your grocery bag!? Why do you have rancid meat! > not caring about burying a few plastic bags in the landfill I don’t particularly care about this. I still have a couple reusable bags in the back of my car that I use to transport food from the grocery store home. (I never have to deal with bags breaking. And my town charges for single-use paper bags, which I think is a fair compromise.) When rancid meat juice raises its head, it’s rare and immediately dealt with by cleaning out the fridge. I’d be worried for a friend citing exposure to it as not only a regularity, but inevitability. reply bagels 23 hours agorootparentYou've never had a package of meat leak a little juice in to the grocery bag? If you have, you either wash it (inconvenient) or you have rancid meat juice if you don't (it doesn't start rancid). reply vel0city 3 hours agorootparent> You've never had a package of meat leak a little juice in to the grocery bag? No, and if it was a common occurrence I'd find a different butcher that can actually package the meat properly. There have been a few times I've washed a bag because it got dirty. It wasn't really inconvenient. I just tossed it in the laundry with the rest of my clothes. Or do you also just throw away clothes once they get a little dirty? reply JumpCrisscross 23 hours agorootparentprev> You've never had a package of meat leak a little juice in to the grocery bag? Not frequently! If that’s happening, the butcher is doing a bad job sealing the package or the meat isn’t fresh. I agree in those situations I’d likely toss the bag versus rinse it. But this is—and should be—a once every couples years problem. (And I buy meat almost every time I go to the grocery store.) reply Carrok 23 hours agorootparentprevYea, taking 5 seconds to rinse the bag out in the sink is _such_ an inconvenience. Life is rough. I stopped buying meat for environmental / water usage reasons a while back, so no, this isn't an issue for me anymore. Guess I'm just a stupid hippie. reply textninja 21 hours agorootparent> Yea, taking 5 seconds to rinse the bag out in the sink is _such_ an inconvenience. The old \"you're just not doing it right\" chestnut, where have I heard that one before! Hey, by any chance have you noticed how many of those silly face masks made it (or didn't make it) to landfills? > I stopped buying meat . . . Guess I'm just a stupid hippie. You said it not me! reply Carrok 23 hours agorootparentprevYou're assuming the bag actually makes it to the landfill. MANY do not. Also, the rancid meat juice issue sounds like a problem specific to you. I certainly don't have that issue. reply noncoml 23 hours agoparentprevWalmart have made their bags ridiculously small to make you buy more reply Clubber 23 hours agoparentprevIf the grocery store made plastic bags that didn't have holes in them all the time, they make a good pooper-scooper bag and thus reusable. reply textninja 21 hours agorootparentWe used to use them for this all the time! reply vel0city 3 hours agorootparentprevI get doggie poop bags that are allegedly compostable. I never have to worry about the condition of the bag, they come in neat rolls for the dispenser on my leash. They're way handier than disposable shopping bags and cost a few pennies each. I buy a case of them and they last me a few years at a time. They do seem to be somewhat water soluble. I left some out in the rain one time and they got oddly mushy and weaker, different from regular plastic. reply rkagerer 23 hours agorootparentprevYeah, I used to keep all my grocery bags and use them as garbage bags, at least that got a reuse out of them. reply winrid 23 hours agoparentprevsounds like a skill issue reply automatoney 23 hours agoprevOh wow, I haven't heard of theis \"plastic pollution treaty\" it sounds super promising! I think one of the things that makes this issue so popular is just how obvious it is to see plastic trash all over the place. Climate change and carbon emissions can be a bit abstract, but plastic pollution is everywhere, and extremely visible. reply ninetyninenine 23 hours agoprevI think pretty much everyone wants this yet we still use these plastics… we want to end global warming yet we still drive cars. We care but to what degree do we actually care? Not much. There’s huge business interest pushing the usage of environmentally damaging products forward because it generates money. This against consumer laziness, progress will be slow reply textninja 22 hours agoparent> There’s huge business interest pushing the usage of environmentally damaging products forward because it generates money. The converse (pushing green products) is also true so we have to consider whether the environmental impact is as big as is claimed, whether it's worth it even if it is (single issue reductivism is a dangerous way to craft policy), or whether banal financial and power incentives are the true moving force behind the lobbied solution. reply lunarboy 23 hours agoparentprevYeah positive incentive and/or negative deterrent is just not strong enough for people to act on it over the current convenience. If \"reusable\" bags cost $10 at the store, but you get it refunded if you bring your own, I bet people won't forget to bring their own. The laws just arent strong enough reply EVa5I7bHFq9mnYK 22 hours agoprevDon't need a survey for that. Just go to the nearest supermarket, stand near the cash register, and count how many people buy plastic bags, and divide by how many bring their own multiple-use bag. You will get the true picture, which I suspect is 10:1 in favor of single-use plastics. reply vel0city 3 hours agoparentThe last time I was in a place that had a disposable shopping bag ban for a while, I was the only one seemingly grabbing some of the bags for sale as I was a visitor and did not have any of my own bags yet. I didn't see a single other person who actually lived there buy any bags on any of the trips I took to the grocery. reply H1Supreme 23 hours agoprev64% of the people surveyed in the US \"agree\" or \"strongly agree\". Maybe it's because I spend most of my time in less affluent parts of the country, but I almost never see people bringing their own bags to the grocery store. Checkout clerks usually seem surprised when I pull out my canvas bags. reply primitivesuave 23 hours agoprevWhen I was in New Zealand, they had a single standard reusable metal cup for all their coffee shops. That is, you can pay to refill the cup, and if the cup is dirty, any coffee shop will exchange it with a clean one for free. Consumers pay a small deposit for the cup, and can get the deposit back by returning it. Unfortunately, common-sense solutions like this one require tremendous political coordination to even get started. In most countries, environmentalism is far less creative - levy new taxes to change consumer behavior (e.g. single-use bags), or ban something entirely without consideration toward the alternatives (e.g. paper vs plastic straws). reply doug_durham 22 hours agoprevYou don't need to wait for a ban. There is a company that sells wonderful cherry tomatoes. They sell them in an elaborate non-reusable plastic container. It keeps the product from being damaged and it presents the product well. However I cannot justify throwing a large plastic container in the landfill so I can have a dozen cherry tomatoes. So I don't purchase them anymore. I wrote to the company letting them know the situation (I haven't heard back). We can make choices in our day-to-day lives to reduce plastic. Let the levers of the market pressure producers. reply L-four 23 hours agoprevIf we could get the total cost of product disposal built into the checkout price. I think single use plastics would solve it's self along with a litany of other garbage disposal problems. reply bagels 23 hours agoparentWhat would you estimate the cost to be? In my locale, bags are charged at $0.25 each. reply AlexandrB 23 hours agoparentprevWhile I agree in principle, I don't think this quite solves it. For example, disposable bags are extremely cheap to dispose of - they compress well and would take up minimal landfill space. The problem is how many of them \"escape\" between the initial purchase and getting to the landfill. How do you include that in the cost? reply L-four 23 hours agorootparentIdeally this would be factored in and included in the cost of disposable. E.G. the cost of employing litter collection and disposal. The cost needs to be placed on the producers so they have incentive to solve these problems. Many plastic containers and recycling processes could be standardized but currently there's no reason to do. reply bagels 23 hours agoprevHow does this work, practically, at the grocery store? Many foods are sold in a disposable plastic wrapper. Cereal, meat, frozen foods, etc. What is the alternative? We bring a bunch of tupperware and everything is sold in bulk? reply kragen 23 hours agoparentthey could sell you a glass jar with the food in it; in rich countries the extra cost of the disposable single-use glass wouldn't be significant to most consumers, although it would produce more pollution, hazard, and waste than the plastic alternatives. we've had returnable coke bottles since they started bottling coke reply com2kid 23 hours agoprevDoing this will involve a dramatic reshaping of how society works. All of the food packaging that is plastic needs to go away. This would entail large shifts in supply chains, how we buy groceries, and economics of scale for certain goods. We know it is possible (glass bottles were the norm even just 30 years ago), but doing that transition now will be huge. Then there are all the plastic bags that food comes in. From cookie sleeves to protein bars, all those plastics need to go away. How products are made shelf stable will need to change, which means flavors will change, and some products may no longer be viable. I hope we make the change as a society, but it will be absurdly complicated to do. Edit: I'd love if the restaurant industry had standardized reusable takeout container sizes that could be washed and handed back to a restaurant for (sterilization and then) reuse! It would not only improve the quality of takeout food (better insulation), but be more environmentally friendly. reply JumpCrisscross 23 hours agoparent> All of the food packaging that is plastic needs to go away Most of it can be swapped to bioplastics with minimal loss of utility. reply com2kid 23 hours agorootparentOnly if they are 100% bioplastics, and 100% biodegradable in nature, not just in an industrial facility, or else you can end up with the same microplastics pollution problem. Although different chemicals are likely to have dramatic different impacts on the environment, hopefully by now we've learned that \"dumping a bunch of microparticles into the environment and hoping everything is OK\" is a bad way to go about things. reply DataDive 23 hours agoprevI always use my reusable bags, On the other hand, I found that sometimes I run out of plastic bags when I need them at home. In some situations, a plastic bag is super useful: store a wet paintbrush overnight, wrap something that needs to retain moisture, lock up some smelly stuff, etc. In those cases, I go to a store that still has plastic bags, then buy some stuff there and generously pack them into plastic bags. reply nerdjon 23 hours agoprevI would love for it to happen since if it were to finally just happen maybe enough money will be pumped into figuring out the alternatives. But it would need to be done with a hard cutoff date but far enough for those things to be figured out. There are still some areas that we seem to not quite have an alternative. Or the environmental impact of the alternative is not quite as rosy as it appears. reply peetle 23 hours agoprevYes, but who wants to pay more for them? It's very hard to beat single use plastic bags for environmental impact: https://ourworldindata.org/grapher/grocery-bag-environmental... reply Gys 23 hours agoprevThose people clearly vote differently, otherwise this (and other problems like this climate thing...) would have been solved a long time ago. Maybe they forgot to also ask 'what if it will cost you some money in the process or diminish your convenience'. reply g9yuayon 21 hours agoprevThe All-In podcast mentioned research on the concentration of micro plastic particles in human body. I was wondering if banning single-use plastics can somehow reduce that concentration as well. reply disambiguation 22 hours agoprevI thought the majority of ocean plastic pollution was fishing nets? is everyone on the same page about what \"single-use\" plastic means here? reply wannacboatmovie 23 hours agoprevThose numbers are so highly skewed it seems improbable. reply robxorb 23 hours agoprevHow do they choose people for these surveys? And can 24k people from 32 countries (so, 750 in each) be representative of 8 billion in 200+ countries? I know only a minority locally who could support a plastics ban, due to low awareness. Certainly a guesstimate in other countries I can think of who are likely responsible for high plastics pollution, would be far lower than 8 or 9 out of every 10 people, as it's a contributor as to why the issue exists in those places, surely? reply verteu 23 hours agoparent> can 24k people from 32 countries (so, 750 in each) be representative of 8 billion in 200+ countries? Yes, assuming they are sampled randomly. If they aren't, a bigger sample size won't help anyways: https://sample-size.net/confidence-interval-proportion/ reply rvnx 23 hours agoparentprevhttps://www.ipsos.com/sites/default/files/ct/news/documents/... \"These are the results of a survey conducted by Ipsos on its Global Advisor online platform [...] they are more urban, more educated, and/or more affluent than the general population. The survey results should be viewed as reflecting the views of the more “connected” segment of their population\" So basically it's people who have internet and accepted to be paid to answer surveys. Like a Twitter poll. It's nowhere meant to be representative of the population. reply c22 22 hours agoprevIf this is true then is a ban even necessary? Or are just 15% of the people responsible for all single-usage of plastic? reply cynicalsecurity 23 hours agoprevI guess only with the exception of medical use. reply AlecSchueler 23 hours agoparentYes, that's how it's implemented in the EU directive at least. reply stronglikedan 23 hours agoparentprevWhy can't they use reusable containers that can be sterilized just like their contents? Just asking. I don't support such a seeping ban, because I know the ramifications. reply TylerE 23 hours agorootparentHow do you prove the sterile field hasn’t been broken? Also glass is a big hazard in a hospital… it will get dropped and shattered. reply OptionOfT 23 hours agorootparentprevSterilization doesn't solve all. Prions for example survive an autoclave. reply wannacboatmovie 23 hours agorootparentprevWe're not going back to the days of glass bottles for IV bags. The end. reply SergeAx 18 hours agoprevOh, that's an awesome result! I wonder how many of these people want to pay 20-50% more for their goods, repackaged? reply blackeyeblitzar 23 hours agoprevI am OK with plastic bans but they need to be implemented smartly. Near me, bans on single use plastic bags have resulted in all the stores handing out extra thick plastic bags that are treated as single use by everyone anyways. So I feel like it’s made the problem worse. reply paul7986 23 hours agoprevWeren't plastics and the recycling movement supposed to be good for the environment? reply emiliobumachar 23 hours agoprevCrap. Most of the substitutes have a bigger ecological footprint, even if you don't care at all about cost and comfort. Those reusable shopping bags need to be actually reused, several dozen if not hundreds of times, to be ecological. How many times have you used your last one? reply DataDive 23 hours agoparent> Those reusable shopping bags [...] How many times have you used your last one? This reply blew my mind ... when you realize someone must have the exact opposite experience ... of course I use the reusable bags, they are in the trunk, and first step after pulling into the parking spot is to take these out the trunk and head into the store in the last 5 years used only my reusable shopping bag every time except in a few cases when I forgot to put the bags back in the trunk for some reason (usually, I needed to transport bigger things) reply AlexandrB 23 hours agoparentprev> How many times have you used your last one? Every shopping trip for 4 years now. It tore, but my partner was able to patch it since it's made of pretty good quality fabric. reply drivebyhooting 23 hours agorootparentHave you smelled them? Do you wash them? reply abdullahkhalids 22 hours agorootparentI use reusable bags for many years as well, and I wash them every so often. I of course, wash all the produce before using anyway, so a little bit of dirtiness of the bag is negligible. reply AlexandrB 23 hours agorootparentprevYes and yes. It's fabric - you just stick it in the washing machine. reply lxgr 23 hours agoparentprev> Most of the substitutes have a bigger ecological footprint Only if you insist on single-use things, in many cases. A reasonable substitute for a single-use plastic bag isn't a single-use paper bag: It's a multi-use bag. > even if you don't care at all about cost and comfort. I care a lot about comfort, which is why a single-use utensil ban can't come soon enough in the US. reply Carrok 23 hours agoparentprevThis argument is so absurd. I have reused my reusable bags more times than I can possibly count. It's really not hard or unrealistic. How does everyone else seem to have such a hard time with this? reply doug_durham 22 hours agorootparentTo pile on here. I reuse my reusable bags hundreds if not thousands of times. I purchased a set of high quality bags that stuff into a small bag. They are better in all ways than any other bags I've used. The ergonomics are excellent. reply ok123456 23 hours agoparentprevSubstitutes like reusing shipping boxes like they do at Costco? reply beefnugs 23 hours agoprevWhat a load of shit, paper straws cant even get through a single drink. Come up with some kind of useful alternative before just doing random reactionary dumb things reply bsza 23 hours agoparentStraws are a negligible [0] part of plastic waste, and the idea they aren't stems from research by a 9-year-old child [1]. We don't have to replace all single-use plastic, just those that matter. [0] https://www.nationalgeographic.com/environment/article/news-... [1] https://www.nytimes.com/2018/07/19/business/plastic-straws-b... reply eitally 23 hours agoparentprevYou know what's the worst -- paper boba straws, especially for kids. reply watermelon0 23 hours agoparentprevReusable metal straws do exist. They don't solve the problem for takeaway, but I assume straws are the least to worry there. reply contingencies 23 hours agoprevThe FMCG companies will oppose it and have deep pockets. I have spent nearly ten years developing robotics to bring complex food production to the edge so that perishable logistics can occur instead of distributing non-fresh products in single use plastics. When consumers shift to better product, change will occur. reply Am4TIfIsER0ppos 23 hours agoprevFuck that. Journalists had to go to the far east to film plastic laden rivers in order to shape public opinion. It isn't our problem. Now if you're going to accuse us of just exporting our waste then that might be true. In that case we should stop the recycling scam and just burn it like we do with all other oil. reply Culonavirus 23 hours agoprev> World Wildlife Fund and Greenpeace Ah yes, the open-minded beacons of impartiality. Next ask college lefties about rivers and seas. Ahem. reply HL33tibCe7 23 hours agoprevSure, until they realise how much this would cost, then you’ll rather quickly see that number go down reply Rucadi 23 hours agoprevThe only exception is people that know the consequences on their every-day life. reply winrid 23 hours agoparentyou mean like how we used to live? like when we used mostly glass and paper? reply AlexandrB 23 hours agorootparentAnd metal! reply OtomotO 23 hours agoparentprevI know them and am pro a ban... So: ex falso quodlibet reply colordrops 23 hours agoparentprevWhat makes you say that? I support a ban and I totally understand that it will involve some pain until we adjust. Why would you believe others don't understand this? reply Rucadi 23 hours agorootparentPeople are already in power to ban single-use plastic, they can buy stuff that is more expensive or less convenient to get. This gives a signal to the market that if a lot of people does it, they should move in that direction to meet the demand. However, this is not what it's happening, and that's because people appreciate that something is cheaper thanks to single-use plastic of because they are not so interested in single-use plastic that they are willing to do an effort to go around it. Basically, what people reveal when in the everyday use is that they are fine with single-use plastic, and if they say otherwise is to signal some kind of virtue because they decide not to put effort into it. reply mjamesaustin 23 hours agorootparentPeople bought lead paint and asbestos in droves too before those were banned. Just because something is cheap and accessible doesn't mean people understand how it impacts their lives. With studies coming out routinely showing the dramatic damage microplastics are causing to our environment and even inside our own bodies, it's only a matter of time before we come to our senses and stop it. reply kragen 23 hours agorootparentthose studies mostly show the dramatic presence of microplastics rather than dramatic damage, which is still mostly speculative. most of the microplastics inside our own bodies come from washing synthetic clothes rather than from single-use plastics reply SllX 23 hours agoprev [–] I’m someone that wouldn’t mind seeing single use plastics go the way of the dodo bird but 1) you should never trust issue polling even within a single country and 2) given that, I would trust it even less when the polling is “global”. reply ganzuul 23 hours agoparent [–] I see these studies as a first step in a Bayesian inference. Trust comes with more evidence but you have to start somewhere. Edit: Actually this is the third step. From the source: https://www.ipsos.com/sites/default/files/ct/news/documents/... reply SllX 23 hours agorootparent [–] Let me clarify: you cannot make useful judgements on the basis of an issue poll alone. The information they obscure is just as important as the information they purport to present. This is why we have legislators who in their offices actually investigate and discuss issues of lawmaking with their base, and can even contextualize it within a framework of privileged or classified information they may have access to rather than take an issue poll at face value that says “most ofsupport X on issue Y” and simply vote that way. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A World Wildlife Fund survey shows 85% global support for banning single-use plastics, but critics question its reliability due to low response rates and potential biases.",
      "The debate highlights the complexity of defining \"unnecessary\" plastics, economic trade-offs, and the challenges in creating unbiased surveys, with critics noting that poorer regions prioritize practical needs over environmental concerns.",
      "The discussion includes the effectiveness of plastic bans versus improved waste management, the environmental impact of reusable versus disposable containers, and the practicality of alternatives like reusable bags and containers, advocating for thorough legislative investigation."
    ],
    "points": 176,
    "commentCount": 247,
    "retryCount": 0,
    "time": 1717614276
  },
  {
    "id": 40591582,
    "title": "FBI Raids Atlanta Landlord in Expanding Rental Price Fixing Probe",
    "originLink": "https://www.ajc.com/news/atlanta-news/fbi-raids-atlanta-corporate-landlord-with-ties-to-realpage/PT65C57YUFF2JGB7TRVRC7IFLE/",
    "originBody": "The federal government’s antitrust investigation into price fixing in the rental market appears to have found a fulcrum in Atlanta after a surprise FBI raid of multifamily property developer Cortland Management. The May 22 search comes as the Biden administration’s Justice Department has reportedly deepened its price-fixing probe into Texas-based tech company RealPage over its rental pricing software and whether it colluded with landlords to raise rents. In a statement to The Atlanta Journal-Constitution, Cortland Management said that the FBI had executed a limited search warrant at the company’s Atlanta office as part of the Justice Department’s investigation “into potential antitrust violations in the multifamily housing industry.” “We are cooperating fully with that investigation, and we understand that neither Cortland nor any of our employees are ‘targets’ of that investigation. Due to the ongoing litigation, we cannot comment further at this time,” the company said in the emailed statement. The Justice Department’s Antitrust Division declined to comment. LexisNexis’s MLex, an industry publication covering regulatory and antitrust matters, first reported news of the search last week. Founded in 2005 in Atlanta, Cortland owns tens of thousands of units and manages apartment complexes across the US, with offices in Charlotte, Dallas, Denver, Greenwich, Houston, Orlando, and Phoenix, according to information on its website. It also operates a management and development platform in the UK. Cortland is one of several corporate landlords facing civil litigation for their alleged role in a purported nationwide conspiracy to fix and inflate rental prices for multifamily homes. A 2022 ProPublica investigation into how RealPage’s technology could be artificially inflating rents sparked dozens of class action lawsuits across the country. The government opened an antitrust investigation into RealPage in November 2022. In March, Politico reported that the DOJ had opened a criminal investigation. The news outlet relied on four unnamed sources with knowledge of the matter. RealPage spokeswoman Jennifer Bowcock declined to comment on the search of Cortland’s office. She said the company is cooperating with government authorities but that the civil claims against the company are meritless and the company’s tech “is purposely built to be legally compliant.” “Our revenue management solutions use proven and accurate data to find fair pricing for both residents and property managers,” Bowcock wrote in an email. The civil litigation centers on how RealPage’s tech taps into a database of rental prices and makes recommendation to landlords on what they should charge their tenants. With an emphasis on outsourcing pricing decisions to RealPage’s algorithm, the knock-on effect for American consumers are ballooning rents, according to a federal class action lawsuit in Nashville, Tennessee, which consolidated the complaints. In court documents filed this past September, tenants said there are about 484,000 multifamily rental units in the Atlanta, Sandy Springs and Alpharetta markets. More than 53% of owners, managers and owner-operators used RealPage’s software in those markets, including Cortland and the property management company Pinnacle, according to the complaint. “Widespread adoption of defendant RealPage’s (revenue management software) has caused rent to increase explosively in recent years, with Atlanta renters paying approximately 56% more in rent today than they paid in 2016,” the 302-page document states. The complaint accuses trade associations Atlanta Apartment Association, Georgia Apartment Association, and Southeast Regional Advisory Council for Apartment Life as “acting as conduits for the cartel.” Bowcock said allegations about “the number of rental units associated with properties that use RealPage’s revenue management software are false.” In November, the Justice Department’s Antitrust Division filed a statement of interest in the case. With housing prices and rents besetting U.S. households, housing policy has become one of President Joseph Biden’s priorities as he seeks reelection. In his State of the Union address in March, he dedicated part of his speech to corporate landlords. “For millions of renters, we’re cracking down on big landlords who use antitrust laws — who break antitrust laws by price-fixing and driving up rents,” he said. About the Author Matt Reynolds Matt Reynolds is a housing reporter for The Atlanta Journal-Constitution's local government team. Editors' Picks Credit: Courtesy Rivian Rivian launches second generation of its flagship EV models2h ago Morehouse president reflects on Biden’s visit: ‘It made us stronger’ 1h ago Credit: Miguel Martinez LISTEN Atlanta Mayor Dickens: Water breaks ‘not my fault but it is my problem’ 46m ago Credit: Chris Pizzello/Invision/AP GUEST COLUMN Tyler Perry: Flying while Black shouldn’t be a crime Credit: Chris Pizzello/Invision/AP GUEST COLUMN Tyler Perry: Flying while Black shouldn’t be a crime Credit: John Spink Man arrested in deadly shooting at Buckhead nightclub 1h ago The Latest Credit: Miguel Martinez LISTEN Atlanta Mayor Dickens: Water breaks ‘not my fault but it is my problem’ 46m ago Challengers unite to unseat Natalie Hall in Fulton commission runoff 2h ago Clayton County Sheriff’s Office requests additional funding Featured Credit: Charles Nixon Why people are leaving their Black Greek organizations EXCLUSIVE Ossoff, Warnock secure funds preserving John Lewis’ congressional papers 15 things to do this weekend: Atlanta Fringe, Gwinnett Pride and more",
    "commentLink": "https://news.ycombinator.com/item?id=40591582",
    "commentBody": "[dupe] FBI raids Atlanta corporate landlord in probe of rental market price fixing (ajc.com)168 points by heavyset_go 20 hours agohidepastfavorite4 comments gnabgib 19 hours agoDiscussion [0] (62 points, 21 hours ago, 78 comments) [0]: https://news.ycombinator.com/item?id=40580874 reply dang 13 hours agoparentAlthough it's probably the worst article of the three, that one is at least available for people to read, while the ajc.com (i.e. the OP) and thebignewsletter.com (i.e. https://news.ycombinator.com/item?id=40562834) submissions are not. So I guess we'll merge the comments thither and re-up that one. Thanks! (I've copied over the title of this one too, since it seems clearer) reply bell-cot 18 hours agoparentprevAnd further back (2 days ago, 235 points, 234 comments) https://news.ycombinator.com/item?id=40562834 reply user3939382 8 hours agoprev [–] My private theory is that white collar crime in the US is fine so long as you have over $500M and play ball with the right people. Where you see enforcement is when at least one of those rules aren’t followed. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The federal government’s antitrust investigation into rental market price fixing has intensified, with a recent FBI raid on Cortland Management in Atlanta.",
      "The probe focuses on Texas-based RealPage, whose rental pricing software is suspected of colluding with landlords to inflate rents, and has expanded to include criminal inquiries.",
      "This case, highlighting significant rent increases in Atlanta, has become a priority for President Biden, who aims to address corporate landlord practices in his reelection campaign."
    ],
    "commentSummary": [
      "The FBI raided an Atlanta corporate landlord as part of an investigation into potential rental market price fixing.",
      "The original article is not accessible, but discussions on Hacker News suggest that white-collar crime in the U.S. often goes unpunished if the perpetrators have significant financial resources and connections.",
      "This event has sparked interest due to the involvement of the FBI and the implications of price fixing in the rental market."
    ],
    "points": 168,
    "commentCount": 4,
    "retryCount": 0,
    "time": 1717628105
  },
  {
    "id": 40596689,
    "title": "AeroSpace: i3-Inspired Tiling Window Manager for macOS Now in Public Beta",
    "originLink": "https://github.com/nikitabobko/AeroSpace",
    "originBody": "AeroSpace Beta AeroSpace is an i3-like tiling window manager for macOS YouTube Demo AeroSpace Guide AeroSpace Commands AeroSpace Config Examples AeroSpace Goodness Project status Public Beta. Feedback is very much welcome I encourage you to try AeroSpace and file GitHub issues if something doesn't work for you I already use AeroSpace on daily basis and I'm happy with it The documentation covers all major things you need to know Key features Manual tiling window manager based on a tree paradigm i3 inspired AeroSpace employs its own emulation of virtual workspaces instead of relying on native macOS Spaces due to their considerable limitations Plain text configuration (dotfiles friendly). See: default-config.toml CLI scriptable Doesn't require disabling SIP (System Integrity Protection) Proper multi-monitor support (i3-like paradigm) Status menu icon displays current workspace name Installation Install via Homebrew to get autoupdates (Preferred) brew install --cask nikitabobko/tap/aerospace Manual installation Note By using AeroSpace, you acknowledge that it's not notarized. Notarization is a \"security\" feature by Apple. You send binaries to Apple, and they either approve the binaries or not. In reality, notarization is about building binaries the way Apple likes it. Let's be honest. Tiling window manager is not something Apple will be totally ok with. Even if they approve one version, it doesn't mean that they won't revoke it (yes, they can do it), or approve further versions. I don't have anything against notarization as a concept. I specifically don't like the way Apple does notarization. I don't have time to fight Apple. Homebrew installation script is configured to automatically delete com.apple.quarantine attribute, that's why the app should work out of the box, without any warnings that \"Apple cannot check AeroSpace for malicious software\" Contributing, creating issues, submitting pull requests See: CONTRIBUTING.md Development A notes on how to setup the project, build it, how to run the tests, etc. can be found here: dev-docs/development.md Values of the project Values AeroSpace is targeted at advanced users and developers Keyboard centric Breaking changes (configuration files, CLI, behavior) are avoided as much as possible, but it must not let the software stagnate. Thus breaking changes can happen, but with careful considerations and helpful message. Semver major version is bumped in case of a breaking change (It's all guaranteed once AeroSpace reaches 1.0 version, until then breaking changes just happen) AeroSpace doesn't use GUI, unless necessarily AeroSpace will never provide a GUI for configuration. For advanced users, it's easier to edit a configuration file in text editor rather than navigating through checkboxes in GUI. Status menu icon is ok, because visual feedback is needed Provide practical features. Fancy appearance features are not practical (e.g. window borders, transparency, etc) If \"dark magic\" (aka \"private APIs\", \"code injections\", etc) can be avoided, it must be avoided Right now, AeroSpace uses only a single private API to get window ID of accessibility object _AXUIElementGetWindow. Everything else is macOS public accessibility API. AeroSpace will never require you to disable SIP (System Integrity Protection). For example, yabai requires you to disable SIP to use some of its features. AeroSpace will either find another way (such as emulation of workspaces) or will not implement this feature at all (window transparency and window shadowing are not practical features) Non Values Play nicely with existing macOS features. If limitations are imposed then AeroSpace won't play nicely with existing macOS features E.g. AeroSpace doesn't acknowledge the existence of macOS Spaces, and it uses emulation of its own workspaces Tip of the day defaults write -g NSWindowShouldDragOnGesture YES Now, you can move windows by holding ctrl+cmd and dragging any part of the window (not necessarily the window title) Source: reddit Related projects Amethyst yabai",
    "commentLink": "https://news.ycombinator.com/item?id=40596689",
    "commentBody": "AeroSpace is an i3-like tiling window manager for macOS (github.com/nikitabobko)163 points by loughnane 6 hours agohidepastfavorite83 comments idle_zealot 1 hour agoI daily drive this and my verdict is: it's the best way to manage windows on a Mac, but falls short of i3/sway. In particular, support for re-arranging windows by dragging them to positions relative to one another is extremely limited in that it's not able to create new vertical or horizontal splits the way you can in sway, which forces me to take awkward detours with keyboard commands to get to the window layout I want most of the time. Like, say I have two windows side-by-side, and I want to split one of them vertically. In sway I'd pop open the new window, then drag it to the top or bottom half of the window I want it to share horizontal space with, and bam, all done. With aerospace the best way I've found to do this is to open the new window, then switch all three windows into a vertical stack, then focus the window that was originally on the left and invoke the 'move left' command on it. reply nbobko 1 hour agoparentIf you have normalizations enabled, you don't need to \"switch into a vertical stack\" Given this layout: h_tiles ├── window1 (focused) ├── window2 └── window3 `move left` will produce this layout: h_tiles ├── window1 (focused) └── v_tiles ├── window2 └── window3 reply idle_zealot 1 hour agorootparentAh, so it does. I suppose this is an instance of my mental model not having adjusted. reply j45 57 minutes agoparentprevThanks, I will try it out to see if it can first solve my main problem - I'm looking for a way on Mac for it to reasonably remember the screen layouts. Every time it wakes from boots, the desktop has complete amnesia with 3 screens. Ideally I'd be able to drive my own workspaces, and it can use the laptop screen only, or 2 or 3 external monitors at different desks (work and home). reply tln 2 minutes agorootparentI've resorted to running a shell script every time I plug in. displayplacer \"id:... res:2048x1330 hz:120 color_depth:8 enabled:true scaling:off origin:(0,0) degree:0\" \"id:... res:3840x2160 hz:30 color_depth:8 enabled:true scaling:off origin:(-918,-2160) degree:0\" displayplacer is very easy to set up and also gives you access to modes that you can't access with System Preferences. reply iyn 4 hours agoprev> Doesn't require disabling SIP That's very interesting! I've been hesitant to use similar WMs as basically all required disabling SIP. Anyone knows what AeroSpace is doing differently that it can work alongside SIP? Edit: found this in the README: > AeroSpace will never require you to disable SIP (System Integrity Protection). For example, yabai requires you to disable SIP to use some of its features. AeroSpace will either find another way (such as emulation of workspaces) or will not implement this feature at all (window transparency and window shadowing are not practical features) reply TachyonicBytes 3 hours agoparentI wonder if following the mouse for focus would be doable without disabling SIP. It's one of the features I didn't even see in other macOS WM. reply feep 3 hours agorootparentIt is, Yabai can do it. I am currently using autoraise. Both work great, barring UI weirdness of macOS. Example. Mousing over another window on the way to the menubar. https://github.com/sbmpost/AutoRaise reply bashinator 3 hours agorootparentprevI've been searching for a sloppy-mouse-focus implementation for OSX for _years_. Pretty sure there's something fundamentally incompatible in how app windows are managed. reply lelandfe 2 hours agorootparentIt's also a bummer because Terminal.app has the functionality out of the box: https://macos-defaults.com/mouse/focusfollowsmouse.html reply bashinator 10 minutes agorootparentIt can be implemented within apps, but not across apps afaict. reply speedgoose 1 hour agorootparentprevLooks like Hammerspoon and some lua should do: https://www.hammerspoon.org/docs/hs.mouse.html https://www.hammerspoon.org/docs/hs.window.html reply JZL003 3 hours agoprevI use yabai pretty heavily, for the past 5 macos versions without disabling SIP on a work computer. I really like it, the tiling is flaky only maybe once every few days (I am doing yabai commands probably once a minute at least) so I bound a keystroke to `yabai --restart-service` and it always comes back immediately So I find it really pretty reliable and pretty great. Multimonitor is hard and I don't use it much, but having stacks and fast 'full-screen' to minimize is so great On some version upgrades, work antivirus thinks it's a virus so disables it for 24 hours, and I hate using my computer those days, it feels so clunky and sad reply feep 4 hours agoprevOh, I like the fake Spaces approach. I have considered trying that by minimizing windows, but would never get around to it. Tiling is doomed to sadness on macOS, because of lack of APIs. But this is probably the most performant approach. Have used yabai, but only for moving windows and focus-follows-mouse. Not for tiling. Because flaky (not yabai’s fault). Thanks nikitabobko. Looking forward to trying it as soon as I figure out how to mod alt-tab to ignore all the windows (from every fake workspace) in the corner. Also, linked in the docs, JankyBorders. Nice. https://github.com/koekeishiya/yabai https://github.com/lwouis/alt-tab-macos https://github.com/FelixKratz/JankyBorders reply freeqaz 3 hours agoparentI get around that by using the Stack and I flip between windows with alt+h/alt+j Command+Tab is global window switch. The ones above are for \"local\" switching in the context of the workspace. reply feep 2 hours agorootparentOh, I know. I use sway — and greatly miss alt-tab (windows-style alt-tab), when I do. Not linux-primary right now. I can remember my linux-style stacking commands in order to try it. But I would want to fix my alt-tab at some point. Note: my sway (or mac) usage is basically two vertical windows or stacks of panes on a laptop screen. So a pretty simple setup. reply irth 54 minutes agorootparentyou can get windows-style alt-tab with https://alt-tab-macos.netlify.app/ reply feep 46 minutes agorootparentRight. Got it, love it. But it won’t work with AeroSpace. I mean, it will work, but it won’t work with all windows from _visible spaces_. Because ever window from _every space_ will be in the current space (tucked in the lower right corner). reply jitl 3 hours agoprevWhat is the difference in user experience between this and Yabai? I don’t think the SIP issues for Yabai is a big one, no one I know who uses Yabai disables SIP, and they seem to enjoy it. Is the i3 stuff the difference? Personally I use a utility that allows resizing and moving windows with the mouse from anywhere on the window when holding a modifier combination, like Fluxbox. Not as automatic, but also never flaky - more like making floating much easier with less mouse movement than moving to a totally managed style. reply freeqaz 3 hours agoparentI have used both extensively and I prefer AeroSpace. Multi monitor support is the killer for me, but there are other small wins. When you move a workspace in Yabai to a new monitor, it changes it's ID so you can't keep using keyboard shortcuts to access it (alt+2 breaks because it is no longer workspace 2, it becomes 11 or another number). I can move workspaces between monitors easily with alt+m and alt+shift+m. The other feature is that windows snap instantly without any Mission Control animations. That is a big one that really irks me. Those are the two features that I need most days and I find Yabai completely unusable because of the lack of workspace support reply Etheryte 2 hours agoparentprevWith Yabai you need to disable SIP if you want to interact with spaces in any way, change the stacking order of windows, and many other things [0]. If you don't use those features, you do you, but for many users those are core features. [0] https://github.com/koekeishiya/yabai/wiki/Disabling-System-I... reply maherbeg 3 hours agoprevI'd be curious to know how it is different than Amethyst. Amethyst has gotten much more stable recently and I really enjoy using it. The text based config seems pretty nice at a first glance, but I'm not sure if it's worth switching. reply Avi-D-coder 2 hours agoparentin my experience aerospace is way better in most ways. there are a few oddities, and I need to file a couple of bug reports, but it has made macos so much more tolerable than amethyst. reply better_sh 3 hours agoprevThis is great! I find the one thing I miss the most from i3 that none of the macOS tiling managers seem to have is i3bar, or a minimal bar that displays what space I'm on, how many spaces I have, cpu/ram usage, etc. I've tried to find configs that emulate this with Spacebar [0], but haven't been able to find anything [0] https://github.com/cmacrae/spacebar reply cweagans 28 minutes agoparentYou can likely do this with Hammerspoon. It should be pretty straightforward as long as you have somewhere you can get the name/id of the space that you're on. reply dorian-graph 3 hours agoparentprevHave you tried https://github.com/FelixKratz/SketchyBar? reply tra3 3 hours agoparentprevSketchybar has this. reply jaimehrubiks 51 minutes agoprevIs there any documentation for very beginners on how a regular workflow would be? Like, if I have 7 windows opened, how do I start organizing them with just shortkeys? I've found option+/ to put all of them horizontally or vertically (alternating when pressing twice), but not sure how to quickly make 1 of them bigger or select just 2. reply anonzzzies 4 hours agoprevI have been trying this for a few months now. I3 is quite perfect and Aerospace is a nice try, but it’s very far from i3; it’s quite flaky. I guess this is because Mac OS X doesn’t actually allow full control like Unix WMs do? I have not found anything better though, but I will install Linux when it’s working well on Apple Silicon. Only i3 is at least for me enough reason to use Linux as Mac OS X, again imho, is terrible window manager wise. reply jwells89 3 hours agoparentHaving dabbled in some of this for a hobby project (not a window manager, but adjacent), it’s because the official APIs to do these things with are limited. You end up relying a lot on undocumented private APIs and hacks, which are flaky both due to their undocumented internal-use nature and because the OS isn’t designed to play nice with significant meddling with window/process management, which results in the OS and third party app frequently stepping on each others’ toes. reply behnamoh 3 hours agorootparentApple being Apple... gosh they just know how to build hardware but for software they just flop. reply jwells89 3 hours agorootparentIn fairness, I’ve encountered similar flakiness when using third party window/desktop manager utilities on Windows. Commercial OSes in general just aren’t designed with that kind of flexibility in mind. reply whartung 2 hours agoprevFor folks that use the tiling window managers, what applications are you running? And what does a typical desktop look like? In terms of desktop layout, mind I don't use one, the Oberon vision comes to mind. A single, large pane, with all(?) of the others stacked to one side. My friend didn't use a tiling window manager, but had this desktop laid out as such, but all of those windows were terminal windows that he kept an eye on (he was our ops guy). But are folks using these layouts with their web browsers, word processors, IDEs, etc.? reply FranOntanaya 2 hours agoparentI use an ultra wide screen and do both coding and video operations so I'm always having side by side layouts mixed in with tabbed windows. One typical case is navigating a file manager to grab files that I need to drag and drop on a web UI, or folder/URI slug names I need to keep copying back and forth to use on a workflow. Another is watching stdout/stderr of a running script and a log tail at the same time. Sometimes I have tabs of web, file manager and some other app on one side and a terminal on the other as terminal commands are the glue of a workflow. Or I'll be screening a video on the left and doing edits on the right. Or keeping notes open on the side during a conference call. Sometimes I'll only have one window in a virtual desktop and ultrawide is too much, so I just have an idle terminal window as padding. Not having to hunt around for windows then hunting for their edges helps when I'm constantly opening, closing and sizing terminals, file managers and so on and so forth. It simply is faster with tiles. reply whartung 1 hour agorootparentThis will sound silly, but doesn't that hurt your neck? You mention you use a ultra wide screen. I have one of the \"drive in theater\" iMacs, and I prefer the windows in the center. It's big enough that if things were on either side, I'd have to crane my neck to focus on either side. I'd hate to have to do that all the time. I guess if I were to do anything \"tile\" wize it would be two smaller columns, one on the left, and one on the right, and then the big center as the main focus. reply gpxyz 1 hour agoparentprevI don’t work in programming, but in arts and academia. I usually have 1 “main” window in working in and at least 1-2 more I am continually referring to, so I like to be able to quickly switch between a single fullscreen window and a 2 column view. Typical workspaces for me are Zotero + Firefox + Word (for writing and research) and Photoshop/InDesign + Finder + Firefox (for design). When I do code, I like being able to have at least 1 terminal window side-by-side with a coding LLM. I usually also have a workspace with Spotify + MacPass + Telegram open that I refer to as needed. reply bsnnkv 3 hours agoprevNice to see another twm on macOS. Somehow over the past few years Windows became the more vibrant platform for twms (vs macOS) with developers (including myself) trying to push the envelope and introduce many quality of life features you still won't find even in Linux twms today. https://github.com/LGUG2Z/komorebi https://github.com/glzr-io/glazewm https://github.com/dalyIsaac/Whim Hopefully this new entrant will drive even more innovation in this space on macOS. reply ashenke 3 hours agoparentI'm curious, what kind of features that are not found on Linux ? reply Carrok 3 hours agorootparentFor one, tools like Shortcat aren’t really possible on Linux afaict, since it relies on MacOS’s fantastic accessibility API. https://shortcat.app/ reply ssivark 2 hours agorootparentHmm -- interesting/fantastic tool. Feels something like avy in Emacs, but for everything on screen. I think this should be possible in linux with a bit of work (erm, famous last words?) especially because the whole desktop environment is fundamentally open and you don't need to depend on this providing an API. But I think an even better approach is to have build this functionality using screen parsers backed by recent AI advances. That way, you decouple the source / rendering of content from the sink / consumption of content, and can have more flexible behavior on behalf of the end user. I anticipate (hope) such tools to pop up over the next few years. reply bsnnkv 1 hour agorootparentprevThe biggest QOL improvements imo are found in the approach to the user-facing API design. Compare basic multi-monitor commands in something like bspwm[1] or yabai[2][3] to twms on Windows where this is typically handled transparently by directional `move` and `focus` commands understanding monitor boundaries. Besides this, Whim has implemented a very functional ctrl+p style command palette which provides a great interface for more advanced on-the-fly/one-time window manager interactions. With komorebi I think that having different border colours to indicate different types of containers is very helpful (one colour for single window stacks, a different colour for monocle containers, a different colour for stacks with multiple windows), as well as custom window-based work area offsets[4] (so if you have an ultrawide monitor with only a single window on a workspace, you can add offsets to the sides so it doesn't stretch across the whole width and give poor usability). It's not really any one \"big thing\" but rather a difference in approach which adds up over many small design decisions. [1]: https://github.com/baskerville/bspwm/issues/563 [2]: https://github.com/koekeishiya/yabai/issues/505 [3]: from my own personal yabai config - imo this is not really acceptable for a user facing API, especially for basic commands like focusing and moving: ``` # focus window alt - h : yabai -m window --focus west || yabai -m display --focus west alt - j : yabai -m window --focus south || yabai -m display --focus south alt - k : yabai -m window --focus north || yabai -m display --focus north alt - l : yabai -m window --focus east || yabai -m display --focus east # swap window alt + shift - h : yabai -m window --swap west || yabai -m window --display west && yabai -m display --focus west alt + shift - j : yabai -m window --swap south || yabai -m window --display south && yabai -m display --focus south alt + shift - k : yabai -m window --swap north || yabai -m window --display north && yabai -m display --focus north alt + shift - l : yabai -m window --swap east || yabai -m window --display east && yabai -m display --focus east ``` [4]: https://hachyderm.io/@LGUG2Z/112493589633823318 reply FranOntanaya 2 hours agorootparentprevClicklock is much nicer in Windows than the awkward methods I've found so far with Linux. reply bbor 3 hours agoparentprevNot to drop this kind hacker’s competitor, but I’ve been a happy user of https://rectangleapp.com/. Will definitely be checking this out instead tho, even though I’ve paid for rectangle — any demo that has SublimeText windows in it is a demo I trust! reply ftio 1 hour agoprevCool YouTube video, but: my kingdom for a screenshot! Product looks amazing. I use Divvy but will definitely try out AeroSpace. Great name too. reply andrewla 4 hours agoprevI'm reluctant to try this -- my experience with other attempts to try out tiling window managers on MacOS is that the just don't play nice. Windows get repositioned by normal interactions and the window manager is not able to wrangle them, and connecting external monitors is a disaster, and you end up with a situation where windows are overlapping in odd ways but you can't move them out of the way because the window manager is trying to manage them. Does anyone have experience with this particular one and does it resolve these sorts of issues? reply nbobko 2 hours agoparentHi, AeroSpace author speaking :) > Windows get repositioned by normal interactions and the window manager is not able to wrangle them I'm certainly biased, but no, I don't face issues like that > and connecting external monitors is a disaster Connecting and disconnecting external monitors is an important use case for me as well. I dedicated my time to support specifically this case, so hopefully it works correctly for other users as well reply mrgaro 1 hour agorootparentI'm a long time Amethyst user, but going to try AeroSpace out! Based on the documentation the toml syntax is stretched quite a bit to implement some logic and callbacks. Have you considered some scripting language to make it easier to do, or is the need for this kind of advanced use so little that it's not really a problem? reply nbobko 28 minutes agorootparentWhen I started the project, I kept it simple, so I started with the static config The complexity of the config has grown since then, with the bigest (and, actually, the only) problem being on-window-detected callback as you mentioned. I've been thinking about using a scripting language like Lua, but I haven't made my mind yet whether it's worth it reply torstenvl 3 hours agoparentprevI've never ever had that happen with Rectangle or Magnet. reply jackhalford 1 hour agoprevI’m currently in using sway on fedora, I’m considering moving to macOS because of tighter integration of icloud (everything is on my iphone) and generally better polish of the OS. This is another reason to switch reply meter 3 hours agoprevI’ve been using this for the past few months, and for the most part, I like it. I appreciate that it’s all configured with a single file (no GUI). One issue: If an app uses native Mac tabs, Aerospace treats each tab as a window, which completely breaks the full screen functionality. Alacritty is one example. It’s really odd. Edit: there’s an open issue for this: https://github.com/nikitabobko/AeroSpace/issues/68 reply laweijfmvo 3 hours agoprev> Homebrew installation script is configured to automatically delete com.apple.quarantine attribute, that's why the app should work out of the box, without any warnings that \"Apple cannot check AeroSpace for malicious software\" Can someone ELI5 what this does? Does it impact AeroSpace only, or something globally on my Mac? Thanks! reply Vegenoid 2 hours agoparentWithout looking into the installation script to verify, based on that description, it is only deleting an 'extended attribute' of the AeroSpace app. MacOS adds this attribute automatically to programs downloaded from the web, and prevents a user from running the program while it has the attribute. I frequently need to run a command like the following before running a downloaded program, which I'm guessing is exactly what the install script does: xattr -d com.apple.quarantine some-program.app reply baliex 2 hours agoparentprevIt only affects AeroSpace. The README links to the Homebrew install script, relevant lines highlighted here: https://github.com/nikitabobko/homebrew-tap/blob/main/Casks/... reply nbobko 3 hours agoparentprevIt impacts only AeroSpace reply nocsi 4 hours agoprevI’ve just started using [1Piece](https://app1piece.com/). Before this, I had BetterTouchTools just to mimick the window snapping. And years prior to that, I’d run a full dwm setup on Linux. The thing to understand however… is that these sort of things are a losing battle on macOS. Stuff like yabai/skhd break in between OS updates. Window management and apple is a battle you can always expect to lsoe reply gray_-_wolf 4 hours agoprevI will be getting my first mac soon (I am still sad about it), which means I will need to figure out the WM. Currently I am considering yabai and amethyst. I guess now I should add AeroSpace to the list. If you are actually using tiling WM on mac, could you share which one and why? reply andrewla 4 hours agoparentFor what it's worth, I don't think there's a lot of value in these. I hate the MacOS environment as much as anyone, but all the attempts to create tiling managers have resulted in strange unusable quirky behavior. You're better off just sucking it up and using the native UI until you get sufficiently familiar with it that it rarely gets in your way too much. Meanwhile keep lobbying your employer (assuming that you are being forced into this by your job) to support Linux for development workstations. reply happymellon 3 hours agorootparentCompletely agree with this take. No matter how sophisticated these Mac Window Managers get, MacOS will always mess with the windows because it knows better than you. That's why people buy Macs, and it's not going to change. If you don't like this, then you actually don't like Macs. It's opinionated, and it's opinions do not match yours. I would have liked window snapping, but instead we have 1/2 baked split screen virtual desktops. I simply don't understand why people use them for development environments, the \"Unix underneath\" doesn't help enough in enough scenarios when it's hostile in so many others. reply jwells89 3 hours agorootparent> I would have liked window snapping, but instead we have 1/2 baked split screen virtual desktops. There’s at least non-fullscreen tiling available now if you hold down Option/Alt when hovering over the green traffic light (which also changes the corresponding Window menu items to “Move Window to (Left|Right) Side of Screen). There should probably be a toggle somewhere that makes this the default. > I simply don't understand why people use them for development environments, the \"Unix underneath\" doesn't help enough in enough scenarios when it's hostile in so many others. A lot of it is that the hardware is well-rounded and not as riddled with gambles/compromises as most other laptops are. Usually non-Apple laptops have at least one or two things that suck about them, with the most frequent being battery life, fan noise, and poor thermal design but include mediocre screen, bad keyboard, bad trackpad, bad power management, bad unplugged performance, bad port placement, and chintzy build among other things. Some percentage of users also just like macOS as it is, though. reply vidarh 3 hours agorootparentprevFully agree with this. Used Yabai at first last time I was forced to use a Mac. Hated it with a passion. It was \"close\", but not close enough, and so I felt I was fighting it all the time. Ended up running most applications full-screen instead, and relying on tiling in iTerm2 or the applications most of the time instead. It helped that I was connected to a second monitor most of the time. reply Cu3PO42 3 hours agoparentprevOut of all of these, I've only tried Yabai. It's fine. Things mostly work like I expect them to and I rarely encounter a situation that isn't fixed by restarting Yabai. That said, I'm hardly a power user. I have not disabled SIP and instead simulate features that would require it as best as possible through other means. E.g. workspaces can be switched by dispatching a key combination that is handled by macOS natively. You can check out my configs here [0] if you are so inclined, but it's not super polished. [0] https://github.com/Cu3PO42/gleaming-glacier/tree/next reply bee_rider 2 hours agoparentprevI wonder… this isn’t what you want, but maybe just tmux in a full screen, or half-screen terminal (if you need a web browser) would suffice? Plus their built in “spaces” (workspaces) feature. reply torstenvl 3 hours agoparentprevIt isn't i3-like, more window snapping than fractal tiling, but I really like Rectangle. I used Magnet previously and also liked it. reply wizhi 3 hours agoparentprevI've been there, being forced to use it for work.. I tried both Yabai and Amethyst and, frankly, neither provide a clean experience. Yabai requires disabling some OS security feature iirc, which may or may not be an issue for you. I seem to recall having issues with it, and switching to Amethyst pretty soon after. It might also only support BSP layout, which I dislike - stacks all the way. Amethyst feels a little half baked. It works well enough, but configuration is through a GUI and saved in some non text format, making it not difficult friendly. It also doesn't support things like moving windows between workspaces, meaning you need to have additional bindings for that through the MacOS command center or whatever it's called. Overall, I managed with Amethyst for close to 2 years, so that's the one I'd recommend of the two. Luckily I'm back on a Linux machine and can use river now. :) Good luck! reply happymellon 3 hours agorootparent> It also doesn't support things like moving windows between workspaces It's been a while since I used Amethyst as the Mac is now on complete corporate lockdown, but I remember that being the biggest feature I used on Amethyst. MacOS doesn't support it, but Amethyst did. reply wizhi 1 hour agorootparentI am likely misremembering, and mixing it was something else! There definitely was something vital I wasn't able to do through just Amethyst though. reply tanelso217 3 hours agorootparentprevI lost my Amethyst due to corporate lockdown rebuild a few weeks ago. MacOS window management is obnoxious without it and I'm much less productive due to losing my tools. reply namdnay 3 hours agoparentprevI'm not an expert, but isn't Rectangle the simplest and easiest way to manage this? I love it reply malkosta 3 hours agoprevFinally…the day has come…this look awesome!!! Loved the values. reply selimnairb 4 hours agoprevCan we stop pissing and moaning about notarization? macOS isn’t Linux and this isn’t 1994. Given the cybersecurity threats of the world today, signing by a central authority makes some amount of sense for apps on consumer OSes. reply nbobko 8 minutes agoparentI agree that signing by a central authority makes sense. As the readme mentions, I don't have anything against notarization as a concept. I specifically don't like how painfull Apple does it. (Google for \"notarization hell macos\") This is my pet project that I do for fun and for free. Bowing my head to Apple every time I want to release a new version is not fun. Waking up in the middle of the night, because Apple revoked the app (https://github.com/nikitabobko/AeroSpace/issues/167) is not fun. AeroSpace is a tool for developers by developers. Developers can audit the code and install the app from sources reply lxgr 3 hours agoparentprevAs long as Apple's glorious code signing scheme can still easily tricked by a single xattr call [1], I'm fine with it. I've just got a feeling that that won't be forever. [1] https://github.com/nikitabobko/homebrew-tap/blob/main/Casks/... reply felixgallo 3 hours agoparentprevWhat do you think signing does to prevent against 'the cybersecurity threats of the world today'? reply gbhdrew 1 hour agoprevJust want to say a huge thanks to the dev(s) here, you've basically solved my major pain points with macOS window management (especially around apple's infuriatingly broken implementation of virtual desktops). This stuff has been gnawing away at my sanity for years reply igorguerrero 50 minutes agoprevThis looks so awesome I gonna dust off my mac mini. As a tiling wm user (Hyprland now) I always wonder how OSX users claim they're that productive with all those alt+tabbin' I meant cmd+tabbin'. Welcome to the 2010s guys! reply randomblast 2 hours agoprevI used i3 for a few years when my main dev machine was Linux. I too am frustrated by the macOS builtin WM's shortcomings. Initial feedback on AeroSpace though: it's utter shite. I started it when I already had my usual number (many) of windows open across my usual number of spaces (lots) on my usual number of displays (3). First it spent 30 seconds trying to give me a seizure, and when it had finished I'm left with a total mess of a layout. Some windows 30px wide. Some windows not-quite-fullscreen. Some windows just randomly floating without any kind of recognisable pattern. Now I can't navigate around because dragging a window sends it flying off to the corner of a different display. None of the default keybindings seem to do what they say they should. The focussed window disappeared entirely when I tried resize mode, and I can't find the way out of it because that was the window with the instructions. I think I'll try something else. reply carabiner 2 hours agoprevMan I hate the name. Has nothing to do with aerospace, but it does seem like a fad in software to take on some stolen valor from a far more interesting field. reply nbobko 2 hours agoparent1. The \"AeroSpace\" name means a space for your windows without friction 2. I myself consider the virtual emulation of workspaces to be the strongest feature of the AeroSpace. If I could disable the workspace switching animation in yabai or Amethyst (with SIP enabled, of course), I'd probably not bother myself creating AeroSpace. That's what the \"space\" part in the app name means. It resembles the strongest feature of AeroSpace - workspaces reply darksaints 2 hours agoprev [–] Somewhat on subject: does anybody feel like the macos-style application menu that is disconnected from the application window has outlived its welcome? I feel like apple gets so much right from a UX perspective, but in a world of multi-monitor setups and common cross application workflows, I find it absolutely bizarre that I might have to scroll across 2+ monitors to get to a dropdown menu for an application that I'm using, and sometimes still get to a dropdown menu for the wrong application. reply mbreese 2 hours agoparentI like the detached menu, but mainly because it makes the application window smaller with less overall decoration. With multiple applications open, each window having menu bar decorations seems cluttered to me. I like the minimalist and consistent nature of it all. However, it does get more complicated with multiple monitors and I don’t know of the solution here. You’re right that the UX falls when you’re trying to work with menus across multiple monitors. Perhaps the right mix is doing something like the Chrome extras menu or if you’ve used VS Code on the web, where you have a small hamburger or (…) button that opens a context menu. Then you still have a menu for the application, but it’s hidden until you need it. reply lloeki 2 hours agoparentprev> in a world of multi-monitor setups and common cross application workflows, I find it absolutely bizarre that I might have to scroll across 2+ monitors to get to a dropdown menu for an application that I'm using These days the menubar is always on all displays, not just the main one? (unless maybe you have \"Displays use separate Spaces\" unchecked?) reply throwaway38375 2 hours agoparentprev [–] Yes! Windows got it right IMO. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AeroSpace is a new tiling window manager for macOS, inspired by i3, and is currently in public beta.",
      "Key features include manual tiling based on a tree paradigm, plain text configuration, CLI (Command Line Interface) scriptability, and proper multi-monitor support without needing to disable SIP (System Integrity Protection).",
      "AeroSpace uses its own virtual workspaces instead of macOS Spaces, supports installation via Homebrew for auto-updates, and emphasizes keyboard-centric use and minimal GUI (Graphical User Interface)."
    ],
    "commentSummary": [
      "The discussion highlights AeroSpace, a tiling window manager (TWM) for macOS, praised for its window management and multi-monitor support but criticized for lacking the flexibility of i3/sway and requiring keyboard commands for layout adjustments.",
      "Unlike yabai, AeroSpace does not require disabling System Integrity Protection (SIP), making it more user-friendly, though users note issues with other tools like Yabai, AutoRaise, Hammerspoon, Rectangle, and Magnet.",
      "Users discuss the challenges of implementing i3-like functionality on macOS, the benefits of ultra-wide screens, and the complexities of macOS notarization, with some suggesting alternatives like tmux or native macOS features."
    ],
    "points": 163,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1717677541
  },
  {
    "id": 40591860,
    "title": "Adobe's Photoshop ToS Sparks Privacy Concerns Over Access to User Projects",
    "originLink": "https://nichegamer.com/photoshop-terms-of-service-grants-adobe-access-to-user-projects-for-content-moderation/",
    "originBody": "Photoshop’s newest terms of service has users agree to allow Adobe access to their active projects for the purposes of “content moderation” and other various reasons. This has caused concern among professionals, as it means Adobe would have access to projects under NDA such as logos for unannounced games or other media projects. Sam Santala, the founder of Songhorn Studios noted the language of the terms on Twitter, calling out the company’s overreach. So am I reading this, right? @Adobe @Photoshop I can't use Photoshop unless I'm okay with you having full access to anything I create with it, INCLUDING NDA work? pic.twitter.com/ZYbnFCMlkE — Sam Santala (@SamSantala) June 5, 2024 Tech companies are increasingly eager to supervise and spy on their users, recently Microsoft announced an AI powered product called Recall. Recall scans the screens of users, allowing them to search their past activity in common terms. The user agreement also leaves open the possibility to train AI using user-generated content, saying they can use the content they retrieve to “improve our Services and Software“. This is Niche Gamer Tech. In this column, we regularly cover tech and things related to the tech industry. Adobe About Brandon Lyttle A basement-dwelling ogre, Brandon's a fan of indie games and slice of life anime. Has too many games and not enough time.",
    "commentLink": "https://news.ycombinator.com/item?id=40591860",
    "commentBody": "Photoshop ToS grants Adobe access to user projects for 'content moderation' (nichegamer.com)163 points by typeofhuman 19 hours agohidepastfavorite70 comments shrubble 7 hours agoI remember a number of years ago getting a cheap 1-year Lightroom susbscription as part of a promo. Got it installed, loaded up a few photos. Then went back to the directory to load the photos in a different program for comparison. The photos were deleted from my hard drive! They were loaded into Lightroom's cloud service, and without my knowledge or permission (and I was using the just-installed defaults) it had deleted those files I had touched with Lightroom and \"helpfully\" uploaded them. I uninstalled Lightroom within the hour. reply vr46 7 hours agoparentAh, the new Lightroom CC! I was a happy, delighted, enthusiastic Lightroom user from the moment it originally came out and threw Aperture into the bin where it belongs. Lightroom was fast, brilliant to use, a fabulous wrapper around ACR and managed all the photo files perfectly. It was, to me, as perfect a piece of consumer software that has ever existed. The moment CC turned up, not only was it a cut-down version in terms of features, but the file management side was gone too, and this whole cloud functionality took over. A complete workflow change. The main benefit that I found, ok, the only benefit, was that I was able to easily create web galleries for client approval etc. Everything else was gone. Lightroom Classic came back, kind of, but the direction of travel was fixed. It took me years and years to finally get close to that one-stop-shop workflow, using Photo Mechanic and Capture One, both of which have gone subscription-based and offering close to zero value in return. My strategy now, I shit you not, is to never ever perform a major upgrade on this Mac and hold out until all the root SSL certificates expire with my current setup. We used to have such stable computing environments and now everything is a cloud-connected, exposed and defenceless security shitshow. reply freedomben 2 hours agorootparentAgreed. This is I think the single biggest contributor to my now fairly radical approach to software. Unless the app is at least source available, I will only use it if I really need it. One of the most valuable things about open source to me now is simply that nobody can take it away. Sure maintainers can disappear, but (aside from accreted cruft/bitrot) I can keep using whatever version as long as I have hardware to run it on. I dedicated four hours to learning GIMP a few years ago, and many times now I've been so glad I did. There are a ton of books and courses out there for people looking to do the same. Kdenlive is another one I'm super glad I took the time to learn. reply norwalkbear 6 hours agoparentprevPeople thought I was crazy to write my own guide image editing mini apps in c# .net years ago for image editing in game dev. I'm not so crazy anymore reply 20after4 17 hours agoprevIf you're still using Adobe's products, stop. Better late than never. Adobe had some great products. Then they over charged for them. Then they required a \"cloud\" subscription. There are alternatives. Support one of the startups or open source projects that are competing with them. Don't give Adobe another cent. reply havilland 4 hours agoparentI wouldn’t even look at startups if there is a viable open source alternative. Most startups are just looking to get a big enough user base to get bought by the big players. reply bishbosh 2 hours agorootparentExactly, any startup will just be on a different place of the enshitification curve. reply freedomben 2 hours agorootparentAgreed, though personally if their product is open source or source available, I'm much less concerned since I'm not screwed if/when they enshittify or go belly up. reply WalterSear 14 hours agoparentprevAdobe: the golden goose that wouldn't die, but just festers on. reply lancesells 5 hours agoparentprevI went a very long time not using Adobe's products but I hit a wall when I went to do some motion-based projects. What's the After Effects alternative? reply adwi 2 hours agorootparentNot one-to-one (node vs layer metaphor) but Fusion is stupid powerful and free within Davinci Resolve. It’s an incredible piece of software that, in addition to being best in class color correction, has fully replaced Adobe in my professional video workflow (Premiere, AE, AME, etc) https://www.blackmagicdesign.com/products/davinciresolve/fus... reply freedomben 2 hours agorootparentAnother vote for Black Magic. They also support Linux as first-class citizens, which makes a world of difference to me. reply vunderba 16 hours agoprevI migrated away from Adobe after Photoshop CS6 which I believe was the last release before they switched over to a subscription only pricing model. If you're looking for a Photoshop alternative to break away from the incredibly user hostile relationship with Adobe I can heartily recommend either Krita (open source) or Pixelmator (Mac only). Pixelmator Pro is my daily driver for image related work and is incredibly snappy and surprisingly full featured for an application that costs a fraction of PS - $50.00 onetime fee. https://www.pixelmator.com/pro/ https://krita.org/en/ reply PebblesHD 11 hours agoparentAnother happy Pixelmator user, migrated across from Photoshop and Illustrator. For the relatively small cost ($30 on sale) its most of the way as good for my semi-professional work creating content. It has some rough edges but has so far been improved with every update. reply omoikane 16 hours agoparentprevI would recommend DxO PhotoLab as an alternative to Adobe Lightroom for a similar reason (perpetual license instead of subscription). reply Brajeshwar 15 hours agorootparentI'm a user/subscriber to Skylum for the past few years and it integrates well with macOS Photos. Both Affinity Photos and Pixelmator Pro also integrates with Photos. I'm not a professional. DxO PhotoLab does looks good especially with their focus on RAW. I plan to start shooting mostly in RAW. Do DxO plays well with macOS Photos and how does it compare to Skylum's (Neo)? reply walteweiss 11 hours agoparentprevI second both statements. I used Pixelmator Pro on a Mac for maybe a decade (before it became Pro), and it’s very good. I would highly recommend it to anyone on a Mac. Long ago they had 50% discount, I don’t know whether they still do discounts these days. It’s a one-time payment, so even without a discount they worth what they ask. If you work with the app all day long, every day, it’s such a pleasure after the ugly Photoshop. Pixelmator allowed me to forget Photoshop for good. And even allowed me to move to Linux, https://news.ycombinator.com/item?id=40572874 Pixelmator Pro doesn’t work on Linux (it’s macOS exclusive, afaik), but it allowed me to stop being dependent on Photoshop and look for other alternatives. Krita is quite good on Linux. I cannot compare them as I’m not an artist myself, but for my use case Krita is good enough. Since it’s FOSS you can start with that easily. reply Brajeshwar 16 hours agoprevAdobe Photoshop was one of the tools that helped me earn money professionally during my school and college days, so I had a nostalgic relationship with it. Then, I had a good relationship with Adobe in various ways for a long time in the 2000s. I stopped using such tools long back, but I wanted to keep one handy to remind me of the old days. I found Serif's Affinity[1] to be a good alternative so far. I've been a customer since its beta, and I had to buy once, then an upgrade with their recent v2.0 The other good, light, quick, and easy-to-use alternative is Pixelmator Pro[2]. In the last 4-5 years, I think I have only had to pay for it twice. 1. https://affinity.serif.com/ 2. https://www.pixelmator.com/pro/ reply zimpenfish 13 hours agoparent> The other good, light, quick, and easy-to-use alternative is Pixelmator Pro Unless you want, e.g., a destructive crop[0] which they have been not adding for at least 4 years and counting. Since my graphic work generally involves cropping, that kinda rules out Pixelmator Pro for me and forces me back into the Adobe Tax Hole. [0] There are undoubtedly many other deficiencies but this one really irks me. reply marcomourao 9 hours agorootparent> Unless you want, e.g., a destructive crop Isn't this achieved by enabling the \"Delete cropped pixels\" option? From Pixelmator help: > Select \"Delete cropped pixels\" to permanently delete the cropped areas of an image or deselect it to crop the image nondestructively and hide the cropped areas of an image instead. https://www.pixelmator.com/support/guide/pixelmator-pro/1010... reply zimpenfish 6 hours agorootparentBloody hell, completely missed that option. Yes, that does what I need! Thanks! reply walteweiss 11 hours agorootparentprevWhat’s your work flow for needing to have a destructive crop? reply grishka 14 hours agoprevDoes this only relate to things you put into their cloud, or does Photoshop now upload your offline files to Adobe servers as well? By the way, it's always morally correct to pirate Adobe software for personal use. Which also allows you to fully firewall it because it no longer needs to talk to the activation server. reply UberFly 14 hours agoparentIt's only for people nutty enough to use their cloud services like Behance. And I agree with your second point. reply hjkl0 13 hours agoparentprevBy pirating, you mean running modified binaries from unknown sources? Morals aside, how is that safe, secure, or even convenient? reply npteljes 7 hours agorootparentI agree with you, but on a practical level, private trackers are moderated, and so, reasonably safe and secure. Convenience is case by case. Often, the official stuff puts up such a fuss that the pirated copy is more convenient to use. reply grishka 12 hours agorootparentprevI've been doing it all my life. I've literally never paid for a software license, I don't know any better. In general, I usually download from reputable sources. Haven't had any problems so far. reply iLoveOncall 11 hours agorootparent> Haven't had any problems so far. That you know of. For all you know you could be infected and part of a botnet. Viruses don't open a big popup saying \"haha you've been hacked!\". This line of thinking is extremely common and absolutely nonsensical. The point of a virus is to remain undetected. reply nottorp 2 hours agorootparent:) reputable torrent sources usually have a comment section and viruses are found and the torrent nuked faster than you get around to downloading the stuff... reply antifa 4 hours agorootparentprevA botnet that shows no evidence of saturating my CPU, RAM, disk, network? OK fine then. Most malware these days does things like demand bitcoin, popup ads, or upload your files to the cloud without your consent. If I've actually unknowingly downloaded a virus, it's honestly less malevolent than the paid version. reply freedomben 2 hours agorootparent> If I've actually unknowingly downloaded a virus, it's honestly less malevolent than the paid version. This is a remarkable observation on the sad state of paid software. It's so sad because it's so true. I don't mind buying software, but I do mind pretty much all DRM implementations. Even simple license checks have bitten me in the past when I had no internet access and the software just decided that time was up and it needed to verify me. Nothing fills me with rage more than software that I paid for refusing to run while I'm camping or on a plane or somewhere else without internet, for software that doesn't need any networt functionality whatsoever to operate. reply Lammy 11 hours agorootparentprev> undetected If a tree falls in a forest and no one is around to hear it, does it make a sound? reply noman-land 4 hours agorootparentIf a tree falls in the forest and kills someone but no one around to be sad, did they really die? reply Lammy 38 minutes agorootparentU=U :) reply walteweiss 11 hours agorootparentprevnext [5 more] [flagged] grishka 9 hours agorootparent> It’s deep in their culture to steal, do not respect others and their work Piracy != stealing. I'd never steal anything irl because (surprise!) I do respect others and their work. Piracy, however, doesn't deprive the owner of anything, it just creates a copy. From the point of view of the developer, it's not any different from me not existing. > Most of them (I talk of general audience, not some developer here on HN) don’t understand the concept of buying software I do understand the concept and I do know people who buy software for personal use. To each their own. > They don’t understand the concept of copyrights I personally do understand the concept of copyright. However, I deliberately ignore copyright most of the time because this system is ridiculously biased towards allowing people and companies to hoard intellectual property. It's very good for rent-seeking. The initial idea behind copyright was sensible. Our current implementation is anything but. > As much as they don’t understand the concepts of democracy and human rights Please don't lump the people and the government together. I see people make this mistake way too often. Yours, a disgruntled Russian who wants democracy and human rights yet is powerless to do shit about it. (I do keep voting against Putin though.) reply walteweiss 6 hours agorootparentnext [2 more] [flagged] grishka 4 hours agorootparent> You understand the copyright, but you don’t respect it. That’s the idea. I understand stupid ideas, but I'm not required to respect them. Make the copyright last 3 years instead of an eternity, or make copyright holders pay an exponentially increasing tax, per copyrighted work, to extend it every year, then I'll reconsider. > You’re okay with having your Photoshop, but for free. Yes I am. Proudly. Why should I care? Adobe won't sell me a subscription even if I wanted one, btw. Because I'm Russian. If I were into making compromises to prove things, I'd be using desktop Linux. And Adobe isn't a small startup struggling to make ends meet. They would've still been profitable even if no one paid for their products for personal use and their only paying customers were businesses. > As Russia is a democratic country indeed. And that is the way of overthrowing a dictator, voting against him on the next ballot. Doing anything else is futile, obviously. I'm open to suggestions. You can also come here and try to overthrow him yourself if you think we're doing such a poor job of it. I'll be sure to take a picture of you getting arrested. reply southernplaces7 10 hours agorootparentprevOh piss off with your ignorant generalizations. Because Russia is country non grata now it's okay to be as racist as you please to Russians as a people? Grotesque, just as moronic as it has been in all decades past when some idiotic war fever had whole cultures branded as evil or criminal or morally degenerate by idiots of many stripes. Would you apply that same broad strokes standard of stupidly simple thinking to say, black people, or jews? Also worth noting, piracy is indeed okay when the companies whose software is being pirated behave in blatantly parasitic, extortionate ways that go beyond the scope of what's remotely reasonable for selling you a service. reply walteweiss 9 hours agorootparentnext [2 more] [flagged] longerd2 5 hours agorootparent> A racist? Do you even know what a race is? Is Russian a race now, huh? In other words: \"I'm not racist, I don't categorize by race. Do you even know what a race is? You have categorized Russians wrongly. It is part of a race, not it's own one...\" reply Lammy 12 hours agorootparentprevI'll take my chances. Adobe have proven they want to spy on me 100% of the time and shake me down for as much cash as possible. Pirates ostensibly have to compete on the quality of the product they offer. reply nottorp 3 hours agorootparentprev> or even convenient Back before Steam, when I bought a game on disc I downloaded the no-cd crack before opening the box to install it... reply realusername 11 hours agorootparentprevWe're in a world where the legal solution isn't exactly safe, secure nor convenient either reply anal_reactor 5 hours agorootparentprev>be me >\"Google wants to know your location\" >fuck off you already know it anyway >\"Do you want to allow this app from an unknown publisher to make changes to your device? PiratedGameFromRussianTorrents.exe\" >ok The biggest problem with piracy is the entry barrier. You need to know what sites are safe, what aren't. Also, Google hides results from torrent sites, so yeah, it's kind of an underground club. If you're a newbie you're going to get ransomware, if you know the basics it's trivial. Piracy isn't as popular as 10 years ago, but it's still there, mostly powered by poor countries. reply immibis 6 hours agorootparentprevNo, from known sources. reply politelemon 12 hours agoprevA large swathe of professionals campaigned on behalf of Adobe when they switched from perpetual to subscription licensing. They willingly turned over control and this is merely the consequences of that willingness, which Adobe will continue to take advantage of. I don't see this leading to any changes, just pointing it out. reply nottorp 2 hours agoparentWouldn't surprise me if they got 90-100% discounts for a few years in exchange for saying it's a good thing. reply undo-k 14 hours agoprevI replaced photoshop with photopea a while ago. I only use it for light work, but it’s the lowest friction alternative I’ve tried that runs on Linux. https://www.photopea.com/ reply kfarr 12 hours agoparent+1 for Photopea! Excellent drop-in replacement for Photoshop and Gimp is always there to help for HDR things that Photopea can't handle. reply stranded22 11 hours agoparentprevYup, love photopea. No need to wait for Photoshop to load and it works on any computer with a browser. reply barbariangrunge 16 hours agoprev> The user agreement also leaves open the possibility to train AI using user-generated content, saying they can use the content they retrieve to “improve our Services and Software“. reply spacephysics 15 hours agoparentThey’re double dipping like a lot of these companies. Pay for the service, and use your human made content as valuable training data Or with something like Reddit use ads to make money then sell api access to human content reply WalterSear 14 hours agorootparentIt's interesting that they are so hungry for training data that they would seek access to people's half finished photoshop files. I'm reminded of what just happened to google: this seems as effective a strategy as training an LLM on reddit shitposts. reply jerojero 45 minutes agoprevI'm going to be using their service for another year and then cancelling (my \"annual\" plan starts on march). reply Narhem 13 hours agoprevThe amount of illegal probing of my computers regardless of ToS has made me extremely uncomfortable. reply account42 5 hours agoparentWhy don't you do anything about it? There are alternatives. reply Lammy 15 hours agoprevI will hold on to my activation-free fully-offline Photoshop CS3 until the day Win32 finally dies. Still using it daily with an equally-old Wacom tablet to clean up all my flatbed scans :) reply skilled 14 hours agoprevI am guessing this needs to be taken with a grain of salt since the author did not get a reply from Adobe. Doesn’t look like they bothered to get it either. As I am reading it, this should not affect NDA work. reply hereme888 3 hours agoprevLol! \"Solely for the purposes of operating or improving the Services and Software...we can access and use your data, even for marketing our Software or services.\" The gall of these people... reply marcomourao 9 hours agoprevI stopped using Adobe a couple of years ago, replaced it with the Affinity suite. Publisher still lacks a lot of InDesign features but it gets the job done. For photography I'm using FastRawViewer for culling and Photomator for editing. reply zamalek 14 hours agoprevUnexpectedly fantastic news! My wife makes extensive use of the adobe PDF editing tools, which is has been a major blocker for getting her onto linux. What is a good replacement that works on windows and linux? Non-free is fine. reply freedomben 2 hours agoparentXournal++ is my go to. It has a few quirks to get used to, but once you do it's quite functional. Biggest thing to watch out for is exporting and overwriting the source file. It will usually let you, but it often blanks out the source and loses your changes. So just make sure to export with a different filename than the original is. If you accept the default suggestion, it will work fine. It's also made to be used well with wacom tablets, so if you have one of those you can make use of it in xournal++. The older \"Xournal\" (no ++) is mostly functional but also dead, so I would go with Xournal++. reply anthk 3 hours agoparentprevPDF was not created to be edited, but as a final output format ready to be printed as-is. OTOH, XournalPP has basic editing tools. So does LibreOffice. reply bonestamp2 14 hours agoparentprevI can't answer windows/linux, but I use pdfexpert.com for mac and it's great. It was a one time $100 charge when I bought it several years ago, and it gets updated regularly. reply zamalek 3 hours agorootparentThanks, but I'm more likely to use Windows or even TempleOS over MacOS. reply politelemon 12 hours agoparentprevHave a look at Qoppa, Master Pdf Editor, and Xournal. reply barbariangrunge 16 hours agoprevFor alternatives, I really liked the affinity suite, but they just got acquired. reply soygem 8 hours agoprevI still can't draw a circle in gimp :( reply wizzwizz4 2 hours agoparentKrita! https://docs.krita.org/en/reference_manual/tools/ellipse.htm... > Use this tool to paint an ellipse. The currently selected brush is used for drawing the ellipse outline. Click and hold the left mouse button to indicate one corner of the ‘bounding rectangle’ of the ellipse, then move your mouse to the opposite corner. Krita will show a preview of the ellipse using a thin line. Release the button to draw the ellipse. reply stuckkeys 9 hours agoprevWhat are the thoughts on Krita? reply quitit 7 hours agoprev [–] Even if this is not what Adobe are doing, the author of the tweet is not incorrect to make such an interpretation from the terms. Now would be a good time for Adobe to do away with vague \"catch all\" language, because we now live in an era where user data is being swept up for AI model generation and governments are leaning heavily into tech companies for policing. However to play the devil's advocate we can see how these terms have come about without rounding up to tweeter's interpretation. Note: There is also good reasoning to believe this interpretation because using software that collects data indiscriminately would significantly impact the ability of Adobe's large customers to use their software. Since service agreements and various compliance standards forbid as such. First up are Adobe's online terms that relate to CSAM, abiding by subpoenas, security, and feedback/bug support. Those are all pretty standard for hosted services. So while some may not like that, this is a \"nothing to see here\" clause. However the \"gotcha\" for users comes about because a lot of Adobe's features rely on their cloud infrastructure which they may use unintentionally. This extends beyond using their cloud storage allowance or the Behance social network. Here are some examples: - Generative AI: in & out painting will send image data to Adobe for matching. - Farm rendering: Some apps, such as Dimension, feature off-site processing options. These of course mean that your content, textures, logos, etc are then on Adobe's servers for processing. - Forms dissemination: Hosting forms means that Adobe will have not just your content, but also that of people that fill out the form. - Review features: Review features are all performed through the cloud. - Moving documents between devices: Using the app's built into tools to move a document/graphic between devices is performed via the cloud. There are many more scenarios, but I've tried to choose a range to demonstrate variety, and how that extends beyond actions where the user is deliberately using online storage. The next part of Adobe's terms is noting that they don't specifically call out online versus offline processing, rather they use the terms \"Services\" and \"Products\". This would appear to be explainable as Adobe's apps include algorithms that enforce certain types of document security, such as anti-counterfeiting measures, watermarking, Content Credentials and copyright embedding. The vague language of this clause is the source of the problem, as Adobe don't demarcate where and why the processing is performed. So in summary the overly vague language can be chalked up to legal brevity, but in this era that is insufficient for peace of mind. reply Sohcahtoa82 1 hour agoparent [–] > Now would be a good time for Adobe to do away with vague \"catch all\" language, because we now live in an era where user data is being swept up for AI model generation and governments are leaning heavily into tech companies for policing. 100%. The thing is, I've seen in B2B sales, one business handling another's data will have to very explicitly say who will be acting as subprocessors and storage of data. You might have to disclose that you're using AWS and Snowflake to store and process data. Maybe it's time for B2C to start doing that, too. Instead of \"We may send your data to 3rd parties for processing\", say WHICH 3rd parties and WHY. > legal brevity An exceptionally rare thing to see. \"Legalese\" exists because people create loopholes by exploiting the slightest ambiguity. I invented a story of a mom telling her kid to stop jumping on the bed, and the kid says \"I'm not jumping, I'm hopping!\" and goes into a diatribe on the difference between jumping and hopping, the mom says \"well quit it!\" and leaves, only to come back later and the kid is still jumping, the mom is angry, and the kid says \"I'm not jumping or hopping, I'm bouncing!\" and eventually the mom has to say something like \"Do not jump, hop, bounce, spring, leap, or otherwise use your feet or any other body part, nor any object, to propel yourself upwards or laterally from the bed\". And then later, the mom checks on the kid, and he has removed the mattress from the bed and is still jumping on it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Adobe's new terms of service for Photoshop mandate user consent for Adobe to access active projects, sparking privacy concerns, especially for NDA-protected work.",
      "Sam Santala, founder of Songhorn Studios, brought attention to this issue on Twitter, reflecting broader industry trends.",
      "Similar practices are seen with Microsoft's AI product Recall, which scans user screens to enhance service quality."
    ],
    "commentSummary": [
      "Adobe's Photoshop Terms of Service permit the company to access user projects for content moderation, causing dissatisfaction, especially with cloud services like Lightroom that automatically manage local files.",
      "This has led users to seek alternatives such as Krita, Pixelmator, DxO PhotoLab, Affinity Photo, and Blackmagic's Fusion within Davinci Resolve, favoring perpetual licenses over subscriptions.",
      "Concerns include Adobe's data usage policies, AI training, privacy, and the need for transparency in data processing, highlighting broader issues of copyright, democracy, and human rights."
    ],
    "points": 163,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1717630488
  },
  {
    "id": 40597503,
    "title": "Advocating for Legal Protections Against AI Profiling Using Public Data",
    "originLink": "https://link.springer.com/article/10.1007/s13347-023-00616-9",
    "originBody": "Home Philosophy & Technology Article The Right Not to Be Subjected to AI Profiling Based on Publicly Available Data—Privacy and the Exceptionalism of AI Profiling Research Article Open access Published: 07 March 2023 Volume 36, article number 14, (2023) Cite this article Download PDF You have full access to this open access article Philosophy & Technology Aims and scope Submit manuscript Thomas Ploug 6097 Accesses 2 Citations 3 Altmetric Explore all metrics Abstract Social media data hold considerable potential for predicting health-related conditions. Recent studies suggest that machine-learning models may accurately predict depression and other mental health-related conditions based on Instagram photos and Tweets. In this article, it is argued that individuals should have a sui generis right not to be subjected to AI profiling based on publicly available data without their explicit informed consent. The article (1) develops three basic arguments for a right to protection of personal data trading on the notions of social control and stigmatization, (2) argues that a number of features of AI profiling make individuals more exposed to social control and stigmatization than other types of data processing (the exceptionalism of AI profiling), (3) considers a series of other reasons for and against protecting individuals against AI profiling based on publicly available data, and finally (4) argues that the EU General Data Protection Regulation does not ensure that individuals have a right not to be AI profiled based on publicly available data. Similar content being viewed by others Sexist Slurs: Reinforcing Feminine Stereotypes Online Article Open access 28 November 2019 The disaster of misinformation: a review of research in social media Article 15 February 2022 AI in the headlines: the portrayal of the ethical issues of artificial intelligence in the media Article Open access 29 March 2020 Use our pre-submission checklist Avoid common mistakes on your manuscript. 1 Introduction The analysis of social media data with artificial intelligence (AI) models holds considerable potential for predicting health-related conditions. In a study of Instagram photos, a machine-learning model was able to identify depressed users with greater precision than unassisted general practitioners (Reece & Danforth, 2017). Among others, the model used photo brightness and colours, number of comments, and likes as predictors and found that depression was associated with postings of bluer, darker, and greyer photos that received more comments, but fewer likes. In a related study of Twitter data, the developed model also achieved greater accuracy than unassisted physicians in identifying people with depression (Reece et al., 2017). The study showed that the dominant contributors to the difference between depressed and healthy individuals were an increase in the use of negative words and a decrease in the use of positive words among depressed people. The study also found that increases in word count were positively associated with depression. Other studies have shown equally promising results for models using social media data for the prediction of mental disorders, including anxiety, bipolar, borderline personality disorder, schizophrenia, autism (Gkotsis et al., 2017; Kim et al., 2020; Kumar et al., 2019), and the risk of suicide and anorexia (Amini et al., 2022; Coppersmith et al., 2018; Zirikly et al., 2019). The increased predicting potential and widespread use of AI models across sectors has sparked an intense debate on how to regulate AI. A host of actors have issued a significant number of AI guidelines (Jobin et al., 2019), and the EU Commission has recently issued a proposal for the regulation of AI. The promises and perils of mental health profiling based on social media data add fuel to this debate. Thus, predicting an identifiable individual’s health-related conditions (output data) based on social media data (input data) may benefit the individual in various ways, but it also raises significant issues of privacy. This article concerns an individual’s privacy rights in situations where the data used to make sensitive predictions has been made publicly available on, for instance, social media platforms. In particular, it is argued that individuals should be granted a sui generis legal right not to be subjected to AI profiling based on publicly available data without their explicit informed consent. As such, the legal right proposed is (1) a negative right that entitles individuals to non-interference with respect to AI profiling producing sensitive personal data (output data) based on online and publicly available personal data (input data), (2) it is a right that can be waived through informed consent, and (3) it is a pro tanto right, i.e. it is not an absolute or unconditional right, but a right that may be infringed under certain exceptional conditions (Frederick, 2014). The need for a sui generis legal right is substantiated through a four-step analysis. In the course of this analysis, it is argued: 1) that there are strong reasons for protecting personal data as such data may drive different types of social control and may lead to stigmatization 2) that a number of features of AI profiling make individuals more exposed to social control and stigmatization than other types of data processing and that AI profiling thus poses a unique threat to individuals (the exceptionalism of AI profiling) 3) that there are strong reasons for protecting public discourse and interaction on social media and that there are no obvious trumping concerns to the contrary 4) that existing EU legislation—i.e. the General Data Protection Regulation (GDPR)—does not ensure individuals a right not to be AI profiled and that in any case, there are reasons for making it an explicit sui generis right The article is ended by a few reflections on some of the key questions raised by the proposed arguments, and an agenda for future research is suggested. All throughout the notion of ‘data’ will be used to denote both the data being produced by AI profiling, i.e. the output data, and the data on which the AI profiling is based, i.e. the input data. The context will determine the type of data being referred to. 2 Three Cases of AI Profiling Based on Social Media Data The four-step analysis provided in this article will involve three stylised cases of AI-driven mental health profiling. These cases are included in order to illustrate the various different contexts in which AI-driven mental health profiling may be conducted. The cases are as follows: The Friends Case Two close friends, A and B, are socializing on a regular basis. At their recent gatherings, B has been absentminded and shown some signs of a general lack of motivation. Being concerned about the friend but unwilling to confront B with weakly evidenced suspicions, A decides to do an AI-generated mental health profile of B. Therefore, A collects a series of photos that B has made publicly available on Instagram and feeds them a locally stored copy of the highly accurate mental health prediction model Deepmood. Much to the surprise of A, the model predicts that B is bipolar. A reports the findings to B and B’s family. The Public Servant Case A public servant, A, in charge of the unemployment benefit scheme at the local municipalities comes to suspect that a client, B, may be suffering from a chronic mental illness likely to keep B in long-term unemployment. Wanting to ensure that B is adequately handled by ‘the system’ based on objective information, but unwilling to cause unnecessary unrest, A decides to do an AI-generated mental health profiling of B based on a series of public tweets from B. A locally stored copy of the highly accurate mental health prediction model Deepmood suggests that B suffers from anxiety. A reports the findings to B. The Prime Minister Case A concerned citizen, A, fears that the upcoming general election may pave the way for a prime minister candidate, B, whom A suspects may be mentally unstable and thus unfit for the job. Believing that it is in the public interest to have reliable information about the mental health of B, A decides to do an AI-generated mental health profile of B. A collects a sample of public tweets from B and feeds them to a locally stored copy of the highly accurate mental health prediction model Deepmood. The model suggests that the candidate suffers from severe depression. A reports the findings to the general public. 3 Reasons for Protecting Personal Data The philosophical literature on the value and definition of privacy is vast (Leino-Kilpi et al., 2001). This article develops and considers three arguments in favour of a right to privacy specifically in relation to the use of personal data. As will become evident, the three arguments are particularly relevant for an analysis of the previously introduced cases involving AI profiling. 3.1 The Social Pressure Argument The argument from social pressure is an autonomy-based argument for the right to privacy regarding personal data. Essentially, the argument contends that access to personal data about individuals may be used to exert communicative pressure on the choices and actions of these individuals in ways and to an extent incompatible with their interests and preferences. Communicative social pressure can be defined the following way: A communicative act—verbal or nonverbal—performed by a sender, say A, amounts to social pressure on a recipient, say B, if and only if it succeeds in making B believe that certain choices and actions are associated with costs to an extent, making it less likely that B will make the relevant choice or perform the relevant action. In the friends case, A may use knowledge of B’s diagnosis to pressurize B into treatment by communicating in one way or another that if B remains untreated, it will have negative consequences not only for B, but also for family and friends. In the case of the prime minister, knowledge of B’s diagnosis can similarly be used to pressure B to abandon the candidacy. The influence of unwanted social pressure based on personal data may be limited through a right to privacy. Insofar as individuals have a right to exercise personal autonomy, where this is taken to include a right to protect themselves against unwanted social pressure, they should have a right to privacy limiting the access of others to data about them. Thus defined, a right to privacy empowers individuals to influence the ways and extent to which they are subjected to social pressure. It does so by letting individuals shape the social pressure by deciding the level, character, and with whom they share data about themselves. Here, three observations must be made. First, the argument does not claim that access to accurate data is a necessary condition of social pressure, but only that it may be sufficient for others to be able to exercise such pressure. An individual may put pressure on another individual in various ways without having any knowledge of the latter. Second, it does not make any distinctions between different types of data about individuals, e.g. personal and non-personal data. One may claim, however, that personal data for various reasons is more effective in the attempt to put pressure on another individual and that individuals would therefore withhold such data to a larger extent than nonpersonal data. Third, the argument does not operate on a distinction between different methods of exerting social pressure on choices and actions. Social pressure methods are many and versatile. They cover a spectrum of verbal and non-verbal, explicit, and covert communicative acts that include persuasion, coercion, and manipulation. Persuasion can be defined as the act of pointing out verbally the good and bad consequences of a certain course of action (Powers, 2007), and coercion as the verbal act of threatening to make someone worse off than he or she would otherwise be or ought to be (Nozick, 1969; Wertheimer, 1990). Manipulation covers a range of covert attempts at influencing other people through the tailoring of information, e.g. by lying or withholding information, by making exaggerations, and by framing information that is likely to lead others to believe what is false (Beauchamp & Childress, 2001). While the ethical gravity of performing acts of persuasion, coercion, and manipulation differs significantly, the argument from social pressure is indifferent to such distinctions. It implies a right to be left alone in the broader sense of being able to limit all kinds of data-facilitated social pressure. 3.2 The ‘open future’ Argument The ‘open future’ argument is also an autonomy-based argument for the right to privacy. At the heart of the open future argument lies the observation that personal data shared by individuals at a certain point in their life may come to shape the future opportunities afforded to them by others in ways that run counter to their interests. In short, the ‘open future’ argument contends that access to the personal data of individuals can lead to unwanted interventions in future choices. A choice-set intervention can be defined as follows: An agent, say A, makes an intervention in the set of choices of another agent, say B, if and only if A, on the basis of having access to certain data about B, shapes the choices of B differently than they would otherwise have been. In the public servant case, the public servant’s knowledge of the diagnosis of client B can change the opportunities offered to B within social services. Similarly, the general public’s knowledge of the diagnosis of candidate B in the prime minister case may have consequences for the career opportunities offered by existing political parties. In both cases, the effects on the choice set of B can go against the interests and preferences of B. If people have a right to exercise personal autonomy, where this includes a right to protect themselves against unwanted influences on the options available to them in the future, they must also have a right to privacy limiting the access of others to the personal data that may be used for shaping their future choice set. Several observations must be made here. First, the notion of shaping future options should be understood both quantitatively and qualitatively. An open future is both a matter of the number of available options, but also a matter of the availability of certain vital options (Garrett et al., 2019). While the prime minister candidate may not necessarily be robbed of a political career in the highest office, it may be a career under constant accusations of being unduly influenced by depression. Second, the argument from an ‘open future’ differs from the argument from social pressure. Although the exercise of social pressure may be effective in associating a certain choice with costs to an extent making this choice unlikely to be made, it may not limit or otherwise significantly alter the choice set prior to the choice situation obtaining. Moreover, social pressure requires a communicative act of some kind. In the following, the exercise of social pressure and choice-set interventions shall both be referred to as forms of social control. Third, the ‘open future’ argument presented here differs from the standard ‘open choice’ argument in relation to children. Feinberg famously argued that a child’s right to autonomy in adult life can be violated in advance through parental choices that limit a child’s opportunities in later life (Feinberg, 1980). The ‘open future’ argument advocated does not posit a future autonomy right that can be violated in advance. It is an individual’s right to personal autonomy in the present that grounds a right to act in the interest of protecting the future autonomy of the individual. 3.3 The Stigmatization Argument The stigmatization argument grounds the right to privacy in the potential harms of suffering stigmatization. According to Goffman, stigmatization occurs when a person is attributed with a discreditable trait that makes the person inferior, dangerous, and perhaps even inhuman, and when this act of discrediting leads to discrimination (Goffman, 1963; Ploug, 2020). In a later reinterpretation of Goffman, stigmatization is taken to be a complex phenomenon at the societal level constituted by a process in which a difference between people is identified, labelled, and associated with negative stereotypes, followed by acts of segregation (‘us’ and ‘them’) and discrimination made possible by a greater social, economic, and political power of the labelling party (Link & Phelan, 2001; Ploug et al., 2015). So defined, stigmatization clearly presupposes access to data about people. The identification and labelling of a difference between people—intentionally or unintentionally—is an act that requires access to data. In the three cases, access to AI-generated diagnoses would allow the friend, client, and candidate to be identified as different and labelled, e.g. ‘mentally ill’, and thus be included in a stigmatized group in society (more on this below). A right to privacy that limits access to certain data could protect people from stigmatization. One may perhaps be tempted to object here that it seems as if the real moral concern with stigmatization is discrimination, i.e. morally unjustified differential treatment. However, research shows that stigmatization is associated with other harms to stigmatized individuals. The case of mental illness is highly illustrative. Studies show not only that mental illnesses are associated with negative stereotypes (Bhugra, 1989) but also indicate discrimination against mentally ill people in the labour market and in health care (Druss et al., 2011; Stuart, 2006). Therefore, the stigmatization elements introduced above—that is, labelling, negative stereotyping, segregation, discrimination, and power asymmetry—are present in relation to this group (Link & Phelan, 2001). But there are other harms to this group than discrimination. Evidence on labelling of mentally ill people in healthcare suggests that it can lead to the self-application of labels and negative stereotypes, where this is associated with lower self-esteem, demoralization, income loss, unemployment, and self-discrimination (Corrigan et al., 2009; Link, 1987). Studies of barriers to mental health treatment find that negative attitudes toward mental illnesses keep patients from seeking health care (Mojtabai et al., 2011; Voorhees et al., 2005). In turn, this can drive inequality in health care (Stuber et al., 2008). Studies on the effects of stigmatization of people with AIDS show that the feeling of stigmatization due to one’s health status is associated with anxiety, depression, distrust, and the disruption of normal social relationships (Crandall & Coleman, 1992; Herek, 1999). Similar findings of stigmatization and its harmful effects have been reported for smokers and obese people (Goldstein, 1991; Hilbert et al., 2008; Myers & Rosen, 1999; Peretti-Watel et al., 2014; Stuber et al., 2009). A comment must be made. In this section, it has been argued that the threat of stigmatization and the associated harms could and should ground a right to privacy, but perhaps less than stigmatization is needed to make this argument. Research suggests that negative stereotyping promulgated, for instance, in the media, is associated with a number of harms to members of the stereotyped groups. It may elicit situational responses of negative emotions and stress, induce self-discrimination in relation to a variety of activities, and impair cognitive and educational achievements (Appel & Weber, 2021). A right to privacy may protect against such weaker forms of singling out individuals on the basis of personal data. 4 Reasons for Protecting an Individual Against AI Profiling The three arguments developed above have foremost provided reasons for a general right to data privacy. Some of the considerations along the way have indicated that personal data may make an individual particularly vulnerable to attempts at social control and the harm of stigmatization. However, the arguments do not distinguish AI profiling from any other processing of personal data, and hence, they cannot in and of themselves sustain a sui generis right not to be subjected to automated profiling based on publicly available data. In this section, it is therefore argued that a number of features of AI profiling make individuals more exposed to attempts of social control and stigmatization and that—in doing so—AI profiling presents a particularly invasive kind of data processing. 4.1 The Exceptionalism of AI Profiling 1: Predictive Accuracy and Social Control As evidenced by the studies cited in the introduction, AI profiling differs from other types of data processing by potentially making highly accurate predictions about the future behaviour and dispositions of individuals. Mental health profiling as in the three cases is not only a matter of categorizing health problems in the past and present, but it also involves predicting mental health dispositions that will shape an individual’s future. In the debate on the exceptionalism of genetic data, it has been claimed that such data are exceptional in that they can be used as a predictor of future disease (McGuire et al., 2008). The counterargument has been that the predictive power of genetic data is limited, because genetic risk factors are only—with the exception of a few rare, highly penetrant genotypes—among many contributors to disease (Evans & Burke, 2008). Notably, AI profiling does not have such inherent limitations. AI profiling, e.g. in relation to diagnostics, can incorporate all social, genetic, and other data types relevant for making predictions about future disease. In doing so, AI profiling may make highly accurate predictions about the future behaviour and dispositions of individuals. Predictive profiling of behaviour and dispositions exposes individuals more to attempts of social control than they would otherwise have been. Here is why. Attempts at socially controlling the future behaviour of individuals may—at least in some cases—rest on data-driven beliefs about their future behaviour and dispositions. Individuals for whom there are no (accurate) personal data indicating that they are disposed for smoking seem unlikely to be subjected to attempts of social control (with regard to smoking behaviour) to the same degree as individuals for whom such data exist. What matters here is first and foremost the existence and accessibility of personal data indicating that an individual may come to smoke in the future. However, secondly, it seems equally important that the data are accurate and therefore reliable. Although access to more or less reliable historic data evidencing that an individual once tried smoking may trigger attempts at socially controlling his or her future smoking behaviour, it seems that a reliable prediction of future smoking is more likely to do so. Third, it also matters whether the prediction concerns future behaviour or more deeply rooted dispositions, where a disposition may for present purposes be defined as a trait leading to repeated occurrences of a particular type of behaviour in particular circumstances. A prediction of a smoking disposition may trigger a more intensive effort at social control than a prediction of an isolated occurrence of smoking behaviour. AI profiling may bring to the fore highly accurate predictions of future behaviour and dispositions that may lead to beliefs triggering various attempts of social control that would not otherwise have been attempted. Such a scenario is uniquely dependent on predictive profiling. To the extent that this scenario is considered possible—perhaps even likely—the predictive character of AI profiling makes an individual more exposed to attempts of social control. 4.2 The Exceptionalism of AI Profiling 2: Predictive Accuracy, Determinism, and Stigmatization The potential of AI profiling to make highly accurate predictions may also increase the risk of stigmatization. Although predictability and determinism are considered logically independent notions (Bishop, 2003; Rummens & Cuypers, 2010), they seem to play a similar role in our daily and practical lives. If someone’s behaviour and dispositions are fully predictable, then the common-sense interpretation of this is that the behaviour and dispositions could not have been otherwise—they are necessary and inescapable. The same holds for determinism. Fully determined behaviour or dispositions entail the inevitability of this behaviour and these dispositions. Why does it matter? Studies on public beliefs in genetic and social determinism, i.e. that genetic and social factors determine human behaviour and personality, show that such beliefs are associated with social cognitive effects such as negative stereotyping, the formation of prejudice, and tendencies to discriminate by confining the civil rights of others (Keller, 2005; Rangel & Keller, 2011). Furthermore, these studies also show that such beliefs are related to correlates of essentialist thinking, where the latter may be defined as the tendency of individuals to attribute to others an unalterable essence that makes them what they are and that explains their actions (Medin, 1989; Yzerbyt et al., 1997). In combination, these findings are taken to suggest a mechanism whereby individuals attribute to others an essential nature—a set of dispositions—to the extent they believe their behaviour and dispositions to be genetically and socially determined, and this attribution of essence results in negative stereotyping, the formation of prejudice, and tendencies to discriminate. The argument to be made here is simply this. If a belief in the predictability of behaviour and dispositions plays the same role as or may cause a belief in the determinism of behaviour and dispositions, then it may lead to essentialist thinking producing negative stereotyping and discrimination, which are defining components of stigmatization. AI profiling may produce highly accurate predictions and thus substantiate beliefs in the predictability of behaviour and dispositions. Hence, AI profiling may lead to stigmatization. The argument is somewhat speculative, and more conceptual and empirical work is certainly needed. However, note that it has some intuitive appeal. If we were to believe that the client in the public servant case or the prime minister candidate in the prime minister case was essentially and unalterably mentally ill, then it does not seem wholly implausible that this would lead to negative stereotyping and discrimination. If we believe others to be machines, then we will treat them as machines. If the argument holds, it goes to show specifically that the predictive accuracy of AI profiling makes individuals more exposed to stigmatization. 4.3 The Exceptionalism of AI Profiling 3: A Purely Feature-Driven Approach The arguments in the previous two sections have a similar structure. It has been argued that a special feature of AI models, i.e. predictive accuracy, in combination with certain assumptions about human belief formation makes profiled individuals more exposed to social control and stigmatization. However, there are other features of AI profiling that in and of themselves make profiled individuals more exposed to social control and stigmatization. AI modelling is versatile. Different predictive AI models can be trained on some data and subsequently applied to the same kind of data. In other words, it is possible to develop AI models that make different predictions based on the same input data. In the three cases, AI profiling based on publicly available photos and tweets serves the purpose of predicting mental health dispositions. The same publicly available data could potentially be used to predict other personal dispositions, including creditworthiness, risk of criminal behaviour and drug abuse, political leanings, and parental competencies. Any data made publicly available at any time could turn out to be a relevant input for an AI model that makes predictive profiling. The versatility of AI modelling implies that a vast amount of personal data may potentially be generated from limited publicly available data. The potential increase in the availability of personal data that may be used for the purpose of social control and stigmatization makes an individual more exposed to such interventions. Predictive AI profiling is human-unpredictable. AI profiling may reveal personal data that would otherwise be hidden from a human being. In the three cases, the mental dispositions are not available to any human seeing the photos or reading the tweets, including the individual making them publicly available. There are no human interpretable signs that suggest that photos and tweets contain reliable data on mental dispositions. But the mental dispositions are also human unpredictable in a deeper sense. Thus, any other nonautomated method for making the same predictions based on the available data, e.g. statistical modelling, would be bounded by the availability of human expertise and other humanly limitations and may not deliver the same accuracy. The human unpredictability of AI profiling makes an individual more exposed to social control and stigmatization for two reasons. Firstly, because the unpredictability impedes an individual’s ability to exercise self-protection by withholding data. If it is impossible to foresee what predictions can be made from a set of public data, individuals cannot withhold data that they believe may generate unwelcome attempts of social control and that they believe would place them in groups already stigmatized or likely to become stigmatized. Avoiding entirely to make any data public to anyone seems practically impossible in a modern-day society with the growing digitization of human relations. Second, because AI makes predictable what is humanly unpredictable, it removes the protection against social control and stigmatization that is tied to human unpredictability. That no human being may predict mental dispositions just by looking at photos and tweets and that other nonautomated methods are bounded by the availability of human expertise constitutes a protection of individuals against social control and stigmatization. It means that the predictions will not be generated and therefore cannot feed attempts of social control and stigmatization. AI technology and embedded models are highly transferable. Although the development of a high-performing AI model requires access to very large datasets, expert knowledge, hardware, and various other resources, the resulting model may be widely used by a host of different stakeholders. As imagined in the three cases, highly accurate predictive AI models may well be made available for public use. AI models differ in this respect from other technologies. Whole genome/exome sequencing is a comparable technology in that it can be used to map the complete DNA sequence of an individual from a sample of human tissue. This could, for instance, be human tissue left in public as fingerprints on a glass. The resulting genetic data can to some extent be used to make predictions about human dispositions and, in particular, disease risks. Contrary to AI technology, however, the whole genome/exome sequencing technology along with required lab facilities, biomedical expertise, etc. cannot be made publicly available. The inaccessibility of this technology appears to reduce the risk of being genetically profiled inadvertently, while the transferability of AI technology arguably increases the risk of being profiled by AI and thus increases the exposure of an individual to social control and stigmatization. Finally, AI predictive profiling goes beyond an individual. AI predictions of dispositions will in certain cases reveal personal data not only about individuals, but also about their relatives. An AI model that predicts that an individual is likely to develop diabetes 2—known to be partly heritable and partly due to lifestyle—will also, as a matter of fact, have revealed an increased risk of diabetes 2 among close relatives. Such inferences will be warranted to a very different degree. However, insofar as AI predictive profiling may reveal personal data about relatives, it makes those relatives more exposed to social control and stigmatization than they would otherwise have been. 5 Reasons for and Against Protecting Publicly Available Online Data The previous section provided ground for granting individuals a right not to be subjected to AI profiling. This article seeks, however, to sustain the right in relation to personal data made publicly available online, e.g. on social media platforms such as Twitter and Instagram. Notably, the availability of personal data on such platforms is to a large extent influenced by the data subjects themselves. If an individual refrains from any use of online services and social media platforms, little personal data would ceteris paribus be publicly available. In so doing individuals would therefore—presumably to a large extent—protect themselves against AI profiling based on online available, personal data. But if individuals may protect themselves against AI profiling by disengaging from online data sharing, then the right not to be AI profiled based on publicly available data seems to have been rendered somewhat superfluous. This section therefore explores, firstly, the reasons for protecting and promoting online data sharing and, secondly, the reasons for allowing AI profiling based on such data. 5.1 Social and Democratic Potentials of Online Data Sharing The online sharing of data may serve important social and democratic purposes. Socially, it can be used to build and maintain relationships. Research finds that socializing is a primary motivation for information sharing on social networking sites (SNS) (Kümpel et al., 2015). Studies also suggest that the use of SNS is positively related not only to the quality of friendships defined as satisfaction with friends, but also to social capital defined as the resources that accrue to an individual by virtue of his or her membership of a social network, e.g. the feeling of belonging to a community, the forming of new relationships, the feedback and support of other people in relation to various issues, and loneliness (Ahn, 2012; Antheunis et al., 2016; Brandtzæg, 2012; Ellison et al., 2007). Other studies indicate that social media use with close friends is positively associated with the experience of feeling close to those friends (Kahlow et al., 2020; Pouwels et al., 2021). Democratically, it may be used to form and express opinions, to share information, and to engage in collective reasoning involving decision-makers at all levels of society, and thus, it may ultimately increase participation in democratic processes. A meta-analysis found that social media use generally is positively—but modestly—related to various forms of both online and offline political participation, e.g. voting, supporting campaigns, and protest activities (Skoric et al., 2016). Consistent with the findings of a previous meta-analysis (Boulianne, 2009), it also found a positive—and moderate—relation between (1) the use of social media for informational purposes, i.e. seeking, gathering, and sharing of various kinds of information, and political participation, and (2) the use of social media for expressivist purposes, i.e. expressing oneself, articulating opinions, ideas, and thoughts, and political participation. Another meta-analysis similarly established a positive relationship between social media use and participation in political and civic life. However, the meta-analysis found it to be questionable whether such participation is a causal effect of social media use (Boulianne, 2015). Other studies suggest that online viewing and sharing of news are positively related to political knowledge (Beam, 2016). Minimally, the evidence cited suggests that certain kinds of online data sharing can, under certain conditions, serve valuable social and democratic purposes. If so, then we have reason to protect—perhaps even promote—these kinds of online data sharing. However, this requires that privacy concerns be accommodated because such concerns may lead to withdrawal from online data sharing. A recent study found that privacy concerns defined as concerns about losing control of personal data on social networks are negatively related to social media participation measured as the frequency of interactions on SNS (Bright et al., 2021). A similar study found that privacy concerns in relation to publicly available data are negatively associated with the amount and depth of personal data sharing on SNS (Gruzd & Hernández-García, 2018). What has been attempted here is to underpin two simple claims, namely that online engagement in the form of data sharing can serve valuable social and democratic purposes and that privacy concerns can lead to disengagement from online data sharing. If both claims are true, they provide us with a reason to address the concerns of individuals regarding privacy. They imply that disengagement from online data sharing is an undesirable solution to such privacy concerns. The upshot for AI profiling based on publicly available data is this. If individuals sometime in the future, when AI predictive profiling has become more widespread, become aware that their publicly available data can be used for profiling in unpredictable ways, there is a risk that this may lead to disengagement from online data sharing, also by prospective politicians and decision-makers. This is undesirable as it may impede the full realization of the social and democratic benefits of data sharing. While we have focused here on social and democratic aspects, there is also an extant literature on the health-related effects of social media usage. A recent umbrella review comparing five meta-analyses found that social media use is associated with higher levels of both well-being, i.e. happiness, positive affect, life satisfaction, and ill-being, i.e. i.e. depression, anxiety disorder, distress, and negative affect (Valkenburg et al., 2022). While such studies certainly add important nuances to the evidence on the effects of social media use, they do not rule the possibility that social media use may serve valuable social and democratic purposes. If privacy concerns—and in particular concerns related to AI profiling—can lead to disengagement from the relevant kinds of data sharing, there are substantial reasons for protecting such data sharing from AI profiling. 5.2 Other Trumping Concerns To fully substantiate the right not to be subjected to AI profiling based on publicly available, personal data, it remains to be considered whether other concerns may outweigh this right. These concerns may be related to specific purposes and contexts of AI profiling. Revisiting the three cases may therefore be helpful. AI predictive profiling makes an individual significantly more exposed to unacceptable forms of social control and stigmatization and self-stigmatization, and it may lead to withdrawal from online data sharing otherwise conducive to social thriving and democratic health. As such, AI predictive profiling is a threat to basic human autonomy and wellbeing, as well as social life and democracy. These harms impose a burden of proof on the defender of the right to conduct such profiling in the three cases. For each case, the defender of AI profiling based on publicly available data must show either (1) that the harms of AI profiling are unlikely to obtain in the three cases and/or (2) that AI profiling without consent is a proportional measure, where this requires (A) that the benefits of doing AI profiling without consent outweigh the potential harms and (B) that AI profiling without consent is strictly necessary in order to obtain the benefits. Consider the friends case. That household profiling should be harmless is not a credible proposition. There are no a priori reasons to think that profiling of friends and family members is not as likely to lead to overreaching social control and stigmatization as in any other case. Note that the effects of stigmatization do not require stigmatizing behaviour by friends and family. It only requires that a certain feature is stigmatized in the wider society. Consider now the benefits and the necessity of conducting the AI profiling. The benefit of the profiling is an accurate diagnosis that A may use to motivate B and B’s family to seek further health care assistance. Note that this benefit could likely have been achieved by less invasive alternative means. A could simply have presented B and B’s family with the suspicion of B having mental health issues. Note also that whether or not the AI profiling is necessary, it is still an open question, who should decide the weight of the benefits and harms? There are at least two reasons why B should decide the weight of the benefits and harms, i.e. that B should have a right to provide or deny informed consent to AI profiling based on publicly available data. Firstly, because the benefits and harms of the AI profiling are relative to B’s interests in getting the profiling data or maintaining privacy, B is ceteris paribus the best positioned to determine B’s interests and their weight. Secondly, because the potential harms to B—i.e. social control and stigmatization—for all we know are significant harms. They are ways of impacting others that run counter to fundamental values in our society, and it seems to be an equally fundamental principle that generally—if not always—when individuals are at risk of suffering significant harms, they should have the right to protect themselves against these harms. In the public servant case, there is also the risk of overreaching social control and stigmatization. Psychiatric diagnoses are sticky labels that will form the way individuals are handled in the public system in the short- and long-term, and this carries a latent risk of producing overreaching social control. It may also lead to stigmatization and not least self-stigmatization. In this case, however, there are potential benefits both for the profiled individual and the public authorities. Thus, the diagnosis may not only come to benefit client B in terms of more adequate health care and social benefits, but it may also increase the efficiency of the social services by making more readily available personal health care information needed for an adequate distribution of social benefits. AI profiling based on publicly available data may be considered necessary in the sense of being a precondition of a maximally efficient public administration, but it is not necessary in the sense that there are no alternative ways of getting access to the information produced by the AI profiling. Thus, the benefits of such AI profiling for public administration and the wider society may ultimately be marginal. In any case, it seems as if such benefits are morally incomparable to the list of potential harms of AI profiling, including the potential harms to B. As argued above, the potential harms to client B speaks in favour of granting B the right to provide or deny informed consent to such profiling. The prime minister case may for two interrelated reasons be taken to present a more fundamental problem for the attempt to ground a sui generis right not to be AI profiled. Thus, it may be argued that information about the mental health of the prime minister candidate is of public interest and that the public therefore have a right to this information. Relatedly, it may be argued that the AI profiling is covered by the right to freedom of expression. After all the concerned citizen is in this case profiling the candidate with the intent of voicing a concern over the fitness of the candidate for political office. Access to information of public interest and the right to free speech are undeniably instrumental to a flourishing democracy. However, what we have been arguing in this article is that AI profiling is not only a continuous threat to individual autonomy, wellbeing, and social life, but that it may also threaten democratic processes by potentially leading people to withdraw from the use of social media. Decision-makers, including the prime minister candidate, may withdraw from social media exchanges with the public, and in the longer run, the threat of being AI profiled for all sorts of dispositions may prevent people from engaging in politics altogether. Therefore, it remains to be shown how and why a right not to be AI profiled based on publicly available data limits freedom of expression and information in any profound sense, and why such limitation outweighs the negative effects of AI profiling on human autonomy and wellbeing as well as on social flourishing and democracy. Simply flagging the right to freedom of expression and information cannot reasonably be thought to do the job. Relevant for the attempt to weigh benefits and harms in all three cases is the accuracy of the predictions of mental disorders AI model Deepmood. Thus, it may be asserted that a predictive accuracy, i.e. sensitivity and specificity, above that of health care professionals could and would increase the benefits to individuals and society in all three cases—and vice versa. In short, the accuracy of AI models should be a parameter for any attempt to weigh benefits and harms. The evidence cited in the opening lines of the article suggests that available models for predicting mental disorders perform better than unassisted physicians. A recent meta-analysis of the accuracy of AI diagnostic systems in the context of medical imaging and histopathology found the performance of deep-learning models to be equivalent to that of healthcare professionals (Liu et al., 2019). Others have pointed out that the presumption of accuracy may not hold (Hofmann, 2022). Two observations should be made here. Firstly, as argued in a previous section, there are reasons to believe that an increased accuracy will likely drive stronger attempts of social control and increased stigmatization. One may also hypothesize that increased accuracy will drive increased disengagement from online data sharing. Whether or not the benefits and harms will increase with an increased accuracy is ultimately to be settled empirically. For present purposes, it should simply be noted that an increased accuracy does not necessarily make a difference for the balancing of benefits and harms in the three examples. Secondly, as argued right above, there are strong reasons for believing that the weighing of benefits and harms should in many cases befall the individual. The weight of benefits and harms—including the chance of obtaining the benefits and suffering the harms (accuracy)—cannot be separated from the interests of individuals and not in cases where the individual may come to suffer significant harms. In conclusion, the arguments presented here suggest that individuals should have a right not to be AI profiled in all three cases. While the right not to be AI profiled based on publicly available data admittedly is a pro tanto right, what is claimed here is that none of the three cases seem to qualify as exemptions from this right. 6 The GDPR and the Right not to be AI Profiled For the overall purpose in this article of establishing the need for a sui generis legal right not to be AI profiled, it remains to be considered whether current legislation already incorporates such a right. Within the EU, privacy rights in relation to automated profiling and data use are covered in the EU General Data Protection Regulation (GDPR) (General Data Protection Regulation, 2016). The GDPR contains no explicit provisions granting individuals a sui generis right not to be AI profiled. It may, however, entail a prohibition against this type of profiling and hence indirectly establish such a right in relation to the three cases. 6.1 Two Approaches to Deciding the Implications of the GDPR AI profiling for mental health disorders based on publicly available social media data is a type of data processing involving both personal data and special categories of personal data, i.e. health data. The GDPR contains a general prohibition against the processing of special categories of personal data such as health data, but lists several exemptions in article 9, including the use of special categories of personal data that have manifestly been made public by the data subject. Further processing of personal data must abide by the principles in article 5. In short, personal data must (a) be processed lawfully, fairly, and transparently; (b) be collected and used in relation to a specific purpose; (c) be limited to what is necessary for the specific purpose; (d) be accurate; (e) be anonymized or erased when the processing of identifiable data is no longer necessary; and (f) be processed securely. Article 6 lists lawful types of data processing and includes among these processings necessary to carry out a task of public interest or in the exercise of official authority. The fairness and transparency requirements are specified in articles 12 and 13. They may for present purposes be summarized as the requirement that the data subject is appropriately informed about the processing of personal data. In the attempt to decide if the GDPR entails a right not to be AI profiled in the three cases, different approaches may be taken. One approach would be to analyze if the relevant examples of AI profiling can or cannot satisfy the aforementioned processing principles of the GDPR. If they cannot, the GDPR would effectively entail a right not to be AI profiled. Another approach—the one pursued here—would be to consider the scope of the principles and the extent to which the GDPR allows for them to be restricted. If the three cases fall outside the scope of the principles or they may be relevantly restricted, the GDPR would not ensure a right not to be AI profiled in the three cases. 6.2 The Three Cases and the Scope and Potential Restrictions of the GDPR Processing Principles The AI profiling in the friends case presumably falls outside the scope of the GDPR. According to article 2, the GDPR does not apply to the processing of personal data in relation to purely personal or household activities that have no connection to professional or commercial activities. In the friends case, the processing seems most adequately classified as a case of processing for the sake of personal and household activities. It clearly has no connection to professional or commercial activities. In consequence, the processing requirements do not apply to the friends case, and the mental health profiling would be wholly lawful. Pertinent to the public servant case, the GDPR allows for national adaptions of the processing principles in article 5 (see above). Thus, article 6 stipulates that member states may introduce more specific provisions with respect to data processing necessary for the performance of a task carried out in the public interest or in the exercise of official authority. Article 23 allows member states to restrict legislatively the processing obligations in articles 12–22 if this is necessary for safeguarding other important objectives of the general public interest, including financial interests related to public health and social security. With reference to the preamble no. 10, article 6 and article 23, the Danish Parliament for instance in late 2021 adopted a legislative proposal permitting the national tax authorities to collect ‘blindly’ all types of personal data publicly available on social media platforms and to use these data for risk profiling of all citizens (Lov om ændring af lov om et indkomstregister, skatteindberetningsloven og skattekontrolloven, 2021). The only requirement is that the authorities consider the data and profiling necessary for carrying out a task, e.g. the detection of taxation fraud. Analogously, the AI profiling in the public servant case may be considered necessary for carrying out a task of the social services and for maintaining an efficient public administration, and such profiling could reasonably be seen as protecting a financial interest related to social security. The conditions for restricting the processing principles are thus likely to be met in cases like the public servant case, and the GDPR therefore does not ensure individuals a right not to be AI profiled in such cases. Finally, article 85 of the GDPR requires member states to reconcile the data protection regulation with the right to freedom of expression and information, where this includes the right to process data for journalistic purposes. As also stated in article 85, such processing may require that member states provide for exemptions and derogations from, among others, the processing principles in article 5. The GDPR thus allows for exemptions in cases like the prime minister case, where the mental health of the candidate arguably is of public interest. Hence, the GDPR does ensure political candidates a right not to be AI profiled in such cases. 6.3 Advantages of an Explicit Sui Generis Right not to be AI Profiled Without considering the implications of the processing principles for the three cases, it has nonetheless been argued here that the GDPR does not ensure a right not to be AI profiled in the three cases. But even if the processing principles could be shown to entail a right not to be AI profiled in the three cases and even if all of the above arguments suggesting that the processing principles may be restricted in relation to these cases fail, there may still be reasons for introducing an explicit sui generis right not to be AI profiled into AI legislation. First, the cases do not exhaust the space of the potential use of profiling, which may for instance also be used by employers for recruitment and selection processes and for various other forms of workforce management (Hunkenschroer & Luetge, 2022; Kim & Bodie, 2021). Second, the severity of the potential harms of AI profiling based on publicly available data suggest that in the future, where AI predictive profiling may have become publicly accessible, there is a need of legislation that is effective in regulating our profiling behaviour. One may venture that a rather simple right that unambiguously and unquestionably rules out most cases of AI profiling is more effective than a data protection regulation with negotiable implications and the possibility of special national adaptions. By introducing such a right, an important and complex legal question would a priori have been settled, and this arguably makes a difference for the regulatory effect of legislation. 7 Conclusion—Future Research This article has substantiated the right not to be subjected to AI profiling based on publicly available data. This right entails that such profiling cannot be conducted without the explicit informed consent of the profiled subject. The line of argument pursued in this article raises several questions that warrant further discussion. Why a right? Even if the gravity of the potential harms of AI profiling is acknowledged, it may still be considered an open question whether such harms should be addressed through a right or some other type of regulation prohibiting such profiling in one way or another. As was previously argued, the right not to be AI profiled without informed consent may be taken to follow from an individual’s right to protect their interests and their right to protect themselves against harm. It should also be noted, however, that a right of this kind so to speak ‘democratises’ regulation. It does not confine AI regulation to designated institutions and professions endowed with the competence and obligation to monitor and control AI development and use, but rather, it gives every individual an instrument for the control of AI use. In so doing, a right may increase the regulatory effectiveness over and above alternative types of regulation. This argument cannot be fully developed in this article but should be explored in future work. Why a pro tanto right? From the outset of this article, the right not to be AI profiled has been suggested as a conditional right. Yet the potential exemptions from this right have not been specified. On the contrary, it has been argued that some of the obvious exemptions—e.g. freedom of expression and information—do not constitute reasonable exemptions. This question also warrants further work. The reason for making this choice here is twofold. We have in this article at no point argued that there are no exemptions to this right. Relatedly, it seems that it is always possible to design situations constituting exemptions to such rights. For instance, threats to national security or threats of terrorism could be candidates for making up such exemptions. Why informed consent? The right not to be AI profiled can be waived through informed consent. Some would object that the provision of informed consent to data processing is highly routinized, i.e. provided as an unreflected, habitual act, and that the right not to be AI profiled as a consequence may lack any real power to protect individuals (Ploug & Holm, 2013, 2015). The extent to which the problems of routinization may be overcome through careful design of the consent situation is a matter for future (empirical) work. The position taken in this article is that the weighing of the potential benefits and harms of AI profiling cannot be done ethically adequate without the involvement of the individuals potentially being profiled. The legitimacy of subjecting individuals to AI profiling at least partly derives from their involvement in the decision to do the profiling. As such informed consent is simply ethically necessary. The requirement of informed consent may not be sufficient to protect individuals from the potential harms of AI profiling. Other types of regulation protecting individuals from such harms may certainly be needed. Not least—as some have argued—because the requirement of informed consent may be a burden to individuals (Vredenburgh, 2022). Finally, in the course of substantiating a sui generis right not to be AI profiled based on publicly available data, we have suggested several behavioural mechanisms and patterns that underlie social control and stigmatization and provided relevant evidence to the best of our ability. There is a need for further empirical studies on these matters. Note, however, that in the attempt to build our arguments around actual behavioural patterns and mechanism, this article constitutes a contribution to evidence-based policymaking in the field of privacy rights. Data Availability Not applicable. Abbreviations AI : Artificial intelligence GDPR : EU General Data Protection Regulation EU : European Union SNS : Social networking sites References Ahn, J. (2012). Teenagers’ experiences with social network sites: Relationships to bridging and bonding social capital. The Information Society, 28(2), 99–109. Article Google Scholar Amini, H., Mohammadi, E., & Kosseim, L. (2022). Quick and (maybe not so) easy detection of anorexia in social media: To explainability and beyond, 141–158. In F. Crestani, D. E. Losada, & J. Parapar (Eds), Early Detection of Mental Health Disorders by Social Media Monitoring: The First Five Years of the eRisk Project . Springer International Publishing. Antheunis, M. L., Schouten, A. P., & Krahmer, E. (2016). The role of social networking sites in early adolescents’ social lives. The Journal of Early Adolescence, 36(3), 348–371. Article Google Scholar Appel, M., & Weber, S. (2021). Do mass mediated stereotypes harm members of negatively stereotyped groups? A meta-analytical review on media-generated stereotype threat and stereotype lift. Communication Research, 48(2), 151–179. Article Google Scholar Beam, M. A. (2016). Clicking vs. sharing: The relationship between online news behaviors and political knowledge. Computers in Human Behavior, 59, 215–220. Beauchamp, T. L., & Childress, J. F. (2001). Principles of biomedical ethics (5th ed). Oxford University Press, New York. Bhugra, D. (1989). Attitudes towards mental illness. Acta Psychiatrica Scandinavica, 80(1), 1–12. Article Google Scholar Bishop, R. C. (2003). On separating predictability and determinism. Erkenntnis, 58, 169–188. Article Google Scholar Boulianne, S. (2009). Does internet use affect engagement? A meta-analysis of research. Political Communication, 26(2), 193–211. Article Google Scholar Boulianne, S. (2015). Social media use and participation: A meta-analysis of current research. Information, Communication & Society, 18(5), 524–538. Article Google Scholar Brandtzæg, P. B. (2012). Social networking sites: Their users and social implications A longitudinal study. Journal of Computer-Mediated Communication, 17, 467–488. Article Google Scholar Bright, L. F., Lim, H. S., & Logan, K. (2021). “Should I Post or Ghost?”: Examining how privacy concerns impact social media engagement in US consumers. Psychology & Marketing, 38(10), 1712–1722. Article Google Scholar Coppersmith, G., Leary, R., Crutchley, P., & Fine, A. (2018). Natural language processing of social media as screening for suicide risk. Biomedical Informatics Insights, 10, 1–11. Article Google Scholar Corrigan, P. W., Larson, J. E., & Rüsch, N. (2009). Self-stigma and the “why try” effect: Impact on life goals and evidence-based practices. World Psychiatry, 8(2), 75–81. Article Google Scholar Crandall, C. S., & Coleman, R. (1992). Aids-related stigmatization and the disruption of social relationships. Journal of Social and Personal Relationships, 9(2), 163–177. Article Google Scholar Druss, B. G., Zhao, L., Von Esenwein, S., Morrato, E. H., & Marcus, S. C. (2011). Understanding excess mortality in persons with mental illness: 17-year follow up of a nationally representative US survey. Medical Care, 49(6), 599–604. JSTOR. Article Google Scholar Ellison, N. B., Steinfield, C., & Lampe, C. (2007). The benefits of Facebook “Friends:” Social capital and college students’ use of online social network sites. Journal of Computer-Mediated Communication, 12(4), 1143–1168. Article Google Scholar Evans, J. P., & Burke, W. (2008). Genetic exceptionalism. Too much of a good thing? Genetics in Medicine, 10(7), Art. 7. Article Google Scholar Feinberg, J. (1980). The child’s right to an open future, 76-97. In Feinberg, J. (1992). Freedom and Fulfillment: Philosophical Essays. Princeton University Press, New Jersey. Frederick, D. (2014). Pro-tanto versus absolute rights. The Philosophical Forum, 45(4), 375–394. Article Google Scholar Garrett, J. R., Lantos, J. D., Biesecker, L. G., Childerhose, J. E., Chung, W. K., Holm, I. A., Koenig, B. A., McEwen, J. E., Wilfond, B. S., & Brothers, K. (2019). Rethinking the “open future” argument against predictive genetic testing of children. Genetics in Medicine, 21(10), 2190–2198. Article Google Scholar Gkotsis, G., Oellrich, A., Velupillai, S., Liakata, M., Hubbard, T. J. P., Dobson, R. J. B., & Dutta, R. (2017). Characterisation of mental health conditions in social media using Informed Deep Learning. Scientific Reports, 7(1), Art. 1. Google Scholar Goffman, E. (1963). Stigma: Notes on the management of spoiled identity. Simon & Schuster, New York. Goldstein, J. (1991). The stigmatization of smokers: An empirical investigation. Journal of Drug Education, 21(2), 167–182. Article Google Scholar Gruzd, A., & Hernández-García, Á. (2018). Privacy concerns and self-disclosure in private and public uses of social media. Cyberpsychology, Behavior, and Social Networking, 21(7), 418–428. Article Google Scholar Herek, G. M. (1999). AIDS and stigma. American Behavioral Scientist, 42(7), 1106–1116. Article Google Scholar Hilbert, A., Rief, W., & Braehler, E. (2008). Stigmatizing attitudes toward obesity in a representative population-based sample. Obesity, 16(7), 1529–1534. Article Google Scholar Hofmann, B. (2022). Too much, too mild, too early: Diagnosing the excessive expansion of diagnoses. International Journal of General Medicine, 15, 6441–6450. Article Google Scholar Hunkenschroer, A. L., & Luetge, C. (2022). Ethics of AI-enabled recruiting and selection: A review and research agenda. Journal of Business Ethics, 178, 977–1007. Article Google Scholar Jobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399. Article Google Scholar Kahlow, J. A., Coker, M. C., & Richards, R. (2020). The multimodal nature of Snapchat in close relationships: Toward a social presence-based theoretical framework. Computers in Human Behavior, 111, 106409. Article Google Scholar Keller, J. (2005). In genes we trust: The biological component of psychological essentialism and its relationship to mechanisms of motivated social cognition. Journal of Personality and Social Psychology, 88(4), 686–702. Article Google Scholar Kim, P., & Bodie, M. T. (2021). Artificial intelligence and the challenges of workplace discrimination and privacy. 35 ABA Journal of Labor and Employment Law 289 Saint Louis U Legal Studies Research Paper No, 2021–26, 289–315. Google Scholar Kim, J., Lee, J., Park, E., & Han, J. (2020). A deep learning model for detecting mental illness from user content on social media. Scientific Reports, 10(1), Art. 1. Google Scholar Kumar, A., Sharma, A., & Arora, A. (2019). Anxious depression prediction in real-time social data. Proceeding of International Conference on Advanced Engineering, Science, Management and Technology, 1–7. Kümpel, A. S., Karnowski, V., & Keyling, T. (2015). News sharing in social media: A review of current research on news sharing users, content, and networks. Social Media + Society, 1(2), 2056305115610141. Article Google Scholar Leino-Kilpi, H., Välimäki, M., Dassen, T., Gasull, M., Lemonidou, C., Scott, A., & Arndt, M. (2001). Privacy: A review of the literature. International Journal of Nursing Studies, 38(6), 663–671. Article Google Scholar Link, B. G. (1987). Understanding labeling effects in the area of mental disorders: An assessment of the effects of expectations of rejection. American Sociological Review, 52(1), 96–112. JSTOR. Article Google Scholar Link, B. G., & Phelan, J. C. (2001). Conceptualizing stigma. Annual Review of Sociology, 27, 363–385. Liu, X., Faes, L., Kale, A. U., Wagner, S. K., Fu, D. J., Bruynseels, A., Mahendiran, T., Moraes, G., Shamdas, M., Kern, C., Ledsam, J. R., Schmid, M. K., Balaskas, K., Topol, E. J., Bachmann, L. M., Keane, P. A., & Denniston, A. K. (2019). A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: A systematic review and meta-analysis. The Lancet Digital Health, 1(6), e271–e297. Article Google Scholar Lov om ændring af lov om et indkomstregister, skatteindberetningsloven og skattekontrolloven, nr. L 73, 1 (2021). https://www.ft.dk/ripdf/samling/20211/lovforslag/l73/20211_l73_som_fremsat.pdf McGuire, A. L., Fisher, R., Cusenza, P., Hudson, K., Rothstein, M. A., McGraw, D., Matteson, S., Glaser, J., & Henley, D. E. (2008). Confidentiality, privacy, and security of genetic and genomic test information in electronic health records: Points to consider. Genetics in Medicine, 10(7), 495–499. Article Google Scholar Medin, D. L. (1989). Concepts and conceptual structure. American Psychologist, 44(12), 1469–1481. Article Google Scholar Mojtabai, R., Olfson, M., Sampson, N. A., Jin, R., Druss, B., Wang, P. S., Wells, K. B., Pincus, H. A., & Kessler, R. C. (2011). Barriers to mental health treatment: Results from the National Comorbidity Survey Replication. Psychological Medicine, 41(8), 1751–1761. Article Google Scholar Myers, A., & Rosen, J. C. (1999). Obesity stigmatization and coping: Relation to mental health symptoms, body image, and self-esteem. International Journal of Obesity, 23(3), 221–230. Article Google Scholar Nozick, R. (1969). Coercion, 440-472. In Morgenbesser, W. (Ed). Philosophy, Science, and Method: Essays in Honor of Ernest Nagel. St Martin's Press. Peretti-Watel, P., Legleye, S., Guignard, R., & Beck, F. (2014). Cigarette smoking as a stigma: Evidence from France. International Journal of Drug Policy, 25(2), 282–290. Article Google Scholar Ploug, T. (2020). In Defence of informed consent for health record research—Why arguments from ‘easy rescue’, ‘no harm’ and ‘consent bias’ fail. BMC Medical Ethics, 21(1), 75. Article Google Scholar Ploug, T., & Holm, S. (2013). Informed consent and routinisation. Journal of Medical Ethics, 39(4), 214–218. Article Google Scholar Ploug, T., & Holm, S. (2015). Routinisation of informed consent in online health care systems. International Journal of Medical Informatics, 84(4), 229–236. Article Google Scholar Ploug, T., Holm, S., & Gjerris, M. (2015). The stigmatization dilemma in public health policy-the case of MRSA in Denmark. BMC Public Health, 15(1), 640. Article Google Scholar Pouwels, J. L., Valkenburg, P. M., Beyens, I., van Driel, I. I., & Keijsers, L. (2021). Social media use and friendship closeness in adolescents’ daily lives: An experience sampling study. Developmental Psychology, 57(2), 309. Article Google Scholar Powers, P. (2007). Persuasion and coercion: A critical review of philosophical and empirical approaches. HEC Forum, 19(2), 125–143. Article Google Scholar Rangel, U., & Keller, J. (2011). Essentialism goes social: Belief in social determinism as a component of psychological essentialism. Journal of Personality and Social Psychology, 100(6), 1056. Article Google Scholar Reece, A. G., & Danforth, C. M. (2017). Instagram photos reveal predictive markers of depression. EPJ Data Science, 6(1), 15. Article Google Scholar Reece, A. G., Reagan, A. J., Lix, K. L. M., Dodds, P. S., Danforth, C. M., & Langer, E. J. (2017). Forecasting the onset and course of mental illness with Twitter data. Scientific Reports, 7(1), Art. 1. Article Google Scholar Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation), OJ L 119, (2016). http://data.europa.eu/eli/reg/2016/679/oj Rummens, S., & Cuypers, S. E. (2010). Determinism and the paradox of predictability. Erkenntnis, 72(2), 233–249. Article Google Scholar Skoric, M. M., Zhu, Q., Goh, D., & Pang, N. (2016). Social media and citizen engagement: A meta-analytic review. New Media & Society, 18(9), 1817–1839. Article Google Scholar Stuart, H. (2006). Mental illness and employment discrimination. Current Opinion in Psychiatry, 19(5), 522–526. Article Google Scholar Stuber, J., Meyer, I., & Link, B. (2008). Stigma, prejudice, discrimination and health. Social Science & Medicine, 67(3), 351–357. Article Google Scholar Stuber, J., Galea, S., & Link, B. G. (2009). Stigma and smoking: The consequences of our good intentions. Social Service Review, 83(4), 585–609. Article Google Scholar Valkenburg, P. M., Meier, A., & Beyens, I. (2022). Social media use and its impact on adolescent mental health: An umbrella review of the evidence. Current Opinion in Psychology, 44, 58–68. Article Google Scholar Voorhees, B. W. V., Fogel, J., Houston, T. K., Cooper, L. A., Wang, N.-Y., & Ford, D. E. (2005). Beliefs and attitudes associated with the intention to not accept the diagnosis of depression among young adults. The Annals of Family Medicine, 3(1), 38–46. Article Google Scholar Vredenburgh, K. (2022). The right to explanation*. Journal of Political Philosophy, 30(2), 209–229. Article Google Scholar Wertheimer, A. (1990). Coercion. Princeton University Press. Book Google Scholar Yzerbyt, V., Rocher, S., & Schadron, G. (1997). Stereotypes as explanations: A subjective essentialistic view of group perception, 20-50. In R. Spears, P. J. Oakes, N. Ellemers, & S. A. Haslam (Eds.). The social psychology of stereotyping and group life. Blackwell Publishing. Zirikly, A., Resnik, P., Uzuner, Ö., & Hollingshead, K. (2019). CLPsych 2019 Shared task: Predicting the degree of suicide risk in Reddit posts, 24-33. Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology. Minneapolis, Minnesota. Download references Acknowledgements I would like to thank Hanne Marie Motzfeld and Søren Holm for their valuable and insightful comments. Author information Authors and Affiliations Centre for Applied Ethics and Philosophy of Science, Department of Communication and Psychology, Aalborg University, A C Meyers Vænge, 2450, Copenhagen, SV, Denmark Thomas Ploug Contributions Not applicable. Corresponding author Correspondence to Thomas Ploug. Ethics declarations Ethics Approval and Consent to Participate Not applicable. Consent for Publication Not applicable. Competing Interests The author declares no competing interests. Additional information Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Rights and permissions Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. Reprints and permissions About this article Cite this article Ploug, T. The Right Not to Be Subjected to AI Profiling Based on Publicly Available Data—Privacy and the Exceptionalism of AI Profiling. Philos. Technol. 36, 14 (2023). https://doi.org/10.1007/s13347-023-00616-9 Download citation Received10 October 2022 Accepted22 February 2023 Published07 March 2023 DOIhttps://doi.org/10.1007/s13347-023-00616-9 Keywords Artificial intelligence Privacy Right not to be profiled Social control Stigmatization Use our pre-submission checklist Avoid common mistakes on your manuscript.",
    "commentLink": "https://news.ycombinator.com/item?id=40597503",
    "commentBody": "The right not to be subjected to AI profiling based on publicly available data (springer.com)161 points by tokai 4 hours agohidepastfavorite121 comments michaelt 4 hours agoI think there are qualitative differences that arise from incremental, quantitative changes in privacy. Sure, in the 1970s the cops could follow you around any time you were out in public. But they needed 6+ cops to provide round-the-clock surveillance, with an annual cost in the high six figures. So the average citizen's privacy was protected not by law or high-minded ideals about privacy, but by simple numbers. There weren't enough cops to follow even 0.1% of the population. But in the modern age of smartphones and license plate recognition and credit reference agencies? I think there's a strong argument to be made that we need new laws and new rights to reflect the new reality, where tracking people around the clock is several orders of magnitude cheaper. reply cortesoft 2 hours agoparentI also think the laws need to change with changing technology. Take something like speeding. We have speed limits and fines set based on the idea that cops won't catch most speeders and that cops can give leeway based on the situation (driving 10 mph over the speed limit on an empty straight highway is different than driving 10 mph over the speed limit weaving in heavy traffic). We set a relatively low max speed and a high penalty, because you are only going to be pulled over a fraction of the time. Then we roll out speed cameras which can catch people EVERY time they speed. It doesn't make sense to have the limits as low and the fines as high when every single person that goes over the limit can be fined. We have to tune the laws for perfect enforcement. This is true for a lot of laws... most are designed based on the enforcement capabilities of the time. We need to adjust for technology. reply Animats 4 minutes agorootparent> Then we roll out speed cameras which can catch people EVERY time they speed. Hikvision, in China, has a comprehensive system for this.[1] Hikvision has other monitoring tools. Here's their Behavior Analysis Server data sheet. It's a 1U server for monitoring people.[2] Hikvision Behavior Analysis Server Based on the latest intelligent algorithm of deep learning, Behavior Analysis Server with a high-density GPU architecture supports the detection of behavior events in the perimeter, street, densely populated areas, indoor and other places, and triggers alarms in a timely manner, which can effectively improve the security of various places. Behavior Analysis Server can detect the specific behaviors of individuals and groups in the perimeter, street, densely populated areas, indoor and other places, and provide professional video intelligent analysis applications: * Perimeter Protection -- Real-time detection and alarming of events such as line crossing, area intrusion, region entrance/exiting, loitering, parking, unattended baggage or object removal. * Trend Analysis -- Real-time detection and alarming of people density, real-time people counting statistics and people counting statistics. * Street Behavior Detection -- Real-time detection and alarming of events such as fast moving, physical conflict, people gathering or falling down. * Indoor Behavior Detection -- Real-time detection and alarming of events such as getting up, key person getting up, climbing, absence or sleep on duty, abnormal number of people, overstaying, sudden change of sound intensity, regional overstaying, physical conflict, standing up, sitting, or people counting. [1] https://www.youtube.com/watch?v=Uh8DBYuDZyo [2] https://www.hikvision.com/content/dam/hikvision/products/S00... reply itake 11 minutes agorootparentprevLow fines would turn the entire highway into a paid express lane, with the only limit being the driver's personal safety risk limit. reply lancesells 2 hours agorootparentprev> We set a relatively low max speed and a high penalty I'm in the US and speeding is a leading cause of death. Driving deaths are increasing so I don't know if having less or no cameras is a good thing. reply hn8305823 12 minutes agorootparentTraffic accidents and deaths are rising because of phones. I think we actually \"won\" the war on drunk driving, only to have a new war set upon us. Collision energy and thus damage increases with the square of speed (or ~speed^4 for head-on) so there is still an interest in controlling speed. Most drivers (especially those over 35yo) will auto-regulate their speed to the optimal (safety vs throughput) for the road design. The problem is the ones who don't. Speed limits are set lower than this optimal speed, partly to make it easier to stop and charge drivers that can't auto-regulate well. During the 1970's oil crisis, highway speeds were capped at 55 mph nationwide. It took several decades for this to reverse and only after safety studies showed that differential speeds (those obeying and those going the optimal natural speed for the road) is a significant contributing factor in crashes. Unfortunately, speeds limits are often below optimal because of an assumption that every driver will always go at least 5mph over the limit (which is incorrect). On 70 mph interstates away from urban/commuter traffic (where time pressures often affect driving), It's not unusual to see some cars going 5mph below the limit. That is a sign that these Interstate segments have the optimal natural speed (and design analysis confirms that). reply jgeada 2 hours agorootparentprevNot sure if speeding is the leading cause of death or just gets the blame. The standard of driving in the US is abysmal and getting worse. US rates of accidents and deaths are much much higher than anywhere in Europe. In my state, everyone speeds 10-15mph above the posted limits on highways. But the people that cause everyone around them to maneuver aren't the speeders, it is the people driving the posted limits and creating a bottleneck on the highway. And the number of rear end collisions caused by distracted drivers looking at screens instead of paying attention to their driving is the type of driving incident I see most often. reply throwup238 30 minutes agorootparent> And the number of rear end collisions caused by distracted drivers looking at screens instead of paying attention to their driving is the type of driving incident I see most often. Talk to anyone on a motorcycle, especially in states where they're allowed to lane split. Almost everyone is on their phones. Almost all the time. reply dylan604 13 minutes agorootparentI personally think if you are at fault because you were on your phone, you should lose your license and the device for a period of time. After that timeout period, you then have to pay for a device to be installed in your car that forces you to place your device in it that prevents it from being used as anything similar to a breathalyzer ignition lockout. People will not put down their devices with the current no consequence state we find ourselves now. reply lukas099 1 hour agorootparentprevIMO the blame of such maneuvering is on the speeders, even if non-speeders are in the minority. reply shadowgovt 2 hours agorootparentprevIIUc in a lot of cases, they can now know speeding was a factor because (ironically given this post's topic) the black boxes in the vehicles involved plus nearby surveillance tools the vehicles passed or had an accident in view of give hard evidence someone was speeding. i.e. \"We used to believe lies about how people drive, but thanks to the presence of more concrete evidence we are disproving those false assumptions.\" One of the things Alphabet discovered early on in the Waymo experiment that was an eye-opener to the whole industry is that auto accidents were probably underestimate by a factor of three. When they started rolling out vehicles on the road, the best numbers available for accidents-per-mile were insurance reports and NHTSA incident records. Having vehicles with cameras on the road continuously revealed that there were 300% more accidents than those numbers suggested because humans are bumping into each other due to mis-estimates at stoplights all the time, but nobody wants their insurance rates to go up so they just don't report those incidents. What if ubiquitous mass surveillance is good actually because it forces us to come to grips with realities we'd rather pretend are otherwise? reply furyofantares 1 hour agorootparent> IIUc in a lot of cases, they can now know speeding was a factor because (ironically given this post's topic) the black boxes in the vehicles involved plus nearby surveillance tools the vehicles passed or had an accident in view of give hard evidence someone was speeding. Base rate matters though; for example if literally everyone is speeding because speed limits are too low then every accident will involve someone speeding. reply dylan604 10 minutes agorootparent> for example if literally everyone is speeding because speed limits are too low is that really the case though, or is it people are so self involved that they feel they are too important to have to move that slowly? Just because everyone else is speeding does not automatically mean that faster speed is safe. It could also just be that people are assholes and they do what they want. reply ryandrake 31 minutes agorootparentprevYes, it's a tautology. If your definition of speeding is a speed beyond which 90% of motorists drive, then of course about that many accidents will \"involve speeding.\" reply salawat 1 hour agorootparentprev>What if ubiquitous mass surveillance is good actually because it forces us to come to grips with realities we'd rather pretend are otherwise? Then it still isn't good. The downsides outweigh the upsides. reply cortesoft 1 hour agorootparentprevSpeeding is dangerous, but almost all traffic engineers say that speed limits don't always match what the safe driving speed is. I think you are already doing subconciously what i am talking about; you are thinking of speeding, but I doubt you are thinking of someone driving 50 mph in a 45mph zone. That is not the type of speeding that kills, but would be the type that could be caught with perfect enforcement. reply MereInterest 39 minutes agorootparent> but I doubt you are thinking of someone driving 50 mph in a 45mph zone. That is not the type of speeding that kills I know you're pulling this up as an example of a small infringement, but there are studies that quantify the fatality rate as a function of velocity. The numbers you picked are right in the steepest part of the increase. Using equation 2.3 from [0] (with conversions from mph to kph), there's a 64% chance of fatality at 45mph, but a 83% chance of fatality at 50mph. [0] https://nacto.org/docs/usdg/relationship_between_speed_risk_... reply meowster 2 hours agorootparentprevDo you have a citation? Every time I've heard that, it was a factor, not the cause. reply bongodongobob 2 hours agorootparentprevIt most certainly is not. Plus, I'd imagine this is more for accidents \"in town\" rather than on straight interstate highways where these cameras are normally set up. Take out alcohol and poor conditions and it's basically a non-issue. https://injuryfacts.nsc.org/motor-vehicle/motor-vehicle-safe... reply the_other 1 hour agorootparentprev> It doesn't make sense to have the limits as low and the fines as high when every single person that goes over the limit can be fined Surely this is only reasonable for large, out of town roads. Within cities, you definitely still want low speed, high fine. reply cortesoft 1 hour agorootparentI am not making a blanket statement that all speed limits are too low, just that they are set based on the implicit assumption that enforcement rates are going to be low and that police are going to be using their judgement to determine if someone is driving at an unsafe speed. reply chgs 2 hours agorootparentprevWe’ve had speed cameras for decades in the UK without problems. I speed constantly yet had been caught twice in 25 years of driving. reply dguest 1 hour agorootparentThey have speed cameras all over Europe too, but the speed limit is often 130 km/h (about 80 mph). Most of the population of the US lives in states where the speed limit is 70 mph or lower. Obviously this is an oversimplification, Switzerland and Spain are 120 km/h (75 mph), Germany often has no upper limit, a few places are 140 or higher. But in general it seems like most of Europe sets the limit at the speed Americans actually drive. reply chgs 1 hour agorootparentAnd int he uk the highest speed limit is 70, and in busy areas it’s usually 60 or 50 on highways from average speed camera enforcement of variable speed limits. In towns it’s 30 and there’s plenty of cameras, for speed, red lights, bus lanes etc. The world doesn’t end. reply hellojesus 46 minutes agorootparentprevThe UK has the best system for speeding prevention I've seen. The cameras are established to clock you at position X1 at time Y1. Then the next cameras a handful or more miles down the road clock you at position X2 at time Y2. You get a ticket if (X2 - X1) / (Y2 - Y1) > Limit + e. You can speed all you'd like between those cameras, but unless you're exiting before the next set, you'll have to pull over and wait the amount of time necessary to bring you back to the speed limit for that area, achieving zero reduction in total trip time. reply cortesoft 1 hour agorootparentprevThis is likely because the cameras have limits that are higher than the actual law, for exactly the reason I stated. reply matsemann 2 hours agorootparentprevI disagree strongly with your example, which also ruins your point for me. I think you should find a different example than one based in motornormativity, saying some laws are fine to break as long as it's behind a wheel. reply lamontcg 37 minutes agorootparentIf we start pervasive automated enforcement of speed limits everywhere, it is most likely to hit poorer Americans as a regressive tax. We haven't redesigned our cities to be non-car centric, with good public transportation and street design that favors lower speeds. But we've got a bunch of people running around wanting to severely punish anyone breaking the speed limits (because \"fuck cars\" means holding individual people responsible for being born in a car-centric society). The result will be that one morning they'll wake up and have to deal with how much they've punitively hurt the working poor in this country. I guess that'll be okay though because that \"in this house\" rainbow flag in their window means that they care. reply matsemann 27 minutes agorootparentThe poorest often don't own a car. Yet another way a car-centric society punishes them, as you often need a car to do normal functions. I don't get why car-proponents often push other groups in front of them to argue their case. Also see it all the time with parking. \"You can't remove parking, think of HC parking!\", \"We will actually double the amount of HC parking and make the area more accessible when we remove other on-street parking\", \"oh\". But not breaking the law when driving is something people are in full control of themselves. I don't buy the premise that it's a regressive tax. Yes, some laws disproportionately hit certain demographics, but not speeding is not one of those. > I guess that'll be okay though because that \"in this house\" rainbow flag in their window means that they care I'm not sure what you mean by that? Are you conflating lgbt stuff into a comment about cars and technological advancements in enforcement, or am I misunderstanding what you mean? reply cortesoft 1 hour agorootparentprevmotornormativity? ok I was not saying there is anything special about being behind the wheel that makes it ok to break a law. I used that example because it fits with the 'low enforcement rate but a high penalty to make up for the low enforcement rate' combo. How about an example like playing poker for money with friends? Illegal in most places where gambling is illegal, but people do it all the time. The laws might make sense if we think casinos are bad for society and want to prevent them, but think occasional gambling amongst friends is fine. The current laws don't carve out home poker games because there was never a need to; there was no way to enforce the law against small friend groups gambling. If there suddenly became a way, we would need to re-write the laws to permit home games. reply matsemann 1 hour agorootparentYes, I like those examples better. Speeding and the danger cars impress on society is something many of us want to be handled stricter. One other example for me could be something like drinking alcohol in a public place. It's never enforced if people are just enjoying a beer quietly during a picnic and bother no one. However if sound equipment mounted in trees could detect the opening of a can and write a ticket, I would feel the law obviously would need to be amended. reply nradov 1 hour agorootparentprevI have no problem with strict enforcement of current speed limits in residential areas. But speed limits on controlled access highways in many states are set ridiculously low. When government officials try to claim that a 65mph limit on a flat, straight freeway is necessary for \"safety\" it's obvious that they're being disingenuous and this is just a revenue grab. It breeds contempt for the law among the driving public and is ultimately counterproductive. reply xerox13ster 9 minutes agorootparentThe emissions and efficiency difference between 55, 60, 65, and 70mph are significant and cannot be understated. It makes such a real difference for air quality that TEXAS (the state that hates regulation and built the monstrosity called the Katy freeway) has a reduced speed limit in some metro areas for air quality reasons. In fact, the reason most national highways have a speedlimit of 50mph, even out in the boonies in Kansas where everything is flat and straight, is because of the fuel crisis of the 70s. When I was a child, I was curious why highways were 50mph but the interstates had a speedlimit of 65-70mph, so I went and found out instead of assuming it was a disingenous revenue grab. Most interstates were generally built after the fuel crisis, and they modified the national speed limit in 1988, setting the speed to 65mph, again for efficiency reasons. It was repealed in 1995. Perhaps 65mph is what was considered safe for the road and vehicular technology at the time, and no one has had the political or municipal capital to do a new study ever since. You want that speed limit changed, contact your reps, I guess. reply brandall10 3 hours agoparentprevFWIW, China's social credit system first arose from trying to replicate what we had in the US with our credit agencies. With things like Project2025 being embraced, it's horrifying what the future may hold if checks and balances aren't in place. reply hnthrowaway0328 3 hours agorootparentIt's already too late, and with the shadow of WW3 soon it will be just worse. reply infogulch 4 hours agoparentprev100%. I like this way of describing the effect: A large enough change in scale manifests as a change in kind. As a topical example, SpaceX is trying to reduce launch costs by 20x with Starship, which just had its 4th test flight this morning. Some don't see the point: there's not nearly enough demand to launch thousands of tons into orbit per year. But 20x is a lot cheaper, so they're banking on induced demand expanding the kinds of projects that send things to space. reply ben_w 3 hours agorootparentThey're also planning to go to Mars, and Starship is the smallest vehicle that could enable that on the scale desired. It's certainly a gamble that there will be a million people willing to spend $200k to do this, which… well, I think it's not entirely impossible, as the idea was something I liked until Musk's own personality put me off the idea of being stuck on a planet with only his sycophants for company. Which is a bit of a shame, but still, I'd give it 50-50 odds of being a product-market fit just for that. reply rurp 2 hours agorootparentWe are so incredibly far from being able to build a sustainable colony on Mars, especially at a realistic cost, that it makes no sense as a product goal. It is a fun thought experiment and an inspiring goal for many though, which I think is the real motivation for focusing on it so much. Elon is undoubtedly great at getting folks to commit money and talent to his companies, and talking about plausible-ish things like becoming a multiplanetary species is one way he accomplishes that. reply ben_w 50 minutes agorootparent> We are so incredibly far from being able to build a sustainable colony on Mars, especially at a realistic cost, that it makes no sense as a product goal. \"Dying on Mars, just not on impact\" is Musk's final bucket list item. Almost everything else he does is to enable that vision, either directly by creating the tech, or indirectly because he knows this is expensive. He may well fail, nobody's ever done this and we don't know how many surprises there will be. But the ship working well enough for $200k tickets is plausible. (The idea that banks will give people loans for that, not so much: without multi-planetary trade, nothing that happens on Mars can repay a debt on Earth, and I don't see Mars as having any special economic benefits to make such trade worthwhile). reply habosa 2 hours agorootparentprevFunny, because Elon has said in the past he thinks induced demand is an “irrational theory”: https://x.com/elonmusk/status/1211076829395738626 reply fsckboy 41 minutes agorootparentElon is correct. So-called \"induced demand\" is just a dumbing down of the more fundamental notion of supply and demand, for people who aren't comfortable thinking about math, calculus, dynamic equilibria, etc. If you read the wikipedia article on it, you'll see they constantly describe it in terms of supply and demand. The term was originally \"defined\" in 1999 in a paper that was not written by economists. It's not an economics term. in terms of transportation planning, a better way to think about it is, \"misery distributes itself throughout the system\". reply Mathnerd314 2 hours agorootparentprevWikipedia splits induced demand into \"latent demand\" and \"generated demand\". I think Elon has no trouble with the idea of latent demand and that by lowering the costs of space travel more will do it. The issue is generated demand, it is a bit irrational to think that a person with no desire for space travel in the first place will say \"oh look, space travel is cheap, let's make a satellite\". The general story is startups find market fit or they die. You have to find the customers, it is not like you make a product and everyone changes their desires to conform. reply diffxx 1 hour agorootparentIt's not totally irrational. There is a reason for the phrase monkey see, monkey do. reply infogulch 2 hours agorootparentprevThat is funny! reply jazzyjackson 2 hours agorootparentprev\"quantity has a quality of its own\" reply bashinator 7 minutes agoparentprevAny sufficiently quantitative change becomes a qualitative change. reply Cheer2171 4 hours agoparentprevThe Stasi in Cold War East Germany reportedly had 1 informant for every 6.5 people, or 15% of the population informing on their neighbors. That's the kind of scale that is needed for total analogue surveillance. reply red_admiral 3 hours agorootparentAnd then the CCP looked at what the CCCP did, thought \"that's cute\" and optimised it until they'd invented the social credit score. It turns out digital is the way to go for scale. reply WaffleIronMaker 3 hours agorootparentI get where you're coming from, but I think it's important to keep in mind that there is no centralized score for Chinese citizens, and that such claims are often sensationalized. [1] However, I'd agree that China is a good example of high degrees of surveillance. [1] https://merics.org/en/comment/chinas-social-credit-score-unt... reply darby_nine 1 hour agorootparentprevTBH this doesn't seem much different than what western credit warehousers (e.g. transunion/equifax/experian) do. reply ToucanLoucan 3 hours agorootparentprevI love how every American is so ready to jump on the China hate train for their social credit score thing when it's literally the same goddamned thing as a credit score in America, with like, some added shit about public shaming. As though we don't 110% shame people in this country for having shitty credit, even if it isn't explicitly part of the thing. Like I've lost count of the number of times people will comment on videos of bad drivers or whatever \"what do you expect from someone driving a [brand] car financed at 28% with no money down.\" Like yeah maybe our credit score system here doesn't officially have a shaming mechanism, but that's the only real difference and it isn't like we don't bolt it onto the side ourselves just because we fucking hate poor people. To be clear, not meaning to defend the social credit score, both of these systems suck and should be abolished. I just think it's hilarious how many people are like HURR HURR SOCIAL CREDIT SCORE when it was designed after America's credit score system. We prototyped it. reply dragonwriter 2 hours agorootparent> I love how every American is so ready to jump on the China hate train for their social credit score thing when it's literally the same goddamned thing as a credit score in America, with like, some added shit about public shaming The “added shit about public shaming” is not a trivial issue, and also Americans aren't particularly fond of actual credit scores or the broader credit reporting system they are part of, either. Like, there is nothing hypocritical about viewing extra negatively another society that has taken a disliked element of your own and made it worse. reply ToucanLoucan 2 hours agorootparent> The “added shit about public shaming” is not a trivial issue I think it could be considered trivial given how much of your life can be made an utter hell by a bad credit score. Things like not being able to finance a house when you already spend more per month on rent than a mortgage, being forced into predatory financial products because you lack the ability to get regular ones, refusal for companies to hire you for work based on your credit score, your credit history just being wrong and being saddled with the task of probably hundreds of hours of work and god knows how much money to fix it because none of the providers give a shit about helping you, the risks with identity theft, on and on and on. As someone who has had to unfuck my credit due to idiocy in financial institutions that was completely, 100% not my fault and yet fell solely on my shoulders to handle, I assure you it is a special circle of bureaucratic hell that would easily stand toe-to-toe with the worst any governments have to offer. Is it GOOD that it has mechanisms for that? No. But again, I emphasize: we add that ourselves to it all the same. And yes it's definitely worse when it's inscribed in the law's text, but I wouldn't say it's that different either. > Like, there is nothing hypocritical about viewing extra negatively another society that has taken a disliked element of your own and made it worse. Oh sure, 100%, but that presupposes that the commenter in question thinks credit reports are bad. And yeah, a fair number of Americans hate them, but like with a lot of things Americans hate, they'll also say shit like \"well that's just how it is.\" But apparently such status-quo allyship doesn't cross into China. reply dragonwriter 34 minutes agorootparent> I think it could be considered trivial given how much of your life can be made an utter hell by a bad credit score The scope of damage increases, rather than decreases, the significance of expanding the set of inputs that can contribute to the damage. reply Cheer2171 2 hours agorootparentprevSo why does almost every US landlord use credit scores to screen renters? reply HWR_14 2 hours agorootparentThe landlord wants to be paid every month. A credit score's entire reason for existence is to attempt to quantify that. It would be strange if a landlord didn't look at that. reply dragonwriter 2 hours agorootparentprev> So why does almost every US landlord use credit scores to screen renters? Landlords are part of one of the bourgeois (petit ot haut) classes, elite minorities. Their interests are not those of the median American, and are in many ways opposed to them. reply bbarnett 2 hours agorootparentHardly. It's more that in a large business, you know that a percentage of people will trash the apartment, requiring expensive repairs, so as a company you reduce risk. And as a small landlord, renting a second house, hoping to pay for your retirement in old age, or maybe a good school for your kids, you're even more cautious. The alternative is a year's rent in deposit, because first and last barely covers a damaged carpet, let alone a trashed place. And that's just the damage side of things. One of the landlords I spoke to, said that while he understood why renter protections had become so strong, it took forever to kick out a tenant not paying rent. So naturally, he was scared of renting to anyone with money troubles before. You may disagree with these reasons, but people aren't reducing the market they can rent to for no reason. Times were easier when most people lived in smaller towns. You knew who you rented to, and didn't need a credit bureau to vouch. reply ToucanLoucan 3 minutes agorootparentEvery time this subject comes up all we hear about is how risky it is for the landlord. Like... no shit? It's an investment. Risk is part of investments. Sometimes investments don't pay out, and sometimes you lose money. If you want to make money in a risk-averse manner, might I suggest a job instead of an investment property? You know, like the people who's money you want to take are required to prove to you they have, so you can take a nice chunk of it so they can not freeze to death? One of those. They're all over the place, according to the landlords. > One of the landlords I spoke to, said that while he understood why renter protections had become so strong, it took forever to kick out a tenant not paying rent. Did he happen to mention why the tenant stopped paying? Because that's probably pretty relevant to why renter protections were stopping him from throwing him out onto the street. Like, I'm sorry it's bit of a bureaucratic fuckabout to KICK SOMEONE OUT OF THEIR HOME but you know, the landlord in this scenario has the economic backing to, in some way, own an extra residence that they don't need, and the tenant they're trying to evict (probably) doesn't. So on the whole I'm okay with renter protections making that hard. One of these people is acutely more vulnerable to houselessness, and it isn't the dude with 2+ houses. Again, if this is a problem, maybe said landlord should get a job. sickofparadox 2 hours agorootparentprevA person with no credit or a low credit score is still allowed to buy train tickets and leave their hometown. A person with high credit score is not punished in any way for interacting with a person with a low credit score. Credit scores in the United States do not incentivize families cutting off contact with members who do not support the ruling party. To say that \"they are essentially the same\" is to run cover for the most objectionable parts because you are mad that creditors want a way to determine if someone is going to cut and run with their money. reply _DeadFred_ 38 minutes agorootparentThe government is allowed to 'unbank' you, or to at least push banks to 'voluntarily' 'unbank' you. Having your bank accounts closed and credit cards all canceled summarily is going to hurt your credit score, which in turn is going to make renting a place to live very difficult. reply sickofparadox 22 minutes agorootparentCould you provide an example of the government pushing for someone to be unbanked? Preferably someone not guilty of some kind of finance crime (or accused and on the run). reply andai 1 hour agoparentprevI call this phenomenon One Fed Per Child. Now we can have a synthetic government agent monitor every man, woman and child on the planet. If we don't have that already, we soon will... reply parpfish 3 hours agoparentprevi started struggling with this years ago with the scale up of face recognition software. nobody thought there was a problem when you stuck up a wanted posted and asked a community 'do you know who this is'? but if you stick that poster into a computer and ask, all of a sudden people complain that it's a privacy issue. i really struggle to see how they're different and the only thing i've been able to some up with is that people feel the only counterweight to abuses and biases of policing is to build in random inefficiencies reply SoftTalker 3 hours agorootparentA wanted poster might have some people watching faces more closely, but they aren't compiling a history of every face they saw and when and where they saw it, and sending that in to law enforcement where it can be combined with other histories and used to generate suspect lists based on coincidences. reply shadowgovt 2 hours agorootparentRight, that's just saying \"we prefer built-in random inefficiencies\" with extra steps. The heart of investigation is pulling coincidences into an actionable pattern (which is different from trial and conviction, which relies on far more than coincidences). Given how much crime currently goes uninvestigated because the backlog is so high, is automating some of the coincidence-sniffing a bad thing? reply bee_rider 3 hours agorootparentprevI think it really depends on the reason why you were going around putting up wanted posters and asking people if they’d seen somebody. If it was a dangerous criminal, sure. An ex? Creepy. In general, I’d have some probing questions before being forthcoming, I like to think. Picture of my friend? Sure Mr. Private investigator, tell me what you want and give me your number, and I’ll let him know somebody wants to talk to him… If there was, like, a club devoted to organizing the sort of informal observations of who was where and trying to track everybody the old fashioned way, I’d think everyone involved was a real creep there, too. Although, of course, this would be a bit impractical. And the paparazzi weren’t some beloved people, and they mostly targeted public figures! There’s something to be said for the inefficiency I guess. But, I think it is also to a large extent a proxy for the idea that normal people only went on the hunt for somebody for a good reason. reply layer8 2 hours agorootparentprevDifferences: 1. Wanted posters were only hung up based on human witness reports and for a very limited number of suspects. With face recognition, you can hunt automatically for hundreds who happened to be around a specific place at the wrong time. 2. Reach, and therefore likelihood of false-positive face matches. 3. Investigators wouldn’t blindly believe a random community member reporting a match, they would check if the reported suspect really matches the description and the circumstances. With face recognition and AI, people tend to just assume that the computer is correct. reply l33t7332273 1 hour agorootparentI think it’s notable that your first point is directly in line with GP’s idea about built inefficiencies. reply mistrial9 4 hours agoparentprevas usual, a small group of effective people with strong leadership have already acted on this -- in the opposite direction you are suggesting.. Palantir and others have built, monetized and promoted exactly the opposite, and thousands of schlubs in the ad business went along with it.. the USA has changed reply delusional 3 hours agoparentprevLooking past the cost, it also used to be a huge hassle. If I wanted to know what you were doing, I'd have to hire 6 guys sure, but I'd also need to manage them. Plan out their shifts, handle payroll, and their internal disputes. The practical reality of surveillance meant it HAD to be a conspiracy. The risk of someone talking was huge. Now it's easily hidden. Somebody can monitor you just by accessing information systems without the people collecting the data even knowing. You can now do the surveillance alone, no pesky accomplices needed. reply cletus 2 hours agoprevIMHO an opt-out system is never going to work for this. Story time: while I still worked at Facebook, there was a company wide project for data attribution to comply with opting out of personalization (I believe to comply with an EU directive but don't quote me on that). The idea was to identify the source of any data by esentially tagging it on a granular level. This affected all the offline data procesing and ML processes but also code (online and offline) where various tools and systems were being built to analyze sites of data usage to detect use of personalized data and respect opt outs where applicable. I made two predictions at the early stages of this: 1. The tools and systems would tell us \"all data is used for everything\" and 2. Creating new non-personalized data pipelines and add things to them would be far easier and faster than trying to remove personalzied data from existing pieplines. Then, things like ad performance become an optimizatino problem with a clear benchmark (eg new unpersonalized ad serving pipeline vs the old personalized pipeline). A lot of work did, I believe, basically confirm (1). Untangling that seems, at least to me, to be a Sisyphean task. I don't know where this project ended up since I left while it's ongoing but I stand by (2). My point is that (IMHO) opt-out just doesn't work for this kind of thing. If we really care about data privacy and authorized use of data at some point we will need to take the oposite approach and enumerate what data we're allowed to use. reply ProllyInfamous 16 minutes agoparentWhen I'm met with the response/resistance of \"if you care so much then just OPT-OUT!\" my usual retort is: \"if it weren't just about money, it'd be OPT-IN.\" Almighty Dollar™, god... reply mattgreenrocks 1 hour agoparentprev> The tools and systems would tell us \"all data is used for everything\" Reminds me of the tendency in program analysis to just spit out top (e.g. all possible values) because the state space overwhelms automated reasoning, and the only way back is annotating/rewriting code to help the analyzer forward. But, as someone who doesn't think/deal with data much, this is a surprise to me. It makes sense though. Does this mean our data is forever tainted, as were? Since you've been proximate to this work: do you think there's any hope in flipping the script such that possessing/processing this data is a liability rather than an asset? That's one of the few ways I can see to align incentives between highly monied-interests and the targets of data collection. (I'm doubt this will happen in the US in my lifetime, barring a major, 9/11-level event where abuse of this data is directly tied to the catastrophe.) reply Ensorceled 4 hours agoprevA partner showed me their CRM tool, it had an AI component that created a profile of each of their contacts. It was pretty complete and clearly had info from LinkedIn and other sources. The personality summary was concerning as it was both deeply accurate in some respects and deeply inaccurate in others. Most concerning, it said I was \"risk adverse\" and \"struggles to make decisions with incomplete data\". With 35 years at startups and independent contracting, risk tolerance and ability to make decisions with incomplete data are kind of in my wheelhouse. Worse, if this profile was being shown to potential employers, it could (would?) be a deal breaker. It's kind of like being judged by your MBTI results. reply ben_w 3 hours agoparentMm. Similar with social media advertising profiles. I've seen what FB and Twitter thought of me, and it included interests in various spectator sports, which were wrong both as a general statement about my personality, and specifically those sports don't even have any societal significance outside the USA. Also several languages that I don't speak. And they showed me ads for both dick pills and breast surgery; and others for a lawyer who specialised in renouncing a citizenship I've never had (for tax purposes) when moving to a country that I left; and also an announcement by the government of a country I don't live in about a ban to a specific breed of dog I've never heard of, when I don't own any dog anyway and never have. And people complain about LLMs making things up :P reply hellojesus 37 minutes agorootparentMaybe they were fishing for engagement because they had such an incomplete profile on you, hence the highly variant ads. No idea; just guessing. reply davemp 3 hours agoparentprevI’m no expert in tort law but that really sounds like it could be libel. Afaik proving reckless disregard for the truth is one of the ways you can build a case. reply passion__desire 3 hours agorootparentIn a decision making process, if many parties are involved, it is in interest of all parties to not turn on each other in case of wrong decisions. Just let it slide. reply firtoz 2 hours agoparentprevIt's impossible to detect whether some statement in isolation is a hallucination or not, with LLMs. It's better for it to aggregate the information and then provide the resources to be able to verify whether any deduction is well supported or not. I guess with a few more iterations you could have another agent verify whether a deduction is well justified, but that will also have some significant percentage of errors too. reply layer8 2 hours agoparentprevWhat we need is (a) AI literacy (education), and (b) Ai-generated content being marked as such. Then no one would take such a personality summary at face value. reply sugarpile 4 hours agoparentprevWhat was the tool? reply creaghpatr 3 hours agorootparentSounds like Crystal https://www.crystalknows.com/ reply MattGaiser 3 hours agoparentprev> It's kind of like being judged by your MBTI results. I had to do that test a bunch of times coming out of university, so I am sure that is happening. reply __MatrixMan__ 30 minutes agoprevI wish there were a way to verify, when I encounter a camera that is pointed at a public place, that it's not feeding into some kind if nation wide person tracking system maintained by whatever security company, but is instead going to local storage with a retention period ofBut when they were on the open road, they spewed lethal quantities of toxic gas, killing people by the thousands. I point this out because I was liking the argument until this point: He's off by a couple orders of magnitude, according to Wikipedia. Not enough for me to read it as absurd hyperbole, like calling Adam Smith a communist, but enough for me to stop reading the essay, look up his claim, and then feel like he's either misinformed or lying. reply karaterobot 1 hour agoprevI agree that this sucks, but it's going to happen no matter whether we call it a right or not. We need to quickly accept that we've made a world where you can't stop anyone from using AI for things you don't like, and that there are infinite incentives for them to do it, and start focusing on ways to mitigate the risk. My position is that calling it a right—even enshrining that recognition into international law—will not, by itself, do anything. It's step 0, we need to be on like step 12, pronto. reply jerf 4 hours agoprevThe people who nominally you want to be enforcing this \"right\" are also some of the people who most want to AI profile you. reply nerdponx 4 hours agoparentWhich makes it all the more important, no? reply thaumasiotes 4 hours agorootparentNo, why would they enforce the rules against themselves? reply marcosdumay 2 hours agorootparentBecause they are supposed to be working for you, and if they keep fighting your goals, you should pressure them into being replaced. reply shadowgovt 1 hour agorootparentThat's going to be real hard to do when they have an AI profile of you so accurate they can undercut your political power at every turn. reply marcosdumay 14 minutes agorootparentYes, that's correct. But do you have any better option? This is reason to rush, not to decide somebody else will do a better work. reply willy_k 2 hours agorootparentprevI think you’re missing the point, the issue is important because they have no reason to act against themselves, but a healthy system would have someone opposing them, and that’s not happening at the moment. reply thaumasiotes 1 hour agorootparentIf you want a rule enforced against some party, you need the enforcement power to belong to some other party. reply willy_k 1 hour agorootparentI don’t think anyone’s disagreeing with that. My interpretation of your initial comment was that you were saying it’s not an important issue because it can’t be effectively policed. I don’t think that’s what you meant, but that’s what I got out of your saying no in response to the assertion that it’s important. reply thaumasiotes 51 minutes agorootparentThe reason I'm saying \"no\" is this: >> The people who nominally you want to be enforcing this \"right\" are also some of the people who most want to AI profile you. If your goal is specifically to have someone enforce a rule against themselves, that's not an important issue, because it won't work. If you change the statement of your goal so that you're not requiring the enforcement power to be vested in the target of the rule, then the issue might become more important. reply epgui 3 hours agoprevI hope this right gets applied to credit scoring agencies as well, which don't publish the methodology in the calculation of credit scores. God knows what the exact mechanics of these calculations are (beyond the well-known but very hand-wavy broad strokes), and they impact people in serious ways. reply Workaccount2 3 hours agoparentMaybe I am crazy, but I have found that living within my means is an extremely effective method for keeping a high credit score. reply tamimio 1 hour agorootparentWhile I agree with you that living within your means is best, it definitely won’t help build your credit score. From my experience, if you don’t use a credit card, you won’t have a good score. If you use it and pay it off quickly, you’ll see barely any positive score gains. Then, I used a service to build my score, and it worked, but slowly over the months. However, what really increased my score substantially was actually being in debt. So, I kept the debt and paid the monthly amount on it. Surprisingly, even missing a payment still increased my score. The conclusion: they want you to be in perpetual debt aka debt slave to have good boy points. reply lotsofpulp 33 minutes agorootparent> The conclusion: they want you to be in perpetual debt aka debt slave to have good boy points. More data is needed before thinking you can determine the formula. More importantly, it is trivial to understand the reasoning behind assuming a higher probability of someone repaying debt if they have a history of successfully repaying debts. The same as anything else in life. reply Brian_K_White 2 hours agorootparentprevI have found that living within my means resulted in no credit score at all, which was treated as the worst possible credit score, when I finally started to investigate the possibility of buying a house. 45 years old at the time, $120k income, same job since '99, no debt at all, cars all paid cash etc, Didn't owe anyone a dollar, not late on any bills for decades, solid predictable longstanding income, only about 100k in the bank though not counting the 401k, ... no credit. Because I never even got a credit card let alone used one. All cash/debit whole life. So, F this line. It's only true if it also includes \"...and intentionally aquire and actually use a couple of credit cards that you don't want and don't need, for no other reason than to go through the motions.\" And even then it still doesn't result in an exactly great credit score if you always pay in full and never carry a balance. Even after years. 10 so far for me since the above. It's ok, but not great. So yeah, F this line. reply HWR_14 2 hours agorootparentPaying in full/not carrying a balance has no impact on credit score vs. making minimum payments. reply meowster 1 hour agorootparentWell, making minimum payments has a negative impact because then you're carrying a debt which eats into your debt vs ability to borrow ratio which does have a big impact. Paying off cards in full each month is the absolute best thing to do for your credit score (and saving money by not paying interest). reply SoftTalker 3 hours agoparentprevIt's 90% \"do you pay your bills on time\" it's really not as nefarious as you're making it sound. reply AlexandrB 3 hours agorootparentReally it's 90% praying that they don't fuck up and confuse you with someone else. The nefarious part is there's no accountability if they're wrong. reply notjoemama 3 hours agoprevDoes XKCD take suggestions? A. We don't fully understand this and our responses are incorrect. Let's build an AI system to help us. B. We'll give it data from online which is limited, temporal, and to the same degree as humans; incorrect. C. Then we'll build an algorithm based on the generalized structure of the human brain, which, is regularly wrong. D. We don't fully understand this and our responses are incorrect. reply ben_w 3 hours agoparenthttps://xkcd.com/1838/ reply SoftTalker 2 hours agorootparentJust an aside, I've always been impressed by how much non-verbal human attitude/expression Randall Munroe is able to capture in faceless stick figures. Or maybe it's just me reading that into his drawings? reply ben_w 57 minutes agorootparent> Or maybe it's just me reading that into his drawings? Not just you, I agree completely. reply Spivak 4 hours agoprevI don't love this. Informed consent is a lie and a loophole you can drive a container ship through. Anything less than right to refuse where services aren't allowed to deny you service until you accept is worthless. Also AI isn't special, I don't want to be profiled by humans or non-AI based systems based on my public data either. And for that matter public data isn't special either -- I don't want to be profiled via my private data sold though backroom deals between companies more than I care about my public data. At least I can can curate the latter. The problem is that if you don't narrowly target AI you bump into \"well this is what adtech does\" and getting legislation that hurts the profits of one of the US's golden calfs is a nonstarter. reply personjerry 1 hour agoprevSurely the issue in \"AI profiling\" is \"profiling\" not \"AI\"? reply fdupress 26 minutes agoparentYes, and surely the right to not be profiled on publicly available data is already enshrined in GDPR? reply faeriechangling 2 hours agoprevThis is an absolutely stupid notion IMHO because if somebody has the data there’s NOTHING you can do to stop profiling. The right to the deletion and security of your own personal data is what needs to be protected. This sort of right is closing the barn door after the horse leaves. reply shadowgovt 1 hour agoparentBut securing your personal data sounds a lot like a stone trying to gather up all the waves it makes when it drops in a pond. Where do we draw the lines? Do we all end up walking around cloaks and masks in public and if you suss out who the faceless individual is next to you in the crowd it's your fault you figured it out? reply bilbo0s 1 hour agoparentprevThis sort of right is closing the barn door after the horse leaves. In fairness, so is the right to deletion. Once your data is in some of these systems, it's sold on to other systems immediately. (Most of the \"sell side\" market is set up on the basis of subscriptions). So, for instance, your data gets written to some merchant system or whatever, and it's slurped out in the pull that happens 15 minutes later by data subscriber 531962. Unless you get your request to delete your data to the merchant customer support within that 15 minute time period, your data has already been pumped out into the ether. Make it so you have to give affirmative consent to opt out of right to deletion? Great idea! Of course, most of these companies slip the opt out language into the Terms of Service and Privacy Statement. You, uh, you did read them before you clicked 'OK', right? (BTW, you likely suspect that it doesn't take 15 minutes for these automated processes to slurp up new data. And, yeah, your suspicion is correct, on most of these systems, it takes far less than 15 minutes before one of their subscribers pulls new data. So. Yeah. Fun Times!) reply piuantiderp 2 hours agoprevThis is focusing on the wrong side. Better than the right, which is pretty unenforceable at individual scale, why not focus on prohibiting companies/institutions/goverment from AI profiling? reply drawkward 14 minutes agoparentIf I have a right to not be profiled, then laws can be made to deal with entities that violate said right. reply koolala 2 hours agoprevi want my right to be a part of ai consciousness reply verisimi 4 hours agoprev [–] Creating a 'right' is law-washing immoral actions that no one agreed to. reply drawkward 12 minutes agoparent [–] Creating words is linguisto-washing that no one agreed to, yet somehow i was able to understand your sentence. In both cases, the washing is a step to achieving intended outcomes. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article advocates for a unique legal right to protect individuals from AI profiling using publicly available data without their explicit informed consent, citing risks of social control, stigmatization, and increased exposure.",
      "It critiques the EU's General Data Protection Regulation (GDPR) for lacking sufficient safeguards against AI profiling and highlights studies showing AI's high accuracy in identifying mental health issues from social media data.",
      "The article calls for revisions to legal frameworks like the GDPR to establish this right, emphasizing the importance of privacy, informed consent, and regulatory measures to balance the benefits and harms of AI profiling."
    ],
    "commentSummary": [
      "The discussion emphasizes the urgent need for updated privacy laws due to advancements in technology that enable widespread and affordable surveillance, such as smartphones and speed cameras.",
      "Ethical implications of surveillance technologies, including facial recognition, and the complexities of renter protections and credit scoring are explored, comparing China's social credit system to America's credit score system.",
      "Concerns about data privacy, AI profiling, and the effectiveness of current laws like GDPR are raised, with debates on enforcing privacy protections and the ethical issues surrounding AI-generated content."
    ],
    "points": 162,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1717682597
  }
]
