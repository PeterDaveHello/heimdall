[
  {
    "id": 39142748,
    "title": "Oasis: A Statically-Linked Linux System Emphasizing Simplicity and Customization",
    "originLink": "https://github.com/oasislinux/oasis",
    "originBody": "oasis oasis is a small linux system. It is probably quite a bit different from other Linux-based operating systems you might be familiar with, and is closer to a BSD. There are many features that distinguish it from other operating systems: Completely statically linked. All software in the base system is linked statically, including the display server (velox) and web browser (netsurf). Compared to dynamic linking, this is a simpler mechanism which eliminates problems with upgrading libraries, and results in completely self-contained binaries that can easily be copied to other systems. Fast builds that are 100% reproducible. All packages are built with samurai, using build manifests generated by Lua scripts. This involves considerable up-front packaging cost, but minimal maintenance cost, and offers numerous advantages, including near optimal build times, predictable and reproducible builds, reduced build-time dependencies, and incremental builds even across package boundaries. Minimal bootstrap dependencies. Any POSIX system with git, lua, curl, a sha256 utility, standard compression utilities, and an x86_64-linux-musl cross compiler can be used to bootstrap oasis. This makes it trivial to cross-compile, even from non-Linux systems such as macOS or OpenBSD. BearSSL is the system TLS and crypto library. BearSSL is incredibly small and well written, but is not widely adopted. Through the use of libcurl, which now has native BearSSL support, and libtls-bearssl, an alternative implementation of libtls based on BearSSL, oasis uses BearSSL throughout the system. Only a few optional packages still require LibreSSL. No package manager. Instead, you configure a set of specifications of what files from which packages to include on your system, and the build system writes the resulting filesystem tree into a git repository. This can then be merged into /, or pulled from another machine. Integrates well with OS-agnostic package systems. Although the aim is to provide a complete system, there is a lot of free software out there, a lot of which does not match up well to our goals. Rather than trying to build and maintain yet another repository with thousands of packages, oasis works well with pkgsrc and nix. This makes it easy to extend your system with software you might need, while keeping the base system small and focused. Extremely simple system configuration. A guiding principle is that the /etc directory should be simple enough for system administrators to understand completely and customize appropriately. The most complex file in the default configuration is the system initialization script, /etc/rc.init, at only 16 lines. Mostly ISO C conformant. A major goal of oasis is to build with cproc, a C compiler which is much stricter about the ISO C standard than gcc or clang, and orders of magnitude smaller. Although this is a work-in-progress effort, all core packages, and most others, build successfully with cproc. Principles Software complexity should be measured by including all transitive dependencies. Executables should be linked statically. Software components should allow for easy customization and/or modification. Package sources should be referenced through a URL or git submodule, but not included directly. /etc should be simple enough to be understood in its entirety. Patches should be well organized, have good descriptions, and should always apply cleanly. Install An install guide can be found on the wiki. However, keep in mind that oasis is an ambitious project, and there is still a lot of work to do. Users should be comfortable building their own kernel and tinkering with their system when things go wrong. If you do run into trouble, I'm always happy to help you out. QEMU If you'd like to give oasis a try without installing it yourself, there is a QEMU image available here. Inside the archive are the root filesystem, a Linux kernel, and a script to launch qemu. There is also README.md with some information about how to use it. In short, use ./run to launch in graphical mode, and ./run -s to launch in serial mode. Software oasis uses smaller and simpler implementations of libraries and tools whenever possible: musl instead of glibc sbase instead of coreutils ubase instead of util-linux pigz instead of gzip mandoc instead of man-db bearssl instead of openssl oksh instead of bash sdhcp instead of dhclient or dhcpcd vis instead of vim or emacs byacc instead of bison perp and sinit instead of sysvinit or systemd netsurf instead of chromium or firefox samurai instead of ninja velox instead of Xorg netbsd-curses instead of ncurses These packages are grouped into logical sets, and the full list is available in the pkg directory. If your favorite software is missing, keep in mind that you can likely still install it via pkgsrc or nix. Contact There is a mailing list at ~mcf/oasis@lists.sr.ht, and an IRC channel at #oasis on libera.chat. Feel free to use them for questions, patches, or general discussion.",
    "commentLink": "https://news.ycombinator.com/item?id=39142748",
    "commentBody": "Oasis – a small, statically-linked Linux system (github.com/oasislinux)463 points by smartmic 19 hours agohidepastfavorite215 comments dijit 19 hours agoI cant speak much about the system, it just works, but the community was really nice when I interacted with them over IRC I had the plan to build oasis with bazel for some immutable OS images that could run as kubernetes nodes. I succeeded with a little pointing. reply eek2121 6 hours agoparent\"it just works\" so you are doing the tech support when it doesn't, right? EDIT: that was meant to be a joke, I forgo HN doesn't support emojies. reply gravypod 18 hours agoparentprevHave you shared your BUILD files upstream? reply dijit 18 hours agorootparentNo, they were quite happy with Samurai reply colatkinson 8 hours agoparentprevIf you don't mind I'm super curious as to what approach you ended up taking. Did you use rules_foreign_cc to build the ninja files they generate? Or generating BUILD files directly? Or something completely different? Sounds like a really cool project! reply malux85 18 hours agoparentprevThats a cool idea! Will you open source it or make it available somehow? I would like to play with it for running Atomic T reply public_void 13 hours agoparentprevWhy did you need to use bazel? reply dijit 13 hours agorootparentI didnt need to use bazel, I like bazel and want to learn more about it. I also have a small, but burning, passion for reproducible builds, distributed compilation and distributed caching. Being able to build an entire OS and essentially anything I want on top in a reproducible and relatively organic way (with incremental compilation) is pretty dope. reply i-use-nixos-btw 11 hours agorootparentYou sound like the perfect Nix cult memb… erm, user. It’s everything you describe and more (plus the language is incredibly powerful compared with starlark). But you speak from sufficient experience that I presume Nix is a “been there, done that” thing for you. What gives? reply chaxor 11 hours agorootparentNix has decentralized caching and memorizing? reply i-use-nixos-btw 10 hours agorootparentDecentralised caching, absolutely - unless I’m misunderstanding what you mean there. You can build across many machines, merge stores, host caches online with cachix (or your own approach), etc. I make fairly heavy use of that, otherwise my CI builds would be brutal. Memorizing isn’t a term I’m familiar with in this context. reply chaxor 9 hours agorootparentSorry - memoizing. I am interested in making a system that can memoize large databases from ETL systems and then serve that on iroh or ipfs/torrent, such that a process that may take a supercomputer a week to process can have the same code run on a laptop and it will notice it's been done my a university supercomputer before already and grab that result automatically from the decentralized network of all people using the software (who downloaded the ETL database). That way you save compute and time. reply i-use-nixos-btw 7 hours agorootparentOh I see! Yes, absolutely doable in Nix. Derivations are just a set of instructions combined with a set of inputs, and a unique hash is made from that. If you make a derivation whose result is the invocation of another, and you try and grab the outcome from that derivation, here’s what will happen: - it will generate the hash - it will look that hash up in your local /nix/store - if not found it will look that hash up in any remote caches you have configured - if not found it will create it using the inputs and instructions This is transitive so any missing inputs will also be searched for and built if missing, etc. So if the outcome from your process is something you want to keep and make accessible to other machines, you can do that. If the machines differ in architecture, the “inputs” might differ between machines (e.g. clang on Mac silicon is not the same as clang on x86-64) and that would result in a different final hash, thus one computation per unique architecture. This is ultimately the correct behaviour as guaranteeing identical output on different architectures is somewhat unrealistic. reply IshKebab 11 hours agorootparentprevNix isn't as fine-grained as Bazel as I understand it? I don't think it's incremental within a package, which is presumably what dijit achieved. reply i-use-nixos-btw 10 hours agorootparentWeirdly enough I came across a blog post last week that talked about exactly this. https://j.phd/nix-needs-a-native-build-system/ Nix can be used as a build system in the same way that bazel can. It already has all of the tooling - a fundamental representation of a hermetic DAG, caching, access to any tool you need, and a vast selection of libraries. The only catch is that no one has used it to write a build system for it in public yet. I’ve seen it done in a couple of companies, though, as using Nix to only partially manage builds can be awkward due to caching loss (if your unit of source is the entire source tree, a tiny change is an entirely new source). reply yx827ha 7 hours agorootparentprevYou should check out the ChromeOS Bazelification project[1]. It has those exact same goals. Not all packages are reproducible though because they embed timestamps. [1]: https://chromium.googlesource.com/chromiumos/bazel/+/HEAD/do... reply MuffinFlavored 13 hours agoparentprev> I cant speak much about the system, it just works, What systems don't just work by this criteria? Just because something is statically linked vs dynamically linked, as long as you are within \"normal expected operating conditions\", does it really make a \"just works vs doesn't work\" quality difference? reply Koshkin 12 hours agorootparentRead after the comma: > it just works, but... reply kentonv 18 hours agoprevDoesn't linking everything statically imply that the base image -- and memory, at runtime -- will be bloated by many copies of libc and other common libraries? I do like the simplicity of static linking but it sort of seems to go against the idea of avoiding \"bloat\". reply jezze 17 hours agoparentA linker typically only includes the parts of the library it needs for each binary so some parts will definately have many copies of the same code when you statically link but it will not make complete copies. But I wouldnt consider this bloat. To me it is just a better seperation of concerns. To me bloat would be to have a system that has to keep track of all library dependencies instead, both from a packaging perspective but also in runtime. I think it depends where you are coming from. To me static linking is just cleaner. I dont care much for the extra memory it might use. reply jvanderbot 17 hours agorootparentDynamic linking served us when OS upgrades came infrequently, user software was almost never upgraded short of mailing out new disks, and vendors had long lead times to incorporate security fixes. In the days of fast networks, embedded OSs, emphemeral containers, and big hard drives, a portable static binary is way less complex and only somewhat less secure (unless you're regularly rebuilding your containers/execs in which case it's break even security wise or possibly more secure, simply because each exec may not include vulnerable code) reply bscphil 14 hours agorootparent> In the days of fast networks, embedded OSs, emphemeral containers, and big hard drives, a portable static binary is way less complex and only somewhat less secure If what you're trying to do is run a single program on a server somewhere, then yes absolutely a static binary is the way to go. There are lots of cases, especially end user desktops, where this doesn't really apply though. In my opinion the debate over static vs dynamic linking is resolved by understanding that they are different tools for different jobs. reply StillBored 11 hours agorootparentunderstanding that they are different tools for different jobs Right, but this goes against the dogma on both sides and the fact that much of Linux userspace is the wild west. Ideally, there should be a set of core system libraries (ex glibc, openssl, xlib, etc) that have extremely stable API/ABI somatics and are rarely updated. Then one dynamically links the core libraries and statically links everything else. This solves the problem that a bug/exploit found in something like OpenSSL doesn't require the entire system to be recompiled and updated while allowing libraries that are not stable, used by few packages, etc, to be statically linked to their users. Then, when lib_coolnew_pos has a bug, it only requires rebuilding the two apps linked to it, and not necessarily even then if those applications don't expose the bug. reply formerly_proven 7 minutes agorootparent> Right, but this goes against the dogma on both sides and the fact that much of Linux userspace is the wild west. Ideally, there should be a set of core system libraries (ex glibc, openssl, xlib, etc) that have extremely stable API/ABI somatics and are rarely updated. This is largely true and how most proprietary software is deployed on Linux. glibc is pretty good about backwards compatibility. It gets shit for not being forwards compatible (i.e. you can't take a binary linked against glibc 2.34 and run it on a glibc 2.17 system). It's not fully bug for bug compatible. Sometimes they'll patch it, sometimes not. On Windows a lot of applications still link and ship their own libc, for example. xlib et al in practice don't break. Programs bring their own GUI framework linking them and it'll work. Some are adventurous and link against system gtk2 or gtk3. Even that generally works. OpenSSL does have a few popular SONAMEs around but they have had particularly nastily broken APIs in the past. Many distros offer two or more versions of OpenSSL for this reason. However, most applications ship their own. If you only need to talk to some servers, you can link against system libcurl though (ABI compatible for like twenty years). This would IMHO be much better than what most applications do today (shipping their own crypto + protocol stack which invariably ends up with holes). While Microsoft ships curl.exe nowadays, they don't include libcurl with their OS. Otherwise that would be pretty close to a universally compatible protocol client API. reply palata 11 hours agorootparentprev> Then one dynamically links the core libraries and statically links everything else. Agreed, and that is already totally possible. - If you split your project in libraries (there are reasons to do that), then by all means link them statically. - If you depend on a third party library that is so unstable that nobody maintains a package for it, then the first question should be: do you really want to depend on it? If yes, you have to understand that you are now the maintainer of that library. Link it dynamically or statically, whichever you want, but you are responsible for its updates in any case. The fashion that goes towards statically linking everything shows, to me, that people generally don't know how to handle dependencies. \"It's simpler\" to copy-paste the library code in your project, build it as part of it, and call that \"statically linking\". And then probably never update it, or try to update it and give up after 10min the first time the update fails (\"well, the old version works for now, I don't have time for an update\"). I am fine with people who know how to do both and choose to statically link. I don't like the arguments coming from those who statically link because they don't know better, but still try to justify themselves. reply superb_dev 9 hours agorootparentStatically linking does not imply copying the code into the project reply palata 8 hours agorootparentOf course not. My point was that people who say \"static linking is better\" because the only thing they know (which is copying the code into their project) results in something that looks like static linking are in the wrong. reply wongarsu 6 hours agorootparentprevWindows makes up the lion's share of desktop computing, and seems to be doing fine without actually sharing libraries. Lots of dynamic linking going on, but since about the XP days the entire Windows ecosystem has given up on different software linking the same library file, except for OS interfaces and C runtimes. Instead everyone just ships their own version of everything they use, and dynamic linking is mostly used to solve licencing, for developer convenience, or for plugin systems. The end result isn't that different from everything being statically linked reply moffkalast 13 hours agorootparentprevIt applies very much to end user desktops as well, with snap, flatpak, etc. working towards it. Lots of software requires dependencies that aren't compatible with each other and result in absolute dependency hell or even a broken install when you dare to have more than one version of something. Because who would ever need that, right? Especially not in a dev desktop environment... Windows is basically all self-contained executables and the few times it isn't it's a complete mess with installing VC++ redistributables or the correct Java runtime or whatever that clueless users inevitably mess up. We have the disk space, we have the memory, we have the broadband to download it all. Even more so on desktop than on some cheap VPS. reply marwis 12 hours agorootparent> Windows is basically all self-contained executables With the caveat that the \"standard library\" they depend on is multiple GBs and provides more features than entire Gnome. Also MS always worked in some tech to avoid library duplication such as WinSxS or now MSIX has autodedupe even at the time of download. reply palata 10 hours agorootparentprev> when you dare to have more than one version of something. Because who would ever need that, right? If done properly, you can have multiple major versions of something and that's fine. If one app depends on libA.so.1.0.3, the other on libA.so.1.1.4, and they can't both live with 1.1.4, it means that `libA` did something wrong. One pretty clear solution to me is that the dev of libA should learn good practice. reply zaphar 10 hours agorootparentYep, the dev(s) of libA should learn good practice. But they didn't and app1 and app2 still have the problem. Static linking solves it for them more reliably than trying to get the dev of libA to \"git gud\". Much of the desire to statically link binaries comes from this specific scenario playing out over and over and over. Heck for a long time upgrading glibc by a minor version was almost guaranteed to break your app and that was often intentional. reply palata 10 hours agorootparent> Yep, the dev(s) of libA should learn good practice. But they didn't and app1 and app2 still have the problem. Sure :-). I just find it sad that app1 and app2 then use the bad libA. Of course that is more productive, but I believe this is exactly the kind of philosophy that makes the software industry produce worse software every year :(. reply zaphar 10 hours agorootparentI used to think the same. But after nearly 30 years of doing this. I no longer think that people will meet the standard you propose. You can either work around it or you can abandon mainstream software entirely and make everything you use bespoke. There are basically no other choices. reply palata 8 hours agorootparentYeah I try really hard to not use \"bad\" dependencies. When I really can't, well... I can't. But still I like to make it clear that the software industry goes in that direction because of quality issues, and not because the modern ways are superior (on the contrary, quite often) :-). reply moffkalast 9 hours agorootparentprevWishing that all people will be smart and always do the correct thing is setting yourself up for madness. The dependency system needs to be robust enough to endure a considerable amount of dumbfuckery. Because there will be a lot of it. reply palata 8 hours agorootparentBecause I have to live with \"malpractice\" doesn't mean I should not say it is, IMHO. I can accept that someone needs to make a hack, but I really want them to realize (and acknowledge) that it is a hack. reply shusfuejdn 7 hours agorootparentprevIt should be noted though that flatpaks and related solutions are NOT equivalent to static linking. They do a lot more and serve a wildly different audience than something like Oasis. They are really much too extreme for non-GUI applications, and I would question the competence of anybody found running ordinary programs packaged in that manner. I recognize that you probably weren't confused on this I'm just clarifying for others since the whole ecosystem can be a bit confusing. reply gnramires 15 hours agorootparentprevAs far as I can see, it would be unwise to roll back 30 years of (Linux) systems building with dynamic linking in favor of static linking. It mostly works very well and does save some memory, disk, and has nice security properties. Both have significant pros and cons. I've been thinking (not a Linux expert by any means) the ideal solution would be to have better dependency management: I think a solution could be if say binaries themselves carried dependency information. That way you get the benefits of dynamic and static linking by just distributing binaries with embedded library requirements. Also, I think there should be a change of culture in library development to clearly mark compatibility breaks (I think something like semantic versioning works like that?). That way, your software could support any newer version up to a compatibility break -- which should be extremely rare. And if you must break compatibility there should be an effort to keep old versions available, secure and bug free (or at least the old versions should be flagged as insecure in some widely accessible database). Moreover, executing old/historical software should become significantly easier if library information was kept in the executable itself (you'd just have to find the old libraries, which could be kept available in repositories). I think something like that could finally enable portable Linux software? (Flatpak and AppImage notwithstanding) reply kentonv 14 hours agorootparentEverything you describe already exists. Executables do list their dependencies, and we have well-defined conventions for indicating ABI breaks. It is entirely normal to have multiple major versions of a library installed for ABI compatibility reasons, and it is also entirely normal to expect that you can upgrade the dependencies out from under a binary as long as the library hasn't had an ABI break. The bigger dependency management problem is that every distro has their own package manager and package repository and it's tough for one application developer to build and test every kind of package. But if they just ship a binary, then it's up to the poor user to figure out what packages to install. Often the library you need may not even be available on some distros or the version may be too old. reply rwmj 14 hours agorootparentThat's why distros ask you to provide just the sources and we'll do the packaging work for you. The upstream developers shouldn't need to provide packages for every distro. (Of course you can help us downstream packagers by not having insane build requirements, using semantic versioning, not breaking stuff randomly etc). reply kentonv 12 hours agorootparentThis is only realistic for established applications with large userbases. For new or very niche apps, distros are understandably not going to be very interested in doing this work. In that case the developer needs to find a way to distribute the app that they can reasonably maintain directly, and that's where containers or statically-linked binaries are really convenient. reply palata 10 hours agorootparentI agree with everything you said up to this. We're talking about a software library, for which the user is a software developer. IMO a software developer should be able to package a library for their own distro (then they can share that package with their community and become this package's maintainer). As the developer of an open source library, I don't think that you should distribute it for systems that you don't use; someone else who uses it should maintain the package. It doesn't have to be a \"distro maintainer\". Anyone can maintain a single package. I am not on a very mainstream distro, and I still haven't found a single package that I use and is not already maintained by someone in the community (though I wish I did, I would like to maintain a package). My point is that it really works well :-). I disagree with the idea that we should build a lot of tooling to \"lower the bar\" such that devs who don't know how to handle a library don't have to learn how to do it. They should learn, it's their job. For proprietary software, it's admittedly a bit harder (I guess? I don't have much experience there). reply rwmj 11 hours agorootparentprevThis isn't really true, Fedora, Debian and Arch have huge numbers of packages, many very niche. You might well need to make the distro aware that the new program exists, but there are established routes for doing that. reply charcircuit 11 hours agorootparentprev>Executables do list their dependencies They list paths to libraries, but not the exact version that the executable depends on. It is a common occurrence for executables to load versions of libraries they were not designed to be used with. reply josephg 14 hours agorootparentprevYes, if someone actually did dependency management in Linux properly then I agree - dynamic linking would be fine. It works pretty well in Nixos as I understand it. But it’s called dependency hell for a reason. And the reason is almost no operating systems handle C dependencies well. There’s always weird, complex, distribution specific systems involving 18 different versions of every library. Do you want llvm18 or llvm18-dev or llvm-18-full-dev or something else entirely? Oh, you’re on gentoo? Better enable some USE flags. Redhat? It’s different again. If Linux dependency management worked well, there would be no need or appetite for docker. But it works badly. So people just use docker and flatpak and whatnot instead, while my hard drive gently weeps. I don’t know about you, but I’m happy to declare bankruptcy on this project. I’d take a 2mb statically linked binary over a 300mb Linux docker image any day of the week. reply palata 10 hours agorootparent> If Linux dependency management worked well, there would be no need or appetite for docker. I kindly disagree here. Linux dependency management does work well. The problem is the bad libraries that don't do semver properly, and the users who still decide to use bad libraries. If people stopped using libraries that break ABI compatibility, then the authors of those libraries would have to do it properly, and it would work. The reason it doesn't work is really just malpractice. reply zaphar 10 hours agorootparentIf Linux dependency management works well in theory but not in practice then it doesn't work. It works in nix because it can literally use multiple minor versions of a library when it needs to with no problem. Most distro's can't or won't do that. You can call it malpractice but it's not going to stop so in practice you need a way to deal with it. reply palata 10 hours agorootparentWell, by calling it \"malpractice\", I say that it works for \"true professionals\". Then we could say that \"it doesn't work in practice if people who don't know what they are doing cannot use it\", of course. The question then is where we want to put the bar. I feel like it is too low, and most software is too bad. And I don't want to participate in making tooling that helps lowering the bar even more. reply StillBored 11 hours agorootparentprevThis isn't really an \"operating system\" problem. Particularly in the open-source world, there are a number of fairly core libraries that refuse to provide any kind of API compatibility. Then, when there are a couple dozen applications/etc that depend on that library, it's almost an impossible problem because each of those applications then needs to be updated in lockstep with the library version. There is nothing \"clean\" about how to handle this situation short of having loads of distro maintainers showing up in the upstream packages to fix them to support newer versions of the library. Of course, then all the distro's need to agree on what those versions are going to be... Hence containers, which don't fix the problem at all. Instead they just move the responsibility away from the distro, which should never really have been packaging applications to begin with. reply palata 10 hours agorootparent> away from the distro, which should never really have been packaging applications to begin with. I disagree here: the whole point of a \"software distribution\" is to \"distribute\" software. And it does so by packaging it. There is a ton of benefit in having distro/package maintainers, and we tend to forget it. reply arghwhat 8 hours agorootparentprevLinus Torvalds disagrees: https://lore.kernel.org/lkml/CAHk-=whs8QZf3YnifdLv57+FhBi5_W... reply gnramires 8 minutes agorootparentI should have been more balanced or nuanced a bit: I also don't think static linking is to be forbidden or completely shunned. As Linus himself says, a combination of both may be ideal. For basic system libraries like GUI libraries the current approach works well. But you should be free to static link if you want, and if there are serious issues if you don't. Maybe dynamic linking should be focused on a smaller number of well curated libraries and the rest should be left to static. Library archeology seems like a potential serious problem years from now. I still think better listing dependencies (perhaps with the option to pin an exact version?) would be helpful, as well as better usage of something like semver. Someone mentioned binaries include paths to dependencies, but as far as I know, there is no tool to automatically try to resolve those dependencies or standard interface, maybe some more tooling in this area would help. Another nice point about how it current works is that I think it relieves work from programmers. The policy of \"Don't worry about distribution (just tell us it exists)\" from distros seems like one less headache for the creator (and you can provide static linked binaries too if you want). As most things in life, the ideal is somewhere in the middle... reply manmal 2 hours agorootparentprevApple has been pushing dynamic libraries for a while, but now realized that they really like static linking better. The result is they found a way to convert dynamic libraries into static ones for release builds, while keeping them dynamic for debug builds: https://developer.apple.com/documentation/xcode/configuring-... reply nequo 11 hours agorootparentprev> Dynamic linking served us when OS upgrades came infrequently, user software was almost never upgraded Even today, dynamic linking is not only a security feature but also serves convenience. A security fix in OpenSSL or libwebp can be applied to everything that uses them by just updating those libraries instead of having to rebuild userland, with Firefox, Emacs, and so on. reply plopz 5 hours agorootparentThen why does every steam game need to install a different version of visual c++ redistributable? reply nequo 5 hours agorootparentBecause they are not packaged by the distros so they are not guaranteed to have the libraries present that they were linked against? I am just guessing, I haven’t used Steam. reply chaxor 11 hours agorootparentprevI'm not versed in this, so apologies for the stupid question, but wouldn't statically linking be more secure, if anything? Or at least have potentially better security? I always thought the better security practice is statically linked Go binary in a docker container for namespace isolation. reply tyingq 10 hours agorootparentIf there is a mechanism to monitor the dependency chain. Otherwise, you may be blissfully unaware that some vulnerability in libwhatever is in some binary you're using. Golang tooling provides some reasonable mechanisms to keep dependencies up to date. Any given C program might or might not. reply palata 10 hours agorootparent> If there is a mechanism to monitor the dependency chain. So that would not be less secure, but it would also not make it more secure than dynamic linking with a good mechanism, right? reply tyingq 9 hours agorootparentPersonally, I think any inherent security advantage (assuming it has great dependency management) would be very small. This \"Oasis\" project doesn't seem to call it out at all, even though they are making a fair amount of effort to track dependencies per binary. They cite the main benefits being this: \"Compared to dynamic linking, this is a simpler mechanism which eliminates problems with upgrading libraries, and results in completely self-contained binaries that can easily be copied to other systems\". Even that \"easily be copied to other systems\" sort of cites one of the security downsides. Is the system you're copying it to going to make any effort to keep the transient statically linked stuff in it up to date? reply teaearlgraycold 17 hours agorootparentprevYeah I’d prefer we just use another gigabyte of storage than add so much complexity. Even with what is a modest SSD capacity today I have a hard time imagining how I’d fill my storage. I’m reminded of my old workstation from 8 years ago. It had a 500GB hard drive and a 32GB SSD for caching. I immediately reconfigured to just use the SSD for everything by default. It ended up being plenty. reply jhallenworld 15 hours agorootparentprev>A linker typically only includes the parts of the library it needs for each binary so some parts will definately have many copies of the same code when you statically link but it will not make complete copies. Just to add to what you said: in the old days the linker would include only the .o files in the .a library that were referenced. Really common libraries like libc should be made to have only a single function per .o for this reason. But modern compilers have link time optimization, which changes everything. The compiler will automatically leave out any items not referenced without regard to .o file boundaries. But more importantly, it can perform more optimizations. Perhaps for a given program a libc function is always called with a constant for a certain argument. The compiler could use this fact to simplify the function. I'm thinking that you might be giving up quite a lot of performance by using shared libraries, unless you are willing to run the compiler during actual loading. Even without lto, you can have the same results in C++ by having your library in the form of a template- so the library is fully in the /usr/include header file, with nothing in /usr/lib. reply inkyoto 7 hours agorootparent> Just to add to what you said: in the old days the linker would include only the .o files in the .a library that were referenced. It was not exactly like that. Yes, the .o file granularity was there but the unused code from that .o file would also get linked in. The original UNIX linker had a very simple and unsophisticated design (compared to its contemporaries) and would not attempt to optimise the final product being linked. Consider a scenario where the binary being linked references A from an «abcde.o» file, and the «abcde.o» file has A, B, C, D and E defined in it, so the original «ld» would link the entire «abcde.o» into the final product. Advanced optimisations came along much later on. reply rwmj 14 hours agorootparentprevYou should be keeping track of those library dependencies anyway if you want to know what you have to recompile when, say, zlib or openssl has a security problem. reply ithkuil 14 hours agorootparentWell, you have to do that anyways reply giljabeab 11 hours agorootparentprevCan’t file systems de dupe this now reply inkyoto 7 hours agorootparentprev> A linker typically only includes the parts of the library it needs for each binary […] It is exactly the same with the dynamic linking due to the demand paging available in all modern UNIX systems: the dynamic library is not loaded into memory in its entirety, it is mapped into the process's virtual address space. Initially, there is no code from the dynamic library loaded into memory until the process attempts to access the first instruction from the required code at which point a memory fault occurs, and the virtual memory management system loads the required page(s) into the process's memory. A dynamic library can be 10Gb in size and appear as a 10Gb in the process's memory map but only 1 page can be physically present in memory. Moreover, under the heavy memory pressure the kernel can invalidate the memory page(s) (using LRU or a more advanced memory page tracking technique) and the process (especially true for background or idlying processes) will reference zero pages with the code from the dynamic library. Fundamentally, dynamic linking is the deferred static linking where the linking functions are delegated to the dynamic library loader. Dynamic libraries incur a [relatively] small overhead of slower (compared to statically linked binaries) process startup times due to the dynamic linker having to load the symbol table, the global offset table from the dynamic library and performing the symbol fixup according to the process's own virtual memory layout. It is a one-off step, though. For large, very large and frequently used dynamic libraries, caching can be employed to reduce such overhead. Dynamic library mapping into the virtual address space != loading the dynamic library into memory, they are two disjoint things. It almost never happens when the entire dynamic library is loaded into memory as the 100% code coverage is exceedingly rare. reply 1vuio0pswjnm7 8 hours agoparentprevI have seen this sort of statement on HN before. I am guessing that the persons who propagate this idea have never actually experimented with replacing dynamically-linked programs having numerous dependencies with statically-compiled ones. It's a theory that makes sense in the abstract, but they have not actually tested it. Though it is not a goal of mine to save storage space by using static binaries, and I actually expect to lose space as a tradeoff, I have actually saved storage space in some cases by using static binaries. This comes from being able to remove libraries from /usr/lib. TBH, I am not exactly sure why this is the case. Perhaps in part because one might be storing large libraries containing significant numbers of functions that one's programs never use. For me using static binaries works well. Even \"common\" libraries can be removed in some cases by using a multi-call/crunched binary like busybox. This might not work for everyone. I think much depends on what selection of programs the computer owner prefers. (Namely, the dependencies required by those programs.) reply Shorel 18 hours agoparentprevIn a world where Docker and Kubernetes exist, where whole copies of operating systems are added to each running service... This seems a weird thing to complain about =) reply palata 16 hours agorootparent> This seems a weird thing to complain about =) On the contrary, I find it relevant: I think that the modern way is wasting way, way too much. reply Shorel 14 hours agorootparentOn that respect, we agree. reply lnxg33k1 18 hours agorootparentprevYeah but there I can still update vulnerable libraries independently, to be a statically linked system just means that if there is a bug in libpng then I have to recompile everything? reply colonwqbang 16 hours agorootparentNot recompile I guess, but you need to relink everything. Oasis seems to have a good way of doing that, with the whole system being built in a single tree by an efficient build tool (my recollection from last time it was posted). A dynamic executable needs to relink every time it's run, which also takes time. reply nordsieck 15 hours agorootparentprev> if there is a bug in libpng then I have to recompile everything? You say that as if it's such a burden. But it's really not. I'm somewhat sympathetic to the space argument, but a package manager/docker registry means that updating software is very easy. And it happens all the time for other reasons today anyhow. reply Shorel 17 hours agorootparentprevI was under the impression only Gentoo users recompile everything. In a statically linked system, your dependency manager will update more packages. And if your program is written in C/C++/Go/Rust, then yes, it will be recompiled. reply lnxg33k1 16 hours agorootparentI use Gentoo, so I am not against rebuild everything, but afaik unless you have static-libs USE flag for something, it's dynamically linked so relinking on rebuilding the dependency is enough, with static-libs the dependent package is also rebuilt reply bzzzt 17 hours agorootparentprevYes, although it very much depends on how big 'everything' is if that's a problem. reply greyw 17 hours agorootparentprevIn most cases relinking is enough. reply kentonv 18 hours agorootparentprevI mean, if you ran every single executable on your desktop in a separate container I think you'd see problems. There are a pretty large number of programs running on most desktops, plus all the programs that get called by shell scripts, etc. Running a handful of containers representing major applications is more reasonable and the memory wastage may be worth it to avoid dependency conflicts. reply drakenot 17 hours agorootparentYou've just described Qubes OS! reply palata 13 hours agorootparentExcept that QubesOS uses VMs for their security benefits, which are greater than those of containers. Containers make a lot of sense to me on servers (\"deploy a controlled environment\"), but often on Desktop I feel like they are used as a solution to \"I don't know how to handle dependencies\" or \"My dependencies are so unstable that it is impossible to install them system-wide\", both of which should be solved by making slightly better software. reply Gabrys1 16 hours agorootparentprevEach electron app is like that reply Gazoche 16 hours agoparentprevI'll take bloat over dependency hell every day of the week. Feels like every single app is a bundled web browser these days anyways. reply nerpderp82 16 hours agorootparentDynamic Library hell is why Docker exists. If operating systems had less global state and less ambient authority, our systems would be vastly more tractable. Instead we still create environments that look like replicas of whole hosts. Might as well go all in and use something with pervasive virtualization like Qubes. https://www.qubes-os.org/ reply palata 11 hours agorootparentTo be fair, QubesOS does not really solve the problem of bad libraries creating dependency hell. If you need to ship every app with its own rootfs because you can't handle dependencies, then you will have to do that on QubesOS as well (you don't want one VM per app). Also the biggest problem I had with QubesOS is that it doesn't support GPU (for security reasons). It feels like that was a big cause for the reduced performance. I wish there was a solution for the GPU, and then I would love to daily-drive QubesOS. reply soulofmischief 10 hours agorootparentSame, I love Qubes' philosophy and UX, but GPU passthrough support was a dealbreaker in the end and I switched to a KVM system. reply IshKebab 11 hours agorootparentprevExactly this. Windows apps aren't distributed as Docker images. Guess why... reply palata 10 hours agorootparentWell nothing prevents you from dynamically linking only glibc and statically linking everything else, without Docker at all. The fact that people distribute their app with a full rootfs in a Docker containers says more about the fact that they don't know how to link stuff properly, IMHO. reply IshKebab 1 hour agorootparentIt's not about static vs dynamic linking at all. It's about bundling dependencies or not. And yes, you totally can do it. Most Linux software just doesn't bother because - while you can do it, in a lot of languages (C, Python, etc.) it's quite a pain to do. Especially if you have lots of dependencies. It's much easier to bundle dependencies in languages that statically link by default (Go, Rust) because of course statically linking implicitly bundles them. reply palata 16 hours agorootparentprev> dependency hell Dependency hell comes from bad dependencies that don't do semver properly. Choose your deps carefully, and that's perfectly fine. > Feels like every single app is a bundled web browser these days anyways. Yep, that's apparently the best way to use the bad libraries people want to use and not give a damn about semver. reply hn_go_brrrrr 15 hours agorootparentSemver is nearly impossible to do \"properly\" because of https://xkcd.com/1172. With a sufficient number of users, all bug fixes are breaking changes. If the behavior can possibly be observed in any way, some user will be depending on it, deliberately or otherwise. reply dwattttt 13 hours agorootparentSemver doesn't stop people from depending on unstable/implementation-specific behaviour; it needs to be coupled with a strong mechanism for defining what behaviour is defined by an API, and the result is that \"the bug\" is with all those users who depend on un-guaranteed behaviour. The breaks happen regardless, but you have a principled way of defining whose fault/problem it is. reply palata 13 hours agorootparentprevI would argue that https://xkcd.com/1172 is a case where the user \"deserves\" the breaking change, because they relied on a hack in the first place. That's the thing: I feel like people tend to call \"dependency hell\" what I would consider downright malpractice. \"Shared libraries don't work because they require good practice\" is, IMO, not a good argument against shared libraries. If you need to design your tool with the constraints that \"users will use it wrongly\", then it's already lost. reply Ar-Curunir 15 hours agorootparentprevSemver defines what is breaking and not-breaking. E.g., Rust semver says that \"code should continue compiling with a minor version bump, but not necessarily for a major version bump\" reply steveklabnik 14 hours agorootparentYes. The very first line of the spec: > Software using Semantic Versioning MUST declare a public API. This API could be declared in the code itself or exist strictly in documentation. However it is done, it SHOULD be precise and comprehensive. If it's not in the API, it is not bound by the rules. Many ecosystems come up with various norms, like Rust has, to help guide people in this. But it's almost certainly not a semver violation to make the change described in the XKCD because \"handle unknown unknowns\" is not possible. That doesn't mean that we should throw out the entire idea of software assisted upgrades to dependencies. reply IshKebab 10 hours agorootparentprevThere are various kinds of \"dependency hell\". To be honest I can't think of any that are due to not doing semver properly. Usually it's: 1. Software depending on versions of libraries that are newer than the latest version available on the distro you have to use (cough RHEL 8). E.g. this very day I ran into a bug where some Asciidoctor plugin craps out with an error because my version of Ruby isn't new enough. Ruby's advice for how to install Ruby is \"use your package manager; you will get an old version btw fuck you\". 90% of the time it's bloody glibc. Every Linux user has run into the dreaded glibc version error dozens of times in their career. 2. Software that can't install multiple versions of the same package, leading to diamond dependency issues. Python is very bad for this. reply palata 10 hours agorootparent> Software depending on versions of libraries that are newer than the latest version available on the distro you have to use (cough RHEL 8). That is a fair point, but it raises a question: if you absolutely need to use software that is not packaged by your distro of choice and that you cannot package yourself (are you sure you can't maintain a \"community\" package yourself with RHEL?), maybe you don't want that distro. Different distros come with different goals. If you take a \"super slow but secure\" distro, it will be slow and secure. If you take a rolling distro, you get updates very quickly but it has drawbacks. It depends on the use-case, but going for a \"slow and secure\" distro and then building tooling to work around that choice (\"nevermind, I'll ship new and less mature software anyway, statically linked\") seems to defeat the purpose of the distro... right? reply IshKebab 1 hour agorootparent> maybe you don't want that distro Well I definitely don't want RHEL 8 but unfortunately I have to use it because some software I use requires it (RHEL 9 doesn't have old enough versions of some libraries) or is only certified on it (this is for work). But even if I was using a more modern distro, none of them have all software packaged. And no I obviously don't want want to become a packager. Some of the software I use is closed source so that's not even an option. The only real option is Docker (or Apptainer/Distrobox etc), which sucks. The fundamental model of \"we'll just ship all software that exists; all software is open source\" that most distros try to use is just fundamentally wrong. Snap and Flatpak are trying to fix that but in my experience they aren't remotely ready yet. reply arghwhat 12 hours agoparentprevStatic linked binaries are a generally lot smaller than a dynamically linked library and its dependencies, especially with link-time optimizations and inlining. You wouldn't want have 100 tools statically link the entirety of chromium, but for normal C library sizes you don't get bloat. The preference for dynamic libraries in Linux distros is just so they can roll out patch updates in one place instead of rebuilding dependents. reply marwis 12 hours agorootparentBut dynamically linked library only needs to be loaded to RAM once whereas with static linking you'd be loading the same code many times (unless you compile everything to single binary like BusyBox). This also gets you better cache utilization. Also I think inlining would typically increase the total size of output rather than decrease it. reply arghwhat 8 hours agorootparentStatic linking gives you better instruction cache utilization as you are executing local code linearly rather than going through indirection with more boilerplate. This indirection costs a few cycles too. Inlining external code reduces the size not only by saving the call, PLT and and stack dance, but also through specialization (removal of unused conditional, pruning of no longer referenced symbols) as the code is locally optimized. This further reduction in size further improves cache behavior and performance. Duplication can be an issue (not necessarily for performance, but for total binary size), but compilers have heuristics for that. Even just having the symbol local saves some space and call overhead though (no PLT). The case for the shared library having better caching implies multiple processes that are distinct executables (otherwise they share program memory regardless of linkage) trying to hammer it at once, sharing the continued caching, but such scenario is hurt by the call overhead and lower optimization opportunities, negating the result. reply marwis 7 hours agorootparent> The case for the shared library having better caching implies multiple processes that are distinct executables But this is the most common case for desktops/multipurpose systems. On my desktop there are tens or hundreds distinct processes sharing most of their code. reply inkyoto 6 hours agorootparentprev> Static linking gives you better instruction cache utilization as you are executing local code linearly rather than going through indirection with more boilerplate. No, it does not, it worsens it. For example, «strlen», if it comes from a dynamic library, will be loaded into the physical memory once and only once, and it will be mapped into each process's address space as many times as there are processes. Since «strlen» is a very frequently used function, there is a very high chance that the page will remain resident in memory for a very long time, and since the physical page is resident in memory, there is also a very good chance that the page will remain resident at least in the L2 cache, but – depending on circumstances – in the L1 cache, too. A TLB flush might not even be necessary in specific circumstances, which is a big performance win. It is a 1:N scenario. With the static linking, on the other hand, if there are 10k processes in the system, there will be 10k distinct pages containing «strlen» loaded into memory at 10k random addresses. It is a M:N scenario. Since the physical memory pages are now distinct, the context switching will nearly always require the TLB to be flushed out which is costly or very costly, and more frequent L1/L2 cache invalidations due to «strlen» now residing at 10k distinct physical memory addresses. P.S. I am aware that C compilers now inline «strlen» so there is no actual function call, but let's pretend that it is not inlined for the sake of the conversation. reply jhallenworld 12 hours agorootparentprevSo you only need to load duplicated code for each different statically linked program. If there are many processes running the same program, they will all share the same physical pages for the code. So for example, having 100s of \"bash\" instances running does not use that much memory. You can see this by running \"pmap-XX\" (the output is very wide- probably load it into an editor). Look at the shared vs. private pages. Also: There is another way to automatically share pages between different programs: de-duplication. This would require common libraries to be statically linked on page boundaries. The OS would quickly de-duplicate during loading by hashing the pages. VMs use this technique to increase effective memory when there are many guest OS running. reply marwis 12 hours agorootparentYes but most processes are unique. The only bash process I have running is my interactive shell. reply zshrc 18 hours agoparentprevmusl is significantly smaller and \"less bloat\" than glibc, so even with a statically linked program, it still remains small in both system memory and storage. reply skywal_l 18 hours agorootparentAnd using LTO[0] can also help. [0]https://gcc.gnu.org/wiki/LinkTimeOptimization reply jacquesm 16 hours agoparentprevNot necessarily. Bloat is one reason why originally dynamic linking was rolled out but the bigger benefit (to manufacturers) was to be able to update libraries without updating the applications. This has been the source of much trouble (dependency hell) and statically linked binaries suffer none of these issues. It's not like every application uses all of every library and an efficient linker is able to see which parts of the library it needs to link and which parts it can safely leave out. reply javierhonduco 11 hours agoparentprevOnce it’s loaded in memory, if Kernel Samepage Merging is enabled it might not be as bad, but would love to hear of somebody has any thoughts https://docs.kernel.org/admin-guide/mm/ksm.html reply LegionMammal978 11 hours agorootparentFrom the link: > KSM only merges anonymous (private) pages, never pagecache (file) pages. So it wouldn't be able to help with static libraries loaded from different executables. (At any rate, they'd have to be at the same alignment within the page, which is unlikely without some special linker configuration.) reply javierhonduco 11 hours agorootparentHad completely missed that line — great point! reply liampulles 18 hours agoparentprevIt would be bloated, but how big of a problem is that these days? A TB of storage is pretty cheap. reply cmovq 17 hours agorootparentA TB of memory is not reply bzzzt 17 hours agoparentprevI know lots of compilers/linkers don't optimize for it but it should be possible to 'tree shake' libraries so only the parts that are used by an application are included. That would shake off a lot of the 'bloat'. reply volemo 17 hours agorootparentWait, it's not being done? reply dieortin 15 hours agorootparentIt is, major compilers do that by default reply Fronzie 12 hours agorootparentprevAs far as I know, even with LTO, it requires -ffunction-sections -fdata-sections in order to strip out unused functions. reply Gabrys1 16 hours agoparentprevI guess each of the copies of libc can be optimized away and only the functions the specific binary calls will be left (and the compiler should be allowed to optimize past the library boundary), so maybe this balances the issues a bit. Not that I really know anything about it, ask jart reply thanatos519 18 hours agoparentprevKSM could help with that: https://docs.kernel.org/admin-guide/mm/ksm.html ... oh wait, the apps have to hint that it's possible. Nebbermind. reply Rochus 18 hours agoprevInteresting, but what is the use case? What is the advantage of using the croc C compiler instead of e.g. TCC? I wasn't aware of Netsurf (https://www.netsurf-browser.org/); this is really amazing. But it seems to use Duktape as the JS engine, so performance might be an issue. reply helloimhonk 17 hours agoparentcproc supports C11, tcc only goes up to c99. There is also something to be said for cproc using QBE which is slowly growing backends like risc-v etc which tcc doesnt support afaik. reply Rochus 16 hours agorootparentOk, thanks, that makes sense. QBE looks interesting, but I'm missing 32 bit support. So currently I'm trying to reuse the TCC backend, which is far from trivial. reply willy_k 11 hours agoparentprevTangential, but the trailing “/“ in the URL you gave seems to include the “);” in the hyperlink, giving a “Not Found” error. Working link: https://www.netsurf-browser.org reply mike_hock 10 hours agoparentprevhttps://www.netsurf-browser.org/documentation/ Every single link on that page is dead. https://www.netsurf-browser.org/about/screenshots/ Judging by the screenshots, it can render BBC, its own website, and Wikipedia. Well, it might be able to render others, we just can't tell from the shots. But we can tell those three websites work with all sorts of different window decorations. reply Rochus 9 hours agorootparent> Every single link on that page is dead Unfortunately, as it seems. On the start page they say \"Last updated 2 January 2007\". But version 3.11 was released on 28 Dec 2023. reply cpach 18 hours agoparentprevAFAICT it could be useful for embedded devices. reply schemescape 17 hours agoprevDoes anyone know how big the base installation is? I couldn't find an answer anywhere, and the link to the QEMU image appears to be broken, currently. I'm curious how it compares to, say, Alpine with a similar set of packages. reply jackothy 12 hours agoparentI have an old (2020) .qcow2 lying around that's about 360MB reply xiconfjs 12 hours agorootparentcould you please upload it? reply elfstead 11 hours agorootparenthttps://elfstead.com/archive/oasis-qemu.tar.xz reply __s 19 hours agoprevmichaelforney was also who did the wayland port of st: https://github.com/michaelforney/st oasis's predecessor would be https://dl.suckless.org/htmlout/sta.li reply sigsev_251 18 hours agoparentMichaelforney has also built croc [1], a qbe based C compiler. Really impressive! [1]: https://github.com/michaelforney/cproc reply Koshkin 13 hours agorootparentNot as \"impressive\" as TCC, I'd say. Why? TCC has its own backend, and it has the preprocessor built in. (But QBE is indeed impressive.) reply ratrocket 10 hours agoprevThere's a (dead) comment lamenting that you can't access Github with javascript turned off. The Oasis repo seems to be mirrored on sourcehut, though, so if that's more acceptable: https://git.sr.ht/~mcf/oasis reply lproven 10 hours agoprevPrevious discussion (Aug 2022): https://news.ycombinator.com/item?id=32458744 reply sluongng 18 hours agoprevWhat is the comparison between using musl and traditional glibc? Is there performance differences between the two? I have been seeing musl used more and more in both Rust and Zig ecosystems lately. reply digikata 18 hours agoparentOne of the reasons I've switched some builds over to musl over glibc, is that I found that glibc linking is brittle if you're going to run a binary over multiple distros in various container environments. Particularly if you want one binary to work on linux across RH and Debian/Ubuntu derived distros or even different ages of distro. reply skywal_l 17 hours agorootparentLinus Torvald agrees with you: https://youtu.be/Pzl1B7nB9Kc?feature=shared&t=261 reply o11c 17 hours agoparentprevThe real comparison is: musl does not provide any preprocessor macro to tell you what libc you're using. And it has so many weird quirks that you need to work around. *** Static linking makes linking more painful, especially regarding global constructors (which are often needed for correctness or performance). This is not a musl-specific issue, but a lot of people are interested in both. Just do your builds on the oldest supported system, and dynamic linking works just fine. You can relative-rpath your non-libc dependencies if they would be a pain to install, though think twice about libstdc++. *** The major advantage of MUSL is that if you're writing a new OS, it's much easier to port. reply yjftsjthsd-h 2 hours agorootparent> musl does not provide any preprocessor macro to tell you what libc you're using. > And it has so many weird quirks that you need to work around. I was under the impression that musl stuck closely to the standard, and glibc frequently did its own thing, so 1. it's not musl that's quirky, 2. if you need to detect something, just detect glibc. reply ComputerGuru 17 hours agoparentprevSpeaking from heavy experimentation and experience, [0] glibc has some more optimized routines but musl has significantly less bloat. If you are haphazardly calling libc functions left and right for everything and have a generally unoptimized code base, your code may fare better better with glibc. But musl’s smaller codebase is a win for faster startup and micro optimizations otherwise - and that’s without lto where it stands to gain more. [0]: https://neosmart.net/blog/a-high-performance-cross-platform-... Edit: Sorry, the correct link is this one: https://neosmart.net/blog/using-simd-acceleration-in-rust-to... reply jart 17 hours agorootparentIf you want an optimized Musl, try Cosmopolitan in `make toolchain MODE=tinylinux`, since it's based on Musl, and its string routines go 2x faster. reply ComputerGuru 17 hours agorootparentI don’t think that was around back then but I can add it to the backlog of things to try for next round. Does that play nice with rust? Presumably I’d have to at least build the standard library from scratch (which I’d want to do against musl as a separate benchmark anyway since it’s now a single environment variable away). (Not that the codebase makes much string function usage.) reply jart 13 hours agorootparentIt should if everything is static and you're only targeting Linux. reply skywal_l 18 hours agoparentprevglibc is LGPL. Static linking your application implies some obligation on your part. Musl being MIT is less restrictive. reply actionfromafar 16 hours agorootparentNot very tough obligations, but it can be a practical hassle. This answer describes it quite well I think: https://opensource.stackexchange.com/questions/13588/how-sho... reply Zambyte 18 hours agorootparentprev> Musl being MIT is less restrictive. It depends who you're speaking for reply bigstrat2003 15 hours agorootparentNo it doesn't. The MIT license is objectively less restrictive than the LGPL. Whether it's a good or bad thing to be less restrictive is a matter of opinion, but whether or not it is less restrictive is a matter of fact. reply Zambyte 12 hours agorootparentLots of software licensed as MIT is distributed under a proprietary sublicense, which is as restrictive as it gets. That isn't the case with GPL licenses. It is a matter of fact that it's a matter of perspective. reply joveian 13 hours agoparentprevFunctional differences described here: https://wiki.musl-libc.org/functional-differences-from-glibc... reply znpy 18 hours agoparentprev> What is the comparison between using musl and traditional glibc? you get weird bugs and failures that don't happen with glibc (like the incomplete dns resolving routines that would fail under some conditions) but you can brag about saving 30-40 mb of disk space. this project seems to be compromising on quality overall, in the name of having smaller size. Even BearSSL, by their own website is beta-quality: \"Current version is 0.6. It is now considered beta-quality software\" (from https://bearssl.org/). reply ghotli 18 hours agorootparenthttps://musl.libc.org/releases.html I maintain a large codebase, widely deployed, cross compiled to many cpu architecures that's built atop musl. You're right that historically in the context of people blindly using alpine for their container base that sort of thing might be the case. The newest version of musl solves the thing you're describing and in general most of the complaints about malloc perf or otherwise have been addressed. Avoiding musl to me seems like an outdated trope, but there was a time wherein that take was valid indeed. reply NewJazz 16 hours agorootparentmalloc performance is still sub-par IMO. It is not nearly as terrible as it was, but scudo, memalloc, and glibc's malloc are better. reply electroly 18 hours agorootparentprev> incomplete dns resolving routines They eventually did fix this, as of musl 1.2.4. reply o11c 17 hours agorootparentWhile not an issue for musl-centric distros if they keep updated, note that e.g. Debian stable doesn't have that version yet, so good luck testing. reply electroly 17 hours agorootparentAt least we have light at the end of the tunnel now. This is a tremendous improvement from the previous status quo of the musl maintainers not even agreeing that it's a problem. reply znpy 16 hours agorootparentThis alone “musl maintainers not even agreeing it’s a problem” should be a good reason to avoid musl imho reply electroly 16 hours agorootparentWhat's a better option for static linking? glibc is religiously against it; they have far worse dogmatic beliefs than this musl DNS thing. I'd be happy to choose a better alternative if one exists, but if one does not, I have to live with the options at hand. From where I'm standing, musl seems like the only game in town. uClibc doesn't seem like it's appropriate for general purpose Linux applications on desktop computers (maybe I'm wrong?). reply znpy 8 hours agorootparent> glibc is religiously against it from my understanding glibc is not \"religiously\" against it, they're against it for technical reasons. In the sense, this is not a dogma. It's about internal details of their implementations. See: https://stackoverflow.com/questions/57476533/why-is-statical... reply o11c 15 hours agorootparentprevStatic linking doesn't actually solve any problem. Just use dynamic linking with (probably relative) rpath, and compile against a sufficiently old libc. There's some common FUD about rpath being insecure, but that only applies if the binary is setuid (or otherwise privileged) and the rpath is writable by someone other than the binary's owner (all relative rpaths are writable since you can use symlinks; absolute rpaths are writable if they point to /tmp/ or a similar directory, which used to be common on buildbots). This is really not hard; working around all static linking's quirks is harder. reply schemescape 14 hours agorootparentWhat are the quirks of static linking you need to work around (in general, not for glibc)? reply o11c 13 hours agorootparentYou have to know the internals of your dependencies so you can link them explicitly, recursively. (admittedly, pkg-config helps a ton, but not all libraries ship (good) .pc files) Global constructors no longer reliably fire unless you are extremely careful with your build system, nor do they run in a predictable order (e.g. you can call a library before it is actually initialized, unlike dynamic linking where only preinit - which nobody uses - is weird), nor can you defer them until dlopen time if you want (which is, admittedly, overdone). It's possible to link to parts of multiple versions of a library (remember, you have to recurse into your dependencies), as opposed to dynamic libraries where at least you're guaranteed all-or-nothing (which is much easier to detect). Linking is slower since it always has to be redone from scratch. Not resilent against system changes. For example, old versions of `bash-static` (grab them from e.g. Debian snapshot and extract them manually; don't install them) are no longer runnable on modern systems since certain system files have changed formats, whereas the dynamically-linked `bash` packages still run just fine. It also encourages bad stability habits, leading to the equivalent of NPM hell, which is far worse than DLL hell ever was. You can't use LD_PRELOAD or other dynamic interception tools. There are probably more reasons to avoid static linking, but I'm trying to ignore the handful from the popular lists. reply schemescape 11 hours agorootparentThanks! Most of those seem like a fair trade-off for portability… for an app. I’m not sure it’s a great idea for an OS as in the OP, but I do like that they claim accurate incremental rebuilds, to ensure everything get updated. Certainly an interesting experiment! Edit: just to clarify, I meant \"app\" as in \"something that isn't part of the OS/distribution\". reply o11c 9 hours agorootparentThe bash-static example alone is proof that the \"usefulness\" for apps isn't actually there. reply raesene9 18 hours agorootparentprevA small point on that last bit. The bearssl authors are pretty conservative when it comes to development milestones, I'd guess that their 0.6 would be pretty solid :) reply znpy 18 hours agorootparent> I'd guess that their 0.6 would be pretty solid :) Would you accept that kind of reasoning for software running on your pacemaker, or on your insuline pump? I think we should respect the developers here: they're not claiming production quality level (they're claiming beta-quality level) so it's not correct to use that library in any kind of product and claim any kind of production-level quality. reply ComputerGuru 17 hours agorootparentI would run away from using glibc on an insulin pump or pacemaker, so I’m not sure what point you’re trying to make. reply foul 17 hours agorootparentprev> Would you accept that kind of reasoning for software running on your pacemaker, or on your insuline pump? God helps me I wouldn't implant anything so fundamental in my body with hard dependencies on encrypted communication to a remote agent elsewhere, no matter the advantage. reply fullspectrumdev 16 hours agorootparentprev30-40mb of disk space is absolutely huge in some environments even today though reply eterps 19 hours agoprevInteresting choices, finally something that isn't just another Linux distribution. reply nightowl_games 18 hours agoprevCan someone explain a couple use cases for something like this? reply ghotli 18 hours agoparentI routinely get embedded linux devices at $dayjob that need my time and attention and they basically never have the tooling I need to get my job done. I'm a pro at looking at how Alpine builds a tool and then just making my own statically linked / minimal size tool to drop in place on the device. The allure of something like this is that I can just potentially grab a drop-in binary and get on with my day. I simply don't attempt to link to libraries already on the device since they're all built in wildly different ways, old tools, old compilers. Hopefully that's helpful context. Overall since I did linux from scratch half a lifetime ago I've always wondered why something like Oasis hasn't gotten more traction. It's got some ambitious ideas in the README so maybe others have other nice use-cases atop all that. I just see small, statically linked and think 'oh boy if i never have to build my own tools again for some weird board'. If so, I'm here for it. reply 8organicbits 18 hours agorootparent> grab a drop-in binary This is a cool approach on Docker as well. FROM some:thing AS bins FROM debian:latest COPY --from=bins /bin/foo /bin/ reply ghotli 18 hours agorootparentAgreed, if the binary is statically linked. If you run `file` on the output from that and it shows 'dynamically linked' then you're playing games with porting over libraries, changing the library loading path, or just going full chroot like linux from scratch does with the bootstrapping part of the install. I find static binaries simplest to work with in that context but agreed I use that pattern too with docker and generally build ad-hoc tools within containers like that. If only these devices could run docker but I'm left to my own tooling to figure out per device. reply lloeki 17 hours agorootparentIn a way, that's what Nix sets out to do, isolating even dynamically linked libraries: if two derivations depend on the same shared lib derivation then it's reused, if not then they don't conflict. Each leaf derivation can be handled completely independently of the others, and independently of the original system†. And then when Nix† is not an option at runtime, dockerTools†† can build a Docker image to do the minimisation+isolation. That said, Nix might also be completely overkill in some scenarios where static linking would be just fine and very practical. The practical simplicity of a single binary should not be overlooked. † nixpkgs is sufficient, a full nixos is not needed †† https://nixos.org/manual/nixpkgs/stable/#sec-pkgs-dockerTool... reply vacuity 15 hours agorootparentSo Nix keeps track of different versions of shared libraries? reply sporeray 14 hours agorootparentYeah, each package/lib is stored in a unified directory by it's hash https://zero-to-nix.com/concepts/nix-store. Different variation different hash. reply 8organicbits 18 hours agorootparentprevAgreed, dynamically linked binaries don't drop in well. reply nightowl_games 5 hours agorootparentprevI still don't understand. Is oasis the \"drop in binary\" you would use? Or do you use oasis to build the tool that you would use? \"The allure of something like this is I could potentially grab a drop in binary\" From where? reply enriquto 17 hours agoparentprev> Can someone explain a couple use cases for something like this? At this point, it would be more useful if someone explained a couple of use cases for dynamic linking. reply pjmlp 15 hours agorootparentPlugins, unless you want to have one process per plugin. Which in the days of running Kubernetes clusters on laptops maybe isn't a big deal. reply enriquto 14 hours agorootparentYou can still call dlopen from your static binary, if you really want to. reply mappu 13 hours agorootparentI tried to do this recently at $DAYJOB, but when you statically link a binary with musl, the dlopen() you get is a no-op: https://github.com/bpowers/musl/blob/master/src/ldso/dlopen.... I tried to hack in a copy of the musl's dynamic loader (and also from old uclibc). But it took a few hours and my only result was segfaults. Do you have any pointers on making this work? reply enriquto 10 hours agorootparentHave you tried it with glibc? It's harder to build static binaries with it, but it's still possible, and it may work. To debug your problem, do you have a minimal example at your fingertips to try? Just a \"hello world\" dynlib that is called from a static program that doesn't do anything else. reply pjmlp 13 hours agorootparentprevSure lets go back to 1980's UNIX, it was such a great experience. reply pjmlp 18 hours agoparentprevYou miss UNIX developer experience until mid-1980's, before shared objects came to be. reply mech422 13 hours agorootparentHeh...rebuilding gcc on slackware to enable shared libs was an adventure - but that wasn't till the late 90s(??). I think I spent like a week bootstrapping the new gcc, rebuilding glibc and rebuilding all the stuff I used. reply pjmlp 13 hours agorootparentUNIX System V 4.0 was the one that kind of uniformized existing parallel solutions from UNIX variants, alongside ELF in the late 1980's. reply mech422 5 hours agorootparentyeah - I never had access to a 'real' unix. Closest I came was solaris and maybe Irix. Other then that, it's just been Linux. Keep meaning to give *BSD a try... P.S. - oh! and I had friends that loved HP/UX - another one I never got to try reply ekianjo 18 hours agoparentprevimmutable images reply notfed 15 hours agoprev> Fast builds that are 100% reproducible. It's unclear to me what \"100%\" refers to here, but surely it does not include the Linux kernel or drivers? (I've recently read conversations about how difficult this would be.) reply azornathogron 15 hours agoparentI'm no expert, but as an interested amateur I thought the Linux kernel could already be built reproducibly? There is some documentation at least... and I know several Linux distributions have been working on reproducible builds for a long time now - I'd be surprised if there hasn't been good progress on this. https://www.kernel.org/doc/html/latest/kbuild/reproducible-b... reply dayjaby 12 hours agorootparentIn container context I've heard a definition of \"100% reproducible\" that means even file timestamps are 100% the same. Like your entire build is bit-by-bit precisely the same if you didn't modify any source. Not sure if that's what they mean here. reply hn_go_brrrrr 15 hours agoparentprevGot a link? Sounds interesting. reply notfed 7 hours agorootparentHere's a link to a recent HN discussion: https://news.ycombinator.com/item?id=38852616 TLDR: Linux kernel doesn't have a stable binary kernel interface. And they don't want one. Given this, the definition of \"reproducible build\" needs, well, a refined definition, if it includes the Linux kernel. [1] https://www.kernel.org/doc/Documentation/process/stable-api-... reply Koshkin 18 hours agoprevThere’s also the “suckless” sta.li reply ratrocket 17 hours agoparentA comment up-thread (currently) says/implies Oasis is a successor to sta.li by the same person. https://news.ycombinator.com/item?id=39143029 I also thought sta.li when I saw this was about a statically linked linux system... reply lubutu 12 hours agorootparentIt's not by the same person — sta.li was by Anselm R Garbe. It's more like a spiritual successor. reply ratrocket 10 hours agorootparentAh, thank you for the clarification. I read the linked to (by me) comment too quickly and/or without thinking enough! Cheers! reply m463 11 hours agoprevHow big is it? I could imagine there were unexpected efficiencies. Although dynamic libraries should be able to share an address space, I think with static libraries, the linked might strip out unused routines. also, it might be faster reply speedgoose 15 hours agoprevBearSSL development’s seems to have stopped and it’s lacking TLS1.3. Are there promising alternatives? reply asmvolatile 15 hours agoparentwolfSSL. Open source, widely used, flexible licensing model, TLS + DTLS 1.3 support, support for all modern ciphers and protocol extensions, extremely tuneable for performance/size, FIPS module, excellent customer support, the list goes on.... reply sylware 13 hours agoprevFor a real statically-linked linux system, the main issue is GPU support: you must relink all apps _really using_ a GPU, that to include the required GPU drivers. With sound, alsa, it is fine since there is IPC/shared-memory based mixing that whatever the playback/capture devices [dmix/dsnoop]. Static linking is reasonable. (pulseaudio[012] IPC interfaces are bloaty kludges, hardly stable in time, 0..1..2.., not to be trusted compared to the hardcore stability of alsa one able to do a beyond good enough job *and* _real_ in-process low latency hardware access at the same time). x11 and wayland are IPC based, then no issue here neither. But for the GPU, we would need a wayland vulkan3D-inspired set of IPC/shared-memory interfaces (with a 3D enabled wayland compositor). For compute, the interfaces would be de-coupled from the wayland compositor (shared dma-buffers). The good part of this would be to free our system interfaces from the ultra complex ELF (one could choose an excrutiatingly simple executable file format, aka a modern executable file format, but will need compilers/linkers support to help legacy support). There is a middle ground though: everything statically linked, except the apps requiring the GPU driver (for that ELF is grotesquely overkill), still provided as a shared library. reply AshamedCaptain 12 hours agoparentI ponder which kind of malaise would push one to dismiss ELF as \"ultra complex\" and at the same time propose pervasive IPC through the entire system including Vulkan calls through IPC. reply stefan_ 12 hours agoparentprevTo be fair ELF is complex mostly because of relocations, which are not purely to support shared libraries but also the nowadays ubiquitous PIE. But GPU drivers is a good point; I don't believe you can even statically link them today, you would only be statically linking a shim that tries to find the real driver at runtime. reply sylware 12 hours agorootparentI am exploring an executable file format of my own (excrutiatingly simple, basically userland syscalls) which is only PIE, and until now, the main real \"issue\" (not really) is actually the lack of support from compilers for static relative global data init (handled by ELF... which is not there anymore). About the shared libs, well, they are the utility shared libs, and the system interface shared libs. With a mostly statically linked elf/linux distro, all the utility libs would be statically linked, and the system interface shared libs would be statically linked if they have an IPC/shared-mem interface. In the end, only the GPU driver is an issue, namely would stay a shared libs. reply lordwiz 18 hours agoprevInteresting, Like how its focused on making it lean by having less bloated versions of the tools reply transfire 4 hours agoprevSomehow this reminds me of Gentoo. reply hkt 19 hours agoprevThis is very very cool. I love the bloat free nature of the thing, especially velox (the WM). Samurai (build system) also looks pretty interesting. I've not managed to work out quite how samurai works, or truthfully, why it differs from ninja, but this project is exactly the kind of brain food I intend on learning a lot from. Many, many props to Michael Forney. reply alexnewman 11 hours agoprevNow I just need them to switch to GitHub actions for the ci/cd reply malux85 18 hours agoprevAnyone have a link to the QEMU tarball in the README? It is hosted on a private server and it looks like it's been HN hugged reply jollyllama 13 hours agoprevAnyway, here's wonder -Wall reply notnmeyer 13 hours agoparentthis is funnier than it has any right to be reply peter_d_sherman 18 hours agoprev [–] I've added links to the below quote: >\"oasis uses smaller and simpler implementations of libraries and tools whenever possible: musl instead of glibc (https://www.musl-libc.org/) sbase instead of coreutils (https://git.suckless.org/sbase/file/README.html) ubase instead of util-linux (https://git.suckless.org/ubase/file/README.html) pigz instead of gzip (https://zlib.net/pigz/) mandoc instead of man-db (https://mandoc.bsd.lv/) bearssl instead of openssl (https://bearssl.org/) oksh instead of bash (https://github.com/ibara/oksh) sdhcp instead of dhclient or dhcpcd (https://core.suckless.org/sdhcp/) vis instead of vim or emacs (https://github.com/martanne/vis) byacc instead of bison (https://invisible-island.net/byacc/) perp and sinit instead of sysvinit or system 44 (http://b0llix.net/perp/ https://github.com/wereHamster/perp https://troubleshooters.com/linux/diy/suckless_init_on_plop....) netsurf instead of chromium or firefox (https://www.netsurf-browser.org/) samurai instead of ninja (https://github.com/michaelforney/samurai) velox instead of Xorg (https://github.com/michaelforney/velox) netbsd-curses instead of ncurses (https://github.com/sabotage-linux/netbsd-curses)\" (Oh, and not to quote Dwayne \"The Rock\" Johnson's character \"Maui\" from Disney's Moana or anything -- but \"You're welcome!\":-) ) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Oasis is a Linux-based operating system that resembles BSD and emphasizes simplicity and customization.",
      "It uses completely statically linked software, fast and reproducible builds, and minimal bootstrap dependencies.",
      "Oasis does not have a package manager but is compatible with pkgsrc and nix, and it uses BearSSL as its TLS and crypto library."
    ],
    "commentSummary": [
      "The discussion covers topics related to Linux systems, including the use of Oasis for creating immutable OS images and the benefits of static and dynamic linking in software development.",
      "Users explore dependency management, distributed compilation, and the challenges of GPU support.",
      "Different libraries, compilers, and alternative solutions like Docker and Nix are discussed, with varying opinions and suggestions on optimizing libraries and binaries, managing dependencies, and improving system stability."
    ],
    "points": 463,
    "commentCount": 215,
    "retryCount": 0,
    "time": 1706278296
  },
  {
    "id": 39143043,
    "title": "ICJ Orders Israel to Prevent Genocide in Gaza, Fails to Order Ceasefire",
    "originLink": "https://apnews.com/article/israel-gaza-genocide-court-south-africa-27cf84e16082cde798395a95e9143c06",
    "originBody": "The United Nations’ top court stopped short Friday of ordering a cease-fire in Gaza in a genocide case but demanded that Israel try to contain death and damage in its military offensive in the tiny coastal enclave. (Jan. 26) Read More Videos 5 Photos 14 By MIKE CORDER and RAF CASERT Updated 4:39 AM UTC, January 27, 2024 Share Share Copy Link copied Email Facebook X Reddit LinkedIn Pinterest Flipboard Print THE HAGUE, Netherlands (AP) — The United Nations’ top court on Friday ordered Israel to do all it can to prevent death, destruction and any acts of genocide in Gaza, but the panel stopped short of ordering an end to the military offensive that has laid waste to the Palestinian enclave. In a ruling that will keep Israel under the legal lens for years to come, the court offered little other comfort to Israeli leaders in a genocide case brought by South Africa that goes to the core of one of the world’s most intractable conflicts. The court’s half-dozen orders will be difficult to achieve without some sort of cease-fire or pause in the fighting. “The court is acutely aware of the extent of the human tragedy that is unfolding in the region and is deeply concerned about the continuing loss of life and human suffering,” court President Joan E. Donoghue said. undefined AP AUDIO: Top UN court orders Israel to prevent genocide in Gaza but stops short of ordering cease-fire. The president of the International Court of Justice, Joan E. Donoghue, says a Hamas attack on October 7, 2023, triggered a major response by Israel. ISRAEL-HAMAS WAR: READ MORE Israel vows to fight Hamas all the way to Gaza’s southern border. That’s fueling tension with Egypt Gaza’s Health Ministry blames Israeli troops for deadly shooting as crowd waited for aid How genocide officially became a crime, and why South Africa is accusing Israel of committing it The ruling amounted to an overwhelming rebuke of Israel’s wartime conduct and added to mounting international pressure to halt the nearly 4-month-old offensive that has killed more than 26,000 Palestinians, decimated vast swaths of Gaza and driven nearly 85% of its 2.3 million people from their homes. Allowing the accusations to stand stung the government of Israel, which was founded as a Jewish state after the Nazi slaughter of 6 million Jews during World War II. Israeli Prime Minister Benjamin Netanyahu said the fact that the court was willing to discuss the genocide charges was a “mark of shame that will not be erased for generations.” He vowed to press ahead with the war. The power of the ruling was magnified by its timing, coming on the eve of International Holocaust Remembrance Day. Later Friday, U.N. Secretary-General Antonio Guterres stressed that the top court’s rulings are legally binding and “trusts” that Israel will comply with its orders, including “to take all measures within its power” to prevent acts that would bring about the destruction of the Palestinian people. “Those truly needing to stand trial are those that murdered and kidnapped children, women and the elderly,” former Israeli Defense Minister Benny Gantz said, referring to Hamas militants who stormed through Israeli communities on Oct. 7 in the attack that set off the war. The assault killed some 1,200 people and resulted in another 250 being kidnapped. The court also called on Hamas to release the hostages who are still in captivity. Hamas urged the international community to make Israel carry out the court’s orders. Many of the measures were approved by an overwhelming majority of the judges. Of the six orders, an Israeli judge voted in favor of two — an order for humanitarian aid and another for the prevention of inflammatory speech. Israeli Judge Aharon Barak said he supported those orders in the hope that they would “help to decrease tensions and discourage damaging rhetoric” while easing the ”consequences of the armed conflict for the most vulnerable.” Such provisional measures issued by the world court are legally binding, but it is not clear if Israel will comply with them. “We will continue to do what is necessary to defend our country and defend our people,” said Netanyahu, who pushed back against the ruling in two languages. In a message aimed at his domestic audience, the tone was more defiant in Hebrew, and he stopped short of overtly criticizing the court in English. The court ruled that Israel must do all it can to prevent genocide, including refraining from harming or killing Palestinians. It also ruled that Israel must urgently get basic aid to Gaza and that the country should punish any incitement to genocide, among other measures. The panel told Israel to submit a report on steps taken within a month. “That’s a time that the court could come back and say, ‘You have not met the orders. You have not complied. Now we find you are in the midst of committing genocide,’” said Mary Ellen O’Connell, a professor of law and international peace studies at Notre Dame University’s Kroc Institute. Friday’s decision was an interim ruling. It could take years for the court to consider all aspects of South Africa’s genocide allegations. The U.N. Security Council scheduled a meeting for Wednesday to follow up on the ruling. In Israel, commentators said the decision not to order a cease-fire was received with some relief since it helped Israel avoid a collision with a top U.N. body. Palestinians and their supporters said the court took an important step toward holding Israel accountable. The Foreign Ministry of the internationally backed Palestinian self-rule government in the West Bank said the ruling “should serve as a wake-up call for Israel and actors who enabled its entrenched impunity,” an apparent reference to the United States, Israel’s chief ally. The U.S. repeated its position that Israel must “take all possible steps” to minimize harm to civilians, increase humanitarian aid and curb “dehumanizing rhetoric.” “We continue to believe that allegations of genocide are unfounded,” the State Department said in a statement. The South African government said the ruling determined that “Israel’s actions in Gaza are plausibly genocidal.” “There is no credible basis for Israel to continue to claim that its military actions are in full compliance with international law,” the government said in a statement. Israel often boycotts international tribunals and U.N. investigations, saying they are unfair and biased. But this time, it took the rare step of sending a high-level legal team — a sign of how seriously it regards the case. The Health Ministry in Hamas-run Gaza does not differentiate between combatants and civilians in its death toll, but the agency has said about two-thirds of those killed have been women and children. The Israeli military claims at least 9,000 of the more than 26,000 dead were Hamas militants. U.N. officials have expressed fears that even more people could die from disease and malnutrition, with at least one-quarter of the Gaza population facing starvation. Yuval Shany, a law professor at Hebrew University and senior fellow at the Israel Democracy Institute, said the court’s decision was “not as bad as Israel feared it would be” and would not fundamentally alter the way the military conducts the war. “The greatest fear was that the court would ask Israel to stop the war,” Shany said, describing the decision as “something that Israel can live with.” ___ Casert reported from Brussels. Associated Press writers Josef Federman and Julia Frankel in Jerusalem; Gerald Imray in Cape Town, South Africa; and Jill Lawless and Danica Kirka in London contributed to this report. ___ Follow AP’s war coverage at https://apnews.com/hub/israel-hamas-war",
    "commentLink": "https://news.ycombinator.com/item?id=39143043",
    "commentBody": "ICJ orders Israel to prevent genocide in Gaza, stops short of ordering ceasefire (apnews.com)443 points by xbar 19 hours agohidepastfavorite1147 comments dang 15 hours agoAll: if you're going to post in this thread, please make sure you're up on the site guidelines at https://news.ycombinator.com/newsguidelines.html and that your comment is strictly within them. That especially means two things here: being kind, and not using the thread to do battle. If you're not able to stick to that, that's fine, but in that case please don't post. What does be kind mean in a context like this? Many things, but here's one in my view: it means finding a place in your heart for the humanity of the other—whoever the other happens to be for you. That isn't easy but it's the spirit we want here. If you can't find it in yourself, that's understandable, but on this topic, please only post if you can. reply ajb 15 hours agoprevThe actual rulings can be found at https://www.icj-cij.org/sites/default/files/case-related/192... and a summary is: https://www.icj-cij.org/sites/default/files/case-related/192... Dissents etc can be found in the case page: https://www.icj-cij.org/case/192 - in particular the opinion of Judge Aharon Barak, the Israeli ad-hoc Judge (a peculiarity of the ICJ is that each side gets to add a judge, but it doesn't have much effect since there are 17 other judges). But interestingly Judge Barak ruled against Israel in the case of two measures, enforcement against Incitement and ensuring humanitarian aid. I believe it's also available in French, for those more familiar with that language. reply throwaway421967 10 hours agoparentSince the comment that I replied to was flagged, I'm posting this here because it is simply a statement of facts. - Judge Barak's numbers on civilian deaths on 7th october are simply wrong and could've been easily checked. 766 civilians were killed, 1200 was the total number of deaths (including armed forces). - Israel's own numbers say \"2 civilians killed for every one militant\"[1], that's 66% in the Gaza offensive. - 766 / 1200 = 63.8% - 63.8% and 66% are indeed close numbers, don't see why would it be flagged. Of course, the numbers claimed by other NGOs / UN make it worse. But Israel's numbers are sufficient to make that claim. [1] - https://edition.cnn.com/2023/12/05/middleeast/israel-hamas-m... reply Qem 8 hours agorootparentRegarding the people that died on October 7, one important detail is evidence surfaced it appears a sizeable fraction was killed due to Israeli military attacking militants and hostages without distinction, to avoid capture, following the so called Hannibal directive: https://thecradle.co/articles/israeli-army-ordered-mass-hann... https://thegrayzone.com/2023/11/25/israels-october-7-propaga... https://en.m.wikipedia.org/wiki/Hannibal_Directive reply shakil 7 hours agorootparentWhy is this flagged/down voted? Its just a plain statement of fact, supported by credible sources and references. Here's some more references if people think this didn't happen. The IDF attacked and fired on the Nova festival goers with Apache helicopters [1], an Israeli tank fired shells at Kibbutz Be'eri killing hostages and children, and stories of eight babies killed at the kibbutz have been proven to be false, among other things [3], [4] 1. https://www.businessinsider.com/idf-mistakenly-hit-festival-... 2. https://en.wikipedia.org/wiki/Be%27eri_massacre#Survivors'_t... 3. https://archive.is/Zn3Bt 4. https://www.youtube.com/watch?v=L91kG_bYsn0 reply oeta 46 minutes agorootparentBecause Zionist tears. reply brighteyes 6 hours agorootparentprevIt is downvoted because it said \"sizable fraction\", which is a conspiracy theory. It is true that there were a few incidents, but they only account for a very small fraction of the death toll. reply rsoto2 6 hours agorootparentThe report that I saw said that there were 70 vehicles completely destroyed by RPG or Helicopter and the Israeli military did not go into specifics(although they undoubtedly have more data about the event than they have released) reply wahnfrieden 6 hours agorootparentprev“A few… A very small fraction” is a conspiracy theory actually reply wahnfrieden 3 hours agorootparentIDF says “immense quantity” of friendly fire, that doesn’t sound like your “a few”: Israel’s army on Tuesday admitted that an “immense and complex quantity” of what it calls “friendly fire” incidents took place on 7 October. The key declaration was buried in the penultimate paragraph of an article by Yoav Zitun, the military correspondent of Israeli outlet Ynet. It is the first known official army admission that a significant number of the hundreds of Israelis who died on 7 October were killed by Israel itself, and not by Hamas or other Palestinian resistance factions. Citing new data released by the Israeli military, Zitun wrote that: “Casualties fell as a result of friendly fire on October 7, but the IDF [Israeli military] believes that … it would not be morally sound to investigate” them. reply edanm 1 hour agorootparentprevAs far as has been credibly reported, it wasn't a \"sizeable fraction\", it was a very small number. There's only one incident I know of that is verified. I'm sure more will surface - such is war. Therefore I want to make it very clear - it is not an important detail, despite you calling it such. Hamas are the ones that attacked - if in the process of trying to stop these attacks, the IDF inadvertantly killed Israeli civilians, that is tragic - but is completely the fault of Hamas. This is true both legally and morally. reply SomeoneFromCA 20 minutes agorootparentIt is absolutely not \"true both legally and morally.\" It all depends on scale and purpose of the operation. If israeli military acted with disregard to the lives of non combatants, that would account to war crimes, against their own population. They have history of war crimes against their own forces, called Hannibal doctrine, so I won't surprised if they have same directives against civilians. reply NicoJuicy 28 minutes agorootparentprevIt's only important when you want to deflect Israel being a victim, yes. The fact is that Israel was attacked by a coordinated group and we both know that Israel's priority was to stop that. reply fortran77 6 hours agorootparentprevThis is akin to 9/11 truther theories. reply JumpCrisscross 7 hours agorootparentprev> 63.8% and 66% are indeed close numbers, don't see why would it be flagged…Israel's numbers are sufficient to make that claim What claim? As far as civilian casualty rates go, mid 60s is nothing to be proud of, but square in the middle of the pack when it comes to modern wars [1]. [1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8581199/#B12 reply xdennis 8 hours agorootparentprevnext [7 more] [flagged] int_19h 8 hours agorootparentWhen Brits were firebombing German cities, that had very little to do with freeing anyone from anything. Even at the time it was recognized by many as an act of revenge, and it's hard to not take the same impression from how Israel is conducting itself in Gaza, especially given some telling remarks from Israeli leadership. reply JumpCrisscross 7 hours agorootparent> at the time it was recognized by many as an act of revenge In part. Air power was new at the time, and there was legitimate strategic ambiguity around the military value of removing war factories’ workforces. (This is why Germany and Britain bombed by night while America bombed by day.) reply kilolima 7 hours agorootparentI'd be curious to see a citation for this claim if you remember it. Thanks! reply jdietrich 6 hours agorootparentThe book Terror from the Sky: The Bombing of German Cities in World War II covers most of the major issues. The key point of distinction between the American and British approach emerged through what the British euphemistically referred to as \"dehousing\" - the idea that destroying German housing stock would disrupt the operation of manufacturing, divert materials and labour away from military use and demoralise the population. On this premise, civilian casualties were merely the incidental consequence of destroying houses. https://www.jstor.org/stable/j.ctt9qchwt https://en.wikipedia.org/wiki/Dehousing reply avmich 8 hours agorootparentprevIt's interesting that we keep quite a critical view of modern politicians, yet when discussing on the field interactions we assume that armies of people, all like one, follow the bloodthirsty orders from commanders above. reply emmelaich 6 hours agorootparentprevWas it not? The war was not over and so no-one was freed, yet. Regarding Dresden, from wikipedia... > United States Air Force reports, declassified decades later, noted as a major rail transport and communication centre, housing 110 factories and 50,000 workers in support of the continued Nazi German war effort reply shmatt 14 hours agoparentprevBarak is no fan of the current Israeli government. And they often attacked him publicly and organized demonstrations around his home. They truly sent the best international law expert the country has to offer reply YZF 12 hours agorootparentThis is more nuanced. Some people in the government respect Barak. I don't know that Barak is active in politics (I haven't really heard him opine on the current government, but one can imagine he's not a fan). The more extreme parties in the government resent/oppose Barak. The \"government\" doesn't attack Barak or protest against him but certainly some (extreme/right-wing) political factions in Israel blame him for many things. I don't think he was sent because he's necessarily the best international law expert, but he's a very sharp and widely respected. His being sent while the government is trying to undermine the practices Barak established in the supreme court is a bit weird. Politics. reply ofirg 8 hours agorootparentBarak very recently (under 1 year) and strongly attacked the governments legal reform plans reply yosefk 12 hours agorootparentprevNot exactly. They sent the guy who controls the local judiciary because not doing so would be impossible due to his immense political power. The Israeli judiciary is unique in nominating itself and having given itself the power to cancel any law or demand any changes to laws/policy on any arbitrary basis; since this state of affairs is backed up by a sufficient number of powerful institutions, it is effectively impossible to challenge. Barak ruling to resupply the enemy (it is widely documented that \"humanitarian aid\" goes first and foremost to Hamas) in an international court is entirely consistent with his lifelong tendency to gradually reduce Israeli independence and voters' impact on policy and to increase Israeli compliance to the policy of outside parties, first and foremost the US. (Resupplying the enemy was required by the US from the start. It is interesting to see other examples where civilians are prevented by the international community to leave the area of hostilities and instead they are supposed to be provided with resources in this area where the monopoly on the use of force belongs to one of the sides in the conflict.) While the exact requirements placed on Israel by larger powers are somewhat unique, having highly influential people in the country effectively work in the interest of larger powers is a common condition for smaller powers. In this Barak is similar to many other high-profile people and organizations in many other countries enjoying limited sovereignty at best. reply tguvot 12 hours agorootparent> The Israeli judiciary is unique in nominating itself this is at most lie and at least misconception. Supreme Court Judges are appointed by the President of Israel, from names submitted by the Judicial Selection Committee, which is composed of nine members: three Supreme Court Judges (including the President of the Supreme Court), two cabinet ministers (one of them being the Minister of Justice), two Knesset members, and two representatives of the Israel Bar Association. Appointing Supreme Court Judges requires a majority of 7 of the 9 committee members, or two less than the number present at the meeting. reply yosefk 12 hours agorootparentIn practice, the 3 Supreme Court Judges, the two representatives of the Israel Bar Association, and the 1 Knesset member \"traditionally\" representing one of the two major political camps [the one aligned with most Supreme Court Judges] always vote together, so most of the judiciary is appointed according to the wishes of the Supreme Court Judges. The veto on appointing Supreme Court Judges adds a modicum of balance, but given that the country can be set on fire at will by the Supreme Court like we've seen in 2023, I don't believe that this veto is that effective at changing appointments (if an appointee is declared illegitimate by the Supreme Court, the country will be paralyzed by protests; and more prosaically, you promote to the highest court from lower courts and everyone appointed to these was appointed by a simple majority without the 7-out-of-9 veto.) The idea that 5 out 9 people nominating judges aren't elected, directly or indirectly, is AFAIK a fairly unique Israeli invention. This is taught in schools as a good thing because there's \"a majority of professionals rather than politicians.\" I presume that this idea is so effective and consistent with the principles of democracy that it should also work for nominating governments and lawmakers. reply jdietrich 11 hours agorootparent>The idea that 5 out 9 people nominating judges aren't elected, directly or indirectly, is AFAIK a fairly unique Israeli invention. Judges in England and Wales (including supreme court judges) are selected entirely by unelected officials; The government is explicitly prohibited from interfering with their decision. Given the influential nature of English law, I would be very surprised if this was unique. https://en.wikipedia.org/wiki/Judicial_Appointments_Commissi... https://en.wikipedia.org/wiki/Justice_of_the_Supreme_Court_o... reply turquoisevar 6 hours agorootparentAnother example: In the Netherlands the Dutch Supreme Court provides parliament with a shortlist of 6 people. The Dutch parliament then makes a short list of 3 people based on that list. Traditionally the first three people on the 6 person list by the Dutch Supreme Court. This 3 person list is then offered to the Dutch government who then appointments one of them, traditionally the first one on the list, as a Supreme Court judge. In the entire history only once did the Dutch parliament deviate from the Supreme Court’s 6 person shortlist and only once did the Dutch government deviate from the parliament’s 3 person shortlist. So in practice it’s the Supreme Court who chooses who should join them, none of the judges are elected officials. Lower court judges aren’t elected either, like say, in the US. Neither are prosecutors for that matter. In general these are all merit based appointments, not unlike your average job application, just with more ceremony. reply ajb 12 hours agorootparentprevDon't quite understand that? Aharon Barak was chief justice, but retired in 2006 and is 87 years old. reply yosefk 12 hours agorootparentMost of the judiciary are his loyalists. An example of his ongoing influence is the ridiculous legal doctrine invented just this year where the Israeli declaration of independence was retroactively declared to be the supreme law of the land, akin to a \"meta-constitution\"; his opinion on the matter was published after many months of campaigns where people would declare their \"allegiance to the declaration of independence.\" reply YZF 12 hours agorootparentI feel like this is an over-simplification that's not going to be well understood by people not familiar with Israel's judicial history and systems. He has some influence but I don't think \"loyalists\" (or the other terminology used in your earlier comment) is that accurate. The supreme court justices today have a range of opinions and are largely independent and interpret law (and some other universal principles, like human rights, is really what Barak brought to the table). The interesting bit to me here is this signals that if those cases were brought in front of Israel's supreme court the outcome would likely be similar to the ICJ (except Israel's supreme court's rulings must be followed, it's not optional or requires security council approval). I think that was partly the intent in sending Barak and really the main argument that people that oppose the government initiatives to restrict the Israeli Supreme Court have. And so there's really no need to take Israel to the ICJ since its independent supreme court would e.g. enforce the same standards anyways. reply cachvico 12 hours agorootparentprevWasn't that struck down? https://www.aljazeera.com/news/2024/1/1/israels-supreme-cour... reply baybal2 12 hours agorootparentprev> The Israeli judiciary is unique in nominating itself and having given itself the power to cancel any law or demand any changes to laws/policy on any arbitrary basis; 1. Not completely. There are quite a few countries with fully independent judiciary, with judges appointing judges. 2. Courts with power to initiate, and prosecute a case by themselves also exist in other countries. reply dragonwriter 12 hours agoparentprev> a peculiarity of the ICJ is that each side gets to add a judge, but it doesn't have much effect since there are 17 other judges There are 15 ICJ judges, plus the two ad hoc judges appointed by the parties. reply ajb 11 hours agorootparentYes, my error. 17 is the total number of judges in this case. reply ComputerGuru 15 hours agoparentprevAn important part of Barak’s involvement is the complete recognition of ICJ’s jurisdiction over the matter, which it found (and Barak didn’t disagree) it had. reply megous 12 hours agoparentprevNotably also voted against telling Israel to follow the raw key prohibitions of Genocide convention as written in the convention, something Israel agreed to in the past. Curious. Also voted against asking Israel to preserve evidence of the crimes. Interesting perspective for a former judge. reply JumpCrisscross 11 hours agorootparent> Interesting perspective for a former judge Do you have a link to Barak’s dissent on those questions? reply ajb 11 hours agorootparenthttps://www.icj-cij.org/sites/default/files/case-related/192... reply JumpCrisscross 11 hours agorootparentHmm, the relevant meat appears in paragraph 43. One one point, he votes against because it’s redundant to the Convention. Fair enough. On the other, a question of “plausibility,” comes up, which seems a term of art I wasn’t able to quickly decipher. reply Timber-6539 9 hours agoparentprevnext [3 more] [flagged] dang 8 hours agorootparentPlease don't post like this. It's against the intention of this site and especially against the intended spirit I tried to describe at the top of the thread. reply Timber-6539 8 hours agorootparentnext [2 more] [flagged] dang 8 hours agorootparentI've been posting similar admonishments to commenters on all sides of this argument when they cross the line into flamewar. Your comments in this thread have clearly been doing that, and not only the comment I replied to. It's common for people with strong feelings on a topic to feel like the mods must be biased against them and secretly in favor of the other side (https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...). Meanwhile the other side(s) feel exactly the same way. These perceptions feel convincing, but you can't trust them—they're a product of some kind of hard-wiring that we all seem to share, especially when our emotions get engaged. Any fair minded person who slogs their way through my moderation posts in this thread, and any similar thread, is going to see how hard we try to be even-handed, apply HN's rules fairly, and so on. Not that we always get it right, of course. By the way, if you see a post that ought to have been moderated but hasn't been, the likeliest explanation is that we didn't see it. There is far too much content on HN, or even in a large thread like this one, for us to see it all. https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... You can help by flagging it or emailing us at hn@ycombinator.com. reply throwaway260124 14 hours agoparentprevnext [24 more] [flagged] nradov 13 hours agorootparentThe civilian death toll in Gaza has been tragically high but there hasn't been any independent verification. Regardless of what's on Wikipedia, we can't trust specific numbers. reply throwaway421967 13 hours agorootparent- Israel's own numbers say \"2 civilians killed for every one militant\"[1], that's 66% - 766 / 1200 = 63.8% Of course, the numbers claimed by other NGOs / UN make it worse. But Israel's numbers are sufficient to make that claim. [1] - https://edition.cnn.com/2023/12/05/middleeast/israel-hamas-m... reply slibhb 13 hours agorootparentHamas can't go toe-to-toe with the IDF. They are hiding in tunnels and among civilians, so these ratios aren't surprising. To some extent, you can't blame Hamas for these tactics. They would quickly lose a conventional war. At the same time, if you have zero chance of winning a military victory, perhaps you shouldn't use violence to pursue your political goals... reply SomeoneFromCA 13 hours agorootparentYes right, if israel is unable to fight conventional war, without massive disproportional amount of civil casualties, they should not probably engage in one. reply llamaLord 13 hours agorootparentLooking at the historical data, that tends to be a pattern of urban warfare, not the IDF. Civilian/combatant fatality ratios of 3/1 are not uncommon in urban warfare. reply SomeoneFromCA 12 hours agorootparentAs if we know how many Hamas fighters have been killed at the first place. According to the official stats there is like 259 IDF casualties during the land operation. Which means that death ratio is 30:1 wrt to supposed 8000 Hamas death.Laughable. Even then, military necessity of killing combatants, not actively particpating in the war is not justified. Yes, you can kill those, who is shooting the rockets at Tel-Aviv, but bombing willy-nilly all of Gaza just because there might be tunnels, where potential combatants might be hiding,. is not acceptable, although not am not an international law lawer. reply runarberg 11 hours agorootparentWell, it is not acceptable, and it seems like the ICJ has, indeed, not accepted it. reply nvm0n2 12 hours agorootparentprevThat wasn't their choice ... reply SomeoneFromCA 12 hours agorootparent\"No choice\" is how all genocidaires justified their actions. reply runarberg 12 hours agorootparentprevThen they shouldn’t. That’s the simple answer of it. If they want to get rid of Hamas they will need to find another way. This level of civilian casualty is unacceptable. And as proven by the ICJ decision, it is not accepted. reply krainboltgreene 13 hours agorootparentprevThe state of israel agrees with and trust sthe numbers coming from Gaza: https://www.newarab.com/news/israeli-intel-confirms-gaza-hea... reply jdietrich 13 hours agorootparentWhile their statistics are regarded as an accurate account of the total death toll, they make no distinction between civilian and combatant deaths. This is obviously a crucial shortcoming if we are trying to ascertain whether the number of civilian deaths are disproportionate to the military objectives. reply runarberg 12 hours agorootparentIf we go all 19th century and assert that all men over the age of 18 are combatants. Then we get 70% of the deaths are civilian, and 30% are combatants. However we know a large number of adult men killed in Gaza or not combatants, e.g. they are journalists, UN workers, poets, university professors, etc. So 66% civilians seems very likely to be a huge underestimate. reply Sporktacular 13 hours agorootparentprevDo you believe 695 Israeli civilians, 373 security forces and 71 foreigners, giving a total of 1,139? They're all numbers from the Israeli government. Weird how only disputing the Hamas numbers as biased is a talking point. reply sebzim4500 13 hours agorootparentIt is way easier to verify those numbers though, there is an actual list of names and journalists can (and have) talk to the families etc. reply Mandain62 12 hours agorootparentAnd from talking to families and people on the ground there there are some reports that IDF killed many Isreali civilians on that day [1]. The extent is not obvious without independent investigation of course. [1] https://www.businessinsider.com/idf-mistakenly-hit-festival-... reply Sporktacular 12 hours agorootparentprevTrue, verifying 695 deaths is easier than 30 times that number. Also convenient then that journalists are allowed to safely operate there. reply tety 11 hours agorootparentkinda different comparing a state with an organization that was caught lying about death statistics numerous times in the past [1] and including in this war (such as the ali ahli hospital incident). it should raise some questions how the casualty count went to 500 in a few hours, where everywhere else in the world it takes days to get a body count after any disaster It is beyond me how someone can believe that an organization capable of kidnapping babies to advance its political goals is beyond lying to do the same [1] https://www.haaretz.com/2010-11-09/ty-article/hamas-admits-6... reply Sporktacular 9 hours agorootparentThere are lies and errors. From both sides. But the 26000 figure is generally accepted by the UN and aid agencies. Figures from Hamas in previous conflicts have been confirmed. https://en.wikipedia.org/wiki/Casualties_of_the_Israel–Hamas... https://www.cbc.ca/news/world/gaza-death-toll-records-1.7010... Simply dismissing a figure as skewed because of its source without a better one is a weak argument. reply tety 3 hours agorootparentit is accepted by the UN because there is no other figure. they have no other way of estimating, also the UN is far from a neutral element in this conflict The UN is a political body composed of the political interests of its members, which are mostly authoritarian states, and it hasn’t shown much support for Israel due to the vast membership of Islamic countries. Parody case in point, Iran being Human Rights commission seat UNRWA, the UN agency on the ground was shown again and again to be in the very least in the mercy of Hamas therefore cooperative, at most its infrastructure and staff was used by the organizations for attacks against Israel and to hold hostages. The ICJ in this case heavily quoted UNRWA as a source while it is an extremely problematic one. The hospital bombing I quoted above is an example case where many experts tried to estimate casualties based on evidence, they arrived to figures that range from tenth to fifth of what Hamas published. This together with the fact they control the casualty figure and have a clear interest at inflating it in order to stop Israel from attacking, is pretty obvious to me what’s going on. Leaving the fact that this figure also includes Hamas members, and therefore is useless at estimating if there is excessive collateral damage reply Sporktacular 1 hour agorootparentThat's just motivated reasoning. The UN is multidisciplinary. If you have a better source, present it. Even if the true numbers are a quarter of the given figure that's still way too high. reply djakaitis 8 hours agorootparentprevHamas is a known bad actor - with a variety of incidences discrediting their “reporting”. reply xdennis 8 hours agorootparentprev> Weird how only disputing the Hamas numbers as biased is a talking point. Why are you surprised that people trust Israel more than Hamas? Israel is a country that's ranked 29 of 167 on the Democracy Index[1], right _above_ the US. Hamas is literally a terrorist organization recognized in many countries, probably yours too. [1]: https://en.wikipedia.org/wiki/The_Economist_Democracy_Index reply locallost 12 hours agoprevMy views on the situation aside, the clearest I saw anyone communicate the issues from a global angle was the former French prime minister Dominique de Villepin Translated here: https://twitter.com/RnaudBertrand/status/1718201487132885246 Viewed from the angle of the West, I think the message it needs to avoid isolating itself from the world is very unusual for Western media and important. Quote: \"Westerners must open their eyes to the extent of the historical drama unfolding before us to find the right answers.\" And \"This Palestinian question will not fade. And so we must address it and find an answer. This is where we need courage. The use of force is a dead end. The moral condemnation of what Hamas did - and there's no \"but\" in my words regarding the moral condemnation of this horror - must not prevent us from moving forward politically and diplomatically in an enlightened manner. The law of retaliation is a never-ending cycle.\" reply pgeorgi 12 hours agoparentAll correct and yet, what should happen? Israel stops their campaign. And then? Spend tons of money on iron dome to shoot down the rockets and hope that Hamas won't manage to conduct another massacre, even if \"only\" half the scope of October 7? This mess features not one but two parties who currently reject the concept of a cease fire. reply anon84873628 11 hours agorootparent>All correct and yet, what should happen? Israel stops their campaign. And then? And then everyone who wants peace invests lots of money and expertise over a long time to build a modern, prosperous, stable Palestinian society, despite whatever setbacks, attacks, and sabotage occur from within and without. The only way to have peace is to give people a better option than becoming terrorists. reply reissbaker 8 hours agorootparentThis is not the approach the West took with ISIS, which involved similarly one-sided fights against terrorist forces [1], nor do I think it's an approach that would have worked. When \"everyone who wants peace\" doesn't include the people in control of the guns and rockets, who instead want to kill their enemies by any means necessary (and themselves do not respect international law), you can't simply dialogue your way out of it any more than Ukraine could have dialogued their way out of getting invaded by Russia. The ICJ ruled that Hamas return the hostages unconditionally, but everyone knows that won't happen — Hamas is simply unaccountable. \"Everyone who wants peace\" can't even get the Red Cross access to the hostages, let alone get them returned. Vague calls for diplomacy with terrorist groups doesn't solve much, which is why people are asking you for specific solutions — it's easy to say Israel should stop fighting, but then: what should it do? How would you actually ensure it doesn't keep getting attacked, repeatedly, as Hamas continues to insist they plan to do? 1: Mosul alone had ~10,000 civilian casualties and that was less densely populated than Gaza City and didn't have tunnels: https://www.pbs.org/newshour/amp/show/thousands-more-civilia... And it similarly had about 1MM civilians displaced: https://www.nytimes.com/2017/07/06/world/middleeast/mosul-ir... And that wasn't the end of the fight against ISIS! reply amluto 8 hours agorootparentA major problem is that the Gazan people have very legitimate problems with Israel, and this leads to a situation in which enough of them become militant to cause serious problems. Solving that seems like it needs a more wholistic approach than simply trying to get rid of the militants at the cost of causing everyone else to have an even bigger beef with Israel. reply jdietrich 6 hours agorootparentI fully accept that many Palestinians are motivated to take up arms against the Israelis by a justifiable sense of grievance, but the issue of anti-Semitism long pre-dates the establishment of Israel and exists far beyond the Palestinian Territories. I really don't want to understate this point - from an outside perspective, it is almost impossible to comprehend the depth of hatred against Jews that exists across the Middle East. Improving the living conditions of Palestinians is almost certainly a necessary precondition to lasting peace, but it is far from sufficient. Unfortunately, we are now stuck in a very stubborn vicious cycle - the Israel-Palestine conflict perpetuates anti-Semitism, which perpetuates the conflict. https://en.wikipedia.org/wiki/1948_Arab%E2%80%93Israeli_War#... https://en.wikipedia.org/wiki/Antisemitism_in_the_Arab_world reply endominus 5 hours agorootparent>the issue of anti-Semitism long pre-dates the establishment of Israel From your second source that seems to not be the case, at least not in serious degree. \"Traditionally, Jews in the Muslim world were considered to be People of the Book and were subjected to dhimmi status. They were afforded relative security against persecution, provided they did not contest the varying inferior social and legal status imposed on them under Islamic rule. While there were antisemitic incidents before the 20th century, during this time antisemitism in the Arab world increased greatly.\" And later, \"The situation of Jews was comparatively better than their European counterparts, though they still suffered persecution.\" There is more detail at https://en.wikipedia.org/wiki/History_of_the_Jews_under_Musl... Anecdotally, I've heard that before the establishment of Israel, relations between the two groups were much less hostile. Muslims and Jews would, for example, have their Jewish or Muslim neighbors watch over their kids during holy days when they'd have to go to mosque/temple. There is also a long history of Jews being treated fairly well in the Arab/Muslim world - better indeed than they were in Christian lands where pogroms were much more common (it's astonishing how many times Germany, in a state of high fervor, decided that the most appropriate thing to do would be to massacre the Jews again). Again, anecdotally, the \"depth of hatred against Jews\" in the Arabs I've spoken with has little to do with Jews and much to do with the actions of the state of Israel and what it does in the name of Jews. reply reissbaker 5 hours agorootparentJews were legal second class citizens and were treated terribly, e.g. being banned from wearing shoes in Morocco, and when the ban was overturned, so many Jews were murdered in riots that the community asked for shoes to be banned again. https://twitter.com/TaliaRinger/status/1738328128999575931 And it's not just Morocco; Yemen for example had official state policy of kidnapping Jewish orphans to forcibly convert them to Islam. Baghdad massacred Jews starting in the 1820s, long before Israel existed. The Damascus affair was in 1840: https://en.m.wikipedia.org/wiki/Damascus_affair Dhimmi status is bad! It's not as bad as being pagan in Muslim countries historically, where you could just legally be killed if you didn't convert to Islam. And at times it was better than Europe, which more-frequently murdered its Jews. But it was bad, and it was bad long, long before Israel. There's a reason Mizrahi Jews form the right-wing base in Israel — it's not because it was good. reply endominus 4 hours agorootparent>Dhimmi status is bad! Except that doesn't seem to the be the case in the context of the time for specifically the Jewish communities living in Muslim-controlled regions? Per https://en.wikipedia.org/wiki/Dhimmi - \"Generally, the Jewish people were allowed to practice their religion and live according to the laws and scriptures of their community. Furthermore, the restrictions to which they were subject were social and symbolic rather than tangible and practical in character. That is to say, these regulations served to define the relationship between the two communities, and not to oppress the Jewish population.\" There's a section on Jews on that page that seems unanimous in the view that while dhimmi status was not as good as being a muslim citizen, it was a better than what they had either before the Muslims took over or what they had available elsewhere. It's weird to label what is generally an improvement in living conditions/social regard as stemming from deep-seated discrimination. Per atrocities - of course there were atrocities committed against Jews. Just as there were atrocities committed by basically every long-lived group against every long-lived group in their territories. No one is stupid enough to say that Muslims have never persecuted Jews, just as they wouldn't say that Christians have never persecuted Jews, or that Muslims never persecuted Christians, or that Christians never persecuted Muslims, or that those groups never persecuted themselves in schisms and internicine warfare. But the impression that Islam is fundamentally and necessarily opposed to the practice of the Jewish faith is fairly contradicted by even the history of dhimma. As the first paragraph of that Wikipedia page states; 'Dhimmī... is a historical term for non-Muslims living in an Islamic state with legal protection. The word literally means \"protected person\", referring to the state's obligation under sharia to protect the individual's life, property, as well as freedom of religion, in exchange for loyalty to the state and payment of the jizya tax, in contrast to the zakat, or obligatory alms, paid by the Muslim subjects. Dhimmi were exempt from certain duties assigned specifically to Muslims if they paid the poll tax (jizya) but were otherwise equal under the laws of property, contract, and obligation.' On the other hand, look at how the Jews were treated during the Islamic Golden Age in Spain; https://en.wikipedia.org/wiki/Golden_age_of_Jewish_culture_i... (\"The golden age of Jewish culture in Spain, which coincided with the Middle Ages in Europe, was a period of Muslim rule during which, intermittently, Jews were generally accepted in society and Jewish religious, cultural, and economic life flourished.\"). It's hard to square that with the idea that there is this deep-seated hatred among Muslims towards Jews as the GP stated. My point is that conflict between the two sides is not inevitable, nor is this idea of extreme latent anti-Jewish sentiment in the Muslim world really true. Purges and persecution that people bring up are probably not caused by ancestral hatred, but rather the same thing that causes every society to suddenly fall into itself in violence and accusation; uncertain economic conditions, unstable political environments, natural disaster, epidemics, war, idiotic rulership, etc. reply reissbaker 3 hours agorootparentExcept that doesn't seem to the be the case in the context of the time I think not being allowed to wear shoes and being murdered in mass riots when the Sultan allows you to wear shoes is bad. To my eyes there is very little difference between the level of hatred then and now, it's just that the power dynamic has changed, so I think blaming the Muslim world's anti-Semitism on Israel's existence (like the OP did) isn't really based in historical fact. There was anti-Semitism long before Israel existed, and it's not like it was getting better prior to its establishment — the stuff in Yemen was happening through the 20th century, under Ottoman rule (and plenty of other bad stuff, e.g. \"Dung Gatherer\" laws requiring Jews to perform latrine servicing for Muslims). reply endominus 2 hours agorootparentThis does not address any of the points I raised. You're just reiterating what you already wrote. Here's an abbreviated summary of the history; 1. Jews exist in a region. 2. Muslims take over. Conditions improve for the Jews. 3. Time passes. 4. Muslim civilization declines. 5. Internal strife and conflict. Among others, Jews are blamed. 6. Commenters 1000 years later; \"This was caused by incipient hatred of Jews by Muslims.\" This does not explain why conditions improved when Muslims originally rose to power in various regions. Again, the persecution of minority population is an expected result of the decline of civilizations. From the Wikipedia article your Twitter source is quoting, https://en.wikipedia.org/wiki/History_of_Moroccan_Jews: \"Morocco's instability and divisions also fueled conflicts, for which Jews were frequent scapegoats. The First Franco-Moroccan War in 1844 brought new misery and ill treatment upon the Moroccan Jews, especially upon those of Mogador (known as Essaouira). When the Hispano-Moroccan War broke out on September 22, 1859, the Mellah of Tetuan was sacked, and many Jews fled to Cadiz and Gibraltar for refuge. Upon the 1860 Spanish seizure of Tetouan in the Hispano-Moroccan War, the pogrom-stricken Jewish community, who spoke archaic Spanish, welcomed the invading Spanish troops as liberators, and collaborated with the Spanish authorities as brokers and translators during the 27-month-long occupation of the city.\" This is a nation in decline, lashing out at every perceived cause of trouble, like plague-stricken Europeans slaying cats and dogs and flagellating themselves. Here are some other quotes from that article; \"The golden age of the Jewish community in Fez lasted for almost three hundred years, from the 9th to 11th centuries. Its yeshivot (religious schools) attracted brilliant scholars, poets and grammarians. This period was marred by a pogrom in 1033, which is described by the Jewish Virtual Library as an isolated event primarily due to political conflict between the Maghrawa and Ifrenid tribes.\" \"The position of the Jews under Almoravid domination was apparently free of major abuses, though there are reports of increasing social hostility against them – particularly in Fes. Unlike the problems encountered by the Jews during the rule of the Almohads (the Almoravids' successor dynasty), there are not many factual complaints of excesses, coercion, or malice on the part of the authorities toward the Jewish communities.\" \"During Marinid rule, Jews were able to return to their religion and practices, once again outwardly professing their Judaism under the protection of the dhimmi status. They were able to re-establish their lives and communities, returning to some sense of normalcy and security. They also established strong vertical relations with the Marinid sultans. When the still-fanatic mobs attacked them in 1275{note; no source for this on the Wikipedia page, no link; unable to find what this is referring to}, the Merinid sultan Abu Yusuf Yaqub ibn Abd Al-Haqq intervened personally to save them. The sovereigns of this dynasty benevolently received the Jewish ambassadors of the Christian kings of Spain and admitted Jews among their closest courtiers.\" This is not what I would expect of a civilization that is fundamentally racist towards Jews. I would not expect, for example, a Louisiana governor in the 18th century to appoint a black man to be his advisor, yet we see Jews in the position of vizier in Morocco. This does not square. Racism is not the most useful lens to view this relationship through. The culture of the Middle East is low-trust compared to post-Enlightenment Western societies. There remain sharp social divisions based on old tribal allegiances in even developed nations there (unsurprising, perhaps; there remain living people who remember that this tribe used to be slavers and that tribe killed our uncle and so on). Lashing out at neighbors who one thinks are being treated too favorably has little to do with race or religion, in my experience, and more to do with envy. It is the narcissism of small differences writ large and exacerbated by actual stakes. reply reissbaker 7 hours agorootparentprevSure, and the people of Iraq had very legitimate problems with NATO. Nonetheless the West dismantled ISIS. People can have legitimate grievances without committing mass murder and rape, and in fact I think the mass murder and rape committed by Hamas have been very counterproductive for the lives of Gazans. What would you have Israel do, that you think would result in it not getting continually attacked by Hamas? Recall that when Israel dismantled its Gazan settlements and withdrew its own citizens at gunpoint nearly 20 years ago — in the hope that would help solve the problem — that's when Hamas took power... reply ignoramous 7 hours agorootparent> Nonetheless the West dismantled ISIS ISIS-K just carried out the worst terrorist attack in Iran (and it was primarily Iran's Q Solemani who dismantled ISIS; later killed by the US Army). Taliban rules Afghanistan again. > What would you have Israel do, that you think would result in it not getting continually attacked by Hamas? Negotiate, like they did with PLO before? > withdrew its own citizens at gunpoint Yeah, cause settlements are a clear breach of International Law. It was no charity. > that's when Hamas took power... Democratically elected, then subsequently undermined and later blockaded. reply reissbaker 7 hours agorootparentISIS was defeated in Iraq by a U.S.-led coalition: https://en.m.wikipedia.org/wiki/War_against_the_Islamic_Stat... IDK what your point is with the Taliban, since they're a different group in a different country that isn't allied with ISIS. (And are unrelated to Israel and Gaza.) Negotiate, like they did with the PLO before? The PLO was willing to negotiate and Hamas is not. Hamas has repeatedly said they are not willing to agree to a permanent peace deal with Israel, and have said that they intend to carry out these attacks repeatedly until Israel is destroyed. In this situation, not a hypothetical one where Hamas wants peace, what exactly do you think Israel can do to prevent being attacked? Democratically elected... They won the legislative elections but not the prime ministership and subsequently started a massive civil war with the rest of the PA, which ended up in the PA maintaining control of the West Bank and Hamas controlling Gaza. Which is why Israel and Gaza have gone to war many times, but Israel and Ramallah have not — Israel and the PA mutually recognize each other, albeit with a fair amount of mutual enmity. reply ignoramous 6 hours agorootparent> ISIS was defeated in Iraq by a U.S.-led coalition Yeah and who defeated them in Syria? There were two coalitions. French/US led and Syria/Iran led. > The PLO was willing to negotiate and Hamas is not. In 2014, in a meeting in the UAE post war, Hamas encouraged PLO to reach a political arrangement with Israel on 67 borders. Then in 2017, ratified their charter again to make that point clear. In 2021, Hamas offered to join the PLO and conduct elections, which almost happened only for Israel to not let East Jerusalem residents vote. > subsequently started a massive civil war US and Israel encouraged a coup by Fatah by arming and training the Presidential Guard in opposition to Hamas. > Israel and Ramallah have not Israel has razed Jenin, Tulkarm, and Nablus just this past month with over 50+ dead. > Israel and the PA mutually recognize each other PA is a puppet with bare minimum control over economy, trade, and security of its own people. reply yyyk 6 hours agorootparent>Hamas encouraged PLO to reach a political arrangement with Israel on 67 borders And then to continue the war from these borders. Duh. > ratified their charter again to make that point clear. The one which opposes recognition of Israel and promises to continue the war? >which almost happened only for Israel to not let East Jerusalem residents vote. This isn't true at all. Israeli opposes PA polling stations there. There are other ways to vote (like having the stations inside the EU consulates, or by mail). Which they already used in 2006, so PA is actually fine with this. It's that Abbas will lose to Hamas and everyone knows it, so he needs an lie that uninformed people would swallow. >Israel has razed Jenin, Tulkarm, and Nablus These cities aren't razed by any normal definition of 'razed'. Some people wanted to start another front and got crushed. reply ignoramous 5 hours agorootparent> And then to continue the war from these borders Not a wise move. > opposes recognition... promises war I think you're confusing Likud's charter with Hamas'? > uninformed people would swallow Some say Egypt, Jordan, and Israel equally sabotaged the elections: https://carnegieendowment.org/sada/84509 > Some people wanted to start another front and got crushed Truly crushed, or rather collective punishment / war crimes were the words you were looking for? https://www.amnesty.org/en/latest/news/2023/01/israel-opt-je... reply reissbaker 6 hours agorootparentprevI'm really not sure why it matters who gets to claim credit in Syria. The point is that the US and its allies used the same tactics as Israel is using in Gaza to defeat ISIS, and I think it's silly to say that the U.S. or Iran or whoever should've just tried dialogue with ISIS. The same is true for Hamas. In 2014, in a meeting in the UAE post war, Hamas encouraged PLO to reach a political arrangement with Israel on 67 borders. Then in 2017, ratified their charter again to make that point clear. In 2021, Hamas offered to join the PLO and conduct elections, which almost happened only for Israel to not let East Jerusalem residents vote. None of these things are Hamas willing to make a permanent peace deal with Israel, which they have repeatedly stated they are not willing to do. After being frustrated by your off-topic or entirely inaccurate responses, I realized I remembered your username, and you have previously tried to claim to me that Hamas was willing to make peace deals and continually failed to back up your claims, along with similar unsourced claims and irrelevant debate points as I'm noticing in this back-and-forth. I am not really interested in having this \"discussion\" again! Just as then, it is still the case that Abbas cancelled the elections, not Israel, even according to Hamas. I cited Hamas's own public statements, Wikipedia, etc and you are still making this same unsourced assertion that somehow Israel did it. But that's not even relevant! Hamas is very clear that they do not want a permanent peace deal with Israel! By the way, the \"PLO\" stopped existing a long time before 2014. It's the PA now. Israel has razed Jenin... No, it didn't \"raze\" Jenin or any other city in the West Bank in \"the past month,\" nor has it razed any city in the West Bank since the end of the Second Intifadah other than its own settlements. It fought a small group of Hamas-aligned terrorists with minimal casualties, agreed upon with the PA. PA is a puppet with bare minimum control over economy, trade, and security of its own people The PA is just the reformed PLO, that you were just saying should supposedly be emulated by Israel and Hamas. And objectively it is doing far better on literally all of those axes — economy, trade, and security — for its own people than Hamas. Anyway, once again I point out: you are unable to say what Israel can actually do to prevent Hamas from repeatedly attacking it, given that Hamas does not want a permanent peace deal with Israel. reply ignoramous 6 hours agorootparentnext [5 more] [flagged] reissbaker 5 hours ago [flagged]rootparentnext [4 more] Yeah yeah you're still trying to cite the single opinion piece that has no sources for Hamas supposedly being willing to make peace. Hamas's official statements on \"peace\" are here: https://thehill.com/video/hamas-we-will-repeat-oct-7-terror-... And their 2017 charter didn't say they were willing to make peace with Israel; in fact it only stated that it was justified to continue fighting Israel as it claims it's an occupying power. Hamas views all of Israel to be \"occupied,\" not just 1967 borders, so that is a call for permanent war. https://en.m.wikipedia.org/wiki/2017_Hamas_charter Hamas offered to join the PLO No they didn't. Why do you keep claiming that? They ran against Fatah in 2021: https://en.m.wikipedia.org/wiki/Next_Palestinian_legislative... And once again, the PLO doesn't exist. Running in PA elections doesn't mean anything about their \"peace\" plans; they ran in 2006 and certainly had no peace plans then either: they had a charter that literally called for the genocide of the Jews (not Israelis! Not \"Zionists.\" Jews). Brooklyn doesn't get to decide that I am not from Brooklyn, nor is any government involved here based in Brooklyn, so I can only assume you're being rabidly antisemitic here. reply ignoramous 5 hours ago [flagged]rootparentnext [3 more] > And their 2017 charter didn't say they were willing to make peace with Israel https://en.wikipedia.org/wiki/2017_Hamas_charter (ctrl+f peace) > No they didn't. Why do you keep claiming that? They ran against Fatah in 2021 Running against Fatah does not mean they can't join the PLO, which is an umbrella organization for establishing the Palestinian State (made up of several rival political factions): https://en.wikipedia.org/wiki/Palestine_Liberation_Organizat... > Brooklyn You said Palestinians in the West Bank were objectively \"far better\", which is completely disregarding their plight against anti-Arab far-right Kahanists (https://en.wikipedia.org/wiki/Meir_Kahane originally from Brooklyn) that control those lands. > so I can only assume you're being rabidly antisemitic here Rabidly? There we go. https://mondoweiss.net/2023/09/jewish-settlers-stole-my-hous... Nothing about the point being made, just a lot of smear. reply reissbaker 4 hours ago [flagged]rootparentnext [2 more] Yeah, if you ctrl-f \"peace\" on that page, you'll see it doesn't appear in the charter at all, not sure why you're copy-pasting the link and saying \"ctrl-f\" as if it were a gotcha. Similarly, posting random articles about Jewish settlers supposedly stealing someone's home is not an argument for why your very weird \"Brooklyn\" statement wasn't just rabid antisemitism. Good luck; not going to keep responding to you. Edit: I see you have now stealth-edited your comment and are pretending that \"Brooklyn doesn't get to decide that\" as a response to me saying that the PA is doing better economically and in terms of the security of its people, is supposedly referencing Kahanists. I am not a Kahanist, and am not from Brooklyn, and this is literally the first time you've brought up Kahanists in this discussion (and no, Kahanists do not control the PA, or Ramallah, or Jenin, or whatever), so nice try but not especially convincing. reply ignoramous 4 hours ago [flagged]rootparentStealth edited? That literally was the point I was making and since it flew over your head, I had to make it explicit. Anyways, good luck with the advocacy and/or intimidation. Need plenty of it given the blowback: https://archive.is/blQkz reply pas 7 hours agorootparentprevIsrael needs to treat Palestinians as equals. This should start with not blockading Gaza, rolling back settlements in the West Bank, and so on. Furthermore, supporting those who oppose Hamas instead of playing the dangerous game that now cost tens of thousands of lives. Also, it's important to note that there are no guarantees. Even if Israel (famous hive mind, of course) did everything right there could have been provocation from/via Iran and whatnot. reply reissbaker 7 hours agorootparentIsrael dismantled all of its Gazan settlements in 2005 and there had never been a blockade at that point, which is exactly what I just referenced in the post you were responding to. Then Hamas took over Gaza, and Israel and Egypt jointly started blockading it. You can't place the blame for Hamas's rule on the blockade — the blockade (and the settlements) didn't exist when they took power. reply dmix 7 hours agorootparentprev> Solving that seems like it needs a more wholistic approach than simply trying to get rid of the militants at the cost of causing everyone else to have an even bigger beef with Israel. Like giving NGOs money which get funneled into overt terrorists groups by the corrupt politicians planted by the same terrorists? Aka the status quo for multiple decades well before Netanyahu was ever prime minister. It’s notable none of the surrounding Muslim countries want anything to do with being the neutral power brokers to temporarily help run the state because they know as well as everyone else it’s a never ending hornets nest, that they’ll have as little control of it as Fatah and the various other iterations of “stable” Palestinian governance, who had little ability or interest to quell the extreme violent fringes. Which in every other country in history means control via police, courts, or worst case military… not tacit appeasement and turning a blind eye. reply kilolima 7 hours agorootparentprevFor every Israeli Jewish civilian, there is an equivalent Palestine refugee living in a camp (~7mil). Israeli can only exist as a Jewish majority state as long as the original inhabitants remain displaced. So the Gazans are probably not going to be pro-Israeli any time soon. reply amluto 4 hours agorootparentI find this argument to be problematic. The world contains an enormous number of descendants of displaced people. I imagine that most of the US population is in this category, for example. (Most people of Native American heritage. The descendants of the Puritans. Most American Jews (displaced from different places, even). The Palestinian-Americans. Descendants of slaves. Many others.) Yet most of these people do not consider themselves to still be displaced! I certainly feel no particular desire to reconquer the (multiple!) places from which my ancestors were displaced. (There’s a lot of nuance here. Plenty of people, for example, think that Native Americans and their descendants should have better treatment, especially in land that remains Native American.) But somehow Palestinian refugees, in particular, have unusual, highly politicized issues. The UN agency involved is a different agency than the one that nominally handles every other refugee situation worldwide. There are multigenerational Palestinian refugee camps in countries that do not grant citizenship to the refugees, and there are people who argue that granting citizenship would do them a disservice. (I don’t know whether the people arguing this are doing so in good faith.) Also… > Israeli can only exist as a Jewish majority state as long as the original inhabitants remain displaced. Stories and written records about the Israel go back a long time. If the stories are all true, essentially all Jews worldwide are the descendants of those displaced from Israel. Control of Jerusalem in particular has changed quite a few times, and there are surely plenty of people around, Jews and otherwise, whose ancestors have been displaced multiple times, hundreds of years apart, from the area. (It’s not just Jews and Arabs. Jesus was killed in Jerusalem. Wars have been fought there repeatedly: the Muslim Conquest of the Levant, the Crusades, etc.) Trying to keep score of the number of living descendants of the various groups who have been displaced from Israel seems unlikely to give any sensible moral answer for who ought to control what part of it, except insofar as maybe the entire place would be better off with a genuine non-religious government, along the lines of how the US nominally works. Good luck! reply yyyk 6 hours agorootparentprevMosul had 40k civilian causalties (more than Hamas totals), the coalition just lied about it: https://www.independent.co.uk/news/world/middle-east/mosul-m... reply bawolff 4 hours agorootparentprev> The ICJ ruled that Hamas return the hostages unconditionally To nitpick, the court did not rule that, they just \"called\" for that. It wasn't an order so its not binding. It was just a symbolic statement. At most it was just a way for the court to acknowledge that the conflict is not one sided. reply peterashford 6 hours agorootparentprevIsrael needs terms with Palestine, not with Hamas reply SirSavary 8 hours agorootparentprevNote: ISIS was a bunch of European guys who got radicalized and then travelled to the middle east; Hamas is homegrown and was democratically elected by the people of the region. reply reissbaker 7 hours agorootparentNo, ISIS wasn't \"a bunch of European guys who got radicalized\": https://en.m.wikipedia.org/wiki/Islamic_State reply SirSavary 7 hours agorootparentMarauding terrorist force that lays claim to an area != the people who inhabit that area* * I understand that they also recruited locally; that doesn't change the fact that there were thousands of Europeans in ISIS' ranks, along with fighters from many other nationalities. reply Sabinus 5 hours agorootparent>ISIS was a bunch of European guys who got radicalized and then travelled to the middle east >there were thousands of Europeans in ISIS' ranks, along with fighters from many other nationalities Why did you start off with such strong statements but then retreat to this one after you're challenged? Is ISIS a bunch of European guys or not? reply SirSavary 3 hours agorootparent> Why did you start off with such strong statements but then retreat to this one after you're challenged? There's no retreating in my comment -- it's a fact that they sourced people from everywhere. I threw an asterisk on there at the last second because I wanted to show good faith; there's nothing nefarious about it. > Is ISIS a bunch of European guys or not? It was definitely a bunch of European guys, and Asian guys, and American guys, etc... my point was that ISIS was a group of people from around the globe and not an ideology endemic to the region. See my other comment here https://news.ycombinator.com/item?id=39153097 reply Jochim 7 hours agorootparentprev> ISIS was a bunch of European guys who got radicalized and then travelled to the middle east; The prevalence of British and American accents whenever the IDF is interviewed was certainly surprising. reply mathieuh 5 hours agorootparentThey were trying to present a certain image, I would imagine they put the German terrorists in front of the German TV cameras, the French in front of the French cameras etc. reply IlikeMadison 4 hours agorootparentprevISIS is 95% of people of African and Middle-Eastern origins. Then maybe a bit of crazies from Indonesia, Chechnya, etc. As well, ISIS was founded in Iraq itself. How is it a \"bunch of European\"? reply SirSavary 3 hours agorootparentYour 95% figure is incorrect -- approximately 45% of fighters hailed from Africa and the Middle East, with ~31% originating from Europe (East and West combined). Here's a BBC article https://www.bbc.com/news/world-middle-east-47286935 and the report that it sources its data from https://icsr.info/wp-content/uploads/2018/07/Women-in-ISIS-r... if you care to learn more. reply yieldcrv 7 hours agorootparentprevDemocratically elected by plurality, where the only competition was incompetent, and still only won by plurality… and hasnt had an election in 18 years, which means 50% of the population has never had a democratically exercised opinion because they werent born yet, and of the other 50% not even 50% of the ones that voted had voted for Hamas people really act like thats a “gotcha” reply SirSavary 3 hours agorootparentIt's not a \"gotcha\", it's a factual statement. You can disagree with the mechanisms that brought them to power but it was still a legitimate election. reply yieldcrv 3 hours agorootparentyes it is accurate and a rhetorical dog whistle for extremist approaches to making Palestinian civilians inseparable from Hamas it is also accurate that it was 18 years ago empathy shouldnt be that hard reply mderazon 10 hours agorootparentprevThis is looking at the conflict from western eyes. Religious fundamentalists don't think like that reply nojvek 10 hours agorootparentWe could have said this about Germany and Japan after WWII. Every human no matter their race and religion cares about having food, water, safety, opportunity, live in a law abiding society where their rights are respected and they get “some” choice to vote for their future. reply bitcurious 10 hours agorootparentGermany and Japan were conquered and unconditionally surrendered, after massive civilian casualties. Nazis were tried and executed. If Israel is should model itself on those examples, it's doing the right and moral thing in waging war until Hamas is destroyed, or unconditionally surrenders. reply danenania 9 hours agorootparentThe point is that it’s possible for relations to improve over time even when previous generations were bitter enemies. There are plenty of other examples in history apart from WW2. Investing heavily in Palestine is likely Israel’s cheapest option for stability in the long term. They certainly aren’t going to bomb their way to stability. If they had gone after Hamas leadership specifically with targeted operations while increasing humanitarian aid, rather than terrorizing the entire population of Gaza, they would have had the world and likely a decent percentage of Palestinians on their side. Instead they have utterly and completely botched it and put themselves in a terrible situation strategically. reply JumpCrisscross 7 hours agorootparent> gone after Hamas leadership specifically with targeted operations while increasing humanitarian aid, rather than terrorizing the entire population of Gaza The aid was going first to fighters, then to stockpiles, then to the people. To the extent it could be traded for weapons it was. Now we’re seeing allegations UNRWA employees participated in the October 7th attacks [1]. [1] https://www.nytimes.com/2024/01/26/world/middleeast/un-aid-i... reply weatherlite 7 hours agorootparentprev> Investing heavily in Palestine is likely Israel’s cheapest option for stability in the long term. They certainly aren’t going to bomb their way to stability. Even that is non trivial. Money going into Gaza first goes through Hamas. After buying arms and building expensive tunnels, and paying its men, the leftovers go to the rest of the population. reply Ozzie_osman 8 hours agorootparentprevThis myth that Hamas can be destroyed and that if they are, everything will be alright, is completely disproven by the fact that there is no Hamas in the West Bank and Israeli extremists continue to perpetrate crimes there. reply weatherlite 7 hours agorootparentThere's also the myth that settlers are responsible for all Palestinian grievances. There are no settlers in Gaza since 2005. reply Ozzie_osman 7 hours agorootparentGaza has been effectively under blockade since then too. Maybe that's a contributing factor? Or maybe there are other common factors? reply weatherlite 7 hours agorootparentHamas is trying to kill as many Israelis as it can, maybe that's a contributing factor to the blockade. reply yon109 7 hours agorootparentprevWhere are you getting the idea that tbere is no Hamas in the West Bank? There are very much Hamas militants there that would love nothing more than to commit another Oct. 7th. reply wahnfrieden 8 hours agorootparentprevWith the support of IDF collaboration (and funding from private US organizations). Downvoters don’t like the facts I guess. reply Ozzie_osman 7 hours agorootparentprevThere are two ways to get peace. One is for one side to completely dominate the other at massive cost, and with risk of blowback even after domination. The other is for cooler heads to prevail. Plenty of examples from history of both. And supposedly we had, as a modern world, decided that we prefer the latter path to peace over the former. Hence the United Nations, the Geneva Conventions, etc. reply leereeves 9 hours agorootparentprev> Germany and Japan were conquered and unconditionally surrendered Israel has already done that to Palestine, many decades ago, but they failed to do anything like the Marshall Plan to invest in the occupied lands and create a lasting peace. If we hope to learn from WW2, we should consider the postwar history of Eastern Europe. Like Israel, the Soviets also failed to invest in the lands they occupied, instead trying to suppress rebellions with violence. Now all of those nations are Russia's enemies. reply throwA29B 6 hours ago [flagged]rootparentnext [2 more] >Like Israel, the Soviets also failed to invest in the lands they occupied Don't know about Israel, but you definitely know nothing about the Soviets. reply dang 4 hours agorootparentPlease omit swipes from your comments here, as the guidelines ask. If you know more than someone else, you're welcome to provide correct information, but please don't post putdowns. https://news.ycombinator.com/newsguidelines.html reply adhamsalama 9 hours agorootparentprevEthnically cleansing a population is not right or moral in any case whatsoever. reply gafferongames 7 hours agorootparentHamas's stated aim and goal is to destroy Israel and ethnically cleanse Palestine of the jews \"from the river to the sea\". When somebody tells you they want to destroy you, over and over for years, and then builds up terror factories and uses it to intentionally target women, children and elderly civilians on Oct 7, maybe -- just maybe, Israel has no choice other than to deal with Hamas as they are. reply falserum 5 hours agorootparentIt’s their prime minister who has no choice. As soon as war ends, he is out. Oct events could have been prevented by military presence at the border. reply bart_spoon 8 hours agorootparentprevGermany was reduced to rubble, their population submitted to complete and total surrender, and their leaders were all executed. Japan was firebombed into oblivion and then had two atomic bombs dropped on their civilian population. And both were then completely occupied and had their government dismantled and replaced by their conquerors. What Israel is doing right now seems to be far closer to what happened in Germany and Japan after WW2 than whatever diplomatic solution you are proposing. reply Ozzie_osman 7 hours agorootparentAnd the world decided we didn't want to have wars like that ever again, and gave the defeated countries a path to prosper. Sadly, Palestinians have no such path. reply gafferongames 7 hours agorootparentHamas has spent the aid and all their funds on funding terror. It's no wonder they have no path to prosper. Hamas made it this way. reply Ozzie_osman 7 hours agorootparentThere's no Hamas in the West Bank and no path to prosper there. reply jdietrich 5 hours agorootparentHamas are active in the West Bank and have significant support and influence. If an election were called (there hasn't been one for more than 18 years) it is overwhelmingly likely that Hamas would win. Fatah are somewhat less politically extreme than Hamas, but they are scarcely any less corrupt; within the West Bank, the PA is widely viewed as illegitimate. https://www.aljazeera.com/news/2021/7/29/palestinian-authori... reply RoyalHenOil 1 hour agorootparentThey support Hamas because they can't see any other potential path to prosperity. If you want to quell extremism in a country, you have to give them a genuine alternative to extremism. If all of the moderate options get them nowhere, they will reject them. This is a vital lesson we learned from WWII. Incentives matter. reply pgeorgi 0 minutes agorootparent> They support Hamas because they can't see any other potential path to prosperity. Prosperity through Hamas? Only for a select few who live in other countries. With the amount of aid and money thrown at Gaza, any third rate politician could have achieved prosperity if only they were genuinely in it for the good of the people. Hamas didn't, because their priority doesn't lie in the welfare of the Palestinian people but in the eradication of Israel. 7402 10 hours agorootparentprevI think the allies (largely the US) were able to effect massive cultural changes in Japan and Germany after WWII from aggressive, totalitarian, racist societies committed to military victory by any means necessary to relatively peaceful, even pacifist societies only via: 1) Forcing unconditional surrender on Germany and Japan, whereby virtually every citizen of those countries was convinced that they had lost the war and that resorting to armed struggle for their goals was a complete failure for Germany and Japan, and, 2) A lengthy occupation in those countries that accomplished many things, including the \"de-nazification\" of educational system. reply Ozzie_osman 7 hours agorootparentThis only worked because enough was invested into the defeated countries for their populations to prosper. Case in point, after WW1, we got WW2. The prospects Palestinians are faced with, as proven by the West Bank, are very bleak, making any peace very very unstable. reply pgeorgi 10 hours agorootparentprevIf Germany or Japan is your guideline here, maybe Israel should get a Bomber Harris (https://en.wikipedia.org/wiki/Arthur_Harris#Second_World_War) or a Truman (see nuclear weapons dropped on Japan) on the scene? People are saying that what Israel is doing right now is a genocide. You have seen nothing yet: With either of them at the helm, there would either be an unconditional surrender by Hamas or no Palestinian alive anymore - and by November 15, last year. We don't do such things anymore, and for good reason, but that means that these past situations are unsuitable as example for the present. reply avmich 8 hours agorootparentWhat Israel is doing right now should be viewed from the point of view of the goal of removing the Hamas threat as such. The logic here is \"Hamas should go - what's the best way to make that happen?\" and from this POV the situation is not too grim. It's obviously best to avoid casualties as much as possible, but we are far from perfect wars. reply HDThoreaun 9 hours agorootparentprevGermany and japan returned to their pre war borders after the war. Gaza does not have the land or resources to sustain its population. It literally needs to expand to have any amount of stability. reply avmich 8 hours agorootparentI think the WWII example is really useful here - completion of hostilities and post-war work. Expansion of Gaza may be not necessary at all, looking at Singapore example, not to mention West Bank. reply HDThoreaun 8 hours agorootparentIt is unimaginable to me for Gaza to ever resemble singapore. Singapore had massive advantages that took hundreds of years to create and its biggest continues to be its position along the straight of malacca. If singapore was not along the straight theres no doubt in my mind that it would be in a much much worse position today. Singapore actually has long standing hostilities with Malaysia. The only reason it exists today in its current form is the economic advantage given by its location. reply avmich 7 hours agorootparentLack of imagination can prevent us from seeing solutions. Gaza certainly has advantages - location, population size and age, attention of the world in XXI century among them. reply siliconwrath 10 hours agorootparentprevGermany and Japan were occupied after WWII. https://www.nationalww2museum.org/war/articles/united-states... reply wahnfrieden 6 hours agorootparentTheir borders were restored. reply pgeorgi 4 minutes agorootparentExcept where they weren't. The German borders after 1945 or after 1990 are unlike any other shape of any German nation (or collection of German states) before. vcryan 10 hours agorootparentprevThe notion that the problem is religious fundamentalists is itself propaganda. The people are just people; the problem is a brutal racist occupation that has gone on for far too long. reply jdietrich 5 hours agorootparentThe \"people are just people\" argument is rarely (if ever) applied to domestic politics. Democrats and Republicans may often loathe each other, but at least they have enough respect to recognise that their differences in opinion are meaningful and sincerely held. Many Palestinians are just ordinary people who want to get on with their lives, but some are fanatics. Unfortunately for everyone involved, it is the fanatics who are in charge. Of course, the same could be justifiably argued about the current Israeli government; the crucial difference is that Netanyahu and Smotrich can (and likely will) be removed at the next election. https://en.wikipedia.org/wiki/Opinion_polling_for_the_next_I... reply mderazon 53 minutes agorootparentprevIt's not propaganda. It's a dispute about land with each side not willing to give up land because it's a holy land that God bestowed upon them reply weatherlite 7 hours agorootparentprevYes people are just people and for some people religion is a big deal. It kinda defines their whole world. reply megaman821 8 hours agorootparentprevWere they occupied or was it an open-air prison? Just throw everything out there and see what sticks. reply peterashford 6 hours agorootparentThe West Bank and Gaza are two different locations. The West Bank is occupied and \"open air prison\" doesn't seem like a bad description of Gaza. reply Ozzie_osman 8 hours agorootparentprevWorth pointing out that both sides have extreme religious fundamentalists. Also worth pointing out that peace was achieved between Egypt/Israel but it took leaders like Carter, Sadat, Begin to transcend the conflict. Sadly, Biden is no Carter. And there are no Sadats or Begins anymore. reply avmich 8 hours agorootparentAsk Carter what he thinks about that. I think he'd at least admit that Biden has a huge hindsight - the world today is so different from 1970-s. reply Ozzie_osman 7 hours agorootparentCarter's approach tells us what he would think. Carter was willing to give the Israelis and the Egyptians massive amounts of aid, conditioned on peace. That is very different than offering one side unconditional support despite that side allowing extremists to formulate and shape plans. reply avmich 6 hours agorootparentThat's rather similar to what we have or going to have. Both Israel and Gaza may receive - keep receiving - external aid. The difference is that peace around Gaza, today's and tomorrow's, is going to be enforced more elaborately. reply samirillian 6 hours agorootparentprevI don't think it's too Western-centric to imagine that Palestinians want freedom, which is a universal human desire. Freedom means statehood and self-governance. Oppression is fertile soil for religious fundamentalists, and radicals of every stripe. reply JumpCrisscross 5 hours agorootparent> Freedom means statehood and self-governance That second bit is a magic variable. reply Aeolun 9 hours agorootparentprevAnd yet, women in Afghanistan were happy going to university until we let the fundamentalists back in. reply sfifs 8 hours agorootparentprevAll major conflicts and wars are fundamentally economic and have been so throughout history reply amscanne 8 hours agorootparentSuch a statement seems, at best, a controversial view. For example, I’m pretty sure that the religious aspects of the crusades are generally accepted as the primary cause. reply xdennis 8 hours agorootparentprev> And then everyone who wants peace invests lots of money and expertise over a long time to build a modern, prosperous, stable Palestinian society When Israel left Gaza in 2005 it had no blockade and an airport. Israel blockaded them and bombed their airport because they kept using everything to attack Israel. If Gaza and the West Bank were given complete independence with no interference, what makes you think it will turn out different and they won't use the open borders to bring in weapons to attack Israel? reply refurb 7 hours agorootparentprevThat’s unlikely to work. Many Palestinians want all of Palestine back. Not some of it, all of it. You could draw similarities with the Vietnam War. LBJ tried to dangle the carrot of economic development funds in from of North Vietnam, it didn’t work. There is a core belief that an independent, whole Palestine is the most important thing. More important that economic development. Even more important than Palestinian lives. reply wernercd 7 hours agorootparentprevDoesn't matter how much people who want peace invest when terrorists who want to continue fighting are in charge. There is no \"modern, prosperous, stable Palestinian society\" when terrorists are in charge. They have had better options... and still choose the path they are on. reply peterashford 6 hours agorootparentprevPeople said Apartheid South Africa couldn't end without a bloodbath. People said peace in Northern Ireland was impossible. People thought the Cold War would never end. Impossible things are impossible until they aren't. I'm not saying that any of these things are easy - they clearly are not. But history shows us again and again that change is possible when people work towards it in good faith. From a practical point of view, I think that the international community needs to be allowed to help - both to maintain the peace and broker a way forward. The status quo will not reach peace. Israel will never have peace and security until Palestine has peace and security. reply irishloop 5 hours agorootparentThe Palestine/Israel conflict is significantly longer than any of the examples you gave. Which is not to say that its impossible. But the older I get, the less hope I have. reply ajb 4 hours agorootparentEthic conflicts all end eventually. A historian: https://archive.is/zADeF TLDR: the ways they end are: - partition - equal representation - one side driving out/murdering the other It does seem like a lot of people have given up on the first two, but if it's not one of those then it's the third one. So we have to work towards making it one of the first two. reply locallost 11 hours agorootparentprevIf I knew the answer to that question I would be a high ranked politician. But for me it's important to keep in mind what he is saying here and also in another part explicitly: a diplomatic solution is possible and history proves that. So what I can do is reject the notion that what is happening is unavoidable. reply noqc 11 hours agorootparentHow does history prove any such thing? That's neither how history or proof work. Most of the wars that have been resolved to everyone's benefit have done so by the unconditional surrender of the aggressors, followed by amicable reconstruction. reply locallost 2 hours agorootparentIt provides examples that it happened and thus proves it's possible. reply shakow 10 hours agorootparentprev> How does history prove any such thing? Because there are Jews living in Germany nowadays? reply paulryanrogers 10 hours agorootparentAre there Jews in Germany today because of diplomacy? Or because those who tried annihilating and enslaving most German Jews were removed from power by force? reply noqc 10 hours agorootparentprevAfter Germany surrendered unconditionally and was amicably reconstructed. reply sgift 10 hours agorootparentprev... after Germany was bombed to the ground and occupied for years. Only after that came the diplomatic efforts. reply shakow 9 hours agorootparent> after Germany was bombed to the ground and occupied for years Well, looks like that box is checked for Gaza; can we jump to diplomacy now? reply avmich 8 hours agorootparentBox is not checked yet, otherwise IDF wouldn't have any resistance. We should try diplomacy all the time, but right now the offer of Israel is unconditional surrender or continuation of hostilities. Maybe - maybe - less atrocious to civilians than what it was during March 1945 in Germany. Diplomats will keep their work; of course everybody's abilities are limited. reply Ozzie_osman 8 hours agorootparentprevWho is the aggressor here? reply gafferongames 7 hours agorootparentHamas on Oct 7th reply Ozzie_osman 7 hours agorootparentMany people would disagree if you look at the history starting from the Nakba. reply gafferongames 7 hours agorootparentnext [3 more] [flagged] peterashford 6 hours agorootparentWhat is that question even for? What are you saying? reply Ozzie_osman 6 hours agorootparentprevNot sure how that easily Google-able question has anything to do with the discussion. Name one famous Israeli from more than 100 years ago. Name one famous American from more than 250 years ago. What am I proving by asking these questions? reply krainboltgreene 10 hours agorootparentprev> If I knew the answer to that question I would be a high ranked politician The solution is simple, avoiding the solution in order to create a western military power ally in the middle east is what high ranked politicians do. reply Sabinus 7 hours agorootparent>avoiding the solution The West isn't the one avoiding the solution. If it were up to us, two state would have been sorted decades ago, as evidenced by the repeated peace summits the US has hosted. Israel believe they can't integrate the bulk of the Palestinian population, and there to afraid of attack to live next to an independent Palestinian state. reply krainboltgreene 6 hours agorootparentIf you continually provide missiles and prevent a ceasefire in the UN (a rather unauthoritative body anyways) I would describe you as \"avoiding\" the solution of not settling/attacking Palestine. The \"We were afraid of the people, they might attack us, we have to do this\" line wasn't believable in the 30's and isn't now. reply Sabinus 5 hours agorootparentThe Israelis would continue the war with Hamas with no US support and a ceasefire in the UN. The US won't sacrifice it's relationship with Israel to try to force a resolution on an intractable issue that doesn't really concern the US, and it's interesting that they would be expected to. >The \"We were afraid of the people, they might attack us, we have to do this\" line wasn't believable in the 30's and isn't now. Haven't the Israelis have come under attack from Palestinians since that time for moving on to the land in numbers that made the Palestinians uncomfortable. reply consumer451 7 hours agorootparentprev> The solution is simple Please explain. reply Jochim 7 hours agorootparentnext [5 more] [flagged] dang 7 hours agorootparentPlease don't post in the flamewar style to HN, and especially not to this thread. It's against the site guidelines (https://news.ycombinator.com/newsguidelines.html) and strongly against the intended spirit that I tried to describe in the comment that's pinned to the top. reply Jochim 7 hours agorootparentApologies, I didn't intend the comment to come across that way, it was too flippant given the topic. reply consumer451 7 hours agorootparentprevThis doesn't track because the USA has bases all around the ME, and supplies Israel's \"competition\" like KSA and Egypt with arms. It is much more complicated. reply Jochim 7 hours agorootparentI don't think the situation is particularly inscrutable. Israel receives a greater degree of US support and benefits from it to a greater degree. Other ME states are aligned with the US out of convenience, the sale of western weapons plays a part in that. reply saiya-jin 10 hours agorootparentprevWell, the alternative to diplomatic solution is total annihilation of palestinians in west bank, be it by forcing them off the land which is impossible since they have nowhere to run and other islamic states refuse them (so much for inter-muslim brotherhood, I guess Iran should take them), or murdering them one by one which seems to be going on now. Or what we had till now, which led to what we have now. It doesnt matter that the other side plays dirty, all sides eventually do. It just doesn't matter for statement above. It doesn't matter a nanofraction of a bit what government(s) publicly say, those are farts in the wind to be polite, I don't understand why people even care about such PR, its like what Putin says, what does it matter when its clearly said for a specific purpose and truth is optional? I honestly dont understand the resistance to their own state. Yes they will hate Israel, just like till now they did, just like every single its neighbor since its creation. So what? How did we/they move from this utter hate of neighbors to cca peace? Well certainly not by following the path of trying to eradicate the other, history is pretty clear there. Yes its a bit easier to invade and kill if you want compared to invading a foreign state, but preventing it should be a good thing. Also, US is effectively giving them a blank check, just empty words flying around, I really expected a bit more. A room for Russia or China to step up. Its like counting some destroyed tunnels or killing few brainwashed young guys mattered in long run, in same vein as say counting Vietcong losses and comparing them to US ones didn't matter. That's whats happening now. What's the plan for rest of existence? I dont see that part, I mean 0. But maybe current Israel government likes this situation, I mean the top guy is former special forces guy, so this is not unusual situation and a bit of blood doesn't matter to them and if there is war people don't focus so much on how effectively he erodes democracy. So what is this, state-sponsored genocide? Because 100% this is not how Hamas disappears for longer than few months (in same vein al qaeda didn't) and I think literally everybody involved realizes that, this will actually make it much stronger long term, think about all those eager volunteers from places like Saudi arabia. Soviet war was what created Osama. US invasion of Iraq is what pointed him to US. Suffice to say, when doing grocery shopping I don't buy products from Israel these days, we don't need more wars in middle east and massive refugees waves in Europe. Tiny wallet, but its all I have (apart from vacations but for that Israel was very low in the list anyway). reply vcryan 10 hours agorootparentWhy should the Palestinians leave? Palestinians leaving is ethnic cleansing. reply abigail95 7 hours agorootparentBecause it's a normal outcome of war for territory to shift. It's especially justified if you try to invade another country and then lose spectacularly. reply avmich 8 hours agorootparentprevBecause there's an anti-terrorism operation turned to city war going on, and to be in the middle of hostilities is dangerous. It's really, really hard for palestinians today, yet just remain in place and ignore all calls to leave doesn't look like a good approach. Maybe we don't know something big, it's possible, but from all information from the region leaving still looks like a better option. reply nerpderp82 9 hours agorootparentprevI wanted to let you know that I agree with all your comments. Nothing you have said is out of line. Sometimes it is really hard interacting with the HN crowd, when they get things wrong, it hurts, because they should be able to use their big brains to see through the chaos. Take care. reply mvdtnz 10 hours agorootparentprevThe Palestinian people can oust Hamas, reject Islamic extremism without exception and reform their society to be compatible with a peaceful relationship with their neighbours. reply kelnos 9 hours agorootparent> The Palestinian people can oust Hamas How? They lack the organization and military capability to do so. And while Hamas hasn't done them any favors, with the way Israel has been behaving, I'm not surprised your average Palestinian in Gaza isn't feeling like helping the Israeli objective, even if it likely would be in their long-term interests as well. reply mvdtnz 8 hours agorootparentThey do it in cooperation with the IDF who are determined to do so. reply kelnos 3 hours agorootparentI addressed that in my very short comment; not sure where I wasn't clear. With Israel itself admitting that they are killing roughly 2 civilians for every Hamas fighter they kill, why would you think any civilian in Palestine would trust Israel or be interested in working with them? The fact that it might make logical sense to you or I that they should is entirely irrelevant. We're not there, and if we were, I doubt we'd be much driven by logic at this point. Not to mention we wouldn't have had access to the internet or regular communications with anyone for months now, and only see the death and devastation. reply Aeolun 9 hours agorootparentprevThey could. But they’ll never do it as long as it looks like Hamas is the only one fighting for them. reply avmich 8 hours agorootparentYes, while their optics is like this, it's hard for them to get to a peaceful solution. reply RoyalHenOil 58 minutes agorootparentIt's not just their optics. It looks that way to the rest of the world as well. When the IDF kills (at least) two civilians to every combatant, and then drives many others out of their homes and into starvation, it really does make it look like Hamas is the only organization that will fight for them. And Hamas barely even does that (seeing as they are a terrorist organization that uses Palestinian civilians like sacrificial pawns), but they come far closer to it than any other organization in a position to do anything. If we want Gazans to support an alternative to Hamas, then we need to come up with an alternative to Hamas that supports Gazans better than Hamas does. That should be pretty easy; it's a very low bar. reply hmcq6 9 hours agorootparentprevThe average age in Palestine before Oct 7th was 19. You’re asking a nation of kids to be more mature and organized than the Israeli government who is killing them and their families reply vcryan 10 hours agorootparentprevIt doesn't seem like the Palestinian people are extremist Muslims any more than the Israeli people are extremist Jews. reply bitcurious 10 hours agorootparentprev> Well, the alternative to diplomatic solution is total annihilation of palestinians in west bank, This conflict is taking place in Gaza. reply weatherlite 7 hours agorootparentprev> Well, the alternative to diplomatic solution is total annihilation of palestinians in west bank, be it by forcing them off the land What makes you so certain it's the Palestinians and not the Jews this will happen to? It's the stated goal of the Palestinians and much of the extreme Muslim world surrounding Israel to drive away the Jews and it's not far fetched to see them eventually succeed. reply Aeolun 9 hours agorootparentprev> All correct and yet, what should happen? Happy, fed, employed people do not become terrorists. They have too much to lose. reply HDThoreaun 9 hours agorootparentToo bad gaza has no land or economy to feed and employ themselves. reply avmich 8 hours agorootparentDoesn't mean they can't build it. reply HDThoreaun 7 hours agorootparentBuilding land is quite difficult. Building an economy is almost impossible when under a blockade, and Israel has no reason to end it. reply avmich 6 hours agorootparentIsrael is the one who's going to build it. See, the approach is the following: eliminate Hamas, then start a sort of deprogramming the society, similar to what was happening in Germany, with local specifics of course. Such an approach will take years, but the goal is to have the same effects as in Germany. It's possible to provide food, water, services while keeping a close eye on the Gaza population and ensuring the idea of peaceful cohabitation is dominant. The economy will slowly - or even not so slowly - rebuild, and that's a part of the demonstration of possible and beneficial, from some positions, approach. reply Sabinus 4 hours agorootparentThe Israelis might not have the appetite to administer Gaza themselves. They would want an Arab state to take it but no one wants that headache and they prefer using the Palestinian issue to bash Israel. UN, maybe? reply mk89 2 hours agorootparentprevDo you believe that people in Gaza will accept that Israel rebuilds it? And for how long? Because I already foresee a minority craving for independence against the old invaders that \"enslaved us with money, first took our land, then they tried to buy us out...\". Etc. The comparison with Germany doesn't stand. Two completely different situations, different histories, different people, different mindsets, different economies. You can't just let them rebuild it and hope that people in Gaza don't plan your destruction again and again. reply bart_spoon 8 hours agorootparentprevThat is certainly not true. Exhibit A: Osama bin Laden’s father was literally a multi-billionaire and he himself inherited $30-50 million. reply avmich 8 hours agorootparentHe's not \"people\", he's a \"human\". One human could be significantly off from the expected behavior; many people are less so. reply Aeolun 2 hours agorootparentprevYou think Osama was happy? The man was clearly very, very angry about something, and I doubt it was inheriting a bunch of money. reply maroonblazer 8 hours agorootparentprevNot if they have more to gain in 'heaven'. Remember, Hamas are religious fanatics. reply Aeolun 2 hours agorootparentThey have to be religious fanatics because that’s all they have to cling to. If I’m going to fight a losing battle against a grossly superior enemy I also want to believe that I’ll end up in paradise for it. You might note that that brand of fanaticism goes down rapidly in countries that have high standards of living. reply peterashford 5 hours agorootparentprevhamas != palestine reply skybrian 8 hours agorootparentprevWhile I'm not a military expert, I think it would be reasonable to rule out the possibility of a similar massacre any time soon, for decades at least. It seems unlikely that Hamas would get away with it a second time? They put everything into a one-day surprise attack. The Israeli defense was caught unprepared despite being warned, but they have much more power and they can learn. What happens in the wider conflict (with other Iran-backed militias) is another question. reply weatherlite 7 hours agorootparent> While I'm not a military expert, I think it would be reasonable to rule out the possibility of a similar massacre any time soon I'm not sure its reasonable. No one in Israel is thinking that way at least, and for good reason imo. The motivation to kill is there, so you have to assume there's a lack of ability. OK maybe for a couple of years Hamas will have to regroup, but how much time does it take to get a couple thousands more guns and grenades and bombs when Iran is giving them for free? It doesn't have to be another attack of this magnitude, even killing \"only\" 100 Israelis would be a huge blow. You prevent this type of shit from happening again by being dead serious about countering terror, about deploying sufficient defense and not assuming too much about what the enemy can do because you might not have an accurate picture. Israel has been doing none of that in Gaza in the last decade or more. reply skybrian 4 hours agorootparentSeems like I'm assuming the Israeli defense will learn enough from this attack to prevent anything similar, and you're assuming they won't. Either way it's a guess; we don't know the future. reply weatherlite 4 hours agorootparent> Seems like I'm assuming the Israeli defense will learn enough from this attack to prevent anything similar, and you're assuming they won't I see what you mean now, I was under the impression you think Hamas lost all motivation or means to even try it in the future. Yes if Israel does all the right things the chances of this happening again soon are low. reply avmich 8 hours agorootparentprevHamas doesn't get away from it this time already. reply amluto 7 hours agorootparentHamas has quite a bit of leadership outside Gaza, and as far as I know, most of them are doing fine. They may even have more political capital than before the attacks. I’m not convinced they didn’t get away with it. reply avmich 6 hours agorootparentThe plan right now could be to deny any remaining Hamas influence to anything in Gaza. Yes, some Hamas members may survive, even politically, outside, but they aren't going to affect anybody in Gaza. reply imtringued 2 hours agorootparentprevYou need an anti Hamas Palestinian force that credibly fights against Hamas and has the support of the Palestinians but it is too late for that now. reply ajross 10 hours agorootparentprev> All correct and y",
    "originSummary": [
      "The United Nations' top court has ruled that Israel has a legal obligation to prevent death, destruction, and genocide in Gaza, but did not explicitly order an end to the ongoing military offensive.",
      "The court's ruling is seen as a criticism of Israel's conduct during the conflict and has intensified international pressure to stop the offensive.",
      "Israel's Prime Minister Benjamin Netanyahu has rejected the ruling and pledged to continue the war, raising uncertainty about whether Israel will comply with the legally binding decision.",
      "The court also called on Hamas to release hostages and urged the international community to ensure Israel's compliance with the ruling.",
      "This ruling coincides with International Holocaust Remembrance Day."
    ],
    "commentSummary": [
      "The summary covers various discussions related to the Israeli-Palestinian conflict, including civilian casualties, the actions of the Israeli military, and the role of the ICJ.",
      "Different perspectives are presented, including debates on casualty figures and the influence of external factors.",
      "The summary also explores the challenges in finding a resolution, the role of Hamas, and the potential for future attacks."
    ],
    "points": 443,
    "commentCount": 1147,
    "retryCount": 0,
    "time": 1706279706
  },
  {
    "id": 39144906,
    "title": "Exploiting a Security Vulnerability: Hacking Chess.com with XSS",
    "originLink": "https://skii.dev/rook-to-xss/",
    "originBody": "Playing Chess is one of the many hobbies I like to do in my spare time, apart from tinkering around with technology. However, I'm not very good at it, and after losing many games, I decided to see if I could do something I'm much better at; hacking the system! This blog post is about how I used my cybersecurity knowledge to find XSS on the #1 chess site on the internet, with a user base of over 100 million members - Chess.com. But first, a bit of preface (that includes a slightly less serious, although amusing, OSRF vulnerability!) The Opening In early 2023, I started playing a lot on chess.com; during a discussion with a friend on Discord, I persuaded them to also sign up to the site and used a feature offered by chess.com to become friends once they signed up immediately. This feature reminded me of the MySpace worm in ~2005 (heck, I wasn't even alive then!) when Samy Kamkar injected some code into his profile that would friend anyone who visited it and then inject the same code into their profile (hence creating the worm). I wondered if it would be possible to do something similar here. I clicked on the link and created a new account, then checked the dev tools network tab - interestingly, after the account had been made, it sent a GET request to htttps://chesss.com/registration-invite?hash=XXX This meant that if I could get a user to request this URL, it would force them to friend me automatically. Coincidentally, I was also messing with my settings when I came across the holy grail.....a TinyMCE rich text editor with an image upload function! Let's see what happens when I insert a link for the image. Is the URL embedded directly, or will there be some safe handling to protect against request forgeries? Chess.com handles this server-side by re-uploading the image to their content hosting server and then pointing the image URL to that. Hmmm...But what about using a link whose root domain is chess.com? Would that still get re-uploaded? This would be important, especially when chained with a specific URL like... BINGO! I switched to my alt account, navigated to my main account's profile and then checked my alt's friend list - it had successfully added my main account. I genuinely couldn't believe this had worked, and I had quite a chuckle about it. During the bug-bounty report & triage, the developers tried to implement a block because when I tried to reproduce it again for them, it came up with the following error message: No problem at all, though; I managed to bypass it again by setting up a subdomain that included chess.com & redirected it to /registration-invite And here's what it looked like when visiting my profile: After finding and reporting this bug, I was very interested in what else I could achieve by abusing TinyMCE - could I get XSS? How good was the sanitisation? That brings us to the exciting part of the blog post... The Middle Game After playing around with the editor for a bit, I realised I wouldn't get very far without using something like Burp's proxy to intercept the request to save my About description and inject raw HTML code directly (Anything written in the editor was treated as text). Of course, as one would expect, there were already preventions to remove any non-whitelisted attributes and tags - so let's look at what is allowed. Viewing the TinyMCE config on the site (you can find this in the tinymce-lazy-client.js file), for img tags the background-image style attribute is in the Allow list and does not get filtered out. This was a long shot, but I wondered if the function to re-upload any external URL for the image also got applied to the attributes. Well...no harm in trying; let's see what happens using the following payload: I actually couldn't believe my eyes when I loaded up my profile. It had indeed conveyed the URL, and somewhere along this process, something had gone terribly wrong, resulting in a \" being appended to the beginning of the new link. This resulted in the style attribute being closed prematurely, causing the URL to be converted into extra attributes! Because adding unfiltered attributes was possible, I tried to figure out how I could generate a payload that the server would manipulate into running malicious javascript on image load. It seemed that in the URL, / was being used as a delimiter, with each element between it being added as a new attribute. So I tried with url('https://test.com/onload') To figure out how to add a payload, I tried fuzzing through all the symbols and seeing how each changed the final result. Through this tactic, I worked out you could add a ? to modify the subsequent attribute data (although this comes with the slight caveat that you wouldn't be able to use the ? symbol in the rest of the payload). Using the following: Now we have another issue: the final \"\" at the end will throw a syntax error every time, preventing code from running...let's use // to comment that out and test a basic alert(1) Damn, brackets are filtered….this means that I wouldn’t be able to call any functions with any parameters. Even worse, practically every useful symbol is filtered – ,’ ^&[]’$% ...so how are we supposed to get any serious impact? Back to basics - Let’s see if we can set a variable, x, to 4. (Luckily, the = symbol isn't filtered out.)Using an ‘ in our payload messes up the JS (encoded to %27) and throws a syntax error. I had to do a bit of thinking here, but after a while, I realised that %27 could also be interpreted as the end part of a modulus operation...maybe I could get the browser to execute that operation and then carry out the variable assignment. Here's the payload I came up with:RESULT! Now we're getting somewhere. Let's see if we can modify some inbuilt variables (like document.cookie) to a string instead. This might be a pain because all the usual ways of defining a new string utilise quotes or backticks that are unfortunately filtered out. Time to do some googling. After a bit of rummaging around on StackOverflow, I came across this comment: So it turns out you can define a regex and then get the string from the source attribute! Let's incorporate this into our payload and try to overwrite the PHPSESSID cookie. (Thank you, Frobinsonj!)Overwriting the cookies is cool, but we want to extract the currently set ones for a more significant impact. We can try to set the document and location variables to redirect the user to a site we own, adding on the cookies as parameters, but the problem is we can't use the ? Symbol, as mentioned earlier. Okay, so maybe not as a parameter - but there are other ways to include data in the URL - for example, by setting it in the path. Something like http:attacker.com/sensitivedata requires the use of a /, but unfortunately, we already use that to format the whole URL as a string via the regex trick. However, who said we need to enter the / character manually? It's used all the time for directory paths, so there must already be a JavaScript variable with it included that we can tack onto! In this case, I quickly found location.pathname Here's the final payload:Nice. So I can extract cookies without HttpOnly or any other stored JavaScript objects. I pulled some sensitive account data and reported it to the security team. The Endgame Having managed to get this far, I felt pretty proud, but I'm always up for a challenge and enjoy pushing myself, so I wanted to try to get full XSS. I pondered for a couple of days about how I could achieve this. Let's return to the original issue of using url() in the background-image style that immediately closes the attribute with the URL leftover to be added as unfiltered attributes. What if we move the url() part to another, more direct attribute like srcset instead of using it in style? It'd be a long shot, but it might be treated slightly differently and thus let us use more symbols for a broader syntax of JS, leading to full XSS! Here's what I came up with:As you can see, this doesn't require a ? to be used, and the (, \" symbols are not encoded, meaning we can base64 any payload and directly execute that! Whoo! To top it all off, I quickly learned that the TinyMCE rich text editor system was used not only in your profile's About Me page but practically everywhere on the site, including comments in forums and blogs! This had a significant impact because thousands of users used the comments and blogs daily. I hope you enjoyed reading this as much as I did finding this intriguing bug! In the end, it turned out that the ability for XSS was already known (this is pretty common in bug bounties). Still, my initial vector through the background-image attribute was not known to them, and they thoroughly enjoyed reading my detailed report, offering me a bonus reward for it. Aside: How I accidentally triggered blind XSS During communication with the triage team at chess.com about the initial OSRF vulnerability, they asked me how I managed to execute XSS (an alert had popped up while viewing my profile) - I was confused because, at that time, I couldn't get any injection possible and had no idea where they got that from. Maybe it was another hacker who also got fed up with losing! It turned out that when viewing my profile, the staff team could roll back previous versions to view - loading these previous versions did not filter out malicious HTML from my input. Thus, when I was trying for XSS, the malicious payload was saved as an earlier version and executed as soon as the staff member viewied it! The Analysis The root issue behind these vulnerabilities is the re-uploading image function. Firstly, its checking system to see if the image was hosted on chess.com can easily be tricked by including chess.com in the domain name. Instead, it should check if the root domain is equal to chess.com or, even better, re-upload the image to its posting CDN no matter what the source is. Rich text editors are a gold mine for achieving XSS because they allow different HTML elements for a more stylish appearance. Instead of accepting input and treating it only as text, it has to get raw HTML and directly embed it - this is why configuring allow-lists for what elements & attributes can be taken is so important, as well as ensuring the RTE is always up-to-date. However, in this case, TinyMCE was up-to-date and had been configured correctly not to allow scripting tags and attributes. The problem was that when we inputted the code for our profile, it firstly sanitised it (good), but it did this before it ran extra code on it, such as the re-uploading function - this led to the final HTML being completely different and not going through sanitisation to recheck it. If chess.com wants to keep RTE, it should ensure that the sanitisation is run directly on the final HTML shown to the user. Even though the HTML modification was caused by the re-uploading function modifying the URL, and technically fixing that would stop this specific attack vector, another function may do something similar. Hence, it's essential to fix the sanitisation directly! (Defense in depth) Finally, here are some extra details about the findings: If you're wondering why I didn't just use friend.chess.com directly for the OSRF exploit, during my testing of this, chess.com changed something to do with how it functioned, and I could only get chess.com/registration-invite to work... Google did not like me setting up a chess.com subdomain, and a couple of weeks later, my domain got flagged for \"phishing.\" - I had to contact them to explain and manually remove it as it affected my whole domain. During the data extraction stage, where I couldn't exfil the data as a parameter, I realised I could have instead set the data as a subdomain like http:sensitivedata.attacker.com . This is possible using a multi-level wildcard (catch-all) DNS system with something like a Cloudflare worker to log the subdomain requested. This, however, would be more complicated to set up, and I haven't dug too deep into it. Alternatively, instead of using Burp to intercept and send the raw data in the About section rich text editor, you could also manually send the POST request using a scripting language like Python import requests, os import urllib3 cookies = { xxxxx } headers = { xxxxxx } data = { 'profile[firstName]': 'Jake', 'profile[lastName]': '', 'profile[location]': '', 'profile[country]': '164', 'profile[language]': '10', 'profile[contentLanguage][contentLanguage]': 'default_and_user', 'profile[timezone]': 'Europe/London', 'profile[ratingType]': '', 'profile[fideRating]': '', 'profile[about]': 'payload here', 'profile[save]': '', 'profile[_token]': 'xxxx', } while True: data['profile[about]'] = input() response = requests.post('https://www.chess.com/settings', cookies=cookies, headers=headers, data=data) print(response) 1234567891011121314151617181920212223242526272829303132 Disclaimer: This process was done under CC's bug bounty program, strictly staying within the scope; PII information has been censored by request. This bug was reported over a year ago and has passed the 9-month disclosure time. Please only hack on sites that you have written permission to! Share",
    "commentLink": "https://news.ycombinator.com/item?id=39144906",
    "commentBody": "Rook to XSS: How I hacked chess.com with a rookie exploit (skii.dev)341 points by el_duderino 16 hours agohidepastfavorite98 comments JakeSkii 11 hours agoHi, OP here! Thank you all so much for the positive commments. To give some background: I'm a 17 year old student in the UK doing my A-Levels, still deciding what uni to go to and looking for degree apprenticeship options! You can checkout my github profile here -> https://github.com/Jayy001 (I'm one of the core members behind HashPals, creating Search-That-Hash as well as being a maintainer for the open-source repository of free software for the ReMarkable tablet) reply tfsh 10 hours agoparentI did a degree apprenticeship at a FAANG company and was lucky to transition into a full time role there. It heavily depends upon the company, however my advice is that an apprenticeship at a well respected company goes much further than uni (bar Oxbridge) in terms of immediate job prospects. I'd be very happy to talk more about this w/ you - email in my desc. reply sirsinsalot 9 hours agoparentprevMy ReMarkable thanks you. You're doing great. Keep going. .. And if you go into IT learn about contract negotiations and finances reply Uptrenda 8 hours agoparentprevBright future ahead. Good luck reply tehlike 11 hours agoparentprevnext [18 more] I am going to try referring you for Meta. Can you send me your resume/email/etc to tehlike gmail com? reply 1over137 10 hours agorootparentWhy would you want to punish the lad with working at Meta?! He seems like a nice chap. reply tehlike 10 hours agorootparentI want to hire good people to the company i work for. Is that wrong? reply endofreach 9 hours agorootparentYes, facebook is an evil corporation. Also: stop calling it meta everyone. Don't let them get away with such a poor away to hide their past & also claim a powerful word like that. reply consumer451 8 hours agorootparentLet's provide solutions in addition to criticisms. What would you recommend OP applies for? What are the pros and cons of the option that you suggest vs. the alternative? reply 91bananas 6 hours agorootparentA company working on physical products that solve real world needs is where I have found solace. reply melagonster 4 hours agorootparentwhy? op is young, needs more money. reply ClimaxGravely 4 hours agorootparentWhy? did they say that elsewhere in this thread? reply mewpmewp2 9 hours agorootparentprevWhy are they evil? And if someone wants to do good for the World, why not join an evil corp to inflict change from within? reply tehlike 9 hours agorootparentprevsorry, endofreach, i'll continue to call it Meta or Facebook interchangeably. One is company's legal name, and the other is its major product. As for the evilness, i will not argue. Everyone is entitled to their opinions. For the OP in question, Facebook will provide the best career launch pad, so i will continue to suggest that. I have been to Google and Facebook, so can compare the two. reply DANmode 8 hours agorootparentprevNot for your goals, seemingly no. reply DANmode 1 hour agorootparentI didn't realize you were offering help with internship/apprenticeship. Carry on. OP, definitely cut your teeth in a place like that! Everywhere else afterward will likely feel like a vacation, in comparison. reply maest 9 hours agorootparentprevI assume Meta has a referral program where you receive a bonus if your referee gets hired. reply tehlike 9 hours agorootparentI personally do not care about that, that was not the reason I offered referral. Same reason I referred very little number of people if any in the past. reply ClimaxGravely 4 hours agorootparentThey do have a referral program and you would presumably benefit from that though? I'm honestly asking because I don't know. reply internetter 10 hours agorootparentprevDoes Meta hire 17 year olds? Edit: oh, is this degree apprentice thing a UK thing I'm not familiar with? reply rodrodrod 9 hours agorootparentThey have in the past, though I assume it's exceedingly rare. https://thehustle.co/how-one-17-year-old-coded-a-number-one-... reply tehlike 9 hours agorootparentprevYes, apprenticeship program. reply Jerrrry 5 hours agoprevBack when my sole internet experience was playing (losing) every match on Chess.com as a \"volunteer librarian\", I'd often inject awkwardly escaped characters, closing tags, common quirky control strings, and even OLE objects into the live Chess.com games. Eric (founder) had politely asked me for a more formal audit (to which I declined, not wanting to out myself as an 11 year old script kiddie) but I did explain the RegExp needed for the chat room censor and we tackled the ultimate problem; how to detect cheaters in asynchronous environments. After consideration I informed him the only way to possibly detect cheaters is to compare every (game-significant/high-mu) move made against the known optimal moves from engines, and use statistical inference to discriminate good humans from cheaters. Of course, at the time, this was laughably unfeasible - which was the answer we had concluded on. But for a barely out of elementary kid to discuss those kinda nuances with a legit webmaster (Hello Eric!), it is one of my more favorable internet memories. reply cortesoft 12 hours agoprev> This feature reminded me of the MySpace worm in ~2005 (heck, I wasn't even alive then!) Well damn, I get older every day reply dhosek 12 hours agoparentMy ex-wife managed the security team at MySpace from about 2006 to 2008. The really wild part was when she went online to the MySpace hacker forums to see how the days’ work had gone. The insistence on allowing users to put HTML onto the site was a huge problem. These days, I think the solution would be to do a proper parse of the HTML input and remove forbidden attributes and tags, but back then it was handled via insanity with regexes. reply orenlindsey 11 hours agorootparentThey seriously tried to parse HTML with regex? That's crazy. reply MatmaRex 4 hours agorootparentIt used to be that the only programs capable of somewhat correctly parsing HTML were web browsers, each one of them produced different results, most weren't open-source, and none were reusable as libraries. If you wanted to parse HTML in... looks up what MySpace was written in... ColdFusion, you were all out of luck. Since then people spent years developing specifications and writing the libraries, so now it's not a big deal. reply dlnovell 10 hours agorootparentprevhttps://stackoverflow.com/a/1732454/378171 reply sebmaynard 2 hours agorootparentLong live Tony the Pony. reply charcircuit 11 hours agorootparentprevThey were using regex to block bad input without needing to parse HTML. reply samatman 7 hours agorootparenthope they were using more than one pass....reply SeriousM 2 hours agorootparentI wonder how many passes it needs at all. I mean, if you ipt>ipt> as many times as possible, you'll end up with a xss. Removingat all would be the safest solution. reply MatmaRex 4 hours agorootparentprevYou can read about some things they did, and didn't! https://samy.pl/myspace/tech.html reply charcircuit 2 hours agorootparentprevYou could identify that as not a valid tag in a single pass and know that you should escape theon it. For the implementation all the real HTML tags should be generated by the formatter and not originate from the original input. When formarring the valid tags get deleted from the input and everything else is properly HTML escaped. As a primitive example imagine that the only HTML tags the formatter is able to output isandtags alongside HTML escaped text. That means it will be impossible for a script tag to ever be outputed by the formatter. reply paulpauper 12 hours agorootparentprevPpl were coding up xss back in the day on Myspace to spread ringtone offers reply hot_gril 10 hours agorootparentInnocent users getting pwned aside, that sounds fun, an anarchy website in Windows XP days. reply scrapcode 12 hours agoparentprevMy first thought was something along the lines of \"great to see these young kids doing this kind of work.\" Doing that math hurt my soul. reply rainonmoon 55 minutes agoprevGreat writeup OP! And good luck on your hacking journey. Just in case you haven't come across this yet, when you find parentheses being filtered/encoded in a payload like alert(1), try alert`1` using backticks. Some great resources if you want to take your JavaScript injection to the next level: Brute Logic's XSS cheat sheet and Gareth Heyes's Javascript for Hackers. Some people roll their eyes at cross-site scripting but it's still very powerful and very widespread (and as plugin-baby pointed out, especially when session cookies aren't flagged as HttpOnly, eek.) reply jjbinx007 14 hours agoprevHmm, I don't think this is related but I've personally witnessed (and even recorded) other people making MY moves in chess.com games and also I've been served up a game in progress and I've been able to make moves when I shouldn't have been able to. There are plenty of threads about this too if you Google it. No idea if chess.com have fixed this in the last few months, but they didn't want to listen when I tried to report it. All these games were when I was not logged into the site. It's never happened to me whilst logged in, but I don't play chess that often as it's no good for my blood pressure! reply rendall 1 hour agoparentSorry, I don't understand. When you wrote people are \"making your moves\" do you mean they are substituting your moves with their own in a game? Or that they are mirroring moves from one of your games into their own game? Or something else? reply JyB 1 hour agoparentprevMy moves? What do you even mean reply TowerTall 2 hours agoparentprevHow can you tell that they are making your moves? reply orenlindsey 13 hours agoprevVery cool. I love seeing bug bounty write-ups, especially XSS. They always seem so easy to find (but that's just confirmation bias, I don't get to see the hours of testing and rabbit trails that go nowhere). reply sureglymop 11 hours agoparentIn my experience they are usually found after finding something weird by accident. Then the real challenge is to exploit that flaw (in this case with the text editor). reply fuomag9 10 hours agorootparentI can confirm this, I've found a lot of stuff by accident during my years doing bug bounty reply lovasoa 10 hours agoprev> This feature reminded me of the MySpace worm in ~2005 (heck, I wasn't even alive then!) I instantly felt old. reply consumer451 7 hours agoparentDon't worry about this too much. It gets worse. My question to OP about this event: how did you learn about this? Darknet Diaries, or via something else? reply hot_gril 10 hours agoprevThe part about the rich text editor being a \"holy grail\" is funny. Chess.com is a big website, but I always see those editors and other extra fancy features on random old forums and wonder if the site is Swiss cheese. Anyway, great writeup! reply mmsc 6 hours agoprevCool bug. Google did not like me setting up a chess.com subdomain, and a couple of weeks later, my domain got flagged for \"phishing.\" - I had to contact them to explain and manually remove it as it affected my whole domain. What? Google’s domain registrar will close your account if you have a subdomain which just happens to be named another website? reply JakeSkii 27 minutes agoparentOP - I'm honestly not sure what happened, it could be just based on the naming or something else to do with it. Either way, when I visited it, Googles Safe Browsing alert popped up with \"Deceptive site ahead - recentley detected phishing\". reply phyzome 12 hours agoprevWhat does \"OSRF\" stand for? Is this like CSRF, but... \"Own-Site Request Forgery\", maybe? reply lkbm 12 hours agoparentYeah, pretty close: \"On-site request forgery\"[0] [0] https://github.com/daffainfo/AllAboutBugBounty/blob/master/O... reply wycliffb 3 hours agoprevNo such thing as a rookie exploit reply atdt 12 hours agoprevCould someone explain how re-directing from a subdomain (chess.com.foo.bar) somehow got past some same-origin check? reply DistractionRect 11 hours agoparentClearly chess.com was using something like \"starts with\" to process the re-upload. Basically don't re-upload if it starts with https://chess.com, but filter out if it starts with https://chess.com/registration-invite Typically same origin policies are relaxed for things like images by default [0]. So they came up with a trampoline, they created a chess.com.theirDomain.tld to get past the re-upload filter, which in turn returned a redirect, which the browser followed. [0] https://developer.mozilla.org/en-US/docs/Web/Security/Same-o... reply JakeSkii 10 hours agoparentprevOP Here - Like the others have said, it wasn't a proper same-origin check. We'll never know for sure how it was handled beacuse it was all done server-side but I'm guessing it was something like an if in statement on the FQDN, hence why I was able to get away with pointing it to my own domain. reply fnimick 12 hours agoparentprevIt wasn't a proper same-origin check - the server code was checking to see if the image was hosted elsewhere, and if so, it would download and self-host it. The code to check if it was on `chess.com` probably just checked to see if the domain included that string, because laziness. reply bmacho 2 hours agoparentprevNot CORS origin check (that does not apply to links), but hand made origin check from chess.com developers. reply betenoire 11 hours agoparentprevit sounded server side code allow-list the source, so it was probably just doing a string prefix check. the code to make the friend relation doesn't happen in the browser reply semitones 12 hours agoparentprevif it's happening server side they might have had a bug where they are doing naive substring comparison instead of actual domain evaluation reply Uptrenda 13 hours agoprevI was expecting this to be more nooby based on the title. But instead they built an exploit that bypassed multiple input validation stages with clever hacks. Even going as far as to setup sub-domains to resemble the base domain. I'd not have expected this to work and found it neat in itself. But I guess seeing how complex domains are to parse with regex makes it easy to miss things (or maybe it was just something like a: '... in variable' check, idk.) Author knows their stuff. I admire how much dedication that kind of craft takes. Spending so much time to get further along. Would make for an interesting career. reply hot_gril 12 hours agoparentThe first exploit of friending profile visitors was pretty simple at least, and also the title is a pun. But then it got very complex going for a full XSS. reply gnrlst 13 hours agoparentprevAlso very young making it even more impressive, considering they were born > 2005 according to the author's passing mention in the post. reply plugin-baby 6 hours agoprevGreat write-up! Why isn’t the PHPSESSID cookie HttpOnly? And why if the XSS was already known had they not fixed it?! reply jpc0 44 minutes agoparentI've had arguments with people storing session tokens in local storage and claiming it is perfectly safe. Not marking the cookie httpOnly ironically doesn't surprise me. TLDR: if you aren't going to look up the very basics of security just use a trusted library reply bbno4 12 hours agoprevWow! This is so cool, love the pun in the title hehe reply djha-skin 9 hours agoprevI don't know this required a lot of thought. Didn't really feel like a rookie exploit. reply olliej 3 hours agoprev“ This feature reminded me of the MySpace worm in ~2005 (heck, I wasn't even alive then!)” Goddammit young people :D reply tiffanyh 13 hours agoprev [30 more] https://lichess.org/ The best I’ve found. It’s also crowd funded and they talk about their interest tech as well. reply edgyquant 12 hours agoparentI and many others find the UX to be worse, the tutorials/lessons definitely way less interactive (usually consist of just a text dump) and the sheer number of games where the opponent doesn’t make a single move to be extremely frustrating. It’s also impossible to discuss anything related to chess.com on here or Reddit because lichess people tend to downvote and brigade anyone who doesn’t praise it. reply kthxb 12 hours agorootparentUX is probably a matter of habit, I for one find the chesscom UI unintuitive and I can never find what I'm looking for, but Lichess certainly also has its problems. The free and (to me) intuitive analysis tools on Lichess are the killer feature for me. reply acangiano 9 hours agorootparentThe UX for the analysis part is actually significantly better on Chess.com reply stavros 9 hours agorootparentI very much disagree. Chess.com has analysis being more human-readable, the Lichess graph of move strength is amazing for zooming in to your major gamechangers. reply yinser 9 hours agorootparentprevWord reply hitekker 11 hours agorootparentprevThe people I've met from chess.com were straightforward and focused on their craft. The product they work on doesn't seem to hurt anyone and I haven't see any exploitation common to tech companies. I heard they don't pay Bay Area salaries, which is probably makes them more sustainable over the long-term. I wonder if the peaceful co-existence of lichess and chess.com co-existing somehow disturbs some esoteric ideology. reply faeriechangling 10 hours agorootparentTheir website also came out at a time when it was common for competitors like ICC to charge people to play chess online, chesscom being his huge well featured free website helped push forward the popularity of online chess, and their for-profit model is what allows many of the aforementioned streamers to make a living. I don't hate lichess but I hardly see chesscom as evil. reply hot_gril 10 hours agorootparentThis is a weird rivalry to read about. There should be an agreeable way for them to settle it, maybe some competitive game they both enjoy. reply hobobaggins 9 hours agorootparentstockfish v stockfish! reply TylerLives 11 hours agorootparentprevIirc, some of the hate comes from the fact they were paying popular chess streamers not to play/stream on lichess. reply hitekker 9 hours agorootparentExclusivity contracts seem pretty common in sports media, streaming, and other fields. I don't know the details but a quick google search turns news like https://www.reddit.com/r/chess/comments/7v7xhp/downvotes_wou... > In a nutshell, Chess.com is sponsoring me to continue making my free YouTube/Twitch content, but playing on their site. Apparently, some people thought Chess.com was trying to paywall chess streaming content. Strange reply n_plus_1_acc 12 hours agoparentprevSince the topic of WebAssembly came up today afain today, lichess uses stockfish compiled to wasm delivered to the client to reduce server costs. reply j0hnyl 13 hours agoparentprevI love lichess, their mobile app is such a pleasure to use compared to chess.com. reply edgyquant 12 hours agorootparentI do use lichess on my iPhone, mostly because the pieces don’t even show up on chess.com. If I’m at my laptop though it’s chess.com reply sourcecodeplz 11 hours agoparentprevI just love LiChess. It is fast and lightweight. People are also very nice. reply sagaro 4 hours agoparentprevI play short time controls like blitz in lichess. But for rapid I prefer chess.com as lichess has too much cheating. I find lichess UI/UX better and faster than Chess.com. reply nonethewiser 11 hours agoparentprev> It’s also crowd funded and they talk about their interest tech as well. As well as communism. > Maker of lichess.org, a hippie communist chess server for drug fueled atheists. https://github.com/ornicar reply cristoperb 11 hours agorootparentCan't tell if this comment is supposed to be griping from dour conservative or praise from a communist lichess fan reply themoonisachees 10 hours agorootparentDidn't you hear? The reds are at our door and want to destroy capitalism! reply nonethewiser 10 hours agorootparentprevOr maybe you can decide for yourself how you feel about “a hippie communist chess server for drug fueled atheists.” reply jurynulifcation 10 hours agorootparent\"None the wiser\" is indeed an appropriate username! Please, tell us, by your snark I can assume you're most displeased with this collection of adjectives. But which ones in particular and why? Do hippies frighten you because they represent a more egalitarian and prosperous ideology than your narrow minded brain can conceive of? Do communists make you quake in your boots because you don't believe you could get on in a society where you might not be able to solve all of your problems with money? indeed, imagine if you might have to rely upon people liking you; I also fear for your ability to get on. Is it the \"drug fueled\" portion, because you perhaps feel some right to tell other consenting adults (whom probably know much better about their bodies and their own lives than you do about yours) what to do on their spare time? Or are you waking up to the fact that we, as a society, are becoming more secular[0], and thus you see the advance of atheism as an attack against the institution of your personal sky daddy? And these are all reasonable things to think of you, since you only wave vaguely at a collection of adjectives while expressing some nebulous form of disdain. Perhaps either clarify the nature of your disagreement, or continue to persist in the shadow of intellectual doubt and fear you appear to be laboring under... which is a disease very common to people who appear to believe as you do. [0] https://web.archive.org/web/20240123000719/https://www.nytim... reply eek2121 5 hours agorootparentI love this comment! It exposes all the hate. I wish I had the ability to respond like you. Good writing! (oh and if I wasn't clear, I agree with you. OP needs to back it up, examine himself, and stop trying to control or hate others) reply hot_gril 10 hours agorootparentprevAm I the only one who took the \"decide for yourself\" at face value? It's not even like digging something up, it says right on the author's GitHub. reply jurynulifcation 10 hours agorootparentPerhaps, but then again, I find that typically only people who find those terms odious would care enough to quote that particular passage from the github and then refuse to elaborate on their own personal opinion of it. I also find that people who engage in such hit and run tactics are, typically, not very courageous in their own beliefs, or they'd be full chested about it. reply DANmode 8 hours agorootparentprevHoly shit, no. You are not! reply opportune 4 hours agorootparentprevThanks for the warning. My male cousin tried playing on Lichess once. She now wears knee-high socks and listens to catgirl-emo music while puffing “the reefer” and praying to Karl Marx reply danparsonson 10 hours agorootparentprevYou should be careful playing there - you might become infected by hippie communist ideology and denounce God during your drug-fuelled chess binges. reply sham1 1 hour agorootparent\"God is dead and Lichess has killed him\" is also what Nietzsche said when writing \"The Gay Science\" and playing on Lichess. reply halayli 9 hours agoparentprev [–] It's painful to play on lichess due to wide spread cheating and people opening new accounts. I've been playing on chess.com as a paid user and having much better experience. I don't know what changes chess.com made in the past year but they are definitely moving in the right direction. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recounts their experience of discovering and exploiting a security vulnerability on Chess.com.",
      "The vulnerability allowed the author to automatically add themselves as a friend by accessing a specific URL.",
      "The author used the image upload function of a rich text editor to inject raw HTML code into their profile description and execute malicious JavaScript.",
      "They discuss the potential impact of a cross-site scripting attack and the challenges they faced with an OSRF exploit.",
      "The author provides suggestions on how to prevent similar vulnerabilities in the future."
    ],
    "commentSummary": [
      "A 17-year-old UK student successfully hacked into chess.com, sparking discussions on career opportunities and degree apprenticeships at Facebook.",
      "The incident raises concerns about HTML parsing challenges and potential XSS attacks on websites.",
      "The conversation also highlights the rivalry between chess.com and lichess.org and mixed opinions on the user experience across different platforms."
    ],
    "points": 341,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1706288620
  },
  {
    "id": 39151937,
    "title": "Rclone: A Versatile Tool for Managing Files on Cloud Storage",
    "originLink": "https://rclone.org/",
    "originBody": "Downloads Docs Installation Usage Filtering GUI Remote Control Changelog Bugs FAQ Flags Licence Authors Privacy Policy Commands Overview rclone rclone about rclone authorize rclone backend rclone bisync rclone cat rclone check rclone checksum rclone cleanup rclone completion rclone config rclone copy rclone copyto rclone copyurl rclone cryptcheck rclone cryptdecode rclone dedupe rclone delete rclone deletefile rclone genautocomplete rclone gendocs rclone hashsum rclone link rclone listremotes rclone ls rclone lsd rclone lsf rclone lsjson rclone lsl rclone md5sum rclone mkdir rclone mount rclone move rclone moveto rclone ncdu rclone nfsmount rclone obscure rclone purge rclone rc rclone rcat rclone rcd rclone rmdir rclone rmdirs rclone selfupdate rclone serve rclone settier rclone sha1sum rclone size rclone sync rclone test rclone touch rclone tree rclone version Storage Systems Overview 1Fichier Akamai NetStorage Alias Amazon Drive Amazon S3 Backblaze B2 Box Chunker (splits large files) Compress (transparent gzip compression) Combine (remotes into a directory tree) Citrix ShareFile Crypt (encrypts the others) Digi Storage Dropbox Enterprise File Fabric FTP Google Cloud Storage Google Drive Google Photos Hasher (better checksums for others) HDFS (Hadoop Distributed Filesystem) HiDrive HTTP ImageKit Internet Archive Jottacloud Koofr Linkbox Mail.ru Cloud Mega Memory Microsoft Azure Blob Storage Microsoft Azure Files Storage Microsoft OneDrive OpenDrive QingStor Openstack Swift Oracle Object Storage pCloud PikPak premiumize.me put.io Proton Drive Quatrix Seafile SFTP Sia SMB / CIFS Storj SugarSync Uptobox Union (merge backends) WebDAV Yandex Disk Zoho WorkDrive The local filesystem Contact Sponsor For Business Rclone syncs your files to cloud storage About rclone What can rclone do for you? What features does rclone have? What providers does rclone support? Download Install About rclone Rclone is a command-line program to manage files on cloud storage. It is a feature-rich alternative to cloud vendors' web storage interfaces. Over 70 cloud storage products support rclone including S3 object stores, business & consumer file storage services, as well as standard transfer protocols. Rclone has powerful cloud equivalents to the unix commands rsync, cp, mv, mount, ls, ncdu, tree, rm, and cat. Rclone's familiar syntax includes shell pipeline support, and --dry-run protection. It is used at the command line, in scripts or via its API. Users call rclone \"The Swiss army knife of cloud storage\", and \"Technology indistinguishable from magic\". Rclone really looks after your data. It preserves timestamps and verifies checksums at all times. Transfers over limited bandwidth; intermittent connections, or subject to quota can be restarted, from the last good file transferred. You can check the integrity of your files. Where possible, rclone employs server-side transfers to minimise local bandwidth use and transfers from one provider to another without using local disk. Virtual backends wrap local and cloud file systems to apply encryption, compression, chunking, hashing and joining. Rclone mounts any local, cloud or virtual filesystem as a disk on Windows, macOS, linux and FreeBSD, and also serves these over SFTP, HTTP, WebDAV, FTP and DLNA. Rclone is mature, open-source software originally inspired by rsync and written in Go. The friendly support community is familiar with varied use cases. Official Ubuntu, Debian, Fedora, Brew and Chocolatey repos. include rclone. For the latest version downloading from rclone.org is recommended. Rclone is widely used on Linux, Windows and Mac. Third-party developers create innovative backup, restore, GUI and business process solutions using the rclone command line or API. Rclone does the heavy lifting of communicating with cloud storage. What can rclone do for you? Rclone helps you: Backup (and encrypt) files to cloud storage Restore (and decrypt) files from cloud storage Mirror cloud data to other cloud services or locally Migrate data to the cloud, or between cloud storage vendors Mount multiple, encrypted, cached or diverse cloud storage as a disk Analyse and account for data held on cloud storage using lsf, ljson, size, ncdu Union file systems together to present multiple local and/or cloud file systems as one Features Transfers MD5, SHA1 hashes are checked at all times for file integrity Timestamps are preserved on files Operations can be restarted at any time Can be to and from network, e.g. two different cloud providers Can use multi-threaded downloads to local disk Copy new or changed files to cloud storage Sync (one way) to make a directory identical Bisync (two way) to keep two directories in sync bidirectionally Move files to cloud storage deleting the local after verification Check hashes and for missing/extra files Mount your cloud storage as a network disk Serve local or remote files over HTTP/WebDav/FTP/SFTP/DLNA Experimental Web based GUI Supported providers (There are many others, built on standard protocols such as WebDAV or S3, that work out of the box.) 1Fichier Home Config Akamai Netstorage Home Config Alibaba Cloud (Aliyun) Object Storage System (OSS) Home Config Amazon Drive (See note) Home Config Amazon S3 Home Config Backblaze B2 Home Config Box Home Config Ceph Home Config China Mobile Ecloud Elastic Object Storage (EOS) Home Config Arvan Cloud Object Storage (AOS) Home Config Citrix ShareFile Home Config Cloudflare R2 Home Config DigitalOcean Spaces Home Config Digi Storage Home Config Dreamhost Home Config Dropbox Home Config Enterprise File Fabric Home Config Fastmail Files Home Config FTP Home Config Google Cloud Storage Home Config Google Drive Home Config Google Photos Home Config HDFS Home Config Hetzner Storage Box Home Config HiDrive Home Config HTTP Home Config ImageKit Home Config Internet Archive Home Config Jottacloud Home Config IBM COS S3 Home Config IDrive e2 Home Config IONOS Cloud Home Config Koofr Home Config Leviia Object Storage Home Config Liara Object Storage Home Config Linkbox Home Config Linode Object Storage Home Config Mail.ru Cloud Home Config Memset Memstore Home Config Mega Home Config Memory Home Config Microsoft Azure Blob Storage Home Config Microsoft Azure Files Storage Home Config Microsoft OneDrive Home Config Minio Home Config Nextcloud Home Config OVH Home Config Blomp Cloud Storage Home Config OpenDrive Home Config OpenStack Swift Home Config Oracle Cloud Storage Swift Home Config Oracle Object Storage Home Config ownCloud Home Config pCloud Home Config Petabox Home Config PikPak Home Config premiumize.me Home Config put.io Home Config Proton Drive Home Config QingStor Home Config Qiniu Cloud Object Storage (Kodo) Home Config Quatrix by Maytech Home Config Rackspace Cloud Files Home Config rsync.net Home Config Scaleway Home Config Seafile Home Config Seagate Lyve Cloud Home Config SeaweedFS Home Config SFTP Home Config Sia Home Config SMB / CIFS Home Config StackPath Home Config Storj Home Config Synology Home Config SugarSync Home Config Tencent Cloud Object Storage (COS) Home Config Uptobox Home Config Wasabi Home Config WebDAV Home Config Yandex Disk Home Config Zoho WorkDrive Home Config The local filesystem Home Config Virtual providers These backends adapt or modify other storage providers: Alias: Rename existing remotes Home Config Cache: Cache remotes (DEPRECATED) Home Config Chunker: Split large files Home Config Combine: Combine multiple remotes into a directory tree Home Config Compress: Compress files Home Config Crypt: Encrypt files Home Config Hasher: Hash files Home Config Union: Join multiple remotes to work together Home Config Links Home page GitHub project page for source and bug tracker Rclone Forum Downloads Gold Sponsor Silver Sponsor Share and Enjoy Twitter Facebook Reddit Links Rclone forum GitHub project Rclone Wiki Sponsor @njcw © Nick Craig-Wood 2014-2024 Source file _index.md last updated 2023-11-08 Uploaded with rclone. Built with Hugo. Logo by @andy23. Served by Caddy. Hosted at Hetzner Cloud.",
    "commentLink": "https://news.ycombinator.com/item?id=39151937",
    "commentBody": "Rclone syncs your files to cloud storage (rclone.org)263 points by thunderbong 7 hours agohidepastfavorite105 comments mike31fr 2 minutes agoAn item on my todo list reads \"Setup a backup system using Borg\". I didn't know about Rclone but it seems very good, so now I want to rename my todo list item as \"Setup a backup system using Rclone\". How would you compare these 2 solutions? reply zero0529 2 minutes agoprevFun fact somebody reverse engineered the Proton Drive API by looking at their open source client and made a plug-in for RClone. This is currently the only way to get Proton Drive on Linux. reply patrickwalton 4 hours agoprevMy Dad left us 30 TB of data when he passed. I trimmed it down to 2 TB and tried to use Google's desktop sync app to upload it to cloud. It ran on my work computer during COVID for 8 months straight before finishing. When I tried to back up that and my other data to a hard drive, Google takeout consistently failed, downloading consistently failed. I went back and forth with support for months with no solution. Finally I found rclone and was done in a couple days. reply tomcam 3 hours agoparent> Google takeout consistently failed, downloading consistently failed I get extra angry about situations like this. I have paid Google many thousands of dollars over the years for their services. I just assume that one of the fundamentals of a company like that would be handling large files even if it’s for a fairly small percentage of customers. I get that their feature set is limited. I kind of get that they don’t provide much support. But for the many compromises I make with a company that size, I feel like semi-competent engineering should be one of the few benefits I get besides low price and high availability. reply firtoz 1 hour agorootparentIn the past few years it has been a leech of brain power that's optimized itself into producing nothing of value except demos that get abandoned immediately. From what I read, they seem to have managers and executives with bad incentives and too much power. So it seems that it doesn't really matter how competent the engineer is, their work goes into numerous black holes in the end. reply harshreality 30 minutes agorootparent> We should also remember how a foolish and willful ignorance of the superpower of rewards caused Soviet communists to get their final result, as described by one employee: “They pretend to pay us, and we pretend to work.” Perhaps the most important rule in management is “Get the incentives right.” -- Charlie Munger, Poor Charlie's Almanack ch. 11, The Psychology of Human Misjudgment (principle #1) reply rakoo 20 minutes agorootparentprevDevil's advocate: egress prices are always extremely high, so if you use their service that doesn't transfer the cost over to you it means it has been factored in that you won't be downloading that much. Making obstacles to actually doing it is, for them, the cost-effective way, and if you want to have an actual full access you're supposed to use their cloud storage. But that's only one possible reasoning. reply Erratic6576 1 hour agoparentprevInability to download from the cloud is happening to me every with every provider. Proton from the web, OneDrive Cryptomator vault through Cyberduck. I’ll have to use rclone, I guess reply artdigital 6 hours agoprevRclone can also mount cloud storage to local disk, especially nice from kubernetes. Write/read speed isn't the fastest when using as a drive with lots of files in the same folder, but a quick and easy way to utilize cloud storage for projects It can also e2e encrypt locations, so everything you put into the mounted drive is getting written encrypted to Dropbox folder /foo, for example. Nice, because Dropbox and other providers like s3 don't have native e2e support yet All in all, Rclone is great! One of those tools that is good to have on hand, and solves so many usecases reply ddeck 3 hours agoparentIt is indeed great for this, but you need to make sure your network is stable. I use it on my desktop and laptop to mount Google drives. The problem on the laptop is that the OS sees the drive as local, and Rclone doesn't timeout on network errors. So if you are not connected to wifi and an application tries to read/write to the drive, it will hang forever. This results in most of the UI locking up under XFCE for example, if you have a Thunar window open. reply stiff 3 hours agorootparentThere is in fact a default timeout of 5 minutes and you can change it: https://rclone.org/docs/#timeout-time I shorten it to prevent lockups like you are describing. reply ddeck 2 hours agorootparentThanks, but unfortunately this doesn't work - for my issues at least. I have this (and conntimeout) set to 15 seconds, but it makes no difference. I tried those based on another user reporting the same issue here: https://forum.rclone.org/t/how-to-get-rclone-mount-to-issue-... The timeout param is listed as \"If a transfer has started but then becomes idle for this long it is considered broken and disconnected\". This seems to be only for file transfers in progress. I traced it once, and Rclone gets a \"temporary DNS failure\" error once the network is down, but just keeps retrying. reply sgbeal 6 hours agoparentprevIt's also a trivial way to set up an ad-hoc ftp server which serves either local or cloud storage. e.g. my Pi4 runs an rclone ftp server which exposes my dropbox to the rest of my intranet, and a separate ftp server which my networked printer can save scans to. The same machine uses rclone to run automated backups of cloud storage for my household and a close friend. rclone is a godsend for my intranet. reply rakoo 16 minutes agorootparentAnd then all you need to do is use a trivial curlftpfs to have a synchronized folder available. Dropbox is not needed anymore ? reply bravura 5 hours agorootparentprevDo you mind explaining why it's so trivial versus setting up traditional ftp? I'm missing something. Thank you reply sgbeal 4 hours agorootparent> Do you mind explaining why it's so trivial versus setting up traditional ftp? nohup /usr/bin/rclone serve ftp --addr MYIP:2121 $PWD &>/dev/null & No configuration needed (beyond rclone's per-cloud-storage-account config (noting that serving local dirs this way does not require any cloud storage config)) and some variation of that can be added to crontab like: @reboot /usr/bin/sleep 30 && ...the above command... Noting that $PWD can be a cloud drive identifier (part of the rclone config) so it can proxy a remote cloud service this same way. So, for example: rclone serve ftp --addr MYIP:2121 mydropbox: assuming \"mydropbox\" is the locally-configured name for your rclone dropbox connection, that will serve your whole dropbox. reply steve_rambo 52 minutes agorootparentJust write a systemd unit. These commands are not any easier to support and are far worse from the purely technical point of view. You'll get: - startup only when the network is up - proper logging - automatic restarts on failure - optional protection for your ssh keys and other data if there's a breach (refer to `systemd-analyze security`) Run: $ systemctl --user edit --full --force rclone-ftp.service this opens a text editor; paste these lines: [Unit] After=network-online.target Wants=network-online.target [Install] WantedBy=default.target [Service] ExecStart=/usr/bin/rclone --your-flags /directory and then enable and start the service: $ systemctl --user enable --now rclone-ftp reply rezonant 12 minutes agorootparentSeriously yes. Crontab isn't meant to keep your services up. We have a proper service manager now, out with the hacks. reply killingtime74 5 hours agorootparentprevCan traditional FTP talk to Dropbox? reply OkGoDoIt 5 hours agorootparentAssuming the Dropbox is synchronized somewhere to your file system, the FTP server could serve that directory. Although I guess not everyone synchronizes their Dropbox locally. reply sgbeal 4 hours agorootparent> Although I guess not everyone synchronizes their Dropbox locally. And i've yet to see a pi-native dropbox client for doing so. PS: i actually do sync dropbox to my main workstation but selectively do so. The lion's share of my dropbox is stuff i don't need locally so don't bother to sync it. The rclone approach gives me easy access to the whole dropbox, when needed, from anywhere in my intranet, and i can use my local file manager instead of the dropbox web interface. reply artdigital 6 hours agorootparentprevOh wow I didn't know about this! Good tip reply safety1st 5 hours agoparentprevHas anyone used it successfully as a replacement for two-way sync apps (like Insync for Google Drive)?. Insync sucks, and Google Drive sucks, but for something I depend on every day I feel like I really need to have a local copy of the files and immediate sync between local and server, particularly when Internet access is spotty. reply avhception 53 minutes agorootparentYou might want to try Unison: https://github.com/bcpierce00/unison I've been using it to great effect for over 10 years on a daily basis. reply sgbeal 3 hours agorootparentprev> Insync sucks... FWIW, i've been using Insync on Linux since it went online (because Google never released a Linux-native client). Aside from one massive screw-up on their part about 8 or 10 years ago (where they automatically converted all of my 100+ gdocs-format files to MS office and deleted the originals), i've not had any issues with them. (In that one particular case the deleted gdocs were all in the trash bin, so could be recovered. Nothing was lost, it was just a huge pain in the butt.) reply tomcam 3 hours agorootparent> Aside from one massive screw-up on their part about 8 or 10 years ago (where they automatically converted all of my 100+ gdocs-format files to MS office and deleted the originals) Why. Just why. How does that shit ever happen in a public release? reply godzillabrennus 5 hours agorootparentprevSeems like a market opportunity exists for this especially with Apple cutting external drive support for third party sync tools including DropBox. reply CharlesW 4 hours agorootparentYou can still do this, but Dropbox can’t use the File Provider API for that yet, so the experience won’t be quite as integrated as it is with Dropbox for macOS on File Provider. See https://help.dropbox.com/installs/dropbox-for-macos-support for more. reply Thri4895o 3 hours agorootparentprevYou probably want syncthing reply akdev1l 4 hours agoparentprevWhen you say “e2e” encryption do you mean client-side encryption? Because S3 supports both client and server side encryption. (It doesn’t really need to do anything on the service side to support client-side encryption tbf) For client side encryption they have a whole encrypted S3 client and everything. (https://docs.aws.amazon.com/amazon-s3-encryption-client/late...) reply aborsy 3 hours agorootparentThis seems to be an SDK or library, not a command line tool. reply xcrunner529 4 hours agoparentprevI first used it at work to sync a OneDrive folder from a shared drive due to different audiences. Very cool tool. The open source stuff I really love. reply FwarkALark 5 hours agoparentprev> Rclone can also mount cloud storage to local disk It's not immediately apparent what this means—does it use FUSE, 9p, a driver, or some other mechanism to convert FS calls into API calls? EDIT: it's FUSE. reply kitd 1 hour agoprevThis is a great landing page IMHO. The first item is not some fancy graphic, but a short paragraph explaining exactly what it is. I had a vague idea about rclone already, but it took about 5 seconds of reading to get a good understanding about its capabilities and how it could help me. A much better sales pitch than having to fight through 'Get started' or Github links to find basic info. reply bobek 3 hours agoprevTake a look at Restic for backups. Rclone and Restic play together really nicely. https://www.bobek.cz/blog/2020/restic-rclone/ reply skrause 14 minutes agoparentThe main disadvantage with pure Restic is that you usually have to end up writing your own shell scripts for some configuration management because Restic itself has none of that. Fortunately there is https://github.com/creativeprojects/resticprofile to solve that problem. reply archon810 3 hours agoparentprevCheck out duplicacy https://twitter.com/ArtemR/status/1159392251992145920 https://github.com/gilbertchen/duplicacy reply skrause 19 minutes agorootparentI moved away from Duplicacy to restic when restic finally implemented compression. Duplicacy is slower and also only free for personal use. reply RockRobotRock 3 hours agoparentprevreally tough for me to decide to use restic or kopia. instead i use a way worse solution because i'm afraid i'll mess something up reply hosteur 3 hours agorootparentI use restic for everything Linux or windows except for Mac’s. There I use kopia. It just works. There is not much to mess up really. Just keep your password safe and be sure to test your backups. reply aborsy 3 hours agorootparentprevI back up TBs with restic, never had issues. When I need a file, I mount the remote repository. The mount is fast with S3. The rclone backend means I can backup anywhere. reply djbusby 6 hours agoprevI use rclone daily. It's replaced sshfs for some cases. Another is to push home server $Archive share to rsync.net. another is to pull photos into $Archive from my Google account, my wife's, moms, dads, and kids account. Also my 3 clound account for different $WORK into $Archive (and then to rsync.net). This is top-tier tooling right here. reply hyperpl 6 hours agoparent> another is to pull photos into $Archive from my Google account I assume you are pulling from Google photos? If so, then I think the only way to get original quality is to use takeout? reply djbusby 5 hours agorootparentThis I'm not sure of. I also have a habit to use Takeout quarterly (but this blob is not merged). I think I should check these configs; I want the full fidelity. reply yunohn 9 minutes agorootparentSadly, it’s not configurable. It’s just an inherent limitation of the API (1). Takeout is the best alternative, but for something more realtime you can use tools (2) that wrap the browser UI which also exports full quality. (1) https://github.com/gilesknap/gphotos-sync#warning-google-api... (2) https://github.com/JakeWharton/docker-gphotos-sync reply archon810 3 hours agoprevrclone ncdu is my favorite rclone trick https://rclone.org/commands/rclone_ncdu/. Most cloud space providers don't show you how much space each folder and subfolder actually occupies. Enter rclone ncdu. reply aragilar 3 hours agoparentWow, this is really nice! reply divbzero 5 hours agoprevRclone has a large selection of storage backends [1] plus a crypt backend [2] for encrypting any of the storage backends. [1]: https://rclone.org/overview/ [2]: https://rclone.org/crypt/ reply danboarder 2 hours agoprevThere is a built in web GUI (experimental), and I also found the RcloneBrowser project that looks helpful when a GUI is handy. https://kapitainsky.github.io/RcloneBrowser/ https://github.com/rclone/rclone-webui-react reply miki123211 5 hours agoprevI'm definitely a Rclone fan, it's an invaluable tool if less technical folks give you lots of data in a consumer / business cloud, and you need to somehow put that data onto a server to do further processing. It's also great for direct cloud-to-cloud transfers if you have lots of data and a crappy home connection. Put clone on a server with good networking, run it under tmux, and your computer doesn't even have be on for the thing to run. reply sgbeal 3 hours agoparent> Put clone on a server with good networking, run it under tmux tmux isn't strictly necessary: nohup /usr/bin/rclone ... &>/dev/null & then log out and it'll keep running. reply tonymet 1 hour agoprevI use rclone on vm instances to sync files across gdrive, google photos , one drive , s3 and gcp object storage . Running migrations on the server side is faster and more reliable. I can monitor transforms and transfers in tmux and then run quality checks when it’s complete And having a vm lets me filter and transform the data during the migration. Eg pruning files , pruning git repos, compressing images . There’s a framework waiting to be made that’s like grub but for personal data warehouse grooming like this reply dmarinus 3 hours agoprevRclone is a magic tool, I've used it for many different use cases. When I last checked it doesn't use the AWS SDK (or the Go version is limited). Anyway, it isn't able to use all settings in .aws/config. But it is kind of understandable that it doesn't support all backend features because it's a multifunctional tool. Also the documentation is full of warnings of unmaintained features (like caching) and experimental features. Which is a fair warning but they don't specifically tell you the limitations. reply CobrastanJorji 4 hours agoprevI appreciate how its home page proudly calls out that it always verifies checksums. I've been boggled in the past how many tools skip that step. Sure, it slows things down, but when you're syncing between cloud storage options, you're probably in a situation where you really, really want to verify your checksums. reply b33j0r 4 hours agoparentI thought the “indistinguishable from magic” testimonial at the top was a bit arrogant, but am currently trying to find out if these extraordinary claims have extraordinary evidence ;) reply jkrubin 2 hours agoprevI have used rclone for several years now and it works so good. I use it in place of rsync often too. It’s great for file moving on local file systems too. reply haloboy777 2 hours agoprevI have been using rclone for over two years now. Typically, I run cron to copy any new files in the directories that are most important to me. The combination of rclone and B2 storage is quite effective, especially considering its ease of use and cost efficiency. reply krick 4 hours agoprevJust browsing the list of supported providers and such makes me a bit overwhelmed. There are so many tools that are kinda similar but slightly different, that from \"wow, rclone seems like a great tool\" I quickly come to \"what should I even use?\" Rclone, restic, borg, git-annex… Is there a case to use several of them together? Are there, like, good comprehensive real-life case studies to see how people use all that stuff and organize vast amounts of data (which are kinda prerequisite for anything like that to be used in the first place)? reply Shakahs 4 hours agoparentRclone is the general purpose \"swiss army knife\". It can be used to read/write/sync/copy/move files between any supported service and your local device, and also mount remote storage as a local drive. Restic and Borg are for making backups only. reply sgbeal 3 hours agorootparent> It can be used to read/write/sync/copy/move To help avoid getting anyone's hopes up: rclone does not do automatic two-way sync. In rclone parlance, \"sync\" means to either pull all files from a remote and make a local copy match that, or do the opposite: push a local dir to a remote and update the remote to match the local one. Note that \"match\" means \"delete anything in the target which is not in the source.\" reply bvrmn 44 minutes agorootparentThere is rclone bisync. reply pdimitar 22 minutes agoparentprevI use Borg to backup my stuff to a local disk repository, which I then synchronize -- encrypted -- to several cloud accounts, and that is done by rclone. reply aragilar 3 hours agoparentprevI use rclone and git-annex together (there's a git-annex special remote plugin for rclone). Rclone handles interfacing with the various cloud providers, while git-annex tracks where the files are. reply _giorgio_ 6 hours agoprevWhat cloud storage provider officially supports this tool or the protocol used by it? The instructions look mostly like a reverse engineering effort that can fail anytime for any reason. Of course you'll get some notification, but still seems a thing to avoid in principle. reply rakoo 9 minutes agoparentThere is no rsync protocol, only whatever protocol exist already. Most providers will have their version of S3, so if a provider wants to implement a strict copy of the AWS api they will be compatible. They can also provide an SFTP API and rclone will work. reply dannyw 6 hours agoparentprevThey generally use official APIs, of which most backends have. I’ve been using rclone for 3 years without issues. Across many different backends. reply IvyMike 3 hours agoparentprevWhat if we looked at all of the cloud providers APIs, which may or may not be similar to one another, may be in constant flux, and may have undocumented quirks, and hid all that complexity inside of one black box that provided a single clear API. The guts of that black box might be kinda ugly, and might need at lot of constant updating, but for a lot of users (including me), that is more appealing dealing with all the raw complexity of the various cloud providers \"offical\" APIs. reply andersa 6 hours agoparentprevMost providers support S3 compatible APIs which rclone can then use to talk to them. For example, S3, Cloudflare R2, Backblaze, ... reply ordersofmag 6 hours agoparentprevIt's a wrapper around a bunch of API's. If that makes you nervous then wait until you hear about how the rest of the modern web is strung together. It's been working reliably for me for a decade. reply password4321 6 hours agoparentprevrsync.net reply FwarkALark 5 hours agoparentprev> What cloud storage provider officially supports this tool or the protocol used by it? Man I wish I lived in a universe where providers actually supported tooling. You're completely delusional tho. reply djbusby 5 hours agorootparentNot delusional. The rsync.net supports low-level tools like scp, and also this. And their team is great for engineer level questions. reply FwarkALark 5 hours agorootparentThat's wonderful! Full endorsement of the support of rsync.net. I sincerely doubt most tools will be supported by most providers (by usage), however, and I question the evaluation of tools by this metric. Support is generally a fairly bad metric by which to evaluate tooling—generally speaking, if you care which client is consuming an API someone has done something horrifically wrong. reply djbusby 4 hours agorootparentWot? Support is THE metric. reply 1vuio0pswjnm7 20 minutes agoprev\"syncs your files to could storage\" == \"saves a copy of your files on someone else's computer\" reply conqrr 2 hours agoprevRestic (rclone)+ B2 + Systemd Has solved backups for my system. Mainly the home sir of my Linux desktop. Never looked at anything else. reply neilv 5 hours agoprevI used `rclone` in one startup to add the storage services the biz people were using, to engineering's easy&inexpensive offline \"catastrophic\" backups. I used the normal ways of accessing AWS, GitLab, etc., but `rclone` made it easy to access the less-technical services. reply qudat 5 hours agoprevrclone is so cool! https://pgs.sh is using similar tech but focusing on a managed service specifically for static sites. reply arcza 2 hours agoprevA shame the features don't indicate it can encrypt at rest. reply tomrod 5 hours agoprevI literally picked up rclone for the first time last weekend and have been running with it. Great tool! reply pcwelder 3 hours agoprevrclone also has a \"universal\" file explorer. I haven't found any other such explorer. reply RockRobotRock 3 hours agoprevup there with ffmpeg in terms of usefulness reply more_corn 6 hours agoprevI use this to replace rsync because it does some things significantly better. reply geerlingguy 6 hours agoprevEvery time I see this pop up on HN, I upvote. I've been using rclone for years for my main backup [1] (now over 18 TB) from my home NAS to Amazon S3 Glacier-backed Deep Archive, and it is by far the easiest backup setup I've ever had (and cheap—like $16/month). [1] https://github.com/geerlingguy/my-backup-plan reply dchftcs 6 hours agoparentEgress costs are significant by the time you want to use your backup, around $1800 to download the 18TB, which is around 10 years of storage cost. If you assume 5 years of HDD data lifetime, you need to roughly triple that monthly cost, which is not too bad, but you can buy an enterprise 20TB drive per year for that cost. Personally I would only use AWS in a way that I would almost never have to pay for egress for the entire dataset except when my house gets burned, as a last-resort backup instead of a main one. reply geerlingguy 5 hours agorootparentThat's exactly what I'm using it for :) I have a primary and backup NAS at home, and a separate archive copy updated weekly offsite locally. Then Glacier is my \"there was a nuclear bomb and my entire city is completely gone\" solution. And in that case, assuming I had survived, I would be willing to pay most anything to get my data back. reply freedomben 5 hours agorootparentNice, that's a great point and a good use case. I normally try to stay away from AWS (when I have to care about the cost) but I think you've found a case where it makes sense! I've already got backblaze (behind rclone) set up for my backups so adding a glacier archive would be quite easy. Thanks! reply krick 5 hours agorootparentprevWouldn't Backblaze be much cheaper for that? reply geerlingguy 5 hours agorootparentLast time I priced it out, Backblaze was more expensive per GB — note that I'm using Glacier Deep Archive, which is something like an order of magnitude less expensive than plain Glacier-backed buckets. It also incurs a delay of at least 6-12 hours before the first byte of retrieval occurs, when you need to restore. So there are tradeoffs for the price. reply krick 4 hours agorootparentOh, I see. I'm shamefully ignorant about everything concerning backups, so I just googled \"Amazon S3 Glacier\" and compared some numbers that pop up to some other providers. > a delay of at least 6-12 hours before the first byte of retrieval occurs Huh. I wonder how it actually works behind the curtains. Do hey actually use HDDs to store all of that, or maybe is there some physical work involved in these 12 hours to retrieve a tape-drive from the archive… reply geerlingguy 4 hours agorootparentFrom what I remember, Deep Archive uses tape libraries, and retrieval requires a robot fetching tapes quite often, leading to that delay. reply judge2020 4 hours agorootparentprevPro tip is to create a Google Workspace org and pay the $18/mo per 5TB of Drive storage to also get no egress fees. With rclone, the process is fairly simple especially when using a service account to authenticate (so no oauth revocations or refreshing). reply freedomben 5 hours agorootparentprevYep, if costs are a concern (which for any personal backup plan they should be) then stay away from AWS. Backblaze is IMHO the best option reply nektro 6 hours agoparentprevyou might be interested in https://restic.net :) reply A1kmm 5 hours agorootparentThe two work together well too - I prefer to let Restic back up to a separate local (magnetic) HDD for my repo, and then use rclone to sync the local repo to Backblaze B2. Compared to a direct cloud repo set up in Restic, it gives me much better restore times and lower costs for the common case where your local site is not completely destroyed (e.g. data corruption etc...), while still giving you the safety of a slower and more expensive off-site backup for when you really need it. reply eek2121 6 hours agoprevSo I see this type of headline happen a lot, and despite being a long time reader and short time commenter, is there a reason the author doesn't make a more specific headline? Rclone has existed forever and has been mentioned here over a thousand times (https://www.google.com/search?client=firefox-b-1-d&q=rclone+...) Most of the time the poster links to a specific news item at least (which is also not okay without a specific headline) but sometimes the link just points to the home page. Regardless, it has been mentioned before. EDIT: Just to be clear, I'm not again an occasional mention of a project. Hacker news has allowed me to find some real gems, but most of those posts are new features added to the software, not just a generic link to the homepage. reply pvg 6 hours agoparentReposts are fine after a year or so and there hasn't been one that recently. Titles are usually the titles of the pages linked as is this one. https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... reply Ayesh 5 hours agoparentprevSome people might end up in the 10,000 (https://xkcd.com/1053/) reply iJohnDoe 6 hours agoparentprevI think it’s meant to generate upvotes on the post and also meant to encourage discussions. Like you mentioned, some real gems are found, and for me are often found in the comments. So, these reposts are helpful. It’s like how many posts were made for “What do you use for note taking?” Some gems are are in the comments. reply mil22 6 hours agoparentprev. reply pvg 6 hours agorootparentIf it isn't newsworthy, why is it on Hacker News? This is discussed in the site docs, it's fine to get news from HN but HN is not really about news. reply mil22 5 hours agorootparentFair enough - as a user, that prompts me to ask myself, why am I using Hacker News for tech news when most of the content I see daily isn't actually news. I guess I will just be more aggressive in hiding posts that I didn't want to waste my time reading. reply ehPReth 3 hours agorootparentprevbecause learning is FUNdamental! reply ggm 6 hours agoprev [–] Onedrive, Google drive and Dropbox but.. not icloud. Says something about Apple maybe reply crazygringo 5 hours agoparent [–] Says that Apple doesn't provide a public web API for it. There's a ticket covering everything you might ever want to know: https://github.com/rclone/rclone/issues/1778 Seems like rclone would support it if Apple ever created an official way to do so. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Rclone is a command-line program for managing files on cloud storage with support for over 70 providers.",
      "It offers features like encryption, compression, and hashing, making it suitable for backup, data restoration, migration, and file syncing.",
      "Rclone preserves timestamps, verifies checksums, and can be used as a disk to access cloud storage, serving files over different protocols. It is open-source and has a helpful community."
    ],
    "commentSummary": [
      "Users discuss the benefits and limitations of using Rclone, a cloud storage syncing tool, for file backup.",
      "Alternative syncing tools and encryption options for cloud storage are mentioned.",
      "The conversation also covers the limitations of the Google API, using Rclone with other backup tools, and the cost and trade-offs of different backup options like Amazon S3 Glacier and Backblaze."
    ],
    "points": 263,
    "commentCount": 105,
    "retryCount": 0,
    "time": 1706323819
  },
  {
    "id": 39144978,
    "title": "The Explosive Growth of Batteries: Unlocking a Sustainable Future",
    "originLink": "https://rmi.org/the-rise-of-batteries-in-six-charts-and-not-too-many-numbers/",
    "originBody": "Strategic Insights The Rise of Batteries in Six Charts and Not Too Many Numbers Shares The Rise of Batteries in Six Charts and Not Too Many Numbers The unstoppable rise of batteries is leading to a domino effect that puts half of global fossil fuel demand at risk. January 25, 2024 By Daan Walter, Sam Butler-Sloss, Kingsmill Bond Battery demand is growing exponentially, driven by a domino effect of adoption that cascades from country to country and from sector to sector. This battery domino effect is set to enable the rapid phaseout of half of global fossil fuel demand and be instrumental in abating transport and power emissions. This is the conclusion of RMI’s recently published report X-Change: Batteries. In this article, we highlight six of the key messages from the report. 1. Battery sales are growing exponentially up S-curves Battery sales are growing exponentially up classic S-curves that characterize the growth of disruptive new technologies. For thirty years, sales have been doubling every two to three years, enjoying a 33 percent average growth rate. In the past decade, as electric cars have taken off, it has been closer to 40 percent. Exhibit 1: Global battery sales by sector, GWh/y Source: Ziegler and Trancik (2021), Placke et al. (2017) for 1991-2014; BNEF Long-Term Electric Vehicle Outlook (2023) for 2015-2022 and the latest outlook for 2023 (*) from the BNEF Lithium-Ion Battery Price Survey (2023). 2. Battery costs keep falling while quality rises As volumes increased, battery costs plummeted and energy density — a key metric of a battery’s quality — rose steadily. Over the past 30 years, battery costs have fallen by a dramatic 99 percent; meanwhile, the density of top-tier cells has risen fivefold. As is the case for many modular technologies, the more batteries we deploy, the cheaper they get, which in turn fuels more deployment. For every doubling of deployment, battery costs have fallen by 19 percent. Couple these cost declines with density gains of 7 percent for every deployment doubling and batteries are the fastest-improving clean energy technology. Exhibit 2: Battery cost and energy density since 1990 Source: Ziegler and Trancik (2021) before 2018 (end of data), BNEF Long-Term Electric Vehicle Outlook (2023) since 2018, BNEF Lithium-Ion Battery Price Survey (2023) for 2015-2023, RMI analysis. 3. Creating a battery domino effect As battery costs fall and energy density improves, one application after another opens up. We call this the battery domino effect: the act of one market going battery-electric brings the scale and technological improvements to tip the next. Battery technology first tipped in consumer electronics, then two- and three-wheelers and cars. Now trucks and battery storage are set to follow. By 2030, batteries will likely be taking market share in shipping and aviation too. Exhibit 3: The battery domino effect by sector Source: BNEF, RMI analysis; Electronics share of addressable market percentage indicative, transport percentage based on 2022 EV sales share, stationary storage defined as sales volume today divided by peak sales in long term (2050). Trains, ships, and airplane total addressable market sizes illustrative. 4. Incumbent modelers remain behind the curve How fast will batteries continue to grow and improve? The answer is a lot faster than today’s consensus view. When it comes to the growth of small modular technologies, there are two rules of thumb: the first is that superior technologies undergoing rapid cost decline tend to grow exponentially; the second is that most analysts miss the first. Batteries have been no exception to this rule, having been consistently underestimated by modelers. Over the past years, many battery forecasts have effectively projected linear growth. As Exhibit 4 illustrates, actual sales keep outrunning such forecasts and as a result analysts keep revising their projections upward. The caution of such linear thinking may, on the surface, seem reasonable, but in reality, it is simply wrong. Exhibit 4: Automotive lithium-ion battery demand, IEA forecast vs. actuals, GWh/y Source: IEA Global EV Outlook (2018-2023) current policy scenarios and actuals; BNEF Long-Term Electric Vehicle Outlook (2023) for 2023 estimate. 5. The drivers of change will strengthen If we look forward to the next seven years, we see the drivers of change strengthening. Notably, we see costs continuing to fall, policy support continuing to rise, and competition between economic blocs continuing to drive a race to the top. And while there are barriers to battery adoption on the horizon, humanity’s wit, will, and capital are scaling proportionally faster. Thus, we do not see a scenario of slow adoption as credible; instead, we model two futures: fast or faster. Reality is likely to lie somewhere between the two. RMI forecasts that in 2030, top-tier density will be between 600 and 800 Wh/kg, costs will fall to $32–$54 per kWh, and battery sales will rise to between 5.5–8 TWh per year. To get a sense of this speed of change, the lower-bound (or the “fast” scenario) is running in line with BNEF’s Net Zero scenario. The faster S-curve scenario exceeds it. Exhibit 5: A reinforcing feedback loop between battery quality, cost and market size Source: Ziegler and Trancik (2021) before 2018 (end of data), BNEF Long-Term Electric Vehicle Outlook (2023) since 2018, BNEF Lithium-Ion Battery Price Survey (2023) for 2015-2023, RMI analysis. 6. Enabling the phase-out of fossil fuels The best strategy to rapidly phase out fossil fuels is to accelerate the deployment of technologies that reduce fossil fuel demand. Batteries are on the path to displace 86 exajoules (EJ) of fossil fuels from road transport (emitting 6 GtCO2 per year) and to put at risk another 23 EJ (or 1.6 GtCO2/y) from shipping and aviation. In the electricity sector, as batteries synchronize the natural rhythms of the sun and the wind with the timing of electricity demand, they help enable the reduction of a further 175 EJ of fossil fuel demand (or almost 15 GtCO2/y). Exhibit 6: CO2 emissions abatement enabled by batteries, GtCO2/y abatement versus emissions today Source: IEA NZE scenario (other transport); RMI analysis (power and road transport) Batteries are growing fast, but that’s no reason to rest on our laurels. Continued growth will require continued effort. Batteries got this far through tireless, concerted efforts of companies, governments, researchers, and climate advocates. And whether the motivation is lower prices, geopolitical advantage, or climate, it is essential to make this fast transition faster. Download the full report here. Recent Posts The Rise of Batteries in Six Charts and Not Too Many Numbers From Global to Local: Climate TRACE Helps Prioritize Emissions Reductions from the Oil and Gas Industry As Petrol Prices Climb, Nigerian Agriculture Extension Officers Cut Fuel Costs with Electric Motorbikes Catherine Coleman Flowers: A Disruptor in the Best Sense Categories Africa Amory Lovins Building Electrification Buildings Carbon Markets China Cities Climate Data Commercial Buildings e-Lab: Electricity Innovation Lab Electricity Energy Efficiency Finance General General Energy Global South Hydrogen India Industry Islands Oil and Gas Solutions Residential Buildings RMI Strategic Insights Supply Chain Emissions Transportation Trucking US Policy",
    "commentLink": "https://news.ycombinator.com/item?id=39144978",
    "commentBody": "The rise of batteries in six charts (rmi.org)255 points by simonebrunozzi 16 hours agohidepastfavorite246 comments aresant 16 hours agoThis is all very encouraging and in particular batteries role in solar Two interesting data points to that end 1) The \"duck curve\" for CA is almost neutral - eg the timing imbalance between peak demand and solar power generation - battery utilization is the most straightforward solution here - https://twitter.com/baker_edmund/status/1750644294673748366 2) There has been a massive decline in rooftop solar applications in CA since solar energy reimbursements dropped - https://twitter.com/thomasopeters/status/1750920941868347539 - some of that is potentially pent up demand, but I think illustrates the role state policy has to play in moving towards \"renewables\" reply radium3d 14 hours agoparentIt's super cool you can watch California's grid level batteries \"breathe\" every day here, https://www.caiso.com/TodaysOutlook/Pages/supply.html#sectio... Yesterday we peaked out at 3GW discharging rate, and 4GW charging rate. We are plowing ahead in the transition to utilizing all of our excess solar! We peak at 25GW expected today, so we have a little ways to go but it's incredible how far and how fast they're replacing everything. Clean air FTW! Thanks sun! reply usefulcat 12 hours agorootparentKind of unrelated, but I'm wondering why TX uses so much more electricity than CA. Right now (afternoon of 1/26) happens to be a good time to compare: -- Temperatures are mild throughout most of TX (50s and 60s F); temps in CA are similar, perhaps a bit warmer; -- It's roughly mid-day in both places (3PM TX, 1PM CA); -- TX has a population of ~30M, CA has ~39M ..yet somehow right now TX is consuming ~47GW (per ercot) while CA is only consuming ~23.5GW (per caiso). What gives? ERCOT: https://www.ercot.com/gridmktinfo/dashboards reply MichaelNolan 12 hours agorootparentThere are a few reasons. 1. TX has more heavy industry than CA. 2. CA has spent decades and billions on energy efficiency improvements. 3. CA prices are higher, which encourages lower demand, and encourages investments in efficiency. TX has lower prices which encourages more demand. reply dgacmu 12 hours agorootparentprevIt's a mix of a bunch of things. CA is more heating day dominated than TX, and as a result of that, more households use natural gas for heating, whereas you're more likely to see supplemental electric heat in TX than, particularly, NorCal. (2) high energy costs lead to more investment in electrical efficiency in CA; (3) high energy costs mean that if you're running an aluminum smelter (for example), you don't run it in CA. Or building a new mega data center. so there are fewer electricity-intensive industrial facilities in CA than there would otherwise be. reply HDThoreaun 4 hours agorootparentprevDoes home solar usage count on this graph? The electricity never hits the grid so I think it might not. If not California's massive push for home solar could be part of the explanation. reply ZeroGravitas 12 hours agorootparentprevCalifornia takes a much more european approach to energy efficiency. reply ketzo 14 hours agorootparentprevthe CAISO website is super rad in general -- so many real-time charts!! demand trend is really cool to watch during heat waves; things get spiky on both the demand side (for obvious reason) and the supply side (peaker plants & \"virtual\" power plants coming online) reply Gibbon1 12 hours agorootparentprevThe amazing thing is there basically were no batteries three four years ago. And they can supply about 10% of the max power demand already. So it feels like the technologies we need are now good to go on an engineering an accounting basis. And adoption can be quite rapid. We're not saying in 50 years, 25 years, 10 years. We're looking at 5 years. reply XorNot 9 hours agorootparent\"power\". This doesn't mean anything. LiFePO4 scales power to energy storage at a rate of about 1:3-1:4. 1GW of \"power\" they can supply for 4 hours if you completely discharge the battery. But that's it. Batteries could supply 100% of the grid briefly, and you still wouldn't be anywhere near having completed a switchover. reply radium3d 6 hours agorootparentYou can see by the graph that the batteries don't piddle out that quickly already. reply Gibbon1 3 hours agorootparentI've looked and not seen numbers on the actual battery capacity. But I think it's about 3-4 hours at name plate power levels. I think from what I know capacity is a function of discharge rate. And wear is also a function of discharge rate and max/min charge levels. Makes the operating economics non trivial. reply LUmBULtERA 14 hours agoparentprevGiven the dramatically lower costs of utility-scale solar vs. residential rooftop solar, is it not better at a society level for state policy to incentivize utility over residential solar? Utility-scale battery installations likewise should be much cheaper. reply epistasis 14 hours agorootparentThis argument ignores the cost of transmission and distribution, which are higher costs than the generation itself. And as electricity prices are driven down even further, T&D will come to dominate over energy generation costs. Few models account for this, but Christopher Clack made one, and the lowest cost energy path was a small amount of investment in distribution now, paired with massive deployment of solar on homes and industrial/commercial. This won't happen unless utilities are forced into it or their allowed profit model is changed to deliver ratepayers the lowest cost energy, however. reply LUmBULtERA 12 hours agorootparentUnless every home is completely off the grid, you’re going to need to pay for most or the majority of that transmission and distribution anyway. Peak winter and summer I also would imagine many or most residential deployments aren’t going to cover their own need, unless they’re incredibly over built with massive batteries. In any case, I should check out your Christopher Clack reference. reply epistasis 12 hours agorootparentThe modeling is a few years old now, but here's a podcast episode diving into details: https://xenetwork.org/ets/episodes/episode-146-why-local-sol... (And of course, perhaps one modeler can get it wrong. But over here in California where the majority of our sky high electricity cost is from T&D, it definitet feels very true. And last national stats I saw had T&D as higher than generation costs) reply _aavaa_ 12 hours agorootparentprevAs long as the houses are still connected to the grid you will indeed by paying for distribution costs. But I think that you should expect to see transmission savings since you'll have more of the demand met locally. reply XorNot 9 hours agorootparentWhy? If there's any possibility those homes will draw 100% of their power from the grid on any given day, then the cost of infrastructure will be pretty much the same since a grid failure is a disaster. And there is a 100% chance they will, like my home is today, because 11kW of solar is making about 800W due to cloud cover which has persisted most days of summer. reply nerdbert 12 hours agorootparentprevYou don't need as much grid capacity if houses have their own generation and storage. reply kalleboo 3 hours agorootparentThe grid still needs to be built for the worst case - houses aren't going to have days of storage for a week of cold weather with dark clouds reply fragmede 3 hours agorootparentWorst case is months. In the depths of winter you need energy captured from the sun during summer. That's a drastic rethinking of the scale of storage. reply kalleboo 3 hours agorootparentAbsolutely. For the sake of the topic of discussion I was trying to think of Californian conditions but for places like Sweden you'll need completely different solutions (Sweden has been powered 100% on Hydro+Nuclear for decades now so that's one way) reply harryseldon 11 hours agorootparentprevMy PG&E bill would make you think so. But that is a PG&E problem (well problem for the consumer and great for their bottom line). Generation is the majority of the cost across the US: https://www.eia.gov/energyexplained/electricity/prices-and-f... reply fbdab103 7 hours agorootparentprevWouldn't that mean further subsidizing rich homeowners? The people best positioned to take advantage of incentives own their own home and have the disposable cash to make the initial outlay for residential generation. reply ketzo 7 hours agorootparentYep, it definitely would. It doesn't mean we shouldn't still do it -- especially because richer folks tend to use more electricity and pollute more in general. reply conradev 13 hours agorootparentprevGenerally, yes, but a few items: - Distribution systems today can only handle some percentage of EV penetration in a given area, not 100%. Charging an EV from the roof skips the grid entirely - The bulk of the cost is labor and permitting, not the modules themselves. Given that, California requires solar on newly constructed homes - California updated their net metering program so that ratepayers aren’t subsidizing rooftop solar anymore (in NEM 3.0, homeowners get paid wholesale rates) reply inglor_cz 11 hours agorootparent\"Charging an EV from the roof skips the grid entirely\" As long as you have enough sunshine hours in your region. Southern Spain is fine year-round, but you won't get any meaningful output out of a solar panel in Finnish winter. The rest of Europe lies between those two extremes. Northern winter will be made more challenging by addition of EVs to the grid, because a lot of electricity is being used for heating as well. reply ghaff 14 hours agorootparentprevResidential solar may still make sense for new construction (maybe?) in the right areas. But there was a lot of scammy behavior around home solar installation at one point. Given that home solar does not effectively give you a backup generator for free (barring a lot of batteries and specific electrical hookups as I recall), it's not clear it's a big win in general. A lot of utility things aren't ideal at the individual house level if there's an option. reply mbgerring 11 hours agorootparentA lot of home solar installers now include grid tied batteries as part of a standard installation, which is what NEM 3 was intended to do (secondarily, after its primary goal of giving CA IOUs a massive free lunch). reply photochemsyn 12 hours agorootparentprevAs far as rooftop solar, it makes a big difference if solar PV is built into the design process at the beginning, rather than tacked on as an afterthought. Similarly, a household battery might be as common in the future as a household hot water heater (with a similar footprint, size-wise). There's also regional variability - cities absolutely require utility-scale solar, just as they require dedicated agricultural land to feed the population, because there's not enough surface area in a city. Rural/suburban areas on the other hand are ideal for integrated rooftop solar. reply 0xbadcafebee 15 hours agoparentprevState policy is fundamental to the entire green revolution. None of it would have been possible without nations incentivizing it. Eventually once the entire energy generation/consumption cycle is entrenched and we are all dependent on it, they can safely take away the incentives. It's a bit like changing the tires on a moving bus. Somebody had to pay for the new tires and wheels, and the support truck to run along side the bus, and the extra fuel, and a discount for the new tires, etc. Once the new tires are on the bus can keep driving without support. reply meandthewallaby 14 hours agoparentprevThat duck curve tweet is disingenuous. That curve in the tweet is for the lowest net load day (net load is actual load or usage minus generation from renewables). In 2023, if you took the day that had the least amount of net load, yes, it was almost entirely covered by solar power. That does _not_ mean the claim made in the tweet that California is run totally by solar power from 10am-4pm every day (today at 11:56 AM PST, it's about 51% run by solar power). California's grid has enough good things going for it that we don't need to lie about it. You can look this up for yourself: https://www.gridstatus.io/live/caiso reply bsder 14 hours agoparentprev> There has been a massive decline in rooftop solar applications in CA since solar energy reimbursements dropped People also learned that the cheap Chinese solar cells die in 5-10 years and aren't worth installing unless your electricity costs are really high. reply jbm 13 hours agorootparentIs this something documented? I haven't heard of this and I've been following the space for a while. reply bsder 7 hours agorootparentMostly installers--probably about 7-10 years ago back when the American manufacturers got pushed out of the market by the Chinese ones. A lot of the installers got out of the business knowing they were on the hook when the warrantees came calling. Although, American manufacturers have been restarting since Biden adjusted some of the tariffs in 2023. We'll see if they go back to producing a decent product or if they just try to shovel garbage like China. reply Tade0 14 hours agoprevRegarding price, leading manufacturers are already selling at a price below what was always understood as the point where EVs win in terms of economics: https://www.nextbigfuture.com/2024/01/ev-lfp-battery-price-w... The recent price war in China is a testament to that. reply Terr_ 13 hours agoparent> the point where EVs win in terms of economics If ubiquitous and cheap charging infrastructure is not being priced in, which is still a blocker for many. For example, I cannot reasonably run lengths of 110v extension cords down the block to charge a car overnight, and acquiring my own house with a garage is dramatically more expensive than any fuel savings. :p reply audunw 11 hours agorootparentTrue. Good point. But that will change surprisingly rapidly. We've experienced it in Norway already. It's been a huge change over the last 5 years. I don't have a garage attached to my house, it's a shared garage building. But once a few owners got EVs, and it became clear to others that EVs were the future, we got some minimal renovations done that allowed anyone to pay to have a slow AC charger installed. Oslo has been rolling out street-side AC charging poles. There's never quite enough but the growth is steady. Other countries may not have the same incentives, but that just shifts the point where the rapid transition starts by a few years I think, since cars get cheaper and better all the time. And remember that Norway is fairly cold, which is brutal on range in the winter, so it's not really a fully ideal place for EVs (though at least the car starts reliably every time unlike diesel) reply Vicinity9635 8 hours agorootparentprevThe only reason I lack a Tesla is I would have to pay $150 a month for a parking spot in my apartment's garage to charge it. That's public parking downtown pricing where I live, which is absurd. Ubiquity of chargers would fix my issue too. Also I rarely use my car which should probably be a bigger factor than it is, lol reply axiolite 10 hours agorootparentprev> I cannot reasonably run lengths of 110v extension cords down the block to charge a car overnight, and acquiring my own house with a garage is dramatically more expensive You don't need a garage, just some sort of reserved parking space... There are plenty of weatherproof electrical boxes. It costs a bit of money to have a trench from your home to your car parking area, but far less than buying a house. And that \"110v extension cord\" can supply 240V with just a change of connectors on either end (e.g.: 6-30p) allowing charging twice as fast. reply nsguy 9 hours agorootparentIn most places you can't just put a trench and an electrical box through public spaces. I'd also worry about someone stealing electricity from me. Double the voltage is hopefully ok on the extension cord- just don't be tempted to run higher current. Extension cords are also not recommended for permanent usage. reply neltnerb 9 hours agorootparentprev> You don't need a garage, just some sort of reserved parking space I don't think the OP was worried about people who have the ability to dig a trench and install underground wiring to a reserved spot in a \"car parking area\". I suppose it's not technically having a garage but it sure feels like it in spirit. reply mauvehaus 9 hours agorootparentprevA 6-30 NEMA connector still only supplies 30 amps. 30A x 240V = 7200W. Which is under 10hp. You're still looking at an awfully slow charge. reply dagss 36 minutes agorootparentMy bet is probably 90% (99%?) of home charging is done at 7.2kW or less. 7.2 kW is in the higher end, not \"awfully slow\". Myself I often charge at 3.6 kW. reply wnissen 8 hours agorootparentprevFor a road trip it's slow, for overnight it's plenty fast. A big battery is 100 kWh. Assuming one only uses the middle, from 20 to 80%, that's 60 kWh, which would charge in 8 hours and 20 minutes at that rate. The vast majority of folks spend at least that long in one location every day. How often do you tend to arrive home at 10 p.m. and leave before 6:30 a.m.? reply cyberax 8 hours agorootparentprev7.2kW is about 30 mph charging speed on regular cars. So you'll gain around 300 miles of range over 10 hours. That's basically a full charge. reply stcredzero 13 hours agorootparentprevI cannot reasonably run lengths of 110v extension cords down the block to charge a car overnight I used to run extension cords out of windows and across the sidewalk to charge a Fiat 500e. reply breischl 12 hours agorootparentWorks if you live in a first-floor, street-facing unit and can reliably park in front of it. Otherwise it can be tough. It's unfortunate that EVs make the most immediate sense in high-density urban settings, but those same settings have lots of people who can't use the simple kinds of charging infrastructure (eg, Level 1/2 chargers). reply vel0city 12 hours agorootparentIMO EVs work best in medium density urban settings, where people still probably have their own garages or at least private parking spots but aren't likely to need to do 100+mi drives constantly. Truly high-density urban settings should ideally find transportation solutions without cars. reply lancewiggs 11 hours agorootparentAnd stop using streets for car storage, opening them up to people and plants. reply kibwen 10 hours agorootparentDon't you dare get my hopes up for streets lined with trees instead of cars. reply stcredzero 10 hours agorootparentprevBandaid-ing plants and naively making public spaces often doesn't work in the US. It's a little more work to make spaces where people actually want to be. Look at the numerous existing city public spaces built into high profile architecture, where basically no one ever hangs out in. (There's a TED talk about this.) reply doubleg72 6 hours agorootparentWhy would their worth be determined on how many people hang out there? I prefer to see green spaces and am okay appreciating them from a distance, such a in a nearby town with a tree lined main street through town. I don't think it would invoke the same aestetic pleasure with people and litter occupying these spaces. reply matthewdgreen 12 hours agorootparentprevCities are going to have to invest in lamppost and curb charging. These already exist. The good news is that with a modest surcharge to the base electricity cost, they will produce a stream of revenue that can be financialized to pay for the install cost (which is basically AC wiring.) The billing needs to be standardized (this is already mostly done with NACS/CCS.) It’s low hanging fruit and will happen within the next few years. reply soperj 9 hours agorootparentprevBikes and transit make the most sense in high density urban settings. Evs make more sense in a suburban world. reply stcredzero 11 hours agorootparentprevWorks if you live in a first-floor, street-facing unit I was not exactly in that situation. First time, I lived in a room on the 3rd floor of a house, but I'd run the extension cord out of the house owner's workshop basement window. I could reliably park in front of the house, however. 2nd time, I ran the cord out of a 2nd story window from my room, but the parking space was behind the house's fence under my window. 3rd situation, I would run the cord from the apartment exercise room, out the window to the fenced in parking lot behind the building. However, the building management actually removed those outlets! Then, that law requiring them to let us charge passed, but by then, it was time for us to move out. Now, I have a garage of my own! reply standardUser 9 hours agorootparentprevThe Biden admin targeted $7.5 billion for exactly this, but apparently the ramp up has been slow so far. They announced $620 million to specific projects just a week or so ago, so it may be accelerating. reply robocat 13 hours agoparentprevFrom linked link[1]: CATL is marketing 173-Ah VDA spec (Rectangular cells: 148mm length, 26.5mm width, 91 mm height - German specification). I presume manufacturers make packs using whatever cell sizes they can source? I had thought the trend was away from cylindrical (eg 4680) and towards prismatic or pouch cells? Whatever happened to the 1 metre long BYD cell: https://pushevs.com/2020/05/26/byd-blade-prismatic-battery-c... [1] https://cnevpost.com/2024/01/17/battery-price-war-catl-byd-c... reply zardo 14 hours agoparentprev> Tesla will be saving $800 in LFP battery costs within 6 months and another $800 within about 18 months. Do they have a model using LiFePOs now? reply ggreer 14 hours agorootparentSince Q2 of 2022, the majority of Teslas produced have been LFP. As of right now, the standard range and long range Model 3 and Model Y are LFP. The Model S, X, and the Performance versions of the 3/Y are NCA. reply strangemonad 14 hours agorootparentprevMany of the china model 3s and Ys use prismatic cells from CATL use lifepo chemistries reply jostmey 14 hours agorootparentprevI got a model 3 RWD last quarter and it has a LFP battery. I think it's the only Tesla with LFP batteries reply pi-rat 14 hours agorootparentModel Y RWD sold in europe is LFP reply coryrc 14 hours agorootparentprevOnly one in the US. There's more in China IIUC. reply AtlasBarfed 7 hours agorootparentprevAnd 200 wh/kg LFP and 160 wh/kg sodium ion is coming into mass production. To the main parent, the runway for further EV drivetrain cost reductions is at least a decade more. The LFP and sodium ion production roadmaps have almost 200 wh/kg sodium ion and 230 wh/kg LFP on it, so that is reasonably a five year likelihood. 10-20 year is solid state, sulfur techs, and other chemistries poised to double or triple density of the cells. The first curve shows the really low commercial vehicle demand on batteries. This will not be the case, commercial vehicles from busses to worksite vehicles to town delivery vans are going to goddamn explode in demand, once all the business owners realize the TCO of EV drivetrains is so low. I've been pretty disappointed in electric companies, perhaps they are pricing in grid adaptation, but wind and solar should be relentlessly driving down the cost of electricity and something is up with that. The dual headed dragon of economies of scale/density in batteries combined with the price drop in electricity for wind/solar is something that ICEs simply cannot win against. Which is why I chuckle at every mainstream media article about EV sales fluctuations or anti-EV stories, or the inevitable \"I can't charge because Apartment/Parking Garage/City\". People, this is an economic tsunami coming, and it has already started. All those infrastructure problems will be solved. The \"I rent\" is the most mystifying thing, indicative of local governments not getting ahead of this. What should be cheaper to wire up, a suburban development sprawled over 10 square miles, or 100 cars in a one block radius? Governments need to be incentivizing apartment charging pronto. reply tonymet 13 hours agoparentprevwhy aren't consumers seeing this price yet? reply cogman10 12 hours agorootparentDemand far outstrips manufacturing capacity at the moment. For batteries not put in EVs a slightly lower price will get them installed in grid storage solutions. Consumers will be the last to see lower prices while demand outpaces supply. reply bmicraft 5 hours agorootparentI really don't get how battery manufacturers have have the better part of a decade of with batteries sold pretty much before they've been manufactured and still haven't scaled up to capture that demand reply AtlasBarfed 7 hours agorootparentprevYEah it's been frustrating. Those two stroke horror shows in leafblowing/lawnmowing/etc need to be cycled out, but e-tools are still priced as luxury. I'm hoping in about 5 years, especially with sodium ion in production, that changes. The really cool thing about battery production is that it's not like an ICE engine where you have to design an ICE for this size application and an ICE for that size application: the batteries can be used in a leaf blower, a moped, a car, a truck, or a massive grid. The battery supply can be routed wherever needed. That should result in a vastly cheaper overall industry than the ICE drivetrain industry. Sure you need different electric motors, but those aren't THAT different, and the industrial world has already been building all the necessary sizes and variations for a century now. reply thinkcontext 9 hours agorootparentprevWhat do you mean? In the past year there have been substantial price cuts in many markets, particularly in the US. The price gap between the average EV and average ICE has also closed could considerably. reply adgjlsfhk1 6 hours agorootparentprevhttps://electrek.co/2023/10/05/tesla-prices-keep-dropping-mo... they are. reply goodSteveramos 5 hours agorootparentThis is Tesla's margins collapsing because of less than forcasted demand for luxury vehicles. Battery prices have dropped much more slowly than the prices of EVs. reply adgjlsfhk1 3 hours agorootparentThey're the only ones who have been mass producing EVs for more than a few years. Sure it's their margins decreasing, but that's because the decreased cost of batteries mean that other car makers were finally offering competitive offerings, in part due to the accumulated decrease in battery price since the original models were released. reply bmicraft 5 hours agorootparentprevTesla is both a luxury car brand and the single most unreliable brand. The masses need an actually cheap and reliable ev, not whatever this is. reply antisthenes 12 hours agorootparentprevWhy would they? Companies will gladly pocket the difference between what they charge the customers and their $100/KWh bulk price. reply tonymet 11 hours agorootparentOk what's not working properly then? reply Mistletoe 8 hours agorootparentProbably unregulated capitalism. reply sixstringtheory 15 hours agoprevThis is a great set of charts and analysis, although I have two problems with it. 1. On the chart of energy density, I'd like to see the the energy density of petrol for comparison. It's much higher, and even though extrapolation is dangerous, I'd like to see how long it could take to reach parity given some of the different forecasting models they mention. Specifically regarding their mention of air travel, I'd like to know what the minimum viable energy density would be for a vessel's fuel source, because my current understanding is that commercial air travel powered by electricity is not feasible. 2. They mention S-curve adoption, but that reaches a horizontal asymptote eventually, it doesn't go up forever. I'd like to see more analysis on where we think we're at on the S-curve, and why. I'd like to see a guess on where it levels out displayed on that chart, instead of the arrow simply pointing at the sky. If nothing else, show where the chemical limit might be based on current battery technology. I want to displace fossil fuels and reduce pollution and slow the greenhouse effect as much as possible. I think transparency and realistic expectations need to be part of the transition. The more information available to markets, the more efficiently they can work towards the goal. I find it very difficult to get answers to these types of questions when discussing renewable energy generation and storage. I'm sure part of it is my own ignorance on where to look, which is why I ask: especially here, hopefully an expert can see this and quickly point me in the right direction. reply thelastgallon 15 hours agoparent> I'd like to see the the energy density of petrol for comparison. Petrol's higher energy density doesn't matter as much as people think. Electric vehicles are around four times as efficient as petrol. In a petrol car, only 20% of the energy is converted to motion. In electric cars, this is around 80% (with some variation dependent on regenerative braking). I wrote about this extensively in a previous article: https://www.sustainabilitybynumbers.com/p/electrification-en... reply Veserv 15 hours agorootparentThat is not even comparing apples to oranges, that is comparing apples to steel. You are correct in that energy density does not matter very much for weight-insensitive generation such as grid-scale generation, but energy density matters for weight-constrained applications such as airplanes and rockets as the poster mentioned. However, assuming that the renewable generation cost curve continues to improve exponentially then the most likely outcome for a carbon-neutral or carbon-negative future will be using electricity to manufacture high density combustible fuels out of atmospheric carbon, effectively using it as a high density \"battery\" for use cases that demand high energy density. To the extent that your analysis is relevant to the concerns of the poster, all it means is that batterys are actually ~4x better than the raw energy density would indicate. As to the specifics, Wikipedia claims petrol is ~12,888 W*h/kg or ~24x the battery energy density in the article, so ~6x better with respect to car motion. Note that the current curve has only gone from ~100 W*h/kg to ~500 W*h/kg, so we would need to see density growth comparable to the last 30 years to happen again. reply aswanson 13 hours agorootparentWhat are the theoretical limits of electrical energy density? reply alted 10 hours agorootparentExcellent question! A sufficiently advanced battery can theoretically beat gasoline. Any given energy storage technology can store a maximum amount of energy in a fixed volume or mass. Behold one of my favorite plots: [1] From lowest to highest energy density: - springs, which use mechanical elastic potential energy, are kinda horrible - capacitors, which use electric permittivity, aren't great - next are both batteries and combusted fuels, which both use chemical reactions. - nuclear gets us another few orders of magnitude - finally, antimatter (E=mc^2) is a ways beyond that Both batteries and fuels rely on the energy difference between unreacted molecules, so their theoretical energy density is the same. Well, actually, fuels are burnt to create heat which is converted to energy, and this heat->energy conversion is fundamentally thermodynamically inefficient (only ~tens of percent), whereas batteries are the same sorts of reaction but much more controlled. A sufficiently clever battery, which moves atoms around to react in the right places at the right time, is thus more efficient and thus energy-dense than fuel. However, moving atoms around like this to make a more efficient battery is much more advanced nanotech than what we currently have. But it's theoretically possible. This is what biology does: us humans are powered by chemical storage (sugar/fat/glucose), which is used more efficiently than current batteries but without combustion. (lithium-ion is ~0.8 MJ/kg, glucose is ~16 MJ/kg, gasoline ~46 MJ/kg) [1] https://en.wikipedia.org/wiki/Energy_density reply fbdab103 7 hours agorootparentThat is indeed a fun chart. One thing I wanted to add is that fat (lipids) are much more energy dense than glucose. ~38 Mj/kg, though I am not sure what fraction of that the body recovers. Which makes sense, you want to maintain your long-term storage in a denser format. reply xxs 7 hours agorootparentprevFuel(gasoline, carbohydrates, fats, etc. but not rocket one) does use oxygen from the atmosphere.Batteries are self contained (like rocket fuel). So the density of chemical reactions is by definition higher. Side note: energy density should apply to volume, not weight, but we'll - it is too common now. reply aswanson 6 hours agorootparentWhat makes one chemical more able to store a greater energy per unit mass than another? Wouldn't the theoretical limit be a volume of pure electrons compressed in the densest unit volume possible? Say, stored in a magnetic field? reply drtgh 10 hours agorootparentprev>Petrol's higher energy density doesn't matter as much as people think. When vehicles uphill, ramp, and fight with the increasing wind resistance due speed, it is needed a high torque for to motion. The petrol's energy density is translated in high torque, that the gearbox latter transforms progressively. In electric vehicles, generating high torque and cooling the overheated coils for to obtain such high torque drains the battery quickly, the range drops quickly. And for to increase the range, more weight is added (more batteries), that requires higher torque for motion, that requires more energy again, and so on. This is why the energy density it is important, in batteries are the watts hour per kilogram. As also it is important the number of cycles before such batteries start to drop energy density until to fail (to note the weight keeps being the same along all of this degradation). With the current technology, due the magnetic fields strength generated in the coils, and the energy density of the batteries, EVs just can not compete with petrol vehicles. It is about torque, among other things. What is needed? batteries with bigger energy density ( higher Wh/Kg with higher number of recharge cycles), and/or higher efficiency generating magnetic fields of high strength (ambient superconductivity, also stronger magnets would help some coil's topologies). reply XorNot 9 hours agorootparentThis is completely wrong: an ICE has 20-25% of the energy of petrol to use to do all those things. The rest is lost as heat. reply drtgh 6 hours agorootparentRegardless of theorical efficiency or not of the energy, in practice the ICE gets the torque needed by the vehicle for driving on all types of slopes (and speed, by transforming part of that high torque with the gearbox). This is why electric and combustion vehicles have such different ranges at even the same weight. Nowadays. Such high torque is needed at the same moment the vehicle doesn't circulate on a flat terrain, or when have to reach highway speeds. For to get at least the same ranges, the electric vehicle must reduce the energy consumption for the generation of the required torque (and speed), or needs to increase the energy density of the battery in companion of increasing the recharge cycles. will be possible to achieve this? of course. (The losses cooling or heating the battery and avoid the self-discharge should get the same advances, as it's counted as stored energy but it's not used for motion) reply BobaFloutist 15 hours agorootparentprevOk, how about \"effective energy density\"? reply nerdbert 12 hours agorootparentprev> In a petrol car, only 20% of the energy is converted to motion. In electric cars, this is around 80% How does it settle out when you take into account the significantly higher weight of EVs? reply vel0city 11 hours agorootparentBy \"significantly heavier\" it is often a difference of a few hundred pounds on a few thousand pound vehicle. A 2L engine is about 400lbs, an automatic transmission is another 220lbs, 20 gallons of gas is 120 lbs, add another 100ish pounds for a much larger cooling system. So sure, the battery is like 1,000lbs but you traded 840 pounds for 200 pounds of EV motors (assuming two of them!) so in reality you're up like 360lbs. Combined with regenerative braking, it doesn't make that big of difference in total energy usage. A massive chunk of the energy used in an EV is aero drag which makes little difference about weight. Weight makes a bigger impact with stop and go traffic on non-regen cars as slowing down that extra mass turns more energy into heat. An object in motion wants to stay in motion and all, once you're up to speed you're using about the same energy. This is why a lot of the EV trucks have close to the same range if the bed is full or not assuming it has the cover on the bed, but towing even a small trailer becomes a massive range hit. I get on average 3.5mi/kWh in my EV, ~1MJ/mi. A gallon of gas is like 120 MJ, an average hybrid will get like 40mpg, so 3 MJ/mi being burned. You'd need to get like 120mpg to match my average efficiency of energy usage, and my EV isn't even that incredibly efficient of an EV. reply slingnow 13 hours agorootparentprev\"Doesn't matter as much as people think\" Doesn't matter for WHAT? You start out talking about energy density, and then cite some numbers regarding efficiency. What does one have to do with the other? You've done nothing to support your opening claim here. reply goodSteveramos 6 hours agorootparentYea it doesn't really follow. I think the idea is that the energy density being 50 times lower doesn't matter because the battery is efficient enough that you can make an EV with a 300 mile range which is good enough for most people. Of course if anyone wanted one, you could build a gas car with a 5,000 mile range if it had a gas tank as massive as an EV battery. reply _aavaa_ 12 hours agorootparentprev\"Energy\" value of gasoline and \"energy\" value of a battery pack are measuring two very different things even though they are both units of energy. When you burn gas in an engine, the engine has a theoretical upper limit on its efficiency which is FAR below 100%, and electric vehicle does not. So saying that gasoline has an energy content of 115,000 BTU/gal doesn't mean much since you'll be lucky to see 30% of that be turned into useful work. reply goodSteveramos 6 hours agorootparentWell, acording to wikipedia gasoline has an energy density of 46.4 MJ/Kg and LiPo batteries have an energy density of 0.36–0.875 MJ/Kg. So if your electric drivetrain has a 100% efficiency and your gas drivetrain has a 30% efficiency then the gasoline car would be able to do 16 times more work per unit of fuel. reply treflop 15 hours agorootparentprevBatteries aren’t just used in cars man. Really hard to beat propane or diesel for heat in the wilderness right now. reply crote 15 hours agorootparentWe don't have billions of people living in the wilderness. And technology has reached a price level where off-grid solar is actually an affordable and superior alternative to propane and diesel for household use in rural Africa. reply amluto 15 hours agorootparentHeat pump heat, in the wilderness or otherwise, is about 4x as efficient as resistance or fire. This is somewhat silly, since a gas-fired heat pump can be very efficient, but gas-fired heat pumps are quite rare. (California has a pricing/policy problem here, IMO. Electricity is absurdly expensive, gas is somewhat reasonable, and the result is that electric heating is not nearly as economical as it should be.) reply semi-extrinsic 14 hours agorootparentGas-fired heat pumps are neither economical nor efficient for single-apartment or single-house systems. Internal combustion engines with shaft power output of 1-2 kW are inefficient, loud and maintenance intensive. They can start to make sense from around 50 kW heating/cooling capacity and upwards, so the smallest units are suitable for 8-15 apartments depending on size. reply treflop 14 hours agorootparentprevYeah but the article is just about batteries and someone asked to see a graph about energy density. Plus they asked about airplanes and somehow you made it about cars. reply earthling8118 12 hours agorootparentThe person you are responded to did not make it about cars. They were responding to someone talking about cars reply vvern 15 hours agorootparentprev“Heat in the wilderness” must be so small in terms of global emissions footprint to be almost irrelevant, no? The wilderness implies ultra low density sort of by definition. reply Spinnaker_ 15 hours agoparentprevThe mention of air travel was strange. I wasn't aware of anyone who thought long range flight would ever be electrified. At least not without some fundamental breakthrough. S-curves are hard to predict. Basically every time someone attempts to do it, they are way off. This [0] is a neat paper that addresses the question. We've blown past every single prediction. [0] https://www.inet.ox.ac.uk/files/energy_transition_paper-INET... reply audunw 11 hours agorootparentWhy do you mention long range flight? I don't see anything in the article saying batteries will take 100% of the airplane market. It does say batteries will start to take market share in 2030. That's almost certainly true. It's a high priority for the Norwegian company to electrify the short distance airplane network in the next coming years. There are already battery electric planes coming out. And battery chemistries suitable for short range planes are starting early production. I suspect battery electric plane will get a surprisingly good range once we start to get highly optimized battery chemistries and optimized airplane designs for that market. The hardest part is to get the first few products to mass market. They might creep into the medium range market by 2050. But long range? It might never happen. Unless we get something like aluminum-air batteries that can exploit oxygen in the air somehow. But it doesn't matter. Long range flights are not the majority of flights. It's a small enough market that e-fuels could cover it. Since flying battery electric will be so much cheaper it's also possible people will have to switch planes multiple times on a journey. Maybe there will be some innovations/optimizations that make that faster and easier. reply brigade 8 hours agorootparentLong haul might not be the majority of flights by number, but they account for ~40% of the emissions from commercial aviation (well more accurately, wide-bodies do.) Regional flights that are prime targets to go fully electric only account for around 6% of emissions. But you're right that starting somewhere is better than not doing that. reply NotSammyHagar 14 hours agorootparentprevThere are some very early stage tests, there is some kind of island hopper electric airplane that flys regular service, and it's only like 5 or 10 miles across water. Batteries will get more energy dense, the range will increase a bit. But yeah, it's hard to see it getting to a few 100 miles. reply pramsey 14 hours agorootparentTesting and development by an actual operational airline, but running into regulation and certification issues. Could be a while even for this relatively narrow use case of seaplane flights of under an hour duration. Interesting update. https://harbourair.com/earth-day-eplane-update/ In terms of battery density, the fact that they have an operational, flyable aircraft, just stuffing batteries and an electric motor into a 60 year old air frame... pretty good and only going to get better! reply KolmogorovComp 14 hours agorootparentprevHello, do you have a link or name? reply schiffern 14 hours agorootparentHere's the link, but the range isn't as bad as they said. https://www.prnewswire.com/news-releases/eviation-announces-... https://en.wikipedia.org/wiki/Eviation_Alice https://en.wikipedia.org/wiki/Cape_Air reply kccqzy 13 hours agorootparentprevThere's also an electric \"flying water taxi\" https://sfstandard.com/2024/01/18/san-francisco-navier-elect... reply PaulHoule 13 hours agorootparentprevI read a book in the 1980s about how you could fit S-curves to predict everything. When I've actually tried it with tools like https://docs.scipy.org/doc/scipy/reference/generated/scipy.o... it's frequently been terribly, terribly wrong. reply nielsbot 13 hours agorootparentprevCan we use excess solar energy to create synthetic fuel (hydrogen?) to power jets? I know almost nothing about this space. I would appreciate a comment on why this is feasible or not... reply NotSammyHagar 12 hours agorootparentThere are people researching it, I believe Airbus is about to test flying with hydrogen. It's the usual thing though for \"green hydrogen\", there's not much green hydrogen, there are some testbeds but just like for cars it seems to be mostly extracted from natural gas. You can extract it with any energy source like solar power. There's still the challenge that hydrogen fuel is not very compact, so it's hard to carry enough energy (in a car or plane) for much use, you end up with very very high pressure tanks. I think hydrogen will make sense eventually for trucks, tractors maybe. The question is will the massive investments in improving batteries make hydrogen vehicles obsolete or not. There are also research programs about making fuel from other sources, like https://www.sciencedirect.com/science/article/pii/S016523702... reply nielsbot 9 hours agorootparentAnswering my own question: Looks like there's something called solar fuel https://en.wikipedia.org/wiki/Solar_fuel reply Phenomenit 15 hours agoparentprev2. If batteries are growing exponentially right now then we are in the beginning of the S curve. reply simonebrunozzi 15 hours agoparentprev#1: certainly decades. Probably several, not few, decades. Unless a BIG breakthrough happens. reply malfist 15 hours agoparentprevComparing energy density between batteries and oil is not \"transparency and realistic expectations\" Once the oil is used it's gone. Batteries can be recharged reply Spivak 15 hours agorootparentThat's not really their point, it's do we have any reasonable hope of applications that require the energy density of fossil fuels (flight) to be powered by electricity. reply jeffbee 14 hours agorootparentFlight will never be powered by electricity, so you can stop checking. Using synthetic liquid fuels for flight is the only currently-foreseeable path to carbon-neutral, long-haul passenger flight. reply PaulHoule 13 hours agorootparentLong haul yes, but it's a little known story that regional airlines are on the edge of disaster because: (1) they can't find pilots, (2) manufacturers have stopped making the 50-seat jets that are the mainstay of that business. Airports like ITH are already at the top of the \"regional development problems\" in third-tier cities and it is not so clear they're going to be able to have service in 20 years the way things are going. Given that the status quo is \"go out of business when old planes can't be maintained anymore\" the possibility of some radical change like electrification or a change in the scope rules is increasingly likely. reply histriosum 13 hours agorootparent...which 50 seat jets are you talking about? At that size I would expect turboprops to be preferred, and turboprops of that size are definitely still being built.. reply PaulHoule 12 hours agorootparenthttps://en.wikipedia.org/wiki/Bombardier_CRJ700_series https://en.wikipedia.org/wiki/Embraer_ERJ_family both of which stopped manufacturing circa 2020. We used to get the DASH-8 which I liked to fly more but they stopped using it because it breaks down more often which is no problem if it happens at PHL but takes hours to get a crew to fix if it breaks down at ITH. reply jeffbee 13 hours agorootparentprevPerhaps I am missing your broader point, but the fact that ITH exists and only has scheduled service to New York is a bit ridiculous. That should be a high-speed rail route that takes you from city center to center, if America intends to become a developed nation. reply PaulHoule 12 hours agorootparentGod it's gotten worse. Last time I looked they had flights to PHL and DTW. As it is now there is fierce competition for bus service from Ithaca to NYC (budget to various grades of premium) and I find it almost unimaginable that I'd fly to NYC to get to NYC because flying to JFK or atrocious EWR (never once made a transfer at EWR that didn't involve re-entering the secure zone) wouldn't save time to get to Midtown. If you try to take the bus in the other direction you find you can't get from here to there. A friend of mine who used to ride the bus through Canada to get to the Detroit suburbs now takes the bus up to Syracuse, then takes Amtrak and gets out at 4am. On the way back one time there was no room on the bus although he paid for a ticket ahead of time. The real significance of the regional airport is that it connects to a hub that goes everywhere. As it is if I have to fly somewhere I'll probably have to go up to SYR where at least I can fly on Jetblue and know I'm flying on an Airbus. ITH used to get https://en.wikipedia.org/wiki/De_Havilland_Canada_Dash_8 which I really enjoyed flying in, but they got replaced with 50-seat regional jets because regional jets are less likely to break down at a small airport requiring a crew to travel two hours to repair them. As it is, academics at Cornell and Ithaca College will struggle to bring in speakers and it's just one more bit of \"stave the countryside\" that will drive knowledge workers to go to blue cities where their votes don't count -- it's how you hand the next election to a Demagogue. reply jeffbee 12 hours agorootparentYou're right I was not thinking of the probable more common use case that a trip originating at ITH is only connecting at JFK and eventually arriving elsewhere. For that traveler a train to Manhattan doesn't work as well. reply PaulHoule 12 hours agorootparentIf it was all integrated it could be great. I have always been puzzled about how few Americans will use public transit to the airport. When I go to a conference in San Francisco I run into European conference goers on the BART but if I am with American coworkers they always insist on taking the SuperShuttle. Similarly I’ve usually taken the subway to JFK even when it meant riding on an insipod shuttle bus reply stcredzero 13 hours agorootparentprevFlight will never be powered by electricity, so you can stop checking. Fuel cells could well enable 30X better power densities. That would count to me as flight powered by electricity. There's also beamed power. Perhaps this wouldn't be practical, but it's a thought experiment that shows there's nothing impossible from first principles for electrical powered flight. reply tonymet 14 hours agoparentprevLithium Battery 0.5 kWh/kg Diesel 12.7 kWh/kg reply mbgerring 11 hours agorootparentWho cares, we need to stop burning fossil fuels, relative energy density in the abstract does not matter in the context of climate change reply api 14 hours agorootparentprevDiesel is more like 3.175 (25%) due to the inefficiencies of small heat engines. You're throwing away like 3/4 of the energy as waste heat. Electric motors are >95% efficient and lithium batteries are in the high-90s percent efficient. Electricity is already low-entropy, whereas energy from burning petrol is high entropy and thus contains less useful work. reply wizardwes 13 hours agorootparentAlso, a kilo of diesel can emit that energy once. A kilo of battery can emit that energy hundreds or even thousands of times reply pkolaczk 12 hours agorootparentprevDiesel has efficiency of 40% not 25%. reply tonymet 13 hours agorootparentprevit's not waste half the year reply nerdbert 12 hours agorootparentIt's still waste, because if you're in a fixed location (which you'd have to be in order to benefit from much of the heat) you'd be better off running a heat pump. reply api 12 hours agorootparentprevTrue if you are cogenerating, but few people do that. Only a miniscule fraction of waste heat from a car engine is required to heat a car. Tangent but: I've always wondered why home cogeneration never took off. Too bad we don't have gas water heaters and gas furnaces that generate electricity and dump the excess onto the grid and heat with the waste heat. Even a low-efficiency thermoelectric generator would recover some useful energy that is otherwise kind of wasted. reply xbmcuser 13 hours agoprevThis is why I say electricity revolution is coming and a lot people and countries are going to be shell shocked by it. Solar and wind electricity costs are also decreasing at a similar rate. reply mbgerring 11 hours agoparentIt’s already here, it’s been here for a decade, renewables are a mature industry. They’ve already effectively destroyed the economics of coal, and natural gas is next. reply ketzo 7 hours agorootparentI was gonna say \"then why did China add so much coal last year\", because I remembered reading that they added something like 50GW of coal, even as they added more than 150GW renewable. But as of Jan 1 2024, they also had to introduce a financial incentive just to keep coal plants online, because otherwise the coal plants can't compete on price, just like you said! Some weird economics going on here, but it seems like China is still adding coal just to maximize total power deployed, even if it's uneconomic at the margins. https://www.reuters.com/world/china/china-guarantee-payments... reply inasio 14 hours agoprevAnecdotal local evidence to exhibit 3: There are a few go-kart places here, I hadn't been there for a few years, and now I learned that they all switched to electrical. Much quieter, no fumes, works great indoors reply liotier 13 hours agoparentFull torque at zero RPM makes motor racing much more exciting - especially compared to the low end karts with puny 2-stroke engines that took forever to accelerate my heavy ass ! reply deadeye 13 hours agoprevChart #2: Top Tier Energy Battery Density vs. Battery Cost. That seems like an odd comparison to me. Is it normal to compare the Top Tier Anything to the Average of another thing? Top Tier Car 0-60 Times vs Average Car Costs? IDK, it doesn't seem to contain any REAL information. Shouldn't the comparison be the costs of the SAME cars and not include cars that aren't top tier? What am I not getting? reply dylan604 13 hours agoparentChart 2 definitely seems strange as it appears that batteries are free in 2023 reply ceejayoz 13 hours agorootparentOnly because it's a wide line. Cost is $139/kWh, which on a scale of 0-9000, is pretty close to zero historically. https://about.bnef.com/blog/lithium-ion-battery-pack-prices-... reply bombcar 13 hours agorootparentprevThe elites don’t want you to know this but the batteries in the cars are free you can take them home I have 458 KwH. reply zamadatix 12 hours agorootparentprevIt would be better served by a log scale if they really want to show the pre-2005 numbers in the chart. reply stcredzero 13 hours agoparentprevTop Tier Car 0-60 Times vs Average Car Costs? IDK, it doesn't seem to contain any REAL information. Actually, if you know the details of the development of consumer cars, you'll find that advances and levels of performance in top tier cars tends to trickle down into average cars. Not without some dilution, but that's a definite trend! So things like disc brakes, fuel injection, microprocessor control. This sort of thing definitely happens with batteries over time. It's a way of peeking into the future. Just fudge factor for a little dilution. reply simonebrunozzi 16 hours agoprevWhat I find really interesting is the huge growth in stationary storage - I believe it's the fastest growing segment. reply beambot 16 hours agoparentStationary systems for grid scale storage have amazing options - e.g. Form Energy - that needn't rely on power density benefits of Lithium chemistries. I wouldn't be surprised to see this sector dominate the GWh/yr chart in the next 6 years. reply bryanlarsen 16 hours agorootparentIt's difficult to see any of the alternatives displacing batteries for short-term storage. Batteries aren't a good fit for long-term storage, which is where alternatives should be competitive. But that market is essentially 0 right now. reply smaudet 15 hours agorootparentBatteries (High capacity chemical) are terrible for long term storage, namely they are toxic: https://www.mountsinai.org/health-library/poison/dry-cell-ba... https://medlineplus.gov/ency/article/002805.htm https://batteryuniversity.com/article/bu-703-health-concerns... And cannot always be easily recycled: https://www.epa.gov/system/files/documents/2023-09/Lithium-I... In addition to general concerns about chemical availability, and processing issues. E.g. Demand expected to outstrip supply as soon as next year: https://www.spglobal.com/commodityinsights/en/market-insight... reply NotSammyHagar 15 hours agorootparentThere's also various schemes to use gravity. Pump water uphill above a dam when power demand is low like at night, also I have read speculation of trying to do this in some underground mine or something so it doesn't evaporate. reply cbmuser 11 hours agorootparentThat has even a worse energy density and thus requires a lot of space. We have nuclear energy, we don’t need to use technology from the medieval ages. reply lukan 15 hours agorootparentprev\"Batteries are terrible for long term storage, namely they are toxic\" Only some are toxic. But can you name the poison or danger with saltwater batteries? https://en.m.wikipedia.org/wiki/Sodium-ion_battery reply smaudet 15 hours agorootparentYes, there are excellent non-\"battery\" technologies. I'm explicitly talking about the high capacity chemical batteries everyone's crazy for these days. reply lukan 15 hours agorootparentSodium ion batteries are chemical and can have as much capacity as you like. They just need a bit more space, but not too much more, as they are already used in cheaper electric cars. \"Chinese automaker Yiwei debuted the first sodium-ion battery-powered car in 2023. It uses JAC Group’s UE module technology, which is similar to CATL's cell-to-pack design.[82] The car has a 23.2 kWh battery pack with a CLTC range of 230 kilometres (140 mi).\" And for grid storage, \"slightly bigger size\" really doesn't matter. reply cbmuser 11 hours agorootparentprevA nuclear reaction has a factor of one million more energy per Mol as compared to chemical reactions. Why would want to build an enery system on low-energy-density technology? That would be equivalent to using relays for building computers in 2024. reply NotSammyHagar 15 hours agorootparentprevThere are lots of companies trying to build out different kinds of flow batteries for storage. Think of a shipping container filled with some substance that stores charge and just sits there, waiting for you to use it, grid storage. But they all seem like research projects. https://news.mit.edu/2023/flow-batteries-grid-scale-energy-s... reply panick21_ 14 hours agorootparentThere have already been some flow battery startups going bust since that started. But there are many battery companies for gird batteries. Flow is just one type and one that seems far less poplar now-days. They were all the hype like 10-15 years ago. The problem is the Li-commodity race has already beaten most of those designs. You need to use very, very cheap materials. Form Energy considered some flow designs but rejected them. That's why Form Energy are going to things like Iron batteries, because Li batteries will never reach those numbers. But very few of those alternative have had any real commercial success yet. reply Phenomenit 15 hours agorootparentprevWhat is the use case of long term storage in batteries? As some kind of reserve? reply NotSammyHagar 15 hours agorootparentDepends on what long term means. But batteries are used for power grid storage. Tesla is selling huge numbers of tesla megapacks (https://en.wikipedia.org/wiki/Tesla_Megapack) often used to replace peaker plants. Peaker plants are power plants sitting there ready to turn on during peak power usage. I think they used to be often coal, which took a while to start up and produced lots of pollution, but then more recently natural gas plants start up faster and have much lower emissions. So during an evening power usage peak, or during really cold or hot times when power demand is high, the grid can tap that power source. Now you can replace those plants with a bunch of batteries that are ready in milliseconds to provide additional power, and then you can charge them if they get used up at night when electric usage is low. reply Phenomenit 13 hours agorootparentYeah, I think my question was a bit fuzzy, what is the definition of long term? Batteries are excellent for short term storage, days or weeks but they don’t have the same storage performance as fossil fuels of where talking months and years. reply mbgerring 11 hours agorootparentprev“Long term” in industry parlance means “greater than 8 hours” reply scythe 15 hours agorootparentprevDoes a battery with low cycle efficiency actually beat hydrogen for seasonal storage? The major problem with hydrogen is the fuel cell efficiency. Electrolysis is above 80%, but fuel cells are barely at 60% and it gets lower when you try to make the design more practical (lower temperature, less platinum). So batteries just have to hit 50% to compete. But that 50% includes both inherent cycle efficiency and self-discharge and Form Energy isn't putting their numbers up front, as far as I can see. More importantly, seasonal storage is heavily concerned with heating, and the conversion of hydrogen to heat is a different matter. The batteries have heat pumps going for them, but you can make a gas-powered heat pump too. So rather than the fuel cell efficiency you look at the CoP difference between electric and gas heat pumps. The latter have received little attention, but could see a surge of interest if green hydrogen becomes more popular (and easier to transport). But here we exhaust my understanding of the situation. reply panick21_ 14 hours agorootparentEfficiency is just one of many issues for hydrogen. Storage is another issue. How fast you can dispatch convert in either direction. I don't think seasonal storage will ever be thing. Having storage for a few days or weeks is practical. Non of the technologies we are talking about will work for seasonal. reply panick21_ 14 hours agorootparentprevForm Energy has made a huge amount of marketing before they had proven anything and claimed to have a product very fast. They have not build a single large better ever. Maybe not exactly the best example. Most of the non Li-Battery grid cell systems have not yet proven much. Many of the first generation of such system went bust. And many of the others have taken a long time and are still not deployed. So far the successful grid battery companies are mostly repackaging other cells. reply Anth-ny 14 hours agoparentprevDoes anyone here think Stem Inc. has any chance of becoming the Microsoft of stationary batteries? reply mbgerring 11 hours agorootparentStem is effectively a services company. There’s a lot of room for general-use hardware and software in this space, especially as more battery storage is deployed and financial incentives for energy arbitrage emerge. reply lukan 15 hours agoparentprevYes, it was by far the most encouraging thing I read in a while, thanks for posting! reply sandworm101 13 hours agoprevTake 25% of the money spend on EV batteries and instead spend it on domestic solar panels. I cannot stand the smugness of people who will pay $$,$$$ for a car but won't spend $,$$$ on the thing to make power for that car. Even batteries. The net carbon saved by in-home battery+solar is far more than putting batteries in the family car. The car runs a few hours a day. A total off-grid solar+batteries domestic system saves carbon 27/7. In other words, (Honda civic IC + home solar/batteries) saves more carbon than a Tesla with no actual power generation capacity. But that just isn't fashionable. reply cogman10 12 hours agoparentBatteries are a required part of the transition to pure renewables. When demand for EVs drops low enough you can bet grid operators will be in line to soak up the cheap batteries. Further, V2G/H is more than likely to be a thing in the near future further putting the EV batteries to work stabilizing the grid. reply breischl 12 hours agorootparent>V2G/H is more than likely to be a thing in the near future further putting the EV batteries to work stabilizing the grid. Yes. Even before we get to full V2G, managed charging provides a helpful degree of flexibility. An EV is a giant battery (several times the size of a Tesla PowerWall, for example) that happens to move sometimes. The battery can be used for other things when the car isn't moving - and it will be. reply matthewdgreen 12 hours agoparentprevI bought an EV because I assumed the dollars I had to spend would have more “leverage” by incentivizing an electric-car business, which would in turn drive improvements and reduced cost in battery production, and that would have follow-on benefits well beyond the car industry. I think the recent drop in battery prices is good evidence that this process is a real one. It goes without saying that any individual’s contribution is negligible. reply candiddevmike 13 hours agoparentprevFrom my interaction with local utilities/electrical companies, they _hate_ domestic solar. They'll do everything in their power to stonewall you getting them installed and make it seem like a useless/expensive option. reply sandworm101 12 hours agorootparentThen ditch the local connection and go with off-grid solar. These days, a totally off-grid solution is sometimes the cheaper option. Panels are cheap. Batteries are cheap. Interest rates are cheap. And no monthly minimums. I'm sitting in a house right now, streaming top gear on a 50-inch tv, completely off-grid. reply antisthenes 12 hours agorootparentHow are you getting internet? Starlink? reply sandworm101 8 hours agorootparentRural wifi system. Waterfront. Relay station on a island about a mile away. From there it bounces to a station on a cellbtower. reply 1970-01-01 12 hours agoparentprevDomestic solar isn't as efficient as solar power plants. If we took this 25% and instead built solar farms, we would be farther ahead. Domestic battery power plants do make sense however. reply sandworm101 12 hours agorootparentYes but a solar panel literally feet from the EV it is charging avoids massive transmission infrastructure. reply 1970-01-01 12 hours agorootparentThat doesn't make sense. Very few EV owners will recharge over the length of the day while sitting at home. reply sandworm101 12 hours agorootparentMost EVs, like any other personal cars, spend more time in a garage at home than they do anywhere else. reply 1970-01-01 12 hours agorootparentYes, at night without the sun. reply ceejayoz 11 hours agorootparentThat’s why we’re on a thread about batteries. reply SECProto 12 hours agoparentprevSingle digit thousands of solar panels might reduce emissions more in your case, but it certainly wouldn't in mine (grid here has very low gCO2/kWh) reply letuv 15 hours agoprevAre these 500 Wh/kg batteries somehow available in powerbank (sub-500g) size? So far the best I found are around 250 Wh/kg (for the whole powerbank). reply cperciva 13 hours agoparentYou'll have trouble finding powerbanks over 100 Whr, due to FAA regulations. reply jauntywundrkind 13 hours agorootparentI wonder when if ever we'll see this re-evaluated. It's still a terrifying amount of energy, but I'd feel much much different about someone with a 300WH LFP pack sitting next to me than I would a lipo pack. reply martythemaniak 13 hours agoparentprevIt'll probably be a while before you see them widely available, much less in small consumer devices. eVTOL and other battery aircraft can't really work without this level of density so I imagine they'll consume all available supply (at premium prices) for a while. reply DrNosferatu 8 hours agoprevWithout log axis, this is all very opaque... Also, battery-powered >=737-size passenger airplanes (also not so sure about trains and cargo ships) will need at least a revolution in battery technology - batteries won't do, they're just too heavy for the little energy they output: https://en.wikipedia.org/wiki/Energy_density#In_energy_stora... reply erikpukinskis 8 hours agoparentI doubt there’s any reason why trains couldn’t run on batteries. Anything that either stops and then starts again before refueling, or goes down and then up again before refueling, should be compatible with batteries due to regenerative braking. Trains have both of those properties. Planes have neither of those properties which is what makes them hard to run off batteries. Cargo ships also wouldn’t seem to have a problem. My understanding is that the drag on a hull increases sub-linearly relative to displacement. So a 10% increase in displacement might only increase drag by 1%. So it’s unlikely the weight penalty of batteries would be prohibitive. reply zizee 11 hours agoprevGiven these trends, what is the predicted year that we'd expect the last fossil fuel burning power plant to be greenlit for construction in China, India, and the US? Follow-up: At what point is continued operation of existing coal become uneconomical (to simplify the question assume decent solar generation locations are available/ grid connected nearby). reply cbmuser 11 hours agoparentFossil fuels are not going anywhere soon as a quick look at the world’s energy mix proves. > https://ourworldindata.org/grapher/global-primary-energy reply zizee 10 hours agorootparentThanks, but that does not answer my question. I guess I want to hear predictions of when fossil fuel usage will peak, and over what time period will it be reduced by 20, 30, 50%. reply dalyons 6 hours agorootparentThe IEA says it will peak in 2025. And they have consistently underestimated predicted renewables growth VS actual every year for the last decade. https://www.iea.org/news/the-energy-world-is-set-to-change-s... reply thelastgallon 15 hours agoprevRelated: Electric vehicle battery prices are falling faster than expected: https://news.ycombinator.com/item?id=38304405 reply choeger 11 hours agoprevWe have 500Wh/kg batteries by now? And they think there'll be 800Wh/kg in 2030? Wasn't that well beyond what's needed for medium-range electric flight? Is that even possible, chemically speaking? reply cbmuser 11 hours agoparentJet fuel has an energy density of 12,000 Wh/kg, so there is still a little room left. > https://en.wikipedia.org/wiki/Energy_density reply scythe 15 hours agoprevI'm a little surprised by that energy density chart. Who's selling batteries that carry 500 Wh/kg? Those are research prototype numbers; I think that Amprius and the gamma-sulfur people have hit (or passed) that mark. But cars and cellphones have been using the Ni-Mn-Al-Co oxide family of cathodes for a decade. The recent large-scale development has been bringing on LiFePO4 which actually accepts a lower density in exchange for lower cost and longer life. That doesn't discredit the predictions, but I don't think that the connection they're trying to draw between energy density and market demand really holds water. The development of higher density batteries is good for certain applications like that ground-effect electric seaplane, but it isn't necessary for cars or grid storage, where the first case is mostly viable already and the second is concerned with the cost outlook and the self-discharge rate. reply kccqzy 13 hours agoparentCATL is. https://www.evlithium.com/lifepo4-battery-news/catl-condense... reply scythe 10 hours agorootparentThat looks like a demo prototype. Farther along than I expected, though. reply martythemaniak 13 hours agoparentprevI think Amprius are further along than you might think, ready to scale commercial production, not research prototype. Super neat factory tour: https://www.youtube.com/watch?v=v_Hd4HfH1ss reply iSnow 15 hours agoprevThe adoption and cost decrease is so ridiculously fast that the first two charts should have been logarithmic instead of linear. reply defrost 10 hours agoprevAs a point of interest, for particular types of investors, underneath all the hoo-rah of the charts How fast will batteries continue to grow and improve? The answer is a lot faster than today’s consensus view. isn't exactly true in reality for the billion+ dollar end of the resources market who expected battery demand to be much much higher than it is, leading to temporary(?) setbacks such as: What's behind the drastic downturn in nickel and lithium prices, and what does it mean? https://www.abc.net.au/news/2024-01-26/examining-the-drastic... TLDR: Despite high expectation demand didn't meet ramped up supply at the raw material end. reply antisthenes 12 hours agoprevBatteries are great, but some of those charts look off. Where are they getting batteries that are 500Wh/kg for commercial applications? Even state of the art NMC cells in the 21700 and 46800 form factors barely scrape at 300Wh/kg, and everything else (LFP) is significantly below that number. reply bejebus8 16 hours agoprevnext [10 more] [flagged] DFHippie 16 hours agoparentWind? Solar? Hydro? Tide? Geothermal? reply bejebus8 16 hours agorootparentnext [9 more] [flagged] DFHippie 16 hours agorootparentAnd that balance is changing. reply bejebus8 15 hours agorootparentIt is a little bit for a bunch of reasons, but how does improving battery storage change the generation mix? reply macintux 15 hours agorootparentNot an expert, but the biggest downside from renewables seems to be the swings in production. Solar is obviously not useful at night. Wind comes and goes. Batteries and other forms of energy storage to normalize distribution are more important for renewables than fossil fuels. reply smaudet 15 hours agorootparentIndeed. Assuming you have a sustainable source, the next most important thing is distribution and storage. The cleanest candidate (Hydrogen-from-electrolysis) suffers from storage and distribution issues. These can be overcome, but at high cost. The easiest (batteries) suffer from a combination of storage and distribution issues (heavy batteries have to be transported, you can't pipe them around, energy grids have power transmission costs/depend on batteries to work, an ouroborian problem) as well as toxicity issues. Given that batteries cannot indefinitely become cheaper, and likely that demand will outpace supply, clean hydrogen, not batteries, seem the logical ultimate choice. reply speedgoose 15 hours agorootparentprevBatteries can also help to handle peak demand. reply smaudet 15 hours agorootparentprevThe bigger issue with \"battery\" technology is that it is unsustainable/toxic. https://www.mountsinai.org/health-library/poison/dry-cell-ba... https://www.nature.com/articles/d41586-021-01735-z Fossil fuels are OFC also toxic, I'm not advocating for indefinite use of those either. reply ceejayoz 15 hours agorootparentWait until you hear about fossil fuels. https://www.mountsinai.org/health-library/poison/fuel-oil-po... You don't want to swallow either one. reply smaudet 15 hours agorootparentSee my updated comment. reply tonymet 14 hours agoprevLithium Battery 0.5 kWh/kg Diesel 12.7 kWh/kg reply chris_va 14 hours agoparentYou probably want kWh_e (electric) instead of kWh_t (thermal), and probably should include the weight of the engine/transmission. Diesel is better still, but not quite the same gap. reply TOMDM 12 hours agorootparentAlso have to account for how many kWh are converted into motion. Again, diesel still wins, but man is that gap closing. reply 0xbadcafebee 16 hours agoprevIf battery growth is exponential, but mining of ore isn't, that's a pretty big red flag imo. Once raw material production hits a wall, prices go back up, profits droop, advancement declines. After a while there'll probably be a new OPEC for batteries. Batteries are here to stay, but the growth rate isn't. reply crote 15 hours agoparentPlenty of ore deposits simply haven't been exploited yet because the demand wasn't there, or the market price made it economically nonviable. Lithium is more abundant than lead, tin, or tungsten. We're not going to run out any time soon. reply __MatrixMan__ 15 hours agoparentprevI hope we find that \"battery\" is a sufficiently broad category such that individual bottlenecks (lithium extraction, for instance) end up being worked around by using different materials. I also think that biotech has picked up some new tricks lately (alphafold, etc) that might let it branch out from academia, medicine, and agriculture and affect things like mining re: bioleeching fungi to move minerals through mycelial networks to the surface. reply ccheney 14 hours agoparentprevThe near-total recyclability of batteries supports a circular economy, which should ease worries about raw material shortages reply wolfram74 15 hours agoparentprevOPEC is a possibility because ease of access to petrofuels was very sporadic, but the same is not true for battery chemistries, sodium and iron batteries are being used for storage scale and even some transport cases [0][1] and even lithium can be extracted from sea water [2]. Given how ubiquitous those 3 things are, there'll be a pretty hard ceiling/competition amongst different options. I suspect we'll encounter something more like agricultural cartels than petrostate cartels. [0] https://www.mprnews.org/story/2023/02/10/rusty-batteries-cou... [1]https://cleantechnica.com/2023/12/29/electric-cars-powered-b... [2]https://samcotech.com/is-it-possible-to-extract-lithium-from... reply Spinnaker_ 15 hours agoparentprevThe comparison to Oil is interesting. Because people have also been saying we would hit a production wall there, and have been saying that for about 90 years now. reply mbgerring 11 hours agoparentprevLithium is abundant and recyclable, and the main thing holding recycling back at the moment is the supply of depleted batteries. It is highly unlikely that the market for lithium will ever look like oil. reply PheonixPharts 14 hours agoparentprevIt's not \"exponential\" it's \"exponential in the S-curve\", which is just some bizarro marketing way of saying \"sigmoid growth\". Sigmoids (the most well know being the logistic curve) begin to tapper off overtime approaching no growth and reaching an upper bound. reply ggreer 14 hours agoparentprevThis is unlikely to happen for several reasons. First, battery technology has changed to require only one rare ore: lithium. Older battery chemistries required nickel and cobalt, but the most popular chemistry in electric vehicles today is lithium iron phosphate.[1] It has lower energy density than nickel manganese cobalt (NMC) or nickel cobalt aluminum (NCA), but lasts longer and is safer. Second, lithium is everywhere. The reason why most lithium comes from salt flats in Australia, Chile, and China is because that's the cheapest way to get it. But there are plenty of other salt flats around the world, and the oceans themselves contain over 100 billion tons of lithium (1,000x more than known land resources). If today's biggest producers form a cartel and try to control prices, other sources will become economically viable. Third, lithium is a tiny fraction of the cost of an electric vehicle. LFP batteries have around 160 grams of lithium per kWh, so a typical car battery (60-90kWh) has 10-15kg of lithium. The spot price for lithium is $15/kg, so the materials cost per car is around $150-250. If lithium prices went up by a factor of 10, the cost of the car would only go up by 5%. In contrast, doubling the price of petroleum almost doubles the cost of driving. Fourth, demand for lithium extraction will go down in the long run. This is because unlike petroleum, lithium stays in the car. Older EVs contain lots of lithium (and other raw materials) that can be recycled into new batteries. Old batteries are basically very high quality ore. Lithium recycling may sound unlikely to some, but we already have existence proofs of recycling happening with other cheaper elements. 80% of all copper ever mined is still in use. The number for aluminum is almost as high. Remember that the cost per kg of copper is half that of lithium, and aluminum is 1% the cost of lithium. I'm really not worried about rare ores being the bottleneck for electric vehicle adoption. In 2022, world lithium production was around 130,000 metric tons. That's enough to produce 9 million cars. In that same year, 85 million motor vehicles were built. Assuming we wanted all vehicle production to be EVs, and assuming an average battery capacity of 90kWh, that would require 1,224,000 tons of lithium. If lithium production increases at the same rate it did from 2016-2022 (3.5x)[2], it will take another 12 years before there is enough capacity to make every vehicle electric. I doubt things will take off that quickly, but you never know. EV designs are simpler than combustion vehicles, and the raw materials costs are similar. As EV production volumes increase and manufacturers design for farther down-market, we should see prices continue to drop. 1. https://en.wikipedia.org/wiki/Lithium_iron_phosphate_battery 2. https://ourworldindata.org/grapher/lithium-production?tab=ch... reply ViewTrick1002 11 hours agorootparent> Third, lithium is a tiny fraction of the cost of an electric vehicle. LFP batteries have around 160 grams of lithium per kWh, so a typical car battery (60-90kWh) has 10-15kg of lithium. The spot price for lithium is $15/kg, so the materials cost per car is around $150-250. If lithium prices went up by a factor of 10, the cost of the car would only go up by 5%. In contrast, doubling the price of petroleum almost doubles the cost of driving. From what I've read this causes the lithium market to be very chaotic. Supply is complicated and capital intensive to bring online while the demand is essentially inelastic. Time it right and you make a fortunes. reply _visgean 15 hours agoparentprevWe are still finding new deposits of lithium. Also its very likely we will eventually switch to other technologies that possibly wont require the same ingredients we need today. reply xbmcuser 13 hours agoparentprevA large growth for batteries is going to come from sodium ion batteries not lithium so there will be no problem for the growth rate. reply donbatman 14 hours agoprevMost of those batteries are being charged by natural gas. Batteries store electricity, they don't create it. reply ceejayoz 14 hours agoparentFor now. (And not everywhere. In Norway, 90% of that power would come from hydro plants.) One of the most common objections to a wholesale switch to renewables is \"what if it's cloudy / not windy\" sort of thing. Cheap, widely deployed energy storage is key to answering that objection. They go hand in hand. More batteries, more renewables, more batteries, more renewables, etc. etc. etc. Eventually, the obvious goal is to charge everything via renewable power. reply Sohcahtoa82 13 hours agoparentprevIt frustrates me that you think this is a genuine talking point. If we're talking about powering cars, then even if your power comes from 100% coal, it's still cleaner to drive the EV than gasoline, simply because the coal power plant benefits from the economy of scale. It merely takes longer for the trade-off of the higher carbon footprint of manufacturing an EV to happen. But it does eventually happen. If we're talking about powering an energy grid, nobody expects them to be charged via consumables. That's just silly. But battery storage is how you make wind/solar energy work without requiring burning consumables as a backup. reply tonymet 14 hours agoprev [–] > \"Enabling the phase-out of fossil fuels\" How much hydrocarbon fuel is needed to produce these batteries each year? How much fuel is needed to charge them? reply stetrain 14 hours agoparentCurrently used? Probably quite a bit. But usually still a net emissions win for using an EV vs a fossil fuel vehicle even with current grids. Required? None. There's nothing in EV battery production or charging or usage that requires burning fossil fuels. That fossil fuels are a major source of our current energy is part of the problem that we are also working to solve. And mass production of economical batteries is part of how we do that with renewable energy. Building grids and vehicles that burn fossil fuels means you need to keep drilling, refining, and transporting that fossil fuel for every future kWH generated or mile driven. Forever. A battery is made once and used for its lifetime, and most of its critical materials can be recycled at end of life into new batteries. If you want current stats on total lifetime emissions of manufacturing and using batteries vs fossil fuels, search for \"EV cradle to grave emissions\" and there are a few studies. My recollection is that the results show that an EV will have lower lifetime emissions than a fossil fuel vehicle even with today's mostly dirty grids in most cases, and break-even in the worst grid mixes. As grids shift to renewables and recycling increases those numbers should only improve. reply tonymet 13 hours agorootparenta quick check showed about 21 Billion Gallons annually to make 130k tons of lithium batteries are produced. so 273 billion kWh of hydrocarbon fuel burned to make batteries that can hold only 51.5 million kWh of energy. And then roughly a few billion or more to fill them up each year. What year will we make enough solar & wind power to compensate for the 21 billion gallons of fuel? reply ceejayoz 13 hours agorootparentA quick check shows the 21 billion gallon number you're (not) citing is likely bullshit. https://www.verifythis.com/article/news/verify/environment-v... > David Checkel, a professor at the University of Alberta and an electric car expert, did some back-of-the-napkin math to dispute the claim. Checkel calculated that if each gallon of fuel costs $3, then 21 billion gallons would cost $63 billion annually. If $63 billion was the price tag for 250,000 batteries, then the cost of raw materials for each battery would be more than $250,000. reply tonymet 12 hours agorootparentwhat's the correct figure? it's easily 100x the output reply ceejayoz 11 hours agorootparentIs that number pulled off a Facebook meme, too? You seem confused by the concept of a reusable battery. It's not a AA battery; you don't throw it away every 300 miles and get a new one. reply recursive 4 hours agorootparentprevGood thing they get charged more than 100 times then. reply stetrain 13 hours agorootparentprev> Nonetheless, it is shown that conventional gasoline and diesel vehicles emit the highest amount of total life-cycle GHGs in comparison to vehicles powered by other available energy resources. When using green electricity, plug-in hybrid electric and fully electric vehicles can reduce the total life-cycle emission in comparison to combustion engine vehicles by 73 % and 89 %, respectively. https://www.sciencedirect.com/science/article/pii/S136403212... Plenty of other papers with similar results. Current total lifecycle emissions are already net negative for EV vs ICE including production of the battery and vehicle, and production of the electricity using the current grid. That margin improves as the grid gets cleaner. reply ceejayoz 14 hours agoparentprev> How much fuel is needed to charge them? The eventual goal would be zero. reply tonymet 13 hours agorootparentin what year? reply ceejayoz 13 hours agorootparentDon't pull a muscle moving those goalposts around. reply mbgerring 11 hours agorootparentprevMany batteries deployed today, in 2024, spend their entire lifecycle being charged entirely from solar. Are you asking what year none of them will be charged with electricity from fossil fuels? I’d bet that we’ll hit that mark in California before 2040. reply tonymet 12 hours agoparentprev [–] typical hackernews climate thread -- don't ask any important questions reply Sohcahtoa82 5 hours agorootparent [–] They're bad faith, loaded questions. Be honest, you didn't ask them to learn something, you asked them because you think they're \"Gotcha!\" questions. Your responses to answers make this painfully obvious. If you want to make a point, then just make it. Don't hide behind a bullshit claim that you're just asking questions and then cry about downvotes. reply tonymet 1 hour agorootparentEvery solution has tradeoffs . What is so wrong about discussing them. We discuss the tradeoffs of everything else. Then electric comes up and that’s off limits reply tonymet 1 hour agorootparentprev [–] My point is no one accounts for the cost and environmental impact . They are fair questions . reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The demand for batteries is rapidly increasing, leading to a potential reduction in global fossil fuel demand by half.",
      "Battery sales have been doubling every two to three years, driven by the growth of electric cars.",
      "Improved battery quality and decreasing costs are enabling new applications across various sectors, including transportation and energy storage. Analysts have consistently underestimated the growth of batteries.",
      "Falling costs and increasing policy support are expected to further drive the adoption of batteries.",
      "Rapid deployment of batteries can facilitate the phaseout of fossil fuels in road transport, shipping, aviation, and the electricity sector, leading to significant carbon emission reductions.",
      "More efforts are needed to accelerate the transition to batteries for a faster and more sustainable future."
    ],
    "commentSummary": [
      "The discussion covers various topics related to energy generation, storage, and consumption, focusing on electric vehicles (EVs) and renewable energy sources.",
      "The conversation explores using batteries to address the timing disparity between peak demand and solar power generation and discusses the decline in rooftop solar applications in California.",
      "There is a debate on residential generation and storage of electricity, the need for improved EV charging infrastructure, and the challenges of implementing EVs in rural areas. The conversation also discusses the efficiency of EVs compared to petrol vehicles and the potential for hydrogen storage and electric-powered flights."
    ],
    "points": 255,
    "commentCount": 246,
    "retryCount": 0,
    "time": 1706289028
  },
  {
    "id": 39144710,
    "title": "Untranslatable: Embracing the World's Linguistic Diversity",
    "originLink": "https://untranslatable.co/",
    "originBody": "explore entries log in add entry support this project The first multilingual urban dictionary Untranslatable is an online dictionary that allows people to add words and expressions from all over the world. see what people have added add something What makes this project unique? Untranslatable is an indie project that delves into the hidden aspects of languages by explaining words, idioms, and expressions contributed by native speakers. It goes beyond traditional translation, offering insights into usage, context, and cultural significance. What we focus on Context Because what something means can be conveyed by how, where, how frequently and by who something is used. Accuracy All entries are approved by one of our moderators, and people can vote on whether they have heard something or not. Inclusivity Untranslatable allows entries in any language, from any dialect, including endangered languages and sign language. Behind the project My name is Amarens, and I started this project in 2019 after I graduated from my Bachelors in Portuguese and Spanish Linguistics. I have since received an MA in Theoretical and Applied Linguistics and a MSc in Computational Linguistics. I originally raised money for the project through a Kickstarter campaign, and learned to program from scratch in order to create this website. About About Features Questions Updates Browse Synonyms Statistics Countries Languages Other More dictionaries Projects we love Feedback Get involved Untranslatable is an online dictionary where native speakers can share words, expressions, idioms, slang and other linguistic curiosities from all around the world. Made with from Barcelona",
    "commentLink": "https://news.ycombinator.com/item?id=39144710",
    "commentBody": "Untranslatable (untranslatable.co)242 points by hk__2 17 hours agohidepastfavorite82 comments Freak_NL 14 hours agoFor any digital crowdsourced dictionary to be useful and viable, step one is to have an open license to prevent contributors from being turned off by the thought of contributing their efforts to what might eventually just end up as commercial as Urban Dictionary. This project makes no mentioning of licensing at all though. That shouldn't be an afterthought. reply akoboldfrying 13 hours agoparent>For any digital crowdsourced dictionary to be useful and viable I'm pro open licenses, but you're overstating things. The sheer usefulness and viability of Urban Dictionary attests to the fact that most people don't actually care about licenses. reply lucideer 12 hours agorootparent> The sheer usefulness and viability of Urban Dictionary attests to the fact that most people don't actually care about licenses. Urban Dictionary is indeed extremely useful, but I think making this out to be evidence that people don't care is oversimplifying things. As useful as it is, it's still pretty clear that the licensing (along with a few other lacks, open moderation, etc.) severely holds it back from being as comprehensive & accurate a source as it could be. It achieves usefulness through sheer volume: the vast majority of entries on it are nonsense, there's just so many that there are diamonds to be found in the rough. reply akoboldfrying 12 hours agorootparentI only claimed that most people don't care (which is indeed borne out by UD's success) as direct evidence contradicting the claim I quoted. I certainly agree that UD could be even better, including through better licensing. reply vendiddy 11 hours agorootparentI agree with you. The thought of licensing won't cross the mind of the vast majority of people. But yeah better licensing would still be nice. reply wodenokoto 4 hours agorootparentprevIs it supposed to be an accurate source? It’s a bit of an in-joke repository. reply amadeuspagel 11 hours agoparentprevHacker News doesn't have an open license either, which doesn't seem to turn you off from contributing. reply psychoslave 10 hours agorootparentThrowing messages in conversations is not the same as contribute to curate a linguistic data base, both in term of cognitive load and easiness to lucratively despoil contributors. reply groby_b 7 hours agorootparentThen maybe you should step up the quality of messages you contribute? reply jimmySixDOF 7 hours agorootparentprevDoes not stop 3rd party readers like the one I paid for and am using now to make the experience a little more what works for me. reply keepamovin 7 hours agoparentprevI don't think folks should rush to infer stuff from this. There's a kind of dogma about open licenses which often undermines the very efforts proponents say it supports. Another way to say that is it might be unwise to let ideological peer pressure coerce you into an open license, under the guise of serving some imagined superset of users who \"really want\" and \"otherwise can't use\" that, while ignoring the actual market segment who would happily use your product commercially, and the benefits that such restrictive protection provide. Open source can be abused to coerce newcomers to surrender any competitive advantage they might compound by using such \"imaginary market\" and \"ideological purity\" arguments, when in reality it may just be a tool of incumbents to weaken any competition, by eroding a startup's ability to capture value. Or in a pithy form: \"Go open source! It's bad if you don't\" said the Big Bad Wolf Corp to the Little Piggy Startup. \"Oh yes, Mr Wolf, anything to please!\" said the Little Piggy Startup, trusting the Big Wolf, because, who would want to hurt Little Piggy? Be cautious before you change anything and consider many options! If your instinct is to stick to stronger protections, then it might be wise to do that! reply stratocumulus0 3 hours agoparentprevI would be more concerned about accuracy, bias and curation sooner than I would think about the license in case of a community-built dataset. Take a website such as TasteAtlas, for example. They frequently publish rankings of best/worst foodstufs, but their data on that is garbage (even if you skip the fact that taste is highly subjective). Not only are there lots of incorrect assumptions made (e.g. a dish always belongs to only one national cuisine), but also the popularity data is not curated at all, so they end up with situations such as the first place in my country on the \"100 Best Food Destinations\" list was a tiny village with a truck stop. reply Aachen 13 hours agoparentprevI was already looking for a bug tracker to fix the swallowed newlines and blank lines after submitting... I'm so used to open source now, it somehow surprises me not to be able to find at least a public bug tracker even if I can't directly submit a simple fix. One can share \"feedback\" via Google Docs, though :') yeah, no thanks Now that you point out the data license, yeah, this project will definitely be dead within two years. No sustainable license and not interesting enough to revisit daily like Mastodon, so it will neither build a community nor a sustainable dataset. It's simple enough that part time support will let it survive in the background for a while, but colour me surprised if the author hasn't fully moved on come 2026 reply RivieraKid 11 hours agoparentprevThat would make it harder to make money with this project if it becomes successful in the future. reply ants_everywhere 5 hours agorootparentI think that's what the parent is saying. Are the site's users unpaid labor? That was a thing corporations tried to do when back when urban dictionary was starting, but in today's climate working for a corporation for free doesn't have the cachet it used to. reply space_ghost 17 hours agoprevI like the idea, but the \"see what people have added\" button on the landing page links to the new-entry page instead of the explore page. reply yorwba 16 hours agoparentThe explore page is here: https://untranslatable.co/pages/explore reply denysvitali 14 hours agoparentprevThis is probably a translation mistake :-) reply phito 16 hours agoparentprevOh I assumed I had miss clicked reply muhammadusman 16 hours agoparentprevhappened to me as well, might just be linked incorrectly. reply not-my-account 12 hours agorootparent'tissee what people have added add somethingreply IlliOnato 5 hours agorootparentCopy-and-paste, I guess. reply Biganon 15 hours agoprevWhen I go to https://untranslatable.co/pages/stats#countries (which is weirdly hidden at the bottom of the page), I cannot open the \"Languages\", \"Countries\" or \"Latest entries\" sections. Therefore, I have no idea how to see slang from one specific country. reply Hamuko 14 hours agoparentThe \"see what people have added\" button on the front page is also broken. Doesn't seem like a particularly well made site. reply emaro 13 hours agorootparentThree are some quite obviuous errors, but the creator writes she has \"learned to program from scratch in order to create this website\". I think it's a good start. reply tim-- 11 hours agorootparentprevSeems like that just needs to link to the same \"Explore\" link on the homepage, very simple fix. reply cobertos 16 hours agoprevVery interesting they were funded partially from Kickstarter! 292 backers at 10k€. I assumed you needed quite the following for Kickstarter to work... And it looks like they do. 49k followers on Facebook and 16k on Instagram. Not sure how far back these go, but looks like very \"shareable\" content, where they would take I translatable words and make little funny pictures or memes or other intriguing things and post them. Lots of interaction comments/reaction-wise Timeline-wise this was backed on Kickstarter in 2020. Site launched in summer 2020. The creator was very active on Kickstarter working on communicating and updating the community with what was going on (until the end there). Also seems to have a Patreon, and worked itself into other places like https://github.com/theimpossibleastronaut/awesome-linguistic... reply tasuki 11 hours agoparentThere's only 2000 entries so this isn't very useful right now. With the kickstarter at 10k€ that's 5€ per entry - quite expensive. Otoh the creator learned to program specifically to create this website, so I guess well done her! reply wrboyce 11 hours agorootparentYeah, well done for crowdfunding some education for herself hah. Fools and their money. reply cobertos 7 hours agorootparentSounds more like the community of people in this interest group/hobby had an interest and she was just stewarding their desires. And her and the communities values ended up aligning. Like a contractor/contractee relationship reply replwoacause 10 hours agorootparentprevThis is a cynical take. reply SamBam 13 hours agoprevSo this is international, but is the aim for it to be used by an international audience? e.g. if a Brazilian were lamenting the fact that UrbanDictionary is in English, is this site for them? Because right now when I explore the entries, all the definitions are in English. Is this the intent? So it's for English people to find out what international slang words are? I feel like it would be good to be really clear about your audience. Maybe one option would be to allow the writing of definitions in multiple languages. Then a user could look up a word, and see all the definitions and find the definition in their language. reply Tijdreiziger 3 hours agoparentThe fact that it’s in English doesn’t preclude its use by the non-English. For example, I (a Dutch person) just found out about some Brazilian and Panamanian slang. Presumably, a Brazilian or Panamanian person could also find out about Dutch expressions (I saw some Dutch entries). So the target audience, to me, is quite clear: people from around the world, who are interested in other languages and cultures. reply jusgu 10 hours agoprevCool but why does clicking both “see what people have added” and “add an entry” link me to the same page to add an entry? Is there no way to view the collection without adding an entry? reply Tijdreiziger 3 hours agoparentIt seems like a bug, if you click ‘explore entries’ in the hamburger menu at the top, it works reply notfed 2 hours agoprev> The first multilingual urban dictionary Is it even legal for a site to call itself \"[an] urban dictionary\"? AFAIK \"Urban Dictionary\" refers to one thing: urbandictionary.com, no? reply notfed 2 hours agoparentAlso, I bet running urbandictionary.com is an absolute moderation nightmare. Imagine that, and now it's in thousands of languages. I wish the authors the best of luck. reply FireInsight 2 hours agoparentprevI know of at least one unaffiliated urban dictionary site using the term, but it's translated so maybe it doesn't count. reply jackyard86 5 hours agoprevI was daydreaming (just a really dumb daydream) about a 'universial language' that would include all the words from every known language, just few minutes ago before I discovered this on HN. haha. I think it's really neat since there are thousands of foreign words that cannot be translated into English or Korean (Languages I speak), and it takes a quite of time just to really understand what those words mean. reply dfee 6 hours agoprevUrban language is vulgar. Seeing “inclusivity” as a value gives me pause to the usefulness of this endeavor. As I’ve gotten older (many years past high school now), I care less about finding and sharing vulgar terms with friends. But, when I come across language on social media that I don’t understand, I want a guide. Fail me that, and I won’t return. Pull the ten most common (but missing) definitions from Urban Dictionary daily and provide a clean room definition. That would serve as a good litmus for the sorts of censorship we could expect. reply FireInsight 2 hours agoprevWhen browsing my native language, I found that many of the words were in fact not untranslatable or urban in any way, but rather common words like \"computer\" that have been formed from roots different than english. reply LaurenSerino 14 hours agoprevBad UX, great idea. Cursing in other languages is my prime influence for learning them. reply rob74 16 hours agoprevCool idea, but definitely needs some more content - the \"explore\" page shows 103 pages with 20 entries each = ~2060 entries, which is a good start, but not really comprehensive I would say. Seems to have had a flurry of activity in 2020, then nothing, then a single new expression added this month? reply input_sh 14 hours agoparentFurthermore they don't seem to do any sort of checks to make sure the same entry isn't added multiple times. Didn't take me long to spot three entries for the same phrase: https://untranslatable.co/pages/explore/?q%5Btitle_or_langua... reply moritzwarhier 11 hours agoprevThis project and landing page succeeded in provoking interest. And when I visited, the \"explore\" link worked :) guess it was fixed recently. Would love for this to grow! reply KolmogorovComp 14 hours agoprevWhat is difference/upside compared to urbandictionary that has fit its role quite well up to now? https://www.urbandictionary.com/ reply emmanueloga_ 13 hours agoparentI think the main difference is that it’s multilingual reply FireInsight 2 hours agorootparentI just searched for non-english slang on UD and found two definitions instantly. I think it's safe to say that the internationalism is at least not prohibited. reply lovegrenoble 15 hours agoprevHow can we choose the language? The UI is not friendly... reply RedNifre 15 hours agoparentYou click on one of the languages on a random post, then change the language in the URL to the one you like. reply fivre 12 hours agorootparenti particularly like that hacking the URL query parameters is apparently the only option for navigating the country and language categories, but those query parameters are at the end of the URL, usually past the edge of the URL bar field they're past the end because the first parameter is a giant \"authenticity token\" base64 blob. you'd think this is maybe important, but removing it doesn't appear to affect the request at all reply ugjka 15 hours agoparentprevThe UI is totally broken reply atomjames 6 hours agorootparentLots of people on here have web dev experience. Maybe someone could offer to help. reply karaterobot 16 hours agoprevThis is pretty neat. I expected it to immediately have descended into the same hell as Urban Dictionary, but it actually seems useful. I appreciate that it tells me who uses a term and where, and I especially like being able to click on those labels to explore more terms in the same category—I wish there were a way to see all those categories and choose between them (if there is, it isn't obvious to me). reply IlliOnato 5 hours agoprevI think, in context I could guess the meaning of \"Not here to fuck spiders\" in Australian English. But I don't think I could guess the meaning of \"0800\" in Brazilian Portuguese... :-) reply cookie_monsta 4 hours agoparentFwiw, as an Australian I have never heard that one but, yeah - there's enough context there to figure it out. Now if you'll excuse me, I have some spiders to wine and dine reply MarcScott 11 hours agoprevSpotted this one: \"Not here to fuck spiders\" Asked an Ausie mate if it was real, and he confirmed he uses it often, as in: \"Look mate, we're not here to fuck spiders, might as well just crack on.\" reply IlliOnato 5 hours agoparentI've seen it too and... LOL! :-) reply jasmas 8 hours agoprevSo Urban Dictionary clone, but English seems to be the second language in this case. Is licensing the draw or the differentiator? I don't think the message on that is clear. reply davidw 16 hours agoprevThe Italian ones are real, but a bit less 'urban dictionary' than phrases that have been around for a while. Probably just needs more contributors though. reply wrboyce 11 hours agoprevLove the idea but the UX needs some serious attention. reply resolutebat 7 hours agoprevThis seems far less comprehensive, open and trustworthy than Wiktionary. reply istrice 10 hours agoprevDid my part, added an Italian expression :) reply bvanderveen 16 hours agoprevA mechanism for filtering by language or searching by keyword would be nice. reply keepamovin 7 hours agoprevI guess Cantonese should have a large contribution to this! reply alexwhb 16 hours agoprevLove the idea of this. Hope it takes off reply stcredzero 16 hours agoprevDuring my last trip to Fujian China, I became fascinated by the Mandarin word that sounds like, \"schma.\" My wife was born there, and she had told me it meant, \"what.\" But this time, I was really listening to how the word was being used, and it occurred to me, it was being used somewhat like \"donc\" in French. (Which my French teacher in high school told me was untranslatable.) When I realized, that, my reaction was, \"What!?\" After our trip, I became obsessed with the word for receipt: \"fapiao.\" I thought my inability to tell the difference in the tones was hilarious, but now she refuses to say the word in front of me at all! This is also hard for me to understand. As far as I'm concerned, she's pretty much just saying, \"ma\" to me 4 times in a row! There's a difference, but it's very difficult! Why is my befuddlement and amusement at that so annoying? There's this Taiwanese comedienne who was talking about being annoyed at her western boyfriend not being able to tell, so apparently that's a thing. reply Al-Khwarizmi 16 hours agoparentThis is curious to me. As a Westerner and speaker of a non-tonal language that started learning Chinese already being an adult, I never had any difficulty telling the difference between the tones. I did have difficulty with other sounds of the language (e.g. telling \"x\" from \"sh\" or \"q\" from \"ch\") - hell, I even have difficulty with English sounds, for example, to this day I need to pay an inordinate amount of attention to tell \"eyes\" from \"ice\" and there's no way I'll successfully pronounce them differently in regular real-time conversation. But the Mandarin tones? I find the difference obvious. I wonder if being a music aficionado, having played an instrument, etc. helps with the tones. reply retrac 15 hours agorootparentNo, you're not alone. Approaching Mandarin I expected tones to be some sort of big hurdle. They're not. They're largely obvious. It's a part of the vowel, basically. Linguistically speaking, there's very little distinction between a vowel and a tone - it's part of how you make the vowel. And tone and vowel quality interact in a complex way, which means you're hearing changes in the vowel, along with the pitches involved. As you mentioned, at the start I was more likely to mix up x and sh than I am to mishear a tone. Other languages use tone, of course, they just don't use it lexically to distinguish words. I also have played an instrument, etc. but I don't know if that's a factor or not. Now, pronouncing the tones is a whole other question. My own Mandarin has like 2.5 tones instead of 4, and I struggle to apply tone contours to long phrases without messing up everything involved. Both English and Mandarin have tone contours (and a lot of them are even the same, for example, slowly rising with a sharp rise over the last few syllables = question) but the tone contours of Mandarin interact with the lexical tones of a word. Something we don't have to worry about in English. I doubt I'll ever get enough practice to make that automatic. reply stcredzero 14 hours agorootparentApproaching Mandarin I expected tones to be some sort of big hurdle. They're not. They're largely obvious. It's a part of the vowel, basically. Linguistically speaking, there's very little distinction between a vowel and a tone - it's part of how you make the vowel. Both a Korean teacher of mine and an old housemate (who was a native Russian speaker and had a degree in French) pointed out to me that Americans are \"lazy\" (that is the technical term, I gathered) about how they use vowels. We get dipthongs confused with pure vowels. Unless it's pointed out to us, we don't think of how we say \"oh\" as containing an element of \"w\" at the end. And tone and vowel quality interact in a complex way, which means you're hearing changes in the vowel, along with the pitches involved. Ah ha! I think you just helped me! I hadn't been thinking of these two together! the tone contours of Mandarin interact with the lexical tones of a word. Something we don't have to worry about in English. Tone of voice is diabolically subtle, the way British and American speakers use it. About half the time, we're using it to indicate the opposite or almost opposite meanings of words. My wife from Fujian doesn't think of speech in quite the same way. We got into an argument, because she kept shouting, \"BE CAREFUL!\" every time someone cut me off in downtown SF traffic. It took me awhile to understand that she was just frightened and was telling me to be careful. (\"HOW COULD YOU TWIST SUCH A TENDER EXPRESSION OF CARE!?\" -- Which she said in that tone of voice.) Tones don't occupy the same part of my brain as parts of vowels. It's more like a musical soundtrack accompanying the dialog. reply stcredzero 16 hours agorootparentprevfor example, to this day I need to pay an inordinate amount of attention to tell \"eyes\" from \"ice\" I just find that obvious. Wherever I've been in the US, \"eyes\" is drawn out, but \"ice\" is short. (Think of imitating a southern accent for \"eyes.\") The only people I've ever heard saying \"eyes\" so it sounds like \"ice\" are native German speakers and other Europeans. (My wife learned German for her Chinese/German comparative lit degree, so the way she says certain things in English sounds menacing to me like how a WWII German movie character says, \"We have ways of making you talk!\" In particular, when she says, \"Your handwriting...looks like WORMS!\") I wonder if being a music aficionado, having played an instrument, etc. helps with the tones. I've been playing traditional music for almost 40 years, and I even qualified to compete at what's basically the world competition once. I think it matters most what one got used to as a child. reply yorwba 15 hours agorootparent> The only people I've ever heard saying \"eyes\" so it sounds like \"ice\" are native German speakers and other Europeans In German, many syllable-final consonants (in particular, \"s\") are always voiceless, but the English plural \"-s\" is voicet (which strangely enough none of my English teachers ever botheret to mention) so if you apply German phonological rules to \"eyes\" you get something that sounts identical to \"ice\". But Germans hafe no problem pronouncing \"eyes\" if the \"s\" is not syllable-final, e.g. in \"Eisen\" (\"eyesn\", iron). To learn to speak a languache like a natife, you neet to break habits of thought you didn't even know you hat. reply totetsu 10 hours agorootparentprevIsn’t the point of difference that, eyes had a little slide in the first vowel, ‘ah-I ss’ and maybe a more voiced z like s And ice just has extended one ‘ah- s’ a and a more interdental friction s reply aamargulies 12 hours agoparentprevMy Japanese teacher said that, for her, the English words “ear” and “year” are indistinguishable. I see how that could be, the words are very close, the ‘y’ sound is very brief, but it helped me understand how something that is so clear for a native speaker could be very difficult for a foreigner to hear. reply nojs 15 hours agoparentprev> During my last trip to Fujian China, I became fascinated by the Mandarin word that sounds like, \"schma.\" My wife was born there, and she had told me it meant, \"what.\" That would be 什麼 shén me, pronounced exactly as you described reply dgunay 14 hours agoparentprevDo you have trouble understanding intonated sentences in English too? You can change the meaning of this question pretty significantly by placing a rising intonation on each word: You stole his pen? _You_ stole his pen? -> It was you who stole his pen? You _stole_ his pen? -> You in fact stole his pen, it was not given willingly? You stole _his_ pen? -> You stole his pen, and not someone else's? You stole his _pen_? -> You stole his pen, and not something else of his? reply stcredzero 14 hours agorootparentDo you have trouble understanding intonated sentences in English too? You can change the meaning of this question pretty significantly by placing a rising intonation on each word Read my other comments. You'll find I'm already talking about this! Ok, so it's totally not a rising intonation to me! Wherever you have the _x_, it's emphasis. \"Rising\" is about the most confusing way to describe it, from my point of view as a layperson. Also, as I point out elsewhere, the way you are talking about \"intonated\" sentences is more akin to an accompanying soundtrack, where there's a \"stinger\" played at the moment something significant is said. It's not a part of the vowel! EDIT: Okay, I've been working this out saying it to my self. There's nothing \"rising\" in \"you\" when I say \"_You_ stole the pen?\" The volume doesn't rise through the word. The pitch doesn't rise through the word. The only thing that rises in the whole sentence is the pitch approaching the last part of the sentence to indicate a question. If \"rising\" is the actual terminology, then that's the most misleading terminology I can think of! reply huhtenberg 15 hours agoparentprev\"donc\" is \"therefore\" (though shorter and less pompous). reply stcredzero 14 hours agorootparentExcept, a French speaker could well just reply, \"Donc\" without anything else in contexts where an English speaker would never say, \"Therefore.\" In those contexts, \"Donc\" is more like, \"Word!\" or \"Right on.\" I would translate those to mean, \"Agreed.\" Or is that just French that French teachers and textbooks talk about to students in America? reply atnnn 13 hours agorootparentI would say \"donc\" is used where some might say \"so\" in English (aka shorter and less pompous \"therefore\"). I think the meaning of \"Agreed\" or \"Right on\" is rare and more implicit. Like saying \"therefore\" might mean \"I accept the premise\". As a question, \"donc?\", like \"so?\", can mean \"and then?\", \"then what?\", \"meaning what?\", \"what next?\" or \"so what?\" As an interjection or at the beginning of a sentence, \"donc\", like \"so\", can mean \"now then\", \"that said\", \"moving on\" or \"without further ado\". reply stcredzero 11 hours agorootparentLike saying \"therefore\" might mean \"I accept the premise\". I basically never hear that as a standalone reply in English! As an interjection or at the beginning of a sentence, \"donc\", like \"so\", can mean \"now then\", \"that said\", \"moving on\" or \"without further ado\". I'm not sure, but I think sometimes when my wife is saying, \"schma\" it's somewhat like \"donc\" you describe above. But sometimes, I think she expressing agreement with a person that a third party was a bit mistaken or off the mark, so it's expressing a kind of disagreement. Not sure. reply blondin 16 hours agoprev [–] saw the expression \"que sopa?\" and thought about all the verlan french rappers brought into the french language. most of them will never make it into the french dictionary. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Untranslatable is a multilingual online dictionary that allows users to contribute words and expressions from different languages and cultures.",
      "The project aims to provide more than just translations, offering insights into context and cultural significance.",
      "It welcomes entries in any language or dialect and is supported by moderators and user voting to maintain quality and accuracy."
    ],
    "commentSummary": [],
    "points": 242,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1706287648
  },
  {
    "id": 39143958,
    "title": "Software Engineer's Journey to O-1 Visa: Quick Approval and Expert Tips",
    "originLink": "https://blog.awais.io/o1-visa/",
    "originBody": "By Awais Hussain in immigration — Jan 21, 2024 How I got an O-1 visa as a software engineer / founder I am a software engineer turned CTO / co-founder. My O-1A petition was approved in ~1 week with premium processing, and was sponsored by the company I co-founded. I met 4 of the 8 ‘extraordinary ability’ eligibility criteria required for the O-1. I have benefitted from reading other people’s writing about their US visa journey. I’d like to pay that forward, and write down my own story in case it is helpful to others. The fact that it’s called the “extraordinary ability” visa can make the O-1 seem intimidating. However, this pathway is surprisingly well suited to many startup founders. The visa is valid initially for 3 years, and extendable indefinitely for one year at a time. Note: None of this is legal advice. It is simply me recounting my own experience, which may or may apply to you. Please speak to an immigration lawyer if you are considering applying for an O-1. Jump ahead Timeline Meeting the extraordinary ability criteria How much does it cost? Should you work with a lawyer? Timeline Earlier - Arrived in the USA on an L1B visa (sponsored by my employer Wave) with an expiry date of Feb 2023 Summer 2022 - Left my SWE job at Wave and incorporated my own startup called Path (a Delaware C corp) I was permitted to remain in the USA, since I was not employed by Path yet. My understanding is that it is permissible to do exploratory work on a new startup as long as you are not employed by that startup, and your previous visa has not expired. It was during this time that my cofounder and I raised money for Path. Note: If I had left the USA during this time, I would not have been permitted to re-enter on my old L1-B visa. Path had 2 co-founders, with 50 / 50 ownership and both of us were on the board. This ensured that I could be fired, and therefore met the employee-employer relationship requirement for the O-1. 16th September 2022 - My lawyer and I discussed the prospect of applying for an O-1 21st October 2022 - Filed the application with USCIS with premium processing I already had the materials ready, so didn’t need to spend time ‘building my profile’ 24th October 2022 - Received a receipt notice from USCIS 27th October 2022 - Received an approval notice 🎉 5 January 2023 - Attended my consular interview at the US Embassy in London Received my passport back with a visa stamp a few days later Meeting the extraordinary ability criteria To apply for an O-1 you must meet 3 of the following 8 USCIS criteria. I met the 4 criteria which are highlighted in bold (*) below. Nationally or internationally recognized awards (*) Membership in organizations which require outstanding achievement Published material in journals, trade publications or major media about the applicant Has judged the work of others (e.g. peer-review, or judging hackathons) Evidence of original contributions in science, scholarship, or business (*) Has authored / published articles in professional journals, or major media Has been employed in a ‘critical capacity’ at an organization with a distinguished reputation (*) Evidence that the beneficiary has commanded a high salary (*) Below are more details on how I met each of the criteria. In general, for every claim made in your O-1 cover letter, you should be able to produce documentary evidence, or a statement in a signed letter from a credible person. Nationally or internationally recognized awards Startup funding counts as an award, if you can demonstrate that the investor(s) were being judicious in their investment. In other words, you must demonstrate that your investors only select a small percentage of the opportunities presented to them. At the time of my application, my company had raised $98,000 on SAFEs from friends, family and angel investors. Alongside copies of all the signed SAFEs (demonstrating total funding amount), we submitted our pitch deck, and letters + CVs from two investors showing their credibility as discerning / selective individuals. Evidence of original contributions in science, scholarship, or business I did not have to do any additional work, beyond the day-to-day work I had done at Wave in order to meet this criterion. While at Wave, I worked on several projects that were original in the industry, primarily because Wave had unique constraints as a fintech targeting sub-Saharan Africa. It helped that I had previously met the L1-B criterion for “specialized knowledge” and we were able to make a similar argument here that I had worked on original, proprietary software at Wave. As evidence, we included my employment contract, letters from the CTO and a cofounder of Wave, and press coverage showing Wave’s success in Africa. We also included material from a conference talk I gave at PyCon Africa in June 2019. Being employed in a ‘critical capacity’ at an organization with a distinguished reputation It’s important for this criterion to show both critical capacity, and distinguished reputation. My lawyer made the argument that I met this criteria both for my work at Path, and my work at Wave. At the new startup, Path, it was easy to show critical capacity since I was a founder, large shareholder, and board member, as evidenced by our incorporation documents. To demonstrate distinguished reputation, we showed that Path had raised nearly $100,000 in funding, and that Path had been accepted into a legal tech sandbox program. To demonstrate critical capacity at Wave, we used the same two letters: one from Wave’s CTO and one from Wave’s cofounder showing that I was an early employee and had worked on key projects which contributed significantly to Wave’s success. To show distinguished reputation we submitted media coverage about Wave’s impressive $200m Series A fundraise. Evidence that the beneficiary has commanded a high salary or remuneration Equity grants in startups count towards this requirement. “if the petitioner demonstrates that receipt of a high salary is not readily applicable to the beneficiary’s position as an entrepreneur, the petitioner might present evidence that the beneficiary’s highly valued equity holdings in the startup are of comparable significance to the high salary criterion.” - USCIS Policy Manual. Volume 2, Part M, Chapter 5, Section 3 I showed that my total compensation (base salary + equity) at Wave for the 2021 calendar year was higher than the top 10th percentile for software engineers in New York City as recorded by the US Bureau of Labor Statistics benchmark, and the Career One Stop website. I benefited from the frothy investment market of 2021. The stock options I was granted at Wave were issued before Wave raised money at a $1.7B valuation, so they were worth a lot on paper at the time of my O-1 application. As documentary evidence, we submitted copies of my Wave stock certificates, and 12 months of paystubs. Note: you can meet this criteria by commanding a high salary at any point in the past, it doesn’t have to be your most recent year of earnings. How much does it cost? The O-1 filing fees were $460, with an additional $2,500 for premium processing. (Note: the premium processing fee is set to increase to $2,805 on February 26th 2024). I was quoted in the $6k-$10k range for immigration lawyer fees (not including filing fees). Should you work with a lawyer? I would definitely recommend working with an immigration lawyer, especially if you are not very familiar with the US immigration system. There were several subtleties within the application process which I did not know about until my lawyer made me aware of them: I didn’t know that I had a good chance at an O-1 until I spoke to a lawyer I didn’t know that fundraising counts as an award I didn’t know equity grants can be used to meet the high compensation criterion I had a mixed experience with my immigration lawyer, so I won’t include them here, but here are some people I would recommend reaching out to if you are interested in an O-1 for yourself. Lawyers: Bay Immigration who I have heard several excellent recommendations for Daniel Larson has been helpful to me as I work towards my EB2-NIW Alcorn Immigration is a staple of Silicon Valley immigration thanks in part to their excellent podcast Amber Davis I have seen recommended in several places Other support: Plymouth Street are a tech-enabled firm helping high-skilled candidates get to the US Logan Ullyot has helped hundreds of tech workers with their visas and is building a cool new tool for O-1 applicants Soundarya’s Unshackled community is a great resource for those who want to build their O-1 profile in a community with others If you would like to see a redacted version of my full O-1 petition, or if you are working towards an O-1 yourself, I would love to hear from you! I hope you found this helpful! At Path, I'm working on software for immigration. If you're considering applying for a visa, leave your email below to stay in touch. * indicates required Email Address * /* real people should not fill this in and expect good things - do not remove this or risk form bot signups */ Previous issue Timeline of Everything",
    "commentLink": "https://news.ycombinator.com/item?id=39143958",
    "commentBody": "How I got an O-1 visa as a software engineer (awais.io)218 points by ahussain 18 hours agohidepastfavorite174 comments hn_throwaway_99 12 hours agoCongrats OP! I'm trying to choose my words carefully, because I don't want to give the wrong impression: 1. I think it's great that OP got the visa, and it's clear (at least to me) that we should be attracting entrepreneurial types like OP to start businesses in the US. I also understand that our immigration system is hopelessly broken, and oftentimes the best one can hope to do is \"hack\" the system. So I commend you for not just hacking the system, but posting this to Hacker News! 2. It seems pretty apparent that while OP may be able to \"check some of these boxes\", he, at least to me, doesn't meet the \"Extraordinary Ability\" intent of this visa. I worry that with more spotlight on these types of applications that various political movements would try to tighten the loopholes for this visa. To expand on number 2, raising 98K from family, friends and seed investors really does not strike me as a \"nationally or internationally recognized award\". Again, clearly it is by the letter of the law (at least the rules of the USCIS), but that surprised me as a layperson. The section on \"Being employed in a ‘critical capacity’ at an organization with a distinguished reputation\" seemed even more dubious. Path, OP's startup that is nothing more than a pitch deck and 100k in funding, is \"an organization with a distinguished reputation\"??? Again, to be 100% clear, I don't fault OP at all for going this route, and on the contrary, I commend him for \"playing the game\" correctly. I just worry about the downstream consequences of \"pulling back the curtain\" and showing how the game works to a larger audience. reply skynetv2 10 hours agoparent100% agree. Someone I know received an O1 EO visa but they had worked on products that were shipping worldwide for 100s of millions of dollars, filed patents, had advanced degrees, worked at some high profile institutions, had 1000s of citations for their papers, papers published in high profile conferences and journals, and recommendation letters from CEOs, CTOs of high profile organizations from US and abroad. And they were employed in a domain which is identified as a critical technology. Their case was still far from being a high confidence case. The lawyers kept the regular process going, including NIV path. No offense to OP and still a nice achievement but OP's listed criteria are not even close to what would qualify for O1 and would not hold up under scrutiny if the letter and spirit of the criteria is applied. It is possible that USCIS is instructed to encourage issuance for start up founders, which is totally fine and is necessary to keep the innovation going. On a related note, the moment OP resigned from their L1B job, I am fairly certain they needed to leave the country in 60 days or so. It may or may not affect them when they pursue citizenship. But if I were OP, I would not advertise this and count my blessings in private. reply returningfory2 8 hours agorootparent> On a related note, the moment OP resigned from their L1B job, I am fairly certain they needed to leave the country in 60 days or so. It may or may not affect them when they pursue citizenship. Just a technical note that it won’t affect them at all. When you apply for an employment based green card you can actually have arbitrary amounts of “unlawful presence” before your most recent admission to the US. The Immigration and Nationality Act explicitly allows it. The challenge is generally recentering the US after being here unlawfully, but it seems OP already did this on their new O-1. reply marwis 6 hours agorootparentBut OP didn't apply for green card? And now they can't anymore. Pretty strange move to go from L1 to O1 since L1 allows relatively straightforward upgrade to green card but O1 is a non-immigrant visa. Correction: they can. Looks like \"non-immigrant\" can still have dual intent of immigrating. reply cqqxo4zV46cp 10 hours agorootparentprevYep. To look at this a different way: this feels like a fluke, and people should take this n=1 recount for what it is. reply dannyw 3 hours agorootparentIt’s not a fluke. The new administration is very startup friendly. They’re even more so if you’re doing anything AI/ML. Be a machine learning engineer, have published one paper, have peer reviewed code, work for a company, be paid typical MLE comp, and you meet 4/8. From my anecdota it seems like they won’t really question it. reply kelnos 4 hours agorootparentprevI'm not sure I'd agree it's a fluke. Someone I worked with at a previous company did something very similar to this, and I recall reading an account on HN a couple years back about someone who did it using different criteria than OP, but still in a way that surprised me. reply aryamaan 2 hours agorootparentCan’t find that blogpost or link anymore. I was along the lines of how I hacked usa visa system reply lebean 4 hours agoparentprevI really hope more people can use this loophole as much as possible. The lack of immigrants is lowering the standards of this country, so perhaps if the trend continues, this will no longer be a loophole but a by-the-book exhibition of extraordinary ability. reply eek2121 6 hours agoparentprevThe process has been broken forever and needs to be reformed. I don't blame any workers either, but just right/left infighting. I have no idea about solving the problem, but if I had to say without giving it thought, I think the US needs a salary/wage database for industry workers that is based on US Citizens and US dollars, and companies shouldn't be allowed to pay less to foreign workers, regardless of if they work here or elsewhere. In exchange, said company should be allowed to hire as many foreign workers as they want and ship them over here. At least then it becomes about talent rather than money, which also helps with the shitshow IT security at many companies that we have now. ...most politicians would never vote for it even though it'd be one of the most competitive laws in the world. Don't want your citizen to leave? get good. reply spullara 10 hours agoparentprevOn the other hand, a lot of O-1 visas are given to models. https://www.wildeslaw.com/services/immigration/o-1-visas-for... reply aiauthoritydev 4 hours agorootparentO1 visas were specially intended for this purpose. Hollywood and other people who provide women to rich and powerful lobbied for this. reply kelnos 4 hours agorootparentWhile I don't doubt many laws are passed with shady intentions, this assertion definitely needs some evidence to back it up. reply sumedh 1 hour agorootparentprevLooks like there is another category called Einstein Visa. Melania Trump got it. https://www.bbc.com/news/world-us-canada-43256318 reply diebeforei485 3 hours agorootparentprevNot exactly. Models also qualify for H-1B's. reply skynetv2 10 hours agorootparentprevAnd there is a specific criteria to meet to qualify for this visa. Actors also have their own list of requirements. Not every model or actor will qualify. reply marwis 6 hours agorootparentprevAnd social media influencers too. It's easier to meet extraordinary ability qualifications in non-technical professions that are more public facing. reply aiauthoritydev 5 hours agoparentprevCongrats OP! this is real american hustle. Few counterpoints > and oftentimes the best one can hope to do is \"hack\" the system None of this is \"hacking\". This is how it works and supposed to work in the law. The manuals given to USCIS agents who handle this are at best low grade pen pushers. They have zero understanding of the work they are doing and are not qualified to make these decisions in any way. The way they work is through checklists and unless you pass this checklist your intent and what you are has zero relevance. When you go deep into why these laws were created and why these specific regulations exist, you will find out that the lawmakers totally intended this. For example, it is ridiculously easy for a model who has even occasionally walked the ramp to \"hack\" the system. This was created so escorts, supermodels and side chicks of rich and powerful could be brought in easily on O1. One such lady even ended up in white house. > It seems pretty apparent that while OP may be able to \"check some of these boxes\", he, at least to me, doesn't meet the \"Extraordinary Ability\" intent of this visa. I worry that with more spotlight on these types of applications that various political movements would try to tighten the loopholes for this visa. You are not in charge of deciding who is extra ordinary, USCIS agent is. I bet if you were in charge of making such decisions you would do a better job and actually let in 10x more people. But that is not the way it is. USCIS agent makes the decision based on a relatively very objective criteria. > To expand on number 2, raising 98K from family, friends and seed investors really does not strike me as a \"nationally or internationally recognized award\". It does not \"strike to you\" is irrelevant. What matters is is it will within the USCIS's defition. Congrats to OP for writign this piece and I hope more and more people use these sort of systematic approach. reply jerrygoyal 5 hours agoparentprev> I commend you for not just hacking the system your comment implies that he did something illegal, but that is not true. > at least to me, doesn't meet the \"Extraordinary Ability\" intent of this visa. sorry, who are you? reply TMWNN 11 hours agoparentprev>I also understand that our immigration system is hopelessly broken, and oftentimes the best one can hope to do is \"hack\" the system. Just because something is difficult/time-consuming != \"hopelessly broken\". (No, kids, the Reason magazine \"What Part of Legal Immigration Don't You Understand?\" flowchart is not ipso facto proof of this, either.) There is no obligation for the US, or any country, to turn something as important as determining whether someone is eligible to enter the country into a one-click online process. One might say that the country would benefit by making the process easier, and that may or may not be correct, but that is not the same argument. reply Tallain 10 hours agorootparentWhen I read \"the immigration system is broken,\" I don't think of the arduous process of filing paperwork. I highly doubt GP was whining about the difficult and time-consuming process of filling out reams of paperwork, especially considering the context of the rest of their post where they talked about exploiting loopholes and the letter of the law to abuse the system. Context is important! No matter how high your horse is. In any case, the instant you fall just a little outside the prescribed lines is when things start to get hairy. Have a talk with any DACA recipient and you will quickly learn how broken the system can be. Or someone seeking refugee status around the time the annual ceiling is being reached. reply lmm 7 hours agorootparent> In any case, the instant you fall just a little outside the prescribed lines is when things start to get hairy. Have a talk with any DACA recipient and you will quickly learn how broken the system can be. DACA is an exception for people who were already in violation of the law, no? So even if that subsystem is inconsistent, unreliable, or totally nonfunctional, it wouldn't be a reason to say the system as a whole is broken. > Or someone seeking refugee status around the time the annual ceiling is being reached. Refugee status is meant to be a last resort for people who flee in fear for their lives. For people who legitimately need it, it's ok if the process is slow or unclear as long as it's safe (frankly, the process of granting refugee status should be slow and cautious; if the system allows economic migrants to gain an advantage by claiming a refugee status that they're not entitled to, that makes the whole system worse for everyone). The system would only be broken if legitimate refugees were getting sent back into places where their lives were in danger. reply kelnos 3 hours agorootparent> DACA is an exception for people who were already in violation of the law, no? Are you really going to try to tell me that a 2-year-old who was brought to the US by their parents and then stayed here into adulthood was \"in violation of the law\"? While I agree that DACA isn't representative of common situations US immigrants (legal and illegal) end up in, I think it's a fine illustration of how our immigration system is broken. If we can't even find a pathway to permanent residency and citizenship for people in that situation (not to mention the constant threat of DACA being scrapped entirely if political winds change), who have only ever known the US as a home... well, it's pretty easy to question the rest of the system then. > Refugee status is meant to be a last resort for people who flee in fear for their lives I think you underestimate the quantity of political persecution outside the US. Remember that this isn't just prominent public figures who have tried to stand up against an oppressive regime and failed. Any average citizen in a situation like that could end up in a precarious situation like that. And political persecution is just one reason someone might fear for their lives to the point where they believe they need to leave their country. But really, we don't need to limit ourselves to DACA or refugees to find serious issues with the US immigration system. The H1-B visa is broken; it's gamed by \"consulting\" companies to mint modern-day indentured servants. The green card process is ridiculous; imagine applying for permanent residency and being told that the wait time meant you'd get it after you were dead, just because you were born in a particular country, not because of anything else about you that actually matters. reply jksflkjl3jk3 3 hours agorootparent> Are you really going to try to tell me that a 2-year-old who was brought to the US by their parents and then stayed here into adulthood was \"in violation of the law\"? Yes? Why would you argue otherwise? reply Tallain 7 hours agorootparentprev> DACA is an exception for people who were already in violation of the law, no? So even if that subsystem is inconsistent, unreliable, or totally nonfunctional, it wouldn't be a reason to say the system as a whole is broken. Let me make sure I understand the point I think you're trying to make. Because people with DACA status were in violation of the law at some point in their lives, it's acceptable to thrust upon them a broken system? So, they deserve it? I just want to be sure because it sounds like you're saying it's acceptable for this system to mistreat or otherwise neglect a subset of people because reasons. Setting aside the fact that DACA status is Deferred Action for Childhood Arrivals, namely, people brought to this country as children at a time in their lives when they could not have known what was happening let alone had the agency to say, \"hey wait, have you tried the normal way to immigrate into this country, mom and / or dad?\" The point I was trying to make with DACA is that the system is broken, not because of long wait times for paperwork, but because at any point the entire thing can be taken away. DACA status has been threatened multiple times. Imagine living a life you didn't ask for, not native to the land in which you live, and not native to the one you were forcibly taken from, and living under the shadow of the threat of being forcibly taken back to a strange country. That's one part of the system that is fundamentally broken, and because these people are \"in violation of the law\", they deserve it? The machine doesn't work unless the parts do. Or to quote Solomon Burke, if \"one of us are chained, none of us are free.\" It's easy to dismiss a single piece that doesn't impact your life directly. \"Great! The illegals have a hard time with immigration. Maybe they should not have broken the law, then!\" But to many it is their entire lives, and through no fault of their own. It's this contentment with injustice elsewhere that's utterly infuriating and really shines a light on the privilege of some on this forum. Not even going to touch the \"economic migrant\" bit. Sounds a little too close to a dog whistle to me. Not even sure why I felt the need to engage this much. reply kelnos 3 hours agorootparent> \"Great! The illegals have a hard time with immigration. Maybe they should not have broken the law, then!\" But to many it is their entire lives, and through no fault of their own. This is the thing that really gets me. There's all this hand-wringing about how people in the country illegally should just accept that they did it \"the wrong way\", and oops, well, I guess that means they're not worthy of being treated as a human with wants and needs and dreams anymore. Because what, they crossed an imaginary line on the ground someone drew, in a way that didn't match up with the rules a bunch of out-of-touch people decided on? Not just out-of-touch, but people who actively use immigration reform (or the lack thereof) as a political weapon. It's so easy for someone (such as myself) who was born in the US, whose family has been in the US for generations, to just not get what a big deal all this is. I will likely never have to worry about feeling unsafe in my own country, feeling like I have absolutely no opportunity to house, clothe, and feed myself. And if I did, I'd still have options! I know it can be hard for some of us to try on the shoes of someone who believes that the only way for them (and their family) to have a future is to pack up whatever they can carry and risk their lives to \"sneak\" into another country where they will have better chances. But I really wish people would show more sympathy and empathy toward people in that situation. reply hn_throwaway_99 10 hours agorootparentprevThank you, said it better than I would have. reply TMWNN 10 hours agorootparentprev>especially considering the context of the rest of their post where they talked about exploiting loopholes and the letter of the law to abuse the system. I didn't read the original post that way. If the poster stayed within the rules and—more importantly—immigration officials agreed with his interpretation of the rules, who am I to gainsay their decisions? To put another way, this is why my response was to hn_throwaway_99's comment, not to the original post itself. >Have a talk with any DACA recipient and you will quickly learn how broken the system can be. Or someone seeking refugee status around the time the annual ceiling is being reached. Again, you are coming at this from the perspective that something like DACA must exist, and therefore ought to be improved/eased/etc. The a priori argument that a country must accept refugees, and the only answer to the question of \"How many?\" is \"As many as possible\". This is the same entitled line of thinking as hn_throwaway_99's declaration that a complex system with many moving parts that operate over a long period of time must therefore be \"broken\", with the implication that the \"fix\" must be to make it as close to a one-button process as possible. reply DrSAR 10 hours agorootparentThe 1951 UNHCR convention [1] would like to disagree that only an entitled line of thinking presupposes rights of refugees. [1] https://www.unhcr.org/about-unhcr/who-we-are/1951-refugee-co... reply remarkEon 5 hours agorootparentThe entitled line of thinking is that everyone who comes from a country where things are shitty is a \"refugee\". That's the problem with the way this discussion is framed. reply cscurmudgeon 5 hours agorootparentprev1. They didn't say ANY refugees in the country is entitled thinking. They meant as MANY as possible is entitled. Wich is a reasonable take. 2. Also, just because a UNHCR convention says it, doesn't mean it isn't entitled. (I would say the UN is an exemplar of entitlement. The US provides the largest budget while countries like China get an equal vote in vetoing.) 3. Everyone coming illegally is either a) a refugee, b) an economic migrant or c) a threat. Every country has the right to a reasonable process to determine which bucket someone falls into. Even the 1951 convention you linked allows for that. The US's process is actually less onereous than the EU's. The EU won't grant you asylum if you come through a safe country. The US has no such concept. You can be a single military aged male from China but you will still be validly considered for asylum just like a child or 80 year old from Afghanistan. reply scheme271 8 hours agorootparentprevI think the hopelessly broken is referring to things like a 50-70 year waits for qualified people to get a green card if they're born in india, or stuff like it taking 1-2 years for someone married to a us citizen to be allowed to join their spouse in the country (and there's a decent chance they'll be denied a visitor visa to see their spouse during the wait) and the situation is even worse if you have a green card and marry a non-us citizen. reply aiauthoritydev 4 hours agorootparentprev> There is no obligation for the US, or any country, to turn something as important as determining whether someone is eligible to enter the country into a one-click online process. One might say that the country would benefit by making the process easier, and that may or may not be correct, but that is not the same argument. No on really cares about US government, federal laws and other wanking that murica first types might engage into. Forget about \"process\". Literally no immigrant cares about the laws or process either and no one will. It is all about people going after their dreams and aspirations. If the process is not reasonable it will be hacked, people will cross border on foot, break walls and swim through water or jump off the ship. The question is whether the law wants this sort of outcome or would rather simplify the process. tip: Government must spread its legs and accept the fate willingly otherwise it just gets harder for the government. In the context of government this is a good thing. reply trealira 4 hours agorootparent> tip: Government must spread its legs and accept the fate willingly otherwise it just gets harder for the government. In the context of government this is a good thing. This is an off-putting analogy. It sounds like the rape of a woman. reply TMWNN 1 hour agorootparentThat's exactly what aiauthoritydev intended: \"It's going to happen, so you might as well make it easier for it to happen\". And how Americans interpret the meaning. reply kelnos 3 hours agorootparentprevOur immigration system is indeed hopelessly broken. While there's a lot here about O-1 being fairly objective and checklist-based (no idea if that's actually true, just taking some comments here at face value), other visa situations can be arbitrary and opaque. And don't get me started on the ridiculous, arbitrary, capricious green card process. > There is no obligation for the US, or any country, to turn something as important as determining whether someone is eligible to enter the country I have the opposite opinion. Borders should be much more open, and people should stop whining so much about immigration. Nearly everyone -- aside from the relatively small number of Native peoples -- in the US is an immigrant, or the descendant of immigrants. We are all here because our ancestors forced their way here, killing and destroying wherever they went. The idea that we have some natural right to decide who comes and goes is entirely laughable to me. I get that we should have some controls in place for at least logistical and security reasons. But our immigration restrictions go far beyond that. And again, let's not pretend it's some natural right of ours to do. We get to do it because we've had more guns than other people who wanted to be here and \"own\" the land. Also remember that this is not the normal or common state of things. The internationally-recognized passport system we take for granted has existed for barely a century[0]. Before that it was a patchwork of various systems (sometimes just the honor system) and much of what we'd call \"illegal immigration\" today was the status quo. On top of that, the US's restrictive immigration system has existed for an even shorter time; when my great-grandparents immigrated about 115 years ago, all that was required was they enter through an official port of entry and truthfully declare who they were and where they were from. They didn't have to have a visa, or apply for permanent residency. My great-grandfather became a citizen about 15 years later shortly after applying and providing a record of his original arrival in the country. Meanwhile, today, adults who were brought here by their parents as toddlers (\"illegally\" -- like a 2 year old has the capacity to do something illegal) can't even get legal residency or citizenship. If that's not hopelessly broken, I don't know what is. The funny thing is that we're talking about this in the context of someone suggesting that OP \"hacked\" a broken system to get a visa. But it sounds like the O-1 system is pretty functional and is working as designed. There's a list of criteria, and a lot of explanation as to what is and isn't covered under those criteria. You document, make your case for why you fit the criteria, and apply. USCIS makes a decision (and pretty quickly, at least in this case!), probably based on a checklist, by people who likely don't really understand the nuances of any particular industry or profession or academic discipline to make any sort of value judgment on the application, beyond the checklist and the case being made. That... seems exactly how it should be? A transparent process with well-defined criteria for acceptance? (You may disagree with the criteria, or the list of things that qualify, but that's a different matter.) [0] (The idea of passports have existed at least for a couple thousand years, of course, but in the earliest days they were more like a hand-written letter asking, \"please allow my subject, Bob, to pass safely through your lands, signed, King Larry\".) reply TMWNN 1 hour agorootparent>Borders should be much more open I don't disagree! I think the US ought to have open borders with Canada, for example, with immediate work rights for anyone who has been a citizen for, say, 18 years. In an ideal world we would be able to institute the Wall Street Journal's longtime mantra of \"We shall have open borders\". But that cannot happen without corresponding changes to domestic welfare policies, among other things. >I have the opposite opinion. Borders should be much more open, and people should stop whining so much about immigration. Nearly everyone -- aside from the relatively small number of Native peoples -- in the US is an immigrant, or the descendant of immigrants. We are all here because our ancestors forced their way here, killing and destroying wherever they went. Sorry, you are going to have to do better than this sort of \"We live in a society\"-level rhetoric. If Burundi tomorrow invades the US with superior military forces and every Burundian moves here, I may not like it but that's how things have worked for the entirety of human history minus the last few decades. >On top of that, the US's restrictive immigration system has existed for an even shorter time; when my great-grandparents immigrated about 115 years ago, all that was required was they enter through an official port of entry and truthfully declare who they were and where they were from. Those stories always omit the details. Every single person who came through Ellis Island * had passed a medical inspection * had proof of having enough resources to pay for their upkeep in the US, or a US financial sponsor guaranteeing same * was turned away if failing any of the above tests, with no possibility of appeal I, for one, am very much in favor of reinstating such barriers to entering the US. PS - One more thing: Every single person who came through Ellis Island was coming to a country with an enormous demand for unskilled labor. This is no longer true. >Meanwhile, today, adults who were brought here by their parents as toddlers (\"illegally\" -- like a 2 year old has the capacity to do something illegal) can't even get legal residency or citizenship. If that's not hopelessly broken, I don't know what is. The parents of those toddlers broke the law, for themselves and for children they brought along. That does not mean that the toddlers themselves are criminals. That also does not mean that they are entitled to the legal and financial rewards of US residency, either. Or that a president can with the stroke of a pen but without the concurrence of Congress create an entire legal infrastructure permitting their legal residency, one which the subsequent president somehow cannot dismantle in the same way. I hope that some process can be devised to grant such people legal US residency, but it has to occur through a law duly passed by Congress, and in the context of other changes; especially, but not only, a strengthening of the southern border and crackdowns on visa overstays. >The funny thing is that we're talking about this in the context of someone suggesting that OP \"hacked\" a broken system to get a visa. But it sounds like the O-1 system is pretty functional and is working as designed. As I said elsewhere, I don't disagree with this either! My disagreement was and is with the reply by hn_throwaway_99 to the original post stating that someone being able to use the O-1 system in this way is proof that the US immigration system is \"hopelessly broken\", by which of course he means \"Requiring such steps is outrageous and unfair\". I would love a system in which everyone entering the US had to comply with the O-1 or some equivalent thereof. reply drtournier 15 hours agoprevGlad you made it OP, congrats! As an immigrant in the US I went through the \"Extraordinary Ability\" path and the process was a journey of pain and anxiety. Many roundabouts with a lawyer that promised me expertise in the process and it ended up with a NOID (Notice of Intention to Deny - something like that) from USCIS. My wife and I had to study the USCIS manual page by page and re-wrote almost all documentation from the lawyer. It wasn't easy but we made it. reply bearjaws 13 hours agoparentUnfortunately immigration law is full of quack attorneys who abuse immigrants. If you feel you were unfairly treated or scammed, you should report your lawyer to their local Bar organization. Most will take it very seriously - especially in immigration, a repeat offender will often lose their license. reply swalberg 13 hours agorootparentAt the same time, the political climate and even the person you get reviewing your application could make a difference. I was denied the first time I applied for PERM after the officer combed through the supporting paperwork to find problems. Was it my lawyer's fault? Did my employer make a mistake in the job search? Was it because it happened in the Trump years? Who knows. reply neuralengine 13 hours agorootparentMy application for EB2-NIW was recently denied for totally inappropriate reasons. The process has a randomness component to it, what you can do is to maximize your chance of success but it’s still a chance. reply apapapa 14 hours agoparentprevHow long did the process take? I became a citizen without an attorney and from start to finish it was about 5 years... Different process used though (got married). Got a pile of paper about 2 inch high from all the forms I had to fill, mail that I sent and received, etc... Painful process. reply drtournier 14 hours agorootparentOur case took around 14 months for the EB-1 from the first call to lawyer to the green card in our mailbox. reply apapapa 12 hours agorootparentHow long including citizenship, if that was the goal? reply j7ake 13 hours agorootparentprevDoes this timeline depend on country of birth? reply swalberg 13 hours agorootparentYes, you'll want to google for the \"Visa Bulletin\" to see the current dates for different countries. India and China are currently backlogged. reply neuralengine 13 hours agorootparentprevIndians applying for EB-2 have a waiting time of 200 years based of the total number of available visas per year and pending cases. reply ahussain 14 hours agoparentprevOP here: Sorry that you had a bad experience, but glad that you made it through in the end! I would love to talk more about your experience if you're up for it. My email is in my bio. reply RustyRussell 4 hours agoprevFor those who don't know the jargon: an O(1) Visa gives you constant-time access to the US. reply anandvc 1 hour agoparentThank you! This made me laugh out loud! reply tlb 10 hours agoprevThanks for talking publicly about this. Thousands of interesting people take this route (also, me) but not many blog about it. My lawyers originally described this category as \"for internationally recognized people such as Nobel prize winners\". That seemed a bit out of my league. But they issue 13k O-1 visas per year, so it's really the top (in some sense) 13k people who want to immigrate to the US each year. So I applied and got it. The annoying part is that it demands legible recognitions: awards the immigration officers have heard of, and recommendation letters from people with Titles in Organizations they've heard of. But they seem to know something about the STEM world. They know about the International Math/Physics/Chemistry Olympiads, and the ACM Programming Contest, good universities, and reputable tech investors. If I can offer a tip, it's the following. You know what's impressive in the STEM field. The immigration officer also has some experience of what's impressive. Your lawyer has the least idea of the 3 of you. So don't be diffident or self-deprecating with your lawyer! You have to tell them what you've accomplished and how notable each thing is. reply elevatedastalt 10 hours agoprevI find it insane that people think it's a good idea to flaunt how they got these things. Good for OP that he gamed the system, I have no ill-will for him. But the smart thing to do would be to keep quiet and enjoy the legal status, not write a blogpost showing how flimsily it was obtained. If I were the USCIS I'd see this as a sign that this whole visa application was made in bad faith. reply starshadowx2 9 hours agoparentThere's a difference in flaunting and explaining or sharing. They've just laid out the steps they took in a clear manner and provided information about it all, assuming it might help other people in the same situation. They're not saying something like \"I cheated the system and here's how\" or \"Look at how smart I am because of what I did\". reply elevatedastalt 8 hours agorootparentI would liken it to tax evasion. It's not illegal, and I absolutely don't mind people doing it. But I'd not publicize it or write a whitepaper on how I am doing it. reply mym1990 7 hours agorootparentTax evasion is most definitely illegal. Tax avoidance is probably what you mean. While the two sound similar, they are very different. reply vanjajaja1 4 hours agorootparentprev'outstanding' is a judgement. seems the criteria people in this HN comment section have is not aligned with the arbiter of the visa (us gov, described by OP). Its not shady for the OP to publish exactly what he did and what result he got, and I don't see any shady actions in his write up reply abigail95 5 hours agoparentprevUSCIS is the one that approved it? Surely they know more about the situation than a blog post. reply dnissley 10 hours agoparentprevWhat seems illegitimate about this application? reply dappermanneke 8 hours agorootparentprobably the lack of extraordinary ability reply imajoredinecon 7 hours agorootparentSpeaking personally an American, any smart person building useful stuff is welcome in my country. That alone _is_ extraordinary ability, in my opinion (can’t speak to the intent behind the law). reply thruway516 5 hours agorootparentprevYou're reading the term too literally. USCIS has set the terms for what it means and the same USCIS has determined that op meets the criteria regardless of what you think it should mean. reply vanjajaja1 4 hours agorootparentprevthe judge of 'extraordinary ability' for O1 visa is not some person writing HN comments, its the people who run the visa approval process reply electrondood 7 hours agorootparentprevI've sincerely wondered how Melania Trump secured one, for the same reason. reply latency-guy2 7 hours agoparentprev> Good for OP that he gamed the system, I have no ill-will for him. But the smart thing to do would be to keep quiet and enjoy the legal status, not write a blogpost showing how flimsily it was obtained. So, really we should hate OP and probably ensure that his current visa gets voided through all legal means, hand him the NOIR he deserves, and then someone who actually deserves it can live in the US. reply cheonic730300 7 hours agorootparent> So, really we should hate OP and probably ensure that his current visa gets voided through all legal means, hand him the NOIR he deserves, and then someone who actually deserves it can live in the US. Yes. After all, when companies or rich people _legally_ avoid paying taxes, everyone says “no they still need to pay, it’s not fair”. Yet when it’s about someone “trying to improve their life” (in other words, poor), all of a sudden we should let it slide? Okay reply roenxi 7 hours agorootparentprevHuh? Are you suggesting that OP is a net negative to US experience? The whole system is basically one big yea or nay on whether someone can stay in the US. OP looks like a pretty easy yea for any country. Maybe he didn't get that yea through a black letter reading of the law, so what? The visa-issuers think it is fine. The outcome is good. So in this case the system could be said to be working. Although the US visa system overall looks a bit silly. reply latency-guy2 5 hours agorootparent> Huh? Are you suggesting that OP is a net negative to US experience? This is what you are suggesting. Further, \"net negative\" means nothing when talking about O-1 visa, which is quite literally a game to get very impactful people into the US. Being \"net positive\" is not enough. > Maybe he didn't get that yea through a black letter reading of the law, so what? The visa-issuers think it is fine. The outcome is good. So in this case the system could be said to be working. Investigators can make redeterminations. That is why a bunch of people do get booted out of these visa programs, and should. You do not stop being judged upon receiving a visa. A system that rubber stamps \"yes\" to a problem in 100% of cases where 99% is cost efficient, but it is not a system that works. That system needs to account for bad data, and should issue \"no\" when it matters. reply angarg12 13 hours agoprev> May 2022 - Left my SWE job at Wave and incorporated my own startup called Path (a Delaware C corp) I was permitted to remain in the USA, since I was not employed by Path yet. My understanding is that it is permissible to do exploratory work on a new startup as long as you are not employed by that startup, and your previous visa has not expired. It was during this time that my cofounder and I raised money for Path. Note: If I had left the USA during this time, I would not have been permitted to re-enter on my old L1-B visa. This sounds iffy. I'm in the US on a L1-B visa as well, and my company went through rounds of layoffs, which concerned me. All information I've read, including the immigration team from my company (Big Tech), points out that if I lost my job, I would have had a short time to leave the country with no chance to find other jobs. Unless I'm reading too much into it, it sounds like OP spent some time in the US in an illegal status, until that gap was bridged with the new visa. reply paxys 12 hours agoparentYou are allowed to remain in the country for up to 60 days after your employment ends. The author doesn't mention how long they stayed, but it is possible that the \"exploratory work\" was done within that period. reply elevatedastalt 8 hours agoparentprevA lot of people do questionable things like this with some hand-waved legal reasoning. Most are lucky that it doesn't bite them in the ass. But I know of cases where it did. For eg. someone I know of was banned from entering the US for 10 or so years because he worked on his startup under a B1 visa. reply beaeglebeached 16 hours agoprevI have a dumb question but how often do tourist visa overstayers get deported while running their own business under an incorporated ITIN? There's not even an I-9 check for non-employee income. There's got to be millions of people doing something like this or as 'independent contractors' considering how trivial it is and the obvious completely broken immigration system that demands these kinds of hacks. reply paxys 15 hours agoparentThere may be \"millions of people\" doing this, but they are running street carts and house cleaning services, not tech companies. reply qingcharles 15 hours agorootparentYou are wrong. Only from personal experience. I have an informal waiver from ICE right now, and I'm running a tech business, but I'm deportable and would ordinarily be in immigration jail except I'm in a sanctuary state. reply paxys 15 hours agorootparentUnless you know of millions of other people in the same situation as you I'm not sure what your anecdote proves? reply bitxbitxbitcoin 14 hours agorootparentA single example (what you are calling an anecdote) is all that’s needed to disprove your blanket statement - he provided it. reply notpushkin 14 hours agorootparentI don't think it was a blanket statement. He's claiming that the millions of people GP is talking about are doing low-skill work – suggesting that there might be tech workers, too, but that there are less than millions of them. reply rmbyrro 12 hours agorootparentprevWhy would you live illegally in the US if you run a tech business? I mean, you can sell tech services to the US market living anywhere legally!.. reply qingcharles 7 hours agorootparentI'm trying to get my immigration status fixed. I was on a green card via a K-1 visa, then I sat in jail for 10 years on false criminal charges waiting for trial. I have since been released and the charges dismissed, but my green card got put into a weird state. There's more to it, but I'm hoping to have my legal status back again by the end of the year. reply throwaway1507 12 hours agorootparentprevPlease, tell me how to do this. My (SW dev) business so far relies heavily on personal relationships built over long periods of time. I wasn't able to find any other way. I don't have much disposable income for online marketing professionals and ads (I had but it all went to waste). reply rmbyrro 12 hours agorootparentLinkedIn is great. You'd be surprised how many welcoming people you'll find if you communicate like a real person. But be prepared and don't take personally when someone ignores you or give a bad response. Just move on. Do extensive research first and make sure there is a real potential that what you offer can be valuable to them. And communicate that. Smaller businesses are much easier to sell to. Startups are even easier, but you have to be sharp, deliver very quickly, and be prepared for a more dynamic environment. I've sold SWE services as a solopreneur to customers in the US, UK, even Hong Kong. All through direct messages on LinkedIn. reply throwaway1507 12 hours agorootparentDid you have any issues regarding your timezone? I had some good leads there (and some success too, but always with local people) but the timezone thing killed it every time. reply wil421 16 hours agoparentprevWhy would you go through the trouble? Most people I worked with in restaurants would just find someone’s name/ssn to use, put they had 10 children, and never ever file taxes. I think there was a shady underground way to match illegal immigrants with SSNs. Or they just networked heavily in their communities. reply 101008 15 hours agorootparentI can imagine this being true but at the same time it's so weird. I tried to open an account with Chase and Bank of America and they ask me for SSN, and I can't get one because I am from outside the US (I just want to get one to have my freelance money in an actual bank and not Paypal/Payoneer/an app). There are companies that provide a LLC with a SSN for just a fix payment of $400, but I am sure it comes with a lot of taxes issues that I don't want to care for now. So, how can the financial system rely on SSN if they can be sold for inmigrants? reply gamepsys 15 hours agorootparent> There are companies that provide a LLC with a SSN for just a fix payment of $400 This has to be a TIN (Tax Identification Number) not a SSN (Social Security Number). As far as I know SSNs are only issued to people. reply qingcharles 15 hours agorootparentprevLegal immigrants get an SSN. I have an SSN it is just suspended or something. If I try to use it online it causes 500 errors everywhere as whatever status is attached to it isn't handled by any financial site. reply ceejayoz 15 hours agorootparentprevThey won't use a Chase account. They'll get paid cash or a physical check they can take to a check cashing place. reply beaeglebeached 15 hours agorootparentWhy wouldn't they? They'd probably just use the business tin as the taxable account owner and then their real foreign passport as the UBO for KYC. If they can't do that it would surely break the wheels of industry as foreign owned US businesses need US bank accounts. IIRC banks need a ITIN or SSN + passport or ID of the UBO reply ceejayoz 15 hours agorootparentDocumented immigrants will get a ITIN and/or EIN. Undocumented immigrants are far more likely to go the... undocumented route. reply petronio 11 hours agorootparentUndocumented immigrants can get an ITIN, and many do. A lot of the time the ITIN will be used where it's allowed (opening bank accounts) and a counterfeit social security card where it's not (applying for employment). reply fooker 8 hours agorootparentWouldn't that, by definition, turn them from undocumented to documented? reply 101008 15 hours agorootparentprevYes but my question was not about how they open a Chase account, but why Chase requires a SSN if SSN are sold in a black market (according to the previous comment) reply smeej 15 hours agorootparentChase requires more than just the SSN. Chase requires you to prove your identity matches the person whose SSN you submit. They require it as part of a larger picture, not in isolation. (Employers are supposed to verify ID too, but they're not scrutinized as heavily as a major bank like Chase.) reply tossedacct 15 hours agorootparentprevChase uses the SSN to look for a bad banking history. reply Aspos 12 hours agorootparentprevBofA happily opens accounts for those with no SSN as long as they show up with somebody who has. And a person with a driver's license and SSN must confirm that the customer resides with them. reply qingcharles 15 hours agorootparentprevAs an illegal, the biggest problem is.. how would I get ID with matching photo that I can use to sign up for web sites? A huge amount of web sites now want to ID verify with government ID and selfie. I have to get other people to do this for me. reply romafirst3 15 hours agorootparentCalifornia does not require proof of legal status to get a driving license. I think the license is just eligible in California afterwards. I had one for a while while I was waiting for my visa to be processed. reply romafirst3 15 hours agorootparenthttps://www.dmv.ca.gov/portal/driver-licenses-identification.... reply alwayslikethis 15 hours agorootparentprevMany 'illegal immigrants' also entered legally with a visa that allows them to get a real SSN, like most J1 exchange scholars or students. These cards usually show a line saying not for work except for permission, but there is probably an underground network for faking a normal one. reply gumby 14 hours agorootparentprevIt's short-sighted nonsense that undocumented immigrants can't get SSNs. They should be issued SSNs and pay taxes as usual. They are working, and the IRS should be collecting taxes, nothing more, nothing less. If they aren't paying taxes, someone else has to make up the difference. Likewise I want them to get licenses if they can pass the driving laws test, and should be able to get insurance. I don't want to be hit (or hit and run) by an uninsured driver. They and their kids should be getting the same vaccines someone with a legal right to live here does, under the same terms. This is basic public health that helps everybody. This is 100% orthogonal to whether ICE should be pursuing and deporting this or that person. They current system makes the rest of us less safe -- and that's not even getting into the massive impingement on the human rights of law abiding folks due to the misincented immigration (and other) laws and their enforcement). reply thruway516 5 hours agorootparentI think its partly about making day to day existence hard enough in the hope that they will self-deport, without making the laws outright inhumane reply petronio 11 hours agorootparentprevUndocumented immigrants can get an ITIN, and many do use them to pay taxes. The IRS really doesn't care where you got your money from, so long as they get their cut. Where undocumented immigrants won't be able to file their taxes is if they used a counterfeit SSN to be employed, but even in those cases they pay anyways through standard withholding. Most Americans don't know you can adjust withholding, nevermind undocumented immigrants. reply hasty_pudding 15 hours agoparentprevIs the immigration system broken? Or are there just billions of Indian and Asian people? reply j7ake 13 hours agorootparentThere are 750 million Europeans , and maybe 4.5 billion Asians (6 times more in Asia than Europe). But the wait and difficulty is much more than 6 times if you’re Asian versus if you’re European. reply tristor 12 hours agorootparentDo you think that might have to do with relative demand, because most Asians would prefer to emigrate elsewhere, and most Europeans would not? If you combine with that the relative population differences, it creates a striking demand curve. reply toast0 7 hours agorootparentRelative demand is a factor. But a larger factor is that many of the immigration categories that are numerically limited have the same limit for all countries, and India and China have a lot larger population than any of the many countries in Europe. reply paxys 12 hours agorootparentprevNow run the same numbers but looking at just visa applications instead of the entire population of these regions. reply hasty_pudding 11 hours agorootparentprevimmigration should be on a country by country basis, not on a population basis. so if your country has tons of people (for whatever reason), that's kind of your country's fault and not the immigration systems fault. while there are benefits to a culture of having 12 kids theres also negatives. Europeans seem to have moderate family sizes for some reason. why is that? reply hasty_pudding 4 hours agorootparentIts a mystery why I was downvoted reply kulor 16 hours agoprevThank you for sharing. It's useful to know that an O-1 is a theoretically viable route. Some serious creativity in using fundraising under the category of \"Nationally or internationally recognized awards\" reply elevatedastalt 10 hours agoparentUnfortunately a lot of people show VC funds for their startup to clear that bullet point for O-1 or EB-1a I think the USCIS will wisen up to it pretty soon and plug that hole. reply returningfory2 8 hours agorootparentI suspect USCIS is consciously allowing it. They have large amounts of discretion and the President can generally get USCIS to exercise this discretion to fit some policy goal. Under Trump it was making it harder to be an immigrant; under Biden it’s making it easier to be an entrepreneur specifically. reply Agingcoder 15 hours agoprevUnless I’ve misunderstood something, a phd holder who has published papers and worked in tech/banking/etc with a high salary can get that kind of visa ? reply ahussain 14 hours agoparentThe high salary is benchmarked against other people doing the same job, in the same geographic area. So you would have to by at a high-tier tech/banking job. reply neuralengine 15 hours agoparentprevEither conditions are typically sufficient, not necessarily both. Still, O-1s still have significant limitations. You can only work for the employer who sponsored you, for example. That means no additional freelancing. reply beaeglebeached 15 hours agorootparentWhy not just start a business, be 'firable' using the article's strategy, then hire yourself out as a contract company thus be able to work for anyone while technically only working for your own sponsor company. reply nsajko 15 hours agorootparentprev> You can only work for the employer who sponsored you, for example. Nice, just like in the good old days with serfs and feudal lords. reply wildzzz 14 hours agorootparentThis applies to many different visas. The point is to ensure you are actually employed and not just here to subsist off of social services or working for illegal enterprises (i.e. organized crime). You can change jobs but the new employer must agree to sponsor you. Visas are not permanent residencies or citizenship. If you just want to tour the country or take university classes, get a tourist or student visa. If you did all the work to prove your \"extraordinary abilities\", you should be putting them to use. And yes, perhaps freelance work should be eligible for employment status but I feel that can be accomplished through some creative structuring of a tiny contracting firm. I can easily compare an O-1 visa to being accepted to a prestigious university. You proved you are smart and talented enough to be there but if you don't actually put in the work (get good grades/stay employed), you get kicked out so that someone else just as smart and talented can take your place. reply hasty_pudding 15 hours agorootparentprevonly in America. in their home country, they're allowed to work freely. reply coherentpony 14 hours agorootparentprev> Nice, just like in the good old days with serfs and feudal lords. I can't tell if you're being sarcastic or not. Serfs were largely agricultural workers bound under the feudal system to work on their lord's estate. Foreign workers aren't serfs. They're not bound to a particular estate, nor do they typically execute agricultural work. They have the right to collectively bargain their salary, working conditions, and benefits. They are free to resign their position and leave the country. The O-1 visa is a temporary worker visa. The expectation is that folks on a temporary work visa work temporarily. That is, there is no intent to immigrate. You are also not bound to a particular employer. You're only bound to that employer on that visa instance. You can, if you like, apply for another O-1 visa sponsored by a different employer. There are, in some cases, restrictions on work even for folks that have the right to work and live in the US. For example, if company A contracts out work to company B, it is often not permitted for company A to offer workers at company B full-time positions at company A because of the existence of the contract. If someone freelances for company A they often can't also hold full-time positions at a competitor to company A. Is this feudalism? Of course not. TL;DR: Freedom to work does not imply or mean, \"I can do whatever work I want for whoever I want.\" There are rules, regulations and laws present for a reason. We can debate whether or not those reasons exist in good faith, but equating \"I can only work for one specific employer on a temporary work visa\" to serfdom is awfully disingenuous, in my opinion. reply scottydog51834 16 hours agoprevSlightly off-topic, but I am curious how difficult it is in general to receive an entrepreneurial visa to the US? I chatted with a potential co-founder, here now for a masters, who would seek out this visa if we were to start a company together. reply otoburb 16 hours agoprevAppreciate sharing this specific immigration journey so far. The biggest positive factor seems to be that the poster was already in the US on an L-1B which also counted towards one out of four of the O-1 eligibility criteria (specialized knowledge). reply dannyw 15 hours agoprevO1 isn’t that hard with a good immigration lawyer. It’s about checking boxes, not extraordinary talent. reply jonny_eh 15 hours agoparentThey just need the guts to do it. reply hasty_pudding 15 hours agoparentprevif you're not hacking the immigration system, are you really an engineer?? reply neuralengine 13 hours agorootparentIt is a system with a feedback time of months-years. At these time horizons, you can’t do rapid iterations, and you have to be extremely risk-averse. The system is also indeterministic so not conducive to hacking. reply dannyw 3 hours agorootparentYou can get an O1 in a couple weeks with premium processing. Pretty sure you also get a rubber stamp if what you’re doing is AI/ML related. reply shutupnerd0000 3 hours agorootparentprevYou missed the joke reply wslh 13 hours agorootparentprevA friend of mine is an actor, not famous at all but was given this visa. Not and engineer at all but has some type of hacker mind: really stubborn and being resourceful in some scenarios. reply skynetv2 10 hours agoparentprevYou are very much mistaken. I have seen someone go through this and it is very hard. You need to prove your contributions to an area of interest to the US, and that it meets the extraordinary qualification. It is ok to not know but maybe dont make such statements. reply epcoa 9 hours agorootparentWell I do know, and I have close associates with very mundane qualifications, masters from non T50 school in a CS related but not CS field, working for non-FAANG large corporation as \"senior\" (think 2-3 yr exp) IC with good legal of course that obtained an O-1. I also know those with T30 masters degree, much more impressive on paper but working for at the time some dumb startup that were denied. They are now doing something extraordinary outside the country. Sorry but the definition of extraordinary qualification is very capricious to make the claim about it being \"hard\" a bit meaningless. There are a lot of factors, but it isn't necessarily hard to obtain. reply elevatedastalt 7 hours agorootparentprevI mean you are literally commenting on a thread about a blog post where someone got it despite having any \"extraordinary ability\" in the generally understood sense of the term. reply j7ake 16 hours agoprevDoes O-1 bypass the country by birth quota for green cards? Or is this just a visa not permanent residency? reply the_svd_doctor 16 hours agoparentMakes no difference. It's a temporary status, not permanent residency. It potentially helps you slightly for EB-1 (permanent residency for \"extraordinary people\") since it has similar requirements, and EB-1 has slightly better quotas than EB-2 (because fewer folks qualify ; EB-2 is for skilled workers like your typical tech employee). If you're from India it's still a very long way out. reply otoburb 16 hours agoparentprevThe O-1 is a nonimmigrant visa[1], but my understanding is that it's also one of the few nonimmigrant visas that USCIS allows for dual-intent consideration. Eventually, you have to go through additional steps to convert to an immigrant visa (e.g. be sponsored by your (own) company, or marrying an American, etc.). [1] https://www.uscis.gov/working-in-the-united-states/temporary... reply CobrastanJorji 16 hours agorootparentRight. The O-1, the \"extraordinary ability\" visa, is easily confused with the EB-1, sometimes called the \"Einstein visa.\" The latter is for those seeking permanent residency, and the former is not. The EB-1 became notorious a few years back in some circles when it was pointed out that the first lady had gotten one for modeling, but like this article points out, the criteria to get one is not as insurmountable as it might seem from the official examples, which will suggest things like Olympic medals, Pulitzer prizes, etc. Being on magazine covers and making a lot of money makes for a pretty solid case to acquire one. reply x86x87 16 hours agorootparentEB-1 is not a visa. It's a category for permanent residence application. It's not an Einstein \"visa\" by any means. https://www.uscis.gov/green-card/green-card-eligibility/gree... You can have extraordinary abilities or you can be a manager at bigcorp. Yes, being a manager will most times qualify you for an EB-1 bracket. reply js2 15 hours agorootparentUSCIS calls it a visa in the first sentence: https://www.uscis.gov/working-in-the-united-states/permanent... You may be eligible for an employment-based, first-preference visa if you are a noncitizen of extraordinary ability, are an outstanding professor or researcher, or are a certain multinational executive or manager. reply elevatedastalt 7 hours agorootparentThere is a difference between what USCIS calls a Visa and what the rest of the world actually means when they say a Visa. For eg. Green Cards (== aka Permanent Residency, which no one in their sane minds calls a Visa), are actually issued against what USCIS calls a \"visa number\". So OP is correct that O-1 is a visa (as that word is understood generally in the world), and EB-1A is a category of Employment Based Permanent Residence filing. reply paxys 15 hours agorootparentprevIt wouldn't be the first government website with confusing wording. They call it visa, but practically \"EB-1 visa\" = green card. There's no intermediate stage between the two. There's no sticker on your passport that says EB-1. You can't use your EB-1 status to enter the country or work or anything else. EB-1 simply means that you jump to the front of the line to get a green card. reply x86x87 12 hours agorootparenteven more. there is no difference in the process (as far as how the process works, not time spent waiting) between EB1, EB2, EB3. Also, calling it a visa is misleading. The Green Card gives you the right to reside here permanently and you don't need any visa once you have it. So it's not a visa, and even if it was a visa it would be the Green Card that would be called out, not the bucket through which you get it. reply x86x87 12 hours agorootparentprevI don't want to fight in the semantics dome, but they do not. > You may be eligible for an employment-based, first-preference visa if you are a noncitizen of extraordinary ability, are an outstanding professor or researcher, or are a certain multinational executive or manager. the employment-based, first-preference visa they are talking about is the green card. they were also lazy and did not update the wording reply fernirello 1 hour agorootparentprevU.S. permanent residency is a visa. It's an immigrant visa, obviously, like several other categories; meaning that it's permissible to state that the applicant has immigrant intent. reply CobrastanJorji 16 hours agorootparentprevWhat makes it not a visa? It's permission to enter the U.S., that's what a visa is, isn't it? Also, I that's it's pretty common to call it that: https://en.wikipedia.org/wiki/EB-1_visa But yes, the majority of recipients get them because they're managers at big companies. reply fernirello 1 hour agorootparentIn the U.S. system, no visa (including a green card==permanent residency) constitutes permission to enter the country. A visa only enables the holder to travel to a port of entry and request permission to enter the country. That permission may be granted or denied regardless of the specific visa category. Even if you have a gold-plated, von-Neumann-league visa... if the employee at the bottom of the CIS/CBP/* org chart who takes your passport is having a bad day, you'll be on the next outbound flight. Only U.S. citizenship implies a right to enter the country. EDIT fix typo reply paxys 15 hours agorootparentprevEB-1 does NOT grant permission to enter the U.S. You can have an approved I-140 in the EB-1 category but it is useless unless you also file an I‑485/DS-260 and get a green card. reply BeetleB 16 hours agorootparentprev> It's permission to enter the U.S., that's what a visa is, isn't it? I don't think so. You can't get EB-1 status unless you are already on some visa (H-1, O-1, etc). Once you start the green card process, at some point, you'll get paperwork letting you travel even though the green card has not yet been approved. Prior to that, you cannot unless your existing visa (H-1, etc) is still valid. EB-1/2/3 are categories under which you apply for a green card - they are not visas. reply neuralengine 16 hours agorootparentThat’s false. You can apply for EB visas from outside the US. After the approval of the I-140 (application for employment-based visa), instead of “adjustment” of your visa status in the US, you perform immigrant visa processing at your local consulate to get your green card. You can still travel after filing the I-140 but not after filing the I-485 (adjustment) without advance parole. reply returningfory2 15 hours agorootparentNot sure why this comment is being downvoted. It's exactly right: you can apply for EB visas (or any other permanent resident classification you're eligible for) without any prior connection to the US and get an \"immigrant visa\" in your passport to travel to the US. reply x86x87 15 hours agorootparentprevThere is no such thing as EB visas. While your greencard is processed you can indefinitely renew your current visa (eg HB1 you get it for 3 years and can renew only once, with application pending you can keep renewing it). Also, Green Card has different stages with their own limitations PERM -> I140 -> I485 -> green card. reply CobrastanJorji 15 hours agorootparentOkay, let's try this another way. 8 US Code § 1153, \"Allocation of immigrant visas,\" has the section for EB (employment-based) immigrants. (b) (1) begins: \"Visas shall first be made available...to qualified immigrants who are aliens described in any of the following subparagraphs (A) through (C): (A) Aliens with extraordinary ability, (B) Outstanding professors and researchers, (C) Certain multinational executives and managers\". Is this section of the U.S. code talking about EB-1s when it says \"Visas shall be made available,\" and, if not, what is it talking about? reply returningfory2 15 hours agorootparentprevThe US Department of State has a webpage literally called \"Employment-Based Immigrant Visas\": https://travel.state.gov/content/travel/en/us-visas/immigrat... It's not common for people with no prior connection to the US get one of these, but it is 100% possible. You can look up statistics on the number of employment green card visas issued here: https://travel.state.gov/content/travel/en/legal/visa-law0/v... In the PDF you need to search for E1, E2, etc. reply x86x87 8 hours agorootparentyou're missing the point. the immigration \"visa\" is actually the green card. while your greencard, under EB-X category is processing, you still need a \"proper\" dual-intent visa like HB1. reply returningfory2 5 hours agorootparentYou don’t need to be the US while applying for a green card. You can be living in, like, France, and apply for an EB1 green card with USCIS and then when it’s approved go to the US Embassy for a EB1 visa stamp and move to the US. This is what I meant. In this case you don’t need a non immigrant visa because you don’t live in the US while it’s processing. reply x86x87 12 hours agorootparentprevso, by this criteria, a US passport is a visa? i mean it does give you the permission to enter the US? reply renewiltord 16 hours agoparentprevEquivalent is Green Card EB-1. But there’s no automatic path. reply ahussain 16 hours agorootparentMost lawyers I've spoken to disagree with this. The O-1 and EB-1 have similar criteria as written, but the EB-1 is adjudicated to a much higher standard than the O-1. reply the_svd_doctor 16 hours agorootparentAnd EB-1 has quotas. So even if you qualify it may take many many years for Indians/Chinese folks. reply x86x87 16 hours agorootparentprevI could argue EB-1 is easier. Become a manager at FANG -> apply for EB1. reply elevatedastalt 7 hours agorootparentEB1c is trivial because of the manager route but with many WITCH companies exploiting it, they might change things in the future. Eb1a is the tough category they are talking about. reply oarla 16 hours agorootparentprevIt's not that simple. You need to have been a manager outside of the US for 1 year, apply and get approved for L1C visa, enter the country on that and then once in the US apply under EB1C. All the time maintaining legal status. reply x86x87 15 hours agorootparentIt's trivial compared to waiting 15 years for your EB-2 to be processed. reply elevatedastalt 10 hours agorootparentMake that 105 reply renewiltord 14 hours agorootparentprevThey locked down on this in the last few years, but I had friends come in through the EB-1. One didn't even get picked in the H-1B lottery and so had to work in India and that gave him the foreign manager experience. This is ~2018. But I agree, I didn't mean it has the same true requirements, just that it is the \"corresponding\" category. So yes, not \"equivalent\", \"corresponding\". reply pedalpete 8 hours agoprevI was going down a similar route in Australia but we were able to get my permanent residency without having to use the Distinguished Talent Visa. I'm surprised the US requirements would be so low as to accept a $100k investment as an award. For most people, this is probably not the way to go, we were using it as a potential last resort. reply codeisawesome 15 hours agoprevThank you for sharing this openly, the content is personally useful for me. reply quasarj 6 hours agoprevTop 10th percentile of software engineer salaries.. well this is definitely not something easily repeatable haha reply maronato 3 hours agoparentIt is repeatable by 10% of people. And honestly, it isn’t that high by big tech standards since you can use both base and stocks in the calculation. reply aiauthoritydev 4 hours agoprevFriendly advice: You got it ? Good. please keep quiet and don't tom tom it. There are indeed America First types out there who will report you to USCIS. These people are vicious and will DOXX you. I know this has happened in past. reply nikshepsvn 15 hours agoprevIf you don't mind sharing, how much funding did you raise? I can't find any information online reply Solvency 13 hours agoprevWhen I worked at a digital agency in 2007-2012 they hired MANY Brazilian art directors all who obtained O-1 visas. Literally just designers/creatives with portfolios online. I remember thinking how great they must be. Flash forward to 2024 I can't think of a single person in my network with one. Did the criteria change? Is it easier in certain fields? Easier from certain origin countries? reply hasty_pudding 15 hours agoprevThere should be a series on hacking the American immigration system to work around all of its draconian rules. reply throwaway1507 12 hours agoparentYou should try immigrating to one of the EU countries... I tried helping a senior programmer friend. No amount of experience, proof or whatever else could change the government's stance - they don't have an employer so they surely must be looking to exploit the social system - bye. reply hasty_pudding 11 hours agorootparentit's good in a way, allowing immigrants to leave their country of origin... deprives a country of its talent. instead of making their own country great another country is benefiting from their talent. and it's a self reinforcing system. reply jacknews 12 hours agoprev [–] I mean well done to the OP for getting their visa, but the whole thing reads like they gamed the system, which is clearly intended for people at the top of their fields, talented researchers, innovators, etc. And the 'outstanding ability' in this case is being put towards an 'immigration software' startup, ie helping others game, uh, navigate, the system, so the whole thing seems quite ironic. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author, a software engineer turned CTO/co-founder, shares their experience obtaining an O-1 visa as a startup founder.",
      "They obtained their visa in just one week with premium processing and met four out of eight extraordinary ability criteria.",
      "The author advises consulting with an immigration lawyer before applying and provides recommendations for lawyers and resources for O-1 applicants."
    ],
    "commentSummary": [
      "The discussion focuses on the US immigration system and the difficulties faced by individuals applying for visas and green cards.",
      "There is debate surrounding visa requirements, the flaws in the immigration system, and the treatment of undocumented immigrants.",
      "The conversation also discusses the O-1 visa for individuals with extraordinary ability, work limitations, and the significance of highlighting achievements."
    ],
    "points": 218,
    "commentCount": 174,
    "retryCount": 0,
    "time": 1706283950
  },
  {
    "id": 39143768,
    "title": "Introducing cssfact: A Lossy CSS Compressor for Reducing Redundancy in Code",
    "originLink": "https://blog.danieljanus.pl/2024/01/26/lossy-css-compression/",
    "originBody": "code • words • emotions Daniel Janus’s blog blog po polsku RSS home page Lossy CSS compression for fun and loss (or profit) 26 January 2024 What Late last year, I had an idea that’s been steadily brewing in my head. I’ve found myself with some free time recently (it coincided with vacation, go figure), and I’ve hacked together some proof-of-concept code. Whether or not it is actually proving the concept I’m not sure, but the results are somewhat interesting, and I believe the idea is novel (I haven’t found any other implementation in the wild). So it’s at least worthy of a blog post. I wrote cssfact, a lossy CSS compressor. That is, a program that takes some CSS and outputs back some other CSS that hopefully retains some (most) of the information in the input, but contains fewer rules than the original. Exactly how many rules it produces is configurable, and the loss depends on that number. The program only works on style rules (which make up the majority of a typical CSS). It leaves the non-style rules unchanged. Here’s the source. It’s not exactly straightforward to get it running, but it shouldn’t be very hard, either. It’s very simple – the program itself doesn’t contain any fancy logic; the actual decisions on what the output will contain are made by an external program. If you just want to see some results, here is a sample with my homepage serving as a patient etherized upon a table. Its CSS is quite small – 55 style rules that cssfact can work on – and here’s how the page looks with various settings: Original: page, CSS, source SASS 1 style rule: page, CSS (93% information loss) 5 style rules: page, CSS (74% information loss) 10 style rules: page, CSS (55% information loss) 20 style rules: page, CSS (31% information loss) 30 style rules: page, CSS (17% information loss) My homepage and both of my blogs all use the same CSS, so you can try to replace the CSS in your browser’s devtools elsewhere on the site and see how it looks. How Three words: binary matrix factorization (BMF, in the Boolean algebra). I guess I could just stop here, but I’ll elaborate just in case it isn’t clear. Consider a simple CSS snippet: h1, h2 { padding: 0; margin-bottom: 0.5em; } h1 { font-size: 32px; font-weight: bold; } h2 { font-size: 24px; font-weight: bold; } The first rule tells you that for all elements that match either the h1 or h2 selectors, the two declarations should apply. You could visualize this CSS as a 5x2 binary matrix AT where the n columns correspond to simple selectors (i.e., without commas in them) and the m rows correspond to declarations:h1 h2 padding: 0 1 1 margin-bottom: 0.5em 1 1 font-size: 32px 1 0 font-size: 24px 0 1 font-weight: bold 1 1 You could also transpose the matrix, yielding A with m rows denoting selectors and n columns denoting declarations. For my homepage’s CSS, m = 60 and n = 81; for bigger stylesheets, several thousand in either direction is not uncommon. Now, linear algebra gives us algorithms to find a matrix A′ ≈ A such that there exists a decomposition A′ = B × C, where B has dimensions m × r, C has dimensions r × n, and r is small – typically much smaller than m or n. So this is a way of dimensionality reduction. In the usual algebra of real numbers, there’s no guarantee that B or C will themselves be binary matrices – in fact, most likely they won’t. But if we operate in Boolean algebra instead (i.e. one where 1 + 1 = 1), then both B and C will be binary. The flip side is that the Boolean BMF problem is NP-hard, so the algorithms found in the wild perform approximate decompositions, not guaranteed to be optimal. But that’s okay, because lossiness is inherent in what we’re doing anyway, and it turns the binary matrices B and C are readily interpretable. Look again at the CSS matrix above: why is there a 1 in the top-left cell? Because at least one of the CSS rules stipulates the declaration padding: 0 for the selector h1. This is exactly the definition of matrix multiplication in the Boolean algebra. The matrix A′ will have a 1 at coordinates [i, j] iff there is at least one k ∈ {1, …, r} such that B[i, k] = 1 and C[k, j] = 1. So the columns of B and rows of C actually correspond to CSS rules! Every time you write CSS, you’re actually writing out binary matrices – and the browser is multiplying them to get at the actual behaviour. Well, not really, but it’s one way to think about it. It’s not perfect – it completely glosses over rules overlapping each other and having precedence, and treats them as equally important – but it somewhat works! You could plug in any BMF algorithm to this approach. For cssfact, I’ve picked the code by Barahona and Goncalves 2019 – sadly, I wasn’t able to find the actual paper – not because it performs spectacularly well (it’s actually dog-slow on larger stylesheets), but because I was easily able to make it work and interface with it. Why Why not? The sheer joy of exploration is reason enough, but I believe there are potential practical applications. CSS codebases have the tendency to grow organically and eventually start collapsing under their own weight, and they have to be maintained very thoughtfully to prevent that. In many CSS monstrosities found in the wild, there are much cleaner, leaner, essence-capturing cores struggling to get out. This tool probably won’t automatically extract them for you – so don’t put it in your CI pipeline – but by perusing the CSS that it produces and cross-checking it with the input, you could encounter hints on what redundancy there is in your styles. Things like “these components are actually very similar, so maybe should be united” may become more apparent. My mental model of transducers →",
    "commentLink": "https://news.ycombinator.com/item?id=39143768",
    "commentBody": "Lossy CSS compression for fun and loss (or profit) (blog.danieljanus.pl)218 points by todsacerdoti 18 hours agohidepastfavorite39 comments dmazzoni 16 hours agoI think it'd be a lot more interesting if you could feed it information about how often each rule is used. For example, add some code to your live site that periodically samples the DOM from a random subset of real user - for every element that's actually visible on the page, see what style rules apply to it. Count those up and get a big histogram. Then let that feed into the compression. The least-used style rules on obscure pages should be the most compressed. Find a way to have those \"reuse\" other style rules that are close enough. Your most important content would be the least degraded. reply no_wizard 13 hours agoparentUsing playwright you can get coverage for your used CSS on each page. It’s straightforward to build into E2E tests. Chrome will also tell you which rules were used on any given page. That in turn could give guidance for how you could pattern match rules even further reply simlevesque 12 hours agorootparentThat's really not as simple as you make it sound. Chrome and Playwright record the rules that were used, but if you don't trigger every media query, a lot of useful CSS will be flagged as useless. Also your playwright test needs to hover every element which has a :hover rule and print css will be discarded. You also have to keep in mind that Chrome isn't the only browser, some browser specific css will be ignored. Another example is if you have rules like :nth-child() on a list of results and the html you test it with doesn't have that element right now but an api call might return more result later. These css rule won't get counted. Also there are some false positives, for example if you set a variable twice and only read it later, then both variable declaration are marked as used while the first one was never read and is therefore useless. There's to my knowledge no tool that automates this process. I wish there was one. The only one I found is doei [1] but it's not finished and it just tries on a couple of hardcoded media queries. It's far from a simple problem but I'm sure someone can do it. [1] https://github.com/JamieMason/doei reply teaearlgraycold 3 hours agorootparentprevTailwind does this through analysis of the source. Not sure why you'd need to do dynamic analysis. You want to spin up a Chrome browser on each build to occasionally shave off a few bytes from a gzip stream? reply nathell 16 hours agoparentprevAuthor here – thanks! This is an interesting avenue of exploration that I hadn’t thought about. Exactly the kind of feedback I hoped for. I’ll try and give it a shot. reply dclowd9901 13 hours agoparentprevI’ve had this same thought for creating better chunking. There needs to be some sort of measuring component. reply muzamil-ali 15 hours agoparentprevnext [3 more] [flagged] wtallis 15 hours agorootparentAre you a bot that just rewrites the comments you're replying to? reply codetrotter 14 hours agorootparentProbably someone using OpenAI with a prompt that says to respond as a Hacker News user reply 51Cards 17 hours agoprevRight from the top I thought \"Why would I risk this breaking my site at random?\"... until the last paragraph. There the author states that (outside of the exploration for exploration's sake benefit) there may be potential gain here in comparing the output from this tool to a CSS monstrosity that has not been well managed. I think that could be quite valuable. reply dingdingdang 11 hours agoparentThis needs upvoting, could well be that this is a life saver for your typical WP install based on 3 competing CSS frameworks and about half a meg of bunged together styles that was once generated by some forgotten Node.js script that has now vacated the premises. Bookmarked. reply quickthrower2 8 hours agoprevNot a free (as in speech) license by the way https://oql.avris.it/license?c=Daniel%20Janus reply jszymborski 14 hours agoprevSome other ideas in this vein: 1. Approximate colours by reducing colours to their three letter hex-codes 2. Detect repetative rules and use native mixins. 3. Ugglify the CSS names, although you'd need to edit the HTML accordingly. reply FiniteLooper 12 hours agoparentAlso possibly finding similar colors that could be combined in rules instead of repeated separately. `.a{color: #FFFFFF;} .b{color:FFFFFE;}` ==> `.a,.b{color:#FFF;}` reply throwaway14356 11 hours agorootparentand the next pass class .b can go since we already have .a then, if that is really all it does it can be called .white next round trip it can look if multiple .b share a parent without other font colors. .white then becomes #wrapper or body. reply jsdwarf 12 hours agorootparentprevSame goes for embedded fonts reply pbnjay 14 hours agoprevIf you could also incorporate precedence rules you could get some more reduction. e.g. for the h1,h2 example, you'd have a selector for `h1,h2` (which is essentially the full h2 rules) and another for `h1` that overrides the font-size. Then when needing to \"reduce\" rules you could select for \"smaller\" rules and the only loss would be that h1 and h2 have the same size. To do that I think you'd need to do the factorization on the CSS properties alone, and then apply the values in a predetermined order. But would be cool/fun to test out! reply ljp_206 14 hours agoprevMy snarky frontend response is \"devs will do anything to avoid fixing their CSS,\" but truly the task is too herculean to bother with on any most timescales. (You think \"Untangle and reduce CSS bundle by X% with 0% improvement to any real KPI\" is a ticket that's ever going to get prioritized?) As others have said, this might be an interesting way to start zapping bloated CSS assets on aging codebases. reply bhaney 12 hours agoprev> Why not? The sheer joy of exploration is reason enough. Amen reply l5870uoo9y 15 hours agoprev> CSS codebases have the tendency to grow organically and eventually start collapsing under their own weight,... This was true if you don't co-locate CSS and code that uses it. Remove the code that imports the modular CSS and you remove the CSS. Interesting project nonetheless (even written in Clojure). reply hirako2000 17 hours agoprevWhile the concept (of lossy compression for other things than bitmaps and audio signals), is interesting, CSS is a pretty bad use case although outputs something that still works, would not for most programming code. E.g ML training datasets. Huggingface is filled with interesting stuff often in the gigabytes in size. I'm sure skimming out what follows patterns of redundant or less useful to ML learning algorithms could offer a nice catalogue of datasets quick to download and cleanup. Image sets for ML learning: loss of irrelevant channels and whatnot. Weather forcasting or historical dumps etc reply altairprime 15 hours agoprevI'd like to see this coded into a browser extension, just to have the experience of seeing whether I notice it affecting sites at various lossiness levels. reply numtel 10 hours agoprevSounds like begriff's (Postgrest author) CSS Ratiocinator https://github.com/begriffs/css-ratiocinator reply DomenicoMazza 7 hours agoparentThis I can get behind. It takes out the redundant or poorly structured rules that accumulate over time when writing CSS. It doesn't modify the style. reply franciscop 14 hours agoprevWait, I cannot believe no one said this would not work with very simple cases like: a { ... } article a { ... } .card a { ... } reply wiradikusuma 16 hours agoprevIt's not mentioned in the article whether structure is preserved, because if it's eliminating the \"wrong\" styles (affecting structure) then everything else it's doing right is irrelevant. reply Gabrys1 16 hours agoparent> The program only works on style rules (which make up the majority of a typical CSS). It leaves the non-style rules unchanged. reply rabbits_2002 16 hours agoprevwow this sounds incredibly useful reply charcircuit 16 hours agoprevI had expected this to tweak colors or margins to make them compress better when passed through brotli or gzip. What was done instead is cool too. reply Solvency 16 hours agoprevCome on this is so stereotypically developer. It's a fun premise and all they had to do was implement it on a test page and screenshot the before/after. Something, ANYTHING to demonstrate visually the end result. Sigh. reply dmazzoni 16 hours agoparentDid you see all of the links below the test \"here’s how the page looks with various settings\"? It's admittedly a pretty trivial page to test it on, but it works. reply FalconSensei 15 hours agoprevSeems interesting, but for a CSS post, I would really expect some screenshots showing the difference reply joemi 13 hours agoparentThere are links to live examples of different compression, and the source code. That's as good as (perhaps even better than) screenshots in this case. reply firefoxd 16 hours agoprev [–] The author was just shy of showing the results of the example he provided, but then didn't. I think this could be a useful tool in the IDE. Imagine vscode highlighting a line and suggesting another place to put it instead. Neat. reply Etheryte 16 hours agoparentThere are literally five live examples, along with ground truth, linked in the article, formatted as a bullet list. What more could you want? reply akoboldfrying 12 hours agorootparentThe \"more\" that I wanted was for the conclusion to the small worked example to be shown. That is, what do the computed factor matrices B and C look like as CSS rules, for this tiny example? Does the A' that they multiply to equal the original A matrix? reply firefoxd 9 hours agorootparentThis is exactly what I meant. He started building a small straight to the point example and didn't show the result. reply pax 16 hours agoparentprevsee 'If you just want to see some results, here is a sample with my homepage serving as a patient etherized upon a table' https://danieljanus.pl/index30.html vs https://danieljanus.pl/ reply kristopolous 16 hours agoparentprev [–] I don't understand what you're expecting but not seeing. reply akoboldfrying 12 hours agorootparent [–] The \"more\" that I wanted was for the conclusion to the small worked example to be shown. That is, what do the computed factor matrices B and C look like as CSS rules, for this tiny example? Does the A' that they multiply to equal the original A matrix? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post introduces a CSS compressor called cssfact that reduces CSS code by using binary matrix factorization.",
      "The technique of reducing CSS matrices helps in identifying redundancy in CSS codebases.",
      "cssfact aims to output a compressed version of CSS code with fewer rules."
    ],
    "commentSummary": [
      "The blog post introduces the concept of lossy compression for CSS and its potential advantages in reducing file size.",
      "The author proposes considering the frequency of rule usage to enhance the compression process.",
      "Commenters share additional tools and ideas related to CSS compression, and there are differing opinions on the practicality and usefulness of the concept. The post includes live examples and code for further experimentation."
    ],
    "points": 218,
    "commentCount": 39,
    "retryCount": 0,
    "time": 1706283064
  },
  {
    "id": 39148336,
    "title": "Tool Generates Quiz Questions and Flashcards from Educational YouTube Videos",
    "originLink": "https://www.platoedu.org",
    "originBody": "Hi HN,I watch A LOT of educational YouTube videos but wasn&#x27;t forgetting a good chunk of the details because I was only really passively watching. So I made a tool that generates quiz questions&#x2F;flashcards from YouTube videos, and uses spaced repetition like Anki or Duolingo to keep it in memory.Let me know if you find it cool&#x2F;useful (or terrible ) or if you want to know a bit about the details!",
    "commentLink": "https://news.ycombinator.com/item?id=39148336",
    "commentBody": "Anki/Duolingo-like app using educational YouTube videos (platoedu.org)197 points by kirill5pol 12 hours agohidepastfavorite67 comments Hi HN, I watch A LOT of educational YouTube videos but wasn't forgetting a good chunk of the details because I was only really passively watching. So I made a tool that generates quiz questions/flashcards from YouTube videos, and uses spaced repetition like Anki or Duolingo to keep it in memory. Let me know if you find it cool/useful (or terrible ) or if you want to know a bit about the details! sonovice 51 minutes agoGreat project! I had to laugh at the very first question I got, though: \"Who is the sponsor of the video?\" reply leoff 38 minutes agoparentPlease drink your verification can to use this website. reply andruby 39 minutes agoprevI love this! I wanted to build a “yt-campus” with a curated list of educational youtube channels. This does it better, thank you. One thing you could consider: allow your community to discuss the video’s. I’ve always wanted to have higher quality discussions about the Engineering videos I watch, and the YouTube comments really disappoint. Would you consider adding that? How about keeping your own personal notes per video? reply snordgren 11 hours agoprevWhen I saw Anki/Duolingo in the bio I assumed it was for language learning, but this is a great idea! I too often watch these kinds of videos without really retaining a lot. This is a perfect complement to turn infotainment into time well spent, or at least, less wasted. reply kirill5pol 10 hours agoparentYes!! I definitely spend a little too much time on YouTube myself, would you mind sharing what kind of content (categories) you watch in a pm? I’d love to get some better ideas of what kind of material to tune the question generations on reply jerpint 11 hours agoparentprevSame! Maybe someone could do some language learning on top of all the videos we consume on YouTube? reply yogurtboy 10 hours agoprevThis is amazing! I tried a couple of videos and the questions seem pretty relevant and answerable (is there a better word for how a question is worded clearly and the provided answers seem clearly distinct and one of them is obviously correct), which is really hard to do by hand, much less by AI. I know you've addressed the video selection in the playlists, but I would highly suggest doing something to get it to differentiate \"educational entertainment\" videos (I notice a lot of Real Engineering and Economics Explained and CGP Grey videos) and actual education videos: primary-source explainers from teachers and subject-matter experts. The information density in the latter is way higher, and I think people overestimate the educational value of the former. reply ruune 10 hours agoparent> and I think people overestimate the educational value of the former. I disagree. Some people might overestimate how in-depth the information is, but the educational value of these videos lies in giving someone a basic understanding of something they otherwise wouldn't have learnt about at all. The lower information density helps making the video easier to understand and thus easier to consume, compared to something like a Havard class. If you want to learn something in-depth, an actual class, a book, etc. will of course always be better, but if that's neither required nor wanted, the infotainment is just fine. reply kirill5pol 8 hours agorootparentYeah, I feel it's not ideal, but at least it's better than doom scrolling, and especially if it's a field that you're not familiar with having some simple explanations is still useful as a starting point reply alexander2002 8 hours agorootparentprevOne point is if the end-user understand it is just infotainment and not a concrete guide.For example,People became \"experts\" on covid thorugh some videos that spread misinformation and became hardcore fanatics.This is just one example of many. reply kirill5pol 8 hours agoparentprevThank you!! Yes, this is actually something I've been thinking about quite a bit, I actually built out the playlist feature just this morning because it's easier to \"show\" how Plato works, but I basically just wrote some scripts to get some good enough videos for the demo If you have any good channel suggestions I'd love to add them :)) One of the things I have on the backburner for now is building a BERT classifier to decide whether the video is Educational, Edu-tainment, or not educational at all and have a more customizable video suggestion than YouTube has (I actually have 2 accounts on YouTube, just so I can watch some random video on 1 without it polluting my education/learning heavy one) One thing though, is I actually think both have their merit, while I agree the actual educational content is pretty different, the educational entertainment is a nice alternative to TikTok or IG reels when you just want to mindlessly scroll, I think there still often some useful content there, especially if you don't have any background in the area reply dayjaby 1 hour agorootparent> classifier to decide whether the video is Educational, Edu-tainment, or not educational at all I'm a bit surprised to only see like 3 questions for a 14 minute video of quantum mechanics. For educational videos with very dense information, is there a way to raise the questions per video rate? Looking forward to see MIT OpenCourseware videos supported. Right now they are too long :D reply balaji1 10 hours agoparentprev\"educational entertainment\" videos are way too many, way too popular and binge-able - much more recommended by YT's AI. Actual education are much harder to discover on YouTube. I have been wanting to build a YT front-end that lets me control how many \"new\" videos are recommended. New videos are the time-sinks. Instead this new FE should make me re-watch so I absorb and retain better - maybe thru more Q&A like OP's platoedu or even make me write out some notes. Then I am forced to curate videos and maybe be more productive. reply KeplerBoy 2 hours agorootparentThis. I don't think most educational content on YouTube is worth remembering (or the best way to spend your time in the first place). So I'd be cautious about an app that helps you memorize the contents of said videos. You might end up with a lot of superficial, clickbaity pieces of knowledge. reply zadokshi 11 minutes agorootparentI invite you to share your own superior knowledge to the masses via your own YouTube videos so we can learn from you. Until then, I’ll learn from what is made available for others. Post back here once you’ve created some better content so we know where to look. reply kirill5pol 8 hours agorootparentprevThis is a problem I've had too, my current solution is to have multiple profiles on YouTube so whenever I click on a random video one it doesn't pollute my other education heavy account. Also just removing videos helps... but even then YouTube still pushes edu-tainment over harder educational videos. One of my ideas that's on the backburner is build a BERT classifier to separate between Educational, edu-tainment, and random, then use that to filter suggestions from the ones of people that use Plato Anyway if you have any good suggestions for better educational content I'd love to add that to Plato over the categories I have now! reply balaji1 5 hours agorootparentMultiple YT profiles is a smart hack! And also, great work on the app! The YT algo is pretty good - it catches on to what I want to follow and magnifies (ie suggest more content on) that topic. But it never pushes me to educational videos. I suspect educational videos are best to watch on Coursera. I know people who just open up Coursera and start listening on commutes, etc - instead of infi-scrolling. The pedagogical (instruction techniques, content structure, etc) aspect in those vids is different. I wonder if there is inspiration for creators/topics from Coursera? reply rollinDyno 7 hours agoprevI've always wanted to do this for Wikipedia, it could even be a Wikimedia add-on. However, I have recently transitioned towards becoming better at compiling information quickly rather than spending a chunk of my day memorizing facts that I am not quite sure will be useful. reply snakey 2 hours agoparentI’ve been doing something similar. If I read a blog post / paper, etc. where I learn a lot on a topic I’m interested in, I will catalogue a pdf of it in Obsidian with a tag and an optional note. This makes it easy to access information locally very quickly and I find I learn a lot more because if I forget something, I open up the resource, read the doc and, come out learning a little more. A kind of convoluted version of spaced-repetition but more passive learning. Granted, I’m aware this probably won’t scale to many topics but a few years and hundreds of notes later, it’s still working well for me. reply ListeningPie 5 hours agoparentprevWhat do you use to compile information and do you keep track of sources? reply dotancohen 9 hours agoprevAmazing, thank you. It even works great for music videos, I never appreciated the poetic lyrical context of Pantera before. )) Small bug, the service requires a youtube.com URL and cannot handle an m.youtube.com URL, as happens when copying from a phone web browser or NewPipe. Perhaps you could support the mobile URL as well. Thanks, great work! reply kirill5pol 9 hours agoparentWell that music video lyrics work is a very unexpected pleasant surprise! :) Thanks for catching that! Will fix that! reply pawelduda 10 hours agoprevI like the idea, but seeing how many new accounts added fake comments makes me a bit suspicious :) reply alexander2002 8 hours agoparentI really dont like the new accounts stigma due to statistical reasons but to each their own! reply schmorptron 2 hours agoprevOh my god, this is something I've wanted to make or see made for a while now! I'll definitely be using this, the design looks straight forward and good too! Any way to self-host to get around the 30 minute video limit? reply puzzydunlop 4 hours agoprevThis is very cool! I'm trying to do something technically similar by using LLMs to summarize the meeting transcript from youtube (https://parths-newsletter-78dbcb.beehiiv.com/). Right now I'm doing this manually by copy/pasting into ChatGPT but I want to automate this aspect. I'm not very technical so any guidance you could provide would be helpful :) reply allenz 4 hours agoparenthttps://www.videogist.co was mentioned previously on HN: https://news.ycombinator.com/item?id=38555629 reply albert_e 4 hours agoprevThis is a cool idea. I wanted to have a bookmarking site that allows me to add my own time-stamped notes to YouTube videos I watch for learning purposes. I was using OneNote without any such features. reply hellcow 4 hours agoprevI like the idea. I’m learning European Portuguese, so I added a video but unfortunately got an error that there were no subtitles. The subtitles for the video in question are auto-generated, so maybe that’s the reason? Would be great if I could use this for foreign language studies. reply kirill5pol 3 hours agoparentAuto generated captions do work but unfortunately only English for now, it would be pretty easy to add other languages but I just haven’t had time to implement it yet. Feel free to pm me with the YouTube video I’ll try to see what’s the problem (email in bio) reply tayo42 2 hours agoparentprevWhat exactly are you looking to do with YouTube and language? I might have a github repo you could be interested in. It takes YouTube videos, creates transcripts, translations and creates audio anki flash cards from it with audio on the front and text on the back reply owenpalmer 7 hours agoprevThis is fantastic! Is there a way to donate? This is the kind of software I want to see in the world! reply kirill5pol 6 hours agoparentPm me (email in bio) and I can come up with some sort of premium plan haha (I'm thinking unlimited time length for videos + podcasts/other material) but very open to suggestions! reply bobmaxup 10 hours agoprevIs NLU really this reliable yet? I tried making some scripts like this with LLMs, and it seemed to do very poorly. So, I abandoned the effort. reply kirill5pol 9 hours agoparentI did quite a bit of that too, I really had trouble getting it to generate good content from scratch but here it's using the transcripts directly. I'm guessing it only really works well on scripts that are meant to be educational, because there already are \"questions\" implicit in the transcript of the video because that's the best way to present information when teaching something reply danielwyb 11 hours agoprevNice! Would be great to use on longer videos and focus on specific topics of the video. reply willmeyers 12 hours agoprevThe 30 minute limit is unfortunate, but otherwise it looks good. Thanks for sharing! reply kirill5pol 12 hours agoparentSo far it’s basically a heuristic for the video having both captions and the token count for generation be reliably under the limit, but I am working on making it work for arbitrary length videos! I did some tests for 2-3 hour podcasts and it worked pretty well reply yterdy 8 hours agoprevIf this works as I expect it to, it'll be something I've been hoping to see for a long time. Thank your for sharing it with us! reply kirill5pol 8 hours agoparentDo you have any specific type of content that you were trying to learn? Right now it's still pretty early/demo stage, but please pm me (email in bio), I'll see if I can tune it better to your use case! reply sebastianvoelkl 9 hours agoprevreally cool. A while back I've build this database of 1000+ hand-selected educational YouTube videos, so I'm going to try out a few of them to put in this tool :) https://www.edutube.app/ reply kirill5pol 9 hours agoparentThis is awesome! Did you hand select all 1000? I wanted to hand select for the categories to get some better starting recommendations but it was taking too long so I was a bit lazy and just scripted it… reply sebastianvoelkl 9 hours agorootparentYeah I literally hand-selected all of them to remain the quality of videos that I wanted reply kirill5pol 7 hours agorootparentIf you have a list of the IDs of the videos (and maybe categories) I can bulk add them! If you want to discuss a collab of some sort feel free to email me! reply jacknews 11 hours agoprevWho chooses the videos? It seems ... opinionated. For example, under 'Physics', we have \"The big lie about carbon capture', 'Why (toilet) flushing isn't for everyone', 'The scientific basis for miracles', etc. reply kirill5pol 11 hours agoparentYeah it’s not ideal yet the suggestions under each category I just YouTube’s own category labels so often it didn’t give the best results, but it’s something I’m working on! reply dotancohen 9 hours agorootparentPerhaps allow the user to integrate with his YouTube history? Does YouTube have an API for that? reply dotancohen 9 hours agorootparentprevPerhaps log the videos that users upload and suggest the most common ones? reply kirill5pol 9 hours agorootparentYep planning on doing that but didn't have enough videos uploaded to \"fill up\" the categories before posting the Show HN, so I just scripted some stuff based on the YouTube suggestions from some YouTube channels I watch. One of my future plans is to actually train a BERT model to limit the video suggestions to something that actually is useful instead of clickbait... I have 2 different accounts on YouTube just so watching random videos on 1 won't pollute the suggestions from the other reply vivzkestrel 6 hours agoprevso how does this worK? you take the video and extract captions from it? and feed it to GPT? i am sorry, can you clarify? reply totetsu 10 hours agoprevI want to make flash card form everything I look up this way. reply kirill5pol 10 hours agoparentAny particular type of content you’re thinking of? I’m currently working on adding podcasts since they’re pretty similar to YouTube videos, but I’m sure with some tuning I could see if it works for other things reply totetsu 10 hours agorootparentPodcast is definitely one. But I’m not sure how one could get the real salient points out of some of the philosophy podcast I listen to without listening carefully the first time and writing them down.. Another would be for example when I ask Chatgpt how to do something in nvim. reply kirill5pol 9 hours agorootparentMind sending me an pm? (my email's in my bio) I'd love to try it out with some of the podcasts/nvim chatgpt responses you mentioned and add it to your account! reply dotancohen 9 hours agorootparentprev> Any particular type of content you’re thinking of? When the wife is mad and ranting, can you email me a summary at the end? With a quiz for the important parts. reply kirill5pol 8 hours agorootparentNow that is a strong need haha, I think will have to be on the Plato premium + plan reply dotancohen 8 hours agorootparentYou've got your first customer! reply totetsu 7 hours agorootparentprevOh god. I did take notes during my last break up.. Maybe I could review those too reply husarcik 11 hours agoprevWhat algorithm do you use for spaced repetition? reply kirill5pol 10 hours agoparentI have a fairly simple implementation of the SM-2 algorithm, and just making the assumption that if you answered the question correctly then you have “perfect recall”. This isn’t exactly correct but I have been using it myself and seems to still be pretty nice. But for the next version I want to use something called knowledge tracing to determine an estimated level of recall to then change the spacing reply jarrett-ye 1 hour agorootparentI recommend the new algorithm of Anki: https://github.com/open-spaced-repetition/fsrs4anki reply wahnfrieden 8 hours agoprevHow do you deal with YouTube Terms of Service for extracting transcripts? reply sidwrestler 11 hours agoprevI love this new Plato app, it’s useful and I educational. The interface is also very clean reply sstanfie 12 hours agoprevthis looks great! reply clairegu123 12 hours agoprevNice reply vanijzen1 12 hours agoprevVery cool! reply Davana 10 hours agoprev [–] You just saved millions of students life's, A great tool that just solved a problem that existed but no one ever noticed reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The individual has developed a tool that generates quiz questions or flashcards from educational YouTube videos.",
      "The tool incorporates spaced repetition technique to enhance memory retention.",
      "The individual is seeking feedback on the tool and willing to provide additional information upon request."
    ],
    "commentSummary": [
      "The author has developed an app that generates quiz questions from educational YouTube videos and uses spaced repetition.",
      "Users find the app helpful and suggest adding features like community discussion and personal note-taking.",
      "There is a debate regarding the value of educational entertainment videos and a desire for more control over YouTube recommendations to prioritize actual education."
    ],
    "points": 197,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1706303078
  },
  {
    "id": 39142560,
    "title": "tinySA Wiki Updated with Info on tinySA Ultra: Small Spectrum Analyzer and Signal Generator",
    "originLink": "https://www.tinysa.org/wiki/",
    "originBody": "Recent Changes - Search: HomePage Where to buy First use Screen Info Model comparison tinySA Basic Menu Tree Menu Details Specification Limitations Technical Description tinySA Ultra Menu Tree Menu Details Specification Ultra mode Limitations Technical Description Updating the firmware Getting support PC control Examples Videos FAQ All available pages PmWiki Initial Setup Tasks Basic Editing Documentation Index PmWiki FAQ PmWikiPhilosophy Release Notes ChangeLog pmwiki.org Cookbook (addons) Skins (themes) PITS (issue tracking) Mailing Lists edit SideBar View Edit History Print Main / HomePage Welcome to the tinySA® wiki! Important info on the tinySA Ultra The tinySA wiki is slowly being updated with info regarding the tinySA Ultra. The names tinySA4 and tinySA Ultra refer to the same device. The tinySA are a small spectrum analyzers and signal generators with some nice capabilities: tinySA Basic Screen size 2.8 inch Spectrum Analyzer with two inputs, high quality MF/HF/VHF input for 0.1MHZ-350MHz, lesser quality UHF input for 240MHz-960MHz or Signal Generator with two output, sine wave output for 0.1MHz - 350MHz and square wave output for 240MHz-960MHz when not used as Spectrum Analyzer. Switchable resolution bandpass filters for both ranges between 2.6kHz and 640kHz Color display showing max 290 scan points providing gapless covering up to the full low or high frequency range. tinySA Ultra Screen size 4 inch Spectrum Analyzer for 0.1-800MHz or, with Ultra mode enabled, level calibrated up to 6GHz. Can observe signals up to 12GHz Signal Generator with sine wave output between 0.1-800MHz or square wave up to 4.4GHz or rf test signal output up to 5.3GHz when not used as Spectrum Analyzer. Switchable resolution bandpass filters from 200Hz to 850kHz Built-in 20dB optional LNA Color display showing max 450 points providing gapless covering up to the full frequency range. MicroSD card slot for storing measurements, settings and screen captures. Input Step attenuator from 0dB to 31dB (can not be used in combination with LNA). A built-in calibration signal generator that is used for automatic self test and (low) input calibration. Connected to a PC via USB it becomes a PC controlled Spectrum Analyzer or Signal Generator Rechargeable battery allowing a minimum of 2 hours of portable use Max input level +10dBm. Do not destroy your tinySA The generator function can not be used as a tracking generator as you can not use the spectrum analyzer and generator functions at the same time. Due to the low cost and very small form factor there are certain relevant tinySA limitations and tinySA Ultra limitations Introduction and other videos A short 7 minute video introducing the main features of the tinySA can be found here. A short introduction video to the tinySA Ultra can be found here. Many more videos in my YouTube channel A user has created an very extensive introduction video to the tinySA Ultra which can be found here Manual For those that prefer to read a document instead of browsing a wiki, there are two options. Kurt Poulson was so kind to write an extensive document explaining various aspects of the tinySA for a Danish Amatuer Radio magazine. The English version can be found here. Kurt describes the operation of the signal generator and spectrum analyzer functions and explains how to update the FW. The document contains many screen captures of example measurements. A second option is a PDF version of the wiki, which allows for easier reading for some people, that can be found here Main subjects covered in this wiki: Spectrum Analyzer introduction Make sure you do not buy a bad performing illegal copy product First use See left navigation bar for more subjects Legal stuff The names tinySA and tinySA Ultra along with the tinySA logo are registered trademarks owned by us. Nobody else is allowed to use the name tinySA or tinySA Ultra for any spectrum analyzer product, without written permission. Credits The tinySA FW is based on the NanoVNA FW created by edy555 Donations You can support the continued development of the tinySA by donating. Donations can be done via credit card or PayPal. The donation link will send you to a new page with a donation button. Edit - History - Print - Recent Changes - Search Page last modified on November 09, 2023, at 11:21 AM",
    "commentLink": "https://news.ycombinator.com/item?id=39142560",
    "commentBody": "TinySA – small spectrum analyzer and signal generator (tinysa.org)169 points by transpute 20 hours agohidepastfavorite55 comments 127361 18 hours agoThese are being used by the Ukrainian army for detecting incoming russian drones. https://www.linkedin.com/posts/eyesonukraine_drone-detector-... The firmware source is on GitHub at https://github.com/erikkaashoek/tinySA. reply TheLoafOfBread 18 hours agoparentIf they know frequency of drones (i.e. Lancet in this case) can they create something like a HARM drone, which will guide itself on source of the signal to intercept the drone itself? reply ramses0 16 hours agorootparentA drone dangling balls of yarn... reply squarefoot 17 hours agoparentprevAre they using any peculiar feature of the TinySA? From the photo it seems they're doing normal spectrum monitoring, but for that purpose a SDR dongle would work as well, For rexample the one by rtl-sdr.com. Beside being much cheaper, it can be interfaced easily with also cheap *Pi-like single board computers and operated remotely to cover wide areas. But again I have no idea if the TinySA offers any advantage over a SDR receiver in that context. reply ThrowawayTestr 16 hours agorootparentThe other reply to you is buried for some reason but as they said, a hand-held battery powered unit is more convenient than something that requires a computer. reply okl 14 hours agorootparentprevUnfortunately, the bandwidth on the RTL-based dongles is quite limited. This means that you'll only see some kHz of spectrum around your LO frequency. reply helpfulContrib 17 hours agorootparentprevPortability and effectiveness. Sure, for you a dongle is great. But not if you're in the trenches covered in mud and you have to dig it out of a pocket somewhere .. reply cadr 18 hours agoparentprevIt surprises me that military drones aren't using spread spectrum to make this harder. reply thsksbd 10 hours agorootparentA lot of the drones are off the shelf drones. This war is revolutionary from a tech POV, a lot of the solutions are cobbled together -> see \"cope cages\" reply wkat4242 6 hours agorootparentprevYeah or satellite uplinks that only transmit straight up, much harder to detect and to jam. reply nurettin 17 hours agorootparentprevIs that a real thing, or a star trek reference? reply cadr 17 hours agorootparentA real thing: https://en.wikipedia.org/wiki/Spread_spectrum Fun fact, the famous actress Hedy Lamarr actually was instrumental in inventing it! reply avisser 14 hours agorootparentYou can tell GP is under 40 or they'd probably remember cordless phones \"Now with 900mhz spread-spectrum technology\" reply cshimmin 17 hours agorootparentprevDefinitely a real thing. Also, during WWII actress Hedy Lamarr developed a system for spread spectrum torpedo guidance to prevent jamming, but the general idea predates that. reply stoneman24 16 hours agorootparentprevYes, it’s a thing. A long time ago, my work involved a frequency hopping, spread spectrum radio link. Can’t say much about it but I’m sure that the technology has improved since then. reply nonrandomstring 13 hours agorootparentHopefully its not pedantic or unwelcome of me to make the distinction between spread-spectrum and frequency hopping. With frequency hopping only one frequency is used at once, and they're selected according to a sequence that matches a shared PRNG. As I understand it, that's what Bluetooth and some Wifi links do. They switch between discrete bands very fast. Spread spectrum is a little different. During modulation, as with FM a series of side bands spread out. Normally we would limit these as they're considered \"interference\". But with the right modulator you can spread (and indeed encrypt at the RF link level) information into some bands but not others. Although all sidebands are present, to an observer who can't tell which ones carry the data at any moment, it makes no sense to even try demodulating the signal. Neither solutions are much use if you need to communicate back because triangulation alone is enough to find you. Curious if this tallys with your understanding, its over a decade since I had anything to so with this sort of thing. The best summary I recall was in Ross Anderson's \"Security Engineering\" book (first ed.) reply NovemberWhiskey 12 hours agorootparent>Hopefully its not pedantic or unwelcome of me to make the distinction between spread-spectrum and frequency hopping Spread spectrum refers to any technique where a narrowband signal is deliberately spread to occupy a larger bandwidth. Frequency-hopping is an example of a spread spectrum technique; they're not different things. Direct-sequence spread spectrum (which is what I think you're describing) is also a spread spectrum technique. There are also other techniques; the most popular one is probably the chirp spread spectrum as used in LoRA. reply nonrandomstring 12 hours agorootparentThanks for the clarification NW reply stoneman24 12 hours agorootparentprevNo, it’s fine by me. I believe that it was thought that the combination of frequency hopping and spread spectrum would make it difficult to monitor and jam ( other than very wide band jamming). My application was rapidly moving so triangulation would be difficult. If I understand the capabilities of modern Software Defined Radio systems, then they can monitor many different frequencies at the same time which might defeat those old systems. It’s been a long time since I read up on the current ideas and capabilities. reply nonrandomstring 12 hours agorootparent> If I understand the capabilities of modern Software Defined Radio systems, then they can monitor many different frequencies at the same time Haven't been keeping up with it as much as I should, but that's very interesting. reply NotSammyHagar 15 hours agorootparentprevIsn't good old cdma a spreadspectrum technique, used for cell phones back in the day from quallcomm? reply MegaDeKay 13 hours agorootparentYes, one of the four basic types. CDMA is the Direct Sequence Spread Spectrum variant. https://en.wikipedia.org/wiki/Spread_spectrum reply p_j_w 16 hours agorootparentprevSpread Spectrum is very real, it was used in 802.11b. reply wkat4242 6 hours agorootparentYes and Bluetooth. In those cases it's not used to make detection harder though but to be more resilient against interference. reply Vigorosotuna96 10 hours agoparentprevThis might have to be my next DIY project... reply cadr 18 hours agoprevMake sure to heed the maximum input and use an attenuator! These are very cool and fun, but I found myself using my NanoVNA a lot more than my TinySA https://nanovna.com/ reply willis936 18 hours agoparentBoth are super handy and super cheap (relative to conventional SAs and NAs). Handy for the personal shop of any EE. reply codefoster 18 hours agorootparentI use a nanoVNA for analyzing antennas. Cool tip is you can tether it to an Android device and get a bigger, nicer touch screen. reply cadr 18 hours agorootparentThat's cool - didn't know that about Android. Another cool tip is to use NanoVNASaver (https://nanovna.com/?page_id=90) reply cadr 18 hours agorootparentprevFor sure - if you can afford them, get both. I was just surprised because I expected to use the SA a lot more when I got it. But I am mostly either testing filters are designing antennas, and the NA is the way to go. reply GeorgeTirebiter 11 hours agorootparentI have only NanoVNAs, up to the 6 GHz one ( https://nanorfe.com/vna6000.html ). But the TinySA at the frequencies of interest seems about the same? I guess what I'm asking: What features of the NanoVNA make it the \"way to go\"? FOR ME: It's the PC SW that allows a big-screen, which converts the fundamental \"R+jX\" measurement into many different views. https://nanovna.com/?page_id=90 Awesome. reply rkangel 12 hours agoprevSimilarly can anyone recommend an affordable oscilloscope? Ideally mixed signal and PC attached. Picoscopes are great and very affordable on a work budget, but a bit much for my home budget particularly if you want a mixed signal one. reply KANahas 10 hours agoparentI’ve been very happy with my Siglent 4 channel/100 MHz scope (with logic analyzer but I don’t have the $200 pod so I don’t use that). The scope was about $400 and I find it worth the investment. It’s on the same level as the popular Rigol lines but I don’t like their UIs very much (too chinesium for me?). reply GeorgeTirebiter 11 hours agoparentprevGet a used TDS-2xxx series used on ebay. I prefer Tek scopes, great trigger, and the TDS 210, TDS220 and their ilk continue to work very well. As to PC attach, yes, you can do that, but that will need some s/w. Many people like the newer Chinese scopes; see https://youtu.be/S8jrpCoZyx8?si=oaI_gxOylYhOSp-m but I have only limited experience with those. Their UI seems less obvious than Tek scopes. The other very important specs besides what you've mentioned are # of channels, and highest operating frequency. Others today would be how fast is the ADC, how many bits, storage depth, post-capture analysis capabilities, and so much more. reply tverbeure 5 hours agorootparentI have a lot of experience with Tek, HP and Siglent scopes. The Tek scopes are IMO some of the least intuitive. But if you want to remote control the scope, stay away from the Chinese ones: that part of the FW is often very buggy. reply lelanthran 3 hours agoparentprevRelated: I recall seeing USB scopes very cheap like ... 5 years ago, maybe 6? Are they any good? In the market for a very cheap 'scope - think, looking at i2c signals, 0v-5v analog signals from (for example) a temp sensor, etc. Is the buspirate still around? reply cadr 11 hours agoparentprevWhat frequencies, how many channels of analog/digital, what bit depth, how much memory, etc? What is your actual application? And what do you mean \"PC attached\" here? What is your budget? I don't think you are going to find much for less than a Picoscope. Maybe something like the Analog Discovery 3? Under 400 USD, 2 channel oscilloscope (30 MHz), 16 channel digital, 2 channel arbitrary waveform generator (12 Mhz) https://digilent.com/shop/analog-discovery-3/ Rigol and Siglent both make mixed signal scopes that will do two channels analog at 100MHz and 16 channel digital for ~1k USD. reply rkangel 11 hours agorootparentI wasn't familiar with the the Analog Discovery. Seems good value as it covers a lot of bases in one go. 30 Mhz is a bit low, but would cover the lower speed digital stuff which is what I need a scope for most of the time. Two scope channels, some logic analyser channels, ideally 50 MHz, ideally 12 bit. That works at as about £500 from Picoscope which is pretty cheap. I was astonished at these Spectrum Analyzers and I was wondering if there was something from china at a fraction of that. reply cadr 10 hours agorootparentThe TinySA is kind of like a tiny radio, just tuning through the channels and measuring how loud at each frequency. And it managed to leverage an exiting chip (designed for other purposes), which is how it got to be so cheap. This is a great explanation of the signal path: https://www.youtube.com/watch?v=z63cXhYzS1A reply halayli 8 hours agoparentprevkeysight(leaders in the industry) released a model(EDUX1052A) for hobbyists starting at $500. https://www.keysight.com/us/en/support/EDUX1052A/oscilloscop... They also have DSOX1202A & DSOX1202G for ~$1k -> ~$1.2k reply gte525u 12 hours agoparentprevAnalog discovery series is cheap and good enough for a lot of tasks. reply GeorgeTirebiter 11 hours agorootparentI've found Analog Discovery true to its name -- great for exploring analog. The scope portion is limited in channel sensitivity and frequency. It's also a bit of a kludge, in that the probes attach via a 2x20 (?) front-panel 0.1\" center connector to an adaptor board that has BNC females for the scope probes. I have one of those (AD2; there is a newer AD3 available), and it's quite a lot of 'stuff' in one package. I wish I had one when I was learning EE. But these days, I use them as 'data acquisition and control' modules to generate and capture signals under program (Python) control. I think of them sort of as a fancy Arduino -- although it can do many more analog tricks. Recommended. reply wkat4242 7 hours agoprevReminds me of that other small and cheap spectrum analyzer the RFExplorer. That's been on the market for 10 years or so. It has a similar need to be careful with strong signals. I didn't know of this one, I'll check it out. It looks way better and the basic one is a lot cheaper too! reply ChrisMarshallNY 17 hours agoprevThis looks exceedingly cool. I probably don't have a use for this type of thing, any more, but, at one time, I would have snatched one up, immediately. reply applied_heat 14 hours agoprevAnyone know a signal generator that can do 60.000 Hz? I used to use the HP 3310A but they are analog and really old now reply wila 9 hours agoparentThe tinySA can also be used for that, it's not only a spectrum analyzer, it can also generate signals and optionally modulate those for you. edit: https://tinysa.org/wiki/pmwiki.php?n=Main.Specification here says it works from 100kHz for the low output. When I just tried it did let me select 60kHz and turn it into output mode. Haven't hooked it up to a scope to see what it does. Sorry no time to set it all up now. 60kHz is very low though, if you browse AliExpress then I'm sure plenty of signal generators will offer that for a really low price (cheaper than the tinySA) edit 2: Sorry my European brain kicked in and missed you are looking for a 60Hz one that is very precise and not a 60kHz one. I'd better get some sleep. reply tverbeure 5 hours agoparentprevCheck out the function generators from FeelTech on Amazon or AliExpress, like the FY6900 or FY6800. They’re cheap in a flimsy plastic case, but they’re good enough for many applications. reply magicalhippo 14 hours agoparentprevAny decent digital one should be able to do that I imagine. I've got an entry-level Siglent[1], it can do 1 microHz and up. Or am I missing something? [1]: https://www.siglenteu.com/waveform-generators/sdg1000x-serie... reply applied_heat 13 hours agorootparentThanks. A lot of the hobbyist level ones did not do low frequencies at all or precisely enough to compare to electrical grid frequency That one for 350 euros looks good reply 0l 9 hours agoparentprevIm not sure how well it would work, but for a low cost solution try your PC's sound card. Reasonably low distorsion and sufficient frequency accuracy. reply nullc 6 hours agoprevThe related NanoVNA has been transforming amateur radio, now almost everyone that can afford a radio can afford a VNA that lets them characterize, tune, and repair antennas and other RF components. Gone are the days when you had to beg a club member with a $10,000 MSRPed bench VNA in the back of his truck to swing by. You can pull a VNA out of a bag while still up the tower. High-Q antennas designs that are sensitive to construction and mounting are much more realistic to use when you can VNA them in situ. reply PM_me_your_math 16 hours agoprevThe TinySA is excellent for finding sources of RFI, although you want to use a small yagi or loop antenna. reply cadr 15 hours agoparentI wish I had it when I was having an RFI issue in my neighborhood. I ended up with my RTL-SDR hooked up to my mac with a homemade copper-on-tape-on-cardboard yagi, and I looked like I was a tinfoil hat away from being needing to be put away. Still would have looked nuts with the TinySA, but... less so. reply polishdude20 7 hours agorootparentDid you find the source of the issue? reply ijhuygft776 13 hours agoprev [–] wow, cheap. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The tinySA Wiki has been updated to include information about the tinySA Ultra, which is a small spectrum analyzer and signal generator.",
      "The tinySA Ultra and tinySA4 are the same device, with the Ultra featuring a larger 4-inch screen and operating within broader frequency ranges.",
      "The tinySA Basic has a 2.8-inch screen and operates within specific frequency ranges, while the Ultra has additional features like a built-in LNA and microSD card slot."
    ],
    "commentSummary": [
      "The Ukrainian army is using the TinySA, a compact spectrum analyzer and signal generator, to detect Russian drones effectively.",
      "The conversation delves into spread spectrum technology and alternative approaches for detecting and intercepting drones.",
      "Various spectrum monitoring and analysis tools, such as the NanoVNA and TinySA, are discussed, along with suggestions for buying affordable oscilloscopes and measuring low frequencies and identifying radio frequency interference sources."
    ],
    "points": 169,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1706277073
  },
  {
    "id": 39145701,
    "title": "PinePhone: A Mixed Bag of Performance and Phone Issues, According to Review",
    "originLink": "https://yaky.dev/2024-01-25-pinephone-post-daily-driver-review/",
    "originBody": "PinePhone - Post daily driver review Review of PinePhone after a month of daily driving. All opinions are my own, and most of the review is for my own use-cases. There are some comparisons, mostly for entertainment purposes, to iOS (based on my previous device, iPhone 12 Pro) and Android (based on my current device, de-googled OnePlus Nord N10 5G). Verdict PinePhone is a great mobile Linux device. I would use it as my daily driver, and probably iron out some issues I ran into, but for me, it failed at... being a phone. I had repeated, unpredictable problems both placing and receiving calls, and I could not resolve them. See below for details. Hardware 3GB RAM Convergence edition original PinePhone rev 1.2B. PinePhone on Pine64 store Body TLDR: Plastic, pretty standard for mid level phone. Well-made, pretty standard dimensions, is a bit slippery, but buttons have a good feel to them. It would be great with a grippy case. Having all three buttons on the right side makes it convenient for environments like SXMO, which uses buttons for navigating menus. Display TLDR: Okay, difficult to see in bright light. After ultra-smooth modern phone touchscreens, PinePhone's screen protector feels strange, but is nothing unusual. (You can take it off or replace it with a glass one for more glossy feel) The display itself is an IPS panel. Not as colorful as OLED, but not as expensive or power-hungry, either. My only complaint is that it's difficult to see in bright light, so I kept the light theme for everything. Battery TLDR: Eh. Enough for occasional texting and short calls. Plug in otherwise. Not great, but not terrible. At first, and when traveling, I carried a power bank with me, but rarely needed it. If you use the phone to occasionally text and chat, you are OK. Browser and WiFi are the two things that noticeably drain the battery. Often, if not actively using bandwidth, I think it makes sense to turn WiFi off. I made an adapter to use with Samsung S20 Ultra battery case, but some strange USB issues kill the modem while case is active, so I could not try it out very well. PinePhone to Samsung Galaxy S20 Ultra back cover adapter Software postmarketOS stable with Phosh (installed on new 128GB SD card) Installation TLDR: EASY. To install an OS, you flash an image to an SD card, put it in the PinePhone and turn it on. That's it. You can swap OSes by changing SD cards as much as you want. Compare to Android, which involves unlocking the bootloader, flashing recovery, booting into recovery, flashing an OS image, and possibly patching the image to get root. Compare to iOS which doesn't let you do that to any reasonable extent. (Yes, I know normal people do not install OS on their phones...) Activation TLDR: No hand-holding, but only few settings. When you start some distros/desktops, you are presented with a short tutorial. You need to configure the mobile connection yourself, but it's usually just setting the APN and MMSC URLs. For postmarketOS+Phosh, the APN setting is in Settings/Mobile Networks, and MMSC setting is in Chats/Settings. PinePhone carrier support on Pine64 wiki Compare to Android, which requires clicking through multiple pages of setup. Although most of that is skippable (depending on the manufacturer too, I guess). Compare to iOS, which not only annoys you to set up Siri and Face ID on setup and at every update, but does not allow you to activate the phone without an SMS message. (Very convenient when in another country with no coverage or high roaming charges) UI TLDR: Phosh is conventional and practical. SXMO is a bit unusual but pretty cool and very customizable. Phosh navigation uses the bar on the bottom of the screen (similar enough to iOS and Android), which opens both a list of running applications and an app drawer. All apps in the drawer are listed alphabetically but can be added to the favorites list on top. I think this unification of home screen with the app drawer is simpler and faster than Android/iOS pinned apps + pages, and much more organized than iOS's \"home screen is an app dumpster\" (which i see on many people's phones). There are occasional slowdowns but they are not significant. Some unimplemented controls, such as switch for location and inhibit-suspend (aka caffeine), I wrote as desktop entries (\"shortcuts\" that show up in app drawer). Most GTK-based apps are more or less consistent in their styling, and you can force a theme on everything if you want to. Qt is a bit all over the place. Phosh does not have a global \"back\" button, so each application has to implement its own UI. Usually, the back button is in the upper left, which is very inconvenient. Although, new Android and iOS now use the \"swipe from left edge\" to go back, which is equally unwieldy for people with regular-length thumbs. Android with its back button on the bottom bar is still the best in this regard. Another desktop environment is SXMO. It has a menu-based UI that you navigate using the volume and power buttons, as well as some pre-defined gestures for other actions. It is intended to be used with simple terminal-based tools, but I had no problems running any other software. I liked being able to open applications side-by-side, override and customize any menu (you can even make app-specific menus for most-used actions, for example), and run hooks on events (such as custom notifications for texts, calls, etc). SXMO website Keyboard TLDR: Simple, but customizable Phosh uses squeekboard, which is a pretty standard, simple keyboard which supports multiple languages and can be very easily customized by editing a YAML file. There's no swipe, spell-check, or predictive text, but there are other projects that try to implement that. SXMO uses wvkbd, which is aimed more towards terminal use and includes cursor keys, modifiers (Ctrl, Alt), and other useful keys (/, -, Tab). To customize wvkbd, you... compile it from source. It's pretty straightforward C and builds in a few seconds. Notifications TLDR: Only calls and SMS notifications are truly real-time. If PinePhone is in sleep (by default, after 2 minutes of idle on Phosh), it cannot receive notifications. The modem (which, itself, is another Linux device) is always on, so once it receives a call or SMS, it will wake PinePhone up. Theoretically, it should be possible to have modem check for notifications, but I am not aware of any project that did this yet. The way notifications present themselves is per-application, more or less. On Phosh, Calls vibrate continuously for calls, Chats vibrates and chimes. Fractal (Matrix messenger), and Dino (XMPP messenger), however, produce notifications silently. But you have access to their source code, so that can be changed - I rebuilt Dino with noisy notifications before. There are no icons on the status bar, but most notifications show in the pull-down panel and make the LED blink blue. Yes, I love blinkenlights. However, blinking the LED is kind of silly, because if the phone goes to sleep, it will keep the LED state it last had (either permanently on or off). Compare with Android, which mostly got rid of the notification light :( But notifications are shown in the status bar and can wake the screen. Compare with iOS, whose UI is terrible in this regard. Notifications wake the screen, and show on lockscreen, but only until you unlock the phone. Then they are dropped somewhere into \"notification center\", which required an additional swipe to open. And unless you start a habit of checking that separate screen, you can miss them for a long time. The status bar is taken up by the notch, so there is no space for icons there. Phone calls TLDR: Probably fine for 2G and 3G calls, but VoLTE is flaky and unpredictable. Your experience may vary wildly. According to forums, github, and reddit: Some people report no issues placing and receiving calls with PinePhone as-is. Some even use it exclusively as a phone, no other software. Some install and use the FOSS modem firmware, and it resolves their issues. Some people report that FOSS modem firmware causes more issues, and recommend reverting to stock 01.003 or 01.002 version for stability. For me, calls were extremely unreliable. Just for the information, I have T-Mobile as my provider (which is one of the few that allow PinePhone in the US), but I live in a hilly neighborhood of a small city where my signal strength shows 50% at best for 4G, and 25% for 2G. 3G has been disabled and 2G significantly scaled down by all US carriers AFAIK. Because of that, I have to rely on VoLTE for calls. Which, I believe, is the main cause of my problems. As far as I know, PinePhone's modem, Quectel EG25-G, is intended for IoT devices, and technically supports VoLTE, but not officially. These are the issues I had: Modem crashes for no apparent reason. Takes about 30 seconds to restart. Somewhat better with FOSS firmware though. Phone shows 4G connectivity, but modem will reboot or stop responding when trying to call or use data. Seems to happen after long periods of sleep. Unable to place a call. Phone either drops the call immediately, or waits about 30 seconds and then drops it. Presumably, the delay is an attempt to place a call over 2G, which, due to poor signal, does not happen. Sometimes, keeping the phone awake for a few minutes seems to reconnect it to VoLTE, and allows me to call. Sometimes not, and once, I have been unable to call for up to 30 minutes. Unable to receive a call. Callers say their call goes straight to voicemail, or rings once and then is sent to voicemail. I get absolutely no indication of missed calls. Usually happens after the phone has been in sleep for some length of time. One way to improve the chances of receving a call is to keep the phone plugged in and awake. My suspicion is that a sleeping modem cannot accept VoLTE calls, and if a call cannot come in through 2G, it is dropped. Rarely, call drops in the middle of the call, then either one of the above issues happens. Usually, once call is connected, it is fine. Phone gets uncomfortably hot at the top, where the earpiece (and, i suppose, the antenna) is. I tried several firmwares, and they all had their benefits and drawbacks, but the VoLTE problems above persisted for all of them: Biktorgj's FOSS firmware 0.7.4, ADSP 01.003 and others. Lots of cool features (tracking, alarm-via-modem), lower power consumption, automatic checking for stuck SMS messages, modem seems to crash less. However, did not seem to connect to 2G properly, no voice / echo correction (I sound super quiet on the call, and cannot use speakerphone), and no automatic GPS switch (have to run a sudo script to enable it). All incoming calls went to voicemail. Stock firmware 30.006, latest. Had voice / echo correction and automatic GPS, but incoming calls still go to voicemail. Crashes more than FOSS though. Stock firmware 01.002, sort-of-original, and recommended for stability. Has voice / echo correction, automatic GPS, and correctly downgrades to 2G when placing calls. Some incoming calls came through. FOSS firmware by biktorgj Some people on the forum recommended modifying udev rules to keep the power to permanently on for stock firmware (it is set to \"auto\" by default), but that did not seem to help, just increased the battery drain. Out of curiosity, I tried Mobian OS, which uses a different kernel with some modem-related improvements. One noticeable change is a very strong mic boost that sounds like rumbling or cat purr to the other part. I suppose this is to address the \"too quiet\" issue for FOSS firmware? At that point, I did not want to try re-installing firmware again. On that note, UBPorts does not support VoLTE on ANY of their devices. To eliminate another potential cause, I got a new SIM card. I didn't think it would matter, but my friend suggested to do it anyway, as he had to get a new SIM card to get 3G working on his phone (many years ago). That didn't help. Interestingly enough, while I was writing this, calling using my current (officially supported by T-Mobile) Android phone, I got a very similar scenario: about 30 seconds of attempting to call, phone frantically switching between VoLTE and VoWiFi, then dropping the call. The second attempt went through 2G and connected. Maybe I should not blame PinePhone's modem here... Voicemail TLDR: You get cryptic texts. When you get a voicemail, you get a data text message from a short number, so you will know you got one. There is VVMD (visual voicemail daemon), but I did not try setting it up. Texting TLDR: Works well. Basic text messaging through SMS and media through MMS work well and without issues. The default (and only?) text messenger, Chats, does not natively play some formats (for example, 3gp video), but they will open as long as you have the appropriate application. I really have no complaints here because I remember when getting MMS and unblocking the SMS queue on the modem were manual operations. On PinePhone, text messages will wake up the phone, so they are almost realtime, as one would expect. Messaging TLDR: Works well, no notifications in sleep. Although Chats lets you use Matrix accounts and even supports encryption messaging, there are several usability issues, resulting in disconnections, missed messages, and crashes. For Matrix, Fractal (via flatpak) works very well, although has some minor UI issues. Nheko works well, seems a bit faster, and has swipe controls (if that's your thing). For XMPP, I have used Dino in the past, and it is also a very well-made messenger, with audio and video call functionality (which I have not tried). I do not have any contacts on Signal, so I have not tried any Signal clients or bridges. For WhatsApp, I run a Matrix bridge, so 99% of messages are routed through my Matrix client. For once-in-a-while calls, I use an old device I keep at home. Camera TLDR: Potato, no video out of the box. Camera works okay. Raw camera data has to be post-processed to balance colors, so it takes several seconds for a photo to appear in a directory. Sometimes, post-processing fails and you get a black rectangle. Editing some shell-scripts, I removed the heavy part of post-processing (sharpening) and reduced the processing time to around a second. The quality is poor by any standard since 2010: the pictures are grainy and have low dynamic range. At the same time, they look like old film photos, and there's a certain charm to it. Do not let the phone go to sleep with the camera app open, or it might enter a state where it cannot wake up and needs to be rebooted. There are no apps to shoot video, but it's possible via scripts (I have not tried). While having a bad camera can be frustrating, think about all the pictures you took and never looked at again. Navigation TLDR: Works. Not Google Maps though, learn your local roads. Osmin is a good navigation app with live directions, voice, and offline maps. GNOME Maps 45 and later has decent mobile UI, but does not have offline capabilities AFAIK. As is with many apps based on OpenStreetMap data, do not expect that you'll be able to find an address (at least in the US) in Osmin, so use POIs or intersections instead. I think the only app that supports address lookup is Pure Maps, but it was fairly slow for me. PinePhone's GNSS/GPS module works through the modem. Which sort of makes sense, but then, you can't use GPS without a SIM card installed... When GPS is enabled, it takes 10-15 minutes to get a precise location. Before that, your location is derived from Mozilla Location Service, map of known WiFi spots and their approximate locations, so it can be VERY rough (precision of a few streets away for me). GPS module does support AGPS (assisted GPS, locations of satellites downloaded over the internet) for faster location detection, but AFAIK none of the OSes implement that. (In fact, the modem has the config for it, and should be able to download it itself). Interestingly, on my degoogled Android, I get a similar experience - very rough location until ~10 minutes later. Makes you consider how much Google knows everyone's router's location. Music TLDR: Spotify playback is spotty. I listen to mostly Spotify, and there is a mobile Linux client called Spot (both postmarketOS/Alpine repos and Flatpak). The main issue with it is that the playback stops after 2-4 songs. Not sure if that is an application issue, or the classic \"sound on Linux\" issue. Of course, there's an official Spotify client, but it is available only for desktop Linux (x86_64). There is spotify-qt, which did not work for me, and spotify-tui for the terminal(!), which I did not try. Browser TLDR: Stick with Firefox ESR. Firefox ESR is the default on many Linux distributions. It is a desktop browser, adapted for mobile. Although it takes a while to load, the browsing is fast. There are some UI issues, and it can feel clumsy to use sometimes, but you should be able to do everything a desktop browser can. And it includes uBlock Origin add-on by default! GNOME Web has great UI, some adblocking, and Firefox account integration (!), but the renderer itself (based on WebKit) is just too slow. Angelfish has a nice UI and seems relatively fast, but I haven't used it much to have an opinion. Another interesting option is BadWolf, WebKit-based browser with toggles for JS and images. Great idea, but I couldn't use it because it cannot focus on a textbox on the page (e.g. search box) And for the terminal, there is the good old Lynx and w3m. For gemini, Geopard looks and works really well. Notes TLDR: Several options. I used gedit instead of the newer Text Editor to keep notes, as I found the UI better (fewer steps to do things). There are several note-taking apps, but they are too slow and have too many features that I don't need. Android applications TLDR: Possible. To run Android applications, postmarketOS supports waydroid, which was surprisingly easy and straightforward to install. Launching LineageOS takes about a minute, and running apps drains the battery much quicker, but I was able to install and use a few things from F-Droid and Aurora Store. Expect apps to complain about Google Play Services. Connecting to PC TLDR: UNLIMITED POWER! The \"killer feature\" of PinePhone is that you can SSH into it as any other Linux machine. If you run SXMO, you can easily navigate the same menus and text/message through the terminal. I wrote a small rsync script to backup/sync notes and pictures onto my laptop. It does not require Syncthing (saves PinePhone's limited resources) or any complicated setup. On Android, I sync my notes and pictures using Syncthing, which requires some setup, but is very convenient too. On iOS, photos are not considered files (WTF Apple?!), so they cannot be synced with Mobius (Syncthing-like app). So the only way to back them up is via USB (which requires additional setup on Linux). Conclusion My daily adventures with PinePhone have reached their end. PinePhone is refreshingly straightforward, and practical for many of my daily tasks. Alas, it was not much of a phone. Perhaps PinePDA would be a more fitting name.",
    "commentLink": "https://news.ycombinator.com/item?id=39145701",
    "commentBody": "PinePhone review after a month of daily driving (yaky.dev)165 points by yaky 15 hours agohidepastfavorite139 comments Almondsetat 14 hours agoI don't know what to make of the fact that 2005 Nokia or Blackberry feature phones had orders of magnitude better software and performance than the PinePhone. Mine is still sitting in a drawer. I take it out twice a year to update it and see if the lock screen (a static image with a text field) still lags and misses inputs reply yaky 13 hours agoparentOn one hand, it's disappointing. On the other hand, most of the PinePhone software has been developed, adapted, and patched by enthusiasts. Many applications were never intended to work on mobile devices in the first place. And no top-down direction. Android and iOS have been around for 10+ years, and it would be interesting to compare early Android to PinePhone now. I believe PinePhones ship with Manjaro and Plasma Mobile, which is notoriously slow and unstable, and is part of the reason why I went with Phosh. For a more feature-phone experience, there is an ongoing project to put NuttX RTOS on PinePhone [0]. For a very performant and customizable but unusual (button navigation, terminal-based) experience, there is SXMO [1] 0: https://lupyuen.github.io/articles/pinephone2 1:https://sxmo.org/ reply tetris11 12 hours agorootparentPhosh is amazing. I'm currently running it on an Alcatel Idol 347 (2015) with 1.9GB using PostmarketOS, and it's just snappy and responsive as any Android UI, using ~ 300MB in RAM with the desktop. Very happy with it. reply pinethrowaway 8 hours agorootparentDoes wifi tethering work ok on that phone? reply xethos 7 hours agorootparentSomething I learned recently is that tethering works correctly on the Pro - had to use it for my Kobo. I was looking around for wifi, and eventually figured it was worth looking into for the Pinephone Pro. And it... just worked. Entirely via GUI, with no hiccups (using Phosh) reply Muromec 11 hours agorootparentprevSXMO was basically the only thing that didn't lag on PinePhone for me. Which makes sense, as it's basically sway with dmenu for phone interface. I was very excited about the whole thing and even made the same scripts work for my desktop sway with baresip, but then decided to just use a normal reliable feature phone that looks cool. reply thaumasiotes 5 hours agorootparentprev> Android and iOS have been around for 10+ years, and it would be interesting to compare early Android to PinePhone now. I used a Nexus S running CyanogenMod more than 10 years ago. Lagging and missing inputs were not problems. The Nexus S is notionally still supported by LineageOS today, but trying to actually run LineageOS on it is unbearably slow. reply ParetoOptimal 13 hours agoparentprev> I take it out twice a year to update it and see if the lock screen (a static image with a text field) still lags and misses inputs Yeah as soon as I got my pinephone and the lag on the lock screen happened I had a sinking feeling it wasn't going to be that great. reply halcek 13 hours agorootparentThat's just a matter of software, not hardware. You can try different UIs, SXMO's quite fun, for example. reply ParetoOptimal 13 hours agorootparentWell... you don't know that until you go to the trouble of installing different software which can be a significant time investment if you haven't done it before. Also, I tinker with many of my devices but it would be perfectly valid if the pinephone I purchased I wanted to just work out of the box, at least to the extent where the first screen doesn't lag on keyboard input. That's a huge sign of immaturity at least in the QA process (if one even exists).j Mind you, I really want things like Pinephone to work and be a viable alternative to the general ad/spyware infested crap on the market. reply nsajko 6 hours agorootparentPinephone is not an end-user product, it's explicitly meant for hacking on it as a hobby. reply sangnoir 1 hour agorootparentprev> I purchased I wanted to just work out of the box, at least to the extent where the first screen doesn't lag on keyboard input. The Pinephone home and order pages had a warning in figurative blinking neon signs clearly stating it's not for consumers and squarely targeted at developers interested in making the software better. reply em-bee 12 hours agorootparentprevit is also the hardware. my budget for a phone is about $150. i have been thinking about getting a pinephone (with a keyboard) but that would have been twice my budget, and after i saw a friend with that having trouble getting the keyboard working, i passed on it. before i had a fairphone 3, which i had received as a gift, but its performance was worse than the $150 phone i had before that. now however i got a very good deal (slightly over my budget) on a refurbished 3 year old oneplus nord that new would have cost $400. and boy, i have never had a phone that was that good. not only is it much faster, the battery lasts longer too. i can now understand why people like to spend money on a high end phone. i still won't spend that much but thanks to refurbishing services i don't need to. i really appreciate what fairphone and pinephone are doing. we need these alternative phones. i had my share of them, firefox phone, geeksphone. a sailfish based phone from india, a samsung phone running tizen. i even got a second hand openmoko very cheap because the owner was unsatisfied with it. and i can really see the evolution. the problem is that these phones are a few years behind the curve and that the apps are written for high end phones. (the fairphone was really struggling to run wechat) so actually, in theory you should be right. there should be software that is snapping fast even on these phones. i mean even the openmoko had usable apps. but in practice, sadly the hardware is simply a limitation. perhaps in a few years phones will reach the same state that desktop and laptop computers have now. they can only speed up by adding more cores, and individual applications can't really go any faster, so a 7 year old computer still performs fine, even for my kids as a gaming device. reply paulproteus 10 hours agorootparentWith that kind of budget, you can get an iPhone SE 2020: https://www.backmarket.com/en-us/p/iphone-se-2020-64-gb-blac... . If you can spare an extra $50, I'd go for the current model: https://www.backmarket.com/en-us/p/iphone-se-2022-64-gb-star... ($202) That's basically what I did: https://announce.asheesh.org/2022/09/i-switched-to-iphone-fo... reply em-bee 10 hours agorootparentinteresting, but i only buy devices where i can install alternative operating systems. that makes iphones entirely uninteresting to me reply thaumasiotes 5 hours agorootparentprev> the problem is that these phones are a few years behind the curve and that the apps are written for high end phones. (the fairphone was really struggling to run wechat) I didn't see issues running wechat on a Pixel 3a, which is slightly older than the Fairphone 3. I replaced my 3a with a 6a, but not for any performance-related reasons. Maybe there's something weird about the Fairphone 3? reply bitwize 10 hours agorootparentprevPart of the problem is Phosh is basically fucking GNOME and inherits all the GNOME enshittification including a render path that requires considerable CPU/GPU oomph to draw smoothly. Windows has a smoother UX on old/weak hardware than GNOME. I don't know why this is and why they can't (or won't bother to) get their act together, but when it comes to a responsive UI, a bare X WM that uses regular 2D draw calls trounces GNOME. On the PinePhone that pretty much means SXMO. reply TingPing 6 hours agorootparentphosh is a custom compositor (phoc) not based on GMOME-Shell at all. It is a simple one made purely in C. reply rchaud 12 hours agoparentprev2005 phones weren't running anything close to a desktop OS. A more reasonable parallel would be the barely-released Nokia N9 from 2011 running MaemoOS. It was abandoned upon launch because the company had already agreed to go exclusively with Windows Phone OS. With that said, I think 3GB RAM feels very low for a device running this kind of software. Even the Nokia N9 had 1GB RAM. reply Almondsetat 10 hours agorootparentAsking feature parity with 20yo feature phones is the bare minimum. reply Loranubi 2 hours agorootparentprevThe iPhone SE 2 has 3GB memory and runs pretty smoothly. reply Saris 10 hours agorootparentprev3GB RAM is wildly low when most Android phones have 8-12GB these days. And the Pinephone is running much heavier software. reply ElectricSpoon 8 hours agoparentprevWhen I look the hardware in it, I feels like the pinephone is just a step above what I would have built from a 3d printer, custom PCB, a microcontroller and an IOT modem from sparkfun. Every part is average, but the sum of it allows calling and has a usable idle battery life. Such a collection of hardware can't realistically compete with mainstream phones which have very tight hardware and software integration to achieve the most performance with the least power draw. It's a bad phone (and bad portable computer), but mine might work for as long as LTE and my desire to recompile exist. Schematics, opensource and spare parts being available are the crux of it. It's the phone for those wanting to build their phones and it's pretty good at that. reply pinethrowaway 8 hours agoparentprevThe only usable OS for the PinePhone had been PostmarketOS with sxmo-de-sway. I had to do lots of tasks using the terminal, but it allowed me to have a stable connection and Wifi hotspot. Phosh and Plasma would disconnect or crash often. I also got lots of shifty looks using my phone on the train as if I were a hacker terrorist or something. It's been much smoother using LineageOS on a very old OnePlus One than the Pinephone, but I still keep it around to try out new OS updates. reply jksmith 5 hours agoparentprevYeah agree with similar experience, and yeah, made me pine (no pun) for my Key2 with a physical keyboard, which was generally bulletproof. There's a reason BB dropped out of the phone business, I get that, but I'd pay iphone prices for a new BB Key2 that was de-googled. But I would not pay iphone prices for an iphone. If the market was still free, the future would be a BB committed to trust reciprocation. But it's too late now. So aside from de-googled provided by some specific vendors, just fuck phones. reply megous 8 hours agoparentprevI doubt it. Pinephone can run this on 1920x1080 screen: https://xnux.eu/log/videos/libreelec6.mp4 Could 2005 Nokia do that? reply Almondsetat 30 minutes agorootparentDo you think a good phone is one that runs Kodi but can't manage calls and messages? reply vdaea 13 hours agoparentprev>I take it out twice a year to update it and see if the lock screen (a static image with a text field) still lags and misses inputs There are some people who do not notice things like this. Or they don't give them importance. Fill your team with them and get prepared for the shitfest. reply Aachen 14 hours agoprev> UNLIMITED POWER! > The \"killer feature\" of PinePhone is that you can SSH into it as any other Linux machine OP, you might be interested in Android I think. It runs a Linux kernel, you can enable root access, and then use something like Linux Deploy to install a distro of your choosing that runs as though it's a normal app. I've been using that since my first Android device and have been able to ssh into my phone \"just like any Linux machine\" this whole time. Indeed, I find it a killer feature and don't understand not more people want to access their DCIM folder via sshfs (bookmark it in the file manager for easy access, never get your phone out of your pocket anymore to send a photo to PC) or make full-system backups via something like restic. I also use qalc as calculator on the command line whenever I need more than simple multiplication. Fully recommended. (Do use ssh keys instead of a password to avoid needing to type some super strong password on the phone to connect to localhost, since phones get taken into all sorts of untrustworthy WiFi networks) reply powersnail 11 hours agoparent> don't understand not more people want to access their DCIM folder via sshfs The thing is that, despite owning rooted Androids, pinephones, and jailbroken iPhone (old days), I have found no real use personally for all the unlocked potential of those devices, beyond the fun and coolness of tinkering. I need to access some photo from PC maybe once every year. I don't edit photos, or categorize them, and if I were to share them, it's likely that the channel already is on the phone. Writing programs on the go? I have installed vim and emacs and set up a lot of crazy stuff on phones, but at the end of the day, I'd rather just carry a laptop. It's too hard to type on the phone regardless of what program you install, and if connected to a external keyboard, the screen is too small. I just don't have a scenario where I want to write programs while not able to bring a laptop. In other words, the hardware and form factor is so limiting, that I don't find unleashing the software to be much of a use, even after spending a lot of time setting them up. I hope I can find some practical reasons, because I really like the tinkering, but I haven't. (This is, of course, highly personal. A lot of people might find many practical use cases.) reply graphe 11 hours agorootparentI used to set an 80% battery limit and want root for adblock and backing up apps. With a desktop chrome equivalent it becomes very useful even without root today. The iPhone gets better and better but I jailbreak for a clipboard that isn't a single paste. reply cristoperb 14 hours agoparentprevYes. Even without enabling root, you can install Termux[1] and have a full Linux cli environment with ssh. > don't understand not more people want to access their DCIM folder via sshfs I agree. I sync my camera folder with Syncthing[1], so as soon as I take a photo it is available on my laptop. 1: https://termux.dev/ 2 https://syncthing.net/ reply hmottestad 13 hours agorootparentI can also recommend the Apple ecosystem. My phone and MacBook keep, messages (and sms), contacts, calendar, clipboard and also photos in sync. reply yaky 13 hours agorootparentI disliked iOS for specifically being absurd about photos. They are not considered \"files\" and therefore cannot be synced by Mobius / Syncthing. I don't want to go through the hassle of hosting Nextcloud to get photos from my phone to my laptop when both are located on the same network. (Not really relevant anymore since I don't own any Apple devices) reply hackmiester 12 hours agorootparentThis app is what you want. It can push the photos to NFS or Samba over the network. https://www.photosync-app.com/ Maybe it will help someone who still uses an iPhone. reply graphe 11 hours agorootparentWhy that one specifically? Doesn't say anything about free or open source. I use this one. https://immich.app/ reply NortySpock 8 hours agorootparentNot your parent poster, but I appreciated that Photosync was a one time purchase, and developed by a German company. Worth it to have a solid backup tool that can push to a Samba share. reply alan-hn 13 hours agorootparentprevWhy not just recommend nextcloud. You can host it yourself and it backs up and syncs your photos, calendar, contacts, and other files automatically And you get to own your data instead of relying on Apple reply COGlory 13 hours agorootparentYeah I use NextCloud. It syncs contacts, calendars, tasks, notes, news, podcasts, recipes(!), photos, and any arbitrary files. If you don't want to self host, just get a Hetzner storage share for $4/mo or whatever it is. reply darkwater 12 hours agorootparentprevConsidering this is a post by and for Free Software enthusiasts, I don't think they would. reply asimovfan 12 hours agorootparentprevI would definitely not recommend that ecosystem as you can't even plug it into a computer and take things out of it / put things in. reply sodality2 11 hours agorootparentI can access my photos by plugging my iPhone into my Linux or Windows PC. reply yjftsjthsd-h 12 hours agoparentprev> OP, you might be interested in Android I think. It runs a Linux kernel, you can enable root access, On average, that's not really true. Android uses badly modified and unmaintained versions of Linux (the kernel), and both root access and the ability to install a replacement operating system are immensely variable depending on the vendor and the exact model. Pine products typically maintain some degree of downstream patches, but they are trying to run mainline Linux and do actually keep up with kernel updates, while also giving the user root access out of the box by default, no caveats. reply jhasse 10 hours agorootparentThis has improved a lot with Android 12 and Google is working towards using a nearly unmodified Linux LTS kernel. See https://arstechnica.com/gadgets/2021/09/android-to-take-an-u... If you can enable root access depends on the boot loader though, which is a different story. If you want to be safe, get a Pixel. reply Aachen 9 hours agorootparentSamsung is also a safe bet afaik, or Fairphone of course. For manufacturers where you need to apply for an unlock code, do it within the legal return window of the device (minimum 14 days in the EU (or EEA?) for online purchases), so then that's also a safe bet. Don't need to use the code straight away, though I'd recommend it as it typically (as an extra hurdle¹) wipes the device and you don't want to be doing that once all your data is on there ¹ user safety security blah blah yeah. If it were about my privacy, it could show the same consent prompt as it does for uploading my pictures and live location and rest of my life to a megacorp. If anything, that decision should have an unlock code you need to apply for and supply on a command line to avoid making a mistake in haste reply Aachen 9 hours agorootparentprevNot sure I'm deep enough into Linux to understand why it matters to run an unmodified mainline kernel version. Everything I've tried to apt install inside the Linux Deploy Debian userspace either worked or ran into selinux restrictions (more and more in the latter category; RIP wavemon, for example, as a better alternative to rate-limited WiFi scanning apps as of around Android 9) reply yjftsjthsd-h 7 hours agorootparent> Not sure I'm deep enough into Linux to understand why it matters to run an unmodified mainline kernel version. Updates. The closer you are to mainline, the easier it is to move to newer versions as they come out (and the more quickly, which especially helps with security patches). reply xattt 13 hours agoparentprevI don’t understand how the author can say KILLER FEATURE if using the killer feature is impeded by a fundamental feature (crappy screen). I, too, had a stage where I was obsessed about some electronic thing that had significant usability issues in day-to-day life. In my case, it was a tri-band EU phone that could only do GSM1900 on a North American network with shitty indoor reception, and cost a pretty penny compared to what was on the market at the time. Never again. Edit: I misread the parent comment, and didn’t realize the SSH part. reply heleninboodler 13 hours agorootparentMaybe I'm misunderstanding you... how does the crappy screen affect your experience when you're ssh'ing into it? reply xattt 12 hours agorootparentI misread the comment… reply nsajko 6 hours agoparentprev> you can enable root access One may be able to get root, but the resulting system isn't very useful. Many apps query Google's attestation and integrity APIs to detect this and then refuse to function. Basically it's a thing of the past. reply squarefoot 14 hours agoparentprevOn one of my old tablets (Android 4 or 5) years ago I put and configured Syncthing so that it would sync automatically all user data to the home NAS running Nas4Free (now XigmaNAS). Didn't make much use of it, but it worked. reply kaanyalova 11 hours agoparentprevYou can also use Kde Connect for file sharing using sshfs if you don't want to configure it manually. The feature is called \"Filesystem Expose\". reply Aachen 9 hours agorootparentI'm not familiar with that, but I'm curious how it can be simpler than what I described using the regular file manager you've probably already got installed. For me, using the defaults of Debian with Cinnamon, the steps are 0. get ssh working 1. type into the location bar of the file browser: sftp:// and then whatever the ssh command would use, e.g.: sftp://root@samsung-0bd2c41 2. there is no step two, you've already got a mounted filesystem Of course, there's some details hidden in step zero, but if KDE Connect uses sshfs as well, I'm not sure how it gets simpler than this to \"expose\" (this means mount, right?) the filesystem. Does KDE Connect do it bidirectionally or so? (I wouldn't actually want that, as my laptop is the trusted device of the pair) reply saidinesh5 2 hours agorootparentPair your phone once with PC (It also supposedly works with Gnome but i never used it) using a single click via. KDE Connect. The phone icon shows up in your file manager without you having to do any additional configuration. Click and browse like any networked folder. Advantage is KDE connect also brings a lot of useful features alongside just accessing phone files. Can share clipboard, notifications (can even reply from desktop), execute commands on pc from phone and vice versa and a lot more reply singpolyma3 13 hours agoprev> Verdict: PinePhone is a great mobile Linux device. I would use it as my daily driver, and probably iron out some issues I ran into, but for me, it failed at... being a phone. I had repeated, unpredictable problems both placing and receiving calls, and I could not resolve them. See below for details. Sounds like exactly what I want. It has been well over a decade since I used my cell radio for anything but data. reply nomel 13 hours agoparentFor me, it is almost exclusively used for some sort of an emergency, the last being a couple weeks ago, where I had to call in for roadside service with a rental. You're not getting through to customer service from the web. Most of my received calls are also some sort of emergency. I suppose if you have some reliable VoIP setup, it might work. Regardless, it's shoddy, dumb, and shouldn't be celebrated. reply lcnPylGDnU4H9OF 13 hours agorootparentI've put a fair amount of thought into the decision to not carry a phone everywhere I go and this beast always rears its head. Obviously, there was a time when people didn't have phones but society's more or less moved on; people generally expect others to have one and social services reflect that. Anyway, I think reading this comment kinda gave me my answer: be selective about when I take my phone. Kinda the inverse of the murderer not taking their phone when they go to hide the body (I'm not planning to murder anyone); I just don't take my phone unless I plan on being in a situation where there will not be a good alternative to having my own means of communication, e.g., a road trip or vacation. Traveling within my city of residence will likely be feasible, especially if I try to do so primarily with a vehicle smaller than a car. But yeah, if one has this idea, keep in mind that people started taking their phones everywhere because they're useful in many situations. reply bluGill 12 hours agorootparentWhen people didn't carry a phone with them there were pay phones all over that mostly worked. Not nearly as convenient as a phone in your pocket and in rural areas hard to find, but could count on one at every gas station, fast food restaurant, and other such places: so they were common. Today they are hard to find at all (and probably don't work if you see one). Thus if you don't have a phone with you, you will run into a worse time than in the past. (OTOH, most people didn't use a pay phone ever - they were expensive) reply brnt 13 hours agorootparentprevI had a Palm PDA and have kept using smartphones for productivity apps, calendring, musical, photos as of the beter part of a decade. The fact that it van place and receiver calls really doesnt matter to me, but PDAs dont exist anymore, and so, why not installatie a basic sim? My 'phone' has been really useful to me so I take it basically always with me, unless I specifically know I don't need it (such as going for a swim). I don't take calls if I don't feel like it, but very few people call me. Do you not use you phone for other things than communication? reply lcnPylGDnU4H9OF 12 hours agorootparentI do use my phone for other things but I could use a \"mobile Linux device\" just the same and without the snooping from cell towers, which is my primary concern (for trivial, self-inflicted reasons to be fair). In practical terms, my phone stays in my pocket until I'm home anyway. To disincentivize me from using it outside my home, I turn off mobile data, which has made it obvious to me that I never use it in public and only carry it around for fear of some emergent situation which would otherwise be trivialized by the ability to communicate over a long distance. Also, something weird happened when I regained the ability to avoid looking at a device in my hands: I started to see that everyone is addicted to their phone. Used to be that any time I had to wait for any length of time, my first instinct was to pull out my phone. Now I just look around and see everyone else do that. The decision to leave my phone at home (with exceptions) is an extension of that change in my habits. reply em-bee 10 hours agorootparentthe primary feature of my phone is to be an audio player, and to research stuff online when i need that on the go (look at maps, search for specific shops, etc), also the shopping list, and taking pictures. messaging is there too, but my phone is always on silent, so like you i mainly use it for urgent stuff. reply nomel 9 hours agorootparentprevI would say my Sony Clie was peak technology symbiosis. Offline, so mindless consumption wasn't possible, but it was filled with books that were carefully selected. Physical writing interface, that tickled that physical part of the brain. I wrote and read more, with quality, than any other time in my life. reply smt88 13 hours agoparentprevYou can easily configure an Android phone so that it doesn't make calls, but it's insane to have a phone that can't make calls. reply smabie 1 hour agoparentprevYou haven't talked on your phone in 10 years? reply awestroke 13 hours agoparentprevUntil you have to call 911 or equivalent and it doesn’t work reply bluGill 12 hours agorootparentYou can flag down someone to call 911 if it is an emergency. Most people will be happy to help once you get their attention. of course if it really is an emergency seconds count and flagging down someone may cost a minute. 911 is a free call, no sim needed. So if that is your only concern a phone that you don't pay for may be fine. reply earthling8118 11 hours agorootparentFlagging someone down to call for you isn't a workable solution. For one, you could easily be nowhere near a city and need to call from the middle of nowhere. For people in the US (and I'm sure elsewhere), the cities are car centric and you could easily be nowhere near anybody out walking around. A regular phone without a sim could work though reply bluGill 11 hours agorootparentThe places so remote you cannot flag someone down are also so remote that you don't have cell service. Most roads that look untraveled still get a fair amount of traffic and so someone will be along soon. reply livueta 10 hours agorootparentThat's assuming someone stops. A while ago I was driving down a road like you describe in the rural pnw and stopped for a person attempting to flag down traffic. They'd gotten their vehicle locked behind a DNR gate and their phone was dead. They were ridiculously grateful because they'd been trying to flag someone down for over an hour and had been ignored by dozens of vehicles, and they didn't even look sketchy or anything. Goes back to the societal assumption that everyone has a working phone: \"if there's cell service, why don't they just call someone?\" reply buildbot 11 hours agorootparentprevThis is absolutely not true for a vast part of the PNW. For example, with Verizon, I've bailed myself out of several situations where the alternative would be - wait (nobody showed up in the time we were waiting for help when we called, so hours more at least) or walk 20+ miles. I've also been in a situation where if we did not have a sat phone in our group, someone very well may have died from heat stroke/way to many sunburns. reply theshackleford 10 hours agorootparentprev> The places so remote you cannot flag someone down are also so remote that you don't have cell service. What an absurd claim. reply soupfordummies 11 hours agorootparentprevIf you're at the point where you're flagging down a stranger to call 911 in an emergency, why not just fully \"cut the cord\" (no pun intended) and stop carrying a phone at all? reply jraph 10 hours agoprevI daily drove it for a year. I now use a feature phone (my first phone!) because the PinePhone took water because of a big rain and took some time to recover. In the meantime I got used to my old feature phone again and the voice quality doesn't suck for the person at the other end of the call with this. Moreover, the PinePhone is unreliable as a phone and I think SMS and call reliability is critical. I also have a PinePhone Pro from when it was affordable. It totally fixes the lags and is fast, making it difficult to use the regular PinePhone again. However, it heats too much and doesn't last long enough on the battery. The PinePhone in general should not be expected to replace your main phone unless you know otherwise. It is still a prototype Linux mobile phone for testing and developing Linux stuff. I still use it daily though. Still useful as a GPS device, to display train tickets and QR codes, to watch videos, listen to things and casually browse e.g. in bed (make sure you don't wrap it in your sheets though). It's not generally practical yet. An Android phone will beat it. It is one of the most practical mobile devices if you care about FOSS and need some smartphone-like features besides calling. Is also occasionally use it as a 4G access point, I also just use my feature phone as a 3G access point through bluetooth for the pinephone when I both want both the calls to work and the smartphone feature or when I'm lazy and don't want to move the sim card but this can be slow. It is an essential device that may make it possible to have an actual fully working Linux mobile device in a few years. reply Tade0 14 hours agoprev> Compare to Android, which involves unlocking the bootloader, flashing recovery, booting into recovery, flashing an OS image, and possibly patching the image to get root. During the holiday break I installed Lineage OS on my father's 10-year-old Motorola Moto G. Turns out in order to unlock the bootloader you have to fill an online form and get a code that unlocks it via email. Additionally initially no custom recovery would install due to an outdated bootloader. I managed to patch it using a script some lone developer wrote for personal use. reply charcircuit 12 hours agoparent>Turns out in order to unlock the bootloader you have to fill an online form and get a code that unlocks it via email. This is to combat groups of people who flash malicious OS builds to phones and resell them to innocent people who have no clue the phone they got is compromised. reply okanat 12 hours agorootparentAlso many frequency bands that modern phones use are regulated, especially heavily with LTE and later due to mixings with the military and public service frequencies. The baseband chips have modifiable software that can be stored in the same flash memory. The companies are trying to avoid the blame by creating a paper trail, if someone modifies a phone to illegally broadcast protected frequencies. reply SV_BubbleTime 6 hours agorootparentprevBut now the phone is flashed, so how did this change anything? reply mixmastamyk 8 hours agorootparentprevAll phones are compromised, see the recent hardware backdoor found in iPhone. reply charcircuit 7 hours agorootparentHaving an operating system that uploads all passwords, makes your phone into into a residential proxy, or other bad is no where comparable to the idea that phones can have security bugs. The \"backdoor\" you are referring to was not a backdoor as the system had to already be compromised to use it. reply mixmastamyk 6 hours agorootparentNot by the powers that be, no. Making a division between public criminals and private ones is amusing to say the least. reply autoexec 12 hours agoprevAll the open/pro-privacy/pro-consumer cell phones I've seen (pinephone, Fairphone, Librem) never go far enough (non-open cellular modems/wireless chipsets) while also being either insanely priced, unobtainable, barely functional, scammy, broken, or some combination of those things. I really want a product like that to succeed, but I'm just not seeing anything reasonable being produced. reply NoboruWataya 11 hours agoparentProbably because developing and making those things is extremely expensive. The \"traditional\" smartphone manufacturers have far lower per-unit costs because of economies of scale and because they externalise many of the production costs by using low-paid labour and environmentally destructive practices. (Some \"open\" phones probably externalise these costs as well, but Fairphone in particular is so expensive because it tries to avoid doing that.) Not to mention that those lower production costs are then further subsidised by the manufacturers' efforts to extract value from the user in other ways. Every time someone tries to make an open/pro-privacy/pro-consumer phone and doesn't produce a perfect product they get heavily criticised, but I think they are up against some fairly fundamental limitations. The fact that there isn't really a satisfactory option out there despite numerous attempts suggests to me that the problem is not with the specific products or companies but something more fundamental. I don't think it will ever be feasible for ethical phones to compete with non-ethical phones on cost. reply autoexec 11 hours agorootparentI'll agree that major smartphone manufacturers will probably always be able undercut them on price. I'd be more forgiving on cost if they actually delivered a quality product, especially one with open chipsets. reply mixmastamyk 8 hours agorootparentHow many open modem chipsets that work are there? Honestly even if one exists it’s a luxury until there’s (other) hardware and software that actually works. 1. Get it to work 2. Sell them 3. Profit 4. Reinvest in hardware That’s what Apple did. reply okanat 10 hours agoparentprevThat's made almost impossible by the bigger players in the SoC world like Qualcomm and Samsung. They created a multi level oligopoly which can only be challenged with nation state support (like Mediatek and Huawei did). The problem is the drivers and documentation for those chips are very limited and short-lived. One simply doesn't get it without signing an NDA and buying some high thousands. Without documentation it gets harder to optimally program them. On top of that add the know-how. Due to both NDAs and pure difficulty of working with low power systems, it is really hard to hire engineers who are both very knowledgeable and not bound by NDAs and willing to work on community projects that doesn't pay the significant wages that the consumer tech giants do. Desktop Linux can get away with it if the desktop computer consumes slightly more power or laptop battery life is 2 hours shorter. People accept it. For phones any extra operations cause significant power usage. Everything in the stack needs to be optimized for it and regular Linux desktop stuff often isn't. Android has much tighter controls but it is 5-10x harder to program in the lower levels which again limits the supply of the engineers. This is just getting a simple SoC and running Linux on top. Add similar complexities for every single peripheral. reply autoexec 7 hours agorootparent> That's made almost impossible by the bigger players in the SoC world like Qualcomm and Samsung. They created a multi level oligopoly which can only be challenged with nation state support (like Mediatek and Huawei did). Which is why we need new chips to replace qualcomm/samsung/mediatek entirely in open devices. It's kind of crazy that nobody is willing to even attempt it. I'd gladly take the inevitable massive hit to performance if it meant fully open, documented, and auditable devices. reply giantrobot 4 hours agorootparentFully open wireless basebands are unlikely if not (legally) impossible. Modern radio front ends have significant software control/definition from the baseband chipset/firmware. They'll happily run outside of regulated limits (ERP etc). The only reason they can get Part 22/15 licenses is because their firmwares are sold locked down and can't be adjusted outside of regulated limits. Anyone that gets halfway interested in trying to make an open baseband, necessitating a custom radio front end, gets quickly uninterested once they look at the development costs and then needing to get a license. reply mixmastamyk 1 hour agorootparentProbably not economically viable in general but a device could have floss *ware and ship with immutable firmware. reply xethos 6 hours agoparentprevThis [0] is the closest we have so far - almost entirely FLOSS, and it consumes ~1/4 (IIRC) the power of the stock firmware. It's also never going to be the default Pine64 ships with, because no OEM wants to tell the FCC \"We asked the users nicely not to send erroneous signals. No, this was not lab-tested, nor verified by the FCC to not interfere with other devices.\" Considering the legal limitations, I think this is an absolutely amazing point to have gotten to. OP may have issues, but he mentioned even his Android handset had similar issues. I have a pretty good carrier (for a carrier), amd have pretty well no issues using my Pinephone Pro as my actual smartphone. I just carry a spare battery :) [0] https://github.com/the-modem-distro/pinephone_modem_sdk reply jancsika 11 hours agoparentprev> (non-open cellular modems/wireless chipsets) > barely functional > insanely priced > I'm just not seeing anything reasonable being produced. It's not reasonable to offer an affordable phone that also runs an open source baseband OS that has been tested to work reliably with the most popular carriers. reply d--b 14 hours agoprev> Verdict: PinePhone is a great mobile Linux device. I would use it as my daily driver, and probably iron out some issues I ran into, but for me, it failed at... being a phone. I had repeated, unpredictable problems both placing and receiving calls, and I could not resolve them. See below for details. Yeah. reply xethos 6 hours agoparent> Interestingly enough, while I was writing this, calling using my current (officially supported by T-Mobile) Android phone, I got a very similar scenario: about 30 seconds of attempting to call, phone frantically switching between VoLTE and VoWiFi, then dropping the call. The second attempt went through 2G and connected. Maybe I should not blame PinePhone's modem here... reply jraph 10 hours agoprev> PinePhone's GNSS/GPS module works through the modem. Which sort of makes sense, but then, you can't use GPS without a SIM card installed... Soon a thing of the past. I worked on a ModemManager patch to fix this, and a MM maintainer reworked and merged it last month [1] > When GPS is enabled, it takes 10-15 minutes to get a precise location. You can manually inject AGPS data to get an instant precise location. Not ideal but this shows the situation is fixable. See instructions for this also at [1]. As for offline mapping, PureMaps with OSM Scout Server works well enough. [1] https://gitlab.freedesktop.org/mobile-broadband/ModemManager... reply yaky 9 hours agoparentThank you! This will be useful as I have considered PinePhone as a carputer / navigation device. reply pxeboot 5 hours agoprevI run Phosh on a OnePlus 6. It is honestly pretty good these days. There are certainly bugs and missing functionality, but it works great for many tasks. I especially like having desktop Firefox with uBlock on a phone. Unfortunately, without popular apps being readily available, there is zero chance this goes mainstream. Desktop Linux has a better chance of surpassing Windows. reply mixmastamyk 59 minutes agoparentWhat is the base os, did you have to break in? reply bhpm 14 hours agoprevSo what is the bar for being a “great mobile Linux device” if it doesn’t include “reliably making phone calls”? reply cookiengineer 2 hours agoparentBoot2gecko and gaia were pretty much what I wanted. But then vendors acted like assholes, and labelled phones as \"open\" without any possibility to get the source, let alone develop anything for their devices due to lack of working build tools. reply yaky 13 hours agoparentprev1. Great community 2. It's mobile 3. It's Linux It did not reliably make phone calls *for me*. There are plenty of people on forums and Reddit who use it. reply tekla 14 hours agoparentprev1) Boots 2) Doesn't immediately crash. My Pinephone seems to still have an issue with crashing randomly all the time. reply mixmastamyk 8 hours agorootparentMy mobian never crashes. Try it. If it doesn’t help you’ve a hardware problem. reply linmob 13 hours agoparentprevI think it's that software is not all bad. ;-) reply qa_acc 11 hours agoprevMy opinion is different: I had one and I found it a poor platform, construction quality if sufficient to be generous. Then, I had hardware problems and the assistance was a Kafkaesque nightmare. I got rid of it and I took an old Pixel 3A on which I installed Ubuntu Touch: I'm not totally satisfied but, waiting for better Linux platform, IMHO it's another planet. reply asah 13 hours agoprevI'd be ok with a phone-form-factor device that lacks cellular and just uses apps over wifi for calls and messages. Kinda like the old iPod Touch. reply cesarb 13 hours agoparentA smartphone minus the cellular modem is just a PDA. Or rather, the modern smartphone could be viewed as the fusion of the PDA form factor and a cellular phone; this can be more clearly be seen in early smartphones like the Treo 650. Before then, it was common to have both as separate devices, and use Bluetooth (or even IRDA!) to connect both so that the PDA could use the cellular phone as a modem. Unfortunately, like the current \"smart TV\" situation, it's going to be hard to find a PDA-like device without a built-in modem, since most people do want the built-in modem. There are tablets, but even them seem to be gaining built-in modems nowadays. reply rchaud 11 hours agoparentprevI got the Onyx Boox Palma for this. Phone-size E-ink screen (no SIM slot), Android + app store support under the hood. reply xu_ituairo 11 hours agorootparentHow are you finding it? reply cookiengineer 2 hours agoprevHonestly there are so many \"pinephone is great\" reviews out there, and they just cannot be truthful. They are always along the lines of \"yeah it is great but actually it was not my daily driver because nothing works\". The pinephone would be great in comparison to a Nokia 3310. Everything that came after, even the i models with Bluetooth, would be better daily drivers than anything running on the pinephone. The bluetooth disconnects alone make me throw this thing into the trashbox, because my 5$ usb mp3 flash stick can handle that better these days. This includes SXMO, phosh, and all the rust weekend projects that nobody cares about. We don't need type safety, we don't need GTK or QT, we don't need X on mobile. These are all outdated ways of thinking about what a mobile computer can do, it's ridiculous that you have to even mention it. There was a reason Android 2.3 moved away from anything related to X at the time. And the reason was: OpenGLES. Nothing in the tech stack that GNOME and KDE provides is made for a quick and efficient shader pipeline, let alone a compositor that can be programmed/influenced from userspace. Just use ANGLE and get over your damned opinions about how you can do it better. If the pinephone had boot2chromium or sth like boot2electron, it probably would be a million times less sluggish. Nobody needs an SSH toy terminal that they cannot exit if it cannot render a special character and crashes, because the process management has a single UI thread. If I cannot make a phone call and cannot use WhatsApp on a phone in 2024, it's utterly useless and can only be described as an expensive brick. I get that it's not the hardware, but the software folks seem to be busy reinventing their own opinions about how to do things without even looking for the reasons why thousands of devs before them with decades more experience might have a point. Linux on the phone will fail as long as this cultural problem of \"not invented here so I can do it better\" isn't fixed. reply saidinesh5 1 hour agoparentI don't think any famous Linux mobile these days use X? Most of them are just wayland compositors. iirc GTKv4 is fully hardware accelerated. Everything/Most of the apps on KDE mobile side uses QtQuick/QML/Kirigami etc.. which is 100% GPU accelerated. Even my Ubuntu touch experience was lot more fluid than anything Android had to offer at the time on the same handset. > If the pinephone had boot2chromium or sth like boot2electron, it probably would be a million times less sluggish. The sluggishness of pinephone, i think, is probably due to slower sdcards (most of them tend to dual boot using an sdcard) and dated hardware for the kind of animated UI people expect these days. There is still boot2gecko/firefox os/whatever they call it these days. reply yjftsjthsd-h 2 hours agoparentprev> If I cannot make a phone call, and cannot use WhatsApp on a phone in 2024, it's utterly useless and can only be described as an expensive brick. Different people care about different things. I've never used WhatsApp in my life. > Nobody needs an SSH toy terminal that they cannot exit if it cannot render a special character and crashes, because the process management has a single UI thread. Er, is that a thing that can happen? I can't see any reason the software would be any less robust just because it's on a phone. In general, it sounds like you're arguing the view that if everyone just reinvented the wheel your way it'd work, but most of those decisions were made for a reason; generally, either for software compatibility, or because just reimplementing Android seems like a questionable value proposition. (And also the usual thing that it's almost all volunteers, so the choice isn't diversity or uniformity, it's diversity or nothing.) reply mixmastamyk 53 minutes agoparentprevSounds like you haven’t used it in a long time, so many details wrong in your post. reply cevn 14 hours agoprevSadly I had a similar experience. Actually had the Pro too, which was even more of a pain, IIRC because of having to press a reset button to boot with a pin, it was really bad. The OG Pinephone eventually would freeze every time I ran apk update on Postmarketos, I think the internal mmc went bad after a year. reply linmob 13 hours agoparentThe eMMC issue sounds like really bad luck - mine is still fine after more than three years (although I have moved on to other mobile Linux devices a year ago, since they are faster). reply spieglt 14 hours agoprevI haven't turned on my PinePhone in a long time because none of the OSes was usable for more than a week at a time. Maybe I should try postmarketOS again. reply geoffeg 10 hours agoprevThat reminds me of something I've been thinking about: Does anyone make a modern Nokia N900? I miss having a small, open Linux machine with a good keyboard in my pocket. I don't want something running Android, I want a common(-ish) Linux distro. reply delijati 13 hours agoprevI can recommend droidian or ubuntu touch (uborts.com) and if need (for me it is) use waydroid to run android apps https://docs.waydro.id/usage/install-on-desktops#ubuntu-debi... reply Ologn 9 hours agoprevI primarily program Android phones, but instead of getting an Android watch I decided to get a PineTime in November. I've been happy with it. I primarily use it to calculate my BPM - while doing cardiovascular exercise, or resting, or whatever. I put GadgetBridge on my Android phone and hooked the watch into it and now get BPM charts of my workouts. I also connected it to my phone notifications so if I get a notification on my phone that I got a Signal message, the message appears on my watch. Cost $27 plus $12 shipping. I upgraded the firmware via Bluetooth - the newer firmware is said to do BPMs better (I checked before and after, and it does seem to). They sell a dev kit for the same price, although you don't need the dev kit to develop unless you're really getting into it. It's very developer friendly - you can write your own OS for it, or modify InfiniTime which is the OS it is shipped with. Source code is on Github. Have been happy with it so far. reply Aachen 14 hours agoprev> To install an OS, you flash an image to an SD card, put it in the PinePhone and turn it on. That's it. You can swap OSes by changing SD cards That's really cool actually! Also think of making backups: just plug the sdcard into your laptop and copy the data. But then also this.. > [...] repeated, unpredictable problems both placing and receiving calls [...] > Notifications TLDR: Only calls and SMS notifications are truly real-time. So the only way someone can reliably reach you is via SMS, which basically means sending an explicit money-costing notification to me whenever I'm not already online and hoping I hear the single ping. That suits a pocket computer, but not for a phone :( The keyboard descriptions are also interesting: no suggestions makes it basically unusable unless it comes with a physical keyboard or you want to have typos in every sentence. I've got a \"hacker keyboard\" enabled on my android as well, but only turn it on when doing terminal things. I tried typing normally on that and I don't think it would reasonably work after a lot of practice either reply 0x1ceb00da 27 minutes agoparentIt's scary. Sounds like anyone can replace the os in your phone in 10s and read your browser cookies. reply jsheard 14 hours agoparentprev> That's really cool actually! Cool on paper but SD cards have abysmal write endurance, as any Raspberry Pi user will attest to. Unless you trust the entire software stack to keep writes to a minimum I wouldn't trust the SD card to last. reply Aachen 14 hours agorootparentI had this issue, presumably because I ran a Debian userspace below Android with a file on the sdcard as filesystem. Every ~3 years, the sdcard would just drop dead. (Other people seemed to upgrade faster than every 3y or don't use sdcards at all, so idk if it was just me.) It hasn't happened anymore recently, and I feel like there's more awareness/support for this type of usage pattern with the higher-end sdcards that are somewhat recent (like, introduced in the last ~8 years, so after the lifespan of an old cheap sdcard, I'm still on my first new-style one and I'm not yet sure it's not randomness that keeps it alive) reply jsheard 14 hours agorootparentIf you must use an SD card then there are industrial-grade ones which use pSLC NAND and are meant to endure a ton of abuse, but they're very expensive compared to an equivalent amount of reliable eMMC/USB/NVMe storage. IME commodity SD cards are still a crapshoot. reply nonrandomstring 13 hours agorootparentprevNot so bad, SD cards can be robust. It depends on the file-system and how much work the controller does to catch errors, mark bad cells, etc. I have a few portable handy recorders, a Zoom, a Tascam and a Sound Devices, and all of them handle the same SD cards for years, rarely complaining about format errors or losing files. reply squarefoot 14 hours agoparentprev> That's really cool actually! It's cool but it's wrong: SD cards are unreliable. reply Aachen 9 hours agorootparentFrom my point of view, you're wrong. They work fine for me for this purpose I don't think you can put a binary label on this (right or wrong): reliability is a number, such as MTBF or write cycles, not a boolean reply squarefoot 3 hours agorootparentI've experienced a number of file corruptions in various ones, including those inserted in SBCs and not carried around; they all were from reliable brands and never bought online. This wasn't systematic, that is, I cannot say all SD cards will fail, but I certainly saw a very noticeable increase in reliability when using as system disk eMMC/SSD instead of plain SD cards. reply zilti 13 hours agoparentprevIs there really any carrier that still charges for SMS? reply Aachen 9 hours agorootparentI doubt it's free literally anywhere, you'd pay it through taxes if not more directly, but you probably mean that, where you live, it's included (with a fair use policy) with every subscription you can possibly get? That's not the case in any country I've been to, especially if you want a flat EU rate you pay a crapton of money (probably this is easier if you don't have friends and family 20 minutes driving over a border, but also within NL and DE I know many people that pay per minute because they hardly ever call or SMS anyway; probably a majority in fact) reply zilti 1 hour agorootparentShow me one, just one. I used to have two different Swiss carriers where SMS were free, and now I have the German WINsim, a cheap carrier, where I pay 10€/month and get 15gb, flat phone calls and flat sms. I haven't paid for sms in at least a decade. reply bonton89 14 hours agoprevI wish there were more options for phones with hardware switches like this. reply filmgirlcw 12 hours agoprevThings like the PinePhone and the Librem 5 are cool on paper but if you can’t use it reliably as a phone, it can’t reliably work in standby, the camera sucks, the battery life is anemic, notifications suck, you can’t stream music from it, and the best thing you can say is “I can ssh into it,” which is cool for sure but I can do that (albeit with limitations) using iSH on iOS and is possible to enable on a number of Android distros. And I fully understand that that isn’t the point. The point is the hard work that has gone into this and the selective-amounts of “freedom” (if we convince ourselves that the modems and firmware in these things being absolutely not free software or open doesn’t to a certain extent obviate the entire thought experiment) you get versus another platform. I get it. I’m glad people are working on this stuff and having fun. And at $200, the Pine Phone is at least cheap enough to try out as a toy if you’re into that kind of thing (I think I’d rather jailbreak an older iPhone or use a modified Android device running an alt-OS, but that’s me). The Librem 5 is either $1000 or $2000 depending on what option you get, and that is to me, only for people who either enjoy setting their money on fire or who have been brainwashed by the marketing that it can do what it cannot do for 99.99999% of the population. I dunno. I don’t like being a hater but I don’t see the real point of having a mobile phone that isn’t a usable phone and that is really only usable if plugged into power all the time and used as a stationary mini computer (and thus, no longer mobile), of which a person could build something much more powerful using a Raspberry Pi or other single-board computer or a used NUC. reply Hackbraten 11 hours agoparent> The Librem 5 is […] only for people who either enjoy setting their money on fire or who have been brainwashed by the marketing Mind that a huge chunk of the $1000 price point is due to cost of mobile-friendly userspace development (e.g. phosh, phoc, libhandy, libadwaita), driver development, and mainlining drivers. Paying for this is absolutely justified because it’s important work, and it benefits the mobile Linux community as a whole, not just L5 owners. reply mixmastamyk 8 hours agoprevI like mine after installing mobian rather than the disaster it shipped with. Just needed something as good as my old iPhone 6s… but not quite there yet. :-/ Also assumed there’d be new hardware by now. Skipped the Pro, when does a new one come out? Been four years I think, which is worse than shipping a phone ten years out of date at launch. reply WesolyKubeczek 14 hours agoprev [–] > but for me, it failed at... being a phone. Unfortunately, true for any \"pure Linux\" phone out there since forever. I used to have a Nokia N900 and root for it very very much, but the dialer freezing and that infamous kernel bug when lots I/O could make everything sluggish made it a necessity to also carry a feature phone with my primary SIM around, too, just in case. reply coffeebeqn 6 hours agoparentN900 was the first one and the product line was immediately killed by Microsoft. Who knows how good it would be now if it was kept alive reply zilti 12 hours agoparentprevI was really hoping for the Astro Slide. Then the fxtex. Both turned out to essentially be a scam. All other \"pure Linux\" phones out there have hardware that is so laughably bad that I almost take it as a personal insult. reply fsflover 13 hours agoparentprev [–] >> but for me, it failed at... being a phone. > Unfortunately, true for any \"pure Linux\" phone out there since forever. Not true for Librem 5, which is my daily driver. See also: https://forums.puri.sm/t/librem-5-daily-driven-in-profession... reply neilsimp1 9 hours agorootparent [–] Seconding this, my L5 has been a daily driver for almost a year and while their are hiccups it's more than usable day to day. I spend a lot of time on the phone for work. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The PinePhone is a mobile Linux device with good performance but has issues with phone capabilities.",
      "It has standard features and a decent display, but is difficult to see in bright light and has average battery life.",
      "The Phosh and SXMO desktop environments are discussed, each with their own strengths and weaknesses.",
      "There are limitations with editing YAML files and using wvkbd for terminal use.",
      "Users have reported issues with the modem, especially with VoLTE, resulting in crashes and difficulties with calls.",
      "Different firmware and operating system versions have been tried, but problems persist.",
      "The camera works but has slow post-processing and limited video shooting capabilities.",
      "Offline navigation apps are also limited.",
      "There are challenges with Spotify playback on mobile Linux clients and the recommended usage of Firefox ESR as the default browser.",
      "Overall, the PinePhone is practical for daily tasks but has limitations as a phone."
    ],
    "commentSummary": [
      "Users discuss their experiences with mobile devices running on Linux, including the PinePhone, Librem 5, and Ubuntu Touch, focusing on areas like software performance, hardware limitations, and user interfaces.",
      "The challenges of creating affordable and fully open-source devices are highlighted, as well as concerns about their reliability and mainstream adoption.",
      "Discussions also cover topics such as file sharing, photo syncing, root access on Android devices, and the cost and availability of SMS services."
    ],
    "points": 165,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1706292304
  },
  {
    "id": 39148544,
    "title": "Google TPU v5p Outperforms Nvidia H100 for AI Workloads",
    "originLink": "https://www.techradar.com/pro/google-is-rapidly-turning-into-a-formidable-opponent-to-bff-nvidia-the-tpu-v5p-ai-chip-powering-its-hypercomputer-is-faster-and-has-more-memory-and-bandwidth-than-ever-before-beating-even-the-mighty-h100",
    "originBody": "Pro Google is rapidly turning into a formidable opponent to BFF Nvidia — the TPU v5p AI chip powering its hypercomputer is faster and has more memory and bandwidth than ever before, beating even the mighty H100 News By Keumars Afifi-Sabet published 23 December 2023 Google's latest AI chip is up to 2.8 times faster at training LLMs than its predecessor, and is fitted into the AI Hypercomputing architecture (Image credit: Future) Google accompanied the recent launch of its Gemini AI models with the latest version of its flagship tensor processing unit (TPU) for AI training and inference, in what appears to be an attempt to take on Nvidia's own market-leading GPUs. TPU v5p – Google's most powerful custom-designed AI accelerator – has been deployed to power the firm's 'AI Hypercomputer'. This is a supercomputing architecture that's built specifically to run AI applications, rather than supercomputers which normally run scientific workloads, because TPUs are unsuited to this. The latest version of its TPU has 8,960 chips per pod (which comprise the system), versus 4,096 in v4, and it's four times as scalable in terms of total availability of FLOPs per pod. These new pods provide a throughput of 4,800Gbps. The new pods also have 95GB of high-bandwidth memory (HBM) versus 32GB HBM RAM in TPU v4. Nvidia H100 vs Google TPU v5p: Which is faster? Unlike Nvidia, which offers its GPUs out for other companies to purchase, Google's custom-made TPUs remain in-house for use across its own products and services. Google's TPUs have long been used to power its services including Gmail, YouTube and Android, and the latest version has also been used to train Gemini. Google's v5p TPUs are up to 2.8 times faster at training large language models than TPU v4, and offer 2.1-times value-for-money. Although the intermediary version, TPU v5e, released earlier this year, offers the most value for money of all three, it's only up to 1.9-times faster than TPU v4, making TPU v5p the most powerful. It's even powerful enough to rival Nvidia's widely in-demand H100 GPU, which is one of the best graphics cards out there for AI workloads. This component is four times faster at training workloads than Nvidia's A100 GPU, according to the company's own data. Google's TPU v4, meanwhile, is estimated to be between 1.2 and 1.7-times faster than the A100, according to research it published in April. Incredibly rough calculations would suggest the TPU v5p, therefore, is roughly between 3.4 and 4.8-times faster than the A100 – which makes it on par or superior to the H100, although more detailed benchmarking is needed before any conclusions can be drawn. More from TechRadar Pro What is Google Gemini? Everything you need to know about Google’s next-gen AI These are the best graphics cards out there that you can buy AMD vs Nvidia: who is the graphics card champion? Are you a pro? Subscribe to our newsletter Sign up to the TechRadar Pro newsletter to get all the top news, opinion, features and guidance your business needs to succeed! Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Keumars Afifi-Sabet Channel Editor (Technology), Live Science Keumars Afifi-Sabet is the Technology Editor for Live Science. He has written for a variety of publications including ITPro, The Week Digital and ComputerActive. He has worked as a technology journalist for more than five years, having previously held the role of features editor with ITPro. In his previous role, he oversaw the commissioning and publishing of long form in areas including AI, cyber security, cloud computing and digital transformation. MORE ABOUT PRO This devious malware uses Bond-inspired driver to kill security suites — then proceeds to systematically encrypt your data and drops a $2 million ransom request Over a thousand jobs are going at eBay as ecommerce giant admits it grew too fast LATEST This M2 Mac mini deal has me double-checking the calendar to make sure it’s not Black Friday SEE MORE LATEST ► TOPICS NVIDIA GOOGLE MOST POPULAR How businesses can adapt to consumers’ changing digital needs By Duncan RobertsJanuary 24, 2024 The Apple Vision Pro arrives in stores next week, but you can 'see' the AR headset at home now using… AR By Lance UlanoffJanuary 24, 2024 Splatoon 3 Side Order DLC has an official release date By Demi WilliamsJanuary 24, 2024 The growing threat of data breaches in the age of AI and data privacy By Fabien RechJanuary 24, 2024 The new Titan Evo Lite is a budget gaming chair that packs a ton of premium features By Dashiell WoodJanuary 24, 2024 One of world's largest water utility company hit by ransomware attack — water supplies could be affected, incident seems to have limited impact with no customer data leaks reported By Sead FadilpašićJanuary 24, 2024 The Day Before developer claims a ‘hate campaign’ towards the game ‘inflicted significant damage’ By Catherine LewisJanuary 24, 2024 AMD’s new graphics driver offers a free frame rate boost for all PC games – with a couple of notable catches By Darren AllanJanuary 24, 2024 15 million Trello users at risk after unknown hacker uses proxy service to scrape data — emails, usernames, full names and other accounts info are available for sale on hacking forum By Sead FadilpašićJanuary 24, 2024 Google Pixel 8a packaging leak points to a potential design change By James IdeJanuary 24, 2024 This Blackberry-style phone with an E-Ink screen wants to fix your scrolling addiction By Mark WilsonJanuary 24, 2024 TOPICS NVIDIA GOOGLE MOST POPULAR MOST SHARED 1 Christmas movies are ruling Netflix’s weekly top 10, but two thrillers are crashing the party 2 Over 100 A24 films are headed to Max – here are 5 must-watches to start with 3 Zenless Zone Zero has an official release window 4 Microsoft is changing the way it updates Windows – and it’s starting to sound like Windows 12 won’t happen 5 Prime Video’s Mr and Mrs Smith trailer shows off an exhilarating spinoff series with a twist",
    "commentLink": "https://news.ycombinator.com/item?id=39148544",
    "commentBody": "Google TPU v5p beats Nvidia H100 (techradar.com)157 points by wslh 12 hours agohidepastfavorite119 comments qeternity 10 hours agoA lot of comments in this thread are parroting the common CUDA moat but that really only applies for training and R&D. The majority of spend is on inference and the world is standardizing around a handful of common architectures that have or are being implemented performantly in non CUDA stacks reply krasin 10 hours agoparent+1. My favorite essay on the topic: https://petewarden.com/2023/09/10/why-nvidias-ai-supremacy-i... reply anonylizard 7 hours agorootparentThe thesis of that essay, is that 1. Nvidia GPUs are dominant at training 2. Inference is easier than training, so other cards will become competitive in inference performance. 3. As AI applications start to proliferate, inference costs will start to dominate training costs. 4. Hence Nvidia's dominance will not last. I think the most problematic assumption is 3. Every AI company we see thus far is locked in an arms race to improve model performance. Getting overtaken by another company's model is very harmful for business performance (See Midjourney's reddit activity after DALLE-3), while a SOTA release instantly results in large revenue leaps. We also haven't reached the stage where most large companies can fine-tune their own models, given the sheer complexity of engineering involved. But this will be solved with a better ecosystem, and will then trigger a boom in training demand that does scale with the number of users. Will this hold in the future? Not indefinitely, but I don't see this ending in say 5 years. We are far from AGI, so scaling laws + market competition mean training runs will grow just as fast as inference costs. Also, 4 is very questionable. Nvidia's cards are not inherently disadvantaged in inference, they may not be specialized ASICs, but are good enough for the job with an extremely mature ecosystem. The only reason why other cards can be competitive against Nvidia's cards in inference, is because of Nvidia's 70% margins. Therefore, all Nvidia needs, to defend against attackers, is to lower their margins. They'll still be extremely profitable, their competitors not so much. This is already showing in the A100 H100 bifurcation. H100s are used for training, while the now old A100s used for inference. Inference card providers will need to compete against a permanently large stock of retired Nvidia training cards. Apple is still utterly dominant in the phone business after nearly 2 decades. They capture the majority of the profits despite 1. Not manufacturing their own hardware 2. The majority of the market share by units sold is say Chinese/Korean If inference is easy, while training is hard. It could just lead to Nvidia capturing all the prestigious and easy profits from training, while the inference market is a brutal low margin business with 10 competitors. This will lead to the Apple situation. reply huac 6 hours agorootparent> See Midjourney's reddit activity after DALLE-3 What stats are you looking at? Looking at https://subredditstats.com/r/midjourney , I see a slower growth curve after the end of July, but still growing and seemingly unrelated to the DALL-E 3 release, which was more like end of October publicly. reply q7xvh97o2pDhNrh 5 hours agorootparentprev> We are far from AGI Do you mind expanding on this? What do you see as the biggest things that make that milestone > 5 years away? Not trolling, just genuinely curious -- I'm a distributed systems engineer (read: dinosaur) who's been stuck in a dead-end job without much time to learn about all this new AI stuff. From a distance, it really looks like a time of rapid and compounding growth curves. Relatedly, it also does look -- again, naively and from a distance -- like an \"AI is going to eat the world\" moment, in the sense that current AI systems seem good enough to apply to a whole host of use cases. It seems like there's money sitting around just waiting to be picked up in all different industries by startups who'll train domain-specific models using current AI technologies. reply a_wild_dandan 1 hour agorootparentIntelligence lies on a spectrum. So does skill generality. Ergo, AGI is already here. Online discussions conflate AGI with ASI -- artificial superhuman intelligence, i.e. sci-fi agents capable of utopian/dystopian world domination. When misused this way, AGI becomes a crude binary which hasn't arrived. With this unearned latitude, people subsequently make meaningless predictions about when silicon deities will manifest. Six months, five years, two decades, etc. In reality, your gut reaction is correct. We have turned general intelligence into a commodity. Any aspect of any situation, process, system, domain, etc. which was formerly starved of intelligence may now be supplied with it. The value unlock here is unspeakable. The possibilities are so vast that many of us fill with anxiety at the thought. reply mleroy 7 minutes agorootparentWhen discussing silicon deities, maybe we can skip the Old Testament's punishing, all-powerful deity and reach for Silicon Buddha. reply mlsu 2 hours agorootparentprevI also think the space of products that involve training per-customer models is quite large, much larger than might be naively assumed given what is currently out there. It may be true that inference is 100x larger than training in terms of raw compute. But I think it very well could be that inference is only 10x larger, or same-sized. And besides, you can look at it in terms of sheer inputs and outputs. The size of data yet to be trained on is absolutely enormous. Photos and video, multimedia. Absolutely enormous. Hell, we need giant stacks of H100's for text. Text! The most compact possible format! reply cavisne 5 hours agorootparentprevRight, and they don't even need to lower their training margins, since training needs a fancy interconnect they can just ship the same chip at different prices based on interconnect (and are already doing so with the 40xx vs H100). reply christkv 3 hours agorootparentprevUnless there is s collapse in AI i would suspect inference will just keep exploding and as prices go down volume will go up. Margins will go down and maybe we will land back in prices similar to standard gpus. Still very expensive but not crazy. reply anon291 7 hours agorootparentprevI also think it's ludicrous to think that NVIDIA hasn't witnessed the rise of alternate architectures and isn't either actively developing them (for inference) or seriously deciding which of the many startups in the field to outright buy. reply buildbot 6 hours agorootparentThey already have inference specialized designs and architectures. For example, the entire Jetson line. Which is inference focused (you can train on them but like, why would you?). They have several DNLA accelerators on chip besides the GPU that are purely for inference tasks. I think Nvidia will continue to be dominant because it's still a lot easier to go from Cuda training to Cuda (TensorRT acerbated lets say) inference than migrating your model to ONNX to get it to run on some weird inference stack. reply imtringued 3 hours agorootparent>you can train on them but like, why would you?). Because you want to learn a new gait on your robot in a few minutes. reply buildbot 2 hours agorootparentWell sure if you model is small and light enough. But there's no training a 7B+ model on one (well, you could it would be so, so, so slow). Like, decades? reply gitfan86 10 hours agorootparentprevI sold my GOOG shares from 2005 to buy NVDA last year and definitely agree with the article. The thing is that Wall St doesn't understand any of the technical details and will just see huge profit growth from NVDA and drive the price crazy high. reply Mistletoe 8 hours agorootparentI don’t understand; hasn’t that already happened and you need to get out now? reply gitfan86 6 hours agorootparentWe are still at the beginning of Wall St freaking out reply Mistletoe 5 hours agorootparentNVDA has a PE of 80 and is up 6x since October 2022. It's the third highest company by market cap in the SP500, how much higher do you think it could possibly go? reply pjmlp 16 minutes agoparentprevMachine learning is not the only thing graphics cards are used for. reply nl 9 hours agoparentprevTPUs are mostly used outside of Google for training. There are better inference options. reply sliken 9 hours agoparentprevDoes pytorch somehow work better on CUDA? If not, who cares about CUDA? reply pjmlp 17 minutes agorootparentEveryone else not using Pytorch for their GPU coding activities. reply anon291 6 hours agorootparentprevYes. to get good perf on pytorch you need to use custom kernels that are written in CUDA, and all the dev work is done in CUDA, so if you want to use new SOTA projects as they come out, you'll probably want an NVIDIA GPU unless you want to spend time hand-optimizing. reply m463 10 hours agoparentprevALL of the comments make no sense after reading this line: > Unlike Nvidia, which offers its GPUs out for other companies to purchase, > Google's custom-made TPUs remain in-house for use across its own products and services. nobody can purchase one of these. and even if someone external to google could purchase one, why would they trust google for software, documentation or (the big if with google) ongoing support. this isn't their core business. reply stonogo 8 hours agoparentprevExcept that Google is buying H100s and nVIDIA is not buying TPUs. Nobody is buying TPUs, even the ancient ones Google is willing to sell. nVIDIA's hardware offerings are products for sale. Google's TPUs are a value-add to their rental market. This distinction is not lost on people. There's a reason all Google's big-load TPU clients they list in press releases are companies Google invested in. reply RantyDave 5 hours agoprevBut you can only buy it as a cloud service, yes? So presumably: * Whether something 'beats' something else is actually a question of price/performance and... * Whether or not the vendor in question is famous for dropping people in the shit. reply killingtime74 5 hours agoparentCompetitors will also never use it reply nabla9 12 hours agoprevGoogle is one generation behind? Google announces TPU v5p with specs competing against H100 when NVIDIA GH200 Grace Hopper is announced. >The new pods also have 95GB of high-bandwidth memory (HBM) GH200 has 282GB of HBM3e memory >These new pods provide a throughput of 4,800Gbps. That equals 600 GB/sec. GH200 has 10TB/sec of combined bandwidth HBM3e memory. reply modeless 11 hours agoparentA few notes: Nvidia always announces their hardware in advance of availability, while Google typically announces some time after they've started using it internally. Also TPU has been more cost-focused than Nvidia, since Google uses these chips internally to serve their web traffic while Nvidia is supply constrained and can name their price right now, plus they don't pay the electricity bills. There are also a few things wrong with the specs you quoted. 282 GB is split between two GPUs, it's 144 GB per GPU (not sure where the extra 6 GB went). The TPU pod throughput number you quoted is interconnect bandwidth which you compared to GH200's memory bandwidth. Those numbers are not comparable. I believe GH200 does beat TPU v5p per chip, however the differences are not anywhere near as large as your comparison suggested. And it's likely that TPU v5p is dramatically more cost effective but we don't have Google's internal numbers to prove that. reply m00x 4 hours agorootparentThat's mostly true. Nvidia also spends a lot of time internally testing their cards before shipping them out. Nothing would be worse than a massive hardware recall. If anything, Google would have an easier time going live sooner than Nvidia since they own all the TPUs and they're onsite. reply nabla9 10 hours agorootparentprev> 282 GB is split between two GPUs There is only one GPU in GH200 and it gets all 282 GB HBM3e memory. There is another 480 GB LPDDR5X memory for the another chip (Grace CPU, not GPU). GH200 interconnect bandwidth trough NVLink is 900 GB/s. reply modeless 10 hours agorootparentI don't believe this is true. GH200's GPU has 144GB of HBM3e according to their datasheet. https://resources.nvidia.com/en-us-grace-cpu/grace-hopper-su... The 282 GB figure comes from a \"dual configuration\" server with two CPU chips and two GPU chips: > the new platform will be available in a wide range of configurations. The dual configuration [...] comprises a single server with 144 Arm Neoverse cores, eight petaflops of AI performance and 282GB of the latest HBM3e memory technology. Note that one Grace Hopper CPU has 72 cores so this configuration clearly has two CPUs and two GPUs in one server, and the 282 GB HBM3e total is split between the two GPUs with 144 GB each (again, not sure where the extra 6 GB went, maybe disabled for yield issues?). https://nvidianews.nvidia.com/news/gh200-grace-hopper-superc... reply bhewes 12 hours agoparentprevI am more interested in TCO of TPU v5p. Right now it seems only Nvidia is making money everyone else loses. reply lordswork 11 hours agorootparentThe article mentions TPU v5p is 2.1 x perf/TCO of H100. reply jsnell 11 hours agorootparentI don't think it does? > Google's v5p TPUs are up to 2.8 times faster at training large language models than TPU v4, and offer 2.1-times value-for-money. That's a comparison of TPUv5p to TPUv4, not to H100. reply bhewes 11 hours agorootparentprevActual dollars would be nice, since that is what the end user understands. Otherwise what are they talking about 1 million unit orders? But nice catch I didn't see it. reply nabla9 11 hours agorootparentprevI think Broadcomm designs and builds TPUs for Google. Their stock was up 100% in 2023 and their profit margin was 39.31%. reply surajrmal 4 hours agorootparentGoogle's TPUs are entirely in house designed. Not sure where you heard broadcomm is involved. reply rreichman 2 hours agorootparenthttps://siliconangle.com/2023/09/21/google-reaffirms-broadco... reply bhewes 11 hours agorootparentprevThey bought VMware for $61B in Nov of last year. Hard to think TPUs are driving much of this at Broadcom. reply Y_Y 11 hours agorootparentprevtable of contents? reply kirubakaran 11 hours agorootparentI think they mean TCO: https://en.wikipedia.org/wiki/Total_cost_of_ownership reply bhewes 11 hours agorootparentThanks. reply wmf 11 hours agoparentprevH100, H200, and GH200 are the same generation although the next generation B100 is coming this year. reply nabla9 10 hours agorootparentThese comparisons are \"Google Pod\" vs. \"Nvidia Supership\" not single chips. Pod/Superships are collections GPU/TPU's, memory and high speed interconnect. One Grace Hopper has: H100 chip, Grace CPU with 72 cores, 282GB of HBM3e memory and 480 GB LPDDR5X for the CPU. reply wmf 9 hours agorootparentYour numbers are still off. A GH200 pod has 144 terabytes of RAM; it isn't even measured in gigabytes. It looks like TPUv5p may have 851 terabytes which would be a generation ahead but you didn't show those numbers. reply versteegen 3 hours agorootparentnabla9 said \"one Grace Hopper\" not \"one GH200 pod\". Actually, DGX GH200 seem to come in different sizes, something that I can't find clearly stated on Nvidia's website, but what I do see are entirely inconsistent specs. I'm thinking they've changed it a few times. https://developer.nvidia.com/blog/announcing-nvidia-dgx-gh20... describes the DGX GH200 as: -256 NVIDIA Grace Hopper Superchips (1 CPU + 1 GPU) -each Grace CPU has 480 GB LPDDR5 CPU memory -each H100 GPU has 96 GB of HBM3 -each GPU can access all of the CPU and GPU memory in the whole system (144TB), at 900 GBps At https://www.nvidia.com/en-us/data-center/dgx-gh200/ (linked to from the DGX page from the website) which has a Datasheet pdf they say the DGX GH200 has: -32 NVIDIA Grace Hopper Superchips (1 CPU + 1 GPU) -each Grace CPU has 72 \"ARM Neoverse V2 Cores with SVE2 4X 128\" -each GPU can access \"19.5TB\" shared memory -that's 624GB per superchip, which is weird. I expect it's actually 96GiB HBM3 + 512GiB LPDDR, a total of 19456GiB = 19.0TiB And other people have found completely different specs elsewhere on the website! reply miohtama 12 hours agoparentprevI guess performance per watt is also a major factor? reply jchonphoenix 11 hours agoprevNone of this matters if they can't get the hardware stack to work correctly. The media keeps missing the real lock in Nvidia has: CUDA. It's not the hardware. It's the ability for someone to use it painlessly. reply nl 9 hours agoparentTPUs have the second best software stack after CUDA though. JAX and Tensorflow support it before CUDA in some cases and it's the only Pytorch environment that comes close to CUDA for support. reply pjmlp 14 minutes agorootparentTPUs are single case use, contrary to CUDA. reply bootsmann 10 hours agoparentprevGoogle has historically been weak at breaking into markets that someone else has already established and I think the TPUs are suffering from the same fate. There is not enough investment in making the chips compatible with anything other googles preferred stack (which happens to not be the established industry stack). Committing to getting torch to switch from device = “cuda” to device = “tpu” (or whatever) without breaking the models would go a long way imo. reply ugh123 8 hours agorootparentI always thought Google was actually pretty good at taking over established, or rising markets, depending on the opportunity or threat they see from a competitor. Either by timely acquisition and/or ability to scale faster due to their own infrastructure capabilities. - Google search (vs previous entrenched search engines in the early '00s) - Adsense/doubleclick (vs early ad networks at the time) - Gmail (vs aol, hotmail, etc) - Android (vs iOS, palm, etc) - Chrome (vs all other browsers) Sure, i'm picking the obvious winners, but these are all market leaders now (Android by global share) where earlier incumbents were big, but not Google-big. Even if Google's use of TPUs are purely self-serving, it will have a noticeable effect on their ability to scale their consumer AI usage at diminishing costs. Their ability to scale AI inference to meet \"Google scale\" demand, and do it cheaply (at least by industry standards), will make them formidable in the \"ai race\". This is why altman/microsoft and others are investing heavily in AI chips. But I don't think their TPU will be only self-serving, rather, they'll scale it's use through GCP for enterprise customers to run AI. Microsoft is already tapping their enterprise customers for this new \"product\". But those kinds of customers will care more about cost than anything else. The long-term game here is a cost game, and Google is very, very good at that and has a headstart on the chip side. reply dekhn 10 hours agorootparentprevTPUs were originally intended to just be for internal use (to keep google from being dependent on Intel and nvidia). Making them an external product through cloud was a mistake (in my opinion). It was a huge drain on internal resources in many ways and few customers were truly using them in the optimal way. They also competed with google's own nvidia GPU offering in cloud. The TPU hardware is great in a lot of ways and it allowed google to move quickly in ML research and product deployments, but I don't think it was ever a money-maker for cloud. reply amelius 8 hours agoparentprev> The media keeps missing the real lock in Nvidia has: CUDA. It's not the hardware. It's the ability for someone to use it painlessly. Really? What if someone writes a new back-end to PyTorch, TensorFlow and perhaps a few other popular libraries? Then will CUDA still matter that much? reply pjmlp 14 minutes agorootparentCan you do Unreal engine's Nanite, or Otoy Ray tracing in Pytorch? reply p1esk 7 hours agorootparentprevif someone writes a new back-end to PyTorch If that was easy to do surely AMD would have done it by now? After many years of trying? reply blitzar 25 minutes agorootparentI am starting to wonder if AMD were even trying all this time. reply fritzo 5 hours agorootparentprevPyTorch has had an XLA backend for years. I don't know how performant it is though. https://pytorch.org/xla reply m00x 4 hours agorootparentIt's pretty fast, just not as nice to use. You need statically defined tensors, and some functions are just not supported (last time I used it). reply dkarras 10 hours agoparentprevmojo language joins the chat: https://www.modular.com/max/mojo reply ipsum2 10 hours agorootparentMojo is a closed source language that will never reach mainstream adoption among ML engineers and scientists. reply jph00 8 hours agorootparent> Mojo is a closed source language that will never reach mainstream adoption among ML engineers and scientists. [Citation needed] The creator, Chris Lattner, previously created LLVM, clang, and Swift. In each case he said these projects would be open sourced, and in each case they were. In each case they reached mainstream adoption in their respective target markets. He's stated that Mojo will be open source. If you're going to claim with great confidence that this language will have a different outcome to his previous ones, then you probably should have some strong evidence for that. reply dkarras 9 hours agorootparentprevhmm the creator says (from his podcast with Lex Friedman when I listened to him) that they are open sourcing it, but that it is a project borne out of their private effort at their company and that it is still being used privately - so the aim is open sourcing it while taking community input and updating their private code to reflect the evolving design so that when they release it their internal lang and the open sourced lang will not diverge. of course not ideal, but better than \"open sourcing\" it and refusing every request because it does not work for their codebase. worse than having it open source from the get go, of course. assuming that day comes, does it have a competitor in the works? a python superset, compatible with python libs, but enables you to go bare metal to the point that it enables you to directly program GPUs and TPUs without CUDA or anything? \"never\" means you believe it will never be open sourced, or a competitor will surpass it by the time it is open sourced. or that you believe the premise of the lang is flawed and we don't need such a thing. Which one is it? Here is their github btw: https://github.com/modularml/mojo From what I see, they have a pretty active community and there is demand for such a system. The github says something similar: >This repo is the beginning of our Mojo open source effort. We've started with Mojo code examples and documentation, and we'll add the Mojo standard library as soon as we get the necessary infrastructure in place. The challenge is that we use Mojo pervasively inside Modular and we need to make sure that community contributions can proceed smoothly with good build and testing tools that will allow this repo to become the source of truth (right now it is not). We'll progressively add the necessary components, such as continuous integration, build tools, and more source code over time. reply pavelstoev 5 hours agorootparentyes there is a much more performant competitor that actually supports Nvidia GPUs [1] https://centml.ai/make-your-ml-models-run-faster-with-hidet/ reply dkarras 5 hours agorootparent...this has very little to do with mojo. mojo is not an nvidia accelerator for a couple ML frameworks. reply lordswork 11 hours agoparentprevWhat's painful about using TPUs? reply refulgentis 10 hours agorootparentin a sentence: google ai stuff is the vendor lockin of 2024 apple with the ecosystem value of 1994 apple. c.f. https://news.ycombinator.com/item?id=39149854 reply postalrat 5 hours agorootparentSo you trade one vendor lockin for another. Nothing lost. reply kjkjhgkjyj 11 hours agoparentprevTensorFlow and PyTorch support TPUs. It's pretty painless. reply Mehdi2277 11 hours agorootparentHaving used it heavily it is nowhere near painless. Where can you get a TPU? To train models you basically need to use GCP services. There are multiple services that offer TPU support, Cloud AI Platform, GKE, and Vertex AI. For GPU you can have a machine and run any tf version you like. For tpu you need different nodes depending on tf version. Which tf versions are supported per GCP service is inconsistent. Some versions are supported on Cloud AI Platform but not Vertex AI and vice versa. I have had a lot of difficulty trying to upgrade to recent tf versions and discovering the inconsistent service support. Additionally many operations that run on GPU but are just unsupported for TPU. Sparse tensors have pretty limited support and there's bunch of models that will crash on TPU and require refactoring. Sometimes pretty heavy thousands of lines refactoring. edit: Pytorch is even worse. Pytorch does not implement efficient tpu device data loading and generally has poor performance no where comparable to tensorflow/jax numbers. I'm unaware of any pytorch benchmarks where tpu actually wins. For tensorflow/jax if you can get it running and your model suits tpu assumptions (so basic CNN) then yes it can be cost effective. For pytorch even simple cases tend to lose. reply htrp 11 hours agorootparentprev> TensorFlow and PyTorch support TPUs. It's pretty painless. Unless you physically work next to the TPU hardware team, the torch support for TPUs is pretty brittle. reply moffkalast 11 hours agoparentprevAnd Nvidia does actually sell their hardware. Nobody will ever get their hands on one of these outside Google Cloud. It might as well not exist. reply buildbot 6 hours agorootparentWell, sometimes they fall of the back of trucks I guess: https://www.ebay.com/itm/134540730431 Archive link: https://archive.ph/7dPFo reply brucethemoose2 9 hours agoprevThis needs to be taken with a massive grain of salt, as LLM training performance hugely depends on the framework used. And by \"performance\" I mean the quality of the end result, the training speed, and what features device is physically capable of handling. While kinda discrete aspects in other fields, all of these are highly correlated in ML training. One specific example I am thinking of is support for efficient long context training. If your stack doesn't, for instance, support flash attention (or roll its own custom implementation), then good luck with that. Another I am thinking of is quantization. Sometimes you want to train with a specific quantization scheme, and sometimes doing that is just a performance compromise. And vendors really love to fudge their numbers with the fastest, most primitive quantization on the device. reply bogwog 8 hours agoparentAdditionally, Google has not been very honest recently with regards to their AI tech. reply tgtweak 11 hours agoprevTwo things matter at cloud-scale: Compatability - does using a tpu require reworking significant parts of your software stack and application stack? If so, that sucks for most companies who's researchers are used to using nvidia libraries, tooling and hardware to get their models running, and reworking the entire bottom end of that to work on an esoteric platform needs to equate to a huge cost savings at scale to be worth it. Cost per tensor flop delivered - likely very low if google has optimized the silicon, memory, voltage, power and temperature envelope, networking, boards and chassis for the server running it, as well as optimizing for optimal process node efficiency/cost. They're probably not on bleeding edge tsmc process, but instead optimizing for total deployed running cost per pflop over 2-3 years. It's also now public (as of November) that microsoft/azure have been working for many years on their own ai chip, dubbed \"Maia\" [1], and appliance with the obvious goal of taking some of that nvidia margin in-house (and with openai/bing/copilot being a massive consumer of capacity). I think this will become even more commonplace with cloud vendors - even medium size ones - than it already is. The knowledge and complexity barrier to designing a tile processor unit seems pretty low and it looks like most of the hard stuff is in the drivers and software - something cloud providers designing and integrating internally can bypass and control to a great degree. It's also very hard to benchmark side by side on these since I'm sure cuda/nvidia hardware can do compute that a TPU cannot. AMD's machine learning accelerators look good on paper too, as do the tensor processors in the apple silicon, but on real world applications and use cases they don't often measure up save for a few optimal workflows. [1] https://www.geekwire.com/2023/microsoft-unveils-custom-ai-ch... reply geor9e 11 hours agoprevHasn't this always been the case? I remember they released TPUs at IO 2018, and they were nice if you build FP16/FP32 models in Google Cloud TensorFlow/CoLab and never ever port them to anything else. Meanwhile the cool new open source stuff coming out every week usually requires a GPU and is rarely compatible with TPU without major changes. If you wait a few months a TPU compatible copycat appears on the Keras demos page but by then you've lost interest. reply porphyra 12 hours agoprevIt is pretty exciting that various companies are making compute for deep learning. I was starting to get worried that the TPUs were lagging behind Nvidia. More diversity in hardware is always nice. Meanwhile I am still waiting for Tesla Dojo to be an actual thing... reply ShamelessC 11 hours agoparentTesla’s dojo is deployed already I thought? I don’t recall them ever having plans to make it publicly available. reply modeless 7 hours agorootparentElon's comments on the latest earnings call, if you read between the lines, strongly imply that Dojo v1, while functioning, has been a disappointment. He seems to hold out hope for future versions but he is markedly less optimistic than for other programs he talked about, and considering his typical unjustifiably optimistic attitude toward future releases of AI-related products that seems to bode poorly for the project. I would not be surprised if it was cancelled or rebooted in the next year or two. I don't recall if they made comments about public availability for Dojo before, but given the difficulty of competing in this market and the huge benefits scale brings in hardware, it would seem foolish to limit the system to internal customers only. reply ShamelessC 6 hours agorootparent> Elon's comments on the latest earnings call, if you read between the lines, strongly imply that Dojo v1, while functioning, has been a disappointment Maybe they shouldn’t have gone with an in-house design. > it would seem foolish to limit the system to internal customers only. My understanding from working with similar HPC systems is that public use cases are likely niche and many tasks don’t benefit from the sort of fast interconnect their setup gives them. If anything being quite public about their design was meant to allow other companies to copy their design and compete with nvidia on a united front perhaps. It’s not really as versatile as AWS, GCP are to profitably work as a compute cloud provider though. Perhaps it could be a provider for other companies who don’t want to own their hardware to do training runs on. reply modeless 5 hours agorootparentI agree that it seems a bit much to try to design their own training supercomputer. But they seemingly did OK with their inference hardware, and they do have an awful lot of money these days. Anyway, even if it is literally only useful for a single task, and that task is training large transformers, there is a use case right now. People are desperate for hardware to train large transformers. reply sxp 11 hours agoprevIs there any good way to program TPUs for non-ML work? The only official way appears to involve encoding the compute operation into a TF graph and loading that. Is there a better way to directly use the hardware? reply lordswork 11 hours agoparentAFAIK, XLA is the only compiler that can target TPUs, so anything written for TPUs would need to lower to HLO. That said, why would you want to to run non-ML workloads on such an ML-specialized chip? reply sxp 11 hours agorootparentI was interested in seeing if raytracing or similar embarrassingly parallel workloads could be ported to a TPU. reply counters 11 hours agoparentprevJust write your code in JAX and run as usual? reply pjmlp 11 minutes agorootparentLooking forward to see Nanite implementation in JAX. reply habibur 9 hours agoprevI was seeking power consumption and price comparison with it, as otherwise only faster doesn't mean much. reply 7e 11 hours agoprevThere are no benchmarks in this s*t article, just SWAGs. If this chip doesn't support FP8, there's no way it's going to beat the H100 on workloads that matter. reply 7e 10 hours agoparentGooglers, stop downvoting me and get back to work! reply nisten 11 hours agoprevMeh, the comparison is somewhat pointless when it doesn't account for the slowdown that the vast majority of pytorch codebases experience on TPU's vs using JAX and it's accelerations specific to TPUs, and vice versa. https://arxiv.org/pdf/2309.07181.pdf Meaning the TPU v5p is likely slower than H100 for most ML workloads that depend on pytorch. reply renewiltord 11 hours agoprevCan only use on Google Cloud, no? Nvidia is the only self-hostable product available. But Google can build good framework integration. Will wait and see. reply wmf 11 hours agoparentGaudi, MI300, Cerebras... reply renewiltord 8 hours agorootparentHave you bought these? Could not find Gaudi or Cerebras device available anywhere. And MI300 risky since software support is poor. But if you have managed to make it work, perhaps there's potential. What stack are you using and what workload? reply wmf 8 hours agorootparentI don't work in ML but I know these are \"call for pricing\" products. reply renewiltord 8 hours agorootparentI don't know of anyone who uses these products. I would probably avoid. reply wmf 8 hours agorootparentJust don't complain about monopoly if you're not willing to try anything. reply renewiltord 8 hours agorootparentWould like to try others, but investment too big. Would have to build entire software ecosystem. I think most people like this. Even geohot suffered trying to do this. reply stonogo 12 hours agoprevI don't see how we're this far in and so many competitors are still trying to ignore the massive market penetration of CUDA. I don't care how fast your chip is if I can only run 20% of the already tiny amount of software capable of leveraging this acceleration. reply vessenes 12 hours agoparentI think this was a more accurate assessment a couple of years ago. AMD historically under invested in their software stack, as is well documented. But, they are catching up. The prevalence of pytorch makes it easier for hardware vendors to target a single set of libraries for implementation and get broad distribution. Even Apple has made major progress getting mps support in more broadly, first directly into pytorch, and they are now charting their own course with MPX with some early interesting successes. Zuck recently used the word \"H100 equivalent\" in compute, and my memory is he indicated roughly 35% of that compute was not from NVIDIA -- that will all be AMD. There's still work to do -- lots of repositories still contain `if device==\"cuda\"` type language, but my own experience is that manging code around to use apple gpus has gotten vastly easier this year, and I see more and more AMD GPU owners floating around github issues with resolvable problems. A year ago they were barely present. All that said - people aren't ignoring it - and entrepreneurs and cloud monopolies are putting real resources into opening things up. I think the playing field will continue to level / get back to competitive over the next two to three years. reply ShamelessC 11 hours agorootparentThe main issue is until you solve 99% of all the problems, you’re still introducing substantial friction to every potential user who may have had to go from zero coding knowledge needed to very specialized coding knowledge needed. And while many problems are trivial to fix at eg the PyTorch layer, lots of stuff like flash attention, DeepSpeed, etc. are coded directly in CUDA kernels. reply glalonde 11 hours agoparentprevIs that true and is that sustainable? My understanding has been that only the relatively low level libraries/kernels are written in cuda and all the magical algorithms are in python using various ML libaries. It's like how intel BLAS isn't much of a moat -- there are several open source implementations and you can mix and match. How is CUDA so sticky when most ML devs aren't writing CUDA but something several layers of abstraction above it? Why can't intel, AMD, google w/e come along and write an adapter for that lowest level to TF, pytorch or whatever is the framework of the day? reply cavisne 10 hours agorootparentIt's a good question. I think fundamentally its because no wants to/can compete with Nvidia when making a general purpose parallel processor. They all want to make something a bit more specialized, so they need to guess what functionality is needed and not needed. This is a really tricky guess, case in point that AMD's latest chip cant compete on training because they could not get Flash Attention 2 working on the backward pass because of their hardware architecture. [1] Attempts to abstract at a higher layer have failed so far because that lower layer is really valuable, again Flash Attention is a good example. [1] https://www.semianalysis.com/p/amd-mi300-performance-faster-... reply 1024core 11 hours agorootparentprev> Why can't intel, AMD, google w/e come along and write an adapter for that lowest level to TF, pytorch or whatever is the framework of the day? A long long time ago, i.e. the last time AMD was competing with Intel (before this time, that is), we used to use Intel's icc in our lab to optimize for the Intel CPUs and squeeze as much as possible out of them. Then AMD came out with their \"Athlon\"(?) and it was an Intel-beater at that time. But AMD never released a compiler for it; I bet they had one internally, but we had to rely on plain old GCC. These hardware companies don't seem to get that a kick-ass software can really add wings to their hardware sales. If I were a hardware vendor, I would, if nothing else, make my hardware's software open so the community can run with it and create better software; which will result in more hardware sales! reply benreesman 11 hours agoparentprevThey’re not ignoring it, they’re eroding it. The API that matters is Torch, and only the API. Letting NVIDIA charge famine prices is both a bad idea and a huge incentive to write software bridging the gap. reply pjmlp 9 minutes agorootparentFor those like myself Torch means nothing, I don't use GPU for machine learning rather graphics programming and general purpose compute. reply kkielhofner 11 hours agorootparentprevI don’t know if you do work in this space but this wasn’t accurate several years ago and it certainly isn’t accurate now. The amount of extremely CUDA specific handwritten compute architecture code, custom kernels, etc has exploded and other than a few things here and there (yes, like torch SDPA) we’re waaaay past vanilla torch for anything beyond a toy. The pricing and theoretical hardware specs of these novelties doesn’t matter when an inferior on paper Nvidia product will wipe the floor with the other in the real world. People have spent 15 years wringing every last penny out of CUDA on Nvidia hardware. There is some light shining through but you’ll still see things like “Woo-hoo FlashAttention finally supports ROCm! Oh wait, what’s that, FlashAttention2 has been running on CUDA for six months?” Don’t even get me started on the “alternative” software stacks and drivers. reply pjmlp 6 minutes agorootparentAlso the anti-CUDA folks keep forgetting the polyglot nature of the ecosystem, made possible since PTX was introduced on CUDA 3.0. The graphical debugging tools that allows stepping through GPU code just like with on the CPU. reply indymike 9 hours agoparentprev> already tiny amount of software capable of leveraging this acceleration. This is why everyone is trying to compete with CUDA. Everyone wants a slice of the pie as we go from tiny amount to everything. reply postalrat 5 hours agoparentprevYou aren't the customer they want. reply collegeburner 12 hours agoparentprevsome stuff is still CUDA-dependent (a lot of scientific code). other stuff is not (major ML frameworks and many math libraries). nobody said CUDA was obsolete, just that there are great options for many use cases that no longer rely on it. reply ilaksh 11 hours agoprevCan we access TPUv4 and/or v5 in Google Cloud? What frameworks support them? reply wmf 11 hours agoparentMaybe Google should invent a search engine that can answer such questions. reply wslh 7 hours agorootparentChatGPT is replacing and better in many queries. The answer is there if you put the OP question. reply wslh 10 hours agoprevI understand that OpenAI used Azure for processing and not Google Cloud right? Using Google Cloud would mean, assuming Google as a bad actor, that they can get the model if OpenAI trains their models with it. reply surajrmal 4 hours agoparentNo one would Google cloud if they were worried about IP theft. This also seems very much irrelevant to the posted article. reply sadhorse 12 hours agoprev [–] More compute can't save you from dumb methods. Memorizing the whole of human text while being fooled by a prompt crafted by a 14 year old doesn't mean its intelligent. reply crakenzak 11 hours agoparent [–] Plenty of intelligent and educated humans have been fooled by \"prompts\" aka lies/social engineering by others many years their younger. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google has released the TPU v5p, an upgraded version of its tensor processing unit AI chip, with enhanced speed, memory, and bandwidth compared to its predecessor.",
      "The TPU v5p is being utilized in Google's AI Hypercomputer and boasts up to 2.8 times faster training for large language models.",
      "Google's custom TPUs are employed internally, and the new TPU v5p is considered a strong competitor to Nvidia's H100 GPU for AI tasks, although further benchmarking is necessary to establish a precise performance comparison."
    ],
    "commentSummary": [
      "The discussion covers Google's TPU hardware and Nvidia's GPUs, highlighting their significance in AI.",
      "The competition between frameworks like PyTorch and CUDA is explored, emphasizing the importance of hardware.",
      "The potential of TPUs in machine learning and the challenges and limitations of using specialized hardware for AI tasks are discussed."
    ],
    "points": 157,
    "commentCount": 119,
    "retryCount": 0,
    "time": 1706303923
  },
  {
    "id": 39144740,
    "title": "Pixel Owners Experience Issues After January 2024 Google Play Update",
    "originLink": "https://www.bleepingcomputer.com/news/google/google-pixel-phones-unusable-after-january-2024-system-update/",
    "originBody": "Google Pixel phones unusable after January 2024 system update{ \"@context\": \"https://schema.org\", \"@type\": \"NewsArticle\", \"url\": \"https://www.bleepingcomputer.com/news/google/google-pixel-phones-unusable-after-january-2024-system-update/\", \"headline\": \"Google Pixel phones unusable after January 2024 system update\", \"name\": \"Google Pixel phones unusable after January 2024 system update\", \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"id\": \"https://www.bleepingcomputer.com/news/google/google-pixel-phones-unusable-after-january-2024-system-update/\" }, \"description\": \"Google Pixel smartphone owners report problems after installing the January 2024 Google Play system update, being unable to access their devices internal storage, open the camera, take screenshots, or even open apps.\", \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://www.bleepstatic.com/content/hl-images/2024/01/24/google-pixel-7.jpg\", \"width\": 1600, \"height\": 900 }, \"author\": { \"@type\": \"Person\", \"name\": \"Bill Toulas\", \"url\": \"https://www.bleepingcomputer.com/author/bill-toulas/\" }, \"keywords\": [\"Google\",\"Google Pixel\",\"Google Play\",\"Google Update\",\"Mobile\",\"Pixel\"], \"datePublished\": \"2024-01-24T10:13:48-05:00\", \"dateModified\": \"2024-01-25T01:50:28-05:00\", \"publisher\": { \"@type\": \"Organization\", \"name\": \"BleepingComputer\", \"url\": \"https://www.bleepingcomputer.com/\", \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://www.bleepstatic.com/logos/bleepingcomputer-logo.png\", \"width\": 700, \"height\": 700 } } }!function(n){if(!window.cnxps){window.cnxps={},window.cnxps.cmd=[];var t=n.createElement('iframe');t.display='none',t.onload=function(){var n=t.contentWindow.document,c=n.createElement('script');c.src='//cd.connatix.com/connatix.playspace.js',c.setAttribute('async','1'),c.setAttribute('type','text/javascript'),n.body.appendChild(c)},n.head.appendChild(t)}}(document);cnxps.cmd.push(function () { cnxps({ playerId: '067e5169-ece3-4ce8-87ad-c7961b8bb396' }).render('6302b4e26cf04d8bbf9ab6cbec18daf4'); });var freestar = freestar || {}; freestar.queue = freestar.queue || []; freestar.config = freestar.config || {}; // Tag IDs set here, must match Tags served in the Body for proper setup freestar.config.enabled_slots = [];freestar.queue.push(function() { googletag.pubads().setTargeting('section', 'news');}); freestar.initCallback = function () { (freestar.config.enabled_slots.length === 0) ? freestar.initCallbackCalled = false : freestar.newAdSlots(freestar.config.enabled_slots) } ;(function(o) { var w=window.top,a='apdAdmin',ft=w.document.getElementsByTagName('head')[0], l=w.location.href,d=w.document;w.apd_options=o; if(l.indexOf('disable_fi')!=-1) { console.error(\"disable_fi has been detected in URL. FI functionality is disabled for this page view.\"); return; } var fiab=d.createElement('script'); fiab.type = 'text/javascript'; fiab.src=o.scheme+'ecdn.analysis.fi/static/js/fab.js';fiab.id='fi+o.websiteId; ft.appendChild(fiab, ft);if(l.indexOf(a)!=-1) w.localStorage[a]=1; var aM = w.localStorage[a]==1, fi=d.createElement('script'); fi.type='text/javascript'; fi.async=true; if(aM) fi['data-cfasync']='false'; fi.src=o.scheme+(aM?'cdn':'ecdn') + '.firstimpression.io/' + (aM ? 'fi.js?id='+o.websiteId : 'fi_client.js'); ft.appendChild(fi); })({ 'websiteId': 5971, 'scheme': '//' });window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-91740-1'); NewsFeatured LatestMicrosoft reveals how hackers breached its Exchange Online accountsPwn2Own Automotive: $1.3M for 49 zero-days, Tesla hacked twice23andMe data breach: Hackers stole raw genotype data, health reportsGlobal fintech firm EquiLend offline after recent cyberattackMicrosoft releases first Windows Server 2025 preview buildHide from snoops with $30 off one year of Windscribe VPNMicrosoft introduces flighting for Windows Server insidersMicrosoft Teams outage causes connection issues, message delays DownloadsLatest Most DownloadedQualys BrowserCheckSTOPDecrypterAuroraDecrypterFilesLockerDecrypterAdwCleanerComboFixRKillJunkware Removal Tool VPNsPopularBest VPNsHow to change IP addressAccess the dark web safelyBest VPN for YouTube Virus Removal GuidesLatest Most Viewed RansomwareRemove the Theonlinesearch.com Search RedirectRemove the Smartwebfinder.com Search RedirectHow to remove the PBlock+ adware browser extensionRemove the Toksearches.xyz Search RedirectRemove Security Tool and SecurityTool (Uninstall Guide)How to Remove WinFixer / Virtumonde / Msevents / Trojan.vundoHow to remove Antivirus 2009 (Uninstall Instructions)How to remove Google Redirects or the TDSS, TDL3, or Alureon rootkit using TDSSKillerLocky Ransomware Information, Help Guide, and FAQCryptoLocker Ransomware Information Guide and FAQCryptorBit and HowDecrypt Information Guide and FAQCryptoDefense and How_Decrypt Ransomware Information Guide and FAQ TutorialsLatest PopularHow to enable Kernel-mode Hardware-enforced Stack Protection in Windows 11How to use the Windows Registry EditorHow to backup and restore the Windows RegistryHow to open a Windows 11 Command Prompt as AdministratorHow to start Windows in Safe ModeHow to remove a Trojan, Virus, Worm, or other MalwareHow to show hidden files in Windows 7How to see hidden files in Windows DealsCategorieseLearningIT Certification CoursesGear + GadgetsSecurity Forums MoreStartup Database Uninstall Database Glossary Chat on Discord Send us a Tip! Welcome Guide freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_728x90_970x90_970x250_320x50_ATF\", slotId: \"bleepingcomputer_728x90_970x90_970x250_320x50_ATF\" }); HomeNewsGoogleGoogle Pixel phones unusable after January 2024 system updateGoogle Pixel phones unusable after January 2024 system update By Bill Toulas January 24, 2024 10:13 AM 11 Google Pixel smartphone owners report problems after installing the January 2024 Google Play system update, being unable to access their devices internal storage, open the camera, take screenshots, or even open apps. The issue is being reported by owners of numerous Pixel models, including the Google Pixel 5, 6, 6a, 7, 7a, 8, and 8 Pro, suggesting that it isn't confined to a particular hardware architecture. The root cause is unknown but is likely a software issue with the January 2024 Play system update that Google hasn't pinpointed or fixed yet. Most proposed solutions coming from affected users don't address the problem, with some reporting solving it by performing a factory reset, in which case, all data is lost. However, these recommendations are coming from impacted Google Pixel owners rather than Google themselves, who simply acknowledged they are aware of and looking into the issue. \"I wonder why this is not something that's getting blown up forcing Google for a fix. Spending so much money on a phone just to be made unusable by an update is very aggravating,\" an affected owner posted in Google's Pixel Phone support forums. Google Play system updates are separate from the monthly security patches, both accessible via Settings > Security & privacy > System & updates.Google introduced Play system updates in Android 10 as a way to deliver crucial security updates and system component enhancements and protections in devices not running the latest patch level and those that have reached the end of support by the OEM. They are served directly by Google, bypassing the OEM update channels, and are effective in keeping older Android versions compatible with modern apps and Google services, and also relatively safe. In the case of Pixels, it appears that Google performed a staged roll-out of the January 2024 Play system updates, so not every Pixel owner has received the problematic update yet. If you are still on an older update (last was November 1, 2023), it is recommended to stay on it and postpone applying the January 2024 update until the situation clears up. BleepingComputer has contacted Google for a comment on the reported problems and their plans to address them, and a member of the firm's press team has sent us the following:We are aware of this issue, and are looking into it. - GoogleSame thing happened a few months back Although the nature of the current problem has not been confirmed yet, memory bugs introduced by a Play system update previously rendered Pixel devices completely unusable in October 2023. Google eventually addressed the media storage access and repeated rebooting problems by releasing an update on November 7, 2023. However, by then, many users had already resorted to performing a factory reset, losing their data as a result. The recurrence of this type of issue in such a short timeframe is quite concerning for Pixel device users, who cannot use the features of their phones. The situation undermines the trust in Google's quality assurance processes and raises concerns about the rigor of the tech giant's validation and testing protocols before deploying a system update. Update 1/25 - Added Google's responseRelated Articles: New Xamalicious Android malware installed 330k times on Google PlayGoogle Search bug shows blank page in Firefox for AndroidAndroid malware Chameleon disables Fingerprint Unlock to steal PINsAutoSpill attack steals credentials from Android password managersiPhone apps abuse iOS push notifications to collect user data freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_728x90_320x50_InContent_1\", slotId: \"bleepingcomputer_728x90_320x50_InContent_1\" });Google Google Pixel Google Play Google Update Mobile PixelBill ToulasBill Toulas is a tech writer and infosec news reporter with over a decade of experience working on various online publications, covering open-source, Linux, malware, data breach incidents, and hacks. Previous ArticleNext ArticleComments wackoinWaco- 2 days agoI have an 8 Pro AND the January 5 update. What's different you ask?? I have GrapheneOS installed. Could that be the only difference? Inquiring minds want to know. Regoat- 2 days ago Funny because I&#39;m reading this on pixel 8 pro. Several people with the problem have the whole world where the device is sold, so how does it affect trust?AngryOxide- 1 day ago I own a Pixel 6 with GrapheneOS and no problems here. rhasce- 1 day ago Same here, I bet ya they were trying to release a kill switch for older models. I also run GrapheneOS and my phone got the same update, of course not from Google, my phone is perfectly fine, clearly it is something google trying, is why I run de-googled software, it is way better. Pixel 5a herezeroroots369- 8 hours ago \"Same here, I bet ya they were trying to release a kill switch for older models. I also run GrapheneOS and my phone got the same update, of course not from Google, my phone is perfectly fine, clearly it is something google trying, is why I run de-googled software, it is way better. Pixel 5a here\" #winner I 2nd... goggomobil- 1 day ago My Fitbit Charge 5 bricked because of a forced update. Google offered a 30% off coupon on a new unit....even though it was still in warranty. Good luck, Pixel owners!SVS24- 23 hours ago Interesting. I had the pixel issue a few months ago and at the beginning of Jan while I was away from my children. I couldn't fix it so purchased a new pixel thinking my phone was out of warranty and dying and at the very same time my Fitbit charge 5 kicked it in as well so purchased a new one of those. Not knowing how to fix it I literally purchased both a new pixel and a Fitbit charge . I'm pretty cheesed right now because in total that $2000 for something that shouldn't have happened. Tvnutt- 20 hours ago Wow! This sucks! I have a 6A and luckily now issues like this and I feel for the people affected . I did do a system update last month and, for some odd reasons reason, the VM icon won't disappear after I delete the VM. I have to restart the phone. No big deal but it is annoying.greg18- 11 hours ago No problems here on my Pixel 7 that is running stock Android 14 Beta firmware.midnightwolf- 9 hours ago Funny this gets coverage but the Samsung S22 Ultra issue on AT&T that still has no fix from November has no coverage. Tons of people are without their phones since the November update. The issue is no network connectivity and AT&T blames Samsung and Samsung blames AT&T but both recognize the issue. The funny part is that the updates shows up as November 1, 2023. Just like these phones. zeroroots369- 8 hours ago I thought everyone got these models because they're the best for De Googling and installing custom Rooms? Like the old Jelly Bombed galaxy notes... Just me? Post a Comment Community RulesYou need to login in order to post a comment Not a member yet? Register NowYou may also like:(adsbygoogle = window.adsbygoogle || []).push({});freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_300x250_300x600_160x600_Right_1\", slotId: \"bleepingcomputer_300x250_300x600_160x600_Right_1\" });Popular Stories Hackers target WordPress database plugin active on 1 million sitesMicrosoft Teams outage causes connection issues, message delaysfreestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_300x250_300x600_160x600_Right_2\", slotId: \"bleepingcomputer_300x250_300x600_160x600_Right_2\" });Latest Downloads Malwarebytes Anti-Malware Version: 4.6.8.311 5M+ Downloads Windows Repair (All In One) Version: 4.14.1 2M+ Downloads McAfee Consumer Products Removal tool Version: NA 441,111 Downloads AdwCleaner Version: 8.4.0.0 56M+ Downloads Everything Desktop Search Version: 1.4.1.1017 24,773 Downloads freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_300x250_300x600_160x600_Right_3\", slotId: \"bleepingcomputer_300x250_300x600_160x600_Right_3\" }); freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_728x90_970x90_970x250_320x50_BTF\", slotId: \"bleepingcomputer_728x90_970x90_970x250_320x50_BTF\" });Follow us:Main SectionsNews VPN Buyer Guides Downloads Virus Removal Guides Tutorials Startup Database Uninstall Database GlossaryCommunityForums Forum Rules ChatUseful ResourcesWelcome Guide SitemapCompanyAbout BleepingComputer Contact Us Send us a Tip! Advertising Write for BleepingComputer Social & Feeds Changelog Terms of Use -Privacy Policy - Ethics Statement - Affiliate Disclosure Copyright @ 2003 - 2024Bleeping Computer® LLC- All Rights Reserved Login UsernamePasswordRemember MeSign in anonymously Sign in with TwitterNot a member yet? Register Now$(document).ready(function(e) { $('.articleBody img').not('a>img').not('.contrib_but>img').click(function(e) { e.preventDefault(); $.fancybox({'href' : $(this).attr('src')}); }); }); $(document).ready(function(){ var content = $('.cz-main-left-section'); var sidebar = $('.bc_right_sidebar'); var count = 0; var myTimer; function setEqualContainer() { var getContentHeight = content.outerHeight(); var getSidebarHeight = sidebar.outerHeight(); if ( getContentHeight > getSidebarHeight ) { sidebar.css('min-height', getContentHeight); } if ( getSidebarHeight > getContentHeight ) { content.css('min-height', getSidebarHeight); } } // creating the timer which will run every 500 milliseconds // and will stop after the container will be loaded // ...or after 15 seconds to not eat a lot of memory myTimer = setInterval( function() { count++; if ( $('.testContainer').length == 0 ) { setEqualContainer(); } else { setEqualContainer(); clearInterval(myTimer); } if ( count == 15) { clearInterval(myTimer); } }, 500); $('#pinned').fixTo('.bc_right_sidebar', { bottom: 25, }); $('#more_dd').click(function (e) { e.preventDefault() }); $('.bc_goto_top a').click(function(){ $(\"html, body\").animate({ scrollTop: 0 }, 600); return false; }); jQuery('.bc_login_btn').on('click', function() { jQuery('.bc_popup').fadeIn(\"slow\"); }); jQuery('.bc_popup_close').on('click', function() { jQuery('.bc_popup').fadeOut(\"slow\"); }); });// validate comment box not empty function validate_comment_box_not_empty() {$('#frm_comment_box').submit(function(e) { if($('#comment_html_box').val().length==0) {alert(\"Please enter a comment before pressing submit\");return false; } else {return true; }}); } function cz_strip_tags(input, allowed) { allowed = (((allowed || '') + '') .toLowerCase() .match(//g) || []) .join(''); // making sure the allowed arg is a string containing only tags in lowercase () var tags = /]*>/gi, commentsAndPhpTags = /|/gi; return input.replace(commentsAndPhpTags, '') .replace(tags, function($0, $1) { return allowed.indexOf('') > -1 ? $0 : ''; }); } function cz_br2nl(str) {var regex = //gi; //var pure_str = str.replace(regex,\"\"); var pure_str = str.replace(regex,\"\"); return cz_strip_tags(pure_str,''); } $(document).ready(function(e) { // validate comment box not empty validate_comment_box_not_empty(); // report comment $('#comment-report-other-reason-wrap').css('display','none'); $('.cz-popup-close').click(function(e) { e.preventDefault(); $('.cz-popup').fadeOut(\"slow\"); }); $('.cz-comment-report-btn').click(function(e) { e.preventDefault(); $('.cz-popup').css('height',$( document ).height()+'px'); //var comment_box_report_top = $(this).offset().top; var comment_box_report_top = $(document).scrollTop(); $('.cz-popup-wrapp').css('top',(comment_box_report_top+100)+'px'); $('#comment-id-report').val($(this).attr('data-id')); $('.cz-popup').fadeIn(\"slow\"); }); $(\"input[type='radio'][name='comment-report-reason']\").click(function(e) { if($(this).val()=='Other') { $('#comment-report-other-reason-wrap').css('display','block'); } else { $('#comment-report-other-reason-wrap').css('display','none'); } }); $('.comment-report-submit-btn').click(function(e) { e.preventDefault(); var comment_report_reason = \"\"; var comment_report_reason = $(\"input[type='radio'][name='comment-report-reason']:checked\").val(); if (comment_report_reason=='Other') { comment_report_reason = $('#comment-report-other-reason').val(); } if(comment_report_reason=='') { alert('Please specify reason'); } else { $('.cz-popup-report-submiting').css('display','inline-block'); $.ajax({type: \"POST\", url: 'https://www.bleepingcomputer.com/report-comment/', data: { comment_id: $('#comment-id-report').val(), reason: comment_report_reason }, success: function(data) { $('.cz-popup-report-submiting').css('display','none'); $('.cz-popup').fadeOut(\"slow\"); }}); } }); // report comment $('.cz_comment_reply_btn').click(function(e) { e.preventDefault(); $('#parent_comment_id').val($(this).attr('data-id')); $('#comment_html_box').attr('placeholder','Replying to '+$(this).attr('data-name')); var comment_box_top = $('.cz-post-comment-wrapp').offset().top; $(\"html, body\").animate({ scrollTop: comment_box_top-100 }, 600); $('#comment_html_box').focus(); }); $('.cz_comment_quote_btn').click(function(e) { e.preventDefault(); var quote_comment_html =''; if($(this).attr('data-id')!=undefined && $(this).attr('data-id')!='') { $('#parent_comment_id').val($(this).attr('data-id')); quote_comment_html = $('#comment_html_'+$(this).attr('data-id')).html(); } quote_comment_html = cz_br2nl(quote_comment_html); $('#comment_html_box').val('\"'+quote_comment_html+'\"'); var comment_box_top = $('.cz-post-comment-wrapp').offset().top; $(\"html, body\").animate({ scrollTop: comment_box_top-100 }, 600); $('#comment_html_box').focus(); }); }); function editForm(cid) { $.ajax({ type: \"GET\", url: window.location.href+\"?sa=1\", data: { f: \"e\", cid: cid }, success: function(data) { $('.cz-post-comment-wrapp').html(data);validate_comment_box_not_empty(); } }); var comment_box_top = $('.cz-post-comment-wrapp').offset().top; $(\"html, body\").animate({ scrollTop: comment_box_top-100 }, 600); } $(document).on('click', '.cz-subscribe-button' , function(e) { e.preventDefault(); $.ajax({type: \"POST\", url: window.location.href, data: { a: 'sub' }, success: function(data) { if(data == '1')$( \"li.cz-subscribe-button\" ).replaceWith( ''); } }); }); $(document).on('click', '.cz-unsubscribe-button' , function(e) { e.preventDefault(); $.ajax({ type: \"POST\", url: window.location.href, data: { a: 'unsub' }, success: function(data) { if(data == '1')$( \"li.cz-unsubscribe-button\" ).replaceWith( ''); } }); });$('.cz-print-icon, .cz-lg-print-icon').click(function(e) { e.preventDefault(); var divToPrint = document.getElementById('.article_section'); var mywindow = window.open('','','left=0,top=0,width=950,height=600,toolbar=0,scrollbars=0,status=0,addressbar=0'); var is_chrome = Boolean(mywindow.chrome); mywindow.document.write($( \".article_section\" ).html()); mywindow.document.close(); // necessary for IE >= 10 and necessary before onload for chrome if (is_chrome) { mywindow.onload = function() { // wait until all resources loaded mywindow.focus(); // necessary for IE >= 10 mywindow.print(); // change window to mywindow mywindow.close();// change window to mywindow }; } else { mywindow.document.close(); // necessary for IE >= 10 mywindow.focus(); // necessary for IE >= 10 mywindow.print(); mywindow.close(); } return true; });var loginhash = '880ea6a14ea49e853634fbdc5015a024'; var main_nav_hide_flag = true; var scrollTop =0; var main_nav_hide_timer = ''; function call_main_nav_hide() { if(main_nav_hide_flag && scrollTop >=100) { $('header').addClass(\"nav-up\"); } } var cz_header_pos = $('header').offset().top; $(window).scroll(function() {$('header').each(function(){var cz_top_of_window = $(window).scrollTop()-100; if (cz_top_of_window > cz_header_pos) { $('.bc_goto_top').fadeIn(\"slow\"); } else {$('.bc_goto_top').fadeOut(\"slow\");}}); }); var prevScrollTop = 0; $(window).scroll(function(event){ scrollTop = $(this).scrollTop(); if ( scrollTop$('body').height() - $(window).height() ) { scrollTop = $('body').height() - $(window).height(); } if (scrollTop >= prevScrollTop && scrollTop) { $('header').addClass(\"nav-up\"); } else {if (scrollTop >=100){ $('header').removeClass(\"nav-up\"); main_nav_hide_timer = setTimeout(\"call_main_nav_hide()\",5000);}else{ $('header').removeClass(\"nav-up\"); clearInterval(main_nav_hide_timer);} } prevScrollTop = scrollTop; }); $(document).ready(function(){var bLazy = new Blazy(); $(\".bc_dropdown a\").mouseenter(function(e) { $(this).parent('.bc_dropdown').delay(250).queue(function(){ $(this).addClass('show_menu').dequeue(); bLazy.revalidate(); }); main_nav_hide_flag = false; }); $(\".bc_dropdown\").mouseleave(function(e) { $(\".bc_dropdown\").clearQueue().stop().removeClass('show_menu'); main_nav_hide_flag = true; if (scrollTop >=100) { main_nav_hide_timer = setTimeout(\"call_main_nav_hide()\",5000); } }); $('.bc_dropdown a').each(function(){ if($(this).is(\":hover\")) { $(this).mouseenter(); } }); $('#bc_drop_tab a').hover(function (e) { e.preventDefault() $(this).tab('show') bLazy.revalidate(); });$('#more_dd').click(function (e) { e.preventDefault()});$('.bc_goto_top a').click(function(){$(\"html, body\").animate({ scrollTop: 0 }, 600);return false;});jQuery('.bc_login_btn').on('click', function() { jQuery('.bc_popup').fadeIn(\"slow\"); $('#ips_username').focus(); });jQuery('.bc_popup_close').on('click', function() { jQuery('.bc_popup').fadeOut(\"slow\"); }); }); $(document).mouseup(function (e) { var container = $(\".bc_login_form\"); if (!container.is(e.target) // if the target of the click isn't the container... && container.has(e.target).length === 0 && $('.bc_popup').css('display') =='block') // ... nor a descendant of the container { jQuery('.bc_popup').fadeOut(\"slow\"); } }); if($(window).width()ReporterHelp us understand the problem. What is going on with this comment? Spam Abusive or Harmful Inappropriate content Strong language OtherRead our posting guidelinese to learn what content is prohibited.Submitting... SUBMITvar loadDeferredStyles = function() { var addStylesNode = document.getElementById(\"deferred-styles\"); var replacement = document.createElement(\"div\"); replacement.innerHTML = addStylesNode.textContent; document.body.appendChild(replacement) addStylesNode.parentElement.removeChild(addStylesNode); }; var raf = requestAnimationFrame || mozRequestAnimationFrame || webkitRequestAnimationFrame || msRequestAnimationFrame; if (raf) raf(function() { window.setTimeout(loadDeferredStyles, 0); }); else window.addEventListener('load', loadDeferredStyles);",
    "commentLink": "https://news.ycombinator.com/item?id=39144740",
    "commentBody": "Pixel owners report problems after installing January 2024 Google Play update (bleepingcomputer.com)157 points by buildbot 17 hours agohidepastfavorite157 comments lacoolj 16 hours agoTitle is super misleading. I have 3 different pixels, all different versions (4, 5a, 7a) and none of them are \"unusable\" after the update. I'm sure others are having issues, but this isn't something that's bricking everyone's phones. reply jjulius 16 hours agoparentFWIW, I'm a Pixel user (who drags his ass installing these updates, so I haven't updated yet) and I naturally assumed reading the headline that this didn't actually impact all Pixel phones. Reason being that we would've obviously heard a loud uproar if every Pixel phone was suddenly bricked. reply ffsm8 15 hours agorootparentPixel 8 pro and pixel 6 owner here. no issues so far, both devices are up-to-date reply ijhuygft776 14 hours agorootparentprev> Reason being that we would've obviously heard a loud uproar if every Pixel phone was suddenly bricked. Many people (most?) have more than one device... computer... etc.. either way, there are many other ways to contact someone. reply JeremyNT 13 hours agoparentprevTotally agree, this headline is misleading and the article isn't useful. It's just blogspam for a reddit thread where some users report issues that coincide with receiving this update. When you have an installed base as large as Google, some users are going to report problems after every update. These problems may not even have anything to do with the update contents, perhaps the update is what the user associates with the onset of their issues. It's entirely possible these \"storage issues\" are hardware and the i/o and reboot cycle of the update just caused it to manifest in a user visible way. By all means I want users to hold Google accountable for mistakes but I feel like there's basically no information in this article beyond the speculation on reddit. The standard for HN should be higher than this IMO. reply josephcsible 15 hours agoparentprevAre you sure they all got the Google Play system update, and that you're not confusing it with the Android security update? reply JAM1971 15 hours agorootparentI'm sure. I have two in my house and they're purring right along. reply slenk 15 hours agoparentprevSame. 8p, 6a and 6p all working fine reply jacquesm 16 hours agoparentprevWith three phones and a one-in-eight chance of being unaffected (assuming 50% for each phone) that still leaves a very large number of phones out there that are potentially affected. 100's of millions of devices. The article is pretty clear that it doesn't seem to affect every phone, but that there are numerous complaints. I'm always imagining 'Some' in front of headlines like these unless it says 'All'. reply bwanab 15 hours agorootparentThat's probably a good policy, but it isn't good English. Any formulation of X has Y characteristic where X is a group implies all members of the group unless the \"some\" is explicit. It's a total clickbait headline, but you already knew that hence your policy. reply lolinder 15 hours agorootparentprev> a one-in-eight chance of being unaffected (assuming 50% for each phone) Where are you getting 50/50 odds of being affected? Is that cited somewhere, or just a random possible percentage? (I own one unaffected Pixel.) reply jacquesm 15 hours agorootparentOut of thin air... reply leto_ii 15 hours agorootparentprev> With three phones and a one-in-eight chance of being affected (assuming 50% for each phone) 1/8 would be the chance to have all 3 affected. The chance of having at least one affected would be 1-1/8. reply jacquesm 15 hours agorootparentCorrect, I meant to write 'unaffected'. I'll fix it, thank you. reply ajross 15 hours agorootparentprev> With three phones and a one-in-eight chance of being unaffected (assuming 50% for each phone) that still leaves a very large number of phones out there that are potentially affected. Sure, but isn't it the primary job of journalists writing about subjects like this to figure that stuff out before publishing? This is a headline that clearly implies \"all\" phones. Now we're in a subthread where it seems like the fraction is \" The issue is being reported by owners of numerous Pixel models, including the Google Pixel 5, 6, 6a, 7, 7a, 8, and 8 Pro, suggesting that it isn't confined to a particular hardware architecture. > The root cause is unknown but is likely a software issue with the January 2024 Play system update that Google hasn't pinpointed or fixed yet. > If you are still on an older update (last was November 1, 2023), it is recommended to stay on it and postpone applying the January 2024 update until the situation clears up. > In the case of Pixels, it appears that Google performed a staged roll-out of the January 2024 Play system updates, so not every Pixel owner has received the problematic update yet. reply 3np 15 hours agoparentSo degoogled GrapheneOS not affected. reply morserer 10 hours agorootparentAm on degoogled graphene, can confirm, solid as a rock now and since day one. GOS is in a class of its own. reply krpl 7 hours agorootparentAlso on Graphene, everything is working just fine. reply zerof1l 18 minutes agoprevNo problems with my Pixel 7a with latest GrapheneOS update is perfectly fine reply therealfiona 16 hours agoprevLoved my Nexus 5x until the high power CPU cores started failing causing instabilities. Loved my pixel 2 until the battery stopped holding a charge. Liked my 4a (it is literally a faster 2 that you can't squeeze to bring up google assistant (the squeeze was my fave feature)) until the April 2023 update that ruined the battery life. They never fixed it. Pixel 7 was suffering the same issues at the time. I made the decision to switch to a Samsung S23+ and not looking back. Build quality of the Google flagships never have been the best, but they always have issues. I am getting too old to have time to fiddle with this stuff and just want something that works. reply bitwize 16 hours agoparentI hear a small company called Apple is making a viable alternative. reply jacquesm 16 hours agorootparentApple is by no means perfect when it comes to updating devices. https://www.google.com/search?q=apple+ota+update+breaks+phon... There isn't a single manufacturer that consistently gets this right, only different shades of gray. reply hbn 13 hours agorootparentAt the scale Apple operates at, if there's a widespread issue with the iPhone, it will be known. And not just reported about on tech nerd sites, it'll be on major news stations because it's potentially affecting your dad and many people you know. That's why bendgate and antennagate were such famous incidents. If Apple was having hardware and software defects at the rate of recent Pixel phones scaled to the iPhone's marketshare, it would be massive news. reply DANmode 10 hours agorootparentApple users aren't as picky about what their device should be doing, or achieving. Half the time, they have no perception of, or perspective whatsoever on what's buggier than what they were previously using. reply bdcravens 15 hours agorootparentprevThis is very true. Maybe it's just perception, but from the outside, it feels like Google plays the most fast and loose of the mainstream options. Samsung and Apple seem more trustworthy. reply nucleardog 14 hours agorootparentprevYes, but in terms of: > I am getting too old to have time to fiddle with this stuff and just want something that works. I definitely find the iPhone great. It _generally_ just works. If shit does break there's no fiddling... it's just broken. If it doesn't work the way you want there's no fiddling... suck it up or get a new phone. I was going to say it's like an appliance and compare it to my toaster, but I would 100% end up at my kitchen table angrily disassembling my toaster if it failed to make me breakfast one morning. reply jacquesm 14 hours agorootparentI'm still on an older Nokia, it is 'just something that works'. It's limited enough that it isn't an distraction and it works very well as a phone. reply ravetcofx 15 hours agorootparentprevSamsung is quite reliable. I really like Dex and their overall multi-tasking capabilities reply bitwize 10 hours agorootparentToo bad they pulled an Other OS with it. reply fletchowns 15 hours agoprevI installed the update on my Pixel 7 but I haven't experienced the issues described in the article. However, I am back to having to re-pair my Garmin Venu 2 Plus watch every day after some Pixel update a few months ago. It was broken in early 2023, then they fixed it, then broke it again :( https://www.reddit.com/r/GarminWatches/comments/12hpk0c/venu... I can't help but think they do it deliberately, in order to drive folks to the Pixel watch. reply cmrdporcupine 15 hours agoparentAh, so. I'm not the only one. In my case I actually can't properly pair the device at all. I hadn't used my watch (Fenix 6 X) in many months, and last time I used it was with another phone. I went to pair with my Pixel on Android 14 and the actual bluetooth pairing works fine -- shows up in the list of Bluetooth devices -- but the Garmin app refuses to add it, thinks it can't talk to it. So the phone / watch connection can never happen. I suspect Google has made changes to bluetooth stack yet again and the Garmin stuff simply isn't working with it. (TBH their apps seem pretty janky) After this I might just go back to an iPhone. reply fletchowns 10 hours agorootparentI always have to go to the gear menu on my phone, Connections -> Connectivity -> Phone -> Pair Phone to put it in pairing mode in order for the Garmin Connect app to detect it. The bluetooth pairing alone is never enough for me, it seems to pair successfully but then like you mentioned, the app never talks to it. reply cmrdporcupine 10 hours agorootparentOh, I'm doing the pair process through the Garmin Connect app. I put the watch into pairing mode, then go to the app. The app sees the watch, then Android prompts for the bluetooth pairing code. That succeeds, the app goes into some sort of state of talking to the watch -- the watch switches to showing a little logo for the app even -- but then the app cacks out saying the pairing was not successful. Something is going wrong with some internal state transitions, or it loses connectivity while doing some sort of data sync or something. Sketchy. reply mataug 14 hours agoprevAs much as I don't like apple's walled garden, reliability and consistency are exteremly valuable for users like my mom who's currently a pixel user. I hate being worried about her calling from a neighbor's phone one day because her phone is unusable. I'm aware that this issue doesn't affect all pixels, but an issue like this affecting even 1% of devices is not okay. I'm holding on to hope that google hasn't agressively pushed out this update, and my mom's phone won't auto update until this is resolved. reply rurp 14 hours agoparentIt's not just breaking changes that are a problem, UX changes just for the heck of it can cause people a lot of frustration. Pretty much every major Android version moves or changes core functionality. Changing the UI without a functional reason is the sort of thing a lot of people in tech get excited about but most people outside of the industry loathe. reply lancesells 13 hours agorootparentI feel Apple does this too. The main app I use is Music and it sure feels like the UI is worse and overly complicated these days. Not to mention uglier. reply seatac76 16 hours agoprevIt was stuff like this that made me switch to iPhone. The notable ones were the December bug and them breaking SMS. What sort of testing they use is beyond me. reply kmeisthax 16 hours agoparentIf Apple were to tone down their anticompetitive monopolistic bullshit by like, one notch, I would have bought an iPhone 15 Pro Max instead of the Pixel 8 Pro I would up buying. Maybe in a few years when the EU has managed to force universal compliance for the DMA... reply HackerThemAll 16 hours agoparentprevThe funny part is that internally they get the update way earlier than anyone outside, so it should already be spotted. https://9to5google.com/2017/04/18/google-pixel-xl-ota-dogfoo... reply kevingadd 15 hours agorootparentDogfooding there was historically kind of a joke. I had severe issues with my Nexus hardware as a Googler and none of them ever got fixed. When they offered to give us all free Nexus phones as a Christmas gift one year I refused because I wasn't about to subject myself to another one. I'd wager money that dogfooders caught this issue and reported it, and nothing was done because it either fell through the cracks or wasn't reported enough to pass the \"care about it\" bar. Don't interpret this as a slam on the individual developers from the Android team, though. They're determined to fix stuff and some of them worked with me to troubleshoot issues. At the end of the day though it was organizational priorities preventing fixes, or high level decisions resulting in trainwrecks down the road. My favorite example is that the Nexus 5x phone I owned (bought out-of-pocket) had horrible thermal characteristics. The second-hand explanation I got was that late in the design process, they decided to put a fingerprint reader on the housing such that it sat directly on top of the main CPU package, and it turns out fingerprint readers don't work terribly well as heat sinks. The people who knew enough to protest about this decision were, it seems, overruled. I can attest that the stupid thing overheated constantly, causing the CPUs to throttle. I had to stop using the official (also purchased from Google) case because the case further impaired heat dissipation. That was my second Google handset and the last time I will ever personally buy one. My current employer did buy me a Pixel 4a for work use but I don't have anything positive to say about it other than \"it only makes me angry some of the time\". reply HackerThemAll 15 hours agorootparentThanks for this perspective. It's mind-boggling that a company with such resources, talent and presence in the whole world is unable to innovate in such a simple thing and it seems they're going similar route Microsoft did with its smartphone, which they eventually killed. Let's look at it from a different perspective. Google is unable to properly launch a phone worldwide and the decisions are incomprehensible to a thinking human. They support Pixel 8 in Ireland (5 million population), Norway (5.4 million), Denmark (5.9) but they don't in Poland (38 million, part of European Union for 20 years) where they bought one of the largest offices for over $600 million USD to support 2,500 employees. Poles consider Pixel's price a fair price, not an expensive one. Not to mention lack of Pixel presence in at least some Asian countries with at least several hundred millions of potential customers. As for the technicalities, they even did not enter all radio frequencies and countries in their version of Android, so that 5G or some Wi-Fi bands don't work in some countries. When you roam from supported country to an unsupported one, you may loose part or all connectivity. They did the same in Chromecast. Multiple layoffs confirm it's all about money at Google, so why they don't reach for an easy money from smartphone market? Lack of vision, lack of knowledge, name it however you want. reply seper8 16 hours agoparentprevApple did the same in the past... reply green-eclipse 15 hours agoparentpreviPhones have plenty of issues too, I've experienced my fair share, as have others. Technology always has bugs: https://discussions.apple.com/community/iphone reply timothyduong 14 hours agorootparentI did a little anecdotal Search using reddit, added “bricked” to iosBetas and Android and found android had more recent results. There’s issues with software which affect a function then there’s issues that ruin the whole phone… reply jacquesm 16 hours agoprevAh, another case of OTA murder of perfectly good devices. You have to wonder at what point regulators will step in to ensure that companies end up liable for updates that effectively cost consumers money. Updates should be to make devices safer and better, never worse. One of the devices in our house has been nagging me since forever to update and I'm just about 99% sure that if I do allow it to update I'll end up regretting it. So now I'm facing a tough choice: potentially run a device with a security issue on the network here or play the update game of Russian Roulette (with 5 bullets instead of the normal single one) and hope that I still have a functional device afterwards. reply lnxg33k1 16 hours agoparentI can already see the storm of people saying that making companies liable for the software that costs consumers money is going to kill hobbyists, because we are just casualties waiting to give everyone money without any expected right reply jacquesm 16 hours agorootparentI have a very simple solution for that: you get to choose: you are either the provider of commercial software and accept liability for your product or you have to open source it. reply sideshowb 15 hours agorootparentSo obviously open source software for proprietary hardware is treated as, er, ..? reply jacquesm 15 hours agorootparentI don't know what you're getting at, that's clearly spelled out already. But in case you didn't get it: that's without liability for the manufacturer because you have the choice to bypass them. Presumably such a situation wouldn't occur very often because 'proprietary hardware' with 'open source software' wouldn't be proprietary for very long. The software would tell you all you need to know about how it works. reply tmsbrg 14 hours agorootparentHave you heard about Android? reply jacquesm 14 hours agorootparentYes, if you have a point to make you should spell it out. Google manufactures phones, has an open source OS and has a bunch of proprietary stuff that they do not release, see: https://en.wikipedia.org/wiki/Android_(operating_system) \"However, most devices run on the proprietary Android version developed by Google, which ships with additional proprietary closed-source software pre-installed, most notably Google Mobile Services (GMS) which includes core apps such as Google Chrome, the digital distribution platform Google Play, and the associated Google Play Services development platform. Firebase Cloud Messaging is used for push notifications. \" reply grotorea 15 hours agoparentprevAt least they're doing updates. reply csdvrx 16 hours agoparentprevI've posted a small summary below, with links to consistent reports of this happening + a software course of action to unbrick the phones. It's totally on google who's refusing to release the QPST files. It's creating ewaste for no acceptable reason. Hopefully, someone will leak the QPST files to allow a restore from the Qualcomm EDL firehose mode. reply jacquesm 15 hours agorootparentNice sleuthing! It's incredible to me that there is no bullet proof recovery mode for this, even something as dumb as an Arduino can recover from almost every form of abuse. reply csdvrx 15 hours agorootparent> It's incredible to me that there is no bullet proof recovery mode for this, even something as dumb as an Arduino can recover from almost every form of abuse. There's a bullet proof recovery mode, check my comment below ( https://news.ycombinator.com/item?id=39145490 ) where I detail the steps and provide links. The EDL firehose mode is just the phone showing up on a very unique USB-ID and waiting to be spoon fed the data to be rewritten to its flash. It needs partition specifications (think like a GPT partition table) + the binary data for each partition (think like the EFI partition for the bootloader, the Windows partition for the actual operating system etc) It would take litteraly 1 minute for someone with access to the QPST to post it to archive.org and help all the people who've been affected by the bug. It would take each of them about 5 minutes to restore their phone to a working state. You may object that not everyone may have the technical ability to do that, but I'm sure the small businesses fixing phones in the malls would be happy to charge for the \"service\" of plugging the phone on a Windows computer, double-clicking on an icon, drag and dropping the right files and clicking on another button. IMHO, the fact this situation is allowed to persist, even after multiple reports of similar pixel phone problems in the past, can only have 2 explanation: 1) the good people at google writing this software have less understanding that you and I, 2 random HN users or 2) there's money to be made in not fixing the problem, as it will increase the update cycle (people with a dead phone will buy another phone) I'm all for making money, but not if the consequence is creating ewaste, and forcing people who may not have deep pockets to spend more money on yet another broken-by-design phone. reply MyNameIs_Hacker 15 hours agorootparentYou forgot 3) It requires money to fix the problem, and Google has become such a bureaucratic mess, that it can't get out its own way to do it. Those of us in large corporations see that pattern quite often. reply csdvrx 15 hours agorootparent> Those of us in large corporations see that pattern quite often. It's sad there's such a dilution of responsibility such problems are allowed to persist, and that nobody cares they are killing random people phones. reply jacquesm 15 hours agorootparentprevThat's way beyond most ordinary users though. reply csdvrx 15 hours agorootparent> That's way beyond most ordinary users though. To take a broken phone to the mall where there're a small store that's known to fix phones? reply jacquesm 15 hours agorootparentYes, precisely. That puts the onus for the fix squarely on the users, who have not created the problem and who likely will mis-identify it. If it were to happen to me - it won't - it would cost me half a day and that's assuming the 'small store in the mall' will be able to do the repair on the spot, which if there is a glut of customers due to this issue may well not be the case. reply NoZebra120vClip 16 hours agoparentprevLook at the bright side: a bricked phone won't collect your personal data, you won't be able to fall for phishing scams on it, and its battery should last a really long time! Hyperbole aside, let's remember that \"better\" and \"safer\" exist in dialectic tension. Or, \"convenience\" vs. \"security\". Often, functionality or features are removed because they were insecure, so now your device is \"safer\". If you've got a big feature update pending, consider how many bugs/flaws it may introduce as the software gets \"better\". reply jacquesm 16 hours agorootparentSlim pickings... reply microflash 15 hours agoprevYou can turn off Automatic system updates with \"Settings > System > Developer options > Automatic system updates > toggle it off\". Also, note that this is not OS update which is causing havoc (as per the article). Google Play system updates are different[1]. [1]: https://support.google.com/product-documentation/answer/1146... reply curt15 16 hours agoprevDoesn't Android use A/B updates these days? How hard would it be to revert to the previous working version? https://source.android.com/docs/core/ota/ab reply csdvrx 16 hours agoparent> How hard would it be to revert to the previous working version? In Qualcomm EDL firehose mode? Super simple if you have the QPST: the phone is waiting for an image to write to the flash. It's actually waiting for the image to immediately reboot once it's written. But google doesn't release these images, so it's like having computer permanently bricked after the hard drive was corrupted because there's no install media available. I think we (as people who are on HN and can understand the problem) have a responsibility in not letting such things happen, if only because they hurt the people who don't understand the problem, the simplicity of the solution, and may just have a phone as their only computing device. reply summm 12 hours agorootparentSince Pixel 6 Qualcomm is no longer used... reply csdvrx 8 hours agorootparentThere are several similar formats allowing to do the exact same thing with other chips: I'm most familiar with mediatek, but essentially it's always a read-only bootloader, in case the normal boot can't start. I can't imagine google forgetting to add an EDL-like reflash mode for their SoC. I can however imagine them not providing the files needed for the reflash, since that's been true since they used Qualcomm. reply ijhuygft776 16 hours agoprevI was unable to register new fingerprints or use existing registered fingerprints and my screen would randomly become unresponsive... I think it was software related because it appear to be working as expected now. (Pixel 7a) I don't auto-update apps though, just manually update the OS. I think it was the last time I bought a Pixel... but I am not sure because I don't know what else to buy. reply mihaic 15 hours agoprevMy Pixel 5's camera has not been working since October 2023 (app crashed on start), and I don't seem to be the only one. No update to fix this seems in sight. Google seems to really have dropped the ball on Pixel QA. It's a damn shame, since the Pixel was really the only good phone that wasn't huge or with an awful glass back. reply viscountchocula 16 hours agoprevIf you're not yet updated to the January Google Play system, can you keep the phone from auto-updating? I know how to do this for a full Android system update, but not for Google Play Services. reply apapapa 6 hours agoparentThe first thing I do with a new phone is disable all app automatic updates... Hope that also disabled the play store updates reply dralley 15 hours agoprevI've lost so much respect for Google over the past few years. I keep having problems with the Youtube app locking up on my Pixel 4a, requiring me to force-stop the app via applications settings before it will work again. And after doing some travel with my phone, I have a difficult time believing that the Android PMs do much traveling with theirs. So many little issues that my wife didn't have with her iPhone. reply tadeegan 15 hours agoparentThe android pm probably wear Patagonia and use iPhones. Honestly reply solarhess 13 hours agoprevThis happened to my Samsung S23 after the update too. The thing would black screen spontaneously following the update. At first it would respond to an hard-reboot, then repeatedly complain about Google Play Services crashing, and eventually black-screen again. After hard-rebooting it a few times it no longer even responds to the hard-reset key combo. reply blackbear_ 15 hours agoprevNo problem whatsoever on my side. GrapheneOS btw reply bloopernova 16 hours agoprevMine is running hot and draining its battery fast. They sure messed up this patch. reply jacek 16 hours agoprevThat's not the first story like this. It seems like more and more often the QA is done by users who have not signed up for it. Why can't a multibillion company do a proper QA? reply jacquesm 16 hours agoparentI wouldn't be surprised if it ends up making them money: people will replace their devices with newer ones. Once the device is sold it no longer has a function for the manufacturer until the next sale happens to the same user. So any update that bricks a percentage of the devices (or makes them effectively unusable) may well extract some more $ from the users. reply jstarfish 15 hours agorootparentI make it a point never to buy replacement devices from the same vendor if the product fails in such fashion. Never reward incompetence with additional revenue. reply jacquesm 15 hours agorootparentWith only two major vendors of phone software that gets problematic pretty quickly. reply radicaldreamer 15 hours agoparentprevStaffing proper QA teams went out of vogue a couple of years ago. Turns out that the way incentives are set up at most tech companies today, nobody gets dinged for shipping major software regressions/bugs while everyone is patted on the back for shipping even completely broken features on time. reply malfist 16 hours agoparentprevEven an unlimited QA budget won't catch everything. Though it is unflattering to have two major issues like this occur so close together. reply saghm 16 hours agorootparentSure, but this is the past half dozen models of the phone made by the same company who makes the OS. You'd think these would be the easiest possible test cases for them to do up front. reply TillE 16 hours agorootparentI'm sure they test those to some extent. I assume it's just a fraction of users affected, so it could be something like a service reading third-party app data and crashing due to a bug. The kind of thing that should be caught in code review, because comprehensive testing is next to impossible. reply 2OEH8eoCRo0 16 hours agorootparentprevWhile true, why would it miss something so glaring? Minor rant but if trillion dollar companies can't get it right then what hope does anybody else have? reply charcircuit 16 hours agorootparentBecause most test devices are likely constantly factory reset and aren't given the chance to live with multiple user profiles on them for a long period of time where cruft can build up and people can notice that using using external storage is broken. reply jeffbee 16 hours agoparentprevThe fact that they have the ability to roll this out to a handful of users, all of whose devices stopped working, and to detect that and not proceed with the rollout is considered success, by them. reply shadowgovt 16 hours agorootparentAnd, indeed, this rollout generally is done after in-house testing. So something's likely up where folks in the wild have their phones configured in a way Googlers don't. reply cantours 16 hours agoparentprevYou can only acquire billions of dollars if you cut corners and cheat as much as possible. reply iopq 15 hours agorootparentThis isn't true, there are a ton of companies that make lots of money while not being pieces of shit AMD is pretty good at having open source drivers, supporting Linux and Wayland, working with Framework to make an upgradable GPU in laptops. reply Sohcahtoa82 15 hours agorootparent> This isn't true Are you misinterpreting the previous comment? They didn't say you HAVE to cut corners to make billions, only that you CAN. EDIT: Oops, I missed the \"only\" in the other comment\" reply wizzwizz4 15 hours agorootparent\"You can only X if Y\" means \"In order to X, Y\" also \"You have to Y in order to X\". reply Sohcahtoa82 14 hours agorootparentShit, I missed the \"only\" in the comment. reply bradleyishungry 15 hours agorootparentprevamd also was sued and settled for price fixing with nvidia in 2008 reply iopq 2 hours agorootparentThat was ATI execs emailing Nvidia https://www.tomshardware.com/news/nvidia-amd-ati-graphics,63... reply nerpderp82 16 hours agoprevE_WONTFIX How many tons of ewaste was just created? Even the core products are hurting. The Boeingification of everything is serious risk for all the civilization. reply Volundr 16 hours agoparent> E_WONTFIX Where are you getting this? The article says they are looking into it. reply nerpderp82 15 hours agorootparentWONTFIX is the most popular bug resolution status at Google. reply neotoy 15 hours agoprevStill using my Pixel 3 and running the latest update, no issues. Hopefully my phone is just too old to be effected. reply kn100 8 hours agoprevpixel 6 pro owner here, up to date on everything, phone is entirely fine. reply anderfernandes1 14 hours agoprevI have a Pixel 7 with the January update and everything is fine. reply devaiops9001 11 hours agoprevGrapheneOS users remain unaffected. reply 0xblinq 15 hours agopreviPhones are expensive for a reason. Moving from android was the best decision I’ve made tech-wise. If you can afford it, it’s totally worth its value. reply GeekyBear 6 hours agoparentAn iPhone SE is not expensive and is supported for just as long as the flagship iPhones are. The OG $399 iPhone SE from 2016 is currently on it's eighth year of security updates, having gotten another update just a week ago. That works out to $50 per supported year. reply blashyrk 10 hours agoparentprevOr, unpopular opinion, if you don't care about brand and/or cutting edge camera quality, just buy a cheap Xiaomi phone. I have been using the Poco X3 for 3.5 years with absolutely zero issues. Even the battery still holds through an entire day of regular usage. It cost me 1/4 of the price of an iPhone and I get the same if not bigger value for my use cases (bigger in terms of battery life which was laughable back when I still used an iPhone 6, don't know if things have gotten better now). reply 0xblinq 2 hours agorootparentI’ve had a Xiaomi phone and it was the worst crap I’ve ever had. I can understand somebody compares a pixel to an iPhone… but the only advantage of a cheap/low tier android phone is that…. They’re cheap. reply csdvrx 16 hours agoprevI don't use smartphones but I find their software stack very interesting. I just investigated a Pixel 5a phone that was brought to me for \"sudden death\". The owner reported the screen showed an update attempt, then ended up bricked. It's allegedly impossible, due to the A/B update mode. Yet it managed to end up bricked, so the question is how, and what can be done. After investigation (you can do it very simply by looking at the USB ids), it's currently in Qualcomm EDL firehose mode: this is likely due to a failed attempted update https://xdaforums.com/t/fix-pixel-3-qusb_bulk_cid-xxxx_sn-xx...: \"because the bootloader has been corrupted during an attempted update - it's in EDL mode because there's nothing else it can boot into. I'd speculate it has some link with that \"clever\" new approach of being able to update the OS in the background and switch to it on the next boot\" The \"clever approach\" that causes the problem is called the FOTA (or OTA, for \"Over The Air\") update, done by the carrier. This is known and documented on https://issuetracker.google.com/issues/248340373 To leave EDL mode, it needs to be fed a bootloader + an image matching its model, to flash the eMMC memory inside. On Windows, it's easy to do Qualcomm Flash tool (GPST/QFIL) , which is easily available from many places like https://github.com/stanislawrogasik/Pixel5-VoLTE-VoWiFi/tree..., and the process is documented on sites like https://imobiefix.com/qualcomm-prog-emmc-firehose/ Ideally, the MBN file has to exactly match the model, brand (etc) so if you have a 5a, you need a 5a MBN (and maybe a XML file, still reading) According to https://support.google.com/fi/thread/227549262/sm7520-or-sdm... the model SM7520 or SDM765 ; this is confirmed by https://github.com/hoplik/Firehose-Finder/blob/master/ForFil... because it's listed as a \"Snapdragon 765G\" / 0011E0E1 According to https://xdaforums.com/t/bricked-google-pixel-4a-5g-mbn-file-... \"Google does not make QPST files available for the Pixel series\" but someone else might have uploaded that somewhere Based on https://discuss.grapheneos.org/d/9656-brick-5a-help it's a well known problem: \"The Pixel 5A has some hardware issues. I had mine poop out on me recently. Contact Googles repair team. If you have warranty they will replace it\" : It's described extensively on https://suspiciouslygeneric.com/2022/11/11/the-hidden-flaw-k... According to https://xdaforums.com/t/ipsa-pixel-5a-extended-warranty-i.46... \"Due to the Pixel 5a Black Screen of Death issue, Google has extended the warranty on 5a devices for one year beyond the original device warranty\" However, google has denied the extended warranty, even while clearly being the cause of death of the phone. Shame on you google, for creating more e-waste by refusing to release the QPST. If anyone reading this works at google, try to do something. It's not nice to put perfectly usable phones in a landfill just because a QPST is not released. I hope someone will leak the QPST, because for people who don't have the money, it's also serious expense. reply blibble 16 hours agoprevAndroid is just awful in terms of reliability I find it hard to believe anyone working for Google on Android actually uses an Android phone as their personal device I suffered all of: phone reboots 50% of the time using the camera, assistant won't answer sometimes, phone calls lock up the phone, alarm clock randomly doesn't work, it just goes on and on I had the original Android phone with Android 1.0 and had bought every 2nd or 3rd nexus/pixel phone now even I've switched to iOS (and in the process of switching my entire family too) reply fooblaster 16 hours agoparentI have used a pixel 4a and pixel 6a for many years now and haven't had any of these issues. It sounds like potentially had defective hardware, and instead of getting it repaired you just lived with it. reply shadowgovt 16 hours agorootparentThis can definitely be the case. I had a phone that for a year would drop out frequently doing cellular data. I assumed my provider was throttling me. Upgraded my phone and the problem went away; likeliest culprit was the cell circuit in the phone was slightly damaged and running full data comms was causing it to reboot. reply SushiHippie 16 hours agoparentprevGrapheneOS is literally the only thing that's keeping me on android. It has been really realiable for me, way more reliable than Samsungs or Google Pixels Android ROM. Though if GrapheneOS dies my next option will probably a linux phone, as I'll never get along with iOS. reply sebastiennight 16 hours agorootparentPlus one to GrapheneOS. Switching from iOS to Graphene was a really smooth experience for me, I can install any app I've needed so far, and I don't have to deal with 200 tracking and buggy default apps. I wish they would keep security updates going longer than the current period though. reply Freak_NL 16 hours agorootparentprevGrapheneOS is what specifically made me buy a Pixel (6 in my case). It's probably the sanest Android distribution available. reply sam2426679 15 hours agoparentprevSame here; had a Pixel 5a with Google Fi. The 1 year old Pixel randomly died one day, totally bricked. Google phone support requires them calling you (after you request it online), and the browser-based “Fi phone” was unable to receive calls from Google phone support. No other callers had this issue. When I finally got in touch with them via my wife’s phone, they wanted me to drive 1.5 hours outside of SF for a phone diagnostic. I said no thanks and switched to iPhone with AT&T. reply kreddor 16 hours agoparentprevI've been using Android since 2010 and don't remember having any stability issues for the last 6-8 years at least. Maybe it's a Pixel-thing? I've mostly owned Sony and Moto devices. They're often 1-2 versions behind on Android which could explain why they're more stable maybe. (I like to customize my phones a lot (minimalist launcher, Termux software, Firefox with extensions) which I would hate to give up for iOS). reply Sohcahtoa82 15 hours agoparentprevI'm always baffled when I hear someone having an experience like this. I've been using Androids since 2010. Motorola Droid, Motorola Droid 4, Motorola Droid Turbo, Pixel 3, and now Pixel 6 Pro. I've never had anything like what you describe. If you're having that many problems on multiple devices, it makes me question what the hell you do to your phones to make them do that. reply sz4kerto 16 hours agoparentprevIt's always a compromise. With Android you can get actually good typing experience in non-English languages, voice typing in non-English, proper desktop view in browsers and really good call quality or better PWM in some cases. It depends on what is important for you. iOS is not a panacea either. By they way, with Android, just use Samsung. Despite the duplicated apps it's just a better experience. reply Gabrys1 16 hours agoparentprevDon't run Google's Android. I've been on Lineage OS for years now and it's awesomely stable. reply orblivion 16 hours agorootparentDon't these alt Androids try to be up to date? Or are they purposely slow with merging upstream to avoid these problems, unless it's a security fix? reply blibble 16 hours agoparentprevapparently I can't edit my own comment now but for context the unreliability was always on the official Google flagship device using the update pushed to me OTA no betas, no rooting, nothing plain Google official Android on the official flagship device and it sucked, hard, for multiple different devices over years (and my family suffer the same pain on their devices too) reply jeffbee 16 hours agorootparentIt seems to me that the flagship device requires the beta. I had to enable beta QPRs to get features that are in the advertisements of the Pixel 8 Pro. Those features didn't exist out of the box, which was confusing. reply flerchin 16 hours agoparentprevYour symptoms are all plausibly explained by a bad battery. reply refulgentis 16 hours agoparentprevAbout 3/4 use Android, but very few have the courage to run recent builds. It's been a frustration point up the ladder, because they feel the ~same as you: why are they the only ones filing bugs? But it's not that. It's decayed internal culture. There's other stuff around the margins they could change*, but, the rot is deep and unlikely to be fixed. Too focused on...non-business objectives...to be effective. Too crucial to risk reforming. And it's very unlikely they hear about it up the ladder. And that's before the morale decline of \"even when you smile and nod and sing along with the antics, you can be let go at any point by a 2 AM email\" * tl;dr: make it dead simple to get a phone. Line managers were always a bit squirrely about expensing. It's a non-starter post late 2021, and there were never ever enough DVTs/EVTs for them to be meaningful. Establish \"everyone is on Pixel next year's - 2\", and have the VP send an org-wide email saying individuals can expense as needed. reply jeffbee 16 hours agorootparentThey used to just give everyone a Nexus every year. reply InCityDreams 16 hours agoparentprevNo chance of letting them (your family) decide for themselves? reply saintfire 16 hours agorootparentThey're not going to let they're family have green bubbles. If you cared about those around you then you would do the same. reply sz4kerto 16 hours agorootparentIn Europe we just use multi platform messengers :) like Telegram or WhatsApp or something. reply 1905 16 hours agoprevImagine when this starts happening to cars reply lgleason 16 hours agoparentTesla owner here. Many stories of that with them, and the latest autosteer update was a major downgrade. reply rconti 16 hours agorootparentThankfully they mostly break the UI. Though my auto wipers got really bad recently. The body control electronics are pretty solid. I mean, you could lock/unlock, drive the car without the tablet. Not that regulators would approve of it. reply ashleyn 16 hours agoparentprevYou don't need to imagine: https://www.reddit.com/r/MachE/comments/18m3ne2 reply radicaldreamer 15 hours agoparentprevRivian, Tesla, Ford (Mustang EVs) all have had bad OTA software shipped to them. The problem will continue to get worse as cars become mostly software defined. reply green-eclipse 16 hours agoprev [–] Mine is working fine. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Pixel smartphone owners have been encountering various issues after a system update in January 2024, including problems with accessing internal storage, using the camera, taking screenshots, and opening apps.",
      "Some users have attempted to resolve the issues by factory resetting their devices, but this has led to data loss.",
      "Google is aware of the problem and is currently investigating, raising concerns about the company's quality assurance and testing protocols. The information provided in the article includes rules from online forums, details from websites, and JavaScript code related to a website called BleepingComputer."
    ],
    "commentSummary": [
      "Pixel phone users have encountered problems after installing the January 2024 Google Play update, specifically storage issues.",
      "Speculation suggests that hardware, rather than the update, may be the cause of these problems.",
      "Dissatisfaction with Google and Apple is expressed, with some users considering switching brands. There are also reports of pairing issues between Garmin watches and Pixel phones, leading to suspicions of intentional problems caused by Google.",
      "The discussion also touches on the balance between convenience and security in technology and concerns about software quality assurance.",
      "The overall theme of the conversation is frustration with tech companies and their software updates."
    ],
    "points": 157,
    "commentCount": 157,
    "retryCount": 0,
    "time": 1706287779
  },
  {
    "id": 39146385,
    "title": "Microsoft Teams outage causing connection issues, login problems, and message delays",
    "originLink": "https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-outage-causes-connection-issues-message-delays/",
    "originBody": "Microsoft Teams outage causes connection issues, message delays{ \"@context\": \"https://schema.org\", \"@type\": \"NewsArticle\", \"url\": \"https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-outage-causes-connection-issues-message-delays/\", \"headline\": \"Microsoft Teams outage causes connection issues, message delays\", \"name\": \"Microsoft Teams outage causes connection issues, message delays\", \"mainEntityOfPage\": { \"@type\": \"WebPage\", \"id\": \"https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-outage-causes-connection-issues-message-delays/\" }, \"description\": \"Microsoft is investigating an ongoing and widespread outage impacting the users of its Teams communication platform and causing connectivity issues, login problems, and message delays.\", \"image\": { \"@type\": \"ImageObject\", \"url\": \"https://www.bleepstatic.com/content/hl-images/2023/03/27/Microsoft_Teams.jpg\", \"width\": 1600, \"height\": 900 }, \"author\": { \"@type\": \"Person\", \"name\": \"Sergiu Gatlan\", \"url\": \"https://www.bleepingcomputer.com/author/sergiu-gatlan/\" }, \"keywords\": [\"Microsoft Teams\",\"Outage\",\"Microsoft\"], \"datePublished\": \"2024-01-26T12:49:18-05:00\", \"dateModified\": \"2024-01-26T15:20:23-05:00\", \"publisher\": { \"@type\": \"Organization\", \"name\": \"BleepingComputer\", \"url\": \"https://www.bleepingcomputer.com/\", \"logo\": { \"@type\": \"ImageObject\", \"url\": \"https://www.bleepstatic.com/logos/bleepingcomputer-logo.png\", \"width\": 700, \"height\": 700 } } }!function(n){if(!window.cnxps){window.cnxps={},window.cnxps.cmd=[];var t=n.createElement('iframe');t.display='none',t.onload=function(){var n=t.contentWindow.document,c=n.createElement('script');c.src='//cd.connatix.com/connatix.playspace.js',c.setAttribute('async','1'),c.setAttribute('type','text/javascript'),n.body.appendChild(c)},n.head.appendChild(t)}}(document);cnxps.cmd.push(function () { cnxps({ playerId: '067e5169-ece3-4ce8-87ad-c7961b8bb396' }).render('6302b4e26cf04d8bbf9ab6cbec18daf4'); });var freestar = freestar || {}; freestar.queue = freestar.queue || []; freestar.config = freestar.config || {}; // Tag IDs set here, must match Tags served in the Body for proper setup freestar.config.enabled_slots = [];freestar.queue.push(function() { googletag.pubads().setTargeting('section', ['news','microsoft']);}); freestar.initCallback = function () { (freestar.config.enabled_slots.length === 0) ? freestar.initCallbackCalled = false : freestar.newAdSlots(freestar.config.enabled_slots) } ;(function(o) { var w=window.top,a='apdAdmin',ft=w.document.getElementsByTagName('head')[0], l=w.location.href,d=w.document;w.apd_options=o; if(l.indexOf('disable_fi')!=-1) { console.error(\"disable_fi has been detected in URL. FI functionality is disabled for this page view.\"); return; } var fiab=d.createElement('script'); fiab.type = 'text/javascript'; fiab.src=o.scheme+'ecdn.analysis.fi/static/js/fab.js';fiab.id='fi+o.websiteId; ft.appendChild(fiab, ft);if(l.indexOf(a)!=-1) w.localStorage[a]=1; var aM = w.localStorage[a]==1, fi=d.createElement('script'); fi.type='text/javascript'; fi.async=true; if(aM) fi['data-cfasync']='false'; fi.src=o.scheme+(aM?'cdn':'ecdn') + '.firstimpression.io/' + (aM ? 'fi.js?id='+o.websiteId : 'fi_client.js'); ft.appendChild(fi); })({ 'websiteId': 5971, 'scheme': '//' });window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-91740-1'); NewsFeatured LatestMicrosoft reveals how hackers breached its Exchange Online accountsPwn2Own Automotive: $1.3M for 49 zero-days, Tesla hacked twice23andMe data breach: Hackers stole raw genotype data, health reportsGlobal fintech firm EquiLend offline after recent cyberattackMicrosoft releases first Windows Server 2025 preview buildHide from snoops with $30 off one year of Windscribe VPNMicrosoft introduces flighting for Windows Server insidersMicrosoft Teams outage causes connection issues, message delays DownloadsLatest Most DownloadedQualys BrowserCheckSTOPDecrypterAuroraDecrypterFilesLockerDecrypterAdwCleanerComboFixRKillJunkware Removal Tool VPNsPopularBest VPNsHow to change IP addressAccess the dark web safelyBest VPN for YouTube Virus Removal GuidesLatest Most Viewed RansomwareRemove the Theonlinesearch.com Search RedirectRemove the Smartwebfinder.com Search RedirectHow to remove the PBlock+ adware browser extensionRemove the Toksearches.xyz Search RedirectRemove Security Tool and SecurityTool (Uninstall Guide)How to Remove WinFixer / Virtumonde / Msevents / Trojan.vundoHow to remove Antivirus 2009 (Uninstall Instructions)How to remove Google Redirects or the TDSS, TDL3, or Alureon rootkit using TDSSKillerLocky Ransomware Information, Help Guide, and FAQCryptoLocker Ransomware Information Guide and FAQCryptorBit and HowDecrypt Information Guide and FAQCryptoDefense and How_Decrypt Ransomware Information Guide and FAQ TutorialsLatest PopularHow to enable Kernel-mode Hardware-enforced Stack Protection in Windows 11How to use the Windows Registry EditorHow to backup and restore the Windows RegistryHow to open a Windows 11 Command Prompt as AdministratorHow to start Windows in Safe ModeHow to remove a Trojan, Virus, Worm, or other MalwareHow to show hidden files in Windows 7How to see hidden files in Windows DealsCategorieseLearningIT Certification CoursesGear + GadgetsSecurity Forums MoreStartup Database Uninstall Database Glossary Chat on Discord Send us a Tip! Welcome Guide freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_728x90_970x90_970x250_320x50_ATF\", slotId: \"bleepingcomputer_728x90_970x90_970x250_320x50_ATF\" }); HomeNewsMicrosoftMicrosoft Teams outage causes connection issues, message delays Microsoft Teams outage causes connection issues, message delays By Sergiu Gatlan January 26, 2024 12:49 PM 0Microsoft is investigating an ongoing and widespread outage impacting the users of its Teams communication platform and causing connectivity issues, login problems, and message delays. While Redmond is still working on addressing these ongoing problems, it revealed that a networking issue might be the root cause of this outage. \"We've identified a networking issue impacting a portion of the Teams service and we're performing a failover to remediate impact. Additional information can be found under TM710344 in the admin center,\" tweeted the official Microsoft account for updates on Microsoft 365 service incidents. Affected customers have reported login and server connection issues, desktop and mobile Teams apps freezing on the loading screen, and message delivery problems. Other reports mention chat history not being available and images no longer displaying in chat, as well as being left in the waiting room after joining Teams meetings.On impacted systems, customers see \"We've run into a server error. Some functions might not work right now but you can continue to use the app\" errors. According to the TM710344 incident report in the Microsoft 365 admin center, the outage was first acknowledged by Redmond at 10:37 AM EST and it impacts customers across North America, Europe, the Middle East, and Africa regions. The outage affects users performing a cold boot, who may not be able to log into teams and will see an \"oops\" page. It also causes users attempting to log into their accounts and unlocking devices to see missing messages. Other scenarios experienced by impacted customers can lead to: Users may fail to load messages in channels and chats Users are unable to view or download their media (images, videos, audio, call recordings, code snippets) Some messages may experience delays being sent Call Recordings might take longer to appear in user's OneDrive for Business and SharePoint Online Bots may be unable to download attachments Sending and receiving read receipt notifications may be delayed \"Our review of service telemetry indicates a portion of database infrastructure that facilitates multiple APls is experiencing a networking issue, resulting in impact,\" Microsoft said. \"We're continuing our investigation to isolate the underlying cause of the networking issue and develop remediation actions.\" Update January 26, 12:55 EST: Added TM710344 incident report info. Update January 26, 13:28 EST: Microsoft says it's working on addressing the server issues and is seeing signs of improvement. \"We've completed the failover in the EMEA region and service telemetry is showing some improvement. The failovers for the North and South America regions are ongoing and we continue to monitor,\" the company tweeted. Update January 26, 14:21 EST: Added details on more affected scenarios shared by Microsoft on the service health portal.Related Articles: Microsoft tests instant access to Android photos in Windows 11Jira down: Atlassian outage affecting multiple cloud servicesMajorca city Calvi&agrave; extorted for $11M in ransomware attackMajor T-Mobile outage takes down account access, mobile appOnline museum collections down after cyberattack on service providerfreestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_728x90_320x50_InContent_1\", slotId: \"bleepingcomputer_728x90_320x50_InContent_1\" }); Microsoft Teams Outage Sergiu GatlanSergiu has covered cybersecurity, technology, and other news beats for more than a decade. Email or Twitter DMs for tips.Previous ArticleNext Article Post a Comment Community RulesYou need to login in order to post a commentNot a member yet? Register NowYou may also like: (adsbygoogle = window.adsbygoogle || []).push({});freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_300x250_300x600_160x600_Right_1\", slotId: \"bleepingcomputer_300x250_300x600_160x600_Right_1\" });Popular Stories Hackers target WordPress database plugin active on 1 million sites23andMe data breach: Hackers stole raw genotype data, health reportsfreestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_300x250_300x600_160x600_Right_2\", slotId: \"bleepingcomputer_300x250_300x600_160x600_Right_2\" });freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_300x250_300x600_160x600_Right_3\", slotId: \"bleepingcomputer_300x250_300x600_160x600_Right_3\" }); freestar.config.enabled_slots.push({ placementName: \"bleepingcomputer_728x90_970x90_970x250_320x50_BTF\", slotId: \"bleepingcomputer_728x90_970x90_970x250_320x50_BTF\" });Follow us:Main SectionsNews VPN Buyer Guides Downloads Virus Removal Guides Tutorials Startup Database Uninstall Database GlossaryCommunityForums Forum Rules ChatUseful ResourcesWelcome Guide SitemapCompanyAbout BleepingComputer Contact Us Send us a Tip! Advertising Write for BleepingComputer Social & Feeds Changelog Terms of Use -Privacy Policy - Ethics Statement - Affiliate Disclosure Copyright @ 2003 - 2024Bleeping Computer® LLC- All Rights Reserved Login UsernamePasswordRemember MeSign in anonymously Sign in with TwitterNot a member yet? Register Now$(document).ready(function(e) { $('.articleBody img').not('a>img').not('.contrib_but>img').click(function(e) { e.preventDefault(); $.fancybox({'href' : $(this).attr('src')}); }); }); $(document).ready(function(){ var content = $('.cz-main-left-section'); var sidebar = $('.bc_right_sidebar'); var count = 0; var myTimer; function setEqualContainer() { var getContentHeight = content.outerHeight(); var getSidebarHeight = sidebar.outerHeight(); if ( getContentHeight > getSidebarHeight ) { sidebar.css('min-height', getContentHeight); } if ( getSidebarHeight > getContentHeight ) { content.css('min-height', getSidebarHeight); } } // creating the timer which will run every 500 milliseconds // and will stop after the container will be loaded // ...or after 15 seconds to not eat a lot of memory myTimer = setInterval( function() { count++; if ( $('.testContainer').length == 0 ) { setEqualContainer(); } else { setEqualContainer(); clearInterval(myTimer); } if ( count == 15) { clearInterval(myTimer); } }, 500); $('#pinned').fixTo('.bc_right_sidebar', { bottom: 25, }); $('#more_dd').click(function (e) { e.preventDefault() }); $('.bc_goto_top a').click(function(){ $(\"html, body\").animate({ scrollTop: 0 }, 600); return false; }); jQuery('.bc_login_btn').on('click', function() { jQuery('.bc_popup').fadeIn(\"slow\"); }); jQuery('.bc_popup_close').on('click', function() { jQuery('.bc_popup').fadeOut(\"slow\"); }); });// validate comment box not empty function validate_comment_box_not_empty() {$('#frm_comment_box').submit(function(e) { if($('#comment_html_box').val().length==0) {alert(\"Please enter a comment before pressing submit\");return false; } else {return true; }}); } function cz_strip_tags(input, allowed) { allowed = (((allowed || '') + '') .toLowerCase() .match(//g) || []) .join(''); // making sure the allowed arg is a string containing only tags in lowercase () var tags = /]*>/gi, commentsAndPhpTags = /|/gi; return input.replace(commentsAndPhpTags, '') .replace(tags, function($0, $1) { return allowed.indexOf('') > -1 ? $0 : ''; }); } function cz_br2nl(str) {var regex = //gi; //var pure_str = str.replace(regex,\"\"); var pure_str = str.replace(regex,\"\"); return cz_strip_tags(pure_str,''); } $(document).ready(function(e) { // validate comment box not empty validate_comment_box_not_empty(); // report comment $('#comment-report-other-reason-wrap').css('display','none'); $('.cz-popup-close').click(function(e) { e.preventDefault(); $('.cz-popup').fadeOut(\"slow\"); }); $('.cz-comment-report-btn').click(function(e) { e.preventDefault(); $('.cz-popup').css('height',$( document ).height()+'px'); //var comment_box_report_top = $(this).offset().top; var comment_box_report_top = $(document).scrollTop(); $('.cz-popup-wrapp').css('top',(comment_box_report_top+100)+'px'); $('#comment-id-report').val($(this).attr('data-id')); $('.cz-popup').fadeIn(\"slow\"); }); $(\"input[type='radio'][name='comment-report-reason']\").click(function(e) { if($(this).val()=='Other') { $('#comment-report-other-reason-wrap').css('display','block'); } else { $('#comment-report-other-reason-wrap').css('display','none'); } }); $('.comment-report-submit-btn').click(function(e) { e.preventDefault(); var comment_report_reason = \"\"; var comment_report_reason = $(\"input[type='radio'][name='comment-report-reason']:checked\").val(); if (comment_report_reason=='Other') { comment_report_reason = $('#comment-report-other-reason').val(); } if(comment_report_reason=='') { alert('Please specify reason'); } else { $('.cz-popup-report-submiting').css('display','inline-block'); $.ajax({type: \"POST\", url: 'https://www.bleepingcomputer.com/report-comment/', data: { comment_id: $('#comment-id-report').val(), reason: comment_report_reason }, success: function(data) { $('.cz-popup-report-submiting').css('display','none'); $('.cz-popup').fadeOut(\"slow\"); }}); } }); // report comment $('.cz_comment_reply_btn').click(function(e) { e.preventDefault(); $('#parent_comment_id').val($(this).attr('data-id')); $('#comment_html_box').attr('placeholder','Replying to '+$(this).attr('data-name')); var comment_box_top = $('.cz-post-comment-wrapp').offset().top; $(\"html, body\").animate({ scrollTop: comment_box_top-100 }, 600); $('#comment_html_box').focus(); }); $('.cz_comment_quote_btn').click(function(e) { e.preventDefault(); var quote_comment_html =''; if($(this).attr('data-id')!=undefined && $(this).attr('data-id')!='') { $('#parent_comment_id').val($(this).attr('data-id')); quote_comment_html = $('#comment_html_'+$(this).attr('data-id')).html(); } quote_comment_html = cz_br2nl(quote_comment_html); $('#comment_html_box').val('\"'+quote_comment_html+'\"'); var comment_box_top = $('.cz-post-comment-wrapp').offset().top; $(\"html, body\").animate({ scrollTop: comment_box_top-100 }, 600); $('#comment_html_box').focus(); }); }); function editForm(cid) { $.ajax({ type: \"GET\", url: window.location.href+\"?sa=1\", data: { f: \"e\", cid: cid }, success: function(data) { $('.cz-post-comment-wrapp').html(data);validate_comment_box_not_empty(); } }); var comment_box_top = $('.cz-post-comment-wrapp').offset().top; $(\"html, body\").animate({ scrollTop: comment_box_top-100 }, 600); } $(document).on('click', '.cz-subscribe-button' , function(e) { e.preventDefault(); $.ajax({type: \"POST\", url: window.location.href, data: { a: 'sub' }, success: function(data) { if(data == '1')$( \"li.cz-subscribe-button\" ).replaceWith( ''); } }); }); $(document).on('click', '.cz-unsubscribe-button' , function(e) { e.preventDefault(); $.ajax({ type: \"POST\", url: window.location.href, data: { a: 'unsub' }, success: function(data) { if(data == '1')$( \"li.cz-unsubscribe-button\" ).replaceWith( ''); } }); });$('.cz-print-icon, .cz-lg-print-icon').click(function(e) { e.preventDefault(); var divToPrint = document.getElementById('.article_section'); var mywindow = window.open('','','left=0,top=0,width=950,height=600,toolbar=0,scrollbars=0,status=0,addressbar=0'); var is_chrome = Boolean(mywindow.chrome); mywindow.document.write($( \".article_section\" ).html()); mywindow.document.close(); // necessary for IE >= 10 and necessary before onload for chrome if (is_chrome) { mywindow.onload = function() { // wait until all resources loaded mywindow.focus(); // necessary for IE >= 10 mywindow.print(); // change window to mywindow mywindow.close();// change window to mywindow }; } else { mywindow.document.close(); // necessary for IE >= 10 mywindow.focus(); // necessary for IE >= 10 mywindow.print(); mywindow.close(); } return true; });var loginhash = '880ea6a14ea49e853634fbdc5015a024'; var main_nav_hide_flag = true; var scrollTop =0; var main_nav_hide_timer = ''; function call_main_nav_hide() { if(main_nav_hide_flag && scrollTop >=100) { $('header').addClass(\"nav-up\"); } } var cz_header_pos = $('header').offset().top; $(window).scroll(function() {$('header').each(function(){var cz_top_of_window = $(window).scrollTop()-100; if (cz_top_of_window > cz_header_pos) { $('.bc_goto_top').fadeIn(\"slow\"); } else {$('.bc_goto_top').fadeOut(\"slow\");}}); }); var prevScrollTop = 0; $(window).scroll(function(event){ scrollTop = $(this).scrollTop(); if ( scrollTop$('body').height() - $(window).height() ) { scrollTop = $('body').height() - $(window).height(); } if (scrollTop >= prevScrollTop && scrollTop) { $('header').addClass(\"nav-up\"); } else {if (scrollTop >=100){ $('header').removeClass(\"nav-up\"); main_nav_hide_timer = setTimeout(\"call_main_nav_hide()\",5000);}else{ $('header').removeClass(\"nav-up\"); clearInterval(main_nav_hide_timer);} } prevScrollTop = scrollTop; }); $(document).ready(function(){var bLazy = new Blazy(); $(\".bc_dropdown a\").mouseenter(function(e) { $(this).parent('.bc_dropdown').delay(250).queue(function(){ $(this).addClass('show_menu').dequeue(); bLazy.revalidate(); }); main_nav_hide_flag = false; }); $(\".bc_dropdown\").mouseleave(function(e) { $(\".bc_dropdown\").clearQueue().stop().removeClass('show_menu'); main_nav_hide_flag = true; if (scrollTop >=100) { main_nav_hide_timer = setTimeout(\"call_main_nav_hide()\",5000); } }); $('.bc_dropdown a').each(function(){ if($(this).is(\":hover\")) { $(this).mouseenter(); } }); $('#bc_drop_tab a').hover(function (e) { e.preventDefault() $(this).tab('show') bLazy.revalidate(); });$('#more_dd').click(function (e) { e.preventDefault()});$('.bc_goto_top a').click(function(){$(\"html, body\").animate({ scrollTop: 0 }, 600);return false;});jQuery('.bc_login_btn').on('click', function() { jQuery('.bc_popup').fadeIn(\"slow\"); $('#ips_username').focus(); });jQuery('.bc_popup_close').on('click', function() { jQuery('.bc_popup').fadeOut(\"slow\"); }); }); $(document).mouseup(function (e) { var container = $(\".bc_login_form\"); if (!container.is(e.target) // if the target of the click isn't the container... && container.has(e.target).length === 0 && $('.bc_popup').css('display') =='block') // ... nor a descendant of the container { jQuery('.bc_popup').fadeOut(\"slow\"); } }); if($(window).width()ReporterHelp us understand the problem. What is going on with this comment? Spam Abusive or Harmful Inappropriate content Strong language OtherRead our posting guidelinese to learn what content is prohibited.Submitting... SUBMITvar loadDeferredStyles = function() { var addStylesNode = document.getElementById(\"deferred-styles\"); var replacement = document.createElement(\"div\"); replacement.innerHTML = addStylesNode.textContent; document.body.appendChild(replacement) addStylesNode.parentElement.removeChild(addStylesNode); }; var raf = requestAnimationFrame || mozRequestAnimationFrame || webkitRequestAnimationFrame || msRequestAnimationFrame; if (raf) raf(function() { window.setTimeout(loadDeferredStyles, 0); }); else window.addEventListener('load', loadDeferredStyles);",
    "commentLink": "https://news.ycombinator.com/item?id=39146385",
    "commentBody": "Microsoft Teams outage causes connection issues, message delays (bleepingcomputer.com)156 points by daviddavis 15 hours agohidepastfavorite93 comments ziml77 8 hours agoI wouldn't have realized this issue if a coworker wasn't looking at my screen, seeing the messages they had sent 10 minutes prior just popping up. There was no way I could have known they were late because the timestamps in Teams were the time I received the messages instead of the time the messages were sent. On his end there was also nothing indicating that there was a delivery problem. At the very least Microsoft could have given us some system-wide notification that there were problems... reply Jedd 8 hours agoparentHow would that work? You'd get an in-app message in 40 minutes saying there's a problem 40 minutes ago? Anyway, this is what status pages are for: https://admin.microsoft.com/servicestatus (currently showing a whole lotta information about problems with Microsoft Teams). reply cqqxo4zV46cp 5 hours agorootparentStatus pages are nerd tools. Anyone that says otherwise is living in a bubble. Pretending momentarily that this is not true, you wouldn’t go to a status page if you thought that everything was fine. Not sure what is warranting such a kneejerk defence… The implication is that the infra required to notify of an outage is lesser/different than what’s required to…run Teams. Publish it on DNS! reply Log_out_ 51 minutes agorootparentThis generation will reinvent the watchdog.. reply winrid 8 hours agorootparentprevUse message sent date for one, and check how late messages are arriving. If late, ping a status check endpoint. reply peteradio 7 hours agoparentprevI think messages need to show sent time and received time. I had basically the opposite issue recently: 1:23 Coworker: Hello 1:24 Me: Hello [20 minutes elapse] 1:44 Me: Did you need something? [No notifications until leave for the day] [Checks back hours later and the conversation appears as] 1:23 Coworker: Hello 1:24 Me: Hello 1:25 Coworker: Could you herp the derp? 1:30 Coworker: Nm got Mo to herp the derp. 1:44 Me: Did you need something? 1:45 Coworker: Nah I'm good. reply willj 5 hours agorootparentThat makes me think of this: https://nohello.net/en/ reply technick 10 hours agoprevI got my first taste of teams about a month ago. I had to install it on my personal laptop for a job interview. After installation, my laptop started displaying notifications encouraging me to renew my monthly subscriptions to Microsoft Office and Xbox Game Pass, things I haven't had a subscription for in over a year. It automatically set itself to start up with the computer which isn't unexpected. However I disabled the startup and it still launches when Windows restarts. Only solution was to remove it. I don't know why people waste their time using teams, it's such a trash app written by a trash company. reply manmal 10 hours agoparent> I don't know why people waste their time using teams Because its use is mandated by workplaces, schools, and lots of other entities & communities. I rather hate Teams, but suddenly I’m finding myself spending half my days with it. reply easton 10 hours agorootparentAnd those places use it because it’s free. You’re already paying for Exchange or Office, so Teams comes free. Nobody believes it’s the best product, but it’s 70% as good as Slack for free. reply krisoft 9 hours agorootparentYou are absolutely right. To me this kind of bundling is absolutely infuriating. I wish we could literally outlaw it. At work we just transfered from zoom to google meet. We did this while everyone who expressed an opinion agreed that zoom is simply a superior product. And we did it because “we are already paying for it with our google docs subscription”. It is just so anti-competitive I can’t even believe we collectively let this happen. reply maronato 3 hours agorootparentI don’t see how it’s anticompetitive. It’s not like Microsoft or Google make it harder to use Slack or Zoom. In fact, Google makes it really easy to integrate Zoom into Google calendar, and Microsoft has slack integrations for all their products. One can even argue that the office experience in slack is better than in Teams. That’s very pro-competition IMO. reply buildbot 8 hours agorootparentprevWhat's the alternative though? I don't like anti-competitive behavior at all, however thinking about what the regulation would be, I am just not sure there is any viable way. You have a few cases where the EU will go after whoever for bundling a browser, which is not really a solution. Are companies only allowed to sell products individually and never discount or bundle anything? What is a \"complete\" product? Is it Office? Word? Windows? - Which the EU has already said is conglomerate of products given the whole IE thing. It seems tricky. reply 120bits 10 hours agoparentprevI switched companies and I had to use teams. From my experience coming Slack, teams feels heavy app. The bootup is slow and overall it felt like its bloated app. I'm using M1Pro Mac. What I don't like the most of the teams app is, the freaking code editor. If I paste code in teams, it feels hard to read, in Slack it looks much better. Also, I hate it when on teams having some serious chat about prod issue and some in the group post a random message and whole thing just goes side ways. Lack of threads is bad experience for me. I can go on.. reply waynesonfire 6 hours agorootparentNevermind bloated, the entire chat workflow experiance is awful. reply peteradio 7 hours agoparentprevLook its not hard to disable the autostart you just got to interrupt on boot and get into the bios settings, from their boot a minimum os of your preference and mount onto the windows partition. Find the registry and kick up the 4d3d3d3. reply nerdjon 13 hours agoprevWhat I find most interesting about this is how long it took to see reporting on this issue, unlike what I remember the reporting on Slack being down 5 or 6 years ago that I could fairly reliably find somewhere that said it was down. Has how we used these tools just changed? They are so janky in the first place that them being \"down\" is questionably different? Just seems weird. reply JohnFen 12 hours agoparentPersonally, I just expect Teams to be janky. At least where I work, I don't think that a day goes by that it doesn't glitch out in one way or another. reply daemonologist 11 hours agorootparentYeah, I noticed Teams messages being out of order (and being re-incorrectly-ordered multiple times) this morning and didn't think anything of it. I hadn't seen that particular bug before but it didn't stand out from the normal background jank. reply logbiscuitswave 1 hour agorootparentprevA million times this. Things seemed more broken than usual in Teams for me today like image attachments not working and such. I just figured it was Teams being Teams until someone informed me there was a service outage degrading things. That’s how low the bar is. reply Quot 12 hours agorootparentprevThat's my experience too. This outage seemed like the same jank I see every day. It just took me longer to realize it's jankier than usual. reply Khaine 6 hours agorootparentprevTeams is a pile of junk. It crashes randomly. It cuts off text when you start typing. It is terrible. reply Vigorosotuna96 11 hours agorootparentprevSpot on analysis. It's a broken product, most of the time, for me. reply saltminer 8 hours agorootparentThe place I work at now uses Teams, and I legitimately didn't notice anything amiss. - Channels randomly taking several minutes to load or outright refusing to load? Normal - Calls dropping on a fast, stable ethernet connection? Normal - Messages not sending, or appearing to send but silently never arriving/being dropped upon arrival? Normal - Messages double- and triple-sending? Normal - Messages being sent out-of-order? Normal - Messages sending extremely slowly? Normal - Attachments not loading? Normal - Teams deciding logging in is just too difficult and I have to restart it at least once? Normal I remember when I got an email today about an apparently outage describing all of the above (minus the call instability), I was like \"wait, it's not supposed to be like this?\" And now that I type this out, especially having used Slack in the past, I realize what an indictment of Teams that is. (But I've also worked at a place that used Lync/Skype for Business/whatever they're calling it now, and it still manages to be pleasant compared to that mess. Though I won't give MS any credit there; the bar was on the floor, and they managed to avoid tripping over it.) reply bboygravity 10 hours agorootparentprevAnd yet companies don't mind the extremely obvious loss of productivity this causes. They also don't mind that it makes them look unprofessional. At all. I've seen townhall meetings where 200+ FTE where sitting around waiting for Teams to stop glitching for like 10 minutes. And after they go back to their desk for real work, the glitching continues. \"innovation\" reply w0m 9 hours agorootparentMy previous employer forced us to use a Hip hat instance. It was legitimately hell, deleting history randomly and just atrocious. Using Teams now (switched jobs) it legitimately feels mystical in comparison. reply mh- 9 hours agorootparentI can't help but imagine what it'll feel like if you find a job that uses Slack. reply addicted 5 hours agorootparentprevEvery week I face a new issue with Teams because every week MS will push a silent update which will invariably fix one thing but break another. reply logbiscuitswave 1 hour agorootparentThe best is when those “silent updates” restart Teams while you are in the middle of using it. reply rubicks 9 hours agoparentprevMy employer uses Teams and it is an extremely reliable productivity killer. reply robertlagrant 12 hours agoparentprevPeople seem much harsher on Slack, for some reason. Sometimes being the better product just means people notice when it's broken. reply FridgeSeal 11 hours agorootparentIs there a term for how people just kind of acclimatise to a broken, buggy tool, and don’t realise when it’s extra broken? A sort of software Stockholm syndrome? reply jurynulifcation 10 hours agorootparentMicrosoft Syndrome reply StarlaAtNight 6 hours agorootparentprevClippyitis reply thecosas 9 hours agorootparentprevI think (in general) Slack has been more open to automations and integrations, so entire workflows rest on it. Teams is catching up in this respect, but fewer people rely on it beyond day-to-day communication. Not that it's not important, but maybe just not as critical to things beyond person-to-person comms. reply juujian 10 hours agorootparentprevWhen I see the Microsoft logo, I always lower my expectations accordingly. reply bastardoperator 9 hours agorootparentprevTeams is typically a free product with an MSFT EA. reply dangerboysteve 13 hours agoparentprevI think it was because it was a widespread problem or did not appear that way. Teams for our company were mostly working. reply hrunt 13 hours agorootparentI think it was because most people are used to Teams being an application with a poor experience, so a widespread degradation in service just looks like what people normally expect from Teams. I know in the orgs that I work with, everyone today blamed any problems on Teams being a crappy application. No one thought twice about it being something more than that. reply digging 12 hours agorootparentThis was my experience. Teams was slow and functioning badly this morning, but it wasn't until someone else said they were also not seeing images that I realized it wasn't just typical jank. Teams is just not good to use in the first place so it doesn't occur to me to think I should check for outages whenever I have a problem. reply nerdjon 12 hours agorootparentprevI think especially with how Teams responded to this problem. It wasn't saying it couldn't connect or anything. I had a few symptoms: First teams froze my entire computer when I started it when it couldn't connect. Then it finally loaded and a message I sent would appear in the preview on the left but not actually in the chat window (the preview where it shows the name list of chats I have). Then messages would just sit with that circle sending, but I would receive messages occasionally. A simple \"can't connect\" would have gone a long way. reply selykg 10 hours agorootparentprevToday was the first day, in the ~4 months that we've been using Teams and MS365 for our company, that anyone noticed an actual outage. I got an email about it from a colleague and they weren't aware of the outage (I wouldn't expect them to, this team is very non-technical). So I get to explain these types of things next week, that we can't really \"fix\" these issues, they will happen though. But yea, Teams is janky. I wish I could say it was the worst thing I experienced at work, but, alas, that remains a wish and a dream. reply hhh 9 hours agoparentprevI didn't even look at HN because our yammer page had a post within a few minutes with a description of the issue, an ETA for a fix, and a time for a next update. I don't know if the speed of a technical status update is related to how much we pay to MS, but it definitely feels that way. reply myko 12 hours agoparentprevTeams is always pretty bad, I noticed slightly worse service/message duplication/call drops today. If it weren't for MS being a monopoly I doubt we'd use it reply portaouflop 10 hours agorootparentHow is MS a monopoly when it comes to workspace tools? Seems to me there are plenty of alternatives and I am lucky enough that I never had to use it at work. reply myko 9 hours agorootparentIf your org uses Microsoft products, typically a Teams license is baked in (or at least was at some point). So when it comes to choosing a better tool vs Teams it is an easy decision for the bean counters - we're already paying for Teams, let's just use it. reply portaouflop 7 hours agorootparentFor sure - maybe I read GP in bad faith, but I understood it as “we have to choose Teams in my org because it’s a monopoly” Few things frustrate me more than being forced into an unproductive situation - completely kills my motivation. reply m348e912 8 hours agoprevI am sheepishly going to chime in and say I recognize many of ms teams shortcomings but I actually cringe when I have to join meetings on zoom or god forbid, webex. Joining meetings in teams and sharing screen works decently well for me and I do it enough that I am fairly satisfied with it. Could it be lighter weight? Yeah for sure. But I am definitely not running into the same issues that some people are seeing on this thread. What I have recognized is that if you don't have teams installed and have to join a teams meeting via your browser, it might work like 10% of the time. reply winrid 8 hours agoparentI will say that WebEx has worked every time I've used it. reply virusduck 7 hours agorootparentI think they’ve improved since 2021, but back then when someone sent me a webex invitation I’d feel secondhand embarrassment for them. It was BY FAR the worst of the videoconferencing platforms despite having a huge head start. reply jwnin 6 hours agoparentprevThe new (non-electron) Teams 2.0 is lighter weight and subjectively feels more responsive, fwiw. reply foobarian 7 hours agoparentprevI think teams is fine for meetings, but I shudder in cold sweat at the thought of using it for chat as well (instead of Slack). reply bloopernova 13 hours agoprevWhat's the correct status page to check? I would have assumed this: https://status.office365.com/ but it shows nothing useful. https://portal.office.com/servicestatus At least this one shows there's an issue. reply pid-1 12 hours agoparentI've found the 'Health > Dashboard' page on the admin portal to be the most reliable place to check for incidents: https://admin.microsoft.com/AdminPortal/Home?#/healthovervie... Some users may experience multiple issues with their Microsoft Teams TM710344, Last updated: Jan 26, 2024, 6:00 PM GMT-3 Estimated start time: Jan 26, 2024, 12:37 PM GMT-3 User impact Users may experience multiple issues with their Microsoft Teams. Title: Some users may experience multiple issues with their Microsoft Teams User impact: Users may experience multiple issues with their Microsoft Teams. More info: Affected scenarios include, but aren't limited to: - Users performing a cold boot may not able to log into teams and will see an \"oops\" page - Users logging in or unlocking their devices after some time may see missing messages - Users may fail to load messages in channels and chats - Users are unable to view or download their media (images, videos, audio, call recordings, code snippets) - Some messages may experience delays being sent - Call Recordings might take longer to appear in user's OneDrive for Business and SharePoint Online - Users may be unable to load previous Copilot history, or new history is not written - Bots may be unable to download attachments - Sending and receiving read receipt notifications may be delayed - Anonymous users may be unable to join meetings - Teams connectors for Power Automate/Power Apps may experiencing errors Current status: Our failover operation did not provide the immediate relief intended for end users in North and South America regions. However, we’re monitoring telemetry closely as we continue to optimize traffic patterns and apply configuration changes intended to reduce customer impact as quickly as possible. We understand the impact an issue like this can have on your organization, and we appreciate your partnership and patience as we work to remediate this issue. Scope of impact: This issue can potentially impact any Microsoft Teams user in the scenarios outlined in the More info section. Start time: Friday, January 26, 2024 at 11:55 AM GMT-3 . Next update by: Friday, January 26, 2024 at 7:00 PM GMT-3 reply numbsafari 11 hours agorootparentYou won’t see “CxO customer tee-times impacted” on that list… reply zamadatix 12 hours agoparentprevThe service health page of the 365 admin center. Normal users won't have access to those though, best place for reliable updates in that case is the X account from the article. reply jwnin 6 hours agoparentprevIt is appalling that the M365 PG resists the transparency that Azure has - no login required to see status & publicly accessible post incident reports. The best they have is an unverified Xitter account. reply LordGrey 13 hours agoparentprevThat page indicates that \"Teams (Consumer)\" is having an issue, but my enterprise version is also fubar'd. Messages are coming through, but with a 30 minute delay. A person's status is not realtime. Weirdly, I am unable to hide an entire conversation, which is something I didn't think would require a round trip to the backend. reply jdksmdbtbdnmsm 13 hours agoparentprevthat usually depends on who wants to know reply BobaFloutist 12 hours agoparentprevhttps://downdetector.com/status/teams/ reply Xiol32 13 hours agoprevSo nothing out of the ordinary, then. reply a_vanderbilt 13 hours agoparentNo one noticing it is down because it usually isn't working anyways. reply stagger87 13 hours agorootparentIt's always interesting to hear others experiences. I've used Teams for 4+ years now with zero issues until this morning. I'm only mad in that I tried troubleshooting my PC and network connection for far too long before seeing this thread. reply earthling8118 44 minutes agorootparentI've been using it for about as long as it has existed and it's never been anything but trouble. Every step of the way. It's an absolute abomination. reply blibble 13 hours agorootparentprevI had a new one this week every time someone tries screensharing to me the call hangs up and I get \"Uh oh, something went wrong!\" yeah something went wrong, someone decided to pay for Teams reply PH95VuimJjqBqy 13 hours agorootparentpretty sure you're wrong, I think Teams gets bundled, no one actually pays for it ;) reply robertlagrant 12 hours agorootparentYeah, it's free. Somehow that's competitive, even though it forced Slack to sell up, but iPhone having a 20% global smartphone market share is anticompetitive. reply JohnFen 11 hours agorootparentprevMy employer certainly pays for it. It's bundled with O365, but they pay for O365 and so they also pay for Teams. reply robertlagrant 12 hours agorootparentprevLogging into two Teams accounts is always hilarious. reply d1sxeyes 11 hours agorootparentEven more hilarious when your account on one tenant gets added as a third party on another tenant that you actually have a different account on... reply zwieback 13 hours agorootparentprevSame here, hp switched to Teams a while back and it's been working great until today. Also think we should have gotten an alert earlier. I switched to my phone app, that kept working for a bit but now it's total blackout. reply stagger87 13 hours agorootparentSome sort of banner at the top of Teams indicating there is ongoing issues would be nice. reply wharvle 10 hours agorootparentprevI haven’t really had problems with it not working. Not more than other chat programs. My main gripe is the “teams” chats having aggressively terrible UI in ways that make my work-life worse. Most of my complaints would go away if they let me make a teams chat that was a normal chat room. reply maxerickson 10 hours agorootparentprevYeah the biggest issue I've had with Teams is that I don't like the icon on the 'new' app. I guess we have enough glitches with starting screen shares (it's not frequent or a cause of extended disruptions, but it shouldn't ever happen either). reply theshackleford 10 hours agorootparentprevYeah it’s odd how that works, I have a similar experience with the appletv YouTube app people complain about and it led me to wondering how it ends up working out that way. That being said in regards to teams, it might literally be the worst software I’ve ever used. It’s a major thorn in the productivity not just of myself, but everyone including the entire org of my client who mandates it. Like not a day goes by it doesn’t impact one or more meetings. It’s bizzare how tolerated it is when everyone involved has issues that leads to them disliking it. reply marcosdumay 7 hours agoparentprevTBH, it worked better today than yesterday. reply packetlost 15 hours agoprevOh good, I was worried my accounts had been locked and I had been laid off reply jacquesm 14 hours agoparentThat could still be the case ;) reply packetlost 13 hours agorootparentIt's not ;) reply waynesonfire 6 hours agoparentprevYou mean an oppertunity to not have to use teams. reply ilikeitdark 11 hours agoprevI really, really, really dislike using Teams. Sometimes I think it's just a cruel joke that Microsoft is playing on us. reply 0xcde4c3db 7 hours agoprevI've been using Teams for a few years, at a small company with (in my admittedly parochial opinion) an uncommonly competent and diligent IT department, and it still vexes me. I've seen intermittent stuff along similar lines as this \"outage\" for as long as I've been using it, but the severity is normally such that it's just the tiniest bit of friction, easily overcome by our team's trust that we're not using it as an excuse to be unresponsive. Usually it works fine. Often enough that it's annoying, presence or meeting status refuses to update until I poke the UI hard enough, with \"enough\" seemingly varying with the phase of the moon. I sometimes watch the little circle in the corner of my icon wondering: is it enough to unlock my Windows desktop? To hover over the Teams window at all? To hover over something that forces it to redraw? To click the window and give it input focus? To reboot my DSL modem? Do the developers of the client (or the Azure message bus backend, or whatever alchemy they're doing over in Redmond) even know the answer? reply thecosas 9 hours agoprevMan, Microsoft is having a rough couple weeks given this too: https://arstechnica.com/security/2024/01/in-major-gaffe-hack... reply heywire 13 hours agoprevWe started seeing signs of issues Wednesday and Thursday with messages being out of order or disappearing and reappearing. Today has been much worse. Not even able to send images (though thankfully gifs still work lol). Not sure if it is related, but in the same time period, Microsoft Family Safety has been flaky. My son will request more Xbox / PC time, I’ll get the notification, but inside the app there is no request to approve. Or I’ll get another notification hours later. reply blitzd 12 hours agoparentThe MS Family stuff has all been broken through the app for me for the past 2-3 months - I get the notifications, get the buttons to approve, and click works, everything seems normal - but nothing ever happens on the Xbox end. I just gave up on it. reply jwnin 6 hours agoprevIt's inexplicable that a critical service such as Teams goes down in multiple geographies simultaneously - unless the root cause is an attacker who knew exactly where to push. reply password4321 11 hours agoprevFor like 2 days a while back I was able to schedule sending messages in Teams, is that a feature controlled by admins or something? reply HumblyTossed 12 hours agoprevTeams is pretty janky anyway, but today sucked. reply nyarlathotep_ 13 hours agoprevExplains my afternoon. reply ParetoOptimal 13 hours agoprevWishful thinking: May this outage be perpetual and signal the demise of the enshittification of messaging platforms like teams. reply ArtemZ 12 hours agoparentYou still are going to have to use them at work, so be careful with your wishes. reply winrid 8 hours agoprevThe client still has references to AngularJS in the source (as of last month anyway)... reply millzlane 11 hours agoprev [–] I honestly though this was all normal. Teams works great when it's working. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Microsoft is investigating a widespread outage impacting users of its Teams communication platform, causing connectivity issues, login difficulties, and message delays.",
      "The company is actively working to fix the problem and has observed signs of improvement after implementing a failover in the EMEA region.",
      "The post also includes code snippets demonstrating JavaScript functions and event handlers for controlling webpage behavior, such as printing, scrolling, dropdown menus, and popups."
    ],
    "commentSummary": [
      "Users are frustrated with Microsoft Teams due to connection problems, message delays, and glitches.",
      "Complaints include slow loading times, crashes, and lack of features compared to alternatives like Slack.",
      "Some users have become accustomed to the poor performance of Teams despite ongoing issues and outages."
    ],
    "points": 156,
    "commentCount": 93,
    "retryCount": 0,
    "time": 1706295044
  }
]
