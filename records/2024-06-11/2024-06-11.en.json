[
  {
    "id": 40639506,
    "title": "Apple Unveils Apple Intelligence with Advanced On-Device and Server AI Models",
    "originLink": "https://machinelearning.apple.com/research/introducing-apple-foundation-models",
    "originBody": "content type Featured highlight Introducing Apple’s On-Device and Server Foundation Models June 10, 2024 At the 2024 Worldwide Developers Conference, we introduced Apple Intelligence, a personal intelligence system integrated deeply into iOS 18, iPadOS 18, and macOS Sequoia. Apple Intelligence is comprised of multiple highly-capable generative models that are specialized for our users’ everyday tasks, and can adapt on the fly for their current activity. The foundation models built into Apple Intelligence have been fine-tuned for user experiences such as writing and refining text, prioritizing and summarizing notifications, creating playful images for conversations with family and friends, and taking in-app actions to simplify interactions across apps. In the following overview, we will detail how two of these models — a ~3 billion parameter on-device language model, and a larger server-based language model available with Private Cloud Compute and running on Apple silicon servers — have been built and adapted to perform specialized tasks efficiently, accurately, and responsibly. These two foundation models are part of a larger family of generative models created by Apple to support users and developers; this includes a coding model to build intelligence into Xcode, as well as a diffusion model to help users express themselves visually, for example, in the Messages app. We look forward to sharing more information soon on this broader set of models. Our Focus on Responsible AI Development Apple Intelligence is designed with our core values at every step and built on a foundation of groundbreaking privacy innovations. Additionally, we have created a set of Responsible AI principles to guide how we develop AI tools, as well as the models that underpin them: Empower users with intelligent tools: We identify areas where AI can be used responsibly to create tools for addressing specific user needs. We respect how our users choose to use these tools to accomplish their goals. Represent our users: We build deeply personal products with the goal of representing users around the globe authentically. We work continuously to avoid perpetuating stereotypes and systemic biases across our AI tools and models. Design with care: We take precautions at every stage of our process, including design, model training, feature development, and quality evaluation to identify how our AI tools may be misused or lead to potential harm. We will continuously and proactively improve our AI tools with the help of user feedback. Protect privacy: We protect our users' privacy with powerful on-device processing and groundbreaking infrastructure like Private Cloud Compute. We do not use our users' private personal data or user interactions when training our foundation models. These principles are reflected throughout the architecture that enables Apple Intelligence, connects features and tools with specialized models, and scans inputs and outputs to provide each feature with the information needed to function responsibly. In the remainder of this overview, we provide details on decisions such as: how we develop models that are highly capable, fast, and power-efficient; how we approach training these models; how our adapters are fine-tuned for specific user needs; and how we evaluate model performance for both helpfulness and unintended harm. Figure 1: Modeling overview for the Apple foundation models. Pre-Training Our foundation models are trained on Apple's AXLearn framework, an open-source project we released in 2023. It builds on top of JAX and XLA, and allows us to train the models with high efficiency and scalability on various training hardware and cloud platforms, including TPUs and both cloud and on-premise GPUs. We used a combination of data parallelism, tensor parallelism, sequence parallelism, and Fully Sharded Data Parallel (FSDP) to scale training along multiple dimensions such as data, model, and sequence length. We train our foundation models on licensed data, including data selected to enhance specific features, as well as publicly available data collected by our web-crawler, AppleBot. Web publishers have the option to opt out of the use of their web content for Apple Intelligence training with a data usage control. We never use our users’ private personal data or user interactions when training our foundation models, and we apply filters to remove personally identifiable information like social security and credit card numbers that are publicly available on the Internet. We also filter profanity and other low-quality content to prevent its inclusion in the training corpus. In addition to filtering, we perform data extraction, deduplication, and the application of a model-based classifier to identify high quality documents. Post-Training We find that data quality is essential to model success, so we utilize a hybrid data strategy in our training pipeline, incorporating both human-annotated and synthetic data, and conduct thorough data curation and filtering procedures. We have developed two novel algorithms in post-training: (1) a rejection sampling fine-tuning algorithm with teacher committee, and (2) a reinforcement learning from human feedback (RLHF) algorithm with mirror descent policy optimization and a leave-one-out advantage estimator. We find that these two algorithms lead to significant improvement in the model’s instruction-following quality. Optimization In addition to ensuring our generative models are highly capable, we have used a range of innovative techniques to optimize them on-device and on our private cloud for speed and efficiency. We have applied an extensive set of optimizations for both first token and extended token inference performance. Both the on-device and server models use grouped-query-attention. We use shared input and output vocab embedding tables to reduce memory requirements and inference cost. These shared embedding tensors are mapped without duplications. The on-device model uses a vocab size of 49K, while the server model uses a vocab size of 100K, which includes additional language and technical tokens. For on-device inference, we use low-bit palletization, a critical optimization technique that achieves the necessary memory, power, and performance requirements. To maintain model quality, we developed a new framework using LoRA adapters that incorporates a mixed 2-bit and 4-bit configuration strategy — averaging 3.5 bits-per-weight — to achieve the same accuracy as the uncompressed models. Additionally, we use an interactive model latency and power analysis tool, Talaria, to better guide the bit rate selection for each operation. We also utilize activation quantization and embedding quantization, and have developed an approach to enable efficient Key-Value (KV) cache update on our neural engines. With this set of optimizations, on iPhone 15 Pro we are able to reach time-to-first-token latency of about 0.6 millisecond per prompt token, and a generation rate of 30 tokens per second. Notably, this performance is attained before employing token speculation techniques, from which we see further enhancement on the token generation rate. Model Adaptation Our foundation models are fine-tuned for users’ everyday activities, and can dynamically specialize themselves on-the-fly for the task at hand. We utilize adapters, small neural network modules that can be plugged into various layers of the pre-trained model, to fine-tune our models for specific tasks. For our models we adapt the attention matrices, the attention projection matrix, and the fully connected layers in the point-wise feedforward networks for a suitable set of the decoding layers of the transformer architecture. By fine-tuning only the adapter layers, the original parameters of the base pre-trained model remain unchanged, preserving the general knowledge of the model while tailoring the adapter layers to support specific tasks. Figure 2: Adapters are small collections of model weights that are overlaid onto the common base foundation model. They can be dynamically loaded and swapped — giving the foundation model the ability to specialize itself on-the-fly for the task at hand. Apple Intelligence includes a broad set of adapters, each fine-tuned for a specific feature. It’s an efficient way to scale the capabilities of our foundation model. We represent the values of the adapter parameters using 16 bits, and for the ~3 billion parameter on-device model, the parameters for a rank 16 adapter typically require 10s of megabytes. The adapter models can be dynamically loaded, temporarily cached in memory, and swapped — giving our foundation model the ability to specialize itself on the fly for the task at hand while efficiently managing memory and guaranteeing the operating system's responsiveness. To facilitate the training of the adapters, we created an efficient infrastructure that allows us to rapidly retrain, test, and deploy adapters when either the base model or the training data gets updated. The adapter parameters are initialized using the accuracy-recovery adapter introduced in the Optimization section. Performance and Evaluation Our focus is on delivering generative models that can enable users to communicate, work, express themselves, and get things done across their Apple products. When benchmarking our models, we focus on human evaluation as we find that these results are highly correlated to user experience in our products. We conducted performance evaluations on both feature-specific adapters and the foundation models. To illustrate our approach, we look at how we evaluated our adapter for summarization. As product requirements for summaries of emails and notifications differ in subtle but important ways, we fine-tune accuracy-recovery low-rank (LoRA) adapters on top of the palletized model to meet these specific requirements. Our training data is based on synthetic summaries generated from bigger server models, filtered by a rejection sampling strategy that keeps only the high quality summaries. To evaluate the product-specific summarization, we use a set of 750 responses carefully sampled for each use case. These evaluation datasets emphasize a diverse set of inputs that our product features are likely to face in production, and include a stratified mixture of single and stacked documents of varying content types and lengths. As product features, it was important to evaluate performance against datasets that are representative of real use cases. We find that our models with adapters generate better summaries than a comparable model. As part of responsible development, we identified and evaluated specific risks inherent to summarization. For example, summaries occasionally remove important nuance or other details in ways that are undesirable. However, we found that the summarization adapter did not amplify sensitive content in over 99% of targeted adversarial examples. We continue to adversarially probe to identify unknown harms and expand our evaluations to help guide further improvements. Figure 3: Ratio of \"good\" and \"poor\" responses for two summarization use cases relative to all responses. Summaries are classified as \"good\", \"neutral\", \"poor\" given the grader's scores across five dimensions. A result is classified as \"good\" if all of the dimensions are good (higher is better). A result is classified as \"poor\" if any of the dimensions are poor (lower is better). Our models with adapters generate better summaries than a comparable model. In addition to evaluating feature specific performance powered by foundation models and adapters, we evaluate both the on-device and server-based models’ general capabilities. We utilize a comprehensive evaluation set of real-world prompts to test the general model capabilities. These prompts are diverse across different difficulty levels and cover major categories such as brainstorming, classification, closed question answering, coding, extraction, mathematical reasoning, open question answering, rewriting, safety, summarization, and writing. We compare our models with both open-source models (Phi-3, Gemma, Mistral, DBRX) and commercial models of comparable size (GPT-3.5-Turbo, GPT-4-Turbo)1. We find that our models are preferred by human graders over most comparable competitor models. On this benchmark, our on-device model, with ~3B parameters, outperforms larger models including Phi-3-mini, Mistral-7B, and Gemma-7B. Our server model compares favorably to DBRX-Instruct, Mixtral-8x22B, and GPT-3.5-Turbo while being highly efficient. Figure 4: Fraction of preferred responses in side-by-side evaluation of Apple's foundation model against comparable models. We find that our models are preferred by human graders. We use a set of diverse adversarial prompts to test the model performance on harmful content, sensitive topics, and factuality. We measure the violation rates of each model as evaluated by human graders on this evaluation set, with a lower number being desirable. Both the on-device and server models are robust when faced with adversarial prompts, achieving violation rates lower than open-source and commercial models. Figure 5: Fraction of violating responses for harmful content, sensitive topics, and factuality (lower is better). Our models are robust when faced with adversarial prompts. Our models are preferred by human graders as safe and helpful over competitor models for these prompts. However, considering the broad capabilities of large language models, we understand the limitation of our safety benchmark. We are actively conducting both manual and automatic red-teaming with internal and external teams to continue evaluating our models' safety. Figure 6: Fraction of preferred responses in side-by-side evaluation of Apple's foundation model against comparable models on safety prompts. Human graders found our responses safer and more helpful. To further evaluate our models, we use the Instruction-Following Eval (IFEval) benchmark to compare their instruction-following capabilities with models of comparable size. The results suggest that both our on-device and server model follow detailed instructions better than the open-source and commercial models of comparable size. Figure 7: Instruction-following capability (measured with IFEval) for Apple's foundation models and models of comparable size (higher is better). We evaluate our models’ writing ability on our internal summarization and composition benchmarks, consisting of a variety of writing instructions. These results do not refer to our feature-specific adapter for summarization (seen in Figure 3), nor do we have an adapter focused on composition. Figure 8: Writing ability on internal summarization and composition benchmarks (higher is better). Conclusion The Apple foundation models and adapters introduced at WWDC24 underlie Apple Intelligence, the new personal intelligence system that is integrated deeply into iPhone, iPad, and Mac, and enables powerful capabilities across language, images, actions, and personal context. Our models have been created with the purpose of helping users do everyday activities across their Apple products, and developed responsibly at every stage and guided by Apple’s core values. We look forward to sharing more information soon on our broader family of generative models, including language, diffusion, and coding models. Footnotes [1] We compared against the following model versions: gpt-3.5-turbo-0125, gpt-4-0125-preview, Phi-3-mini-4k-instruct, Mistral-7B-Instruct-v0.2, Mixtral-8x22B-Instruct-v0.1, Gemma-1.1-2B, and Gemma-1.1-7B. The open-source and Apple models are evaluated in bfloat16 precision. Related readings and updates. Advancing Speech Accessibility with Personal Voice A voice replicator is a powerful tool for people at risk of losing their ability to speak, including those with a recent diagnosis of amyotrophic lateral sclerosis (ALS) or other conditions that can progressively impact speaking ability. First introduced in May 2023 and made available on iOS 17 in September 2023, Personal Voice is a tool that creates a synthesized voice for such users to speak in FaceTime, phone calls, assistive communication apps, and in-person conversations. See highlight details Apple Natural Language Understanding Workshop 2023 Earlier this year, Apple hosted the Natural Language Understanding workshop. This two-day hybrid event brought together Apple and members of the academic research community for talks and discussions on the state of the art in natural language understanding. In this post, we share highlights from workshop discussions and recordings of select workshop talks. See event details Discover opportunities in Machine Learning. Our research in machine learning breaks new ground every day. Work with us",
    "commentLink": "https://news.ycombinator.com/item?id=40639506",
    "commentBody": "Apple's On-Device and Server Foundation Models (machinelearning.apple.com)862 points by 2bit 21 hours agohidepastfavorite462 comments rishabhjain1198 17 hours agoFor people interested in AI research, there's nothing new here. IMO they should do a better job of referencing existing papers and techniques. The way they wrote about \"adaptors\" can make it seem like it's something novel, but it's actually just re-iterating vanilla LoRA. It was enough to convince one of the top-voted HackerNews comments that this was a \"huge development\". Benchmarks are nice though. reply frompom 12 minutes agoparentDo you have the same expectations for any company launching hardware that they cite the various papers related to how the tech was developed? EVERY piece of tech announced by ANY company relies on a variety of research out there yet it doesn't seem expected that every time anyone launches something they cite the numerous papers related to that. Why would products/services in this category be any different? reply lolinder 16 hours agoparentprev> For people interested in AI research, there's nothing new here. Was anyone expecting anything new? Apple has never been big on living at the cutting edge of technology exploring spaces that no one has explored before—from laptops to the iPhone to iPads to watches, every success they've had has come from taking tech that was already prototyped by many other companies and smoothing out the usability kinks to get it ready for the mainstream. Why would deep learning be different? reply csvm 9 hours agorootparentPrototyping tech is one thing; making it a widely adopted success is another. For instance, Apple was the first to bring WiFi to laptops in 1999. Everyone laughed at them at the time. Who needs a wireless network when you can have a physical LAN, ey? reply steve1977 6 hours agorootparent> For instance, Apple was the first to bring WiFi to laptops in 1999. Everyone laughed at them at the time. Who needs a wireless network when you can have a physical LAN, ey? From https://en.wikipedia.org/wiki/AirPort: \"AirPort 802.11b card\" \"The original model, known as simply AirPort card, was a re-branded Lucent WaveLAN/Orinoco Gold PC card, in a modified housing that lacked the integrated antenna.\" reply gumby 6 hours agorootparentThat was also how lucent’s access points worked. reply bildung 6 hours agorootparentprevWas that really the case? I remember they were mocked for e.g. offering wifi only, firewire only etc., while the respective removed alternatives were way more common. reply blihp 5 hours agorootparentIn the consumer space at least, WiFi was nowhere to be seen on a typical PC when Apple adopted it. Same with USB. So while it technically originated and existed elsewhere, there was no serious traction on it prior to Apple adoption. What you say is also true: many people weren't ready to ditch the old when Apple decide to deprecate it. reply Matl 7 hours agorootparentprevOn the other hand, people who laughed at them removing the 3.5mm jack can still safely laugh away. reply throw0101d 6 hours agorootparent> On the other hand, people who laughed at them removing the 3.5mm jack can still safely laugh away. Then laugh at Samsung and their flagship line of phones as well, since they haven't had headphone jacks for a while now. \"After Note 10 dumps headphone jack, Samsung ads mocking iPhone dongles disappear\" (2019): * https://www.cnet.com/tech/mobile/after-removing-headphone-ja... \"Samsung is hiding its ads that made fun of Apple's removal of headphone jack\": * https://www.androidauthority.com/samsung-headphone-jack-ads-... reply tivert 6 hours agorootparent>> On the other hand, people who laughed at them removing the 3.5mm jack can still safely laugh away. > Then laugh at Samsung and their flagship line of phones as well, since they haven't had headphone jacks for a while now. \"After Note 10 dumps headphone jack, Samsung ads mocking iPhone dongles disappear\" (2019): I totally do. One of the problems with Apple is the industry seems to mindlessly ape their good and bad decisions. Their marketing has been so good, many people just assume whatever they do must be the best way. reply barbecue_sauce 5 hours agorootparentAt the time I felt like Apple was getting rid of the 3.5mm jack as a potential bottleneck for future iPhone designs (as one of the limiting aspects of form factor), but there still doesn't seem to be anything design-wise to justify it, even several years later. It is very clear now that it was merely to encourage Air Pod adoption. reply user_7832 5 hours agorootparentI would say this was obvious to the cynical of us from the very beginning. Unless you are trying to go portless (for water resistance perhaps?) or have a very thin phone, there’s very little benefits of removing the jack… except to drive airpod sales, of course. reply WanderPanda 2 hours agorootparentI mean to go thinner than 6/6s I can see the 3.5mm causing trouble. Part of me is still sad they bounced they went the other direction when it comes to iPhone thickness reply monooso 5 hours agorootparentprev> One of the problems with Apple is the industry seems to mindlessly ape their good and bad decisions... That's not a problem with Apple. reply talldayo 2 hours agorootparentIt's more of a regulatory problem, under a certain light. reply skeaker 2 hours agorootparentprevWe absolutely do laugh at both already. reply jb1991 6 hours agorootparentprevInteresting that you suggest laughing at their decision to remove the headphone jack, when it was actually just the first of an industry-wide shift that has done so by other companies. reply joshstrange 5 hours agorootparentprevThis is such a tired talking point. Use a (lightning|USB-C)->3.5mm adapter or use bluetooth. reply astrange 8 minutes agorootparentAnd your experience for phone use cases will be better, because walking with wired headphones in gives you nasty telephonic effects (sound transmission along the cable) and they get tangled up. reply IOT_Apprentice 13 hours agorootparentprevApple was first with 64 bit iPhone chips. Remember Qualcomm VP at the time claimed it was nothing. Apple Silicon for M1 was impressive for instant in low power high performance. reply lolinder 13 hours agorootparentThose are both still (major) incremental improvements to known tech, not cutting-edge research. Apple takes what other companies have already done and does it better. reply sunshinerag 10 hours agorootparentall cutting-edge research other companies are supposedly doing are also incremental. Depends on your vantage point. reply prmoustache 12 hours agorootparentprevBut last at bringing a calculator on the iPad =) reply rmbyrro 7 hours agorootparentprevI think you misinterpreted OP's comment. Apple makes it sound like there's smth new, but there isn't. They don't have to innovate, but it's good practice to credit who've done what they're taking and using. Also to use the names everyone else is already using. reply marci 6 hours agorootparentThe strange thing is Apple did mention (twice) in the article that their adapters are loras so I don't understand OP's comment. reply aceazzameen 6 hours agorootparentI gathered from OP's \"huge development\" comment he was talking about others people's popular perception that it wasn't a lora. reply steve1977 6 hours agorootparentprev> Also to use the names everyone else is already using. That would be a very un-Apple thing to do. They really like to use their own marketing terms for technologies. It's not ARM, it's Apple Silicon. It wasn't Wi-Fi, it was AirPort. etc. etc. reply astrange 7 minutes agorootparent> It wasn't Wi-Fi, it was AirPort. Except in Japan, where it's AirMac. And China, where it's WWAN not Wi-Fi. reply gumby 6 hours agorootparentprev> It wasn't Wi-Fi, it was AirPort. etc. etc. FWIW the term “airport” predated the name “wifi” — in those days you had to otherwise call it IEEE 802.11. And the name as great: people were buying them like crazy and hiding them in the drop ceiling to get around the corporate IT department. A nice echo of how analysts would buy their own apple II + visicalc to…get around corporate IT. I’m OK with Apple using “apple silicon” as the ARM is only part of it. Just commenting on your two examples; in general I agree with your point. reply steve1977 5 hours agorootparentAs far as I know, both the AirPort trademark and the term Wi-Fi got introduced in 1999 (could be that AirPort was a couple of weeks earlier) reply Tijdreiziger 5 hours agorootparentprevSee also: FireWire, iSight, Retina, FaceTime, etc. reply KerrAvon 1 hour agorootparentNone of these really fit the pattern. Apple invented FireWire, called it FireWire, and other companies chose to call it different things in their implementations (partly because Apple originally charged for licensing the name, IIRC). iSight is an Apple product. FaceTime is an Apple product. Retina is branding for high-resolution displays beyond a certain visual density. reply steve1977 58 minutes agorootparent\"Apple invented FireWire\" is maybe not fully accurate (but actually a good example of the point here). Wikipedia: FireWire is Apple's name for the IEEE 1394 High Speed Serial Bus. Its development was initiated by Apple[1] in 1986,[3] and developed by the IEEE P1394 Working Group, largely driven by contributions from Sony (102 patents), Apple (58 patents), Panasonic (46 patents), and Philips (43 patents), in addition to contributions made by engineers from LG Electronics, Toshiba, Hitachi, Canon,[4] INMOS/SGS Thomson (now STMicroelectronics),[5] and Texas Instruments. What might be interesting in this regard is that Sony was also using its own trademark for it: \"i.LINK\". reply jeanlucas 15 hours agorootparentprev> For people interested in AI research I think he is pointing out for people interested in research. OTOH, it is interesting to see how a company is applying AI to customers at the end. It will bring up new challenges that will be interesting from at least an engineering point of view. reply caseyy 5 hours agorootparentprev> Apple has never been big on living at the cutting edge of technology There was such a time. Same as with Google. Interestingly, around 2015-2016 both companies significantly shifted to iterative products from big innovations. It's more visible with Google than Apple, but here's both. Apple: - Final Cut Pro - 1998: iMac - 1999: iBook G3 (father of all MacBooks) - 2000: Power Mac G4 Cube (the early grandparent of the Mac Mini form factor), Mac OS X - 2001: iPod, iTunes - 2002: Xserve (rackable servers) - 2003: Iterative products only - 2004: iWork Suite, Garage Band - 2005: iPod Nano, Mac mini - 2006: Intel Macs, Boot Camp - 2007: iPhone and Apple TV - 2008: MacBook Air, iPhone 3G - 2009: iPhone 3Gs, all-in-one iMac - 2010: iPad, iPhone 4 - 2011: Final Cut Pro X - 2012: Retina displays, iBooks Author - 2013: iWork for iCloud - 2014: Swift - 2015: Apple Watch, Apple Music - 2016: Iterative products only - 2017: Iterative products mainly, plus ARKit - 2018: Iterative products only - 2019: Apple TV +, Apple Arcade - 2020: M1 - 2021: Iterative products only - 2022: Iterative products only - 2023: Apple Vision Pro Google: - 1998: Google Search - 2000: AdWords (this is where it all started going wrong, lol) - 2001: Google Images Search - 2002: Google News - 2003: Google AdSense - 2004: Gmail, Google Books, Google Scholar - 2005: Google Maps, Google Earth, Google Talk, Google Reader - 2006: Google Calendar, Google Docs, Google Sheets, YouTube bought this year - 2007: Street View, G Suite - 2008: Google Chrome, Android 1.0 - 2009: Google Voice, Google Wave (early Docs if I recall correctly) - 2010: Google Nexus One, Google TV - 2012: Google Drive - 2013: Chromecast - 2014: Android Wear, Android Auto, Google Cardboard, Nexus 6, Google Fit - 2015: Google Photos - 2016: Google Assistant, Google Home - 2017: Mainly iterative products only, Google Lens announced but it never rolled out really - 2018: Iterative products only - 2019: Iterative products only - 2020: Iterative products only, and some rebrands (Talk->Chat, etc) - 2021: Iterative products only, and Tensor Chip - 2022: Iterative products only - 2023: Iterative products only, and Bard (half-baked). reply vile_wretch 5 hours agorootparentSome of your choices and what you consider iterative/innovative are strange to me. For 2009, a chassis update for the iMac and a spec/camera bump for the iPhone doesn't seem particularly innovative especially in comparison to say the HomePod in 2017 or Satellite SOS in 2022. Also small correction but iTunes (as Soundjam MP) was originally third-party software and Final Cut was acquired by Apple. reply caseyy 2 hours agorootparentYes, it's not perfect. About iTunes: I did not know that! Thank you. About iterative/innovative: I considered hardware and software that became household names or general knowledge to be significant innovations. It is not rigorous, I tried to include more rather than less. Still, on some years these companies mostly did version increases for their hardware and software, like new iOS and macOS versions, and that was it. Those years I marked as iterative. I included a few too many iPhones, although when I wrote that, my thought process was that these phones were pivotal to how iPhones developed. I should have included the original iPhone, and iPhone 3G — the first iPhone developed around the concept of an app platform and with an App Store. This has undoubtedly been a big innovation. iPhone 4 and 3Gs, perhaps, should not have been included. It's loose and just to illustrate a general trend, individual items are less important, we could all pick slightly different ones. But I believe the trend would remain. reply KerrAvon 1 hour agorootparentYou're missing Apple Silicon, which has had a huge impact across the entire industry even if random soccer dad doesn't know about it -- if any one thing is responsible for Intel's marketshare collapsing in the future, the M series of processors is it. reply barbecue_sauce 5 hours agorootparentprevNo Newton? reply caseyy 2 hours agorootparentMissed it, but should have been included for 1998. A very good example. reply lolinder 4 hours agorootparentprevThe iMac refined a form factor that dated back to at least Commodore. The iBook came after decades of iteration by other companies on laptops. The Cube was just a PC with a more compressed form factor. The iPod came a few years after other commercial digital media players. Etc, etc. Note that I'm not saying that there's anything wrong with their approach or that they didn't make real improvements. I'm just saying that Apple has never produced any successful product that would count as \"new\" to someone interested in cutting-edge research. They've always looked around at things that exist but aren't yet huge successes and given them the final push to the mainstream. reply caseyy 2 hours agorootparentIt depends on the definition of \"new\". With some definitions, we may claim that nothing is ever new — we may say computers started with the Antikythera mechanism and abaci, or maybe before. With other definitions (like \"new\" as in a \"new for most people\") we will see that Apple has brought about many new things. So we need to agree on the definition. I used the definition of new somewhere between \"new for most people\", \"newly popular\", and \"meaningfully advanced from the previous iteration\". With such a definition, I think you can agree with me. reply KerrAvon 56 minutes agorootparentprevIn the consumer space, I'm not sure I can think of any examples from anyone ever that are examples of cutting-edge research at the time. It's hard to build consumer products on the bleeding edge. You'd be releasing phones today using CHERI, for example, which is not quite ready for prime time. reply throwaway4good 13 hours agoparentprevI thought the news of them using Apple Silicon rather than NVIDIA in their data centers was significant. Perhaps there is still hope of a relaunch of xserve; with the widespread use of Apple computers amongst developers Apple has a real chance of challenging NVIDIA's CUDA moat. reply pjmlp 13 hours agorootparentNot at Apple's price points. reply throwaway4good 13 hours agorootparentI think NVIDIA has the highest hardware markup at the moment. reply Hugsun 12 hours agorootparentYou get considerably more ML FLOPS per dollar in a 4090 than any mac. It seems like the base M2 MAX is at roughly the same price point. It does grant you more RAM. Quadro and Tesla cards might be a different story. I would still like to see concrete FLOPS/$ numbers. reply hajile 6 hours agorootparentThey don't need the entire mac. Their cost per Max chip is probably $200-300 which beats the 4090 by a massive margin and each chip can do more than a 4090 because it also has a CPU onboard. 4090 peaks out at around 550w which means they can run 5+ of their Max chips in the same power budget. A 4090 is $2000. Apple can probably get 5 chips on a custom motherboard for that cost. They'll use the same amount of power, but get a lot more raw compute. reply eek2121 5 hours agorootparentThe GPU in the M-series is much slower than a 4090. 4060-4070ish performance at best, and it varies quite a bit. reply hajile 4 hours agorootparentIf they can get 5 4070s for the price and power of one 4090, that's a win for them as they'll get more performance per dollar and per watt. reply throwaway4good 12 hours agorootparentprevThe M2 is a chip designed to be in a laptop (and it is quite powerful given its low power consumption). Presumedly they have a different chip or at least completely different configuration (RAM, network, etc.) in their data centers. reply mrweasel 11 hours agorootparentThe interesting point here is that developers targeting the Mac can safely assume that the users will have a processor capable of significant AI/ML workloads. On the Windows (and Linux) side of things, there's no common platform, no assumption that the users will have an NPU or GPU capable of doing what you want. I think that's also why Microsoft was initially going for the ARM laptops, where they'd be sure that the required processing power is available. reply qwytw 11 hours agorootparent> The interesting point here is that developers targeting the Mac can safely assume that the users will have a processor capable of significant AI/ML workloads Also that a significant proportion (majority?) of them will have just 8 GB of memory which is not exactly sufficient to run any complex AI/ML workloads. reply skohan 10 hours agorootparentprevI believe MS is trying to standardize this, in the same way as they do with DirectX support levels, but I agree it's probably going to be inherently a bit less consistent than Apple offerings reply pjmlp 7 hours agorootparentDirectML can use multiple backends. reply InsomniacL 9 hours agorootparentprevThat sounds like a big issue, but surely assuming for either case is bad. I expect OS's will expose an API which, when queried, will indicate the level of AI inference available. Similar to video decoding/encoding where clients can check if hardware acceleration is available. reply sofixa 11 hours agorootparentprevThat's probably where Microsoft's \"Copilot+ PCs\" come in. reply pjmlp 7 hours agorootparentPlus DirectML, wich as the name implies, builds on top of DirectX, allowing multiple backends, CPU, GPU, NPU. reply treprinum 10 hours agorootparentprevHow does it help me (with maxed out M3 Max) that Apple might have some chip in the future right now? I do DL on A6000 and 4090, not waiting until Apple produces a chip someday that is faster than 1650 in ML... reply skohan 10 hours agorootparentprevThere was a rumor floating around that Apple might try to enter the server chip business with an AI chip, which is an interesting concept. Apple's never really succeeded in the B2B business, but they have proven a lot of competency in the silicon space. Even their high-end prosumer hardware could be interesting as an AI workstation given the VRAM available if the software support were better. reply jitl 6 hours agorootparent> Apple's never really succeeded in the B2B business Idk every business I’ve worked and all the places my friends work seem to be 90% Apple hardware, with a few Lenovo issued for special case roles in finance or something. reply neodymiumphish 5 hours agorootparentThey mean server infrastructure. reply esskay 10 hours agorootparentprevOf course you do, Apple's selling mobile SOC's not high end cards. That doesn't mean they're incapable of making them for the right application. You don't seriously think the server farms running on M4 Pro Max chips do you... reply pjmlp 13 hours agorootparentprevDepends on which card one is talking about. reply throwaway4good 12 hours agorootparentMaybe. It is not really obvious how much you for the AI accellerator part of their offerings. For example the chips in iPhones are quite powerful even adjusted for price. However for some cases - like the max chip in the macbooks or the extra ram - their pricing seems high - maybe even nvidia high. reply bayindirh 12 hours agorootparentprevnext [4 more] [flagged] pjmlp 12 hours agorootparentYes, it does. Should we keep arguing like on school playground? reply bayindirh 12 hours agorootparentMaybe, if you prefer. Honestly, I'm migrating a server fleet today, so notifications are hard to hear over these Apollo 6500 fans. reply pjmlp 11 hours agorootparentNot everyone needs those. reply bayindirh 12 hours agorootparentprevI mean, even Apple can't match the markups nVidia has right now. If you break a GPU in your compute server, you wait months for a replacement, and the part is sent back if you can't replace it in five days. Crazy times. reply c0balt 11 hours agorootparentEnterprise offerings tend to differ. You can get a replacement NVIDIA GPU via a partner, like Lenovo, in 2-3 weeks. And that's on the high side for some support contracts. reply bayindirh 11 hours agorootparentThat's from HPE, for an Apollo 6500. reply grecy 3 hours agorootparentprevI'm wondering how my electricity they will save just from moving from Intel to Apple Silicon in their data centers. reply derefr 15 hours agoparentprevI think the thing they're saying that's novel, isn't what they have (LoRAs), but where and when and how they make them. Rather than just pre-baking static LoRAs to ship with the base model (e.g. one global \"rewrite this in a friendly style\" LoRA, etc), Apple seem to have chosen a bounded set of behaviors they want to implement as LoRAs — one for each \"mode\" they want their base model to operate in — and then set up a pipeline where each LoRA gets fine-tuned per user, and re-fine-tuned any time the data dependencies that go into the training dataset for the given LoRA (e.g. mail, contacts, browsing history, photos, etc) would change. In other words, Apple are using their LoRAs as the state-keepers for what will end up feeling to the user like semi-online Direct Preference Optimization. (Compare/contrast: what Character.AI does with their chatbot response ratings.) --- I'm not as sure, from what they've said here, whether they're also implying that these models are being trained in the background on-device. It could very well be possible: training something that's only LoRA-sized, on a vertically-integrated platform optimized for low-energy ML, that sits around awake but doing nothing for 8 hours a day, might be practical. (Normally it'd require a non-quantized copy of the model, though. Maybe they'll waste even more of your iPhone's disk space by having both quantized and non-quantized copies of the model, one for fast inference and the other for dog-slow training?) But I'm guessing they've chosen not to do this — as, even if it were practical, it would mean that any cloud-offloaded queries wouldn't have access to these models. Instead, I'm guessing the LoRA training is triggered by the iCloud servers noticing you've pushed new data to them, and throwing a lifecycle notification into a message queue of which the LoRA training system is a consumer. The training system reduces over changes to bake out a new version of any affected training datasets; bakes out new LoRAs; and then basically dumps the resulting tensor files out into your iCloud Drive, where they end up synced to all your devices. reply Hugsun 12 hours agorootparentThere is no way they would secretly train loras in the background of their user's phones. The benefits are small compared to the many potential problems. They describe some LoRA training infrastructure which is likely using the same capacity as they used to train the base models. > ...each LoRA gets fine-tuned per user... Apple would not implement these sophisticated user specific LoRA training techniques without mentioning them anywhere. No big player has done anything like this and Apple would want the credit for this innovation. reply throwthrowuknow 6 hours agorootparentprevI think you’re misunderstanding what they mean by adapting to use cases. See this passage: > The adapter models can be dynamically loaded, temporarily cached in memory, and swapped — giving our foundation model the ability to specialize itself on the fly for the task at hand This along with other statements in the article about keeping the base model weights unchanged says to me that they are simply swapping out adapters on a per app or per task basis. I highly doubt they will fine tune adapters on user data since they have taken a position against this. I wonder how successful this approach will be vs merging the adapters with the base model. I can see the benefits but there are also downsides. reply wmf 15 hours agorootparentprevI don't think the LoRAs are fine-tuned locally at all. It sounds like they use RAG to access data. reply derefr 15 hours agorootparentConsider a feature from earlier in the keynote: the thing Notes (and Math Notes) does now where it fixes up your handwriting into a facsimile of your handwriting, with the resulting letters then acting semantically as text (snapping to a baseline grid; being reflowable; being interpretable as math equations) but still having the kind of long-distance context-dependent variations that can't be accomplished by just generating a \"handwriting font\" with glyph variations selected by ligature. They didn't say that this is an \"AI thing\", but I can't honestly see how else you'd do it other than by fine-tuning a vision model on the user's own handwriting. reply Hugsun 12 hours agorootparentI didn't see the presentation but judging by your description, this is achievable using in-context learning. reply wmf 14 hours agorootparentprevFor everything other than handwriting I don't think the LoRAs are fine-tuned locally. reply derefr 14 hours agorootparentWell, here's another one: they promised that your local (non-iCloud) photos don't leave the device. Yet they will now — among many other things they mentioned doing with your photos — allow you to generate \"Memoji\" that look like the people in your photos. Which includes the non-iCloud photos. I can't picture any way to use a RAG to do that. I can picture a way to do that that doesn't involve any model fine-tuning, but it'd be pretty ridiculous, and the results would probably not be very good either. (Load a static image2text LoRA tuned to describe the subjects of photos; run that once over each photo as it's imported/taken, and save the resulting descriptions. Later, whenever a photo is classified as a particular subject, load up a static LLM fine-tune that summarizes down all the descriptions of photos classified as subject X so far, into a single description of the platonic ideal of subject X's appearance. Finally, when asked for a \"memoji\", load up a static \"memoji\" diffusion LoRA, and prompt it with the that subject-platonic-appearance description.) But really, isn't it easier to just fine-tune a regular diffusion base-model — one that's been pre-trained on photos of people — by feeding it your photos and their corresponding metadata (incl. the names of subjects in each photo); and then load up that LoRA and the (static) memoji-style LoRA, and prompt the model with those same people's names plus the \"memoji\" DreamBooth-keyword? (Okay, admittedly, you don't need to do this with a locally-trained LoRA. You could also do it by activating the static memoji-style LoRA, and then training to produce a textual-inversion embedding that locates the subject in the memoji LoRA's latent space. But the \"hard part\" of that is still the training, and it's just as costly!) reply janekm 10 hours agorootparentThat's going to be something similar to IPAdapter FaceID: https://ipadapterfaceid.com Basically you use a facial structure representation that you'd use for face recognition (which of course Apple already compute on all your photos) together with some additional feature representations to guide the image generation. No need for additional fine-tuning. A similar approach could likely be used for handwriting generation. reply gokuldas011011 13 hours agorootparentprevI believe this could be achieved by providing a seed image to the diffusion model and generating memoji based on it. This way fine tuning isn't required. reply raverbashing 12 hours agorootparentYup this is pretty much it, and DALLE and others can do this already reply rvaish 14 hours agorootparentprevEasel has been on iMessage for a bit now: https://apps.apple.com/us/app/easel-ai/id6448734086 reply selimnairb 8 hours agoparentprevVery little of the “AI” boom has been novel, most has been iterative elaborations (though innovative nonetheless). Academics have been using neural network statistical models for decades. What’s new is the combination of compute capability and data volume available for training. It’s iterative all the way down though, that’s how all technologies are developed. reply astrange 5 minutes agorootparentThe \"bitter lesson of machine learning\" means that you actually can't do anything novel; it won't work as well as just doing the simple thing but bigger. (So there is room left if you're limited by memory or budget.) reply sigmoid10 8 hours agorootparentprevMost people don't realize this, but almost all research works that way. Only the media spins research as breakthrough-based, because that way it is easier to sell stories. But almost everything is incremental/iterative. Even the transformer architecture, which in some way can be seen as the most significant architectural advancement in AI in the past years, was a pretty small, incremental step when it came out. Only with a lot of further work building on top of that did it become what we see today. The problem is that science-journalists vastly outnumber scientists producing these incremental steps, so instead of reporting on topics when improvements actually accumulated to a big advancement, every step along the way gets its own article with tons of unnecessary commentary heralding its features. reply w10-1 2 hours agorootparentprev> What’s new is the combination of compute capability and data volume available for training This is the important part. My advisor said new means old method applied to new data or new method on old data. Commercially, that means price points, i.e., discrete points where something becomes viable. Maybe that's iterative, but maybe not. Either way, once the opportunity presents, time is of the essence. reply threeseed 16 hours agoparentprevIt's a huge development in terms of it being a consumer-ready, on-device LLM. And if Karpathy thinks so then I assume it's good enough for HN: https://x.com/karpathy/status/1800242310116262150 reply rishabhjain1198 16 hours agorootparentThe productization of it (like Karpathy mentioned) is awesome. But I think the URL for that would be this maybe? [link](https://www.apple.com/apple-intelligence/) reply kfrzcode 15 hours agorootparentprevnext [5 more] [flagged] threeseed 15 hours agorootparenta) I would trust Karpathy over Elon given he doesn't have a competing product. b) Apple only provides information to ChatGPT when the user consents to doing so and the information is only for that request i.e. it is not logged for future training. reply pests 14 hours agorootparentprevThe temp around Elon here is lower than you think. I would say almost the exact opposite of your claim. reply slimebot80 13 hours agorootparentElon is talking out his arse as usual. reply camillomiller 13 hours agorootparentprevHe is factually wrong and has been rekted by his own community notes reply Cthulhu_ 11 hours agoparentprevThing is, Apple takes these concepts and polishes them, makes them accessible to maybe not laypeople but definitely a much wider audience compared to those already \"in the industry\", so to speak. reply WiSaGaN 16 hours agoparentprevThis gives me the vibe of calling high resolution screens as \"retina\" screens. reply dishsoap 14 hours agorootparentI don't see anything wrong with that at all. They've created a branding term that allows consumers to get an idea of the sort of pixel density they can expect without having to actually check, should they not want to bother. reply necovek 14 hours agorootparentExcept that everyone has different visual acuity and different distance they use the same devices at, and in the end, \"retina\" means nothing at all. But this is exactly the type of marketing Apple is good at, though \"retina\" is probably not the most successful example. reply theshrike79 13 hours agorootparentIf your \"visual acuity\" is so good that you can see the pixels of a retina-branded display from the intended viewing distance, you might need to be studied for science. reply necovek 5 hours agorootparentIf your visual acuity is 20/10, you'd roughly need 3600 pixels vertically to not notice any pixelation if Bill Otto did the calculations right at https://www.quora.com/What-resolution-does-20-10-vision-corr... 20/10 is rare but can easily be corrected to with glasses or contacts. You also left that \"intended viewing distance\" hanging there, without at all acknowledging what that is at a minimum? reply jackothy 12 hours agorootparentprevIt's not so impossible to spot flaws if you're using worst-case testing scenarios. Which are not worthless because such patterns do actually pop up in real world usage, albeit rarely. reply kolinko 10 hours agorootparentExamples? reply jackothy 9 hours agorootparentHad one happen to me recently where I was scrolling Spotify, and they do the thing where if you try to scroll past max they will stretch the content. One of the album covers being stretched had some kind of fine pattern on it that caused a clearly visible shifting/flashing Moiré pattern as it was being stretched. Wish I could remember what album cover it was now. Though really it's simple enough: As long as you can still spot a single dark pixel in the middle of an illuminated white screen, the pixels could benefit from being smaller. (Edit: swapped black and white) reply ngcc_hk 14 hours agorootparentprevAgreed. It is not high resolution as such, but high resolution that the user can relate to - like cannot see the pixel. Still remember the hard time using Apple newton in a conference vs the palm freely on loan in a Gartner group conference. Palm solved a problem, even though not very Apple … user can input on a small device. I kept it, on top of my newly bought newton. It is the user … reply viktorcode 5 hours agorootparentprevRetina means high pixel density, not high resolution. And there are very few standalone displays on the market which can be called “retina”, unfortunately. reply pyinstallwoes 10 hours agorootparentprevStill no manufacturer compares to the quality of apple screens and resolution … reply Malcolmlisk 9 hours agorootparentThose screens are produced by samsung. reply astrange 4 minutes agorootparentExcept for when it's LG, Sharp or BOE. reply mensetmanusman 6 hours agorootparentprevPart of the screen is, yes. Apple designs the full stack and sources new technology from multiple suppliers including Samsung. reply PaulRobinson 7 hours agorootparentprevBy your logic, I own a Foxconn smartphone with a FreeBSD-based OS. If you bought a Porsche, would you call it a Volkswagen? reply monkeydust 5 hours agoparentprevFeel Apple should have just focused on their models for this one and not complicate the conversation with OpenAI. They could have left that to another announcement later. Quick straw poll survey around the office, many think their data will be sent off to OpenAI by default for these new features which is not the case. reply scosman 10 hours agoparentprevI think you’re referring to my comment about this being huge for developers? Just want to point out I call this launch huge, didn’t say “huge development” as quoted, and didn’t imply what was interesting was the ML research. No one in this thread used the quoted words, at least that I can see. My comment was about dev experience, memory swapping, potential for tuning base models to each HW release, fine tune deployment, and app size. Those things do have the potential to be huge for developers, as mentioned. They are the things that will make a local+private ML developer ecosystem work. I think the article and comment make sense in their context: a developer conference for Mac and iOS devs. Apple also explicitly says it’s LoRA. reply marcellus23 16 hours agoparentprevThey refer to LoRA explicitly in the post. reply rishabhjain1198 16 hours agorootparentAlthough I caught that on the first read, I found myself questioning when I read the adaptors part, \"is this not just LoRA...\". Maybe it's my fault as a reader, but I think the writing could be clearer. Usually in a research paper you would link to the LoRA paper there too. reply franzb 11 hours agoparentprevThis isn't about AI research, it's about delivering AI at unimaginable scale. reply throwthrowuknow 3 hours agorootparent180 million users for chatgpt isn’t unimaginable but it does exceed the number of iPhone users in the United States. reply lhl 6 hours agoparentprevI think your conclusion is uncharitable or at least depends on how deep your interest in AI research actually is. Reading the docs, there are at least several points of novelty/interest: * Clearly outlining their intent/policies for training/data use. Committing to no using user data or interactions for training their base models is IMO actually a pretty big deal and a differentiator from everyone else. * There's a never-ending stream of new RL variants ofc, but that's how technology advances, and I'm pretty interested to see how these compare with the rest: \"We have developed two novel algorithms in post-training: (1) a rejection sampling fine-tuning algorithm with teacher committee, and (2) a reinforcement learning from human feedback (RLHF) algorithm with mirror descent policy optimization and a leave-one-out advantage estimator. We find that these two algorithms lead to significant improvement in the model’s instruction-following quality.\" * I'm interested to see how their custom quantization compares with the current SoTA (probably AQLM atm) * It looks like they've done some interesting optimizations to lower TTFT, this includes the use of some sort of self-speculation. It looks like they also have a new KV-cache update mechanism and looking forward to reading about that as well. 0.6ms/token means that for your average I dunno, 20 token query you might only wait 12ms for TTFT (I have my doubts, maybe they're getting their numbers from much larger prompts, again, I'm interested to see for myself) * Yes, it looks like they're using pretty standard LoRAs, the more interesting part is their (automated) training/re-training infrastructure but I doubt that's something that will be shared. The actual training pipeline (feedback collection, refinement, automated deployment) is where the real meat and potatoes of being able to deploy AI for prod/at scale lies. Still, what they shared about their tuning procedures is still pretty interesting, as well as seeing which models they're comparing against. As this article doesn't claim to be a technical report or a paper, while citations would be nice, I can also understand why they were elided. OpenAI has done the same (and sometimes gotten heat for it, like w/ Matroyshka embeddings). For all we know, maybe the original author had references, or maybe since PEFT isn't new to those in the field, that describing it is just being done as a service to the reader - at the end of the day, it's up to the reader to make their own judgements on what's new or not, or a huge development or not. From my reading of the article, your conclusion, which funnily enough is now the new top-rated comment on this thread isn't actually much more accurate the the one old one you're criticizing. reply gigglesupstairs 16 hours agoparentprevWas there anything about searching through our own photos using prompts? I thought this could be pretty amazing and still a natural way to find very specific photos in one’s own photo gallery. reply mazzystar 13 hours agorootparentRun OpenAI's CLIP model on iOS to search photos. https://github.com/mazzzystar/Queryable reply gigglesupstairs 9 hours agorootparentYes, exactly this. I have had this for a while and works wonderfully well in most cases but it’s wonky and not seamless. I wanted a more integrated approach with Photos app which only Apple can bring to the table. reply avereveard 15 hours agorootparentprevWhich is in turn just multimodal embedding Besides I could do \"named person on a beach in August\" and get the correct thing in photos on Android photos, so I don't get it. It's amazing for apple users if they didn't have it before. But from a tech stand point people could have had it for a while. reply azinman2 15 hours agorootparentPhotos has had this for a while with structured natural language queries, and this kind of prompt was part of the WWDC video. reply theshrike79 13 hours agorootparentprevThe difference is that Apple has been doing this on-device for maybe 4-5 years already with the Neural Engine. Every iOS version has brought more stuff you can search for. The current addition is \"just\" about adding a natural language interface on top of data they already have about your photos (on device, not in the cloud). My iPhone 14 can, for example, detect the breed of my dog correctly from the pictures and it can search for a specific pet by name. Again on-device, not by sending my stuff to Google's cloud to be analysed. reply fauigerzigerk 10 hours agorootparentThey have been trying and failing to do a tiny little bit of this. It's so broken and useless that I've been uploading all my iCloud photos to Google as well, for search and sharing. reply theshrike79 10 hours agorootparentIf you like Google using your personal photos for machine learning, that's your option. Now they have your every photo, geotagged and timestamped so they can see where you have been and at what times. Then they of course anonymise that information into an \"advertiser id\" they tag on to you and a sufficient quantity of other people so they can claim they're not directly targeting anyone. I prefer Apple's privacy focused option myself. reply fauigerzigerk 5 hours agorootparent>If you like Google using your personal photos for machine learning, that's your option. It's a trade-off between getting the features I need and the price I have to pay. All else being equal I do prefer privacy as well. Unfortunately, all else is not equal. >I prefer Apple's privacy focused option myself. It's only an option if it works. reply steve1977 6 hours agoparentprevYou know what company you are talking about here? reply Spooky23 4 hours agoparentprevThose people aren’t looking at Apple. They seem to have a good model for adding value to their products without the hold my beer, conquer the world bullshit that you get from OpenAI, et al. reply rvaish 14 hours agoparentprevreminds me of Easel on iMessage: https://easelapps.ai/ reply kfrzcode 15 hours agoparentprev\"AI for the rest of us.\" reply wkat4242 15 hours agorootparentExcept Apple isn't really for the rest of us. Outside of America and a handful wealthy western countries it's for the top 5-20% earners only. reply jahewson 13 hours agorootparentApproximately 33% of all smartphones in the world are iPhones. reply rvnx 10 hours agorootparent60% in the US reply whynotminot 5 hours agorootparentprevWho do you think this presentation is geared toward? reply throwaway2037 14 hours agorootparentprevJapan and Taiwan are both more than 50% iOS. Ref: https://worldpopulationreview.com/country-rankings/iphone-ma... reply theshrike79 13 hours agorootparentprevIn the EU the market share is 30% reply d1sxeyes 12 hours agorootparentYes but not evenly distributed, BeNeLux, Germany, Austria, and Nordic countries have a lot of iPhone users, while moving further east (or south) you see lower market share. Maybe it’s “two handfuls” of wealthy western countries rather than just one, but I think OPs point holds true. reply theshrike79 8 hours agorootparenthttps://worldpopulationreview.com/country-rankings/iphone-ma... Poland, Greece, Hungary and Bosnia-Herzegovina are the only ones under 20% (and maybe a few others). OTOH Britain is over 50% as is Sweden. Finland, the land of Nokia is over 35%. reply XajniN 6 hours agorootparentprevOne average American user is probably worth 5-10 average European users. reply theshrike79 2 hours agorootparent(I've dabbled in mobile games) Yes. Americans are THE most valuable customer base, y'all use insane amounts of money on mobile crap. reply kolinko 10 hours agorootparentprevIn Poland it’s 33% reply d1sxeyes 7 hours agorootparentPoland seems to be 14%: https://gs.statcounter.com/os-market-share/mobile/poland reply elbear 10 hours agorootparentprevIn Romania it's 24.7% reply d1sxeyes 7 hours agorootparentHuh interesting, I missed that. You’re right (actually I see even 25.5%). reply chuckjchen 12 hours agorootparentprevThis sounds like every newcomers to the stage except for big players like Apple. reply w10-1 50 minutes agoprevI think we as tech people lost the forest for the trees. Apple (unwisely I think) is allowing UI's to just generate responses. The wow-neat! experience will wear off quickly. Then even as a miss rate of 0.1%, there will be thousands - millions - of cringe-worthy examples that sully the Apple brand for quality. It will be impossible to create quality filter good enough, and there will be no way to back these features out of the OS. For targeted use-cases (like coding and editing), this will be useful. But these features may be what finally makes contempt for Apple go mainstream, and that would be a shame. Internally at Apple, they likely discussed how much to limit the rollout and control usage. I think they decided to bake it into API's more to maintain developer mindshare than to keep users happy. The one feature that could flip that script is interacting with Siri/AI in order to get things done. The frustration with knowing what you want but not how or whether it can be done drives a lot of tech angst. If this only meant ordinary people could use their existing phones to their full extent, it would be a huge win. reply cube2222 20 hours agoprevHalfway down the article contains some great charts with comparisons to other relevant models, like Mistral-7B for the on-device models, and both gpt-3.5 and 4 for the server-side models. They include data about the ratio of which outputs human graders preferred (for server side it’s better than 3.5, worse than 4). BUT, the interesting chart to me is „Human Evaluation of Output Harmfulness” which is much, much ”better„ than the other models. Both on-device and server-side. I wonder if that’s part of wanting to have gpt as the „level 3”. Making their own models much more cautious, and using OpenAI’s models in a way that makes it clear „it was ChatGPT that said this, not us”. Instruction following accuracy seems to be really good as well. reply crooked-v 19 hours agoparentI want to know what they consider \"harmful\". Is it going to refuse to operate for sex workers, murder mystery writers, or people who use knives? reply arthur_sav 13 hours agorootparentThey'll inject whatever ideology / dogma is \"the current thing\" into this. reply rvnx 10 hours agorootparent\"Think Different\" reply HeatrayEnjoyer 11 hours agorootparentprevnext [3 more] [flagged] mvandermeulen 11 hours agorootparentDo they have exclusive rights? reply soygem 11 hours agorootparentprevYes, what's your point? reply m463 12 hours agorootparentprevBet it depends on the country. In the USA, you won't be able to ask about sex, but you can probably ask about tank man. reply jeroenhd 12 hours agorootparentI would've thought the same until Microsoft started hiding tank man results in Bing. I'm not so sure if companies will start training different models for every oppressive regime. reply t-writescode 11 hours agorootparentOh? https://www.bing.com/images/search?q=tank%20man Looks visible, to me. Tiananmen Square even shows Tank Man on the first page, 13th and 15th entry, for me. Admittedly, I expected it more quickly on Tiananmen Square; but that might be because I, as a person, forgot that it's also a literal square with more stuff going on at it than a single moment in history. reply lelandfe 6 hours agorootparentprev2021, a classic, “we made a whoopsie” response. https://theguardian.com/technology/2021/jun/04/microsoft-bin... reply its_ethan 19 hours agorootparentprevThe caption for the image gives a little more insight into \"harmful\" and one of the things it mentions is factuality - which is interesting, but doesn't reveal a whole lot unless they were to break it out by \"type of harmful\". reply Aerbil313 6 hours agorootparentprevNone of the use cases they presented in WWDC using Apple Intelligence was creative writing. There is one, that uses ChatGPT explicitly: > And with Compose in Writing Tools, you can create and illustrate original content from scratch. https://www.apple.com/apple-intelligence/ reply hotdogscout 16 hours agorootparentprevI bet it's the usual double standards the AI one percenters cater to. No sex because apparently it's harmful yet never explained why. No homophobia/transphobia if you're Christian but if you're Muslim it's fine. reply causal 13 hours agoparentprevRefusing to answer any question would result in a perfect score for the first chart since it says nothing of specificity reply tonynator 17 hours agoparentprevSo it's not going to be better than other models, but it will be more censored. I guess that might be a selling point for their customer base? reply dghlsakjg 17 hours agorootparentiPhone share is ~59% of smartphones in the US. Their customer base is effectively all demographics. reply tonynator 16 hours agorootparentThose who dislike censorship and enjoy hacking avoid iPhones for obvious reasons. reply overstay8930 16 hours agorootparentPeople who understand cybersecurity hygiene use iPhones for obvious reasons reply Hugsun 11 hours agorootparentThe reasons are very not obvious to me. Could you elaborate? reply astrange 0 minutes agorootparentiPhone security is very good, better than, say, your desktop even though you don't carry your desktop everywhere you go. (Some Android security is also very good, depends on the hardware though.) Aerbil313 5 hours agorootparentprevPeople who understand cybersecurity who are not operating within a US-allied country use ... I don't know what to be honest. What to do in such a situation, where Apple is a US-based company obligated by law to comply with requests from three letter agencies and Android is a buggy mess which probably is backdoored by every major power? reply astrange 1 minute agorootparentYour threat model shouldn't be about three letter agencies unless you're running a terrorist group. It should be about porn spammers or something. realusername 12 hours agorootparentprevThose cybersecurity experts are using GrapheneOS and certainly not an iPhone where they can't even check if all is going well... reply jitl 5 hours agorootparentI’ve worked with a few people from NCC Group, Matasano, security staff at Airbnb and OpenAI, all carry and recommend iPhones for security footing. Depending on threat model, “lockdown mode” on iOS has a lot of what is useful in Grapheme like turning off built in connectivity services & disabling JIT and other code paths in the webview. reply realusername 4 hours agorootparentTo each their own, I certainly would not recommend an iPhone in this scenario, especially even more at a top tech company. reply binkethy 11 hours agorootparentprevIt would seem that integrating a backdoor funnel to OpenAI is a bit of a security issue to those who care about such things. Yay, we can all train corporate models for free involuntarily. I guess it's time to check out Lineage OS and Postmarket OS. It was always a matter of time. reply scarface_74 8 hours agorootparentNo one is going to train an AI on random user generated data. The data is going to be horrible and it’s going to be full of PII that’s too risky to expose. reply duxup 16 hours agorootparentprevI feel that way, have an iPhone. reply ihumanable 55 minutes agorootparentYea, same. I have literally no desire to hack and fuck around with my personal cell phone, doing so would take away time from the hacking I actually want to do. reply gfourfour 13 hours agorootparentprevHow does an iPhone contribute to censorship? reply ksec 18 hours agoprevI hope, this could mean Apple will push the baseline of ALL Macs to have higher than 8GB of Memory. While I wish we all get 16GB M4 as baseline. Apple being Apple may only give us 12GB, and charges extra $100 for the 16GB option. It will still be a lot better than 8GB though. reply talldayo 17 hours agoparentThe Steam Deck ships with 16 gigs of quad-channel LPDDR5 and it costs $400. Apple knows exaaaactly what they're doing with this sort of pricing. Can't forget about that cozy 256gb SSD either. An AI computer will need more than that, right? reply wraptile 14 hours agorootparentRAM is literally the cheapest primary component in a laptop at going rate of 1-4usd/GB. I'd say that shipping 8GB base model in 2024 is clearly manipulation by Apple, i.e. planned obsolescence or a way to moat Apple software. Anyone who doesn't see this is just being delusional. Same way Apple and Samsung ship 128GB of storage when the production price between 128gb and 1tb is like 10$ (on a 1000$ device). Samsung even got rid of micro sd slot. It's so blatant it's actually depressing. reply glial 14 hours agorootparent> RAM is literally the cheapest primary component Is that still true for Apple's integrated memory? It might be - I just don't know. reply talldayo 14 hours agorootparentFor the LPDDR4 and LPDDR5 that goes into the M1 and M2/M3 systems, yes. You might need to spend more money on memory controllers (since M1 and up is 8-channel) but the physical memory component itself is highly availible and relatively cheap. Same goes for SSD storage, nowadays. reply p_l 9 hours agorootparentprevThe memory used by Apple isn't anything magical or special - it's bog standard LPDDR5, essentially same as phone - and in a laptop it's way less limited by thermal and power constraints to add more (which is how you have the rather large possible set of options). While going for the top tier of memory sizes Apple offers does cost considerable amounts, making 16, or even 32GB standard is peanuts. reply rfoo 10 hours agorootparentprev> integrated memory Yes. The cost of bonding memory to their chip is mostly the same for 8G / 16G / 32G / practically any number. reply PaulRobinson 7 hours agorootparentprevOn the number of devices they sell, an extra $64 of cost per device (taking your higher figure and assuming an extra 8GB), across Mac, iPad and iPhone, they'd be looking at a cost of ~$12.8bn a year. If they just did it for Mac, it's still in the region of $2bn/year. Sure they could pass that onto a mostly price-insensitive audience, but they like round numbers, and it's not the size of decision you take without making sure its necessary: that your customers are going to go elsewhere in either scenario of doing it or not doing it. reply pjmlp 13 hours agorootparentprevTyping this from a Samsung with SD slot, need to chose your models wisely. reply zer0zzz 16 hours agorootparentprevIs steamdeck sold at cost? From what I know Apple has a rule that everything must be sold at 40% margins. That is prob the main reason. reply makeitdouble 16 hours agorootparent> From what I know Apple has a rule that everything must be sold at 40% margins. As for all rules, it's a rule except when it's not. On the top of my head Apple TV [0] had a 20% predicted margin presumably because they wanted to actually sell them. Otherwise 40% margin is usually calculated against the BOM, which doesn't mean 40% of actual profit when the product is sold. In that respect we have no idea of the actual margin on a macbook air for instance, it could be 10% when including their operating costs and marketing, or it could 60% if they negociated prices way below the estimated BOM for instance. It's just to say: Apple sells at 8Gb because they want to, at the end of the day nothing is stopping them to play with their margin or the product price. [0] https://www.reuters.com/article/idUSN06424767/ reply talldayo 14 hours agorootparentprevAs a consumer I really cannot be made to care why it's the case. This artificial price tiering is stupid and everyone has been calling it a scam for years. Apple clearly knows they're in the wrong, but continues because they know nobody can stop them. reply andruby 5 hours agorootparentFrom a business perspective it's not _stupid_. It sucks for us customers, but it's \"smart\" from a business point of view. Until they get serious competition, I doubt they'll change their practices. And while I hate the overpriced memory upgrades, I still prefer paying extra, rather than Apple switching to a Ad-based business model like Google (and potentially OpenAI in the future) reply talldayo 3 hours agorootparent> From a business perspective it's not _stupid_. It sucks for us customers, but it's \"smart\" from a business point of view. Well, I'm not a business. I appreciate smart consumer choices and I applaud any company that doesn't have to be forced into doing the right thing. > I still prefer paying extra, rather than Apple switching to a Ad-based business model like Google (and potentially OpenAI in the future) Oh you sweet summer child. You think Apple doesn't also have an ad-based business model on top of that? I switched to Linux after MacOS Mojave, and I do not miss any of this brouhaha one bit. It's almost rich hearing people talk about how few ads MacOS has, when it's constantly begging you to try or pay for Apple software services. Even Android isn't as ad-ridden as MacOS, the only victory Apple can claim is relative to Windows (which is a grim reflection of MacOS's eventual service-dominated fate). You should try out Linux, though. It's a culture shock, trying to get work done with no inbuilt advertisement whatsoever. I could never go back to Mac or Windows and be this productive. reply pjmlp 13 hours agorootparentprevYes they can, buy something else. reply talldayo 3 hours agorootparentI've been doing that for six fucking years and not a single thing has changed. The base memory and storage has not changed in that time. During that same amount of time: - Macs transitioned to Apple Silicon, got rid of dGPU memory - Baseline Macbook Air models increased in price by $100 - AI became a realistic and usable technology - Gaming is slightly feasible with GPTK Of course we shouldn't be starting at 8 gigs of memory. This is highway robbery and the only thing you can say in defense is \"buy something else then\" reply creshal 13 hours agorootparentprev40% margin on parts that cost tens of dollars isn't going to have a huge impact on the sticker price of devices costing hundreds to thousands. reply brandall10 5 hours agorootparentprevIt's been speculated that base config macbooks essentially act as loss leaders for higher end configs, so overall, probably sales across the line net somewhere around that. The cost of the upgrades themselves can get to multiple times the actual market cost. reply breuleux 24 minutes agorootparentI feel like this is very obviously what they are doing: they have a small margin on the entry config where people are a lot more price-aware, and jack up the upgrade costs to get a fat margin on configs bought by orgs and power users who generally care less about how much it costs. Frankly, I'd do the same thing. reply torginus 11 hours agoparentprevI remember hearing that Apple's researching running AI models straight from flash storage (which would make immense amount of sense imo). You could create special, high read bandwidth flash chips (which would probably involve connecting a fast transciever in parallel to the 3D flash stack). If you could do that, you could easily get hundreds of GB/s read speed out of simple TLC flash. Obviously this is the future, but I think it's a promising one. reply dgellow 5 hours agoparentprevThe have insane margin on ram and storage, it would be really surprising to see them move away from their current strategy reply vishnugupta 11 hours agoparentprevDoes it matter what the baseline memory is as long as they have 16GB M4 as an option? reply manmal 11 hours agorootparentSome companies give their employees only base models. reply joshstrange 4 hours agorootparentSome companies are stupid, news at 6. It's not Apple's (or any computer manufacturer's) responsibility to put out products that can solve every problem with the base model. I'll never understand why companies pay high salaries then give employees sub-optimal computers to do their job. reply keyle 17 hours agoparentprevIt probably will change. Note that, so far, a 16GB apple device has much better usability than the equivalent on windows. This may sound biased, but the memory compression and foreground/background actions by macOS tight integration with the hardware is really good. I've never felt like I couldn't do things on smaller hardware, except (larges) LLMs. Also when I compare with my co-workers the memory pressure is a lot less running the same software on macOS than Windows. This might have to be due to the UI framework at play. But that said, I totally agree that Apple is doing daylight robbery with their additional RAM pricing, and the minimum on offer is laughable. reply Aeolun 10 hours agorootparentAny apple device has much better usability than a windows machine, regardless of RAM. reply wwtrv 11 hours agorootparentprev> This may sound biased, It certainly does, close to irrational even. IIRC memory compression is enabled by default on Windows as well. reply dialup_sounds 8 hours agorootparentBiased and irrational are both things HN readers say to avoid using the word \"subjective\". reply snemvalts 15 hours agorootparentprevThe swapping is indeed faster as the SSD is on the SoC and so fast to access. To the point that an 4 year old 8gb M1 Air is enough for simpler development work, at least for me. reply pests 8 hours agorootparentI would think any 4 year old 8gh laptop would be enough for simpler development work. reply andreasmetsala 9 hours agorootparentprevSSD on chip might be a thing one day but I’m pretty sure only the RAM is on the same chip. reply ndgold 19 hours agoprevAbsolutely awesome amount of content in these two pages. This was not expected. It is appreciated. I can’t wait to use the server model on a Mac to spin up my own cloud optimized for the Apple stack. reply solarkraft 17 hours agoparentWhat makes you think you'll get that model? Edit: I see they're committing to publishing the OS images running on their inference servers (https://security.apple.com/blog/private-cloud-compute/). Would be cool if that allowed people to run their own. reply msephton 17 hours agorootparentApparently they will in a VM but it seems perhaps only security researchers? reply whazor 6 hours agorootparentprevIt would be much cooler if enterprises can swap to their custom models in their own clouds. reply rekoil 9 hours agorootparentprev> Would be cool if that allowed people to run their own. Oh my god that would be absolutely amazing! reply titaniumtown 17 hours agoparentprevDid it mentioned being able to spin up the server model locally? I must've missed that part in the article. reply vzaliva 19 hours agoprevI love that they use machinelearning.apple.com not ai.apple.com reply tmpz22 17 hours agoparentFor the majority of the keynote they explicitly avoided the word AI instead substituting the word Intelligence, then Apple Intelligence, and then towards the end they said AI and ChatGPT once or twice. I think they saw the response to all the AI shoveling and Microsoft Recall and executed a fantastic strategy to reposition themselves in industry discussions. I still have tons of reservations about privacy and what this will all look like in a few years, but you really have to take your hat off to them. WWDC has been awesome and it makes me excited to develop for their platform in a way I haven't felt in a very, very, long time. reply worstspotgain 17 hours agorootparent> executed a fantastic strategy to reposition themselves in industry discussions Just the usual marketing angle, IMO. It's not TV, it's HBO. No one is reluctant to use the word smartphone to include iPhones. I don't think anyone is going to use the Apple Intelligence moniker except in the same cases where they'd say iCloud instead of cloud services. It's also a little clunky. Maybe they could have gone with... xI? Too close to the Chinese Xi. iAI? Sounds like the Spanish \"ay ay ay.\" Not an easy one I think. The number of person-hours spent on this must have been something. reply tmpz22 16 hours agorootparentI don't think they actually expect \"Apple Intelligence\" to enter popular vernacular. I think it was more to drive home the distinction between what Apple is doing and what everybody else is doing. reply andsoitis 14 hours agorootparent> distinction between what Apple is doing and what everybody else is doing it is artificial intelligence, applied intelligently. In Apple's case: \"personalised AI system\" reply swyx 7 hours agorootparentprevcorrect. last year instead of VR they went with Spatial Intelligence reply hbn 2 hours agorootparentVision Pro isn't really designed to be a VR device first and foremost. The primary usecase is the passthrough mode whereas VR usually describes the software putting you in a different place. reply spogbiper 4 hours agorootparentprev\"spatial computing\" reply dgellow 5 hours agorootparentprevWhat excites you specifically as a developer? reply seydor 13 hours agorootparentprev> makes me excited to develop for their platform in a way I haven't felt in a very, very, long time AI will ultimately do all the 'development', and will replace all apps. The integrations are going to be a temporary measure. Only apps that will survive are the ones that control things that apple cannot control (ie. how Uber controls its fleet) reply Hugsun 11 hours agorootparentPerhaps. It will be exciting to see if/how that happens. It does seem relatively far off still. At least some years. reply andbberger 19 hours agoparentprevglad someone sane is in charge in cupertino reply okdood64 18 hours agorootparentApple Intelligence. reply bfung 15 hours agorootparentWaiting for aiPhone in a few iterationsreply xwolfi 18 hours agoparentprevYeah they probably were still working on the last buzzword reply Jayakumark 2 hours agoprevThe model is not opensource. Also now we are stuck with walled garden for models thats deeply integrated at OS or Browser level. 1. Apple Models not open - so we cannot run Android, also not on Desktop Chrome or Edge. 2. Microsoft Phi3 - Can run inside iOS ,but on Android only as an APP but not on OS level or no supported APIs. Can run on Desktop Edge not chrome. 3. Google GEmini nano - Can only run inside Android and Desktop Chrome not Edge, not on iOS as weights are not open. So we cannot get a similar answer from LLM as its different models, you cannot across ecosystem. reply dingclancy 13 hours agoprevIt’s interesting that a sub-ChatGPT 3.5 class model can do a lot of things on-device if you marry it with a good platform and feed it personal context. GPT-4o, living on the browser, is not as compelling as a product compared to what Apple Intelligence can do on the iPhone with a less capable model. reply aixpert 5 hours agoparenttheir 3 billion parameter model can't do shit, Only some basic grammar check style rewrite and maybe summarization reply pertymcpert 34 minutes agorootparentHave you tried it much? reply miven 14 hours agoprev> For on-device inference, we use low-bit palletization, a critical optimization technique that achieves the necessary memory, power, and performance requirements. Did they go over the entire text with a thesaurus? I've never seen \"palletization\" be used as a viable synonym for \"quantization\" before, and I've read quite a few papers on LLM quantization reply bagrow 14 hours agoparenthttps://apple.github.io/coremltools/docs-guides/source/palet... reply miven 13 hours agorootparentHuh, generally whenever I saw the lookup table approach in literature it was also referred to as quantization, guess they wanted to disambiguate the two methods Though I'm not sure how warranted it really is, in both cases it's still pretty much the same idea of reducing the precision, just with different implementations Edit: they even refer to it as LUT quantization on another page: https://apple.github.io/coremltools/docs-guides/source/quant... reply fudged71 13 hours agorootparentprev404 reply miven 13 hours agorootparentYeah, it just got updated, here's the new link, they added sections on block-wise quantization for both the rounding-based and LUT-based approach: https://apple.github.io/coremltools/docs-guides/source/opt-p... reply elcritch 13 hours agorootparentprevHuh, it’s PNG for AI weights. reply cgearhart 13 hours agoparentprevI also found it confusing the first time I saw it. I believe it is sometimes used because the techniques for DL are very similar (in some cases identical) to algorithms that were developed for color palette quantization (in some places shortened to \"palettization\"). [1] At this point my understanding is that this term is used to be more specific about the type of quantization being performed. https://en.wikipedia.org/wiki/Color_quantization reply ra7 20 hours agoprev> Our foundation models are trained on Apple's AXLearn framework, an open-source project we released in 2023. It builds on top of JAX and XLA, and allows us to train the models with high efficiency and scalability on various training hardware and cloud platforms, including TPUs and both cloud and on-premise GPUs. Interesting that they’re using TPUs for training, in addition to GPUs. Is it both a technical decision (JAX and XLA) and a hedge against Nvidia? reply m-s-y 19 hours agoparentThey’d be silly not to hedge. Anyone, in fact, would be silly. It to hedge. On pretty much everything. reply anvuong 17 hours agoparentprevJax was built with TPUs in mind, so it's not surprising that they use TPUs reply gokuldas011011 13 hours agoparentprev\"Use the best tool available\" reply flakiness 9 hours agorootparentThey hired people nearby. Conveniently there is a small town called Mountain View. reply anshumankmr 6 hours agoprevAs someone who has been dabbling with Prompt Engineering and now fine tuning some models (working on a use case where we may have to fine tune one of the Mistral's 7B instruct models), I want to know what kind of skillsets I need to really have so that I can join this team (or a similar team building these sort of things) reply scosman 20 hours agoprev“We utilize adapters, small neural network modules that can be plugged into various layers of the pre-trained model, to fine-tune our models for specific tasks.” This is huuuuge. I don’t see announcement of 3rd party training support yet, but I imagine/hope it’s planned. One of the hard things about local+private ML is I don’t want every app I download to need GBs of weights, and don’t want a delay when I open a new app and all the memory swap happens. As an app developer I want the best model that runs on each HW model, not one lowest common denominator model for slowest HW I support. Apple has the chance to make this smooth: great models tuned to each chip, adapters for each use case, new use cases only have a few MB of weights (for a set of current base models), and base models can get better over time (new HW and improved models). Basically app thinning for models. Even if the base models aren’t SOTA to start, the developer experience is great and they can iterate. Server side is so much easier, but look forward to local+private taking over for a lot of use cases. reply dimtion 18 hours agoparentWith huge blobs of binary model weights, dynamic linking is cool again. reply pjmlp 13 hours agorootparentDynamic linking has always been cool for writing plugins. It is kind of ironic that languages that praise so much for going back to early linking models, have to resort for much heavier OS IPC for similar capabilities. reply rfoo 9 hours agorootparentWhich languages? IIUC Go and Rust resort to OS IPC based plugin system mainly because they refused to have a stable ABI. On the other hand, at $DAYJOB we have a query engine written in C++ (which itself uses mostly static linking [1]) loading mostly static linked UDFs and ... it works. [1] Without glibc, but with libstdc++ / libgcc etc. reply skohan 2 hours agorootparentDoesn’t rust’s static linking also have to do with the strategy of aggressive minimization? Iirc for instance every concrete instantiation of a dynamic type will have its own compiled binary, so it would basically be impossible for a dynamic library to do this since it wouldn’t know how it would be used, at least not without some major limitations or performance tradeoffs reply pjmlp 6 hours agorootparentprevWell if it loads code dynamically, it is no longer static linking. Also it isn't as if there is a stable ABI for C and C++ either, unless everything is compiled with the same compiler, or using Windows like dynamic libraries, or something like COM to work around the ABI limitations. reply inickt 18 hours agorootparentprevWhich Apple has put some pretty large effort in the last few years to improve in iOS reply eightysixfour 18 hours agoparentprevThis is how Google is doing it too. reply gokuldas011011 13 hours agorootparentIndeed. Google said LoRA and apple said adapter plugging. Wonder the difference is at, Apple's dev conference is for consumers and Google's dev conference is for developers. reply scosman 10 hours agorootparentprevOh missed that! But kinda as expected: only works on 2 android phones (pixel 8 pro, S24). Pretty typical: Apple isn’t first, but also typically will scale faster with HW+platform integration. reply Deathmax 9 hours agorootparentOn Apple’s side, Apple Intelligence will only be enabled on A17 Pro and M-series chips, so only the iPhone 15 Pro and Pro Max will be supported in terms of phones. reply scosman 8 hours agorootparent2 phones, ~4 tablets, ~12 PCs. Looking at sales, looks like about 10x the phone volume of s24 (and pixel 8 doesn’t register on the chats). reply rfoo 9 hours agorootparentprev> will scale faster * Only in USA, both intentionally and not. reply lossolo 18 hours agoparentprevIt's LORA, most of the things you saw in Apple Intelligence on device presentation are basically different LORAs. reply scosman 10 hours agorootparentThe article says it’s lora a bunch of times. That’s clear. My comment above is about dev experience, memory swapping, tuning base models to each HW release, and app size. reply danielmarkbruce 18 hours agoparentprevthis is pretty stock standard lora. reply idiotsecant 17 hours agorootparentnext [4 more] [flagged] dang 17 hours agorootparent\"Don't be snarky.\" https://news.ycombinator.com/newsguidelines.html reply Sabinus 17 hours agorootparentOne day they're going to train a moderation bot on your account, and it's going to be amazing. reply bowsamic 13 hours agorootparentI’m sure you will continue to think so until he permanently restricts your account for getting downvoted reply seydor 13 hours agoparentprevLocal models are also extremely energy consuming. I don't see local AI working for long, because Large models are going to get so incomparably smarter and eventually reach general intelligence reply 196 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "At the 2024 Worldwide Developers Conference, Apple introduced Apple Intelligence, a personal intelligence system integrated into iOS 18, iPadOS 18, and macOS Sequoia, featuring generative models for tasks like text refinement and image creation.",
      "Apple emphasizes responsible AI development, focusing on user empowerment, privacy, and efficient model performance, using on-device processing and Private Cloud Compute to protect user data.",
      "The system employs the AXLearn framework for efficient training, with models optimized for speed and efficiency, and includes specialized neural network modules called adapters for task-specific performance."
    ],
    "commentSummary": [
      "Apple's announcement of On-Device and Server Foundation Models has received mixed reactions, with critics accusing them of repackaging existing AI techniques and supporters praising their refinement and popularization of established technologies.",
      "The discussion highlights Apple's strategy of refining and popularizing existing technologies, such as with \"Apple Silicon\" and \"AirPort,\" rather than focusing on groundbreaking research.",
      "Speculation suggests Apple might enter the server chip market with an AI chip, leveraging their silicon expertise, while debates continue over their high pricing, minimal RAM in base models, and tight ecosystem control."
    ],
    "points": 862,
    "commentCount": 462,
    "retryCount": 0,
    "time": 1718055731
  },
  {
    "id": 40639606,
    "title": "Apple's Private Cloud Compute Enhances AI Privacy and Security for iOS and macOS",
    "originLink": "https://security.apple.com/blog/private-cloud-compute/",
    "originBody": "Apple Intelligence is the personal intelligence system that brings powerful generative models to iPhone, iPad, and Mac. For advanced features that need to reason over complex data with larger foundation models, we created Private Cloud Compute (PCC), a groundbreaking cloud intelligence system designed specifically for private AI processing. For the first time ever, Private Cloud Compute extends the industry-leading security and privacy of Apple devices into the cloud, making sure that personal user data sent to PCC isn’t accessible to anyone other than the user — not even to Apple. Built with custom Apple silicon and a hardened operating system designed for privacy, we believe PCC is the most advanced security architecture ever deployed for cloud AI compute at scale. Apple has long championed on-device processing as the cornerstone for the security and privacy of user data. Data that exists only on user devices is by definition disaggregated and not subject to any centralized point of attack. When Apple is responsible for user data in the cloud, we protect it with state-of-the-art security in our services — and for the most sensitive data, we believe end-to-end encryption is our most powerful defense. For cloud services where end-to-end encryption is not appropriate, we strive to process user data ephemerally or under uncorrelated randomized identifiers that obscure the user’s identity. Secure and private AI processing in the cloud poses a formidable new challenge. Powerful AI hardware in the data center can fulfill a user’s request with large, complex machine learning models — but it requires unencrypted access to the user's request and accompanying personal data. That precludes the use of end-to-end encryption, so cloud AI applications have to date employed traditional approaches to cloud security. Such approaches present a few key challenges: Cloud AI security and privacy guarantees are difficult to verify and enforce. If a cloud AI service states that it does not log certain user data, there is generally no way for security researchers to verify this promise — and often no way for the service provider to durably enforce it. For example, a new version of the AI service may introduce additional routine logging that inadvertently logs sensitive user data without any way for a researcher to detect this. Similarly, a perimeter load balancer that terminates TLS may end up logging thousands of user requests wholesale during a troubleshooting session. It’s difficult to provide runtime transparency for AI in the cloud. Cloud AI services are opaque: providers do not typically specify details of the software stack they are using to run their services, and those details are often considered proprietary. Even if a cloud AI service relied only on open source software, which is inspectable by security researchers, there is no widely deployed way for a user device (or browser) to confirm that the service it’s connecting to is running an unmodified version of the software that it purports to run, or to detect that the software running on the service has changed. It’s challenging for cloud AI environments to enforce strong limits to privileged access. Cloud AI services are complex and expensive to run at scale, and their runtime performance and other operational metrics are constantly monitored and investigated by site reliability engineers and other administrative staff at the cloud service provider. During outages and other severe incidents, these administrators can generally make use of highly privileged access to the service, such as via SSH and equivalent remote shell interfaces. Though access controls for these privileged, break-glass interfaces may be well-designed, it’s exceptionally difficult to place enforceable limits on them while they’re in active use. For example, a service administrator who is trying to back up data from a live server during an outage could inadvertently copy sensitive user data in the process. More perniciously, criminals such as ransomware operators routinely strive to compromise service administrator credentials precisely to take advantage of privileged access interfaces and make away with user data. When on-device computation with Apple devices such as iPhone and Mac is possible, the security and privacy advantages are clear: users control their own devices, researchers can inspect both hardware and software, runtime transparency is cryptographically assured through Secure Boot, and Apple retains no privileged access (as a concrete example, the Data Protection file encryption system cryptographically prevents Apple from disabling or guessing the passcode of a given iPhone). However, to process more sophisticated requests, Apple Intelligence needs to be able to enlist help from larger, more complex models in the cloud. For these cloud requests to live up to the security and privacy guarantees that our users expect from our devices, the traditional cloud service security model isn't a viable starting point. Instead, we need to bring our industry-leading device security model, for the first time ever, to the cloud. The rest of this post is an initial technical overview of Private Cloud Compute, to be followed by a deep dive after PCC becomes available in beta. We know researchers will have many detailed questions, and we look forward to answering more of them in our follow-up post. Designing Private Cloud Compute We set out to build Private Cloud Compute with a set of core requirements: Stateless computation on personal user data. Private Cloud Compute must use the personal user data that it receives exclusively for the purpose of fulfilling the user’s request. This data must never be available to anyone other than the user, not even to Apple staff, not even during active processing. And this data must not be retained, including via logging or for debugging, after the response is returned to the user. In other words, we want a strong form of stateless data processing where personal data leaves no trace in the PCC system. Enforceable guarantees. Security and privacy guarantees are strongest when they are entirely technically enforceable, which means it must be possible to constrain and analyze all the components that critically contribute to the guarantees of the overall Private Cloud Compute system. To use our example from earlier, it’s very difficult to reason about what a TLS-terminating load balancer may do with user data during a debugging session. Therefore, PCC must not depend on such external components for its core security and privacy guarantees. Similarly, operational requirements such as collecting server metrics and error logs must be supported with mechanisms that do not undermine privacy protections. No privileged runtime access. Private Cloud Compute must not contain privileged interfaces that would enable Apple’s site reliability staff to bypass PCC privacy guarantees, even when working to resolve an outage or other severe incident. This also means that PCC must not support a mechanism by which the privileged access envelope could be enlarged at runtime, such as by loading additional software. Non-targetability. An attacker should not be able to attempt to compromise personal data that belongs to specific, targeted Private Cloud Compute users without attempting a broad compromise of the entire PCC system. This must hold true even for exceptionally sophisticated attackers who can attempt physical attacks on PCC nodes in the supply chain or attempt to obtain malicious access to PCC data centers. In other words, a limited PCC compromise must not allow the attacker to steer requests from specific users to compromised nodes; targeting users should require a wide attack that’s likely to be detected. To understand this more intuitively, contrast it with a traditional cloud service design where every application server is provisioned with database credentials for the entire application database, so a compromise of a single application server is sufficient to access any user’s data, even if that user doesn’t have any active sessions with the compromised application server. Verifiable transparency. Security researchers need to be able to verify, with a high degree of confidence, that our privacy and security guarantees for Private Cloud Compute match our public promises. We already have an earlier requirement for our guarantees to be enforceable. Hypothetically, then, if security researchers had sufficient access to the system, they would be able to verify the guarantees. But this last requirement, verifiable transparency, goes one step further and does away with the hypothetical: security researchers must be able to verify the security and privacy guarantees of Private Cloud Compute, and they must be able to verify that the software that’s running in the PCC production environment is the same as the software they inspected when verifying the guarantees. This is an extraordinary set of requirements, and one that we believe represents a generational leap over any traditional cloud service security model. Introducing Private Cloud Compute nodes The root of trust for Private Cloud Compute is our compute node: custom-built server hardware that brings the power and security of Apple silicon to the data center, with the same hardware security technologies used in iPhone, including the Secure Enclave and Secure Boot. We paired this hardware with a new operating system: a hardened subset of the foundations of iOS and macOS tailored to support Large Language Model (LLM) inference workloads while presenting an extremely narrow attack surface. This allows us to take advantage of iOS security technologies such as Code Signing and sandboxing. On top of this foundation, we built a custom set of cloud extensions with privacy in mind. We excluded components that are traditionally critical to data center administration, such as remote shells and system introspection and observability tools. We replaced those general-purpose software components with components that are purpose-built to deterministically provide only a small, restricted set of operational metrics to SRE staff. And finally, we used Swift on Server to build a new Machine Learning stack specifically for hosting our cloud-based foundation model. Let’s take another look at our core Private Cloud Compute requirements and the features we built to achieve them. Stateless computation and enforceable guarantees With services that are end-to-end encrypted, such as iMessage, the service operator cannot access the data that transits through the system. One of the key reasons such designs can assure privacy is specifically because they prevent the service from performing computations on user data. Since Private Cloud Compute needs to be able to access the data in the user’s request to allow a large foundation model to fulfill it, complete end-to-end encryption is not an option. Instead, the PCC compute node must have technical enforcement for the privacy of user data during processing, and must be incapable of retaining user data after its duty cycle is complete. We designed Private Cloud Compute to make several guarantees about the way it handles user data: A user’s device sends data to PCC for the sole, exclusive purpose of fulfilling the user’s inference request. PCC uses that data only to perform the operations requested by the user. User data stays on the PCC nodes that are processing the request only until the response is returned. PCC deletes the user’s data after fulfilling the request, and no user data is retained in any form after the response is returned. User data is never available to Apple — even to staff with administrative access to the production service or hardware. When Apple Intelligence needs to draw on Private Cloud Compute, it constructs a request — consisting of the prompt, plus the desired model and inferencing parameters — that will serve as input to the cloud model. The PCC client on the user’s device then encrypts this request directly to the public keys of the PCC nodes that it has first confirmed are valid and cryptographically certified. This provides end-to-end encryption from the user’s device to the validated PCC nodes, ensuring the request cannot be accessed in transit by anything outside those highly protected PCC nodes. Supporting data center services, such as load balancers and privacy gateways, run outside of this trust boundary and do not have the keys required to decrypt the user’s request, thus contributing to our enforceable guarantees. Next, we must protect the integrity of the PCC node and prevent any tampering with the keys used by PCC to decrypt user requests. The system uses Secure Boot and Code Signing for an enforceable guarantee that only authorized and cryptographically measured code is executable on the node. All code that can run on the node must be part of a trust cache that has been signed by Apple, approved for that specific PCC node, and loaded by the Secure Enclave such that it cannot be changed or amended at runtime. This also ensures that JIT mappings cannot be created, preventing compilation or injection of new code at runtime. Additionally, all code and model assets use the same integrity protection that powers the Signed System Volume. Finally, the Secure Enclave provides an enforceable guarantee that the keys that are used to decrypt requests cannot be duplicated or extracted. The Private Cloud Compute software stack is designed to ensure that user data is not leaked outside the trust boundary or retained once a request is complete, even in the presence of implementation errors. The Secure Enclave randomizes the data volume’s encryption keys on every reboot and does not persist these random keys, ensuring that data written to the data volume cannot be retained across reboot. In other words, there is an enforceable guarantee that the data volume is cryptographically erased every time the PCC node’s Secure Enclave Processor reboots. The inference process on the PCC node deletes data associated with a request upon completion, and the address spaces that are used to handle user data are periodically recycled to limit the impact of any data that may have been unexpectedly retained in memory. Finally, for our enforceable guarantees to be meaningful, we also need to protect against exploitation that could bypass these guarantees. Technologies such as Pointer Authentication Codes and sandboxing act to resist such exploitation and limit an attacker’s horizontal movement within the PCC node. The inference control and dispatch layers are written in Swift, ensuring memory safety, and use separate address spaces to isolate initial processing of requests. This combination of memory safety and the principle of least privilege removes entire classes of attacks on the inference stack itself and limits the level of control and capability that a successful attack can obtain. No privileged runtime access We designed Private Cloud Compute to ensure that privileged access doesn’t allow anyone to bypass our stateless computation guarantees. First, we intentionally did not include remote shell or interactive debugging mechanisms on the PCC node. Our Code Signing machinery prevents such mechanisms from loading additional code, but this sort of open-ended access would provide a broad attack surface to subvert the system’s security or privacy. Beyond simply not including a shell, remote or otherwise, PCC nodes cannot enable Developer Mode and do not include the tools needed by debugging workflows. Next, we built the system’s observability and management tooling with privacy safeguards that are designed to prevent user data from being exposed. For example, the system doesn’t even include a general-purpose logging mechanism. Instead, only pre-specified, structured, and audited logs and metrics can leave the node, and multiple independent layers of review help prevent user data from accidentally being exposed through these mechanisms. With traditional cloud AI services, such mechanisms might allow someone with privileged access to observe or collect user data. Together, these techniques provide enforceable guarantees that only specifically designated code has access to user data and that user data cannot leak outside the PCC node during system administration. Non-targetability Our threat model for Private Cloud Compute includes an attacker with physical access to a compute node and a high level of sophistication — that is, an attacker who has the resources and expertise to subvert some of the hardware security properties of the system and potentially extract data that is being actively processed by a compute node. We defend against this type of attack in two ways: We supplement the built-in protections of Apple silicon with a hardened supply chain for PCC hardware, so that performing a hardware attack at scale would be both prohibitively expensive and likely to be discovered. We limit the impact of small-scale attacks by ensuring that they cannot be used to target the data of a specific user. Private Cloud Compute hardware security starts at manufacturing, where we inventory and perform high-resolution imaging of the components of the PCC node before each server is sealed and its tamper switch is activated. When they arrive in the data center, we perform extensive revalidation before the servers are allowed to be provisioned for PCC. The process involves multiple Apple teams that cross-check data from independent sources, and the process is further monitored by a third-party observer not affiliated with Apple. At the end, a certificate is issued for keys rooted in the Secure Enclave UID for each PCC node. The user’s device will not send data to any PCC nodes if it cannot validate their certificates. These processes broadly protect hardware from compromise. To guard against smaller, more sophisticated attacks that might otherwise avoid detection, Private Cloud Compute uses an approach we call target diffusion to ensure requests cannot be routed to specific nodes based on the user or their content. Target diffusion starts with the request metadata, which leaves out any personally identifiable information about the source device or user, and includes only limited contextual data about the request that’s required to enable routing to the appropriate model. This metadata is the only part of the user’s request that is available to load balancers and other data center components running outside of the PCC trust boundary. The metadata also includes a single-use credential, based on RSA Blind Signatures, to authorize valid requests without tying them to a specific user. Additionally, PCC requests go through an OHTTP relay — operated by a third party — which hides the device’s source IP address before the request ever reaches the PCC infrastructure. This prevents an attacker from using an IP address to identify requests or associate them with an individual. It also means that an attacker would have to compromise both the third-party relay and our load balancer to steer traffic based on the source IP address. User devices encrypt requests only for a subset of PCC nodes, rather than the PCC service as a whole. When asked by a user device, the load balancer returns a subset of PCC nodes that are most likely to be ready to process the user’s inference request — however, as the load balancer has no identifying information about the user or device for which it’s choosing nodes, it cannot bias the set for targeted users. By limiting the PCC nodes that can decrypt each request in this way, we ensure that if a single node were ever to be compromised, it would not be able to decrypt more than a small portion of incoming requests. Finally, the selection of PCC nodes by the load balancer is statistically auditable to protect against a highly sophisticated attack where the attacker compromises a PCC node as well as obtains complete control of the PCC load balancer. Verifiable transparency We consider allowing security researchers to verify the end-to-end security and privacy guarantees of Private Cloud Compute to be a critical requirement for ongoing public trust in the system. Traditional cloud services do not make their full production software images available to researchers — and even if they did, there’s no general mechanism to allow researchers to verify that those software images match what’s actually running in the production environment. (Some specialized mechanisms exist, such as Intel SGX and AWS Nitro attestation.) When we launch Private Cloud Compute, we’ll take the extraordinary step of making software images of every production build of PCC publicly available for security research. This promise, too, is an enforceable guarantee: user devices will be willing to send data only to PCC nodes that can cryptographically attest to running publicly listed software. We want to ensure that security and privacy researchers can inspect Private Cloud Compute software, verify its functionality, and help identify issues — just like they can with Apple devices. Our commitment to verifiable transparency includes: Publishing the measurements of all code running on PCC in an append-only and cryptographically tamper-proof transparency log. Making the log and associated binary software images publicly available for inspection and validation by privacy and security experts. Publishing and maintaining an official set of tools for researchers analyzing PCC node software. Rewarding important research findings through the Apple Security Bounty program. Every production Private Cloud Compute software image will be published for independent binary inspection — including the OS, applications, and all relevant executables, which researchers can verify against the measurements in the transparency log. Software will be published within 90 days of inclusion in the log, or after relevant software updates are available, whichever is sooner. Once a release has been signed into the log, it cannot be removed without detection, much like the log-backed map data structure used by the Key Transparency mechanism for iMessage Contact Key Verification. As we mentioned, user devices will ensure that they’re communicating only with PCC nodes running authorized and verifiable software images. Specifically, the user’s device will wrap its request payload key only to the public keys of those PCC nodes whose attested measurements match a software release in the public transparency log. And the same strict Code Signing technologies that prevent loading unauthorized software also ensure that all code on the PCC node is included in the attestation. Making Private Cloud Compute software logged and inspectable in this way is a strong demonstration of our commitment to enable independent research on the platform. But we want to ensure researchers can rapidly get up to speed, verify our PCC privacy claims, and look for issues, so we’re going further with three specific steps: We’ll release a PCC Virtual Research Environment: a set of tools and images that simulate a PCC node on a Mac with Apple silicon, and that can boot a version of PCC software minimally modified for successful virtualization. While we’re publishing the binary images of every production PCC build, to further aid research we will periodically also publish a subset of the security-critical PCC source code. In a first for any Apple platform, PCC images will include the sepOS firmware and the iBoot bootloader in plaintext, making it easier than ever for researchers to study these critical components. The Apple Security Bounty will reward research findings in the entire Private Cloud Compute software stack — with especially significant payouts for any issues that undermine our privacy claims. More to come Private Cloud Compute continues Apple’s profound commitment to user privacy. With sophisticated technologies to satisfy our requirements of stateless computation, enforceable guarantees, no privileged access, non-targetability, and verifiable transparency, we believe Private Cloud Compute is nothing short of the world-leading security architecture for cloud AI compute at scale. We look forward to sharing many more technical details about PCC, including the implementation and behavior behind each of our core requirements. And we’re especially excited to soon invite security researchers for a first look at the Private Cloud Compute software and our PCC Virtual Research Environment.",
    "commentLink": "https://news.ycombinator.com/item?id=40639606",
    "commentBody": "Private Cloud Compute: A new frontier for AI privacy in the cloud (security.apple.com)567 points by serhack_ 21 hours agohidepastfavorite306 comments hexage1814 13 hours agoThe thing with cloud and with anything related to it, anything that connects to the internet somehow... is that, unless it's open source and the servers decentralized, you are always trusting SOMEONE. Sure, Apple might make their best to ensure nobody – but them – have access to your data... but Apple controls all the end points. It controls the updates your iPhone receives, it controls the servers where this happens. Like, they are so many opportunities for them to find what you are doing. It reminds me of this article \"Web-based cryptography is always snake oil\" https://www.devever.net/~hl/webcrypto And to be fair, this doesn't apply only to this case. Even the data you have stored locally, Apple could access it if they wanted, they sure have power to do it if they so wish or were ordered by the government. They might have done it already and just didn't told anyone for obvious reasons. So, I would argue the best you could say is that it's private in the sense that only Apples knows/can know what you are doing rather than a larger number of entities . Which, you could argue it's a win when the alternatives will leak your data to many more parts... But still far away from being this unbreakable cryptography that it's portrayed it to be. reply noahtallen 12 hours agoparentI don’t think that’s completely fair. It basically puts Apple in the same bucket as Google or OpenAI. Google obviously tracks everything you do for ads, recommendations, AI, you name it. They don’t even hide it, it’s a core part of their business model. Apple, on the other hand, has made a pretty serious effort to ensure that no employee can access your data on these AI systems. That’s hugely different! They’re going as far as to severely restrict logging and observability and even building and designing their own chips and operating systems. And ensuring that clients will refuse to talk to non-audited systems. Yes, we can’t take Apple’s word for it. But I think the third party audits are a huge part of how we trust, and also verify, that this system will be private. I don’t think it’s far to claim that “Apple knows what you’re doing.” That implies that some one, at some level at Apple can at some point access the data sent from your device to this private cloud. That does not seem to be true. I think another facet of trust here is that a rather big part of Apple’s business model is privacy. They’ve been very successful financially by creating products that generate money in other ways, and it’s very much not necessary or even a sound business idea for them to do something else. While I think it’s fair to be skeptical about the claims without 3rd party verification, I don’t think it’s fair to say that Apple’s approach isn’t better for your data and privacy than openAI or Google. (Which I think is the broad implication — openAI tracks prompts for its own model training, not to resell, so it’s also “only openAI knows what your doing.”) reply chem83 12 hours agorootparentWhat makes you think that internal access control at Apple is any better than Google's, Microsoft's or OpenAI's? Google employees have long reported that you can't access user data with standard credentials, for example. Also, what makes you think that Apple's investments on chip design and OS is superior to Google's? Google is known for OpenTitan and other in-house silicon projects. It's also been working in secure enclave tech (https://news.ycombinator.com/item?id=20265625), which has been open-source for years. You're making unverifiable claims about Apple's actual implementation of the technical systems and policies it is marketing. Apple also sells ads (App Store, but other surfaces as well) and you don't have evidence that your AI data is not being used to target you. Conversely, not all user data is used by Google for ad targeting. reply Spooky23 7 hours agorootparentIt’s not about technology. It’s about their business. Apple generally engineers their business so that there isn’t an incentive to violate those access controls or principles. Thats not where the money is for them. Behavior is always shaped by rewards and punishments. Positive reinforcement is always stronger. reply whynotminot 6 hours agorootparentOne hundred percent this. All these conversations always end up boiling down to someone thinking they’re being clever for pointing out you have to trust a company at the end of the day when it comes to security and privacy. Yes. Valid. So if you have to trust someone, doesn’t it make sense for it to be someone who has built protecting privacy into their core value proposition, versus a company that has baked violating your privacy into their value prop? reply talldayo 2 hours agorootparentIt's not about being clever, it's about being perceptive. Apple's cloud commitment has a history of being sketchy, whether it's their government alliance in China, the FIVE-EYES/PRISM membership in America, or their obsession with creating \"private\" experiences that rely on the benefit of the doubt. Apple doesn't care about you, the individual. Your value as a singular customer is worthless. They do care about the whole; a whole that governments can threaten to exclude them from if they don't cooperate with domestic surveillance demands. How far off do you really think American iCloud is from China? If Apple is willing to backdoor one server, what's stopping them from backdooring them all? If they're willing to lie about notification security, what's stopping them from lying about server integrity too? And worst off, Apple markets security. That's it; you can't go verify their veracity outside the dinky little whitepapers they publish. You can't know for sure if they have privacy violation baked-in to their system because you can't actually verify anything. You simply have to guess, and the best guess you can make gets based off whatever Apple markets as \"true\" to you. In reality, we can do better with security and should probably expect more from one of the largest consumer technology brands in the world. Simply assuming that they aren't violating user privacy is an absurd thing to gamble your security on. reply TremendousJudge 4 hours agorootparentprevThat's a false dichotomy. You may have to trust someone but that someone could be something else than an opaque for-profit company. reply whynotminot 4 hours agorootparentGive me some examples of benevolent non profits that provide anywhere near the level of consumer services as a company like Apple. reply talldayo 3 hours agorootparentI'll do better, here's a benevolent nonprofit that goes beyond what Apple provides to ensure top-notch consumer service: https://grapheneos.org/ reply Teever 2 hours agorootparentprevThey're not trying to be clever, they're trying to point out the very important philisophy of maximizing self reliance that so many people like you eschew. How do you distinguish between a company who 'has built protecting privacy into their core value proposition' and one who just says they've done so? What are you going to do if a major privacy scandal comes out with Apple at the center? If you wouldn't jump ship from Apple after a major privacy scandal then why does your input on this matter at all? Some people feel that is inevitable so it's best to just rip that bandaid off now. reply whynotminot 2 hours agorootparentI'm taking aim at the Google bros who try to raise these arguments to muddy the waters into a sort of false equivalence between Apple and Google. If you're already using a dumb phone and eschewing modern software services, then I'm not really talking to you. Roll on brother/sister, you are living your ideals. > How do you distinguish between a company who 'has built protecting privacy into their core value proposition' and one who just says they've done so? The business incentives. Apple's brand and market valuation to some extent depends on being the secure and privacy oriented company you and your family can trust. While Google's valuation and profit depends almost entirely on exploiting as much of your personal data as they possibly can get away with. The business models speaks for themselves. Does this guarantee privacy and security? Does Apple have a perfect track record here? No of course not, but again if these are my two smartphone choices it seems fairly clear to me. reply robmccoll 4 hours agorootparentprevThat's becoming less the case. As Apple's advertising and services revenue grows and hardware sales slow, they have increasing incentive to mine your data the same as any company does. They already use quite a bit data on the location and content personalization front. I would argue that Apple perhaps cares about protecting your data more from malicious third parties (again like any company should - it's never good for FAANG when data leaks or is abused), but they are better at it (and definitely better at marketing it). reply cdata 5 hours agorootparentprevThat's not even getting to the fact that Apple is also running a display ads business: https://searchads.apple.com/ reply theshrike79 10 hours agorootparentprev> What makes you think that internal access control at Apple is any better There are multiple verified stories on the lengths Apple goes internally to keep things secret. I saw a talk years ago about (I think) booting up some bits of the iCloud infrastructure, which needed two different USB keys with different keys to boot up. Then both keys were destroyed so that nobody knows the encryption keys and can't decrypt the contents. reply padolsey 9 hours agorootparentWhat's funny is that, in all these orgs, it ends up being the low-tech vulns that compromise you in the end. Physical access, social engineering, etc. However, I'm really impressed by the technical lengths Apples goes to though. The key-burning thing reminds me of ICANN' Root KSK Ceremonies. reply p_l 9 hours agorootparentprevThe stories about Apple keeping things secret usually go about protecting their business secrets from normal people, up to doing probably illegal actions. Using deniable, one-time keys etc. are... not that unusual. In fact I'd say I'm more worried about the use of random USB keys there instead of proper KMS system. (There are similar stories with how doing a cold start can be difficult when you end up with a loop in your access controls, from Google, where a fortunately simulated cold-start showed that they couldn't access necessary KMS physically to bootstrap the system... because access controls depended, after many layers, on the system to be cold-started). reply milkshakes 8 hours agorootparentthey used smartcards, not usb keys reply p_l 8 hours agorootparentWhich probably were just key transport devices from offline secured KMSes reply treprinum 5 hours agorootparentprevDestroyed? Where? In all places where they were stored? Or just in some of them? How can you tell? You still need to trust them they didn't copy them somewhere. reply theshrike79 2 hours agorootparentIt's impossible to use any technology if you don't trust anyone. Any piece of technology MAY have a backdoor or secondary function you don't know of and can't find out without breaking said device. reply 1vuio0pswjnm7 8 hours agorootparentprev\"I think another facet of trust here is that a rather big part of Apple's business model is privacy. They've been very successful financially by creating products that generate money in other ways, and it's very much not necessary or even a sound business idea for them to do something else.\" If a third party wants that data, whether the third party is an online criminal, government law enforcement or a \"business partner\", this idea that Apple's \"business model\" will somehow negate the downsides of \"cloud computing\", online advertising and internet privacy is futile. Moreover, it is a myth. Apple is spending more and more on ad services, we can see this in its SEC filings. Before he died, Steve Jobs was named on an Apple patent application for showing ads during boot. The company uses \"privacy\" as a marketing tactic. There is no evidence of an ideological or actual effort to avoid the so-called \"tech\" company \"business model\". Apple follows what these companies do. It considers them competitors. Apple collects a motherload of user data and metadata. A company that was serious about privacy would not do this. It's a cop out, not a trade off. To truly avoid the risks of cloud computing, online advertising and associated privacy issues, choosing Apple instead of Google is a half-baked effort. Anyone who was serious about it would choose neither. Of course, do what is necessary, trust whomever; no one is faulting anyone for making practical choices, but let's not pretend choosing Apple and trusting it solves these problems introduced by so-called \"tech\" company competitors. Apple pursues online advertising, cloud computing and data collection. All at the expense of privacy. With billions in cash on hand, it is one of the wealthiest companies on Earth, does it really need to do that. In the good old days, we could call Apple a hardware company. The boundaries were clear. Those days are long gone. Connect an Apple computer to a network and watch what goes over the wire wth zero user input, destined for servers controlled by the mothership. There is nothing \"private\" about that design. reply troyvit 3 hours agorootparent> Of course, do what is necessary, trust whomever; no one is faulting anyone for making practical choices, but let's not pretend choosing Apple and trusting it solves these problems introduced by so-called \"tech\" company competitors. Apple pursues online advertising, cloud computing and data collection. All at the expense of privacy. With billions in cash on hand, it is one of the wealthiest companies on Earth, does it really need to do that. Yeah. I feel like the conversation needs some guard rails like, \"Within the realm of big tech, which has discovered that one of its most profitable models is to make you the product, Apple is really quite privacy friendly!\" reply devjab 12 hours agorootparentprevI think it’s pretty fair. This example isn’t about Apple but about Microsoft, but we’ve had a decade long period where Microsoft has easily been the best IT-business partner for enterprise organisations. I’ve never been much of a fan of Microsoft personally, but it’s hard to deny just how good they are at building relationships with enterprise. I can’t think of any other tech company that knows enterprise the way Microsoft does, but I think you get the point… anyway they too are beginning to “snoop” around. Every teams meeting we have is now transcribed by AI, and while it’s something we want, it’s also a lot of data in the hands of a company where we don’t fully know what happens with it. Maybe they keep it safe and only really share it with the NSA or whichever American sneaky agency listens in on our traffic. Which isn’t particularly tin-foil-hat. We’ve semi-recently had a spy scandal where it somewhat unrelated (this wasn’t the scandal) was revealed that our own government basically lets the US snoop on every internet exit node our country has. It is what it is when you’re basically a form of vassal state to the Us. Anyway, with the increased AI monitoring tools build directly into Microsoft products, we’re now handing over more data than ever. To get the point, we’re currently seeing some debate on whether Chromebooks and Google education/workspaces should be allowed in schools. Which is a good debate. Or at least it would be if the alternative wasn’t Microsoft… Because does it really matter if it’s Google or Microsoft that invades your privacy? Apple is increasingly joining this trend. Only recently it was revealed that new Apple devices have some sort of radio build into them, even though it’s not on their tech sheets. Or in other words, Apple has now joined the trend of devices that can form their own internet by being near other Apple devices. Similar to how Samsung and most car manufacturers have operated for years now. And again if sort of leads to… does it really matter if it’s Google or Apple that intrudes on your privacy? To some degree it does, of course, I’d personally rather have Microsoft or Apple spy on me, but I would frankly prefer if no one spied on me. reply Sporktacular 10 hours agorootparentprev\"ensuring that clients will refuse to talk to non-audited systems.\" I'm trying to understand if this is really possible. I know they claim so but is there any info on how this would prevent Apple from executing different code to what is presented for audit? reply brookst 5 hours agorootparentThe servers provide a hash of their environment to clients, who can compare it to the published list of audited environments. So the question is: could the hash be falsified? That’s why they’re publishing the source code to firmware and bootloader, so researchers can audit the secure boot foundations. I am sure there is some way that a completely malevolent Apple could design a weakness into this system so they could spend a fortune on the trappings while still being able to access user information they could never use without exposing the lie and being crushed under class actions and regulatory assault. But I reject the idea that that remote possibility means the whole system offers no benefit users should consider in purchasing decisions. reply p_l 9 hours agorootparentprevUnless they pass all keys authorized by the system to third parties that ensure appropriate auditing, none. And at least after my experiences with T2 chip, I consider Apple devices to be always owned by Apple first... reply verisimi 12 hours agorootparentprevIt's completely fair, because regardless of third party audits, chips, etc, there are backdoors right along the line, that are going to provide Apple and the government with secret legal access to your data. They can simply go to a secret court, receive a secret judgment, and be authorised to secretly view your data. Does anyone really think this is not already the case? There is no transparency. A licensed third party auditor would not be able to tell you this. We have to operate with the awareness that all data online is already not private - no need to pretend/imagine that Apple's marketing is actually true, and that it is possible to buy online privacy utopia. reply theshrike79 10 hours agorootparentThe best protection against \"secret orders\" is to use mathematics. Build your system so that it can't be decrypted, don't log anything etc. Mullvad has been doing this with VPNs and law enforcement has tested it - there's nothing for them to get. Same has been proven with Apple not allowing FBI to open an iPhone, because it'd set a precedent. Future iPhone versions were made so that it's literally impossible for even Apple to open a locked iPhone. There's no reason why they wouldn't go to same lengths on their private cloud compute. It's the one thing they can do that Google can't. reply KaiserPro 7 hours agorootparent> Build your system so that it can't be decrypted Now you can't debug anything. > Mullvad has been doing this with VPNs Mullvad do not need to store any data at all. Infact any data that they store is a risk. Minimising the data stored minimises their risk. The only thing they need to store is keys. Look, if you want to ask an AI service if this photo has a dog in, thats simple and requires no state other than the photo. If you want to ask it does it have my dog in, thats a whole 'nother kettle of fish. How do you communicate the descriptors that describe your dog? how do you generate them? on device? that'll drain your battery in a very short order. > Apple not allowing FBI to open an iPhone, because it'd set a precedent Because they didn't follow process. > Future iPhone versions were made so that it's literally impossible for even Apple to open a locked iPhone. They don't need to, just hack the icloud backup. plus its not impossible, its just difficult. If you own the key authority then its less hard. reply verisimi 9 hours agorootparentprev> Same has been proven with Apple not allowing FBI to open an iPhone, because it'd set a precedent. Future iPhone versions were made so that it's literally impossible for even Apple to open a locked iPhone. Right, but I have no reason to think that this isn't a marketing ploy either, just another story. There is simply no way that Apple is as big as it is, without providing whatever data the government requires. Corporations and governments are not your friend. reply theshrike79 8 hours agorootparentApple will obey government orders to give data they have and can access. No government order short of targeting a specific backdoored update to a specific person will allow them to give data they can't access. And if you're doing something that can make a TLA force Apple to create a targeted iOS update just for you, it's not something regular people can or should worry about. Apple keeps normal people safe from mass surveillance, being protected from CIA/NSA required going Full Snowden and it's not a technological problem, you need to change the way you live. reply verisimi 8 hours agorootparentDo you not remember Edward Snowden? Eg this sort of info: > The scandal broke in early June 2013, external when the Guardian newspaper reported that the US National Security Agency (NSA) was collecting the telephone records of tens of millions of Americans. > The paper published the secret court order directing telecommunications company Verizon to hand over all its telephone data to the NSA on an \"ongoing daily basis\". https://www.bbc.com/news/world-us-canada-23123964 You seem to think that 10 years, under cover of secret orders, that this is NOT going on now. Not Apple! People's lovely trusting natures in corporations and government never ceases to amaze me. reply theshrike79 2 hours agorootparent\"telephone data\" != \"contents of every phone call\" reply verisimi 50 minutes agorootparentYou and I have no idea. reply dwaite 9 hours agorootparentprev> Does anyone really think this is not already the case? I don't think this is already the case, and I think the article is an example of safeguards being put into place (in this particular scenario) to prevent it. reply verisimi 9 hours agorootparentOn the basis of not having information, cos all this occurs out of sight, you believe this is not the case. Ok. reply brookst 5 hours agorootparentprevIf you’re presenting a conspiracy theory, you have to at least poke holes in the claims you consider false. Under the system described in the linked paper, your scenario is not possible. In fact, the whole thing looks to be designed to prevent exactly that scenario. Where do you see the weakness? How could a secret order result in undetectable data capture? reply verisimi 5 hours agorootparentNo. The information is all out there - secret courts, secret judgements, its all been put out there. I don't need to dissect any technical information, to recognise that I cannot know what I do not know. In case anyone was uncertain about whether to trust what we are told - we heard that the US government was taping millions of phone records from the Snowden revelations. So, we are told there are secrets, and we are told that there are mechanisms in place to prevent this information from being made public. You are also free to believe that the revelations are no longer relevant... I'd like to hear the reason. IMO - the reverse is the case - in that you need to show why Apple have now become trustworthy. Why would Apple not be subject to secret judgements? I know there is a lot of marketing spin about Apple's privacy - but do you really think that they would actually confront the government system, in a way that isn't some further publicity stunt? Can one confront the government and retain a license to operate, do you think? Is it not probable that the reality is that Apple have huge support from the government? Perhaps this kind of idea is hard to understand - that one can make a big noise about privacy, and how one is doing this or that to prevent access, and all the while ensuring that access is provided to authorised parties. Corporations can say this sort of thing with a straight face - its not a privacy issue to private information - its a (secret) legal issue! Sorry, but secret courts and secret judgements, along with existing disclosure that millions were being spied upon, means one needs to expect the worst. reply brookst 1 hour agorootparentFair, go ahead and expect the worse, and handwave away any attempts to mitigate. But I'm not sure where that leaves you. Is it just a nihilistic \"no security matters, it's all a show\" viewpoint? reply verisimi 43 minutes agorootparentIt is fair, I don't accept attempts to mitigate. The trust is gone, and nothing can recover it. The idea of trusting government and corporations was ridiculous in the first place as these entities are not your friends. You wouldn't expect a repeat abuser to stop abusing just because of 'time' or a marketing campaign. And yet this is the case here. People keep looking to their tormentors for solutions. Not expecting healing from those also inflicting the trauma, ie changing one's expectations, seems like a minimum effort/engagement in my view, but it's somehow inconceivable. reply TeMPOraL 12 hours agoparentprev> unless it's open source and the servers decentralized, you are always trusting SOMEONE Specifically, open-source and self-hostable. Open source doesn't save you if people can't run their own servers, because you never know whether what's in the public repo is the exact same thing that's running on the cloud servers. reply jjav 11 hours agorootparent> exact same thing that's running on the cloud servers What runs on the servers isn't actually very important. Why? Becuase even if you could somehow know with 100% certainty that what a server runs is the same code you can see, any provider is still subject to all kinds of court orders. What matters is the client code. If you can audit the client code (or better yet, build your own compatible client based on API specs) then you know for sure what the server side sees. If everything is encrypted locally with keys only you control, it doesn't matter what runs on the server. reply flakeoil 5 hours agorootparentBut in this use case of AI in the cloud I suppose it's not possible to send encrypted data which only you have the keys to as that makes the data useless and thus no AI processing in the cloud can be made. So the whole point of AI in the cloud vs. AI on device goes away. reply dwaite 9 hours agorootparentprevYou can by having an attestation of the signed software components up from the secure boot process, and having the client device validate said attestation corresponds to the known public version of each component, and randomize client connections across infrastructure. Other than obvious \"open source software isn't perfectly secure\" attack scenarios, this would require a non-targeted hardware attack, where the entire infrastructure would need to misinterpret the software or misrepresent the chain of custody. I believe this is one of the protections Apple is attempting to implement here. reply andersa 9 hours agorootparentUsually this is done the other way around - servers verifying client devices using a chip the manufacturer put in them and fully trusts. They can trust it, because it's virtually impossible for you (the user) to modify the behavior of this chip. However, you can't put something in Apple's server. So if you don't trust Apple, this improves the trust by... 0%. Their device says it's been attested. Has it? Who knows? They control the hardware, so can just make the server attest whatever they want, even if it's not true. It'd be trivial to just use a fake hash for the system volume data. You didn't build the attestation chip. You will never find out. Happy to be proven wrong here, but at first glance the whole idea seems like a sham. This is security theater. It does nothing. reply brookst 5 hours agorootparentIf it is all a lie, Apple will lose so much money from class action lawsuits and regulatory penalties. > It’d be trivial to just use a fake hash You have to go deeper to support this. Apple is publishing source code to firmware and bootloader, and the software above that is available to researchers. The volume hash is computed way up in the stack, subject to the chain of trust from these components. Are you suggesting that Apple will actually use totally different firmware and bootloaders, just to be able to run different system images that report fake hashes, and do so perfectly so differences between actual execution environment and attested environment cannot be detected, all while none of the executives, architects, developers, or operators involved in the sham ever leaks? And the nefarious use of the data is never noticed? At some point this crosses over into “maybe I’m just a software simulation and the entire world and everyone in it are just constructs” territory. reply andersa 5 hours agorootparentI don't know if they will. It is highly unlikely. But theoretically, it is possible, and very well within their technical capabilities to do so. It's also not as complicated as you make it sound here. Because Apple controls the hardware, and thus also the data passing into attestation, they can freely attest whatever they want - no need to truly run the whole stack. reply brookst 4 hours agorootparentIt is as complicated as I make it sound. Technically, it's trivial, of course. But operationally it is incredibly complicated to deliver and operate this kind of false attestation at massive scale. reply p_l 9 hours agorootparentprevUsually the attestation systems operate on neither side having everything to compute a result that will match attestation requirements, and thus require that both server-side and client-side secret are involved in attestation process. The big issue with Apple is that their attestation infrastructure is wholly private to them, you can't self-host (Android is a bit similar in that application using Google's attestation system have the same limitation, but you can in theory setup your own). reply andersa 8 hours agorootparentAttestation requires a root of trust, i.e. if data hashes are involved in the computation, you have to be able to trust that the hardware is actually using the real data here. Apple has this for your device, because they built it. You don't have it for their server, making the whole thing meaningless. The maximum information you can get out of this is \"Apple trusts Apple\". Under the assumption that Apple is telling the truth about what the server hardware is doing, this could protect against unauthorized modifications to the server software by third parties. If however, we assume Apple itself is untrustworthy (such as, because the US government secretly ordered them to run a different system image with their spyware installed) then this will not help you at all to detect that. reply nardi 11 hours agorootparentprevThis is what the “attestation” bit is supposed to take care of—if it works, which I’m assuming it will, because they’re open sourcing it for security auditing. reply underdeserver 1 hour agoparentprevUnless you personally validate hardware designs, manufacturing processes, and all software, even when running locally you're trusting many, many people. reply nl 8 hours agoparentprevThis isn't right. If you trust math you can prove the software is what they say it is. Yes it is work to do this, but this is a big step forward. reply robmccoll 4 hours agorootparentIt's not fully homomorphic encryption. The compute is happening in the plain on the other side, and given the scale of models they are running, it's not likely that all of the data involved in a computation is happening inside a single instance of particularly secure and hardened hardware. I don't think it's reasonable for most individuals to expect to be protected from nation-state actors or something, but their claims seem a little too absolute to me. reply ADeerAppeared 7 hours agorootparentprevThe only thing the math tells you is that the server software gave you a correct key. It does not tell you how it got that key. A compromised server would send you the key all the same. You still have to trust in the security infrastructure. Trust that Apple is running the hardware it says it is, Trust that apple is running the software it says it is. Security audits help build that trust, but it is not and never will be proof. A three-letter-agency of choice can still walk in and demand they change things without telling anyone. (And while that particular risk is irrelevant to most users, various countries are still opposed to the US having that power over such critical user data.) reply nl 6 hours agorootparentNo, this really isn't right. To quote: verifiable transparency, goes one step further and does away with the hypothetical: security researchers must be able to verify the security and privacy guarantees of Private Cloud Compute, and they must be able to verify that the software that’s running in the PCC production environment is the same as the software they inspected when verifying the guarantees. So how does this work? > The PCC client on the user’s device then encrypts this request directly to the public keys of the PCC nodes that it has first confirmed are valid and cryptographically certified. This provides end-to-end encryption from the user’s device to the validated PCC nodes, ensuring the request cannot be accessed in transit by anything outside those highly protected PCC nodes > Next, we must protect the integrity of the PCC node and prevent any tampering with the keys used by PCC to decrypt user requests. The system uses Secure Boot and Code Signing for an enforceable guarantee that only authorized and cryptographically measured code is executable on the node. All code that can run on the node must be part of a trust cache that has been signed by Apple, approved for that specific PCC node, and loaded by the Secure Enclave such that it cannot be changed or amended at runtime. But why can't a 3-letter agency bypass this? > We designed Private Cloud Compute to ensure that privileged access doesn’t allow anyone to bypass our stateless computation guarantees. > We consider allowing security researchers to verify the end-to-end security and privacy guarantees of Private Cloud Compute to be a critical requirement for ongoing public trust in the system.... When we launch Private Cloud Compute, we’ll take the extraordinary step of making software images of every production build of PCC publicly available for security research. This promise, too, is an enforceable guarantee: user devices will be willing to send data only to PCC nodes that can cryptographically attest to running publicly listed software. So your data will not be sent to node that are not cryptographically attested by third parties. These are pretty strong guarantees, and really make it difficult for Apple to bypass. It's like end-to-end encryption using the Signal protocol: relatively easy to verify it is doing what is claimed, and extraordinarily hard to bypass. Specifically: > The only thing the math tells you is that the server software gave you a correct key. No, this is secure attestation. See for example https://courses.cs.washington.edu/courses/csep590/06wi/final... which explains it quite well. The weakness of attestation is that you don't know what the root of trust is. But Apple strengthens this by their public inspection and public transparency logs, as well as the target diffusion technique which forces an attack to be very widespread to target a single user. These aren't simple things for a 3LA to work around. reply mbesto 3 hours agoparentprevThey already have your private pictures. What difference is it that it's now running AI? reply detourdog 10 hours agoparentprevIf one has to use tech one has to trust someone. Apple has focused on the individual using computers since inception. They have maintained a consistent message and have a good track record. I will trust them because the alternatives I see are scattered and unfocused. reply seydor 13 hours agoparentprev> if wanted. Or if someone compels them to reply loteck 19 hours agoprevSome good comments on this from cryptographer Matt Green here: https://x.com/matthew_d_green/status/1800291897245835616?t=C... (I wonder if Matt realizes nobody can read his tweets without a X account? Use BlueSky or Masto man) Edit: here's his thread combined https://threadreaderapp.com/thread/1800291897245835616.html?... reply BenFranklin100 17 hours agoparentIf he really wanted no one to be reading his tweets he’d be using BluSky or Masto… reply theshrike79 10 hours agorootparenthttps://infosec.exchange/ has a ton of infosec people, big names. https://ioc.exchange/@matthew_d_green - And he's there BTW :) reply unshavedyak 16 hours agorootparentprevIs there more to that thread? I can't read it if it exists, not sure if that is what the parent is talking about? But i don't have a Twitter account anymore, so maybe it's locked? reply capybara_2020 16 hours agorootparentWithout being logged into X, you can only see the first post in a thread. reply jjav 11 hours agorootparentNot even that anymore, all links show is \"Something went wrong, but don’t fret — let’s give it another shot.\" Impossible to see any content. reply AnonC 10 hours agorootparentThat's likely due to tracking prevention or protection by your browser because X really, really wants to track you. If you disable the tracking protection and related settings, you may be able to see the single tweet. reply qingcharles 16 hours agorootparentprevI don't know what you're seeing. It's a very long thread. Exceptionally good take on the whole thing. Apple has gone way out of their way to try and sell this thing. Above and beyond compared to how I imagine Microsoft or Google would have tackled this. reply zooq_ai 15 hours agorootparentIf your AI model sucks, you have to use other gimmicks to lure customers. That's marketing 101. Create irrational fear about piracy, push privacy focused products and profits as the sheeple promptly fall for this reply astrange 11 hours agorootparentI've never seen someone use \"sheeple\" in an anti-privacy argument. reply zooq_ai 2 hours agorootparentthe most successful sheeple operation is the one the sheeple and the entire world is completely oblivious of it. jokes aside, this is no different from people selling bunker beds, gold, ammunition, crypto, vpns. It is specifically for the set of gullible people who think they and their data is so important. Reality (except for 10,000 people or so) is, most lives and their 'precious' data is worthless. (I'm not talking about SSN, Bank Accounts -- those are well protected by tech cos HN seem to hate on) reply rmm 16 hours agorootparentprevOk that made me spill my coffee. reply Andrex 3 hours agorootparentprevOr maybe (gasp!) a blog? reply transpute 18 hours agoparentprevThanks for the link. > As best I can tell, Apple does not have explicit plans to announce when your data is going off-device for to Private Compute. You won't opt into this, you won't necessarily even be told it's happening. It will just happen. Magically. Presumably it will be possible to opt out of AI features entirely, i.e. both on-device and off-device? Why would a device vendor not have an option for on-device AI only? iOS 17 AI features can be used today without iCloud. Hopefully Apple uses a unique domain (e.g. *.pcc.apple.com) that can be filtered at the network level. reply onel 11 hours agorootparentI think the main reason might be the on-device AI is fairly limited features wise. For Apple to actually offer something useful they would need to switch between device/server constantly and they don't want to limit the product by allowing users to disable going to a server. With OpenAI calls is different because the privacy point is stronger reply azinman2 17 hours agorootparentprevYou would have to activate a clearly LLM-powered software feature and have internet access. I don't know if settings will appear to disable this, but you could imagine it would be the case. This isn't just siphoning off all your data at random. reply transpute 17 hours agorootparentWould Spotlight be considered a \"clearly LLM-powered software feature\"? Will there be an option for \"non-AI Spotlight\"? Disabling dozens of software features, or identifying all apps which might use LLM services, is a daunting proposition. It would be good to have a PCC kill switch, which makes opt-in usage meaningful, rather than forced. reply chefandy 16 hours agorootparentPrivacy \"consent\" is fundamentally broken. We've moved from \"we're doing whatever the fuck we want\" to \"we're doing whatever the fuck we want, but on paper it's whatever the fuck you expressly asked for, whether you wanted to or not.\" reply sneak 13 hours agorootparentprevAlmost certainly you will be able to disable it entirely and hide the UI to re-enable it via provisioning profiles via Apple Configurator 2 or MDM. This is actually what you have to do now if you don’t want Siri and Mail to leak your address book to Apple. reply transpute 11 hours agorootparent> if you don’t want Siri and Mail to leak your address book to Apple. By disabling Siri and iCloud, or other policies? reply wmf 17 hours agorootparentprevIf you have no threat model and want to opt out of random features just because... you probably shouldn't use Apple products at all. Or Google or Microsoft. reply transpute 17 hours agorootparentFor years, Apple has a documented set of security policies to disable off-device processing (e.g iCloud, Siri), via MDM / Apple Configurator. Apple also published details needed for enterprise network filtering to limit Apple telemetry, if all you want from Apple servers are software security updates and notifications. With a hardened configuration, Apple has world-class device security. In time, remote PCC may prove as robust against real-world threats. Until then, it would be good to retain on-device security policy and choice for remote computation. reply sneak 13 hours agorootparentApple does not publish details to limit telemetry. Nowhere in MDM or in their docs do they tell you that you can safely block xp.apple.com (telemetry) but not gs.apple.com (boot ticket signing server for updates). reply transpute 11 hours agorootparentThanks, both are listed as required for software updates, https://support.apple.com/en-us/101555 Is there a good non-Apple reference for the functions performed by their servers? reply 1vuio0pswjnm7 14 hours agoparentprev\"I wonder if Matt realises nobody can read his tweets without a X account?\" https://nitter.poast.org/matthew_d_green/status/180029189724... reply Tepix 12 hours agorootparentThanks. I wonder how long that service is going to last. reply dmix 4 hours agorootparentits been around a loong time reply gvurrdon 5 hours agoparentprevHere's the Mastodon thread: https://ioc.exchange/@matthew_d_green/112597849837858606 reply vaylian 13 hours agoparentprev> (I wonder if Matt realizes nobody can read his tweets without a X account? Use BlueSky or Masto man) He actually has an active Mastodon account, but this particular story is not on there (yet): https://ioc.exchange/@matthew_d_green reply Tepix 12 hours agorootparentInactive since 2 months reply vaylian 3 hours agorootparentYou were right until a couple of hours ago. Then this happened: https://ioc.exchange/@matthew_d_green/112597917470493480 reply brigandish 17 hours agoparentprevThese two tweets stand out for me: > Ok there are probably half a dozen more technical details in the blog post. It’s a very thoughtful design. Indeed, if you gave an excellent team a huge pile of money and told them to build the best “private” cloud in the world, it would probably look like this. and > And of course, keep in mind that super-spies aren’t your biggest adversary. For many people your biggest adversary is the company who sold you your device/software. This PCC system represents a real commitment by Apple not to “peek” at your data. That’s a big deal. I'd prefer things stay on the device but at least this is a big commitment in the right direction - or in the wrong direction but done better than their competitors, I'm not sure which. reply stavros 12 hours agoparentprevHe's not wrong that, given that you want to do this, this is the best way. The alternative would be to not do it at all (though an opt-out would have been good). reply wslh 16 hours agoparentprevBeyond all the hardware complexity, another attack vector is the network infrastructure. reply astrange 11 hours agorootparentThat is covered in the article. reply firecall 16 hours agoparentprevThreads also is popular. Probably the mainstream Twitter alternative at this point? reply jxi 15 hours agorootparentThreads is far from mainstream and just filled with spam and OnlyFans spammers at this point. reply JimDabell 4 hours agorootparentThat sounds far more like Twitter than Threads. I get so much spam on Twitter now that I hit rate limits reporting it all. reply threeseed 11 hours agorootparentprevBy every metric Threads is mainstream: a) Top 10 App Store charts in every country. b) Heavily promoted through Facebook and Instagram. c) DAUs are higher than X. reply fragmede 12 hours agorootparentprevweird, i get a bunch of music and programming stuff on my Threads feed. it's not very deep, but what's on the surface is quite nice and not a bunch of almost-porn. Twitters become half porn though reply tantalor 17 hours agoparentprev> nobody can read his tweets without a X account False; works fine for me logged out or incognito.. reply windexh8er 16 hours agorootparentNo, you can't see the thread. You can see the first post, but X took this away [0]. Nitter still works [1]. Also Threadreader (as can be seen linked in Green's tweet). [0] https://tweetdelete.net/resources/view-twitter-without-accou... [1] https://nitter.poast.org/matthew_d_green reply unshavedyak 16 hours agorootparentprevAlso can't see the thread. reply steg132 17 hours agorootparentprevI’m on iOS. I can’t see the thread. Incognito or normally. reply OneLeggedCat 15 hours agorootparentprevFalse reply zmmmmm 15 hours agoprevRead through it all, it still comes down to \"trust us\". Apple can sign and authorise an update at any time that will backdoor it, and the government is the stroke of a pen away from forcing them to, all completely silently. I get that there's benefit to what they are doing. But the problem of selling a message of trust is you absolutely have to be 100% truthful about it, and them failing to be transparent that people's data is still subject to access like this poisons the larger message they are selling. reply troad 14 hours agoparentThey already have root. Their software is closed source. There is absolutely nothing stopping them from uploading all of your data right now. If you don't trust the people making your OS, your problems are much deeper than fretting about off-device AI processing. reply Vegenoid 14 hours agorootparentWhile true, the gap between \"we send your data to our datacenters but we don't look at it\" to \"we look at it a little bit without telling you\" is much smaller than \"we leave your data on your device alone\" to \"we upload data from your device\", both on a technical and policy level. Even if the org has been trustworthy to this point, I think this step makes it more likely (maybe still unlikely, but more likely) that in the future they do look at your data, as less things have to change for that to happen. reply __MatrixMan__ 14 hours agorootparentprevThat's true, but also it should be possible to make an OS that people can trust without trusting you, and as users we should encourage movement in that direction. reply troad 14 hours agorootparentI understand the sentiment, but it's impractical to live in a trust-less society. If you've ever had dental work done, you've put an awful lot of faith in a stranger pushing a drill into your head. Ditto for riding buses and bus drivers, etc etc. Trust can be abused, certainly, but it also allows collaboration and specialisation, and without those I doubt we'd have gotten very far. reply __MatrixMan__ 5 hours agorootparentI'm happy to trust many kinds of people, dentists included, just not the kind people who find themselves at the helm of companies like Apple and Google. Better to trust many people narrowly (e.g. I don't trust the bus driver to drill my cavities) than to trust a small handful of people broadly (e.g. like Apple expects of their users). reply Aerbil313 5 hours agorootparentprevAny kind of practical OS would contain code of unpractical amounts to manually review and audit. That's not to mention the argument that any software of a LOC count of higher than some number is impossible to audit because of complex state handling. Rice's Theorem applies to your brain too, probably, to some extent. Idk about purely functional Haskell though. reply abtinf 14 hours agorootparentprev> should be possible What makes you think this? reply brookst 5 hours agorootparentIt’s especially funny because I believe it is provably impossible. You’ll have to trust me that I’ve done the proof. reply __MatrixMan__ 5 hours agorootparentprevBecause there are so freaking many of us, and some of us trust each other. If we were better at coordinating about which parts of the code we trust and to what degree, we could determine which parts of it are untrustworthy and patch the problem out of it. The GrapheneOS people are doing this, for example. It's not crazy to consider your device vendor as part of your threat model, because like it or not, they are a threat. reply EternalFury 14 hours agorootparentprevGood luck. It’s much easier to talk about it. The last open OS I have seen reach a semi-mainstream level of adoption was started in the early 90’s, more than 30 years ago, by some Linus guy. reply fastball 12 hours agorootparentAnd (basically) nobody running linux is individually verifying the source code of every little piece of software that goes into it (maybe Linus is), so you're still trusting someone. reply detourdog 10 hours agorootparentI can’t even find the appropriate documentation. reply dialup_sounds 9 hours agorootparentIt's all on Discord now. reply tsimionescu 9 hours agorootparentprevHow would documentation help you trust the code? reply detourdog 9 hours agorootparentHow does one understand what is going on with out a clear set of documentation? Either one is so smart they can review everyline of everything they are running. My contention is that it is hard enough to find authoritative documentation much less developing an understanding of the code needed or running. The choice is either many little trust relationships or a giant leap of faith. I feel better served by a giant leap of faith and access to all the technology I can use. I prefer no documentation and consistent behavior to no documentation and a bunch of internet howtos on what might work. reply jchw 14 hours agorootparentprevThat's true, but if you don't update your local software and it isn't currently backdoored, then it won't magically become backdoored without some active involvement somewhere. The trouble with remotely pushing data somewhere is that you can't tell if anything has changed even if you wanted to. (Attestation only works if it's not compromised, and for obvious reasons, there's no way to know that an attestation mechanism is compromised.) That said I really don't disagree with this point at all in terms of it being a valid problem. It's not a fixable problem either (it comes down to, again, building trustworthy computers) but it could be biased way towards being solved whereas today it is still \"trust me bro\". I don't think Apple will be the company to make progress towards this, though. reply troad 14 hours agorootparent> if you don't update your local software and it isn't currently backdoored, then it won't magically become backdoored without some active involvement somewhere If you don't update your local software then it will certainly become automatically backdoored by an accumulating series of security vulnerabilities over time. > I don't think Apple will be the company to make progress towards this, though. I agree. reply jchw 13 hours agorootparent> If you don't update your local software then it will certainly become automatically backdoored by an accumulating series of security vulnerabilities over time. Y'know though, when you put it that way, it sounds inherent that security vulnerabilities will pop up, which is kinda true, at least for the foreseeable future, but to be pedantic, the security vulnerabilities are already there, it's discovering them that's the problem. If we could make secure computers... (time to formally prove everything from the ground up I guess.) But, that said, I wasn't overlooking this, I'm just looping \"getting pwned\" into \"active involvement\". If you have some sufficiently isolated machines, they're probably fine indefinitely. The practicality of this is limited outside of thought experiments. However it's definitely worth noting that unlike a compromised remote, it is at least technically feasible to work on the problem of making local compromise more evident, whereas a remote compromise is truly impossible to reliably be able to detect from the outside. reply troad 13 hours agorootparent> If you have some sufficiently isolated machines, they're probably fine indefinitely. The eternal dream of unplugging, and living free on Amigas. reply buzzerbetrayed 14 hours agoparentprevYour argument is no different than what Apple could do to your iPhone. The fact that it happens on the server changes nothing. Apple could push a button and have your iPhone upload whatever they want to their servers. In other words, based on your argument, you shouldn't trust anything, including locally run AI. You're probably right, but it isn't practical. Edit: The final couple tweets from the Matthew Green tweet thread posted in another comment sum it up well: > Wrapping up on a more positive note: it’s worth keeping in mind that sometimes the perfect is the enemy of the really good. > In practice the alternative to on-device is: ship private data to OpenAI or someplace sketchier, where who knows what might happen to it. And of course, keep in mind that super-spies aren’t your biggest adversary. For many people your biggest adversary is the company who sold you your device/software. This PCC system represents a real commitment by Apple not to “peek” at your data. That’s a big deal. In any case, this is the world we’re moving to. Your phone might seem to be in your pocket, but a part of it lives 2,000 miles away in a data center. As security folks we probably need to get used to that fact, and do the best we can to make sure all parts are secure. reply devjab 12 hours agorootparentI think he has a nice pragmatic view on things. I’m EU enterprise we basically view things like picking cloud providers as a question of who we want to spy on us. Typically it comes down to AWS or Azure if you’re pocking a “everything included” service. That being said, I’m not really sure I’m on board with this part: > As security folks we probably need to get used to that fact, and do the best we can to make sure all parts are secure. Isn’t that sort of where the pragmatism ends? All the parts aren’t going to be secure… Unless I misunderstood his intention, I think the conclusion should be more along the lines of approaching the cloud without trust. reply kfreds 10 hours agoprevWow! This is incredibly exciting. Apple's Private Cloud Compute seems to be conceptually equivalent with System Transparency - an open-source software project my colleagues and I started six years ago. I'm very much looking forward to more technical details. Should anyone at Apple see this, please feel free to reach out to me at stromberg@mullvad.net. I'd be more than happy to discuss our design, your design, and/or give you feedback. Relevant links: - https://mullvad.net/en/blog/system-transparency-future - http://system-transparency.org (somewhat outdated) - http://sigsum.org reply v4dok 8 hours agoparenthttps://en.m.wikipedia.org/wiki/Confidential_computing This is what they are doing. Search implementations of this to understand more technical details. reply jiveturkey 1 hour agorootparentIt's not, AFAICT from the press release. Confidential Compute involves technologies such as SGX and SEV, and for which I think Asylo is an abstraction for (not sure), where the operator (eg Azure) cannot _hardware intercept_ data. The description of what Apple is doing \"just\" uses their existing code signing and secure boot mechanisms to ensure that everything from the boot firmware (the computers that start before the actual computer starts) to the application, is what you intended it to be. Once it lands in the PCC node it is inspectable though. Confidential Compute goes a step further to ensure that the operator cannot observe the data being operated on, thus also defeating shared workloads that exploit speculative barriers, and hardware bus intercept devices. Confidential Compute also allows attestation of the software being run, something Apple is not providing here. EDIT: looks like they do have attestation, however it's different to how SEV etc attestation works. The client still has to trust that the private key isn't leaked, so this is dependent on other infrastructure working correctly. It also depends on the client getting a correct public key. There's no description of how the client attests that. Interesting that they go through all this effort just for (let's be honest) AI marketing. All your data in the past (location, photos, contacts, safari history) is just as sensitive and deserving of such protection. But apparently PCC will apply only to AI inference workloads. Siri was already and continues to be a kind of cloud AI. reply rekoil 9 hours agoparentprevThis was my take from the presentation as well, immediately thought of your feature. Will be interesting to hear your take on it once the details have been made available and fully understood. reply ThePhysicist 8 hours agoparentprevYeah it seems so, though most of these systems (e.g. Intel SGX, AMD SEV, NVIDIAs new tech) use the same basic building blocks (Apple itself isn't member of the confidential computing consortium but ARM is), for me it's the quality of the overall implementation and system that sets this apart. I'm also quite bullish about trusted computing, seems it gains significant momentum. I would like some technologies to be more open and e.g. allow you to control the whole stack and install your own root certificates / keys on a hardware platform, but even so I think it can provide many benefits. With Apple pushing this further into the mainstream I expect to see more adoption. reply Shank 19 hours agoprev> In a first for any Apple platform, PCC images will include the sepOS firmware and the iBoot bootloader in plaintext, making it easier than ever for researchers to study these critical components. Yes! > Software will be published within 90 days of inclusion in the log, or after relevant software updates are available, whichever is sooner. I think this theoretically leaves a 90-day maximum gap between publishing vulnerable software and potential-for-discovery. I sincerely hope that the actual availability of images is closer to instant than the maximum, though. reply gigel82 16 hours agoparentWell, a 89-day \"update-and-revert\" schedule will take care of those pesky auditors asking too many questions about NSA's backdoor or CCP's backdoor and all that. reply gpm 15 hours agorootparentNo, because the log of what source was used will still show the backdoored version, and you can't unpublish the information that it was used. Reverting doesn't solve the problem that people will be able to say \"this software was attested 90 days ago and it hasn't been released\". If you're trying to do a quiet backdoor and you have the power to compel Apple to assist, the route to take is to simply misuse the keys that are supposed to only go into hardware for attestation, and instead simply use them to forge messages attesting to be running software on hardware that you aren't. Or just find a bug in the software stack that gives you RCE and use it reply brookst 5 hours agorootparent> simply use them to forge messages attesting to be running software on hardware that you aren't Well, your messages have to be congruent with the expected messages from the real hardware, and your fake hardware has to register with the real load balancers to receive user requests. > RCE That’s probably the best attack vector, and presumably why Apple is only making binary executables available. Not that that stops RCE. But even then you can’t pick and choose the users whose data you compromise. It’s still a sev0 problem, but less exploitable for the goals of nation states so less likely to be heavily invested in for exploiting. reply gpm 3 hours agorootparent> Well, your messages have to be congruent with the expected messages from the real hardware, Yes, which is why you need the keys that are used to make real hardware. Provided you have those very secret and well protected keys (you are Apple being compelled by the government) that's not an issue. > and your fake hardware has to register with the real load balancers to receive user requests. Absolutely, but we're apple in this scenario so that's \"easy\". reply brookst 1 hour agorootparentI think I misunderstood your point -- I took it to mean someone impersonating a server, but you're saying it's Apple. So the part you're attacking (as Apple) is: > The process involves multiple Apple teams that cross-check data from independent sources, and the process is further monitored by a third-party observer not affiliated with Apple. At the end, a certificate is issued for keys rooted in the Secure Enclave UID for each PCC node. So, in your scenario, the in-house certificate issuer is compelled to provide certificates for unverified hardware, which will then be loaded with a parallel software stack that is malicious but reports the attestation ID of a verified stack. So far, so good. Seems like a lot of people involved, but probably still just tens of people, so maybe possible. Are you envisioning this being done on every server, so there are no real ones in use? Or a subset? Just for sampling, or also with a way to circumvent user diffusion so you can target specific users? It's an interesting thought exercise but the complexity of getting anything of real value from this without leaks or errors that expose the program seems pretty small. reply ein0p 17 hours agoprevIt is not possible for this to be fully private in the United States because the government not only can force Apple to open up the kimono, it can also forbid it to talk about it. There’s not really anything Apple can do to work around this “limitation”. Thank your “representative” for extending the PATRIOT Act when you get a chance. reply amiantos 15 hours agoparentPrivate Cloud Compute servers have no persistent storage so there would be nothing to see upon opening the kimono. You'd need some sort of government requested live wire tap thing to harvest the data out of the incoming requests, which might be a different situation. I'm, of course, just some dude on the internet, thinking up a counter-point to this concern, who knows if I am even remotely in the right ballpark. reply KaiserPro 7 hours agorootparent> Private Cloud Compute servers have no persistent storage so there would be nothing to see upon opening the kimono It doesn't actually say there is no persistent storage, it says that the compute node will not store it for longer than the request. There's nothing to stop the data coming from a datastore outside of the \"PCC\" in another part of apple's infrastructure. reply transpute 11 hours agorootparentprev> have no persistent storage How often do PCC servers reboot and wipe the temporary encryption key? reply choppaface 13 hours agorootparentprevApple already services US Gov cloud data requests, see e.g. https://www.reddit.com/r/privacy/comments/eqg5gc/apple_compl... reply visarga 14 hours agorootparentprevmandatory 30 day retention policies or something like it reply theshrike79 10 hours agorootparentYou can't mandate retention on stuff you're not storing anyway - or because of encryption can't store. reply talldayo 3 hours agorootparentYou would think that, but cell carriers have been found to retain both plaintext and encrypted traffic for several years in some cases: https://www.vice.com/en/article/m7vqkv/how-fbi-gets-phone-da... reply paradite 15 hours agoparentprevSlightly off-topic, \"open up the kimono\" sounds disturbing and creepy to me as an Asian. I suspect I'm not alone in this. reply dxbednarczyk 14 hours agorootparentSome share your sentiment. https://www.npr.org/sections/codeswitch/2014/11/02/360479744... reply _heimdall 6 hours agorootparentI'm not sure how I've been in tech since before this article was written and today is the first time I've ever even seen/heard this phrase. reply bn-l 12 hours agorootparentprevIs this phrase worth an entire long form blog post from NPR? reply rpastuszak 10 hours agorootparentHonestly, why not? I love reading about etymologies and I know that many people here do as well. reply ein0p 14 hours agorootparentprevThat’s even better. I do think it’s disturbing and creepy when someone goes through my private data without my knowledge. reply sciolist 16 hours agoparentprevThere's a difference between guaranteed privacy and certifiable privacy. Yes, the government can request one's data. However, Apple's system would reveal those intrusions to the public, even if Apple themselves couldn't say it. reply afh1 16 hours agorootparentHow? reply aalimov_ 15 hours agoparentprevTheir post sure makes it seam like it’s possible. Was there something that stood out to you? reply quenix 13 hours agorootparentI mean, the software running on the client (phone/mac/ipad) is closed-source and, if we assume Apple is compromised, can be made to circumvent all of these fancy protections at the push of a button. If pressured by the government, Apple can simply change the client software to loosen the attestation requirements for private compute. And that would be the most inconspicuous choice. reply rvnx 12 hours agorootparentOr target a device by IMEI or iCloud to be candidate to receive a software update, and push an update that sends data to \"dev-llm-assistant.ai.apple.com\". \"oh it's our dev version ? what's the problem ? we need data access for troubleshooting\" reply tantalor 16 hours agoparentprevWarrant canary reply egorfine 9 hours agorootparentIt makes zero sense for a company of this size. I bet they are served with gag orders like daily, so the warrant canary is going to expire the moment it is published. reply afh1 16 hours agorootparentprevApple removed theirs year ago. reply sneak 13 hours agorootparentprevThe orders in question aren’t search warrants and don’t require probable cause. 70,000+ Apple user accounts are surveilled in this manner every year. reply sneak 13 hours agoparentprevIt seems to me that this security architecture is a direct response to the hostile regulatory environment Apple finds themselves in wrt USA PATRIOT and the CCP et al. reply ls612 15 hours agoparentprevWhat Apple can do (and appears to be doing throughout its products) is not have the data requested. Or not have it in cleartext. NSLs can't request data that doesn't exist anymore. reply ein0p 13 hours agorootparentLLMs work on clear text inputs reply ls612 13 hours agorootparentBut the setup is that Apple doesn't know which cleartexts currently being processed are associated with which user meaning that even live surveillance can't work without surveilling everybody, making any such program very quickly discoverable. Read the section about non-targetability in the link. Apple deserves credit for correctly analyzing their threat model and designing their system accordingly. reply ein0p 12 hours agorootparentI’m willing to concede that Apple’s system is the best designed of the bunch. I’m not willing to call it “private”, however, if it processes unencrypted inputs in the jurisdiction of a nation state with pervasive government surveillance. reply WatchDog 14 hours agoprevI'm interested in how this compares to AWS nitro enclaves, which they mention briefly. The main difference seems to be verifiability down to the firmware level. Nitro enclaves does not provide measurements of the firmware[0], or hypervisor, furthermore they state that the hypervisor code can be updated transparently at any time[1]. Apple is going to provide images of the secure enclave processor operating system(sepOS), as well as the bootloader. It also sounds like they will provide the source code for these components too, although the blog post isn't clear on that. [0]: https://docs.aws.amazon.com/enclaves/latest/user/set-up-atte.... [1]: https://docs.aws.amazon.com/pdfs/whitepapers/latest/security... reply yolovoe 6 hours agoparentNitro does measure firmware. If any firmware is unexpected, server will essentially stop being connected to the EC2 substrate network and/or server wiped clean automatically. People will be paged automatically, security will likely be pulled in, etc. There is no reason to measure hypervisor firmware as it’s not firmware in the case of EC2. The BIOS/UEFI firmware on the mobo is overwritten if it’s tampered with. Hypervisor code (always signed, like all code) is streamed via a verifiably secure system on the server (Nitro cards, which make use of measured boot and/or secure boot). No idea what the customer facing term “Nitro enclaves” means, but EC2 engineers are literally mobilized like an army with pages when any security risk (even minor ones) is determined. Basic stuff like this is covered. We even go as far as guaranteeing core dumps don’t contain any real customer data, even encrypted reply ram_rattle 12 hours agoparentprevAws had to do it this way because of their custom silicon, Intel, ARM and AMD do provide firmware/hypervisor level attestation reply advael 19 hours agoprevI really want to see this OS, and have cautious optimism that this could be the first time we'll see a big tech company actually provide an auditable security guarantee! I think depending on how this plays out, Apple might manage to earn some of the trust its users have in it, which would be pretty cool! But even cooler will be if we get full chain-of-custody audits, which I think will have to entail opening up some other bits of their stack In particular, the cloud OS being open-source, if they make good on that commitment, will be incredibly valuable. My main concern right now is that if virtualization is employed in their actual deployment, there could be a backdoor that passes keys from secure enclaves in still-proprietary parts of the OSes running on user devices to a hypervisor we didn't audit that can access the containers. Surely people with more security expertise than me will have even better questions. Maybe Apple will be responsive to feedback from researchers and this could lead to more of this toolchain being auditable. But even if we can't verify that their sanctioned use case is secure, the cloud OS could be a great step forward in secure inference and secure clouds, which people could independently host or build an independent derivative of The worst case is still that they just don't actually do it, but it seems reasonably likely they'll follow through on at least that, and then the worst case becomes \"Super informative open-source codebase for secure computing at scale just dropped\" which is a great thing no matter how the other stuff goes reply ignoramous 19 hours agoparent> could be the first time we'll see a big tech company actually provide an auditable security guarantee AWS Nitro Enclaves [0] come close but of course what Apple has done is productize private compute for its 1b+ macOS & iOS customers! [0] https://docs.aws.amazon.com/enclaves/latest/user/nitro-encla... reply threeseed 18 hours agorootparentYou would combine that with AWS BottleRocket: https://aws.amazon.com/bottlerocket reply stensonb 18 hours agorootparentAbsolutely looking forward to that possibility: https://github.com/bottlerocket-os/bottlerocket/issues/3348 reply transpute 19 hours agoparentprev> even if we can't verify that their sanctioned use case is secure, the cloud OS could be a great step forward in secure inference and secure clouds, which people could independently host or build an independent derivative of Yes, the tech industry loves to copy Apple :) Asahi Linux has a good overview of on-device boot chain security, https://github.com/AsahiLinux/docs/wiki/Apple-Platform-Secur... > My main concern right now is that if virtualization is employed in their actual deployment, there could be a backdoor that passes keys from secure enclaves in still-proprietary parts of the OSes running on user devices to a hypervisor we didn't audit that can access the containers. We’ll release a PCC Virtual Research Environment: a set of tools and images that simulate a PCC node on a Mac with Apple silicon, and that can boot a version of PCC software minimally modified for successful virtualization. This seems to imply that PCC nodes are bare-metal. Could a PCC node be simulated on iPad Pro with M4 Apple Silicon? reply advael 19 hours agorootparent> Yes, the tech industry loves to copy Apple :) Yes, most technology is built on other technology ;) > This seems to imply that normal PCC nodes are bare-metal. I realize that, but there's plausible deniability in it, especially since the modification could also hide the mechanism I've described in some other virtualization context that uses the unmodified image, without the statement being untrue reply zer00eyz 18 hours agoprevI have a big question here. Who is this for? Dont get me wrong I think it's a great effort. This is some A+ nerd stuff right here. It's speaking my languge. But Im just going to figure out how to turn off \"calls home\". Cause I dont want it doing this at all. Is this speaking to me so I tell others \"apple is the most secure option\"? I don't want to tell others \"linux\" because I don't want to do tech support for that. At this point I feel like an old man shouting \"Dam you keep your hands off my data\". reply al_borland 17 hours agoparentApple needs to differentiate itself, and they have chosen privacy as a way to do that, which I'm all for. The headlines around Microsoft's AI efforts have largely been a nightmare, with a ton of bad press. If the press around Apple's AI is all about how over the top they went with security and privacy, that will likely make people feel a little better about using it. I'm not a big user of OpenAI's stuff, but if I was going to use any of it, I'd rather use it through Apple's anonymizing layer than going directly to OpenAI. reply gpm 15 hours agorootparentI actually thought one notable thing in the presentation was that they spent all this time talking about their new private cloud compute architecture. And then showed that they have a prompt asking if you're ok sending the data to OpenAI. Presumably because despite OpenAI promising not to use your data (a promise apple relayed) OpenAI didn't buy into this new architecture. reply brookst 5 hours agorootparentDifferent features. OpenAI provides the chatbot interface we all know. The PCC cloud serves all of the other integrated AI features like notification prioritization, summarization, semantic search, etc. At least when those can’t be run on device. reply al_borland 14 hours agorootparentprevThank you for mentioning this. I thought I was going crazy, because I heard this too, but kept seeing comment after comment on other sites asking if a person could choose not to use OpenAI, or that it was happening magically in the background. The way I heard it, the user was in control. I think this goes back to what Steve said in 2010. https://youtube.com/watch?v=Ij-jlF98SzA And yes, while the data might not be linked to the user and striped of sensitive data, I could see people not wanting something very personal things to go to OpenAI, even if there should be no link. For example, I wouldn’t want any of my pictures going to OpenAI unless I specifically say it is OK for a given image. reply rekoil 9 hours agorootparentI was under the impression that the OpenAI integrations were more about content generation and correction than the Apple Intelligence-driven personal stuff. reply manmal 6 hours agorootparentprevI’m not sure but I thought I saw it mentioned that OpenAI is still allowed to train on the data received from Apple customers. reply FumblingBear 3 hours agorootparentActually the opposite. They’re explicitly not allowed to. reply hapticmonkey 13 hours agoparentprevIt's for shareholders. Microsoft and Nvidia have a bigger market cap than Apple now, thanks to the AI investor boom. Apple need to show they can be all about AI, too. But Apple have the institutional culture to maintain privacy. reply written-beyond 10 hours agorootparentThis is exactly what I was thinking during the entire keynote. It was blatantly the WWSC (worldwide shareholder conference) and hackernews commenters are eating it up. Don't get me wrong, I've always appreciated apples on device ml/AI features, those have always been powerful, interesting and private but these announcements feel very rushed, it's literally a few weeks after Microsoft's announcements. They've basically done almost exactly what Microsoft announced with a better UX and a pinky promise about privacy. How are they going to pay for all of that compute? Is this going to be adjusted into the price of the iPhones and MacBook? and then a subscription layer is going to be added to continue paying for it? I don't feel comfortable with the fact that my phone is basically extending it's hardware to the cloud. No matter how \"private\" it is it's just discomforting to know that apple will be doing inference on things seemingly randomly to \"extend\" compute capabilities. Also what on earth is apple high on, integrating a third party API into the OS, how does that even make sense. Google was always a separate app, or a setting in safari, you didn't have Google integrated at an OS level heck you don't have that on Android. It feels very discomforting to know that today my phone could phone home to somewhere other than iCloud. reply lurking_swe 13 hours agoparentprevMe I don’t care if the government has access to the data. I just don’t want “bad actors” (scammers, foreign governments, ad-tech companies, insurance companies, etc) to have access to my private data. But i also want the power of LLM’s. Does that sound so far fetched? I’m a realist. I already EXPECT the US govt has all my data. I don’t like the status quos, but it is what is is. reply wmf 17 hours agoparentprevWhat if you can't turn it off and this extreme security is the justification for why? reply transpute 17 hours agorootparentIf user data disclosure is forced, would user data be limited to PCC nodes located within the same legal jurisdiction, e.g. EU, UK, US, China, etc? reply wmf 17 hours agorootparentPCC is as government-proof as the iPhone itself so jurisdiction may not matter much. reply transpute 17 hours agorootparentSome jurisdictions require data to be processed within the jurisdiction. reply m463 17 hours agorootparentprevwhat happens when your apple id is turned off? reply theshrike79 10 hours agoparentprevNSA already has all our data and if they don't, they have direct contacts at Meta and Alphabet to get it same-day delivery. I'm trusting Apple more in this case, they have an incentive to keep things private and according to experts they're doing everything they can to do so. \"Indeed, if you gave an excellent team a huge pile of money and told them to build the best “private” cloud in the world, it would probably look like this.\" - Matthew D. Green reply _heimdall 5 hours agorootparentThe NSA partners directly with telecoms companies, especially AT&T. Its easier when companies like Meta and Facebook will play along, but that's not the only way they get access to a bunch of our data. reply theshrike79 2 hours agorootparentHow do telecom companies unravel public key encryption in transit? reply fundad 3 hours agoparentprevIt’s for their competitors who have pushed a narrative that Apple was caught “flat-footed”. Well there is actually a line of LLM and cloud infrastructure at iPhone scale. This is not merely 2 years of work. They push the privacy because it’s expected of them. Gemini could claim privacy but I think people would assume that if true, it would make it less effective. reply yla92 18 hours agoprev> And finally, we used Swift on Server to build a new Machine Learning stack specifically for hosting our cloud-based foundation model. Interesting to see Swift on Server here! https://www.swift.org/documentation/server/ reply nardi 11 hours agoprevMany people in this thread are extremely cynical and also ignorant of the actual security guarantees. If you don’t think Apple is doing what they say they’re doing, you can go audit the code and prove it doesn’t work. Apple is open sourcing all of it to prove it’s secure and private. If you don’t believe them, the code is right there. reply rldjbpin 1 hour agoprevnot trusting any of the privacy/security mumbo-jumbo when their icloud free tier still allows for a paltry 5 gigs, when even google offers thrice as much for their public service. i am happy for those who see the positives here, but for the skeptic a toggle to prevent any online processing would be more satisfactory. reply tzs 7 hours agoprev> The Secure Enclave randomizes the data volume’s encryption keys on every reboot and does not persist these random keys, ensuring that data written to the data volume cannot be retained across reboot. In other words, there is an enforceable guarantee that the data volume is cryptographically erased every time the PCC node’s Secure Enclave Processor reboots. I wonder if there is anything that enforces an upper limit on the time between reboots? Since they are building their own chips it would be interesting to include a watchdog timer that runs off an internal oscillator, cannot be disabled by software, and forces a reboot when it expires. reply piccirello 17 hours agoprev> The Secure Enclave randomizes the data volume’s encryption keys on every reboot and does not persist these random keys, ensuring that data written to the data volume cannot be retained across reboot. In other words, there is an enforceable guarantee that the data volume is cryptographically erased every time the PCC node’s Secure Enclave Processor reboots. reply Timber-6539 17 hours agoparentFeels like an uptime screenshot would be appropriate here reply transpute 17 hours agorootparentPCC node execution should be per-transaction, i.e. relatively short lived. reply wmf 15 hours agorootparentThe server can't afford to do one transaction then reboot. reply transpute 15 hours agorootparentIntel and AMD server processors can use DRTM late launch for fast attested restart, https://www.semanticscholar.org/paper/An-Execution-Infrastru.... If future Apple Silicon processors can support late launch, then PCC nodes can reduce intermingling of data from multiple customer transactions. > The server can't afford What reboot frequency is affordable for PCC nodes? reply paul2paul 12 hours agoprevWe don't need \"a new frontier\". I want to be the only one who holds the private key to my encrypted data. I think it's pretty lame to sell privacy when it's not. reply dyauspitr 3 hours agoparentThe problem with that is it’s not possible for you to be the only one to hold the private key and have the cloud run your data against a model. reply krosaen 6 hours agoprevI wonder if they will ever make this available to developers - I can think of many products that would be nice to have at least part of the cloud infra being hosted in a trusted provider like this, e.g indoor cameras for health metrics: sounds awesome but I would never trust a startup to handle private data this sensitive. reply j0e1 18 hours agoprev> The Apple Security Bounty will reward research findings in the entire Private Cloud Compute software stack — with especially significant payouts for any issues that undermine our privacy claims. Let the games begin! reply bayareabadboy 18 hours agoprevWhat are the longer term implications that Apple is doing this on their own hardware and not Nvidia? This seems like a big thing to me, an idiot. reply wmf 17 hours agoparentIf you're one of the richest companies in history you can \"simply\" invest 15 years into developing your own chips instead of buying Nvidia GPUs. reply transpute 17 hours agorootparent> simply invest 15 years into developing your own chips instead of buying Nvidia GPUs https://www.notebookcheck.net/Apple-and-Imagination-strike-G... Following the loss of Apple, easily its biggest client, Imagination was bought out by a Chinese-based investment group. Apple subsequently released its first in-house designed mobile GPU as part of the A11 Bionic SoC that powered the iPhone X.. The new “multi-year license agreement” gives Apple official access to much wider range of Imagination’s mobile GPU IP as well as its AI technologies. The A11 Bionic also included the first neural processing engine in an iPhone https://9to5mac.com/2020/01/01/apple-imagination-agreement/ Apple described Imagination’s characterizations as misleading while hiring Imagination employees to work for Apple’s GPU team in the same community. reply wmf 17 hours agorootparentThat probably has nothing to do with the Neural Engine though. reply transpute 17 hours agorootparentProbably a coincidence that Apple GPU and NPU both appeared at the same time (A11). reply jrk 15 hours agorootparentIt is a coincidence. They are unrelated hardware blocks and very different architectures. reply onesociety2022 16 hours agoparentprevBut this is just inference. What did they use to train their foundation models? reply theshrike79 10 hours agorootparentThe M-series CPUs are stupidly effective in LLM operations. Even my relatively old M1 mac mini can do decent speeds of 7B models. And Apple clearly has made some custom server hardware and slapped a ton of them on a board just to do the PCC stuff. reply dindobre 10 hours agoparentprevThis feels like the biggest part of the news to me reply ls612 15 hours agoparentprevApple doesn't want to pay the Jensen Leather Jacket Fee and has $200 billion in cash it is sitting on to make it happen. If anyone can create an Nvidia substitute for AI chips its Apple and their cash hoard combined with their world-class design team and exclusive access to all of TSMC 3nm and next year 2nm production they could possibly want. reply whatever1 3 hours agoprevFyi this is the same company that has been accused of showing people's photos and videos in stranger people's devices by accident. https://discussions.apple.com/thread/252459254?sortBy=best reply v4dok 8 hours agoprevThis is Confidential Computing https://en.m.wikipedia.org/wiki/Confidential_computing with another name. Intel, AMD and Nvidia have been working for years on this. OpenAI released a blog some time ago where they mentioned this as the \"next step\". Exciting that Apple went ahead and deployed first, it will motivate the rest as well. reply ethbr1 20 hours agoprevThis entire platform is the first time I've strategically considered realigning the majority of my use to Apple. Airtag anonymity was pretty cool, technically speaking, but a peripheral use case for me. To me, PCC is a well-reasoned, surprisingly customer-centric response to the fact that due to (processing, storage, battery) limitations not all useful models can be run on-device. And they tried to build a privacy architecture before widely deploying it, instead of post-hoc bolting it on. >> 4. Non-targetability. An attacker should not be able to attempt to compromise personal data that belongs to specific, targeted Private Cloud Compute users without attempting a broad compromise of the entire PCC system. This must hold true even for exceptionally sophisticated attackers who can attempt physical attacks on PCC nodes in the supply chain or attempt to obtain malicious access to PCC data centers. Oof. That's a pretty damn specific (literally) attacker, and it's impressive that made it into their threat model. And neat use of onion-style encryption to expose the bare minimum necessary for routing, before the request reaches its target node. Also [0] >> For example, the [PCC node OS] doesn’t even include a general-purpose logging mechanism. Instead, only pre-specified, structured, and audited logs and metrics can leave the node, and multiple independent layers of review help prevent user data from accidentally being exposed through these mechanisms. My condolences to Apple SREs, between this and the other privacy guarantees. >> Our commitment to verifiable transparency includes: (1) Publishing the measurements of all code running on PCC in an append-only and cryptographically tamper-proof transparency log. (2) Making the log and associated binary software images publicly available for inspection and validation by privacy and security experts. (3) Publishing and maintaining an official set of tools for researchers analyzing PCC node software. (4) Rewarding important research findings through the Apple Security Bounty program. So binary-only for majority, except the following: >> While we’re publishing the binary images of every production PCC build, to further aid research we will periodically also publish a subset of the security-critical PCC source code. >> In a first for any Apple platform, PCC images will include the sepOS firmware and the iBoot bootloader in plaintext, making it easier than ever for researchers to study these critical components. [0] Oblivious HTTP, https://www.rfc-editor.org/rfc/rfc9458 reply manquer 19 hours agoparent> Oof. That's a pretty damn specific (literally) attacker, and it's impressive that made it into their threat model. How so ? There are any number of state and state sponsored attackers who it should apply it including china, North Korea , Russia , Israel as nation states and their various affiliates like NSO group . Even if NSA its related entities are going to be notably absent. If your threat model includes unfriendly nation state actors then the security depends on security at NSA and less on Apple, they have all your data anyway. If nation state actors are interested in you, no smartphone that is not fully open source on both hardware and OS side that has been independently verified by multiple reviewers is worth it, i.e. no phone in the market today, everything else is tradeoff for convenience for risk, the degree of each is quite subjective to each individual. For the rest of us, the threat model is advertisers, identity thieves, scammers and spammers and now AI companies using it for training. Apple will protect against other advertisers insofar to grow their own ad platform , they already sell searches to Google for $20B/year and there is no knowing the details of the OpenAI deal on what kind of data will be shared. reply transpute 19 hours agoparentprevIt's very encouraging. Another good step in this direction would be publishing a list of all on-device Apple software (including Spotlight models for image analysis) and details of any information that is sent to Apple, along with opt-out instructions via device Settings or Apple Configurator MDM profiles. Apple does publish a list of network ports and servers, so that network traffic can be permitted for specific services. The list is complicated by 3rd-party CDNs, but can be made to work with dnsmasq and ipset, \"Use Apple products on enterprise networks\", https://support.apple.com/en-us/101555 reply dymk 5 hours agoprevI would love to be able to run a PCC node locally on my M2 MacBook or similar for my iPhone to offload to, even if it’s only for doing what 15 Pro iPhones can do on-device. There’s precedent for this sort of thing as well, like Apple TVs or iPads acting as HomeKit hubs and processing security can footage on-device. Maybe they’ll open that up in the future. reply tiffanyh 16 hours agoprevI wonder who Apple will be colocating with for data centers. And what the PCC chassis looks like for these compute devices (will it be a display-less iPad)? reply jrk 15 hours agoparentThe have built and operated a growing number of their own data centers for years. Presumably this will go into those. reply jachee 15 hours agoparentprevApple’s rich enough to build and own their own datacenters. Savvy enough, too. I’d imagine the chassis are custom Apple-NOC-specific M-chip powered servers. reply tiffanyh 4 hours agorootparentSo basically, a Mac mini. reply jnaina 15 hours agoparentprevStarts with A and ends with S reply tiffanyh 4 hours agorootparentApple DatacenterS Gotcha, makes sense :) reply asp_hornet 11 hours agoprevThis thread reads like a whole bunch of sour grapes. Hopefully this challenges other companies to do better reply jaydeegee 18 hours agoprevOutside of all the security aspects which look to be handled quite well on the surface I do enjoy that the client mainframe architecture is still a staple of computing. reply vlovich123 15 hours agoprevWhat I haven’t heard from the announcement is whether the private cloud has external network access. Presumably it wouldn’t otherwise the guarantees of your request staying in your cloud is meaningless. Conversely, a lot of trivial network stuff can be involved (eg downloading the model). Anyone know which balance Apple is choosing to strike initially? reply ramesh31 16 hours agoprevHere's the answer to the \"what's taking Apple so long to get on the LLM train?\" folks. Per usual, they lag a bit and then do it better than anyone else. reply JimDabell 3 hours agoparentIt’s also because they have a twelve month release cycle. reply CGamesPlay 15 hours agoprevAll of this is interesting, but how easy is this to circumvent? When Apple changes their mind for whatever reason, don't they just return a key to a fake PCC node, which would bypass all of their listed protections? Furthermore, what prevents Apple from doing this for specific users? reply a2128 14 hours agoparentAccording to the article, it would be difficult to tie any request to a user: > Target diffusion starts with the request metadata, which leaves out any personally identifiable information about the source device or user, and includes only limited contextual data about the request that’s required to enable routing to the appropriate model If this is the case, I wonder how the authentication would work. Is it a security through obscurity sort of situation? Wouldn't it be possible for someone, through extensive reverse engineering, to write a client in Python that gives you a nice free chat API and Apple would be none the wiser? reply filleokus 7 hours agorootparentDon't know if they use it (or if it would somehow weaken/break the privacy claims you cited), but Apple has an SDK called DeviceCheck[0]. Essentially, your server send a nonce which the client signs using a key pair derived from the Secure Enclave. The server can then verify the signature by an API provided by Apple's servers, and they respond whether it was signed by a Secure Enclave resident key or not. I'm guessing this could be helpful to make it hard(er) to write a Python client. [0]: https://developer.apple.com/documentation/devicecheck/establ... reply JimDabell 3 hours agoparentpreviOS won’t send requests to it unless that node appears in the transparency log. If it appears in the transparency log, the whole world will be able to see that a suspicious node has started serving requests. If Apple changes iOS to remove that restriction, the whole world will be able to see that change because it’s client side. If Apple tries to deliver a custom version of iOS to a single user, the iOS hardware will refuse to run it unless it has a valid signature. If it has a valid signature, that copy of the firmware is irrefutable evidence that Apple is deliberately breaking its privacy promises and spying on people in a way they specifically said they wouldn’t, which would be extremely harmful to their business. Apple seems to be going all-out in binding themselves in a way that makes it as difficult as possible to do what you are suggesting. reply croes 13 hours agoprevWho pays for the costs of private cloud compute, is it free of charge for the iPhone owner (at least until they turn it into a subscription)? What about second hand iPhone users? reply AnonHP 2 hours agoparent> Who pays for the costs of private cloud compute, is it free of charge for the iPhone owner (at least until they turn it into a subscription)? My guess is that this is similar to how iOS upgrades are “free”, how Apple Maps is free, how iMessage is free, how iCloud Mail is free, etc. To a good extent, it’s all paid for by the price paid by the customer for the hardware. I’d also wager that there will be a paid service/subscription that will get baked into iCloud+ at some point in time (maybe a year from now). This will offer a lot more and Apple will try to attract more customers into its paid services net. reply repler 8 hours agoparentprevExactly - nothing is for free. They explicitly state that PCC data gets destroyed after a response is returned. Are the anonymized queries (minus user data context) worth anything? It’s gotta be some kind of subscription/per query charge model to pay for the servers, electricity, and bandwidth. reply thomasahle 20 hours agoprevDid Apple say anything about what training data they used for their generative image models? reply wmf 19 hours agoparentThere's a thread about the models: https://news.ycombinator.com/item?id=40639506 reply jml78 19 hours agoparentprevYes, basically if you opted out of Apple scraping, your data isn’t used reply EternalFury 14 hours agoprevLet’s not be too picky. This is a good thing. reply cherioo 19 hours agoprevCan some ELI5 how remote attestation is supposed to work? It feels like asking a remote endpoint “are you who you say you are”. What’s stopping remote endpoint always responding “yes” reply transpute 18 hours agoparent> What’s stopping remote endpoint always responding “yes” It requires a small, trusted remote observer hardware component, e.g. TCG TPM/DICE, Apple Secure Enclave, Google OpenTitan, Microsoft Pluton. 2021 literature review, https://arxiv.org/abs/2105.02466 2022 HN thread on remote attestation, https://news.ycombinator.com/item?id=32282305 reply GrantMoyer 15 hours agoparentprevMy understanding is that it's similar to TLS authentication. The remote endpoint has special hardware which keeps secret signing keys (similar to a TLS server's signing keys). The hardware refuses to reveal the private keys, but will sign certain payloads under certain conditions. In addition, Intel or AMD or whoever also has super duper mega secret master keys (similar to a CA's signing keys), which they use to sign the device's signing keys. The certificate signing the device keys is also stored on the device. So, each time the endpoint is asked to attest its software, it says yes and signs its response with its keys, and it al",
    "originSummary": [
      "Apple's Private Cloud Compute (PCC) introduces advanced generative AI models to iPhone, iPad, and Mac, with a strong focus on security and privacy.",
      "PCC ensures user data remains private and inaccessible, even to Apple staff, by using end-to-end encryption, ephemeral processing, and anonymizing request metadata.",
      "Apple will make PCC's production software publicly available for security research, supporting independent verification and maintaining public trust."
    ],
    "commentSummary": [
      "The debate on AI data privacy in Apple's private cloud contrasts open-source, decentralized systems with Apple's robust privacy measures, including third-party audits and custom hardware.",
      "Critics question Apple's transparency and potential backdoors, despite acknowledging strong internal security from competitors like Google and OpenAI, and suggest non-profit alternatives like GrapheneOS for verifiable security.",
      "Concerns include Apple's data collection for ads, the need for strong encryption, minimal data logging, and the risks of government interference, highlighting the complexity of network infrastructure and the trade-offs between isolated machines and cloud-based systems."
    ],
    "points": 567,
    "commentCount": 306,
    "retryCount": 0,
    "time": 1718056387
  },
  {
    "id": 40648470,
    "title": "Pioneering Computer Scientist and Transgender Activist Lynn Conway Passes Away at 85",
    "originLink": "https://en.wikipedia.org/wiki/Lynn_Conway",
    "originBody": "Toggle the table of contents Lynn Conway 28 languages العربية Asturianu تۆرکجه বাংলা Català Čeština Deutsch Español Euskara فارسی Français 한국어 Italiano עברית Latina Malagasy മലയാളം مصرى 日本語 Polski Português Română Русский Shqip Simple English Suomi اردو 中文 Edit links Article Talk English Read Edit View history Tools Tools move to sidebar hide Actions Read Edit View history General What links here Related changes Upload file Special pages Permanent link Page information Cite this page Get shortened URL Download QR code Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Appearance move to sidebar hide From Wikipedia, the free encyclopedia Lynn Conway Conway in 2006 Born January 2, 1938 Mount Vernon, New York, U.S.[2] Died June 9, 2024 (aged 86) Jackson, Michigan, U.S. Alma mater Columbia University Known forMead–Conway VLSI chip design revolution transgender activism Spouse Charles Rogers (m. 2002) AwardsHarold Pender Award (1984) John Price Wetherill Medal (1985) Secretary of Defense Meritorious Civilian Service Award (1985) National Academy of Engineering (1989) Computer Pioneer Award (2009) Computer History Museum Fellow (2014)[1] IEEE/RSE James Clerk Maxwell Medal (2015) National Inventors Hall of Fame (2023) Scientific career FieldsComputer science Electrical engineering Institutions IBM Advanced Computing Systems (1964–68), Memorex, Xerox PARC (1970s), DARPA, University of Michigan Lynn Ann Conway (January 2, 1938 - June 9, 2024[3])[4][5] was an American computer scientist, electrical engineer and transgender activist.[6] She worked at IBM in the 1960s and invented generalized dynamic instruction handling, a key advance used in out-of-order execution, used by most modern computer processors to improve performance. She initiated the Mead–Conway VLSI chip design revolution in very large scale integrated (VLSI) microchip design. That revolution spread rapidly through the research universities and computing industries during the 1980s, incubating an emerging electronic design automation industry, spawning the modern 'foundry' infrastructure for chip design and production, and triggering a rush of impactful high-tech startups in the 1980s and 1990s.[7][8][9][10][11] Early life and education[edit] Conway grew up in White Plains, New York. Conway was shy and experienced gender dysphoria as a child. She became fascinated by astronomy (building a 6-inch (150 mm) reflector telescope one summer) and did well in math and science in high school. Conway entered MIT in 1955, earning high grades but ultimately leaving in despair after an attempted gender transition, from male to female in 1957–58, failed due to the medical climate at the time.[citation needed] After working as an electronics technician for several years, Conway resumed education at Columbia University's School of Engineering and Applied Science, earning B.S. and M.S.E.E. degrees in 1962 and 1963.[12][13] Early research at IBM[edit] Conway was recruited by IBM Research in Yorktown Heights, New York in 1964, and was soon selected to join the architecture team designing an advanced supercomputer, working alongside John Cocke, Brian Randell, Herbert Schorr, Ed Sussenguth, Fran Allen and other IBM researchers on the Advanced Computing Systems (ACS) project, inventing multiple-issue out-of-order dynamic instruction scheduling while working there.[7][8][9][14][15] The Computer History Museum has stated that \"the ACS machines appears to have been the first superscalar design, a computer architectural paradigm widely exploited in modern high-performance microprocessors.\"[10][11][16][17] Gender transition[edit] After learning of the pioneering research of Harry Benjamin in healthcare for transsexual women[18] and realising that gender affirmation surgery was now possible, Conway sought his help and became his patient. After suffering from severe depression from gender dysphoria, Conway contacted Benjamin, who agreed to provide counseling and prescribe hormones. Under Benjamin's care, Conway began her medical gender transition.[19] While struggling with life in a male role,[19] Conway had been married to a woman and had two children. Under the legal constraints then in place, she was denied access to their children after transitioning.[19] Although she had hoped to be allowed to transition on the job, IBM fired Conway in 1968 after she revealed her intention to transition.[20] IBM apologized for this in 2020.[21] Career as computer scientist[edit] Upon completing her transition in 1968, Conway took a new name and identity, and restarted her career in what she called \"stealth-mode\" as a contract programmer at Computer Applications, Inc. She went on to work at Memorex during 1969–1972 as a digital system designer and computer architect.[19][22] Conway joined Xerox PARC in 1973, where she led the \"LSI Systems\" group under Bert Sutherland.[23][24] When in PARC, Conway founded the \"multiproject wafers\" (MPW). This new technology made it possible to pack multiple circuit designs from various sources into one single silicon wafer. Her new invention increased production and decreased costs.[25] Collaborating with Ivan Sutherland and Carver Mead of Caltech on VLSI design methodology, she co-authored Introduction to VLSI Systems, a groundbreaking work that would soon become a standard textbook in chip design, used in nearly 120 universities by 1983.[26][27][28][29] With over 70,000 copies sold, and the new integration of her MPC79/MOSIS innovations, the Mead and Conway revolution became part of VLSI design.[27][30] In 1978, Conway served as visiting associate professor of electrical engineering and computer science at MIT, teaching a now famous VLSI design course based on a draft of the Mead–Conway text.[19] The course validated the new design methods and textbook, and established the syllabus and instructor's guidebook used in later courses worldwide.[31][32] Among Conway's contributions were the invention of dimensionless, scalable design rules that greatly simplified chip design and design tools,[8][13][33] and invention of a new form of internet-based infrastructure for rapid prototyping and short-run fabrication of large numbers of chip designs.[8][34] The problem they were solving was how to cope with the increasing complexity of chip design while the number of transistors per chip doubled every two years as Gordon Moore (chairman of Intel) had predicted in 1965. The design methods in use in the semiconductor industry were rapidly running out of steam.[35] The new infrastructure was institutionalized as the Metal Oxide Semiconductor Implementation Service (MOSIS) system in 1981. Two years into its success, Mead and Conway received Electronics magazine's annual award of achievement.[36] Since then, MOSIS has fabricated more than 50,000 circuit designs for commercial firms, government agencies, and research and educational institutions around the world.[37] VLSI researcher Charles Seitz commented that \"MOSIS represented the first period since the pioneering work of Eckert and Mauchley on the ENIAC in the late 1940s that universities and small companies had access to state-of-the-art digital technology.\"[34] The research methods used to develop the Mead–Conway VLSI design methodology and the MOSIS prototype are documented in a 1981 Xerox report[38] and the Euromicro Journal.[39] The impact of the Mead–Conway work is described in a number of historical overviews of computing.[34][40][41][42][43][44] Conway and her colleagues have compiled an online archive of original papers that documents much of that work.[45][46] The methods also came under ethnographic study in 1980 by PARC anthropologist Lucy Suchman, who published her interviews with Conway in 2021.[47][48] In the early 1980s, Conway left Xerox to join DARPA, where she was a key architect of the Defense Department's Strategic Computing Initiative, a research program studying high-performance computing, autonomous systems technology, and intelligent weapons technology.[13][49] In a USA Today article about Conway's joining DARPA, Mark Stefik, a Xerox scientist who worked with her, said \"Lynn would like to live five lives in the course of one life\" and that she's \"charismatic and very energetic\".[50] Douglas Fairbairn, a former Xerox associate, said \"She figures out a way so that everybody wins.\"[50] Conway joined the University of Michigan in 1985 as professor of electrical engineering and computer science, and associate dean of engineering. There she worked on \"visual communications and control probing for basic system and user-interface concepts as applicable to hybridized internet/broadband-cable communications\".[13] She retired from active teaching and research in 1998, as professor emerita at Michigan.[51] Legacy[edit] As sociologist Thomas Streeter discusses in The Net Effect:[52][53] \"By taking this job, Conway was demonstrating that she was no antiwar liberal. (In response to critics, she has said, 'if you have to fight, and sometimes you must in order to deal with bad people, history tells us that it really helps to have the best weapons available)\".[12] But Conway carried a sense of computers as tools for horizontal communications that she had absorbed at PARC right into DARPA – at one of the hottest moments of the cold war.\" In the fall of 2012, the IEEE published a special issue of the IEEE Solid-State Circuits Magazine devoted to Lynn Conway's career,[54][55] including a career memoir by Conway[20] and peer commentaries by Chuck House,[56] former Director of Engineering at HP, Carlo Séquin, Professor of EECS at U.C. Berkeley,[57] and Ken Shepard, of Columbia University.[58] Subsequently the scope of Conway's contributions gained wider retrospective attention. \"Since I didn't #LookLikeanEngineer, few people caught on to what I was really doing back in the 70s and 80s,\" says Conway.[21] \"Clearly a new paradigm had emerged ... Importantly, imaginative support in terms of infrastructure and idea dissemination proved as valuable as the concepts, tools, and chips. The \"electronic book\" and the \"foundry\" were both prescient and necessary, providing momentum and proof-points.\"[56] James F. \"Jim\" Gibbons, former dean of engineering at Stanford University, further states that Lynn Conway, from his perspective, \"...was the singular force behind the entire 'foundry' development that emerged.\"[56] Kenneth Shepard, Professor of Biomedical and Electrical Engineering at Columbia University, stated that \"Lynn's amazing story of accomplishment and personal triumph in the face of personal adversity and overt discrimination should serve as an inspiration to all young engineers.\"[58][59] In 2020, NAE President John L. Anderson stated that \"Lynn Conway is not only a revolutionary pioneer in the design of VLSI systems ... But just as important, Lynn has been very brave in telling her own story, and her perseverance has been a reminder to society that it should not be blind to the innovations of women, people of color, or others who don't fit long outdated – but unfortunately, persistent – perceptions of what an engineer looks like.\"[21] In 2023, Lynn Conway collaborated with Jim Boulton to create Lines in the Sand,[60] a short comic book that tells the story of Conway's groundbreaking invention of Very Large-Scale Integration (VLSI). The launch event[61] took place at the Centre for Computing History on November 23, 2023 Transgender activism[edit] When nearing retirement, Conway learned that the story of her early work at IBM might soon be revealed through the investigations of Mark Smotherman that were being prepared for a 2001 publication.[7] She began quietly coming out in 1999 to friends and colleagues about her past gender transition,[62][63][64] using her personal website to tell the story in her own words.[12] Her story was then more widely reported in 2000 in profiles in Scientific American[14] and the Los Angeles Times.[19] In a later Forbes interview, Conway commented \"From the 1970s to 1999 I was recognized as breaking the gender barrier in the computer science field as a woman, but in 2000 it became the transgender barrier I was breaking.\"[21] After going public with her story, she began work in transgender activism, intending to \"illuminate and normalize the issues of gender identity and the processes of gender transition\".[65] She has worked to protect and expand the rights of transgender people. She has provided direct and indirect assistance to numerous other transgender women going through transition and maintains a website providing medical resources and emotional advice. Parts have been translated into most of the world's major languages.[66] She maintained a listing of many successful post-transition transgender people, to, in her words \"provide role models for individuals who are facing gender transition\".[67] Her website also provided news related to transgender issues and information on sex reassignment surgery for transsexual women, facial feminization surgery, academic inquiries into the prevalence of transsexualism[68] and transgender and transsexual issues in general.[69][70] She has also advocated for equal opportunities and employment protections for transgender people in high-technology industry,[71][72][73][74][75][76] and for elimination of the pathologization of transgender people by the psychiatric community.[77][78] Conway has been a critic of the Blanchard, Bailey, and Lawrence theory of male-to-female transsexualism that all trans women are motivated either by feminine homosexuality or autogynephilia.[79] Along with American transgender rights activist Andrea James and University of Chicago economics professor Dierdre McCloskey, she was also a key person in the campaign against J. Michael Bailey's book about the theory, The Man Who Would Be Queen.[80][81] Conway and McCloskey wrote letters to Northwestern University, accusing Bailey of \"conducting intimate research observations on human subjects without telling them that they were objects of the study.\"[79] American bioethicist Alice Dreger in her book Galilieo's Middle Finger criticized Conway for filing a lawsuit against Bailey which had \"no legal basis\", referring to her allegation that Bailey lacked a license as a clinical psychologist when he wrote letters in support of a young trans woman seeking to transition. According to Dreger, as Bailey did not receive compensation for his services, he would not have needed a license in Illinois, and was \"completely forthright in his letters supporting the women, both about the fact that he had only had brief conversations with them (as opposed to having provided them with extensive counseling) and about his own qualifications and expertise... [and] even attached copies of his CV.\" As Dreger argues, \"presumably all this was why [Illinois] never bothered to pursue the charge.\"[82] In response, Conway argued that Dreger \"deflects attention away from Bailey's book and the massive trans community protest, and caricatures the entire controversy as nothing more than a vicious effort by three rather witch-like women to 'ruin the life' of a brilliant scientist.[83] Conway was a cast member in the first all-transgender performance of The Vagina Monologues in Los Angeles in 2004,[84] and appeared in a LOGO-Channel documentary film about that event entitled Beautiful Daughters.[62][85] In 2009, Conway was named one of the \"Stonewall 40 trans heroes\" on the 40th anniversary of the Stonewall riots by the International Court System, one of the oldest and largest predominantly gay organizations in the world, and the National Gay and Lesbian Task Force.[86][87] In 2013, with support from many hi-tech thought-leaders, Conway and Leandra Vicci of the University of North Carolina at Chapel Hill lobbied the directors of the Institute of Electrical and Electronics Engineers (IEEE), the world's largest professional engineering society, for transgender inclusion in the IEEE's code of ethics.[88] The code, known within the profession as much as a code of honor as one of ethics, became fully LGBT inclusive in January 2014.[89][90][91] In 2014, Time Magazine named Conway as one of \"21 Transgender People Who Influenced American Culture\".[6] In 2015, she was selected for inclusion in \"The Trans100\"[92] and was interviewed in 2020 for inclusion in the Trans Activism Oral History Project.[93] Personal life[edit] In 1987, Conway met her husband Charles \"Charlie\" Rogers, a professional engineer who shares her interest in the outdoors, including whitewater canoeing and motocross racing.[19][94] They soon started living together, and bought a house with 24 acres (9.7 ha) of meadow, marsh, and woodland in rural Michigan in 1994.[19] On August 13, 2002, they were married.[15][62][95] In 2014, the University of Michigan's The Michigan Engineer alumni magazine documented the connections between Conway's engineering explorations and the adventures in her personal life.[96][97] Awards and honors[edit] Conway has received a number of awards and distinctions: Electronics 1981 Award for Achievement, with Carver Mead[98] Harold Pender Award of the Moore School, University of Pennsylvania, with Carver Mead, 1984[99] IEEE EAB Major Educational Innovation Award, 1984[100] Fellow of the IEEE, 1985, \"for contributions to VLSI technology\"[101] John Price Wetherill Medal of the Franklin Institute, with Carver Mead, 1985[102] Secretary of Defense Meritorious Civilian Service Award, May 1985[51][103] Member of the National Academy of Engineering, 1989[104] National Achievement Award, Society of Women Engineers, 1990[105] Presidential Appointment to the United States Air Force Academy Board of Visitors, 1996[106] Honorary Doctorate, Trinity College, 1998[107] Electronic Design Hall of Fame, 2002[108] Engineer of the Year, National Organization of Gay and Lesbian Scientists and Technical Professionals, 2005[109] Named one of the \"Stonewall 40 trans heroes\" by the Imperial Court System and the National LGBTQ Task Force, 2009.[86][87] Computer Pioneer Award, IEEE Computer Society, 2009[8] Member of the Corporation, Emerita, The Charles Stark Draper Laboratory, 1993–2010[110] Fellow Award, Computer History Museum, 2014, \"For her work in developing and disseminating new methods of integrated circuit design.\"[111][112][113][114][115][116] Honorary Doctorate, Illinois Institute of Technology, 2014[117] Steinmetz Memorial Lecture, (Invitational), IEEE/Union College, 2015.[118][119][120][121][122] IEEE/RSE James Clerk Maxwell Medal, 2015[123][124][125][126][127][128][129][130] Magill Lecture in Science, Technology and the Arts (Invited), Columbia University, 2016[131][132] Honorary Doctorate, University of Victoria, 2016[133][134][135][136][137] Fellow Award, American Association for the Advancement of Science (AAAS), 2016[138][139][140][141] Honorary Doctorate and Commencement Address, University of Michigan, Ann Arbor, 2018[142][143][144][145] Pioneer in Tech Award, National Center for Women in Technology (NCWIT), 2019[146] Lifetime Achievement Award, IBM Corporation, 2020[147] Induction into the National Inventors Hall of Fame (NIHF), 2023[148][149][150][151][152] Honorary Doctorate, Princeton University, 2023.[153] Honorary Doctor of Science, Syracuse University, 2024[154] IBM's apology[edit] In 2020, 52 years after IBM fired her for being transgender, IBM officially and publicly apologized to Conway;[155][156][157][158][159][160] IBM held a public event \"Tech Trailblazer and Transgender Pioneer Lynn Conway in conversation with Diane Gherson\" (IBM's senior VP of HR); IBM's Director of Research Dario Gil said \"Lynn was recently awarded the rare IBM Lifetime Achievement Award, given to individuals who have changed the world through technology inventions. Lynn's extraordinary technical achievements helped define the modern computing industry. She paved the way for how we design and make computing chips today – and forever changed microelectronics, devices, and people's lives.\"[147] Selected works[edit] Mead, Carver; Conway, Lynn (1980). Introduction to VLSI Systems. Addison-Wesley. ISBN 0201043580. Conway, L. (February 1981). \"THE MPC ADVENTURES: Experiences with the Generation of VLSI Design and Implementation Methodologies\" (PDF). Xerox PARC Technical Report VLSI-81-2. Conway, L. (September 23, 1982). \"The Design of VLSI Design Methods\" (PDF). Proc. VUB European Solid-State Circuits Conference (Invited Lecture). Vrije Universiteit Brüssel, Brussels, Belgium: 106–117. Conway, Lynn (2012). \"Reminiscences of the VLSI Revolution: How a Series of Failures Triggered a Paradigm Shift in Digital Design\" (PDF). Solid-State Circuits Magazine. Vol. 4, no. 4. IEEE. pp. 8–31. doi:10.1109/MSSC.2012.2215752. Conway, L. (October 2018). \"The Disappeared: Beyond Winning and Losing\". Computer. Vol. 51. IEEE Computer Society. pp. 66–73. Conway, Lynn (2011). \"IBM-ACS: Reminiscences and Lessons Learned from a 1960's Supercomputer Project\" (PDF). In Jones, C. B.; Lloyd, J. L. (eds.). Dependable and Historic Computing: Essays Dedicated to Brian Randell on the Occasion of his 75th Birthday. Springer-Verlag. pp. 185–224. ISBN 978-3-642-24541-1. Conway, Lynn. \"Lynn Conway's IBM-ACS Archive\". University of Michigan. Retrieved June 4, 2016. Conway, L.; Randell, Brian; Senzig, D. (February 23, 1966). \"Dynamic Instruction Scheduling\" (PDF). IBM-ACS. Rozenberg, D.; Conway, L.; Riekert, R. (March 15, 1966). \"ACS Simulation Technique\" (PDF). IBM-ACS. Conway, L. (August 25, 1967). \"MPM Timing Simulation\" (PDF). IBM-ACS. Conway, L. (November 29, 1967). \"ACS Logic Design Conventions: A Guide for the Novice\" (PDF). IBM-ACS. Conway, L (October 31, 1967). \"A Proposed ACS Logic Simulation System\" (PDF). IBM-ACS. Conway, L. (August 6, 1968). \"The Computer Design Process: A Proposed Plan for ACS\" (PDF). IBM-ACS. Patents[edit] US 5046022, Conway, Lynn; Volz, Richard & Walker, Michael, \"Teleautonomous System and Method Employing Time/Position Synchrony/Desynchrony\", issued September 3, 1991. US 5444476, Conway, Lynn, \"System and Method for Teleinteraction\", issued August 22, 1995 US 5652849, Conway, Lynn & Cohen, Charles, \"Apparatus and Method for Remote Control Using a Visual Information Stream\", issued July 20, 1997 US 5719622, Conway, Lynn, \"Visual Control Selection of Remote Mechanisms\", issued February 17, 1998 US 5745782, Conway, Lynn, \"Method and System for Organizing and Presenting Audio/Visual Information\", issued April 28, 1998 References[edit] ^ \"CHM 2014 Fellow \"For her work in developing and disseminating new methods of integrated circuit design\"\". Computer History Museum. Archived from the original on July 3, 2016. Retrieved April 10, 2018. ^ Saari, Peggy; Allison, Stephen; Ellavich, Marie C. (1996). Scientists: A-F. U-X-L. ISBN 978-0-7876-0960-3. ^ Boyd, Helen. \"Lynn Conway: Trans Icon and Pioneer, 1938 – 2024\". (En)gender. Archived from the original on June 11, 2024. Retrieved June 11, 2024. ^ Lee, John A. N. (1995). International Biographical Dictionary of Computer Pioneers. Fitzroy Dearborn. ISBN 1-884964-47-8. ^ \"Computer Pioneers - Lynn Conway\". IEEE Computer Society. IEEE. Archived from the original on November 10, 2014. Retrieved November 10, 2014. ^ a b \"21 Transgender People Who Influenced American Culture\". Time. May 29, 2014. ^ a b c Smotherman, Mark. \"IBM Advanced Computing Systems (ACS) – 1961–1969\". ^ a b c d e \"Lynn Conway: 2009 Computer Pioneer Award Recipient\". IEEE Computer Society. Archived from the original on January 3, 2015. Retrieved January 20, 2010. ^ a b Lynn Conway receives 2009 IEEE Computer Society Computer Pioneer Award. IEEE Computer Society. July 30, 2010 – via YouTube. ^ a b \"CHM Events: IBM ACS System: A Pioneering Supercomputer Project of the 1960's\". Computer History Museum. February 18, 2010. Archived from the original on April 20, 2010. ^ a b Smotherman, Mark; Spicer, Dag (December 2010). \"IBM's single-processor supercomputer efforts\". Communications of the ACM. 53 (12): 28–30. doi:10.1145/1859204.1859216. ^ a b c Conway, Lynn (March 15, 2004). \"Lynn Conway's Retrospective PART I: CHILDHOOD AND EDUCATION\". lynnconway.com. Retrieved July 9, 2008. ^ a b c d Kilbane, Doris (October 20, 2003). \"Lynn Conway: A Trailblazer On Professional, Personal Levels\". Products > News. Electronic Design. Archived from the original on 2008-06-08. Retrieved 2023-02-17. ^ a b Paul Wallich, \"Profile: Lynn Conway—Completing the Circuit Archived October 4, 2013, at the Wayback Machine,\" Scientific American, December 2000. ^ a b Dianne Lynch, \"The Secret Behind 'Project Y': One Woman's Success Story — 'What Works, Works'\", ABCNews.com, November 29, 2001. ^ Smotherman, Mark. \"IBM ACS Reunion – February 18, 2010, in California\". ^ \"The IBM ACS System: A Pioneering Supercomputer Project – Video\". YouTube. Archived from the original on December 21, 2021. ^ Benjamin, Harry (1966). The Transsexual Phenomenon. Julian Press. ISBN 9780446824262. ^ a b c d e f g h Hiltzik, Michael A. (November 19, 2000.) \"Through the Gender Labyrinth.\" Archived October 15, 2012, at the Wayback Machine. Los Angeles Times, Los Angeles Times Magazine, page 1. (Free reprint. Retrieved on September 19, 2007.) ^ a b Conway, Lynn (2012). \"Reminiscences of the VLSI revolution: How a series of failures triggered a paradigm shift in digital design\" (PDF). IEEE Solid-State Circuits Magazine. 4 (4). IEEE: 8–31. doi:10.1109/MSSC.2012.2215752. ISSN 1943-0582. S2CID 9286356. ^ a b c d Alicandri, Jeremy. \"IBM Apologizes For Firing Computer Pioneer For Being Transgender...52 Years Later\". Forbes. ^ \"Lynn Conway's Retrospective PART III: Starting Over\". Ai.eecs.umich.edu. May 12, 1960. Retrieved December 5, 2013. ^ Goldberg, Adele J. (September 1980). \"About This Issue...\" ACM Computing Surveys. 12 (3): 257–258. doi:10.1145/356819.356820. ISSN 0360-0300. S2CID 27661653. ^ Walker, Rob; Tersini, Nancy (1992). Silicon Destiny: The Story of Application Specific Integrated Circuits and LSI Logic Corporation. Walker Research Associates. ISBN 0-9632654-0-7. ^ \"Sense of Wonder Motivates VLSI Chip Revolutionary, Lynn Conway\". American Association for the Advancement of Science. Retrieved March 20, 2020. ^ Conway, Lynn (December 31, 2012). \"The 'Sutherland Letter' of 1976\". ^ a b \"Impact of the Mead-Conway VLSI Design Methodology and of the MOSIS Service\". ai.eecs.umich.edu. Retrieved March 13, 2020. ^ Wallich, Paul (December 2000). \"Profile: Lynn Conway—Completing the Circuit\". Scientific American. Archived from the original on October 28, 2006. Retrieved April 24, 2024. ^ Smith, Gina (December 3, 2007). \"Unsung innovators: Lynn Conway and Carver Mead: They literally wrote the book on chip design\". Computerworld. Archived from the original on December 26, 2008. Retrieved April 24, 2024. ^ Miller, Chris (2022). Chip War: The Fight for the World's Most Critical Technology. Scribner. pp. 136–137, 140, 166, 378. ^ The MIT'78 VLSI System Design Course: A Guidebook for the Instructor of VLSI System Design, Lynn Conway, Xerox Palo Alto Research Center, August 12, 1979. ^ Paul Penfield \"The VLSI Revolution at MIT\" by Paul Penfield 2014 MIT EECS Connector, Spring 2014, pp. 11–13. ^ Carliss Y. Baldwin and Kim B. Clark (2000). Design Rules: The Power of Modularity. MIT Press. ISBN 0-262-02466-7. ^ a b c National Research Council (1999), Funding a Revolution: Government Support for Computing Research, National Academy Press (excerpt) ^ \"Lynn Conway\". Gebbie Lab. January 29, 2024. Archived from the original on April 25, 2024. Retrieved April 24, 2024. ^ \"Impact of the Mead-Conway VLSI Design Methodology and of the MOSIS Service\". ai.eecs.umich.edu. Retrieved March 22, 2020. ^ \"The MOSIS Service – More than 50,000 designs in 25 years of operation\", http://www.mosis.com/, 2008 ^ THE MPC Adventures: Experiences with the Generation of VLSI Design and Implementation Methodologies, Lynn Conway, Xerox PARC Technical Report VLSI-81-2, January 19, 1981. ^ THE MPC Adventures: Experiences with the Generation of VLSI Design and Implementation Methodologies, by Lynn Conway, Microprocessing and Microprogramming – The Euromicro Journal, Vol. 10, No. 4, November 1982, pp 209–228. ^ Allocating Federal Funds for Science and Technology, by Committee on Criteria for Federal Support of Research and Development, National Academy of Sciences, National Academy of Engineering, Institute of Medicine, National Research Council, National Academy Press, Washington DC, 1995, page 75. ^ \"Figure II.13: Technological Developments in Computing\", in Allocating Federal Funds for Science and Technology, National Academy Press, Washington, DC 1995, page 75.\". Ai.eecs.umich.edu. May 7, 1999. Retrieved December 5, 2013. ^ Evolving the High Performance Computing and Communications Initiative to Support the Nation's Information Infrastructure, by Committee to Study High Performance Computing and Communications: Status of a Major Initiative, National Research Council, National Academy Press, Washington DC, 1995, page 20. ^ \"Figure 1.2: Government-sponsored computing research and development stimulates creation of innovative ideas and industries\", in Evolving the High Performance Computing and Communications Initiative to Support the Nation's Information Infrastructure, National Academy Press, 1995, page 20.\". Ai.eecs.umich.edu. May 7, 1999. Retrieved December 5, 2013. ^ Feinstein, Jonathan S. (2023). Creativity in Large-Scale Contexts. Stanford University Press. pp. 196–199, 266–270, 299–304. ^ The VLSI Archive Archived February 8, 2013, at archive.today, by Lynn Conway, Electronic Design News, June 3, 2009. ^ \"VLSI Archive: An online archive of documents and artifacts from the Mead-Conway VLSI design revolution\". Ai.eecs.umich.edu. Archived from the original on December 8, 2007. Retrieved December 5, 2013. ^ Suchman, Lucy (March 1, 2021). \"A Sociotechnical Exchange, Redux\". BackchannelsReflections. Archived from the original on March 4, 2021. ^ Conway, Lynn; Suchman, Lucy (February 28, 2021). \"Conway-Suchman conversation\". Conway Suchman Conversation. ^ Dwight B. Davis \"Assessing the Stragetic Computing Initiative,\" by Dwight B. Davis High Technology, Vol. 5, No. 4, April 1985. ^ a b Osborn, Michelle (June 7, 1983). \"Hi-tech researcher chips in to develop smart computer\" (PDF). USA Today. Archived from the original (PDF) on April 20, 2014. Retrieved April 24, 2024. ^ a b \"Lynn Conway awarded Emerita status at the University of Michigan\". University of Michigan. December 31, 1998. Archived from the original on December 5, 2003. Retrieved April 24, 2024. ^ \"The Net Effect, Romanticism, Capitalism, and the Internet\", Thomas Steeter, New York University Press, 2011, p, 101. ^ \"On Streeter's The Net Effect: A Culture Digitally Dialogue\", Gina Neff, Mary Gray, and Thomas Streeter, April 25, 2013. ^ Lanzerotti, Mary, ed. (2012). \"Editor's Note\" (PDF). IEEE Solid-State Circuits Magazine. 4. IEEE: 1. doi:10.1109/MSSC.2012.2214274. ^ \"Solid-State Circuits Publishes Special Issue with Lynn Conway's Memoir of the VLSI Revolution\", Michigan EECS News, January 31, 2013. ^ a b c House, Chuck (2012). \"A Paradigm Shift Was Happening All Around Us\" (PDF). IEEE Solid-State Circuits Magazine. 4 (4). IEEE: 32–35. doi:10.1109/MSSC.2012.2215759. ISSN 1943-0582. S2CID 8738682. ^ Sequin, Carlo (2012). \"Witnessing the Birth of VLSI Design\" (PDF). IEEE Solid-State Circuits Magazine. 4 (4). IEEE: 36–39. doi:10.1109/MSSC.2012.2215758. ISSN 1943-0582. S2CID 20280958. ^ a b Shepard, Ken (2012). \"\"Covering\": How We Missed the Inside-Story of the VLSI Revolution\" (PDF). IEEE Solid-State Circuits Magazine. 4 (4). IEEE: 40–42. doi:10.1109/MSSC.2012.2215757. ISSN 1943-0582. S2CID 25240158. ^ ACM News (October 12, 2018). \"Lynn Conway and the VLSI Revolution in Microchip Design\". Communications of the ACM. ^ Boulton, Jim (2024). Lines in the Sand, The Lynn Conway Story (Unsung Heroes of the Information Age). Unsung Heroes (published February 21, 2024). ASIN B0CW1LNGFD. ^ The Centre for Computing History (April 26, 2024). Lynn Conway - If you want to change the future, start living as if you're already there. Retrieved June 6, 2024 – via YouTube. ^ a b c \"Beautiful Daughters Cast: Lynn Conway\", LOGO Channel, 2006 ^ \"Class Notes: 2002 Inductees: Here's how many of our 2002 Hall Of Famers enjoy their leisure time and how they still give back to society\" Archived October 3, 2008, at the Wayback Machine, Doris Kilbane, Electronic Design, October 20, 2003. ^ \"Secrets Are Out: Lesbian, gay, bisexual, and transgender engineers are no longer willing to hide their true selves\" Jaimie Schock, Prism Magazine, American Society of Engineering Education, October 2011, pp. 44–47. ^ \"Lynn Conway's homepage\". Ai.eecs.umich.edu. ^ \"Status of translations of Lynn's webpages, 12-10-13\". December 10, 2013. Retrieved December 23, 2013. ^ \"Transsexual Women's Successes\". Ai.eecs.umich.edu. ^ Olyslager F, Conway L (2008). Transseksualiteit komt vaker voor dan u denkt [Transsexualism is more common than you think]. Tijdschrift voor Genderstudies, Vol. 11, no. 2, pp. 39–51, 2008. (abstract in English) ^ \"\"Profile: Lynn Conway,\" Human Rights Campaign (HRC) website\". HRC. Archived from the original on November 3, 2013. Retrieved December 5, 2013. ^ \"Biographies of famous LGBT people: Science: Professor Lynn Conway, Lesbian Gay Bisexual Trans History Month website\". Lgbthistorymonth.org.uk. Archived from the original on April 6, 2014. Retrieved December 5, 2013. ^ \"Embracing Diversity – HP employees in Fort Collins, Colorado, welcome Dr. Lynn Conway\", hpNOW, February 8, 2001. ^ \"Computer pioneer speaks from the heart about diversity: Transsexual talks at HP, CSU\", by Kate Forgach, Fort Collins Coloradoan, January 26, 2001. ^ \"Chipping Away at Prejudice\", by Sarah Wildman, The Advocate, March 13, 2001. ^ \"What's pride got to do with it?\", by Teri Warner, Employee Communications, Circuit for Employees@Intel, July 1, 2003. ^ \"Why HR should wake up to the needs of transsexual employees\", by Christine Burns, Personnel Today, November 18, 2003. ^ \"Professor Lynn Conway, Guest at Out & Equal\". Ai.eecs.umich.edu. Retrieved April 10, 2018. ^ \"Dr. Kenneth Zucker's War on Transgenders\". Queerty. February 6, 2009. ^ Antoine, Chagmion (March 6, 2009). \"Transgender Crusader – A professor at the University of Michigan is taking on the psychiatric community's ideas about transgendered people and mental illness\". CBS News / YouTube. Archived from the original on December 21, 2021. ^ a b Carey, Benedict (August 21, 2007). \"Criticism of a Gender Theory, and a Scientist Under Siege\". New York Times. ^ Dreger, A. D. (2008). \"The controversy surrounding The man who would be queen: A case history of the politics of science, identity, and sex in the Internet age\". Archives of Sexual Behavior. 37 (3): 366–421. doi:10.1007/s10508-007-9301-1. PMC 3170124. PMID 18431641. ^ Conway, Lynn (July 16, 2003). \"Shockingly defamatory official publicity by the US National Academies for Bailey's book\". lynnconway.com. ^ Dreger, Alice (March 10, 2015). \"Galileo's Middle Finger: Heretics, Activists, and One Scholar's Search for Justice\". ^ Conway, Lynn (June 18, 2008). \"Dreger's Defense of J. Michael Bailey: The Peer Commentary Papers Tear It Apart\". ^ VDay LA 2004 Commemorative Page, DeepStealth Productions, Los Angeles California, 2004. ^ \"Beautiful Daughters\", a documentary by Josh Aronson and Ariel Orr Jordan, LOGO Channel, 2006. ^ a b \"Trans Hero: Lynn Conway\". Stonewall 40: Trans Heroes. International Court System. 2009. Archived from the original on June 15, 2009. Retrieved June 14, 2009. ^ a b \"Recognizing Outstanding Transgender and Gender-Nonconforming Individuals in the Struggle for LGBT Equality\". National Gay and Lesbian Task Force. June 10, 2009. Archived from the original on September 30, 2009. Retrieved June 14, 2009. ^ Beyer, Dana (January 8, 2014). \"Leadership and the Value of Exceptional Allies\". Huffington Post. ^ \"IEEE at a Glace\". IEEE. ^ \"IEEE Code of Ethics\". IEEE. ^ McCarty, Maureen (January 13, 2014). \"The Institute of Electrical and Electronic Engineers Adopts LGBT-Inclusive Code of Ethics\". HRC. Archived from the original on February 1, 2014. Retrieved January 17, 2014. ^ \"The 2015 Trans 100\". ^ Taylor, Evan (February 4, 2020). \"Trans Activism Oral History Project - Lynn Conway Full Interview\". The ArQuives. ^ Forman, Ross (September 18, 2013) \"Transgender pioneer reflects on sports past\". Windy City Times. ^ \"A Wedding Trip to Mackinac Island\". 2002. Archived from the original on September 28, 2002. ^ Nicole Casal Moore,\"Life, Engineered: How Lynn Conway reinvented her world and ours Archived January 6, 2018, at the Wayback Machine,\" The Michigan Engineer, College of Engineering, University of Michigan, Fall 2014, pp. 42–49. ^ Marcin Szczepanski and Evan Dougherty,\"A Place to Be Wild,\" Michigan Engineering, October 8, 2014. ^ \"The 1981 Achievement Award – Lynn Conway, Carver Mead\" by Martin Marshall, Larry Waller, and Howard Wolff, Electronics, October 20, 1981 ^ \"Penn Engineering: The Harold Pender Award\". Archived from the original on July 5, 2008. ^ \"IEEE EAB Major Educational Innovation Award, 1984\". Ieee.org. Retrieved December 5, 2013. ^ \"Services Update\". Ieee.org. Retrieved April 10, 2018. ^ \"Franklin Institute honors eight physicists\", Physics Today, July 1985. ^ \"Secretary of Defense Meritorious Achievement Award, May 1985\", Meritorious Service Award, May 1985. ^ NAE Member Directory, Section 05. Archived October 4, 2008, at the Wayback Machine (year from The White House Office of the Press Secretary Archived October 3, 2008, at the Wayback Machine) ^ \"Society of Women Engineers: Achievement Award Winners\". Archived from the original on February 16, 2012. ^ President Clinton Names Lynn Conway to the Air Force Academy Board of Visitors\" Archived October 3, 2008, at the Wayback Machine, The White House Office of the Press Secretary, January 31, 1996. ^ \"100 years of engineering excellence\". Archived from the original on June 15, 2002. Retrieved August 17, 2008., Trinity Reporter, Trinity College, Hartford, CN, Winter 98. ^ \"Electronic Design Hall of Fame – 2002 Inductees\", Electronic Design, October 21, 2002. ^ \"NOGLSTP to Honor Aberson, Conway, and Raytheon at Awards Ceremony in February\" Archived October 2, 2008, at the Wayback Machine, Press Release, National Organization of Gay and Lesbian Scientists and Technical Professionals, January 25, 2005. ^ \"The Charles Stark Draper Laboratory, Members of the Corporation\". Draper.com. Archived from the original on December 10, 2013. Retrieved December 5, 2013. ^ \"\"Lynn Conway: 2014 Fellow\", Computer History Museum, 2014 Fellow Awards\". Computerhistory.org. Archived from the original on July 3, 2016. Retrieved April 10, 2018. ^ Computer History Museum (May 29, 2014). \"Computer History Museum 2014 Fellow Lynn Conway\". YouTube. Archived from the original on December 21, 2021. Retrieved April 10, 2018. ^ \"\"Lynn Conway: Fellow Award Acceptance Speech\", Computer History Museum, April 26, 2014\" (PDF). Ai.eecs.umich.edu. Retrieved April 10, 2018. ^ Computer History Museum (May 20, 2014). \"2014 Fellow Lynn Conway\". YouTube. Archived from the original on December 21, 2021. Retrieved April 10, 2018. ^ \"Oral History of Lynn Conway\" (PDF). Computer History Museum. February 24, 2014. ^ \"\"Thank Lynn Conway for your cell phone\" by Nicole Casal Moore, Michigan Engineering, 2014-04-24\". Engin.umich.edu. Archived from the original on July 1, 2017. Retrieved April 10, 2018. ^ \"Illinois Institute of Technology, ITT Commencement\", May 17, 2014. ^ \"Electrical & Computer Engineering ‹ Log In\". Muse.union.edu. Retrieved April 10, 2018. ^ Gregg Millett (March 17, 2015). \"Steinmetz Memorial Lecture on Schenectady Today\". Muse.union.de. Archived from the original on December 21, 2021. Retrieved April 10, 2018 – via YouTube. ^ \"Technology innovator to headline Steinmetz Memorial Lecture\". Union.edu. Retrieved April 10, 2018. ^ \"\"IEEE Online (Slideshow): Our Travels Through Time: Envisioning Historical Waves of Technological Innovation\", The 2015 Steinmetz Memorial Lecture by Lynn Conway, Union College, Apr 21, 2015\" (PDF). Sites.ieee.org. Retrieved April 10, 2018. ^ \"Steinmetz Memorial Lecture\". Ny6mediashare.ensemblevideo.com. Retrieved April 10, 2018. ^ \"IEEE/RSE James Clerk Maxwell Medal\", December 2014. ^ \"Lynn Conway to receive 2015 IEEE/RSE James Clerk Maxwell Medal\" Archived April 2, 2015, at the Wayback Machine, Michigan Engineering News, December 15, 2014. ^ \"2015 IEEE Honors: IEEE-RSE James Clerk Maxwell Medal – Lynn Conway\", IEEE TV, July 2, 2015. ^ \"IEEE/RSE 2015 James Clerk Maxwell Medal Ceremony and Lecture – Professor Lynn Conway\". IEEE-TV. November 12, 2015. ^ Conway, Lynn (November 12, 2015), \"Our travels through time: envisioning historical waves of technological innovation\", IEEE/RSE James Clerk Maxwell Medal Lecture, Royal Society of Edinburgh ^ Shoop, Barry (November 12, 2015). \"IEEE/RSE Maxwell Medal Citation for Lynn Conway\" (PDF). Royal Society of Edinburgh. ^ Farrar, Steve (November 12, 2015). \"Review of Professor Lynn Conway's 2015 IEEE/RSE James Clerk Maxwell Medal Lecture\" (PDF). Royal Society of Edinburgh. Archived from the original (PDF) on March 24, 2016. Retrieved June 25, 2016. ^ Linklater, Magnus (November 14, 2015). \"'Life in stealth' of a microchip pioneer who migrated to a new identity: Lynn Conway beat transgender bias and began a revolution\" (PDF). The Times (UK), Scotland Edition. pp. 36–37. ^ Conway, Lynn (March 23, 2016), \"Our Travels Through Techno-Social Space-Time: Envisioning Incoming Waves of Technological Innovation\", 2016 Magill Lecture in Science, Technology and the Arts, Columbia University ^ Adams, Jesse (April 7, 2016). \"Magill Lecture: Visionary Engineer Lynn Conway BS'62, MS'63 Heralds Dawn of the Techno-Social Age\". Columbia University. ^ \"University of Victoria News, Leaders in computing, athletics, telecommunications and public service receive honorary degrees\", September 14, 2016. ^ UVic Transgender Archives (November 22, 2016). \"Lynn Conway UVic Convocation Nov. 9, 2016\". YouTube. Archived from the original on December 21, 2021. ^ \"Lynn Conway: Honorary Doctor of Engineering\". University of Victoria. November 9, 2016. ^ Mary Sanseverino, orator (November 9, 2016). \"Professor Lynn Conway's Citation for the Degree Doctor of Engineering, Honoris Causa\" (PDF). University of Victoria. Original physical document archived at University of Victoria Libraries, Transgender Archives. Archived from the original (PDF) on June 15, 2017. ^ \"What Words Will You Leave to Guide Them\" (PDF). University of Victoria. Lynn Conway Honorary Degree Comments & Convocation Quoem. November 9, 2016. Archived from the original (PDF) on June 15, 2017. ^ \"Lynn Conway. AAAS\". Aaas.org. Archived from the original on March 7, 2018. Retrieved April 10, 2018. ^ \"2016 Fellow\". AAAS\". Aaas.org. Retrieved April 10, 2018. ^ \"O'Hara, Delia (28 August 2017). \"Sense of Wonder Motivates VLSI Chip Revolutionary, Lynn Conway\". AAAS\". Aaas.org. Retrieved April 10, 2018. ^ \"Member Spotlight. \"Lynn Conway\". AAAS\". Aaas.org. Archived from the original on March 7, 2018. Retrieved April 10, 2018. ^ Robertson, Zach (October 18, 2018). \"Computing pioneer to receive honorary U-M doctorate\". Michigan Engineering News. Archived from the original on June 15, 2019. ^ University of Michigan, Ann Arbor, Winter 2018 Commencement: Honorary Degree Recipients (December 16, 2018). \"University of Michigan Video\". YouTube. (t = 0:46:22 to 0:56:56). ^ \"Citation: Lynn Conway, honorary Doctor of Science, University of Michigan, Ann Arbor, Winter 2018 Commencement\" (PDF). December 16, 2018. ^ University of Michigan, Ann Arbor, Winter 2018 Commencement: Lynn Conway Commencement Address (December 16, 2018). \"University of Michigan Video\". YouTube. (t = 1:11:40 to 1:20:52). ^ \"2019 NCWIT Summit: Lynn Conway – Pioneer Award Ceremony\". Nashville, TN. May 16, 2019. ^ a b Alicandri, Jeremy (November 18, 2020). \"IBM Apologizes For Firing Computer Pioneer For Being Transgender...52 Years Later\". Forbes. Retrieved November 21, 2020. ^ \"Prof. Emerita Lynn Conway to be inducted into National Inventors Hall of Fame\". Computer Science & Engineering News. University of Michigan. January 6, 2023. ^ \"Lynn Conway, Very Large-Scale Integration (VLSI)\". National Inventors Hall of Fame. January 6, 2023. ^ \"10 Things You Need to Know About Lynn Conway\" (PDF). National Inventors Hall of Fame. January 6, 2023. ^ \"Providing Freedom: The Lynn Conway Story\". National Inventors Hall of Fame (Video). October 26, 2023. ^ Dodds, Io (November 25, 2023). \"'I lived a pretty adventurous life': Meet Lynn Conway, the hidden figure behind the smartphone in your pocket\". The Telegraph (US Edition). ^ Princeton awards five honorary degrees. (2023, May 30). Princeton University. https://www.princeton.edu/news/2023/05/30/princeton-awards-five-honorary-degrees ^ \"5 Honorary Degrees to Be Presented at 2024 Commencement\". April 19, 2024. ^ Maurice, Emma Powys (November 20, 2020). \"Business giant IBM finally apologises for firing a computer pioneer 52 years ago just because she was trans\". PinkNews. ^ Hiltzik, Michael (November 30, 2020). \"Column: IBM apologizes for firing a transgender pioneer, a half-century later\". Los Angeles Times. ^ Page, Sydney (November 23, 2020). \"In 1968, IBM fired Lynn Conway for being transgender – She finally got an apology\". The Lily (Washington Post). ^ Kane, Roni (November 29, 2020). \"IBM fired U-M professor Lynn Conway for coming out as trans in 1968. 52 years later, the company apologized\". The Michigan Daily. ^ Assunção, Muri (November 20, 2020). \"IBM apologizes to 'tech trailblazer' Lynn Conway for firing her for being transgender, 52 years after the fact\". New York Daily News. ^ Cramer, Maria (November 21, 2020). \"52 Years Later, IBM Apologizes for Firing Transgender Woman\". The New York Times. Further reading[edit] Saari, Peggy; Allison, Stephen (1996). Scientists: The Lives and Works of 150 Scientists. New York [u.a.]: UXL. ISBN 9780787609603. External links[edit] Media related to Lynn Conway at Wikimedia Commons Official website Authority control databases InternationalISNIVIAFWorldCat NationalNorwayGermanyIsraelBelgiumUnited StatesJapanNetherlands AcademicsAssociation for Computing MachineryCiNiiDBLP OtherSNACIdRef Retrieved from \"https://en.wikipedia.org/w/index.php?title=Lynn_Conway&oldid=1228525334\" Categories: 1938 births 20th-century American inventors American computer scientists American women academics American women computer scientists Columbia School of Engineering and Applied Science alumni Computer hardware engineers IBM employees LGBT mathematicians LGBT people from Michigan American LGBT scientists American transgender women Massachusetts Institute of Technology alumni Engineers from Ann Arbor, Michigan People from White Plains, New York Scientists at PARC (company) Scientists from New York (state) Transgender academics Transgender rights activists Transgender scientists University of Michigan faculty American women inventors Transgender history in the United States Hidden categories: Webarchive template wayback links Webarchive template archiveis links CS1 maint: bot: original URL status unknown CS1 maint: location CS1 maint: multiple names: authors list CS1 maint: numeric names: authors list Articles with short description Short description is different from Wikidata Use mdy dates from January 2021 Articles with hCards All articles with unsourced statements Articles with unsourced statements from February 2022 Commons category link from Wikidata Articles with ISNI identifiers Articles with VIAF identifiers Articles with WorldCat Entities identifiers Articles with BIBSYS identifiers Articles with GND identifiers Articles with J9U identifiers Articles with KBR identifiers Articles with LCCN identifiers Articles with NDL identifiers Articles with NTA identifiers Articles with ACM-DL identifiers Articles with CINII identifiers Articles with DBLP identifiers Articles with SNAC-ID identifiers Articles with SUDOC identifiers",
    "commentLink": "https://news.ycombinator.com/item?id=40648470",
    "commentBody": "Lynn Conway Has Died (wikipedia.org)465 points by kevvok 2 hours agohidepastfavorite69 comments mlsu 1 hour agoI recommend reading Lynn's story, written in her own words: https://ai.eecs.umich.edu/people/conway/RetrospectiveT.html It is amazing, tragic, and triumphant in so many ways. reply spencerchubb 1 hour agoparentIncredible \"The fact that I started a new career all over again, at the bottom of the ladder, after being fired by IBM and rejected by family and friends . . . may also give hope to others trapped in similar situations.\" reply meifun 59 minutes agoparentprevThank you for sharing!! Fascinating and really helpful to those of us who are undergoing our own gender transitions! reply max_ 49 minutes agoparentprevSame link without SSL errors: https://archive.is/zVIWu reply nerdponx 18 minutes agorootparentInterestingly the cert expired just a few days ago. reply barbazoo 1 hour agoparentprevThanks for sharing! In case anyone knows, what's the best way to get this to be readable on an e-reader? Haven't found a PDF yet, probably exporting into a PDF is the easiest since it's only a couple dozen pages maybe?! reply lye 55 minutes agorootparentSave as HTML with images and run through Calibre: $ ebook-convert index.html book.epub Here are the files if you trust a rando on the internet. Since they're just ZIP archives, you can unpack and inspect both to make sure there's no JS there. .mobi looks fine on my Kindle. https://0x0.st/Xc8M.epub https://0x0.st/Xc8B.mobi reply ballooney 0 minutes agorootparentA comment when an upvote would do - this is the kind of small act of generosity that I wish to acknowledge and praise in prose - thank you for taking the couple of minutes to do this. I've been feeling a little bleak about the internet lately as the SNR plummets in the tidal wave of AI seo search results, AI comments, etc. Thank you for taking the trouble. I went to EMFCamp in the UK a couple of weeks ago and had a similar resurgence in enthusiasm about simple things like asking a question of someone and getting an above-and-beyond, going-out-of-their-way response to share their enthusiasm and knowledge about something with you. We must defend these pockets of human interaction. [brought to you after a boozy work lunch but the sentiment is genuine]. barbazoo 46 minutes agorootparentprev> if you trust a rando on the internet Why did you say that, now I have to check the files :) Thank you reply michaelmior 46 minutes agorootparentprevMediaWiki2Latex can convert to ePub. https://mediawiki2latex.wmflabs.org/ reply meifun 57 minutes agoprevThank you for the inspiration as I continue my gender transition. I appreciate your struggles and dedication to living a life that was \"for you\" and not for anyone else. RIP. reply 0xbadcafebee 22 minutes agoparentSad but poignant during Pride month. Even in the US, we still have so many people who oppress those who are different, in gender, sexual orientation, relationship style, etc. Lynn suffered that oppression. Yet despite it, she achieved great things. I'll think of her whenever I see a Pride flag this month. reply startupsfail 36 minutes agoparentprevnext [6 more] [flagged] bo0tzz 34 minutes agorootparentWhat are you trying to say? reply KolmogorovComp 26 minutes agorootparentThat as a child seeing a parent struggle deeply has a very strong impact on their wellbeing? This is obviously true, but it is unclear had they not undergone transition the children would have come better. For the children it has probably not been worse than a bad divorce that unfortunately happens way more often. And to pursue the analogy, it is often hard to tell what is best for them, keep an unhappy marriage until they leave the house, or cut it short as soon as possible to leave more time to re-create stability afterwards. reply adamomada 27 minutes agorootparentprevYou don’t live your life exclusively for you after you have kids, I think reply zdimension 23 minutes agorootparentMost would agree that a trans parent is better than a dead parent, though. reply tedajax 25 minutes agorootparentprevFuck you reply mk_stjames 6 minutes agoprevI am actually part way through reading Mead & Conway's \"Introduction to VLSI Systems\" right now; I decided to go through it just for history's sake a few weeks ago. It's amazing to imagine that time period, it seemed like they were just creating so many new ideas so fast in a completely new realm; making the tools to build new processors to make the tools faster to make new processors faster... on and on and on. They published the book in 1978. We've been on that roller coaster ever since. RIP. reply nxobject 1 hour agoprevA woman of incredible courage - to be able to rebuild her career after being kicked out of IBM despite her achievements, is inspirational. And, given how even the implementation of superscalar processors confuses me, smarter than I’ll ever be for understanding that AND chip fabbing at the same time, one of humanity’s finest technical achievements. reply dekhn 1 hour agoprevI met her totally at random at a bio conference in hawaii- I sat down next to her at a bar and we started chatting. I asked what she did and she said VLSI- something I knew nothing about (I was a biologist). She was curious about biology and wanted to learn about how she could help. I looked her name up later and learned she really did work in VLSI :) reply cbanek 5 minutes agoprevLynn was a real role model for me over the past 25 years. I'm sad that I never got to meet her, but her technical impact is everywhere. reply steveklabnik 1 hour agoprevIs there a citation for this, or an announcement somewhere? The Wikipedia page was changed, but with no link backing it up, and I can't find any. EDIT: ah, found it: http://www.myhusbandbetty.com/wordPressNEW/2024/06/11/lynn-c... RIP. reply neonate 1 hour agoparenthttps://web.archive.org/web/20240611172823/http://www.myhusb... reply SnooSux 31 minutes agoprevShe spoke at my commencement a few years back. Her story is an interesting one reply kstrauser 1 hour agoprevWhat an absolute genius. RIP, Lynn. reply betimsl 1 hour agoprevGreat loss for our community. reply DonHopkins 1 hour agoprevLynn Conway, co-author along with Carver Mead of \"the textbook\" on VLSI design, \"Introduction to VLSI Systems\", created and taught this historic VLSI Design Course in 1978, which was the first time students designed and fabricated their own integrated circuits: >\"Importantly, these weren’t just any designs, for many pushed the envelope of system architecture. Jim Clark, for instance, prototyped the Geometry Engine and went on to launch Silicon Graphics Incorporated based on that work (see Fig. 16). Guy Steele, Gerry Sussman, Jack Holloway and Alan Bell created the follow-on ‘Scheme’ (a dialect of LISP) microprocessor, another stunning design.\" Many more links and beautiful illustrations of her student's VLSI designs: https://news.ycombinator.com/item?id=31758139 Also, Jim Clark (SGI, Netscape) was one of Lynn Conway's students, and she taught him how to make his first prototype \"Geometry Engine\"! http://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv.ht... Just 29 days after the design deadline time at the end of the courses, packaged custom wire-bonded chips were shipped back to all the MPC79 designers. Many of these worked as planned, and the overall activity was a great success. I'll now project photos of several interesting MPC79 projects. First is one of the multiproject chips produced by students and faculty researchers at Stanford University (Fig. 5). Among these is the first prototype of the \"Geometry Engine\", a high performance computer graphics image-generation system, designed by Jim Clark. That project has since evolved into a very interesting architectural exploration and development project.[9] Figure 5. Photo of MPC79 Die-Type BK (containing projects from Stanford University): http://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/SU-BK1.jp... [...] The text itself passed through drafts, became a manuscript, went on to become a published text. Design environments evolved from primitive CIF editors and CIF plotting software on to include all sorts of advanced symbolic layout generators and analysis aids. Some new architectural paradigms have begun to similarly evolve. An example is the series of designs produced by the OM project here at Caltech. At MIT there has been the work on evolving the LISP microprocessors [3,10]. At Stanford, Jim Clark's prototype geometry engine, done as a project for MPC79, has gone on to become the basis of a very powerful graphics processing system architecture [9], involving a later iteration of his prototype plus new work by Marc Hannah on an image memory processor [20]. [...] For example, the early circuit extractor work done by Clark Baker [16] at MIT became very widely known because Clark made access to the program available to a number of people in the network community. From Clark's viewpoint, this further tested the program and validated the concepts involved. But Clark's use of the network made many, many people aware of what the concept was about. The extractor proved so useful that knowledge about it propagated very rapidly through the community. (Another factor may have been the clever and often bizarre error-messages that Clark's program generated when it found an error in a user's design!) 9. J. Clark, \"A VLSI Geometry Processor for Graphics\", Computer, Vol. 13, No. 7, July, 1980. reply fwip 1 hour agoparentThis book was so good that I bought myself a new copy years after leaving college - the only textbook I've done that for. reply KennyBlanken 55 minutes agoprev> Although she had hoped to be allowed to transition on the job, IBM fired Conway in 1968 after she revealed her intention to transition.[19] IBM apologized for this in 2020. Given that in 2012 there was an entire IEEE magazine issue dedicated to her career and contributions to the field which really brought awareness of all her contributions...it's disappointing it took IBM so long to apologize, especially given they outed her circa ~2000. reply hyperliner 19 minutes agoparentBut it eventually happened, which is a good thing. Society does not always change fast enough. reply DonHopkins 1 hour agoprevLynn Conway co-wrote \"the book\" on VLSI design, \"Introduction to VLSI Systems\", created and taught this historic VLSI Design Course in 1978, which was the first time students designed and fabricated their own integrated circuits, including James Clark (SGI) who made the Geometry Engine, and Guy L Steel (MIT) who made the Scheme Microprocessor. She invented superscalar architecture at IBM, just to be fired in 1968 after she revealed her intention to transition, then 52 years later IBM formally apologized to her in 2020. She successfully rebooted her life, invented and taught VLSI design to industry pioneers who founded many successful companies based on the design methodology she invented, wrote the book on, and personally taught to them, and then she became a trans activist who helped many people transition, find each other, and avoid suicide, fight abuse and bigotry, and find acceptance, by telling her story and building an online community. Lynn Conway receives 2009 IEEE Computer Society Computer Pioneer Award: https://www.youtube.com/watch?v=i4Txvjia3p0 reply Upvoter33 1 hour agoprevGreat prof. Changed my entire career arc. RIP. reply minedwiz 1 hour agoprevIf this is verified, I think a black band is 100% warranted. As I understand it, she was a real innovator in VLSI, which I think we all agree is somewhat important :) EDIT: GG, the black band appeared as I sent this reply adrian_b 43 minutes agoparentWhile her contributions to the VLSI design methodologies are the best known and the most influential, that is because at that time she worked in academia, in plain sight. She had another extremely important contribution much earlier, when working at IBM, at the Advanced Computer System project. She invented the first methods that could be used for designing a CPU that can initiate multiple instructions in the same clock cycle and also out of order in comparison with the program. Such a CPU will be named only 2 decades later as a superscalar CPU (also inside IBM and by people familiar with the old ACS project). (The earlier CDC 6600 could initiate only 1 instruction per clock cycle, in program order, even if after initiation it could execute the instructions concurrently and complete them out-of-order, depending on the availability of execution units.) Her work on superscalar CPUs did not become known until much later, because it was written in confidential internal reports about the ACS project, which was canceled, unlike the later and much less comprehensive work of Tomasulo, which was published in a journal and which was used in a commercial product, so it became the reference on out-of-order execution in the open literature, for several decades. At the time when she worked at IBM, her legal gender was still male, and when she announced her intention of gender change, she was fired by IBM, which is likely to have contributed to the obscurity that covered her ACS work at IBM. Her \"Dynamic Instruction Scheduling\" report from 1966 is mandatory reading for anyone who is interested about the evolution of the superscalar and out-of-order CPUs. https://ai.eecs.umich.edu/people/conway/ACS/Archive/ACSarchi... reply DonHopkins 1 hour agoparentprevAbsolutely. I was friends with her on Facebook and enjoyed reading her many postings. She has a huge network of fans and followers whose lives she's touched. Jonathan Payne, an old co-worker and former friend of mine who I worked with at Sun on NeWS, and who also worked on Java, on two different recent occasions dropped in on my Facebook page uninvited in the middle of friendly discussions with my friends about trans and LGBTQ issues, and spouted unexpected hateful transphobic bigotry, and parroted J K Rowlings unhinged hate speech (that even was too much for Elon Musk). I was mortified and embarrassed that Lynn Conway might see what Jonathan wrote in public for all to see on my own Facebook page, and shocked that he was so obsessed with letting everyone know about his own bigotry. She's had to deal with so much abuse and hatred in her life, and selflessly helped so many people, that she and my many other LGBTQ friends absolutely didn't deserve to read the kind of vile stuff that Jonathan wrote, floating across her Facebook feed like a turd in the swimming pool, with my name associated with it. It was really disappointing that Jonathan Payne, someone I've known for 35 years, who professes to be \"progressive\", not only fell for but also spewed in public the same horrible lies that the right wing bigots have been telling about gay people for ages, and still tell about trans people now that gay people have finally been begrudgingly granted the right to marry. They cast themselves as the victim because they can't get away with being openly anti-gay any more, so they take it out even more mendaciously on trans people, using the exact same hate speech and lies about \"groomers\" and moral panic about \"not knowing what it means to be a woman\". Disgraceful. ljsprague: What he said was way too vile to repeat here, but contact me by email and I will send you a screen snapshot. Obviously he (and J K Rowling and Elon Musk) are pathologically fixated and obsessed to the point of mental illness to be that aggressive about attacking people out of the blue in public who they don't even know and who have absolutely no negative effect on their lives. In the case of Lynn, she's had a huge positive effect on all of our lives, and I'd expect a programmer like Jonathan to be aware of that. But all people deserve respect simply for being human, they shouldn't have to invent both superscalar architecture and VLSI design in one lifetime just to be treated politely. brcmthrowaway: The only thing he's the victim of are his own words, and I kept the receipts. So no. But at least he had the courage to do it under his own name, coward. reply breadbasket 2 minutes agorootparent> J K Rowlings unhinged hate speech What has she said that you would consider to be hate speech? As far as I've seen, she's just been outspoken on women's rights, especially in regard to scenarios where women and girls are at their most vulnerable. reply ljsprague 1 hour agorootparentprevWhat did Jonathan Payne say? reply minedwiz 1 hour agorootparentprevQuite disappointing to hear; I know the feeling on discovering unfortunate things coworkers believe :(. I can scarcely imagine the feeling of seeing real progress happen on trans acceptance, only to then see a blowback coming, right at the end of your life. Glad she will be remembered positively. reply brcmthrowaway 31 minutes agorootparentprevJonathan Payne can sue you for defamation for this, you know? reply sokoloff 24 minutes agorootparentAnyone can sue anyone for nearly anything. Whether they can win or not is the more relevant question and it seems like Don has evidence that he's comfortable keeping in reserve and would prefer to call out poor behavior and fade the risk of a frivolous lawsuit rather than keeping quiet and safe. reply metalliqaz 1 hour agoparentprevomg is that what that is? all this time I thought the CSS was screwed up on my browser. I had assumed it all my anti-ad/privacy plugins. reply minedwiz 1 hour agorootparentYep, loss of a prominent HN-relevant person. reply mattecypress 1 hour agoprevNot to be mistaken with John Conway, known for Conway’s game of life. reply reducesuffering 1 hour agoparentNor the Melvin Conway, of Conway's law. reply wincy 1 hour agoparentprevHonestly considering Lynn Conway’s Wikipedia profile mentions being a transgender activist and not knowing much about either of them, I thought maybe I’d just missed that John Conway had transitioned at some point, and had now died. reply someperson 56 minutes agorootparentIt really doesn't help that the Wikipedia page doesn't currently appear to state the former name anywhere, like it often does for other people (like celebrities) who legally change their names at some point in their lives. reply amysox 53 minutes agorootparentThis is in keeping with their gender identity guidelines. > Former, pre-transition names may only be included if the person was notable while using the name; outside of the main biographical article, such names should only appear once, in a footnote or parentheses. reply mlyle 45 minutes agorootparent> if the person was notable while using the name ACS was a notable project and her involvement in it, pre-transition, was notable. reply LukasMathis 36 minutes agorootparentI guess the point is that she, herself, was not notable at that point, since her work was not widely and publicly known. Otherwise we'd already know her pre-transition name. reply skyyler 32 minutes agorootparentprevA notable project where her work was confidential. Her deadname did not have achievements publicly associated with it in the way wikipedia requires. reply kragen 53 minutes agorootparentprevshe had to go to significant pains to conceal her former name because it revealed her former sex, and trans women are at significant risk of getting lynched, even more so 50 years ago reply samatman 48 minutes agorootparentprevThere's a whole set of criteria for when Wikipedia will and will not list former names for people who transition, which boils down to whether they achieved notability under the old name. Which Lynn did not. There's a conversation to be had about whether the decisions Wikipedia has made about prior names and consistent use of pronouns in the biography of trans persons is the correct one for an encyclopedia. But this is definitely not the place or time to have that conversation. reply dexwiz 1 hour agorootparentprevJohn Conway died over 4 years ago. reply wiseowise 4 minutes agorootparentprevThat’s what I thought. reply electriclove 1 hour agoprevWhy does Wikipedia not list the first spouse or children? reply amysox 56 minutes agoparentNo confirmed sources. This was discussed on the talk page. reply mattigames 6 minutes agoparentprevOr her name at birth. reply tibbydudeza 54 minutes agoprevI hope that at some point she could reconnect with her kids from her prior marriage. reply 1024core 46 minutes agoprev [–] Why does the Wiki page say \"citation needed\" for calling her a \"computer scientist, electrical engineer\"? reply waterhouse 32 minutes agoparentIf you were looking at the same revision I saw, the \"citation needed\" was on the word \"was\", and on mouseover said \"Please add credible news of death\". reply amin 40 minutes agoparentprevThe beauty of Wikipedia is that you (yes you) can add a citation in which she’s called a “computer scientist, electrical engineer”, and then remove the [citation needed]. I hope you give it a try. I’ve been editing Wikipedia for 6 years now. reply adamomada 22 minutes agorootparentThe tragedy of Wikipedia is that something like 3,000 people in the entire world are active editors (>100 edits) reply skyyler 18 minutes agorootparentBe the change you wish to see :) I edit wikipedia casually. reply m0llusk 14 minutes agorootparentprevAnd they focus largely on deletions which makes contributing frustrating. reply renewiltord 24 minutes agoparentprev [–] Outrage bait. Seriously. Here's a screenshot: https://imgur.com/a/G3lN3FR It's actually interesting that so much of this is self-answerable in so many ways: - view source - view commit history - mouseover But the helplessness of the average HN user comes to the forefront again. As Sophocles said: heaven ne'er helps the men who will not act. reply rdlw 15 minutes agorootparent [–] You're outraged that Wikipedia requires a source for the death of a public figure? reply paulspl 12 minutes agorootparent [–] No, he's outraged that someone that frequents a tech forum regularly doesn't think to check what the \"citation needed\" was for and that their first instinct was to post outrage bait reply rdlw 9 minutes agorootparent [–] Oh, that makes much more sense. I posted my comment before they elaborated on what they were saying, so the comment just said \"Outrage bait, seriously: here's a screenshot.\", which seemed like a direct response reply renewiltord 1 minute agorootparent [–] Yeah, I thought it was obvious but it clearly wasn't (I asked an LLM and it reached the conclusion you did as well) so I elaborated. GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Lynn Conway (1938-2024) was a pioneering computer scientist and electrical engineer who significantly advanced modern processors and microchip design.",
      "Despite facing discrimination and being fired by IBM in 1968 for transitioning, she had a notable career at Xerox PARC, DARPA, and the University of Michigan, and co-authored the influential textbook \"Introduction to VLSI Systems.\"",
      "Conway was also a prominent transgender rights advocate, receiving numerous awards, including an apology and the IBM Lifetime Achievement Award in 2020, leaving a lasting legacy in both technology and transgender rights."
    ],
    "commentSummary": [
      "Lynn Conway, a pioneering computer scientist and transgender activist, has passed away, leaving behind a legacy of inspiration and resilience.",
      "Despite being fired by IBM for her gender transition, Conway rebuilt her career and became a significant figure in VLSI (Very Large Scale Integration) design, co-authoring the influential textbook \"Introduction to VLSI Systems\" and teaching a groundbreaking VLSI Design Course.",
      "Her legacy is especially poignant during Pride Month, highlighting ongoing struggles against oppression and the lasting impact of her work and activism, despite facing transphobic backlash."
    ],
    "points": 465,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1718124251
  },
  {
    "id": 40646061,
    "title": "RP2040: Raspberry Pi's Cost-Effective, Versatile Microcontroller for Engineers",
    "originLink": "https://dgroshev.com/blog/rp2040/",
    "originBody": "← All posts Published: 2024-06-11 I really like the RP2040 The RP2040 is a microcontroller made by Raspberry Pi. Unlike their more widely known products, the RP2040 is meant to be embedded in consumer electronics. It's cheap and available in tens of thousands for immediate dispatch from your local Mouser. I really like the RP2040 and I want you to know why. Just the right size Here is the Mouser stock for a microcontroller manufacturer Espressif: Dozens of slightly different controllers. Why? Unlike software, physical products cost money to manufacture. Every cent saved on a gizmo's components is a cent in earnings, which adds up when the gizmos are manufactured by the million. This creates an incentive to pick a microcontroller that is only just powerful enough (to \"right size\" it), and usually microcontroller manufacturers are happy to help, offering dozens of variations of the same microcontroller. Here is the Mouser stock for Raspberry Pi: (This is the same microcontroller, just two different packaging options1.) What? …as long as it's black Raspberry Pi pulled a Henry Ford and boldly went with just one microcontroller. There is no choice, no right sizing, but that might be OK! An RP2040 costs ~70 cents, and not all gizmos are produced by the million. In return, Raspberry Pi ensured that everyone on the planet works with the same part. Compared to more traditional wide lineups, there is a disproportionate number of StackExchange questions, blog posts (including this one), experience, Github issues, libraries, and tools for the RP20402. This is a good tradeoff for projects like Late Mate, which are likely to save more on development costs than on parts3. Down the stack This single model pragmatism is evident in the choices Raspberry Pi made for the microcontroller itself. It is designed to be a jack-of-all-trades, trading \"excellent\" for \"sufficient and flexible\": Two decent cores. The second core is there if you need it. 30 GPIO pins, a very average number. No on-board flash, spending the budget on more internal RAM that is much harder to wire externally. An OK ADC, good USB support, and the usual peripherals (UART/SPI/I2C/PWM). Less conventionally, the RP2040 comes with a peripheral called \"PIO\" for Programmable Input/Output. It's like two tiny coprocessors that can execute your IO fast, with precise timing, and without spending CPU time. Some cool things people do with PIO: communication protocols like DShot ESC a fully featured USB stack on PIO, giving RP2040 a second USB controller coupled with DMA, display drivers that completely offload display+touch communication from the CPU The RP2040 is impossible to brick. It comes with a read-only bootloader that can either mount as a USB mass storage device (firmware updates can just be copypasted to the \"storage device\"), or use its own simple USB protocol. In the same pragmatic vein, the RP2040 doesn't engage in security theatre. Protecting the firmware from a dedicated attacker is nearly impossible, but there are complexity and DX costs to trying, so I'm glad Raspberry Pi made the call. I just love the deliberate design of this little square of silicon. When I work with it, I can see how smart people thought hard about the niche the RP2040 is in and drove the tradeoffs accordingly. As an engineer aspiring to be good someday, I appreciate it. Discuss on Hackernews More of ^this^ on Mastodon, Twitter, RSS, or a very occasional newsletter. Or just let me know what you think at dan@dgroshev.com! 1 Shout out to axoltl for a correction.↩ 2 In particular, Rust support is excellent and examples are plenty (firmwares for keyboards, drones, football robots, …).↩ 3 I suspect that it might not even be so clear cut on costs, since Raspberry Pi is likely to enjoy economies of scale producing just one part.↩",
    "commentLink": "https://news.ycombinator.com/item?id=40646061",
    "commentBody": "I like the RP2040 (dgroshev.com)286 points by dgroshev 5 hours agohidepastfavorite205 comments peteforde 2 hours agoI also like the RP2040, but I'd like to explain why I migrated away from it for my current project. First, the drama with PlatformIO really rubbed me the wrong way. I'm taking the side of the developers who are hurt by confusion in tooling. Second, the top of the line ESP32-S3 comes in a module format that can be dropped on a PCB with basically nothing but a few decoupling capacitors. The RP2040 requires careful placement of about a dozen components, including a crystal. Not only does a module reduce implementation complexity dramatically, standardization skips every engineer potentially making their own dumb component placement mistakes. Third, the ESP32-S3 has 14 GPIO pins that can be configured to do capacitive touch, while the RP2040 has none. Most of the projects that use RP2040 and capacitive touch rely on the MPR121, an IC that past its EOL and will likely cause a lot of hasty redesigns over the next few months. It's also worth saying that eventually RP2040 will likely release more or less powerful versions, and hopefully versions in a module format. I doubt they will ever let it become an STM or PIC situation, but the ESP32 product lineup doesn't look so crazy once you are acclimatized to it. reply geerlingguy 2 hours agoparentIt seems like Espressif are in the same situation as Pi w/r/t PlatformIO[1]. As an outsider, it sounds like PlatformIO was trying to extract a very large annual payment from RPi and Espressif, and that was after the initial support was added in, and some of the community started adopting it. It's a weird situation, but I think PlatformIO built up a dominant position by supporting all these platforms and accepting community contributions to do so, then tried extracting value from the manufacturers directly after the fact, blocking further community PRs that would add new board revisions or fix bugs. See related: [2] [1] https://github.com/platformio/platform-espressif32/issues/12... [2] https://github.com/platformio/platform-raspberrypi/pull/36 reply peteforde 2 hours agorootparentThanks for all of your rational contributions to those many threads, Jeff. It is an extremely weird situation, and a deeply bad look. If I was pressed for an opinion, I would say that I wish Eben had taken the high road and gone all in on supporting PIO despite the tangy mystery aftertaste for the simple reason that it would be a net-positive for developers. The way things stand, migrating away from the Arduino IDE to using VSCode with RP2040 feels like you're being actively messed with; there's so many projects and forum posts that sound like the right path, when it seems like the actual answer should be super simple. This is super painful for newcomers. reply gchadwick 1 hour agorootparent> It is an extremely weird situation, and a deeply bad look I never followed all the ins and outs but from having a quick look through the comments on https://github.com/platformio/platform-raspberrypi/pull/36 the following happened: - Developer independent of RPi opens PR to add RP2040 support to PlatformIO - PlatformIO don't want to merge it, expecting some financial contribution to help maintain the support (seems reasonable) - They discuss this with RPi, ultimately RPi don't want to pay the asked contributions so that PlatformIO are happy maintaining support (this also seems reasonable) - End result is no RP2040 support in PlatformIO Ultimately maintaining things isn't free. RPi have chosen the development environment(s) they wish to support and it hasn't included PlatformIO. What's weird or a bad look? reply sangnoir 43 minutes agorootparent> Ultimately maintaining things isn't free. This is a hypocritical stance for any project that accepts free contributions from the public. Besides rent-seeking, what reason could justify preventing the community from maintaining features/microcontrollers that the organization is unwilling to (due to costs)? reply KaiserPro 22 minutes agorootparent> Besides rent-seeking, what reason could justify preventing the community from maintaining features/microcontrollers that the organization is unwilling to (due to costs)? Platformio I suspect. reply throwup238 1 hour agorootparentprevCan you provide a TLDR to what the state of things are? I was under the impression that ESPHome was built on top of PlatformIO so this sounds scary... reply zbrozek 34 minutes agoparentprevI really don't think there's any significant value to be gained by turning this into a module. Everyone wants a slightly different form factor and the thing is so easy to design around that a module isn't meaningfully achieving anything. Touch is a niche single tasker. I'm glad they didn't include it. Using another ic for that makes sense, and folks being lazy and sticking to an EOL part to provide that functionality isn't RPi's problem. Or do it in software. I'm with the OP on this one, I really think the foundation nailed the product definition. reply aswanson 12 minutes agorootparentThe pico board is the de facto module for me. Very cheap and breaks out every useful signal. reply crote 1 hour agoparentprev> The RP2040 requires careful placement of about a dozen components, including a crystal. To be fair, the chip is designed to make these really easy to place. There's pretty much one single layout which makes sense, and it provides easy access to all the pins you could possibly want. Combine that with the excellent documentation they have provided, and it's essentially just a multi-part drop-in design you don't ever have to think about again. It did look a little bit intimidating at first, but it was a genuinely pleasure to implement. reply peteforde 1 hour agorootparentYou're kind of making my point for me; when every engineer has to place a dozen components, a non-zero number of them are going to make facepalm mistakes. Even if you create a sub-module layout that you include in every project you work on... that's still n slightly different permutations of the same thing, even if they are all perfect. (They aren't.) reply adriancr 1 hour agoparentprev> First, the drama with PlatformIO really rubbed me the wrong way. I'm taking the side of the developers who are hurt by confusion in tooling. I'm out of the loop, have been using rp2040 since launch and never used platformIO. How did you use it and what rubbed you the wrong way? Developing locally either with cmake and pico sdk or micropython seems very easy... why add platformio in the mix? reply danhor 2 hours agoparentprevThe Pi Pico is intended to be the module format (and can be delivered on reels and used with some PnP machines), though it is much larger than it needs to be for this purpose (and this might be why you didn't mention it). I have only implement touch buttons for hobby projects using a different MCU, but is there a reason to not just use the PIOs for touch sensing? reply peteforde 1 hour agorootparentI can appreciate intentions, but a Pi Pico does not compare favorably to a chip module in any regard. It's huge, it only exposes 26 GPIOs. I'm not saying Pico sucks by any means. It has uses and places. It's just very not this: https://www.digikey.ca/en/products/detail/espressif-systems/... reply petsfed 1 hour agoparentprev>Not only does a module reduce implementation complexity dramatically, standardization skips every engineer potentially making their own dumb component placement mistakes. And we've never found a way around that for the decades we've been putting Atmel, STM, TI, Ambiq, Nordic, etc chips in our designs... There's an intern 2 yards away from me who will be wrestling with getting the right components in place around an STM, for his very first pcb design. This is not a hard problem for anyone who has been doing this for any period of time. And anyway, those dozen or so components are the oscillator/crystal circuit, the reset holdup, and the 3.3v supply. And then like a bazillion decoupling caps. Certainly, antenna tuning can be hard, but if you can use chip antennas, its not that hard. All of those are so bog standard that when I looked at e.g. the adafruit RP2040 Feather's schematic, I was sort of surprised at how much is just lifted wholesale from all of their other feathers. Like, the only difference between the RP2040 feather and the nRF52840 feather is the micro itself, the timing circuit (all 5 components of it for the RP2040), and the antenna circuit for the Nordic board. As to the convenience of modules, I submit that they are very handy for sale to the hobbyist market, but if you want to actually sell your products, you still have to go through the process of RF certification (although at a lower cost. Only you can decide if the higher upfront cost of using a module vs. spinning your own is offset by the lower certification cost), so the benefit is a lot more mixed. Even so, you're only saving the antenna tuning step, which is usually done as a BOM variation, not a major trace adjustment. As to the dozens of STM and PIC chips, TI has the same situation. Customers want to pay for only what they need and those manufacturers have the manufacturing capacity to support that desire. Its not daunting if the difference matters. This is very much akin to complaining that Home Depot sells too many different kinds of lumber. As for capacitive touch ICs, sure Adafruit only carries one. But mouser carries 199 that are not end of life. To keep that functionality going, adafruit need only pick up one of them. The cheapest one is even in a TSOT package, so the DFM will be pretty easy. Hell, if I'm not too tired from my job designing and programming these things, I might go home and spin one up tonight. Ought to only take me an hour or so. And the I2C driver another couple hours. reply aswanson 11 minutes agoparentprevPico board is the module. I agree that placing the xtal etc is too much. reply SAI_Peregrinus 1 hour agoparentprevI did manual capacitive touch on an ATMega328. Peripheral support is easier and more reliable, but not strictly necessary. You \"just\" need a GPIO with analog input and a timer. reply 127 2 hours agoparentprevYou can do capacitive touch with RP2040 just fine. Turn on, turn off, measure time. Plus I don't like modules as they seem pointless complexity when I just want to order a ready-assembled, self-designed PCB. reply _Microft 5 minutes agorootparentI also didn‘t understand this complaint. On a Pico, any GPIO can be used for touch. reply olabyne 1 hour agoparentprevwhat is the drama with platformIO ? reply peteforde 1 hour agorootparenthttps://github.com/platformio/platform-raspberrypi/pull/36 reply flohoff 3 hours agoprevThe issue is that its a comparison about apples to peaches. The RPI2040 is JUST the chip whereas the ESP32 come with tons of peripherals for your liking. From Wifi/Bluetooth Antenna, LI Battery Controller, Ethernet whatever, Display or Camera Connector - You choose. And then we have a multitude of even CPU choices and when running on a coin cell it makes a difference powering a second, unnecessary core or even wifi. And with the C6 variants, Espressif even switches ISA again, from 8266, to ESP32 to a RISC-V based ISA. So you are comparing the first of its kind SOC with a decade old Family of SBCs. reply snufkin97 3 hours agoparentYou're right about the technicals, but I think its about the use cases. RP2040 is indeed one of its kind and is suddenly a great choice for so many projects, both hobby/educational and proffessional embedded devices. With its price vs possibilities it just covers soooo much when You know it's just one single chip version. To me, this is what tech progress is all about. reply HyulianGrader 3 hours agoparentprevIt's safe to assume he's talking about the chip in both cases. You can connect either of them to a battery charger, camera, or nuclear reactor but all of those 'peripherals' are completely irrelevant to this comparison. reply milesvp 1 hour agorootparentFYI. In the embedded space, peripherals refer to the chip's built in capabilities. Typically there is a peripheral that handles SPI, a peripheral that handles I2C, a peripheral that handles USART. There might be a peripheral that handles USB, or I2S, or any number of different abilities. It's either transistors or microcode on more sophisticated MCUs that allows these peripherals, and not every pin is connected to every peripheral, which can make chip selection even trickier. It really sucks to start designing around a chip that looks like it does everything you need with enough pins to only find out that once you start doing pin layouts you can't use both USART2 and I2C because they use the same pins. Worse, is when the datasheet makes this difficult to discern, and you only find out when doing some firmware work on a devboard. reply 0x457 1 hour agorootparent> Worse, is when the datasheet makes this difficult to discern, That's why I like RP2040 so much. Datasheet is amazing and clear, even for someone like me who hasn't spent too much time in embedded world. There is a special, much shorter document just for hardware design that makes designing a board that uses RP2040 even easier. reply HyulianGrader 1 hour agorootparentprevFYI the RP2040 has peripherals too, a lot of the same ones. It's very clear that GP has an odd misconception that an ESP32 is some kind of development board complete with \"connectors\" and possibly a battery charger, while an RP2040 is just the SoC itself. reply croes 13 minutes agorootparentprevBut if it's about the chip then just grab any ESP32. reply sophacles 3 hours agorootparentprevSo is GP. The silicon chip itself for an ESP has: bluetooth, ethernet, wifi, SD/EMMC, and a bunch more \"peripherals\" built into it. The RP2040 does not. To make this painfully clear: For an esp32 to do wifi you wire the esp32 to an antenna. For an RP2040 to do wifi you wire the 2040 to another chip, and that other chip to an antenna. Do you see the difference? reply HyulianGrader 3 hours agorootparentNo, that's both \"just the chip\", the chips have different peripherals. They both have the usual SPI, I2C, UART, ADC, etc., and they have their differences too. I could just as well say \"For an RP2040 to do USB you wire the RP2040 to the connector. For an ESP32 to do USB you wire the 32 to another chip, and that other chip to a connector.\" It's clear to me GP has the impression that ESP32 is something more (a development board with an ESP32?) than the ESP32 \"chip\" itself. reply krisoft 2 hours agorootparentMaybe look at the ESP32 chip's datasheet? [1] This is the first sentence in it: \"ESP32 is a single 2.4 GHz Wi-Fi-and-Bluetooth combo chip designed with the TSMC low-power 40 nm technology.\" That's the chip. Not the development board. 1: https://www.espressif.com/sites/default/files/documentation/... reply Aurornis 2 hours agorootparentThe Espressif chips are available as cheap modules, and frequently used as such. People generally refer to the module, not the isolated chip. The modules are effectively like a chip that you solder to the board. reply 0x457 1 hour agorootparentModules are \"just\" chip + all necessary hardware to start + antenna connector/pcb antenna. Those modules don't add any functionality to the chip. The main benefit of those modules is: it's already certified with FCC and others, so you don't have to re-certify your design for radio communication. Since RP2040 does not have a radio, this is unnecessary. reply HyulianGrader 2 hours agorootparentprevWhat part of that contradicts my comment? To be clear, GP is the one saying the ESP32 is more than just the chip itself, complete with battery controller and camera connector. reply moefh 2 hours agorootparentprevGP is clearly talking about ESP32 boards, not the chip; they mentioned \"LI Battery Controller\", and \"Display or Camera Connector\". People sell RP2040 boards with those too, for example: - board with a battery charger: https://learn.adafruit.com/adafruit-feather-rp2040-pico/powe... - board with camera: https://www.waveshare.com/pico-cam-a.htm reply Aurornis 2 hours agorootparentESP32 is available as a tiny module that is soldered to the board as if it was a chip. Ignoring the module results in a flawed comparison. The module is chip and frequently used. If they encased the module in plastic and called it a chip, it would be the same. You can think of it as a chip. reply moefh 2 hours agorootparentDo they sell chip-like modules with camera connectors and battery controllers, though? I don't deny that ESP32 modules look like and are soldered as though they were chips, but to me it's clear that GP was mixing up chips (and chip-like modules) with boards. reply jvanderbot 1 hour agoparentprevIs there a non-Chinese version of ESP that compares in terms of module integration re: Wifi et al? reply kragen 11 minutes agorootparentno, of course not reply smcameron 3 hours agoprevWe've been using the RP2040 in the electronic badges[1] for the RVASec security conference[2] for the past several years, and it's been very nice to write software for. Here's the github repo for this year's badge (there's a software-only badge simulator so you can kind of play around with it even without the hardware, although some of the multi-player things that rely on infrared badge-to-badge communication won't be any fun): https://github.com/HackRVA/badge2024 [1] Video of the 2023 badge: https://www.youtube.com/watch?v=KWZriUMNpLc [2] https://rvasec.com/ reply MegaDeKay 4 hours agoprevThe PIO's really are the star of the RP2040 show, giving it a capability that competing chips like the ESP32 can't match. They are appearing all over the place in the console hacking space for this reason. Lower power consumption in steep modes for battery-backed applications would be a welcome addition in any V2 version though. reply jsheard 4 hours agoparentThings like battery life will probably improve with experience, I was talking to a silicon guy about the RP2040 and they said it's pretty characteristic of a first generation design. The digital logic that can be validated on an FPGA is fine for the most part, but the analog elements are much more difficult to fine tune, hence the poor power consumption, poor ADCs, and lack of internal DACs or opamps in the RP2040, and why the Pico Ws radio is a separate off-the-shelf part rather than fully integrated like it is on the ESP32. reply dgacmu 2 hours agorootparentThough it's a continuing puzzle to me why ESPs have worse ADCs than the rp2040, given their relative maturity. (Neither is particularly good, mind you, but I'm generally ok with the rp for my toy applications.) reply nimish 2 hours agorootparentprevAnalog is large area and expensive in general so sticking to good digital and passable analog is a very good strategy to keep costs down. reply dragontamer 2 hours agorootparentModern Microcontrollers focus on analog because modern microprocessors start at like $5, maybe even cheaper. If you need digital girth, don't mess with lol 264kB RP2040 systems. Just buy $3 of DDR3L RAM (aka: 128MB) and run Linux for goodness sake. --------- Even ESP32 is a glorified Bluetooth/Wifi chip first and everything secondary. You have to have a niche at this price point to be competitive. RP2040's niche is the 264kB of SRAM, but not much else. It needs a bunch of external parts before it can become a reasonable solution as well, so its not really cost optimized IMO. reply crote 1 hour agoparentprevThe most annoying part about the PIO is that there are only two of them (though with 4 sub-units each), they only have space for 32 instructions, and they don't have an external clock input. They are great for implementing very basic peripherals, but more than once I've started to implement something more complex just to realize it would be unacceptably slow and run out of space. If they were to beef them up just a little, they could easily replace the more trivial FPGA applications. reply dvdbloc 4 hours agoparentprevWhere can I learn more about how they are used in console hacking? This sounds very interesting reply MegaDeKay 2 hours agorootparentHere you go. There might be more but these are all I can think of off the top of my head. Nintendo Switch modchip - PicoFly: https://github.com/rehius/usk. That is the OG source of the firmware behind the already mentioned https://github.com/Ansem-SoD/Picofly OG XBox Modchip - Modxo: https://github.com/shalxmva/modxo (see initial impressions from ModzvilleUSA at https://www.youtube.com/watch?v=uUsov3i6jL0) XBox360 NAND reader / writer - Picoflasher: https://github.com/X360Tools/PicoFlasher (used in the RGH3 hack for some versions of the console as described at https://consolemods.org/wiki/Xbox_360:RGH/RGH3) Gamecube Modchip - Picoboot: https://github.com/webhdx/PicoBoot Gamecube Optical Drive Emulator - Flippydrive: https://github.com/OffBroadway/flippydrive as described at https://teamoffbroadway.com/ reply mewse-hn 2 hours agorootparentThe flippydrive is such a nice, clean install on a gamecube that it leaves me wondering if the rp2040 could make better ODE's for every other console (psx, saturn in particular) reply nereye 3 hours agorootparentprevOne use case is related to the Nintendo Switch, as mentioned in another post. E.g. see https://github.com/Ansem-SoD/Picofly. reply JAlexoid 3 hours agoparentprevComparing ESP32 to RP2040 is like comparing oranges to apples. If you need a lot of IO - you're probably not looking at ESP32. It's just cheap and has WiFi builtin. There are many options for other MCUs, that compare favorably to with RP2040... though majority aren't for the hobbyist market. reply moffkalast 3 hours agoparentprevDitto for robotics. 8 PIO units are enough to read and log four quadrature encoders at practically no interrupt cost, so it's possible to build a perfectly performant closed loop controller in something as slow as Micropython. reply axoltl 4 hours agoprev\"(This is the same microcontroller, just two bugfix revisions.)\" It is exactly the same microcontroller! They're just two different packaging options. One is a 7\" reel with 500 units the other is a 13\" reel with 3400 units. (See \"Ordering code\" in the datasheet (https://datasheets.raspberrypi.com/rp2040/rp2040-datasheet.p...)) reply jsheard 4 hours agoparentThat said they have done a few bugfix revisions, RP2040-B0 is the original, -B1 has some refinements to the ROM code, and -B2 has further ROM changes and also fixes some silicon bugs from the earlier versions. If you're using the official SDK you probably don't need to care too much about which version you have though, because the standard high level libraries detect the hardware revision at runtime and enable or disable workarounds as needed. reply dgroshev 4 hours agoparentprevOoops, you're right! Fixed & attributed. reply antirez 4 hours agoprevI switched from ESP32 to the RP2040 because it's a much more reliable and documented device. My only concern right now with the RP2040 is that there are many ESP32 models with SPIRAM but it's not so simple to find a SPIRAM equipped RP2040 board. To be honest, given that the C development environment of the RP2040 is so good, you can make good use of the memory, but when one wants to develop a large MicroPython project, the SPIRAM is really a great asset. Other than that, everything about the RP2040 is just great. reply dgroshev 4 hours agoparentI ended up cutting a section on Rust support from the post, but if you're open to Rust (iirc you were sceptical at some point?), async Rust is really pleasant to use in embedded. Dario Nieuwenhuis, one of the main people behind Embassy, gave a great overview talk at RustNL: https://www.youtube.com/watch?v=H7NtzyP9q8E reply antirez 3 hours agorootparentThanks, I prefer using C :) But happy that there are options out there. reply the__alchemist 3 hours agorootparentprevI disagree. Rust on embedded is fantastic (I do STM32 programming on rust all the time, and have used the RISC-V ESP chips and nRF-52 as well), but Async Rust on embedded suffers from the same problems of contagion and coloring that non-embedded async rust has. reply fleventynine 3 hours agorootparentEverything had tradeoffs, but the composability of the state machines built by the compiler's async support allows you to easily build multi-tasking bare-metal systems with thousands of \"tasks\" and no RTOS (or SRAM-wasting threads). I highly recommend playing with Embassy for a week before discounting this approach for embedded software. If you care about RAM consumption, you need to share the stack between tasks, forcing you to write event-driven code. Rust async makes this easy, and a bit of function coloring is no big deal compared to converting blocking code into event-driven code the traditional way... reply the__alchemist 3 hours agorootparentI have - it does not avoid the structural and compatibility problems of Async in other contexts. reply fleventynine 3 hours agorootparentCan you go into more details? Most of the criticism I've read tends to be more abstract (\"I don't like how ALL my blocking-style calls need to be async\"), and doesn't propose an alternative mechanism to async that can provide a similar coding style in the same tight RAM footprint. reply the__alchemist 3 hours agorootparentI think you'll find details regarding any discussion of async in rust and other languages - I don't mean to casually dismiss your question, but my objections are not unique. The alternative mechanism is to use interrupts, DMA, multiple cores, distributed devices (eg a CAN network) a state machine, an RTOS, or, it sounds like in context of this thread, PIOs! You get the point. Do these provide a similar coding style? No, and that's the point. The coding style is the objection. I find the \"how else would you do it\" style questions that come up frequently re Async rust (embedded or not) amusing. It's as if there is a new method of accomplishing a task, and asking a world that has been accomplishing this task for decades how it's possible to accomplish the task without the new thing! reply fleventynine 2 hours agorootparentAs I see it, if you need everything to run on a single cpu core, the alternatives are to either implement threads (wasting memory on redundant stacks) or to write the event-driven state machines manually. Whether the state machine is pumped by interrupts or not doesn't change anything IMHO. Because of RAM constraints, all the bare-metal projects I've worked on have used manually-written state machines, and I'm comfortable enough with this approach. But sometimes these state machines can be hard to understand when the control flow is complicated, and I am seriously considering adding some compiler-generated state machines that will fit nicely into my existing model. reply kragen 3 minutes agorootparentnone of this will be news to you, but it's probably of interest to other people reading the discussion. you can do stuff inside the interrupt handler itself, and while what you do there does have to be an event-driven explicit state machine, interrupts introduce two key differences: - the rest of your program doesn't have to be an explicit state machine; it can use structured control flow with nested loops and conditionals and subroutines - the interaction between the interrupt handlers and the rest of the program is almost completely asynchronous, because as long as interrupts are enabled, the interrupt can fire between any two instructions of the rest of the program; if you look at it as multitasking, it's preemptive multitasking rather than cooperative multitasking. preemptive multitasking introduces a lot of hairy error cases, and this is only moderately simplified by the fact that the rest of the program can't preempt your interrupt handler, only vice versa. arguably that makes the problem worse rather than better because you can't solve the problem with locks (except by disabling interrupts as a sort of global lock) nickcw 4 hours agoprevIf you are an electronics hobbyist but don't want to make/design your own surface mount boards (like me) there are lots of very accessible RP2040 boards at very low prices. I've used it in the Raspbery Pi Pico ($5) which comes on a nice board with lots of IO. There is a W version for a bit more with WiFi. If you don't mind slightly less IO then you can order an RP-2040 Zero. I got 6 off AliExpress for about $12. These only have 23 IO pins but they have a reset button, USB-C and are tiny (1.5cm x 2.5cm). The nice thing about all of these is that they use the standard Raspberry Pi dev tools, micropython, C++ just works with convenient USB loading of the firmware. reply willis936 3 hours agoparentI like to shout out the pico ice. Most of the $30 price tag is for the UP5K tied at the hip, but for embedded projects where you have some sub-microsecond activities it's a (relatively) inexpensive option with open source tooling. reply crote 1 hour agoparentprevI also highly recommend shopping around for alternative RP2040-based dev boards. The official Pi Pico is surprisingly bad, and just about every alternative out there is better in one way or another. I mean, come on: no reset, huge form factor, only 2Mbit flash, micro USB - in 2024? Just about the only pro it has is that it is widely available. reply moffkalast 2 hours agoparentprevUnless you're incredibly space constrained I don't really get the point of that 2040 Zero, it just costs more for fewer features. The Pico is already pretty tiny. The Pico is really good at pin interoperability at least, in the land of ESP, what appears to be lots of IO pins quickly turns into barely enough if you're lucky, with pins connected internally to flash or the bootloader or whatever. I really wonder why they even bother breaking those out. The ESP32-CAM comes with 10 data pins, and only 4 of them are actually generally usable lol. reply dgacmu 2 hours agorootparentI think it's about the clones on aliexpress, which are about $2.50, vs $5 for the pico. reply weinzierl 1 hour agoprevI think the PIO state machines are pretty cool and relatively unique. I am also glad the Foundation resisted the temptation to market them as extra cores and sell the RP2040 as 10-core processor. When it comes to the Raspi Pico and similar devices[1], I think UF2 flashing is the best thing since sliced bread. This alone lowers the barrier for beginners significantly. Things I don't like: power consumption. But you can't have everything... [1] I know it is not restricted to RP2040 boards, but I think it is nowhere as common as there. reply mdp2021 1 hour agoparent> Things I don't like: power consumption I understand it could use ~0.08W, given it draws 3.3V at ~24mA... I am not a specialist, is that a lot? Ref.: https://learn.sparkfun.com/tutorials/rp2040-thing-plus-hooku... reply dragontamer 1 hour agorootparentTI's MSPM0G350x (also a low-cost Cortex-M0+ design) runs full-tilt at 8mA, STOP-sleeps at 400uA, STANDBY-sleeps at 5uA, and SHUTDOWN-sleeps at 80nA. https://www.ti.com/lit/ds/symlink/mspm0g3507-q1.pdf -------- RP2040's full-speed is okay. 20+mA is a lot but it is easily explained by the absurdly huge SRAM banks it has. But RP2040's sleep states are absolutely AWFUL. The Cortex-M0+ chips are all extremely power-competitive vs each other, because Cortex-M0+ is extremely low-end with regards to core-design. You're pretty much only getting a Cortex-M0+ because its the absolute minimum 32-bit processor on the market. (8-bitters and 4-bitters exist if you're willing to go even lower-end, but Cortex-M0+ is the bottom of ARM's offerings). So low-power seems to be a must in this market, IMO anyway. If you're willing to use higher amounts of power, you really should get a few more features, like an FPU on the Cortex-M4. reply seba_dos1 55 minutes agorootparentprevYes, it's a lot. It will empty a 1000mAh battery in about two days. In sleep states, you'll find it challenging to reach a single month on RP2040 while you can build things with other controllers that would last years on the same battery. reply uncletaco 2 hours agoprevRP2040 has single handedly reinvigorated a really niche market: custom controllers. Due to the wonderful work done on gp2040[1] which is open source game pad firmware, people can buy cheap, quality, fightsticks and leverless controllers for a lot cheaper than they can from vendors like Victrix or Razer. Not only that but because its open sourced the hobbyist side of the controller community are building RP2040 pcbs to accommodate all kinds of projects and weird controller ideas. [1] https://gp2040-ce.info reply crote 1 hour agoparentI do wonder how much of that can be accounted directly to the RP2040. Projects like QMK[0] have been using a technically quite similar codebase for making DIY keyboards for quite a while now. At first glance I'm not really seeing anything in GP2040 which couldn't have been done with any other somewhat-modern MCU. The RP2040 has undoubtedly been the catalyst leading to GP2040's widespread adoption, but it seems the same could've happened with a Pro Micro instead. [0]: https://github.com/qmk/qmk_firmware reply JohnFen 3 hours agoprevThe RP2040 is pretty cool. I've used them in a half dozen projects now. > Raspberry Pi pulled a Henry Ford and boldly went with just one microcontroller. However, this one size fits all thing doesn't work for me. I prefer to use the least microcontroller that will do the job I need done. > There is no choice, no right sizing, but that might be OK! An RP2040 costs ~70 cents, and not all gizmos are produced by the million. The reason I like to use the wimpiest microcontroller possible is not related to monetary cost. It's related to my power budget. Most of my projects are battery-powered, and having them use the least possible amount of juice is a huge advantage. But even so, why use a $1 microcontroller when a 20 cent one will do the job equally well? reply crote 1 hour agoprevI have mixed feelings about the RP2040. On the one hand, it's a great chip for hobbyists. It's cheap, it's easily available, it's easy to build a board around, and it offers plenty of stuff for your average application. On the other hand, it's definitely a bit lacking from a professional perspective. The peripherals are fine, but once you start looking into the details it's easy to run into limitations. That XIP interface is great - but it doesn't support writing so you can't hook up an FRAM chip and expand your memory. That PIO interface is amazing - but having only 2x32 instructions is quite limiting once you try to implement more complex interfaces. And where are my Timer/Counters? No capacitive touch? Analog on only four pins? No 5V tolerance? No high-speed clock input for the PIO modules? Why can't I run the bootloader off the internal ring oscillator? Hmm, a USB-C PHY sure would've been helpful... I was also surprised about its poor ESD performance. An Atmega or STM32 can handle the occasional zap just fine - ESD protection is more of a nice-to-have on external-facing ports. The RP2040? If you don't add external protection to every single pin you are basically guaranteed to see a few of them die due to day-to-day use. To summarize: neat chip, great for hobbyists, wouldn't be my first choice in professional environments. reply dfox 1 hour agoparentI suspect that the Synopsys DesignWare SSI macro in RP2040 can in fact be used for R/W PSRAM or FRAM, but the abridged documentation of it in RP2040 datasheet is not sufficient for one to configure it that way. reply ChiefNotAClue 1 hour agoparentprevWell said. I'll add that, as a hobbyist, you'll eventually work on more involved projects and run into those exact limitations. reply doubloon 1 hour agoparentprevRaspberry pi was originally an educational non profit reply stefan_ 1 hour agoparentprevWhat do you mean by USB-C PHY? USB-C is the connector, and you can run USB 1.1/2.0/3.0/3.1 through it, but realistically a RP2040 can not feed even a USB 2.0 PHY. reply HyulianGrader 4 hours agoprevnit: There are 6 different espressif microcontrollers in that table, not \"dozens\". Espressif also went many years with only the ESP8266, then many years more after introducing the ESP32 before this recent binge of releasing a new series every time they blink. ESP-IDF is really suffering for it, so I hope Raspberry avoid this fate or at least find a better way to support them all. reply rdlw 3 hours agoparenthttps://products.espressif.com/#/product-selector?language=e... This is the official Espressif \"ESP Product Selector\". I checked everything in the ESP series, and limited to \"Mass Production\" status, and then it showed me a list of 175 products. I'm sure some of those are doubled up, or just the same chip with different packaging options or whatever, but as a potential customer I'm still presented with 175 things and told to pick one. reply dfox 1 hour agorootparentMost of that are not bare microcontrollers (or “SoC”s as Espressif calls it), but entire modules with different combinations of SoC, Flash, PSRAM, antenna configuration and packaging. If you filter only SoCs, you get 39 products, which in fact are 9 different chips and rest are packaging variants and versions with package-on-package Flash. reply em3rgent0rdr 4 hours agoparentprevConsidering how many different Raspberry Pis are out there now, I wouldn't be surprised if the Raspberry Foundation makes a plethora of newer microcontrollers. reply ajsnigrutin 3 hours agoparentprevMany of the variants listed are the same chip but with different amounts of storage, oboard vs external (vs both) options, etc. reply djfergus 3 hours agoprevFor hobbists buying dev boards note that an ESP32 comes with WiFi and maybe Bluetooth depending on the model, whereas a vanilla Pi Pico has no radio - you need a Pi Pico W for that, which in my experience is double the cost of an esp32 board. I agree with the authors points that the RP2040 is a great chip would love to see the Pico W pricing come down as popularity grows. reply AtillaBosma 1 hour agoprevI want to shout out the fighting game community with: https://gp2040-ce.info/ It has been using the RP2040 to create cheap and easy to make controllers for fighting games while providing the lowest possible input delay. The RP2040 does a great job acting as a chip for the base of a gamepad, so it doesn't even have to be for a fighting game controller, but any controller you want to create. reply Havoc 4 hours agoprevHow are people using this in practice? I’ve never worked with a BGA device. I’m guessing you need to design a board send it to say pcbway and then have the equipment to solder the bga in? reply dave78 3 hours agoparentI built a custom RP2040-based board by designing it KiCad and then sending it off to JLCPCB to be fabbed and they assembled the SMT components. I didn't do a direct comparison, but it was cheap - cheap enough that it's possible that getting the board pre-assembled from JLC was cheaper than buying the raw parts in low quantities from Digikey and assembling it myself (which, given my experience level, would be pushing the edge of my capabilities). I made a second run recently and even added some through-hole to the assembly and the board cost was still single digit dollars per board. The major problem was that shipping prices from JLC seem to have gone up significantly in the past year. Keep in mind that it's not just the RP2040 that is difficult to solder. To do a decent PCB layout you'll need to use very small passives in order to get the placement right. I did my layout with mostly 0402 resistors and capacitors - I know plenty of people are capable of hand-soldering those but I think it would be difficult for most. Perhaps easier if you had a decent microscope, which I do not have yet. I don't think my magnifying visor would be nearly enough. reply dragontamer 1 hour agorootparent> To do a decent PCB layout you'll need to use very small passives in order to get the placement right. 0402 (inches) is small but doable. They really start to feel like grains of sand at that point. But I personally stick with 0805 and 0603 when doing my own board layouts. I can't say I've ever felt space constrained. The placement of decoupling capacitors can be a few mil off, and in fact the \"extra space\" for placement helps your tweezers anyway, so you don't really want to push everything so close together. Especially for hobby projects, I don't think anyone is really in the business of counting up the savings of 0.01\" in the hobby world. Like, how small are you actually aiming for, and is it really so bad that you can't add another 0.5\" to your board? -------- Professionals use 0201 (inches) for maximum flexibility and minimal sizes. So even 0402 is larger than professional projects. If we're all accepting \"larger hobbyist sizes\" anyway, might as well go all the way up to the much easier 0603 or 0805 parts. While a 0402 is slightly larger than a grain of sand, I'd say 0805 is approximately the size of a grain of rice. So yeah, doable with tweezers and solder paste. Just imagine lining up dry rice and its well within the capabilities of most hobbyists. Its just problematic when you get smaller than that. reply dave78 57 minutes agorootparent> Especially for hobby projects, I don't think anyone is really in the business of counting up the savings of 0.01\" in the hobby world. Like, how small are you actually aiming for, and is it really so bad that you can't add another 0.5\" to your board? It's not really about saving board space. Decoupling capacitors need to be placed \"close\" to the chip, and at higher clock frequencies this can be an issue. There's enough decoupling caps needed on a RP2040 that doing them in 0805 would require moving them quite a bit further away from the chip just to have room to place them all. An ATmega (Arduino) at something like 8MHz is really forgiving and you can take a lot of liberties with the layout. The RP2040 runs much faster at 133MHz, so presumably the tolerances are much tighter. Admittedly, I didn't try a doing a design with 0805s for the RP2040 but I read enough from people more experienced than me that gave me the impression that compromising the layout with larger passives had a greater chance of things not working right. Since assembly is so cheap at places like JLC these days, even in small quantities, it really wasn't worth the hassle. I've done many other boards by hand with 0805s and and agree they're pretty easy to deal with. reply dragontamer 2 hours agoparentprevRP2040 is QFN, not BGA. QFN is doable at home, though more difficult than TQFP leads or larger SOIC-chips. Still, far too many components are QFN today so its a good skill to pickup. ------ The techninque is: 1. Reflow soldering brings the _whole_ board to soldering temperatures, and then relies upon surface-tension to pull all the devices into proper place. 2. Solder paste is applies ahead of time. You can cleanup solder paste with a toothpick before you bring the board up to temperature. Solder paste tends to go bad pretty quickly however. When doing prototypes, opt for the more expensive low-melt solder paste to minimize potential heat damage. 3. Prefer to use a stencil to apply solder paste. But its more than doable to be sloppy with a syringe and then rely upon the solder mask + surface tension to magically cleanup things during reflow temperatures. 4. Use a hot-air gun to fix any issues. The #1 issue you'll have is tombstoning, QFNs or TQFP chips are usually pretty good about settling into place. For TQFP issues (ex: bridging), you'll need solder-wick + soldering iron. EDIT: And flux: lots of flux helps. Also, flux goes bad, so throw away Flux all the time and keep buying new batches. --------- BGA is also doable at home btw, thanks to the above principles. But its even harder than QFN. The real issue of BGAs is that you're looking at 4-layer minimum, maybe 6, 8, or 10-layer designs. There's also substantial grounding and other advanced PCB concepts you need before you can layout a BGA-capable PCB. Its not so much the physical activity of soldering that's hard or difficult for BGAs. Its all the theory you need to study to breakout BGAs + minimize inductance + deal with impedance matching and trace-length matching. reply morio 1 hour agorootparentI find hand soldering QFN is faster, easier and more reliable than (T)QFP once you got enough practice. If you need to rework the QFN part the key is to FLOOD the footprint with good solder flux from a syringe. Do not use one of those flux pens, those do not dispense enough flux. reply dragontamer 1 hour agorootparent> If you need to rework the QFN part the key is to FLOOD the footprint with good solder flux from a syringe. I've never tried this but this makes a lot of sense in my mind's eye. I'll try this next time I have such an issue. ------- TQFP seems nice because I can sloppily shove tons of solder down, and then just wick up all the excess solder with solder wick. In fact, I purposefully over-solder all the TQFP joints for this practice. (Too much solder during reflow, and then just a quick cleanup step with a soldering iron later). reply KaiserPro 15 minutes agorootparentYeah I've been seeing a bunch of chip swaps that use this method, its wild how forgiving it appears to be. reply neilo40 4 hours agoparentprevAlthough it looks like BGA, it actually uses a QFN package where all the contacts are accessible at the edge. With a little practice they are relatively easy to hand solder (I've done many, not just rp2040) reply dvdkon 3 hours agorootparentQFN packages are very nice to hand-solder in my experience, considering the pitch. Better than the bridge-prone pins of QFP. The bottom pads do need some preparation, but you don't need hot air or reflow. reply kragen 2 hours agorootparentprevi admit to being intimidated by qfns still. any tips for hand-soldering them successfully? reply dfox 1 hour agorootparentKind of cheating trick for the QFN substrate pad is to put a grid of somewhat higher diameter vias in there and solder the pad from the other side of the board through these vias. Another approach is to just ignore the substrate pad altogether (in many devices it should not be connected to anything anyway and has no real thermal management purpose). reply kragen 1 hour agorootparenti wonder if you could use the vias trick for the regular pins too, and bga balls reply dfox 48 minutes agorootparentI have in fact seen the via trick used for 50mil pitch BGAs, but cannot remember where. I even vaguely recollect some board where that was used for CGA, which seems like really ridiculous idea (you don't use CGA packages and then invent some weird kludge pseudo-process). reply kragen 19 minutes agorootparentwow, i'd never even heard of cgas reply GlibMonkeyDeath 4 hours agoparentprevAlmost universally a hobbyist would purchase the RP2040 mounted to a pcb with other i/o components (e.g. the Seeeduino Xiao https://wiki.seeedstudio.com/XIAO-RP2040/) There are other versions which bring out more lines to accessible solder points. Of course you can design your own custom board, but I'd wager most people don't need or want to do this. reply floxy 3 hours agoparentprevYou would probably be surprised what you can do with a $65 hot plate [0], no-refrigeration-required solder paste[1] and the matching laser-cut solder stencil[2]. [0] -- https://www.amazon.com/Soiiw-Microcomputer-Soldering-Preheat... [1] -- https://www.chipquik.com/store/index.php?cPath=470&osCsid=8t... [2] -- https://www.pololu.com/product/446/ reply dragontamer 2 hours agorootparentPololu's stencils leave much to be desired. They do work but I feel like https://www.oshstencils.com/ makes a higher quality stencil instead at similar prices. ----- Note that BGA chips mostly come pre-soldered / solder balls. You also design PCBs so that there is a \"well\" for the balls to melt into and settle into place, and molten-solder has a significant amount of surface tension, so you can magically watch the solder \"pull\" your designs into place. Of course, the OP is likely talking about QFN not BGA, but... just in case people are worried about BGAs its not terrible... (its just impossible to inspect a BGA XRays). The surface-tension can be harmful in the case of tombstoning (ex: a resistor or capacitor with two leads, especially a \"sideways\" low-inductance capacitor, will get \"pulled up\" by one side, lifting off the 2nd pad). If you have a solder-plate + hot-gun, you can \"feel\" the surface tension by just grabbing a toothpick and pushing on these components as they're still hot. You'll find the pressure to be far higher than you expect. reply floxy 1 hour agorootparentFunny, I had the exact opposite experience. For OSH Stencils, they had a scaling issue with their setup that I pointed out to them, and they just shrugged and said that was the nature of the beast essentially and they couldn't do anything about it. They might have said something about Kapton shrinkage or some such. (I don't currently have the exact numbers, but it was off a couple of percent linearly, which doesn't matter for a tiny board, but for a 4\" board, the difference adds up, so that if you align the apertures on one end of the board, they don't on the other side of the board. Like the aperture was off by a whole 0603 pad or more). I went back to Pololu for that same board, and everything was spot on. And I have had zero complaints with them since. If I had to complain about something, I might slightly ding them slightly on the super-tiny aperture shapes and the kerf width of their laser. But everything has always worked. Apparently YMMV. reply dragontamer 1 hour agorootparentHmmm, maybe my designs have been small enough that it hasn't been an issue. I'll keep your experience in mind then. Thanks for sharing your experience. reply botdan 2 hours agoparentprevJust in case you were unaware, the RP2040 is available on dozens of ready-made, arduino-compatible boards like the Pi Pico, the Adafruit feather boards, of the Seeed XIAO RP2040 boards. Those have all (or at least most) of the IO already mapped to pins, USB headers, booatloaders, reset buttons, etc already mapped. Things like the Pico are really easy to solder onto a designed PCB as well because of the castellations, so it's easy enough to design a board around the footprint and then just solder the entire pico onto your PCB with a soldering iron, avoiding the need to use something like a hot-plate or reflow oven. This has been my preferred way of working with it. reply eulgro 4 hours agoparentprevIt's not a BGA, it's a QFN with a ground pad. reply Havoc 2 hours agorootparentI see. What does that change in terms of process needed? reply a1o 2 hours agorootparentBGA you need hot air and reflow but a QFN I think you can just position and solder by the side with a simple solder iron with a knife like tip. reply the__alchemist 4 hours agoparentprevThat's the desired approach, yes, but... hot take incoming! I think BGAs are easier to \"hand\" solder than other footprints (QFP, QFN etc). You drop the item in place, place it on a hot plate and or heat gun, and start melting it. Of course, if you screw it up, you are screwed. (Reballing sounds not worth it for most cases). And, you can't visually inspect. I think this is because, at least for me, most of the soldering faults I have are due to uneven application, or improper amount of solder. BGA solves this. reply seba_dos1 2 hours agoprev> Dozens of slightly different controllers. Why? Many of those listed are the same controllers in various modules. Espressif has a bunch of different µC series, but not that many. In contrast, aside of the whole Pico dev board, Raspberry Pi does not offer any ready-made module with RP2040. reply 127 2 hours agoprevPIO is fantastic. Revolutionary. Not trivial to use but extremely powerful and adaptable. Too bad about the ADC. To be clear: the ADC is not \"OK\". It' s BAD. reply cide1 4 hours agoprevThe lack of security features really limits where this can be used in commercial designs. reply ndiddy 4 hours agoparentIn general, read-out protection provides a very limited level of protection that I wouldn't rely on to stop cloning. There's quite a few firms that will extract the firmware from protected microcontrollers for a couple thousand dollars (i.e. https://russiansemiresearch.com/ ) which is a drop in the bucket considering the potential profit from industrialized cloning. Lots of microcontroller series also have exploits that can allow hobbyists with very little funding to bypass read-out protection (here's one for the STM32F0 series for example: https://github.com/racerxdl/stm32f0-pico-dump ). reply hitekker 4 hours agoparentprevCan you explain how? Genuinely curious. The author only refers to \"security theater\" which seems to be when a product or system around a product makes people feel like they're safer, when actually it's not making anything more safer or more secure. https://en.wikipedia.org/wiki/Security_theater reply kj4ips 4 hours agorootparentI suspect this mostly refers to \"Code Protect\" or similar functions, that are designed to stop the user for extracting the firmware from a device in the field. Typically, when this is enabled, large parts of the debug interface stop working, and turning it off requires a \"secure\" erase, that clears the loaded firmware. While many CP implementations are flawed, or can be bypassed by a skilled attacker (power glitching, &c), I wouldn't say they are purely theater, as they raise the required investment from aThe RP2040 is impossible to brick. It comes with a read-only bootloader that can either mount as a USB mass storage device (firmware updates can just be copypasted to the \"storage device\"), or use its own simple USB protocol. Can anyone explain what this means? How is it both read-only and updateable? If the latter, how is it unbrickable? reply ndiddy 4 hours agoparentHe's saying that the bootloader is in ROM so it's unbrickable, but the application code that the bootloader jumps into can be updated over USB. Most mid-range and higher microcontrollers have a similar feature, but they almost always have a custom protocol that requires a specialized flashing program rather than showing up as a mass storage device. reply seba_dos1 4 hours agorootparentTo be frank, I don't get its appeal at all. Most hobbyist uCs were already unbrickable, and using mass storage mode for flashing is rather cumbersome and clunky to automate as soon as you're past hello worlds. reply timenova 4 hours agorootparentHence they made the Pico Debug Probe [0]. It makes it super easy to reflash firmware to the Pico in a quick iterative loop. However, the appeal of mounting as a mass storage device is not for iterative development (as you mentioned). Invariably something breaks, and the easiest way to get back on track is to reflash their default blank firmware using the mass storage interface. [0] https://www.raspberrypi.com/products/debug-probe/ reply seba_dos1 3 hours agorootparentI can use things like dfu-util or esptool for quick iterative loops without any additional hardware. Hence my point - mass storage is a downgrade over what other µCs on the market were already doing with their ROM bootloaders before RP2040. reply moefh 2 hours agorootparentJust to note: with the RP2040 you don't need additional hardware (debug probe) for quick iterative development, you can use picotool[1] (using -f allows you to flash and reboot without needing to get it to bootsel mode). [1] https://github.com/raspberrypi/picotool reply seba_dos1 2 hours agorootparent...and it doesn't use mass storage at all, blocking access to it in a clunky way to prevent simultaneous usage. UMS seems like a nice idea when you first hear about it, but it doesn't really offer much once you look at it closer. The only proper argument for it is \"no special software needed\", but it a world where picotool is `apt install picotool` away that's not very advantageous anyway and only causes automount annoyances. UMS shines where you have a device with a filesystem in its flash that you can access to actually manage the files stored there. Super useful for stuff like MicroPython. In contrast, pseudo-mass storage like on RP2040 doesn't seem very useful at all. It makes it appear more approachable, but only superficially. reply dfox 1 hour agorootparentThe whole UF2 idea has to do with the educational background of RaspberryPi. The protocol was invented by Microsoft for use in some kind of similar educational board with the express purpose of not needing drivers, being reasonably crossplatform and crucially not needing any special permissions to access the device. The end result is that in some kind of educational setting you can use some kind of cloud/remote IDE on iPad, stick the RPi-Pico into the iPad and flash it, no blessing from Apple needed. reply seba_dos1 1 hour agorootparentOh. So it's just a result of locked-down walled gardens being so widespread that they influence the world around them. Depressing, but thank you for pointing it out anyway; on my phone I can just run picotool itself and it's easy to forget how dystopian it all got outside of the niche I'm in. reply crote 1 hour agorootparentprevInteresting, I've got the exact opposite experience. Small to medium production runs are always a bit of a pain, because you have to do a lot of coordination with the factory when it comes to tooling. You have to ship a custom programmer, get them to install the drivers on whatever OS they are using, and then find a way to write custom code to interact with the programmer and deal with all the possible error conditions. The RP2040? A simple script which detects the presence of a RPI-labelled flash drive, copies a file, and repeats. Written in half an hour. Drivers? Not an issue. Hardware? Everyone has a USB cable lying around already. Error conditions? It either succeeds, or it doesn't - the OS handles the rest. reply jrockway 4 hours agorootparentprevI've never had great luck with the mass storage flashing. It works fine, but boy is it slow. I bought a J-Link a few years ago and haven't looked back. (It just takes a long time for the OS to recognize a USB device. And you have to press the reset button yourself in order to enter the bootloader. With something like J-Link, your build script can handle pressing the reset button and sending the code, saving you quite a bit of time between iterations.) reply drrotmos 3 hours agorootparentA debug probe is nice (quite possibly a must) if you're actively developing, but for deploying in a hobbyist environment, USB is hard to beat. I make open source espresso machine hardware (github.com/variegated-coffee), and it's nice to be able to give users a wired way to update firmwares that doesn't require extra hardware. reply dgroshev 3 hours agorootparentprevI completely agree that it's inconvenient as a developer tool, a debug probe is much, much nicer. I just think that despite all testing and care bugs are still possible, and the ROM bootloader is a backup that's always there. Plop a tiny switch on the PCB, and even if I screw up an OTA update customers will still be able to flash with no special tools (if the device has a USB port, that is). I also use it as a recovery state for panics, makes the device impossible to brick by a panic loop. reply seba_dos1 3 hours agorootparent> I just think that despite all testing and care bugs are still possible, and the ROM bootloader is a backup that's always there. That's orthogonal to mass storage mode. ROM bootloaders were standard in this class of microcontrollers for years, but they usually don't use UMS. One could argue that UMS is perhaps better than some custom incompatible solutions, but then that's what DFU is there for - a standard way to flash things over USB. reply orlp 4 hours agoparentprevThe bootloader is read-only. What the bootloader loads isn't. If the thing you're trying to boot into is faulty, it doesn't matter because you can just replace the thing the bootloader is trying to load. If the bootloader itself was faulty, the device would be bricked. reply sshine 4 hours agorootparentTo elaborate on the alternative: When the bootloader is not read-only, you can upload another bootloader. This is great in a different way because custom bootloaders allow for more flexibility. For example, you may want to keep two copies of your firmware on the chip: One that you're uploading, and one you can fall back to if the most recent one has problems. This protects you against failure during firmware upload or post-deployment failure, because you only overwrite one of the two. So if the device switches off while flashing it, and you boot back up, a custom bootloader can just default to the older copy. But... what if you update the bootloader and it fails? Then you can't use the bootloader to upload new firmware. Bricked. To unbrick a bootloader you need to overwrite the bootloader using alternative methods that don't involve the bootloader, which usually involves attaching wires to the print. This is highly inconvenient in a production setting: Maybe your hardware is encased, embedded in a bigger thing, or located on a pole on a mountain top in a different country. So a read-only bootloader is a safe choice, and you can make other workarounds wrt. flexibility. reply HyulianGrader 4 hours agorootparentNobody in their right mind is updating a bootloader in the field OTA, let alone one inaccessible on a mountain top. reply dave78 4 hours agorootparentI used to work on a product where we did exactly that, and the devices literally ran on mountain tops. Our development and testing process was very rigorous and would be unrecognizable to most developers today, however. We certainly weren't shipping new code to those devices after every sprint. reply freedomben 4 hours agorootparentprevI don't disagree, but it leads to the question from the security guy: how do you fix CVEs in the bootloader after it's shipped (aka in the field)? reply HyulianGrader 3 hours agorootparentIf you anticipate the need to update the bootloader, you would use a multistage bootloader approach where the first is never altered (as the bootloader should never be altered) and its main function is to select which updatable second stage bootloader to load from multiple options (multiple so that even if one is interrupted mid-update by the application, there is a valid fallback). My gut says if you're worried about this in the bootloader, it might be doing too much. reply dfox 54 minutes agorootparentParticularly neat approach to both reducing the attack surface of the bootloader and improving the reliability of the actual OTA update process is to have only the bootloader flash the active application/second-stage flash partition. The idea is that the normal application code somehow acquires the new version, verifies it and writes it into separate flash partition and then reboots, bootloader sees that record and, does minimal check for correctness and flashes that to right location. That way the bootloader does not have to know anything about how to get the new firmware image and does not process any untrusted input. reply AlotOfReading 3 hours agorootparentprevYou don't. When I actually have these conversations with security guys, it's because they've either missed their window on contributing to part selection (in one case because that team hadn't been hired yet!) or no one consulted them in the first place. In both cases the solution is to write some guidelines and get the EEs to use them during part selection in the future. reply dgroshev 3 hours agorootparentprevYou can have several bootloader stages, and in fact that's how the RP2040 works [1]! Stage 1 bootloader is the one in ROM and it normally just reads stage 2 from the flash chip. Stage 2 then initialises the flash properly, and you can have further stages like [2] to implement the trial-rollback procedure. Stage 1 is a safety net, even if the trial-rollback procedure goes terribly wrong the device can still be unbricked over USB. [1]: https://blog.usedbytes.com/2021/12/pico-serial-bootloader/ [2]: https://embassy.dev/book/#_bootloader reply perbu 4 hours agoparentprevThe bootloader is read-only, the firmware it boots is updateable. The bootloader allows you to update the device with new firmware. MCU are different than computers. And since you can't overwrite the bootloader, you can't brick the MCU. You can always just reset it. fwiw; I've never bricked an MCU buy flashing something weird onto it. The hobbyist MCUs sold are typically quite easy to re-flash with new firmware. reply cryptonector 3 hours agoparentprevI think it's saying that firmware updates are not persistent. You have to apply them every time at boot time. So if it boots once, it will boot every time. If you ever get bad firmware, you just rollback or roll further forward in your boot media. reply mkj 3 hours agoparentprevUnbrickable for the RP2040 itself, but most SPI flash chips (including ones on the RP Pico) have permanently lockable regions. You can lock them open though. reply jcalvinowens 4 hours agoprevThe lack of built-in flash kills it for me. STM32 M3s with comparable throughput are cheaper and don't require an external flash chip (example: STM32F103C8T6 for $1.20 from jlc). I love the generic PIO though, I really hope other manufacturers pick up on that. reply riskable 2 hours agoparentI used to have the same beliefs but the flexibility of being able to use just about any pin for any purpose really sold me on the RP2040. When I decide to add a new feature to my boards I don't have to spend an hour examining the minutiae of the data sheet to see if I can use a given pin for SPI (oops: no, I can't because I enabled alternate function 3...). It saves a TON of track routing time and simplifies boards considerably. Once I decided to start using the RP2040 I realized the \"strange\" flash situation turned into a feature, not a drawback! With STM32 you pick your part and then you can order an expensive version (if it's available!) with the max RAM of say, 512Kb or you can save a few bucks and go with say, 64Kb. Either way you're paying like $2.50-4 for a single chip. Now compare that with the super fast, dual-core RP2040 which costs $1 (yeah it's technically $0.70 in bulk) paired with a 16 FUCKING MEGABYTE SPI flash chip (W25Q128JVSIQ, basic part at JLCPCB :thumbsup:) that costs $0.60. You get a vastly more capable MCU with so much goddamned flash space you could fit a truck in there! You can even partition that flash chip's space so that your RP2040 firmware is reserved to the say, the first 2MB (or wherever you wish!) and the rest can be used for storing stuff like settings. It eliminates the need for an EEPROM! Not to mention there's enough storage space in there to store all your settings in something absurdly inefficient like JSON and the chip is fast enough to parse it too! Working with the RP2040 in reality is just SO NICE. Seriously, try it! You won't be disappointed. reply diydsp 52 minutes agorootparentHaven't used the RP2040 yet, but having worked with SPIRAM and SPIflash on the ESP32, and also on many different STM32s, I can say this: if your project reaches a certain size, lots of tasks or multiple chunks of discontiguous memory, then the caching of the SPI memories becomes a traffic jam and things that should be really fast get really slow. And you start running into lots of weird error messages from inside the esp-idf drivers that you can't do much about. It will drive you crazy. You have to start strategically partitioning your memory, create/delete tasks dynamically, adjust lots of params in menuconfig, etc etc. Not a problem for most hobbyist projects, but when you start to push the limits the ESP32 feels like a chipboard apartment building compared to STM32's concrete and rebar. Hopefully the RP2040 doesn't suffer the same problems. reply dave78 2 hours agorootparentprevI agree with all that and would add that the documentation is fantastic, and the software tooling and SDK is well-done. That's a big advantage that vastly outweighs small differences in cost (unless you're selling millions of something). reply bangaladore 3 hours agoparentprevThat chip has over 10x less RAM and only 60k flash. It has only one core and that core is clocked at half the speeds compared to both the RP2040 cores. And it cost six bucks from US distributors. I can buy a single RP2040 chip from Digikey for 70 cents. Even if you add another dollar for flash memory, you are still far better off. reply jcalvinowens 3 hours agorootparentI mean, that's sort of my point: the rp2040 has an absurd amount of RAM for a micro, I don't need it and don't want to pay for it. I care more about the cost to manufacture boards with the part, than the cost to get sample parts mailed to me in the US :) reply jsheard 3 hours agoparentprev> I love the generic PIO though, I really hope other manufacturers pick up on that. Unfortunately the Pi Foundation is seeking patents on the PIO architecture. I don't think they've been granted yet though. reply KaiserPro 10 minutes agorootparentSource? I've not seen a patent for that, plus I suspect its not actually patentable reply amelius 3 hours agorootparentprevIsn't that already covered by FPGAs? I mean, it is just a way of configuring ports. And FPGAs are much broader (also configuring computation). reply crote 1 hour agorootparentNo, FPGAs work substantially different. You can think of an FPGA as a bunch of \"programmable transistors\". You've got a whole bunch of basic logic building blocks, and you program the wires between them to build a logic circuit. This means it is great for building relatively simple but high-speed logic (grab sample from sensor, do some additions and multiplications, store result in external DRAM chip, repeat at 5GHz). However, they are really inflexible: getting them to do different operations depending on some condition is extremely costly. The PIO, on the other hand, is essentially a really basic CPU core. It reads and executes a stream of instructions, and it can do (very simple) math and conditional logic. This means it is great for building some kind of state machine, which dynamically adjusts it behaviour based on some kind of external condition. The unique selling point of the PIO is that the instruction set is completely designed around super-fast IO, so reading or writing two dozen pins can be done in one or even zero(!) instructions. And because every instruction executes in exactly one cycle, you've got really good control over the exact timing. This makes it ideal for implementing hardware-level protocols in software. reply arlort 1 hour agorootparentprevThe same features of pio can be implemented via FPGA, but it's a lot more complicated to do so, and probably you won't find FPGAs as cheap as on the pi reply vitiral 3 hours agorootparentprevseeking patents to then open source it? Right?... Right?!? reply jcalvinowens 3 hours agorootparentprevThat's really disappointing :/ reply joezydeco 3 hours agoparentprevAre you gated on PCB real estate, or cost? 8 megabits of QSPI is under 50 cents. I really don't care that it's external if the entire chipset is under 2 bucks. reply the__alchemist 3 hours agorootparentNot the OP, but I'll say, whenever designing a fresh board, this sort of convenience built-in is nice. Individually, it's not a huge deal, but when you start adding things that are sometimes built in (external crystal vice internal? flash? PDs on USB or a bus?), you appreciate when it's one less component to allow spacing for, that might be out of stock at a given order etc. Also note that QSPI flash has a number of connections, you have to check the datasheet etc to know what to wire where, if you are changing MCU footprint you have to re-wire it each design etc. reply joezydeco 2 hours agorootparentI'd agree with most of those points, but in my decades of experience here...YAGNI. reply jcalvinowens 3 hours agorootparentprevExactly this, it's just another thing to deal with and I save a little time by not having to. reply tiku 4 hours agoprevMy Switch is unlocked by a rp2040. A lot of devices could be modded with it, given the size etc. reply fxtentacle 1 hour agoprevThe real competition is the STM32 line-up, in my opinion. Much more computing power at a comparable price. Or half price if you only need a few MHz. reply snufkin97 3 hours agoprevYES! TL;DR: its more powerful yet cheaper than most of MCU market, well documented and very straightforward yet extendable on many levels I agree with the post in 100%, I use RP2040 for both hobby projects and my keyboard startup project (arrowmechanics.com in case sb was interested). IMHO What RP foundation did is the greatest breakthrough in the world of embedded tech projects since the popularization of atmegas. reply dragontamer 2 hours agoprevRP2040 is awkward in my experience. Everyone needs Flash, and RP2040 has none. Very few projects need more than 32kB of SRAM (especially on an anemic Cortex-M0+ core). You're missing an FPU (like on Cortex-M4 or higher chip), so DSP capabilities are awful even if your clock speed is high. RP2040 has awful power consumption: 20mA. The M0+ competitors are 10mA, 5mA, or even sub 1mA. Once we get to more recent Cortex-M23 or Cortex-M33 (or the 8-bitters)... many competitors sleep in the under 1uA (!!!) regime, meaning \"always on\" chips (when you're under 15uA or so, you're undercutting many battery's internal leakage currents, so your chip's current usage becomes a rounding error). RP2040 is incapable of \"always on\" computation like this, so this limits applicability. RP2040 has some peripherals, but its missing common modern components. Many competitors (AVR DB, TI's MSP430 and MSPM0, STM32G4) have OpAmps for mixed-signal conditioning. Most competitors have multiple analog-comparators. DACs are somewhat uncommon but AVR and TI offer them. ------- So comes the question: what kind of project are people using RP2040 for? It can't be cost-optimized, because by the time you buy a flash-chip and external oscillator you've overrun the costs of the competitors. Its not power-efficiency, because RP2040 is a power-hog. You're getting far less battery life compared to competitors. (Case in point: the microcontroller that handles your wireless credit-card transactions is battery-less, running purely off of the energy of latent energy waves in the NFC protocol. RP2040 will never reach these low levels of power consumption). Where I see RP2040 as useful, is utilizing its absurd 264kB SRAM (far, far larger figure than most chips). If you need a graphics framebuffer for a small 300x200 8-bit color screen or something, then RP2040 is probably the right choice. (60kB for the framebuffer, and likely 2 or 3 of them for various computations on the frame buffer). But outside of a display driver, its difficult for me to find projects where RP2040 is actually the correct choice. Besides, screens are relatively expensive (in both $ and in power consumption), so if you're getting a screen you probably can upgrade to a SAM9x75 with full 2D GPU, DDR3L 800MHz and Linux support for like $12 for those SiP packages. ------- At a minimum, the next version of RP2040 needs to include on-board Flash / on-board programming. This is something _every_ project needs (RP2040 needs to run its code off of _something_ anyway). The fact that it ships flash-free is incredibly absurd to me at least. RP2040 forces a microprocessor-mindset (\"one chip\" where you add a bunch of addons) inside of the low-cost microcontroller market segment. Its very strange. reply gbin 1 hour agoprevIndeed the software support is awesome, even using rust on it is a pleasure! reply a1o 2 hours agoprevWell it's still young so of course there's only RP2040. I remember the 8051, 8052, 80C51, up to the recent ADuC845... reply amelius 4 hours agoprevI have just one question: is this product meant for the \"hobbyist\" space only? reply joezydeco 3 hours agoparentI was on the fence about using it for a small commercial project I'm doing, but the lifetime has been put out long enough (2041 at this point), and it's so freaking cheap that I'm going to do a one-time buy of 10 years worth of parts. Lack of code security and onboard flash weren't dealbreakers for me here, but others will have more stringent requirements. QSPI is so incredibly cheap now. reply amelius 3 hours agorootparentOk. One thing I'm worried about is that the tooling is made for hobbyists only. Is there a way to do everything from the commandline with FOSS tools and without installing e.g. the Arduino-IDE? reply dave78 1 hour agorootparent> Is there a way to do everything from the commandline with FOSS tools and without installing e.g. the Arduino-IDE? Yes. In fact, the official getting started guide[0] is all command-line based, with an optional chapter later on about using VS Code if you wish. I have a low volume product in production using the RP2040 and I've never once opened up any sort of GUI for developing the software or programming it. [0] https://datasheets.raspberrypi.com/pico/getting-started-with... reply riskable 3 hours agorootparentprevSince the RP2040 uses external flash you can pre-program the flash chips before they even get soldered on to the board. Other standard methods still work like breaking out the debug pins to some spot on your PCB so you can quickly \"pogo flash\" it as part of an assembly process. reply joezydeco 3 hours agorootparentprevI'm using the CircuitPython environment. I'm editing in vi and writing directly to the USB storage on the RP2040, which reboots upon write and runs the code. It's no big deal. There's also a virtual UART off that USB connection for light debugging. reply mordae 3 hours agorootparentprevYes. Pico SDK is C with CMake and Rust is bare metal (I think). reply silvanocerza 2 hours agorootparentprevMaybe with the Arduino CLI? reply dgroshev 3 hours agorootparentprevI'm not sure how things are in the C land, but if you write Rust take a look at this book [1], Embassy has a very good support for the RP2040. Probe-rs [2] works perfectly well with GDB and the CLion debugger. [1]: https://embassy.dev/book/ [2]: https://probe.rs/ reply mmoskal 4 hours agoparentprevDefinitely not. My understanding is they got significant market share on lunch - since it was during the pandemic chip shortage and they were the only ones with sub year lead times. reply amelius 3 hours agorootparentOk, but does it fulfill military or automotive standards? reply riskable 2 hours agorootparentI don't know about military standards but there's only ONE automotive standard and it's ISO 26262: https://en.wikipedia.org/wiki/ISO_26262 There's nothing in ISO 26262 that would prevent someone from using an RP2040 in a car. You'd just have to be redundant about everything which you have to do anyway regardless of the chip you choose. Also, ISO 26262 is not a law. It's up to the auto manufacturer whether or not they'd require it and no single chip on its own can claim to be \"certified\" (or similar) for ISO 26262 since the focus is on redundancy and error checking (which means one chip would check the status of the other and vice versa, not some special internal consistency checking feature... That's just marketing). Most \"automotive\" versions of chips (e.g. Atmel's stuff) are just branded that way. Atmel will make a claim like, \"this chip has been tested to function properly under these sort of extreme conditions...\" (that happen to match what car manufacturers are looking for) and then a car company would just trust that and make it so that only chips that are marked \"automotive\" and manufactured by Atmel will be allowed to be used by their electrical engineers (or suppliers). It's all entirely arbitrary though: If you can convince the manufacturer that your board works fine under the conditions they require they'll probably buy it. Well, they won't hold it against you that you used one chip or the other. They just want some assurances. reply aaronmdjones 2 hours agorootparentThere are several automotive standards for electronic components. GP was probably asking about e.g. AEC-Q100, AEC-Q101, and/or AEC-Q200. These establish that the device is going to work in automotive environments (temperature, humidity, vibration & shock) by verifying functionality while subjecting them to those conditions. A component may work without these tests, but you are merely hoping that that is the case if they haven't been tested. Hope is not a viable strategy for product design. reply riskable 1 hour agorootparentThe AEC standards aren't enforced by anything and are mostly just promises that chip manufacturers make (the AEC itself is a private entity). Specifically, that any given chip will still be available in 15 years and that it'll operate fine within certain temperature ranges. If some part claims to be AEC compliant it's basically just the manufacturer saying so. There's no independent body or even standardized tests to prove a part adheres to any given AEC document. Their own docs state as much: AEC Certification Note that there are no \"certifications\" for AEC-Q100 qualification and there is no certification board run by AEC to qualify parts. Each supplier performs their qualification to AEC standards, considers customer requirements and submits the data to the user to verify compliance to Q100 In other words, it would be up to any given car manufacturer to verify the claims of any chip vendor using their own testing methods. Since they're going to have to do that anyway, slapping AEC-(whatever) on a product doesn't mean much. If you test your part in similar conditions and make some availability promises you too can slap an AEC-Q100 label on to your chip! reply mordae 3 hours agorootparentprevProbably yes, but it doesn't have the paperwork AFAIK. reply dgroshev 3 hours agoparentprevPersonally I wouldn't put it into a toothbrush (the benefit of right sizing is too high when you produce tens of millions of those), but for lower volumes I'd go for it. Fwiw I'm working on my own consumer product/dev tool and I'm very happy with the RP2040. reply BruceEel 4 hours agoprevdata sheet: https://datasheets.raspberrypi.com/rp2040/rp2040-datasheet.p... reply IshKebab 4 hours agoprevTL;DR: he likes it because there's only one version available, whereas most microcontrollers have many more than one variant. This seems like a very weak argument. IMO (just based on the specs; haven't actually used it), the main reason to use this is for the PIO stuff. That's a very niche use case though. reply t43562 3 hours agoparent...because that means there's a lot of support and documentation for that 1 variant and lots of people have solved problems and written about it, This is like the iPhone strategy against Nokia. When I worked at Nokia it produced many variant phones - each with a little more ram or a bit less or a better screen or a different chipset. This was because they thought that people bought on price and wanted to have a product at every price point. The builds took more than a week to finish, the bug fixing was horrendous. The software sometimes had to work with not enough RAM sometimes with different chipset bugs, different graphics limitations. It was a nightmare to produce a quality product. Then out of e.g. 18 phone models we had to customise each one for 1000 operators in the world which intensified the pain and effort. At that time Apple had one iPhone. It was over specified - lots of RAM, great graphics etc. They only had to test their code once - not 18 times. reply SillyUsername 3 hours agorootparentThe ESP8266 and ESP32 from what I've seen have got far more documentation and support (also due to library compatibility between the two chips). I've personally not come across any lack of documentation or compatibility issues, which I guess only happens if you need to target many versions of a chip, which isn't a problem for most people unless you're an API developer. reply miunau 3 hours agorootparentprevMaking software for all those models was exhausting. It took an entire team just to profile phones and make configurations for compilers (what is the screen resolution? does it have feature x? is there a physical keyboard, and how many buttons does it have? where are the crucial buttons located? ...), and then you ended up with hundreds of targets taking days or weeks to make a build. I know many programmers that quit the industry altogether during those times. reply vitiral 3 hours agorootparentprev... and because they designed the chip to be a jack of all trades, which he really likes. reply dragontamer 1 hour agoparentprev> IMO (just based on the specs; haven't actually used it), the main reason to use this is for the PIO stuff. That's a very niche use case though. PIO is interesting but I'm not fully convinced they're better than a suite of dedicated timers, especially in the realm of power-efficiency. The _real_ wtf?!?!? spec here is 264kB of SRAM. At this price point / power-consumption, that's a _LOT_ of SRAM. Any application that needs a ton of SRAM (ex: 300 x 200 pixel 8-bit LCD screen) will find good use in the RP2040. A lot of the other parts of the RP2040 are quite lackluster. PIO is \"interesting\" but seem somewhat overhyped to me. reply CamperBob2 3 hours agoparentprevThe real risk with the chips that offer the same die in dozens of slightly-different packages is the supply chain. Rest assured about 80% of those variants will be out of stock more or less permanently in a few years, once a few major customers have settled on a few specific parts. Good luck guessing which ones you'll be able to get. reply written-beyond 4 hours agoprevInb4 esp32 reply cockings 4 hours agoparentIt's mentioned in the article. reply topspin 1 hour agorootparentThat bit of snark is about the ESP32 brigade that plagues every project or story that involves any non-ESP32 MCU, including this one. Yesterday I watched a long live video by the engineer of a open source engine management system, and he too had to deal with the ESP32 brigade in live chat. He has entirely reasonable technical justifications for his choices, and his explanation had about as much impact with the ESP32 brigade as I've come to expect. reply metadat 3 hours agoprev [–] If this RPi main chip costs $0.70, why does the finished product currently cost $93.00 (RPi 5)? They're quite expensive nowadays, I miss when you could purchase them for ~$30.00. Meanwhile, Expressif chips are literally everywhere and becoming ever more ubiquitous. Edit: Thanks friends for the correction. It is cool you can still buy an RPi Pico for $13.00 :) reply wheybags 3 hours agoparentBecause it's not the same chip? https://en.m.wikipedia.org/wiki/RP2040 read the the specs and it's clear that is not the main chip in an rpi 5 reply oakesm9 3 hours agoparentprevThe main chip in a Raspberry Pi 5 is a Broadcom BCM2712. The main chip in the Raspberry Pi Pico is the RP2040, which costs $4. reply seveibar 3 hours agoparentprevA raspberry pi 5 doesn’t use this chip (at least as the main chip). The RP2040 is for microcontrollers/embedded applications. reply j_leboulanger 3 hours agoparentprevBecause the RP2040 is not the main controller of the RPi. It's a micro controller, on which the Raspberry Pi Pico is based, at $4 reply smcameron 3 hours agoparentprev [–] The RP2040 is not what the RPi 5 uses. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The RP2040 is a versatile microcontroller by Raspberry Pi, designed for embedding in consumer electronics.",
      "Unlike other manufacturers, Raspberry Pi offers just one model, simplifying development and fostering a large support community.",
      "Priced at around 70 cents, it features two cores, 30 GPIO pins, ample internal RAM, and a unique PIO peripheral for efficient IO operations, making it a favorite among engineers for its balance of cost, functionality, and support."
    ],
    "commentSummary": [
      "A user switched from the RP2040 to the ESP32-S3 microcontroller due to issues with the PlatformIO tool, simpler module format, and better GPIO pin capabilities for capacitive touch.",
      "The RP2040 was praised for its affordability, excellent documentation, and unique Programmable I/O (PIO) feature, but criticized for high power consumption and lack of peripherals.",
      "The ESP32 was highlighted for its integrated Bluetooth and Wi-Fi, despite having inferior ADCs and facing performance issues with large projects."
    ],
    "points": 286,
    "commentCount": 207,
    "retryCount": 0,
    "time": 1718113189
  },
  {
    "id": 40643207,
    "title": "POV-Ray Celebrates 30 Years with New Beta Release and Educational IDE Campaign",
    "originLink": "http://www.povray.org/",
    "originBody": "HomeDownloadHall Of FameDocsFAQResources & SupportForumsSearchLoginWelcomeThe Persistence of Vision Raytracer is a high-quality, Free Software tool for creating stunning three-dimensional graphics. The source code is available for those wanting to do their own ports. Download and NavigationTo navigate about this site please use the navigation links at the top of this page. If you want to download POV-Ray, please visit our download page. Contacting UsFor general resources and support information, please visit our resource and support page. For website-related issues only, please contact our webmaster. To contact us regarding licensing matters, please use the address given at the bottom of our license page. POV-Ray-related NewsDKBTrace (foundation of POV-Ray) creator has kickstarter for educational IDE David K. Buck - the creator of DKBTrace, the pioneering raytracer that was the genesis of POV-Ray - has created a KickStarter campaign to fund creation of an open-source IDE for PigeonTalk (PigeonTalk is a smalltalk implementation created by David that is aimed at being a programming environment to explore computing). \"I chose Smalltalk as a language because it provides the most immersive experience I've encountered. Smalltalk allows you to create, use, and explore software in a very hands-on way. It's an ideal environment for learning and playing with software. This Kickstarter project is to provide a development environment for this Smalltalk which I'm calling PigeonTalk. The development environment would run in a web browser and would communicate with the Smalltalk engine using WebSockets. Once this is available, PigeonTalk becomes a viable programming environment that others could use.\" We wish David the best in this endeavor and are hopeful the Kickstarter will meet its goal as POV-Ray itself would not exist if it were not for David's kind contribution of the DKBTrace source code. [February 04, 2022] [Permalink] POV-Ray v3.8.0 beta tests available POV-Ray 3.8 is now in beta-test. You may obtain beta releases via our GitHub repository. Discussion regarding the betas should be directed to the beta-test group in our forums. [August 31, 2021] [Permalink] POV-Ray turns 30 30 years ago today, on July 29 1991, the first beta of what would become POV-Ray became available in the GRAPHDEV forum on CompuServe. See \"The Early History of POV-Ray\", \"The Original Creation Message\", \"The Name\" and \"A Historic Version History\" in our v3.6 documentation for more details about the early days of this project. [July 29, 2021] [Permalink] Wiki back online The POV-Wiki is now back online and is running the latest version of MediaWiki. Additionally we have restored our legacy bugtracker, which tracked issues prior to moving our source code to GitHub. [April 12, 2021] [Permalink] Forums back online Following more recovery work since the server crash we're happy to say our ... ... [read more] [March 28, 2021] [Permalink] Server Recovery The www.povray.org site is now back in read-write mode ... ... [read more] [March 21, 2021] [Permalink] POV-Ray Server Downtime Our server recently experienced a catastrophic hardware failure ... ... [read more] [March 15, 2021] [Permalink] Blender to Persistence of Vision New Release: Blender to Persistence of Vision ... [read more] [August 01, 2020] [Permalink] white_dune VRML/X3D editor adds POV-Ray export The folks at the open-source white_dune 3d editor project let us know that they've added POV-Ray export capability. Neat! It looks like a useful tool, definitely worth checking out. You can find their github repo here or if you prefer you can go straight to their project website for downloads. [July 23, 2020] [Permalink] Call for papers: Ray Tracing Gems Eric Haines dropped us a line to let us know that there is still time to submit papers to Ray Tracing Gems ... ... [read more] [July 01, 2018] [Permalink] Older News POV-Ray 3.7.1 enters beta phase Converting POV-Ray scenes into 3D-printable STL meshes POV-Ray turns 25 (or 30) Python modeller for POV-Ray Routing problems for some users in Sweden and Finland POV-Ray 3.7 released Lathe and Prism Utility Available Viewshed Analysis with POV-Ray POV-Ray Helps Visualize Bee Keeper Data POV-Ray, Export & View, for Mathematica Koppi's Bullet Physics Playground Parallella supercomputer kickstarter nearing end Spectral Rendering with POV-Ray ANIMUSIC 3 kickstarter campaign in its last week Update of Insert Menus Add-on Caedium Version 4 Available Another PoseRay Update Making of a Rose Colored Leaves PoseRay Beta Release Other items of possible interestVisualization Library Visualization Library is a C++ middleware for high-performance 2D and 3D graphics applications based on the industry standard OpenGL 2.1, designed to develop portable applications for the Windows, Linux and Mac OS X operating systems. [June 03, 2010] [Permalink] Jupiter Loses a Stripe Lost: A giant belt of brown clouds big enough to swallow Earth twenty times over. [June 03, 2010] [Permalink] OGRE 1.7.1 Since 2001, OGRE has grown to become one of the most popular open-source graphics rendering engines, and has been used in a large number of production projects. Check out the first maintenance release to the new 1.7 stable branch codenamed Cthugha. [June 03, 2010] [Permalink] E-on Software Ships Vue 8.5 e-on software, maker of the leading solutions for Digital Nature, announced today the immediate availability of Vue 8.5 xStream and Infinite, its professional solutions for the creation, animation and rendering of natural 3D environments. [June 03, 2010] [Permalink] Solar Dynamics Observatory NASA's Solar Dynamics Observatory ... [read more] [June 03, 2010] [Permalink] DAZ 3D-Gizmoz Introduces Digimi Digimi the ultimate platform for generating personalized avatars. ... [read more] [June 03, 2010] [Permalink] OpenTK Library 1.0 RC1 The OpenTK is an advanced, low-level C# library ... [read more] [June 03, 2010] [Permalink] Rhino for OS X is in development During development, pre-release Rhino OS X is free ... [read more] [June 03, 2010] [Permalink] SymLab RANS Flow Symscape's commercial range of simulation products has now been expanded to include SymLab RANS Flow for the simulation of realistic (viscous) ... [read more] [June 03, 2010] [Permalink] Hall of Fame\"Bonsai Life\" \"TopMod StarBall\" \"Tiffany Cheerio\" \"Tribute to Myrna Loy\" \"Pebbles\" See more images... [dialup version] Privacy Policy You may view our Privacy Policy here.",
    "commentLink": "https://news.ycombinator.com/item?id=40643207",
    "commentBody": "POV-Ray – The Persistence of Vision Raytracer (2021) (povray.org)270 points by RafelMri 12 hours agohidepastfavorite147 comments susam 10 hours agoAbout 11 years ago, after having written a tiny ray tracer from scratch using Java, I taught myself some ray tracing with POV-Ray. My goal was to learn a few POV-Ray features each day over 25 days and render some interesting scenes that exercise those features. I began with simple spheres and cubes and gradually progressed to more intricate shapes and textures. Here are the results: https://github.com/susam/pov25 The source code is in the \"src/\" directory. The rendered images are included in the README (scroll down to see them). I hope you like them! reply cl3misch 8 hours agoparentI find the kaleidoscope surprisingly cool. In hindsight it's obvious but to get this out of a raytracer is somewhat unexpected to me. https://github.com/susam/pov25#Kaleidoscope reply ABS 10 hours agoprevI still remember when I used to leave my 386 sx 25Mhz running all night to render very simple scenes with POV-Ray (somehow sleeping through the loud fan noise!). And the extreme excitement the day I upgraded to a 486 dx 33/66 Mhz which, thanks to the math co-processor, rendered those same scenes in (10s of) minutes instead!! reply entropyie 8 hours agoparentAre you me? :-D Same story, had an AST 386 which I upgraded to a 486 DX33... I learned to program in the 90s by writing povray scene files, which taught me C style syntax and primed me to write actual C/C++/Java in the years that followed. I spent thousands of hours with povcad and povray on windows 3.1... reply dcpit 7 hours agorootparentStop showing off, guys ... ;-) About 30 years ago, I let my Atari 1040STF (8Mhz, no hard drive...) scratching a floppy disk all night long to render this very blob : http://csi.chemie.tu-darmstadt.de/ak/immel/graphics/povray35... reply G3rn0ti 6 hours agorootparentYou ddos'ed your university home page. ;) reply andrehacker 1 hour agorootparentMaybe he'll get to use the \"that would be impressive except if they had known what they were looking for,they would have seen it written on my dorm room window\" quote later today. reply prox 5 hours agorootparentprevNo the Atari is still rendering to this day! reply chaboud 3 hours agorootparentprevSeems like the Atari was repurposed into doing duty as a webserver… (Kidding. Posting links on HN is basically a community load test.) reply technothrasher 4 hours agorootparentprevI feel like the privileged guy in the room, as I was running POV-Ray on a fancy new SPARCstation back in those days. reply entropyie 5 hours agorootparentprevLol, I also have some povray renders still online on my uni page... Not linking though ;-) reply bfmalky 5 hours agorootparentprevAlso are you me? Except I had a 486sx and I tried in vain to persuade my parents to buy a maths co-processor for it. It would have probably saved them money in the long run from electricity bills. Some of my first programming was writing QBasic programs to generate povray scene files. reply fullstop 5 hours agorootparentI had a 486dx and it was such a huge upgrade over a 286. I ordered pov-ray from some shareware catalog since I didn't have internet access, and it arrived on 3.5\" floppies. reply ABS 8 hours agorootparentprev:-D I already knew (some) C, lots of Turbo Pascal and Basic by that time so I would generate povray scene files using a small C program I had developed which took various equations as starting point to plot spheres on the curves reply dayjah 7 hours agorootparentHah, same except my dad showed me how to write a simple search and replace using a DOS batch script to generate many files to then pass into the renderer. I used it to do camera pans, lighting effects, etc. reply glimshe 7 hours agoparentprevWhat 386 owner hasn't rendered that sample POV Ray scene with a glass of wine? It made me feel that my beloved computer could do \"professional\" graphics. reply sumtechguy 6 hours agorootparentThen you would find the NCC-1701 from some BBS... reply glonq 1 hour agoparentprevI'm old [and stupid] enough to remember running a floating-point-only raytracer on a non-FP PC using a software-emulated math coprocessor. I think I measured output in *hours per frame*. reply CrLf 8 hours agoparentprevMy personal record was 50 hours for a single 640x480 scene on my Pentium 100 MHz. Memories... reply angst_ridden 1 hour agoparentprevSame here! I still have some fairly simple 320x240 images that took all night to render. reply mattanimation 3 hours agoparentprevyes! I did the same thing, although I never got a 486 and jumped to a amd k6-2 with Blender when it came out. Never had the math co-processor either, although it would have been nice. reply thesnide 6 hours agoparentprevmy dad wanted to buy a 486sx, i convinced him to go for the more expensive dx for povray and factint... Yeah. I know now about the int in fractint :D reply stevage 6 hours agorootparentAnd then Terragen. reply Twirrim 5 hours agorootparentIt was VistaPro, for me. So many hours of fiddling with variables, and rendering new worlds. reply kstrauser 2 hours agorootparentI spent so much time on VistaPro on my Amiga 1000. I later bought a 2000, then an 030+FPU card. I was a rendering madman for the next month. reply Damogran6 4 hours agorootparentprevahh. Fractint. reply LoganDark 9 hours agoparentprev> somehow sleeping through the loud fan noise Sometimes white noise helps with sleep, so this may not be that big of a surprise. reply eru 9 hours agorootparentPedantic nitpick: you are most likely talking about a different 'colour' of noise. White noise is really harsh, and probably not what your fan produces. See https://en.wikipedia.org/wiki/Colors_of_noise reply ABS 9 hours agorootparentprevyes, but that wasn't white noise I assure you :-D reply p_l 9 hours agorootparentEspecially if there was classic IDE HDD grinding involved :D reply blacklion 3 hours agorootparentI've had 24x7 FIDO node in my room for years. I've silenced modem pulse dialing by replacing relay with expensive one. I've silenced CPU cooler by using 90mm 12v fans connected to 5v (yes, in 486DX era). But HDD was unbeatable. On the other hand, if I wake up in the middle of the night due to HDD grinding, I was sure that I have new mail (echoareas) to read! reply amlib 4 hours agorootparentprevI loved that deep scratchy bass, modern hard drives are so quiet... I miss sleeping to my computer defragging all night long :( reply doubled112 4 hours agorootparentNot all modern drives. One of mine goes \"thunk thunk thunk\". I could hear it from rooms away in one case I had it in. reply Something1234 5 hours agoprevI love POV-Ray. I learned about it in college when I was trying to find things to do on my gaming desktop that weren’t gaming. It’s so much fun to mess with and make different things with. There’s some super impressive examples and stitching the images together is a lot like magic. It’s honestly really satisfying to use. I imagine a lot of people can use it. I made dice with it already. https://www.henryschmale.org/2022/02/22/povray-dice.html reply tantalor 5 hours agoparent> things to do on my gaming desktop that weren’t gaming This is such a funny statement. What a strange perspective. reply maweki 9 hours agoprev10 years ago I implemented a brainfuck interpreter that had as output an animated povray scene description with a visualisation of the brainfuck abstract machine. https://www.youtube.com/watch?v=6PIZTFrkl0w reply tverrbjelke 7 hours agoparentNeat video. With some subtext to explain what the different \"subthings\" are for in brainfuck to stage and then do become \"multiply\" would make it even more \"bro!\"ish :-) I also spotted your openxcom play from 6 years ago and must confess that I am playing it these days! reply Keyframe 9 hours agoparentprevbro... reply lizknope 5 hours agoprevMy roommate in 1992 would run this on his 386DX with the 387 math coprocessor. It would take literally days to run to create a small 640x480 image. This was in the days of DOS where you could only run one program at a time. It would run all night and then in the morning he would stop it so he could use the computer for other things. But he had some kind of Targa .tga file utility to merge the files together. Then he compiled povray for our Sun workstations and he would split up the rendering so that each machine would render 50 lines of the image and he could merge them together with that utility. I remember how happy he was that he could render stuff 20 times faster. reply kqr 9 hours agoprevMany years ago I asked one of my role models how he had made some pre-rendered sprites for a game, and he told me it was with POV-Ray, but that he did not recommend it because it used its scripting language to define scenes, which he was concerned would be too complicated for someone who has not done 3D work before. I have only done 3D work as a waxing and waning hobby, but then, and to this day, the POV-Ray scripting interface seems like one of the more natural ways to define a scene to me. reply m-i-l 9 hours agoprevIn 1991 or 1992 I used POV-Ray on my Atari ST to create some title screens for some home videos. Completely gratuitous marble text infront of a glass ball on top of water type of stuff, which took all night to render, but it was fun, and crucially free. For years I'd looked enviously at Cyber Studio for the Atari ST, with its StereoTek liquid crystal shutter 3D glasses add-on, but it was just too expensive for me at the time. Then in 1996 or 1997 I thought it would be fun to use it in a professional context at the software company I worked at, making a 3D animated GIF version of one of the product logos which I put on the web site (FWIW it looks like the 3D non-animated version is still visible on the Internet Archive Way Back Machine at https://web.archive.org/web/19971211003918/http://www.sophos... 27 years later). Although no-one had asked for it, I was still in effect getting paid to do something I used to do for fun, which felt good. reply ecliptik 5 hours agoprevPOV-Ray was my first introduction to HPC clusters. In the early aughts a few of us in college participated in a summer program at Wright Patterson Air-force Base to build a MPIPOV [1] cluster out of 10 old Sun SPARCStation 20s with \"Happy Meal\" NICs. We documented the process of installing Linux (Debian), configuring the network, compiling MPIPOV from source and clustering them together. It was a thing of beauty to watch the rendering speeds increase and the blinkenlights putting on a show in that lab when we were done. If I remember correctly they planned to take what we documented and use for a much larger cluster they were building, but never found out the specifics. 1. https://dl.acm.org/doi/10.5555/648136.748781 reply indyjo 6 hours agoprevWhile POV-Ray was a cool project, let's not forget how far we have come with Blender and what a great success for the Free Software movement it represents. reply dagw 6 hours agoparentWhat I'm kind of missing with Blender and the likes is the procedural 'magic' and surprise of POV-Ray. How just typing a few lines of 'code' into a text file could produce wondrous and mind blowing images, and then just changing a couple of numbers would give you an entirely different and unexpected result. Blender makes it infinitely easier to get exactly the result you want, but sometimes that not what you actually want. reply eggy 5 hours agoparentprevI was one of the original donors in June 2202, iirc, for Ton to buy Blender and start the Blender Foundation. I used birthday money and sent I think, $50, that's why I remember it to this day. I still use Blender, but I was using it back then to generate 3D reliefs to carve on my self-built 4x8 foot CNC router table. I wrote a script based on a shape-from-shading algorithm originally developed by NASA to get more out of all of the single-lens B&W satellite photos they had. My company was The Wooden Image. To the other poster: you could do procedural stuff in Blender early on using Python scripting, although I was using POV-Ray very early on. reply anthk 1 hour agoparentprevPOV-Ray was free too since a few versions. reply amenghra 7 hours agoprevI love the hall of fame (https://hof.povray.org/), with https://hof.povray.org/Riemann_Sphere-Isosurface.html being my favorite. If someone made a simple povray => stl converter, I would get that one 3d printed. reply no_news_is 6 hours agoparenthttps://grabcad.com/library/m-c-escher-sphere-spirals-1 reply weinzierl 6 hours agoprevMark Shuttleworth used it to render Reach for the stars on the ISS in 2002. For me, POV-Ray and FractInt were the first real programs I read and understood. They were my C tutors. Also, you've probably been raytracing too much if you're in this thread. And you probably know who David K. Buck is. reply pjmlp 10 hours agoprevBack in the 90's we had to leave our computers running all night, to get nice images out of POV-Ray, this brings back some memories. reply jpalomaki 10 hours agoparentWe wrote some small tools with Turbo Pascal to generate number of scene files, then rendered these to create small animations. Having a camera move over a reflective chessboard was pretty amazing. reply vertnerd 9 hours agoprevI really liked the scripting language for defining 3D scenes; I bet today you could have an interactive UI that shows the scene in real-time as you modify the script. The last scene I rendered, about 14 years ago, was a picture of the NIST national standard for pi: https://raw.githubusercontent.com/tiggerntatie/pivis/master/... reply EnigmaFlare 7 hours agoparentCan you explain what that pi thing is for? reply vertnerd 12 minutes agorootparentIt is a joke or a riddle, depending on your point of view. I used to be a high school math/science teacher, so this fits in at the intersection of those. If we have national standards for physical things like length, or mass, why not a national standard for a mathematical constant? It's just a ring with a scale on it that measures the circumference. Every now and then, a technician checks the value and records what they see in the log. Even my fellow teachers struggled to grasp the humor of the thing. I suppose I'm a little strange. reply jasomill 4 hours agorootparentprevI think it's a joke. The arbitrarily accurate power series approximation of pi (4 - 4/3 + 4/5 - 4/7 + ⋯) predates NIST (and the US). reply mscharrer 7 hours agoprevSome POV-Ray art I created years ago: https://mscharrer.net/povray/scenes/ Source code is always included. reply geon 6 hours agoprevPovray and the Internet Raytracing Competition was my entire world in the late 90s. https://www.irtc.org/stills/ reply angst_ridden 1 hour agoparentSame here! And yet the only time I placed it was for an image I'd created in Strata Studio-Pro. reply mobiuscog 9 hours agoprevI think it was in 1994 that I posted to usenet (lost in time), offering 'render time' on my 286 for POV-Ray. They were such amazing times, yet compared to today seem so innocent. POV-Ray was my main hobby at the time, along with the community of the Raytech BBS in the UK, and defined so much of my interests going forward, through many 3D modelling and rendering packages. Such a huge part of my younger years, and one of the biggest influences on my life overall. reply alexisread 6 hours agoparentA lot of people do similar with 3D printing now (esp. over COVID to print PPE), so there is a glimmer of this time :) Time to offer a real-world POV-Ray printing service? ;) reply thomashabets2 1 hour agoprevI'm rendering Quake Done Quick (a Quake 1 demo) using POV-Ray. It's not fast. :-) https://blog.habets.se/2015/03/Raytracing-Quake-demos.html and qpov.retrofitta.se Here's an earlier video from before I added level texture mapping support: https://www.youtube.com/watch?v=y85pVYyK2uA reply fidotron 5 hours agoprevPovray clearly holds a special place for many of us. For me it was the first use (via slow dial up) to access HENSA (higher ed national software archive) in the uk for public domain software, and this by itself was mind blowing, in between dealing with my mother keeping picking the other phone up and dropping the connection. The batch processing tools of that era for graphics were qualitatively different from the real time interactive editors. There is something to be said for the imperfect serendipity that would result. The closest thing these days, oddly, is ML training, where part of the appeal is the sense the computer is working super hard for you. Were you to recreate the same concepts on modern hardware you would do something like SDF CSG on GPUs, but it would be surprisingly interactive and so missing this surprise element. reply codazoda 5 hours agoprevI cut my teeth on POV-Ray. It hasn't been updated in some time but being able to code scenes has a lot of advantages. For product design I use OpenSCAD. Maybe POV-Ray made this style of design popular. A couple weeks ago I decided to use Blender for some 3D print modeling. I needed to make a wheel cap for my son, who had broken his. Although I love Blender I was disappointed when I wanted to update some things later in the design phase. Blender has some destructive editing that caused me grief. Perhaps you could avoid this with some additional mastery of the tool. reply prox 5 hours agoparentThere are tools like Fluent that help a lot : https://blendermarket.com/products/fluent The programmer is really cool and responsive on his Discord reply vergessenmir 10 hours agoprevShowing my age here but povray is what got me into software engineering. I wrote a raytracer in Pascal + Assembly and then in C and ASM This was in 1995. reply sumtechguy 6 hours agoparentHaving to write one for a class in college made me a master of pointers and C. Arrays within arrays rendering to Z buffers and crude matrix operators. Now all built into a nice lib and 3 calls away. reply jwells89 3 hours agoprevI think I remember playing with POV-Ray (along with Yafaray) as alternative renderers for Blender back in the early 2000s, not long after Blender had been ported to OS X. At that point I had been making simple scenes in Blender for a while but had grown tired of the limitations of its internal renderer, most notably its inability to render caustics and bounced light, and so was trying my luck with other renderers. Never did get that far with either. If I recall, the problem with POV-Ray was getting the Blender file translated correctly for POV-Ray to render right, and while Yafray didn’t have the translation issue it was too slow to practically use on my little 400Mhz iMac G3. It never even crossed my mind back then to directly write code for POV-Ray. At that point, in my teenage mind 3D was something you did with GUI software packages like Strata 3D and Blender. reply CiaranMcNulty 10 hours agoprevI played with this a lot during my degree back in 97-99. A friend used it to render her final year project. Amazing to see it's still going! reply KqAmJQ7 6 hours agoprevThis is very old but imo very interesting index of pov-ray stuff by various artists. https://www.f-lohmueller.de/links/index_re.htm reply masswerk 9 hours agoprevHere are some game characters, I did with POV-Ray, and it was great for such things! https://www.masswerk.at/JavaPac/LostInMaze-FamilyPortrait.ht... (See the link at the bottom for the game, yet another Pac-Man clone. Mind that pixels where still bigger, then.) reply rffn 9 hours agoprevAh, the memories. First DKB Trace, then the newly renamed POV-Ray. Left the computer on for hours to get tiny pictures. Adding a 387 was a huge step forward; IIRC approximately a 10x speedup. reply steve1977 7 hours agoprevTo add some anecdote, I remember doing a short animation with a Star Wars A-Wing Fighter (the model for which I downloaded, not made myself). I added light sources in the engines for that \"glow\" effect. Unfortunately, I messed up some of the geometry in the animation, so while the A-Wing was rolling to one side, the two lights were rolling to the other side ;) Which I of course only found out after a day or so, as renders were so slow (and this was something the size of a poststamp...) reply dicroce 6 hours agoprevDamn, I remember finding POVray on BBS's in the pre internet days. So cool that they have kept it going all this time. reply usefulcat 4 hours agoprevI remember being in college in the 90s when the school got a bunch of new HP workstations for the lab. perl + povray + rsh = distributed rendering! reply CodeCompost 10 hours agoprevIt's been a long time since I have looked at POV ray and my knowledge of it is woefully out of date, but does POV ray currently make use of hardware acceleration or is it still CPU bound? reply defrost 10 hours agoparentBy their FAQ: CPU, FPU, Bus speed, and Memory bound - in decreasing order of relevance. Will POV-Ray render faster if I buy the latest and fastest 3D videocard? 3D-cards are not designed for raytracing. They read polygon meshes and then scanline-render them. Scanline rendering has very little, if anything, to do with raytracing. 3D-cards can't calculate typical features of raytracing as reflections etc. The algorithms used in 3D-cards have nothing to do with raytracing. Does POV-Ray support 3DNow for faster rendering? No, and most likely never will. https://wiki.povray.org/content/Knowledgebase:Miscellaneous POV-Ray 3.7.0 (released 6 November 2013) is the current official version for all platforms. There are significant internal changes in this version due to the introduction of SMP support. https://www.povray.org/download/ reply jb1991 10 hours agorootparent> 3D-cards are not designed for raytracing. That's a rather old statement. Nvidia and Apple GPUs have hardware-accelerated raytracing now. But even without specific raytracing features, lots of renderers use GPU compute for some of the raytracing workflow. reply Kim_Bruning 7 hours agorootparentThings have changed a bit since that was written. Of course nowadays Graphics cards do permit somewhat arbitrary code to run, and can also be used by a ray tracing engine. Of course said engine has to be written to utilize them. For instance, the Cycles [1] engine in Blender. If you're into ray tracing as a hobby you have to play with it at least once! Cycles does probabilistic rendering and can handle tricky things like caustics. [1] https://www.cycles-renderer.org/ [2] https://docs.blender.org/manual/en/latest/render/cycles/gpu_... (edit) : TIL there's also Luxcorerender, which is also an engine that can render using GPU. https://luxcorerender.org/heterogeneous-computing/ reply jb1991 4 hours agorootparentCycles is not the only one, about half of mainstream commercial 3D renderers are using the GPU for rendering now. Possibly more than that. reply defrost 10 hours agorootparentprevIt dates back to 2013. I've merely quoted what the POX-Ray site has to say about it's own capabilities and beliefs at the time of writing. reply TapamN 9 hours agorootparentIt's older than that. I remember that from ~2002, when I used POV-Ray for a class project. reply dagw 9 hours agorootparentPOV-Ray itself dates back to the early 90s (and was based on code from the 80s). The FAQ in question was last updated 2013, and the paragraph about graphics cards is probably older than that. reply ofrzeta 10 hours agorootparentprevAre you telling me my 3dfx Voodoo card is useless? reply _joel 7 hours agorootparentStill in production... I guess :) https://www.vogons.org/viewtopic.php?t=100871 reply animal531 8 hours agoprevProbably 25 or so years ago I created my first render ever, in POV-Ray of a LEGO character's head using a hypercube. I only had a ruler to use for measurements of the head shape and the face and it took me quite a while, but it came out better than any other LEGO render I ever saw during that time. I was quite proud of it for such a simple thing. reply lordfrito 3 hours agoparentBricklink Studio 2.0 lets you build and render Lego models using POV-Ray [1]. Looks as amazing as it sounds [1] https://studiohelp.bricklink.com/hc/en-us/articles/650602210... reply nanoxide 8 hours agoprevMy first ever contact with programming back in 8th grade some 20 years ago. My then-teacher's website about PoV-Ray is still online, in all its late 90s goodness (in German): http://asti.vistecprivat.de/index.html reply david_p 7 hours agoprevI was 12 in 1996, in southern France, and my art teacher held a lunch-time club to teach us 3D modelling. We were using MNM (midnight modeler) and POVRay to create some cool 3D models on my schools 386 computers. I was dreaming of, one day, working at ILM. Good memories :) reply hooby 5 hours agoprevI remember playing around with that like... 20 to 25-ish years ago. Back then only pre-rendered cut-scenes could come close to having graphics like that, and I dreamed of the day when games actually look like that realtime. Kinda ironic that now that games actually do look like that (if not even better), I prefer to play retro pixel-art indie games, which actually put their focus on gameplay instead of graphics. reply anthk 1 hour agoparent>Do look like that Eeeeeeh... some advanced scenes with crazy complex lightning are still unmatched even from Unreal 5. reply jpitz 3 hours agoprevI spent a lot of time with POV-Ray. Back in ~1992 I had the IBM C++ Compiler for OS/2 and spent a day or so tweaking the source to get it to compile. Fun times. reply chadcmulligan 7 hours agoprevUsed to use this and moray to make \"cool\" 3d graphics for clients around the early 2000's, such fun edit: moray is available on the wayback machine https://web.archive.org/web/20220331032107/http://www.stmuc.... reply dayjah 7 hours agoparentAble to share any of the “cool”? I feel like a hit of nostalgia rn. reply chadcmulligan 6 hours agorootparentlong gone unfortunately, though not that fancy, just made some text in moray and applied some materials, in a semi transparent box or sphere, render. The reaction was always wow, I always chuckled at the time. reply chaoticmass 3 hours agoprevThere was a POV ray render of a McIntosh tube amp that I used to show people and nobody knew it was computer generated. reply chaoticmass 3 hours agoparenthttps://hof.povray.org/images/mcintoshhdri3.jpg reply Keyframe 9 hours agoprevMemories! POV vs Vivid flame wars. I think it were amongst first adventures in gfx on PC I had, outside of SGI and Amiga. reply usrusr 9 hours agoprevThe POV-ray syntax with its wild mix of curly and whitespace state description driven by a C-preprocessor lookalike successfully primed my mind for making the jump from Basic and Pascal to C (and eventually to other curly languages). Eternally grateful, also to the IRTC that made me spend enough time with the syntax to have a strong learning effect. reply cadr 4 hours agoprevI remember including something I rendered in POV-Ray on one of my college applications in the mid-90s. reply MentallyRetired 4 hours agoparentRight? seeing the name brought back a rush of memories. I had no idea it was still around. reply benterix 4 hours agoprevAh sweet 1990s... I remember tinkering with POV-ray and then discovering Blue Moon Rendering Tools - it felt like magic! reply jgarzik 5 hours agoprevDKBTrace and POV-Ray were my introduction to CGI. Open source meant it was possible for an Average Person with No Budget to do CGI animations and stills. reply sztanko 9 hours agoprevAre there any modern alternatives to POV-Ray? reply dagw 9 hours agoparentDepends what you mean? If you want a modern high performance ray tracer with support for all the latest hardware and implementing all the cutting edge ray tracing research, there is Embree and OptiX. They don't however come with their own scene description language, which is what made POV-Ray so popular in the first place. reply zokier 4 hours agorootparentOpenUSD is probably the closest thing in terms of scene description? You have both Python Api and human-readable ascii format reply sztanko 9 hours agorootparentprevI was thinking for some python (or similar language) api for Ray tracer that doesn't have a steep learning curve and is easy to use. reply kristianp 8 hours agorootparenthttps://mitsuba.readthedocs.io/en/stable/index.html There seems to exist python front ends to embree. How good this one is, I don't know. reply jlarocco 1 hour agoparentprevWhat's wrong with using POV-Ray? reply _pferreir_ 8 hours agoparentprevDoesn't Blender's main rendering engine, Cycles, sort of use ray tracing (path tracing, I believe)? reply icf80 10 hours agoprevthis is old as me play it with a long time ago ~20 years reply Nekorosu 10 hours agoparentIt's 29 years for me. It's my first 3D rendering software. reply secretsatan 10 hours agorootparentMe too, oof reply falcor84 10 hours agoparentprevWould you mind sharing some detail? reply Aardwolf 10 hours agorootparentWhile I can't know what the parent-parent post meant, POV Ray is around for over 30 years and was popular in the early 2000's on the internet as well, and is fun to play around with, I remember people posting renderings on forums like gamedev.net etc... reply deepakg 10 hours agorootparentAlso reminded me of the internet ray tracing competition https://www.irtc.org/ where many submissions would’ve been produced using POV Ray. reply schoen 10 hours agorootparentI really appreciate seeing things that are named after the Internet as part of the exuberance of being able to do or share them on a worldwide network. Naming something after the Internet itself is probably most common in the 1990s. reply bobim 6 hours agorootparentprevParticiped once, and ranked low... I could only dream about the skill level of our french master Mr Tran. reply pragma_x 4 hours agoprev32+ years and still kicking. Simplicity at it's best: all you need is a text editor and lots of CPU time. reply jandrese 3 hours agoprevWow, POV-Ray, what a blast from the past. I thought it might be fun to see how fast a scene renders today vs. back in the 90s with my Pentium-75, but apparently they've decided to integrate Boost so it takes forever to compile. Edit: My old scripts are no longer compatible. :( Edit2: The -MV option is your friend. :) Yeah, modern machines are fast. Trace Time: 0 hours 0 minutes 0 seconds (0.126 seconds) I seem to recall this render taking a couple of minutes on my old machine. reply mytailorisrich 10 hours agoprevIt ran on Atari ST and I remember I had to let it run all night to get fancy reflective spheres in all their 320x200 glory. reply DragonMaus 7 hours agoprevI spent so many hours with POV-Ray when I was younger, rendering LEGO models I had made with MLCAD. Some of those renders even found their way into a project I did in school for CAD class. reply josefdlange 3 hours agoparentNostalgia unlocked... reply contingencies 8 hours agoprevIf you once enjoyed POV, check out OpenSCAD. It's quite similar in terms of CSG concepts and primitive animation capability, but more useful for getting actual mechanical design work done. https://openscad.org/ reply RobRivera 1 hour agoprevPovRay, now thats a name I have not heard in quite some time reply benwerd 4 hours agoprevHonestly delighted that this still exists. Like others, I used to leave my computer running overnight to render. Dating myself, but it was a big deal in the BBS scene in the UK in the early nineties - so many files and techniques being swapped. reply brcmthrowaway 2 hours agoprevHow does POVRay compare to Cycles? reply koolala 5 hours agoprevPOV: PLY Author reply opentokix 9 hours agoprevIt's been a minute since I heard pov-ray mentioned :D - Had fun playing around with it in the early 2000s reply doubloon 7 hours agoprev [–] This is what I thought the internet wiuld become, back in the 1990s, just tons of projects like Povray. Not addeictive dark pattern trillionaires, see the recent Eli Gray article posted on HN how big tech enables link fraud for example. This was before FAANG existed as it does now. Apple was a struggling PC maker and Microsoft was the evil empire being challenged by a Finnish college student. Sun and SGI and DEC were big tech and they made you know… actual tech. It was this crazy dream that it would last like that forever, that the internet would just be one huge BBS of Povray style people, makers and users, who were interested in art and science above all else. Nobody was thinking you could contract third parties of poor people to screen out death videos on your BBS so they would have PTSD but you could make billions. Nobody was thinking to clickfarm children. reply goeiedaggoeie 7 hours agoparentAs I have aged (almost 50 now) I have realised that greed will turn any good thing dark without vigilance, and then who watches the watchers. Eternal spring perpetually. A culture which prioritises individual profits over the commons will destroy anything not regulated. As I have said before on this forum, we need a way to price in the whole lifecycle of manufacturing through to waste and punishments for behaviour like Purdue and the opioid crisis should be the loss of all wealth generated by such dark behaviour. of course this is also unworkable, but I am not personally certain what is workable without a secular moral revolution. reply wcerfgba 7 hours agorootparentOr we could move away from pricing everything and the neoliberal obsession to turn everything into a market, and restructure our economy to provide everyone with their basic material needs, regardless of how much income they have. reply goeiedaggoeie 6 hours agorootparenteven if we restructure everything to meet human basic needs, pricing will still be part of the equation. finite resources means value has to be attached to materials. reply wcerfgba 6 hours agorootparentValue and price are not the same thing. Money is a form of access control which limits the availability of scarce resources to those people and organisations which have enough funds. It also collapses the value of all things to a single dimension. There are other ways to decide how much of something is produced and how it is distributed, for example participatory economics. reply TheOtherHobbes 6 hours agorootparentMoney isn't just a form of rationing, it creates the scarcity it claims to solve. A neoliberal economy wastes talent and skill in much the same way an ICE wastes most of the energy from the gas it burns. Vested interests clog up the engine and keep it from running cleanly and efficiently. This doesn't just create pollution of all kinds - physical, social, political, and ecological - which makes the environment a very unpleasant space for most humans. It also puts a hard cap on the maximum speed, which is nowhere close to what's possible. reply goeiedaggoeie 3 hours agorootparentpricing is the exercise of determining value, even in a non monetary economy (think barter or contribution) you still need to price the value of materials and time. obviously money creates secondary effects which are not related to value due to arbitrages and other effects, but I do not believe you can have finite resources without determining value, which is what I meant by pricing. reply miki123211 6 hours agorootparentprevWe still haven't found a better resource allocation model than pricing. We have tried central planning, and it resulted in horrendous living standards (as compared to the western world), queues all-night-long that you had to wait in if you wanted to buy bread in the morning, \"if you're not stealing from your employer, you're stealing from your family\" being adopted as a common proverb, and the whole system basically running (for some definition of running) on bribes, favors and theft. Communism finally fell around '89 in most of Eastern Europe, and we're still recovering. Perhaps you could solve some of these points with computer-aided optimization and dystopian AI-powered mass surveillance, but is that really what we want? In my view, the problem isn't capitalism, the problem is the government trying to fix capitalism, but instead making it much harder for small competitors to emerge, effectively causing almost-government-mandated monopolies. Think about what industries are complained about most in America, and how regulated those industries are. You can't just lay fiber, make medications or help patients without going through a regulatory minefield, mostly for good reasons, but this is why the big providers of these services aren't outcompeted by smaller ones. There's a reason why the mostly-unregulated big tech is considered to be one of the most trustworthy industries among most (non ideologically motivated) consumers, far surpassing any political party. Capitalism is sometimes bad, central planning is worse, but heavily regulated capitalism is the worst of them all. reply goeiedaggoeie 5 hours agorootparentA key problem with unfettered capitalism is the tragedy of the commons. If left alone rogue/selfish actors will destroy that which belongs to all of us and is required to live (see nature). How do you propose to solve this without \"benign\" interference? reply papa0101 6 hours agorootparentprevSo, a socialist society then? reply notact 6 hours agorootparentMake it opt-in, please. reply evilotto 3 hours agorootparentprevSee also: enshittification reply katzenversteher 7 hours agoparentprevVery well said. I miss the early days of the internet. In addition: Event though the net was not very safe at the time (no/poor encryption, no much monitoring by officials etc.) it kind of felt differently. Many users where at least aware of the dangers of speaking with strangers and downloading things but today it's somehow of more deceiving. It looks nice and shiny on the outside but full of traps. Maybe because the 90s web was less \"shiny\" on the outside, it was less deceiving? reply tacostakohashi 6 hours agoparentprevMe too... Sometimes I wonder, what is current / next thing that's like the PC / BBS / early internet scene of the 90s, with such a rich ecosystem of innovation, hobbyists, open source / shareware, where one or two people in a garage have as much of a chance of changing the direction as any entrenched company? At least from the outside, the bitcoin scene of the early-mid 2010s looked like that - although there was plenty of dumb hype about the \"product\" itself, there was also of opportunity for innovation with mining, exchanges, and trading setups. What seems like it could be the next such scene? reply sillysaurusx 7 hours agoparentprevWould you really go back to the internet as it was in the 90s? The current one may have problems (to say the least) but it also has miracles. I’d go back for nostalgia, but not for practical purposes. Even in the 2000s it was much harder to find information. Wikipedia didn’t launch until 2001, and wasn’t useful till long after. reply mmcgaha 5 hours agorootparentYes! Mostly for usenet but also for efnet and dalnet. reply lizknope 4 hours agorootparentUsenet in the early 1990's is still superior to modern forums. Threads could go on for years, the newsreader programs automatically marked posts as read and would only show you new posts in the thread. Compared to today it is hard to find what is new and then discussions die after a day on places like Hacker News and Reddit after it is no longer a top post on the page or subreddit. reply PhasmaFelis 2 hours agorootparentprev> Would you really go back to the internet as it was in the 90s? It's like looking at a sweet kid who grew up to be a huge asshole and saying \"would you really go back to that kid? He couldn't even drive a car!\" I don't want to be frozen in the embryonic phase. I want the bright future that was promised and then snatched away. reply hyperthesis 6 hours agoparentprev [–] Also the high-quality amateur scientist webpages. e.g. measurements on radiation heat loss to the sky when camping. OTOH... we now have sci-hub.se with high-quality professional scientist papers. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Persistence of Vision Raytracer (POV-Ray) is a free, high-quality tool for creating 3D graphics, with customizable source code.",
      "Notable updates include the beta release of POV-Ray v3.8.0, a Kickstarter campaign for an educational IDE by DKBTrace creator David K. Buck, and the 30th anniversary of POV-Ray.",
      "The site has recovered from a server crash, restored its wiki and forums, and announced new features like POV-Ray export in the white_dune 3D editor."
    ],
    "commentSummary": [
      "A Hacker News user shared their 25-day experience learning ray tracing with POV-Ray, igniting nostalgic discussions about early computer graphics and programming on older systems like the 386 and 486 processors.",
      "Users reminisced about long rendering times, hardware upgrades, and using software like POV-Ray and VistaPro, as well as programming in languages like C and Turbo Pascal.",
      "The conversation also covered modern tools like Blender, the evolution of 3D rendering, and the impact of big tech and economic models on innovation and resource allocation, highlighting the enduring influence of POV-Ray and early internet communities."
    ],
    "points": 271,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1718087804
  },
  {
    "id": 40641361,
    "title": "Noam Chomsky Unable to Communicate or Walk After Medical Event",
    "originLink": "https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html",
    "originBody": "CultureBooksNews Noam Chomsky, 95, ‘no longer able to talk’ after famed professor suffered ‘medical event’, ex assistant says The 95-year-old famed linguist has not been seen in public since June last year Maira Butt 1 day ago Noam Chomsky: ‘Israeli Intervention In U.S. Elections Vastly Overwhelms Anything The Russians May Have Done’ For free real time breaking news alerts sent straight to your inbox sign up to our breaking news emails SIGN UP I would like to be emailed about offers, events and updates from The Independent. Read our privacy policy Noam Chomsky’s health has deterioriated following a medical event, leaving him unable to communicate, his former assistant has said. The 95-year-old famed linguist has not been seen in public since June last year, with many commenting on the weight of his absence from the broader debate surrounding the war in Gaza. Chomsky, who has been vocal about his support for the Palestinian cause and what he has called the “crimes” of the Israeli state, has been notably absent from demonstrations and discussions on the issue over the last year. In a post shared by Media Lens, it was revealed that the MIT professor is unlikely to ever return to the public eye following the deterioration of his health. The post quoted Professor Chomsky’s former assistant Bev Stohl, who first shared the news on a reddit forum as she explained why the usually responsive academic “hasn’t been returning emails, or interviewing”. Stohl, who worked as Chomsky’s office manager at MIT for 24 years until her retirement in 2017, wrote on 5 February: “I’m in contact with a close family member, and we know the basics, and hope to know more in the near future. “In a nutshell, Noam is 95-years-old and suffered a medical event in June. As many have noticed, he has not been writing, corresponding, or interviewing, as his health situation has taken the majority of his time and energy. “He is still with us, now watching the news (he doesn’t look happy about what he’s watching).” Stohl shared further details on the linguist’s ability to communicate, adding that he was no longer mobile or walking either. (AFP via Getty Images) “His ability to speak is complicated by factors I can’t yet disclose,” she continued. “When the relative I’m in touch with visited him a month ago, he did not communicate with her. “He is not ambulatory. I’m not sure for how long this will go on. He is not in pain. His eyes are open and he seems to be watching what’s happening around him.” The assistant, who also wrote a memoir titled Chomsky and Me on her time working with the world-renowned thinker, provided an update in April as she wrote, “Noam has not made significant progress, I’m sorry to say. I doubt he will be able to return to the public eye, as he is not communicating much if at all.” Chomsky has been unbelievably kind over the years I've known him. He treats everyone as an equal. Doesn't care who you are. He would give as much of his time to a high school student as some celebrity or NYT reporter. And devoted himself to attacking cruelty and injustice. https://t.co/6aQBZSSSQX — Nathan J Robinson (@NathanJRobinson) June 8, 2024 Some of the comments have since been deleted as Stohl edited a post to say that Chomsky’s “family is very private” and she will “no longer be adding to this discussion”. The Independent has contacted Noam Chomsky and his literary agent for comment. Tributes have poured in from across the media industry as many noted the linguist’s passion for language, having dedicated over seven decades to the study of words and communication, and expressed sadness at his now limited ability. Nathan Robinson, founder and editor of socialist magazine, Current Affairs, is also co-author of Chomsky’s forthcoming book, The Myth of American Idealism: How US Foreign Policy Endangers the World. He wrote: “Chomsky has been unbelievably kind over the years I’ve known him. “He treats everyone as an equal. Doesn’t care who you are. He would give as much of his time to a high school student as some celebrity or NYT reporter. And devoted himself to attacking cruelty and injustice. “So many thousands of people have stories about how he has changed their lives. He certainly changed mine.” British-American journalist and Zeteo founder Mehdi Hasan added, “Sending prayers Noam’s way. There has been no one else like him in our lifetime.” More aboutNoam ChomskyGaza Most Popular Popular videos Sponsored Features",
    "commentLink": "https://news.ycombinator.com/item?id=40641361",
    "commentBody": "Noam Chomsky 'no longer able to talk' after 'medical event' (independent.co.uk)268 points by rudolfwinestock 17 hours agohidepastfavorite225 comments lz400 11 hours agoChomsky was doing so many podcasts up to the moment he disappeared from the radar presumably due to medical issues. I've seen him going for 2 hours with some nobody with 5K followers, being asked juvenile and stupid questions and answering with the patient of a Saint. He looked quite diminished physically, elderly and frail but mentally he's always sharp and his recall and memory is scary. I feel that in his later years he made a conscious effort to talk to young people and made them aware of the history and depth of the problems the world is facing, and he used very modern avenues to do so, like podcast interviews. I will always have the highest degree of respect for this man and an admiration for his integrity, sensitivity and scholarship. reply bbor 10 hours agoparentI’ve spent so much time watching this kind of content (plus the older lectures that are available) over almost a year of chores, lunches, and walks that it’s honestly bordering on parasocial. I of course don’t regret a minute; if you check these recent videos out it’s clear that he reiterates the same points over and over, but it never quite gets tiresome. Rather it gives the impression of someone who has truly glimpsed the structure of the universe, and thus is consistently going back to those same principles. Of course, I would recommend choosing “one half of his brain” (his terms) and not mixing the politics interviews with the cognitive science / philosophy ones lol. I haven’t looked for many linguistics talks of his from recent years, but I had the impression he was working on seriously technical stuff there right up until he couldn’t, too. I don’t know how I hope to sleep after this comment… I guess I’ll do him the honor of trying to rationalize my emotional/ethical interests, and care less about the passing of a world-renowned twice-(happily-)married scholar than the passing of children from war and famine. I hope he believes in us to finish his life’s work, answering the most fundamental question: “What kind of creatures are we?” He was never able to see his theories in the recent LLM breakthroughs, but we’re in the early stages of the Chomskian era of AI, philosophy, and human endeavors writ large, I think… the ChatGPT outage from earlier this year couldn’t have supported him any better without having said “colorless green ideas sleep furiously” outright! reply TiredOfLife 9 hours agoparentprevnext [2 more] [flagged] zkid18 9 hours agorootparentHave I overlooked anything? I'm not sure if, at the age of 95, he needs money from Russia reply sitkack 12 hours agoprevI love Noam Chomsky so much. To me he is epitome of what a rational caring intellectual should be. Number one, he strives for the truth and while can have intellectual blind spots, isn't afraid of calling them out. We had him has a guest speaker for an internal presentation at Google and of course we had some hyper-rational libertarian eastern block swe kid who was going to take him down and Noam was super respectful, spared with the kid for awhile and then changed the subject slightly while destroying the libertarian kid's entire argument. You don't just debate Noam Chomsky. https://nerocam.com/DrFun/Dave/Dr-Fun/df200304/df20030409.jp... Noam Chomsky vs. Michel Foucault - Dictatorship of the Proletariat https://www.youtube.com/watch?v=hpoLLAJ1t74 reply credit_guy 7 hours agoparent> I love Noam Chomsky so much. I don't. There are some things out there that are up for debate. But not Russia's invasion of Ukraine. Chomsky, for some weird reason, chose to take Russia's side. Edit: To be sure, I wish him full recovery and many more happy years. https://www.e-flux.com/notes/470005/open-letter-to-noam-chom... reply jcranmer 6 hours agorootparent> Chomsky, for some weird reason, chose to take Russia's side. Chomsky's foreign policy views can somewhat accurately be reduced to \"everything is either American imperialism or reactions against it,\" to a degree that he ignores the imperialist tendencies (and other unpleasantries) of countries that aren't the US because they're against the US. For example, his denial of the Cambodian genocide essentially boiled down to \"well, the US doesn't like the Khmer Rouge, so therefore everybody criticizing the Khmer Rouge was overselling the criticism, how was anyone at the time to know what they were doing?\" reply alecco 6 hours agorootparentprevJust Russia? Noam Chomsky had some financial money transfers and a series of meetings arranged by Jeffrey Epstein. At least one meeting with Ehud Barak (former PM of Israel). And he refused to explain himself. This got quickly swept under the rug. But it's there even on mainstream media if you bother to search for it. reply addicted 6 hours agorootparentConsidering he’s significantly anti-Israel I’m curious even if there were nefarious purposes behind his meeting with Barak what direction do you think it swayed him in? In addition a LOT of academics met with Epstein. The whole point of Epstein was that he clawed himself up the social ladder by schmoozing with money people and raising funds for academic work. It would be entirely shocking if Epstein raised all this money for academia and didn’t even try and meet probably the only famous academic in the world. reply hdbenne 6 hours agorootparentprevIf I recall, he did explain himself… it boiled down to it being none of your or my business. I despise Epstein, but as he was heavily involved in finance, I am sure many people had dealings with him that were not sexual in nature. You can find many things that Noam missed the mark on. To err is human. But this is conspiratorial and not fair. If you were judged by all the people you had financial or social dealings with I’d imagine you would share a similar sentiment. reply jasonvorhe 4 hours agorootparentJeffrey Epstein was sus ever since he appeared because of the way he suddenly rose up in ranks, got handed billions of dollars without having done any significant deals himself. His connections to Mossad and US elites should've raised red flags for someone like Chomsky. I see no reason to give anyone dealing with Epstein the benefit of the doubt. reply pcthrowaway 11 hours agoparentprev> We had him has a guest speaker for an internal presentation at Google Would have loved to be a fly on the wall had he been able to do a guest spot at Google recently. I'm willing to bet he would've gone off-script and given Google hell for their engagements with Israel and treatment of their own employees who protested. reply sitkack 11 hours agorootparentNoam wouldn't be allowed to speak at NeuGoogle. reply shrimp_emoji 1 hour agoparentprev>To me he is epitome of what a rational caring intellectual should be. >America bad, everything bad = America What a frighteningly distorted view of \"rational\" and \"intellectual\". reply collyw 5 hours agoparentprevEspecially when he said that the unvaccinated should be excluded from society. Nothing nice about him at all. reply sickofparadox 4 hours agoparentprevHe is such a terrible person he has his own section on the Wikipedia page for \"Cambodian Genocide Denial\"[1] and is heavily featured in the page for \"Bosnian Genocide Denial\"[2]. Chomsky is a disgusting hack who runs cover for any genocidal freak that pays lip service to the hammer and sickle. [1]https://en.wikipedia.org/wiki/Cambodian_genocide_denial#Chom... [2]https://en.wikipedia.org/wiki/Bosnian_genocide_denial#Revisi... reply me_me_me 2 hours agorootparentoh wow, its the same dead horse being beaten again and again and again. The whole thing is more semantical argument than ideological. Chomsky is not 100% right on everything and his world views are more black and white than the world they describe. But he is an excellent linchpin to validate your own views against. People who hate him always attack him based on few things from the past, while following/praising people who are spineless. reply cbanek 15 hours agoprevI actually emailed Noam Chomsky asking questions about Manufacturing Consent and actually got a reply. I always thought he was really cool for being so accessible to those who just had honest questions. I really hope he gets well soon. reply benbreen 14 hours agoparentSame. I emailed him about whether he'd ever met Margaret Mead, John C. Lilly, or Gregory Bateson in the 1960s while researching my book. I got this reply within hours: \"Afraid I never met any of those you mention, though I’ve followed their work for many years. I’ve never been close to intellectual elite circles, including people I very much admire.\" The time stamp for my email was Tuesday, Nov 26, 2019 at 2:19 PM. It was answered by chomsky@mit.edu at Tuesday, Nov 26, 2019 at 9:29 PM. Pretty remarkable. reply bn-l 14 hours agorootparent> I’ve never been close to intellectual elite circles That is very humble reply exe34 13 hours agorootparentis this sarcasm? I read it as \"I'm not welcome to parties because I don't toe the line\" reply Scarblac 11 hours agorootparentI don't understand how you can get any information from that line about the reasons why he wasn't close to them. reply bn-l 12 hours agorootparentprevNo, no sarcasm and that's how I read it too. reply vasco 11 hours agorootparentSo how is it humble? He is just saying he didn't hobnob with known intellectuals - isn't that just a statement of fact? reply exe34 12 minutes agorootparenti think it's the opposite of humble, it's saying that he knows something that these intellectuals don't. reply dotancohen 11 hours agorootparentprevChomsky has very controversial opinions on some subjects and I suspect that precludes him being invited to many parties. reply serf 10 hours agoparentprevSame. When I was young I emailed him with a question something like \"I am too young to have witnessed the events of the Vietnam War, can you please recommend me some reading material or push me in the right direction?\" That question turned into 5 or 6 (long) emails back and fourth that i'll always cherish that delved into his unique perspective on what the war was like as a protestor from the West, which papers got released that actually had some truth in them, among a lot of other valuable insights into the time period I had no access to myself. At the end of our conversation he advocated finding a group that needs volunteers and effort. He didn't care what group that might be, he only cared that individual political concern of individuals be empowered by the necessary groups and collective effort. I think that kind unequivocal support of 'being political' is something that is truly special. I hope the best for him -- I view him as one of the only 'truly accessible' academics in this world; just as happy to slowly and carefully explain his thoughts to 'the rabble' as he would be while explaining the same thoughts to high academia and the press. A great man. reply nomilk 15 hours agoparentprevDocumentary of the same title for anyone curious: https://www.youtube.com/watch?v=Li2m3rvsO0I reply cbanek 14 hours agorootparentI honestly think the documentary is shorter and better than the book, thanks for the link. reply me_me_me 2 hours agorootparentThe book is very much still relevant reply llmblockchain 14 hours agoparentprevI emailed him in ~2012 and got a response as well. Keep in mind, I was not a student at his university and I emailed him out of the blue. Incredible guy! reply TaylorAlexander 12 hours agoparentprevSame! I emailed him asking for his thoughts on robotics and anarcho-communism and he replied pretty promptly. He said it was an important subject and that he was moving offices (this was his move to Arizona), but I could ask again another time. I never quite had the time to prepare for what I would have asked for, some kind of discussion I could record, which he was doing a lot at the time, but I was very happy just to have gotten a supportive reply the first time. For anyone curious, here is Chomsky in 1976 discussing the relevance of automation and anarcho syndicalism to modern productive economies: https://youtu.be/h_x0Y3FqkEI I truly believe we can build a world where everyone benefits from automation, getting the freedom and time to do what we will that every person deserves. The reason I develop open source farming robots is to explore concepts of community ownership of the means of production and community oriented engineering. Noam Chomsky’s work heavily inspired the thinking that got me where I am today. reply cbanek 12 hours agorootparentThat's definitely a big question. I asked a pretty open ended question about how he thinks the internet (and filter bubbles in specific) might have changed some of his thoughts in manufacturing consent as the main media went from TV / newspapers (broadcast) to internet (personalized). He said that basically the big companies own it all anyway. reply vasco 11 hours agorootparentprevWhat makes you believe this would work? Specifically any form of anarchism? Have you seen groups of people operate for large periods of time successfully like this? Anything I've looked into shows me human nature would make any anarcho-anything system fail due to infighting. reply orwin 7 hours agorootparentLip's history. My father knew Neuschwander, so maybe i'm biased, but Lip was truly an example of what anarcho-syndicalism can and should be, and survived 5 years despite fighting both a government and all the industry leaders, because it couldn't be allowed to work. I think US historians wrote books on it, but often fail to mention that after (or really, a bit before) Neuschwander took control, the metal and steel industry that sold them metal gave them structurally deficient steel, poor quality copper and were largely inconsistent in their metal delivery, being late for months, then giving them all the late commands at the same time, stretching or overflowing their storage. The luxury store and industry wasn't any better (one more reason to hate LVMH and never support them as a French), leaving their products in inventory and not in display, rejecting previously accepted commands, and limiting foreign exports to less than the number of exported goods than when Lip watches had to be smuggled. The courts and police didn't help and (according to what i heard: this is a biased account) refused to take any declaration. reply TaylorAlexander 8 hours agorootparentprevHave you seen what the current system of bourgeoisie corporate rule is doing to us? Is that system “working”? In June 1888 Peter Kropotkin wrote “Are we good enough?” on the subject of human nature and anarchism. It’s well worth a listen: https://youtu.be/jytf-5St8WU reply em-bee 1 hour agorootparentpeter kropotkin was right about the then state of things, but he missed the true solution. if i understand it correctly he is saying that in light of us not being good enough, a communist system is better than a capitalist one. and yet, communist systems largely failed. the real solution is to fix the \"are we good enough\" problem and change education such that we actually become good enough. this requires moral education to a degree that is not happening anywhere yet. the reality is that as peter says in the beginning, if we were good enough, then the system would not matter. and has history has shown, as long as we are not good enough, any system remains exploitable. communism brought a temporary relief but ended up failing because we still were not good enough. so lets forget this arguing about which system is better. it does not matter. what matters is that we learn to become good enough. that should be our goal. that's the only way to eliminate all problems. reply vasco 6 hours agorootparentprevThanks for sharing. I don't need to think we have a great system to have questions about something else not working, I'm just curious if it has because when I read about most anarcho-* philosophies I seem to see gaps in them. It doesn’t mean I'm right, just trying to learn more. There's already two good shares to read up later :) edit: thanks again, your linked video is perfect, I have held this exact view that \"we're not good enough\" for communism/anarchy, so this is the perfect challenge to my current beliefs! reply ngcazz 11 hours agorootparentprevWhat makes you believe anything would work? Things take people wanting them. reply vasco 11 hours agorootparentThere's many years of evidence of other systems and how they work and their trade-offs, so you can read about them. I haven't read about a successful anarchistic system so I asked for more info in case they had it. reply Eisenstein 11 hours agorootparentprevGrand ideas about structuring a society based on a premise or an ideology or ideal end up being disasters when attempts are made to put them into practice. It should be pretty simple to understand why: no one person or group of people can predict all eventualities or contingencies and it is not possible to design a system based on rigid ideals that can fail gracefully. reply pydry 9 hours agorootparentprevSpain, the Paris Commune... The problem with anarchism is never infighting it just wasnt good at defending itself from external military threats. Stalinism on the other hand, was a perfectly crafted machine for dealing with external military threats, but wasn't very nice to live under. reply Anthony-G 4 hours agorootparentHistorically, there have been a few examples of radical egalitarianism in revolutionary movements but like the Paris Commune they generally are short-lived – or never even become the dominant force, e.g., the Levellers during the English Civil Wars. It was the accomplishments of the CNT/FAI in organising one million members in 1930’s Spain that inspired me to become a libertarian socialist. However, since then I’ve come to the conclusion that the more egalitarian and democratic a society is, the more vulnerable it is to external and other threats. reply graphe 15 hours agoparentprevWhen did you ask him? I hope it was recently. reply cbanek 14 hours agorootparentSeptember 2022 reply xnx 15 hours agoprevThe full obituaries and reflections will come later, but the volume alone of papers, essays, books, articles, and interviews he's generated over his 95 year life is staggering. reply vr46 13 hours agoparentThe man writes faster than I can realistically read, but I still have a full shelf that I have dipped into over the last 32 years. Linguistics to Gaza, one of my proudest moments was once having some wingnut include me on a public list of enemies alongside Chomsky. reply vasco 11 hours agorootparentValentino Rossi and Noam Chomsky together against the world really is a pairing I didn't expect! reply hi-v-rocknroll 13 hours agoparentprevWithout a doubt. Manufacturing Consent and The Fateful Triangle* should be assigned reading to US high school students. * Today is in more-or-less the same predicament as 40 years ago Ralph Nader is also still out there at 90 producing content regularly. https://www.youtube.com/@RalphNaderRadioHour reply azinman2 15 hours agoprevSad to lose such an intellectual juggernaut’s voice. The world needs more Chomsky’s of all persuasions, and a culture that will elevate them. reply collyw 5 hours agoparentNah, we need more Thomas Sowells. reply throw__away7391 11 hours agoparentprevConsider an alternative perspective: He is an intellectual weakling who uses some highly speculative academic work, the veracity of which is still very much up in the air, as intellectual cover for a body of fallacious political commentary which is fully summed up as \"USA bad\". For example, he has refused to acknowledge the Bosnian genocide, downplayed every element, claimed the concentration camps where brutal torture was performed were \"refugee camps\", made all sorts of excuses for what happened, saying the guy on the cover of that '92 Time magazine (who looked like a skeleton) wasn't really that skinny. He has claimed that all of this was a western conspiracy to justify intervention. Why all of this? Because the perpetrators were communist, and in his world everything the US does is evil and everything the communists do is excusable. In Hegemony or Survival he doubled down on this again, even going as far as to make false claims about what the sources he cited said, a tactic he has employed repeatedly throughout his career. His writing and speaking style whenever he is talking about this is very dismissive, like \"of course everyone knows that...\", even when there is no such consensus, essentially trying to intimidate his audience into accepting his version of reality. When challenged on any of this he is quick on the ad hominem attacks, comes across as a pretty nasty person overall whenever he isn't in the company of adoring fans. His recent comments on the Russian invasion of Ukraine downplaying Russia's actions, blaming the West, and whataboutism references to various past US actions are merely a continuation of his life long anti-US, anti-NATO, pro-socialism view. I'd consider him essentially an enemy, at best a naive foreign asset. reply drekembe 11 hours agorootparentHis view regarding the Bosnian genocide is really strange imo. I would correct you that the people perpetrating it weren't really communists, but serbian nationalists. However, his \"USA bad\" take is correct because it's true. Being anti-US, anti-NATO, anti-imperialism is the only moral view to have when you look at the history and current politics of the US. reply StefanBatory 9 hours agorootparent\"Being anti-US, anti-NATO, anti-imperialism is the only moral view\" And trade it for Russian imperialism? Chinese? As an Eastern European being pro-US and pro-NATO is the only moral view. reply where-group-by 7 hours agorootparentI agree, but would reword it to \"self determination on a state scale is the only moral view\". And in most Eastern European cases that seems to be very much pro-US and pro-NATO. After all it is not like anyone is forced to join. reply foobarqux 10 hours agorootparentprevThey are not strange it's very easy to understand: He says that throwing around the word genocide for every atrocity cheapens the word and diminishes how bad the holocaust was. As for the parent the \"fat man\" he is referring to is the man in the back, not the man in the front. And the picture is pure propaganda: as he points out (and I believe was confirmed by the actual photographer) what is depicted and understood to show a prison isn't even fenced in. I would love to know what the \"false claims about what the sources he cited said\". I only know of one case were he mis-cited someone and it didn't change the meaning. reply surfingdino 12 hours agoprevSad news. I do not agree with him on everything, but I found his work and arguments he made a good counterbalance to those who are followers of Edward Bernays and his \"The Engineering of Consent\". reply lajosbacs 11 hours agoprevTo contrast a bit with other comments, he is very much disliked in eastern Europe. He was always pushing his multipolar worldview and not respecting that the Poles, Czechs etc. do not want to live under the Soviet/Russian 'pole'. My personal opinion is that he 1) hates the US 2) hates eastern Europe because it defeated socialism. I'd love to be proven wrong, but I do not think I will be. reply bantunes 11 hours agoparent> My personal opinion is that he 1) hates the US 2) hates eastern Europe because it defeated socialism. He doesn't hate the US. He hates that the US has been captured by warmongering elites and hates its poor. And he'd probably school you on the USSR's state authoritarian capitalism not being a good example of socialism. reply glimshe 10 hours agorootparentIs there a good example of socialism? reply imtringued 8 hours agorootparentI'm not sure it falls under socialism, but I always enjoy reading about the \"Miracle of Wörgl\" and Wörgl's mayor Unterguggenberger. There is even a movie about it! https://unterguggenberger.org/the-free-economy-experiment-of... reply rswskg 9 hours agorootparentprevlol, no. reply Malcolmlisk 9 hours agorootparentprevThe DDR. reply glimshe 8 hours agorootparentTrue, the Stasi was indeed pretty good at what they did. reply dgrin91 8 hours agorootparentprevEast Germany? Why do you call that a good example of socialism? Post-wall coming down it was mostly East Germans coming to West Germany, less of the reverse. Even today the eastern half of Germany is typically socioeconomically lower on most stats, and a lot of that stems from decades of decisions made in DDR. reply lajosbacs 8 hours agorootparentprev* actually deleted my reply, a non-troll cannot say this reply jbaber 8 hours agorootparentprevIs this ironic? reply lajosbacs 11 hours agorootparentprevWhat would then be a good example of socialism? reply Malcolmlisk 9 hours agorootparentThe DDR reply IsTom 5 hours agorootparentIt was so good that to this day there is an economic rift between former west and east Germany. reply hi-v-rocknroll 14 hours agoprevNooooooooooooooo...... How will colorless green ideas sleep furiously? :'[ Will miss his interviews on various forums often posted on YT and appearances on Democracy Now. Classic: Yanis Varoufakis with Professor Noam Chomsky at NYPL, April 16, 2016DiEM25 https://youtu.be/szIGZVrSAyc reply turndown 14 hours agoprevIntellectual giant whose shadow will be cast deep into the future. I don't need to review any of his work wrt to CS or linguistics to tell you that his legacy will be massive. I think Manufacturing Consent should go down as one of the most important books ever written in our culture. He was right about much, but wrong about much also. His beliefs on Cambodia strain credulity and I still have trouble separating that Chomsky, so bent on drawing an equivalence(however valid) between American actions and the Khmer Rouge that he missed the point entirely, and Chomsky the visionary philosopher who I admire deeply. reply hughesjj 13 hours agoparentHis thoughts on Serbia/Kosovo, Russia/Ukraine, likely Russia/ Georgia etc have all been problematic too. Chomsky was illuminating in my personal character development. I grew up in a pretty conservative area, and his name carried a lot of hate like Hillary/Clinton did, but i didn't know why. Later, I saw some of his writings on American interventionism, and I found myself nodding my head in agreement over the mistakes my country/we have made. Later yet, I'm in college going for the math+cs degrees and his stuff on formal languages was probably the peak of my admiration for him... but with the admiration comes research, and perhaps the most important thing chomsky illustrated to me was that you can be a genius, but that doesn't mean you can't be blind, myopic, wrong, an asshole, or ... non-credible. I don't know why chomsky's beliefs and supported causes are so inconsistent with the morals he pushes, but it's been an exemplar for me regardless -- good and bad, functional and broken. reply foobarqux 10 hours agorootparentAll these claims of \"problematic\" views fall apart as soon as you try to support them with citations/evidence. reply yakshaving_jgt 3 hours agorootparentThere is unfortunately a staggering amount of evidence of genocide in Ukraine committed by russia. To suggest otherwise, or to suggest that russia is \"acting with restraint and moderation\" as Chomsky said, is tantamount to Holocaust denial. https://www.newstatesman.com/the-weekend-interview/2023/04/n... reply foobarqux 2 hours agorootparentRegarding whether Russia were less destructive than the US in Iraq (or the other case he cites Israel in Lebanon) is a factual question. He cites the much lower UN casualty figures and points out that Russia did not target (initially, now they are) major essential civilian infrastructure like power plants. When people are confronted with this fact they typically turn to the argument that our team are pure-of-heart so their killing doesn't count. (By the way I can't find Chomsky saying the phrase you put in quotes in the transcript). I don't remember where or if he talked about the claim of genocide in Ukraine but there is not a \"staggering amount of evidence\" unless your definition of genocide is so broad as to include a large proportion of armed conflicts. In fact the only piece of evidence I know of is the displacement of children which was portrayed as kidnapping but I don't think there is any evidence supporting this compared to the more rational explanation that they evacuated civilians. The latest article I read on the topic gave instances of these kidnapped children now living with their families in Germany and elsewhere. Like I said these criticisms fall apart almost immediately when you start discussing the facts. reply roenxi 11 hours agorootparentprev> I don't know why chomsky's beliefs and supported causes are so inconsistent with the morals he pushes The obvious resolution to that paradox is either you don't understand Chomsky's morals or have mistaken what his beliefs are. Judging by some random interview from 2022 [0] it looks like he has a position on Russia/Ukraine that is easy to defend. He describes it as a \"principled, internationalist, anti-imperialist left response\" and that seems like a fair assessment from what I'm reading. Looks like pretty standard fare for anyone who doesn't like war and propaganda. [0] https://chomsky.info/20220408/ reply hughesjj 11 hours agorootparentI was thinking more about February 2022, where he tries to blame the Ukrainian invasion on nato expansion or something https://chomsky.info/20220204/ Oh also his georgian take https://chomsky.info/200809__2/ reply phatfish 10 hours agorootparentHe is still annoyed communism failed so epically. In his mind the Soviet satellites were to blame for wanting independence. It can been seen again with Ukraine, it's not that the Ukrainians are standing up for their independence, it is somehow NATOs fault. He has made some good points about western politics from time to time. Even a stopped clock is correct twice a day. reply roenxi 10 hours agorootparentprevWhat do you expect him to believe? If you go in with an anti-imperialist anti-war bias, then NATO expansion is a bit of a beacon when asking questions like \"why is their an active land war in Eastern Europe?\". I don't actually remember if there is a serious counter-proposal; most people tend to rely on the theory that Putin suddenly went unhinged - which is obviously not the belief a thoughtful leftist would come to. reply _djo_ 5 hours agorootparentNo, the alternative liberal internationalist view is that the preservation of imperial-like spheres of influence and ironclad regional hegemonies is unfair, u democratic, and at odds with the rules-based trade-oriented order we’d like to see the world continue to adopt. No country was forced to join NATO. In fact, it took years and years of lobbying from Eastern European countries before the first new members were allowed to join in 1999. Even then, plenty of care was taken to signal to Russia that it was strictly seen as a defensive measure, from allowing the Russian government in as an observer at all levels, to limiting the military capacity of the Baltics and putting a very low cap on the number and type of NATO assets that could be deployed in countries bordering Russia. The intellectual mistake that Chomsky and many who share his ideas make is to believe that just because Russia might reasonably feel aggrieved at no longer being able to politically and economically dominate the countries around it through the use of military force as it could as the USSR, that it somehow has a right to have that situation reversed and is therefore justified at launching an unprovoked attack on a neighbouring democratic country to gain back that power. There should be no such right in the modern era, and believing in it is a betrayal of traditional left-wing ideals. Ironically, returning to a might-makes-right global order as envisioned by Russia would mean the United States could behave far worse in future, pulling off the same kinds of annexations and similar as it did as a young power, and when it was far less powerful than it is now. reply roenxi 5 hours agorootparentI don't disagree with any of that. But you didn't deal with the \"why is their an active land war in Eastern Europe?\" question; which is what Chomsky was picking at to get to the NATO expansion point. > Ironically, returning to a might-makes-right global order as envisioned by Russia would mean the United States could behave far worse in future The US could act much worse in the present if it wanted. Only China is really in a position to stop them and even there only in a geographically limited area of Asia. The reason the US often doesn't bother with a might-makes-right response is because it isn't effective, not because they're purposefully holding themselves back from useful options. It is more effective to have the rule based order where, famously, the US makes the rules and gives the orders. reply _djo_ 2 hours agorootparent> I don't disagree with any of that. But you didn't deal with the \"why is there an active land war in Eastern Europe?\" question; which is what Chomsky was picking at to get to the NATO expansion point. Fair enough. To answer that, I’d say the actual trigger wasn’t NATO but the EU, and Ukraine wanting to join it and move out of Russia’s sphere of influence. This was coupled to a wave of new leadership who wanted a more western and central European alignment. That’s what the Maidan was all about, when Yanukovych unilaterally refused to sign the European Union–Ukraine Association Agreement and brutally cracked down on the resulting protests. That desire for closer ties with western and central Europe played out economically too, with the Ukrainian tech sector in particular being promoted as an outsourcing hub for European companies and holding conferences like Devoxx. Russia invaded because it knew it either subjugated Ukraine now, while it was still relatively weak but growing fast, or it lost the opportunity altogether. And in Russian strategic thought the idea of not being able to control Ukraine, which they see as an integral part of Russia, is anathema. > The reason the US often doesn't bother with a might-makes-right response is because it isn't effective, not because they're purposefully holding themselves back from useful options. It is more effective to have the rule based order where, famously, the US makes the rules and gives the orders. On some level, sure, but as China’s rise has shown the rules based order does not prevent competitors from rising up and eventually eclipsing US power. While the rules based order allows the US to use economic coercion, it also allows China to do the same. A might-makes-right approach can be effective, but it can also lead to world wars which are immensely destructive and which the US wants to avoid. It’s not just the US though, the EU is similarly in favour of substituting diplomacy and trade for military power. reply foobarqux 10 hours agorootparentprevThe same view that is held by a plethora of senior western officials such as Obama, William Burns (Former ambassador to Russia), Gates (Former Secretary of Defence), Angela Merkle, etc. reply pydry 10 hours agorootparentprevHe was entirely right about that too. NATO is an aggressive alliance that has exclusively invaded three countries in the last 20 years, zero of whom were threat to it. The worst one was probably Libya, because NATO pretended to engage in a humanitarian mission to gain approval from the security council and then left the country utterly destroyed state afterwards. The country was shredded. It's a tool of western imperialism that dangles the false promise of protection. In this respect it operates with the same logic as a gang recruiting teenagers before using them as cannon fodder. Of course you can't say these things in polite company just as I couldn't say that WMDs were a complete load of bullshit in 2003 without being verbally attacked. In 20 years time it will be seen as obvious, however. reply _djo_ 5 hours agorootparentThe invasion of Libya was fully authorised by the UNSC, and it was not conducted or approved solely by NATO. Libya was also already in a highly destructive civil war before the intervention, which is why it happened, so it’s not like they went in and destabilised a stable country. Gaddafi had built Libya’s security around himself in a cult of personality, things were always going to fall apart once his power waned. Which other countries did NATO invade? reply M2Ys4U 4 hours agorootparentNATO's intervention in Kosovo is the one that routinely cited. That wasn't defensive by any means, but that also doesn't make it unjustified nor should it really be called \"aggressive\". Chomsky, naturally, denied that ethnic cleansing was happening there because it wasn't the US or \"western\" countries doing it. reply _djo_ 4 hours agorootparentAgreed, Kosovo is the only actual NATO intervention of that sort. And agreed that it was neither unjustified nor ‘aggressive’. reply pydry 2 hours agorootparentKosovo, Libya and Afghanistan. In each case it was an aggressive imperialist power play. Putin's war was also a \"humanitarian intervention\" and his supporters mirror the exact same propaganda line uncritically. If NATO gave two shits about humanitarian interventions they would send troops to defend Gazans from a genocide. The people who think they do are little different to Putin supporters. reply _djo_ 2 hours agorootparentSee my other reply. In any case, that you can refer to these as ‘aggressive imperialist power plays’ shows you’re both not to be taken seriously and are not willing to engage in a good faith and informed discussion. reply pydry 2 hours agorootparentYes... in your other reply you said it was a humanitarian intervention to stop a genocide in Kosovo. Exactly like a Putin supporter would say about Ukraine. Except there was no genocide in Kosovo (Kosovo is not Bosnia) and there is no genocide in Ukraine. There is one in Gaza though and it is backed by NATO, the same people you called humanitarians. A Putin supporter also wouldnt be bothered about the murderous hypocrisy, but Chomsky was. Thats what set him apart. reply _djo_ 1 hour agorootparentThe Serbian campaign was ethnic cleansing on a massive scale, forcefully and methodically expelling over a million Kosovar Albanians from the area by the time they were stopped by NATO’s intervention. That does, arguably, rise to the level of genocide under the standard definitions. Just because someone can claim something doesn’t mean it’s right. That determination is up to independent observers, experts, and courts, and tribunals. Russia tried to claim at the ICJ that it was invading Ukraine under the Genocide Convention. The court ruled that it had to end to the invasion immediately, which Russia ignored. reply jcranmer 4 hours agorootparentprevThe other NATO interventions: * Intervention in the violent breakup of Yugoslavia, invited to do so by the UN in response to the genocide going on there. * Invasion of Afghanistan, following the invocation of Article 5 after an attack on a NATO country (i.e., 9/11). reply _djo_ 4 hours agorootparent> * Intervention in the violent breakup of Yugoslavia, invited to do so by the UN in response to the genocide going on there. Indeed. So not an aggressive invasion but a humanitarian intervention. > * Invasion of Afghanistan, following the invocation of Article 5 after an attack on a NATO country (i.e., 9/11). Not quite. Technically speaking, neither of the official NATO missions in Afghanistan, ISAF and Resolute Support, were Article 5 missions. When the US triggered Article 5 in October 2001 it explicitly did not request a full NATO response, but initially only for support such as NATO AWACS aircraft in US airspace. When it invaded Afghanistan, which was entirely justified in international law as an act of self defence, a handful of NATO countries opted to send support contingents, like SOF, as a way of showing solidarity. But it was not a NATO mission under NATO command: Operation Enduring Freedom was American-led and commanded from the beginning. At best you can say several NATO allies invaded. Later, NATO launched ISAF and Resolute Support and became more involved as an organisation deploying forces, but that was post-invasion. reply pydry 2 hours agorootparentThe invasion of Afghanistan was as much self defence as the invasion of Ukraine. Probably less, actually. The idea that it was any kind of self defence is kind of pathetic, and mirrors Putinesque propaganda. It was occupation pure and simple. America really wanted to set up military bases there. It was a black spot in the world which it lacked imperial force projection and it was right between 3 major rivals (Russia, China and Iran). reply _djo_ 2 hours agorootparentIn what sense was it not self defence under international law? reply pydry 1 hour agorootparentAfghanistan did not knock down the twin towers. It actually offered to hand over bin Laden if the US provided evidence of his involvement and tried him in a neutral country. That wasn't good enough for the US, who were itching for a military invasion anyway, and were keen to build some military bases in a spot where they didnt yet have any. The idea that the US follows international law is a sick joke. The idea that the country that created the Hague invasion act has nonzero respect for international law is laughable. reply _djo_ 1 hour agorootparentYou can’t seriously believe that. First, the Taliban ‘offer’ was so full of caveats as to be worthless and, most importantly, they refused to do anything about the rest of the Al-Qaeda organisation that they hosted and shared power with and which attacked the US. Putting Bin Laden on trial in some supposed neutral third country would’ve done nothing to remove the clear and present threat to the US that Al-Qaeda at the time presented. So, yes, the US’s actions were legal under international law. None of the major powers outside Europe have acceded to the ICC. Neither the US, nor India, nor China, nor Russia. reply pydry 2 hours agorootparentprev>The invasion of Libya was fully authorised by the UNSC, Yes as I pointed out. As I pointed out that made it worse because they lied to the security. They simply wanted to take sides in a civil war. Did you read what I wrote at all? reply LunaSea 11 hours agorootparentprevChomsky defends imperialism as long as it's not coming from western countries. reply nayaketo 11 hours agorootparentThis is the truth. He is only moral when it suits his hatred for his own country. reply racional 6 hours agorootparentprevHe describes it as a \"principled, internationalist, anti-imperialist left response\" and that seems like a fair assessment from what I'm reading. It's also a complete mindfuck of a piece, with obvious cognitive distortions and major factual evasions flying from every paragraph. But because it's expressed in that calm, authoritative, rational (sounding) voice -- and it's coming from Saint Chomsky after all -- \"principled, internationalist\" lefties eat it up like candy. I admire Chomsky for other things he's done. But he's got a split personality also, and in some cases his \"morals\" are very deeply flawed. reply KptMarchewa 10 hours agorootparentprevAll the \"anti-imperialist left\" support is someone else's empire. reply cageface 13 hours agoparentprevI grew up taking Chomsky's perspectives on the Vietnam war as gospel. After actually living there for 8 years and talking to many people about it I realized it was a lot less black and white then he paints it. reply feedforward 13 hours agoparentprevThe US began arming the \"Khmer Rouge\" (whatever that means) in 1979 as well as protecting them in the UN, so the equivalence seems pretty valid to me. Not to mention the US 1970 invasion of Cambodia and concurrent CIA-backed overthrow of the Cambodian government, which including shooting dead US students who protested against it at Kent State and Jackson State, or the US carpet bombing of Cambodia during and after Operation Freedom Deal. reply ein0p 13 hours agorootparentI recall vehemently disagreeing with Chomsky on many things when I was much younger, but then I somehow stumbled upon Howard Zinn’s “People’s history of the United States” and realized the version of history I knew was basically concentrated propaganda I was brainwashed into believing. That opened the door to understanding Chomsky. “Manufacturing consent” explains our present state of affairs really well. reply tptacek 13 hours agorootparentZinn's reputation among historians: not all that great. reply ein0p 13 hours agorootparentReputation of historians according to Zinn: not all that great either. Read him as a counterpoint, and food for critical thought, not as the sole source of truth. He doesn’t hide that he has an agenda. reply tptacek 12 hours agorootparentOK, but to be clear: his reputation among leftist historians, of which there are many: not all that great! reply caycep 13 hours agorootparentprevI did actually see him talk at a rally in Boston Common, around '04 or so. While his written stuff may well be better, what struck me was the gist was basically self promotion about how he know \"secret\" things from \"secret\" sources, but never really bothered to elaborate, only that the \"US Govt is lying to you\". Well yes but...I would say if one had such information, it is not well served by presenting oneself as a conspiratorial crank.... reply ein0p 12 hours agorootparentYes, US Govt is routinely lying to you. That is not controversial at all at this point. Read the book. It’s a difficult read though. Might ruffle some patriotic feathers. Think of how difficult it is today to get even remotely truthful news. And then think about how this horseshit will be written up by government funded historians once all the political scores are settled and winners are determined reply Eisenstein 11 hours agorootparentI don't think the solution to having been taught one biased view is to turn around and embrace the oppositely biased view. Countering one form of extreme with another does not make truth, it makes people who hate each other who refuse to find common ground or compromise. reply vasco 11 hours agorootparentprevI mean if you want another perspective you can simple Wikipedia \"American Empire\". It'll be simple enough for another view of current state of affairs without going into politically motivated alternative history, either from communists or from milton friedman fans. It annoys me to no end that both right wingers and left wingers like so much to tell history how it's convenient to them and always hard to get something unbiased. Even numbers of deaths can't be trusted before you check who you are reading. reply ein0p 3 hours agorootparentBut Wikipedia is also full of lies and omissions, though. You're going to have to work to synthesize some plausible version of the past from the politically motivated sources either way. reply yareal 13 hours agorootparentprev\"People who I am critical of don't like me\" is not particularly surprising, to be honest. reply hi-v-rocknroll 13 hours agorootparentprevI was more-or-less a free-market, atheist libertarian until about age 16 because I didn't know any better and it seemed so righteous and freedom flag-waving. Then, I learned a few things decades since then (but kept the atheism), especially about the dark origins of libertarianism. The truth is that America is a neocolonial power that flirts authoritarianism where one can live an easy life if they're moderately rich, but on the backs of a massive, struggling underclass that has it much worse than most countries in Europe. \"Socialism\" is a taboo word in America that it needs much more of, but the problem is that most people have too much faith in strongmen, corruption of campaign financing, and giving corporations more money, more power, and favorable regulations including regulatory capture. reply ein0p 12 hours agorootparentI’m starting to waver on atheism also. I’m not likely to start believing in god this far in my life, of course, but I now see why a lot of people feel the need to believe, and I no longer judge them for it. I do however judge religious organizations for shamelessly exploiting that need. reply karmakurtisaani 2 hours agorootparentPerhaps I could sell you the idea of ignosticism: one cannot prove anything about any supernatural beings, so the whole question of existence of gods is meaningless, and can be therefore happily be ignored. Thus, all religious questions are resolved. Even atheism is a strong stance and asserts a belief that you cannot test! reply verticalscaler 11 hours agorootparentprevIf you reread what you wrote carefully an amazing irony falls out. You might consider your consent has simply been manufactured in another direction. Lots of Chomsky acolytes never quite reach that epiphany. They simply follow in his footsteps of being oh so traumatized by the sudden realization that governments lie and propaganda is a thing that you could get them to opt in to an even deeper set of absurdities and half truths quite easily. To the great delight of the enemies of the US. This is how you get college students to chant \"Death to America\". reply corimaith 9 hours agorootparentSecond option bias comes to mind here, funnily enough the alt-right utilizes the same tactics. reply verticalscaler 8 hours agorootparentIndeed. Alt-right/left/whatever. Very potent tactics as you can tell even from reading this thread. You would think people who come to these bitter realizations would know better but many inevitably land on \"the ends justifies the means\" or the less sophisticated \"only our scum enemies lie!\" and round and round we go. reply cm2187 10 hours agorootparentprev1979 was after the genocide and after Pol Pot was pushed out of power. Implying the US had something to do with the killing fields defies common sense. The khmer rouges were primarily China and North Vietnam backed. Now the US did support some incompetent and corrupt militia in Cambodia to oppose the Khmer rouges, and those did their fair share of misdeeds, to the frustration of local US officers. But given the crimes the khmer rouges ended up committing, it is hard to argue that not opposing them was the morally superior position, even with hindsight. reply foobarqux 10 hours agorootparentIt's like saying the war in Iraq has no effect on the current situation there. reply cm2187 9 hours agorootparentYou mean like saying the US is the cause of the Shia-Sunni hatred? reply feedforward 2 hours agorootparentprev> The khmer rouges were primarily China and North Vietnam backed. Vietnam invaded Cambodia in 1979 and China invaded Vietnam in 1979. What are you talking about? reply cm2187 1 hour agorootparentIn April 1975, the Khmer Rouge seized power in Cambodia, and in January 1976, Democratic Kampuchea was established. During the Cambodian genocide, the CCP was the main international patron of the Khmer Rouge, supplying \"more than 15,000 military advisers\" and most of its external aid.[82] It is estimated that at least 90% of the foreign aid to Khmer Rouge came from China, with 1975 alone seeing US$1 billion in interest-free economic and military aid and US$20 million gift, which was \"the biggest aid ever given to any one country by China\" And if you read the article, north vietnam was their main backer before. https://en.wikipedia.org/wiki/Khmer_Rouge#1975%E2%80%931993 reply turndown 13 hours agorootparentprevI worded that part poorly, and did not bring up what really bothers me about it, that he tried to deny that there was a genocide in Cambodia. I agree with what you said. The idea that the US is innocent in Cambodia or really anything going on in that part of the world at that time is beyond false. reply lamontcg 12 hours agorootparentHis point was always that the most inflated estimates of deaths in Cambodia were uncritically accepted by Western media and widely broadcast, while atrocities committed by friendly nations always leaned towards the very low estimates and the stories were buried. reply vintermann 12 hours agorootparentYes, the accusation that he denied the Cambodian genocide is false, and a tactical smear. reply Aloisius 12 hours agorootparentChomsky wrote that \"The 'slaughter' by the Khmer Rouge is a Moss-New York Times creation.\" I'm unsure as to how that would be anything but genocide denial. reply andrepd 11 hours agorootparentHe wrote that before the truth was known, while the genocide was ongoing and the only thing we had was scattered reports of atrocities. This was the 70s, we did not exactly have telegram livestream channels from the frontlines. It was a mistake and he recanted those views in the later stages of the regime and afterwards, when the evidence became overwhelming. reply Aloisius 11 hours agorootparentBefore the truth was known? No. Before he accepted the truth after it became untenable for him to continue to reject it. Chomsky simply rejected all the earlier evidence pointing to a genocide as an American imperialist lie. For goodness sake, he characterized Barron and Paul's Murder of a Gentle Land as being sourced from \"informal briefings from specialists at the State and Defense Departments\" despite it clearly sourcing testimony of hundreds of Cambodian refugees and Khmer Rouge radio broadcasts. His characterization of it was so intellectually dishonest that it is difficult to believe it was either an intentional lie or willful ignorance. He searched for any counter-evidence that would confirm his belief that the US was evil (and its adversaries were good or just misunderstood), no matter how questionable - a pattern he continued his entire life. reply foobarqux 9 hours agorootparentThis is just false. The main piece of evidence -- the death figures published by La Couture -- which was being widely cited, had to be retracted after Chomsky fact-checked it. The author himself said in the retraction something to the effect of \"it doesn't matter what the numbers are\". As for \"Gentle Land\" he supports his claim that \"[their] scholarship collapses under the barest scrutiny\". He writes: \"To cite a few cases, they state that among those evacuated from Phnom Penh, “virtually everybody saw the consequences of [summary executions] in the form of the corpses of men, women and children rapidly bloating and rotting in the hot sun,” citing, among others, J.J. Cazaux, who wrote, in fact, that “not a single corpse was seen along our evacuation route,” and that early reports of massacres proved fallacious (The Washington Post, May 9, 1975). They also cite The New York Times, May 9, 1975, where Sydney Shanberg wrote that “there have been unconfirmed reports of executions of senior military and civilian officials … But none of this will apparently bear any resemblance to the mass executions that had been predicted by Westerners,” and that “Here and there were bodies, but it was difficult to tell if they were people who had succumbed to the hardships of the march or simply civilians and soldiers killed in the last battles.” They do not mention the Swedish journalist, Olle Tolgraven, or Richard Boyle of Pacific News Service, the last newsman to leave Cambodia, who denied the existence of wholesale executions; nor do they cite the testimony of Father Jacques Engelmann, a priest with nearly two decades of experience in Cambodia, who was evacuated at the same time and reported that evacuated priests “were not witness to any cruelties” and that there were deaths, but “not thousands, as certain newspapers have written” (cited by Hildebrand and Porter).\" Elsewhere he cites official CIA figures which also did not support the claim. But none of this was even the point of his article, he explicitly writes \"We do not pretend to know where the truth lies amidst these sharply conflicting assessments\". The point is that the evidence is distorted to smear enemies and make ourselves look good. He writes in the penultimate paragraph: \"What filters through to the American public is a seriously distorted version of the evidence available, emphasizing alleged Khmer Rouge atrocities and downplaying or ignoring the crucial U.S. role, direct and indirect, in the torment that Cambodia has suffered. Evidence that focuses on the American role, like the Hildebrand and Porter volume, is ignored, not on the basis of truthfulness or scholarship but because the message is unpalatable.\" That is the simple message that Chomsky has been conveying his entire political life and, as exemplified by current events, people continue to ignore it. reply Aloisius 15 minutes agorootparentChomsky's entire shtick was to start from the belief that the US is evil and that any evidence that might be favorable to US positions is suspect, then searching for contrary evidence, no matter how questionable, to show this was the case - even if it means manufacturing or distorting it. Olle Tolgraven? He said the Khmer Rouge were shooting people during the ordered mass evacuation, something Chomsky left out. He also left out the other accounts from the same article which describe Phnom Penh as being littered with decomposing bodies. He pointed to Hildebrand and Porter and called it \"based on a wide range of sources\" when in reality, everything documented after the Khmer Rouge took charge came from one source: official Khmer Rouge propaganda. In order to refute claim Barron and Paul that \"virtually everybody saw the consequences\" he invented citations to J.J. Cazaux and Schanberg so he could use carefully cherry-picked quotes from them against it. Chomsky claimed publications like the Economist have \"analyses by highly qualified specialists who have studied the full range of evidence available, and who concluded that executions have numbered at most in the thousands.\" Notably, the Economist did write an article that hundreds of thousands had been executed. The claim the number was in the thousands came not from the Economist's highly qualified specialists, but rather a letter from a reader in response to that article. It goes on and on and on and on. If Chomsky was held to the standard he held others, we would dismiss him as not credible for even a fraction of the half-truths and lies he peddled. aborsy 12 hours agoprevSad news. He was remarkably sharp even in old age. reply Zanfa 9 hours agoparentI can't speak to his opinions on other topics, but since the full-scale Russian invasion started a few years ago, his frequent opinion pieces on world politics started popping up a lot. They were some of the most batshit insane, genocide-apologist takes on the situation that I've ever read. reply 1equalsequals1 6 hours agorootparentYou should try reading more then reply collyw 5 hours agorootparent\"The unvaccinated should be excluded from society\". Amazing the he wrote manufacturing consent yet fell for the COVID propaganda so hard. reply chipotle_coyote 3 hours agorootparentIf you believe that \"vaccinations protect us against disease\" is propaganda, I have very bad news about whatever information sources you've been following. reply Izkata 1 hour agorootparentHe was talking about the covid vaccines when he said that, which never prevented infection or spread. That belief started from a misunderstanding of the press releases. He either didn't know what he was talking about or was making it a moral thing without regard to effectiveness. reply karmakurtisaani 2 hours agorootparentprevWe're quite fortunate the internet wasn't a thing when polio was still around. reply beaeglebeachedd 22 minutes agorootparentPolio measures did not focus on sacrificing the children for the elderly. COVID school and social/learning activity shutdowns did. reply serial_dev 12 hours agoparentprevI'm not sure he was. Just 2 years ago, he wanted to remove everyone from the community who was refusing to get the vaccine, and emphasizing that how they get food is \"actually their problem\". https://youtu.be/Cc_neyVp-rI&t=508 For a man who wrote on manipulation, he went full on authoritarian wanting to force a vaccine that was neither safe, nor effective (and 2 years ago that was clear, it wasn't \"fog of war\"). Me and my family all got the vaccine, and we all got COVID afterwards, and two of us now have heart problems at the age of 30. He believed every lie that big pharma presented him and hated everyone who thought differently to a point where he was ready to treat people who didn't get the vaxx as people in jail. reply jjeaff 11 hours agorootparentRegardless of whether you think vaccines should be required or not, the mRNA COVID vaccines have objectively proven to be both safe and effective. Though not as effective as everyone would have liked at reducing spread, it certainly reduced severity of cases. reply therein 11 hours agorootparentnext [2 more] [flagged] KptMarchewa 10 hours agorootparentNo. reply logicchains 11 hours agorootparentprev>Regardless of whether you think vaccines should be required or not, the mRNA COVID vaccines have objectively proven to be both safe and effective. By all existing measures of safety they're by far the least safe vaccines on the market, and even their apparent effectiveness may have just been the result of their immune suppressive effect: https://www.frontiersin.org/journals/immunology/articles/10.... . >In support of this hypothesis, Dr. Netea’s group reported dampened transcriptional reactivity of the immune cells and decreased type I interferon responses in vaccinated individuals to secondary viral stimulation (97), while our group described inhibition of adaptive immune responses and alteration in innate immune fitness in mice with this platform (99). The immune-tolerant environment induced by these vaccines is further supported by recent studies that have discovered a correlation between an increased number of prior mRNA vaccine doses and a higher risk of catching COVID-19 (100–102). Thus, these data suggest that these vaccines’ efficacy in decreasing disease severity and death might lie with their previously undiscovered immune suppressive characteristics. reply foobarqux 9 hours agorootparentprevThe general idea that it is \"authoritarian\" to force people into isolation to prevent them from harming others is obviously absurd (imagine an airborne disease with Ebola-like mortality). You could probably make an argument that it wasn't justified in this case using information known at the time but you have to actually make that case, not resort to appeals to \"freedom\" or information we know now. reply ImAnAmateur 10 hours agoprevCould anyone recommend a Noam Chomsky talk about language? I'm curious about his work but have never read or listened to anything from the man. reply alexarnesen 5 hours agoparentThe ghost in the machine and the limits of understanding . A bit wider than linguistics but a great talk and intro to his style of prose reply pvaldes 8 hours agoprevBy the description provided, I assume that \"medical event\" here is a synonym of ictus reply jokoon 10 hours agoprevAt first I thought he said interesting things But with time, I also realized he is a linguist, not an historian or political scientist. He is controversial. reply rand846633 5 hours agoparentI often find controversial to correlate with interesting. reply akaij 8 hours agoparentprevI think you mean that he is mainly a linguist. reply SomeoneFromCA 13 hours agoprevSpeaking of non-political side of him: was not he wrong about \"innate grammar\" necessary to understand langage? LLM do not have such circuitry, yet they somehow work well... reply tgv 12 hours agoparentThere have been many attempts to model and emulate human syntactic acquisition and processing, but the general consensus is that it cannot be done without presupposing some mechanism that enables hierarchical structure. The number of tokens a child needs to learn syntax is the tiniest fraction of the amount of tokens an LLM is trained on. Humans can also lose parts of their language processing capabilities, without losing others (start at e.g. https://en.wikipedia.org/wiki/Language_disorder), which is highly suggestive of modular language development. The only question on which there isn't much consensus concerns the origin of that modularity. And humans can lose knowledge while still being able to speak and understand, or lose language while retaining knowledge. LLMs don't have that at all: they predict the next token. reply renonce 11 hours agorootparentLLMs does have that, or at least it’s very likely that we will eventually be able to manipulate LLMs in a modular way (see https://news.ycombinator.com/item?id=40429540). One point remains: humans learn language with much fewer tokens than LLMs need, which suggests presence of a priori knowledge about the world. The LLM metaphor is finetuning, so babies are born with a base model and then finetuned with environment data, but it’s still within LLM scope. reply tgv 9 hours agorootparent> presence of a priori knowledge about the world 1. A certain architecture (e.g. a module that enables syntactic processing) is not knowledge about the world. 2. We model the world according to our capabilities. 3. Modular language models have been tried, but did not meet with success. 4. The link you include is about the conceptual space, which is not (directly) related to human syntactic processing. 5. The question is not about metaphors, but about reality. 6. Babies aren't born with a base model and fine-tuned. They learn. This is the metaphor NNs are actually based on. reply materielle 12 hours agoparentprevI don't think LLMs have all that much to do with \"innate grammar\". \"Innate grammar\" are essentially the meta-rules that govern why the rules are what they are. For instance, an English phrase can be recognized as valid or invalid by other native speakers according to the rules of the language. But why are the rules what they are? This is especially puzzling due to the dazzling variety of human languages. And the fact that, after a period of immersion, humans seem to have the natural capacity to learn all of them. How do LLMs fit into this? Well, I think it would be interesting if we left a group of LLM to talk to each other for 1000 years. Then see if 1) they developed a new language branch 2) that could be relearned by humans through immersion alone. It's true that LLMs have learned (have they? I suppose that's a loaded word) human languages like English. But it's unclear if they are governed by the same meta-rules that both constrains and drives the evolution of humanities thousands of distinct languages. reply gizmo686 13 hours agoparentprevNo. Innate grammar has always been about how humans aquire language, not how any possible system which understands human language must posses that innate grammar. reply teruakohatu 13 hours agorootparentTrying to put his in an uncontroversial way: the human brain (or a brain plus paper and a pencil) can be turning complete/equivalent. Therefor a human sitting down with a pen and pencil could, in a painstakingly long time, compute the backwards and forward passes of a transformer network. Therefor a human with no understanding of grammar/language, and using no innate biological circuits, could process grammar and respond with language. The flaw in this argument would be how to teach a human to do this without grammar ... reply SomeoneFromCA 13 hours agorootparentprevBut that has never been proven that this is how indeed human acquire language; it is essentially a hypothesis. We may as well do it the way LLMs do - some undifferentiated networks acquires the grammar by unknown means. reply nsingh2 13 hours agorootparentLLMs are universal approximators and can pick up patterns in sequences that are very different from Human languages. Sure, they don't have many inductive biases and can understand language, but as a consequence require a tremendous amount of data to work. Humans don't, which implies a certain bias towards Human language built into our heads. A bias is also implied by the similarities across Human languages, though what structure(s) in the brain are responsible is not exactly clear. reply SomeoneFromCA 12 hours agorootparentIt still does not proof anything, as claiming that \"there is certain bias for Human Language built into our heads\" is quite different thing that saying there is some universal grammar in the brain structures, as much we do not have innate abilities to comprehend calculus or play chess, yet we still able to learn it, with a lot less training information than LLMs. In fact 2 books will suffice for the both. reply nsingh2 12 hours agorootparentMy comment was more of a response to > We may as well do it the way LLMs do We almost certainly don't learn the way LLMs do, it's just too data inefficient. And I don't see what current LLMs can say about a universal grammar in the Human brain, unless there is proof that a LLM-style attention mechanism exists in the brain, and that it is somehow related to language understanding. reply codeflo 12 hours agorootparentprevWe don’t learn language from textbooks though. reply foobarqux 9 hours agorootparentprevChomsky has explicitly answered this: Moro has shown in experiments that humans do not appear to be able to learn arbitrary grammatical structures in the same way as human-like (hierarchical) languages. Non-human like languages take longer to interpret and use non-language parts of the brain. LLMs on the other hand can easily learn these non-human grammatical structures which means that they are not the way humans do it. reply codeflo 12 hours agoparentprevCompared to an LLM, how many hundreds of gigabytes of text do humans need to acquire a language? And isn’t that disparity already proof that some sort of innate structure must be going on? reply EVa5I7bHFq9mnYK 11 hours agorootparentOr that llm learning algos should be further improved, which will happen at some point. I remember Kasparov's tirades to the tune of I have an eternal soul therefore computers can never beat me in chess. reply yareal 13 hours agoparentprevLLMs are an approximation of all the human media they consume. An LLM cannot exist with out human circuitry. It's at best an ersatz language user. reply SomeoneFromCA 13 hours agorootparentUnrelated to what I said, with all due respect. reply sitkack 13 hours agorootparentIt isn't tho, if you look at the bulk of tokens needed to train gen1 over LLMs and what is possible with better data and smaller models. The fact that LLMs trained on dumptrucks full of data cannot achieve what a middle schooler begrudgingly achieves using existence and snide remarks. reply flaminHotSpeedo 12 hours agorootparentprevI'd consider it related, for two reasons: First and foremost (and what I think the parent comment is getting at) whether you could truly say an LLM \"understands\" language As a secondary quibble in the context of the parent post, though big overall, I would argue that the whole argument is moot since a human couldn't possibly learn the way an LLM does in a single lifetime reply graphe 4 hours agoparentprevhttps://www.discovermagazine.com/the-sciences/fruit-fly-brai... He mentioned a structure and scientists hacked a fruit fly Kenyon organ to process language which it does pretty well, also at MIT. The approach is relatively straightforward. The team began by using a computer program to recreate the network that mushroom bodies rely on — a number of projection neurons feeding data to about 2,000 Kenyon cells. The team then trained the network to recognize the correlations between words in the text. The task is based on the idea that a word can be characterized by it its context, or the other words that usually appear near it. The idea is to start with a corpus of text and then, for each word, to analyze those words that appear before and after it. reply ronhav3 11 hours agoprevHe has denied his last genocide. Cambodians,Bosnians,Cosovars and Ukranians breathe a sigh of relief. reply Jean-Papoulos 11 hours agoprevHere's your monthly reminder that despite the large place he occupies in the \"sciency\" cultural landscape, a lot of his work has been debunked and he has not gone back on his genocide-denying claims about Serbia. His anti US imperialism views blind him. reply foobarqux 9 hours agoparentUniversal grammar has not been \"debunked\", despite evidence-free claims otherwise. reply ilikehurdles 11 hours agoparentprevnext [2 more] [flagged] nsingh2 11 hours agorootparentI've been following this post for a while. Most of the flagged comments were inflammatory or in some instances even celebrating. reply nashashmi 13 hours agoprevHe is more than ever important today in light of Israel’s war. He was an open and ardent critic of Israel and a blatant supporter of Palestine. And even verbally supported Hamas best I can remember. reply pydry 13 hours agoparent>And even verbally supported Hamas best I can remember. Did he say something controversial like \"Gaza has a right to defend itself?\" reply LunaSea 9 hours agorootparentSeems like the right to defend one-selves is a one-way street. reply nailer 13 hours agorootparentprevGaza is not under threat from Israel, who pulled out in 2005, and gave Gazans a 250-300M flower export business. You can confirm this from any source you like. Israel is under threat from Gaza. reply racional 2 hours agorootparentIsrael gave Gazans a 250-300M flower export business. Which promptly failed due to Israeli-imposed border closures. You can confirm this from any source you like. reply yareal 13 hours agorootparentprevI checked sources, turns out literally tens of millions of people vocally and loudly disagree with you. I think it's not helpful to anyone to come in here and be so resolute and so black and white. Especially in the face of an event that has drawn the eye of the international community as a potential genocide. I'm not telling you what to believe, just that like, posting like you did is not engaging in any meaningful discussion. reply YZF 13 hours agorootparent[EDIT: ok, I'm gonna remove my appeal/preaching] I think the parent is referring to the situation before Oct 7th and likely going back to Israel's withdrawal in 2005. The detail I think he's trying to put forward is that before Israel's withdrawal the settlers in Gaza operated a flower export business of about that economic magnitude and that the greenhouses and infrastructure that was used for that business was left after Israel withdrew. There is some discussion of this here: https://en.wikipedia.org/wiki/Gush_Katif#Economy [snippety snip] reply houseplant 12 hours agorootparentnext [2 more] [flagged] YZF 12 hours agorootparentI don't think I said that. We're talking about the history of the conflict which I think is important. The Israeli disengagement from Gaza in 2005 is part of how we got here so I think it's important for people following the conflict to know the details and not just respond emotionally to the terrible images of war- which I agree are disturbing. reply zo1 12 hours agorootparentprevNot OP. Sometimes it's good to have a lack of nuance and come with absolute black/white thoughts. At some point, we all internally, draw our own lines in the sand about how we think on a topic (that is hopefully until we encounter new information that necessitates a change). I know for a fact that my opinion on this topic is not accepted, likely won't be accepted by either prominent side, but I stick with it because it conforms to my internal thoughts, priorities and problem-solving properties. reply houseplant 12 hours agorootparentprevit's truly surreal to hear people say this with their entire chest when the mountains of first-hand evidence proves otherwise. I've never seen anyone say things like this when they can be disproven so easily at this point. we know tens of thousands of gazan women and children have been killed so I won't pretend you don't know that, but my question is: exactly what evidence would you need to even entertain the idea that it's the other way around? reply tome 11 hours agorootparentWhat combatant to civilian death ratio would make Israel's actions in Gaza justified, in your opinion? reply nailer 6 hours agorootparentprev> it's truly surreal to hear people say this with their entire chest when the mountains of first-hand evidence proves otherwise. Evidence from the post you are replying to, but did not address: >> Gaza is not under threat from Israel, who pulled out in 2005, and gave Gazans a 250-300M flower export business. You can confirm this from any source you like. Additionally, there should be no need to state that Hamas (which is widely supported in Gaza) attacked Israel and started this current war. Ie, Israel is under threat from Gaza. The death ratio of civilian to combatant casualties from this war is 1:1 which is the lowest in any recent war, much to the credit of the IDF. To entertain genocide conspiracy theories, those numbers, as well as Gaza population growth, would have to be very different for one thing. reply grumple 9 hours agoparentprevHe’s a tankie and anti-western. He is not to be admired for his views on politics. He favor Hamas purely because they are anti-western. Terrorists who intentionally target innocents and desire the ethnic cleansing of Jews, like Hamas, are the bad guys. This has been the dominant Palestinian position for the past 100 years, from Al-Qassam to today, and it was preceded by 1300 years of genocide, sex slavery, and oppression of Jews by Muslim colonizers in the very same area. reply nashashmi 2 hours agorootparentGlad someone said it. Hamas is not a terrorist because they terrorize. Hamas is a terrorist because they are a threat to western govt and world order. Similarly south africa post apartheid was a threat to western world order. reply aszantu 12 hours agoprevLast time i heard him in an Interview he was already sluring and taking long times bevore he answered. I think there's metabolic problems and that he hasnt got much time left - sadly. I learned a lot from his lectures. reply alexnewman 13 hours agoprevFirst of all he's a hell of a linguist theorist. I disagree with about everything this guy wrote politically. I totally disagree with this guys perspective, it drives me up a wall frankly. But I have always have had incredible respect and think he played an important role in the dialogue. I read everything he wrote, and generally enjoy his writing. The very definition of the constant loyal opposition. Always getting people to think about things differently and with incredible moral courage. I wrote and argued with him and he always responded. We are all better off because of Chomsky. reply escapecharacter 11 hours agoprevDoes this change his opinion on Sapir-Whorf? Is that even knowable? reply Garvi 4 hours agoprevDamn, this topic got downvoted onto the 3rd page by the HN hive mind in no time. Right after: SQLSync – collaborative offline-first wrapper around SQLite, 16 points, 20 hours old ..must have a hell of a lot of downvotes. reply ilikehurdles 12 hours ago [flagged]prevThe world is losing a man who has been on the wrong side of every atrocity. He downplayed Srebrenica, celebrated the Khmer Rouge and denied their atrocities, penned fond letters to a holocaust denier, and can’t say a bad thing about Rwanda’s Hutu role in the genocide. Today, his views on Ukraine would earn him tenure in Putin’s Russia. A man, once famous for inventing a now discredited school of linguistic thought, who was one of the pioneers of pivoting an academic career into writing books that stroke leftist egos, may be silent for the rest of his days. When he passes, he will be mourned. Not by me, since I’ve grown past my younger years of radical ignorance, nor by the victims of the despots he loves to this day, but certainly by someone out there. Almost certainly someone who themselves has never sought refuge in the West. reply fortran77 15 hours agoprevnext [18 more] [flagged] biimugan 15 hours agoparentWhat's the implication of this comment? reply zer00eyz 15 hours agorootparentThere is a group of people who see Chomsky and his \"school\" as Alchemy and not \"science\". Minisky is one of his critics. The comment isnt saying anything other than \"there is an alternative point of view\". reply defrost 15 hours agorootparentThe comment in question was edited. The original comment was simply ב\"ה or בס״ד https://en.wikipedia.org/wiki/Besiyata_Dishmaya reply zdw 14 hours agorootparentTotally unrelated to the original topic, but looking at the linked article, is the name of the store \"B&H Photo\" a reference not only to the initials of the founders names but also tangentially to this concept? reply woodruffw 14 hours agorootparentThat's funny, I'd never made that connection before. The B&H owners are Szatmars (who tend to be pretty stringent in their practices), so I don't think they'd make this exact reference -- ה substitutes for HaShem which (very) roughly equates to taking god's name in vain. (They'd maybe write the בס״ד variant, so \"B&D\".) reply skissane 10 hours agorootparent> The B&H owners are Szatmars This is getting very tangential, but I've never seen someone spell it in English Szatmar before as opposed to Satmar. (From what I understand, Szatmar is the Hungarian-derived spelling, whereas Satmar is the Yiddish-derived one.) reply woodruffw 4 hours agorootparentMy family is from pretty close to there (on the modern Ukrainian side not Romanian, but Hungarian and Eastern Yiddish speaking), so I’ve always seen it spelled “Szatmar.” But yeah, looks like “Satmar” is much more common in English and there’s no ז in the Yiddish spellings either. reply graphe 14 hours agorootparentprevIs it like inshallah? https://en.wiktionary.org/wiki/إن_شاء_الله > if it is God’s will (literally, “if God has willed [it]” >In sarcastic contexts, it suggests that the speaker has no interest in making the future event occur (thus, it will only occur if God steps in and wills it). Unlike the Arabic usage, this seems to be more attested in English than the literal meaning. I've heard it used in terms of avoiding the evil eye. reply nsguy 14 hours agorootparentIn religious circles it's not uncommon to prefix each and every writing with that. It's very generic sort of implying god is everywhere. So in writing, in that context, it has no real special significance other than to hint the writer is religious. In some contexts Inshallah and \"Bae Ezarat Hashem\" could I guess have similar meanings. E.g. in the Wikipedia example: \"I will visit my relatives in Riyadh this summer, God willing.\" it can be used exactly the same way. reply 082349872349872 9 hours agorootparentIn the context of https://xkcd.com/2904/ : Some languages have a distinct grammatical mood[0] for expressing wishes, curses, etc.: things that the speaker would like to pass but may or may not. (here are the dynamics, I think I've set the right initial conditions, but let's integrate them forward...) Other languages have a distinct grammatical mood[1] for expressing things that, as day follows night, are certain to happen: (here's the Lagrangian, and there's the attractor) In these senses, בס״ד could be viewed as a syntactic marker for the optative, somewhat like, but much shorter than, \"forward-looking statements are provided to allow potential investors the opportunity to understand management’s beliefs and opinions in respect of the future so that they may use such beliefs and opinions as one factor in evaluating an investment.\" [I am bitterly disappointed that זב\"שך is outmoded] [0] https://en.wikipedia.org/wiki/Optative_mood [1] in HWC (alas, it has no wikipedia!), \"bumbai\" can be used for prophecy: \"You stay X, bumbai Y\" is IIUC: \"if you continue to do X, Y shall come to pass.\" Lagniappe: https://en.wikipedia.org/wiki/Hawaiian_Pidgin#/media/File:Ha... reply woodruffw 15 hours agorootparentprevIt's an abbreviation meaning roughly \"with the help of God.\" GP is either saying something neutral with respect to Chomsky's age or being snide. I'm not sure which. reply euW3EeBe 15 hours agorootparentTake a look at their comment history, and keep in mind that Chomsky has been openly critical of Israel for a long time. reply woodruffw 15 hours agorootparentThat's why I wasn't sure which. Without that context, I could read it purely innocently (if a slightly weird choice). With it, it's probably snide, but who knows. reply relaunched 15 hours agorootparentprevMy first thought was snide / next level anti-Semitic trolling. But, then I reminded myself that you shouldn't infer tone to comments online. reply skissane 15 hours agorootparent> My first thought was snide / next level anti-Semitic trolling Chomsky has been very critical of Israel, and as a result there are many pro-Israel people who strongly dislike him. So, while it isn’t impossible for Hebrew language trolling to be from an antisemite, my first thought would be it is from one of his pro-Israel critics reply ignoramous 14 hours agoparentprevnext [3 more] [flagged] emptysongglass 14 hours agorootparentI couldn't tell if you meant Minsky or Chomsky. Chomsky has doubled down on some pretty terrible positions into his old age, including \"Ukraine asked for it\" when it came to Russia's invasion of Ukraine or a continuous stream of apologies and whataboutisms for regimes who resemble his ideal politics in name only reply ignoramous 4 hours agorootparentI mean OP who edited their original comment to remove a snide remark on Chomsky just because he's been critical of the occupation. reply EVa5I7bHFq9mnYK 11 hours agoprevnext [2 more] [flagged] burrish 11 hours agoparentlol not a chance, we are talking about hn here, anything they don't like will be flagged and downvoted to hell reply UberFly 12 hours agoprev [–] Noam Chomsky always stuck me as the \"don't be so open minded that your brain falls out\" type of individual. His support for such causes as the holocaust denial movement (among others) always made me wonder why he has such a following. reply gklitz 12 hours agoparentIndependent of what people believe of him or his defense of Faurisson's freedom of speech one thing is clear, they have both been the target of extremely aggressive smearing campaigns by Israel. I would defend the right to freedom of speech of people who believe the earth is flat, that does not mean “I support the flat-earth movement” reply GolfPopper 12 hours agorootparentUltimately that leads to Popper's Paradox of Tolerance.[1] Do you defend the absolute freedoms of those whose goal is to destroy that freedom, along with you and many others with it? If yes, how do you stop them from accomplishing their goals? If no, where do you draw the line? (To be clear, I consider these critical but ultimately rhetorical questions with no obvious good answers.) 1. https://en.wikipedia.org/wiki/Paradox_of_tolerance reply defrost 12 hours agoparentprevContext: Chomsky had long publicly criticized Nazism, and totalitarianism more generally, but his commitment to freedom of speech led him to defend the right of French historian Robert Faurisson to advocate a position widely characterized as Holocaust denial. Without Chomsky's knowledge, his plea for Faurisson's freedom of speech was published as the preface to the latter's 1980 book Mémoire en défense contre ceux qui m'accusent de falsifier l'histoire. Chomsky was widely condemned for defending Faurisson, and France's mainstream press accused Chomsky of being a Holocaust denier himself, refusing to publish his rebuttals to their accusations. - https://en.wikipedia.org/wiki/Noam_Chomsky reply raverbashing 12 hours agorootparentThis is a good reminder why everything should have boundaries, and everything should have a \"surrounding frame\" In theory this sounds like \"intellectual courage\", in practice it's just apology and bootlicking Camps and war and tanks were all too real. But of course you can waste time and space in your cushy western university seat reply andrepd 11 hours agorootparentAnd how do you know they are real? Because historians have been free to dig around and publish arguments and rebuttals and evidence. Not because anyone by decree or force declared it to be so. reply raverbashing 11 hours agorootparentSome people (usually the too self-centered ones) only discover it when it's too late. reply tines 12 hours agoparentprevAnd the ACLU \"supported\" the Nazi movement in Skokie. Do you have any evidence that Chomsky himself denies the holocaust, or are you just slinging shit? reply Mikushi 12 hours agorootparentJust slinging, Chomsky only supported freedom of speech. reply UberFly 1 hour agorootparentWho's the bigger problem, the idiot yelling fire in the crowded movie theater, or the morally superior intellectual supporting their right to do so? I'm not so sure. reply tines 6 minutes agorootparentIf this guy was yelling fire then so are we all. reply froh 12 hours agoparentprev [–] he didn't support that cause. he radically supported free speech. if someone has him discuss the paradox of (in)tolerance I'd appreciate links or pointers ps: I come from a country with limits ob the freedom of speech and I defend those limits. I'm just saying Chomsky in contrast held freedom of speech as an absolute, even for anger and hate inciting lies. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Noam Chomsky, a 95-year-old linguist and political activist, has suffered a severe health decline since a medical event in June last year, rendering him unable to communicate or walk.",
      "His former assistant, Bev Stohl, confirmed that Chomsky has not appeared in public since the incident and is unlikely to do so again.",
      "Tributes emphasize Chomsky's kindness, dedication to fighting injustice, and significant influence, with his absence notably felt in discussions about the Gaza conflict."
    ],
    "commentSummary": [
      "Noam Chomsky, despite losing his ability to speak, remains mentally sharp and actively engages with young audiences, maintaining his influence in political and cognitive science.",
      "He faces criticism for his views on geopolitical issues, including Russia's invasion of Ukraine and past interactions with Jeffrey Epstein, as well as his stances on American interventionism and historical events like the Cambodian genocide.",
      "The text contrasts Chomsky's theories on innate grammar with the functioning of large language models (LLMs) and discusses his controversial opinions on the Israeli-Palestinian conflict, NATO, and US foreign policy, highlighting the polarized reactions he provokes."
    ],
    "points": 268,
    "commentCount": 225,
    "retryCount": 0,
    "time": 1718069975
  },
  {
    "id": 40646658,
    "title": "Norway Unveils Europe's Largest Rare Earth Metals Deposit, Easing Reliance on China",
    "originLink": "https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html",
    "originBody": "SKIP NAVIGATION MARKETS BUSINESS INVESTING TECH POLITICS CNBC TV MAKE IT SELECT USA INTL WATCH LIVE Search quotes, news & videos WATCHLIST SIGN IN ENERGY TECHNOLOGY INVESTING CLEAN START REGULATION & POLICY FORUM NETWORK SUSTAINABLE FUTURE Norway discovers Europe's largest deposit of rare earth metals PUBLISHED TUE, JUN 11 20247:01 AM EDTUPDATED 27 MIN AGO Sam Meredith @IN/SAMUELMEREDITH @SMEREDITH19 KEY POINTS Mining firm Rare Earths Norway says it has discovered Europe's largest proven deposit of highly prized rare earth elements. One of the few deposits not owned or controlled by China, the discovery of continental Europe's largest rare earths deposit is considered a welcome boost in Europe's bid to break China's rare earths dominance. Alf Reistad, CEO of Rare Earths Norway, told CNBC that the discovery represents a \"great milestone\" for the company. Neodymium is displayed at the Inner Mongolia Baotou Steel Rare-Earth Hi-Tech Co. factory in Baotou, Inner Mongolia, China. Nelson ChingBloombergGetty Images Mining firm Rare Earths Norway says it has discovered Europe's largest proven deposit of highly prized rare earth elements, potentially reflecting a watershed moment for both the Nordic country and the broader region. One of the few deposits not owned or controlled by China, the discovery of continental Europe's largest rare earths deposit is considered a welcome boost in Europe's bid to break China's rare earths dominance. Demand for rare earths and critical minerals is expected to grow exponentially in the coming years as the clean energy transition picks up pace. Rare Earths Norway said in a June 6 statement that its Fen Carbonatite Complex in the southeast of the country boasts 8.8 million metric tons of total rare earth oxides (TREOs) with a reasonable prospect for economic extraction. Within the TREOs, which are considered vital to the global shift away from fossil fuels, the company says there is an estimated 1.5 million metric tons of magnet-related rare earths which can be used in electric vehicles and wind turbines. The discovery eclipses a massive rare earths deposit found last year in neighboring Sweden. Alf Reistad, CEO of Rare Earths Norway, told CNBC that the discovery at Fen represents a \"great milestone\" for the company. \"It is important to state that there is absolutely no extraction of rare earth elements in Europe today,\" Reistad said via videoconference Monday. One of the aims of the Critical Raw Materials Act is to extract at least 10% of the European Union's annual demand for rare earths by 2030 and Rare Earths Norway says it hopes to contribute to that goal. Rare Earths Norway said the rare earths deposit in Telemark, roughly 210 kilometers (130 miles) southwest of Oslo, is likely to underscore Norway's position as an integral part of Europe's rare earth and critical raw material value chain. Rare earths 'more important' than oil and gas The International Energy Agency has said that today's supply falls short of what is needed to transform the energy sector. That's because there is a relatively high geographical concentration of the production of many energy transition elements. Most rare earth elements are located in China, with the world's second-largest economy estimated to account for 70% of global rare earth ore extraction and 90% of rare earth ore processing. China was the EU's largest partner for imports of rare earth elements in 2022, accounting for 40% of overall imports based on weight. Workers transport soil containing rare earth elements for export at a port in Lianyungang, Jiangsu province, China October 31, 2010. StringerReuters Looking ahead, Rare Earths Norway said exploration work at the complex will continue, with further drilling scheduled for next month. The company said it is working to develop the first stage of mining by 2030. Asked whether he believed the discovered resources could be considered of more value than Norway's oil and gas supplies, Rare Earths Norway's Reistad replied, \"Not of more value but [European Commission President] Ursula von der Leyen has stated that lithium and rare earth element will soon be more important than oil and gas.\" \"So, it will be more important but not have the same value, of course,\" he added. Don’t miss these exclusives from CNBC PRO Nvidia could one day be an unprecedented 15% of the S&P 500, predicts Evercore ISI Beyond the Magnificent 7: Morgan Stanley fund manager says diversify with these 2 stocks Goldman Sachs downplays the Nvidia stock split hype, sees little impact Morningstar calls this ETF the ‘gold standard’ for dividend funds. Here’s why MORE IN SUSTAINABLE FUTURE With EVs, Honda may be North America's most committed automaker, for the moment Kevin Williams EV slump, Hertz fire sale take used Teslas to 'no haggle' $25,000 price Bob Woods World likely to blast beyond grim warming milestone in the next 5 years, UN weather agency says Sam Meredith READ MORE Subscribe to CNBC PRO Subscribe to Investing Club Licensing & Reprints CNBC Councils Select Personal Finance CNBC on Peacock Join the CNBC Panel Supply Chain Values Select Shopping Closed Captioning Digital Products News Releases Internships Corrections About CNBC Ad Choices Site Map Podcasts Careers Help Contact News Tips Got a confidential news tip? We want to hear from you. GET IN TOUCH CNBC Newsletters Sign up for free newsletters and get more CNBC delivered to your inbox SIGN UP NOW Get this delivered to your inbox, and more info about our products and services. Advertise With Us PLEASE CONTACT US Privacy Policy CA Notice Terms of Service © 2024 CNBC LLC. All Rights Reserved. A Division of NBCUniversal Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis. Market Data Terms of Use and Disclaimers Data also provided by",
    "commentLink": "https://news.ycombinator.com/item?id=40646658",
    "commentBody": "Norway discovers Europe's largest deposit of rare earth metals (cnbc.com)209 points by belter 4 hours agohidepastfavorite197 comments sofixa 4 hours agoOn one hand, it's unfair that a country already very rich with natural resources discovers more of them. On the other hand, if there is a country which can be trusted to exploit natural resources in a way that benefits the whole country and its population, and not fall down the resource curse[1], it's Norway. 1 - https://en.wikipedia.org/wiki/Resource_curse reply mogadsheu 4 hours agoparentThe thing about Norway is that it’s a cold, barren, remote place where very few people want to live. Most of the year it’s cold and gray, and most of the country is uninhabitable. The result is that its natural resources haven’t been consumed to the degree that most developed countries’ resources have, and there aren’t as many people to consume them. I find it a strangely fair situation. Their luck comes from having friendly neighbors who care about their well-being and responsible development. reply somenameforme 3 hours agorootparentHistory would disagree with you there pretty strongly. Norway (and Scandiland in general) was fought over for millennia, leading to an extremely rich, interesting, and bloody history - even well after the Viking era. As a somewhat random aside this [1] book is an extremely interesting read for anybody into history - the 'King's Mirror.' It's a book written around 1250 intended exclusively for the education of a Norwegian King. It takes the Plato-type style of a question and answer session between a learned man (father) and pupil (son). It covers basically every aspect of life, but the most interesting thing about it that it was written near a millennia ago now, yet so many things in it feel so incredibly familiar. The Wiki page links to a bunch of different free translations. Here [2] is the one that I read. [1] - https://en.wikipedia.org/wiki/Konungs_skuggsj%C3%A1#Editions... [2] - https://archive.org/details/kingsmirrorspecu00konuuoft reply marginalia_nu 2 hours agorootparent> so many things in it feel so incredibly familiar I get this reading a lot of old texts. \"De natura deorum\" in particular struck me as downright uncanny. I've seen this exact discussion play out time and time again in discussion boards in the early 2000s. The only thing that's a bit off is that the tone is civil and level-headed. Like the thing is 2000 years old, how long have we been having these arguments? reply SoftTalker 2 hours agorootparentprev> it was written near a millennia ago now, yet so many things in it feel so incredibly familiar It's sometimes forgotten that 13th century humans were the same as us. reply ethbr1 7 minutes agorootparent> It's sometimes forgotten that 13th century humans were the same as us. Ceiling is probably closer than median. One of the crowning achievements of the modern area has been to more broadly extend knowledge and prosperity (both globally and within countries). We still have a looong way to go, but it's important not to forget what 'median education' looked like in the 1200s. reply godelski 1 hour agorootparentprevIt's often forgotten how much conflict there was in Europe (and most of the world) in the 18th and 19th centuries. How this was fairly \"normal\" It's really forgotten how relatively peaceful our time is. I'm not complaining, in fact, I want to protect it. And that means we can't forget what was. https://youtu.be/UY9P0QSxlnI?t=10m5s reply dieselgate 1 hour agorootparentprevPretty crazy how that’s not even 1k years ago. Humans have been the same for like, at least dozens of thousands of years? Maybe even more? reply temp0826 1 hour agorootparentHomo sapiens (with the exact hardware that we carry today) emerged ~300k years ago. Wikipedia says- \"Humans began exhibiting behavioral modernity about 160,000–70,000 years ago, and possibly earlier.\" reply datameta 46 minutes agorootparentI think modern hardware would be more like 200k, no? I believe 300k is robust/archaic Homo sapiens. reply gklitz 2 hours agorootparentprevWhat a strange perspective, the oil reserves aren’t located anywhere near the “barren remote” parts of Norway, consider the famous ekofisk oil field, it’s in the ocean roughly in the middle between Denmark England and Norway. And the southern Coast of Norway isn’t dramatically different from Denmark climate wise, they do have amazing cliffs there though and the culture around boating to town is a sharp contrast to Denmark. Anyways, hardly a rough barren wasteland with dreadful weather as described. This discovery is at Fen which is much more north, but it’s near a fjord, and a skiing resort. It’s hardly some uninhabitable place. It’s true Norway stretches very far north and some parts are not inhabited, but that’s not anywhere near where the resources that have provided the Norwegian wealth are, and not this time either. Now if you want to dive into the true reason for their wealth it’s a cultural thing, when the negotiations around ekofisk took place they famously got the Danish foreign minister of the day, Per Hækkerup so drunk while he visited Oslo that he agreed to pretty much just give them all the oil. Ever since Danes lost all respect for him, not for giving up the oil, but for not being able to hold his liquor. This last part is of cause all hyperbol, part myth part joke, but many did believe that he just gave it up to easily because no one expected this amount of oil off the coast of Norway. reply fuglede_ 1 hour agorootparentSaid myth being debunked: https://videnskab.dk/kultur-samfund/myte-foraerede-haekkerup... reply anonyfox 3 hours agorootparentprev> where very few people want to live just as a sole data point: been there a few times, and my personal ideal weather _is_ cool/gray/wet with ideal outside temperature of 15C. I can withstand the cold, but find it hard to tolerate heat (as in >20C). Purely from a weather perspective, I'd move there. What holds me back is that I also need dense urban surroundings nearby with all the buzz it brings (cyberpunk style) - norway is lacking that, including Oslo. _Too_ quiet/beautiful/peaceful for my liking. reply NegatioN 3 hours agorootparentWhat gets most foreigners is usually the darkness in the winter, and not the temperature fwiw. It's hard to describe, but many people end up quite depressed. reply Broken_Hippo 1 hour agorootparentI'd just like to add: I'm an immigrant in Norway. The darkness is enough of an issue that told us know about this in the state-funded language classes and made sure we knew help was available. I'm in Trondheim, so December is full of 4.5 hours of poor sunlight each day. If there were something else that really gets folks, it is that Norway's people are rather reserved, to a point, and it really makes some folks lonely. This combined with the dark winters really causes some folks to struggle. Everyone gets used to the weather and quickly learns how to dress properly enough. reply grugagag 20 minutes agorootparentHow are you faring so far? Can you join some groups of less reserved/more gregarious immigrants and carry on together? reply konschubert 2 hours agorootparentprevLiving in northernmost Germany, I can confirm. It’s not the cold or the endless weeks of rain. It’s the days that barely feel like daylight. reply mattpallissard 24 minutes agorootparentLiving in Alaska I struggle more with the endless daylight than the short dark days. It messes with my sleep too much. reply grugagag 23 minutes agorootparentprevHave locals adapted to this or they’re generally more depressive over the winter months? reply foobarian 1 hour agorootparentprevIt's actually surprising how north the famous EU countries are. Already south France and Italy are about the same latitude as New England; Norway must be like Alaska as far as daylight goes. If it weren't for the warm Atlantic current the place would be a glacier. reply input_sh 1 hour agorootparentThe example that blew my mind once and I've been repeating it since: New York is as north as Madrid. Like, almost exactly, 0.3 degrees difference (or 20 miles, or 33 kilometres). reply VBprogrammer 4 minutes agorootparentLondon is further north than St John's Newfoundland. coob 14 minutes agorootparentprevHis bless His Majesty’s Gulf Stream. reply NLips 54 minutes agorootparentprevThe entirety of Great Britain is farther north than the entirety of the contiguous 48 USA states. reply ethbr1 0 minutes agorootparentSo that's why they held onto Canada... snowpid 1 hour agorootparentprevThe south of Alaska starts in Northern Germany. reply mnsc 1 hour agorootparentprevLiving in Northern Sweden with \"midnight sun\", what gets me the most the few times I've been approaching the equator is warm nights that are pitch dark. So strange! And then I remember that this is the experience of the majority of the world. :D reply dev1ycan 1 hour agorootparentprevI know about this from living in Lima (Peru), the weather due to our geological position is always temperate, goes from min temps of 11 degrees to like 32 in summer (top), usually around ~18/19 degrees up to like 23 throughout most of the year. You'd think climate is great, but it's ALWAYS \"foggy\", you can't see a clear blue sky like in the inner regions of the country such as Cusco, it depresses you, I can't imagine it being even darker. It's why I simply can't believe nordic \"stories\" about being the happiest place, I simply can't believe with all the money in the world you'd be happier than at a tropical beach with half of that money. reply 331c8c71 19 minutes agorootparent> you'd be happier than at a tropical beach with half of that money. Waaay too warm and humid. And no seasons. Thanks, but no thanks. My ideal climate is proper 4 seasons with sub-zero and snowy winters. I am pretty sure I am not the only one. reply novaRom 3 hours agorootparentprev> my personal ideal weather _is_ cool/gray/wet with ideal outside temperature of 15C 15C day temps? morning/night temps can be much lower. Winters in Norway are much colder. If you are looking for stable day-night temps year around in that range, then there is no such place in Europe, well maybe except Ireland? reply mrspuratic 2 hours agorootparentJune-Sept in most places in Ireland has a mean daily temp of around 15C, and around 6C winter time. It infrequently gets much above 20C, or much below 0C year round. 5 consecutive days of 25C is the meteorological definition of \"heatwave\". As a predominantly temperate maritime/oceanic climate it's unpredictable and erratic, from 15C mid-winter days to 4C mid-summer nights :/ Plenty of grey and wet though. reply baq 2 hours agorootparentprevOnly San Francisco has San Francisco weather... reply datameta 43 minutes agorootparentWell, temperature-wise mid-April SF struck me as almost exactly like CDMX in early December. reply anonyfox 3 hours agorootparentprevno, more like ideal lunch time temp, lower is okay, above 20 and I start to feel miserable. Yes very cold is also okay :-) The only thing that sucks is hovering around 0C for a long time, since this means oscillating between frozen/mud reply pier25 3 hours agorootparentprevFor me it's the food. Norway is a beautiful country. I love cold weather and grey skies but all that fish stuff is not for me. reply jonasdegendt 20 minutes agorootparentNorway also has a weekly tradition called \"Taco Friday\" that a decent amount of people participate in, so it's safe to say that generalizing food habits doesn't really work anymore nowadays. reply j7ake 48 minutes agorootparentprevActually Norwegian food is mostly a thick slice of buttered bread and a thin slice of cheese or meat. If feeling luxurious, then maybe both meat and cheese on bread. reply vidarh 3 hours agorootparentprevI grew up in Norway, and I hardly eat fish, and we hardly ever had fish for dinner when I grew up. reply KingOfCoders 2 hours agorootparentWhen in Norway, the only thing I didn't like was that sweet, brown cheese :-) reply nkurz 2 hours agorootparentYou must not have tried the \"Gammelost\": https://norwayathome.com/?p=319 The sweet brown \"Brunost\" (https://en.wikipedia.org/wiki/Brunost) might not be your favorite, but I doubt it haunts you in nightmares. The Gammelost though will stay pungent in your mind for years. It's been years, and I still wonder whether I was the victim of a particularly cruel practical joke. reply dagw 2 hours agorootparentThe difference is the Gammelost isn't actually a thing in Norway. I grew up there and never saw it. Whereas Brunost is staple food eaten every day by a large part of the population. reply kristofferR 11 minutes agorootparentEh, large part of the population is relative. I'd guess 1/20th, or something like that. Filligree 2 hours agorootparentprevGammelost is just fermented cheese. No biggie. reply epolanski 2 hours agorootparentprevWhy? Sounds odd for a country with so much sea to not have a fish culture. Looking around the internet indeed there's very little fish in most popular Norwegian dishes, except for fish meatballs. reply dagw 2 hours agorootparentWhy? Honestly no idea. They just don't. Growing up the only fish we really ate was fish sticks and heavily processed fish cakes. When going out to restaurants I have no real memory of anybody really ordering fish. Even when I was living in down town Oslo (admittedly 20+ years ago), just getting ahold of fresh fish was hard. The only food store that had a fish mongers and sold fresh fish was the really fancy store in the most expensive part of town. There were maybe two fish stores in all of central Oslo that I knew of, one of which was a high end luxury food sort of place that also sold fancy caviar, foie gras and oysters. Compared to basically any costal town anywhere in Europe where fresh fish is plentiful and ubiquitous, it is really strange. reply epolanski 2 hours agorootparentI am so confused though. Some data says Norway is the second country in the world by amount of fish eaten [1][2] [1]https://joint-research-centre.ec.europa.eu/jrc-news-and-upda... [2]https://en.wikipedia.org/wiki/List_of_countries_by_seafood_c... reply dagw 1 hour agorootparentThe only three possible explanations I can think of are 1) Things have radically changed since I last lived there 20+ years ago 2) My view is heavily biased by only having lived in/around Oslo and the rest of the country eats a lot more fish 3) Norwegians eat a lot of heavily processed fish based foodstuff (fish sticks, fish cakes etc), but hardly any fresh fish. reply kivle 25 minutes agorootparentThat would probably be point number 2 in your list. West coast and northern Norway eat a lot of fish/seafood. Also within the last 20 years sushi has gotten a lot more popular here, even around Oslo. reply dagw 3 hours agorootparentprevWhat fish stuff? I grew up in Norway and lived there for a chunk of my adult life, and honestly Norwegians (at leats in/around Oslo) seem to eat less fish than most other European countries I've been to. reply boringg 2 hours agorootparentI think globally norway cuisine is identified with cured or other fish etc. thats probably not what the local diet really eats probsbly (based on two comments in this thread) reply foobarian 1 hour agorootparentCured fish is fine, it's the fermented fish that I draw the line on :-) reply boringg 1 hour agorootparentThats right! Fermented not cured ;) reply KingOfCoders 2 hours agorootparentprev\"The thing about Norway is that it’s a cold, barren, remote place where very few people want to live.\" We walked 700km through Norway in the summer, from Oslo to Trondheim (the South were most people live). The country was sunny and warm, it seldom rained, people were exceptionally friendly, and it had the best wild strawberries and raspberries I ever ate. The Dovrefjell was the only very cold place. We'll might move there in the future. reply Someone 2 hours agorootparent> We walked 700km through Norway in the summer “in the summer” must have helped. In the depth of winter, there’s less than 6 hours between sunrise and sunset in Oslo (https://www.timeanddate.com/sun/norway/oslo?month=12), just over 4 1/2 in Trondheim (https://www.timeanddate.com/sun/norway/trondheim?month=12). To make matters worse, the sun doesn’t get high in the sky. reply NorwegianDude 2 hours agorootparentThere is not much sun in the winter, but that also means there is more sun in summer. The variance is greater, but it averages out. reply Toutouxc 1 hour agorootparentThe country lies north of the Northern Tropic, which means that it gets less sun in summer AND significantly less sun in winter. reply NorwegianDude 1 hour agorootparentEhh, what? Just because Norway is far north does not mean that it gets less sun all year round. It has more sun in summer, and less in winter. You can be at the northern most point of mainland Norway now and wait for sunset. But you will have to wait until August. It's been up since May 11. reply Toutouxc 35 minutes agorootparentI wrote that in a rush and was thinking more about the angle, i.e. peak intensity. You get more sun hours, but not that warm. reply ithkuil 1 hour agorootparentprevLess sun intensity but longer days during summer reply bongodongobob 1 hour agorootparentprevIt's summer for like a month. Living that far north is hellish for most people. It's not just like a colder Seattle or something. reply zrules 1 hour agorootparentprevI find the best arrangement is spending a month or at least two weeks in Norway during the summer. I prefer to stay around Stryn. You can do some what I consider good drive outings in every direction. Because the day is longer it’s perfect for going into rabbit holes, hacking something together to explore new tech and just plan out what’s next. The scenery and the very friendly folks helps too. Only tough thing right now is it’s hard to find things to do for kids. I have not found a summer camp for non-Norwegian speaking kids. This definitely limits how much hacking is done. reply tyfon 3 hours agorootparentprevBeing born in Norway and living here (on a remote island with only ferry connection as well), I personally wouldn't want to live anywhere else. There are areas where it is cold and barren, but not the cost. Writing this on the ferry on the way home from work :) reply fwsgonzo 22 minutes agorootparentI live on a remote island too, but it has a bridge! Same feeling: Wouldn't want to live anywhere else! reply eschulz 2 hours agorootparentprevThat sounds cool (no pun intended) reply ajmurmann 3 hours agorootparentprev> The result is that its natural resources haven’t been consumed to the degree that most developed countries’ resources have, and there aren’t as many people to consume them. I find this a strange train of thought in this context of rare metals like this. Did other countries truly discover their Neodymium reserves decades or centuries ago and exhaust them back then or did they never have them in the first place? reply Loughla 1 hour agorootparentI'm with you. What were people in the early 1900's using rare earth metals for that they would be used up by now? reply adrian_b 1 hour agorootparentThe first large-scale use of the rare-earth metals was since the last decade of the 19th century in gas lamps with high brightness, which were used especially for street lighting in Europe, until they were replaced by electric lamps. The next large-scale use appeared soon after the start of the 20th century, in the portable lighters, which are still used today. reply skilled 3 hours agorootparentprevThe weather in Norway sucks big time. In some parts of the country it is really bad, especially if you live near the sea. Summer isn’t guaranteed either. That’s a pretty big price to pay for an otherwise great country with really chill people. reply dehrmann 3 hours agorootparentI remember Swedes telling me summer is the nicest week of the year. reply elygre 3 hours agorootparentprev20c/68f outside in Oslo, at 5pm today. High of 27c/80f in may. I’m satisfied. reply Turing_Machine 3 hours agorootparentprev> The weather in Norway sucks big time. Seems like a matter of taste, but then I live in Alaska. :-) Edit: right now it's 50 degrees F and misty. Perfect, as far as I'm concerned. reply epolanski 2 hours agorootparentOf course it's a matter of taste, but statistically humans prefer warmer climates. reply veqz 2 hours agorootparentprevEh, don't know about that... We're really just like anyone else, we've just ended up with a fairly decent political environment by the time we found oil, specifically. We've been pretty good at mining out our copper ores and everything else that we knew of that had value; we've built a whole bunch of hydro plants and have dammed up numerous valleys; no one thought there was oil in the North Sea or that it was valuable enough to get it up, but now we have a pretty extensive petroleum industry, and it barely took five decades since the first oil was discovered. What resources we have been good with, however, is fish. But that's just proper regulation over the last century or so. As for our friendly neighbours... Norway was ruled by Denmark for 400 years and we've been part of all their wars, for a start. Our national anthem has 8 verses, 6 of them are about how we killed Swedes, Danes and Scots. And we'd like Jamtland, Herjedalen, and all the islands in the Atlantic back, thankyouverymuch! reply Moldoteck 2 hours agorootparentprevYou say that like norway can't and didn't sell a lot of these resources reply antisthenes 2 hours agorootparentprev> The thing about Norway is that it’s a cold, barren, remote place where very few people want to live. Most of the year it’s cold and gray, and most of the country is uninhabitable. It would be true if the Gulfstream did not exist. But it's not. reply samastur 35 minutes agorootparentprevWhat the hell are you talking about? I've been to Norway 4-5 times and will visit again in about a month. It's wonderful throughout and wish we could live there. reply dikaio 31 minutes agorootparentprevI for one would love to live in Norway. reply MisterBastahrd 1 hour agorootparentprevThe thing about money is that people will chase it regardless of the weather conditions if they can make enough of it. The folks out there in the Gulf of Mexico who spend 16 hour days working on oil rigs aren't there because it's fun. reply bbarnett 3 hours agorootparentprevThat, and the heroes that risked life and limb to start those first oil rigs, many dying, so a poor country could use the wealth to help its own people. reply onlyrealcuzzo 3 hours agorootparentNorway has been relatively wealthy since 1870... reply zer00eyz 3 hours agoparentprev> in a way that benefits the whole country and its population Selling oil to the world and buying Nestle stock. Great for Norway, too bad for everyone else. Its akin to apple and musk saying \"fuck it where gonna split the pie with every one in CA\" and the rest of America getting bupkis. Norway is a model for good for NORWAY, not a model for good. reply dmix 3 hours agorootparent> Norway is a model for good for NORWAY, not a model for good. Why should a country prioritize other countries over their own interests, particularly when it comes to economics? Everyone does that I guess it's only bad when youre doing well or something, then you're obliged to be the world's benefactor. We're not even talking about donating to developing countries either. reply zer00eyz 2 hours agorootparentThe line is very arbitrary... > Why should a country prioritize other countries over their own interests, particularly when it comes to economics? Everyone does that Why should a person prioritize other people over their own interests, particularly when it comes to economics? Everyone does that... I guess it's only bad when youre doing well or something, then you're obliged to be the peoples's benefactor. We're not even talking about donating to developing people either. reply supplied_demand 2 hours agorootparent==The line is very arbitrary...== Is it? Countries are not people. Democracies like Norway, are comprised of many people who elect officials to represent their interests as a people. How is that the same as an individual person? reply zer00eyz 1 hour agorootparentSo it's fine for Norway to sell oil and buy nestle for the good of its people. But it's bad for the ultra rich to do the same? reply supplied_demand 1 hour agorootparentWhat \"good of its people\" are the ultra rich serving? They are serving the good of themselves, no other people involved. When Norway sells oil, lots of that money goes to a generous social safety net that supports people of Norway. The analogy doesn't really work. reply fbdisiavagsjd 1 hour agorootparentprevYou have to draw a line somewhere. Countries seem like the natural place to start. You’re welcome to pitch your own lines and see who agrees. Though, this will likely end up with you being at odds with other arbitrary line drawers. What happens from there is usually not great. reply nicce 1 hour agorootparentprevWhat do you think about imperialism? It follows the same analogue. reply rqtwteye 1 hour agorootparentprevIt beats the model of the rest of the world where billionaires get resources for cheap and then sell oil to the world and buy Nestle stock. \"Its akin to apple and musk saying \"fuck it where gonna split the pie with every one in CA\" and the rest of America getting bupkis.\" It beats taking the whole pie and complaining about taxes. reply iwontberude 3 hours agorootparentprevApple is not the reason why Silcon Valley is the way it is, this is emergent and not in any agents control. Let’s not forget Apple has large campuses around the US and in Ireland. reply analognoise 3 hours agorootparentEspecially Ireland, because that’s how you can shelter a bunch of your profits from taxes. Apple cares about Ireland as much as they can abuse them to not pay their share of taxes. reply selectodude 3 hours agorootparentApple has had a pretty large office in cork since 1980. reply 7thaccount 4 hours agoparentprevThere are a lot of unfair things in the world :) reply jmyeet 2 minutes agoparentprevNorway isn't a lucky outlier. Norway's control over resource extraction is simply tolerated by the United States because they're a European nation. When other countries try and do anything similar, which can include just broaching the subject of nationalizing resource extraction, their (often democratically elected) governments get overthrown in a coup by some fascist government with mysterious connections to the CIA who will always give production contracts to Western companies. And if that fails, just starve (\"sanction\") them until they comply. Examples: - Guatemala (1954) [1] - Cuba (1952 and the many later attempts to assassinate Castro) [2] - Iran (1953) after the Iranian parliament passed legislation to nationalize the oil industry [3] - Syria (1949) [4] - Congo (1960) [5] There are dozens of these. These countries aren't mysteriously poor. They haven't failed. They have been active exploited and their wealth stolen. [1]: https://en.wikipedia.org/wiki/1954_Guatemalan_coup_d%27%C3%A... [2]: https://en.wikipedia.org/wiki/1952_Cuban_coup_d%27%C3%A9tat [3]: https://en.wikipedia.org/wiki/1953_Iran_coup [4]: https://en.wikipedia.org/wiki/March_1949_Syrian_coup_d%27%C3... [5]: https://en.wikipedia.org/wiki/Congo_Crisis reply blackhawkC17 3 hours agoparentprevNorway already had a developed, functional economy before discovering oil, so it didn't fall into the resource curse. In contrast, any developing country that discovers a valuable resource will almost always devolve into corruption and, at worst, conflict because their weak institutions can easily be corrupted by internal and external parties. A case study is my country (Nigeria), a notoriously corrupt oil-dependent cratered economy. I'm honestly happy for Norway to find more resources. Any country that demonstrates responsible use of resources for internal development deserves more..this includes most of Western and Northern Europe plus the US and Canada. reply Vinnl 3 hours agorootparent> Any country that demonstrates responsible use of resources for internal development deserves more..this includes most of Western and Northern Europe Then again, there's also https://en.m.wikipedia.org/wiki/Dutch_disease reply blackhawkC17 3 hours agorootparentYou have a point. It's actually bad to wish for excessive natural resources in a developed country. reply snowpid 3 hours agorootparentprevDo (educated) people in Nigeria see Norway as a role model for political development? Also how is Botswana seen in Nigeria? (If this questions arent too broad, my apologies) reply blackhawkC17 3 hours agorootparent> Do (educated) people in Nigeria see Norway as a role model for political development? Corruption and incompetence are too rampant here, so the Norwegian model will never work—nobody thinks of it. We also have 40 times the population and fewer resources than Norway, making it impossible. > Also, how is Botswana seen in Nigeria? Almost no one thinks of it, lol. But it's arguably the best African country for the average citizen, owing to relatively low corruption and a high value for the rule of law. Compared to Europe, Bostwana is a backwater, but in Africa, it's currently our peak :( reply snowpid 1 hour agorootparent\"Compared to Europe, Bostwana is a backwater, but in Africa, it's currently our peak :( \" Perfect (and Europe is not perfect) is the enemy of good. Botswana can be a role model for many African nations. Hopefully South Africa in the future also again! reply mwigdahl 43 minutes agorootparentprevWhat are the current ideas in Nigeria and other African nations in similar situations about how to improve national quality of life and reduce corruption? Are there any plausible paths for improvement? reply epolanski 2 hours agorootparentprevFrom what I've read about Botswana is way ahead on many matters compared to most of Europe (e.g. gender equality). reply blackhawkC17 1 hour agorootparentEven if that were true (I doubt it), Botswana remains way behind on economic prospects for the average individual, the core issue when we talk about development. > Based on these estimates, 17.2 percent of the population in Botswana (446 thousand people in 2021) is multidimensionally poor, while an additional 19.7 percent is classified as vulnerable to multidimensional poverty (509 thousand people in 2021). https://hdr.undp.org/sites/default/files/Country-Profiles/MP... reply smegsicle 4 hours agoparentprevalso unfair number of fjords reply w-m 3 hours agorootparentI happen to like them, and I’m old-fashioned enough to think that they give a lovely baroque feel to a continent. reply sib 3 hours agorootparentI took GP's comment to mean \"unfair in a good way\" (of course my priors are \"fjords good\") reply msds 3 hours agorootparentThat was a line directly from The Hitchhiker's Guide to the Galaxy. reply wumbo 3 hours agorootparentprevunaffjordable reply tiborsaas 1 hour agorootparentgreat, so they have endless puns now too. reply wizardforhire 40 minutes agoparentprevThis recent real life yore video backs up your claims https://youtube.com/watch?v=RO8vWJfmY88&pp=ygUJTm9yd2F5IG9w reply screye 1 hour agoparentprevIt's unfair. Period. But nothing in the world has ever been fair. So unfair as it maybe, it's also normal. General question, has any high HDI country fallen prey to the resource curse? (Maybe California and some communist nations?) Norway has done well, and they've done very very well.... But, high HDI, no immigration, cultural homogeninity and infinite money hack does make it seem like they're playing on easy mode. Many countries with lower starting HDI have navigated around their resource curses just as well (Singapore, Botswana). Norway deserves credit, but it is an ineffective blueprint for nations looking to beat their own economic traps. reply EA-3167 1 hour agorootparentTruthfully it's neither fair nor unfair, it's academic. These minerals are not actually rare, they're ubiquitous, but they're energetically and environmentally unfavorable to exploit. China does it because of their um... unique economic system, and lack of eff's to give about the environmental consequences. Everyone else would have to pay a fortune in energy costs and another fortune mitigating environmental effects, which makes them economically unfavorable to exploit. For Norway, just like Wyoming and a dozen other places this same story has played out, this changes nothing. reply dncornholio 3 hours agoparentprevThis has absolutely nothing to with what is fair. They just lucky. Nothing unfair, unless you think about who put the metals there. reply CamperBob2 3 hours agoparentprevHonestly, it seems like the \"rare earth elements\" are considered \"rare\" because people didn't bother looking for them until recently. They seem to be pretty widely distributed in reality, just not always easy to access. reply dagw 3 hours agorootparentThey seem to be pretty widely distributed in reality That's the problem. They're 'everywhere', but generally in such low concentrations that it just isn't profitable to extract them. reply karaterobot 2 hours agorootparentprevThis is my understanding as well. Until recently, it wasn't worth the cost for most countries to secure their own supplies, so they just bought them from the countries that sold them cheaply. When push comes to shove—or, when rare earth metals because strategic—it's a question of \"do we want to invest in digging up our own?\" not \"gee, do we have enough of this stuff in the ground at all?\". reply fifilura 3 hours agorootparentprevI agree. It seems like these news got old pretty quickly https://lkab.com/en/press/europes-largest-deposit-of-rare-ea... reply KptMarchewa 3 hours agorootparentprevThat's the case with great majority of the limited minerals. reply ajuc 3 hours agorootparentprevYup. Lead is less common in Earth's crust than: - lithium - cobalt - neodymium - lanthanum - ytrium - scandium - cerium https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth... We simply had far more uses for lead till very recently. reply Animats 1 hour agoprevRare-earths supply has been picking up for years. - Australian rare earth mines.[1] - MP Minerals Mountain Pass, California mine.[2] Now the price of raw ore has dropped. \"Revenue decreased 49% year-over-year to $48.7 million, driven by a 54% decrease in the realized price of rare earth oxide (“REO”) in concentrate and a 9% decrease in REO sales volumes partially offset by initial sales of separated NdPr.\"[3] Rare earth gluts have happened before. There's some price manipulation from China, and too much financialization at MP Minerals (they just did a stock buyback) but it's mostly that demand isn't that sensitive to price. Rare earth costs are a small fraction of the cost of a motor. MP Minerals is still running at a loss. The previous owner of that mine went bankrupt. The bottleneck now seems to be the next steps in ore processing. MP Minerals announced in 2021 that they were starting to build a processing plant in Fort Worth, Texas.[4] The building has been built and there are cars in the parking lot.[5] It's a small facility, subsidized by General Motors and DoD. Production of product (magnets) is supposed to start in 2025. There's no fundamental shortage of rare earths, but making money at this seems to be very difficult. [1] https://www.mining-technology.com/features/australia-rare-ea... [2] https://mpmaterials.com [3] https://investors.mpmaterials.com/investor-news/news-details... [4] https://mpmaterials.com/articles/mp-materials-begins-constru... [5] https://earth.google.com/web/search/13840+Independence+Pkwy,... reply GlibMonkeyDeath 3 hours agoprev\"The 'rare' in the name \"rare earths\" has more to do with the difficulty of separating of the individual elements than the scarcity of any of them. \" https://en.wikipedia.org/wiki/Lanthanide The lanthanide series of elements is interesting because the 4f levels that are getting filled are actually physically closer to the nucleus than the outer orbitals, so their chemical properties are very similar between elements. That also makes them hard to separate from one another. Unless there is a special Norwegian process for this separation, I am not sure this announcement will mean much. reply georgeecollins 3 hours agoparentThis is one of those weird narratives where you see stories about rare earth minerals are thought to be rare like gold, not rare as in practically everywhere but in very small quantities. They used to mine rare earth metals in California. It's terrible for the environment and labor costs are high. But in an emergency you could do it there and many other places. reply dvh 3 hours agoparentprev\"cloud computing\" -> \"someone's elses computer\" \"serverless\" -> \"pay per request\" \"rare earth minerals\" -> \"hard to process minerals\" reply dmix 3 hours agoparentprevAre some mines easier to seperate than others? Or is it a niche industrial skill? reply georgeecollins 3 hours agorootparentYes, some ground is easier to process, but that isn't the limiting factor. But the real cost is the toxic waste created and labor and the ground is super torn up because you process so much. It helps if you can do it far away from people. Hopefully they have a better plan to clean up afterward. reply veqz 2 hours agorootparentUnfortunately this is also in pretty decent farming land. The land owners will be compensated, but I understand many don't feel too happy about leaving their farms... reply JoeAltmaier 3 hours agoprevCareful when talking about mineral resources. It's not a matter of throwing around textbook phrases about how common something is in the Earth's crust. Mining is always, always, always about the economics. How concentrated; how accessible by road; how easy to extract; distance to refineries; cost of building and transporting people and supplies to the mine. Even, affect on prices once the mine starts delivering! A mine can deliver so much it deflates prices and drives itself out of business. Lots of everything, everywhere. But to build a mine, you have to ask a mining engineer, and they measure if it's worth anybody's effort. reply kristofferR 0 minutes agoparentIt's relatively central: https://akamai.vgc.no/v2/images/9fdc0877-a37a-4bf1-ba64-6185... https://maps.app.goo.gl/92bDQtmUkf7ZyJYZ6 reply coldtea 3 hours agoparentprev>A mine can deliver so much it deflates prices and drives itself out of business. Couldn't the owners just ...hoard the extra/throttle the delivery of the supefluous amount to keep prices up? reply dflock 3 hours agorootparentYes, but... storing stuff costs money, keeping a mine open and unflooded, etc... costs money, even if you're not doing any mining, etc... Also markets will adjust prices if they know about your stockpile, too. reply permo-w 36 minutes agorootparentprevthis is what OPEC does with oil reply mwigdahl 41 minutes agorootparentprevDe Beers has entered the chat... reply tiffanyh 3 hours agoprevNorway is so interesting. They purposefully setup a sovereign fund & political structure that incentives long-term thinking. Great video below on how they think about energy, use and raw materials. https://www.youtube.com/watch?v=RO8vWJfmY88 reply piva00 3 hours agoparentThey have to thank Farouk al-Kasim for that, an Iraqi geologist from Basra who worked at the Iraqi Petroleum Company and moved to Norway, wrote a white paper selling the idea of the state participation in exploiting oil in Norway and the rest is history. reply tiffanyh 3 hours agorootparentAnd it's not just oil, the country is 99% renewal energy usage. reply blackhawkC17 3 hours agorootparentDon't get high on your own supply reply philip1209 3 hours agoprevWow, Norway is going to go from rich to richer. They already have put $1.5 trillion (!) into their national pension fund with oil: https://en.wikipedia.org/wiki/Government_Pension_Fund_of_Nor... reply vundercind 3 hours agoparentThis is what the US should have done. Huge amounts of collective wealth, frittered away. Alaska’s the only state I know of that even kind-of demands that permanent extraction from the very land under our feet benefit its people broadly, instead of only a few. reply Gud 1 hour agorootparentNot frittered away. That money went straight to the rich and well connected. reply rqtwteye 1 hour agorootparentSeems the plan worked really well. reply bpodgursky 48 minutes agorootparentprevAlaska does the exact opposite of what you are glamorizing, by frittering away extracted wealth on a state UBI (which many recipients use to avoid building careers or skills). reply vundercind 8 minutes agorootparentAt least the unrecoverable wealth of the very land of the state is distributed to residents, I mean. That’s not the opposite, it’s just less than the ideal of capturing quite a bit of that value and investing it for citizens’ benefit so that some of the wealth isn’t lost to a few private hands forever. It’s the closest the US gets to doing something that’s a good idea, with its vast non-renewable natural resources. reply reducesuffering 1 hour agorootparentprevSo while Norwegians have collectively saved ~$300k per citizen, Americans are collectively in debt ~$100k per citizen. reply lionkor 2 hours agoprevMan Norway looks an awful lot like it has weapons of mass destruction right about now reply Pulcinella 2 hours agoparentIndeed. I am hearing the Norwegian people yearn for freedom. reply t43562 3 hours agoprevAs far as electric motors are concerned we might want to consider using rare-earth-free motors. Example: https://advancedelectricmachines.com/ssrd/ This one also uses aluminium rather than copper wiring which has advantages when recycling apparently because any copper content that remains with recycled steel makes it less durable. reply the_duke 2 hours agoparentCopper is not a rare earth. reply nuz 3 hours agoprev\"Demand for rare earths and critical minerals is expected to grow exponentially in the coming years\" For a limited resource. reply bryanlarsen 3 hours agoparentThey're essentially unlimited. They make up 68ppm of the Earth's crust. If we used all of that to make stuff, we'd run out of room to put the stuff before we'd run out of rare earths. reply BurningFrog 3 hours agoparentprevAll resources are limited! reply breck 3 hours agoparentprev\"We have never run out of a single resource.\" https://x.com/naval/status/1800363450180522313 reply woodruffw 3 hours agorootparentI can think of several species we've run out of. (We also came very close to running \"out of\" ozone over a large part of our planet. The idea that a resource is \"done\" only when it's been utterly depleted isn't how it goes in practice.) reply addaon 3 hours agorootparentprev… he said, as he seasoned his stew with silphium. reply riffraff 2 hours agorootparenta dodo stew! reply coldtea 3 hours agorootparentprev>Whenever a resource becomes scarce, incentives drive technology to find better alternatives, we move towards abundance at each iteration. The denial is strong in these ones... \"Hey, it worked in the past, when the population was 1/100th to 1/4th (start of 20th century), industrial production and consumption was 1/10000th was it is, demand for most modern necessary resources zero, and so on, so should work in millenia to come. And if not we can always pull a pivot to an alternative resource out of our magic hats, because 'science'\". reply UberFly 16 minutes agorootparentWell technically the line you quoted is valid and your response is also mostly valid. I guess the answer lies somewhere in the middle. reply whereismyacc 3 hours agoprevDidn't we have this headline for Sweden like a year ago? Same deposit? reply dagw 3 hours agoparentYea, they found one in Sweden last year, but this one is much bigger. Also two entirely different deposits. The one in Sweden is right at its northern border, and this one is in the southern part of Norway. reply dncornholio 3 hours agoparentprevFrom the article: > The discovery eclipses a massive rare earths deposit found last year in neighboring Sweden. reply piva00 3 hours agoparentprevCompletely different, the Norwegian discovery is in the southeast of Norway while the Swedish discovery is in Kiruna, north of the Arctic circle. reply fifilura 3 hours agorootparentThe location in Sweden is not particularly bad. The logistics to shipping is very well established through the all season harbor Narvik (in Norway) because of the iron ore mines. The culprit is the Sami people that just happened to live there before the more powerful swedish government annexed it. Who is right? The people who were here first herding reindeer or the government? Not a trivial question to answer if you take a step back. reply peroo 2 hours agorootparentIf you're a cynic, announcing that you've \"discovered\" a large of amount of REE in your iron ore tailings - and having the chief executive of the EU declare it strategically important - seems like a very good way of making sure you can continue mining iron ore for the forseeable future. reply patall 2 hours agorootparentprev> The logistics to shipping is very well established through the all season harbor Narvik (in Norway) because of the iron ore mines. Unless a train derails. Once. Or twice. Or, out of a sudden, it become too warm in May. Then some minor mines start to close. (Just telling it as it is, lol. Who knows what happens next) reply maxglute 3 hours agoprevSo who/where is going to do dirty the processing? reply ck2 3 hours agoprevI thought the irony is that \"rare\" earth metals are not rare at all? It's just that no-one wants to mine them at great expense for little profit? (edit: are not, not are) reply breck 3 hours agoparentCorrect, the term is a misnomer. The Wikipedia page on \"rare\" earths is very interesting: https://en.wikipedia.org/wiki/Rare-earth_element reply ajmurmann 3 hours agoparentprevIt means the mineral wasn't cooked to a high internal temperature (sorry, I accept the downvotes in advance) reply pestatije 1 hour agorootparentwell done! reply soco 3 hours agoprevI wonder how's it working in Norway, what will the locals have to say about getting huge holes in their backyards... reply epolanski 2 hours agoparentIn cases of higher national interest, what locals think is irrelevant. reply admissionsguy 3 hours agoprev> Europe's largest deposit of rare earth metals There was one discovered in Kiruna, Sweden last year [1] and announced to much fanfare during an EU summit. I wonder if there is any particular reason behind this trend. In both cases the path to commercial extraction is long and uncertain. [1] https://lkab.com/en/press/europes-largest-deposit-of-rare-ea... reply epolanski 2 hours agoparentBecause it is a huge news that we may have the capacity in Europe to not be completely reliant on imports. reply bbarnett 3 hours agoprevIt should be noted that there is no shortage of places in, for example North America, with rare earths, but instead all mines were shut down. Why? China. China purposefully sold such way under production cost, then once all competing mines closed, raised prices. And if you're in business, and thinking of going through the cost of reopening, you certainly wouldn't now that your competition has shown it can bankrupt you at a whim. It's actually not a bad strategy for China to have taken. Now though, China is restricting on political principles, to hobble chip production for the West. Now, there is a desire for domestic production again. But if I had a dormant rare earths mine, I wouldn't step up without some protection, such as duties on foreign imports. Because otherwise, if the duty is just on China, it will still flow cheap through other countries. reply bdauvergne 3 hours agoparentThere is a french expression « Gouverner c'est prévoir », « To govern is to predict ». If China wants to frequently subsidize west consumption (rare earth, EV cars, batteries, solar panels, microwave ovens in the past, the list is long...), great for us, but our government should have the lucidity to keep some industry under limited economic perfusion (keep the machine tools, fire most of the workers, but keep things running and knowledge) for when the scheme will with certainly came to its end; COVID should have been an eye opener for most. reply BurningFrog 3 hours agoparentprevIs there any documentation that this happened? I ask because this is one of the most common myths in Economics. reply pkaye 3 hours agorootparentI researched this a bit earlier this week but didn't save the links. Its not just that China could produce rare earth minerals at lower costs but western countries starting tightening their laws on mining (due to uranium byproducts) but also environments laws. Then they willingly shared the production techniques to China to do all the dirty work. However US restarted its rare earth mining a few years back and now it ranks second in production through far behind China. I'm guess the main concern was the need of these rare earth minerals for military equipment. https://www.statista.com/statistics/268011/top-countries-in-... reply georgeecollins 3 hours agoparentprevMining them also creates a lot of toxic waste, which is expensive to clean up if you do actually clean it up. reply jajko 3 hours agoparentprevDon't blame every woe you ever saw on China as its modern these days in US, this is solely US government incompetence par excellence. I am pretty sure there must have been a competent bureaucrat yelling this left and right 2 decades ago but completely ignored or worse. They could foresee it from lightyears ahead and compensate miners due to strategic resource and it would cost US literally nothing, you know in same vein as GM or Boeing were/are 'strategic' shitshows. But they did nothing and let simple market force decide outcome. China didn't close US mines, US mine owners due to economical pressures and lack of support form US did. reply khaki54 3 hours agoprevNorway just moved up on Russia's \"countries to invade\" list reply lye 3 hours agoparentYou're thinking of another country that has a habit of invading or destabilizing countries rich in natural resources, especially when they don't do as they're told. Russia has more oil, gas and rare earths of its own than it knows what to do with. reply wumeow 1 hour agorootparentSo does the US so surely you’re not referring to them. reply bauruine 3 hours agoparentprevNorway is a NATO member. One of the founding members even. I hope they are on the \"Do NOT invade\" list. reply astrodust 3 hours agoparentprevThey'll have to fight their way through Finland which has a history of not working out for them. reply skrebbel 3 hours agorootparentFinland and (Soviet) Russia fought two wars and Finland lost territory in both. reply AnimalMuppet 2 hours agorootparentAnd in both cases, Soviet Russia took less of Finland than they wanted to, because the losses were unacceptable to continue. reply spinningarrow 3 hours agorootparentprevNorway and Russia do share a border (albeit a small remote one). reply astrodust 2 hours agorootparentBefore they could, theoretically, just roll past, but now Finland will be compelled to join due to Article 5. Not that they'd need much compelling. reply veqz 2 hours agoparentprevStrangely enough Russia (and their predecessors) and Norway has never been at war. Ever. Not that the past is a predictor of the future, of course, and Putin is operating quite a few spies and saboteurs here too. But having both Sweden and Finland with us makes it rather unlikely they would get anywhere near the Fen area. :p reply Moldoteck 2 hours agorootparentRussia did 'liberate' norway during ww2 and tried to drag it unde it's influence. It's not war per se but still reply adhamsalama 1 hour agoparentprevMore like just moved up the US' \"countries to give freedom\" list. reply syngrog66 3 hours agoprevgood. anything that reduces the West's dependence on CRINK nations is wise (China, Russia, Iran, North Korea.) The 4 we have higher than normal risk of war with, or at least total boycott/embargo. reply timonoko 3 hours agoprev [–] You only need strong Green party in the country and odds will even out. As we all know Finland has more fossil fuel than Norway. Peat is basically oil, but little younger. Finnish Green Party has managed to block all use of peat, because while it is totally renewable, it does not grow back fast enough. reply Peroni 3 hours agoparentConsidering it takes 1,000 years for 1m of peat to build back up, I'm not sure it's reasonable to call it renewable. reply kragen 1 hour agorootparentwell, you could extract it sustainably at 1000 cubic meters per square kilometer per year, and that is a thing that people have done in the past. but it's not going to be an economically competitive source of energy reply originalvichy 3 hours agoparentprevPeat is worse than coal with regards to co2 emissions, so I will vote to keep it in the ground. reply master-lincoln 3 hours agoparentprevThat's like saying coal is renewable. E.g. Lignite (brown coal) is just Peat that was compressed over many years. reply vintermann 3 hours agoparentprev [–] Burning topsoil is kind of insane. Peat is not renewable on practical human timescales. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Norway has discovered Europe's largest deposit of rare earth metals in the Fen Carbonatite Complex, containing 8.8 million metric tons of rare earth oxides.",
      "This find includes 1.5 million metric tons of magnet-related rare earths crucial for electric vehicles and wind turbines, potentially reducing Europe's reliance on China.",
      "The discovery is a milestone for Rare Earths Norway and aligns with Europe's goal to meet its rare earth demand domestically by 2030, with mining expected to start by then."
    ],
    "commentSummary": [
      "Norway has discovered Europe's largest rare earth metals deposit, leading to mixed reactions about resource distribution and management.",
      "The discussion emphasizes Norway's historical and geographical context, effective resource management, and the broader implications of rare earth mining, including environmental concerns and geopolitical dynamics with China and Russia.",
      "Misconceptions about rare earth elements are addressed, highlighting their abundance but the challenges associated with extraction."
    ],
    "points": 209,
    "commentCount": 197,
    "retryCount": 0,
    "time": 1718116594
  },
  {
    "id": 40645983,
    "title": "Slop: The Rise of Low-Quality A.I.-Generated Content and Its Impact on Online Platforms",
    "originLink": "https://www.nytimes.com/2024/06/11/style/ai-search-slop.html",
    "originBody": "ADVERTISEMENT SKIP ADVERTISEMENT First Came ‘Spam.’ Now, With A.I., We’ve Got ‘Slop’ A new term has emerged to describe dubious A.I.-generated material. Listen to this article · 5:11 min Learn more Share full article Google’s so-called A.I. Overview feature has changed online searches, and some internet users are not pleased. Credit... Andrew Paterson/Alamy Stock Photo By Benjamin Hoffman June 11, 2024 Updated 9:10 a.m. ET You may not know exactly what “slop” means in relation to artificial intelligence. But on some level you probably do. Slop, at least in the fast-moving world of online message boards, is a broad term that has developed some traction in reference to shoddy or unwanted A.I. content in social media, art, books and, increasingly, in search results. Google suggesting that you could add nontoxic glue to make cheese stick to a pizza? That’s slop. So is a low-price digital book that seems like the one you were looking for, but not quite. And those posts in your Facebook feed that seemingly came from nowhere? They’re slop as well. The term became more prevalent last month when Google incorporated its Gemini A.I. model into its U.S.-based search results. Rather than pointing users toward links, the service attempts to solve a query directly with an “A.I. Overview” — a chunk of text at the top of a results page that uses Gemini to form its best guess at what the user is looking for. The change was a reaction to Microsoft having incorporated A.I. into its search results on Bing, and it had some immediate missteps, leading Google to declare it would roll back some of its A.I. features until problems can be ironed out. But with the dominant search engines having made A.I. a priority, it appears that vast quantities of information generated by machines, rather than largely curated by humans, will be served up as a daily part of life on the internet for the foreseeable future. Hence the term slop, which conjures images of heaps of unappetizing food being shoveled into troughs for livestock. Like that type of slop, A.I.-assisted search comes together quickly, but not necessarily in a way that critical thinkers can stomach. Kristian Hammond, the director of Northwestern University’s Center for Advancing Safety of Machine Intelligence, noted a problem in the current model: the information from A.I. Overview is being presented as a definitive answer, rather than as a place to start an internet user’s research into a given subject. “You search for something and you get back what you need in order to think — and it actually encourages you to think,” Mr. Hammond said. “What it’s becoming, in this integration with language models, is something that does not encourage you to think. It encourages you to accept. And that, I think, is dangerous.” For a problem to be targeted, giving it a name can prove helpful. And while slop is one option, it is still an open question of whether it will catch on with a mainstream audience, or end up in the slang dustbin with cheugy, bae and skibidi. Adam Aleksic, a linguist and content creator who uses the handle etymologynerd on social media, believes that slop — which he said has yet to cross over to a broader audience — shows promise. “I think this is a great example of an unobtrusive word right now, because it is a word we’re all familiar with,” Mr. Aleksic said. “It’s a word that feels like it’s naturally applicable to this situation. Therefore, it’s less in your face.” @etymologynerd More great discussion of this in Alan Metcalf's book \"Predicting New Words\" #etymology #linguistics #language #memehistory #rizz #skibidi ♬ original sound - etymologynerd The use of slop as a descriptor for low-grade A.I. material seemingly came about in reaction to the release of A.I. art generators in 2022. Some have identified Simon Willison, a developer, as an early adopter of the term — but Mr. Willison, who has pushed for the phrase’s adoption, said it was in use long before he found it. “I think I might actually have been quite late to the party!” he said in an email. The term has sprung up in 4chan, Hacker News and YouTube comments, where anonymous posters sometimes project their proficiency in complex subject matter by using in-group language. “What we always see with any slang is that it starts in a niche community and then spreads from there,” Mr. Aleksic said. “Usually, coolness is a factor that helps it spread, but not necessarily. Like, we’ve had a lot of words spread from a bunch of coding nerds, right? Look at the word ‘spam.’ Usually, the word is created because there is a particular group with shared interests, with a shared need to invent words.” In the short term, the effect of A.I. on search engines and the internet in general may be less extreme than some would fear. News organizations have worried about shrinking online audiences as people rely more on A.I.-generated answers and data from Chartbeat, a company that researches internet traffic, indicates that there was an immediate drop in referrals from Google Discover to websites in the first days of A.I. overviews. But that dip has since recovered, and in the first three weeks of the overviews, overall search traffic to more than 2,000 major websites in the U.S. actually went up, according to Chartbeat. But as people become accustomed to A.I.’s increasing role in how the internet works, Mr. Willison, who identified himself as an optimist for A.I. when it is used correctly, thought that slop could become the go-to term for the lesser forms of machine-generated content. “Society needs concise ways to talk about modern A.I. — both the positives and the negatives,” he said. “‘Ignore that email, it’s spam,’ and ‘Ignore that article, it’s slop,’ are both useful lessons.” Benjamin Hoffman is a senior editor who writes, assigns and edits stories primarily on the intersection between sports, lifestyle and culture. More about Benjamin Hoffman See more on: Alphabet Inc. Share full article Explore Our Style Coverage The latest in fashion, trends, love and more. The Age of Brooke Shields: The model and actress is defining a new era for herself with three new titles: Netflix rom-com star, union boss and C.E.O. of a beauty brand aimed at women over 40. Spring Street Style: Spring’s warmth is a flirt, but New Yorkers are ready for the season’s unpredictability. Here’s what they’re wearing. Is Pants Sizing Sexist?: Our fashion critic examines the history of women’s trousers and “the sheer ridiculousness of the current state of sizing.” A New Start Sans Prison Uniforms: Bindle & Keep, a suit maker in Brooklyn, offers free formal wear to newly exonerated men and women trying to rebuild their lives, helping rekindle a sense of personal style. An Influential Jeans Guy: Benjamin Talley Smith may well have made the jeans in your closet. And your friend’s closet. And your friend’s friends’. Here’s why they’re so ubiquitous. FaceTime Calls With Mom: What started as a way for the filmmaker Josh Seftel and his mother, Pat, to stay in touch has become a popular feature on “CBS Sunday Morning.” ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=40645983",
    "commentBody": "A new term, ‘slop’, has emerged to describe dubious A.I.-generated material (nytimes.com)191 points by 65 5 hours agohidepastfavorite193 comments Joeboy 4 hours agohttps://archive.ph/PueKj duxup 4 hours agoprevSlop seems like a good term for unwanted AI generated content. But I wonder how much this is AI and how much we've sort of curated a slop pattern even before AI: - Video game tips web pages with massive chunks of text / ads before you get to the inevitable answer of \"hit A when X happens\". - The horrendous mess that Quora became with technically correct in some ways but also misleading answers to historical content. - Medium articles about coding that are filled with irrelevant pics and blocks of text that are \"not wrong\" but also \"not right\" followed by weirdly specific code... We had all that before AI. reply imabotbeep2937 4 hours agoparentAgree. Content was the OG slop. Buzzfeed with monkeys on typewriters. The problem is that dopamine addicts generate outsized engagement. I know a literal crack mom who spends a solid 90+ hours a week watching accident videos to keep her brain triggered. The algorithm caters to her. Send promotional emails daily or more, constant notifications, recommend the same few videos over and over. Gotta get in there before she clicks another car crash video. IMHO: Marketing is a top societal evil right now. If the media machine wasn't so desperate for content, AI wouldn't be a fraction of the problem it is. But with everyone obsessing over the next piece of content, fake AI presentations are mandatory. reply AnimalMuppet 4 hours agorootparentHmm. An AI trained to maximize dopamine could be a very bad thing. (It won't be stated that way. It will be trained to \"maximize engagement\", but it amounts to the same thing.) reply pjc50 2 hours agorootparent> An AI trained to maximize dopamine could be a very bad thing. Spelled \"profitable\". This is definitely something that's already happened/happening; see algorithmic timelines and the widespread sudden legalization and acceptance of gambling. reply pmtcc 3 hours agorootparentprevOur brains have been under attack for years. Zuckerberg, Dorsey, and company have already spent decades and billions doing just that. With capabilities already in the AI realm. reply baq 1 hour agorootparentStill can’t decide how terrified should I be that somehow zuck is the good guy in the AI wars. reply Tao3300 4 hours agorootparentprev> could be is reply islandert 3 hours agorootparentprevTikTok? reply brcmthrowaway 2 hours agorootparentprevDude take me back to BuzzFeed listicles. Some millenials being cringe >> AI slop reply wdutch 4 hours agoparentprevI think you're right. Since LLMs went mainstream, I've seen a lot of my colleagues' presentations and thought \"was this written by ChatGPT?\" but I've come to wonder if it's just given me the frame of mind to identify low-effort slop that lacks any original insight but uses all the right sorts of words and phrases, regardless of if it was authored by a human or not. reply cjbgkagh 4 hours agorootparentMy hope is that equivocating waffle will look so much like ChatGPT that humans will have to write clearly and precisely to differentiate ourselves and we can put this horrible era of essay writing style behind us. Though I’m starting to think that AI might improve faster than us so there might only be a diminishing margin of opportunity left to do this. reply bee_rider 2 hours agorootparentWe’ll have AI tools to take our bullet-points and expand them into prose (crappy now, eventually beautiful prose). Then we’ll use AI tools to summarize that prose into bullet points. Eventually we’ll realize we can just send the bullet points and generate the prose on the receiving side. This will be great because most of the time the AI’s will be able to say “let’s just be a nop.” reply cjbgkagh 2 hours agorootparentReminds me of the SMBC comic https://www.smbc-comics.com/?id=3576 that explores the idea further. I am less optimistic than the comic. reply imabotbeep2937 4 hours agorootparentprevIt's both. Especially the out of context tinfoil rage response. They always existed. But now it's so common to see some totally benign article about pizza, and the top comment is \"don't let them tell you not to remember in 1995 when US implanted radios in Syrian babies\". The algorithm is being trained solely for engagement. It is horrifying. reply Capricorn2481 2 hours agorootparentThis sounds completely unrelated. If someone is really leaving a comment like that, it has nothing to do with the article and everything to do with the way weirdos engage with the internet. The Slop is the wordy vapid garbage that maximizes SEO. reply smcin 2 hours agorootparentParent is right though: AI slop in an article is to maximize SEO. AI slop in a comment is a weird jumble of implausible claims to maximize engagement. I see both on a daily basis now. reply duxup 4 hours agorootparentprevI've had similar false positive experiences where I swore some content had to be some form of LLM generated content, until I discovered the source was just poorly done or even just text from some older writing that \"sounded\" wonky but was more of a product of its time (like a 1940s newsreel). reply datavirtue 2 hours agorootparentprevThis. Bad AI output is indistinguishable from bad human output. It's literally the same exact shit. reply d0odk 2 hours agorootparentWith AI, there can be more content, produced faster and probably more cheaply, that is tailored to individual users. reply flessner 4 hours agoparentprevYes, AI isn't entirely to blame for this - it's low quality, irrelevant and misleading content in general. Also, we have to look at the incentives: advertisement. Somehow, this is acceptable to consumers, profitable for companies and profitable for publishers. How, is absolutely beyond me... and it won't change so long as Google has a majority in the \"search\"-space as they are directly profiting from this. reply Propelloni 2 hours agorootparentToday's AI is not to blame for anything because those AIs lack agency. Take a good look at the theory and real-life algorithms and soon you will realize that GPTs are just better parrots. Tools that they are the blame does not lie in the tool, but in the user. Not unlike guns. reply lovethevoid 3 hours agorootparentprevGood point. The standards for advertising networks has to increase tenfold, right now they reward slop, companies drain their ad budgets on channels they can’t even fully measure, and it repeats since it takes too long for companies to notice the effects. It’s the reason advertising costs have ballooned digitally, and also the cause of many lawsuits that Google continues downplaying in the public eye. reply kokanee 38 minutes agoparentprevIt's true... the quality of content on the Internet has a bunch of problems, and AI is just one of them. The economic incentives to trick people into staying on your page and scrolling as much as possible are a fundamental part of the problem. Politically-motivated ragebait and lies are a separate huge problem. AI-generated slop is also a problem for content quality and UX, but I'm far more concerned about the impact of AI on the value of human labor and intellectual property than I am about the UX of my search result pages. reply giancarlostoro 4 hours agoparentprev> - The horrendous mess that Quora became with technically correct in some ways but also misleading answers to historical content. What kills me is I have to hunt for the answer in Quora now. I just treat quora like I do pinterest, just back out and never return. reply disqard 3 hours agorootparentIf you happen to use kagi, you can \"ban\" Pinterest from your SERP. For me, it's one of those \"quality of life\" things that really improves my search experience (and is therefore worth paying for). reply janalsncm 2 hours agorootparentThere are chrome plugins that block domains from Google results for free and don’t require a login. reply giancarlostoro 1 hour agorootparentprevI was, and I just might re-subscribe to it, I'm getting tired of how increasingly useless Google is becoming. reply martin293 3 hours agorootparentprevI remember finding Quora when it was good. It was a literal godsend, actually interesting and meaningful questions and answers. Basically what the internet was advertised as (information interchange). Sadly it only lasted like 6 months. reply tivert 44 minutes agoparentprev> We had all that before AI. What AI gives us is vastly cheaper slop, so now it can be produced at a scale unimaginable to prior generations. No more paying some schmuck a penny a word to bang out \"private label articles,\" so they were only practical as SEO. Now you can have a unique slop for every spam email, every search query! Truly, we are making the world a better place. reply tananaev 4 hours agoparentprevThat's a result of natural selection forced by search engines. I think that's why I like ChatGPT so much. You can ask it very specific things and it will tell you exactly what you need. It does also output verbose answers by default, but you can control it by promoting for a short answer. reply AlexandrB 4 hours agorootparentEnjoy it while you can. Once the marketing guys and monetization engineers get to it I suspect things will get a lot more annoying. reply tavavex 1 hour agorootparentLuckily, unlike search engines and similar, LLMs can be run completely locally. As long as there are corporate interests trying to squeeze new tech for every cent with no regard to anything else, there will be hobbyists making what's actually useful for them. reply TeMPOraL 2 hours agorootparentprevThis. Marketing is a cancer on modern society, and it's metastasizing to new communication media increasingly quickly. reply datavirtue 2 hours agorootparentMarketing is literally customer/product (market) identification and all the activity required to produce and deliver the product to customers. Business. Did you mean advertising? reply orge 2 hours agorootparentAre engineering, design, and logistics just sub fields of marketing? Is this really how people use the word marketing? reply TeMPOraL 2 hours agorootparentprevMotte and bailey. Marketing is what you say on paper, but nothing like it in practice. (And people have been giving me identical response with \"advertising\" in place of \"marketing\" for years now, so I'll say yes to both; the terms are effectively interchangeable in both motte and bailey cases.) reply datavirtue 2 hours agorootparentprevNot if my company is paying for it. Which they will, because they have to. The price will be kept in check becauae it is a commodity. Anyone wanting enterprise business will have to include it (Microsoft 365). reply duxup 4 hours agorootparentprevGood point. I do find myself sometimes even prompting for a shorter answer after it hits me with a blob of text ;) reply moi2388 3 hours agorootparentI do so as well, but usually the response is the chatbot first generating a paragraph about how it’ll comply with the request, making the prompt moot reply TeMPOraL 2 hours agorootparentKeep in mind that tokens are LLM units of thought; the only moment the model does any computation is when generating tokens. Therefore, asking it to be succinct means effectively dumbing it down. reply wafflemaker 3 hours agorootparentprevIt is probably an internalized \"prompt engineering\" trick from gpt3.5 times, where you could achieve near gpt-4 performance using stuff like that. Rephrase the question and plan your answer was on top of the list. reply henriquecm8 4 hours agoparentprevI can see the use to describe AI spam, but I am starting to seeing people using it to describe anything they don't like, basically a replacement for \"mid\" with was highly used the last couple of years. I noticed that when some people learn a new \"trendy\" word, they want to use it in every possible opportunity until it loses meaning. reply brazzy 4 hours agorootparent> basically a replacement for \"mid\" with was highly used the last couple of years Wot now? Somehow I managed to completely miss that. Edit: ah, seems like it's mainly a twitter thing. That explains it. reply cj 3 hours agorootparent\"mid\" is something I hear from people high school age most commonly. reply GaggiX 4 hours agorootparentprev\"Slop\" is a internet slang that has always been used to refer to low quality content that exploits current internet trends, using it to refer specifically to AI generated content is pretty new. reply datavirtue 2 hours agorootparentprevOf course, it's seeking it's low energy state. reply threetonesun 4 hours agoparentprevThe signal to noise being so bad on the web today is AI's most compelling use for me, it's better at getting a pretty-close-to-right answer than searching the web, with much less crap I have to block along the way. But, consider that all that crap ended up on the web for a reason, and wonder how long before AI just injects it itself into its own results. reply woodruffw 1 hour agoparentprevAs with everything, I think it's scope and scale: Quora was always a cesspool, but now every single question has a machine-generated response that's frequently incorrect or misleading (sometimes in legally concerning ways, like one was for me recently). reply guidoism 2 hours agoparentprevRecipe articles with hundreds of words of irrelevant text before the actual recipe. reply badgersnake 3 hours agoparentprevYoutube videos that could have been a one paragraph answer. reply somenameforme 3 hours agorootparentExactly why I literally never use videos for 'how to do [x]', when 'x' can be expected to be fairly straight forward, anymore. - 10 seconds intro - 10 seconds yoooo guys wassss up - 30 seconds build up - 30 seconds showing what the answer will do - 30 seconds encouraging you to post comments to the video - 2 seconds to explain the answer - 20 seconds yooo don't forget to pound that like and subscribe If this is really what's optimal for the sacred algorithm, then that algorithm needs a serious tune up. reply lxgr 1 minute agorootparentYou forgot the NordVPN ad! reply ryandrake 2 hours agorootparentprevWhat we need is an AI agent who can parse through 10 minute videos, and then extract out and summarize in text format only the important 2 seconds. reply ghaff 2 hours agorootparentprevI've seen examples where seeing someone make e.g. some repair really benefits from video. But I certainly won't argue in general. reply disqard 3 hours agorootparentprevIf it's a somewhat-successful YouTuber, then you missed the 60-second shout-out to their sponsor. reply TeMPOraL 2 hours agorootparentPlus 30 seconds to 2 minutes of Patreon segment, depending on whether they're reciting the list of newest/bestest patrons, and then 30 seconds of outro in the end, creating a frame for YouTube to stuff recommended videos of the creator in. reply p_l 2 hours agoparentprevAI hype allows one to push \"slop\" about AI slop. Just like simple template generated SEO, template-written \"content\", etc. before. In fact, a lot of writing about AI slop could be considered just as much slop... reply lux 3 hours agoparentprevThe endless drivel of recipe websites is another one, burying the actual recipe under an absolute mountain of slop. reply aidenn0 2 hours agorootparentRecipe for cinnamon rolls: When I was a kid we used to spend summers with my grandmother. It was an idyllica pastoral setting and we used to chase the goats around and catch butterflys. [snip 3000 words] ...when I asked her for her recipe, it turns out she made cinnamon rolls by buying pillsbury ones at the grocery store! So if you don't want to be like grandmother, use 2 cups of flour... reply marginalia_nu 1 hour agoparentprevYeah, slop isn't new, AI makes it easier to produce. Other examples include those books where each chapter generously estimated has a tweet worth of thought padded out with 35 pages of meandering anecdotes that just paraphrase the same idea. Like it's very clearly a sort of scam, the padding is there to make it seem like the book has more information that it does when you look at it in a digital bookstore. reply GaggiX 4 hours agoparentprevWe also had the term \"slop\" before and it's not strictly related to AI but \"content or media of little-to-no value\". reply PheonixPharts 2 hours agorootparentComing up with and quickly adopting new terms to sound \"hip\" is one of the most important skills for AI practitioners. We've had \"agent-based\" concepts in CS for decades, but if you're \"in\" you'll of course refer to \"agentic\" workflows and the like. It make sense to come up with terms to describe common patterns: Chain-of-Thought, RAG etc. are good examples of this. But the passion some members of this community have for being intentionally confusing is tiresome. reply CM30 4 hours agoparentprevYeah, and most of the reason for that can basically be summed up as \"it's what Google incentivises\". They look for detailed pages, so pages are bloated with irrelevant information. They look for pages people spend a lot of time on, so the same thing occurs. Plus, the hellscape that is modern advertising means that rushing content out quickly and cheaply is encouraged over anything else. AI will probably accelerate the process even more, but it's already been a huge issue for years now. reply TeMPOraL 2 hours agorootparentThere's a bit of blaming a victim going on here. Especially early on in the days of SEO, Google incentivized slop the same way a bank vault incentivized armed robbery: by having something of value in it. Google incentives don't matter much for honest website operators. They're only relevant when you want to abuse the system to promote your worthless bullshit[0] at the expense of the commons. I really wish society started to treat marketing hustlers with the same disdain it has for robbers. -- [0] - If it was worth anything, you wouldn't be worried about SEO all that much, especially back before it all turned into a race to the bottom. reply anal_reactor 2 hours agoparentprevWhen I was a kid and I was told to write an essay \"what is slop\" teachers would give lots of extra points for dumping useless and somehow vaguely related information just to raise the word count. Answers along \"slop is useless shit created only to serve as filler content to make money on stupid people\" would get zero points, I was expected to write the history of slop, the etymology of the word, the cultural context, the projected future, blah blah blah, don't forget at least ten citations, even if they're even more useless than the essay I was writing and 100% pure unadulterated slop. My master's thesis was on a topic that nobody else researched (it wasn't revolutionary, just a fun novel gimmick), so I had to write filler just to have a chapter on a topic possible to find references to, in order to get the citations count, even if the chapter wasn't relevant to the actual topic of the thesis So yes, I think that the push to create slop was there even before computers became a thing, we just didn't recognize it reply antisthenes 3 hours agoparentprevLiterally all of these are just the symptoms of declining ability of people (general public) to perform critical thinking. The content/spam/slop is simply being tailored to be effective with its intended audience. But that's not the scary part. The difference with AI slop is just the enormity of the scale and speed at which we can produce it. Finally, a couple of data centers can produce more slop than the entirety of humanity, combined. reply wafflemaker 3 hours agorootparentDon't think so. It's just democratizing of the internet. It went from elitist, well read and educated bunch to people communicating with pictures. Nothing wrong with that, tho text internet was nice. At work people often ask me for help with documents or translation. Or I see some friends' conversations. While Polish grammar is pretty difficult, it's not surprising to see messages with orthographic errors in 5 out of six words. You just live in a bubble of people who can read and write well. reply antisthenes 45 minutes agorootparent> It went from elitist, well read and educated bunch to people communicating with pictures. Nothing wrong with that, tho text internet was nice. There is absolutely everything wrong with that if it consistently invades and drowns out the voices of the well-educated elite. The worst tyranny in this world is the tyranny of the ignorant against the learned. In its worst form, it can lead to mob justice and other horrible things. Maybe that's not your worldview, but it is the view of many, and it's just as legitimate as yours. reply wizzwizz4 1 hour agorootparentprev> it's not surprising to see messages with orthographic errors in 5 out of six words But they're saying something. The characteristic feature of slop is not informality: it's fundamental meaninglessness. reply echelon 2 hours agorootparentprev> The difference with AI slop is just the enormity of the scale and speed at which we can produce it. Finally, a couple of data centers can produce more slop than the entirety of humanity, combined. Think only about your own consumption for a second. You're not going to engage with slop, are you? I'm imagining that whatever your filter process is, that you manage to heavily engage with content that is mostly good and well-suited for you. Discounting Google search becoming crummy, of course. AI in the hands of talented people is a tool, and they'll use it to make better stuff that appeals to you. I wouldn't worry about other people. Lots of people like rage bait, yellow journalism, tabloid spam, celebrity gossip, etc. There's not much you can do about that. reply djaouen 3 hours agoparentprevI don’t think they are saying that the internet hasn’t been shit. It is. I think what they are saying is that it is about to get a whole lot shittier thanks to AI. reply tkgally 4 hours agoprevBoth HN itself and prolific HN contributor simonw get shoutouts in the article: “The term [‘slop’] has sprung up in 4chan, Hacker News and YouTube comments, where anonymous posters sometimes project their proficiency in complex subject matter by using in-group language.” “Some have identified Simon Willison, a developer, as an early adopter of the term — but Mr. Willison, who has pushed for the phrase’s adoption, said it was in use long before he found it. ‘I think I might actually have been quite late to the party!’ he said in an email.” The first substantive discussion of the word here seems to be this: https://news.ycombinator.com/item?id=40301490 reply atomicnumber3 2 hours agoparent4chan has been calling things \"slop\" for literally so long I can't remember when it started. If you go to /g/ literally right now, ctrl F slop, 4 hits just on the front page previews. If anything, it originally started as calling things \"goyslop\", which you might be able to deduce is a portmanteau of \"goyim\" and \"slop\", the implication (given it's 4chan) of course being that it's low-quality stuff made by Jews that is foisted upon the \"goyim\" (non-Jews). To the point that I usually see people calling it \"AIslop\"... specifically to differentiate it from \"goyslop\", so pervasive is the use of the term. I'm honestly surprised \"slop\" (in this specific context) is hitting the mainstream (apparently) given it's so closely married to anti-Semitic undertones. I assume it's kind of like Pepe? People see the cute frog or the edgy designation of things as \"slop\" not knowing that's kind of a minced version of how it's actually used on 4chan. reply woodruffw 1 hour agorootparentIt helps that \"slop\" has a widespread, intuitive meaning (in this setting) that doesn't need 4chan's anti-semitic usage. I hadn't even made the connection to the 4chan phrase, even though I'd heard it before. (This is in contrast to Pepe, which was popularized principally on 4chan and then exported by reactionaries.) reply coldblues 2 hours agorootparentprevThe regular person will never get these terms right. Most people are not aware of this game of telephone they're unwillingly being part of. It will never ceases to annoy me. I still shudder at seeing \"Troll\" being misused. reply cletus 4 hours agoprevI'm a huge Neal Stephenson fan. Cryptonomicon is to this day one of my all-time favorite books. Years ago now I read Anathem. It wasn't as good but it had some really interesting ideas. One such idea was how the Internet was filled with garbage by all these agents (which were implied or stated were AI, I can't recall). They would subtly change things to be wrong. Why? Essentially to sell you a solution to this that filters out all the crap. Currently we rely a lot on altruism for much of the information on the Internet (eg Wikipedia). AI agents will get harder and harder to differentiate from actual humans making Wikipedia edits. I don't think we're that far away from human-vs-AI Wikipedia edit wars. I really wonder how much human knowledge will be destroyed by (intentional or otherwise) AI vandalism in the future. reply visarga 1 hour agoparentWe can always rely on pre-2022 data. But I guess what you're saying is plausible, I see it becoming like the adversarial game of virus vs immune system, a constant arms race. We got to build our immunity. On the one hand AI can churn bullshit on command, on the other hand training on large datasets tends to cancel out many errors across the corpus. All the more reason to use local models and curated feeds from now on. Local LLMs can clean / firewall the bad stuff, and follow our guidance. They will be like the new anti-virus software. I've predicted early in 2023 that in the future operating systems and browsers will all sport a small LLM that will ensure we don't get abused by the internet and provide a \"room of our own\", where we have total privacy. It's already a reality. reply tivert 39 minutes agorootparent> We can always rely on pre-2022 data. No we can't. How many websites from 1998 survive today, in a form you can actually find (e.g. not the Wayback Machine)? In ten or twenty years, most pre-2022 data will be inaccessible. reply pavel_lishin 4 hours agoparentprev> “Early in the Reticulum-thousands of years ago-it became almost useless because it was cluttered with faulty, obsolete, or downright misleading information,” Sammann said. > “Crap, you once called it,” I reminded him. > “Yes-a technical term. So crap filtering became important. Businesses were built around it. Some of those businesses came up with a clever plan to make more money: they poisoned the well. They began to put crap on the Reticulum deliberately, forcing people to use their products to filter that crap back out. They created syndevs whose sole purpose was to spew crap into the Reticulum. But it had to be good crap.” > “What is good crap?” Arsibalt asked in a politely incredulous tone. > “Well, bad crap would be an unformatted document consisting of random letters. Good crap would be a beautifully typeset, well-written document that contained a hundred correct, verifiable sentences and one that was subtly false. It’s a lot harder to generate good crap. At first they had to hire humans to churn it out. They mostly did it by taking legitimate documents and inserting errors-swapping one name for another, say. But it didn’t really take off until the military got interested.” > “As a tactic for planting misinformation in the enemy’s reticules, you mean,” Osa said. “This I know about. You are referring to the Artificial Inanity programs of the mid-First Millennium A.R.” > “Exactly!” Sammann said. “Artificial Inanity systems of enormous sophistication and power were built for exactly the purpose Fraa Osa has mentioned. In no time at all, the praxis leaked to the commercial sector and spread to the Rampant Orphan Botnet Ecologies. Never mind. The point is that there was a sort of Dark Age on the Reticulum that lasted until my Ita forerunners were able to bring matters in hand.” reply mvdtnz 0 minutes agorootparentI'm re-reading Anathem now (my favourite book). Something I noticed on my second reading is Stephenson describes Sammann's physical appearance exactly once in the book and I must have missed it the first time around. I always pictured the Ita as wearing elaborate robes with hoods darkening their faces due to their secretive nature. But in fact he describes Sammann as looking basically just like Gilfoyle from Silicon Valley, including the way he dresses. Which is amazing given the roots of the Ita (he describes the word as coming from Information Technology and the meaning of the A is lost to time, but it's obvious to a 20th century Earth-born reader it comes from IT Administrator). There are so many delightful details in Anathem, it's well worth a second reading. reply greendestiny_re 55 minutes agorootparentprev100 good sentences and 1 subtly wrong one? That makes for an extraordinary text! I suppose the idea sounded better in the writer's head but it would not be nearly as bad as implied. reply gamepsys 3 hours agoparentprevThe same idea is explored in more details in his later book 'Fall; or Dodge in Hell' where AI generated individualized content radicalizes parts of the population and convinces them to believe blatantly false facts. It's a decently large B plot in the novel that ties into some of the larger themes. reply soco 3 hours agorootparentWe didn't need AI for that, but it surely helps a lot making it easier possible. reply fullshark 4 hours agoprevI see no alternative if people are unwilling to actually pay for content. It's just going to be individualized slop feeds on every advertising based media app until they get tired of that (zero sign of that coming). Maybe the algorithms will be so good, and enough creative people will use these tools to generate truly exciting content that they wouldn't have been able to otherwise but it just looks totally dire to me for creatives at this moment. reply jl6 4 hours agoparent> unwilling to actually pay for content The \"content\" industry (books, music, movies, all of it) has a systemic issue of which we are only just seeing the beginning. Namely, there is now so much content, and it is all so easily accessible, that the relative value of any one piece of content has fallen way, way down. There are only so many hours in the day, and only so many days in a lifetime, and only so many humans on the planet, and growth in that aggregate content consumption capacity has been far outstripped by the growth in content production capacity. There's just obscenely more high quality new-to-you content than you can ever consume - and an increasing proportion of it is available very cheaply, or even free. Anything new faces an uphill battle against everything old - and now, against AI too. This is going to get a lot worse before it gets better (and it may never get better). reply apantel 3 hours agorootparentWell said. It’s the same with news. When something big happens in the world, there is an explosion of communication about it on the internet. You can absorb the event from countless sources. So what value is any one news outlet’s coverage? It’s not worth much. The media outlets used to be able to monetize a captive audience, i.e. people living in a certain locale would have a few newspapers and television channels to choose from. Now anyone, anywhere, can go online and absorb news from all of the posting and aggregating and reprocessing and commenting going on. It’s almost impossible to sell into that. The value of generic / impersonal content is rapidly approaching zero. The only thing that still has value is a particular creator of interest posting their next video — like your favorite YouTube channel, you’ll watch that. It seems like the only way to succeed in this new environment is to be a real human person who builds a following / cult of personality around themselves and their content with its signature that is unique to them. It’s something like ‘releasing content that is personally signed’ where the person’s signature has value to a certain audience. The audience is ‘captive’ because they can’t get that ‘personal signature’ anywhere else. Even AI can’t deepfake it, because the perceived value of it is specifically that it is coming from a particular real human person. reply TeMPOraL 1 hour agorootparent> It seems like the only way to succeed in this new environment is to be a real human person who builds a following / cult of personality around themselves and their content with its signature that is unique to them. Correction: pretend to be a real human (or even a hyperreal human), not to be a real human. This is the game YouTubers and Instagram influencers have been playing for over a decade - there's a team of people building a brand around the face of the vlogger/influencer, making them seem like a really nice and interesting human, where in fact the opposite is the case. The point of it is to exploit human vulnerability to parasocial relationships, creating a captive audience primed to be receptive to the deluge of advertising that follows. Yes, this is one of the few ways for \"content\" to keep value these days. Which is ironic, given that the net value of it to the consumer and society is squarely negative. reply cess11 3 hours agorootparentprev\"There's just obscenely more high quality new-to-you content\" Are you sure about this? How are you measuring quality? For me, if something resembles advertising I consider it to be of very low quality. There are some exceptions, for example some of the movie work by Roy Andersson, but they are very few. As far as I can tell, ad-discourse and ad-style permeates pretty much everything in contemporary \"content\". Every time I go to my library and open something older than me the language is like a fresh air, it's clear that someone put some intellectual work into it and there is a distinct character to the text, personality imbued by the typographers, authors and editors. This is very rare on the Internet, and whenever I come across it the typography is usually ad-adjacent anyway. reply jl6 2 hours agorootparentEven if a super-Sturgeon's-Law holds at a 10000:1 crap:quality ratio, there's still overwhelmingly so much stuff out there, produced over so many generations of talented writers, artists, musicians and directors, that you'd have to be unreasonably picky not to be able to fill a whole lifetime of consumption with enjoyable content. It's only our predilection for novelty that keeps the content mills going, and I wonder how long that can last against the ever-growing accumulation of culture. reply willvarfar 4 hours agoparentprevCompanies will serve slop to paying subscribers too. reply s1artibartfast 3 hours agorootparentIf it gets bad enough that people will pay, I think some will pay for exclusively real content. I hope this is the start of walled garden human internet. Web-rings, moderated forums, ect. A common cyberpunk trope is a trashed net and a private net. reply TeMPOraL 1 hour agorootparent> If it gets bad enough that people will pay, I think some will pay for exclusively real content. People who pay for content demonstrate that they have disposable income and are willing to spend it, which makes them prime population for advertisers to target. By paying, they're distinguishing themselves for the net-near-worthless population of free users. There's a huge pressure for advertisers to tap into that juicy population of paying users; it takes only so long before any given service succumbs to that pressure. reply s1artibartfast 52 minutes agorootparentReal content doesnt necessarily mean advertising free. There are tons of high quality pages and services funded by ads. The problem is with the spam and slop. Any sucessful walled garden will need to keep this crap out. banning adds is just one way. Content review is another. reply pixl97 4 hours agorootparentprevExactly. Slop is like meth for corporations. It costs nearly nothing to produce unlike real content, and for a short period of time can give a real boost to number of viewers/ad impressions/etc, the current board members can get that jump in their stocks and take a golden parachute while their replacements have to deal with a company that can no longer produce anything useful and has to spend a massive amount of money to get everything back in shape. reply fullshark 2 hours agorootparentprevTrue, let's get even more cynical actually, companies will serve ads to paying customers too, even those paying for \"ad-free\" versions of the product. reply skydhash 4 hours agoparentprevPeople wants to pay for content, but publishers are either not working on content worth paying for or don’t want you to purchase, they want you to rent instead. reply pjc50 2 hours agorootparentThe fundamental issue is that it's unreliable to know if you'll like content before you've experienced it. But afterwards you're not going to pay because you have already experienced it. It's a \"market for lemons\". reply skydhash 2 hours agorootparentIt was always a bet. You make something and hope that people like it enough to pay for it. Just like any business. Why should businesses be entitled to my money if their offerings have no value to me? reply duxup 4 hours agorootparentprevChicken and the egg there as far as \"worth paying for\" although I'd argue that's not really any different than \"don't want to pay\". reply StableAlkyne 4 hours agorootparentIf it's \"worth paying for,\" they can just squeeze more money out of the equation until it's barely worth the cost. For a real world example, just look at the scientific journal system - researchers pay upwards of $5k to publish (after spending however many tens to hundreds of thousands on the science, out of their own pocket), readers can pay $50 per article or their institution can subscribe for tens of thousands of dollars (if they're lucky and have a good negotiator). Journals do nothing of value aside from hosting the PDFs (which absolutely does not cost $50/download) and facilitating anonymous peer review (which amounts to sending emails to a few academics who will review it for free, at no cost to the journal). Even content that is worth paying for, like research, will quickly reach an equilibrium that maximizes profit while minimizing effort. reply ThrowawayTestr 4 hours agorootparentprevDecades of internet use has shown me that people absolutely do not want to pay for content. The average person will choose free+ads over paying every time. reply Workaccount2 4 hours agorootparentA large subset of those will choose free+ads with ad-block, so free+free. Then they will complain that the internet is full of trash content that doesn't suite them. reply pixl97 4 hours agorootparent>Then they will complain that the internet is full of trash content that doesn't suite them. This will happen regardless if you paid for content or not. The natural world is filled with parasites, it is an effective evolutionary strategy. reply techjamie 1 hour agorootparentprevAs someone that blocks ads with a vengeance, I'll turn off my ad blocker when advertising companies turn off their privacy invasion, and stop running ads for criminals and scammers. reply TeMPOraL 1 hour agorootparentAs another person that blocks ads with vengeance, I'll turn off my ad blocker only when advertising companies go bankrupt and effectively disappear from the face of the planet. Even non-surveilling, non-criminal advertising is still brain poison. Why would I want to ever expose myself to that? Especially when on the margin, the damage inflicted to my life by ads is usually comparable to, or greater than, the value provided by the piece of content nested between those ads. reply skydhash 2 hours agorootparentprevFree is free, and you can choose not to look at the ads. No wonder people are taking this option. In the process, it cheapens the whole thing. reply paulddraper 4 hours agorootparentprevThe overwhelming majority do not want to pay for online publications. They are willing to view ads (proving they value the material) but as a rule are unwilling to pay any cash. reply petercooper 3 hours agoparentprevAnd this is where branding and reputation comes into play. For all their problems, I trust numerous media brands to not give me slop: The New York Times, The Financial Times, Monocle, Matt Levine, Linus Tech Tips, The Verge, hundreds of YouTubers and Twitter users, even Hacker News. Let media companies and creators who want to set fire to their good names get on with it, because it'll hopefully mean anyone doing a good, consistent job will rise. reply anal_reactor 2 hours agorootparent> Linus Tech Tips Caught red-handed faking test results, the official response \"if we actually did the tests we wouldn't be able to publish videos fast enough\" reply petercooper 59 minutes agorootparentI did say \"for all their problems\" ;-) I still trust LTT more than a channel pumping out faceless review videos or one so unknown that there aren't enough viewers to even provide any scrutiny. To butcher the eponymous Linus's law: given enough eyeballs, all mistakes are shallow? reply CM30 3 hours agoparentprevAt least part of the issue is that much of this slop is 'good enough' for many people. As bad as many of those terrible recipe sites and video game walkthroughs and news articles might be, they're clearly good enough for the majority of the population, and enough so they don't see paying for content as worth the price. The other part is that practically speaking, there's enough good free content in most fields that paying doesn't get you anything better. It's not surfaced well enough by the algorithms, but it does exist, and it makes it so in most areas, there's very little reason to pay for anything. reply rini17 4 hours agoparentprevThe subscription usually comes in a package and people hate to pay for something they disagree with, even if it's just one author of several, or the occassional mistake. Might not be the main reason, just that these unsatisfied users are so vocal, idk. reply Workaccount2 4 hours agorootparentIn my experience with a voluntary donation only service targeted and used primarily by educated middle and upper class people, virtually no one pays if they don't have to. reply scotty79 1 hour agoparentprevThe problem is people wouldn't know what content to pay for because paid content in large part is also scam and bait and switch these days. You literally can't evaluate content before you consume it in it's entirety or the at least the amount you wish. Given that copyright should be abolished, adverts should be banned and content industry should move to entirely post-paid voluntary financing. Something like gaming piracy where you play the whole game for free and if you really liked it you \"buy\" \"a copy\" to support developers and their investors. reply barfbagginus 4 hours agoparentprevFalse. False. False. 1. People could forcibly seize and redistribute content already made in years 1980-2020. Even that would be better than slop. 2. People could read only those - like scientists or open source and public domain authors - either funded by the state or otherwise willing to publish their works for free at high quality without the monetization slop text. The content exists, but monetized slop hides it. 3. Actually good AI can compress multiple slop articles into useful, non-sloppy content. I'd be perfectly fine if the internet consists of just math textbooks and science papers, and actually good articles automatically distilled from slop. It has the potential to give us what we need. The problem is that slop hides all that! reply fullshark 4 hours agorootparentSo the other alternative is piracy and only consuming public domain information? reply barfbagginus 4 hours agorootparentThose are other alternatives, yes. That and mining the slop with automated tools. The problem with public domain stuff is that there is more than enough of it, but you cannot access public domain information because monetized slop has superseded it in the search results. I believe that automated AI engines will eventually help individuals find non-sloppy public domain articles, or assemble them from slop directly. But piracy is always a good option. reply Zambyte 4 hours agorootparentprevMaybe we should stop demonizing unauthorized sharing? People like to pretend nobody would make art in the absence of copyright, but it's easy to point them to millenia of contrary evidence. reply ALittleLight 3 hours agoparentprevIf OpenAI, or whoever, turns the AI crank once more and we go from GPT-4 to 5, and the jump is the same size as 3 to 4, then I think the answer will be pretty clear: AI content will improve in quality to meet or exceed human content. reply EForEndeavour 4 hours agoprevThe LLM/generative-AI genie is out of the lamp. I'm just some random midwit, but some predictions: - Slop will continue to become cheaper to generate, and people will only notice the obvious stuff - Hyperpersonalized content will abound, yet authenticity will run dry - The lack of authenticity in electronic channels will drive a small segment of people offline into less fakeable (for now) social contexts - Humans online will walk a treadmill of increasingly convoluted shibboleths / Gnirut tests (reverse Turing tests ;)) to self-identify as likely not AI-generated, i.e., subtly run-on sentences that are intelligible but slightly non-conformist to prevailing AI model outputs, and usage of old-school emoticons and other quirks - Humans will walk on similar \"Gnirut treadmills\" for visual art, speech, video, and music - AI models will gladly chase humans along these Gnirut treadmills, filling in canyons and sections of the Uncanny Valley with fractally sophisticated humanlike content reply 4star3star 3 hours agoparentFifteen years ago (I remember the apartment where I had this thought), it occurred to me that time was running out to write an authentic novel. Soon, computers would generate whole stories in an endless variety of styles, and even if future authors would hand write a book from start to finish, they would likely have been influenced by other artificial writing at some point. Readers would be unable to emotionally connect with authors due to the nagging awareness that the text might have been fully or partially generated by an unthinking, unfeeling machine. Though I try, I fail to think of a comparable scenario in our past, at least as relates to language. You can look around whatever room you are in and try to identify an object that was made by human hands rather than a factory process. That's a fact that always makes me a bit sad. I think we're headed in a similar direction with the language we consume. Craftsmanship falls by the wayside, and our world loses even more of the human touch that connects us with one another. reply axpvms 1 hour agorootparentInteresting thought. Looking around the room I'm in the only think I'm sure was definitely handmade is a musical instrument, because I know the guy who made it for me. And even then it uses parts which were machine made: strings, tuners, bridge etc. reply scrps 3 hours agoparentprev- The lack of authenticity in electronic channels will drive a small segment of people offline into less fakeable (for now) social contexts I think this segment might start small but I think it will grow rapidly if the utility of the internet is dwarfed with low quality crap. The belief that non-technical people won't catch on to the shenanigans and simply look elsewhere is a bad bet some are making and I think everyone living on the internet during covid gave non-technical people an intuitive feeling for all the manipulation and tenuous quality of the internet as a tool/public utility they can trust in any form. reply citizenpaul 36 minutes agorootparentHop on various markertplace apps like craiglist or facebook market and you will discover there already exists a decent chunk of invisible population that largely rejects the online world for all but basic communication means. reply pixl97 3 hours agoparentprevOnce we get to the point where models are or are nearly continuous learning and are getting data streamed from thousands of sources I feel it may be very hard to figure out if humans are leading the Gnirut or following. reply noman-land 3 hours agoparentprevI weirdly think the shibbolethization of human culture will be a good thing because it will encourage everyone to be creative, lest they be accused of being a bot and ignored. reply tromp 4 hours agoprevIt's AI generated spam. Why not simply call it AI spam, as already in use by e.g. [1][2][3]. [1] https://www.businessinsider.com/ai-spam-google-ruin-internet... [2] https://www.ghostery.com/blog/how-to-prepare-for-ai-spam [3] https://www.theregister.com/2024/04/13/google_ai_spam/ reply wy35 3 hours agoparentIt's definitely not the same. Spam is trying to sell you something, e.g. an unsolicited email peddling a supplements. Slop is low-quality content, e.g. someone taking a bunch of bird pictures off Google and posting it in a birding Facebook group. Spam is an ad, slop is not. With AI, it is now much easier to generate slop. reply ranger_danger 2 hours agorootparentPeople already use AI to generate ads though. It's only going to get worse. reply ketralnis 1 hour agoparentprevFeels like people calling bad scrolling and other jitter \"janky\" to just mean that it's a bit crap and people deciding that \"jank\" is a technical term. No buddy jank just means jank and slop just means slop. This isn't a \"new term\". reply sjsdaiuasgdia 1 hour agoparentprevI have similar feelings about \"smishing\", \"vishing\", and other medium-specific variants of \"phishing\". reply rdlw 3 hours agoparentprevSpam is content that is delivered to people who did not request it. Slop is content which pretends to be what you want, but turns out to be of low quality. reply quantified 3 hours agorootparentHuh. Whether or not a word has this meaning or that depends upon acceptance. You say it means X, someone else says it means Y, where X and Y can be arbitrarily dissimilar. And as much as you might be saying \"means this to me\", the way you are each phrasing it you mean \"for all\". How do either of you resolve this? reply rdlw 2 hours agorootparentWhat is there to resolve? The comment I responded to was saying there's no useful distinction between the two words, I pointed out a distinction that I see between the two in what I think is accepted usage. Of course I see my opinion as more correct, since if I found something more convincing I would change my opinion. As the word becomes more widely used, usage will settle down. reply quantified 2 hours agorootparentArgh, my apologies. The comment above yours in the sequence I see defines spam as unwanted marketing content, yours as unwanted content in general. For reasons unknown I saw that one as the parent of yours. reply cess11 3 hours agorootparentprevI don't see the difference. An email that pretends that I need to buy some pills and turns out to be a card collecting scam is obviously of low quality and not something I have requested. Computer generated fake texts are spam, doesn't matter if they're selling pills to me or my attention to ad networks. reply rdlw 2 hours agorootparentI see 'slop' used more often in contexts where, say, you look up a problem you're working on, find an article that seems to be relevant and may have the answer you want, but at some point turns out to be devoid of content and possibly AI-generated. reply cess11 2 hours agorootparentThat's spam. That's like the messages in your inbox of yesteryear that tried to entice you to look at them but they'll just waste your time or worse if you do. reply pmtcc 2 hours agorootparentprevSpam = unwanted and against what you asked for, trying to sell you something or get you to do something Slop = technically what you asked for, but intentionally created just to fill space and increase traffic/hits, generally of the lowest quality rendering it unusable reply cess11 2 hours agorootparentThen, to me, it's spam. The only times I've asked for fake text generated by a computer I stitched together some markov chain library and a corpus myself, and then it was to make the point that some people are so badly affected by ads and political propaganda that their contributions to the texts of humanity could easily be replaced by my code. reply simonw 18 minutes agorootparentSounds like you'd prefer to interpret slop as being a subset of spam. So all slop is spam but not all spam is slop. reply wy35 1 hour agorootparentprevOk, think about it like this. It's your anniversary with your partner so you decide to commission a drawing from an artist as a gift. However, when you receive it, it's clearly an AI-generated image that was printed out. Would you still consider that \"spam\"? reply pmtcc 2 hours agorootparentprevThe problem is that sometimes slop looks like content from a far enough distance. And to the untrained eye, it is indistinguishable from real content. For example, a Kafka tutorial could start with pages about other irrelevant technology before getting to the real material. But you wouldn't know which content is useless at first. reply duxup 4 hours agoparentprevIMO it's slightly different in terms of how it plays out so a new term seems reasonable. reply willvarfar 4 hours agoprevBeyond slop, there will be personalized slop where AI 'optimizes' articles for each reader. And beyond slop, there will be AI models that do product placement. OpenAI's \"publisher partnerships\" deck explains https://news.ycombinator.com/item?id=40310228 So soon you'll go to a news website and get the political filter bubble that reinforces - or outrages - your prejudices to maximize your engagement. And in the middle of it, the AI will slip in that the brand of grill that caused the fire was rumoured to be ${insert_name_of_competitor_here} etc? The big future for AI is to move slop beyond outrage and into intimacy territory. If rage was the engagement of the last ten years, then ending up only talking to AIs who pretend to care will be the even more addictive engagement of the next ten :( reply duxup 4 hours agoparentWhat happens if AI slop learns that I like accurate content and it suddenly gets good? reply willvarfar 3 hours agorootparentThe incentives are not aligned. They are not optimizing strictly for your preferences, they have agendas they are paid by advertisers to push. reply chromaton 4 hours agoprevSlop has been around a while. I was researching a topic, and noticed that most of the top search results had the same misunderstanding of some of the definitions. The writers were clearly not familiar with the topic, and I'm sure they were just copying each other. All of the articles pre-dated GPT-3.5. The kicker is that if you ask GPT-4 about it, it spits out the same incorrect information, meaning that GPT-4 was likely trained on this bad data. FWIW, GPT-4o gives a much more accurate response. reply soco 3 hours agoparentI wonder (as an outsider) why would GPT-4o give more accurate responses? The training data is the same, right... so maybe somebody can point this out like for a kid, thank you. reply tolerance 3 hours agoprevAll this talk and jargon is indicative of a mass existential crisis as humanity is faced with the reality that many of its shared cultural artifacts are essentially frivolous. reply SirMaster 27 minutes agoprevIf only we had an AI that could sift through all the slop and give us only the decent information that we wanted... reply iamleppert 1 hour agoprevAI will never come close to producing what people can, because an AI cannot be made to suffer. Suffering is essential to the creative process. Suffering is the key, it's the whole point, and at the core of the human experience. When we look at creative output, we are looking at the sum of the suffering experienced by the creator. The more suffering, the better the content. reply fluffet 4 hours agoprevLove the term. People should call it for what it is. Tried to find some answers on Google earlier in the day, and the first result pages were 100% generated slop. Funnily enough, any AI summary of the slop would be slop squared. It's everywhere, and I hate it. What ways do people have to combat it out of their day? reply kjkjadksj 2 hours agoparentIts infesting google image search too. I tried to find a picture of a guitarist playing a certain guitar. I got hits from “openart” where it looked like kurt cobain got crossed with a sand worm reply bazil376 4 hours agoprevThere’s going to be a lot of garbage content out there—but isn’t there already? People have been writing junk to try to get search engine placement for 20+ years. I’m not necessarily seeing the slop problem. People should always have been skeptical of content on untrusted websites. Now, if reputable sources start trying to pump out content with AI, that’d be a problem. I suspect for those who try, they’ll quickly lose their reputation. reply pavel_lishin 4 hours agoparent> There’s going to be a lot of garbage content out there—but isn’t there already? People have been writing junk to try to get search engine placement for 20+ years. Yes, but people's output is limited by their ability to type words on a keyboard. LLMs and other generative A.I. aren't bound by this limitation, and can put out significantly more. > People should always have been skeptical of content on untrusted websites. Now, if reputable sources start trying to pump out content with AI, that’d be a problem. How do you define untrusted websites, or reputable source? Especially when Google - which should be a trusted, reputable source - starts pumping out garbage as they did? reply bazil376 3 hours agorootparentOn the first point - I’m not sure there’s a difference to internet users between 1 billion junk articles on a topic and 1 trillion junk articles. On the second point - this is precisely what I’m talking about when I say if reputable sources start churning out junk, they will lose their reputation. This is a negative publicity event for google. If it keeps happening, people will no longer trust the information coming from google. reply haizan 2 hours agorootparent> On the first point - I’m not sure there’s a difference to internet users between 1 billion junk articles on a topic and 1 trillion junk articles. But there is a difference whether the ratio of good to bad articles is 1:10 or 1:10,000 one is tedious but managable, the other is hopeless. reply sangnoir 1 hour agoprevAll I need is a Cloud-to-Butt-like browser plugin that replaces all instances of \"GenAI\" and \"generative AI\" with \"AI slop\" reply callamdelaney 2 hours agoprevYou'll soon no longer be able to find anything of use via traditional search engines. How will we keep improving AI models when the amount of 'slop' in their training data starts to outnumber the real content? reply dorkwood 1 hour agoparentDo they need new training data? I'm pretty sure Midjourney, OpenAI etc. already scraped all of the images in existence long before the well was poisoned. They can use other methods, such as improved tagging, to improve their models. reply nateburke 2 hours agoprevhttps://www.amazon.com/Really-Like-Slop-Elephant-Piggie/dp/1... Irrelevant, but also fantastic. reply FezzikTheGiant 3 hours agoprevWould people be willing to pay for a gmail plugin that takes a stab at combatting ai email spam? something like Mailman [1] but with an LLM layer for detecting AI slop? [1]: https://mailmanhq.com/ reply Havoc 2 hours agoprevIt’s starting to get more noticeable week on week. Both on insta and google At this velocity it’ll make some categories pure noise by end of year reply Swizec 4 hours agoprevIs slop new or is it just a continuation of SEO, blogspam, and “content”? I love that we have a new better word that captures the nuance, but it doesn’t feel like a new phenomena. reply thih9 4 hours agoparentI'd guess both: a continuation and its own new flavor. It's better than what automated scripts could produce and cheaper than human generated copy. It has expertise of the whole Internet and its reasoning capabilities are often worse than those of a three year old. Similar for sure, and yet something different. reply cj 4 hours agoparentprevOur company is working with a SEO firm we pay $11k/mo for (who I want to fire). They sent us new copy for our core marketing pages last week, and many sections simply sound non-sensical. As in it just didn't make cohesive sense, and it was clear a human being didn't write (or even review) the content. This is the problem with new AI \"slop\". In the past, blogspam / SEO spam was at least reviewed and written by a human. Now, we have content getting published straight out of the mouth of text generators. The quality of long-form content from text generators is significantly worse than even mediocre $10/hr copywriters in many cases. reply whyage 4 hours agoparentprevUnlike slop, SEO content can't be totally off-base, or search engines will rank it low. The ecosystem keeps it annoying but consistent with the facts, at least. reply whstl 4 hours agoparentprevI'd argue that the strange Gemini answers that were making the rounds of social media are more absurd than what you would see in regular blogspam. But again, they're extremes (and some of the reported screenshots were even fake). On the other hand, there's indeed a lot of popular human-made fake content lately, especially in TikTok, like fake guitar playing and fake nonsensical DIY videos. So it's not an AI exclusive phenomena. reply troyvit 3 hours agorootparentNow I want to go ask one of my AIs to produce some clearly fake content so that I can get boosted on social media for complaining about awful AI. reply pmdr 2 hours agoprevWe've been feeding it slop for years, if anything it's become better at writing it than us humans. reply yadaeno 2 hours agoprevSlop is more of a term to describe extreme cost savings pushed onto consumers and marketed as “progress”. reply eugenekolo 2 hours agoprevSchlopp. Beautiful schlopp. Beautiful schlopp with a cherry on top. reply coldblues 2 hours agoprevI think it's pretty obvious that the term \"slop\" has food origins. When you think of \"slop\", you think of oily, greasy fast food, or disgusting amounts of sugar, syrup, icing, etc. The food allegory strikes again. When someone says something is \"slop\", they obviously mean mass-produced content that regular people willingly consume at their detriment, because it appeals to our most primitive desires. Something lacking of substance, non-challenging material, \"Roller coaster\" content. https://www.youtube.com/watch?v=wyoNGSKWIaw reply tuckerpo 23 minutes agoparentLike most sticky internet slang terms, \"slop\" stems from 4chan's \"sloppa\", initially used to describe gross looking food, i.e. \"slop of shit\" shortened to \"sloppa\" Now used to describe anything that looks half-assed, poorly put together, etc. reply neogodless 2 hours agoparentprevThat's not what I think of. I think of the buckets of scraps you would feed a pig. The stuff the humans don't want to eat and would just as well put in the garbage bin. reply coldblues 2 hours agorootparentReasonable individuals would think of the food I've described as pig feed, if not worse, of course with some hyperbole added. The reality is that most people are not knowledgeable enough to even tell \"AI slop\" apart from regular slop, or even human-made content. In that regard, people are eating pig feed, scraps no reasonable people would want to touch. Best example is AI generated Facebook posts with comments and likes from elderly folk or the the lower end of the bell curve. reply spacecadet 1 hour agoprevIt was slop before reply novaRom 3 hours agoprevInterestingly, this article itself is an example of \"slop\" reply simonw 17 minutes agoparentWhy? reply justinclift 4 hours agoprevEven Kagi has this crap too. :( reply m3kw9 2 hours agoprevGoogle leading again on the minus side reply ai4ever 4 hours agoprevsee slop ? say something ! there will be a backlash against robotic phone assistants in support centers. support businesses that dont put out slop or ai-garbage. reply telepathy 4 hours agoprevSLOP: Judith Miller at the NY Times circa 2003 reply hm-nah 2 hours agoprevNice work Simon! reply ChrisArchitect 3 hours agoprevSee also: \"botshit\" https://www.sciencedirect.com/science/article/pii/S000768132... reply GaggiX 4 hours agoprev\"Slop\" is a general term, you can create slop as a human, for example YouTubers who upload daily talking about the latest Twitter drama they are usually referred to as making slop, especially if they have a main channel where they upload high quality content. It's not a new term and it has little to do with AI by itself. reply pavel_lishin 4 hours agoparentI think an important difference between Youtubers putting out low-quality videos is that it still takes them at least as much time to generate the video as the video's run-time - same with pointless self-promo blogposts, unhinged LinkedIn posts, etc. With generative A.I., this kind of slop can be pumped out at an industrial scale. It'd be like equating your neighbor dumping a bag of garbage on the roadside, with the industrial plant down the road pouring out thousands of gallons of toxic waste per minute into a river. reply ChrisMarshallNY 4 hours agorootparent> at least as much time to generate the video as the video's run-time That's for the very lowest-tier video. The usual formula, is that for every minute of runtime, you have at least 30 minutes of editing. With professionally-produced video, I think it's triple or quadruple that. reply GaggiX 4 hours agorootparentprevI'm talking about how the term is used because the author doesn't seem to be too familiar with Internet slang and believes that the term is new and strictly related to AI. reply veesahni 4 hours agoprevtldr: \"slop\" is defined as unwanted AI content reply taco_emoji 3 hours agoprev [–] wish i could read the fucking paywalled article reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The term \"slop\" has emerged to describe low-quality, unwanted A.I.-generated content across various online platforms, including social media, art, books, and search results.",
      "The term gained traction after Google integrated its Gemini A.I. model into U.S. search results, leading to initial user dissatisfaction and missteps.",
      "Experts warn that such content discourages critical thinking by presenting information as definitive answers, and advocates believe having terms like \"slop\" is essential for societal discourse on modern A.I. usage."
    ],
    "commentSummary": [
      "The term \"slop\" refers to low-quality, often AI-generated content, reflecting concerns about AI's impact on content quality and societal well-being.",
      "Critics argue that AI exacerbates the issue by enabling mass production of low-quality content, driven by economic incentives and advertising profits.",
      "The discussion highlights the challenge of distinguishing between low-effort human content and AI-generated material, with concerns about the future of content creation and the potential for AI to manage both creation and summarization."
    ],
    "points": 191,
    "commentCount": 193,
    "retryCount": 0,
    "time": 1718112730
  },
  {
    "id": 40638386,
    "title": "Corporate Influence Raises Concerns at Entomological Society Conference",
    "originLink": "https://usrtk.org/bees-neonics/entomological-society-america-corporate-partners/",
    "originBody": "Anatomy of a science meeting: How controversial pesticide research all but vanished from a major conference Print Email Share Tweet LinkedIn WhatsApp Reddit Telegram Posted: June 10, 2024 by Rebecca Raney Illustration by Mark Fiore If you scroll through the social media posts for the 2023 meeting of the Entomological Society of America, one face jumps out: The Corteva guy. It’s the face that greeted the 3,000 attendees of the meeting every time they opened the conference app: A smiling, balding man in early middle age, presumably an entomologist, wearing a plaid shirt. This face of Corteva Agriscience, one of several agrochemical companies that has paid hundreds of thousands of dollars to the organization over several years, was so omnipresent that the insect scientists posted memes about it. At the end of the meeting, the entomologists even joked about how much they would miss him. Abigail M. Hayes, a postdoctoral researcher, posted: “Shout out to the #Entsoc23 app for letting me hang out with Corteva guy until the very end – I wonder if I leave the app installed and don’t update, will he stay until next year?” For $65,000, the pervasive “Corteva guy” ad – a slot that was exclusively held by Corteva in 2023 – is just one of the dozens of benefits in packages that corporations can purchase this year through a partnership program from the Entomological Society of America, whose conference is considered the Super Bowl of meetings in the field. The society, with nearly 7,000 members, is the largest organization dedicated to entomology in the world. It publishes eight scientific journals and offers prestigious awards and fellowship designations for distinguished scientists. Its meetings lend prestige to scientists who are invited to speak. From 2017 to 2023, the ESA’s corporate partnership program brought in an estimated $1 million, based upon publicly available records. At its meeting in 2023, scientists encountered the pervasive face of Corteva while presenting research on weighty topics that included the health of bee colonies, the impact of climate change on vector-borne diseases, food insecurity, the unintended effects of pesticides, and exotic topics such as utilizing insects for food and feed in impoverished societies. However, during hundreds of sessions on these subjects, a significant topic went missing: scholarly research on one of Corteva’s products – neonicotinoids, a factor in one of the most controversial, high-profile areas of research in entomology. That research concerns whether the neonicotinoids that coat corn and soybean seeds – the most widely used insecticides in human history – contribute to the decline of bee colonies. Extensive research during the last two decades has shown that exposure to this type of insecticide, which was introduced during the 1990s, harms bees’ foraging, survival and immune responses, as well as damages their ability to reproduce and survive the winters. Neonicotinoids have been banned for outdoor uses in the European Union and Québec. Manufacturers report that if used properly, the products are safe for bees and other pollinators. While the scientists who were interviewed for this story said that they felt no influence from corporate interests in the selection of papers that were presented at the ESA meeting, they were surprised to hear that neonicotinoid research barely made a showing. “I’ve never had a problem getting a neonic paper in a symposium,” said Vera Krischik, a tenure-track associate professor at the University of Minnesota who has conducted extensive research into the effects of neonicotinoids on pollinators. “I’m not going to deny that there is an uninterest, or a bias, to not talk about pesticides and bees,” she said. “I don’t think it’s at the level of the ESA.” According to the results of a session-by-session review of the conference’s presentations conducted by U.S. Right to Know, the few papers and posters that were dedicated to the effects of neonicotinoids on bees were presented by students, not by scholars. Only four papers and posters that examined the topic made it into the conference, out of nearly 100 papers, posters and symposia on bee science. In some instances, according to attendees, scholars engaged in general discussions of neonicotinoids and pollinators on panels that were not dedicated to the presentation of specific papers. Top findings of U.S. Right to Know’s review of the papers, posters, symposia and workshops at the ESA meeting: Out of nearly 100 papers and posters presented on bee science in 2023, four specifically related to the role of neonicotinoids in the declining health of bees. All four were presented by students. By comparison, in 2013, scholars presented at least 19 papers on the effects of neonicotinoids on bees at the ESA meeting. In 2023, 26 percent of the symposia, workshops and science policy sessions were organized by employees from the corporate sector; in most cases, those organizers were employed by agrochemical companies. Also in 2023, 16 percent of panelists in symposia, workshops and science policy discussions were employed by corporations. Chris Stelzig, the executive director of the ESA, did not dispute these findings, but in a written response to questions from U.S. Right to Know, he pointed out that in a search on the term “neonic” in the conference app, the results show 30 abstracts. Those results included the student work on the effects of neonicotinoids on bees, as well as research conducted outside bee science, into areas such as resistance to the insecticides among bed bugs and the Colorado potato beetle, effects of pesticides on burying beetles, and effects of pesticides on restoration prairie plants. Stelzig’s response noted that the ESA “doesn’t prescribe specific topics for coverage in its conference program, nor do we track the trends in conference presentation subjects in detail. “For any given subject within entomology, what is covered in ESA conference programs reflects the ebb and flow of interest in it among the community and the focus of research being conducted in the field.” Several entomologists who organized panels in bee science for the conference said that they were surprised to hear that research about the effects of neonicotinoids on bees had all but vanished from the program. While many of these scientists said that they believe neonicotinoids should be banned to protect bees, they also said that the field has shifted to an approach that accounts for multiple stressors on individual bees and hives, rather than studies of individual factors, and that the research presented at the conference reflects that way of thinking. That approach to research tracks with the point of view of agrochemical companies, which have posited, for years, that the collapse of bee colonies has occurred as a result of multiple factors – not just neonicotinoids – despite the extensive body of research that shows the harm caused by the products in isolation. Bayer has even produced a children’s book called Toby and the Bees, in which the perils of mites figure prominently, without a word about neonicotinoids. Here is an excerpt from a fact sheet on bee health and neonicotinoids by Bayer: Source: Bayer Two hundred thousand square feet dedicated to science The ESA meeting in 2023 brought in more than 3,000 attendees and offered more than 2,000 presentations. It was held at the Gaylord National Resort & Conference Center in National Harbor, Maryland. The society used 130,000 square feet of meeting space and an additional 100,000 square feet for the exhibit and poster hall – an area that covered an area greater than two city blocks in Manhattan. Source: Marriott.com According to the entomological society’s annual report, the group took in more than $1.7 million in revenue for its meetings in 2023. It spent more than $1.6 million on its meetings, leaving the group about $100,000 in the black in that category. In 2022, the society reported that it lost $160,000 in meetings. The top corporate sponsors for the ESA last year were Corteva Agriscience, which was spun from DowDuPont in 2019; Bayer, a leading seller of neonicotinoids that purchased the Monsanto Co. in 2018; and Syngenta, a Chinese state-owned company based in Switzerland that was acquired by the China National Chemical Corp, also known as ChemChina. Like Corteva and Bayer, the Syngenta Group sells seeds, seed treatments, herbicides and fungicides. Other large corporate sponsors are BASF, based in Ludwigshafen, Germany, which manufactures herbicides, and the Racine, Wisc.-based SCJohnson, which sells pest control products. According to the ESA, the partnership program accounts for the vast majority of donations to the society, but Corteva and Bayer still pay additional fees to sponsor special events at the conference. Employees of Corteva hold two seats on the ESA’s 18-member governing board. Melissa Willrich Siebert is the incoming vice president for the society and sits on its eight-member executive board. The early career representative on the governing board, Scott O’Neal, also works for Corteva. Here is the breakdown of top corporate sponsors and how much they gave the society from 2017 to 2023. Source: Publicly available documents; totals confirmed by ESA. The ESA confirmed that its total income from the program, over seven years, came to more than $1 million. The reach of the corporate partners runs deep into the society. According to ESA spokesmen, two Corteva employees serve as editors on three of the organization’s eight scientific journals: the Annals of the Entomological Society of America and American Entomologist. (One serves as an editor on American Entomologist as well as the Journal of Integrated Pest Management.) Bayer employees serve as editors for the Journal of Economic Entomology, Environmental Entomology and the Journal of Integrated Pest Management. The editor in chief of the Journal of Integrated Pest Management started the job while employed in academia and continued in the role after going to work for FMC Corp. FMC, based in Philadelphia, is a leading manufacturer of neonicotinoid products, as well as insecticides, herbicides and fungicides. To date, FMC has not participated in the ESA’s partnership program, according to the ESA. The society’s publications draw on the expertise of about 350 editors, in total. According to the ESA’s partnership pricing list, options for companies that pay at the platinum tier include: Sponsorship of mini golf in the exhibit halls at the meeting, with branded golf balls A “Pet a Puppy” event, complete with signage and branded bandanas Banner ads in each of ESA’s newsletters Ads in the society’s scientific journals Email from the company to ESA’s members, sent by ESA Speaking opportunities at the annual meeting’s opening session Unlimited job postings on the ESA career site “They’re bringing puppies,” said Nick Chartres, a senior research fellow at the University of Sydney who has written about corporate influence in public health fields. “This stuff is wild.” Source: Entomological Society of America website According to Stelzig’s statement from the ESA, the revenue from the corporate partner program accounts for approximately 3 to 3.5 percent of the society’s total annual revenue. Based on total revenue for 2023, the society took in between $200,000 and $235,000 through the corporate partnership program that year. That funding, Stelzig added, supports a variety of programs – not just the meetings. “Throughout ESA membership, programs, and publications,” the statement said, “we seek a diversity of scientific expertise, professional backgrounds, and personal perspectives. That diversity ensures a healthy and productive mix of ideas to advance ESA’s mission and strengthen entomology as a scientific field and profession.” The partnership approach, which the society adopted in 2017, mostly replaced the traditional sponsorship model, in which companies paid for specific receptions and events at meetings. “This reduced the number of elements of the meeting that were linked to individual sponsors and instead allowed us to recognize groups of partners collectively,” Stelzig’s statement said. It also said that “ESA’s Corporate Partner program offers companies with an interest in entomology the opportunity to support the entomological community and engage with fellow researchers around their shared interest in advancing insect science. It is a year-round partnership that is not tied into any one specific ESA program, though benefits may include opportunities for visibility and attendee engagement at the Annual Meeting.” Tess Legg, a research associate in the Tobacco Control Research Group at the University of Bath who has developed a “Science for Profit” model to explain how and why corporations influence science, explained that, in various fields, “one key part of this influence has been to push out their preferred scientific messages by infiltrating professional organizations, including through funding and through speaking at their scientific and educational events, and publishing in their academic journals.” Source: Entomlogical Society of America 2023 annual report To Chartres, the research fellow in Sydney, the concern with the partnership program lies with the prominence of members from industry in key roles throughout the operations of the society. “Industry is afforded key positions/roles of influence throughout the society, which allows them to shape the society’s scientific priorities, agenda, and public statements,” Chartres wrote in an email. “Unless you dig, you do not realize there is this level of influence throughout the society.” According to a statement from Bayer, company officials do not see their employees’ involvement in the partnership program as the exercising of influence. Bayer’s prepared statement said, “As a global company, we invest and are a part of many science-based organizations around the world. “The Entomological Society of America is the largest entomological society in the world. Protecting plants from harmful insects is an important part of what we do at Bayer, so it’s natural for us to be a part of the society and partake in the meeting. Many Bayer employees are active members of this organization, working to advance entomological research for the betterment of our world, and our farmer customers. Bayer employees actively serve on ESA committees, and submit papers for publishing in the ESA journals – our sponsorship of the convention has no bearing on those actions. “Our investment in the ESA meeting allows us to invite a number of employees to the conference and have a booth which facilitates networking, and the ability to share our science. The meeting is a mix of both public and private sector scientists, presenting additional opportunity for collaboration.” Company representatives for Corteva, Syngenta and BASF acknowledged having received questions from U.S. Right to Know about their companies’ involvement in the ESA, but declined to respond. SCJohnson provided an auto-response that acknowledged an inquiry sent through the company’s media web page, but no one from the company responded to the inquiry. To Chartres, who considered the corporate presence at the meeting, as well as the board members from companies and the journal editors employed by corporations, it appeared that “the entire society is captured by industry.” “If you are the ‘largest organization in the world serving the professional and scientific needs of entomologists and individuals in related disciplines,’ ” Chartres wrote in an email, “you would expect that people in positions of authority, like the governing board and editor-in-chief of a journal on pest management to be free of conflicts of interest. “You can essentially buy credibility and endorsement in this society if you have the money.” For the ESA, corporations are part of the entomological community as major funders of research and employers of entomologists. “Throughout ESA membership, programs, and publications, we seek a diversity of scientific expertise, professional backgrounds, and personal perspectives,” Stelzig’s statement said. “That diversity ensures a healthy and productive mix of ideas to advance ESA’s mission and strengthen entomology as a scientific field and profession.” On the topic of pesticides, debate can turn into intimidation In a half-dozen interviews with presenters and organizers at the ESA conference – interviews that covered one-third of the organizers of bee science panels – most of the scientists said that they perceived that this meeting was dominated by corporations, much more than smaller conferences put on by universities and groups oriented toward bee health. (Seven of the organizers of bee science panels worked for the U.S. Department of Agriculture, whose communications department forbade its scientists from speaking with U.S. Right to Know for this story.) Not every presenter has had an easy time when talking about pesticides at the ESA meeting. Emily May, a pollinator conservation biologist who studies pesticides for the Xerces Society, a Portland, Ore.-based nonprofit group, recounted facing intimidation by agrochemical industry attendees after her talk. She spoke at the meeting about how government regulators focus on the effects of individual pesticides on pollinators without factoring in the cumulative effects of a range of chemicals. After she spoke, she said, five people from the audience stepped up and fired off highly technical questions, such as whether she had completed indexes of cumulative effects. “Questions came in with ‘Have you done indexes about toxicity?’ . . . They were just getting very technical in their specific pushback on approaches to looking at cumulative toxicity,” May said. “It was like my worst-case scenario, really. It made me nervous about the next conference I presented at, to be honest. It’s hard. People wanted to make me look bad.” The source of that onslaught of technical questions: Employees of agrochemical companies, May said. Stelzig’s statement noted that the ESA maintains a code of conduct that prohibits harassment at its events. “As in any scientific field—and given the diversity of expertise and perspectives across entomology—healthy, constructive debate is a natural aspect of the exchange of ideas, and it is an important part of the scientific process,” his statement said. “At ESA conferences, our code of conduct fosters civil discourse and prohibits behavior that is threatening or harassing.” May said that she had expected to face an audience that drew from industry because her talk involved pesticide regulation. “I knew that it was likely to have an industry audience, that it was likely to have pushback,” she said. “So I didn’t exactly go in unprepared. I knew that what I was saying was not palatable to some parts of the audience.” Even so, it’s not an experience that she is eager to repeat. “I really don’t enjoy being in that scenario personally. I will have to work my nerve back up again, to do it again,” May said. She also said that it was easier to get papers on any topic into the conference when she was a graduate student. She was not surprised to hear that neonicotinoid research was exclusively presented by students at the 2023 conference. “On the grad student side of things, there’s a whole different mix of types of research being presented,” May said. “I don’t think there’s any direction on that side of things. I remember, when I was in grad school, I could submit a talk on anything and participate in the grad student sessions. . . . It’s a very diverse set of topics.” Scientists who organize panels and present papers differ over whether research is marginalized when it is presented by students rather than full scholars. “It should be that way,” Krischik said. “You get a grant, you put a student under grant, and they have to present papers, because they need a job. . . . So absolutely, it should be the students doing the papers.” On the other hand, some researchers view scholarly presentations as carrying more weight. “In general, what I find is that students, unless they’re at the end of their Ph.D., do not have a full, complete story,” said James Nieh, professor of biology in the department of ecology, behavior and evolution at the University of California at San Diego. “They may have less weight in giving the presentation than somebody, for example, who’s a junior professor or a postdoc, who has a full story to dedicate a talk about.” The ‘largest organization dedicated to entomology in the world’ The Entomological Society of America is based in Annapolis, Md. Aside from its thousands of members, scientific journals and fellowships for distinguished scientists, the society offers certification study courses, leadership training and robust job listings for entomologists who are starting their careers. If anything, the robust recruitment environment at its meetings has attracted criticism as a “pipeline to industry.” Symposia at the ESA conference in 2023 included sessions called “Learn More About Industry Careers, It’s Not the Dark Side!” as well as “How I joined the pest control family” and “We’re Not the Ferengi Either.” It’s hard to overstate the organization’s prominence in the field. According to its 2023 annual report, the nonprofit organization holds more than $5 million in investment reserves. Its total revenue in 2023 was $6.4 million, including the $1.7 million that came from attendees of meetings as well as organizations such as exhibitors. Source: Entomological Society of America 2023 annual report In the science world, the ESA’s meetings are as influential as its standing in the field; researchers present critical findings on hundreds of topics. Many papers relate to phenomena that threaten insect species as well as the nation’s food supply. A glance at the group’s conference program conveys the magnitude of the research presented through the society. Here are a few of the sessions from the program in 2023: “The Impact of Climate Change on Vector-Borne Diseases: Navigating the Social and Political Landscape” “Unbiased Introduction: Is it more important to prioritize honey bee or native pollinator health for long-term food security within North America? “Role of Pesticides in Addressing Food Insecurity” “Food for Thought: Influences of Global Policy and Implementation on Insects as Food and Feed.” ‘ESA can be very competitive’ Seven hundred miles from Maryland, at the Hyatt Regency in Jacksonville, Fla., the American Bee Research Conference held a meeting in 2023. At that conference, 10 percent of the papers that were presented dealt specifically with the effects of neonicotinoids on bees, including one paper presented by a student. The meeting, which is dedicated exclusively to bee science, is much smaller than ESA. In some cases, scientists present the same papers at both conferences. “We try to accommodate everyone,” said Priyadarshini Chakrabarti Basu, the secretary and treasurer of the American Association of Professional Apiculturists, which organizes the bee research conference. Funds from the nonprofit bee resource groups that sponsored the events cover less than 10 percent of the cost of the meetings and typically consist of a few hundred dollars for food at the poster sessions. Chakrabarti Basu has also organized panels at the ESA conference. “ESA symposium selection can be very competitive,” she said. Chakrabarti Basu, who is also is also an assistant professor of pollinator health and apiculture at Mississippi State University, described the system like this: The entomological society develops themes. Then, based on those themes, organizers of symposia and workshops come up with ideas for panels. They submit applications, and, if selected, invite scientists to speak at a symposium or panel. Specific topics and papers can be selected on several criteria: Whether they track with the theme; whether they satisfy diversity interests, which can include the diversity of both the scientists and their career stages; and whether the topic is relevant to the changing world. Chakrabarti Basu has never felt that corporate sponsors influenced her work for ESA. “A lot of these decisions are made higher up,” she said. “I’ve organized a number of symposia. I’ve organized a number of workshops. Sponsorship had no effect on what I organized.” She and other scientists noted that the current state of the research into bee colony collapse examines multiple stressors. As a result, bee science is becoming more interdisciplinary than ever. “If you look at a bee in the landscape,” she said, “that bee is not only facing stress from climate change. It is also facing a mite or a disease stress. Or pesticides. Or poor nutrition. So it is actually a lot of different things that are happening at the same time.” Several scientists said that 10 years ago, the field had less of an interdisciplinary focus, and research on single stressors, such as neonicotinoids, carried more weight. At ESA’s meeting in 2013, scientists presented at least 19 papers, posters and symposia focused on the effects of neonicotinoids on bees, according to multiple keyword searches of the sessions at that meeting. S. Hollis Woodard, an associate professor of entomology at the University of California at Riverside, said that as an editor of the journal Current Opinion in Insect Science, a paper on neonicotinoids needs to say something new to get in. For many researchers, the fundamental idea that pesticides are harming bees is settled science, she said. “I think it’s not as much of a focus,” Woodard said. “To me, now, when I have someone that wants to work on a neonic study, I always say, ‘There has to be something unique and interesting.’ It can’t just be, ‘What if they disrupt something,’ because they definitely do. They disrupt so many different processes in bees. “For a lot of us bee scientists,” she said, “we already have a verdict. They’re doing harm, and if we care about conserving bee populations, we should do what’s been done in the UK and other countries where they stopped using them.” The topics at the 2023 ESA meeting reflect that focus on multiple stressors contributing to the decline of bee colonies. In nearly 100 papers, posters and symposia on bee science presented by scholars, the top topics were: Bees’ thermal tolerance in a warming world, with more than 20 panels and papers on the subject Habitats that improve pollinators’ survival, with 19 panels and papers Bee genetics, with 14 papers, posters and symposia. Other general areas of research included foraging; social behavior; the effects of varroa mites, which harm bees’ development; and effective beekeeping practices. Globally, neonic research and citation rates are increasing While some researchers and symposium organizers at the ESA may be experiencing research fatigue with neonicotinoid studies, a recent review of the global scientific literature, published in the journal Environmental Research in 2022, showed that “the increase in publications over time is significant and shows a dynamic citation pattern. It indicates a comparatively high interest in current research, with ecological issues becoming more and more the focus of international research.” The survey, conducted by researchers at Goethe University in Frankfurt, drew on the collection of literature in the database Web of Science, and deployed multiple search terms for neonicotinoids. It showed robust funding for research into the effects of neonicotinoids, particularly in the United States and China, and that “the publication output on neonicotinoids has increased relatively more than in biomedical science as a whole, and also that this increase shows a steady trend with higher rates in recent years.” The researchers also counted the number of grants for research, as identified in the literature, and found that globally, funding for neonicotinoid research has steadily increased since the products were introduced during the 1990s. Top global funders of neonicotinoid research: The Chinese government at No. 1, followed by the U.S. Department of Agriculture and Bayer, according to the review. Amid a serious downturn, Bayer strives to control the message One group has a vested interest in keeping negative narratives about the widely used pesticides out of the public eye: The agrochemical industry. Of the big players in the sector, executives and employees for Bayer Crop Science – the division of the health conglomerate once known as Monsanto – have repeatedly pushed back on the idea that neonicotinoids harm bees. In company information on bee safety and neonicotinoids, the company wrote that “the existing, extensive data consistently suggests that neonicotinoids, if used responsibly and in accordance with usage recommendations, do not represent an unacceptable risk to honey bees and other pollinators.” According to Global Market Insights, a global market research and management consulting firm, the neonicotinoid pesticide market was worth an estimated $5 billion in 2023. The firm reported that environmental concerns over pollinator health remains one of the top concerns for the business outlook of the product. By any account, the Bayer Crop Science business division is in serious trouble, with significant declines in revenue that pulled down stock valuations for the entire company, according to the company’s annual and quarterly reports. Source: Bayer 2023 annual report In comments for the company’s 2023 annual report, executives reported that the company’s performance is suffering because of significant losses in legal judgments. Bayer’s provision for the glyphosate litigation totaled $6.3 billion, as of Dec. 31, 2023, from lawsuits over Roundup, an herbicide that has been the target of more than 11,000 lawsuits because of links to cancer. The Bayer annual report also mentioned the risk of damages from a class action suit by beekeepers in Canada who claim neonicotinoids caused losses of bee colonies and impaired the health of their bees. The plaintiffs allege Bayer and Syngenta were negligent in the design, development, marketing and sales of neonicotinoids and seek both compensatory and punitive damages. Potential damages in the suit, which is moving through the court system in Canada, could reach $400 million, according to a report by the Canadian Broadcasting Corp. According to the company’s annual report, “Bayer believes it has meritorious defenses and intends to defend itself vigorously” in the suit brought by beekeepers in Canada. Linda J. Visser, a partner in Siskinds LLP, a law firm that is representing beekeepers in Ontario in the case, said that the class covers at least 500 beekeepers in Québec and 15,000 beekeepers in Ontario. The suit, if not settled, could go to trial in two to three years. “There’s a lot of research out there – thousands of studies – supporting the link between neonics and harms to bees,” Visser said. “Neonics were introduced in Canada around 2006,” she said. “And shortly thereafter is when honeybee keepers started experiencing larger than normal bee die-offs. And we saw that in other jurisdictions as well. France is probably an early good example, where, once neonics got introduced in the 1990s, and shortly thereafter, they experienced large-scale bee die-offs.” When Bayer officials discuss the claims against the company and research that’s critical of any of its products, they use words like misrepresentation and “anti-neonic attack” to describe those claims. For example, in his message in the 2023 annual report for Bayer, CEO Bill Anderson reported that the company will continue to advance its message about the safety of glyphosate: “The scientific and regulatory facts are on our side, as was demonstrated again last year, when the safety of glyphosate was confirmed by its reapproval in the European Union. We will make every effort to ensure that the plaintiff attorneys are not allowed to misrepresent these facts in court. After all, we want to invest our resources in innovation, not in the US litigation industry.” Creating carefully crafted messaging around the company’s products has been common practice for years. According to documents acquired by U.S. Right to Know under the Virginia Freedom of Information Act, in March 2013, David Fischer, a Bayer toxicologist who is now retired, was dismissive toward research that countered Bayer’s narrative about the safety of neonicotinoids. “I was assuming I’d write up my abstract this weekend,” Fischer wrote to a Virginia Tech scientist who was organizing a panel for the American Chemical Society, “but had to spend it instead preparing a rebuttal to the latest anti-neonic NGO attack paper – this one coming from the American Bird Conservancy.” The Virginia FOIA documents also showed that Bayer executives aggressively worked to place their employees on conference panels that related to neonicotinoids and bee health for various organizations. In an email in 2013, Fischer asked Mary Purcell, who is currently a national program leader at the U.S. Department of Agriculture National Institute of Food and Agriculture, to slot in a new employee, along with himself and two others from the company. The “varroa summit,” held by the USDA in early 2014, addressed issues with Varroa mites, a pest that causes deformities in developing bees – and a major focus of agrochemical company research in bee science. Since then, Cabrera has served in conference slots at the meetings of different organizations. Since she started the job with Bayer a decade ago, Cabrera has become a visible organizer and speaker at the ESA conference. In 2023, she was a presenting author at a section symposium called “Beyond the requirements: A multi-disciplinary approach to advancing pesticide risk assessment for pollinators,” a moderator at a graduate competition on pollinator biology, and an organizer of the Latin/Hispanic Symposium who introduced and gave introductory remarks. The ESA’s ‘pipeline’ to industry To Emily May, the conservation biologist at the nonprofit Xerces Society, the ESA meeting, more than anything, serves as a pipeline for students to go to work for corporations. “I went into entomology because I wanted to conserve insects – and specifically bees,” she said. Her impression of the school-to-industry pipeline is not misplaced. The conference offers a rich variety of ways for emerging entomologists to learn about career tracks and training for internships, with 14 separate workshops and symposia targeted at early career attendees at the 2023 conference. Corteva sponsored a “Women and Allies Entomology Breakfast.” The Latin/Hispanic Symposium was organized by a scientist employed by Bayer Crop Science. Bayer also sponsored an invitation-only student mixer. David Inouye, emeritus professor at the University of Maryland, typically presents his research at smaller conferences that focus on his specific area, which involves the interaction between plants and animals. He has not presented at ESA in decades, but he said that the conferences of big, corporate-backed organizations look substantially different from the conferences run by smaller groups. “One of the most conspicuous differences is the hospitality suites,” Inouye said. “If it’s got a corporate sponsor, they’ll have a hospitality suite and host a reception one afternoon or evening, and provide free drinks and food for people, and that’s something that’s often out of the budgets of nonprofits.” The big conferences also differ because of their corporate recruiting environment, he said. At ESA, he said, “they’re trying to attract people who may, at some point, want to work for their companies and do testing for the mortality of insects, testing for the effects on the plants that they’re trying to protect. “I guess that’s a given, that their economic interest is selling their chemical products, and your research is going to be focused on one aspect or another of those chemical products.” In one session at the ESA conference in 2023, which was organized by a scientist from Corteva, early career attendees could review CVs and resumes from professors, government researchers and corporate scientists. It was one of several resume-building sessions. “There’s a real direct pipeline from entomology departments into Syngenta, Bayer, Corteva,” May said. “This conference is one of those networking opportunities where industry meets students, students meet industry, and then there’s kind of that pipeline towards, ‘Well, if you don’t want to pursue a professorship, or even if you do, come work with us.’ ” The ESA provided this breakdown of its membership composition: Krischik, the entomologist from the University of Minnesota, said that the large footprint of the agrochemical companies does not trouble her, because insecticides are an essential part of maintaining the food supply, and the money keeps rigorous science in the public eye. She is quick to add that in her opinion, as a researcher of neonicotinoids, the products should be banned. But she does not find the presence of the companies at the meetings overbearing. “I don’t think the scientific meetings are run by them or overrun by them,” she said. “You donate money, you get a perk. . . . It doesn’t mean anything. It doesn’t. Without pesticides, you’re not going to eat anything. Without pesticides, you can’t live,” Krischik said. In 2024, the return of the ‘Corteva guy’ For several months after the 2023 conference, the app for the ESA meetings opened and closed without fanfare. It contained vast data from meetings going back to 2019. The presenters were all listed, and the panels and symposia quickly popped up in searches. But the image that left the biggest impression – the Corteva ad — was gone. Then, before Memorial Day, for just a few days, the whole experience on the app changed. For a $65,000 fee, Corteva Agriscience had renewed its annual partnership with ESA at the new platinum tier, and the face of the agrochemical company returned to the app briefly as the developers prepared for the 2024 meeting. He was back: The Corteva guy, relaxed, wearing plaid, and squinting his way into the next ballroom. ____________________________________________ Tagged Primary Article PFAS ‘forever chemicals’ tied to cancer, birth defects Fauci’s institute hid mpox gain-of-function plans from Congress and the media",
    "commentLink": "https://news.ycombinator.com/item?id=40638386",
    "commentBody": "Controversial pesticide research all but vanished from a major conference (usrtk.org)188 points by stareatgoats 22 hours agohidepastfavorite77 comments yuliyp 21 hours agoI gave up reading the article about halfway when they hadn't mentioned at all how the program committee of the conference is assembled. That corporations sponsor academic conferences is natural: there are a lot of reasons it's useful: recruiting, networking, cooperating with other researchers, etc. And they're the part of those scientific communities that has the spare money to be able to provide sponsorships. That the article spent so long trying to convince me that this was sinister is bizarre. reply swatcoder 20 hours agoparent> That corporations sponsor academic conferences is natural But of course, not all \"natural\" things are ideal. Pervasive corporate influence over scientific communication and funding puts a really big thumb on the scale of which programs get pursued and which findings get acknowledged and explored. It doesn't make sense to forbid corporate participation in research altogether (that would be bad too), but it's prudent to look at real-world examples in real research domains to see if important work contrary to moneyed interests is being stifled or misrepresented by way of these money+power dynamics. reply fieldcny 19 hours agorootparentWhy would eliminating corporate funding in academic research be bad? The way it stands now is that it’s a nice tax write of the the company and a great way to play the heads I win tails you lose game. reply swatcoder 19 hours agorootparentNot all science is performed by way of academic research. Industry performs research too, and the best way to ground both biased industrial research and impractical/naive academic research is to have the two communities engaged as commingled peers, where both have standing in funding and process and are each obliged to provide justification and transparency to the other. reply ants_everywhere 18 hours agorootparent> impractical/naive academic research I think this is a common confusion. You need impractical/naive research because that's how exploration gets done. If you heavily bias the search towards areas of the search space that you've already seen a lot then you've basically killed science and its ability to deliver useful results. reply imabotbeep2937 18 hours agorootparentprevThe phrase \"Eliminate corporations from academic research\" does a lot of heavy lifting here. If a company wants to bring a pesticide to market. We would like them to bear the brunt of safety research costs before they launch. You might say that product safety is different from pure academic research. We're just arguing semantics and incentives at that point. Like giving them a tax break for that research. Sure that sucks. But how else shall we make it happen. reply kaashif 19 hours agorootparentprev> The way it stands now is that it’s a nice tax write of the the company and a great way to play the heads I win tails you lose game. What do you mean by this? Can you elaborate? reply jmcmichael 18 hours agorootparentCorporations can fund research in ways that allow them to suppress results that threaten their profits. If science is conducted in these ways, corporations can fund science (for which they receive tax benefits) and if the results are positive, it gets published and the corporation wins because the research supports their business model (tails, I win). If the research results does not support their business model, they can decline to publish it (tails, you lose). There are ways to do science that avoid this kind of corruption. reply pbj1968 17 hours agorootparentName three academic institutions that would sign a contract that prevented them from publishing adverse results. You are at least fifty years out of date on this argument. reply _aavaa_ 16 hours agorootparentA) They don't have to have that in writing, it's very implicity understood that you don't bite the hand that feeds. B) Even if they do find adverse results, depending on what they are (e.g. actively harmful versus negative results) you may have a hard time publishing them since journals don't care much for negative results. reply gruez 18 hours agorootparentprevPresumably he means you can use company funds to donate to a pro-pesticide charity/NGO, and then use that donation to claim a tax credit (around 50%, subject to some limits). It's not really a \"heads I win tails you lose\" situation though. If you donate $100k, and claim the tax credits, you're still out $50k. You might get back more than $50k worth of monetary benefits from whatever the NGO/charity does, but that's not really guaranteed. It's like buying some junk on wish.com with a 50% coupon and saying that it's a \"heads I win tails you lose\" because if it turns out to be not junk, then you win, but if it's shit you still saved 50%. A far more straightforward and honest way of describing it would just be to say that they get a discount on their charity spend. reply naniwaduni 18 hours agorootparentThat's also money you're spending out of your \"profit\" instead of netting it off as an expense, so it's really a fairly minor discount on pre-allocating money over a multi-year horizon for purposes that can be structured as a charity. reply godelski 15 hours agorootparentprev> Why would eliminating corporate funding in academic research be bad? The honest answer is because there isn't enough funding through government and philanthropy. You'll find a really odd opinion, that many people think engineering endeavors are significantly more important than research ones. When instead the truth is that both are two sides of the same coin. After all, research funds the next generation of engineering. I think there's an unfortunate effect of this because there is quite a bit of science that is beholden to corporate... let's say \"motivations\"(?) rather than more free intellectual pursuit. Then the money that is more free is much more competitive and frankly people are metric hacking to get there (publish or perish paradigm is weird when you have to frequently publish novel works). The system was fine but the environment changes and eventually all metrics are hacked. For personal values, I think it is quite important to fund research. From the very basic low level to even higher engineering research.[0] I'd actually be in favor of 5-10xing the federal science budget. I'd argue this should be primarily funded through federal grants, because people will take that research and go make things which will then be sold (world wide) and we'll tax through that. It's like venture capital if it was less risky but had a longer time frame for ROI. The category of \"General Science, Space, and Technology\" accounts for 20.5 bn dollars[1]. The problem is, people understand this to be a big number and hear about these huge costs (often of projects that last decades!), but this is actually 0.4% of the 2024 budget! 64% of that (13.2bn) is going into space flight, research, and supporting activities. The other 7.3bn is going to the rest of science! To put this into perspective, we spend 8.4bn dollars on salaries and expenses for Social Security. The Navy gets 16bn for research, Army 11.5, Air Force 8.2, and another 14 on \"Defense Wide\" (so a total of ~50bn). edit: To be clear, I'm not against corporate funding of science or even corporations working with academics for research. I think it can often work out great. But I think there needs to be some balance or academia gets captured by industry. I think we can think of some where this may have happened (or is in danger of), including domains closely related to the topics HN cares about the most. [0] If you're unfamiliar, the Technology Readiness Level (TRL) is a often referenced and useful (albeit vague) map to point to https://en.wikipedia.org/wiki/Technology_readiness_level [1] https://www.usaspending.gov/explorer [side note] A fun thing I do is talk about the ultra wealthy's wealth in terms of \"CERNs\" instead of dollars. Because numbers in the billions are just unimaginable (I have a physics degree and work with numbers this large -- or the inverse -- and if you tell me you understand this more than an abstract concept, I'll call you a liar). But we can imagine a CERN (which is funded by several countries btw and not a significant part of any of those budgets. Despite being the largest if not most expensive physics experiment ever). Which is a (roughly) 10 billion dollar super project that took (roughly) 10 years to build and costs (roughly) 1 billion dollars a year to operate. This actually makes for a good comparison for people like billionaires because their money is so massive that it is often growing far faster than they can actually conceivably spend it. Maybe the best example of this is Mackenzie Scott who in 2019 got $35.6bn in Amazon stock when divorcing Bezos, has given away $14 billion (5.8 in 2020 alone!) AND Forbes has her at 34.9 billion in net worth (Amazon has done 30% better than VOO since 2019 for context. So, not counting her givings, it's the difference of about 5bn) reply fnordpiglet 16 hours agorootparentprevI would say the right word is “emergent” not “natural” reply ImHereToVote 5 hours agorootparentLike a cell becoming cancerous. reply fabian2k 21 hours agoparentprevI also found the article to be far too verbose and the parts I read mostly tried to imply some malfeasance, but there was hardly any specific accusations. Industry sponsorship is entirely normal for scientific conferences, they would not really be possible without it. This also isn't an issue usually, the sponsors get some advertisment on the conference and some space to represent themselves. If sponsors actually would affect the talk selection that certainly would be a very serious problem, but I didn't see any real evidence of that in the article. reply gerdesj 19 hours agorootparentThey spell out that: \"This face of Corteva Agriscience, ... that has paid hundreds of thousands of dollars to the organization ... \" and: \"However, during hundreds of sessions on these subjects, a significant topic went missing: scholarly research on one of Corteva’s products – neonicotinoids, a factor in one of the most controversial, high-profile areas of research in entomology.\" The article discusses quite a few angles about neonics. Close to the conclusion it quotes a researcher from the Uni of Minnesota: \"I don’t think the scientific meetings are run by them or overrun by them,\" she said. ... \"You donate money, you get a perk. . . . It doesn’t mean anything. It doesn’t.\" So, an issue that even I (a civilian) have heard of fails to be mentioned at a massive conference that should be discussing it (int al). That conference has a major sponsor who also manufacturer's said \"issue\". Also it seems to be accepted that if you pay, you get perks. reply yuliyp 7 hours agorootparentThat's an insinuation, not an accusation of anything specific at all. There are lots of reasons that in that particular year neonicotinoids were under-represented at the conference. The article basically presents one possible hand-wavy explanation as if it must be the explanation, and then offers no evidence of a link at all. Yes those companies sponsor the organizers of the conference, and yes the topic in question was under-represented relative to the article's expectations. No there is not necessarily a causal link between those statements. reply JumpCrisscross 20 hours agoparentprev> corporations sponsor academic conferences is natural There is a vocal minority that treats \"corporation\" as a dirty word. This sort of writing is fodder for them. It doesn't actually have to make a point, just point out that corporations exist. It's helps campaigns get out the vote and electeds' staffers filter out stupid feedback. reply mbostleman 20 hours agorootparentYes, along with capitalism, free markets, anti-union - once you have enough positive confirmation bias momentum on words already agreed upon as bad, then all you need is a little ad hominem implication nudge and you captured a large number of readers. reply JumpCrisscross 20 hours agorootparent> along with capitalism, free markets, anti-union On the other side you have socialism, DEI and cisgender. You really don't have to make a point to get that section riled up, just mention the term. (One could literally start a speech to the respective crowds by repeating a single word, e.g. corporations or socialism, taking a dramatic pause, and get a strong response.) And again, it's safe to toss out policy feedback that obsesses over these terms. (Both the far left and right also have a weird obsession with capitalising random words. I think it seems evocative of Enlightenment-era English?) reply mbostleman 20 hours agorootparentAbsolutely. It goes both ways. I just realized I may have implied otherwise. I was sticking to the negative words that go with corporation. reply coin 15 hours agoparentprevThat’s because USRTK is an organic industry funded PR group. They get paid to attack conventional agriculture. They are quick to point out corporate sponsors yet they themselves are a corporate sponsor. reply 486sx33 19 hours agoparentprevThis kind of “it must be sinister because … look at all the things that weren’t there!” Is highly damaging to the pursuit of science. It’s like gas lighting … so disappointing . The absence of anything is NOT proof that was purposely omitted reply KennyBlanken 21 hours agoparentprevThe article extensively details how insecticide companies, and neonic producers in particular, have a huge role in the organization leadership, funding, and its conferences. It quotes people who describe how industry infiltrates professional and academic organizations and influence. At that \"halfway\" mark, the author describes employees of these companies gish-galloping conference presenters. Then the author describes a couple of scientists in the ESA describing how neonic research isn't selected because it doesn't \"add anything new.\" except the author then shows that neonic research and citations are both growing - the complete opposite of what several ESA people said. These insecticide companies are getting to keep their cake (aggressively challenging neonic research as poorly supported) and eat it too (suppress representation of neonic research at their conferences because \"it doesn't add anything new\" and \"is settled science.\") reply JumpCrisscross 20 hours agorootparent> the author describes a couple of scientists in the ESA describing how neonic research isn't selected because it doesn't \"add anything new.\" except the author then shows that neonic research and citations are both growing I suppose this needs to be expanded on. It could be that neonic research is growing, but that the papers being submitted aren't adding anything novel. OP's point stands. Burying the lede after, essentially, a series of paragraphs that filters the readership to a particular political bent is bad writing. reply JMiao 21 hours agoparentprevuseful for careers, maybe reply pessimizer 20 hours agoparentprev> That corporations sponsor academic conferences is natural: there are a lot of reasons it's useful: recruiting, networking, cooperating with other researchers, etc. And for manipulating the scientific consensus, for rewarding scholars that agree with them, etc. But who actually cares? I don't think anyone was saying that sponsoring scientific conferences wasn't useful for corporations. It's a straw man. The question is whether it's good for science and public health, specifically in the case of neonicotinoids. > And they're the part of those scientific communities that has the spare money to be able to provide sponsorships. The fewer challenges to what is currently profitable to them, the more spare money they have. reply doubloon 18 hours agoprevyou know whats funny is how we have become so efficient at producing food the government literally has to stop companies from producing it more efficiently or it would crash prices and cause economic disruptions. and restaurants throw out millions of tons of edible food every night but if you try to eat it you get arrested for stealing. your true crime was upsetting supply/demand. if people realized they could get free food at like 9pm every night then demand would plummet, so would prices, the restaurants would all go out of business. artificial scarcity is the business model of a huge section of the economy. but then there is also all this attempt by companies to make new chemicals to grow food more efficiently. and the government wont stop that. its ok if you are more efficient just not TOO much more efficient. if you made a chemical that could drop the price of corn by 99% ... the government would probably have to stop that in order to support prices. its like we have this weird machine where we have 5 different brake pedals and 5 different accelerators and different people are constantly trying to push all 10 of them. the bees get caught in the middle. reply tmaly 21 hours agoprevMy local garden place use to tell me roundup was safe to drink. A few years later the that big cancer lawsuit hit the news. reply Modified3019 20 hours agoparentI work in agriculture as an agronomist, and did some time putting out small plots sprays. I absolutely fucking hate the drinking roundup meme. Yeah sure, pure Glyphosate has an acute toxicity similar to that of table salt (in rodents). So if you’re a rodent you can drink a solution of it similar to what you could tolerate with a salt water solution. But this says nothing of long term effects and is not a realistic situation and is fucking stupid. Glyphosate on its own is completely ineffective, it requires adjuvants in order to do its work, for the same reason you use dish soap when washing plates. You will never see pure glyphosate used unless you’re working in research where you’re intending to mix it with something. It’s like all that research that equivocates coffee with caffeine, but even worse. Roundup is always glyphosate plus surfactants, in fact the water/surfactant mix will typically be the majority of the bottle. Not only will these surfactants strip the protective mucus from your gut, it’s help the gylphsate cross barriers it would never be able to on its own, where it causes all sorts of havoc. If someone drinks undiluted roundup, they will die in a painful way, though that requires managing to get it down, which typically only happens in suicide attempts. A fully diluted solution intended for spraying is much, much safer, but still likely to make you very sick on ingestion or significant skin exposure like if you get drenched in it. Any study on the short or long term safety of pure glyphosate is worse than worthless, it’s outright misleading because Glyphosate is not Roundup. Bonus: most adjuvants (which often make up the majority of the chemicals we actually spray out) are exempted from the types of registration and safety trials we typically apply to pesticides. Only a few states are starting to make changes to that (California and Oregon or Washington I think, been a while since I’ve looked at it). reply stogot 15 hours agorootparentYou buried the lead. Do you think roundup is unsafe or safe? reply Modified3019 12 hours agorootparentThat is a fundamentally incorrect way to think about things, there is no such thing as a safe pesticide. If it was safe, it wouldn't have any usable detrimental effect. On the list of things I worry about when it comes to acute chemical exposure (eye danger, lung danger, absorption through skin), the various kinds of Roundup and associated generic formulations is personally down at the bottom as \"least concern\" at all levels of exposure. If I had to be drenched in a pesticide, this is the one I would choose offhand. It'd still be bad, chemical concentrate is not a joke. I cannot speak to it's potential long term effects like cancer, as I neither have the skill, time, or desire to search through and evaluate the mess of biased literature available. Given my religious use of PPE and the short 3 year period of applicating small plot trials, my current level of concern for it's potential cancer effects is also \"least concern\". What's actually going to kill me is a heart attack/stroke given my family history, so I spend my limited mental and physical energy on maintaining a healthy weight and exercise. reply ssl-3 12 hours agorootparentprevIt seems pretty clear to me that they think that Roundup, in the form that is sold to regular consumers, is unsafe to drink. They even provided a detailed and rational explanation for why they hold this opinion. reply hammock 21 hours agoparentprevNot to take away from your comment, but for those who clicked comments before reading, this article is about neonics not roundup reply pkaye 16 hours agoparentprev> In 2022, the European Chemicals Agency (ECHA) carried out a hazard assessment of glyphosate and concluded that it did not meet the scientific criteria to be classified as a carcinogenic, mutagenic or reprotoxic substance. EFSA used ECHA’s hazard classification for the purposes of the EU risk assessment on glyphosate. https://www.efsa.europa.eu/en/news/glyphosate-no-critical-ar... reply josefx 15 hours agorootparentAssessments by EFSA/ECHA are mainly based on studies and reports collected by the manufacturers. They rely in those being complete and honest. Monsantos internal email correspondence was rather explicit on how they would rather reach out to their contacts and kill any study they did not approve of before it could become problematic. reply mardifoufs 19 hours agoparentprevSalt saturated water is also dangerous and lethal to drink. Does that mean that eating a little bit of salt, or any regular portion you'd usually come across in food, would be unsafe and lethal? reply google234123 21 hours agoparentprevA lawsuit != scientific evidence... which points the otherway reply memkit 21 hours agorootparentSure... but Roundup definitely causes cancer in humans. It's well established at this point. \"One international scientific organization, the International Agency for Research on Cancer (IARC), classified glyphosate in Group 2A, \"probably carcinogenic to humans\" in 2015. In 2017, California environmental regulators listed glyphosate as “known to the state to cause cancer.”\" That's not to mention the strong-arming, harassment, and threats towards researchers publishing papers that paint Monsanto and Bayer in a negative light. [1] 1. https://usrtk.org/monsanto/attacks-on-scientists-journalists... reply JumpCrisscross 20 hours agorootparent> International Agency for Research on Cancer (IARC), classified glyphosate in Group 2A, \"probably carcinogenic to humans\" Group 2A includes red meat and hot coffee [1]. To the extent glyphosphate is problematic, it's in being toxic [2], not carcinogenic. (Though again, we can speak similarly of barbecue [3].) [1] https://en.wikipedia.org/wiki/IARC_group_2A [2] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9101768/ [3] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4993204/ reply memkit 20 hours agorootparent> To the extent glyphosphate is problematic, it's in being toxi [2], not carcinogenic. This is a fair assessment based on the published scientific literature. But you have to take into account the fact that the owners of glyphosate have 1) surveilled, harassed, defamed, and threatened individual scientists and 2) paid millions of dollars to ethically dubious scientists to publish articles in favor of the safety of glyphosate 3) paid billions of dollars to victims of glyphosate exposure because they were found liable (or thought they would be) of causing them harm Given those facts, I think it's reasonable to assume that glyphosate is pretty f*cking bad for you and it's truly mind boggling that people feel the need to defend it. It feels like everyone you talk to on the topic is a bureaucrat in the Soviet Union engaging in doublespeak. Clearly, the people harassing, threatening, surveilling, defaming, and bribing are the baddies. Clearly, they have something to hide. reply JumpCrisscross 20 hours agorootparent> you have to take into account the fact that the owners of glyphosate have... Monsanto was absolutely shady. That doesn't change the biochemistry of glyphosphate. > it's reasonable to assume that glyphosate is pretty f-cking bad for you Almost every industry has someone being shady. Concluding adversely from that is not reasonable. (It's literally ad hominem, concluding an argument by way of the speaker's character and motives.) You said \"Roundup definitely causes cancer in humans\" and then provided sources. Your sources don't support that assertion beyond a very weak definition of causation, at which point we're back to it being similarly carcinogenic to widely-consumed foodstuffs. reply memkit 20 hours agorootparentSure, there aren't many sources on my side of the argument because everyone who tried to publish was either threatened, harassed, surveilled, or bribed. I'll give you that one. reply JumpCrisscross 20 hours agorootparent> there aren't many sources on my side of the argument because everyone who tried to publish was either threatened, harassed, surveilled, or bribed Right, a global conspiracy despite the repeated attempts by scientists who were being funded by interests opposite to Monsanto's trying to find evidence. If you want a conspiracy, try this one: focus people on the provably-weak claims around carcinogenicity to distract from the stronger ones around toxicity. reply memkit 20 hours agorootparent> Right, a global conspiracy It's not up for debate. It happened. We know the threats, harassment, surveillance, and bribery happened. We know the specific people, the specific threats, the specific dollar amounts. reply JumpCrisscross 19 hours agorootparent> It's not up for debate. It happened False equivalence and straw man [1][2]. You claimed \"everyone who tried to publish was either threatened, harassed, surveilled, or bribed.\" You're trying to conclude that argument by showing some people were threatened, harassed, surveilled or bribed. Going back to your first post, you made a claim and provided sources that don't support it. Now you're backing up into, essentially, \"trust me.\" This isn't arguing in good faith. > We know the threats, harassment, surveillance, and bribery happened. We know the specific people, the specific threats, the specific dollar amounts Sure. These actions apply to plenty of things. That doesn't prove the inverse. The bottom line is there is a multi-billion dollar pay-out for anyone who can show Roundup causes cancer. As a $50bn company, Monsanto has weight, but it's in the low tier among the heavyweights. Hell, if someone has convincing research and is scared, hit me up. I'll indemnify you against civil claims, finance the litigation and even pay for personal security and countersurveillance (if they're caught illegally surveilling, it adds to the damages). In exchange, I want my costs back first plus 51% of the damages. SIDE NOTE: Memkit looks cool. [1] https://en.wikipedia.org/wiki/False_equivalence [2] https://en.wikipedia.org/wiki/Straw_man reply memkit 19 hours agorootparentI mean, I agree with your claims about my logical fallacies. I guess what I'm trying to say is: If we could magically determine the truthiness of all these statements and I had to bet money, I would take my side. reply JumpCrisscross 19 hours agorootparent> what I'm trying to say is: If we could magically determine the truthiness of all these statements and I had to bet money, I would take my side. This is, in my opinion, a more-compelling statement than \"Roundup definitely causes cancer in humans. It's well established at this point.\" (Also, Roundup != glyphosphate. The nastiest bit in Roundup may be the surfactants [1].) [1] https://en.wikipedia.org/wiki/Polyethoxylated_tallow_amine#H... reply s1artibartfast 13 hours agorootparentprevThe thing about that fact pattern is I would expect the same thing if the chemical was completely inert. This makes it very difficult to infer guilt or innocence based on Behavior alone reply nonameiguess 20 hours agorootparentprevI admittedly get annoyed when people link to video and audio, but in this case, the best source I can think of for information about how IARC classification works is a Stronger By Science podcast episode about Aspartame: https://www.strongerbyscience.com/podcast-episode-116/ If you ever have five hours to listen to someone geek out over esoteric history and regulatory state stuff, in a way that is presumably somewhat tangential to your political bents (presuming you have no strong opinions about strength training), this is a very good non-political source of information. JumpCrissCross gives the short version, but IARC's class 2 is probably not what you think it is. It's not just that it contains a whole lot of stuff I guarantee you ingest regularly without thinking about it. It's not meant to be an advisory to consumers at all. It's a recommendation to researchers about what sorts of compounds are worth putting further research into. The way the media reports about it is wrong and misleading to the people it scares. reply infecto 20 hours agorootparentprevIs there anything in CA that is not known to cause cancer? reply erik_seaberg 20 hours agorootparentThere's actually a list, but it's really big and includes possible exposure to toast (acrylamide) and beer (ethanol). There's also no compensation or incentive for doing any work to prove that a warning isn't justified, so everyone errs on the side of spamming them everywhere. reply roywiggins 19 hours agorootparentThe evidence for alcohol consumption causing cancer is actually pretty strong: https://www.cancer.gov/about-cancer/causes-prevention/risk/a... reply JumpCrisscross 19 hours agorootparent> evidence for alcohol consumption causing cancer is actually pretty strong As it is for red meat and hot drinks. These are low-magnitude high-significance effects. reply bpodgursky 21 hours agorootparentprevIt's really not. reply KennyBlanken 20 hours agorootparentThen why is Monsanto presenting pre-written papers and \"high quality drafts\" to scientists and journalists to \"edit\" and put their names on? https://www.nytimes.com/2017/08/01/business/monsantos-sway-o... Then why has Monsanto settled one hundred thousand claims and paid ten billion dollars in judgements against them and settlements? Then why was a top official at the EPA emailing Monsanto executives saying he should \"get a medal\" if he was able to kill the CDC's study? https://www.npr.org/sections/thesalt/2017/03/15/520250505/em... reply JumpCrisscross 20 hours agorootparentBecause glyphosphate is almost certainly toxic. We have evidence for that. (Roundup is more toxic than glyphosphate alone [1].) That doesn't mean it's carcinogenic in a colloquial sense--we don't have evidence for that, again, beyond the carcinogenic capacity of commonly-eaten foods. [1] https://en.wikipedia.org/wiki/Glyphosate#Toxicity reply memkit 21 hours agorootparentprevI mean what do you make of the threats towards researchers? Surely that has limited the amount of scientific evidence published against the safety of Bayer's products, no? It's also a damning piece of evidence in and of itself, at least stochastically speaking. reply gruez 20 hours agorootparent>I mean what do you make of the threats towards researchers? source? reply memkit 19 hours agorootparentThis is a decent summary of one tiny fraction of their unethical doings: https://usrtk.org/monsanto/attacks-on-scientists-journalists... reply gruez 19 hours agorootparentSkimming the first few parts, since the linked article is long and I'd like to avoid engaging in a gish gallop: >when Rachel Carson published Silent Spring, her scientific analysis of the harms of DDT, Monsanto engaged in targeted personal attacks to try to undermine her research They said mean things, but calling it a \"threat\" seems like a stretch. Moreover after clicking through some of the links I still have no idea what they actually said aside from some well chosen quotes. >In the lead up to IARC’s report, Monsanto rolled out an “an unprecedented and harsh strategy” to discredit experts, wrote Colorado School of Public Health Dean Jonathan Samet. Monsanto’s attacks, he said, amounted to an “attack on expert review” itself. I skimmed the linked article and it doesn't offer specifics about what the \"attacks\" actually were. >Journalists at France’s largest newspaper Le Monde, in their award-winning series about the Monsanto Papers, described the Monsanto-led attack on IARC as “an effort to destroy the United Nations’ cancer agency by any means possible.” Skimming the linked source, it looks like the \"attacks\" in question are FOIA requests. >Following that email exchange, GLP went on to publish dozens of articles critical of the cancer agency — many of them personal attacks on the scientists involved in the glyphosate review, and some of them written by former chemical industry lobbyists and climate science skeptics. See first reply in this comment. >Engaging climate science denialists bad/questionable, not exactly \"threatening\" >Another document reveals that Monsanto consultants drafted at least one letter calling for an investigation of the “flawed” IARC process — and designed to look like it was written by a member of Congress. 1. The process is arguably flawed, as other commenters have mentioned. I think it's fair game to criticize them for that 2. I looked at the linked document and I can't imagine how anyone thinks it \"look like it was written by a member of Congress\". Nowhere does it claim that it's written by a congressman, and the signature block just says \"NAME\"? Is this even a real letter that was sent to Dr. Collins, or a draft letter that they wanted an actual congressman to send? reply andrewmcwatters 20 hours agorootparentprevI can't help but think of the movie Erin Brockovich: Erin Brockovich: By the way, we had that water brought in specially for you folks. Came from a well in Hinkley. Ms. Sanchez: [Puts down the glass, without drinking] I think this meeting is over. Ed Masry: Damn right it is. Would you personally spray Roundup directly on your skin? Because if you've ever treated a large area of your plot with weed killer with a spray indicator, it's clear as day that stuff is getting all over you with the slightest breeze. reply ChrisMarshallNY 20 hours agorootparentI have a friend that suffered the exact type of lymph cancer that Roundup is supposed to cause. He used Roundup in his properties for years. When I was a bench tech, back in the early eighties, we had gallon jugs of trichlor, all over the building. Each tech had a bottle at their bench. We were explicitly told, by management, that it was completely harmless. reply andrewmcwatters 20 hours agorootparentYep. I don't buy it. reply memkit 19 hours agorootparentFair. I don't believe the company that bribed the head of the EPA gives a sh*t about \"science\" or the health of their customers. This affects my view of how safe their product is. This is the real world, not a philosophical sandbox. I understand that a person's character should be ontologically castrated from their argument in a philosophical sandbox. But 99% of the time that a company does evil shit like this in the real world, they have very strong reason to do so. It's increasingly likely that Monsanto/Bayer don't want the scientific process to run its natural course. They feel the need to intervene. Why? reply bpodgursky 20 hours agorootparentprevI've used roundup on weeds around my house and not been especially fussed when it gets on my skin. reply justatdotin 20 hours agorootparentsure: hand-held household application is different to indiscriminate spraying from a pumped tank on the back of a truck reply JumpCrisscross 19 hours agorootparent> hand-held household application is different to indiscriminate spraying from a pumped tank on the back of a truck Critically, it appears the surfactants in Roundup are the nasty bit, not glyphosphate. To my knowledge, they don't permeate the skin. But if you're inhaling it, it's in your blood stream. It shouldn't be shocking that a chemical your body isn't used to designed to keep organic compounds apart messes with at least some of your biochemistry. reply MostlyStable 21 hours agoprevSo....this seemingly just reflects a shift in research priorities, and there is no evidence provided to the contrary, and no reason to remark at all, except that >Several entomologists who organized panels in bee science for the conference said that they were surprised to hear that research about the effects of neonicotinoids on bees had all but vanished from the program. but then also: > they also said that the field has shifted to an approach that accounts for multiple stressors on individual bees and hives, rather than studies of individual factors, and that the research presented at the conference reflects that way of thinking. This seems like a real nothing-burger of an article. Research interests ebb and flow. Science is as subject to fads as almost anything else, and conferences more than most things tend to reflect these fads. reply wazoox 21 hours agoprevThere is no controversy at all among entomologists and biologists : pesticides are responsible for the huge destruction of insects, birds and biodiversity in general; they're probably very dangerous even to us. But money. reply RoyalHenOil 20 hours agoparentPesticides are a factor in insect loss, but they are VERY far from the major cause of lost biodiversity in general. The major causes are overwhelmingly environmental destruction (e.g., the clearcutting of virtually all old growth forests) and the introduction of invasive species and diseases. reply giantg2 20 hours agorootparentI think you're probably right globally and historically. However, I think the parent's point is still valid for many localities. Sure, the medium to large animal diversity is probably low in our already mostly destroyed habitats (cities, suburbs, etc) but the insecticides are likely to be destroying what's left for the remaining insects and small animals. reply KennyBlanken 20 hours agorootparentprev> Pesticides are a factor in insect loss, but they are VERY far from the major cause of lost biodiversity in general Oh hey, look at that - the exact position of the insecticide industry... ...which does not explain why bee die-offs in various countries (at different times) have coincided with the introduction of neonic pesticides in that country. reply allemagne 17 hours agoprevThe clear implication of this headline is that pesticide research was deliberately covered up. A few paragraphs in the writer makes it obvious that faceless corporations are to blame. Here's the lede: >Only four papers and posters that examined [the effects of neonicotinoids on bees] made it into the conference, out of nearly 100 papers, posters and symposia on bee science. (Now it makes sense why the headline says all but vanished) Specifically, this is referring to a conference of the Entomologist Society of America. \"Entomology\" being the study of all insects. Bees, ants, katydids, flies, etc. How much out of a sample of 100 papers/posts/symposia should insect scientists be presenting new research on neonicotinoids and bees? Should it be more or less than 4%? Should it be 30%? 50%? I don't know, how on earth would I know that? Actual entomologists quoted: \"I’ve never had a problem getting a neonic paper in a symposium\", \"For any given subject within entomology, what is covered in ESA conference programs reflects the ebb and flow of interest in it among the community and the focus of research being conducted in the field.\" However, this writer knows it's a lot more than 4%. How does she know this? Well here's an extensive study of a (probably nefarious) corporate partnership program by the ESA that accounts for... 3 to 3.5 percent of the society’s total annual revenue, and here's some people who argue that corporations are too involved with science. You do the math! The writer also repeats some variation of \"pipeline to industry\" six times in an attempt to horrify the reader. Why you should be surprised or angry that entomologists are by and large working regular jobs for private businesses after graduating, is also left as an exercise for the reader. Including this particular anecdote is also pretty telling: >Emily May, a pollinator conservation biologist who studies pesticides for the Xerces Society, a Portland, Ore.-based nonprofit group, recounted facing intimidation by agrochemical industry attendees after her talk. >She spoke at the meeting about how government regulators focus on the effects of individual pesticides on pollinators without factoring in the cumulative effects of a range of chemicals. >After she spoke, she said, five people from the audience stepped up and fired off highly technical questions, such as whether she had completed indexes of cumulative effects. >“Questions came in with ‘Have you done indexes about toxicity?’ . . . They were just getting very technical in their specific pushback on approaches to looking at cumulative toxicity,” May said. >“It was like my worst-case scenario, really. It made me nervous about the next conference I presented at, to be honest. It’s hard. People wanted to make me look bad.” >The source of that onslaught of technical questions: Employees of agrochemical companies, May said. Am I crazy to think that a conference is not where you get your ideas uncritically accepted, but challenged on a \"specific\" and \"technical\" level? Am I crazy for thinking that agrochemical industry stooges should probably be torn to shreds when up against a biologist who has done the research? We don't need to close our eyes and pretend like there's nothing to fear from corporations. There was an entomologist quoted saying \"I’m not going to deny that there is an uninterest, or a bias, to not talk about pesticides and bees\", which isn't nothing, but this was clearly drawn out as a response to some kind of pointed question from the writer about the ESA and neonicotonoids. I get that it gets clicks and eyeballs to play into certain narratives. Are we even slightly worried that if you rely on lazy and dishonest innuendo too much, everyone will become just as lazy and won't believe you when you finally break an important story that goes against their priors? reply 3lit3krew 18 hours agoprev [–] Obviously nobody can trust The Science any more, too much big money involved. The best you can do is try to keep up with bro-science, which is often decades ahead of The Science, and avoid any new chemicals, food additives, drugs or therapies for several decades until we learn if they're really, actually safe or not by observing what happens to the guinea pigs called the general public. At this point we've all seen enough evidence to have destroyed either some, or all trust in The Science, anybody left using Science Juice or Science Gas or Science Pills either doesn't care, or wouldn't even if they knew. reply fincycaden 17 hours agoparent [–] Absolutely. I began thinking this way when I was the guinea pig, and suffered a permanent life-alerting effect from a medication, which was anecdotally reported despite there being no official correlation or link by the \"science\" reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "At the 2023 Entomological Society of America (ESA) meeting, significant corporate sponsorship, especially from agrochemical companies like Corteva Agriscience, was evident.",
      "Despite discussions on critical topics like bee health and climate change, research on neonicotinoids—a pesticide linked to bee colony declines and produced by Corteva—was notably sparse, raising concerns about corporate influence on scientific discourse.",
      "Critics argue that corporate involvement may compromise the integrity of the ESA, although the organization defends its inclusivity and diversity of scientific perspectives."
    ],
    "commentSummary": [
      "A major conference experienced a decline in controversial pesticide research, igniting debates about the impact of corporate sponsorship in academia.",
      "Critics argue that corporate funding skews research priorities and suppresses less profitable studies, while supporters believe it fosters beneficial collaboration.",
      "The discussion underscores the tension between industry involvement and scientific integrity, advocating for increased federal science funding to mitigate corporate influence."
    ],
    "points": 188,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1718050593
  },
  {
    "id": 40640927,
    "title": "Daily Commitments: Boosting Productivity and Team Visibility",
    "originLink": "https://maxleiter.com/blog/ship-every-day",
    "originBody": "Jun 10, 2024 Ship something every day Edit: A better title would've been \"commit every day that you work\". I don't mean you should work on weekends or not take time off, and whatever you work on doesn't need to \"ship to prod\". I don't feel particularly qualified to give advice (I blame imposter syndrome), but I do have one tip to share that I think has been useful for me. It applies both to professional software dev and personal projects. You probably guessed it from the title: ship something every day. It doesn't need to be a major feature or even a bug fix. It just needs to be something you can point to. Why? A few reasons: The dopamine rush of your code being shipped Your team sees you're working There's more to this than just performance reviews; with remote work, it's easy for you and co-workers to feel isolated. It encourages incremental work. Your future self and co-workers will thank you Your git commit streak looks good Yes, people say this doesn't matter. But I'm sure people like recruiters look at GitHub profiles, and an empty page isn't a great look. The satisfaction and mental benefits of getting something done. Note: People mentioned it seems like I'm advocating for you to push code every day. My point is that you should contribute something: docs, triage, whatever. For me, it's usually code. Thanks for reading! If you want to see future content, you can follow me on Twitter or subscribe to my RSS feed. ← Older Why your website's fonts might be larger than intended",
    "commentLink": "https://news.ycombinator.com/item?id=40640927",
    "commentBody": "Ship Something Every Day (maxleiter.com)185 points by MaxLeiter 18 hours agohidepastfavorite122 comments userbinator 16 hours agoIMHO \"every day\" is far too frequent, and this ADHD-ish attitude is one of the reasons why the quality of average software has gone down the drain. Developers need to step back, think more deeply, and not worry about being pressured into \"shipping code\" that barely works. The dopamine rush of your code being shipped This frequent overstimulation leads to less ability for long-term attention. When I taught programming, I saw plenty of beginners do this, especially with an IDE, and the addictive nature of being able to edit and run to see the changes immediately lead to many of them falling into an unproductive rapid iteration loop where they were barely even thinking about what they were doing, just making random changes until something seemed to work. Your team (and manager) sees you're working Tough problems need time to solve, and you won't see much meanwhile. If needing to put on a show for others is more important than actually working, something is very wrong. Your git commit streak looks good Yes, people say this doesn't matter. But I'm sure people like recruiters look at GitHub profiles, and an empty page isn't a great look. Optimising for metrics never works for those who can see through the illusion, and that's an increasing number of people over time. If I was a recruiter and saw that sort of activity, I wouldn't think of it as more than someone just putting on a show --- especially if the majority of those commits are effectively \"thrashing\" or \"churning\". The satisfaction (and mental benefits) of getting something done I can personally say that the satisfaction is far bigger the longer you've persevered. reply karmarepellent 12 hours agoparentActually I first thought this person was joking in their blog post. As you already mentioned almost every piece of advice in there is related to how to look good in others eyes. I would not dare interpreting too much into it but I do not think this is how you achieve satisfaction in your job. In fact I get anxious just thinking about me sitting there and being \"oh my, I have not committed in an hour, people must be thinking I'm slacking\". On another note I also think much more goes into what makes a good commit than frequency. It's a topic that has already been widely discussed a lot and will continue to be discussed in the future. Edit: I suppose this sentiment may also be one of the reasons why I'm increasingly reluctant to work with Gitlab. Their UI changes multiple times per year and I have yet to encounter a UI change that I would actually call an improvement. I value some level of stability in software that is being used by all our developers throughout the day. But someone seems to think their customers need to \"see things changing\" or they will stop paying for licences. reply mythhabit 13 hours agoparentprevSome of the main benefits of shipping every day, is: 1. Develop a system where you can turn codepaths on and off with a toggle. 2. Become better at architecture. Learning to split a task into smaller chunks that are easier to reason about, both overall and individually. 3. Learn to do multi phase increment. 4. Develop an automatic deploy/rollback system. All are good practices, and essential if you need HA. It also gets the velocity into your daily work, so if you need to deploy extra logging, a bugfix ect, you can do it in minuts and not hours/days/weeks. Can you do all of that and ship on a weekly basis? Absolutely, I just haven't met anyone that do that. reply chipdart 12 hours agorootparent> Can you do all of that and ship on a weekly basis? Absolutely, I just haven't met anyone that do that. I'd go as far as to claim that you cannot, at least at a level close to a highly available system updated with full CD without any gating or manual intervention. Weekly deployments implicitly lead to merge trains and large PRs and team members sitting on their ass to approve changes. Each deployment is huge and introduces larger changes which have a larger risk profile. As deployments are a rare occurrence, teams don't have incentives to invest in automated tests or mechanisms to revert changes, which leads you to a brittle system and pressure to be conservative with the changes you do. As deployments are rare, breaking deployments becomes a major issue and a source of pressure. To understand this, we only need to think about the work that it takes to support frequent deployments. You need to catch breaking changes early, so you feel the need to increase test coverage and invest in TDD or TDD-like development approaches. You also feel the need to have sandbox deployments available and easy to pull off. You feel the need to gate deployments between stages if any automated test set breaks. You feel the need to improve testing so that prod does not break as often. If prod breaks often,you also feel the need to automate how deployments are rolled back and changes are reverted. You also feel the need to improve troubleshooting and observability and alarming to know if and hoe things break, and improve development workflows and testing to the ensure those failures don't happen again. You get none of this if your project deploys at best 3 or 4 times a month. Another problem that infrequent deployments causes is team impedance. You need more meetings to prepare for things which would otherwise be automated away. You have meetings for deployments for specific non-prod stages, you have meetings to plan rollback strategies, you have meetings to keep changelogs, you have meetings to finalize release versions, you have meetings to discuss if a change should go on this or that release cycle, etc. bullshit all around. reply Arainach 11 hours agorootparentIf your tests only run as part of deploy, you've already lost. So long as you have a good set of integration tests and the right staging environments to run those tests against, when you ship doesn't matter. I've worked on multiple teams with test suites that give very high confidence what changes are good and are not; most tests were fast and could run before code was merged and block submission. The expensive integration tests ran against a staging environment, and when they started failing it was very quick to identify the range of CLs there and understand what to rollback/fix. For most of my time there those services only pushed to prod twice a week - sometimes less if the integration tests were failing on the day of one of the deploys. Not every day, not every commit. And yet we had all of those benefits that you claim are impossible. No list of idle people waiting to approve changes, no \"huge\" deployments, infrastructure for automated tests and more. There are no meetings - those two weekly rollouts are entirely automated infrastructure, and unless an abnormal error rate is detected during the canary proceed entirely without human involvement. The world didn't fall down. Customers didn't ask us where things were. Oncall appreciated that there weren't constant builds at risk of breaking and falling over - they only had to monitor rollouts twice a week and otherwise could focus on failing tests, logs, and alerts. reply zarathustreal 5 hours agorootparentprev> 1. Develop a system where you can turn codepaths on and off with a toggle. > All are good practices… I beg to differ on this point actually. It’s very difficult to get right and leads to subtle bugs (or even potential security vulnerabilities). It also pollutes the codebase with conditional statements that aren’t related to the business logic and makes it harder to read. Avoid feature flags. reply zer00eyz 15 hours agoparentprevI think this would be better if it was \"Do something every day\". Close a bug, clean up a file, take a pass at a refactor. Set up a new monitor. Build some utility for yourself, or your work flow. Learn something. Play with some new tech and try it out. > I can personally say that the satisfaction is far bigger the longer you've persevered. I dont disagree but one can collect small joys along the way to make it easier. reply esafak 15 hours agorootparentBut then it's a trivial observation; of course you should do something. reply baxtr 13 hours agorootparentI think it’s different. It’s not just doing something but doing something with an end in mind. I’m not saying one is better than the other. But having an end in mind will yield more productivity. reply exe34 13 hours agorootparentprevi think it's do something small, manageable, something you can finish soon, to get the feeling you're being productive, while the stuff in the slow-cooker works its magic. reply jethro_tell 15 hours agorootparentprevI write a lot of dev ops type stuff so I ship a lot of smaller things as a rule. But, I have adopted a ship every day rule for myself, which can often keeps me from yak shaving, which is actually a direct combat for my ADHD deep dive tendency. I love what I do and I love to make perfect code, but sometimes that's less than helpful. One of the ways that ship every day is extremely helpful for me is in helping me with realistic time boxing. If I'm working on a bigger module or something really complex, I'll note that in the morning and spend 15 minutes adding a new graph to the dash, or knock out a quick bug fix that's been annoying me. While there's lots of circle jerking about dopamine rush of ADHD, for me, if I had my way, I'd go so deep and ship perfect code once a month or twice a year. But, we also know there is no such thing as perfect code, but there is a sweet spot that gets quality code into the wild with the least possible amount of time working speculative edge cases. Looking at my stack and deciding if I'm going to ship my main project today or take a 15-30 minute warm up bug/push thing, has been extremely useful for me and I end up with better small single function commits, and pushing working code with a slot for the edge case. I still do the edge case before we go to prod, but my projects move a touch faster, I don't rabbit hole and my bus factor is quite a bit lower. reply userbinator 14 hours agorootparentprevIn other words, \"make progress every day\". reply zer00eyz 14 hours agorootparentLearning something useless for fun counts as doing something! reply chipdart 12 hours agoparentprev> IMHO \"every day\" is far too frequent, and this ADHD-ish attitude is one of the reasons why the quality of average software has gone down the drain. I think you are too quick to try to claim someone is incompetent or unsuited for a job just because you can't or won't understand a point they make over how many commits they make. I disagree with you: I think that posting at least one commit per day is an incredible low goal. A commit can be anything, from a major refactoring to fixing a typo. Any developer worth its title is well aware of stuff that needs to be done in a project in spite of not being a high priority. From renaming a function to refactoring a class, from adding a unit test to tweak how a test is setup, there is always, and I mean always, things that need to be done in a project. Even updating a document or adding a comment counts as a commit. And in the very least, if you feel that touching something in a project is a risky ordeal, your project needs tests. This has nothing to do with streaks or dopamine rushes or pleasing managers. This is about getting stuff done. To me, a developer who can't figure out ways to be productive by contributing tiny commits spread over time is a developer who is wasting space in a team. reply moring 12 hours agorootparent> This has nothing to do with streaks or dopamine rushes or pleasing managers. This is about getting stuff done. To me, a developer who can't figure out ways to be productive by contributing tiny commits spread over time is a developer who is wasting space in a team. This totally discounts any work that does not result in commits, such as requirements analysis, legacy code analysis, or code that results in insights but won't be merged. But then, anyone who knows how incredibly valuable such work is will likely not want to argue whether they are \"wasting space in a team\" either, and leave on their part when confronted with such claims. reply chipdart 11 hours agorootparent> This totally discounts any work that does not result in commits, such as requirements analysis, legacy code analysis, or code that results in insights but won't be merged. I don't think it does. My point was not \"do this OR that\". My point is that posting a commit a day is a goal that's easily achieved if you do professional work. The work it takes you to fix a typo or add a commit is not something you need to plan around, or have to choose in place of doing requirements analysis. reply bluGill 6 hours agorootparentOnly if your job is to write new code/features. I've been involved with critical bugs that took 6 months to figure out the root cause. What are you supposed to commit for those 6 months while staring at core dumps, trying to guess what might be going on? reply kalaksi 7 hours agorootparentprevWhat's the point of having such a goal? Seems like additional overhead if you need to remember and go out of your way to do such a trivial commit. reply strken 11 hours agorootparentprevThis goes back to the \"ADHD-ish attitude\". I've had entire weeks where I didn't commit anything, because I was doing discovery or documentation or some other useful task with an outcome that wasn't code. Should I have deliberately broken my flow state to go put up a commit for a random unrelated typo? The article does in fact note that documentation is acceptable. reply BoorishBears 11 hours agorootparentprevIf you're regularly unable to make even a single line change as an IC, your team will probably not be at a loss. Some of my biggest breakthroughs have been far away from a computer, but I can easily understand where the OP is coming from: give yourself a chance to make tangible contribution each day, and maybe it snowballs into something more. Maybe it doesn't and that's ok, but at least give yourself the chance for it to. (It also says something to read the OP and not be able to imagine any interpretation other than \"they just don't understand how work is done\") reply creshal 8 hours agorootparentEqualling \"tangible contributions\" to \"git commits\" is insanely reductionist. It works maybe if everything your org does - tickets, documentation, manuals, analyses, meeting transcripts, research notes, everything - lives in git, but otherwise, you're just asking to lower the quality of your org's organization and work culture for the sake of hitting made up KPIs. reply BoorishBears 6 hours agorootparentKey terms in what I wrote: - regularly unable: When you're an IC, there's plenty of non-code contributions needed but if it's so fantastically wild that you should regularly contribute code, something might be off. - not be able to imagine any interpretation: the article literally says it now, but any half charitable reading already covers a productive day of non-code work. There's just still something to be said for making \"butt in chair in front of editor\" time. If there's so much \"other\" taking your time in an organization that this seems onerous, it might be all the more reason to push for that time or question why that is. reply auggierose 11 hours agorootparentprevThat almost sounds reasonable! Except it isn't. This is the reason why software is shitty, and most teams are shitty, too. I write software because I have a vision in my mind, which I want to achieve. Coding up stuff and trying it out helps a lot, but so do phases of quiet introspection and reflection. reply ZaoLahma 9 hours agorootparentprev> I think that posting at least one commit per day is an incredible low goal. A commit can be anything, from a major refactoring to fixing a typo. This is an easy goal in some companies / projects, while in others (usually bigger companies / projects) it's unreasonable and will even be counter productive. You might need hours of execution time in a test cluster, then need code reviews from several peers (who are busy working on prioritized items), and if your commit is later integrated with commits from other organizations and tested as a whole which results in failures, you put extra load on those who are tasked with finding and sorting out the offending commits. In principle I do absolutely agree with you that ideally it should be encouraged to spontaneously fix and commit, but in practice \"it depends\". I've found that larger companies / projects have a certain cadence, and trying to deviate from that cadence too much just results in grinding gears on all levels. reply PheonixPharts 6 hours agorootparentprev> I think that posting at least one commit per day Notice that the article has been edited. > Edit: A better title would've been \"commit every day that you work\". I don't mean you should work on weekends or not take time off, and whatever you work on doesn't need to \"ship to prod\". I'm pretty sure parent comment was replying to the original version which, at quick skim, gives the impression that the article was about pushing to prod everyday. I've worked at startups to do push to pod every day at it's an absolute frenetic nightmare. Posting a commit everyday is so uncontroversial that I doubt the headline would have made it to the FP of HN. I've also never heard the term \"shipping\" in software refer to anything other than getting something into prod. reply MaxLeiter 3 hours agorootparentThis confusion came from me not thinking too long before writing. My work makes use of feature flags so we incrementally merge features all the time, internally (and can do it quickly). But its still “shipped.” reply mirekrusin 10 hours agorootparentprevYou both are right but talking about slightly different aspects. The morale of the story is don’t play speed chess but make move every day. reply sibeliuss 11 hours agorootparentprevThis right here is the truth. Yes, there's all the of the other stuff -- \"requirements\", etc -- but in reality, as an IC, we're here to push code and review code. All of the requirements stuff comes on top of that. (In my experience, the people who aren't pushing or reviewing code are _also_ not doing the other stuff either.) Remember, commenting on PRs counts as activity. That's PR review -- that's doing something, and potentially a _lot_ of something. Big long stretches of empty space on Github is absolutely a red flag, until you get into the highest levels of IC seniority and are mostly in meetings all day. It is extremely easy to do nothing at all as a software engineer, when there is so much stuff to do any given day. It's easy to get defensive when faced with such privilege. reply Tommy430 13 hours agoparentprevuserbinator speaking out again, loving your posts on \"modern\" stuff. Unfortunately, that's how it's like sadly. People just want the \"constant CONSTANT CONSTANT UPDATES!!!\" without thinking properly, even if they don't need the new features but it's just because the company said so. Heck, physical books don't even need to get any updates and I can still enjoy picking them up and reading them, just like I can still enjoy launching the old software and using them. IMHO the software is already feeling like 99% complete, companies just want to abuse the users, get them to use their abusive models, and milk the software in general just because they're lacking any ideas for new \"features\". Anyways, feel free to throw pitchforks at me all you want ;) reply vram22 11 hours agorootparentI just threw a pitchfork at you. It had only one tine, though. It was to the left of your username above, and pointing upward. Heck, it just disappeared into the screen or something. reply neilv 15 hours agoparentprevI think the article would come across better, did the field not have such widespread problems right now. For developers who are seriously hardcore, sometimes it might be good to lighten up, and enjoy a little daily reward and recognition. But in the current state of things, the advice sounds closer to embracing the dysfunction, and feeling good about it. reply gfourfour 13 hours agoparentprevWow, your second paragraph hit the nail on the head about the effect that any sort of ML/AI work has on me. Tweaking hyperparameters/prompts/features and running it “one more time” is like sitting down at a slot machine for me. Can burn a day without any real work done iterating towards some unreachable perfect run. reply intull 13 hours agoparentprev> ... and this ADHD-ish attitude ... How did \"ADHD\" enter the conversation out of the blue? If you're thinking this is how \"ADHD-ish\" experience is, I recommend you to check out /r/ADHD_programmers where people actually with ADD struggle to figure out how to ship consistently, let alone every day! reply giancarlostoro 6 hours agoparentprevMy attention span is not nearly enough to push releases everyday, but you also need to basically own the QA team. I've worked in enough places that if I don't have a QA team handy, I assume the worst possible environment. Devs get tunnel vision, we make really dumb UI choices, or account for x, y and z scenarios as issues, and forget a, b and c, which happen when the user uses your software while holding a toaster or whatever. This is probably why 2 weeks prints are very common, its enough time to get some things out, enough time for QA to test it, and \"short enough\" that nobody is hounding as to why some feature is taking months. They can at least get it in incremental pieces with 2 week sprints (or whatever you prefer, 1 week, 3 weeks, 4, doesnt matter to me, just be consistent). reply MaxLeiter 15 hours agoparentprevI left off a key point; your code doesn’t need to ship to production, I just think you should do _something_. Thanks for sharing your thoughts. > I can personally say that the satisfaction is far bigger the longer you've persevered. It’s a great feeling to finish something. I find I’m more likely to finish it well if I break it up versus ship it all at once (and my teammates thank me) reply safety1st 13 hours agorootparentI was about to say; if we replace 'ship' with 'commit' I'm in full agreement. If you're a full time developer I don't know why you wouldn't. Commits are communication. If we're making them often and correctly, there's that much less fluffing around with reports and status updates and meetings that we need to do. The merits of CI/CD notwithstanding I definitely do NOT want my reports feeling like they need to deploy every day. That will lead to rushed work and errors on production. But commit, why not? I don't care if it's in a private branch, behind a feature flag, or even some notes/pseudocode in a comment, commit it. Write an actual decent commit message while you're at it. That way as your manager, I can call up your commit history before our 1:1, and by the time the meeting starts it's already 80% finished because I was able to update myself on what you've been doing. reply mewpmewp2 8 hours agorootparentManagers watch commit histories? Haven't ever heard of something like that. reply anbotero 12 hours agoparentprev> IMHO \"every day\" is far too frequent, and this ADHD-ish attitude is one of the reasons why the quality of average software has gone down the drain. Developers need to step back, think more deeply, and not worry about being pressured into \"shipping code\" that barely works. I agree with you partially because I’ve seen this Rush-Driven Development you describe, but with proper gates in place (hooks, Pull Request checks, culture, etc.), this worry mostly disappears in mature teams. I’ve worked on teams where there aren’t Code Reviews if you’ve successfully deployed without errors last 3 times. Like, the system has this information stored, so if you’re trusted and the change is not marked as critical, it will deploy automatically after passing all previous automated checks/tests. It works wonders, believe me, and you can still apply other policies, like error budgets and stuff. I agree some of the other Appearance Driven Development practices sound mostly useless to some, but the reality is that such practices, in my experience, are what made code development explode (in a good way) everywhere. Most people are somewhat social, virtual or in person, so they like to have some notoriety. reply vram22 11 hours agorootparent>seen this Rush-Driven Development Y. Also: s/ush/esume reply flir 10 hours agoparentprevI agree with everything you said. But... Your team (and manager) sees you're working our industry is not rational. reply morgante 8 hours agoparentprevYou're conflating shipping with release. Of course, many tasks take more than a day to do well. That doesn't mean you can't break it up into atomic parts and ship each part every day (behind a feature flag). I personally find the hubris of disappearing into a branch for many days without any feedback incredibly offputting. If you're working on a team, your team should be able to see your daily progress. reply simiones 8 hours agorootparentA day is barely enough time to have even a first go at a more serious problem. Why would you push failed starts into the main branch? And why do you think it's somehow better to have code behind a runtime branch (if) rather than a git branch? reply morgante 8 hours agorootparentYou might not finish a serious problem, but there isn't any problem where you can't check something in. > And why do you think it's somehow better to have code behind a runtime branch (if) rather than a git branch? 1. It's a communication mechanism. Other people on your team should know what approaches you're exploring. 2. It is much easier to review small, incremental PRs than a massive PR dumped at the end of a project. 3. The lift from merge conflicts / integration work is less. reply simiones 1 hour agorootparent> 1. It's a communication mechanism. Other people on your team should know what approaches you're exploring. If they have the time to do that, they can look at a branch as well. > 2. It is much easier to review small, incremental PRs than a massive PR dumped at the end of a project. It's also much easier to entirely lose track of what the purpose of a feature was if you only review it in small, incremental chunks. The chunks often make sense individually, but are a convoluted mess when you look at the full picture. Also, a feature branch should still have many small commits on it, and you can easily review those individually as well, but you also get to look at the whole picture before putting everything in. Not to mention, if it needs to be reverted, much much much easier if there's a single PR with 50 commits instead of 50 disparate commits over 3 weeks. > 3. The lift from merge conflicts / integration work is less. If you pull everyday from the main branch, there's rarely a problem with merge conflicts and integration work, unless someone else is doing a major refactor. And if they are, there is going to be a problem regardless of whether you commit early or late, you'll still have to keep adjusting to their ongoing refactor (and the possibility of ever reverting will be slim to none). reply camhart 15 hours agoparentprevI mean, sure, if shipping everyday means stuff breaks everyday then its a bad idea--that sounds miserable. But it doesn't have to mean that. I'd rather have a culture of shipping frequently and fixing the occasional mistake instead of shipping slowly and moving at the pace of a snail. Thats assuming \"breaking\" occasionally is an acceptable risk. Speed does matter, especially with new products. Shipping frequentily often speeds up the feedback loop which speeds up how fast you learn (and how long it takes to build something useful). There's tons of assumptions in both our comments though, and loads of context thats important. Spend more time on the code for life support systems, healthcare, etc. If its just a bunch of rest API's for a crud app with few consequences if you break stuff, then its okay to live life on the edge. reply jamil7 14 hours agoparentprevWhile I agree everyday is too frequent. Too infrequent release cycles also lead to poorer quality software as the gap between implementing a feature and getting it into user’s hands widens. You generally want that context to be fresh enough in your team’s head that they can quickly fix or improve it. reply begueradj 14 hours agoparentprev> If needing to put on a show for others is more important than actually working, something is very wrong. Then certainly something is very wrong in every single company that exists out there. reply exe34 13 hours agoparentprevme helping a newbie: \"type find....\" him: presses enter me: \"no, don't just press enter, I wasn't done yet, did I say press enter?! oh well, type find dot slash....\" him: presses enter me: \"okay please take your hands off the keyboard! I'll type it for you in the chat.\" reply senkora 13 hours agorootparentI once TA’d an intro to unix class where I had to help a lot of students this way. I would vocalize e.g. “find -name '*png'” as “find space hyphen name space single-quote asterisk png single-quote enter”. I found that saying it exactly like that had the highest success rate. I never wanted to type it for them because the point of the class was to get familiar with unix and the shell. reply exe34 12 hours agorootparentah space might help, I'll try that. i keep having to prefix everything with please don't press enter until I tell you. reply sibeliuss 15 hours agoparentprevThis comment is really quite opinionated! This sounds like your way of working, but there are many ways to work. reply anal_reactor 7 hours agoparentprev> Optimising for metrics never works for those who can see through the illusion, and that's an increasing number of people over time. Adorable. reply richrichie 9 hours agoparentprev> I can personally say that the satisfaction is far bigger the longer you've persevered. Moi aussi. Volume of ejaculate is highly correlated with level of satisfaction. reply ramesh31 15 hours agoparentprevIt doesn't have to be feature work. It can be as simple as a single line bug fix or writing a test. But keeping the pace of doing \"something\" every day, even if you're burned out or stuck on a hard problem, adds up quickly. reply hxii 13 hours agoprevThese, to me, seem like highly invalid reasons to do something and will definitely backfire. Ship incomplete features just so your manager sees you’re working? Sounds like a toxic work environment to me. Fill up your GitHub profile with colors? Seems like a superficial display of smoke and mirrors for those who value such a thing, not for what’s actually beneath the surface of it. I have the “gift” of ADHD, and I’m quite content with learning something, solving a bug, finding something that can help my team, survive through meetings or just close up tickets every day, without the added stress or cognitive load that I have to ship something besides my usual tasks. Strive for progress. Learn by doing. But it’s also fine if you don’t on some days. Don’t burn out. Not worth it. reply zeroq 15 hours agoprev|> Your team (and manager) sees you're working That's one of the greatest corporate flaws and my biggest personal failure that I fail, and refuse, to adapt to. When I work in a team I often try to empower lacking teammates by taking a challanging task, do most of the hard work, and give it to somebody else to finish up the easy part and ship the solution. While working on it they have to understand how the solution actually works (for instance by writing tests), and usually they are happy that they can contribute something bigger than they normally could. I don't mind passing the credit, as long as I know that the person actually made some work and understand the code. Meanwhile I offer myself for help or pair programming (although I'm not really a fan of the concept per se) to kickstart someone elses tasks, helping with architecture or just the general approach to the problem. My coworkes like me, it worked wonders when I was running my own company, yet, when working in BigCo I have to constantly explain myself to higher ups that I'm actually present, not slacking and doing my job, because my jira/github profile doesn't shine. One could say I'm a fool by not building up \"portfolio\" and paving my way to promotion/raise, but I genuinely think that this brings much bigger value in a long run. :) reply cmur 15 hours agoparentthis comment resonates with me. I think it’s a common mistake for a lot of folks to forget that programming is a creative task, and creative tasks rarely fit into metrics effectively. I have a bad habit at my place of work for not ticketing things out correctly and pushing larger than average commits. reply zeroq 6 hours agorootparentAt one point I just realized that the work in BigCo has very little to do with actual value, and much more politics and PR. In my last workplace we had two teams working on almost identical applications - large, multistage web forms for insurance. At that time it was a common practice at the office to estimate in units of time. One team was constantly commiting sprints to 300 units and delivering 200, and the other was commiting to 100 and delivering 150. First was quickly disbanded and fired, and the latter was praised for performing beyond expecations. reply storoj 8 hours agoparentprev> do most of the hard work, and give it to somebody else to finish up the easy part and ship the solution once I realized that the hardest part is actually _finishing_ reply Hasu 5 hours agorootparentMaybe for you. I'm terrible at starting projects and the beginning of them, but I love getting all the pieces in place and getting the product/feature to a production-ready state. It's easy and natural for me. I used to work closely with a \"starter\" who is great at getting the activation energy to start, and we made a great team. Find yourself a \"finisher\". reply euroderf 13 hours agoparentprevAlso, as a senior employee, I found that just general technical and even organizational troubleshooting was difficult to quantify or even justify (in formal management-style terms), and did not really form any kind of \"portfolio\". Oh well. reply imiric 13 hours agoprevOr don't. The older I get, the more I find the obsession with work and hyper productivity to be pointless. This might be good advice for young people starting their careers, but even then I would advise prioritizing real life goals over work. Don't buy into the entrepreneur ideals you see on social media. People can be successful without working all day, everyday. Take rests, prioritize your health, and enjoy life first. Work is secondary. reply zeroq 6 hours agoparentI don't blog, but blogging is something I carry on my todo list for years. Knowing how important is the cadance to keeping the public engaged I always planned to post at most one post per month, and keeping a steady backlog of articles for at least 6 months in case I won't be able to come up with something new or simply not having time to add something new. reply Dachande663 8 hours agoparentprevThis reflects my own changes. Me at 25 and me at 35 are completely different when it comes to code. I'd rather finish early, spend time with family, and come back tomorrow with a better solution than keep on hammering away on an overnighter to try and hit some arbitrary metric. reply cantSpellSober 6 hours agoprev> contribute something: docs, triage, whatever > whatever you work on doesn't need to \"ship to prod\" The author walked that back pretty quickly. My understanding is \"ship to prod\" is redundant, \"shipping\" means \"ship to end-users (in prod)\". I guess \"do your job on the days you're expected to\" isn't great clickbait. reply tppiotrowski 16 hours agoprev> The satisfaction (and mental benefits) of getting something done I used to think that motivation would come to me if I just waited long enough but I now believe that action breeds motivation. You need to do something no matter how small and your motivation will benefit from it. reply PullJosh 15 hours agoparentTotally agree. I’ll also add that although I am often tempted to work alone, sharing my work or ideas or output with someone else boosts motivation a lot. reply kgeist 7 hours agoprevOur team is slowing down instead. The quality of the code has become so poor, full of bugs and what not, that we have decided to slow down and instead invest in quality. We currently spend so much time fixing bugs and refactoring spaghetti code to shoehorn the next shiny new feature, that the amount of actually useful features we deliver has decreased. Half-assed features which work on paper but totally unusable for users because we're still at MVP where nothing really works but the PM is happy because he can report to CEO we shipped another cool feature. It's actually quite demotivating to learn that no user actually uses the feature you developed because it's total crap. Yes, we shipped often, but we shipped crap. Now we focus on writing more tests and doing more design reviews. reply fefe23 11 hours agoprevI find the reasons why he's advocating that interesting. It's got for his mental health, it looks good to recruiters, it makes the work more incremental (wat?), and it gives him a dopamine hit. Notably absent are reasons that would benefit the project or product. To me checking something in every day does not look impressive. It looks like someone had nothing to do worth talking about and went around the neighborhood cutting off leaves from the hedges. Causing a lot of transactions is a great way to stop people assigning you actual work. I suspect OP forgot to mention that reason. You already look busy without actually being busy. It's like managers scheduling useless meetings. They want to look busy so nobody gives them actual work to make them actually busy. reply TeMPOraL 8 hours agoparent\"Mental health\", motivation (\"dopamine hit\") and even incremental work all benefit the project, by helping them work consistently, and keep them focused - as opposed to coasting and doing not much, and/or getting burned out further. Some people have large inertia when it comes to doing things with delayed gratification (if at all), and ideas like this help. reply nicbou 5 hours agoprevThis doesn't make sense to me. Sometimes I need to sit down with a problem for a few days before I can even get to writing code. There is nothing to ship because I'm still wrapping my head around the business logic. On other days I get nothing done because the most productive thing I can do is rest, or tend to personal matters. That doesn't mesh well with hustle culture, but it contributes to my personal happiness and long term productivity. reply hollerith 5 hours agoparentI think some developers cannot create and refine a mental model of the finished product well enough for it to be worth it for them to spend days doing it. Also, many managers perceive only writing code as worthwhile. reply harwoodjp 15 hours agoprevIt’s actually off putting if you check out a potential employer’s GitHub and it’s filled with obsessive committers, obviously working late hours, weekends, holidays, etc. reply seoulmetro 15 hours agoparentOr just pretending to work, as is more often the case if there's no empty days. reply imiric 13 hours agorootparentEven worse: I've seen profiles that run scripts to generate fake commits for the sole purpose of making their GitHub stats look like they're working. Absolutely asinine, and a huge red flag when hiring. reply lee 5 hours agoprevI've experienced being on teams where PRs and commits happen infrequently, resulting in massive PRs and merges/rebases that constantly have conflicts. The spirit of pushing small incremental changes on a team really helps address that. This can be sustainable if everyone on the team realizes that every PR is expected to be small and incremental. It shouldn't be a large push every time. reply sibeliuss 15 hours agoprevMy personal take is to ship a PR every day, even if its something small. Its been a very good practice that has enabled and taught much over the years. reply kristjank 9 hours agoprevI noticed the same rush when consistently journalling and keeping track of my habits. There is something commit-like about checking in on yourself, even if it's not even remotely code-related. I also think it builds a well-maintained framework that you can attach other (especially time management) chores to. (Well, I'm already at my desk for journalling, let's also write down other tasks I need to do today/tomorrow and get started with the first one) I'm not quite sure whether it's really important to keep your github bathroom wall green, but it builds a quite useful habit imo. reply dailykoder 9 hours agoparentI think what you are pointing out is really really important. All of this \"get SOME work done every day\" is really really good, but (atleast in my experience) you have to separate your feelings from likes or stars on social media. Do it for yourself. Do it because you like to do it. Do it because you can develop your inner strength with it. Sure, github stars and a great commit history might give you a dopamine rush, but so does learning to appreciate the struggle and working through it. It doesn't matter what anybody else thinks about it. Over the past year/months I built a RISC-V CPU in VHDL. It can barely do anything and if I show it to most people they'd probably think it's super boring. But I love it. I love to work on it. I love to let the LEDs blink the way I wanted to, because I achieved to implement some small thing in hardware and see that it works (imagine my dopamine rush the first time it successfully ran gcc-generated code and blinked an LED on actual hardware. That's boring, innit? But I loved it.). It's often a really hard struggle, because the progress is so little, but I learned to force myself to do it, even if I don't want to/don't feel like it, because I know it will bring me joy in the end, even if I hate it for days/weeks. I sitll do it. Same with journaling, as you said. It's all about the habits. Find your habit and do it. reply TeMPOraL 8 hours agorootparentFor some of us, setting habits is hard-to-impossible. Finding a source of \"a dopamine rush\" that's correlated with the work at hand is how we get by. reply notatoad 16 hours agoprevi followed this religiously for a month or two, and found it really beneficial. not necessarily for the product i was building (some of those things i shipped probably shouldn't have been) but for my own motivation. however, i expanded my definition to mean not just software features, i included writing a new help doc as \"shipping\". as long as it was something user-visible and for users in general, and not something for one specific user, it counted. reply kwar13 10 hours agoprevAre we talking about writing code or this is shoveling content on tiktok? reply asp_hornet 8 hours agoparentIt truly is indistinguishable at this point. Its all posturing and optics. reply purple-leafy 14 hours agoprevSpell it with me team B U R N O U T reply TeMPOraL 8 hours agoparentTotally. Some of us can't afford to stop working for a year or two or however long it takes to properly deal with burnout, so we need metods like this to keep our families from going hungry. reply liampulles 11 hours agoprevNo, focus on pushing the right solution. If you hold off pushing code that works but does not solve the correct (actual) problem, that's good. Tracking commit frequency is one step away from tracking lines of code. If this is really the metric of performance, then you are a cog. My take would be: plan upfront consistently. What do you need to do now to unblock the work later? Does the solution make sense? Is there something more useful? Think lots, talk lots, commit sometimes. reply blt 15 hours agoprevThis is only reasonable if internal docs, design notes, research notes, etc. count as shipping. reply pjd7 11 hours agoprevLaughs at a PostgreSQL schema change backfill jobs that need a few days to complete on i4i.16xlarge. Or that time I spent $120k USD on testing some upgrade paths on a dataset in elasticsearch from version 2.4 -> 5 -> 6 -> 7 that took about 5-6 days runtime on imports per upgrade step. reply collinvandyck76 15 hours agoprevI try to do this, but it's often my own dotfiles or other programs I work on. I have a things.app db of different things I want to do for various projects, most of which are not work related. Just committing a new dotfiles script, fixing an existing one, adding a neovim command to automate something, or deploying a container to my vps that i was curious about -- all of that is shipping imho and i get energy from the creative aspect of it. reply __0x01 12 hours agoprevMy final draft is often completely different to my first draft, which I wouldn’t want to ship. Most of the time I only start to see the real shape of the solution after a few days of work. Those iterations each day have value as they propel me toward a solution. But it’s more of an internal type of shipping. I’m shipping to myself. reply Tade0 11 hours agoparentSame here. Every damn time it's only my third idea that is sufficiently correct and maintainable. Unfortunately that means I need to sit and wait before it comes to me. I could go the analytical road and write down all the requirements, edge cases and just tick them off one bu one but that's throughly exhausting. At work more often than not I settle on the second iteration, but that is still slow by some people's standards and incurs tech debt. reply a_petrov 15 hours agoprevAs I'm still a coding noob, I don't ship code as much as I want to. However, I make a simple bullet task list and work on it. Tasks are not necessarily related to coding. It could be a task related to image editing. Initially, I was feeling very bad if I can't finish a task within the time I've set for it. Now I don't feel bad if I can't finish that task on time. I perceive it as a micro-iteration of the task. The trick is to iterate further, until the task is done. While rushing to do a task within a specific timeframe, might be productive in the short-term, I don't see it feasible if you push yourself all the time doing it. I imagine it might reflect on the quality of your work and lead to a self-induced burnout. Shipping for the sake of it, in my opinion, might create some false perception of work being done. In my experience, employers tend to reward that behavior. So maybe the question here would be: why are you shipping in first place? To show off, to boost dopamine through gamifying yourself, or to deliver a piece of work you'll be proud of before going to bed. reply vertis 6 hours agoprevThere are a lot of people here that seem to be taking the view of \"Oh no, it's a toxic to do this. You shouldn't work on the weekend. Why are you doing this just to get attention for your GitHub profile, or what your managers see?\" However, one concept that comes up in research like the book Atomic Habits, is that there's a much better reason to commit code frequently - quantity leads to quality. There's a famous story from the book Art & Fear about a university pottery class. The lecturer decided to grade half the class on the number of pots they produced, and the other half on the quality of a single pot. It turned out that the half of the class focused on quantity ended up producing higher quality pots over time. This is because the group that only had to produce one pot spent the whole time overthinking it rather than actually practicing and mastering their craft. I think this is a much better reason to be committing code frequently and working on your skills every day. We're in an environment where it's a challenging hiring market, so it's important to set yourself apart from others within the industry. Some people have turned their nose up against \"colouring in\" their GitHub profile, but there are a number of psychological effects like \"don't break the chain\" that can be helpful in consistently putting in the effort. Some commenters have mentioned tasks that simply take a long time, but I don't think the author of the original blog post was arguing against that. Rather, he's advocating that you should be continuously working on and improving your abilities. reply wowozizi 15 hours agoprevI would say the better version could be \"do something meaningful every day\". reply d--b 13 hours agoprevBreak something every day. reply securam 8 hours agoparentThat's OK, someone else will have to fix it. If you're churning out a feature a day, then you're to valuable to do \"bug fixes\". reply theginger 11 hours agoparentprevBreak 6 impossible to fix things before breakfast. Then spend the rest of the day fixing them. reply Tao3300 6 hours agoprev> I'm sure people like recruiters look at GitHub profiles, and an empty page isn't a great look. What recruiter is going to see my company's private GitHub repos? reply erik_seaberg 1 hour agoparentThis. Since 2008 I've worked at one company using a Perforce derivative and three others using Gitolite or GitLab privately, but never GitHub. Maybe commit history matters to recruiters, but I've been on a lot of interview debriefs (discussing whom to hire) and it never came up. reply swader999 8 hours agoprevOur customers want release notes and time to test features so we have a monthly cadence. reply szundi 9 hours agoprevOf course the title is a bit overachiever, but I see how toxic is when this is not the goal There should be exceptions though reply dailykoder 13 hours agoprev>Your git commit streak looks good Do people unironically care about this shit? What the fuck man. Stop it. Now. reply MaxLeiter 12 hours agoparentDo I care? No Does my manager? No, but what if they leave and I have a new manager right before performance reviews? I’d hope they don’t care about it, but I assume they’ll see it. May as well make it look nice. Does the random recruiter looking at your resume care? At some point in your career you might be able to afford to not care about this. Most people don’t have that luxury. reply dailykoder 12 hours agorootparentI wouldn't want to work for a company where the manager cares about green pixels tbh. But maybe I have that luxury you are talking about, I don't know reply MaxLeiter 12 hours agorootparentMe neither. But companies (and people) aren’t perfect. Your situation can change any day. reply Tade0 11 hours agorootparentprevPretty sure the first thing that random recruiter is going to do is go \"wow, this guy worked at Vercel. Can we even afford him?\" I get that the market is pretty tight at the moment but strong CV positions have always trumped proverbial internet points. reply asp_hornet 8 hours agorootparentprevIf people invested as much time improving their abilities as they did gaming the system, they might find the problem solves itself. reply TeMPOraL 8 hours agorootparentRight - you fail at leetcode interviews despite your high abilities, and leave programming behind in anger to become a gardener. reply conroydave 16 hours agoprevA side benefit from this is that there is now a prerequisite that your ci/cd pipelines are always operational reply candiddevmike 16 hours agoparentYou could run them every night reply einpoklum 6 hours agoprevThat blog post is an example of insisting on posting something on your blog every day. reply malux85 17 hours agoprevI’ve been doing this for longer than a year now: https://github.com/blackrabbit17 One thing that really helps me is “do nothing time” When I sit down, it’s tempting to fire up a browser, or Spotify or YouTube or something, then spend time faffing about looking for a good song, no no no, this is really just me avoiding the work. I sit down, resist that initial temptation and my mind calms, like a storm clearing, and then I let it calm and little more, and then I can start. That do nothing period is only 2-3 minutes but it allows me to slip into flow state quickly. I recommend to others to try… reply joshuaturner 16 hours agoparent> No contributions on December 19th. smh (I realize this could just be down to timezone differences considering I'm in the US) reply RheingoldRiver 15 hours agorootparentSeveral years ago I was doing something that showed your consecutive-days streak. I lost mine at about 300 days because I flew to Europe and the time zone was calculated from the USA, and on the day of my flight I missed a (US timezone) day. I was so sad lol reply securam 8 hours agoprevAlternative title: Train Yourself To Only Work On Low Hanging Fruits reply llmblockchain 14 hours agoprevA better expression of this idea is, \"No zero days.\" Do something every day. Maybe it's getting up on time. Maybe it's exercise. Maybe it's a bug fix. reply hollerith 14 hours agoparent\"zero-day\" already has a meaning, and that is not it. reply malux85 9 hours agorootparentEven still, \"no zero days\" is a desirable state, so the phrase still holds reply balfirevic 8 hours agoparentprevWTF, zero days are the best days. reply satisfice 15 hours agoprevNone of those are good reasons to ship. I mean if you want to ship but you believe that wanting to is not a good enough reason, none of these reasons are any more persuasive. It is a distraction to ship things. reply seoulmetro 15 hours agoprevIf a doctor told you to poop every day or eat steak every day would you actually do it or would you consider it excessive? Do you really need those inputs to get outputs that mean something? No. \"ship something every day\" is dumb because a day is quite a small piece of time for even small pieces of useful inventive work. Even geniuses don't produce all their things in one day, that would be dumb and geniuses know better. \"ship something every week\" would make sense and leave you open to actual proper work still being done in proper time scales. reply securam 8 hours agoprev [–] In the same fashion: There are around 8 hours in a minimal work day. If if you're not shipping every hour you might want to reconsider your career. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recommends making daily tangible contributions at work, which don't have to be major features or bug fixes.",
      "Benefits include a dopamine rush, increased visibility to your team, encouragement of incremental progress, and an impressive GitHub profile.",
      "Contributions can also include documentation or triage, helping to combat isolation in remote work and providing daily satisfaction."
    ],
    "commentSummary": [
      "The \"ship something every day\" approach in software development is critiqued for potentially lowering quality and promoting superficial productivity through rapid, unreflective iterations.",
      "Critics argue that focusing on metrics like commit streaks can be misleading, induce anxiety, and negatively impact software stability, suggesting that meaningful work often requires more time.",
      "The discussion advocates for a balanced approach to productivity, emphasizing quality over arbitrary metrics, consistent incremental progress, effective communication, and the value of internal documentation and creative projects for sustained motivation."
    ],
    "points": 185,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1718065705
  },
  {
    "id": 40639628,
    "title": "Mastering Clear Communication: Tips from Vicky Zhao's Effective Strategies",
    "originLink": "https://iandanielstewart.com/2024/06/09/engage-your-audience-by-getting-to-the-point-using-story-structure-and-forcing-specificity/",
    "originBody": "Engage your audience by getting to the point, using story structure, and forcing specificity Jun 9, 2024 • Communication • min read I came across this recent video from Vicky Zhao last week and loved her brief summary of how she grew in her ability to clearly articulate ideas on the spot by getting to the point, using story structure from improv, and forcing specificty in sharp, boilerplate phrasing with clever mental models. Highly recommended watch. I loved it so much, I took notes. I’m sharing those here but with some other related advice for writing, reading, thinking, and decision-making folded in. I hope you’ll find it useful as you watch, or re-watch. Get to the point Vicky Zhao recommends following the framework of “the one thing you must know about this topic is …” when you start sharing an idea. Use your language to guide your thinking before you even have chance to ramble. The easiest way to get to the point is to use the word “one.” Start with, “the one thing you must know about this topic is …” It doesn’t have to be a groundbreaking statement. The purpose is to provide clarity and direction for you and your audience. As you continue, you’ll be able to refine the initial statement. This idea is a lot like a McKinsey- or BCG-style Action Title for presentations in Slide Decks. An action title is like the “So what?” statement for your slide that captures the singular point and key takeaway of what your slide is all about. Conventional title Action title Survey results Survey output indicates main root cause of churn is awareness of better value for money offering. Monthly churn by customer tenure Yearly renewal prompt found to be strong driver of churn Overview of churn management initiatives Based on current performance and required implementation efforts we have identified 11 initiatives to initiate in the short run Sales in M USD and number of widgets sold Widget market in US is estimated to be 907 mUSD with 5.1% growth p.a. but with DtC segment in decline Providing this at the top of a slide — just like starting with “the one thing you must know about this topic is,” — frames the whole presentation you’re making, grabs your audience right away, and helps them evaluate and understand everything you’re going to say next. Lately, I’ve been doing this even in my Slack communication, leading with a tl;dr or something like Dharmesh Shah’s communication with Flashtags and then following with a short, bullet list expansion of the statement. You can also follow this framework when it’s you who is the audience. If you’re reading a non-fiction book, follow Mortimer Adler’s advice on How to Read a Book. Read the book backwards, read the index, and skim the whole book — before you even consider reading it. This lets you absorb the main thesis, the “one thing”, and better understand the arguments to follow. Add story structure Sharing ideas in the framework of a 3-line scene will help you think on your feet and get your point across. Line 1 The first line sets the scene and you already have this in place if you’re starting with “the one thing you must know about this topic is …” This will put everyone on the edge of their seat eager to know more. Line 2 The second line adds depth and you can add depth in two ways. First, you can go deeper with statements like, “What I mean by X is …” and follow up with an explanation of your “one thing.” Or you can add depth by introducing a surprise — something that people wouldn’t know by staying on the surface. Introduce a “BUT the surprising thing about X is …” statement that adds a surprising wrinkle to the “one thing.” This really puts people on the edge of their seat. Line 3 The third line answers the question, “What’s next?” and you have two options for resolution here. First, you can open the conversation with a Question, “And the question is X — discuss.” This will propel you into a discussion and contribution phase. Or, you can close the conversation with an Answer by using the phrase, “And it’s because … X.” This 3-line scene framework of setting the stage, introducing a new wrinkle, and then swinging into a resolution phase follows the structure of all great storytelling. The Story Spine is a great example of what that looks like in a structure we’re all probably more familiar with. Once upon a time there was ______. Every day, ______. One day ______. Because of that, ______. Because of that, ______. Until finally ______. The Story Spine with optional moral via Sketchplanations. You’ll find stories like that set up everywhere. Even in UX Design. Be specific Specificity forces articulate communicaiton. The advice above uses set phrases to introduce specificity like, “The one thing you need to know about this topic is …”, “What I mean by X is …”, “But the surprising thing about X is …”, “And the question is …”, “And it’s because … X.” To practice being more specific use Via Negativa: talking about what something is not rather than what it is. Sometimes it can be really difficult to articulate exactly what something is but it’s easier to say what it’s not. When you’re on the spot and under pressure, using Via Negativa can really help you rethink what you’re trying to say, and focus in on the specific things people need to understand. This is also just great advice when you’re not on the spot and trying to check your own thinking. I’ll leave you with the advice of legendary investor Charlie Munger here in his famous speech at Harvard in 1986, How to Guarantee a Life of Misery, and expanded version of Johnny Carson’s similar speech to the Harvard Class, which itself is Via Negativa in action. His recommendation to always “invert” reminds me of it most though. What Carson did was to approach the study of how to create X by turning the question backward, that is, by studying how to create non-X. The great algebraist, Jacobi, had exactly the same approach as Carson and was known for his constant repetition of one phrase: “Invert, always invert.” It is in the nature of things, as Jacobi knew, that many hard problems are best solved only when they are addressed backward I’ve also heard this expressed as a way to get to decisions faster. When people can’t decide on a several options you can promote a “bad idea” and watch people start defining better ones in answer to it. Like suggesting McDonald’s as the choice when no one can decide on a restaurant. Suddenly, people can decide pretty quickly in the moment then. 🙂 Share this: Click to share on Facebook (Opens in new window) Click to share on Pinterest (Opens in new window) Click to share on Twitter (Opens in new window) Click to share on Reddit (Opens in new window) Click to email a link to a friend (Opens in new window) Like this: Like Loading… Communication Leave a Reply ←Communicate quickly, seek results quickly",
    "commentLink": "https://news.ycombinator.com/item?id=40639628",
    "commentBody": "Engage your audience: get to the point, use story structure, force specificity (iandanielstewart.com)185 points by ingve 21 hours agohidepastfavorite64 comments danybittel 12 hours agoVicky is not talking about the a story structure. If you followed a story structure, you start with how you've been (I always loved windows), then what happened (I got an automatic update), then piles of problems (The computer wouldn't start, lost some data, couldn't reinstall windows) then the solution (until I installed Linux) the moral (use Linux). Vickys structure is sort of the opposite. Start with the most important part (You should use Linux), go deeper (for example Gnome, for desktop) or add surprise (it's very easy to install), open the conversation with a question (do you use Linux?) or close it with an answer (it doesn't have automatic updates). That's why this blog post is kind of a mess, with conflicting ideas. reply chrisdbanks 43 minutes agoparentMost story structures start with exposition, i.e. the background info. However this is quite boring normally so to get you through that they often add a \"hook\". That's what's being suggested here. So normally a story is hook, exposition, conflict, resolution. That's what's being suggested here, just not very clearly. reply chadcmulligan 11 hours agoparentprevThat's how newspaper articles are structured (the second part you mention), start off with the important bit (there was a car crash no one was hurt) then add more details as paragraphs proceed, if someone wants to know more they keep reading. Of course the web has sort of ruined this, but I'm talking old school newspapers. reply kstenerud 10 hours agorootparentThat's one annoying thing with modern articles. You have to wade through paragraphs and paragraphs of \"John grew up a taxidermist's son and bla bla bla bla...\" before you even get to what the article is supposed to be about. Then you get a couple of on-topic sentences followed by another deluge of fluff. Oldschool newspapers were great because space was at such a premium that this kind of garbage wouldn't happen. reply lencastre 10 hours agorootparentTry reading a recipe for a simple chocolate cake. You get the author’s deep rooted trauma of being that weird kid shamed in HS for some reason as well as over sharing of political stances on the war in Ukraine ending with promoting penny stocks or some MLM pyramid scheme. FFS just give me ingredients and steps. reply kstenerud 9 hours agorootparent\"We can't bust heads like we used to, but we have our ways. One trick is to tell 'em stories that don't go anywhere. Like the time I caught the ferry over to Shelbyville. I needed a new heel for my shoe. So, I decided to go to Morganville - which is what they called Shelbyville in those days. So I tied an onion to my belt, which was the style at the time. Now, to take the ferry cost a nickel, and in those days nickels had pictures of bumble bees on 'em. Gimme five bees for a quarter, they'd say. Now where was I... Oh yeah! The important thing was that I had an onion on my belt, which was the style at the time. They didn't have white onions, because of the war. The only thing you could get was those big yellow ones.\" - Abe Simpson reply BeetleB 3 hours agorootparentprevAlthough people are talking about copyright, the real reason is SEO. If you write just the recipe, your site appears lower in the search results than those with all the fluff (or so it was believed). Ask most of the people who write those recipes - they claim to hate writing all that fluff, and that's why all of them have a \"Jump to recipe\" link. See this, for example: https://www.searchenginejournal.com/google-explains-how-it-r... reply mwcremer 4 hours agorootparentprevRecipes generally cannot be copyrighted. But the filler text, that definitely can be, and is. So if I wrap my recipe in a pointless anecdote, I make it that much harder for The Unscrupulous Gourmet to use a web scraper to steal my recipe. reply krisoft 6 hours agorootparentprev> FFS just give me ingredients and steps. The commonly believed reason is that a simple list of ingredients and steps would not be copyrightable. So they add fluff which can be copyrighted. reply unholiness 6 hours agorootparentI mean it's pretty clearly just to get you to scroll past more ads. You would not need nearly so much text just to qualify for copyright. reply vundercind 4 hours agorootparentI thought it started with the google algorithm rewarding more body text and high linger-time. Sites that just present info concisely are down ranked (then google extracts the concise info from long time-wasting sites and puts it directly on their search page—a whole thriving ecosystem of bullshit jobs, but at least now we can automate every part of that!) reply cainxinth 6 hours agorootparentprevHence the classic newsroom refrain: “Don’t bury the lede!” reply ajuc 10 hours agoparentprevA historian I know rants a lot about the fashion to write historic books in anything but chronological order. There's a lot of machinery in our brains that automatically parse chronological stories for dependencies and correlations. If you break up the order you throw it all away and everything becomes manual. It makes it easier to force people to agree with your interpretation, nothing feels \"off\". It's like writing sequential imperative code vs a bunch of callbacks. Pretty obvious what's easier to debug. reply dehrmann 2 hours agoparentprevDon't bore us, get to the chorus. reply XorNot 12 hours agoparentprevThe second part is the structure I tell everyone to use in presentations - and yeah, its explicitly not narrative. I have a conclusion, so that goes up front - it's the most important part, it goes first. Then the second row rank of assumptions which support the conclusion go next, and only then do you start doing the background on how some of those are reached - if it matters. I find it's as much a writing tool as it is useful for getting to the point quickly with presentations: the goal of presentation is not to surprise the audience, or have a clever twist. It's to be plain, open and honest. (Which is to say, anytime you don't see this structure in any context other then fiction, you're probably being market pitched and what you see is fiction). reply hotdogscout 2 hours agorootparent>the goal of presentation is not to surprise the audience, or have a clever twist. It's to be plain, open and honest. Sometimes it is. >you're probably being market pitched and what you see is fiction Sometimes you are being market pitched. It's all Steve Jobs did yet he's the classic example of good Power Point presentations. reply danielovichdk 6 hours agoprevI was introduced to the STAR framework recently which lays it out like so : Situation > Task > Action > Result Situation: I was asked by my wife if we should sail around the world for a few years. Task: I agreed on the spot now we had to work hard towards looking for possible sail boats that could be our home for a few years and keep us safe while sailing. Action: We travlled around the continent looking at boats, at the same time we saved up as much money we could. When we found a boat we bougt it, sold our house and lived on the boat. We took sailing and navigational classes and used a lot of time researching where in the world we wanted to go. Result: We went sailing on May 17th 2023 and at the moment we are in the pacific helping environmental organisations de-plastic Hawaiian islands. I found it being a good framework getting to the actual point! reply WaitWaitWha 18 minutes agoparentThis is near how I conduct business, as I cannot keep track of everything, nor can I have a non-stop scribe to note and catalog things. AWS and several others use this in interviews. I use STAR/SPAR: [S]ituation or context [T]ask or [P]roblem [A]ction or solution [R]esult or expected outcome Basically, tell me the background, tell me the problem or thing that needs done, tell me all the ways it was reviewed, and the actual picked solution or action, and finally what is the expected outcome or result. As an exec I can be a stateless machine and with that set of details, I can make a decision. Sometimes I dig into it a bit to see if proper due diligence was done, if there is real info & data is present, but once I am comfortable that the person distills it properly, it is a no brainer decision. I can say, \"yes, go forth with your action/solution\" or \"no, because XYZ, go back and consider that\" (usually from the T/PA/R areas). There might be a way to craft this for story telling, after all, most things are stories. reply pandemic_region 4 hours agoparentprevSo, wait, how long from never seen a boat before to yolo sailing around the world ? reply BeetleB 3 hours agoparentprevSTAR, though, is the antithesis of storytelling. reply stevage 5 hours agoparentprevSTAR is the standard thing people are expected to use for job interviews these days. reply bawolff 14 hours agoprevI found myself first agreeing with this, and then hating the examples used. I think the part i liked boils down to: have a thesis and be very upfront on what it is. Everything you say should build up that thesis. To a lesser extent, i also agree with the idea that presentations should (usually) have a narrative structure, but i wouldn't put it the same way they did. But at the same time, when they started to go into examples, everything started to sound click-baity. \"One important thing you have to know about X\" just feels like a click-bait headline. It also kind of assumes that i want to know one thing about X. Maybe i would rather know zero things. The \"why\" is left unadressed. reply another-dave 8 hours agoparent> \"One important thing you have to know about X\" just feels like a click-bait headline. It also kind of assumes that i want to know one thing about X. Maybe i would rather know zero things. The \"why\" is left unadressed. Agree that the phrasing feels a little clickbaity, but don't think it detracts too much. There are scenarios that you can safely assume that someone does want to know about X — maybe you're presenting at a conference or giving a lecture; asked a \"Tell us about a time when…\" question in interview or, as in her example, you're giving a report about what your team did to senior managers. reply bawolff 1 hour agorootparent> There are scenarios that you can safely assume that someone does want to know about X — maybe you're presenting at a conference or giving a lecture; asked a \"Tell us about a time when…\" question in interview or, as in her example, you're giving a report about what your team did to senior managers. On the contrary, i think that is one of the biggest mistakes people make when talking at conferences. It is very important to justify why the audience should care about the specific aspect of the issue you are presenting on. reply ricc 10 hours agoparentprevThis comment seems misleading… The example used was “the one thing you must know about this topic is …”, and I would have agreed with this comment if they forgot the “is …” part. reply logifail 11 hours agoparentprev> everything started to sound click-baity. \"One important thing you have to know about X\" just feels like a click-bait headline \"X important things you have to know about Y. Number N will surprise you!\" reply solatic 13 hours agoprevThere's a latent bias here that any audience can be engaged. That's simply not true. Some stories are told in a medium that is difficult for specific audiences to agree with (I'm thinking here of the difference between people who learn by listening, reading, doing), but some audiences just won't care about the story you're telling. You could be Tolkien himself, but if people you happen to be telling a story to aren't interested in fantasy, they won't engage. Engagement is like dating: be attractive, don't be unattractive, and remember that it's a numbers game. \"Be attractive\" meaning, learn how to tell a good story. \"Don't be unattractive\" meaning, don't make stupid mistakes like not using a microphone and speaker in a large group, or hitting send at 7 PM on a Friday night. \"Remember that it's a numbers game\" meaning, don't spend all your energy on your first audience and get discouraged if they don't engage; just do you and tell your story to as many people as possible until you find those who do engage with you. reply stevage 5 hours agoparentNo, the \"be attractive\" of story-telling is, have a story that's worth telling. The dark side of all this \"how to tell a good story\" stuff is teaching people how to suck up other people's attention on something that is fundamentally unworthy, like marketing drivel. reply hotdogscout 2 hours agorootparentThe attention market is filled with things that are fundamentally unworthy. It's Darwinism at play not an attempt at science. reply mvkel 15 hours agoprevWhenever a video about making a compelling story is per se not compelling, I wonder. The most powerful example would be a meta video that explains the concept within its own content. Like the acronym GNU (Gnu's Not Unix). reply sebstefan 4 hours agoprevI hate when something tries to sell me a framework, like, following the \"stories in 8 steps\" for making concise points, because obviously the question that follows is: Why 8? Why not 7 or 9? If that's just an opinion then I'd rather have it backed by something more than \"it worked for you\" Did it work for you despite this, or thanks to this? Would somebody else's 9 step program work better? Did somebody distill it down to some other more elegant principles that you just happened to follow by doing the 8-step thing? There's never anything rigorous in the realm of marketing & communication courses reply czl 4 hours agoparent> the question that follows is: Why 8? Why not 7 or 9? The reaction you may get: https://youtu.be/rnso4nfdM9w?si=YixDlKDmBXB7xrXc (From \"Something about Mary\" film.) reply aubanel 11 hours agoprevSomething great I've specifically witnessed yesterday: when doing a small request, like ask for a feature request in the team channel, don't just describe a small use case. Instead, provide the bigger picture: e.g. \"I'm currently trying to climb that benchmark, I'm close to the top and only need a few % points that I could get with this new feature\" For me it worked wonders: a PR that I had been awaiting for some time was done overnight by an enthusiastic and helpful coworker! reply kamikaz1k 15 hours agoprevAlmost two decades ago now, I came across a PUA book where the author emphasized the importance of telling good stories, along with some good practical tips on how to structure. I’ve used them regularly to great success. I tried to give this advice to some of my friends for interviews who followed STAR method a bit too rigidly. It didn’t work out…but over time they organically became better story tellers through practice. This is a large tangent, but the post gives good business communication tips. I wrote a more succinct guide for my team, but I think I’ll share this too. Our company suffers from slack disease, so stuff like this can really help. reply hmmmcurious1 15 hours agoparentSounds interesting, which book was it? Im looking for more practical ways to improve communication despite the PUA label. Although you can find many similarities between dates and interviews heh reply skydhash 7 hours agorootparentMy recommendations are On Writing Well and Made to Stick for texts. As for verbal communication, “How to win friends and influence people” helps with the cues and motivations. reply stevage 5 hours agorootparentprevFor sure. I work as a freelancer, and I think there is an awful lot of similarity between dating and engaging new clients. Fundamentally, both sides are thinking \"do I want to spend more time with this person\", in addition to what they concretely offer. reply gumby 14 hours agoparentprevWhat are PUA and STAR? Hard to search for them. reply leetrout 14 hours agorootparentPick Up Artist https://en.m.wikipedia.org/wiki/Pickup_artist Situation Task Action Result https://en.m.wikipedia.org/wiki/Situation,_task,_action,_res... reply SteveDR 14 hours agorootparentprevPick up artist (I think?), and STAR is a technique for answering interview questions reply runamuck 5 hours agoprevI find \"subject verb object\" prose, combined with avoiding all forms of the verb \"to be\" yields clean, active, and easy to read text. reply ChrisMarshallNY 8 hours agoprevThis all seems quite ... familiar. I feel like it's basic common sense. Almost all of my writing and presentation classes -all the way back to grade school- have advocated this kind of thing. Her video is pretty good, though. reply FredPret 16 hours agoprevThe recommended texts are way longer than the originals. Engagement decreases per word written. reply bawolff 13 hours agoparentYes, but i don't think that is the only consideration. After all, if only number of words written mattered, the best thing to do would be to just have an empty slide. Being concise is better than verbosity all things being equal, but not at the expense of failing to clearly get your point across. reply kamikaz1k 15 hours agoparentprevWDYM? The slides? I actually thought they were quite good. reply FredPret 15 hours agorootparentFor example: Original: \"Survey results\" Suggested: \"Survey output indicates main root cause of churn is awareness of better value for money offering.\" My suggestion depending on the context would be: \"Survey: we're too expensive\" or \"Survey: churn due to cheaper alternatives\" which will be read by 5x more people. reply andsoitis 15 hours agorootparent> \"Survey: we're too expensive\" or \"Survey: churn due to cheaper alternatives\" I, for one, think the specificity is worth the extra couple of words. reply FredPret 6 hours agorootparentIt’s certainly better… if you can get people to read it reply AlbertCory 3 hours agoprevThe problem with any hard formula like this is: people twig onto it. When your presentation looks exactly like everyone else's, you've already lost, because you're boring. When Sting was being interviewed by Rick Beato, he said that when he listens to a new song, if he isn't surprised by something real quick, he loses interest. \"If it was easy, everyone would be doing it. Oh wait! Everyone IS doing it.\" reply aaronbrethorst 15 hours agoprevI gave up on the video after about 40 seconds. Get to the point, Vicky. reply nottorp 11 hours agoprevSo... the content is irrelevant :) All that matters is presentation and then you'll have \"engagement\". No need to be talking about anything interesting. reply stevage 5 hours agoparentI realised recently that many of the posts I see on social media that have the highest engagement achieve it through...ambiguity. People interpret the thing differently, then argue about their understanding, creating \"engagement\". Often the ambiguity isn't even intentional, it's just vague communication. reply czl 4 hours agorootparent\"Strategic ambiguity\" can help a political party capture more voters than they otherwise would for similar reasons. Useful because it gives flexibility in decision-making and helps in managing different expectations without committing to a specific course of action. By being vague, leaders can avoid conflicts and keep their options open, allowing them to adapt to changing situations and negotiate better outcomes. Effective in diplomacy and business, where clear, direct statements might limit possibilities or provoke opposition. reply another-dave 8 hours agoparentprevThe post isn't saying that though. It's saying that presentation is important _too_ (which is most definitely is). I think a lot of people can relate to \"I did good work, why is it not landing well?\" > Please respond to the strongest plausible interpretation of what someone says, not a weaker one that's easier to criticize. Assume good faith. reply nottorp 8 hours agorootparentBut what if my interpretation of 'engagement' (and 'content creation' while we're at it) excludes good faith? The way I see it, 'content creation' is all about quantity not quality or having any message/goal. And 'engagement' is about getting people to react emotionally (doesn't matter if positively or negatively) to get them to spam your 'content' to others. reply brainzap 8 hours agoprevenrage your audience reply hotdogscout 15 hours agoprevAs others said, that video bored me and so did the blog post. The hero's journey is not good Framework for a technical talk. Be interesting, create a hook, what do you find interesting? What style draws you in? Emulate that, then branch off. Conversation is a lot more complex and depends on reaction, audience, expertize. Every verbal interaction is a lot like writing. If you're gonna read a book about it it should be How to Make Friends and and Influence People. Corny title but a timeless working strategy for communication. On Writing by Stephen King is fine too but tldr; be honest. reply bawolff 14 hours agoparentIt depends on what you are talking about, but i actually think the hero's journey is actually a good framework for many (not all) technical talks. [I agree the blog post did a poor job selling it] A lot of technical talks are essentially a story on how you (or your team/company/whatever) solved some problem. Essentially you are the hero, and you are regailing everyone with the tale of how you solved some technical problem. That naturally forms a sort of narrative story, that isn't that different from fictional stories where the hero's peaceful life is interupted by some call to action, go through some hardships, and eventually slay the dragon. reply skydhash 7 hours agorootparentYou’re right. But people fails often to define the characters, build the scene, and structure the plot. I’ve been reading some of the books from “Write Great Fiction” series [0] and you can apply the advices to nonfiction too. [0]: https://www.writersdigest.com/wd-books/wgf-plot-structure reply hotdogscout 2 hours agorootparentprevFor one the hero's journey includes resenting the call to action. That makes the hero relatable but is not a strategy you can always easily include in a corporate technical talk. \"Just buy more of last year's product and let me enjoy my vacation, but no, you needed more features!\" If you're horrible at communicating it'll help as it forces you to simplify yourself as a character of simple motivations but it's not a recipe for success or attention or quality content, especially when you kill most of what people found interesting about the Iliad/Odyssey as theatre plays: Violence, Sex, Death, Love, Hate. Death/Rebirth moment would best be embodied as a massive failure and some positions don't allow that kind of honesty or framing without risking your job, although it would indeed be more interesting. The hero's journey is a bread and butter narrative from stage plays from 8th century BC. I'm of the belief that the structure is useless and what engages us are the emotions at display. Even act structures are just an excuse so actors can change clothes during the play - there's no divine insight about writing there. reply bawolff 1 hour agorootparent> For one the hero's journey includes resenting the call to action. Which is super common in tech talks. Tech talks often have the form: there is some legacy solution we tried really hard to make work, but eventually we realized that despite all the hacks to make it work for us, it simply wasn't viable so we did something else. reply Barrin92 11 hours agoprev [–] The only thing one should care about is to speak in your own voice. All these MBA cookie cutter slide deck presentation styles that introduce phrases or 3 part structures just mean you're on autopilot. I find nothing more off-putting than hearing someone give a talk and you can precisely pinpoint where they just start to borrow phrases or go down some generic list of items. reply jononor 11 hours agoparent [–] In my opinion that misses out on some critical steps: 1) Think about the purpose of the communication, the goals. 2) Consider the audience, their background and communication preferences reply Barrin92 6 hours agorootparent [–] the problem with focusing on the audience is that we're in an age where people are already over-obsessed with reception, it's no accident that the title of this post starts with \"Engage your audience...\" and deals almost exclusively with structure and how to say things rather than substance. Much more interesting these days to look for people who write for themselves and take an audience as it comes rather than trying to optimize for engagement. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article highlights communication strategies inspired by Vicky Zhao's video on clear articulation of ideas.",
      "Key techniques include starting with a clear main point, using a 3-line story structure, and being specific with set phrases and the Via Negativa method.",
      "These methods aim to improve writing, reading, thinking, and decision-making by ensuring communication is clear, engaging, and precise."
    ],
    "commentSummary": [
      "The discussion emphasizes effective audience engagement through concise communication and structured storytelling, contrasting different approaches like starting with the main point versus traditional story structures.",
      "It highlights the importance of clear presentations using frameworks such as STAR (Situation, Task, Action, Result) for clarity and quick decision-making.",
      "The conversation underscores the balance between brevity and clarity, the role of engaging presentation styles, and the effectiveness of storytelling techniques like the hero's journey, ultimately valuing genuine emotion and personal voice over rigid structures."
    ],
    "points": 185,
    "commentCount": 64,
    "retryCount": 0,
    "time": 1718056513
  },
  {
    "id": 40643167,
    "title": "Why Gleam V1 is Winning Over Developers with Its Type-Safe BEAM Integration",
    "originLink": "https://christopher.engineering/en/blog/gleam-overview/",
    "originBody": "Exploring Gleam, a type-safe language on the BEAM! Published on Saturday, June 1st, 2024 🇫🇷 Article disponible en français From Erlang, to Elixir and now, GLEAM!? If you know me, you’d probably say, “Omg Chris, yet another new language???!!!“. The truth is, this is the only way I found to keep my motivation as a software engineer. A new language means a new way of both building and thinking. I’m trying to stay open-minded when it comes to my craft. I’ll just get the best out of this new experience and move on. In this article, I’m going to talk about Gleam, how I found it, and why I’m already LOVING it. How I heard about Gleam? Gleam V1 launched on March 4th 2024. As a built different engineer, I found out about it back in November 2023, when I started being seriously interested in Elixir. The thing that always kind of put me off regarding Elixir was the dynamic typing. I’m a static typing person; it solves a LOT of common issues in my day-to-day job and provides cool benefits like: Less runtime errors, since the compiler YELLS at you when something is wrong about your code structure. Trust in what goes to production, since it was approved by the boss (the compiler). Code with typing indications is often (not always, but still, often) clearer and easier to understand. If the documentation is incomplete or non-existent, you still have something to go by, and new engineers can start contributing faster. Coding by thinking about the data structure FIRST, and then, the implementation matches my thinking process. Anyway, you get it, I a type-sexual. So, one day, I was googling “Static typing elixir”, and I saw Gleam in the results. What did I do? I just ignored the thing and moved on. WHY ? Because I’m more mature than ever. Like look, I did my due diligence on Gleam: adoption, use cases, versions (it was on v0.something), and I wasn’t impressed. I thought that Gleam was super early, a cool gimmick, an experimental toy, but it stayed somewhere in my brain, in the box where I put the stuff I might get into, but not RIGHT NOW. What Gleam brings to the table Fast forward, it’s March 1st, 2024: Gleam is officially on V1. I read the changelog, I get the SDK to play with the language and folks… the vibes are IMMACULATE. I’m starting to regret the time I had the occasion to be involved super early (I know it’s dumb), but as they (idk who’s “they”) said, better late than never. I’ll go through the features I love the most and tell you what I like, and what can be better. Types and structures I think it’s BEAUTIFUL, like: type Vehicle { Car(make: String, brand: String) Skateboard(brand: String) Spaceship(year: Int) } What you’re seeing here is a Gleam custom type or Record, with Vehicle being the type’s name, Car, Skateboard, and Spaceship being the constructors available for this type. This is basically a tagged union, or if you prefer, some sort of enumeration, where each member gets its own set of attributes. It’s being used like: let my_car = Car(\"Honda\", \"Civic\") and it allows pretty cool structures, like this cute pattern matching: fn get_driving_requirements(vehicule: Vehicle) -> String { case vehicule { Car(make, brand) -> \"To drive the car \"make\" \"brand\", your need a driver licence.\" Skateboard(brand) -> \"Anybody can ride a \"brand\" skateboard!\" Spaceship(_) -> \"You need to be a NASA astronaut for that!\" } } Let’s spend some time on the function above: get_driving_requirements takes only one Vehicle type argument and returns a String. Both Gleam’s compiler and LSP will let you know if any of those conditions are not respected. Specifying what a function returns in Gleam is optional; due to type inference, Gleam will understand it anyway. In the function’s body, you can see the case structure. This is how you perform pattern matching, which is essentially a switch control on steroids. Using a case, you can execute code path if a specific pattern is matched for a given variable. It’s pretty crazy how deeply you leverage this technique. In my example, I check every possible constructor for the vehicle variable. Once again, the tooling will alert you if your pattern matching is not exhaustive (safety first!). It’s super expressive, the code is concise and elegant (to me). Gleam’s tooling… …is CRAZY. Like, crazy CRAZY. I spent so much time in the cursed lands of Javascript that I forgot grass could be THIS green elsewhere. The only thing you need to do it to install the gleam CLI. To do so, I used asdf, but you can do the same using any other package manager like Homebrew. What does the gleam command do? Check this out: ❯ gleam gleam 1.2.0-rc1 Usage: gleamCommands: add Add new project dependencies build Build the project check Type check the project clean Clean build artifacts deps Work with dependency packages docs Render HTML documentation export Export something useful from the Gleam project fix Rewrite deprecated Gleam code format Format source code help Print this message or the help of the given subcommand(s) hex Work with the Hex package manager lsp Run the language server, to be used by editors new Create a new project publish Publish the project to the Hex package manager remove Remove project dependencies run Run the project shell Start an Erlang shell test Run the project tests update Update dependency packages to their latest versions Options: -h, --help Print help -V, --version Print version package manager ➡ gleam add repl ➡ gleam shell test runner ➡ gleam test formatter ➡ gleam format lsp ➡ gleam lsp and more… All you need to get started with Gleam is already in this CLI. You dont’t have ANYTHING else check, there’s ZERO decision paralysis: THIS-IS-WHAT-WE-WANT. Javascript makes you pick a tool among hundred of options, for each tool provided in Gleam’s CLI. One more thing: each language version comes bundled with its own set of tools; to prevent tooling incompabilities. Let’s reuse the previous example: import gleam/io /// This is some type related to type Vehicle type Vehicle { /// Car type used for... a car I guess... Car(make: String, brand: String) Skateboard(brand: String) Spaceship(year: Int) } fn get_driving_requirements(vehicle: Vehicle) -> String { case vehicle { Car(make, brand) -> \"To drive the car \"make\" \"brand\", your need a driver licence.\" Spaceship(_) -> \"You need to be a NASA astronaut for that!\" Skateboard(brand) -> \"Anybody can ride a \"brand\" skateboard!\" } } pub fn main() { get_driving_requirements(Car(make: \"Hyundai\", brand: \"Kona\")) io.println(\"Hello from gl_playground!\") } When I hover my mouse vehcule in my function body, I’m seeing: LSP is capable of getting both type and documentation related to the variable. Another exemple if, what happens when I hover on the Car constructor: Here, the LSP shows both the parent custom type’name and the associated documentation. One last example, when I hover on brand, for the code block executed when Skateboard is matched: The LSP understands that brand is the first attribute in Skateboard. This is the attention to details that makes you love an ecosystem. It helps you ship quality code, and it drives the language adoption up: this is a true win-win situation. OTP implementation Earlier, I told you that Gleam runs on the BEAM (never said that tbh). BEAM means Erlang, and Erlang means OTP. Please, sit down and relax, cuz I’m about to try to tell you what OTP is about. OTP (Open Telecom Platform) is an architecture (and some kind of philosophy) for building fault-tolerant and highly concurrent software. The key principle is to divide a program into small execution units called processes (unrelated to OS processes) and making those processes communicate through message passing. Those processes can die at any time for any reason, so OTP advise you to put them under a supervision tree, so that a supervisor (which is also a process) can restart them. Erlang and Elixir give the developer the abstractions needed to build on top of OTP, with the BEAM allowing you to run MILLIONS of processes, even on a tiny server. Dang, I really gave my everything on this one, but now you kind of know what OTP is. That being said, Gleam also has its own OTP primitives, using an external official package. The abstraction I used the most is the actor (btw, you should learn about the actor model; this thing is CRAZY). Let me show you how this works: import gleam/io import gleam/int import gleam/erlang/process.{type Subject} import gleam/otp/actor type AsyncTaskMessage { Increment(reply_to: Subject(Int)) Decrement(reply_to: Subject(Int)) } fn handle_async_task(message: AsyncTaskMessage, state: Int) { case message { Increment(client) -> { let new_value = state + 1 process.send(client, new_value) actor.continue(new_value) } Decrement(client) -> { let new_value = state - 1 process.send(client, new_value) actor.continue(new_value) } } } fn start_async_task(state: Int) { actor.start(state, handle_async_task) } fn main() { let assert Ok(actor) = start_async_task(0) let response = actor.call(actor, fn(subject) { Increment(subject) }, 10_000) io.println(\"New value: \"int.to_string(response)) } For a Gleam actor, you need a few things: A custom type for all kind of messages your actor can receive. It’s called AsyncTaskMessage in this example. A function which takes a message and a state (the state being whatever you’d like) and returns a new state, or something indicating that the task should end. This is handle_async_task in our example. A function starting everything. In our example this is the start_async function. With all of these pieces, you get a new stateful process that can live on its own. You can send messages for it to do… stuffs, I guess. Yeah, I know the demo is kind of lame, BUT it shows you how powerful Gleam’s type system is when coupled with OTP. You cannot send any message to your process that isn’t type-checked AT COMPILE TIME! Something less cool, is the fact that OTP isn’t fully ported to Gleam. Few features, like Registries are missing… Lustre, a curious web framework YEAH, I KNOW, another new web framework. You have to understand, a new language needs that kind of popular tooling. Some people (web devs) are waiting for it. Lustre is a Gleam web framework. It’s been around in Gleam ecosystem for a long time and I think, is mature in Gleam’s context. I didn’t tried it yet, (it should be one of my next article), but we’re talking about a tech with a lot of cool features: It’s isomorphic, it’s running on both backend and frontend. It’s heavily inspired from Elm, this scary thing we got from weed smoking Haskell geniuses (this is a compliment, huge respect for them). It’s opinionated, from an app to another, you supposed to see the same conventions and code structure. I’ll let you check the documentation and see if it’s something that you’d be interrested in. Javascript, interoperability I JUST TOLD YOU!!! Gleam has a web framework and it’s ISOMORPHIC. How does it run on web? It runs because Gleam can transpile to Javascript. This is an interesting strategy. They are trying to convince the easiest crowd: Javascript developers. Those people (me, I’m “these people”) are tired of Typescript / Javascript nonsense. They’re looking for simplicity, robustness and Gleam has all the tool they need for that. There’s few players in this space, like ReasonML and ReScript. Check the code below: import gleam/io type Vehicle { Car(make: String, brand: String) Skateboard(brand: String) Spaceship(year: Int) } fn get_driving_requirements(vehicle: Vehicle) -> String { case vehicle { Car(make, brand) -> \"To drive the car \"make\" \"brand\", your need a driver licence.\" Spaceship(_) -> \"You need to be a NASA astronaut for that!\" Skateboard(brand) -> \"Anybody can ride a \"brand\" skateboard!\" } } pub fn main() { Car(make: \"Hyundai\", brand: \"Kona\") |> get_driving_requirements() |> io.println() } This snippet is quite at exposing Gleam’s key features, there’s types, pattern matching, pipe operator… See below the Javascript output after running gleam build --target javascript: import * as $io from \"../gleam_stdlib/gleam/io.mjs\"; import { CustomType as $CustomType } from \"./gleam.mjs\"; class Car extends $CustomType { constructor(make, brand) { super(); this.make = make; this.brand = brand; } } class Skateboard extends $CustomType { constructor(brand) { super(); this.brand = brand; } } class Spaceship extends $CustomType { constructor(year) { super(); this.year = year; } } function get_driving_requirements(vehicle) { if (vehicle instanceof Car) { let make = vehicle.make; let brand = vehicle.brand; return ( \"To drive the car \" + make + \" \" + brand + \", your need a driver licence.\" ); } else if (vehicle instanceof Spaceship) { return \"You need to be a NASA astronaut for that!\"; } else { let brand = vehicle.brand; return \"Anybody can ride a \" + brand + \" skateboard!\"; } } export function main() { let _pipe = new Car(\"Hyundai\", \"Kona\"); let _pipe$1 = get_driving_requirements(_pipe); return $io.println(_pipe$1); } The JS code you’re getting is super understandable. You can read it, debug it and understand how Gleam transforms Gleam code into Javascript code. There are two important imports: $io, which is library that matches what we have in the std lib gleam/io. CustomType, which is a class imported from prelude.mjs, that contains stuff Gleam needs when operating in a Javascript context. What’s next with Gleam We spoke briefly about everything interesting with Gleam. As you may have noticed, there’s nothing that I dislike, for now. I’ll keep experimenting while doing CodeCrafters puzzles (sponsored link). I’m currently building my own Redis with Gleam. Hit me up on Twitter or Twitch if you want to talk about it. All rights reserved © Christopher N. Katoyi Kaba - 2023",
    "commentLink": "https://news.ycombinator.com/item?id=40643167",
    "commentBody": "Exploring Gleam, a type-safe language on the BEAM (christopher.engineering)177 points by crowdhailer 12 hours agohidepastfavorite79 comments rkangel 6 hours agoI'd like to clarify a little what the OTP is vs the BEAM - this article does an OK job at that explanation but confuses it a little. The BEAM is the underlying VM used by Erlang, Elixir and Gleam. The BEAM provides the basic primitives like spawning processes, sending messages, handling messages etc. Processes are lightweight pre-emptively scheduled tasks, similar to go-routines or green-threads in other languages. These primitives are mostly lower level than you want to deal with on a day to day basis. The OTP is a standard library built on top of that, to provide a convenient, battle-tested way of building systems. The GenServer is the most well known component - it simplifies writing code that handles messages one by one, updating held state, and sending replies. And bits around it to the caller, sending that message and getting to the reply is just like making a function call. GenServers are then managed by Supervisors that know what to restart when something crashes. One notable difference between Elixir and Gleam is that Elixir gets to just re-use the OTP code as-is (with some Elixir wrappers on top for convenience). Gleam concluded that the OTP is built expecting dynamic types, and that for best results in Gleam they'd need to re-implement the key primitives. That's why the example shown is an \"Actor\" not a GenServer - it serves the same purpose, and might even fit in a Supervision tree, but isn't actually a GenServer. reply llcoolchris_ 5 hours agoparentThanks a lot for the missing context! Explaining OTP is not an easy task!!! reply benrutter 9 hours agoprevEvery time I see gleam examples I'm filled with calm, it seems like a very nice language to use. I'm a data engineer so unless I feel like doing a lot of library development, I'll probably wait on the data ecosystem to advance a little bit more. I hope it does some day, the BEAM feels like the perfect place for a distributed dataframe library to live. reply gigatexal 6 hours agoparentSame here. Data Eng by day but looking to move away from Python but Go and Rust i dunno doesn't feel like a good replacement for it plus the Python ecosystem in the data space is huge. reply perrygeo 6 hours agoprevWhat I find very fun about Gleam is its minimalism. You've got functions, types, a case expression, and modules to organize them. That's it. No inheritance, no methods, no ifs, no loops, no early returns, no macros. And yet it's fairly productive and ergonomic to write. For the most part, Gleam feels like it has gathered the best ideas from some interesting langs (perhaps a chimera of Rust, Go, ML and Lisp) and put them into one coherent, simple language. It's not that the ideas are new, they're just very well organized. Gleam's labelled arguments are AFAIK a unique feature. (Edit: Nope see comments below) This lets you have named function argument appear differently to the caller than they do internally. The caller may way to refer by verb (\"multiply_by\") and the function may want to refer to it as a noun (\"multiplier\"). The `use ` can reduce boilerplate with nested function calls in a lot of cases. It's a nod to the ergonomic benefits of metaprograming without giving the user a full macro system. Finally Gleam's tooling is the best in the business, hands down. The entire language, the compiler, package manager, LSP, etc, is all built into a single binary with an ergnomic CLI. Compared that to cobbling together a python environment or pretty much any other language where you need to assemble and install your own piecemeal toolkit to be productive. Very excited to try Gleam more. reply _flux 6 hours agoparent> Gleam's labelled arguments are AFAIK a unique feature OCaml also does this: # let foo ~bar:baz = baz + 42;; val foo : bar:int -> int =# foo ~bar:12765;; - : int = 12807 What I really enjoyed was its parameter forwarding, which is available in some languages for records: # let bar = 42;; val bar : int = 42 # foo ~bar;; - : int = 84 Works similarly for optional values: # let test ?(arg=5) () = arg;; val test : ?arg:int -> unit -> int =# let arg = None;; val arg : 'a option = None # test ?arg ();; - : int = 5 And if you used ~arg, it would be a non-optional parameter: # let arg = 5;; val arg : int = 5 # test ~arg ();; - : int = 5 Overall pretty spiffy. Partial application also works here nicely, but it does cause some trouble with optional arguments :/. For example, here \"test\" needs to have a final argument () so the optional parameter can be erased: # test;; - : ?arg:int -> unit -> int =# test ();; - : int = 5 reply bfLives 6 hours agoparentprev> Gleam's labelled arguments are AFAIK a unique feature. This lets you have named function argument appear differently to the caller than they do internally. The caller may way to refer by verb (\"multiply_by\") and the function may want to refer to it as a noun (\"multiplier\"). Swift has this feature as well. reply giraffe_lady 5 hours agoparentprev> perhaps a chimera of Rust, Go, ML and Lisp I think it is pretty much just ML on the beam? It resembles rust and go maybe in the ways that they have also been influenced by ML. The syntax is fairly C-like which I guess resembles rust more than ocaml but I think that's surface level. I don't know rust or go but I don't see any concepts in gleam that aren't familiar either from ocaml or erlang. Lisp I don't see it at all, except treating functions as entities in their own right, which is a nearly universal language feature at this point and doesn't ring as particularly lispish to me anymore. reply oDot 8 hours agoprevGleam is a very fun language to write in, and no need to start a project from scratch to explore it I wrote Vleam to help incorporate Gleam into a Vue project, if you have one already https://github.com/vleam/vleam reply liampulles 7 hours agoprevI've explored Gleam on a side project and I like it. The only real issue I had at the time was that it was a bit too niche to use for anything \"serious\", but that seems to be changing - which is cool. I really want to see a demonstration that it can work with Phoenix LiveView though, or a Gleam equivalent with good IDE and tooling support. The productivity of the Phoenix LivewView + Elixir stack, and the ability to build async message-driven systems in concert with the UI remains a killer feature for me. reply kstenerud 10 hours agoprev> Specifying what a function returns in Gleam is optional; due to type inference, Gleam will understand it anyway. Oh yuck, I don't like that. Function signatures are for HUMANS to read. Sure, the compiler can reach into a function implementation to glean what it returns, but that's no reason to force a human reader waste time on it as well. \"I'll accept this and this from you and then return that kind of thing to you.\" vs \"I'll accept this and this from you and then return something to you that your supervisor will tell you if you're using correctly or not - or you could watch me as I work to see what it is I've made for you.\" reply widdershins 9 hours agoparentGenerally the advice is that public functions should have type annotations, and private functions needn't if you don't want to. But I could see arguments for either actually. Sometimes it's a bit of an annoying overhead if it's obvious what the function returns, and it certainly helps make prototyping code feel nice, especially since everything's typesafe anyway. As I said in another comment, as the compiler knows the type of everything, it would be easy to have the LSP overlay the type (or annotate it into the text via code action for you). reply lpil 8 hours agoparentprevI think if I were making Gleam again from scratch it'd be required, them being optional was somewhat inherited as Gleam is an ML family language. Luckily Gleam programmers do write return annotations in practice. reply __jonas 9 hours agoparentprevAs a user of a package, you see the signature including the return type in the generated documenation and in your editor through the LSP which is part of the core language, so it's not really an issue. But I agree that specifying the returns explicitly is a bit nicer when reading the source, don't think it's a big issue that it's optional though. reply kstenerud 9 hours agorootparentBut what if the inference generates a contract based on the narrowest scope of the types returned, and then later you add a wider type (because that's what you'd originally intended but didn't have any actual use cases at the time) and now everyone's code blows up because they assumed the narrower type and don't handle the wider one? If you were forced to specify the return type, your original intent becomes clear for all (rather than leaving it to a machine that can only assume the narrowest scope). reply __jonas 9 hours agorootparentIt won't, because there is no type narrowing in Gleam currently, the type system is also very different to something like Typescript, I just don't see what you are describing as something that could realistically happen, but if you have an example I would be curious. If the return type changes, the code using the function should definitely blow up until it's changed, don't think that's a bad thing. reply scns 7 hours agorootparent> If the return type changes, the code using the function should definitely blow up until it's changed, don't think that's a bad thing. This. The big upside of algebraic data types. The function won't blow up though, the compiler shows you every piece of code where the added type needs to be handled and therefore ensures the program runs correctly. reply lpil 8 hours agorootparentprevGleam doesn't have subtyping, so this drawback is impossible. Its type system is similar to OCaml, Elm, F#, etc. reply danybittel 9 hours agoparentprevI usually also like type annotations for return types. The problem I'm having with my PL is with generics: If the return type depends on T but is not T. If I infer the return type it's obvious. reply valenterry 7 hours agoparentprevWith the right tooling, this is a non-issue. Compare with Scala, a language that also allows you to omit return types (except for recursive functions). IntelliJ (the best Scala IDE) now has something called X-Ray mode, see the videos here: https://blog.jetbrains.com/scala/2023/12/21/the-x-ray-mode/ Alternatively, it also allows you to configure it to always show the inferred types on functions. Before, I annotated things a lot, but after having this I've never felt the need to annotate functions ever again. I still do it for certain things though but for other reasons than readability (e.g. for type-driven development). reply k_bx 10 hours agoparentprevVery often in Elm/Haskell would I write the code first, then let my IDE insert the type annotation. Not always perfect, but often the case. reply ThinkBeat 8 hours agoparentprevA seriously important point you make. The little bit of time it takes to annotate the type that the function returns will save a lot of time when other people take over the codebase. Humans are not great compilers and spending time try to figure out what the hell is returned from a function reply mrkeen 7 hours agorootparent> Humans are not great compilers and spending time try to figure out what the hell is returned from a function That's why I leave it to the compiler and don't try to do it as a human. reply thunky 5 hours agorootparentIf you aren't able to figure out the return type then something has gone wrong: maybe the language or code is too complex, or maybe you don't understand the code very well. reply mrkeen 1 hour agorootparentAs was said above, humans aren't great at it. If I want to know the type of an expression, I ask the compiler. reply benrutter 9 hours agoparentprevHonestly, on this one, I see both sides. I think functions should be written so that there type signatures are readable in the code, but I'm not sure I want a language making something semantically incorrect just to discourage bad style. Either way, I use (and honestly love) python on a daily basis and I wish my gripes with it were on this small a level. Yes, I'm looking at you, passed by assignment and late binding closure. reply viraptor 9 hours agoparentprevIt's honestly nice when it's optional but with tooling understanding the inferred type. (Both LSP and docs) Sometimes you have a function with a single line implementation and an obvious return (bool or string). Having to add explicit types to everything becomes a bit silly. reply Barrin92 6 hours agoparentprev> Function signatures are for HUMANS to read Nope, exactly the other way around. Function signatures are to help machines optimize your code. What humans should care about are names. It's just that we've normalized an extremely misguided practice of abusing type systems as a crutch for non-descriptive variable and function names. reply itishappy 6 hours agorootparentHard disagree. It's a contract between compiler and coder, and it needs to be exposed to both. Type information does not belong in names. // For example, this: fn get_driving_requirements(vehicle: Vehicle) -> String { ... } // Is just so much nicer than this: fn get_driving_requirement_description_from_vehicle(vehicle) { ... } This is nicer for me (a human) to read, even if the compiler can infer the types of both. reply PartiallyTyped 10 hours agoparentprevDoesn’t gleam come with a linter? If so, it’s likely that that can be enforced. reply widdershins 9 hours agorootparentThe designer of gleam is trying to make a linter unnecessary, by not having extraneous language features that need to be discouraged. Guess it's not working 100% if someone feels this way! However, I would say that since the compiler/LSP knows the full type of every function it should be possible to have a code action that says 'annotate the type of this function for me'. reply kstenerud 9 hours agorootparentYup that would be fine, so long as it's required to be done before you release your code. Putting return types on functions is signaling intent, much like left and right signaling on a car. I want to know what your function COULD produce, not what it happens to produce now. Type inference can only show that in every current path you return a TYPE_X, and that works fine until one day you return an instance of its supertype TYPE_A, and now my code blows up because I misunderstood the contract. You may have always intended for it to return TYPE_A and its subtypes, but you never signaled that intent to others. This is why enforcing explicit contracts is necessary. reply widdershins 8 hours agorootparentWell Gleam doesn't have supertypes, so the function signature (even when inferred) does describe everything your function could possibly produce. If the author changes that, your code will stop compiling, not blow up at runtime. I agree that packages authors really should annotate their types though, and possibly that they ought to be forced to do so, just to make reading the code easier. reply lpil 8 hours agorootparentprevGleam doesn't have subtyping, so the drawback described here is not possible. reply wrsh07 6 hours agoprevI just downloaded livebook yesterday, and it will be a great thing for gleam when you can include code blocks for gleam in livebook. Also, if you're looking to pick up elixir or Erlang, I don't think there's a better tool. It's a jupyter-style notebook that feels really really good reply OutOfHere 5 hours agoprevThe main reason for using a BEAM language is to leverage multicore/concurrency conveniently and reliably. Gleam's OTP seems not as mature as that of Erlang or Elixir. If you want to write simple programs, then Gleam seems okay. If you want mature multicore or concurrent use, then I would think twice. Here is a critical review of the officially listed limitations of Gleam's OTP: 1. Lack of Support for Named Processes: This is a significant limitation because named processes are essential for easy reference and communication between different parts of the system. Without support, developers might resort to workarounds that could lead to errors and inefficiencies. 2. Untyped Global Mutable Variables: The use of untyped global mutable variables introduces potential risks, such as runtime errors and unpredictable behavior, especially since they can be uninitialized. This undermines the type safety and reliability generally expected in functional programming environments. 3. Limited Actor Abstractions: The current scarcity of actor abstractions could restrict developers from implementing more complex or varied concurrency patterns, limiting the utility of the library until more abstractions are added. 4. Unsupported OTP System Messages: Dropping unsupported system messages can lead to unexpected behavior and bugs that are difficult to trace. Full support for OTP system messages is crucial for reliable and predictable actor-based concurrency. 5. Uniform Shutdown Period for Supervisors' Children: Not having different shutdown periods for child processes, especially for child supervisors, can lead to improper shutdowns and potential data loss or corruption. This deviates from the behavior in Erlang and Elixir, where more granular control is available. 6. Limited Testing: The lack of extensive testing, both in unit tests and real-world applications, indicates that the library might be unstable or have undiscovered bugs. This could affect its adoption and reliability in production environments. reply cdelsolar 4 hours agoparentok, chatgpt reply pmontra 8 hours agoprevIt looks like a nice language with the {} syntax to tease all the C and Java developers out there. That's more important than it looks to help spreading the language. The OTP example lets me state one of my few sore points about all the BEAM languages I worked with or looked at: the handle_this / handle_that madness. Search for \"type AsyncTaskMessage\" in the post to get there. I don't want to write code like this (I omit the details, ... are ellipsis from mine) type AsyncTaskMessage { Increment(reply_to: Subject(Int)) Decrement(reply_to: Subject(Int)) } fn handle_async_task(message ...) { case message { Increment(client) -> { code ... } Decrement(client) -> { code ... } ... } I want to write code like this type AsyncTaskMessage { Increment(reply_to: Subject(Int)) Decrement(reply_to: Subject(Int)) } fn Increment(client) { code ... } fn Decrement(client) { code ... } or any variation of that, maybe this OO-ish one (after all this is a stateful object) type AsyncTaskMessage { fn Increment(reply_to: Subject(Int)) { code ... } fn Decrement(reply_to: Subject(Int)) { code ... } } Maybe one of the next BEAM languages will handle that automatically for us. reply lpil 8 hours agoparent> Maybe one of the next BEAM languages will handle that automatically for us. It not being automatic is a feature as that pattern is only what you want in the trivial case, but in real programs you are going to want more control. In early Elixir there was a relatively popular macro library[1] that offered what you ask for (see code example below) but as Elixir matured and started being used in more than toy projects it was largely abandoned. defmodule Calculator do use ExActor.GenServer defstart start_link, do: initial_state(0) defcast inc(x), state: state, do: new_state(state + x) defcast dec(x), state: state, do: new_state(state - x) defcall get, state: state, do: reply(state) defcast stop, do: stop_server(:normal) end [1]: https://github.com/sasa1977/exactor reply pmontra 7 hours agorootparentGreat. That was basically all we used of GenServers in the Elixir projects I worked on. I remember one or two handle_info but nearly all our GenServers were (in OO parlance) objects with methods to update their status, trigger actions and sometimes read the status. reply hjadal 8 hours agoparentprevCould you possibly do this by transpiling to Gleam? Seems like the transformation is possibly simple enough that it could be done without implementing a new language. reply cess11 8 hours agoparentprevNot sure what the macro story is in Gleam but in Elixir you could write Increment/Decrement macros that ties into the process API. Kinda contrived example though. reply simoncion 8 hours agoparentprevYeah, this syntax kinda sucks fn handle_async_task(message ...) { case message { Increment(client) -> { In Erlang to \"just call the damn function\" I'd write it something like handle_cast(R=#message{type=increment}, S) -> work_module:increment(R, S); handle_cast(R=#message{type=decrement}, S) -> work_module:decrement(R, S). Or I'd use maps instead of records. reply dugmartin 7 hours agorootparentIt looks like Gleam doesn't allow for multiple function heads. That is one of my favorite features of Elixir as it reduces complexity. reply simoncion 4 hours agorootparentOh that's very sad! That's one of the great features of Elixir/Erlang. I wonder why they decided to not permit that sort of thing. :( reply Keats 5 hours agoprevHas anyone very familiar to Elixir tried Gleam? I've been eyeing Elixir for years but I would miss types. Gleam looks nice but you lose Phoenix/Liveview which is 90% of the appeal of Elixir to me. reply giraffe_lady 5 hours agoparentI've used both and like both. It's pretty smooth to use gleam code from elixir, so you could implement core data handling and business logic in gleam then still just use phoenix for the webapp layer. But also just try elixir? In a lot of ways it handles like a typed language because of exhaustive pattern match and being able guard/match in function parameters. There's not much practical difference between matching on Some(data) or {:ok, data}. I prefer having types too, but for everything elixir (or erlang for that matter) gives you, it's a manageable compromise. Anyway elixir is getting a type system right now. I like gleam a lot but I'm not sure it's really aiming to be a universal elixir replacement. reply __jonas 9 hours agoprevThis is a sweet blog post, I'm really enjoying Gleam for its simplicity, I'm excited for gleam_otp to mature more eventually reply crowdhailer 8 hours agoparent100% agree with this. Some success stories with Gleam OTP in the wild will be amazing. I'm sure they will come reply agentultra 6 hours agoprevWhy does the author progressively spell “vehicle,” worse throughout this post!? Other than that, Gleam seems pretty neat. Wish it the best of luck. reply j-krieger 7 hours agoprevI love the rust-like syntax. I write a lot of Rust and there have been times where I wished for a language on top of Rust with a tiny bit of OO patterns and a GC, so the borrow checker doesn't get in my way. reply metayrnc 8 hours agoprevThe author mentions lustre, the web framework for Gleam that was inspired by Elm. I really like Elm. However, the limitation for me was the lack of a really robust component library. When I say component library, I don’t mean aesthetics but function. For example, a feature complete search bar with autocomplete, multiselect, create, delete, clear, etc. functionality. The reason I use typescript is because of component libraries like Mantine where generic components such as a search bar are already implemented, fully functional and accessible. I hope someone sees this gap and tries to fill it so that functional languages can be viable on the web! reply hayleighdotdev 8 hours agoparentAuthor of Lustre here! Yeah I agree, lack of a robust headless component library like radix-ui or react-aria is such a mark against Elm. I think it's even more important for Lustre because really all our users are going to be backendy folks with little interest in the nitty gritty frontend stuff. Lustre will eventually have a companion ui library to plug this gap but it turns out maintaining all this stuff is a bit of a time sink, so I'm taking baby steps ^.^ reply lpil 8 hours agoparentprevI believe this is on the roadmap for the Lustre framework. reply giraffe_lady 4 hours agoparentprevReScript is really solid in this niche IMO. It's basically ocaml that compiles to js. The standard library includes excellent bindings to react, so you can use react components without too much extra work. You do have to write your own type annotations for them, but it's way way less trouble than elm ports. reply michaelmior 6 hours agoprev> All you need to get started with Gleam is already in this CLI. You dont’t have ANYTHING else check, there’s ZERO decision paralysis: THIS-IS-WHAT-WE-WANT. Javascript makes you pick a tool among hundred of options, for each tool provided in Gleam’s CLI. This is undoubtedly true, although if Gleam ever becomes as popular as JavaScript, there will almost inevitably be the same set of choices to be made for Gleam. reply zachallaun 6 hours agoparentI'm not so sure. Both Go and Rust seem like examples of very popular ecosystems with a set of common, \"blessed\" tooling. (They didn't have everything from the get-go, e.g. rust-analyzer was very popular before it became part of the Rust project, but it still demonstrates that a large ecosystem can rally around a set of common tooling.) reply michaelmior 4 hours agorootparentThat's a fair point, but I don't think it's really fair to say Gleam has everything necessary included when it's brand new. Because it currently doesn't suffer from the problems of the JS ecosystem doesn't mean it won't in the future. (As another example besides rust-analyzer, there's also all the Go dependency management tools that existed before native Go modules, e.g. Dep, Glide, Go Package Manager, etc.) reply __jonas 6 hours agoparentprev> This is undoubtedly true, although if Gleam ever becomes as popular as JavaScript, there will almost inevitably be the same set of choices to be made for Gleam. Huh? I don't think so at all, Go and Rust did this same thing (include great and easy to use tooling as part of the language), they are super popular now and the tooling is still great. reply michaelmior 4 hours agorootparentGo originally didn't include a great way to manage dependencies. That fortunately got fixed. I think my initial statement of it being inevitable was an exaggeration. My point was that I don't think you can fairly compare a new language with one that has existed for decades as if there's not a chance it will end up having similar problems. reply rkharsan64 5 hours agoprevOne minor nitpick that irks me more than it probably should: in Gleam, 1 / 0 gives you 0. reply lemper 5 hours agoprevbro, just wait til you learn that gleam has something similar to monad. now pass me the joint (also a compliment) reply neonsunset 8 hours agoprev [–] Impossibly slow, just use F#. reply lpil 8 hours agoparentI think you may be thinking of some other language. Gleam adds no overhead to the target platform used and both the Erlang VM and JavaScript runtimes have respectable performance. The Erlang VM specifically outcompetes F# for networked services, which is its main use case. reply neonsunset 8 hours agorootparentThis applies to the entire BEAM family. HN loves to sign praises to it yet never looks into the detail nor has performance intuition to know that the use of predominantly interpreted languages is frequently inappropriate (note how Erlang is next to Ruby): https://benchmarksgame-team.pages.debian.net/benchmarksgame/... With that said, I had no idea it could target JS and will need to look into that, thanks (V8 is surprisingly competent at number crunching if it can inline everything, otherwise still subject to harsh limitations of dynamic nature of JS). Also, F#, building on top of .NET, has rich ecosystem and a set of its own async abstractions with all kinds of actor patterns being popular (within very small F# community that is). It’s fast, and so is its networking stack. Why am I criticizing Gleam? Because we had two decades of programming languages built on slow foundations imposing strict performance ceiling. There is no reason for nice languages like Gleam to be slow, yet they are. I’m not sure why, maybe because of the myth of compiled languages requiring more effort and interpreted languages being more productive to write in? reply h0l0cube 7 hours agorootparent> benchmarksgame/ I suppose if you want to do some distributed mandelbrot in Erlang, you'd just use NIFs to use an actual systems language for compute. > maybe because of the myth of compiled languages requiring more effort and interpreted languages being more productive to write in? Erlang focuses it's ergonomics around distributed processing, dispatch, and communication. Some of that is really in the decisions around the language (e.g., fully functional, hot-swappable and remote dispatchable modules (using message passing), metaprogramming, pattern matching), the runtime (e.g., genserver, the supervisor, lightweight processes with isolated garbage collection), and the core libraries (e.g., ETS, http client/server), but also it's the ecosystem that has built around the Erlang because of its soft real-time flavor. If things like soft real-time, high process count, network dispatch, etc. aren't really interesting to you, and the language isn't your cup of tea, then you aren't the target market for Erlang and its ilk. But certainly it is useful and productive for a number of people/orgs who've made the leap to OTP based on actual business value (e.g., Discord and (historically) Whatsapp) reply igouy 1 hour agorootparentThe benchmarks game website does quote the Erlang FAQ: https://benchmarksgame-team.pages.debian.net/benchmarksgame/... reply seventyone 6 hours agorootparentprev\"Make it work, then make it beautiful, then if you really, really have to, make it fast. 90 percent of the time, if you make it beautiful, it will already be fast. So really, just make it beautiful!\" – Joe Armstrong reply neonsunset 6 hours agorootparentThis together with misunderstanding Donald Knuth's quote (it was talking about not hand-writing ASM rather than throwing the baby out with the bathwater) is why we don't have nice things in places we are ought to. You have a set of tools with comparable degrees of features and productivity*, but one of them comes at a steep performance cost, perhaps you might want to pick the one that is snappier and easier to use? * Though one could argue F# offers more in regular niceties at the cost of not having distributed framework built-in, requiring you to reach for Akka. I certainly find F# significantly easier to read and write than Erlang. reply seventyone 1 hour agorootparentElixir is one of the most productive languages there is right now. Run into something slow? Replace that small bit with a Rust NIF and move on with your life. reply neonsunset 38 minutes agorootparentOr write it in a language where you don't even have to think about it. (you have to maintain separate toolchain and exports in Rust, to achieve this, and complex types cannot be easily exported/imported - it is subject to limitations of C ABI, and FFI is not free either, even when as cheap as it gets - .NET has that with P/Invoke yet still it is a deoptimization in data-intensive algorithms, which benefit from being rewritten in C#/F#) reply spinningslate 5 hours agorootparentprev> HN loves to sign praises to it yet never looks into the detail nor has performance intuition to know that the use of predominantly interpreted languages is frequently inappropriate (note how Erlang is next to Ruby): And you seem singularly focused in your belief that .Net is \"the answer\" every time a post promoting a BEAM ecosystem language comes up. It's clear you like .Net - good for you. It's solid and has nice features. But you're painting performance as some sort of absolute. It's not. > Also, F#, building on top of .NET, has rich ecosystem and a set of its own async abstractions with all kinds of actor patterns being popular What if I don't want \"all sorts of async abstractions\", but just one that works well? > Why am I criticizing Gleam? Because we had two decades of programming languages built on slow foundations imposing strict performance ceiling. And those programming languages have been used to develop sites like GitHub, WhatsApp, Facebook and countless other internet-scale apps. Every language and ecosystem imposes some form of performance ceiling. If performance was all that mattered, we'd all be writing assembler. It's about trade-offs: some of them technical, some of them social. .Net is a mature, stable, and performant ecosystem. You do it a disservice by rubbishing alternatives per your original comment (\"Impossibly slow, just use F#\"). -- EDIT: fixed spelling & grammar reply scns 7 hours agorootparentprevPicking Erlang for number crunching is a Bad Idea™. You can use NIFs in C or Rust though for expensive computations. If you play to its' strengths it outshines the competition eg WhatsApp and 99.999999999% of uptime (that is a few seconds of downtime per year). Horses for courses. [Edit] Zero snark intended. https://www.youtube.com/watch?v=JvBT4XBdoUE reply lawn 7 hours agorootparentprevYou're not seeing the fundamental trade-off that BEAM is taking. They're not focusing on maximizing througput (number crunching) but on minimizing latency for the 99th percentile (keeping the server highly responsive even under heavy load). You really need to understand the pros- and cons of each tool. Dismissing the BEAM family because of a single attribute strikes me as a bit ignorant. reply fire_lake 7 hours agoparentprevA bit of a dismissive comment. However, there is a point here: F# offers the things that people are getting all excited about with Gleam (pragmatic functional programming in the ML school) and yet receives little hype. Perhaps it need a Beam compiler target? reply llcoolchris_ 6 hours agorootparentHey, article author here! I knew about F# since my university days and I'm guilty for not really dig into it except for toys projects. I worked in many companies and most of them were Microsoft hostile. That would explain why I'm kind of far away from the .NET affiliated technologies. We all agree that this is a silly reason, but if you wonder why F# doesn't get any love, I'd bet that this is because a lot of people are ignoring Microsoft. Let's change that reply fire_lake 1 hour agorootparentPerceptions are slow to shift. Nowadays, you can use .NET on Linux with VS Code and Ionide (open-source LSP). No need to ever talk to a Microsoft sales rep :) reply neonsunset 7 hours agorootparentprevThis would make it much slower and reduce the amount of libraries it can use by a factor of 10, maybe more, without improving its concurrency capabilities, possibly degrading them (because .NET threadpool and task system are robust and low overhead). But I guess that could make HN like it instead? reply mrkeen 7 hours agoparentprev [–] For someone who's advocating a functional programming language, this is a weirdly terse \"don't use this for performance reasons\" take. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article highlights Chris, a software engineer, who revisited Gleam, a type-safe language on the BEAM, after the release of Gleam V1 in March 2024 and was impressed by its static typing.",
      "Key features of Gleam include tagged unions, pattern matching, and a robust type system, with a compiler and CLI that simplify development, contrasting with JavaScript's complexity.",
      "Gleam's integration with the BEAM ecosystem and OTP for building fault-tolerant software, along with its ability to transpile to JavaScript, makes it appealing to JavaScript developers; the article also introduces Lustre, a Gleam web framework."
    ],
    "commentSummary": [
      "Gleam is a type-safe language designed for the BEAM virtual machine, known for its minimalistic design and productive features.",
      "Unlike Elixir, Gleam re-implements key primitives to align with its static type system, offering simplicity, labeled arguments, and integrated tooling.",
      "While Gleam's OTP (Open Telecom Platform) is less mature than Erlang's or Elixir's, it is evolving and appreciated for its ergonomic design and potential integration with projects like Vue."
    ],
    "points": 177,
    "commentCount": 79,
    "retryCount": 0,
    "time": 1718087389
  },
  {
    "id": 40638764,
    "title": "New Framework Unveils How Large-Scale Order Emerges from Microscopic Interactions",
    "originLink": "https://www.quantamagazine.org/the-new-math-of-how-large-scale-order-emerges-20240610/",
    "originBody": "The New Math of How Large-Scale Order Emerges Read Later Share Copied! Comments Read Later Read Later complex systems The New Math of How Large-Scale Order Emerges By Philip Ball June 10, 2024 The puzzle of emergence asks how regularities emerge on macro scales out of uncountable constituent parts. A new framework has researchers hopeful that a solution is near. Read Later Jupiter’s Great Red Spot, seen in this animation based on Voyager 1 and Hubble images, has swirled for hundreds of years, exemplifying the way large-scale patterns and organization can arise from innumerable microscopic interactions. Equinox Graphics By Philip Ball Contributing Writer June 10, 2024 View PDF/Print Mode complex systemscomplexityemergenceneurosciencephysicsAll topics Introduction A few centuries ago, the swirling polychromatic chaos of Jupiter’s atmosphere spawned the immense vortex that we call the Great Red Spot. From the frantic firing of billions of neurons in your brain comes your unique and coherent experience of reading these words. As pedestrians each try to weave their path on a crowded sidewalk, they begin to follow one another, forming streams that no one ordained or consciously chose. The world is full of such emergent phenomena: large-scale patterns and organization arising from innumerable interactions between component parts. And yet there is no agreed scientific theory to explain emergence. Loosely, the behavior of a complex system might be considered emergent if it can’t be predicted from the properties of the parts alone. But when will such large-scale structures and patterns arise, and what’s the criterion for when a phenomenon is emergent and when it isn’t? Confusion has reigned. “It’s just a muddle,” said Jim Crutchfield, a physicist at the University of California, Davis. “Philosophers have long been arguing about emergence, and going round in circles,” said Anil Seth, a neuroscientist at the University of Sussex in England. The problem, according to Seth, is that we haven’t had the right tools — “not only the tools for analysis, but the tools for thinking. Having measures and theories of emergence would not only be something we can throw at data but would also be tools that can help us think about these systems in a richer way.” Though the problem remains unsolved, over the past few years, a community of physicists, computer scientists and neuroscientists has been working toward a better understanding. These researchers have developed theoretical tools for identifying when emergence has occurred. And in February, Fernando Rosas, a complex systems scientist at Sussex, together with Seth and five co-authors, went further, with a framework for understanding how emergence arises. Fernando Rosas, a complex systems scientist at the University of Sussex, suggests thinking of emergent phenomena as “software in the natural world.” Courtesy of Fernando Rosas A complex system exhibits emergence, according to the new framework, by organizing itself into a hierarchy of levels that each operate independently of the details of the lower levels. The researchers suggest we think about emergence as a kind of “software in the natural world.” Just as the software of your laptop runs without having to keep track of all the microscale information about the electrons in the computer circuitry, so emergent phenomena are governed by macroscale rules that seem self-contained, without heed to what the component parts are doing. Using a mathematical formalism called computational mechanics, the researchers identified criteria for determining which systems have this kind of hierarchical structure. They tested these criteria on several model systems known to display emergent-type phenomena, including neural networks and Game-of-Life-style cellular automata. Indeed, the degrees of freedom, or independent variables, that capture the behavior of these systems at microscopic and macroscopic scales have precisely the relationship that the theory predicts. No new matter or energy appears at the macroscopic level in emergent systems that isn’t there microscopically, of course. Rather, emergent phenomena, from Great Red Spots to conscious thoughts, demand a new language for describing the system. “What these authors have done is to try to formalize that,” said Chris Adami, a complex-systems researcher at Michigan State University. “I fully applaud this idea of making things mathematical.” A Need for Closure Rosas came at the topic of emergence from multiple directions. His father was a famous conductor in Chile, where Rosas first studied and played music. “I grew up in concert halls,” he said. Then he switched to philosophy, followed by a degree in pure mathematics, giving him “an overdose of abstractions” that he “cured” with a Ph.D. in electrical engineering. A few years ago, Rosas started thinking about the vexed question of whether the brain is a computer. Consider what goes on in your laptop. The software generates predictable and repeatable outputs for a given set of inputs. But if you look at the actual physics of the system, the electrons won’t all follow identical trajectories each time. “It’s a mess,” said Rosas. “It’ll never be exactly the same.” The software seems to be “closed,” in the sense that it doesn’t depend on the detailed physics of the microelectronic hardware. The brain behaves somewhat like this too: There’s a consistency to our behaviors even though the neural activity is never identical in any circumstance. Rosas and colleagues figured that in fact there are three different types of closure involved in emergent systems. Would the output of your laptop be any more predictable if you invested lots of time and energy in collecting information about all the microstates — electron energies and so forth — in the system? Generally, no. This corresponds to the case of informational closure: As Rosas put it, “All the details below the macro are not helpful for predicting the macro.” What if you want not just to predict but to control the system — does the lower-level information help there? Again, typically no: Interventions we make at the macro level, such as changing the software code by typing on the keyboard, are not made more reliable by trying to alter individual electron trajectories. If the lower-level information adds no further control of macro outcomes, the macro level is causally closed: It alone is causing its own future. Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters Jim Crutchfield, a physicist at the University of California, Davis, is shown with an underwater microphone he recently designed for recording humpback whale vocalizations, to which he is applying his pattern discovery methods in hopes of decoding the causal relationships between vocalizations. Tonje Hessen Schei Introduction This situation is rather common. Consider, for instance, that we can use macroscopic variables like pressure and viscosity to talk about (and control) fluid flow, and knowing the positions and trajectories of individual molecules doesn’t add useful information for those purposes. And we can describe the market economy by considering companies as single entities, ignoring any details about the individuals that constitute them. The existence of a useful coarse-grained description doesn’t, however, by itself define an emergent phenomenon, said Seth. “You want to say something else in terms of the relationship between levels.” Enter the third level of closure that Rosas and colleagues think is needed to complete the conceptual apparatus: computational closure. For this they have turned to computational mechanics, a discipline pioneered by Crutchfield. Crutchfield introduced a conceptual device called the ε- (epsilon) machine. This device can exist in some finite set of states and can predict its own future state on the basis of its current one. It’s a bit like an elevator, said Rosas; an input to the machine, like pressing a button, will cause the machine to transition to a different state (floor) in a deterministic way that depends on its past history — namely, its current floor, whether it’s going up or down and which other buttons were pressed already. Of course an elevator has myriad component parts, but you don’t need to think about them. Likewise, an ε-machine is an optimal way to represent how unspecified interactions between component parts “compute” — or, one might say, cause — the machine’s future state. Computational mechanics allows the web of interactions between a complex system’s components to be reduced to the simplest description, called its causal state. The state of the complex system at any moment, which includes information about its past states, produces a distribution of possible future states. Whenever two or more such present states have the same distribution of possible futures, they are said to be in the same causal state. Our brains will never twice have exactly the same firing pattern of neurons, but there are plenty of circumstances where nevertheless we’ll end up doing the same thing. Rosas and colleagues considered a generic complex system as a set of ε-machines working at different scales. One of these might, say, represent all the molecular-scale ions, ion channels and so forth that produce currents in our neurons; another represents the firing patterns of the neurons themselves; another, the activity seen in compartments of the brain such as the hippocampus and frontal cortex. The system (here the brain) evolves at all those levels, and in general the relationship between these ε-machines is complicated. But for an emergent system that is computationally closed, the machines at each level can be constructed by coarse-graining the components on just the level below: They are, in the researchers’ terminology, “strongly lumpable.” We might, for example, imagine lumping all the dynamics of the ions and neurotransmitters moving in and out of a neuron into a representation of whether the neuron fires or not. In principle, one could imagine all kinds of different “lumpings” of this sort, but the system is only computationally closed if the ε-machines that represent them are coarse-grained versions of each other in this way. “There is a nestedness” to the structure, Rosas said. A highly compressed description of the system then emerges at the macro level that captures those dynamics of the micro level that matter to the macroscale behavior — filtered, as it were, through the nested web of intermediate ε-machines. In that case, the behavior of the macro level can be predicted as fully as possible using only macroscale information — there is no need to refer to finer-scale information. It is, in other words, fully emergent. The key characteristic of this emergence, the researchers say, is this hierarchical structure of “strongly lumpable causal states.” Leaky Emergence The researchers tested their ideas by seeing what they reveal about a range of emergent behaviors in some model systems. One is a version of a random walk, where some agent wanders around haphazardly in a network that could represent, for example, the streets of a city. A city often exhibits a hierarchy of scales, with densely connected streets within neighborhoods and much more sparsely connected streets between neighborhoods. The researchers find that the outcome of a random walk through such a network is highly lumpable. That is, the probability of the wanderer starting in neighborhood A and ending up in neighborhood B — the macroscale behavior — remains the same regardless of which streets within A or B the walker randomly traverses. The researchers also considered artificial neural networks like those used in machine-learning and artificial-intelligence algorithms. Some of these networks organize themselves into states that can reliably identify macroscopic patterns in data regardless of microscopic differences between the states of individual neurons in the network. The decision of which pattern will be output by the network “works at a higher level,” said Rosas. Anil Seth, a neuroscientist at the University of Sussex who studies consciousness, conducts an experiment on perception. Tom Medwell Introduction Would Rosas’ scheme help to understand the emergence of robust, large-scale structure in a case like Jupiter’s Great Red Spot? The huge vortex “might satisfy computational closure” Rosas said, “but we’d need to do a proper analysis before being able to claim anything.” As for living organisms, they seem sometimes to be emergent but sometimes more “vertically integrated,” where microscopic changes do influence large-scale behavior. Consider, for example, a heart. Despite considerable variations in the details of which genes are being expressed, and how much, or what the concentrations of proteins are from place to place, all of our heart muscle cells seem to work in essentially the same way, enabling them to function en masse as a pump driven by coherent, macroscopic electrical pulses passing through the tissue. But it’s not always this way. While many of our genes carry mutations that make no difference to our health, sometimes a mutation — just one genetic “letter” in a DNA sequence that is “wrong” — can be catastrophic. So the independence of the macro from the micro is not complete: There is some leakage between levels. Rosas wonders if living organisms are in fact optimized by allowing for such “leaky” partial emergence — because in life, sometimes it is essential for the macro to heed the details of the micro. Emergent Causes Rosas’ framework could help complex systems researchers see when they can and can’t hope to develop predictive coarse-grained models. When a system meets the key requirement of being computationally closed, “you don’t lose any faithfulness by simulating the upper levels and neglecting the lower levels,” he said. But ultimately Rosas hopes an approach like his might answer some deep questions about the structure of the universe — why, for example, life seems to exist only at scales intermediate between the atomic and the galactic. The framework also has implications for understanding the tricky question of cause and effect in complex and emergent systems. Traditionally, causation has been assumed to flow from the bottom up: Our choices and actions, for example, are ultimately attributed to those firing patterns of our neurons, which in turn are caused by flows of ions across cell membranes. consciousness A Theory of Reality as More Than the Sum of Its Parts June 1, 2017 Read Later But in an emergent system, this is not necessarily so; causation can operate at a higher level independently from lower-level details. Rosas’ new computational framework seems to capture this aspect of emergence, which was also explored in earlier work. In 2013, neuroscientist Giulio Tononi of the University of Wisconsin, Madison, working with Erik Hoel and Larissa Albantakis (also at Wisconsin), claimed that, according to a particular measure of causal influence called effective information, the overall behavior of some complex systems is caused more at the higher than the lower levels. This is called causal emergence. The 2013 work using effective information could have been just a quirk of measuring causal influence this way. But recently, Hoel and neuroscientist Renzo Comolatti have shown that it is not. They took 12 different measures of causal power proposed in the literature and found that with all of them, some complex systems show causal emergence. “It doesn’t matter what measure of causation you pick,” Hoel said. “We just went out into the literature and picked other people’s definitions of causation, and all of them showed causal emergence.” It would be bizarre if this were some chance quirk of all those different measures. For Hoel, emergent systems are ones whose macroscale behavior has some immunity to randomness or noise at the microscale. For many complex systems, there’s a good chance you can find coarse-grained, macroscopic descriptions that minimize that noise. “It’s that minimization that lies at the heart of a good notion of emergence,” he said. Tononi says that, while his approach and that of Rosas and colleagues address the same kinds of systems, they have somewhat different criteria for causal emergence. “They define emergence as being when the macro system can predict itself as much as it can be predicted from the micro level,” he said. “But we require more causal information at the macro level than at the micro level.” Related: How Life (and Death) Spring From Disorder ‘Digital Alchemist’ Seeks Rules of Emergence The Unpredictable Abilities Emerging From Large AI Models The new ideas touch on the issue of free will. While hardened reductionists have argued that there can be no free will because all causation ultimately arises from interactions of atoms and molecules, free will may be rescued by the formalism of higher-level causation. If the main cause of our actions is not our molecules but the emergent mental states that encode memories, intentions, beliefs and so forth, isn’t that enough for a meaningful notion of free will? The new work shows that “there are sensible ways to think about macro-level causation that explain how agents can have a worthwhile form of causal efficacy,” Seth said. Still, there remains disagreement among researchers about whether macroscopic, agent-level causation can emerge in complex systems. “I’m uncomfortable with this idea that the macroscale can drive the microscale,” said Adami. “The macroscale is just degrees of freedom that you’ve invented.” This is the sort of issue that the scheme proposed by Rosas and colleagues might help to resolve, by burrowing into the mechanics of how different levels of the system speak to one another, and how this conversation must be structured to achieve independence of the macro from the details of the levels below. At this point, some of the arguments are pretty fuzzy. But Crutchfield is optimistic. “We’ll have this figured out in five or 10 years,” he said. “I really think the pieces are there.” By Philip Ball Contributing Writer June 10, 2024 View PDF/Print Mode complex systemscomplexityemergenceneurosciencephysicsAll topics Share this article Copied! Newsletter Get Quanta Magazine delivered to your inbox Subscribe now Recent newsletters The Quanta Newsletter Get highlights of the most important news delivered to your email inbox Email Subscribe Recent newsletters Comment on this article Quanta Magazine moderates comments to facilitate an informed, substantive, civil conversation. Abusive, profane, self-promotional, misleading, incoherent or off-topic comments will be rejected. Moderators are staffed during regular business hours (New York time) and can only accept comments written in English. Show comments Next article In Highly Connected Networks, There’s Always a Loop",
    "commentLink": "https://news.ycombinator.com/item?id=40638764",
    "commentBody": "The new math of how large-scale order emerges (quantamagazine.org)166 points by gradus_ad 22 hours agohidepastfavorite37 comments jsenn 19 hours agoVery cool to see an article that discusses Crutchfield's Epsilon machine formalism. It's one of those rare theories that is conceptually powerful but also simple and concrete enough that it can be implemented in a couple hundred lines of code. For those interested, [1] is a readable (if quirky) introduction to the theory. The paper discussed in this article seems to discuss a way of \"stacking\" epsilon machines, so that you have a machine that describes the state transitions of a machine that describes a data set. I wonder if this gets around the main weakness of the e-machine formalism, namely that for a process with non-finite memory, there's no obvious next class of automata to try after finite state machines. In a sense FSMs are the only non-arbitrary model of computation; everything else basically boils down to augmenting a finite-state control with a gadget for storing data, like a stack (pushdown automata), register (counter/register machines), random-access tape (Turing machines), random-access tape but you're only allowed a tape the size of the input (linear-bounded automata) etc. You can constrain that gadget in pretty much arbitrary ways, which makes it difficult to choose a computational model for a non-finite process. [1]: https://csc.ucdavis.edu/~cmg/papers/CalcEmerg.pdf reply habitue 15 hours agoparentThis is really cool. Thanks for the link. reply gnulinux 14 hours agoparentprevAmazing paper, thank you for sharing! reply badrunaway 5 hours agoprevCan someone summarise what this changes overall in the field? What I got is that there was no proper formalism to study emergence earlier and now we have a mathematical framework. reply rramadass 12 hours agoprevWhat are some good resources (books/papers/videos/etc.) to get started on \"Complex Systems\", \"Emergence\", \"Self-Organization\" and related topics? reply dlojudice 6 hours agoparent\"Introduction to Complexity\" by Melanie Mitchell from Santa Fe Institute. https://www.complexityexplorer.org/courses/185-introduction-... This free course is based on her book \"Complexity: A Guided Tour\" https://www.amazon.com/Complexity-Guided-Tour-Melanie-Mitche... reply chermi 2 hours agoparentprevCrutchfield has recorded lectures on YouTube. I thought they were quite good. I'm biased toward learning statistical mechanics and nonlinear dynamics as a starting point. Search \"phy 256 a(b) crutchfield\" on YouTube. Crutchfield has been doing amazing work for quite some time. If you want a critical and very entertaining read, I would check out cosma shalizi's blog. He does a lot of book reviews too that may be helpful. http://bactra.org/weblog/ Other names/references include \"The nature of computation\" Stuart kauffman. \"Nonlinear dynamics and chaos\" Too many stat mech books to possibly recommend, for the idea of emergence you'll want something including phase transitions so... Can't go wrong with 'thermodynamics and an introduction to thermostatistics\". And for stat mech with lots of complex systems diversions, Sethna's book is excellent but difficult to learn from. \"Entropy, complexity, and order parameters. Names in thermo/complexity: Sethna Goldenfeld Parisi HE stanley Finally, it's hard to talk about complex systems without talking about networks, \"Networks\"-Newman is unambiguously the best choice. Names in networks: Mark Newman Reka Albert Avoid barabasi especially more recent stuff. There may be better lectures/resources out there I don't know of, but I would start with crutchields lectures. Note again I am coming from heavy physics bias. reply abetusk 6 hours agoparentprevComplexity and Criticality by Christensen and Moloney [0]. It goes through three main systems, percolation, the Ising model and the rice pile model. It's an introduction that gives the tools to analyze each and provides the foundation to understand other models and other literature in the area. I found it pretty accessible from a programmers point of view. [0] https://www.amazon.com/COMPLEXITY-CRITICALITY-Imperial-Colle... reply JPC21 10 hours agoparentprevPersonally I would read a book on statistical physics instead, since this is where the study of 'emergence' began. The Feynman lectures would be good for this. I actually haven't found many good books for 'Complex systems', but if you want to take a shot anyway, I would look at https://academic.oup.com/book/25504 and https://press.princeton.edu/books/paperback/9780691122045/cr... reply rramadass 9 hours agorootparentGreat. The OUP book linked above viz. Introduction to the Theory of Complex Systems by Stefan Thurner et al. looks particularly good since the ToC lists all the needed interdisciplinary topics for a study of this subject. reply pdfernhout 2 hours agoparentprevMy wife (Cynthia F. Kurtz) wrote a non-mathematical book on complexity a couple years ago: \"Confluence: Tools for Thinking about How Organized Plans and Self-organized Patterns Flow Together\" https://www.cfkurtz.com/confluence/ The blurb: \"A path winds its way through a forest. Why does it go the way it goes? Did someone design it? Or was the path made smooth by feet that chose the smoothest path? Maybe some of both? Confluence examines the many ways in which organized, intentional plans (like paths we design) and self-organized, unintentional patterns (like paths that emerge where we walk) intermingle (happen at the same time and place) and interact (influence each other). The book lays out seven “thinking spaces” (like this one) that explore various aspects of the structures and relationships that flow together in our lives.\" reply FergusArgyll 5 hours agoparentprevKind of tangentially related but I think pretty relevant is Scale by Geoffreys West reply epsilonic 12 hours agoparentprevAnything by John H. Holland is good. reply rramadass 12 hours agorootparentThanks. I have his Hidden Order book and also Per Bak's How Nature Works. Any others you would recommend by these or other authors? reply danyala 12 hours agoparentprevI can't recommend books but here are a couple of other good phrases to search with, or just to discuss with one of the sparkier LLMs, which tend to find this topic quite interesting: 1. cross-scale interaction 2. downward causation Would be happy to learn of other terms too. reply rramadass 9 hours agorootparentI generally find Wikipedia a very good starting point to get an overview and a gateway to further research/study; their \"See Also\" sections list plenty of terms/phrases to look up; 1) https://en.wikipedia.org/wiki/Complex_system#See_also 2) https://en.wikipedia.org/wiki/Self-organization#See_also 3) https://en.wikipedia.org/wiki/Emergence#See_also reply uoaei 11 hours agoparentprevPrerequisites are heavily aligned with physics / applied math, particularly: thermodynamics, dynamical systems, network theory, and a strong emphasis on interdisciplinary study. All should be approached from a perspective rooted mostly in rigorous information theory. reply rramadass 9 hours agorootparentWell said. This recommendation from user JPC21 seems to cover everything you list - https://news.ycombinator.com/item?id=40644189 reply uoaei 4 hours agorootparentI did a master's in complexity science and a lot of it was basically \"what if this graph of things is a computer? what does it compute?\" reply fiforpg 19 hours agoprevThis Quanta trickled through my head Like water through a sieve. reply nico 15 hours agoprev> exemplifying the way large-scale patterns and organization can arise from innumerable microscopic interactions Is it proven that the flow of emergence is from micro to macro? ie. Can emergence go the other way? What’s the starting point of the process? Can a macro process cause micro processes? Or is it always the other way around? Does causality always run in one direction? reply hallgrim 4 hours agoparentNot sure but turbulent diffusion might be an example? Fluid dynamics is emergent from its constituent particles, creating sometimes vortices etc. which can decay into ever smaller vortices through the fluid’s coarser dynamics. At some point the vortices become so small that the kinetic energy is turned into diffusive behavior at the particle level instead. reply hammock 4 hours agoparentprevHow about high pressure creating diamonds? Wars creating great (not in the normative sense) leaders? Climate and natural disasters creating selection pressure? reply naasking 14 hours agoparentprevWhat would be an example of a macro process causing a micro without going through micro processes? I would think the best you can do is something like fractal geometry, where self-similarity appears at all scales. In some sense, the rules are both micro and macroscopic. An example where this might have real-world implications is Palmer's Invariant Set Theory, which suggests that this fractal structure shapes both cosmological structures and what we see in quantum theory, eg. like violations of Bell's inequality, reply benfarahmand 5 hours agorootparentI can't think of physical processes that could go from macro -> micro. The examples I can think of stem from Yuval Harari's human fictions affecting the world. For example, a nation state or a corporation or a story could set the stage for the macro affecting the micro. If we look at a story, it communicates an idea that changes the behaviors of humans, which in turn causes those humans to interact with the micro and the macro. As I'm writing this out and thinking about it, where would fictional objects fit on the micromacro axis? reply naasking 4 hours agorootparentFictions are encoded in the brain's microstates and drive its behaviour, comparable to how gate charge on transistors drives a computer state. But that is an interesting thought, because all of those microstates and their evolution are counterfactually described by a computer program, and much like math, perhaps a computer program in some sense has a platonic existence that isn't reducible to physical states. I probably wouldn't go in that direction, but some philosophers have made this case for math. reply boxfire 13 hours agorootparentprevThe Mars global dust storm is caused by coupling of angular momentum of the (solar) system, a global a effect. The Mars system itself down to the dust does not create sufficient conditions reply naasking 6 hours agorootparentThat coupling is due to aggregate interactions of all system particles, so it's still comes down to a cumulative microscopic effect. Pretty good example though! reply Erem 12 hours agorootparentprevWould lunar gravity -> tides -> waves -> erosion of particles from a rock count? reply tines 12 hours agorootparent\"Lunar gravity\" is the effect of innumerable individual particles exerting a gravitational force, so that's not really macro. reply GoblinSlayer 4 hours agorootparentprevMaxwell demon? reply Blahah 8 hours agorootparentprevMedicine reply naasking 6 hours agorootparentMedicine is all biochemistry. reply PaulDavisThe1st 4 hours agoparentprevDoug Hofstadter's concept of \"heterarchy\" is somewhat apropros here. A heterarchy matches TFA's concept of a \"closure\" (information about the micro doesn't really aid in predicting or understanding the macro), but adds in the ability for higher (more macro) levels to feedback to the lower (more micro) levels. I don't know how much Hofstadter still invests in this idea, but at the time of GEB, he seemed pretty convinced it is/was a central part of how complex systems like minds/brains function. reply peter_d_sherman 3 hours agoprev>\"A complex system exhibits emergence, according to the new framework, by organizing itself into a hierarchy of levels that each operate independently of the details of the lower levels. The researchers suggest we think about emergence as a kind of “software in the natural world.” Just as the software of your laptop runs without having to keep track of all the microscale information about the electrons in the computer circuitry, so emergent phenomena are governed by macroscale rules that seem self-contained, without heed to what the component parts are doing. Using a mathematical formalism called computational mechanics, the researchers identified criteria for determining which systems have this kind of hierarchical structure.\" [...] >\"Indeed, the degrees of freedom, or independent variables, that capture the behavior of these systems at microscopic and macroscopic scales have precisely the relationship that the theory predicts.\" Related: https://en.wikipedia.org/wiki/Hierarchy https://en.wikipedia.org/wiki/Dimension https://en.wikipedia.org/wiki/Degrees_of_freedom https://en.wikipedia.org/wiki/Phase_space https://en.wikipedia.org/wiki/Computational_mechanics https://en.wikipedia.org/wiki/Partial_differential_equation https://en.wikipedia.org/wiki/Self-organization (a.k.a. \"Self Organizing System(s)\") https://en.wikipedia.org/wiki/Consciousness https://news.ycombinator.com/item?id=39860388 https://en.wikipedia.org/wiki/Emergence And they're all related! Magic! reply danyala 13 hours agoprevI wish Descartes and his peers could have lived to see this. It must have been misery. reply wslh 4 hours agoprev [–] I started reading the abstract and thought immediately about Gregory Chaitin [1] measure of complexity, then searching on the text it is obviously there. I think it is a simple and good read to review Solomonoff–Kolmogorov–Chaitin [2] before reading the paper. [1] https://en.wikipedia.org/wiki/Gregory_Chaitin [2] https://en.wikipedia.org/wiki/Kolmogorov_complexity reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article by Philip Ball discusses the concept of emergence, where large-scale patterns arise from numerous microscopic interactions, and the challenge of developing a unified scientific theory for it.",
      "Researchers, including Fernando Rosas, have proposed a new framework using computational mechanics to identify criteria for emergent structures, suggesting that complex systems self-organize into hierarchical levels independent of lower-level details.",
      "The study introduces the concept of informational closure, indicating that macro-level predictability and control are not enhanced by detailed microstate information, and explores its implications for understanding the universe's structure, causation, and the debate on free will."
    ],
    "commentSummary": [
      "The article introduces Crutchfield's Epsilon machine formalism, a new method for modeling state transitions in systems with non-finite memory, addressing the limitations of finite state machines.",
      "It recommends key resources on complex systems, including works by Melanie Mitchell, Crutchfield, and Cosma Shalizi, and books like \"The Nature of Computation\" by Stuart Kauffman and \"Networks\" by Mark Newman.",
      "The discussion covers the interplay between macro and micro processes, the concept of heterarchy, and the importance of interdisciplinary study rooted in information theory, referencing theories by Gregory Chaitin and the Solomonoff–Kolmogorov–Chaitin framework."
    ],
    "points": 166,
    "commentCount": 37,
    "retryCount": 0,
    "time": 1718052124
  },
  {
    "id": 40642801,
    "title": "British Duo Arrested for SMS Phishing Using Homemade \"Text Message Blaster\"",
    "originLink": "https://www.theregister.com/2024/06/10/two_arrested_in_uk_over/",
    "originBody": "Cyber-crime 17 Two cuffed over suspected smishing campaign using 'text message blaster' 17 Thousands of dodgy SMSes bypassed network filters in UK-first case, it is claimed Connor Jones Mon 10 Jun 2024 // 11:31 UTC British police have arrested two individuals following an investigation into an SMS-based phishing campaign using some kind of homebrew hardware. That equipment, described by the cops variously as a \"homemade mobile antenna,\" \"an illegitimate telephone mast,\" and a \"text message blaster,\" is thought to be a first-of-its-kind device in the UK designed to fire dodgy texts out en masse to marks, all while allegedly bypassing network operators' anti-SMS-based phishing, or smishing, defenses. Thousands of messages were sent using this setup, City of London Police claimed on Friday, with those suspected to be behind the operation misrepresenting themselves as banks \"and other official organizations\" in their texts. \"The criminals committing these types of crimes are only getting smarter, working in more complex ways to trick unknowing members of the public and steal whatever they can get their hands on. It is vital we work with partners to help prevent the public from falling victim to fraud,\" said temporary detective chief inspector David Vint, head of City's Dedicated Card and Payment Crime Unit (DCPCU). \"Remember, a bank or another official authority will not ask you to share personal information over text or phone. If you think you have received a fraudulent text message, report it by forwarding it to 7726.\" Most network operators in the UK are enrolled in a scheme that allows customers to forward suspicious SMS messages to 7726 – a dedicated number for assessing the potential threat of any given message. Network operators can then decide whether to block or ban the sender if foul play is afoot. For example, EE has stopped tens of millions of scam SMS messages since stepping up its anti-spam filter in 2021. It also runs a scheme in its retail stores whereby new customers can verify their identity with the network, vastly reducing the likelihood that messages stemming from their accounts would ever be spammy in nature. Huayong Xu, 32, of Alton Road in Croydon, was arrested on May 23 and remains the only individual identified by police in this investigation at this stage. He has been charged with possession of articles for use in fraud and will appear at Inner London Crown Court on June 26. The other individual, who wasn't identified and did not have their charges disclosed by police, was arrested on May 9 in Manchester and was bailed. City of London Police said it was working with network operators, communications regulator Ofcom, and the National Cyber Security Centre (NCSC) on the case. Ofcom told us: “Criminals who defraud people using mobile technology cause huge distress and financial harm to their victims. We’re working closely with the police, the National Cyber Security Centre, other regulators, and industry to tackle the problem.” The Register asked NCSC for more details on the masts and if there are thought to be additional devices popping up around the UK. NCSC referred us to the City of Police for comment. April brings tulips, taxes ... and phisherfolk scammers Voicemail phishing emails steal Microsoft credentials Cybercriminals are stealing iOS users' face scans to break into mobile banking accounts Meta says risk of account theft after phone number recycling isn't its problem to solve Without any additional information to go on, it's difficult to make any kind of assumption about what these \"text message blaster\" devices might be. However, one possibility, judging from the messaging from the police, is that the plod are referring to an IMSI catcher aka a Stingray, which acts as a cellphone tower to communicate with people's handhelds. But those are intended primarily for surveillance. What's more likely is that the suspected UK device is perhaps some kind of SIM bank or collection of phones programmed to spam out shedloads of SMSes at a time. ® Editor's note: This article was revised on June 11 to clarify what the alleged \"illegitimate telephone mast\" may be. Whitepaper: Top 5 Tips For Navigating Your SASE Journey Share More about Cybercrime Cybersecurity Phishing More like these × More about Cybercrime Cybersecurity Phishing Telecommunications Narrower topics 5G AT&T British Telecom Comcast EE Emergency Services Network Ericsson Mobile Network National Broadband Network NCSC NTT Orange RSA Conference Telecommunications Act of 1996 TETRA Verizon Vodafone Voice over IP Broader topics Sector Security More about Share 17 COMMENTS More about Cybercrime Cybersecurity Phishing More like these × More about Cybercrime Cybersecurity Phishing Telecommunications Narrower topics 5G AT&T British Telecom Comcast EE Emergency Services Network Ericsson Mobile Network National Broadband Network NCSC NTT Orange RSA Conference Telecommunications Act of 1996 TETRA Verizon Vodafone Voice over IP Broader topics Sector Security TIP US OFF Send us news",
    "commentLink": "https://news.ycombinator.com/item?id=40642801",
    "commentBody": "British duo arrested for SMS phishing via homemade cell tower (theregister.com)153 points by skilled 13 hours agohidepastfavorite131 comments tamimio 45 minutes agoBuilding a homemade BTS (Base Transceiver Station) is easy. I remember making one back in 2011 with a USRP SDR. Nowadays, you can even create a 5G network, not just LTE. There’s plenty of good open-source software available. Paired with an SDR, you are good to go. The rest is just some scripting to automate some tasks, probably how they flooded the SMS. reply Scoundreller 1 hour agoprev> For example, EE has stopped tens of millions of scam SMS messages since stepping up its anti-spam filter in 2021. So, they blocked like 2% ? reply mdp2021 11 hours agoprev> Most phone providers are part of a scheme that allows customers to report suspicious text messages for free by forwarding it to 7726. If you forward a text to 7726, your provider can investigate the origin of the text and arrange to block or ban the sender, if it’s found to be malicious It would be useful to have a list of Countries/operators adopting the 7726 (\"SPAM\") number. It seems also some European Countries do. reply doophus 52 minutes agoparentWould this even work in the article's situation, where someone's MITMing SMS? reply mdp2021 28 minutes agorootparentIf you believe the cell you are under is compromised, further action should be performed under a different cell. Actually, I would like to have an option to identify the cells devices are connected to. reply mminer237 16 minutes agorootparentCellMapper is an app on Android to do this: https://play.google.com/store/apps/details?id=cellmapper.net... reply mminer237 17 minutes agoparentprevAll major US carriers do. reply slowmotiony 11 hours agoparentprevHow do you forward a text? reply orra 10 hours agorootparentOften there's a long click menu in your SMS app to do it. But all that really does is copy the body into a new SMS. There's no metadata to indicate it's forwarded, as you suspect. This means texting 7726 is a two step process. First you send the body. You immediately get a response asking for the phone number of the spam sender, so then you sent that. reply lxgr 6 hours agorootparentDoes the phone number even matter for tracing? As far as I understand SMS delivery, it’s not authenticated at all. I suppose it can be used to help the operator identify the actual incoming message in their logs? reply gravescale 12 hours agoprevThat's a pretty clever way to be very stupid! Anyone who reports the message (forward it to 7726, spells SPAM) to a network tips the network off that messages are landing on subscribers devices that didn't come through their system. And I guarantee there are devices listening into, characterising and locating radio emitters in major cities at the very least. reply guerby 10 hours agoparentIn France it's 33700 to report SMS spam to the authorities https://www.33700.fr/informations-pratiques/signaler-un-mess... reply seabass-labrax 10 hours agorootparentIs it supposed to stand for something in the French language as 7726 does in English? reply codetrotter 9 hours agorootparentThe 0 button doesn’t have any letters associated with it. So I doubt it. reply colanderman 6 hours agorootparentHistorically Q and Z lived on 0. reply codetrotter 4 hours agorootparentLooking at https://en.wikipedia.org/wiki/Telephone_exchange_names I see a few different mappings over time. I like the fact that some of the earliest mappings had 0 mapped to \"OPER\" (\"Operator\"), because it makes me imagine that this number 33700 is like some interpretation of 337 and then shouting twice for the \"operator\" (as in, the literal physical person that used to sit and connect calls using wires and a patch board). Taking this further then, and given that: - 3 is assigned to any of the three letters DEF, and - 7 is assigned to any of the three letters PRS, we could invent the following meaning: DES = \"Déclaration d'Envoi de Spam\". (Lit. \"Declaration of sending of spam\", as in a report about spam sending). The double 0 is, as mentioned, in our invented meaning like shouting \"Operator! Operator!\" And with this invented meaning it's like we are shouting for help from the operator to deal with this spam :D Of course here I'm starting with 337 and backronyming \"DES\" to a plausible but probably weird sentence. If it was a real, the French would probably have worded the original sentence quite differently and the resulting number would be different as well. (Also, looking at the article I'm not sure if any European countries also had 0 used for \"OPER\" or not. Guess I'll have to travel to some museums in France and have a look at some old phones with my own eyes at some point.) reply Havoc 10 hours agoparentprev> And I guarantee there are devices listening into, characterising and locating radio emitters in major cities at the very least. Not convinced there is that level of sophistication at play reply gravescale 10 hours agorootparentI don't know if it was involved here, but \"spectrum monitoring\" (that's the keyword for more information about equipment you can get and who the expected customers are) is definitely a thing that is done in many places, and not only by the military, but also by police and regulators. It's not clear where the mast was installed (the CoL police aren't specifically limited to that very small area and one arrest was South London and one was Manchester) but if it was in central London, as a glaring terrorist target with an airport (London City) and heliport, I'd be very, very surprised if there's nothing watching the spectrum. Whether the operators of the spendy gear would share the information up for such \"petty\" crime, I don't know. And there's always the Ham community who really, really hate spectrum abusers. reply GJim 9 hours agorootparent> spectrum monitoring\".... is definitely a thing that is done in many places Not by Ofcom it isn't! (At least, certainly not on any scale as far as RF interference/spoofing is concerned). reply implements 9 hours agorootparentRingway Manchester (YT radio enthusiast) has a good video about OFCOM DF monitoring: https://www.youtube.com/watch?v=lMUwIpWvnbE - may have been scaled back now, though. reply gravescale 6 hours agorootparentCome to think of it, the mobile operators themselves have a large national network of radio receivers with lots of fancy time-of-flight, phased array multi-path, multi-band capabilities. Maybe these days Ofcom can just ask them if they are interested in something specific. reply giantg2 47 minutes agorootparentThey also rent space on the towers for other people's equiptment. reply Scramblejams 10 hours agorootparentprevAnd if there is, they’re probably not going to be burning those resources on little people problems like phishing. reply relaxing 9 hours agorootparentBurning resources? By turning on their spectrum analyzer and letting it log what it hears? reply vasco 12 hours agoparentprevYeah if you run a private antenna either the police or some men from your country's equivalent to FCC will come to your door and politely ask you to stop, if they are having a good day, most likely confiscate some of the equipment as well. And that's just for emitting anything on reserved spectrum or with too much power, not even for crime. reply GordonS 10 hours agorootparentI guess you could hoover up traffic at a location for a few hours, then move to another location and keep going like that without getting caught. reply miki123211 7 hours agorootparentThe Polish democratic opposition used to do this in the 80's, during the communist era. As far as I remember, their technique relied on balloons, they would attach a homemade antenna and tape player to a balloon, set it on a timer and release the balloon into the air. Before the transmission started, they'd be long gone and the balloon would have drifted far from the original site, making the perpetrators much harder to track down. As a bonus, they'd get an antenna high up in the air (which is good for reception), which was also hard to disable, even if you managed to pinpoint its location. reply lxgr 5 hours agorootparentprevVery unlikely. You'd probably be walking all over some other cell that's reusing that frequency in the new location, causing detectable issues. reply vasco 10 hours agorootparentprevListening isn't illegal so you can do that without moving. People move just to listen to different things with limited range, one form of it is called wardriving if you're doing it to wifi for example. reply gravescale 7 hours agorootparentYou can't send a phishing SMS from a receive-only device. Any mobile tower must have an active transmitter (at the very least, so the handset knows what network it thinks it's connected to!). Transmitting on a licensed mobile service band without the license is a very good way to earn a knock on your door. Eavesdropping on tower-to-handset comms is illegal too (in the UK), but it's not very practical to find just a receiver, unless they already know almost exactly where it is and are able to do a TEMPEST-like attack on the local oscillator or something. So as long as you keep quiet and don't do anything to indicate you're listening, such as, posting on Twitter about it or you do crime based on it, you'll get away with it. However, a receiver can't bump a victim handset down to a primitive-enough protocol, so all you'll get is encrypted content and maybe a smidge of metadata (I'm not sure exactly what is and isn't encrypted for each \"G\"). reply seabass-labrax 10 hours agorootparentprevThat's not true - it is indeed illegal to listen in to radio transmissions which are not intended for you. Doing so is a criminal offence punishable by an unlimited summary fine (the precise amount is determined based on the offender's personal income and other circumstances). https://www.legislation.gov.uk/ukpga/2006/36/section/48 reply mnw21cam 8 hours agorootparentCorrect. That's one reason why LiveATC has recordings of air traffic control radio calls from most countries, but not the UK. reply GordonS 10 hours agorootparentprevI'm fairly sure in the UK it's illegal, tho I don't know for certain. But even if not, you could be arrested for conspiracy to commit fraud (or similar). reply robbyiq999 2 hours agoprevWhat interests me is the intelligence and innovation of this. You would think these bad actors would fair well doing societal good using their skills and not resort to crime. reply ChrisMarshallNY 1 hour agoparentThat's always been the case. Dumb crooks don't last long. As to why they choose this way, over a \"legitimate\" (like dark pattern writing, or PID mining) vocation, there are many reasons. I suspect that a big one, is the \"blackball\" effect, that having a conviction on your record will create. Once we are convicted, then we become unhireable, in many industries, so it's not like we have a choice. Also, the pay for nefarious work can be quite good. reply rthnbgrredf 38 minutes agorootparentCan confirm. Have read many articles about known gang members and drug lords. It usually starts with doing some dumb things at younger age and then struggle to find and keep a legal job. reply dubcanada 1 hour agoparentprevWhy does that interest you? This is fairly common. reply RIMR 55 minutes agoparentprevThink about the \"innovation\" here. Learning to set up your own cell tower is quite a feat, but how are you going to monetize it? Are you going to start your own cell provider and try to compete with the existing major players? Or are you going to use the tech for some fast capital right now? If the goal was to learn just enough about cell tech to exploit it for profit, then a legal approach is off-the-table because of the extraordinary effort needed to ever get anything off the ground. reply Infinity315 11 hours agoprevSlightly off topic, but this is demonstrated in a show called Mr. Robot. I find it insanely cool that the hacking in Mr. Robot closely resembles real life. reply NilMostChill 11 hours agoparentIIRC they hired a bunch of real life professional white hats to consult. https://en.wikipedia.org/wiki/Mr._Robot#Technical_accuracy reply mastermedo 12 hours agoprevWhy does this work? How simple is it to follow the sms protocol, I thought there were spam filters in place on the phones to prevent receiving any traffic from towers which are not registered to a well known network provider (or what have you). reply jeroenhd 12 hours agoparentSMS is sent in some leftover space in the mobile data channel, there's very little verification to that up until relatively recent standards. If you can pretend to be a 2G/3G tower and jam the real tower, you can force phones to connect to you and you can send whatever calls and texts you want. This is mostly a 2G issue. Modern Android devices, and perhaps iOS devices, have a toggle to disable 2G for this reason. With fully compliant 5G, even police IMSI catchers become pretty difficult to use. reply lxgr 6 hours agorootparentI’ve always found that a weird characterization. It’s sent in the signaling channel, but why is that “leftover”? The channel is still established for the SMS, and it’s not like that channel bandwidth would go unused otherwise. It’s like saying “postcards are delivered in the leftover part of the mail truck unused by letters and parcels” :) reply zinekeller 3 hours agorootparent> I’ve always found that a weird characterization. It’s sent in the signaling channel, but why is that “leftover”? The channel is still established for the SMS, and it’s not like that channel bandwidth would go unused otherwise. In modern standards, it is indeed not a “leftover” (although RCS exists which is another can of worms), but originally it was transmitted in a best-effort manner using what is essentially a \"hack\" on SS7 (unlike phone calls which is guaranteed reception - or at least not going through). reply lxgr 3 hours agorootparentI don't think this was ever true, unless I'm misunderstanding what you mean by \"best-effort\" or \"hack\". In GSM, SMS are delivered either over the SDCCH (when no voice call is happening simultaneously) or the SACCH (when a voice call is already in progress). In the latter case, you might argue that they're piggy-backing onto existing resources, but in the former, there are definitely dedicated resources being allocated specifically for SMS delivery. SMS delivery has also always been reliable, both on the lower level (both SDCCH and SACCH are reliable) and the upper one (the phone reports successful delivery back to the sending SMSC), so while there are no timing guarantees (is that what you mean by best-effort?), delivery always eventually succeeds once resources are available. The protocol even goes to significant lengths to ensure timely (re)delivery in case various error scenarios, such as a full inbox on a phone or a phone being out of reception. While 140 bytes aren't much, reliability is actually great, until you add spam filtering, roaming, and inter-network delivery to the mix, when things can quickly go off the rails. (One unexpected consequence of how it's implemented is that for mutual reachability, it doesn't only matter what operators the sender and recipient have a contract with, but also in which network the recipient is currently roaming.) reply andyjohnson0 11 hours agorootparentprev> This is mostly a 2G issue. Modern Android devices, and perhaps iOS devices, have a toggle to disable 2G for this reason. My Android phone, Motorola Edge 20, has a setting for preferred network type. Options are 5G/4G/3G/2G, 4G/3G/2G, 3G/2G, or 2G only. Doesn't seem to be a way to disable 2G or 3G, even though most networks here (UK) no longer support them. reply jeroenhd 9 hours agorootparentFor phones that support it, there's a separate toggle for disabling 2G. I don't think the preference setting you're referring to has the same effect. If I recall correctly, The separate 2G toggle goes down to the modem especially rather than just being configuration. I do have my phone set to 4G+5G only through that same screen, though, as my modem lacks the 2G toggle as well. If there are missing options in the dropdown, try dialing *#*#4636#*#* and see if you can configure it through there. I don't know exactly what determines what configuration is exposed to the UI, it's possible your modem simply lacks support for disabling entire generations of cellular technology. reply Scoundreller 1 hour agorootparentI believe the SIM supports all kinds of rules for what networks and xG should be visible to the user. I know for a fact a local network has 3G here, but it’s not exposed on my phone to choose, presumably because it knows there’s 4G and 5G and carriers don’t want some dolt camping on 3G and eating more mhz/bit. I used to camp on 3G because Canada sent out too many dumb “emergency alerts” for custody disputes 1000km away, but those only operated over LTE, not 3G. People don’t believe me when I say you can see, and sometimes connect to, US networks from a tall building in Toronto from over the lake because Canadian SIMs have rules/conditions to hide them, but if you put in an overseas SIM, you’ll see them on a scan. Have also had a world of a time with a French SIM refuse to connect to a Canadian tower because it really preferred the US towers (lower roaming costs maybe?). reply lxgr 5 hours agorootparentprevHuh, are you sure that's true? I was under the impression that most European countries were keeping 2G around for legacy applications and voice calls on roaming (until VoLTE roaming and emergency calls finally become equally reliable), shutting down 3G if anything? reply LZ2DMV 11 hours agoparentprevThe problem is mostly the insecure defaults. Every modern phone is configured to be backward compatible and connect to an older generation of network if a newer generation is not present (like in the case of being deliberately jammed by an adversary). In 2G, mutual authentication is not existent, it happens only one way - only the network authenticates the handset. If you are close enough to the victim (only screaming louder, i.e. more power than the legitimate network, but from a significant distance doesn't work, because of the RTT of the signal - TDMA-based systems are very time-sensitive in nature), nothing prevents you from operating your own mobile infrastructure and disable any encryption (i.e. in 2G, during the handshake, you just say A5/0 - no encryption, to the handset) - you can not enable encryption anyway, because you do not have the corresponding key that is on the SIM card, only the legitimate carrier has that. Whether or not the victim will be notified about the absence of encryption, depends on the state of a single bit on the SIM card [1]. In 99% of the cases, there is no warning that the handset is currently using A5/0. From now on, you are at the grace of the rogue network operator - they can send you anything from any number, sit in the middle of every call and capture every frame of data. I don't think the current level of technological education of the general public is enough for most of them to know why it is important to force your phone to work only with modern network standards and that is what police and other government agencies interested in operating IMSI catchers exploit. [1] http://blog.taddong.com/2011/02/does-your-phone-warn-you-whe... reply seabass-labrax 9 hours agorootparent> ...that is what police and other government agencies interested in operating IMSI catchers exploit. Is encryption really significant to whether or not the police are able to monitor cellular phones? As bandwidth is already centrally allocated, there is a limited number of legal cellular network operators, and a competent authority could already compel (indeed, could have already compelled) mobile operators to provide master keys and diversification information under the Snooper Charter 2016[1]. https://www.legislation.gov.uk/ukpga/2016/25/ reply LZ2DMV 8 hours agorootparentThis implies compliance with the law and a formal procedure, and an authority might not always follow the law for various reasons. At least the use of encryption means one is less likely to be a subject of surveillance in an unlawful manner. Consider intelligence operation abroad, for example. reply tiku 12 hours agoprevWhy is sms such a crappy protocol that this is even possible? reply robaato 10 hours agoparentIt was a hack to use \"unused\" control/signalling paths - see https://en.wikipedia.org/wiki/SMS Effectively came \"for free\" for mobile operators... reply lxgr 6 hours agorootparentThat’s a common misconception. The signaling channels used aren’t “unused” – they’re literally set up and torn down to deliver SMS! reply aidenn0 57 minutes agorootparentI think you meant to end that with \"phone calls\" rather than \"to deliver SMS?\" SS7 was used for that, but had a significant amount of idle time since most phone calls are much longer than the time needed to setup the connection. reply lxgr 15 minutes agorootparentI do indeed mean SMS, but I was focusing more on the air interface. There, SMS definitely consume resources in the same way that calls do (although of course at a very different rate: SDCCH uses 0.8 kbit/s, as opposed to 13 kbps for full rate voice/CSD traffic channels). reply dotancohen 11 hours agoparentprevBecause it dates to a time when such attacks were infeasible. GPS is very similar in that regard. Even HTTPS was uncommon back when I was in university. NASA spacecraft still communicate over unencrypted channels. Mindsets were different then. reply nanna 1 hour agorootparentAlso to a dumb phone it doesn't matter whether an SMS contains a phishing link because it has no way of accessing it. Until the advent of smart phones SMS phishing was a non-issue. reply fragmede 11 hours agorootparentprevnot just mindsets, but the computing power available. These days, my smartphone is millions of times more powerful and the computation to do TLS encryption on every website I visit is trivial for a computer that fits in the palm of my hand. Way back when, the 1 or 2 kilobytes or so a modern RSA private key (PEM format) would take up on disk was meaningful when you only had 4 megabytes of RAM and CPUs ran in the megahertz range. reply oldgradstudent 11 hours agorootparentprev> GPS is very similar in that regard. GPS originated as a military protocol and has some level of encryption and authentication, but this is not available to the general public. reply GJim 9 hours agorootparentGPS *had* no encryption or authentication; indeed, such security is only a recent addition to the L2 frequency. USK: Galileo also has authentication available on its civilian frequencies. reply lxgr 5 hours agorootparent> such security is only a recent addition to the L2 frequency Is that already available? I thought GPS L2C didn't include authentication yet. reply sunbum 12 hours agoparentprevSMS isn't a protocol. Attacks like these are done via 2G. Which is really why most people should disable it if they can. reply est 11 hours agoparentprevencryption was expensive in GSM days. People seem to forget that dedicated TLS acceleration hardware was a thing not long ago. reply usr1106 12 hours agoprevnext [13 more] Cloudflare turnstyle making government resources inaccessible (it's always an endless loop of clicking that I am human on my mobile) reply randunel 12 hours agoparentSame here, I cannot access that website, it's an infinite turnstile loop. Same issue with hibp, as far as I can see. reply moomin 10 hours agorootparentPretty ironic considering it’s the City of London Police website. If malicious clients want to try their luck, I’d say let them. reply Perz1val 11 hours agoparentprevLets me in on my microg lineageos with brave browser reply pheggs 12 hours agoparentprevhow certain are you actually that you are not an android? :) reply happymellon 9 hours agorootparentThis comment instantly made me think of this. https://en.m.wikipedia.org/wiki/The_6th_Day Apparently it was also Terry Crews acting debut. reply szundi 9 hours agorootparentprevWe are bio androids anyway reply jgrahamc 5 hours agoparentprevIf you hit a problem like this I'd like to hear about it. If you're willing I an take a HAR file and pass it on to the Turnstile team and they can see why. reply Traubenfuchs 12 hours agoparentprevYou are probably using the suspicious setup Cloudflare wants to lock out. Please try again with Google (R) Chrome (TM), no experience manipulating addons (e.g. adblockers), no VPN and from a non-non-friendly country. reply jeroenhd 9 hours agorootparentWorks fine on Firefox from a custom Android ROM through a VPN here. Last time I checked a post where people complained about Cloudflare, even Ladybird for Android made it through. You need cookies and Javascript, but that's all you need to pass the technical checks it seems. Cloudflare likes to block things like Tor and CGNAT because of the abuse and unidentifiability those networks provide, and maybe there's a filter on some enemy states set up by the British government, but they really don't seem to care all that much about what you're running on your phone. Blocks seem to be largely network-based in my experience. reply mdp2021 11 hours agorootparentprevIt is not that, it works on some odd setups. reply tgv 9 hours agorootparentprevI can access with Firefox, macOS, UBlock Origin. reply cqqxo4zV46cp 9 hours agorootparentprevThis is absurdly dishonest. I don’t use Chrome. I use a VPN sometimes, when I’m travelling, in a DigitalOcean IP range (which has a dubious reputation). I don’t live in the US or Europe, which is often Californian for ‘a list of trusted countries’. I’ve never, once, ever, had an issue with CloudFlare. The regular vocal super-minority of people that have this issue need only expose the fact that they’re running Lynx on their Gentoo-powered toaster, upside down, on the international space station. reply cjrp 12 hours agoprevSlightly more detail on The Register: https://www.theregister.com/2024/06/10/two_arrested_in_uk_ov... Sounds like they were using a Stingray-esque device, as the police do. reply dang 1 hour agoparentThanks! We've changed to that from https://www.cityoflondon.police.uk/news/city-of-london/news/... now. reply skilled 3 hours agoparentprevI have emailed mods to ask for a link update so your comment can be demoted, and more room given for discussion. Thanks for pointing it out, did not see/check when submitting. reply jack_riminton 12 hours agoprevFor those unaware the \"City of London\" is in fact a small part of London, what you might call downtown, and they have their own police force. fwiw they're regarded as a very competent police force reply justinclift 9 hours agoparent> fwiw they're regarded as a very competent police force That's not at all the reputation they have. They've been acting as an extension of the copyright lobby for years: • https://torrentfreak.com/new-uk-police-unit-announces-two-ar... • https://www.vice.com/en/article/bvn4nw/cops-arrest-3-people-... • https://www.cityoflondon.police.uk/news/city-of-london/news/... There are probably hundreds of instances of them doing stuff like the above, that was just the results from a quick search. reply socksy 4 hours agorootparentTo be fair, a police force doing stuff you don't like doesn't necessarily mean that they're incompetent at doing those things reply justinclift 3 hours agorootparentSure. But their reputation is pretty much \"police force for hire\" rather than anything to do with competence. reply dubcanada 1 hour agorootparentBut isn't that what police are? I don't see a ton of volunteer police... reply andylynch 26 minutes agorootparentprevIt’s not a conspiracy; the City of London police, alongside normal local duties, have a national responsibility for many kinds of economic and cyber crime. This almost certainly comes from long experience investigating fraud and other financial crimes amongst the businesses and people based there, to a degree and level of complexity not found in other regions of the UK. For instance they host Action Fraud for the entire country. If you want to talk about enforcement priorities, contact your PCC, or better yet, right now, your local candidates. reply Doe-_ 2 hours agorootparentprevThe City is also unique in that businesses represent the majority of the voters in its council elections. Moreover, the council is also the police authority, which could explain a more active copyright infringement force. reply jack_riminton 9 hours agorootparentprevPersonal opinion may vary reply euroderf 8 hours agoparentprevIt's more like an autonomous enclave free of any control by Parliament. The Guardian plumbs the depths once in a while, such as in this article: https://www.theguardian.com/commentisfree/2011/oct/31/corpor... reply walthamstow 8 hours agorootparentIt's not the Wild West, the laws of the UK Parliament apply to people and companies in the City. In that piece Monbiot tries to blame the Corporation for the 2008 crash, which is laughable. reply fragmede 11 hours agoparentprevGCP Grey on the city of London: https://youtu.be/LrObZ_HZZUc reply mintplant 11 hours agorootparentMap Men on London's 32 boroughs: https://www.youtube.com/watch?v=daeB46Z4fjs reply jack_riminton 10 hours agorootparentprevAs a londoner, even I learned several things from that video. And it's done by an American! reply oakesm9 8 hours agorootparentHe's american, but moved to the UK to study and then become a Physics teacher in London. I think he's been London based for all of his YouTube career. reply cjk2 12 hours agoparentprevapart from the financial crimes unit... reply LAC-Tech 11 hours agoparentprevfwiw they're regarded as a very competent police force What makes them different? reply jack_riminton 11 hours agorootparentWell it’s a reputation, so it’s hard to quantify. But anecdotally I’ve heard from numerous people who had dealings with that they were very competent (compared to most British forces presumably). I’ve also heard that their average level of policeman is more educated , ie many holding degrees, masters etc. I presume this must be due to the nature of the work they’re most known for ie combatting complex fraud, organised crime etc reply walthamstow 8 hours agorootparentThey have about 1 officer per 10 people living there which helps quite a bit For reference, the Met has 33k officers for 10m people reply Steve44 42 minutes agorootparentThere is one very important caveat about the population of the City though. Whilst there are only 8,600 residents, there are apparently over 600,000 commuters working there every day. https://www.cityoflondon.gov.uk/about-us/about-the-city-of-l... reply OJFord 8 hours agorootparentprevBecause policing is all about who's resident in the territory covered? reply r-w 7 hours agorootparentGood point, bad tone :) reply walthamstow 8 hours agorootparentprevIs that what I said? Nope reply razakel 10 hours agorootparentprevTheir focus is more on complex financial crimes, so they're a bit better educated than your typical cop. reply mytailorisrich 11 hours agorootparentprevThe City of London is very small, safe (quick look online returns that the crime rate is \"73% lower than London and 67% lower than national average\"), and very rich, and obviously right in the middle of a top world city. So I am guessing that their police force is well resourced, able to attract \"top talent\", and not bogged down by anti-social and petty crime. reply gadders 9 hours agorootparentIt's also mostly an office district. Not many people live there. It's mostly a ghost town at night and weekends. reply LAC-Tech 10 hours agorootparentprevI'm always suspicious of low crime rates - often it means people don't bother reporting crimes as they know nothing will happen. IE, if I get robbed in the City of London is it even worth calling the police? reply cannonpr 9 hours agorootparentYes it is, a friend had their laptop stolen, the police tracked down the offenders within 2 hours and returned the items. What they also don’t tell you is that it’s a dystopian panopticon and runs on a slightly different legal system than the rest of the U.K. reply mytailorisrich 9 hours agorootparentprevWhy would there be a difference in reporting in the City vs the rest of London? reply andylynch 15 minutes agorootparentThe City Police have a very, small patch and little violent crime, but are geared up to deal with IRA/ISIS-type threats. Part of this means they have surveillance coverage of virtually the entire areas. It also mean that they can get anywhere very, very quickly. reply bloqs 11 hours agorootparentprevThey have different branding from the rest of the police forces! reply bloqs 11 hours agoprevThis is the police force for the ancient financial district in London called the City of London. Best explanation: https://youtu.be/LrObZ_HZZUc reply scoot 9 hours agoparentThe former financial district. The financial district has long since migrated to Canary Wharf and, since Brexit, increasingly overseas. reply gadders 9 hours agorootparentCompanies are moving back out of the Wharf to the City. >>and, since Brexit, increasingly overseas And this isn't even remotely true. reply swiftcoder 8 hours agoprevI enjoyed the \"Sorry, there was a technical problem. Please try again.\" when I tried to reject cookies reply exabrial 3 hours agoprevnext [2 more] Oh good, we better make sure we tie our bank accounts to SMS reply dang 1 hour agoparentCould you please stop posting unsubstantive comments and flamebait? You've unfortunately been doing it repeatedly. It's not what this site is for, and destroys what it is for. If you wouldn't mind reviewing https://news.ycombinator.com/newsguidelines.html and taking the intended spirit of the site more to heart, we'd be grateful. reply ReptileMan 11 hours agoprevTrivial to make one - you just need a SDR and encryption key (harder to obtain, but probably could be found on the black market). reply lxgr 6 hours agoparentYou don’t need any key for GSM, since the network/base station only started authenticating itself to the phone/SIM with 3G. That’s why it would be good to shut down GSM at some point: It would raise the difficulty of such attacks significantly. What I don’t understand is how they managed to actually intercept any SMS with an IMSI catcher. They’d need to get the network to send these through their infrastructure, so I wonder how that worked? Update: Ah, they were just sending out texts themselves, not intercepting anything. reply bestbuyer__ 8 hours ago [flagged]parentprevThis is giving off HackerNews DropBox vibes :) reply shiroiushi 11 hours ago [flagged]prev [11 more] People in the UK still use SMS? reply johneth 9 hours agoparentIt's almost exclusively used by businesses and government to send notifications. They use SMS because it's a baseline that every phone, smart or dumb, has. No need to have an email address, no need to have an app. Most people use Whatsapp / Messenger / social media / to a lesser extent iMessage. reply denton-scratch 8 hours agorootparent> because it's a baseline that every phone, smart or dumb, has My phone is an IP phone. It doesn't do SMS. Did you mean \"mobile phone\"? > No need to have an email address I'm pretty sure that more people have an email address but no SMS capability, than have SMS but no email capability. reply johneth 3 hours agorootparent> My phone is an IP phone. It doesn't do SMS. Did you mean \"mobile phone\"? UK landlines are transitioning to VoIP. SMS messages sent to UK landlines are read out by a text-to-speech system (well, my parents' does). reply denton-scratch 3 hours agorootparentYes; mine does that too. Have you ever tried to use one of those TTS systems? They can just about read standard international English; anything more interesting, like someone's name, and they fall back to spelling-out the letters. reply mdp2021 11 hours agoparentprev> still use SMS? Instead of? If you have to send text to an occasional user, what do you think should be used? The article is about /receiving/ messages supposedly from firms. How should they have sent it? reply lrvick 11 hours agorootparentMaybe something with at least TLS like email. reply mdp2021 10 hours agorootparentThe issue with those kind of messages is sender authentication, not content confidentiality. reply porker 10 hours agoparentprevThe National Health Service communicates with people via SMS. The NHS has an app, but doesn't send notifications through it. My guess is because our population can all cope with SMS by now, but anything more... reply denton-scratch 8 hours agorootparentHMRC also seems to require an SMS-capable device for 2FA. Using the HMRC website is a soul-destroying adventure through severe speed-bumps, short session timeouts, and 72-hour delays. It's the epitome of awful, large-scale British public computer-system acquisition. reply Havoc 10 hours agoparentprev [–] People not so much but services yes reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "British police have arrested two individuals involved in an SMS-based phishing (smishing) campaign using a homemade \"text message blaster\" to send thousands of fraudulent texts.",
      "The suspects impersonated banks and official organizations to deceive recipients, with one identified suspect, Huayong Xu, charged and set to appear in court.",
      "The investigation, involving network operators, Ofcom, and the National Cyber Security Centre (NCSC), highlights the importance of reporting suspicious messages to 7726."
    ],
    "commentSummary": [
      "Two British individuals were arrested for SMS phishing using a homemade cell tower built with Software-Defined Radio (SDR) and open-source software.",
      "The article discusses the ease of creating such systems and anti-spam measures by phone providers, including reporting suspicious texts to numbers like 7726 (SPAM).",
      "The conversation highlights the sophistication of spectrum monitoring in cities, especially in high-risk areas like central London, and the involvement of various authorities."
    ],
    "points": 154,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1718084413
  }
]
