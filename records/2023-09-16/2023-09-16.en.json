[
  {
    "id": 37526047,
    "title": "My favourite API is a zipfile on the European Central Bank's website",
    "originLink": "https://csvbase.com/blog/5",
    "originBody": "csvbase Paste/Upload Convert Pricing Blog About Register csvbase is a simple web database. Learn more on the about page. Simple data pipeline powertools: sqlite, pandas, gnuplot and friends Why my favourite API is a zipfile on the European Central Bank's website 2023-09-13 by Cal Paterson When was the Dollar highest against the Euro? Here is a small program that calculates it: curl -s https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.zip \\gunzip \\sqlite3 -csv ':memory:' '.import /dev/stdin stdin' \\ \"select Date from stdin order by USD asc limit 1;\" The output: 2000-10-26. (Try running it yourself.) How it works: The curl bit downloads the official historical data that the European Central Bank publishes on the position of the Euro against other currencies. (The -s flag just removes some noise from standard error.) That data comes as a zipfile, which gunzip will decompress. sqlite3 queries the csv inside. :memory tells sqlite to use an in-memory file. After that, .import /dev/stdin stdin tells sqlite to load standard input into a table called stdin. The string that follows that is a SQL query. Cleanup in column 42 Although pulling out a simple max is easy, the data shape is not ideal. It's in \"wide\" format - a Date column, and then an extra column for every currency. Here's the csv header for that file: Date,USD,JPY,BGN,CYP,CZK,DKK,EEK,GBP,HUF,LTL,LVL,MTL,[and on, and on] When doing filters and aggregations, life is easier if the data is in \"long\" format, like this: Date,Currency,Rate Switching from wide to long is a simple operation, commonly called a \"melt\". Unfortunately, it's not available in SQL. No matter, you can melt with pandas: curl -s https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.zip\\ gunzip\\ python3 -c 'import sys, pandas as pd pd.read_csv(sys.stdin).melt(\"Date\").to_csv(sys.stdout, index=False)' There is one more problem. The file mungers at ECB have wrongly put a trailing comma at the end of every line. The makes csv parsers pick up an extra, blank column at the end. Our sqlite query didn't notice, but these commas interfere with the melt, creating a whole set of junk rows at the end: The effects of that extra comma can be removed via pandas by adding one more thing to our method chain: .iloc[:, :-1], which effectively says \"give me all rows (\":\") and all but the last column (\":-1\"). So: curl -s https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.zip\\ gunzip\\ python3 -c 'import sys, pandas as pd pd.read_csv(sys.stdin).iloc[:, :-1].melt(\"Date\")\\ .to_csv(sys.stdout, index=False)' Does everyone who uses this file have to repeat this data shitwork? Tragically, the answer is yes. As they say: \"data janitor: nobody's dream, everyone's job\". In full fairness, though, the ECB foreign exchange data is probably in the top 10% of all open data releases. Usually, getting viable tabular data out of someone is a much more tortuous and involved process. Some things we didn't have to do in this case: negotiate access (for example by paying money or talking to a salesman); deposit our email address/company name/job title into someone's database of qualified leads, observe any quota; authenticate (often a substantial side-quest of its own), read any API docs at all or deal with any issues more serious than basic formatting and shape. So eurofxref-hist.zip is, relatively speaking, pretty nice actually. But anyway - I'll put my cleaned up copy into a csvbase table so you, dear reader, can skip the tedium and just have fun. Here's how I do that: curl -s https://www.ecb.europa.eu/stats/eurofxref/eurofxref-hist.zip\\ gunzip\\ python3 -c 'import sys, pandas as pd pd.read_csv(sys.stdin).iloc[:, :-1].melt(\"Date\")\\ .to_csv(sys.stdout, index=False)'\\ # this is the new bit: \\ curl -n --upload-file - \\ 'https://csvbase.com/calpaterson/eurofxref-hist?public=yes' All I've done is add another curl, to HTTP PUT the csv file into csvbase. --upload-file - uploads from standard input to the given url (via HTTP PUT). If the table doesn't already exist in csvbase, it is created. -n adds my credentials from my ~/.netrc. That's it. Simples. Drawing pretty graphs Alright, now the data cleaning phase is over, let's do some more interesting stuff. Let's graph the data: curl -s https://csvbase.com/calpaterson/eurofxref-hist\\ grep USD\\ cut --delim=, -f 2,4\\ gnuplot -e \"set datafile separator ','; set term dumb; \\ plot '-' using 1:2 with lines title 'usd'\" That's somewhat legible for over 6000 datapoints in an 80x25 character terminal. You can make out the broad trend. A reasonable data-ink ratio. (If you're wondering how https://csvbase.com/calpaterson/eurofxref-hist returns a webpage to your browser but a csv file to curl, see an earlier blogpost.) gnuplot is like a little mini-programming language of it's own. Here's what the above snippet does: set datafile separator ',' - says it's a csv set term dumb - draw ascii-art! plot - plot the data coming from standard input using 1:2 with lines draw lines from columns 1 and 2 (the date and the rate respectively) title 'usd' name the line You can, of course, also draw graphs to proper images: curl -s https://csvbase.com/calpaterson/eurofxref-hist\\ grep USD\\ cut --delim=, -f 2,4\\ gnuplot -e \"set datafile separator ','; set term svg; \\ set output 'usd.svg'; set xdata time; set timefmt '%Y-%m-%d'; \\ set format x '%Y-%m-%d'; set xtics rotate; \\ plot '-' using 1:2 with lines title 'usd'\" Outputting to SVG is only a bit more complicated than ascii art. In order for it look decent you need to help gnuplot understand that it's \"timeseries\" data - ie: that the x axis is time; give a format for that time and then tell it to rotate the markings on the x axis so that they are readable. It's a bit wordy though: let's bind it to bash function so we can reuse it: plot_timeseries_to_svg () { # $1 is the first param gnuplot -e \"set datafile separator ','; set term svg; \\ set output '$1.svg'; set xdata time; set timefmt '%Y-%m-%d'; \\ set format x '%Y-%m-%d'; set xtics rotate; \\ plot '-' using 1:2 with lines title '$1'\" } Rolling averages and new tools So far, so good. But it would be nice to try out more sophisticated analyses: let's try putting a nice rolling average in so that we can see a trend line: curl -s https://csvbase.com/calpaterson/eurofxref-hist\\ duckdb -csv -c \"select Date, avg(value) over \\ (order by date rows between 100 preceding and current row) \\ as rolling from read_csv_auto('/dev/stdin') where variable = 'USD';\"\\ plot_timeseries_to_svg rolling Smooth. If you don't have duckdb installed, it's not hard to adapt the above for sqlite3 (the query is the same). DuckDB is a tool I wanted to show because it's a lot like sqlite but instead is columnar (rather than row-oriented). However for me the main value is that it has a lot of easy ergonomics. Here is one of them: you can load csvs into table files straight from HTTP: -- it works with csvbase! CREATE TABLE eurofxref_hist AS SELECT * FROM read_csv_auto(\"https://csvbase.com/calpaterson/eurofxref-hist\"); That's pretty easy, and DuckDB does a reasonable job of inferring types. There are a lot of other usability niceties too: for example, it helpfully detects your terminal size and abridges tables by default rather than flooding your terminal with an enormous resultset. It has a progress bar for big queries! It can output markdown tables! Etc! Open data is also an open API A lot is possible with a zipfile of data and just the programs that are either already installed or a quick brew install/apt install away. I remember how impressed I was when I was first shown this eurofxref-hist.zip by an old hand from foreign exchange when I worked in a bank. It was so simple: the simplest cross-organisation data interchange protocol I had then seen (and probably since). A mere zipfile with a csv in it seems so diminutive, but in fact an enormous mass of financial applications use this particular zipfile every day. I'm pretty sure that's why they've left those commas in - if they removed them now they'd break a lot of code. When open data is made really easily available, it also functions double duty as an open API. After all, for the largeish fraction of APIs in which are less about calling remote functions than about exchanging data, what is the functional difference? So I think the ECB's zipfile is a pretty good starting point for a data interchange format. I love the simplicity - and I've tried to keep that with csvbase. In csvbase, every table has a single url, following the form: https://csvbase.com// eg https://csvbase.com/calpaterson/eurofxref-hist And on each url, there are four main verbs: When you GET: you get a csv (or a web page, if you're in a browser). When you PUT a new csv: you create a new table, or overwrite the existing one. When you POST a new csv: you bulk add more rows to an existing table. When you DELETE: that table is no more. To authenticate, just use HTTP Basic Auth. Could it be any simpler? If you can think of a way: write me an email. Notes I said above that most SQL databases don't have a \"melt\" operation. The ones that I know of that do are Snowflake and MS SQL Server. One question that SQL-knowers frequently ask is: why does anyone use R or Pandas at all when SQL already exists? A key reason is that R and Pandas are very strong on data cleanup. One under-appreciated feature of bash pipelines is that they are multi-process. Each program runs independently, in it's own process. While curl is downloading data from the web, grep is filtering it, sqlite is querying it and perhaps curl is uploading it again, etc. All in parallel, which can, surprisingly, make it very competitive with fancy cloud alternatives. Why was the Euro so weak back in 2000? It was launched, without coins or notes, in January 1999. The Euro was, initially, a sort of in-game currency for the European Union. It existed only inside banks - so there were no notes or coins for it. That all came later. So did belief - early on it didn't look like the little Euro was going to make it: so the rate against the Dollar was 0.8252. That means that in October 2000, a Dollar would buy you 1.21 Euros (to reverse exchange rates, do 1/rate). Nowadays the Euro is much stronger: a Dollar would buy you less than 1 Euro. Source code Privacy policy Terms",
    "commentLink": "https://news.ycombinator.com/item?id=37526047",
    "commentBody": "My favourite API is a zipfile on the European Central Bank&#x27;s websiteHacker NewspastloginMy favourite API is a zipfile on the European Central Bank&#x27;s website (csvbase.com) 869 points by qsantos 17 hours ago| hidepastfavorite232 comments stevoski 14 hours agoAh, I remember this specific file from my time at the ECB 15-ish years ago.IIRC it was by far the most downloaded file on the ECB website. Tons of people, including many financial institutions, downloaded it daily, and used it to update their own systems.IIRC #2 in the minutes immediately after the daily scheduled time for publishing this file, there was a massive traffic spike.It was a conscious decision to make it a simple CSV file (once unzipped): it made it possible to serve the file reliably, fast, and with little resources needed.The small team responsible at the time for the ECB’S public website was inordinately proud of the technical decisions made to serve this data in a single static file. And rightly so. reply tharkun__ 10 hours agoparentThis is something that powers a lot of data interchange but lots of people don&#x27;t realize because they never work with older systems like that. It&#x27;s not shiny. No frameworks.I used to work for a large, old company whose products you have all bought and buy (and which shall remain nameless) about 15 years ago. I worked on data interchange between the systems used for record keeping of said products and various other downstream or parallel systems (same purpose, separate system because left over from merger&#x2F;acquisition).So basically bulk data import and export. The product was 15 years old at that point. Data interchange was via various fixed width or delimited (CSV but the C might be some other character or character sequence) files transferred to and from various SFTP servers.It&#x27;s been a while but there were probably like 20 or 30 different such data sources or exports going in and out. Worked like a charm. I bet they&#x27;re still used without much change. The frontend was being rewritten at the time (old one was in Smalltalk). reply keepamovin 9 hours agorootparentI&#x27;m using this type of simple approach to build a SaaS right now. We need to spin up many VPS and provision them, and the fastest way to do that is with rsync and ssh.But we didn&#x27;t stop there: this SaaS for our open source browser product is entirely built like this: behind the scenes it&#x27;s a collection of bash scripts that implement and execute the business operation of the SaaS.So basically, it&#x27;s a command-line interface to the SaaS. Think of it this way, say I didn&#x27;t have a website, with login, and \"click a button to open a browser\", but instead people would write me letters, send me cheques, or call me on the phone. Then I can serve their requests manually, at the command line.The reason I made it like this was:- clear separation between thin web front-end and actual business logic- nice command-line interface (options, usage, help, clear error messages) to business logic for maintenance and support to jump on and fix things- inheritance of operating system permissions and user process isolation- highly testable implementationMaybe this is dumb, but I really like it. To me it&#x27;s an architecture and approach that makes sense.I&#x27;m sure this is not new, and I think a lot of good quality operations must be built via this way. I highly align with the author&#x27;s stance of the composition of a few simple command line tools to get the job done.Perhaps we can call this \"unix driven development\", or \"unix-philosophy backend engineering\"browser product: https:&#x2F;&#x2F;github.com&#x2F;dosyago&#x2F;BrowserBoxPro (saas coming soonish) reply fourstepper 3 hours agorootparentI feel like you went way overboard with this one.. I think the first paragraph and an example of what you&#x27;re doing that&#x27;s similar to OP would&#x27;ve been plenty reply PH95VuimJjqBqy 1 hour agorootparentprevA lot of developers talk smack about CSV files (or tab delimited) but they really are the workhorse of our industry. They&#x27;re simple, textual, compress really well, and as long as everyone on both sides has an agreement about the format, they&#x27;re almost a standard.sure, a lot of the criticisms of CSV are true, but given the above constraints it&#x27;s really hard to beat them. reply sambazi 1 hour agorootparent\"everything is a file\" still going strong reply leokennis 4 hours agoparentprevWow. I’m just thinking of the hoops I’d have to go through to host changing data as a static CSV&#x2F;ZIP at my employer.Architects would complain ZIP isn’t a format conform to their specs for this purpose. Compliance would complain there needs to be a check that no private informatie leaked. Risk that I should prevent bad actors from downloading the file. Web people that I need an approved change to add stuff to the site. reply TeMPOraL 2 hours agorootparentYeah, but modern, approved practices don&#x27;t really address any of that - they just hide it under a pile of extra complexity that&#x27;s too big for most devs and managers&#x27; attention span, effectively disappearing it. reply andylynch 14 hours agoparentprevI know this file too, I was one of them. Of all the data sources we used, it was the best to work with. reply mstade 11 hours agoparentprevDo you know why they decided to host a zip file instead of just hosting the CSV and relying on HTTP compression? reply theamk 11 hours agorootparentHTTP compression is optional, so they either have to compress on the fly (wasting cpu) or provide multiple versions (complicating setup and deployment) or make some HTTP clients not work.simgle zip file is really the easiest solution for cases when the file must absolutely be compressed reply sethhochberg 10 hours agorootparentMany webservers allow you to serve a compressed file (stored on disk) and _decompress_ when a client specifically can&#x27;t support the compressed encoding. Since most clients should support compression, this means you only use the CPU for the rarer case where the uncompressed data is required.Eg, http:&#x2F;&#x2F;nginx.org&#x2F;en&#x2F;docs&#x2F;http&#x2F;ngx_http_gunzip_module.html reply nikau 9 hours agorootparentOr you can just zip it explicitly and remove complexity and future issues it they have to move to another web server platform. reply MengerSponge 9 hours agorootparentBut what if an analyst needs to access this data and run their regressions on a potato? Surely that use case is worth adding a few libraries to handle. reply innocenat 8 hours agorootparentI would think running regression should be more demanding on the potato then decompressing ZIP file. reply CJefferson 7 hours agorootparentprevWhat machine could anyone be running an analysis on where unzip is a limiting factor? reply londonReed 6 hours agorootparentWhoosh reply nikau 1 hour agorootparentprevhmm good point, can you draft up an architecture plan using multiple microservices and redundancy via a kubernetes cluster and have it on my desk by Monday please. reply avandelay1 9 hours agorootparentprevNginx or Apache would both cache these versions transparently. I think they just wanted to distribute as a zip reply anakaine 9 hours agorootparentThe business logic here is >15 years old. Http compression was only in early stages then, and you can guarantee that many client side scripts and libraries would jot have supported it. Zip was well known. Compress and place.If I&#x27;m not missing the point here, this was, and still is, about offering the simplest, most reliable solution over a long period. This is a near perfect example of how to do exactly that. No changing formats, no moving requirements, no big swings in frameworks, apis, or even standards. And most importantly, no breaking your customers business workflows. reply skylanh 8 hours agorootparentNo edge case dependencies on the WWW server&#x27;s configuration, and no sudden \"why did we just saturate our external connection?\"No emergency change requests from the outage team that has to be impacted by other areas and fit into the infrastructure&#x27;s teams maintenance windows and their capacity to address that.No rebalancing of workloads because Jane had to implement (or schedule the task and monitor it) that change, Joe had to check and verify that the external availability tests passed, and Annick had to sign off on the change complete, and now everyone isn&#x27;t available for another OT window for the week.Or something. reply firecall 9 hours agorootparentprevMaybe in part because it encourages you to work with a local copy, rather than just hitting the hosted .csv repeatedly?Just guessing. I have no idea :-) reply mmis1000 5 hours agorootparentIt it exactly what most api optimization does. For example, batch queries merge several api calls into one to reduce api call counts. And it this case, it is perfectly optimized. You have literally one zip file, and there is no more. reply Nux 11 hours agorootparentprevI could see 2 reasons:1 - save on cpu usage, compress once, serve many2 - with zip you can have some rudimentary data integrity checks (unzip -t) reply rsaxvc 10 hours agorootparentprevThe CSV was available at https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.csv but isn&#x27;t up to date. reply pstuart 10 hours agorootparentprevAnother option would be save it as a gzip file and serve it raw with implied gzip compression.Nginx does this: https:&#x2F;&#x2F;docs.nginx.com&#x2F;nginx&#x2F;admin-guide&#x2F;web-server&#x2F;compress...Last entry: the directive is `gzip_static on;` reply nlehuen 12 hours agoparentprevIt&#x27;s a bit scary to imagine the consequences if this file was somehow corrupted (wrong column headers for instance)! reply thghtihadanacct 11 hours agorootparentJust wait until you inherit a service that, sans documentation, pulls in a web resource file that suddenly is no longer available :( reply dizhn 2 hours agorootparentscale8 recently archived their GitHub repo without explanation and right after that the url for a GDPR opt-in list they were using changed. The product is now dead because the code doesn&#x27;t handle the situation where that file might not be available.(Scale8 is a web analytics and tag management software like google analytics) reply NelsonMinar 16 hours agoprevSimple file downloads and CSV files are fantastic. I wish more folks would publish data in simple formats like this. Every time I have to fill a \"shopping cart\" for a US government data download I die a little.There&#x27;s a bunch of wrapper tools to make this particular pipeline easier. Also something like Datasette is great if you want a web view and some fancier features. reply wefarrell 13 hours agoparentOne nice thing about CSV files being zipped and served via the web is they can be streamed directly into the database incredibly fast without having to persist them anywhere (aside from the db).You can load the zip file as a stream, read the CSV line by line, transform it, and then load it to the db using COPY FROM stdin (assuming Postgres). reply thibaut_barrere 12 hours agorootparentDefinitely, it is much easier to stream CSV than say JSON or XML (even if JSONL&#x2F;Sax parsers exist etc). reply eastbound 12 hours agorootparentprevI you feel risky, try a Foreign Data Wrapper ;) reply heavenlyblue 13 hours agorootparentprevThat doesn&#x27;t sound like an amazingly safe idea reply berkes 12 hours agorootparentIt isn&#x27;t. But that&#x27;s easily mitigated with temp tables, ephemeral database and COPY etc.Upstream can easily f-up and (accidentally) delete production data if you do this on a live db. Which is why PostgreSQL and nearly all other DBS have a miriad of tools to solve this by not doing it directly on a production database reply wefarrell 9 hours agorootparentMaybe I&#x27;m missing something but I don&#x27;t see how it&#x27;s possible for a COPY statement alone to remove existing data. reply LgWoodenBadger 7 hours agorootparentIf in the regular scenario you load 10000 rows of new data and delete the old then it’s fine.What if someone screws up the zip and instead of 10000 today, it’s only 10? reply aidos 2 hours agorootparentI had this last week, but instead it was a 3rd party api and their service started returning null instead of true for the has_more property beyond the second page of results.In either the solution is probably to check rough counts and error if not reasonable. reply dambi0 13 hours agorootparentprevWhat specific risks do you foresee with this approach? reply diroussel 13 hours agorootparentSeem totally fine to me. As long as you can rollback if the download is truncated or the crc checksum doesn’t match. reply chii 5 hours agorootparent> or the crc checksum doesn’t match.which wouldn&#x27;t exist if the api is simply just a single CSV file?at least with a zip, the CRC exists (an incomplete zip file is detectable, an incomplete, but syntactically correct CSV file is not) reply NL807 4 hours agorootparentprevDROP DATABASE blah; reply aidos 2 hours agorootparentThat’s not how COPY FROM works in postgres. You give it a csv and a table matching the structure and it hammers the data into the table faster than anything else can. replyusername_my1 15 hours agoparentprevit blows my mind that you can use sqlite with csv as input and then query it, it sounds so logical and useful yet I never came by it.we have lots of reporting in CSV, can&#x27;t wait to start using it to run queries quickly reply shortrounddev2 14 hours agorootparentYou should checkout powershell; it supports converting CSV into in-memory structured data and then you can run regular powershell queries on that data: $> csvData = @\" Name,Department,Salary John Doe,IT,60000 Jane Smith,Finance,75000 Alice Johnson,HR,65000 Bob Anderson,IT,71000 \"@; $> csvDataConvertFrom-CsvSelect Name, SalarySort Salary -Descending Name Salary ---- ------ Jane Smith 75000 Bob Anderson 71000 Alice Johnson 65000 John Doe 60000You can also then convert the results back into CSV by piping into ConvertTo-Csv $> csvDataConvertFrom-CsvSelect Name, SalarySort Salary -DescendingConvertTo-Csv \"Name\",\"Salary\" \"Jane Smith\",\"75000\" \"Bob Anderson\",\"71000\" \"Alice Johnson\",\"65000\" \"John Doe\",\"60000\" reply llimllib 14 hours agorootparentnushell does too: &#x2F;tmp&#x2F;> \"Name,Department,Salary ::: John Doe,IT,60000 ::: Jane Smith,Finance,75000 ::: Alice Johnson,HR,65000 ::: Bob Anderson,IT,71000\"::: from csv::: select Name Salary::: sort-by -r Salary ╭───┬───────────────┬────────╮ │ # │ Name │ Salary │ ├───┼───────────────┼────────┤ │ 0 │ Jane Smith │ 75000 │ │ 1 │ Bob Anderson │ 71000 │ │ 2 │ Alice Johnson │ 65000 │ │ 3 │ John Doe │ 60000 │ ╰───┴───────────────┴────────╯ reply marzell 12 hours agorootparentfor something a bit more robust, check out DuckDB. It&#x27;s a library you can embed, use it to run SQL on local files as well as connect to databases, do joins, analytics, etc. reply scumola 12 hours agorootparentAgreed. The article mentioned duckdb and I&#x27;m her to thumbs-up the use of DuckDB wholeheartedly. If you like the world of public CSV files as data sources that you can query or cross-query, duckdb is the tool for you. Just follow the demo on the duckdb website and you&#x27;ll be wow&#x27;d for sure. reply llimllib 9 hours agorootparentI use both, and I have found it helpful to have nushell around when munging csv and parquet files, even when working with duckdb - I find it quicker to ask for the first few rows of a thing or do simple stuff with it, then deeper analysis with duckdb.They&#x27;re a powerful pairing reply shortrounddev2 14 hours agorootparentprevCrazy how similar the commands are. reply rzmk 13 hours agorootparentprevqsv (https:&#x2F;&#x2F;github.com&#x2F;jqnatividad&#x2F;qsv) also has a sqlp command which lets you run Polars SQL queries on CSV(s).Here I&#x27;ll: - Send the csv data from stdin (using echo and referred to in the command by -) - Refer to the data in the query by stdin. You may also use the _t_N syntax (first table is _t_1, then _t_2, etc.), or the file name itself before the .csv extension if we were using files. - Pipe the output to the table command for formatting. - Also, the shape of the result is printed to stderr (the (4, 2) below). $ echo &#x27;Name,Department,Salary John Doe,IT,60000 Jane Smith,Finance,75000 Alice Johnson,HR,65000 Bob Anderson,IT,71000&#x27;qsv sqlp - &#x27;SELECT Name, Salary FROM stdin ORDER BY Salary DESC&#x27;qsv table (4, 2) Name Salary Jane Smith 75000 Bob Anderson 71000 Alice Johnson 65000 John Doe 60000 reply smooc 8 hours agorootparentprevYou do realize that this happened also on the article? I.e. In memory and autoinference reply WorldMaker 14 hours agorootparentprevYou might find a lot of interesting tools in the Datasette ecosystem. Data dashboarding for SQLite with all sorts of import and export and visualization plugins.https:&#x2F;&#x2F;datasette.io&#x2F; reply whartung 14 hours agorootparentprevWhat’s really interesting about it is that Awk is now, finally, getting support for CSV. But I bet a large amount of Awk+CSV use cases can be met with SQLite and SQL+CSV. reply nuc1e0n 13 hours agorootparentAWK&#x27;s new CSV and UTF-8 support is great, but when querying data I think in terms of SQL. reply fiddlerwoaroof 14 hours agorootparentprevThe clickhouse-local tool is also really great for querying a bunch of systems, and it has connectors and converters for a whole bunch of other systems and formats. reply j0hnyl 14 hours agorootparentprevHave you used duckdb? It&#x27;s great for that. reply ISL 8 hours agorootparentprevThere&#x27;s a chance this HN post is going to more than halve my awk-usage.... reply wiredfool 11 hours agorootparentprevLook at duckdb. Queries against csv, parquet, Jason, locally or via http. It’s like SQLite, but faster and better. reply dima55 12 hours agorootparentprevOr the vnlog tools can do this. There are many ways to do data processing on the commandline now. reply freedude 11 hours agorootparentprevperl with the right plugins makes data janitor situations simplified. reply stormfather 16 hours agoparentprevI&#x27;ve never stopped to question the absurdity of the gov data shopping cart thing. WHY!?!? Is there some justification for that? reply icyfox 16 hours agorootparentI can almost assure you it was an explicit requirement in an RFP that was copied from some master template. So not a good justification - but a justification in the eyes of the bureaucracy.The book Recoding America has a lot of anecdotes to this effect; most of these situations reduce to a Congressional mandate that got misinterpreted along the way. My favorite was for an update to Social Security. The department in charge of the implementation swore that Congress was forcing them to build a facebook for doctors (literally where doctors could friend other doctors and message them). Congress had no such intention; it was actually 3rd party lobbying that wanted the requirement so they could build their own solution outside of government. Really crazy stuff. reply reverius42 12 hours agorootparent> Congress had no such intention; it was actually 3rd party lobbyingRight, but 3rd party lobbying can&#x27;t force anyone to do anything, whereas Congress can (and did) give this mandate the force of law. The fact that lobbyists got Congress to do something that they had \"no such intention\" to do is its own problem, but let&#x27;s not lose sight of who is responsible for laws. reply icyfox 11 hours agorootparentThat&#x27;s the interesting part of this story; Congress didn&#x27;t think this requirement existed, neither did the lobbyists. But the language that congress adopted (with the consultation of this lobbying group) made the agencies _think_ it was what congress wanted. So the agency was left holding the bag for something no one actually wanted in the first place. Like a big game of telephone.I agree with your broader point however. Congress needs to do a better job of owning outcomes. reply ics 14 hours agorootparentprevI for one was tickled the first time I paid an NYC parking ticket online and had to add it to my cart, as if they might upsell me on some other more serious violation. Act now before it&#x27;s too late! reply dkarl 13 hours agorootparentWhen you&#x27;re paying for things, and can pay for several things at the same time, it makes sense. I helped my mother pay her property taxes this year, and for two properties we had to make four payments. Without the shopping cart (or a functional equivalent) I would have had to enter my payment information four times instead of once. reply yard2010 12 hours agorootparentprevAnd if you don&#x27;t like the service you have free returns for 14 days no questions asked reply NelsonMinar 14 hours agorootparentprevI assume it&#x27;s a vestige from the old days when you ordered actual tapes or printouts from government agencies. The notion of an order that had to be prepared is baked into how they think about the service and product.All sorts of strange things happen with accessing US government data. But most agencies have a lot of excellent data available for free and motivated data scientists who want to make it available to you. reply d1sxeyes 16 hours agorootparentprevProbably because it’s the out-of-the-box functionality on ServiceNow or whatever tool they’re using. reply jstarfish 15 hours agorootparentprevSome records are only released for a fee, so I always assumed implementing a standard interface to handle commercial transactions and making select items free was easier than maintaining separate commercial&#x2F;noncommercial sites. reply dTal 12 hours agorootparentWhich in itself is fairly antidemocratic. reply RicoElectrico 14 hours agorootparentprevMy guess would be to gather information about who is using the data - and present it to the stakeholders.Sometimes they send questionnaires to data consumers. reply btown 15 hours agorootparentprevProbably made by the same people who made https:&#x2F;&#x2F;pacer.uscourts.gov&#x2F;pacer-pricing-how-fees-work ...(As a side note, I can understand why in years past it would cost multiple cents per page to physically photocopy a federal document - but it is absolutely absurd that already-digitized documents, documents which are fundamentally part of the precedent that decides whether our behavior does or doesn&#x27;t cause civil or criminal liability, are behind a paywall for a digital download!) reply dmvdoug 13 hours agorootparentPacer physically hurts to use. They should have to pay us for having to use it. reply turquoisevar 10 hours agorootparentprevI’d go further and say that government websites and services in general are weird and often feel outdated, especially the more local you get.Some of them look like they’re straight from the early 2000s.Another thing is that privacy is dead and almost everything is deemed public information. Your address, mugshot, voter rolls, you name it, it’s all deemed public information.But once you actually want to access information that is useful to society as whole, more often than not it’s behind a paywall. Despite this, they still call it “public” information because theoretically anyone can pay for it and get access.It’s one of the first things I noticed when I moved to the US.Another thing that I’ve noticed is that, if possible, there always needs to be a middle man inserted, a private corporation that can make a profit out of it.You want to identify yourself to the government? Well you’re gonna need an ID.me account or complete a quiz provided to you by LexisNexis or one of the credit reporting agencies.Why? How is it that the government of all entities, isn’t capable of verifying me themselves?Zooming out even further you’ll start to recognize even more ancient processes you interact with in daily life.The whole banking situation and the backbone that’s running it is a great example. The concept of pending transactions, checks and expensive and slow transfers is baffling to me.It’s so weird, like ooh, aah this country is the pinnacle of technological innovation, yet in daily life there’s so much that hinges on ancient and suboptimal processes that you don’t see in, say, Western Europe.My best guess is that’s this is because of a mix of lack of funding and politicians that wanting to placate profit seeking corporations.Ironically, and I have no hard evidence for this because I’m too lazy to look into it, I suspect that on the long term it costs more to outsource it than it does to do it themselves.&#x2F;rant reply domh 3 hours agorootparentI feel like the USA was probably ahead of the curve on things like the banking system in the 90s but removing all of that cruft and replacing with a v2 is not an easy thing to do. Especially when the population are generally skeptical of government and outsourcing to a private corporation is seen as the cheaper option. Short term it&#x27;s potentially cheaper&#x2F;quicker to outsource but long term maintenance contracts and lobbying to keep things as they are is much more expensive.In the USA you find these whole industries that exist due to the inadequacies of the old systems. E.g. venmo doesnt need to exist in Western Europe (and probably rest of world?) because person-to-person bank transactions are free and easy. reply phatskat 15 hours agorootparentprevBureaucracy = $$$ reply nerevarthelame 14 hours agorootparentWho is making money with shopping cart-style downloads? reply redavni 12 hours agorootparentThe web development companies that are subcontracted by the government agencies to repurpose their silly shopping cart software.I will decline to share my personal anecdote&#x27;s about these companies because I am like 10+ years out of date, but I can tell you that most of these companies seemed to have certain very specific non-technical things in common. reply FranOntanaya 3 hours agoparentprevThe main thing for me is that the data isn&#x27;t broken down in a way that ends you having to make a thousand requests and collate them. If the client is expected to be able to pull the whole set of data, provide the whole set. There&#x27;s other ways to rate limit. reply jd3 6 hours agoparentprev> Every time I have to fill a \"shopping cart\" for a US government data download I die a little.I&#x27;ve worked in gov&#x2F;civic tech for 5+ years and, as you&#x27;re probably aware, there is now a highly lucrative business in centralizing and consequently selling easy access to this data to lobbyists&#x2F;fortune 500s&#x2F;nonprofits.USDS&#x2F;18f are sort of addressing this, but haven&#x27;t really made a dent in the market afaik since they&#x27;re focusing on modernizing specific agencies rather than centralizing everything. reply thibaut_barrere 12 hours agoparentprevAgreed! People are surprised but CSV files (while I would not use them for everything) work great in low-tech environment, for instance, or when files must be produced by many different actors with different technical levels.They also work nicely as an interop between different stacks (CobolRuby).One concrete example is the French standard to describe Electrical Vehicles Charge Points, which is made of 2 parts (static = position & overall description, dynamic = current state, occupancy etc). Both \"files\" are just CSV files:https:&#x2F;&#x2F;github.com&#x2F;etalab&#x2F;schema-irveBoth sub-formats are specified via TableSchema (https:&#x2F;&#x2F;frictionlessdata.io&#x2F;schemas&#x2F;table-schema.json).Files are produced directly by electrical charge points operators, which can have widely different sizes & technicality, so CSV works nicely in that case. reply rjh29 12 hours agorootparentI worked for a company that used TSV for huge datasets. It was extremely efficient, far more so than any database. reply xp84 11 hours agorootparentTSV is criminally underrated compared to CSV. reply digging 15 hours agoparentprevCan you explain what the shopping cart is?I mean... do they make you select one or more files, then navigate to another page to download your selected files? reply crizzlenizzle 15 hours agorootparentSounds like Germany’s company register[1].You can search for companies, select the documents you’d like to see (like shareholder lists), then you go through a checkout process and pay 0 EUR (used to be like a few euros years ago), and then you can finally download your file. Still a super tedious process, but at least for free nowadays.[1] https:&#x2F;&#x2F;www.unternehmensregister.de&#x2F;ureg&#x2F; reply RosanaAnaDana 15 hours agorootparentprevQuite literally yes. There are often multiple click throughs. Every Department, agency, sub-agency, all the way down to federal dog catcher has decided the most important thing is to invent a new way of getting data from them. reply imchillyb 12 hours agorootparentSolutions vary as the budgets and talent assigned the projects do.Federal, State, local and hyper local solutions cannot be the same unless the financier is also the same. reply pininja 14 hours agorootparentprevPretty much. USGS’s EarthExplorer requires a login just to download free files https:&#x2F;&#x2F;earthexplorer.usgs.gov&#x2F;There are other ways to access the data on here, but they’re fragmented. It’s nicely organized here so it’s a bummer they make it hard to programmatically retrieve files once you find what you’re looking for. reply x86x87 14 hours agoparentprevLol. Tell me you never had to parse CSV files without telling me.CSV files can be a nightmare to work with depending where they come from and various liberties that were taken when generating the file or reading the file.Use a goddam battle tested library people and don&#x27;t reinvent the wheel. &#x2F;oldman rant over reply wavemode 12 hours agorootparentYes, you eventually realize the hard way that \"CSV\" is actually a blanket of various similar formats, with different rules and conventions. The way one program outputs CSV&#x27;s may be completely different from another. reply NelsonMinar 10 hours agorootparentprevActually, I worked on OpenAddresses, a project to parse thousands of CSV files containing address data from many different county, state, and national systems around the world. It really wasn&#x27;t that hard, even Python&#x27;s basic csv parser was sufficient to the task (and there are plenty of better options).CSV is remarkably robust in practice. reply thefurdrake 12 hours agorootparentprevHey, CSV is hard, guys.I&#x27;ve found template injection in a CSV upload before because they didn&#x27;t anticipate a doublequote being syntactically relevant or something.It was my job to find these things and I still felt betrayed by a file format I didn&#x27;t realize wasn&#x27;t just comma separated values only. reply x86x87 11 hours agorootparentSomeone can find all these issues on 200 lines of code :) see sibling comment reply nuc1e0n 10 hours agorootparentThis isn&#x27;t my code, but gives you an idea of the level of complexity involved. But don&#x27;t reimplement what you don&#x27;t need to.https:&#x2F;&#x2F;github.com&#x2F;mafintosh&#x2F;csv-parser&#x2F;blob&#x2F;master&#x2F;index.js reply x86x87 8 hours agorootparentTo be clear my comment was meant as a joke.Looking at the parser I see a few problems with it just by skimming the code. I&#x27;m not saying it wouldn&#x27;t work or that it&#x27;s not good enough for certain purposes. reply nuc1e0n 13 hours agorootparentprevIt&#x27;s not as bad as all that. There&#x27;s some gochas sure but you can cover them all with about 200 lines of code.However, I would recommend using a tested library to do the parsing, sqlite for example, rather than rolling your own. Unless you have to of course. reply chankstein38 13 hours agoparentprevI don&#x27;t know if this is the cart you&#x27;re talking about but the USGS does this for LiDAR data and yeah I&#x27;m with you I die a little every time I use that site. I love that the data is available but why in the world do we have to cart everything? Just give me a one click download reply msla 14 hours agoparentprevCSV would be great if there were one CSV, and if you absolutely guarantee that nobody has \"improved\" the CSV by editing it with a spreadsheet program (including opening it with a spreadsheet program) or their own deft little fingers in a text editor.For example: \"Look, this contains \\\"quotes\\\"!\",012345Or: \"Look, this contains \"\"quotes\"\"!\",012345Or, for some degenerate examples: \"Look, this contains \"quotes\"!\",012345Or: Look, this contains \"quotes\"!,012345Or the spoor of a spreadsheet: \"Look, this contains \"\"quotes\"\"!\",12345Theoretically, JSON isn&#x27;t immune to being hand-hacked into a semi-coherent mess. In practice, people don&#x27;t seem to do that to JSON files, at least not that I&#x27;ve seen. Ditto number problems, in that in JSON, serial numbers and such tend to be strings instead of integers a \"helpful\" application can lop a few zeroes off of. reply AshamedCaptain 13 hours agorootparent> CSV would be great if there were one CSV, and if you absolutely guarantee that nobody has \"improved\" the CSV by editing it with a spreadsheet program (including opening it with a spreadsheet program)Practically no formats actually pass those rules. Even plain text is bound to be \"improved\" by text editors frequently (uniformation of line endings, removal of data not in a known encoding, UTF BOM, UTF normalization, etc.)Just don&#x27;t do that. reply nly 9 hours agorootparentprevI mean in practice you open up the CSV file, figure out the escaping rules, change one line of your code, and get on with your life. reply nuc1e0n 13 hours agorootparentprevStick to files conforming to RFC-4180 then reply ianburrell 13 hours agorootparentprevJSONL should replace CSV. It is standardized and the escapes mostly well specified. It is effectively CSV with \"[\" and \"]\" surrounding lines.Regular JSON would work fine for static file, and make Schema and links (JSON-LD) possible. But then the file could be any structure. JSONL works better for systems that assume line-based records, and are more likely to have consistent, simple records. reply jhwhite 12 hours agoparentprevclinicaltrials.gov let&#x27;s you save a search term then download the results as a zip. But there&#x27;s an xml file for each search result for the trial.One of the first things I played around with was using Python to get that file, unzip it, then iterate through the xml files grabbing the info I wanted and putting it into ElasticSearch to make it searchable then putting an angular front end on it.I used to have it published somewhere but I think I let it all die. :( reply pbreit 14 hours agoparentprevPretty much all data eventually ends up in 2 dimensions (rows & columns) so all these complicated data models are just mostly complicating things. reply mhh__ 14 hours agoparentprevSomeone posted me a pdf in the last year! Online even! (But posted!) reply rewmie 14 hours agoparentprev> Simple file downloads and CSV files are fantastic. I wish more folks would publish data in simple formats like this.The document format doesn&#x27;t seem to have much to do with the problem. I mean, if the CSV is replaced by a zipped JSON doc then the benefits are the same.> Every time I have to fill a \"shopping cart\" for a US government data download I die a little.Now that seems to be the real problem: too many hurdles in the way of a simple download of a statically-served file. reply dividedbyzero 14 hours agorootparent> if the CSV is replaced by a zipped JSON doc then the benefits are the same.Being able to use things like jq and gron might make simple use cases extremely straightforward. I&#x27;m not aware of anything similarly nimble for CSV. reply BeefWellington 13 hours agorootparentcsvtool is probably what you&#x27;re looking for, though I think the use case for JSON vs CSV is different as one is hierarchy-oriented and the other is flat. reply darkwater 13 hours agorootparentprevYou dont gron with CSV, normal grep will work wonders. reply dividedbyzero 9 hours agorootparentgron gives you both the complete key and value in a single line (which you then grep). Directly grep-ing a specific column in a CSV file isn&#x27;t very straightforward. reply two_handfuls 14 hours agorootparentprevFor CSV? DuckDB, Datasette, awk, pawk, and tons of others. reply eru 4 hours agoprevGoing on a tangent:> Why was the Euro so weak back in 2000? It was launched, without coins or notes, in January 1999. The Euro was, initially, a sort of in-game currency for the European Union. It existed only inside banks - so there were no notes or coins for it. That all came later. So did belief - early on it didn&#x27;t look like the little Euro was going to make it: so the rate against the Dollar was 0.8252. That means that in October 2000, a Dollar would buy you 1.21 Euros (to reverse exchange rates, do 1&#x2F;rate). Nowadays the Euro is much stronger: a Dollar would buy you less than 1 Euro.Even if the Euro initially only existed electronically, it still had fixed exchange rates with the old currencies of the EU zone members. Most importantly with the established and well-trusted Deutsche Mark of Germany.So any explanation of &#x27;why was the Euro initially weak&#x27; also has to explain why the DEM was weak at the time. The explanation given in that paragraph doesn&#x27;t sound like it&#x27;s passing that test. reply liamkinne 16 hours agoprevI once hade the unfortunate experience of building an API for a government org where the data changed once a year or when amendments were made which happens very infrequently.The whole data set could have been zipped into aworking ETag&#x2F;If-Modified-Since supportI completely agree and csvbase already implements this (so does curl btw), try: curl --etag-compare stock-exchanges-etag.txt --etag-save stock-exchanges-etag.txt https:&#x2F;&#x2F;csvbase.com&#x2F;meripaterson&#x2F;stock-exchanges.parquet -O reply justsomehnguy 15 hours agorootparentprev> ETag&#x2F;If-Modified-SinceSee above. Also you can just publish the version in DNS with a long enough TTL reply deeringc 15 hours agoparentprevA zip file on a web server that supports etags, that&#x27;s polled every time access is required. When nothing has changed since last time, you get an empty HTTP 304 response and if it has changed then you simply download theCaching would introduce more complexitiesApache&#x2F;nginx do it just fine... reply pests 13 hours agorootparentprevCan&#x27;t cache so you need to read it whenever you use the data, not just when it changes. reply justsomehnguy 15 hours agorootparentprevnext [–]cat &#x2F;api&#x2F;version.txt 2023.01.01 ls &#x2F;api version.txt data.zip reply accrual 15 hours agorootparentOr maybe encode the version into the filename? It would overwrite if nothing changed, and the previous versions would remain available. 2023.01.01-data.zip reply justsomehnguy 14 hours agorootparentThat requires preprocessing on the client and there are some ppl who has.. weird assumptions about how the dates should be written.The version file can be quired at least the two ways:the ETag&#x2F;If-Modified-Since way (metadata only)content itselfThe best part with the last one - you don&#x27;t need semver shenanigans. Just compare it with the latest dloaded copy, if version != dloaded => do_the_thing replycrazygringo 16 hours agoprevNo, it&#x27;s a terrible API if retrieving the result &#x27;2000-10-26&#x27; requires downloading a 565 KB file.I don&#x27;t want to seem overly negative -- zipped CSV files are fantastic when you want to import lots of data that you then re-serve to users. I would vastly prefer it over e.g. protobufs that are currently used for mass transit system&#x27;s live train times, but have terrible support in many languages.But it&#x27;s incredibly wasteful to treat it like an API to retrieve a single value. I hope nobody would ever write something like that into an app...(So the article is cool, it&#x27;s just the headline that&#x27;s too much of a \"hot take\" for me.) reply piaste 16 hours agoparentIt&#x27;s historical data. There is zero reason to request it more than once a day, and the users of such data will be interested in wildly different filters or aggregates over that data.If this were being used to get the current rates, then yes, it would be a terrible design choice. But there are other services for that. This one fits its typical use case. reply pixl97 16 hours agoparentprev> I hope nobody would ever write something like that into an app...I have got some bad news for you...Not directly API related, but I remember supporting some land management application, and a new version of their software came out. Before that point it was working fine on our slow satellite offices that may have been on something like ISDN at the time. New version didn&#x27;t work at all. The company said to run it on an RDP server.I thought their answer was bullshit and investigated what they were doing. One particular call, for no particular reason was doing a &#x27;SELECT * FROM sometable&#x27; for no particular reason. There were many other calls that were using proper SQL select clauses in the same execution.I brought this up with the vendor and at first they were confused as hell how we could even figure this out. Eventually they pushed out a new version with a fixed call that was usable over slow speed lines, but for hells sake, how could they not figure that out in their own testing and instead pushed customers to expensive solutions? reply gray_-_wolf 16 hours agorootparent> how could they not figure that out in their own testingThis one is easy. Testing with little data on fast network (likely localhost). reply codetrotter 15 hours agorootparentAlso, if there are any ORMs involved it could be that it’s not immediately obvious from their code itself that this would happen.I’ve seen code that was using an ORM, where they needed to find some data that matched certain criteria. With plain SQL it would have resulted in just a few rows of data. Put instead with their use of the ORM they ended up selecting all rows in the table from the database, and then looping over the resulting rows in code.The result of that was that the code was really slow to run, for something that would’ve been super fast if it wasn’t for the way they used the ORM in that code. reply xp84 10 hours agorootparentSeen this so many times by novice developers, whose work style is often \"Trial and error, and as soon as it works, stop and change nothing.\" And it&#x27;s so easy to slip in there because it works perfectly locally and often even in non-production envs, unless you&#x27;ve seeded them with production-like amounts of data, and with the ORM it looks fine. Like in Rails: Product.where(category_id: xx).filter {|p| p.name.include?(\"computer\") }vs Product.where(category_id: xx).where(\"name like &#x27;%?%&#x27;\", \"computer\")PS: I know there&#x27;s an Arel way of doing the above without putting any SQL into the app -- use your imagination and pretend that&#x27;s what I did, because I still don&#x27;t have that memorized :) reply mrighele 11 hours agorootparentprevI just see recently an example of that, a REST call returning a few KB of data that would fetch a few million rows from the database and use 10+ GB of memory (unfortunately some people think that you should always use join fetches with JPA...). reply jrm4 15 hours agoparentprevKinda feels like 20 years ago called and wants its argument back, like have you seen any javascript ever?565 KB + the logic to get the big one is miniscule today by any reasonable factor. reply scubbo 14 hours agorootparentTrue, though ironic that also OP is implicitly making the argument for GraphQL-like interfaces (\"just specify the data that you want returned\" rather than \"get all the data, then process it\"), which are themselves the New Hotness in some areas. reply thekashifmalik 13 hours agorootparentAt risk of sounding pedantic, REST also allows for \"just specify the data that you want returned\" style APIs.Something like: curl https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;api?fields=Date&order=USD&limit=1 reply scubbo 13 hours agorootparentA very fair point well-made! reply Telemakhos 15 hours agoparentprevI think a lot of people in this thread are glossing over a difference in definitions. Some people see \"API\" as \"how to get data, even if that means all data with no filtering.\" Personally, I regard downloading an entire table as downloading a data model without any logic operating on the model, and an API as logic that returns only part of the model filtered in some way that interests me. reply berkes 12 hours agoparentprevWhy do you assume that 565KB even matters?I&#x27;ve been building loads of financial software, both back and front ends. In frontend world it, sadly is quite common to send that amount of \"data\" over wires before even getting to actual dataAnd in backends it&#x27;s really a design decision. There&#x27;s nothing faster than a Cron job parsing echange rates nightly and writing them to a purpose designed todays-rates.json served as static file to your mobile, web or microservices apps.Nothing implies your mobile app has to consume this zip-csv_over_http reply theLiminator 16 hours agoparentprevThey should ship parquet, supports predicate pushdown and is dramatically more compact, while you can&#x27;t get row level data, it&#x27;s great for analytical queries. reply RobinL 16 hours agorootparentTotally agree! So much that I wrote a whole article about it a while back!\"Why parquet files are my preferred API for bulk open data\" https:&#x2F;&#x2F;www.robinlinacre.com&#x2F;parquet_api&#x2F; reply swader999 14 hours agorootparentParquet is a level better than csv but difficult to get customers to adopt and transmit in that format. reply calpaterson 14 hours agorootparentprevcsvbase does ship parquet!Just add \".parquet\" - eg https:&#x2F;&#x2F;csvbase.com&#x2F;meripaterson&#x2F;stock-exchanges.parquet reply theLiminator 13 hours agorootparentNice! reply IanCal 16 hours agorootparentprevIMO this is the best simple option right now.For sorted data you only need the relevant row groups which can be tunable to sensible sizes for your data and access pattern. reply netsharc 16 hours agoparentprevI&#x27;m an old fart, seeing the curl in every example is like nails on chalkboard.565 KB, that&#x27;s about 3 minutes download on a 28.8kbps modem I started getting online with... reply zamadatix 15 hours agorootparentWhen you got that modem were you concerned with how long it would have taken to type&#x2F;write the information sent over it or were you just happy it didn&#x27;t matter anymore?I often wonder what I&#x27;ll think of technology in say another 20 years but I can never tell if it&#x27;s all just some general shift in perspective or, as you look farther back, if certain people were always just about a certain perspective (e.g. doing the most given the constraints) and technology changes enough that different perspectives (e.g. getting the most done easily for the same unit of human time) become the most common users for the newer stuff and that these people will also have a different perspective than the ones another 20 years down the line from them and so on.For example, maybe you think it&#x27;s crazy to ask for the exact piece of data you need, I think it&#x27;s crazy to do all the work to not just grab the whole half MB and just extract what you need quickly on the client side as often as you want, and someone equidistant from me will think it&#x27;s nuts to not just feed all the data into their AI tool and ask it \"what is the data for ${thing}\" instead of caring about how the data gets delivered at all. Or maybe that&#x27;s just something I hope for because I don&#x27;t want to end up a guy who says everything is the same just done slower on faster computers since that seems... depressing in comparison :). reply smallpipe 16 hours agoparentprevHow much data do I need to download before I can do a protobuf request ? reply crazygringo 11 hours agorootparentMass transit files are often a single protobuf file that is like a megabyte or something.I&#x27;m talking about zipped CSV files as easier to use than protobuf files. Neither is a request in this comparison. reply eddythompson80 16 hours agorootparentprevAre you counting the client size? TLS handshake? Because otherwise the answer is none. reply mhh__ 16 hours agoparentprevBut what if I want the average over time? The query depends on every value, should everything be computed on the server? reply maxbond 16 hours agoparentprevHere&#x27;s an API built on top of this data that allows for more fine tuned queries.https:&#x2F;&#x2F;exchangeratesapi.io&#x2F;https:&#x2F;&#x2F;github.com&#x2F;exchangeratesapi&#x2F;exchangeratesapi reply dang 11 hours agoparentprev> (So the article is cool, it&#x27;s just the headline that&#x27;s too much of a \"hot take\" for me.)It&#x27;s one of those headlines that we&#x27;d never allow if it were an editorialization by the submitter (even if the submitter were the author, in this case), but since it&#x27;s the article&#x27;s own subtitle, it&#x27;s ok. A bit baity but more in a whimsical than a hardened-shameless way.(I&#x27;m sure you probably noticed this but I thought the gloss might be interesting) reply Hamuko 16 hours agoparentprevHow much bandwidth does the average API documentation page use? reply eddythompson80 16 hours agorootparentDoes your client query the API documentation every time it&#x27;s querying an API? reply ajcp 15 hours agorootparentWell of course it does; how else would it know how to query the API? &#x2F;s reply lovasoa 16 hours agoprevnext [–]> curl -s https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.zipgunzipsqlite3 &#x27;:memory:&#x27; &#x27;.import &#x2F;dev&#x2F;stdin stdin&#x27; \"select Date from stdin order by USD asc limit 1;\" Error: in prepare, no such column: Date (1)There is a typo in the example (that is not in the screenshot): you need to add a -csv argument to sqlite. reply calpaterson 15 hours agoparentThis is odd, I did originally have that argument but I removed it because it didn&#x27;t seem to matter - it works without (\"On My Machine\"(tm))Erk - readding it and busting the cache. After I put my kids to bed I will figure out what is wrongEDIT: the reason it works for me is because I&#x27;ve got this config in ~&#x2F;.sqliterc: .separator &#x27;,&#x27;Apparently at some point in the past I realised that I mostly insert csv files into it and set that default. reply c7b 15 hours agorootparentGenerally curious - any particular reasons you chose sqlite and gnuplot for this task rather than, say, Python? reply calpaterson 15 hours agorootparentI do also use Python (pandas) partway down the page :) I&#x27;m just trying to show different tools to give people ideas about how much is possible with stuff that is already in &#x2F;usr&#x2F;bin&#x2F;If you were to ask my own tool preferences which I use for $DAYJOB: pandas for data cleaning and small data because I think that dataframes are genuinely a good API. I use SQL for larger datasets and I am not keen on matplotlib but still use it for graphs I have to show to other people. reply taldo 15 hours agoprevA very simple optimization for those complaining about having to fetch a large file every time you need a little datapoint: if they promised the file was append-only, and used HTTP gzip&#x2F;brotli&#x2F;whatever compression (as opposed to shipping a zip file), you could use range requests to only get the new data after your last refresh. Throw in an extra checksum header for peace of mind, and you have a pretty efficient, yet extremely simple incremental API.(Yes, this assumes you keep the state, and you have to pay the price of the first download + state-keeping. Yes, it&#x27;s also inefficient if you just need to get the EUR&#x2F;JPY rate from 2007-08-22 a single time.) reply calpaterson 15 hours agoparentAbsolutely! I have a plan for a client lib that uses ETags (+ other tricks) to do just that.Very WIP but check out my current \"research quality\" code here: https:&#x2F;&#x2F;pypi.org&#x2F;project&#x2F;csvbase-client&#x2F; reply GuB-42 10 hours agoparentprevOr, just serve a bunch of diff files. Just having a single daily patch can drastically reduce the bandwidth required to keep the file up to date on your side.That&#x27;s if downloading a few hundred kB more per day matters to you. It probably doesn&#x27;t. reply acqq 11 hours agoparentprevAlso, on the topic of range requests, when a server allows the range requests for zip files, the zip files are huge and one needs just a few files from them, one can actually download just the \"central directory\" and the compressed data of the needed files without downloading the whole zip file:https:&#x2F;&#x2F;github.com&#x2F;gtsystem&#x2F;python-remotezip reply Joel_Mckay 5 hours agoprevThere are several reasons a compressed archive isn&#x27;t a good data format outside trusted backups.1. inconsistent binary formats, float precision edge conditions, and unknown Endianness. Thus, assuming the Marshalling of some document is reliable is risky&#x2F;fragile, so pick some standard your partners also support... try XML&#x2F;XSLT, BSON, JSON, SOAP, AMQP+why, or even EDIFACT.2. \"dump and load\" is usually inefficient, with an exception when the entire dataset is going to change every time (NOAA weather maps etc.)3. Anyone wise to the 42TiB bzip 18kiB file joke is acutely aware of what compressed files can do to server scripts.4. Tuning firewall traffic-shaping for a web-server is different from a server designed to handle large files. Too tolerant rules causes persistent DDoS exposure issues, and too strict causes connections to become unreliable when busy&#x2F;slow.5. Anyone that has to deal with CSV files knows how many proprietary interpretations of a simple document format emerge.Best of luck, and remember to have fun =) reply isoprophlex 5 hours agoparentAbout your Point 5, let me tell you about the ESV file format: Eggplant Separated Values! Who needs escaping if you have the eggplant emoji! reply Joel_Mckay 4 hours agorootparentMy favorite was console control-characters accidentally embedded in plain text by cross-platform document code-page encoding errors.One learns over the years that every program stage&#x2F;interface must sanitize input, sanity check formats, and isolate data on a per account log.Did the user intend \"P=0&#x2F;O\" as a joke... we&#x27;ll never know. =) reply Waterluvian 16 hours agoprevFor little problems where you can just download the entire database every time and do read-only work, never underestimate the value of keeping it simple! I really like SQLite for this because it has the portability of a .Json or .csv file but it’s more ready to interact with as a database. reply semi-extrinsic 16 hours agoparentJust use clickhouse-local, and you can interact with any old CSV file as if it was a database. reply AceJohnny2 16 hours agoprevKey point:> Some things we didn&#x27;t have to do in this case: negotiate access (for example by paying money or talking to a salesman); deposit our email address&#x2F;company name&#x2F;job title into someone&#x27;s database of qualified leads, observe any quota; authenticate (often a substantial side-quest of its own), read any API docs at all or deal with any issues more serious than basic formatting and shape. reply lovasoa 16 hours agoparentI am skeptical about the \"observe any quota\" part. Bandwidth is not free. reply hatthew 9 hours agorootparentThere probably is a quota of some sort, but since there&#x27;s no reason to download the file very often, it&#x27;s probably not a quota you need to worry about. reply hamilyon2 1 hour agoprevIf your data is somewhat sparse, somewhat hierarchical or have evolving&#x2F;amorphous schema, gzipped jsonl is better. Jsonl is supposed by clickhouse and jq and a bit more consistent around escaping&#x2F;delimiting reply pietz 1 hour agoprevJust thinking out loud: If we make the zip file a parquet file, wouldn&#x27;t we be able to do partial downloads (like getting the first 1000 lines) instead of getting the whole file every single time? reply pharrington 16 hours agoprevYeah having a local snapshot of an entire dataset is obviously nice when it&#x27;s feasible. But there&#x27;s no need to conflate that with \"application programming interface\" just to market csvbase. reply lxgr 16 hours agoprevThe example is failing at decompression for me, and I suspect it&#x27;s because of this:> That data comes as a zipfile, which gunzip will decompress.Doesn&#x27;t gunzip expect gzip files, as opposed to ZIP (i.e. .zip) files?On Linux I get further (apparently Linux gunzip is more tolerant of the format error than the macOS default one), but there, I then run into:> Error: no such column: Date reply halJordan 16 hours agoparentHere&#x27;s the gzipped tarball of the docs you can read to find outhttps:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;gzip&#x2F;manual&#x2F;gzip.txt.gz reply jandrese 16 hours agoparentprevThis is slightly abusive of gunzip, but it does work, but only because the zipfile in question only contains a single file and you are piping it in via shell. If you had tried to download the file and then run gunzip on it the program would have refused.As for the second error, I think you might be trying to import an empty file or maybe an error message? Probably related to the first problem. reply lxgr 16 hours agorootparent> but it does workOnly on some gzip implementations, e.g. the one shipping with many Linux distributions. It doesn&#x27;t work on macOS, for example. reply lovasoa 16 hours agorootparentprevthe second error is because you need to add a `-csv` argument to sqlite reply pixl97 16 hours agoparentprevAt least in Ubuntu it doesn&#x27;t do anything at all.# gunzip -d master.zip gunzip: master.zip: unknown suffix -- ignored reply lxgr 16 hours agorootparentIt&#x27;s a ZIP file, so you&#x27;ll want to use unzip, not gunzip.Ubuntu&#x27;s version of g(un)zip actually does tolerate ZIP inputs though; for that usage, just omit the &#x27;-d&#x27;. reply Scene_Cast2 16 hours agoprevThere&#x27;s an issue with openly & freely available financial data. It tends to be limited (i.e. you need many sources to answer the questions you want and not just the questions a particular source is able to answer). And if you&#x27;re bringing in different sources of data, each source requires custom fetching and parsing, along with being just annoyingly slightly different from other sources. Even if the value is given on a per-day basis (which is a huge assumption, lots of things like interest rates are published much slower), you have things like \"is the value at the start of day, end of day, market close, median? What time zone? Which exchange? What about days when the exchange was closed? What about odd exchange hours or halts?\", \"what&#x27;s the date and time format, what&#x27;s the naming convention?\" reply mhh__ 16 hours agoparentThis why Bloomberg and friends make money. They&#x27;re a cartel but they at least do both making all this data work together and also transcribe stuff that is written in English into structured data etc (hence their interest in AI) reply mhh__ 16 hours agoparentprevTarget rates aren&#x27;t published very frequently but interest rates themselves are typically daily or better. reply nextaccountic 9 hours agoprev> Although pulling out a simple max is easy, the data shape is not ideal. It&#x27;s in \"wide\" format - a Date column, and then an extra column for every currency. Here&#x27;s the csv header for that file:> Date,USD,JPY,BGN,CYP,CZK,DKK,EEK,GBP,HUF,LTL,LVL,MTL,[and on, and on]> When doing filters and aggregations, life is easier if the data is in \"long\" format, like this:> Date,Currency,Rate> Switching from wide to long is a simple operation, commonly called a \"melt\". Unfortunately, it&#x27;s not available in SQL.> No matter, you can melt with pandas:> curl -s https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.zip\\ gunzip\\ > python3 -c &#x27;import sys, pandas as pd > pd.read_csv(sys.stdin).melt(\"Date\").to_csv(sys.stdout, index=False)&#x27;You sure this can&#x27;t be done in SQL? I myself don&#x27;t know enough SQL, but I believe that you can decompose a single row into multiple rows in SQL by joining multiple queries using UNION ALL:https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;46217564&#x2F;converting-sing...https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;52279384&#x2F;how-do-i-melt-a...Now the question is, how to make this less verbose (so that the query doesn&#x27;t need to mention each of the 42 columns) reply tbrownaw 5 hours agoparentThat sounds like PIVOT and UNPIVOT. But of course being SQL you have to list all the columns explicitly, which can get kind of annoying. reply mrighele 10 hours agoprev> Switching from wide to long is a simple operation, commonly called a \"melt\". Unfortunately, it&#x27;s not available in SQL.That&#x27;s not completely true. In most SQL databases you can query information about the table, and this is true for Sqlite too. You cannot use this information to have a query with a \"dynamic\" number of columns, but you can always generate the query from the metadata and then executed the generated queries. It is not exactly fun to do as a one-liner, but it works:> curl &#x27;https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.csv&#x27;sqlite3 -csv &#x27;:memory:&#x27; &#x27;.import &#x2F;dev&#x2F;stdin stdin&#x27; &#x27;.mode list&#x27; &#x27;.output query.sql&#x27; \"select &#x27;select Date, &#x27;&#x27;&#x27; || name || &#x27;&#x27;&#x27;, &#x27; || name || &#x27; from stdin ;&#x27; from pragma_table_info(&#x27;stdin&#x27;) where cid > 0 and cid(invoke-webrequest \"https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.csv\").ContentConvertFrom-Csvsort \"usd\"select \"date\" -first 1 Date ---- 2000-10-26Doing it with a zip file would be a little more verbose since there is no built in \"gunzip\" type command which operates on streams, but you can write one which does basically that out of built in .Net functions: function ConvertFrom-Zip { param( [Parameter(Position=0, Mandatory=$true, ValueFromPipeline=$true)] [byte[]]$Data ) process { $memoryStream = [System.IO.MemoryStream]::new($Data) $zipArchive = [System.IO.Compression.ZipArchive]::new($memoryStream) $outputStreams = @() foreach ($entry in $zipArchive.Entries) { $reader = [System.IO.StreamReader]::new($entry.Open()) $outputStreams += $reader.ReadToEnd() $reader.Close() } $zipArchive.Dispose() $memoryStream.Dispose() return $outputStreams } }and call it like: # unary \",\" operator required to have powershell # pipe the byte[] as a single argument rather # than piping each byte individually to # ConvertFrom-Zip $> ,(invoke-webrequest \"https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.zip\").ContentConvertFrom-ZipConvertFrom-Csvsort \"usd\"select \"date\" -first 1 Date ---- 2000-10-26I love powershell reply llimllib 13 hours agoparentHere it is in nushell: &#x2F;tmp> # be kind to the server and only download the file if it&#x27;s updated &#x2F;tmp> curl -s -o &#x2F;tmp&#x2F;euro.zip -z &#x2F;tmp&#x2F;euro.zip https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.zip &#x2F;tmp> unzip -p &#x2F;tmp&#x2F;euro.zipfrom csvselect Date USDsort-by USDfirst ╭──────┬────────────╮ │ Date │ 2000-10-26 │ │ USD │ 0.83 │ ╰──────┴────────────╯(I removed the pipe to gunzip because 1. gunzip doesn&#x27;t work like that on mac and 2. it&#x27;s not something you should expect to work anyway, zip files often won&#x27;t work like that, they&#x27;re a container and their unzip can&#x27;t normally be streamed) reply jwilk 2 hours agorootparentThis is not a secure use of &#x2F;tmp. reply shortrounddev2 12 hours agorootparentprev> be kind to the server and only download the file if it&#x27;s updatedI wonder if their webserver supports the If-modified-since http header reply sltkr 11 hours agorootparentYou can check with `curl -v`.tl;dr: the server doesn&#x27;t support that header, but since the response does include a Last-Modified header, curl helpfully aborts the transfer if the Last-Modified date is the same as the mtime of the previously downloaded file. reply jakswa 15 hours agoprevI&#x27;ll throw out the the GTFS transit standard involves publishing zipped CSVs representing your DB tables regularly. There are nice things about it and downsides IMO. This is how google map&#x27;s transit directions function -- they rely on agencies to publish their schedules regularly in zipped CSVs I think.One downside is that dev experience is pretty bad in my opinion. It took me years of fiddling in my free time to realize that if you happen to try to use the CSVs near a schedule change, you don&#x27;t know what data you&#x27;re missing, or that you&#x27;re missing data, until you go to use it. My local agency doesn&#x27;t publish historical CSVs so if you just missed that old CSV and need it, you&#x27;re relying on the community to have a copy somewhere. Similarly, if a schedule change just happened but you failed to download the CSV, you don&#x27;t know until you go to match up IDs in the APIs. reply thibran 9 hours agoprevToo many different tools with weird syntax... once you are used to Nushell, you keep using it :)http get https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref-hist.zipgunzipfrom csvsort-by USDfirstget Date reply paradox460 16 hours agoprevIf this is his favorite API, he should check out patent office gazettes reply babblingfish 13 hours agoprevI believe that curl does not have client side caching so every time you run the command it downloads the csv. While downloading the csv and then analyzing it would no longer makes it a magic one-liner you can send to people. It would save bandwidth and reduce traffic on the API.Unless there is caching going on here? Perhaps a CDN cache on the server side? reply acqq 8 hours agoparent> I believe that curl does not have client side cachingSee:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37528558by llimllibSpecifically: curl -o &#x2F;tmp&#x2F;euro.zip -z &#x2F;tmp&#x2F;euro.zipOption o is output, option z says\"Request a file that has been modified later than the given time and date, or one that has been modified before that time.\"And:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37529690by sltkr:\"the server doesn&#x27;t support that header, but since the response does include a Last-Modified header, curl helpfully aborts the transfer if the Last-Modified date is the same as the mtime of the previously downloaded file.\" reply michelb 3 hours agoprevFinally something I actually CAN build in a weekend ;) reply supergeek133 16 hours agoprevI used to help run the Best Buy product catalog API. We did nightly CSVs instead of making people poll&#x2F;paginate the entire catalog. It was super widely used. reply twobitshifter 10 hours agoprevIf you’re going to go all bash, use cut (made for it) or sed to remove the extra comma.And you could use awk to do the melt if you don’t have python and pandas. reply ninjin 45 minutes agoparentIn my case it is not Bash, but POSIX shell: #!&#x2F;bin&#x2F;sh set -eu u=https:&#x2F;&#x2F;www.ecb.europa.eu&#x2F;stats&#x2F;eurofxref&#x2F;eurofxref.zip ftp -Vo - $uzcatsed &#x27;s&#x2F;, $&#x2F;&#x2F;&#x27;awk -F &#x27;, &#x27; &#x27; NR == 1 { for(i = 1; i = 2 { printf \"%s\\t\", $1 for(i = 2; i <= NF; ++i) { c = (i != col[\"GBP\"]) ? $i&#x2F;$(col[\"GBP\"]) : $i printf \"%s%s\", c, (i < NF) ? \"\\t\" : \"\\n\" } } &#x27;Fetches the latest rates and converts the base currency to GBP and format to TSV. Then I run a cron(8) job 15~30 minutes after the release each work day and dump the output so that I can retrieve it from httpd(8) over HTTPS to be injected into my window manager status bar. A pretty elegant solution that spares the ECB from my desktops hammering their server. All with tools from the OpenBSD base install. reply keepamovin 9 hours agoparentprevI find awk to be more reliable even for simple string manipulation. Something about sed&#x27;s regexes throw me for a loop! reply mmcnl 15 hours agoprevGreat read. I didn&#x27;t know it&#x27;s so easy to plot something in the terminal. Also really shows the power of 2D data structures. A good long format and you can do anything. reply gkfasdfasdf 11 hours agoprevHow about caching the zip file and adding a &#x27;-z&#x27; to the curl command to only download if newer. reply georgespencer 9 hours agoprevSee also: the US “no fly” list, which is a read-only Excel file in the cloud. reply j7ake 16 hours agoprevThe other annoying thing is the large file that is behind some click button, so you cannot easily copy and paste the url and download it via wget. reply gigatexal 15 hours agoprevYup! I built a pipeline to grab this and create a historical table of rates on GCP. It was a fun little project. reply mannyv 10 hours agoprevETL: the engine behind a whole lot of everything. reply RyanHamilton 16 hours agoprevcsvbase looks really good. Nice landing page, well written docs. Great work shipping. reply albertzeyer 13 hours agoprevI get: gunzip: unknown compression format reply lucb1e 13 hours agoparentYour comment was closed with reason: Missing steps to reproduce reply golem14 7 hours agoparentprevthat&#x27;s because curl returns an empty file. reply andrewmcwatters 16 hours agoprevThe EDGAR API bulk data is similar in nature, albeit in JSON instead.[1][1]: https:&#x2F;&#x2F;github.com&#x2F;andrewmcwattersandco&#x2F;programming-language... reply eql5 12 hours agoprevSimplicity Wins.All. Ways. (TM) reply sdfghswe 15 hours agoprev [–] What&#x27;s the use case here? For a quick look up you&#x27;re not going to write that monster command. And for a more ongoing repeated use, you&#x27;re not going to download and uncompress the file every time you want to query it...I get the satisfaction as a curiosity, but other than that, to me that wouldn&#x27;t be enough to make the my \"favorite\" or even \"good\". reply accrual 15 hours agoparent [–] I viewed it as an example of how simple it could be (essentially a one-liner), but not meant for actual repeated use as your points suggest. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author details their methodology of utilizing csvbase, a basic web database, for extracting and transforming foreign exchange rate data from the European Central Bank (ECB).",
      "The interactive process includes downloading the data, converting it into a more practical format using a software library called pandas, and then uploading it to csvbase; followed by visualization with gnuplot and complex analysis via duckdb.",
      "Open data availability, simple usage and the efficacy of ECB's data as an exchange format are strongly emphasized in the text."
    ],
    "commentSummary": [
      "The post and thread focus on the European Central Bank's zipfile API that allow users to download CSV files, appreciated for its efficiency and reliability.",
      "The discussion mentions the struggles and constraints of government data usage and brings up the issues of inefficient data management and API (Application Programming Interface) design.",
      "The participants insist on the need for user-friendly, optimized solutions, and suggest various tools, techniques and data formats for effective data storing and processing."
    ],
    "points": 869,
    "commentCount": 232,
    "retryCount": 0,
    "time": 1694797155
  },
  {
    "id": 37527720,
    "title": "I built Excel for Uber and they ditched it",
    "originLink": "https://basta.substack.com/p/no-sacred-masterpieces",
    "originBody": "Basta’s Notes Subscribe Sign in Discover more from Basta’s Notes My regularly scheduled notes Subscribe Continue reading Sign in No sacred masterpieces Or \"that time I built Excel for Uber and they ditched it like a week after launch\" MATT BASTA SEP 15, 2023 28 6 Share This past month I’ve been working on a project that I’m eager to write way too many words about. But for now, it’s not ready to talk about in public. Meanwhile, I either have way too many words about topics that I’m confident nobody wants to hear about or too few words about topics that folks tend to find interesting. In lieu of publishing something too unappealing or too trite, I’ve decided to tell a (true!) story that’s been rattling around in the back of my head for more than a few years. In 2016 I joined Uber. I’d followed a director from Box who had been offered to lead Business Intelligence at Uber. She told me about a team that she thought I’d be perfect for—it was called “Crystal Ball” and it was doing some of the most incredible work she’d come across. I’d put in two good years at Box and seen it through an IPO and was ready for something new, so I jumped. Uber was weird from the get-go. The first week (dubbed “Engucation”) was a mix of learning how to do things that I’d never need to do in the role that I held and setting up benefits and taking compliance classes. Travis Kalanick joined us for a Q&A where he showed off pictures of the self-driving car that the ATG arm of the company was building (it just looked like an SUV with cameras) and the more visually impressive mapping car that was gathering data for the self-driving project (it looked like a weird Dalek on wheels). When I met the members of the Crystal Ball team, it was about four people (not including myself). Everyone was heavily biased towards back-end. I was given a brief tour to the fourth floor of 1455 Market St to understand the problem that the team was solving. “You see all these desks?” “Yeah” “This is where the data scientists sit. They build data science models in R. They run those models on data that they download from Vertica1.” “Okay” “The problem is that the models are slow and take up a lot of resources. So the data scientists have multiple laptops that they download the data to, then run the models overnight. When the data scientists arrive in the morning, the laptops whose models didn’t crash have data that’s maybe usable that day.” “What about the other laptops?” “We don’t have the data we need and we lose money.” “Oh.” This was a big problem for the business: they needed a way to take two kinds of inputs (data and code) and run the code to produce useful outputs. Or, hopefully useful. Testing a model meant running it, so the iteration cycle was very close to one iteration per day per laptop. The team, when I joined, had the beginnings of a tool to automate this. It was called “R-Crusher” and it was essentially a system for scheduling work. They were able to make some API calls and code would be downloaded and executed, and an output file would appear in a directory eventually. As the first (self-professed) front-end engineer on the team, it was my job to build the tool to expose this to the rest of the company. I was grateful that I didn’t need to write any “real” code. I lived in the world of React building UIs with Uber’s in-house front-end framework2 (“Bedrock”). Any time I needed something, I could ask the back-end folks to update the R-Crusher API and I’d get some notes a few hours later to unblock me. The first version of the front-end for R-Crusher (“Wesley”3) was ready in very little time—maybe a few weeks from the point I joined? It was a joy. The next 6-7 months were a hectic rush. I was tasked with hiring more front-end engineers. I built a front-end team4 of seven people. We added user-facing features to Wesley and R-Crusher (“Can we have a text box that only takes capital letters?” “Can we make this text box allow a number whose maximum value is this other text box?”) and debugging tools for the team (“Can we see the output log of the running jobs?”). There were effectively only two things that people were working on at Uber in 2016: The app rewrite/redesign (which launched in November 2016) Uber China All of my work and the team’s work, ultimately, was to support Uber China. R-Crusher was a tool to help get the data we needed to compete with Didi. Nobody really cared very much about the processes for the US and any other country—we had less to lose and Lyft wasn’t seen as remarkable competition except in the handful of cities they were operating at scale. China was a make-or-break opportunity for Uber, China was only going to succeed if we had the data for it5, and the data was going to come (at least in part) from R-Crusher. Over the summer of 2016, we came up against a new twist on the project. We had a model that ran overnight to generate data for anticipated ridership in China. That data wasn’t useful on its own, but if you fed it into a tab on a special Excel spreadsheet, you’d get a little interactive Excel tool for choosing driver incentives. Our job was to take that spreadsheet and make it available as the interface for this model’s data. Now, this was no small feat on the back-end or front-end. First, the data needed to be run and moved to an appropriate location. Then, we had a challenging problem: we needed to take all the logic from this spreadsheet (with hundreds if not thousands of formulas across multiple sheets) and turn it into a UI that Uber China city teams could log into to use. The direction we got from the head of finance at Uber (who, for whatever reason, was seemingly responsible for the project) was “take this [the spreadsheet] and put it in on the website [Wesley].” We asked how we could simplify the UI to meet the resource constraints (engineer time) we had. “The city teams only know how to use Excel, just make it like Excel.” We tried explaining why that was hard and what we could confidently deliver in the time allotted. “Every day that we don’t have this tool as specced, we’re losing millions of dollars.” There was no budging on the spec. The back-end folks tried pushing the project over to the front-end side—there was just no time to convert the spreadsheet to Python or R code. On the front-end, the naive answer was “well I guess we’ve got a lot of JavaScript to write.” But I had something up my sleeve. In 2015, I had built a prototype of a tool at Box. Box had a collaborative note-taking product called Box Notes (based on Hackpad). I had the idea to make a similar project for working with numbers: sometimes you didn’t need a full spreadsheet, you just needed a place to put together a handful of formulas, format it with some headings and text, and share it with other people. Sort of like an ipython notebook for spreadsheets. I called it Box Sums. When I built this, I created a simple React-based spreadsheet UI6 and a super basic spreadsheet formula engine. A few hundred lines of code. And if you dropped an XLS/XLSX file onto the page, I used a Node library to parse it and extract the contents. I demoed Box Sums to the Box Notes team at some point, and they nitpicked the UI and implementation details (“What if two people type in the same cell at the same time? They’ll just overwrite each other.” 🙄). Nothing came of it, but I took the code and shoved it into my back pocket for a rainy day. My idea was to take this code and spruce it up for Uber’s use case. Fill in all the missing features in the spreadsheet engine so that everything the spreadsheet needed to run was supported. The back-end could serve up a 2D array of data representing the ridership data input, and we'd feed that in. And the UI would simply make all but the cells that were meant to be interactive read-only instead. I wasn’t going to be Excel, but it would behave sort of like Excel, it would read an Excel file as input, and it would Excel formulas on some data. That was about as close to “just make it like Excel” that we were going to get. And it also meant that we could skip the process of translating thousands of dense formulas to JavaScript. I got to work polishing up the code. I parsed the XLS file and extracted all the formulas. I found all of the functions those formulas used, and implemented them in my spreadsheet engine. I then went through and implemented all the fun syntax that I hadn’t implemented for my demo at Box (like absolute cell references, where inserting $ characters into cell references makes them keep their column/row when you drag the corner of the cell, or referencing cells in other sheets). A photo of the literal couch that I worked from to build this. Courtesy of California Drywall’s portfolio of building interiors that they helped construct. I sat in the black mirrored wall “spaceship hallway” of 1455’s fifth floor with my headphones playing the same handful of songs on repeat. I spent the early days fixing crashes and debugging errant NaNs. Then I dug into big performance issues7. And finally, I spent time polishing the UI. When everything was working, I started checking my work. I entered some values into the Excel version and my version, and compared the numbers. Excel’s output: 3.03 My output: 3.01 Hmm Excel’s output: 1.002 My output: 1.000 The answers were all almost correct. After a week of work, I was very pleased to see the sheet working to the extent that it was, but having answers that were very, very close is objectively worse than having numbers that are wildly wrong: very wrong numbers usually always mean a simply logic problem. Almost-correct numbers mean something more insidious. I started stepping through the debugger as the calculation engine crawled the spreadsheet’s formula graph. I compared computed values to what they were in the Excel version. The sheer size of the spreadsheet made it almost impossible to trace through all of the formulas (there were simply too many), and I didn’t have another spreadsheet which exhibited this problem. I wrote unit tests. They all passed. I started reading about how Excel represents floating point numbers—maybe JavaScript’s doubles were somehow different than Excel’s notion of a double? This led nowhere. I googled for esoteric knowledge about Excel, rounding, or anything related to non-integer numbers that I could find. It all led nowhere. Just as I was about to resign myself to stepping through the thousands of formulas and recomputations, I decided to head down to the fourth floor to just ask one of the data scientists. I approached their desks. They looked up and had a look of recognition. “Hey guys. I’m working on the driver incentive spreadsheet. I’m trying to mimic the calculations that you have in Excel, but my numbers are all just a little bit off. I was hoping you might have some ideas about what’s going on.” “Can I take a look?” I showed him my laptop and he played with a few numbers in the inputs. “Oh, that’s the circ.” “The ‘circ’?” Another data scientist looked up, “The circular reference.” “I’m sorry?” “We use a circular reference in Excel to do linear regression.” My mind was blown. I had thought, naively perhaps, that circular references in Excel simply created an error. But this data scientist showed me that Excel doesn’t error on circular references—if the computed value of the cell converges. You see, when formulas create a circular reference, Excel will run that computation up to a number of times. If, in those computations, the magnitude of the difference between the most recent and previous computed values for the cell falls below some pre-defined epsilon value (usually a very small number, like 0.00001), Excel will stop recomputing the cell and pretend like it finished successfully. Yeah, really. I thanked the data scientists and returned to the spaceship hallway to think about what the fuck I was going to do next. The changes I needed to make were pretty straightforward. First, it required knowing whether a downstream cell was already computed upstream (for whatever definitions of “downstream” and “upstream” you want to use; there’s not really a good notion of “up” and “down” in a spreadsheet or this graph). If you went to recompute a cell with a formula that referenced an already-recomputed cell, you’d simply keep track of the number of times you computed that cell. If the recomputed value was close enough to the previous value that it fell below the epsilon, you simply pretended like you didn’t recompute the cell and moved on. If it didn’t, you’d continue the process until the number of iterations that you’re keeping track of hit some arbitrary limit (for me, 1000), at which point you’d bail. The changes took a day and a half to make. And would you believe, it worked. The outputs were exactly what they should have been. I wrote tests, I integrated the damn thing into Wesley, and I brought it to the team. We delivered the project in the second week of July. Two things happened. The first was of little consequence but I enjoy telling the story. Rakesh, the team lead working on the back-end, asked me where I got the Excel component. “I made it.” “But where did you get the Excel engine?” “I made it.” “But how are you running Excel in the browser?” “Everything you see is built by me, from scratch.” He simply couldn’t believe that I’d written a full spreadsheet engine that ran in the browser. All things considered, it was maybe only five thousand lines of code total. A gnarly five thousand lines, but (obviously) not intractable. His assumption about the sheer complexity of that option was that it wasn’t a reasonable project to take on. I do think that if I had challenged Rakesh—under no time pressure—to build a spreadsheet engine, he’d get to a working solution as well. My recollection is that he was a very competent engineer. Despite that, I think his intuition about the complexity and scope were based on bad assumptions about what we were ultimately accomplishing, and it’s a good case study in estimating reasonable project outcomes. It goes to show that the sheer imagined complexity of a possible solution is enough to disqualify it in some folks’ minds, even if it's the best possible outcome. The second thing that happened was we shipped. We got the Uber China city team members logging in and using the tool. They plugged away at it, and to my knowledge, the numbers it produced drove driver incentives. That was the third week of July. The last week of July, the head of finance rushed over to our desks. “Why can you see the formulas?” “Sorry?” “When you click in the cells of the spreadsheet you can see the formulas. You shouldn’t be able to do that.” “You said to make it just like Excel.” “People working for Didi apply for intern jobs at Uber China and then exfiltrate our data. We can’t let them see the formulas or they’ll just copy what we do!” Apparently that was a thing. I remember being only half-surprised at the time. I hadn’t considered that our threat model might include employees leaking the computations used to produce the numbers in question. Of course, short of moving the computations up to the server, we couldn't *really* protect the formulas, but that was beyond the scope of what we were being asked to do. The fix was straightforward: I updated the UI to simply not show formulas when you clicked in cells. Easy enough, I guess. The first week of August 2016, Uber China was sold to Didi. Most of us found out because our phones started dinging with news stories about it. We all stopped working and waited until an email arrived a couple hours later announcing the deal internally. If I remember correctly, I just left the office and headed home around lunch time because our team didn’t have anything to do that wasn’t Uber China-related (yet). After Uber China evaporated, the tool was unceremoniously ripped out of Wesley. It was a bespoke UI for a data job that would never run again. We were never asked to build Excel in the browser again8. I feel no sense of loss or disappointment. I wasn’t disappointed at the time, either. My first reaction was to publish the code on Github. https://github.com/WebSheets My second reaction was to move on. There was maybe a part of me—my younger self—that was disappointed that this major piece of code that I’d labored over had been so gently used before being retired. I wasn’t recognized for it in any material way. My manager didn’t even know what I’d built. On the other hand, we as engineers need to be real with ourselves. Every piece of code you write as an engineer is legacy code. Maybe not right now, but it will be. Someone will take joy in ripping it out someday. Every masterpiece will be gleefully replaced, it’s just a matter of time. So why get precious about how long that period of time is? I often hear fairly junior folks saying things to the effect of “I’m here to grow as an engineer.” Growing as an engineer is mutually exclusive with the longevity of your output as an engineer. “Growing as an engineer” means becoming a better engineer, and becoming a better engineer (directly or indirectly) means getting better at using your skills to create business value. Early in your career, the work you do will likely have far less longevity than the work you do later on, simply because you gain maturity over time and learn to build tools that tend to be useful for longer. Sometimes the business value your work generates comes in the way of technical output. Sometimes it’s how you work with the people around you (collaborating, mentoring, etc.). Sometimes it’s about how you support the rest of the team. There are many ways that business value is created. The end (demise?) of Uber China implicitly meant that there was no business value left to create with this project. Continuing to push on it wouldn’t have gotten me or the business anywhere, even if what I'd done was the best possible solution to the problem. Sometimes that’s just how it is. The devops saying “Cattle, not pets” is apt here: code (and by proxy, the products built with that code) is cattle. It does a job for you, and when that job is no longer useful, the code is ready to be retired. If you treat the code like a pet for sentimental reasons, you’re working in direct opposition to the interests of the business. As much as I’d love to work on Uber Excel (I'm ashamed to admit that I thought of “Uber Sheets\" far too long after I left the company), I was hired to solve problems. Having Excel in the browser was a useful solution, but the problem wasn’t showing spreadsheets in the browser: the problem was getting a specific UI delivered to the right users quickly. It’s easy to treat a particularly clever or elegant piece of code as a masterpiece. It might very well be a beautiful trinket! But we engineers are not in the business of beautiful trinkets, we’re in the business of outcomes. In the same way that a chef shouldn’t be disappointed that a beautiful plate of food is “destroyed” by a hungry customer eating it, we shouldn’t be disappointed that our beautiful git repos are marked as “Archived” and shuffled off the production kube cluster. The attitudes that we have towards the things that we make are good indicators of maturity. It’s natural for us to want our work to have staying power and longevity. It’s extremely human to want the validation of our beautiful things being seen and used and recognized; it means we’ve done well. On the other hand, our work being discarded gives us an opportunity to understand what (if anything) we could have done better: Did we build something that didn’t meet the project constraints? Did we build what was requested, but what was requested wasn’t the right thing to ask for? Was the core problem misunderstood? Did the requested solution actually address the needs of the end user? What questions didn’t we ask the stakeholders that could have better-aligned our output with the business need that triggered the request to engineering? Were the expectations that we set around the project inaccurate or vague? Did the project need to be as robust as what was delivered? Could a simpler or less clever solution solved the need equally well? Did we focus on the wrong success criteria? Did we even have success criteria beyond “build what was requested?” Who could have been consulted before or after delivery of the project to validate whether all of the actual project requirements were satisfied? You won’t have the opportunity to take lessons away from the project if you see the sunsetting of the project as a failure: there’s often much to learn about what non-technical aspects of the project broke down. Perhaps there aren’t any, and maybe management is just a group of fools! But often that’s not the case; your delicately milled cog wasn’t ripped out of the machine because it was misunderstood, it was ripped out because it didn’t operate smoothly as a part of the larger system it was installed in. 1 Vertica, for those unfamiliar, is an analytics database that’s designed for very fast queries over very large sets of mostly read-only data. 2 To this day, I’ve never encountered an in-house application system as well-designed as Uber’s. You could go from start to Hello World running on a *.uberinternal.com subdomain in under 30 minutes with full CI/CD. 3 I like to name my projects well, and this one is probably the best-named project in my career. It turns out that Wesley Crusher’s middle initial is “R”, and so that simply had to be the name. 4 Initially we had no manager and instead reported directly to the director that I’d followed. I doubt she had much time to act as the hiring manager, and my suspicion is that she looked at my yes/no recommendation on the interview scorecard as her decision. We eventually got an EM who acted as the hiring manager, but—while perhaps a story for another blog post—he was absolutely dogshit terrible as his job and I suspect he also was not invested in the hiring process and just took my recommendation. Talking about this awful EM and the other particularly bad EM(s?) I’ve had is a topic for another post. 5 For instance, knowing what to offer to drivers as incentives so they wouldn’t drive for Didi instead. The company had real issues where if we got driver incentives wrong, drivers would open the app to check incentives, switch to Didi to see their incentives, and simply not switch back. 6 I cannot underscore enough how remedial this UI was, supporting only the most trivial of spreadsheet functionality. Selecting cells, editing their contents, navigating around with your keyboard—that sort of thing. I think the most advanced feature was the draggable corner in the bottom right to copy the contents of the cell left or right (adjusting cell references in formulas appropriately). 7 I modeled the spreadsheets as a directed graph: each cell was a node, and each cell reference in a cell’s formula was an edge to another cell. Initially, a changed cell meant first computing its value by looking at the cached value of its dependencies (if you reference another cell in the one you just changed, the value of that other cell hasn’t changed, so just use the previously computed value). But then, you need to recompute every cell that depends on the one you just updated. My initial algorithm did this naively, leading to lots of wasted computations. Rather than walking the inbound edges for a cell and computing their values, the algorithm was changed to walk the graph of dependent cells (that is, the cells that depend on the one that changed) in a breadth-first manner to produce a set of cells to recompute, preferring that order. You don’t need to get the order perfect; the goal is to avoid recomputing the same cell more than once. 8 Big asterisk here: we were, but not for spreadsheet formulas. What I was tasked with building is fodder for another blog post another time. Subscribe to Basta’s Notes By Matt Basta · Launched a year ago My regularly scheduled notes Subscribe 28 Likes · 4 Restacks 28 6 Share 6 Comments Joseph Wiess Writes Crann na beatha 12 hrs ago Liked by Matt Basta You did what software engineers do: you designed something, and it worked. It's not your fault that the suits decided to sell the company to the enemy. What you did was a success. It's something for your working resume. LIKE (4) REPLY SHARE Sashko Stubailo 14 hrs ago Liked by Matt Basta Wonderful story. An example of one of those projects that must have felt so good when it actually worked! Sometimes those things end up not being needed long term, but as a software engineer I get such great enjoyment out of the cases where it actually is a game changer to build a small yet sophisticated piece of software that just works super well. LIKE (2) REPLY SHARE 4 more comments... Top New Community The absolute audacity of Apple Podcasts A bit of a rant about Apple JAN 25 • MATT BASTA 12 3 Thoughts on layoffs and making points through writing What a week, huh NOV 5, 2022 • MATT BASTA 15 1 I ask three questions When I'm interviewing for a job, these are the questions I ask APR 14 • MATT BASTA 5 See all Ready for more? Subscribe © 2023 Matt Basta Privacy ∙ Terms ∙ Collection notice Start Writing Get the app Substack is the home for great writing",
    "commentLink": "https://news.ycombinator.com/item?id=37527720",
    "commentBody": "I built Excel for Uber and they ditched itHacker NewspastloginI built Excel for Uber and they ditched it (basta.substack.com) 538 points by robdimarco 15 hours ago| hidepastfavorite396 comments ipython 10 hours agoBest quote: \"People working for Didi apply for intern jobs at Uber China and then exfiltrate our data. We can’t let them see the formulas or they’ll just copy what we do!”This is so true. People in the US just don&#x27;t understand the level of economic and industrial espionage that happens in China on a daily basis. I was responding to an unrelated breach at an unnamed tech company back in mid-2000s time frame and had a side bar conversation that went like the following:Them: \"Yeah, we just opened a tech center in Xinjiang and ... wow, we&#x27;ve had quite the rash of lost ID badges there recently\"Me: \"Have you considered that they&#x27;re not &#x27;lost&#x27;, but rather &#x27;sold&#x27; for profit?\"... silence ...I don&#x27;t know if executives are aware but just don&#x27;t care, or if they&#x27;re simply incompetent, but China has productized industrial espionage on a massive scale. GE Aviation was a victim more recently: https:&#x2F;&#x2F;www.cincinnati.com&#x2F;story&#x2F;news&#x2F;2022&#x2F;11&#x2F;16&#x2F;accused-chi... reply iancmceachern 4 hours agoparentI&#x27;ve watched this happen.I&#x27;ve watched key, core engineers and technical leaders work for US and European companies, develop their next generation products, then turn around and design and develop essentially the exact same thing for the Chinese market. They then build a company, in China, that makes essentially the same product, but for the Chinese Market, and with Chinese investors, etc.Examples: Thoratec&#x2F;Abbot Heartmate III & CH BiomedicalAuris&#x2F;Verb&#x2F;J&J Robotic & Digital Solutions & Renovo SurgicalThe ironic thing, is that some of these companies after success in China are working to sell and be competitive in the US and Europe.It&#x27;s not even secret or under the table anymore, it&#x27;s overt and largely accepted as the way it is in our industry. A brave new world.The other factor, is that it is very very difficult for a foreign company to do business and protect their assets in China, so often the wise companies don&#x27;t even try. They often just license their stuff for the Chinese market to a Chinese company. That way they at least have a chance of not having it all just stolen. reply vkazanov 3 hours agorootparentSo an engineer learns how to make something, and then goes elsewhere to make it.To be honest, the way you put ut, the story feels OK to me.There are many truly bad examples, e.g. the arm china story, but engineers doing their thing is not one of them. reply iancmceachern 3 hours agorootparentThis isn&#x27;t that.This is engineers deliberately taking tech to somewhere where they know IP laws won&#x27;t be enforced.It&#x27;s not like I&#x27;m saying they can learn calculus here and then go to China and use calculus to design things.It&#x27;s that I&#x27;m saying they design a very specific thing, a very specific way, for hire, then go make that exact specific thing, that same specific way.If it were in any other country but China, it wouldn&#x27;t be allowed to happen. reply barry-cotter 1 hour agorootparent> It&#x27;s that I&#x27;m saying they design a very specific thing, a very specific way, for hire, then go make that exact specific thing, that same specific way.I really doubt this unless all the inputs are commoditised. Industrial espionage usually fails because if you don’t have the know how to make the tools that make the tools it’s difficult to impossible to literally copy it. Not saying what you’re saying doesn’t happen, it does, all the time. But usually the engineering is substantially different if only because different things are cheap or expensive, or just unavailable.> If it were in any other country but China, it wouldn&#x27;t be allowed to happen.Historically, the US, Japan, Korea, Taiwan all did it. No doubt Vietnam does it now too. Not like they have an excellent civil legal system. Joys of working in developing countries. reply flakeoil 44 minutes agorootparent> if you don’t have the know how to make the tools that make the tools it’s difficult to impossible to literally copy it.Smart and knowledgable people in a certain field, but who are slightly stuck, can be helped by a few tiny details. If someone can provide a specific manual or piece of documentation, or just a photo copy or image of some key detail then those smart and knowledgable people can pass the hurdle and continue. reply harles 3 hours agorootparentprevThe espionage really is next level in China. It’s not just reconstructing software (that’s part of it) but stealing binaries (and source where they can) for everything along the way.I worked at a large tech co with an assembly line in China and experienced this first hand. A routine scan of one of our calibration machines turned up a Trojan with a copy of all calibration software squirreled away. Fortunately nothing is network connected there, but it was obvious someone was planning to come back for it. The stash had our calibration software and the factory’s proprietary control software on it. Both companies sent security to watch the machine for 48 hours straight until a hard drive shredder could be procured to mutually assure each party no software would leak. It was nuts, but apparently common. reply prox 3 hours agorootparentHow did this become a thing on a cultural scale? Like that everyone does it and it is almost expected as it were? reply iancmceachern 2 hours agorootparentIt&#x27;s master planned by the government.Just Google \"Chinese protectionist\" and then any industry. The Chinese government has been actively targeting everything from CNC machine tools to medical devices and semiconductors for decades. Some industries with more success than others. Anything they import, especially industrial equipment like textile looms, cnc machines, semiconductor equipment, etc. There are big, long term, well funded pushes to manufacture indigenous versions of just about everything. Airplanes, jet engines, computer chips, industrial equipment, on and on reply varjag 1 hour agorootparentprevMainand Chinese culture owes itself more to Stalin than to Confucius. If you lived in USSR stories like this have certain warmth of deep cultural connect. reply kome 1 hour agorootparentprevit&#x27;s not espionage, it&#x27;s a development strategy, and it&#x27;s working well. it foster local knowledge, local know how and local production.the deal is: you can use our cheap labor force, but we can use your ideas reply nrb 58 minutes agorootparentThe issue appears to be when they’re not just using the ideas, but the implementations verbatim? reply emptysongglass 57 minutes agorootparentprevThat&#x27;s not \"the deal\". It&#x27;s illegal. No one on either side agreed to do this and had that been part of the negotiation, the offended party would have walked away or else agreed to a higher sale price in exchange for technology transfer. reply ClumsyPilot 12 minutes agorootparentprev> So an engineer learns how to make something, and then goes elsewhere to make it.It&#x27;s not long till the capital class claims ownership of your brain too. &#x2F;s reply noobface 4 hours agorootparentprevEveryone should&#x27;ve seen what happened to Cisco and thought better, but short sighted execs focused only on next quarter gladly opened the gates and accepted the horse. reply Moru 2 hours agorootparentEveryone did see it coming. Interviews of experts on TV, talked about at the coffee table at every industry in the west. But since the stockmarket demands constant growth we have to move production to china. And when the move is done, the CEO has a nice rep-sheet showing how much profits went up while he was working at the company and gets hired by the next one. reply swader999 3 hours agorootparentprevNortel too. reply nikau 1 hour agorootparentprevTerrible, such actions are only tolerable when the US do it via moral operations like operation paperclip. reply bbor 59 minutes agorootparentHow is that related? Are you actually saying that the US was being unfair to Germany by stepping on their IP? Of all the criticisms of that program I’ve never heard “but won’t somebody think of the Germans” lol.Also, two wrongs don’t make a right, and 1945 was 2-3 scientific revolutions ago reply mkii 9 hours agoparentprevAnd yet, when the author takes code from one company to use for another, or releases company code on Github, nobody bats an eyelid. reply zik 8 hours agorootparentMy hair stood on end both times he did this. Holy crap that&#x27;s some massive legal liability. reply lovich 6 hours agorootparentI got into this with another set of engineers on Reddit where I discovered there’s a subculture of engineers who don’t believe you can’t actually own code and apparently take a copy of their employers source code repository everytime they switch jobs.Edit: Updated “can actually own code” to “can’t actually own code” reply sk0g 2 hours agorootparentFYI the edit might have made it more confusing, since there&#x27;s a double negative now. \"don&#x27;t believe you can&#x27;t actually own code\" reads as \"believe you can actually own code\", which I&#x27;m not sure is what you were going for. reply lovich 2 hours agorootparentWell fuck, too late to edit it again. My grammatical error shall live on forever reply concordDance 2 hours agorootparentprevOne thing I regret is not taking a copy of the code I wrote for another company, so many handy little utility functions I made that I then had to recreate. The transaction costs for b2b are far too high for any reasonable sale, so exfiltration is the utilitarian choice. reply lovich 2 hours agorootparentThat’s still just theft if you’re not a contractor? Full time software employees are doing work for hire. There’s plenty of moral and ideological arguments about theft being morally acceptable in this situation but I was more marveling at the people who thought that taking source code from their company was legally not theft reply concordDance 50 minutes agorootparentIt&#x27;s not theft, it&#x27;s copyright infringement and is very morally and practically different from theft.The range of circumstances in which it is morally acceptable are MUCH broader. reply aragonite 1 hour agorootparentprev1. Suppose the OP did not take the source code files, but memorized the source code and later recalled it from memory. Would that be theft?2. Suppose the OP neither took the file nor memorized the code, but had photographic memory and replayed the exact visual scenes during their creation of the utility functions and copied down the code from what they saw in their mind&#x27;s eye. Would that be theft?3. Suppose the OP was solving a seemingly novel problem and suddenly remembered how they solved the exact same problem when they were employed by company X. Are they obligated to banish this solution from their mind? reply sneak 7 hours agorootparentprevThe code is MIT licensed. Anyone is legally allowed to upload MIT licensed code to GitHub, it&#x27;s free software and may be freely redistributed. reply treesknees 7 hours agorootparentIt’s alarming because, in my experience, anything you write for an employer is intellectual property of the company. Unless he wrote that Box demo all on his own time and his own equipment completely outside of work, or Box has some abnormal contract with their employees, he can’t just slap an MIT license onto it and call it open source.I worked with a few people who were successfully sued by our employer when those people left and brought a “spare time” project&#x2F;tool with them and tried to publish it. It wasn’t even code we sold or ended up using internally, but was still IP of the company because they wrote it during business hours on a work machine. reply lll-o-lll 6 hours agorootparentWorse than that, many companies have clauses that indicate that any software you write (regardless of whether for the company or not), belongs to them. I don’t know if this would hold up in court, but it’s there in the contract. reply fiddlerwoaroof 4 hours agorootparentIn California, at least, this is illegal unless the code competes with the company&#x27;s products. reply harles 3 hours agorootparentIt’s pretty hard not to overlap with big tech companies. Everything has been touched internally.My understanding is the same though. Unfortunately whether a clause is legal or not may matter little - you’ll run out of cash for legal bills before they do. The best defense is probably just that most companies don’t care about your side projects. reply oddmiral 2 hours agorootparentprevAll your codebase are belong to us. reply sneak 7 hours agorootparentprevYes, but if we speculate as to the invalidity of the explicitly published license, we basically can&#x27;t use any foss code on GitHub.Any reasonable person can expect that the MIT license on this code is valid and authorized by the rightsholder.Did Uber or Box explicitly agree to release it under an foss license? Is it the author&#x27;s personal individual copyright made on personal hardware outside of work location&#x2F;time? Does it predate their employment? Nothing in the article linked indicates clearly that it was written for an employer.If I am expected to research this for every foss library published on GitHub by someone who works for Big Tech, then we are all capital-f fucked.It&#x27;s easiest and sanest to assume that people are not lying. reply nwiswell 7 hours agorootparent\"It&#x27;s easiest and safest to assume that property is not stolen\" is a parallel construction of your argument.You can assume whatever you want but the cops may not be very impressed.There are a lot of polite fictions in law, and this is one of them. If you had no reasonable way of knowing that a license was invalid (or property was stolen), the judge is probably going to be sympathetic, but the property will still get returned to its proper owner.If you DID have a reasonable way to know that the status of the property was suspect (as in this case), they are likely to take a dim view of the situation. reply sneak 6 hours agorootparentI&#x27;m not talking about this code in particular - I am talking about all code presumably written by individuals and posted on GitHub with a LICENSE file saying it&#x27;s free software.It is standard, reasonable person practice to use foss-labeled code on GitHub under the presumption that the license is not a lie.This case is no different.Nothing in the author&#x27;s linked story suggests this code is not MIT licensed as the repo claims. It is unreasonable to assume that the license file in the repo is false; nothing available to us supports this assumption. reply kubanczyk 1 hour agorootparentYeah, you want to get rid of uncertainty, but it&#x27;s here to stay. The whole legal system is not brought to its knees over the fact that no code on GitHub (gasp) is automatically guaranteed to be safe against copyright infringement.> It is standard, reasonable person practice to use foss-labeled code on GitHub under the presumption that the license is not a lie.Yes, absolutely: presumption, not certainty. (Nitpicking the phrasing: presumption that the copyright is not a lie, the issue does not even venture into licensing.) reply justinclift 4 hours agorootparentprev> Any reasonable person can expect that the MIT license on this code is valid and authorized by the rightsholder.Yep, that&#x27;s the reasonable default position.If however, the author of the code wrote a length article about how they&#x27;d developed this code while working for a company (not in their spare time), and you happen to read the article in question... then for that specific repo you might look at it differently.The article in question doesn&#x27;t clarify things regarding the Box derived code, nor whether they sought and received permission from Uber prior to publishing. Absent both of those, I&#x27;d personally not use code from this repo.That&#x27;s just me being risk-adverse here, as I don&#x27;t personally have a use for the code. Others might make different choices. :) reply dima55 6 hours agorootparentprevSorta. He has a license (MIT), but no copyright statement. The license is an agreement between the copyright holder and the user. Normally he would have gotten the sign-off from his employer to release this, and this thing would be Copyright: Box, License: MIT. But there&#x27;s no explicit copyright holder stated, which makes me think that he just uploaded and \"licensed\" code that he doesn&#x27;t own. reply camkego 2 hours agorootparentprevYou can be 99.999% sure unless the engineer went through a long painstaking process to get Box or Uber to open-source and then re-license the code to MIT, it was fully owned under traditional copyright by Box when it was originally authored. Actually, it gets fairly complicated, because he created a derivate work at Uber with with what is likely Box&#x27;s IP. reply acjohnson55 6 hours agorootparentprevIt&#x27;s probably not legally his code to license, if his employment agreement is like the vast majority of engineers&#x27;. reply speedgoose 3 hours agorootparentHe could be authorised to open source the company code he wrote. Though, I wouldn’t bet it’s the case there. But Uber has a lot of Open-source projects so they are perhaps allowing engineers to decide themselves. reply dclowd9901 7 hours agorootparentprevNot when he wrote it for and showed it to box. Doesn’t matter how he “licensed” it. They would have had good legal standing to come after him. I can’t believe he wrote that on his blog. He should honestly take it down. reply choppaface 2 hours agorootparentprevIt&#x27;s MIT licensed now. It probably wasn&#x27;t originally, and&#x2F;or he may not have had the authority to choose the license while at Box &#x2F; Uber. reply camkego 2 hours agorootparentYou can&#x27;t just re-license intellectual property that someone owns the rights to. EVEN if you authored originally. It&#x27;s likely Box and Uber own rights to different parts of the IP, under both employment law, and his employment contract. reply tomcam 6 hours agorootparentprevHell to the yes. I don’t know why these aren’t the top rated comments. reply stickfigure 9 hours agorootparentprevIf we&#x27;re being generous, the author may have had permission to do so. It&#x27;s not inconceivable; the code was abandoned. If one of my reports had asked, I would have approved. reply tomcam 6 hours agorootparentI’m assuming you own the company. Because if you don’t, you don’t have that right. reply stickfigure 4 hours agorootparentYou might or might not; it&#x27;s not like Google polls the shareholders to decide what source license to use for each project. Authority gets delegated and every company is different. reply tgsovlerkhgsel 2 hours agorootparentprevUnless the company has an open source program that allows open source releases with manager approval. reply Kon-Peki 7 hours agorootparentprevYou probably don&#x27;t have the authority to allow your report to release \"company code\" on their personal Github account. reply justinwp 6 hours agorootparentI think you might be surprised how easy this process is at some big tech companies. For me the bigger hurdle is getting past a privacy review, not the issue of the license. reply glandium 11 minutes agorootparentStory time. In a past life, I tried to open source code I wrote at work. My manager greenlit it, but obviously that wasn&#x27;t enough. Next thing I know, I&#x27;m in a room with a lawyer trying to write a patent. In the end, no patent was filed, and the code was never open sourced. What a waste. Arguably, that was 15+ years ago, it would probably go down differently now... reply crazygringo 5 hours agorootparentprevYes, I would be surprised.What big tech company makes it easy for you to take code written and deployed there while you were employed, and just open-source it?I know there are big tech firms that own everything you do outside of work, but have a fairly easy process to allow you to release that as open-source.But this is different, this is about code written for and deployed by the company itself, that isn&#x27;t part of any corporate open-source strategy. reply swores 13 minutes agorootparentI&#x27;ve only managed small businesses not large ones, but personally I&#x27;d be fine 9 times out of 10 with a developer who asked to open source a project they had built an mvp&#x2F;poc of, but that never got approved to be used at all.I could even imagine approving of a policy for the open sourcing &#x2F; licensing of code, where any code that&#x27;s used or previously used by the company in any way needs to go through an approvals process if anyone wants to open source it, while anything created but never used has a much simpler barrier such as manager agreeing in writing that it&#x27;s unneeded code and therefore eligible for instant open sourcing under a specific license and specific terms of release.> \"But this is different, this is about code written for and deployed by the company itself\"Written for, yes, but seemingly never deployed (except to the extent that it could be demo&#x27;d and rejected). From the article:> [After looking at a product owned by an unrelated team in the company, he single-handedly decided to make what he thought would be a good add-on or sibling to it] \"I demoed Box Sums to the Box Notes team at some point, and they nitpicked the UI and implementation details (“What if two people type in the same cell at the same time? They’ll just overwrite each other.” ). Nothing came of it, but I took the code and shoved it into my back pocket for a rainy day.\"It&#x27;s not impossible \"nothing came of it\" is a shortened version of \"they said it seemed like an awesome tool but too far from the original scope to want to take on and commit to maintaining, and as they said there was no chance that decision would change my manager agreed to sign off on my releasing it under MIT license as is allowed for un-used code.\" reply closeparen 4 hours agorootparentprev“Corporate open source strategy” where I work is just having a form that engineers can fill out to request to open source things, and a committee on the other end of the form to sign off. It’s similar to the process for speaking at a conference or publishing on the company blog. Management sometimes steers in the direction of more or less public content, but specific releases are always individual initiative by engineers who want to develop their project in the open. Tech brand wants our name associated with high quality work. replytomcam 6 hours agorootparentprevThat jumped right out at me too. Two levels of IP theft except on the remote chance that both companies allowed OP to open source the code. reply concordDance 2 hours agorootparentprevThat&#x27;s because that code wasn&#x27;t in use, so there&#x27;s no lost business. reply robertlagrant 2 hours agorootparentThat isn&#x27;t how ownership works. reply concordDance 51 minutes agorootparentWho cares about copyright \"ownership\"? It&#x27;s a means to an end, more innovation.When it can&#x27;t possible serve that end (again, selling a set of utility methods that would take a dev a few hours to make from spec is impossible) people should discard it. reply kome 1 hour agorootparentprevyes, but who cares. software is software. reply robertlagrant 1 hour agorootparentNo idea what your point is, sorry. reply kome 1 hour agorootparenti understand ownership, but software and code are so easy to copy, transfer and modify that it would be stupid not to do it. it&#x27;s not like stealing a car. arrrin other words: ownership of immaterial goods is mostly a scam replycamel_gopher 6 hours agorootparentprevThat’s called being a Code Gypsy reply slim 4 hours agorootparentprevto be fair it was not obvious the author was from asian origins, I had to look up his picture in linkedin &#x2F;s reply cflewis 10 hours agoparentprevWell, not just corporate espionage, right? State espionage is going to be at every large US company too. To speak to the article, I can only imagine how excited an agency would be to get real-time updates on the Uber movements of a target. reply nextaccountic 9 hours agorootparent> State espionage is going to be at every large US company too.Snowden revealed, among other things, that the NSA did state espionage on Brazil&#x27;s state oil company, Petrobrashttps:&#x2F;&#x2F;www.nytimes.com&#x2F;2013&#x2F;09&#x2F;09&#x2F;world&#x2F;americas&#x2F;nsa-spied-...https:&#x2F;&#x2F;www.theguardian.com&#x2F;world&#x2F;2013&#x2F;sep&#x2F;09&#x2F;nsa-spying-bra...https:&#x2F;&#x2F;g1.globo.com&#x2F;fantastico&#x2F;noticia&#x2F;2013&#x2F;09&#x2F;nsa-document...International relations are based on reciprocity. I sincerely think that if the US didn&#x27;t think that industrial espionage would be a legitimate activity of intelligence agencies, they wouldn&#x27;t practice it themselves. reply fnordpiglet 9 hours agorootparentA crucial difference is the US spying is for state use, whereas in China the state is deeply intermixed with industry. State industrial espionage is used for commercial competitive advantage. This is a huge structural and cultural difference.For instance it’s hard to believe China bootstrapped BYD and GWM among others from green fields. They’ve been exfiltrating and transferring automotive technology for decades. Their products are often near duplicates of other brands - such as the fiat case:https:&#x2F;&#x2F;www.carsguide.com.au&#x2F;car-news&#x2F;spot-the-difference-ca...These aren’t cheap knock offs, they have a relatively high quality and with stolen R&D it’s easy to produce at a low cost - the cost can’t be explained by labor alone, as automakers outside China have access to similarly low cost labor.Note, I don’t think China is incapable of making their own R&D at the same quality as anywhere else; they can. But they don’t when they don’t have to.The next few decades will see a huge realignment as the decades of theft and forced transfer will begin to seriously pay off. reply PeterStuer 4 hours agorootparentUS corporate espionage is also shared with select companies for economic gains. This has been going on since forever. Google Echelon. reply ezconnect 8 hours agorootparentprevUS government have been using all it&#x27;s tools to destroy US corporation competition since forever. Look at Huawei for just one example. reply nonethewiser 6 hours agorootparentHuaweis main competition is Ericson and Nokiabin the networking space. Neither American. reply aurareturn 6 hours agorootparentCisco, Apple, Google, Qualcomm reply blackoil 6 hours agorootparentprevHuawei is a giant. In phones they had bigger marketshare than Apple. Their chips are nearly on par with Qualcomm. It is naive to believe they are banned for security concerns. reply ezconnect 5 hours agorootparentprevQualcomm is their main competitor in 5G patents and technology. reply sumedh 5 hours agorootparentprev> Look at Huawei for just one example.Didnt Huawei steal from Nortel? reply aurareturn 9 hours agorootparentprev“When governments permit counterfeiting or copying of American products, it is stealing our future, and it is no longer free trade.” - US President Donald Trump, commenting on China.Actually, the above quote is not Trump and not on China. It&#x27;s Ronald Raegan on Japan in 1985.When a new economic threat rises, the US will use the same playbook- demonizing in media, accusations, turn the public against said country, ban products, increase tariffs from said country, turn to allies, etc. reply fnordpiglet 8 hours agorootparentExcept China has required technology transfer and has been actively committing state sponsored industrial espionage for decades. Surely this isn’t news?I’m down with China as a competitor, but we have a strong division between state and industry and China does not. I don’t think a unipolar world is a good idea, and I’m glad for a resurgent China. But it’s absurd to put on blinders and believe forced technology transfer and industrial espionage isn’t a cornerstone of their success.https:&#x2F;&#x2F;www.investopedia.com&#x2F;forced-technology-transfer-ftt-...https:&#x2F;&#x2F;www.csis.org&#x2F;programs&#x2F;strategic-technologies-program...At several megacorps seeking access to Chinese markets we were forced to transfer crucial trade secrets in exchange for access. We did our best to render it as useless as possible, but it was still very key stuff. Over two decades the Chinese government erected barrier after barrier even after complying to the point that the market access failed and competitors based on our technology dominated the domestic Chinese economy.I see your parallel comments where you vigorously decry these statements as some sort of nationalism and anti Chinese sentiment. This isn’t that - this is simple historical fact, and I have had first hand experience with it and know the game being played from personal experience. I assumed this was all common knowledge given how much press it’s gotten over the last twenty years, which makes me wonder why you’re grinding this contrarian axe so hard?Edit: I would note that this is fundamentally different from counterfeiting. This is capturing R&D directly at the top end of technology and processes through extortion and outright theft. I don’t actually blame China or Chinese people, it’s just a cultural difference in what’s acceptable and a belief that the state and industry are separate, which China doesn’t agree with. But the lesson to be learned is China doesn’t play by our rules, and we need to adapt to the situation better. reply jbm 5 hours agorootparent> actively committing state sponsored industrial espionage for decadesI&#x27;m sure you are right but I feel this is actually beneficial.The interests that have captured China are likely different from the ones in the US, and much different from the inferior oligarchs that have captured my home country (Canada). I see their national interests having an unintended consequence; the creation of markets of scale for products that are not politically viable here.We all know the stories of oil companies buying the rights to battery technologies and sitting on them. There is even a Wikipedia article about it [1] that I&#x27;ll link to below. China is never going to have enough oil to export, and as such, Oil will always be a cost center for them.Copyright maximalism and intellectual \"property\" is strangling all of us, and I don&#x27;t want it to put us in an early grave as a race. I&#x27;m grateful that China is \"stealing\" this \"property\" and turning it into batteries, solar panels and other products that I can buy, and that it iterates on them rapidly - rather than being put in a box.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Patent_encumbrance_of_large_au... reply barrysteve 5 hours agorootparentprevI don&#x27;t get it. Literally everyone is doing this concept. Everbody is snatching every last drop of data that isn&#x27;t nailed down. Nobody asks for permission.ChatGPT is the most recent example.\"Study hard and keep the rewards\" is basically a dead concept.The separation between state and corporation is a red herring. It&#x27;s trivially easy for Bill Gates to reveal secrets to Bill Clinton behind closed doors.Corporations are absolutely abmysal at keeping secrets. They are open-by-default and cannot legally stay in business with the level of security required to keep knowledge from leaking.Why is this even a conversation.... reply shostack 8 hours agorootparentprevDon&#x27;t bother. These whataboutism accounts pop up all the time on stories like this. reply aurareturn 6 hours agorootparentAnd you use the “whataboutism” as your main argument for whenever someone isn’t anti-china. The world runs on reciprocity. Whataboutism is built into assumptions. It’s called fairness and it’s an intrinsic human trait. reply fnordpiglet 5 hours agorootparentFallacious thinking is in fact an intrinsic human trait, but to equate fallacious thinking with fairness is a little creepy.I’d also note while we are on the topic of anti-China, and you’ve lobbed anti Chinese out there - I’ll wager almost (almost!) everyone here, myself especially, isn’t anti anything about China or Chinese people. But that doesn’t mean we are pro the communist party’s policies - and frankly so are very few Chinese. The fact that forced tech transfer and industrial espionage is embarrassing to the Chinese government and sullies all success is no one’s fault but the Chinese governments, and that’s where it begins and ends.I’m no defender of the US government either, but that’s not even the topic here. I’ll be happy to engage on that topic in the relevant threads. That’s, after all, fair. reply blackoil 6 hours agorootparentprevWhataboutism is shield of hypocrites. Ignore all atrocities and human rights abuse we are doing, only wrongs of country X are relevant. reply aurareturn 5 hours agorootparentUS media: China is wrong to use its military power to bully countries.Poster: But the US does it too and has done it for far longer and more often.Average HN reply: Omg, whataboutism. reply fnordpiglet 5 hours agorootparentThat is sort of the definition of the informal red herring fallacy whataboutism. It doesn’t mean the US hasn’t. It means it’s not related to China being wrong to use military power to bully countries. An awful lot of folks here agree it’s wrong for anyone to bully anyone in any context, especially nations bullying the people of another country. We are all, after all, people. But people citing a fallacy when a fallacy is used is fully appropriate, even if you really wish it wasn’t a fallacy. reply aurareturn 4 hours agorootparentI don&#x27;t have a problem with the US bullying others. My problem is that people here on HN and in the west in general, demonizing China for doing the exact same thing when the US has done worse. They think it&#x27;s ok to boycott Chinese products, but they won&#x27;t boycott product from their own country. They will say that the Chinese government is evil, but is completely ok with the government of their own. They will say China has no right to bully Vietnam, but they will vote in politicians who advocate for war with just about anyone.It&#x27;s hypocritical. Don&#x27;t demonize China unless you&#x27;re willing to demonize yourself.Hell, don&#x27;t demonize China unless you read their point of view too. I&#x27;m sure you&#x27;re only getting one POV. reply robertlagrant 2 hours agorootparent> My problem is that people here on HN and in the west in general, demonizing China for doing the exact same thing when the US has done worseEr, no. Far more ink is spilled on the US being bad, or Western countries in general being bad, by people in the West. What you&#x27;re saying is not true for HN, nor for the West in general. reply waffleiron 2 hours agorootparentprev> An awful lot of folks here agree it’s wrong for anyone to bully anyone in any context, especially nations bullying the people of another country.Sure, but the hypocrisy is also in how things get reported. See for example:https:&#x2F;&#x2F;www.reuters.com&#x2F;investigates&#x2F;special-report&#x2F;us-china...Which says:> through incentives and pressure on consortium members.No doubt this would be \"bribes and threats\" if it were done by a geopolitical opponent.Second, posts critical of the US tend to get many less votes or flagged quickly, with people calling it whataboutism in posts about China or Russia. That leaves no space to properly discuss those things.Finally, it’s good to have things in a realist context. It’s idealist thinking if we get upset when a geopolitical enemy does something which is commonplace in out own country and that if allies. replyaurareturn 6 hours agorootparentprevWhat you’re doing is completely denouncing BYD’s accomplishments by saying they must have stolen the technology to get to where they are today.That’s the exact argument you will use to convince yourself of any of China’s successes stories. They can’t possibly innovate because they’re Chinese and not western. Therefore, they must have stolen the tech. This is how Raegan convinced the public in 1980s. reply fnordpiglet 5 hours agorootparentI don’t think you read anything I wrote.China has enormous success stories that don’t depend on pilfering or extorting, and a rich history for thousands of years. In fact I think the Chinese governments behavior in this respect is below the divinity of Chinese people and Chinese culture. This plays out in the recent domestic behavior of the Chinese government towards its own people. I even said I welcome a multipolar world with a resurgent china.But if you think forced technology transfer and industrial espionage by the Chinese state to benefit the Chinese states industrial interests - which have become pervasive in China under Xi with most major Chinese ventures being forced to take state funding and control - you are deluded, or are trying to delude. I say this with all the force of someone who has experienced the fact of what’s happening directly - you can throw racism or nationalism around all you want, but there’s a cold reality that exists independent of such concepts and I - and many others in technology - have experienced it first hand. It’s calculating, cold, and very much real - and race and nationalism have very little to do with it. It’s political and it’s absolutely real.Btw, you can’t sit in a BYD and not see the technology transfers and the espionage spoils. China could be successful on its own merit, but not with the Chinese communist party controlling industry and civil society. I just hope some day Chinese people will be free to be that competitor on equal footing with the world. What happens in China today is a disgrace to Chinese everywhere, who are some of the most brilliant and hard working people out there. Until that day I welcome them to work with me here, and we can make great things together. reply Dylan16807 6 hours agorootparentprev> Actually, the above quote is not Trump and not on China. It&#x27;s Ronald Raegan on Japan in 1985.Good, I was surprised at the claim that trump would say something so balanced.What&#x27;s \"demonizing\" about this? It doesn&#x27;t even mention a specific country.\"accusations\" are not a problem if they&#x27;re true... reply ipython 10 hours agorootparentprevTwo things. First, this isn&#x27;t the same thing; you&#x27;re talking about embedding a resource in a company to read out real time telemetry from internal systems (information with a short shelf life), not stealing industrial trade secrets (information with a very long shelf life). Second, I can assure you that, even with our imperfect systems, there is actually a set of checks and balances in place to prevent rampant (note I said rampant) abuse of this kind.Yes, agencies would be very excited for this sort of capability. Do they get it as a matter of course that easily? No. There are layers of accountability, legal authorities, and (warranted) push back from commercial entities. reply BlueTemplar 6 hours agorootparentThe last bit strikes me as dubious, considering the Snowden revelations.Yeah, sure, I&#x27;d guess that what China does is at least an order of magnitude worse, and sure, because they&#x27;re less democratic, but also because they are much often behind - and let&#x27;s not kid ourselves, in the situations the US feels it&#x27;s behind, it&#x27;s also using the widespread backdoors they have access to (Crypto AG, Cisco routers, Juniper Networks, Windows, Intel&Ryzen CPUs...) reply willcipriano 2 hours agoparentprevIntellectual property is a western invention as I understand it. I don&#x27;t think China agrees that you can own an idea like we assert that we do. reply layer8 1 hour agorootparentChina certainly did agree in various ways: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Intellectual_property_in_China reply willcipriano 1 hour agorootparentInteresting commentary on the talk page there. reply mmcwilliams 9 hours agoparentprevIt&#x27;s somewhat ironic to frame that as a problem that \"isn&#x27;t understood\" in the US considering what the CEO of this company was convicted of. reply makeitdouble 10 hours agoparentprevThey don&#x27;t understand it, because what you&#x27;re quoting as a behavior is pretty standard anywhere in the world. That&#x27;s why companies protect their secrets from low rank employees.Except if you&#x27;re arguing that western companies are bound by stronger ethics, in which case I&#x27;d like to see some evidence. reply envsubst 9 hours agorootparent> western companies are bound by stronger ethicsI wouldn&#x27;t say people in the west are \"better people in their hearts\" but they absolutely follow more strict norms regarding honesty and theft. This is one of the main reasons why companies pay a premium for workers in the west when they could hire from other places.One example: accounting scandals in the US are rare. I don&#x27;t think anyone trusts accounting figures for public companies from India or china.> in which case I&#x27;d like to see some evidence.The alternative to trust is enforcement. The evidence you are looking for is the prevalence of the latter principle in systems that deal with things of value. reply late25 8 hours agorootparent>One example: accounting scandals in the US are rare. I don&#x27;t think anyone trusts accounting figures for public companies from India or china.I work in accounting. You’re right, I trust the US more than India or China, but you’d be surprised at the liberties US companies make and how many individuals from India are auditing their work. Auditors (excluding partners and some senior managers) are just not equipped to deal with the technical accounting concepts and to challenge management. Remember, the company employs the auditors. You certainly don’t want to ruin a $1MM contract for your firm but pressing too hard. reply envsubst 8 hours agorootparentI agree.> You certainly don’t want to ruin a $1MM contract for your firm but pressing too hard.Only in the west would you get any push back at all. The auditor would feel some duty to bring up an issue even if it reflected poorly on the company and even their own managers.I agree they likely wouldn&#x27;t push an issue beyond its welcome, but this particular value is unheard of in many parts of the world. reply aragonite 1 hour agorootparentprevCounterpoint: scihub, libgen links are routinely shared on HN as a matter of course (likewise in academia). I&#x27;ve seen HN threads in which people unapologetically reminisce about torrenting movies&#x2F;music.Perhaps your will object: \"But the publishers&#x2F;Disney&#x2F;etc are evil, greedy entities and I don&#x27;t owe them anything.\" But I&#x27;m sure anyone who&#x27;s stolen corporate secret elsewhere can come up with a similar justification in their head! After all, that may well be why they left the company in the first place. reply makeitdouble 8 hours agorootparentprev> This is one of the main reasons why companies pay a premium for workers in the west when they could hire from other places.By this token \"other places\" companies would also want to pay a premium to hire US workers outside of sheer competency. Yet we&#x27;re not seeing Samsung massively moving institutional operations to US centers for instance.> accounting scandalsWhait, what ? You&#x27;re telling me that while the crypto bubble is bursting and they&#x27;re going to prison for egregious fraud ?Also, scandals being few in number would probably be a sign of overcorruption and systematic rot or the controlling structure. I&#x27;m not sure that&#x27;s what we want. reply shard 7 hours agorootparent> Yet we&#x27;re not seeing Samsung massively moving institutional operations to US centers for instance.Culture matters a lot. Korea is a high context society, and relationship building is extremely important. Its very difficult to migrate functions to other locations when the way to get things done is through building trust and relationships over long periods of time. That said, Samsung does have significant offices all over the world. reply envsubst 8 hours agorootparentprev> hire US workers outside of sheer competencyIt&#x27;s not a competency it&#x27;s a network effect.> Yet we&#x27;re not seeing Samsung massively moving institutional operations to US centers for instance.Samsung probably has great trust developed among its senior management. reply ipython 10 hours agorootparentprevIf a low ranking employee in Cincinnati divulged corporate trade secrets, they&#x27;d be tried and convicted. If a low ranking employee in Shanghai did the same, what can the US company do? Not much. So it&#x27;s a low risk activity, that is also actively encouraged and in many cases financed by the Chinese government. This is in no way intended to be disparaging of folks who are of Chinese descent, but rather a reflection of the reality of contemporary Chinese government politics and policies. reply makeitdouble 9 hours agorootparentWould you get tried in the US for interning at a company and then go to a competitor with all your inside knowledge ? [edit: barring a paid non compete agreement]Then a step further from that, sure there are laws to prevent you from wholesale lifting corporate data and bringing them out as you leave, but as many laws it will be extremely difficult to detect and prove that happened in many low profile cases. That&#x27;s why instead of just relying on the law you&#x27;ll lock usb ports monitor network activity and get laptops returned when someone leaves.It&#x27;s kinda like preventing shop lifting, you know it will happen at some scale.> US company &#x2F; Chinese govHow much leverage do you thing a Chinese company has to if a three letter US agency spies on them and pass the info to US companies ? And would you argue that scenario wouldn&#x27;t happen if a specific Chinese company had a decisive advantage that could severly hurt US interests ? reply concordDance 1 hour agorootparentprevThe workers who make up the companies tend to have higher levels of honesty and fair dealing and lower levels of corruption and theft.Though I cannot provide evidence for this offhand beyond anecdote and the corruption perception index. reply anikan_vader 10 hours agorootparentprevLess so ethics and more so credible legal action against offending companies and individuals. reply pjmlp 1 hour agoparentprevNot only there, everywhere.Since I also wear a security hat, when doing code reviews, architecture and devops stuff, it is surprising how much stuff regular developers never think about in regards to security. reply pbj1968 6 hours agoparentprevAnd I was called a racist 25 years ago when I said, “like, our engineering school is, like, crawling with Chinese nationals.” We said like a lot on the 90s. reply robertlagrant 1 hour agorootparentIt&#x27;s probably the \"crawling with\" that did it. reply endisneigh 9 hours agoparentprevWell information wants to be free, copyright shouldn’t exist, piracy is ok yadda yadda reply glogla 1 hour agoparentprevMight sound like non-sequitur but this makes me not fan of RISC-V. Right now, most of the good CPU knowledge is owned and locked by the West. It is also locked down by corporations of course.I get the drive for something open, but are we helping Chinese regime by giving them free stuff they will then use against us? reply choppaface 2 hours agoparentprevGiven Uber&#x27;s efforts on Greyballing, booking fake Lyft rides, hiring Anthony Levandowski etc etc ... it&#x27;s very on-brand for them to (1) fall into an espionage war with Didi (wonder where all their Vertica data came from?) and (2) have an engineer write about using code he lifted from a prior gig and then also self-published.https:&#x2F;&#x2F;www.nytimes.com&#x2F;2017&#x2F;03&#x2F;03&#x2F;technology&#x2F;uber-greyball-...https:&#x2F;&#x2F;www.theverge.com&#x2F;2014&#x2F;8&#x2F;12&#x2F;5994077&#x2F;uber-cancellation... reply diogenes4 7 hours agoparentprev> People in the US just don&#x27;t understand the level of economic and industrial espionage that happens in China on a daily basis.Back in my day this was called \"competition\" and worked for the consumer, not against them. I find the espionage factor to be theatrical hogwash trotted out by the corporate types. We americans love competition, right? Stfu and compete. reply concordDance 1 hour agorootparentI&#x27;m a bit confused what that would look like. Sending Americans to China to steal their secrets wouldn&#x27;t work because the Chinese wouldn&#x27;t hire them for exactly this reason. reply rfrey 1 hour agorootparentprevWhen exactly was this \"day\" when industrial espionage was legal? reply fmbb 32 minutes agorootparentIn the US, before 1996.The economic power of the USA was arguably built on it. reply phendrenad2 7 hours agorootparentprevYou&#x27;re missing a huge part of this: The \"competition\" you think you&#x27;re referring to had, you know, actual rules. Sending people to get jobs at a rival, and steal all of their internal documents and trade secrets, is illegal in most countries. reply treyd 6 hours agorootparentPerhaps we should reframe how intellectual property works to make secrecy no longer desirable and allow industries that rely on \"trade secrets\" to realign naturally. reply ffhhttt 1 hour agorootparentPerhaps (well.. almost certainly) that would disincentivize any of the companies in these industry from innovating at all (if you can’t gain any edge by additional investment since anything you do will be stolen you might as well start stealing if that cheaper).This would also especially favor large mega corporations as long as they are efficient enough (due to obvious reasons). reply Proziam 7 hours agorootparentprevIs it \"competition\" when you&#x27;re up against state-sponsored actors who will use tactics the rest of the world would consider illegal? reply oh_sigh 7 hours agorootparentprevWhat it would do is punish companies that do real R&D, and reward companies that have no actual talent in that area. So ultimately the field would stagnate because no one would invest in R&D. reply erulabs 13 hours agoprevI read this article looking forward to the complex bespoke code to be ripped out and deleted - but the author clearly grew as an engineer in a way I didn’t expect:> Sometimes that’s just how it is. The devops saying “Cattle, not pets” is apt here: code (and by proxy, the products built with that code) is cattle. It does a job for you, and when that job is no longer useful, the code is ready to be retired. If you treat the code like a pet for sentimental reasons, you’re working in direct opposition to the interests of the business.A lot of code is fun to write. A lot of problems are fun to solve. But a business, especially a startup, needs to stay razor focused. My entire career is effectively to sit in meetings and tell young, passionate engineers not to build things. It’s a bit depressing, but it’s also vital.A good engineer can solve any problem with clever code. A great engineer knows what problems aren’t really problems and probably an XLS download link updated daily would have been fine. reply fader 11 hours agoparent> My entire career is effectively to sit in meetings and tell young, passionate engineers not to build things. It’s a bit depressing, but it’s also vital.This was the single most impactful thing I learned in my early career. I was building out monitoring systems for an in-house service we hosted on site. My boss wanted to buy some small utility to keep tabs on some minor aspect of our environment. I was a bit offended -- I could have written that myself and here he was paying someone else to do it!He asked: \"How long would it take you to write and test this?\" Me: \"Probably a week. Maybe a bit less, maybe a bit more if I run into something tricky.\" Him: \"Okay. This tool will cost us $500 to buy. What&#x27;s your hourly pay rate for 40 hours?\"With this I achieved enlightenment. I&#x27;ve never again built something at work that I could buy cheaper. reply fiddlerwoaroof 10 hours agorootparent> This tool will cost us $500 to buy. What&#x27;s your hourly pay rate for 40 hoursThis argument makes sense, but I worry that it’s a bit short-sighted. There are a lot of metrics that are hard to quantify where it might end up better: for one thing, I’ve found that integration costs and maintenance of integration of third-party systems are routinely underestimated: I’ve implemented “buy” for various systems where the work to integrate was essentially the work to build. The cost of learning a proprietary toolset rather than developing experience with open tools. The cost to the industry as a whole when something like AWS or React becomes the unreflective default choice. reply jacurtis 10 hours agorootparentIts extremely short sighted. The cost is much more than (hourly wage x code hours).There is ongoing maintenance cost that no one considers. I&#x27;ve never seen a project that gets built and just sails off for eternity with no maintenance or bugs. There will be times when the libraries or frameworks that built the underlying tool need upgrading. The requirements of the job might change even slightly and need a change in the code because custom tools are always built to only solve the narrow problem.There is also the overhead of the fact that this junior developer will inevitably leave in 6 months and now someone who has never seen this project before has to pick it up to fix it, which means it will take even longer.Plus that ignores the fact that if a developer tells you it will take 40 hours it will actually take 80-120 hours.When you buy, the tools you buy are designed to be integrated with. They have support teams that will help you, and ongoing maintenance. Plus the tool is going to be more robust because it was built and used by many different companies with slightly different requirements. Plus someone else&#x27;s developers will keep it up to date for you so you don&#x27;t have to.Internal tools are almost never worth it unless a pre-existing tool literally doesn&#x27;t exist which happens when you are either solving insanely complex problems or insanely niche problems. reply delusional 2 hours agorootparent> When you buy, the tools you buy are designed to be integrated with[...]This makes me question if you&#x27;re speaking theoretical, or actually have any practical experience.I&#x27;ve been part of about a dozen \"buy it\" projects now, and so rarely they&#x27;ve been \"designed to be integrated with. A lot of the time it&#x27;s deeply legacy systems that have a half-hearted api slapped on top to check that box, but once you start using it you notice that everything you want to do somehow requires contacting the vendor first.Which dovetails into an issue that, although vendors will give you the impression that their system is well tested and widely deployed, it all too often ends up being a lie. We&#x27;ve had quite a few instances where vendors have sold us what turned out to be something they were still building. reply fiddlerwoaroof 9 hours agorootparentprev> the tools you buy are designed to be integrated with.Until they change on a whim and force you to spend hours rebuilding your integration for negligible benefits. And then there’s the good old “change our vendors every five minutes because the last one wasn’t quite right” reply rcxdude 3 hours agorootparentprevIt all sounds great in theory but it still happens that buy turns out to be a total waste if time and money. reply moonchrome 5 hours agorootparentprev> I’ve implemented “buy” for various systems where the work to integrate was essentially the work to buildI&#x27;ve felt this way before, but I didn&#x27;t realize that I haven&#x27;t factored in the risks of actually building it. I was comparing real world integration effort with an estimate, influenced by my experience of integrating with a working product.Common sense applies, but in general I&#x27;m terrible at giving estimates unless I&#x27;ve done something very similar before. reply trickstra 3 hours agorootparentprevI&#x27;m surprised nobody here mentioned the copyrights yet. By building it, you are gaining the copyright. By buying it, you are gaining a vendor lock-in. reply hnlmorg 1 hour agorootparentIf your company isn’t making money from the product then whoever owns the copyright is irrelevant.Good engineering is building the stuff that adds commercial value to the business and buying the stuff that only adds support to the stuff that adds commercial value.In this instance, monitoring falls into the latter category. It’s not a business differentiator. reply dasil003 10 hours agorootparentprevSure it’s shortsighted, but we’re all shortsighted, that’s the human condition. We can’t know all ends, which is why experience and judgement matter. The worst thing you could do is handwring over it though. Gather whatever data you can quickly leveraging the extent of your current expertise, make a call, implement and learn. reply TAForObvReasons 10 hours agorootparentprevIs it any more shortsighted than using the \"open tools\" in the first place? There will be integration costs and maintenance of integration with open tools. You may not be able to pay anyone for support issues because those people may not provide the sort of customer support you expect when you pay someone. reply AnthonyMouse 8 hours agorootparentThe integration costs were part of the 40 hours. The trouble is you haven&#x27;t avoided them by paying the money.Open tools also tend to have a longer life, because a community survives even as members come and go, but one boss decides that a product isn&#x27;t sufficiently profitable or the company gets bought out by a competitor and now it&#x27;s discontinued and you have to start over. reply fiddlerwoaroof 8 hours agorootparentAnd the open tools often end up with more transferable skills down the road: e.g. learning to deploy to AWS only helps with AWS; learning to deploy to k8s lets you be productive in a lot more situations. replysublinear 12 hours agoparentprev> (from the article) - Having Excel in the browser was a useful solution, but the problem wasn’t showing spreadsheets in the browser: the problem was getting a specific UI delivered to the right users quickly.> (from the above comment) - A good engineer can solve any problem with clever code. A great engineer knows what problems aren’t really problems and probably an XLS download link updated daily would have been fine.I saw the bullet list further down the substack page and it&#x27;s still not good enough for this level of requirements gathering. Those questions describe the scenario, but asking them would not have arrived at this simple solution. Checklist thinking is a crutch and just overcomplicates the problem. All the signals here were organizational and social, and not a matter of improving a process.This should be obvious, but people who are not involved with implementation details can&#x27;t answer questions about implementation details.\"Just make it like Excel\" is a super low quality answer from someone who has a completely different set of objectives. The only way forward would have been to consult with someone closer to the actual users and counter-argue from there. What&#x27;s missing here is the courage to recognize weak assumptions and deliberately avoid writing any code until enough details are pinned down to get to an agreement from all parties, not just say yes to the person \"in charge\". reply bastawhiz 11 hours agorootparent> \"Just make it like Excel\" is a super low quality answer from someone who has a completely different set of objectives. The only way forward would have been to consult with someone closer to the actual users and counter-argue from there.The only contact we had with \"actual users\" was over WeChat because they were on the other side of the planet.> What&#x27;s missing here is the courage to recognize weak assumptions and deliberately avoid writing any code until enough details are pinned down to get to an agreement from all parties, not just say yes to the person \"in charge\".Uber was pathologically bad in this sense. There was no time to get details pinned down. We had a product to ship in two weeks for non-technical stakeholders. If we didn&#x27;t, the stated consequence was millions of dollars in losses to the business. Throwing up your hands until you get product clarity when you know you can solve the problem as-is is a great way to find yourself with a PIP. reply user_named 9 hours agorootparentNah, that&#x27;s why you have product managers. I would have talked to this stakeholder for an hour and realized the solution is not to build another excel. reply cornel_io 8 hours agorootparentYou&#x27;re routinely successful at arguing down C-level execs who have already rejected your pushback multiple times?Seems like a risky strategy... reply user_named 6 hours agorootparentYou don&#x27;t reject it you understand what the problem is and design the solution and explain it to them. I&#x27;m sure this entire team didn&#x27;t need to exist in the first place but that&#x27;s what you get when you only have a business person and the Dev team they hire.A PM here would have saved the company what, $5m per year? reply Aeolun 9 hours agorootparentprevExcept in this case you’d wait a few weeks and have the whole problem be OBE. reply Retric 12 hours agoparentprevExactly, in 2016 there was several off the shelf options for doing the exact same thing. It’s a perfect example of a young engineer feeling a huge accomplishment from reinventing the wheel, and then realizing the clever solution wasn’t actually worth anything like the effort required to create it.I had a long conversation to convince someone not to go down that path in 2006, and I am sure someone’s going to do it in 2026.Pausing to think: I wonder how someone else solved this exact problem is such a huge part of how you grow as a developer I wish schools would focus more on it. reply yard2010 11 hours agorootparentI would say what you talk about is experience. To have an experience, you must go this path to realize what to not do. It feels like a catch 22 kind of thing. reply Retric 11 hours agorootparentDoing it well comes down to experience, but doing it at all comes down to asking which of your unconscious assumptions are hard requirements. Nobody is actually saying you have skills X, Y, Z, which you must use to solve this problem, which is a huge difference from how schools prepare people for the workforce. reply BlueTemplar 6 hours agorootparentprevExperience certainly helps, but last time I checked, schools are supposed to teach you how to use reference tools (reference manuals, company listings, search engines...), and how to use them well - a pretty fundamental skill of being an engineer ? reply OJFord 10 hours agoparentprevI&#x27;m not really sure what you&#x27;re saying, or what the criticism is, if it is one - but shortly before the bit you quoted OP links the code on GitHub: https:&#x2F;&#x2F;github.com&#x2F;WebSheets;And you can&#x27;t really conclude they made a poor implementation choice on a report of completing it successfully (albeit too successfully even, too much of Excel implemented, and then fixed by removing that (how do you do that to your XLS download link?)) on time within a short deadline.The takeaway is supposed to be &#x27;don&#x27;t get too attached to your code&#x27;, which in some circumstances (not this one) might mean &#x27;don&#x27;t succumb to NIH syndrome, use an XLS download link&#x27;, but that&#x27;s not the whole. reply emmo 12 hours agoparentprevGive the time and labour you&#x27;re paid for, don&#x27;t give emotional energy. reply stocknoob 12 hours agorootparentShort term yes, but long term, life&#x27;s too short. Pursue FI, especially if you&#x27;re a craftsman, so you can work on what brings you joy, without an expiration date.\"Cattle, not pets\" may be a good way to run a business, but not your life. reply emmo 12 hours agorootparentOh on your own projects and personal passions absolutely, I think emotional investment should be high. Not for someone else, though. reply fruit2020 4 hours agoparentprevA great engineer should be both good and great. I do a lot of ‘great’ stuff at work, but that won’t help me to get into my next gig unless I also code a lot and don’t lose my skill. reply teaearlgraycold 9 hours agoparentprevAny time I identify a fun and novel problem I get suspicious. Generally, programming should be mundane and you should be solving problems that have been solved thousands of times before. If something looks new it&#x27;s more likely you haven&#x27;t correctly identified the problem you&#x27;re solving. reply Znafon 13 hours agoprev\"Nothing came of it, but I took the code and shoved it into my back pocket for a rainy day.My idea was to take this code and spruce it up for Uber’s use case.\"\"My first reaction was to publish the code on Github.\"I’m very surprised by this, isn’t the code property of Box, or Uber? The author does not mention their authorisation before releasing it under MIT license. reply bastawhiz 13 hours agoparentAuthor here. The code was originally written outside of work hours. I offered the code to Box and they didn&#x27;t want it.If Uber wants a few thousand lines of JavaScript from over half a decade ago that didn&#x27;t originate with them and that they used for less than a month, they can send me a letter. reply tempaway85751 13 hours agorootparent... Nothing came of it, but I took the code and shoved it into my back pocket for a rainy day ...You can&#x27;t really do this. Depends on your employment contract but code you write for an employer is usually copyright to them... My first reaction was to publish the code on Github ...You can&#x27;t really do that either. reply bastawhiz 12 hours agorootparentI mean, I asked at the time, and I did it. If either company wants to start a legal fight over a pile of code that neither of them wanted that&#x27;s old enough to be in elementary school, they know how to reach me. reply wodenokoto 5 hours agorootparentI’d recommend you update the article on those two points, because because as it is now, the article makes it sound like you stole code from both Box and Uber. reply tempaway85751 12 hours agorootparentprevFair enough. But I&#x27;ll leave my comment there as general advice for other readersenjoyed the article, the bit about Excel circular ref linear regression was wild reply lowbloodsugar 10 hours agorootparentprevThe problem is that you are claiming ownership of this code and by making it available on GitHub under an MIT license you are claiming that you have the right to do so.If I take that code and make a billion dollar business out of it, Box or Uber could then claim a share of it. That&#x27;s the kind of things that companies do with the lawyers on retainer.I then sue you for falsely claiming that you own it. You are particularly fucked because, thanks to this thread, you can&#x27;t claim that you didn&#x27;t know.Even in California the \"I wrote it on my own time\" doesn&#x27;t apply to software that relates to an employer&#x27;s core business. In other places, like Washington State, you could be employed to write TPS reports and write a video game at home, and your employer would own that too.IANAL but I have paid for advice on this very topic. I suggest you pay one too. reply burner420042 9 hours agorootparentLong time ago my employer at the time had this in-house deployment system written by a guy that worked there. It worked well and we used it well after he had moved on. He left suddenly and started a company based on the idea. Employer went to sue him and discovered the ‘all your code belongs to us’ form was missing from his permanent file so they didn’t pursue it. That company is called Chef. reply geoelectric 8 hours agorootparentprevA spreadsheet UI didn’t relate to Box’s core business because Box didn’t sell spreadsheet UIs. Box could have had the author’s hobby project been adopted as a feature but explicitly chose not to. The author clearly owned that bit if they did it on their own resources and own time.In other words, you can write generally useful components and utilities on your own time, network, and equipment; license them to your employer if everyone agrees; and either way you still own them. You just can’t write something directly related to or competitive with the products or processes that make your employer money.The spreadsheet formulae and enhancements the author wrote during work hours at Uber, though, no. But even just their direct boss as an agent of their employer saying it’s ok to throw it on GitHub would probably cut them loose, especially since it’d be a derivative work with joint ownership.All IMO of course, but that’s how I would have seen it in their shoes. reply adastra22 8 hours agorootparentWell, you are not a lawyer. OP specifically wrote the code to help Box with its business. That&#x27;s cut and dry within the scope of an employment contract, under California law. This doesn&#x27;t get a safe harbor exception. reply Dylan16807 6 hours agorootparent> OP specifically wrote the code to help Box with its business.That was the intent, but not what actually happened.Is intent to donate code enough to put it within your employment contract, when it&#x27;s done outside work hours and would otherwise be outside the scope of employment? reply dragonwriter 5 hours agorootparent> That was the intent, but not what actually happened.The intent is a fact of what actually happened: which appears to be that it was written by an employee within the scope of employment to solve a business problem. Possibly outside of usual working hours, but if it’s by a salaried employee where doing work at home outside of usual working hours is itself a normal if not consistent part of employment, is probably not particularly significant.That the employer later chose not to make use of it doesn’t change the circumstances of its creation; businesses often choose to not pursue use of exploratory work done by employees in the course of employment, that doesn’t surrender ownership of the work product.And the version that was further developed within and in response to Uber business needs and actively used at Uber before the function for which it was used was terminated is an even clearer case (insofar as it is a distinct work from the original) of work-product (that it quite likely is also an unlicensed derivative work by Uber of proprietary Box code doesn’t mitigate that, though it puts Uber in the position of potentially being both a beneficiary and victim of IP violations.) reply Dylan16807 5 hours agorootparent> which appears to be that it was written by an employee within the scope of employment to solve a business problem.An imagined business problem.If the code wasn&#x27;t relevant to their actual business practices, that&#x27;s quite relevant. They not only didn&#x27;t want that code, they didn&#x27;t want anything like it.As for the modifications for Uber, that&#x27;s not what I&#x27;m here to contest. reply adastra22 4 hours agorootparentNo, it’s not relevant. Seriously, go consult a lawyer in this. I have. They’re very consistent on this point because there are tons of case law regarding it.There are a massive number of examples of patent and copyright litigation stemming from work done for one employer, who rejected it, then the employee goes off and founds their own company and gets successfully sued.Fairchild was unique in that they had claim to the IP that their employees wanted to use in new startups, yet they decided not to follow through and allowed the employees to start their own companies. They could’ve prosecuted but didn’t, and as a result we got Silicon Valley and the culture that surrounds it.But it’s no guarantee that that your employer won’t pursue a copyright claim they are perfectly within their rights to do. Don’t assume your employer is Fairchild. reply lowbloodsugar 6 hours agorootparentprevYou misunderstand. When he wrote the code, which was related to the company&#x27;s business, the company owned it. Even in California. He couldn&#x27;t have \"intent to donate the code\" because he didn&#x27;t own it in the first place. The fact that he \"intended to donate it\" demonstrates that it was related to the company&#x27;s business.From a practical perspective, even if you think they don&#x27;t own it, do you have the money to argue that in court if they decide that they do?IANAL. If you are having issues like this, get legal advice from a lawyer. Not HN. reply Dylan16807 6 hours agorootparent> which was related to the company&#x27;s businessRelatedness is relative but I&#x27;d argue against it here. They didn&#x27;t have functionality like that, and they didn&#x27;t want it.> The fact that he \"intended to donate it\" demonstrates that it was related to the company&#x27;s business....yes, that&#x27;s my point. We&#x27;re using that intent to make the decision that it&#x27;s covered. That doesn&#x27;t seem like a good way to decide whether it&#x27;s covered.If he just made a web spreadsheet and did nothing else, people would shrug. replyAeolun 9 hours agorootparentprevExcel does not relate to Ubers’ core business.I’m nearly 100% certain we can look back at this comment in 20 years and find that absolutely nothing happened. reply acjohnson55 6 hours agorootparentLiterally today I was in a fireside chat where the speaker told us the IP law department at a previous employer brought in a couple billions in revenue by suing for infringement. reply Aeolun 2 hours agorootparentSure, but they weren’t sueing a rock.Getting a judgement against an individual is vanishingly unlikely to result in any profits. reply lowbloodsugar 9 hours agorootparentprevThe author explains how analyzing and presenting data was worth millions of dollars. The author documents how a senior executive instructed him to write excel. It is clearly their core business. Also, and this comes back to the fantasy&#x2F;denial&#x2F;wishful-thinking aspect here, neither I nor the law says core business. That&#x27;s a word that you added. If you did it as part of your job, then it is, by definition, part of their business.I am also nearly 100% certain we can look back at this comment in 20 years and find nothing happened, but only because nobody will take this code and make a billion dollar business. If they did, I guarantee there would be a law suit. reply ncallaway 8 hours agorootparent> neither I nor the law says core businessThat’s just factually false. You specifically wrote:> Even in California the \"I wrote it on my own time\" doesn&#x27;t apply to software that relates to an employer&#x27;s ***core*** business.You can’t complain about people being “wishful” or in “denial” when they are quoting you.Maybe California law is silent in the topic, but Aeolus wasn’t the person who introduced that specific phrase. reply lowbloodsugar 6 hours agorootparentOh that’s embarrassing. I did. Apologies. I was wrong to write “core” and wrong to complain when you did it. reply ncallaway 5 hours agorootparentEh, it happens. No worries reply user_named 9 hours agorootparentprevExcel is not their före business. That executive knows nothing. This is an example why you need product managers and engineers don&#x27;t talk to users. reply yeahwhatever10 4 hours agorootparentprevCan you source the claim about Washington State? reply grepfru_it 9 hours agorootparentprevBig facts reply migf 12 hours agorootparentprevI was also absolutely gob smacked at this. Will they care? Probably not. Are you putting yourself at the absolute mercy of them deciding not to care? Absolutely.I would have a hard time sleeping... like this would be like being in IT and knowing the backups were bullshit. reply sebzim4500 12 hours agorootparentIs this a thing in the US? Here, if the code was written of your own volition outside of work hours then it&#x27;s yours. reply dragonwriter 12 hours agorootparent“Work hours” are less clear for salaried workers who may or may not take work home: if it was written to solve a problem for the employer, reviewed with other workers at work, but ultimately not further pursued the status seems murky.The later derivative that was actively used by and updated for the requirements of another employer during the coarse of work seems to more clearly their property as a derivative (but also murky because it is potentially an illegal derivative of the earlier work, if that was owned by the earlier employer.) reply adastra22 7 hours agorootparentprevThat&#x27;s not what happened here though. For salaried workers everything you do that is related to your job is owned by your job. That&#x27;s the default even if your contract doesn&#x27;t state it. He may not have been directed by his boss to make the code for Box, but he did it with the intent of helping Box&#x27;s business, as a salaried worker. That makes it Box&#x27;s property.But even if you are unconvinced of that, work was clearly done on it on company time at Uber, where it was deployed as part of Uber China&#x27;s business infrastructure. That work is absolutely owned by Uber (with maybe also some claim by Box). Not owned by OP. reply migf 12 hours agorootparentprevIt depends on your employment agreement or contract. Most contracts I have seen say that any IP you develop related to what you&#x27;re doing at work is the employers. reply adastra22 7 hours agorootparentIt only depends on your employment agreement in the other direction. Work done for hire is by default owned by your employer under federal law. For salaried employees it doesn&#x27;t matter if it is done during working hours.The employment agreement can give up this right for things not related to the company&#x27;s core business, and I usually insist on that in my agreements. But that is not the default behavior. reply Dylan16807 6 hours agorootparentSurely someone has to ask for it before it&#x27;s work done \"for hire\". reply adastra22 4 hours agorootparentI usually insist that personal and open source work done outside of the product areas I work on are not company owned. Otherwise if I work on financial software at a bank, and then at home I work on defi&#x2F;blockchain based financial stuff, I could be setting up a liability for me or my users. reply santoshalper 11 hours agorootparentprevThat story just doesn&#x27;t seem plausible. Maybe for Box, but it feels like a stretch, and definitely not for Uber. reply mkii 9 hours agorootparentprevThe real liability is sharing publicly that you did this. But hey, people have done far worse for attention and fake internet points, right? reply zarzavat 7 hours agorootparentprevIt’s pointless to worry about being sued by a large corporation. If they want to bankrupt you, they always can, regardless of whether you did anything wrong or not.We are like ants to them, they can squash us at any time, but most of the time we are too small to worry about. reply xpe 6 hours agorootparent> If they want to bankrupt you, they always can, regardless of whether you did anything wrong or not.Misses the point, which is: the likelihood of being sued increases when you break contracts or appear to do so reply thebradbain 12 hours agorootparentprevCool -- if one of the companies wants to issue a takedown request, they&#x27;re free to make the case for it.It&#x27;s funny there&#x27;s this idea that a company _might_ be potentially injured over code they do not want or know they had being made open source by its actual author, even though many of those companies will gladly use open-source tooling without ever contributing anything back.Perhaps more soundly, though, in California – where Uber is headquartered – IP&#x2F;Copyright for code is a huge legal question that the state and federal Supreme Court has no clear answer to. Sure, you obviously can&#x27;t secretly clone Uber&#x27;s entire stack, slap a new company logo on it, and start up as a competitor. But if you, as an author, wrote some code for a company under an IP agreement, then no-longer worked at said company, and then later adapted and expanded upon that code (or even started over, with the knowledge of what you learned from others&#x27; work): are you, at the originator, not legally allowed to be inspired by your past work? That&#x27;s not something you, me, or even the company could decide. reply andrewxdiamond 12 hours agorootparentThere are gray areas but I do not think you are in one.> and then later adapted and expanded upon that code (or even started over, with the knowledge of what you learned from others&#x27; work)These are extremely different scenarios. Starting with a copyrighted material and modifying it is not at all the same as reading material and starting over. The first is violating copyright, the second is a derivative work.If I read everything correctly, what you describe doing is taking code owned by the first company and modifying it for the second company. That’s not at all a gray area. It’s a copyright violation. You the engineer sign away your rights to the code when you built it for company 1 while employed by them. Their employment contract for-sure states they own any work produced by you during your employment, and you agreed to this.If the first project was done off of company time, posted publicly on a private account, you might have a claim to the rights.I know you’ve dug your trench too deeply to change your mind at this point, but anyone reading your comments should know what you did was technically illegal and can get people in legal hot water. reply thebradbain 12 hours agorootparentI wrote the comment above, though I&#x27;m not the author of the code that you appear to think I am. But I am in agreement with him.> Their employment contract for-sure states they own any work produced by you during your employment, and you agreed to this.There are many open legal questions as to where this line is drawn. Surely the line falls somewhere between \"every character I&#x27;ve ever typed on a keyboard\" and \"the verbatim code\". I personally don&#x27;t think he&#x27;s crossed it. IP ownership is much more complex than portrayed in HBO&#x27;s Silicon Valley. That is my opinion.Furthermore, when I worked at GitHub (now acquired by Microsoft, so I&#x27;m sure things have changed drastically) -- there were very lax IP ownership agreements in the employment contracts around code ownership, because the legal department was worried that if found in any way conflicting with California law it would render the entire IP claims null and void (which does have precedent in California).The point is we don&#x27;t know, and I think OP would know better than us if it was disallowed or not. reply fragmede 1 hour agorootparent> IP ownership is much more complex than portrayed in HBO&#x27;s Silicon Valley.IANAL; ut&#x27;s not quite that simple, but it&#x27;s in the right general direction. If you need specific advice, talk to an actual lawyer tho. reply ryandrake 11 hours agorootparentprevLike many things in this area, the answer is usually \"You&#x27;ll find out if you want to go up against an army of lawyers\". The last three companies I worked for all claimed ownership of any IP I create, on or off the job, using company&#x27;s equipment or using my own equipment. One of them explicitly called it out during the interview: You will have to stop working on open source or publishing side projects when working here. Can they do that? Maybe, probably not. It doesn&#x27;t matter because I do not plan to bankrupt myself fighting their lawyers. reply thebradbain 8 hours agorootparentRegardless of the fact that California is much, much more strict in what they allow, to the point where oftentimes a company’s lawyers won’t even try:Fine. Don’t fight, I agree, that would be an unfair fight and a waste of time&#x2F;money.The US court system requires a “good faith” effort to settle the issue before it enters the legal system. A cease and desist for example— whatever it is, you’d have plenty of time to simply decide it’s not worth it and remove the code once they take notice.As it is, this is all no harm, no foul. reply lowbloodsugar 10 hours agorootparentprevIANAL: In California they cannot, unless it is related to the employer&#x27;s business (so if the employer is Apple, Google or AWS, they probably can). In most states they can. reply lowbloodsugar 10 hours agorootparentprevIANAL but I understand the distinction is:1. I copied this to disk, and I&#x27;ve iterated on it. Derivative work. Company owns it.2. I created a new original work from scratch, based on my experiencing doing it once or twice before. Independent work. Author owns it. reply kqr 2 hours agorootparentprevI agree this seems fairly clearly illegal.That said, I think OP is morally in the right here, and I wish I had the guts to do similar things.Sharing code is a good thing. Helping one company innovate using code that another company chose to ignore is also a good thing. reply egwor 1 hour agorootparentI&#x27;m not sure how we weigh up the morals here. If you&#x27;ve done something using a companies resources (laptop, desk, chair etc.) and they&#x27;re paying you and the contract says they own it I don&#x27;t see how you can have a moral high ground. Maybe there should be some way to allow these ownership concepts to expire so that society benefits overall but right now we don&#x27;t have that. reply Aeolun 9 hours agorootparentprevDifferent person, but when I asked if I could publish code as open source (where appropriate), I was told that that’s fine, as long as I don’t associate it with the company in any way (e.g. non-company specific stuff is ok). reply sushiburps 10 hours agorootparentprevWell, he just... did reply xwdv 12 hours agorootparentprevIt’s trivial to tell ChatGPT to rewrite the code base so it not longer resembles the original and then publish as a new thing. So yea, you can. reply xpe 6 hours agorootparentTrivial to ask for a ChatGPT rewrite. Not trivial to make sure it works. reply HPsquared 10 hours agorootparentprevDerived work reply continuitylimit 13 hours agorootparentprevSo come on man, let’s be honest here. I got serious sacred masterpiece vibes from this story.This reminds me of some Hindu parable about people who let go of possessions and head out to become ascetics. So there is this wealthy man and wife and the wife is all upset because her brother keeps insinuating that he’s gonna go ascetic and cut loose. The husband tells her to stop her crying and don’t worry about it, he ain’t going to do it. The wife asks him: ‘but how can you be so sure?’ Because, the husband says, this is how you do it, and then and there he rips open his shirt, tells her “you’re my mother” and heads out to the woods. reply cowthulhu 10 hours agorootparentI want to know what GPT model was used to generate this comment so I can make sure to avoid it reply cpursley 9 hours agorootparentYou won an internet, needed the laugh - thanks. reply bastawhiz 12 hours agorootparentprevI just like telling fun stories from a long time ago reply hitekker 11 hours agorootparentprevI might be dumb today but I think this parable is incomprehensible. Do you have a link to another version? reply deodar 11 hours agorootparentIt&#x27;s almost as incomprehensible as a Zen koan. I think the husband is showing the difference between talking and doing by, well, doing it. A radical way to demonstrate it. reply mock-possum 10 hours agorootparentprevWhat an utterly bizarre story. What’s the point of it? Why is the wife upset about her brother? Why is the husband so sure the brother won’t do it? What’s the significance of his little performance at the end? Why is the wife the husband’s mother, what does that have to do with anything, considering the issue is with the wife’s brother? Why don’t we get to see what the wife’s reaction to the husband’s stunt is - is she convinced by his actions, or is she as baffled as i am?Did I just fall for a chat gpt generated nonsense fable?What is going on here! reply julianeon 10 hours agorootparentIt&#x27;s a simple twist ending. The twist is that the wife was worried her brother would become an ascetic - but the person she should have worried about, the person who was planning to and did become an ascetic, was her husband. The performance is his declaration of asceticism, and the \"you&#x27;re my mother\" line is a stock part of it, essentially meaning I renounce sexual attraction when said to your (former) partner. reply deodar 10 hours agorootparentprevI put one (possibly wrong) interpretation in an earlier comment.As for the mother part, in many Hindu traditions monks and voluntary celibates are encouraged to see all women the same as their mothers, to remove temptation. Now he&#x27;s an ascetic ergo his ex-wife is like a mother to him.The cryptic yet amusing tone is much like a Zen koan, not a Hindu parable. reply plagiarist 10 hours agorootparentprevI think the wife is upset because \"going ascetic\" means cutting off contact. The husband is sure he won&#x27;t do it because the brother is talking about it instead of doing it, which he demonstrates.It feels like there should be more to the lesson learned than, \"people who have decided will act, people who haven&#x27;t only talk,\" but I am not quite grasping it. Maybe the other part is, \"and worrying about things you cannot change harms yourself,\" or something? reply slim 3 hours agorootparentprevI just want to say I am sorry you have to cope with people trying to convince you you are not free for no reason reply brtkdotse 12 hours agorootparentprev> they can send me a letter.Why am I reminded of this meme?https:&#x2F;&#x2F;amp.knowyourmeme.com&#x2F;memes&#x2F;what-are-you-gonna-do-sta... reply dclowd9901 7 hours agorootparentprevThat’s really not how it works. Ostensibly by showing it to box, it was written for box, and they would be well within a standard of legal standing to make your life a living hell for taking it elsewhere. You should really be more careful with what you say.Why would you wontonly open yourself to legal liability? You say “they’re free to come after you” but you really _really_ don’t want that. Ive seen that happen to friends and the stress almost killed them. reply treesknees 7 hours agorootparentprev“half a decade” is practically yesterday in most codebases. reply sidewndr46 13 hours agoparentprevI believe this kind of story is the kind that gives most legal counsel nightmares. reply pc86 12 hours agorootparentEspecially the brazenness with which the author basically says \"if they want to sue me for this verified and admitted IP theft, they can.\"Sure, they probably won&#x27;t. But they might. And if they do, you&#x27;ll lose immediately. Seems like a pretty high risk no reward scenario. reply concordDance 56 minutes agorootparentNot all rewards are monetary, in this case the reward is thinking his tool might be used by others at some point. reply sokoloff 12 hours agorootparentprevAnd if you lose immediately, you likely owe damages. Those damages, even if trebled, appear to be $0 here. reply akozak 12 hours agorootparentPretty sure that&#x27;s not how copyright damages work. Don&#x27;t take legal advice on HN folks. reply concordDance 56 minutes agorootparentWhat makes you think that&#x27;s not how it works? reply pc86 12 hours agorootparentprevWhich would be a great solace to someone who just spent $10k or more like 2-3x that responding to a lawsuit. But that&#x27;s also why I agree the odds of actually getting sued are near-zero. reply Alupis 12 hours agorootparentSome companies, armed with floors of attorneys and retained outside counsel, do that sort of thing just for the message alone. It costs them next to nothing, relatively, ruins the defendant regardless of outcome, and makes it clear for others to not mess around with IP. reply Aeolun 9 hours agorootparentprevWhy would you spend any money on a suit you intend to lose? reply IshKebab 3 hours agorootparentBecause you intend to lose it with 0 damages. reply kopecs 7 hours agorootparentprevExcept there are statutory damages for copyright infringement. reply m00x 11 hours agorootparentprevI&#x27;m sure they could find damages amounting to a large enough amount that OP would regret. reply michael1999 13 hours agoparentprevUber and the people they hired never struck me as particularly concerned by things like \"laws\" and \"property\". reply pavlov 12 hours agorootparentOh, you’re missing a few qualifiers. They’re not concerned with laws applied to them, and other people’s property. But in all other cases they’re big believers in law and using it to protect their property. reply PNWChris 10 hours agorootparentprevThe Levandowski lawsuit comes to mind https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anthony_Levandowski#Civil_laws...---Edit:Since I enjoyed OP&#x27;s story, I thought I should clarify a bit.I&#x27;m speaking broadly of how I remember (from the outside) Uber&#x27;s fast-and-loose IP attitudes in the 2010s.I don&#x27;t think OP did anything of a similar sort. From comments here it sounds like they used some code they built in their free time that a previous employer didn&#x27;t want.At Uber it sounds like they asked and were permitted to post their no-longer-needed code to GitHub. It&#x27;s got its own GH org and everything.This whole chain is legally risky (I wouldn&#x27;t do it and would strongly advise others not to do it).I feel OPs actions are not Ethically Wrong, though. I wouldn&#x27;t enjoy living in a world where OP gets sued for this, since it sounds like nobody at work wanted the work and it&#x27;s not giving competitors an advantage. I won&#x27;t claim the world isn&#x27;t like that, though.I really wish I could share OP&#x27;s attitude and sense of ownership. I built something really cool (entirely in my free time) for a previous employer&#x27;s hackathon. That code lives on some server they own now, possibly deleted. I deleted my copy after submitting it to the hackathon because I didn&#x27;t want to risk anything. Company lawyers make just building things for fun feel so risky! It takes the soul out of our work. reply 140 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author developed an automated data science model tool named R-Crusher for a project at Uber China, known as Crystal Ball.",
      "Despite the success, the project was discontinued after Uber China's sale, igniting reflections on the transient nature of code and the importance of providing business value.",
      "The author shares encouraging feedback from the software engineering community and offers links to previous pieces for further reading."
    ],
    "commentSummary": [
      "The discussion is centered around issues of economic and industrial espionage, code ownership, usage rights, intellectual property theft, and the implications of building vs buying software tools.",
      "Varied perspectives are debated, with some focusing on ethical and legal implications of code ownership, while others argue for code sharing and criticize perceived Western hypocrisy.",
      "There's an emphasis on understanding employment agreements and seeking legal advice, indicative of the complex and often confusing nature of code ownership and intellectual property in the tech sphere."
    ],
    "points": 538,
    "commentCount": 396,
    "retryCount": 0,
    "time": 1694804509
  },
  {
    "id": 37522858,
    "title": "Carrefour puts ‘shrinkflation’ price warnings on food to shame brands",
    "originLink": "https://www.theguardian.com/business/2023/sep/14/carrefour-puts-shrinkflation-price-warnings-on-food-to-shame-brands",
    "originBody": "Skip to main content Skip to navigation Skip to navigation Print subscriptions Sign in Search jobs Search US edition The Guardian - Back to home The Guardian Support the Guardian Fund independent journalism with $5 per month Support us News Opinion Sport Culture Lifestyle Show More World Europe US Americas Asia Australia Middle East Africa Inequality Global development A sign in a French Carrefour store reads: ‘Shrinkflation. This product has seen its litreage decrease and the price charged by our supplier increase.’ Photograph: Sarah Meyssonnier/Reuters Supermarkets Carrefour puts ‘shrinkflation’ price warnings on food to shame brands French supermarket chain labels products that have shrunk in size but cost more before contract talks with suppliers Tell us your experiences of ‘skimpflation’ and ‘shrinkflation’ Reuters Thu 14 Sep 2023 12.09 EDT The French supermarket chain Carrefour has put labels on its shelves this week warning shoppers of “shrinkflation”, the phenomenon where manufacturers reduce pack sizes rather than increase prices. It has slapped price warnings on products from Lindt chocolates to Lipton iced tea to pressure top consumer goods suppliers Nestlé, PepsiCo and Unilever to tackle the issue in advance of much-anticipated contract talks. Since Monday, Carrefour has been putting stickers on products that have shrunk in size but cost more even after raw materials prices have eased, to rally consumer support as retailers prepare to face the world’s biggest brands in negotiations due to start soon and end by 15 October. Tell us your experiences of ‘skimpflation’ and ‘shrinkflation’ Read more Carrefour has marked 26 products in its stores in France with the labels, which say: “This product has seen its volume or weight fall and the effective price from the supplier rise.” For example, Carrefour said a bottle of sugar-free peach-flavoured Lipton iced tea, produced by PepsiCo, shrank to 1.25 litres (0.33 gallon) from 1.5 litres, resulting in a 40% effective increase in the price a litre. Guigoz infant formula produced by Nestlé went from 900 grams (31.75 oz) to 830 grams, while Unilever’s Viennetta ice-cream cake shrank to 320 grams from 350 grams. “Obviously, the aim in stigmatising these products is to be able to tell manufacturers to rethink their pricing policy,” Stefen Bompais, the director of client communications at Carrefour, said in an interview. A shrinkflation warning on Liptons ice tea in a Carrefour store near Paris. Photograph: Sarah Meyssonnier/Reuters The Carrefour chief executive, Alexandre Bompard, who also heads the retail industry lobby group FDC, has repeatedly said consumer goods companies are not cooperating in efforts to cut the price of thousands of staples despite a fall in the cost of raw materials. In this he is backed by the French finance minister, Bruno Le Maire, who in June summoned 75 big retailers and consumer groups to his ministry urging them to cut prices. After a new round of meetings last month, Le Maire said Unilever, Nestlé and PepsiCo were among companies not toeing the line on prices. Lindt’s “chocolat au lait extra fin” was one of three of the Swiss chocolatier’s products named by Carrefour in its shrinkflation list. “Lindt & Sprüngli increased its prices group-wide on average by 9.3% in line with local cost structures,” a company spokesperson told Reuters. “We have made a concerted effort to compensate for increased costs by increasing efficiency as much as possible. Therefore, we have only passed on the costs we could not absorb ourselves in the form of price increases to our customers.” PepsiCo did not respond to a request for comment. Nestlé and Unilever declined to comment. Consumer groups say shrinkflation is a widespread practice, which supermarkets like Carrefour are also guilty of in their own-label products. The shrinkflation warnings are in all French Carrefour stores, and will last until the targeted suppliers agree to price cuts, Bompais said. The retailer could extend warnings to other goods, but does not plan to extend the initiative to other countries. Explore more on these topics Supermarkets Inflation France Europe Retail industry news Reuse this content More on this story France pushes for more factory farming in food U-turn 2d ago Planning a UK mini-break? See how the price has gone up – from hotels to fish and chips 4 Aug 2023 France investigates deaths of four Champagne workers in heatwave 2d ago UK alcohol tax changes: will your favourite drink cost more or less? 1 Aug 2023 Woman dies and 12 in hospital after botulism outbreak at Bordeaux restaurant 3d ago Make your price labels clearer, watchdog tells UK supermarkets 20 Jul 2023 France halts iPhone 12 sales over radiation exposure levels 3d ago Bank of England boss vows to ‘see the job through’ on reducing inflation 10 Jul 2023 French actor Mathieu Kassovitz says he was being an ‘idiot’ before motorbike crash 5d ago UK tax cuts unlikely before election, says Jeremy Hunt 8 Jul 2023 Most viewed World Europe US Americas Asia Australia Middle East Africa Inequality Global development News Opinion Sport Culture Lifestyle Original reporting and incisive analysis, direct from the Guardian every morning Sign up for our email About us Help Complaints & corrections SecureDrop Work for us California resident – Do Not Sell Privacy policy Cookie policy Terms & conditions Contact us All topics All writers Digital newspaper archive Facebook YouTube Instagram LinkedIn Twitter Newsletters Advertise with us Guardian Labs Search jobs Back to top © 2023 Guardian News & Media Limited or its affiliated companies. All rights reserved. (modern)",
    "commentLink": "https://news.ycombinator.com/item?id=37522858",
    "commentBody": "Carrefour puts ‘shrinkflation’ price warnings on food to shame brandsHacker NewspastloginCarrefour puts ‘shrinkflation’ price warnings on food to shame brands (theguardian.com) 470 points by cainxinth 20 hours ago| hidepastfavorite359 comments h1fra 19 hours agoFor those wondering if it&#x27;s truly representative, it&#x27;s estimated that 50% of the inflation in Europe is due to margin increase not bc of the inflation itself.https:&#x2F;&#x2F;www.imf.org&#x2F;en&#x2F;Blogs&#x2F;Articles&#x2F;2023&#x2F;06&#x2F;26&#x2F;europes-inf... reply enoch_r 18 hours agoparentThis argument is completely incoherent. You can&#x27;t study the cause of inflation by looking at the distributional effects of inflation.For example, in 2020 there was a huge increase in demand for used cars, and the price of used cars increased by ~40% within a few months. But people who sold used cars did not have their costs increase - they were, after all, selling an already completed product. The IMF would therefore estimate that between 2019 and 2020, ~100% of inflation in used car prices was due to margin increases rather than inflation itself.This is obviously silly - the increase in prices was because there were too many buyers and too few cars, not because the owners of used cars suddenly because significantly more greedy overnight. It&#x27;s the same with corporate profits. Inflation has distributional effects which are interesting to study, but we shouldn&#x27;t confuse ourselves by claiming that the effects are actually the causes. reply anigbrowl 16 hours agorootparentIt&#x27;s the same with corporate profits.LMAO no. It&#x27;s foolish to equate an individual selling a single asset like a car with businesses that can range from little niche supply workshops up to dominating whole industries. Pure laws of supply and demand only hold true under conditions of perfect competition, and much of what we call &#x27;business&#x27; is about playing the meta-game - out maneuvering competitors financially, creating moats and other barriers to entry to keep competitors out of a market sector, using marketing to maximize product differentiation and shape consumer perception, leveraging regulatory complexity in one&#x27;s favor or lobbying for it to be reduced in order to gain some cost advantage.Real world markets are a lot more complex than the little toy ones used to explain fundamental economic concepts. reply enoch_r 15 hours agorootparentMy claim is that we can&#x27;t determine what caused a price change by looking at the distributional effects of that price change.I demonstrated this with an example, where we know what caused a price change (supply chain issues for a substitute product plus increased demand) and know the distributional effect (higher margins for sellers of used cars). If we naively try to explain the price change based on the distributional effect, we would claim that higher prices were purely caused by increased greed. We know this to be false.Look, perhaps companies really did become more greedy in 2020 and that&#x27;s what has really caused inflation. Or maybe large amounts of stimulus caused increased demand. Or perhaps the war in Ukraine has caused supply chain issues which drives up prices. My point is that looking at the distributional effects of inflation is just completely disconnected from the question of what caused inflation in the first place.At the very least, if you&#x27;re claiming that we can figure out what caused inflation by looking at the distributional effects, can you provide some evidence, or some argument, to support that claim? Because I think my example demonstrates that common sense (\"X benefitted from inflation, therefore X caused inflation\") is not a good guide here, and if anything, the additional complexity of real markets works against you here - if we can&#x27;t even explain inflation based on distributional effects in a toy market, what makes you so confident we can do so in the market as a whole? reply anigbrowl 11 hours agorootparentFor some goods (like cars) supply issues have indeed been the major driver of price inflation.But for many consumer goods, manufacturers have exploited the perception of inflation to increase prices or (as highlighted in the source article) to shrink package volumes while retaining the same price point. It&#x27;s much less clear that supply is the driver here; bear in mind the fact that moving to smaller package sizes often imposes considerable overhead as whole production lines need to be retooled, new package containers designed and manufactured etc. It&#x27;s not a passive response to market phenomena, it&#x27;s a straightforward investment in the idea of giving consumers less value for their money.While I don&#x27;t disagree that government policy and economic shocks can often be inflationary without any intention on the part of the business community to drive prices up, consider too that sometimes there is such intent and organizations like the Chamber of Commerce exist largely to beg for support from the public purse in hard times and deflect criticism onto whatever scapegoats are convenient in good times. reply arcticbull 17 hours agorootparentprevThat&#x27;s not necessarily true, over the last few years we saw that companies were able to begin pushing prices to increase margins and profits on the same volume of goods instead of manufacturing more goods and making the profit on volume. Some of the margin increase was due to real supply constraints, but not all of it. For instance, when Coke and Pepsi lost ~4% of their global sales by abandoning the Russian market, they just raised prices everywhere else to compensate, because they could, and people were willing to pay. Now moving forward, they seem to be losing their ability to push prices. My point is not all cost increases were due to real constraints - they were in the auto sector, but that&#x27;s not true of all sectors.If I know this, I suspect the IMF does too, and incorporated that into the report. reply vineyardmike 16 hours agorootparentprev> the increase in prices was because there were too many buyers and too few cars, not because the owners of used cars suddenly because significantly more greedy overnight.No it’s literally greed. You can choose to not raise the price of your used car when you sell it. “Market price” is a hallucination that you can ignore. You’re not forced to go along with it. As you said, sellers of used cars didn’t have their cost increase, so what was the forcing function for price increases except greed?Which brings me to corporate profits… reply enoch_r 15 hours agorootparent> “Market price” is a hallucination that you can ignore. You’re not forced to go along with it.It&#x27;s a powerful signal containing important information! You don&#x27;t have to go along with it, but it may be beneficial to others if you do.As an example, we bought a new car in 2019. We were planning to sell our old car but every time we were about to sell it, it came in handy - family came to town and we needed two cars, or it was nice to be able to go two places at once.In 2020, prices shot up. Suddenly, it was worth it to sell the car.Someone who valued it more than us got to use the vehicle. Was that greed? reply vineyardmike 14 hours agorootparent> Someone who valued it more than us got to use the vehicle. Was that greed?You sold it because you could get more money for it. That’s what greed is - you chose more money. You could make the case that you weren’t behaving immorally -not everything in life has to be a charity- but you acted out of a selfish desire for more money.I’d also argue that “value it more” is pretty flimsy. Yes in a shortage the buyer clearly needed a car and was willing to spend more to acquire it instead of waiting for prices to drop. But you clearly didn’t value it beyond the 2019 price based on your stated desire to sell then, it was just an inconvenient transaction. reply rottingchris 13 hours agorootparentNo, what you&#x27;re describing has nothing to do with greed. Self-interest is not the same as greed. There would be nothing between greed and charity using according to your definition. Indeed, keeping the car when they didn&#x27;t need it would also be greed. The only in-between is selling it for a fair value - but there is no objective fair price. reply jabradoodle 14 hours agorootparentprevSo what price do you sell it for and who do you choose to sell to at your below market price? reply c22 12 hours agorootparentI usually list slightly above market then knock a bunch off if the buyer seems like a decent person with a real problem. reply yunohn 16 hours agorootparentprevYour comment also seems incoherent.You’re comparing the concept of economy-wide inflation with the basic supply-demand economics for one item. reply mcphage 15 hours agorootparentprev> But people who sold used cars did not have their costs increase - they were, after all, selling an already completed product.Didn&#x27;t they? Increased demand for used cars should mean that used car buyers are forced to pay more for the same car than they would previously. Maybe it&#x27;s lagging by a bit, but I would absolutely expect that their costs would go up. reply josu 18 hours agoparentprevDo not buy into that narrative. This inflationary process has been mostly driven by monetary policy. Margin increases are the result of businesses trying to navigate an inflationary period. These margin increases are not resulting in increased profits across the board (there are some notable exceptions). For example, Carrefour&#x27;s profits in 2022 were about the same as in 2019. [1]From the article you linked: \"Profits (adjusted for inflation) were about 1 percent above their pre-pandemic level in the first quarter of this year.\"[1] https:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;CA.PA&#x2F;financials?p=CA.PA reply milesvp 18 hours agorootparentWithout a doubt monetary policy has fueled inflation, but do not ignore the policies of allowing corporate mergers for the last 40 years. Lack of competition reduces price elasticity, and the end game of every monopoly is to raise prices. We are living in a world of global monopsonies, and my expectation is to contine to pay this monopoly tax for years.Worse, is it’s never been easier to collude. It used to be you had to pay a big consulting firm big money for them to tell you “current market rates” for many goods and services. Now you can just subscribe to same SaaS everyone in your industry uses and have it tell you how much to charge. This tends to help break out of a prisoner’s dilemma.This was something I never quite anticipated. I used the intenet when it was young to help do price discovery and find better deals. Never occurred to me the end game was for companies to do it even better for pricing. Even after seeing thrift store pricing adjust due to seeing online prices on ebay, it didn’t occur to me the scale it would happen elsewhere. reply kortilla 17 hours agorootparentThere are 20 different burger restaurants within 10 miles of me. Some are chains, some are local. Some use major beef suppliers, some use local organic ones. All of their prices have gone way up.There is no collusion here and this has jack shit to do with mergers. If those were the causes, inflation would have been a crisis 10 years ago. reply milesvp 15 hours agorootparentHow many of these burger joints own the building they operate in?This is a very shallow look at economic forces. And ignores some of the bigger squeezes happening. The number of landlords continues to decline as real estate is consolidated in fewer hands. And worse, the number of landlords that abdicate their roles to real estate management companies grows every year, and the percentage of properties in an area run by a given management company continues to grow as well. This creates a level of “collusion” that didn’t really exist 30 years ago.Our current market abhors competition, and regulators and courts have increasingly sided with the bigger business.Inflation was a huge problem 10 years ago. It’s why I stopped renting. reply kortilla 3 hours agorootparent>How many of these burger joints own the building they operate in?Roughly half. Nearly all of the locally owned ones.>Inflation was a huge problem 10 years ago. It’s why I stopped renting.No it wasn’t. At least not by any quantitative measures. reply Draiken 17 hours agorootparentprevThe only collusion is the default one: profit at all costs.Everyone raises prices to increase profits, increasing inflation, that increases prices further...I don&#x27;t understand why people are so happy to blame governments and treat companies, in which profit is their raison d&#x27;être, as if they&#x27;re only \"reacting to the government\".Of course both are to blame, but let&#x27;s stop pretending companies are victims while record profits are seen everywhere (adjusted to inflation). Many (if not most) are clearly taking advantage of this exact sentiment against the government to pocket even more profit. It&#x27;s not me, it&#x27;s the inflation! reply josu 9 hours agorootparentIf this is true, why are inflationary periods relatively rare? reply chromoblob 11 hours agorootparentprevThanks for the collusion&#x2F;dilemma tip, I didn&#x27;t know. reply m000 18 hours agorootparentprev> Do not buy into that narrative. ... Carrefour&#x27;s profits in 2022 were about the same as in 2019.Isn&#x27;t this exactly why we should buy into this narrative? The manufacturers increased their margins, so Carrefour sells more expensive, but in the end gets the same total profit. reply deelowe 18 hours agorootparentThe parent is saying that these \"increase in margins\" are companies trying to get ahead of inflation. The media narrative has been to blame the corporations, despite the real issue being the economy. There are elections to worry about, so we can&#x27;t have that.Smart businesses don&#x27;t wait until they start losing money to make adjustments. They plan ahead. These \"margin increases\" are literally increases due to inflation which will companies expect to take hold over the next 1-2 years. There could be a variety of factors for this. One such example is corporate bonds rolling over to new interest rates which are expected to start happening en masse very soon. reply m000 17 hours agorootparentManufacturers trying to get ahead of inflation and ending up with record profits. How convenient.I&#x27;ll buy the media narrative this time, thank you. reply kortilla 17 hours agorootparentThey are only record profits when you don’t adjust for inflation. Companies in Zimbabwe were making record profits every year, what a booming economy!!! reply Loughla 18 hours agorootparentprev>The media narrative has been to blame the corporations, despite the real issue being the economy.This might be a really, really stupid question, but aren&#x27;t corporate decisions sort of the economy? replyjustinclift 18 hours agorootparentprevHere in Australia we seem to be having high inflation of food, which the main supermarkets (a duopoly) are blaming on the cost of goods.Meanwhile, they&#x27;ve both reported their highest ever company profits. :(So, clearly they&#x27;re full of shit about the cost of goods being the cause rather than their own price gouging. reply Manuel_D 18 hours agorootparentRecord profits in a period of inflation is not surprising.If the value of the Australian dollar halves, then a company doubling it&#x27;s raw profit figures is really just staying maintaining the same profits in real value. reply ta1243 18 hours agorootparentRecord profits as a percentage of revenue.The problem in Austrialia is a lack of competition, hence Woolworths can get a 5.9% profit compared with say Tesco in the UK with 3.8% profit (the UK having far more competition)Not only that but while demand is decreasing, profits are increasing. That&#x27;s a ridiculous system and shows a broken market. reply Gigachad 12 hours agorootparentPlenty of competitors have prepared to enter Australia, and then left after finding there is no money to be made.Too few people spread too far apart. reply justinclift 5 hours agorootparent> Plenty of competitors have prepared to enter Australia, and then left after finding there is no money to be made.Explain ALDI? reply justinclift 18 hours agorootparentprevIf the value of the Australian dollar halves, and a company manages to double its raw profit figures... doesn&#x27;t that still sound like price gouging?Why would their \"maintaining the same profits in real value\" be acceptable when no-one else in the end to end chain (producers, customers, etc) managed to in the situation. reply Manuel_D 17 hours agorootparentIt&#x27;s not price gouging: the value of currencies are almost certainly never going to return to their pre-pandemic levels. Price gouging typically refers to raising prices in a specific exceptional situation like a disaster. Inflation is not exceptional, it&#x27;s happening worldwide (though more in some countries than others). It&#x27;s also not a temporary. It&#x27;s lasted years and even if inflation returns to 2% the prices are going to stay high.Again, if the value of currency halves and profits in raw curry terms doubles then profit in terms of real value has remained the same. If a company pays it&#x27;s employees $30 and the value of currency halves, and it raises wages to $45 did they really raise wages? In raw terms, yes, but in real terms no. The value of wages has actually gone down. reply nradov 18 hours agorootparentprevWhat is price gouging? reply lm28469 17 hours agorootparentprevPrices are rising because inflation because pricing are rising because inflationSmart. reply Manuel_D 17 hours agorootparentExcept that really is what happens. If the prices of your inputs increase, then you have to raise the prices of your goods. And then companies that use your goods isn&#x27;t puts have to raise their prices, and so on.In terms of labor and wages, it&#x27;s called a wage price spiral: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Wage-price_spiralSimilar dynamics exist for physical goods. reply josu 18 hours agorootparentprevI&#x27;ll just quote myself.>Do not buy into that narrative.Would you mind sharing the data? I&#x27;ve done a quick search, but I can&#x27;t confirm what you said.I found this, which contradicts what you said, but Statista is not super reliable: https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;1116200&#x2F;australia-net-pr...But even if it&#x27;s true, and they recorded the largest profits, the catalyst still is the monetary policy. If businesses could just price gauge their clients, they would have already done it before. The goal of a corporation has always been to maximize utility, and this hasn&#x27;t suddenly changed; so ask yourself, why are they raising prices now. reply polygamous_bat 17 hours agorootparent> But even if it&#x27;s true, and they recorded the largest profits, the catalyst still is the monetary policy. If businesses could just price gauge their clients, they would have already done it before.You can&#x27;t think of any major global event that happened since 2020 that may work as a \"distraction\" and a cover while businesses engage in monopolistic&#x2F;anti-competitive behavior? reply PowerfulWizard2 18 hours agorootparentprevThe research paper linked by the parent comment is using Gross Operating Surplus and EBITDA metrics: Gross operating surplus differs from profits shown in company accounts for several reasons. Only a subset of total costs are subtracted from gross output to calculate the gross operating surplus. Essentially it is gross output less the cost of intermediate goods and services to give gross value added, and less compensation of employees and taxes and subsidies on production and imports.There are obvious financial cost increases that have happened which are falsely represented as &#x27;profit&#x27; in this analysis. reply whazor 2 hours agorootparentprevSorry but branded products particularly from big brands like Unilever have become crazily expensive. The branded product is sometimes up to 5 times more expensive than the store brand for the same product. To me the most crazy product that was too expensive was some water ice, which is literally water, sugar, and some flavoring&#x2F;coloring.Sure there is inflation, but maybe those companies keep sending excel files to each-others department and keep increasing prices multiple times more than needed. reply rocgf 18 hours agorootparentprevI am amazed to finally see a comment like yours, I&#x27;ve argued this point in various contexts and I was treated like I am crazy. reply KennyBlanken 17 hours agorootparentprevThat \"narrative\" is coming from food corporations bragging in their quarterly earnings calls that they&#x27;re not lowering prices even as fuel, labor, and material prices fall coming off the pandemic, because they&#x27;ve gotten people used to the higher prices. reply NickM 19 hours agoparentprevSupply constraints typically lead to higher prices and higher margins. The fact that the margins have gone up does not somehow imply that the higher prices are something other than inflation. reply tommiegannert 19 hours agorootparentFrom my perspective, you&#x27;re saying the same thing as the parent: both prices and margins have gone up. Then you&#x27;re stating the definition of inflation.Parent&#x27;s comment was (implicitly) about 50% of this inflation being avoidable and thus surprising, because margins didn&#x27;t necessarily have to go up to keep business going. It was just a seized opportunity. If you can show that margins unavoidably always go up during inflation because of some fundamental mechanism, then that would be a refutal of the parent argument. reply marcosdumay 18 hours agorootparentMargins almost always increase anyway.I&#x27;m not sure anybody fully understands the mechanism (for the most studied phenomenon of economics, inflation is quite badly understood), but that doesn&#x27;t change the fact.Anyway, if you run the Keynes model for macroeconomics, the average margin increases very naturally when the money supply increases. It increases even more if the new money is injected in the economy by well distributed government spending. Still, that&#x27;s one model we have that kinda works, but it&#x27;s so full of problems that you can&#x27;t take its predictions for granted. reply vasco 19 hours agorootparentprevTemporarily and in a localized way, yes.For example, if there&#x27;s a natural disaster, and the people in power aren&#x27;t dumb, they&#x27;ll let prices float instead of putting caps in place, and everyone will be incentivised to rent big trucks full of water bottles and sell it for 20-50x the normal price. For the affected people it makes sense because now they can drink water, and if the prices were controlled nobody would make the drive. Eventually enough people do the drive or the disaster passes and prices normalize.At the moment it&#x27;s hard to explain what is happening but it might be more complex than just \"nothing to see here\". I&#x27;ve come to realize that reality is more nuanced than Milton Friedman made it out to be (and he did too later in life). reply Brybry 18 hours agorootparent> if there&#x27;s a natural disaster, and the people in power aren&#x27;t dumb, they&#x27;ll let prices float instead of putting caps in placeI think most states that experience natural disasters have price gouging laws that make it illegal to raise prices, during a declared emergency, beyond the level required by increased costs.Or at least I know Louisiana[1] and California[2] do.And here in Louisiana we&#x27;ve had a lot of disasters and it generally works (sometimes gouging still happens).[1] https:&#x2F;&#x2F;legis.la.gov&#x2F;legis&#x2F;Law.aspx?d=85680[2] https:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;codes_displaySectio... reply MostlyStable 18 hours agorootparent\"Works\" in the sense that it keeps prices from going to high. Fails in that it prevents people from preparing adequately for forseeable disasters and bringing in more of the things people need in a disaster.In my opinion, disasters that have some level of predictability (hurricanes are the best example) shouldn&#x27;t have price gouging laws. If you were allowed to raise your prices arbitrarily high, and you knew a hurricane was coming, what would you do? Bring in as many of the goods as you thought you could get higher prices for as you could. This results in an equilibrium where lots more water, food, batteries, etc. gets brought in, prices rise only somewhat, and no law is necessary.Now, I agree that for disasters that aren&#x27;t forseeable (like earthquakes), you lose the signalling value, so I&#x27;m more amenable to it. reply Brybry 17 hours agorootparentI think implying people aren&#x27;t able to adequately prepare for hurricanes in Louisiana is begging the question. I&#x27;ve lived here for almost 40 years, through a lot of hurricanes, and that is not my experience.Sure, some shelves might be bare the day before the storm but that doesn&#x27;t mean people aren&#x27;t prepared, that they aren&#x27;t able to get the things they need, or that the current method does not work.And when the power is out for a week+ for a whole region (goes beyond the supplies urban locals typically prepare) then government uses the national guard to hand out MREs and&#x2F;or bottled water in commercial parking lots. This is very rare. reply JumpCrisscross 16 hours agorootparent> some shelves might be bare the day before the storm but that doesn&#x27;t mean people aren&#x27;t preparedI remember a study on New York following Hurricane Sandy. Fuel was out. Drugs were supplied. Because nobody was incentivised to bring in extra fuel before the hurricane hit; there was no margin to incentivise it. But there was an incentive to bring in drugs, because dealers could make a killing selling at a premium.Price-gouging laws are the price of keeping the peace with a population illiterate in basic economics. (And in any case, there is always a black market in play.) reply Brybry 15 hours agorootparentGas stations can&#x27;t pump if they don&#x27;t have power. That&#x27;s generally why there&#x27;s a lack of fuel.Sometimes they have backup power or power companies prioritize them. In the south, local media will help notify which gas stations are operable. More fuel won&#x27;t solve that problem.For Sandy they had more issues than just pumps without power. 40% of their supply was reduced before the storm even hit from shutting down refineries. And then the refineries suffered damage. Storage tanks were damaged. Pipelines were inoperative. They couldn&#x27;t fill delivery trucks. [1][2]For a typical hurricane, why would there even need to be extra fuel over normal supply? In a hurricane people are driving less. They&#x27;re staying home. The only extra fuel will be from generators and hoarders.Price increases would probably decrease hoarders but it wouldn&#x27;t turn refineries back on and magically make more gas.[1] https:&#x2F;&#x2F;www.preventionweb.net&#x2F;english&#x2F;hyogo&#x2F;gar&#x2F;2015&#x2F;en&#x2F;bgdo... [pdf][page 6][2] https:&#x2F;&#x2F;www.nbcnewyork.com&#x2F;news&#x2F;local&#x2F;sandy-storm-anniversar... reply JumpCrisscross 15 hours agorootparent> stations can&#x27;t pump if they don&#x27;t have power. That&#x27;s generally why there&#x27;s a lack of fuel.They’re a gas station. They’re sitting on a fuel source. Why do you think it isn’t economical to install a generator? (Or even lease one.)> why would there even need to be extra fuel over normal supplyEmergency vehicles. Trucks bringing supplies for repairs. People checking in on each other. People coming back from evacuation or leaving to find peace of mind. Also returning to normal life.And it’s not about extra fuel. It’s about maintaining supplies. New shipments aren’t coming in, which means supplies need to be rationed. New shipments come in slower than they would if prices could rise; nobody serving the general population is incentivised to rush.> increases would probably decrease hoarders but it wouldn&#x27;t turn refineries back on and magically make more gasEmergency shortages are all about distribution, not production. There is plenty of gas in the world in a disaster. It just isn’t making it to disaster victims. (Well, it is. But you have the pay the cab driver cash to pay the guy by Riverside Park for a can at $20&#x2F;gallon.) reply selimthegrim 14 hours agorootparentprevI think it’s a little more complicated than that. I remember fueling up in Chalmette right before Ida, early in the morning, and by the evening or the next day the gas station was out of fuel. Would no price gouging laws have allowed them to inflate the price so much that people couldn’t afford to buy a day early like I did to be able to evacuate? reply jabradoodle 14 hours agorootparentprevGovernment had to provide basic services during a time of emergency and there are regulations in place to stop people taking advantage of vulnerable people.Sounds good, I&#x27;d pay tax money toward it. reply JumpCrisscross 14 hours agorootparent> Government had to provide basic services during a time of emergencyThere were widespread fuel shortages.> regulations in place to stop people taking advantage of vulnerable peopleThere were no fuel shortages for folks who could buy on the black market.> Sounds goodIn a sense, the system works. The part of the population that feels good with these rules sits out of the market. The part that thinks it’s silly has access, in part thanks to the shortages&#x2F;forced curtailment caused by regulation in the legal market, albeit at a steeper mark-up (plus the inherent risks to black market trading). replyorangepurple 18 hours agorootparentprevI have been through multiple natural disasters in the Houston Texas area over some years and I have seen first hand that these price caps cause shortages resulting in people that need supplies not being able to obtain them. The people wanted price caps in the name of preventing price gouging and the state state obliged: the majority of people get nothing and everyone is happy. reply vineyardmike 16 hours agorootparentprevYikes. If the people in power are really smart though they’ll protect their constituents against greedy opportunists and fund the water transportation at cost. Maybe even paid for by taxpayers. reply feoren 16 hours agorootparent> If the people in power are really smart though they’ll protect their constituentsThey have no incentive to do so. If they were actual human beings with functioning consciences maybe, but we often see people use the word \"smart\" to mean \"ruthless asshole without a functioning moral compass\". Those people assume everyone else would torture their own grandmother for an extra dollar just like they would, and so everyone who&#x27;s not abusing the system to its fullest extent is just dumber than them. So in fact the people who are likely to be in power, who have absolutely no incentive to protect their constituents, will likely be in on the con as much as they can, and will actually call themselves \"smart\" for doing so. reply vineyardmike 14 hours agorootparentMany US states actually have price gouging laws. In the US, during a natural disaster, many places deploy emergency personnel employed by the government (eg national guard) to pass out water and aid. I’d say the US ranks highly among developed nations as “politicians who are assholes due to bad incentives”.Thankfully not everyone behaves like an economics textbook. reply true_religion 18 hours agorootparentprevI guess all people in power must be dumb because every county has laws against grifting necessary essentials in a natural disaster.It’s possible your point does apply to normal price shifts when supply for something like electronics becomes constrained but right now your example detracts from understanding that. reply lobocinza 15 hours agorootparent> I guess all people in power must be dumbSome are smart psycopaths. The issue isn&#x27;t dumb in power but dumb people voting. People get outraged by price gouging so populists create laws against it. Even though those laws don&#x27;t make economic sense they make political sense.Most of the time IMO state agents will just ignore price gouging because they know it is a necessary evil but if the need arises they can always intervene in prices, say they are doing something and save face. But this destroys the economy if done often. It&#x27;s not black and white. reply true_religion 15 hours agorootparentI think it makes more economic sense for the government to directly subsidize necessities by shipping them in and controlling the price or giving them away for free. This is what FEMA does in the US.What does not make sense is a world where people have to buy disaster issuance just to make sure they can afford water when a hurricane strikes. reply yndoendo 8 hours agorootparentprevWouldn&#x27;t Texas and their electric infrastructure and pricing be that defines the reality of price floating while showing people in power are dumb? As showing by the lack of regulation to weather treat your power infrastructure? So cold that the water pumps to cool nuclear power plants freeze? So cold that the natural gas lines freeze? So low in quality that they cannot be connect to the national electric infrastructure to allow for non-price gouging use during national disasters, hot or cold?Shouldn&#x27;t it be humanity that takes offense in a natural disaster instead of financial exploitation? reply JohnFen 16 hours agorootparentprev> For the affected people it makes sense because now they can drink waterOnly the rich people. It does nothing for everyone else. reply eddtests 19 hours agorootparentprevWhy does it cause such higher margins? reply bluesign 19 hours agorootparentImagine you buy for X, and sell to some supermarket for Y, and they pay you in T time.Optimum Y is not related to X, but the price when you replace the stock. ( let&#x27;s say X2 ) When supply has problems, or economy is unpredictable, it is harder to predict X2, so usually your estimation is a bit off.So you have to have bigger margin to cover for this estimation error. ( assume the worst ) reply throwaway019254 18 hours agorootparentSo they increase margin to cover for uncertainty and incorrect estimations. And in case the original estimations were right, the higher profit is just unintended consequence. reply Miraste 19 hours agorootparentprevThe rather soulless economics answer is that the companies want to make the same profit as before the inflation, so they need higher margins on individual sales to make up for the reduction in volume. Since demand doesn&#x27;t drop, this is a feasible strategy. reply vkou 18 hours agorootparentThat answer doesn&#x27;t make sense, because surely, companies want to increase their profits regardless of whether inflation is happening or not.The real answer is that when inflation is happening, it provides an easy excuse for raising prices far beyond the cost of your inputs. Everyone expects prices to go up, so they don&#x27;t balk at yours going up faster than inflation. reply Miraste 17 hours agorootparentThe idea is that the company normally prices their products at the intersection of supply and demand, where there is maximum profit. When supply is artificially constrained, they raise prices to the corresponding spot on the curve. This is not as profitable as before, but it&#x27;s the new local maximum.It&#x27;s one of those simple macro-econ models that sound good, but never play out in real life because humans aren&#x27;t calculators. The reality is a mix of both, probably more of your explanation. reply Retric 19 hours agorootparentprevSupply drops mean price increases. Goods have multiple inputs but don’t see equal increases across the board. Ie rent isn’t going up in a grain shortage.Critically higher profit margins doesn’t necessarily translate to higher profits because you’re selling fewer goods. reply gwbas1c 19 hours agorootparentprevBecause a lot of companies are using \"inflation\" as an excuse to raise prices.Remember, prices generally are a function of the cost the market will bear. If the general public will pay more for something, why not rise the price? If everyone is rising their prices at the same time, you have less pressure to compete on prices. reply WalterBright 19 hours agorootparentprevIt takes a while for the river of money helicoptered into the economy to spread its inflation out evenly. reply eru 18 hours agorootparentThat theory only works if people are morons who can&#x27;t anticipate long expected (price) developments. reply psychoslave 19 hours agorootparentprevBecause the middle man typically see there an opportunity to extort more money? reply jahewson 17 hours agorootparentprevFrom the original article:> consumer goods companies are not cooperating in efforts to cut the price of thousands of staples despite a fall in the cost of raw materials. reply JumpCrisscross 16 hours agoparentprev> it&#x27;s estimated that 50% of the inflation in Europe is due to marginIs this just constant margins being spun as conspiracy?Say I have a 10% margin on a $100 product. Costs rise 10%, i.e. to $99. If I want to keep a 10% margin, I raise prices to $110. How much of that price rise was inflation versus margin increase? Will someone now claim that 90% of cost rises were due to inflation and 10% margin? (Keep in mind, too, that inflation is forward looking.)Put another way, how enviable have manufacturers’ margins in Argentina, Turkey or Zimbabwe been? reply pid-1 18 hours agoparentprevWhy there was no inflation in the past decades? Did companies used to be generous? reply ceejayoz 18 hours agorootparentCompanies didn&#x27;t have a single easy worldwide excuse that people would readily accept for big price hikes. \"Oh, it&#x27;s because of the pandemic\" was not a PR strategy available in 2010.See also: 9&#x2F;11 and various civil liberties. reply badcppdev 19 hours agoprevThis is such a good idea. I know that everyone in the Western World is told that they eat too much but people need to be able to buy food and eat it. And if the same packaging this week has 90% of what it had last week then then consumers are going to suffer.In the UK many people rely on Food banks and parents skip meals to feed their children. Cutting the amount of food in a package in a manner that is not even visible without carefully examination is a morally dubious practice.Corporate profits are high. This is one of the reasons why. reply Cthulhu_ 19 hours agoparentI wish there was legislation in place that sets legal standard sizes; for one, it would allow for more uniform packaging, allowing reuse between brands and reducing trash. It would be more predictable box &#x2F; pallet sizes, reducing transport costs. And it would give consumers more security, even with the mandatory price per liter &#x2F; kilo notices which are often hard to read.One example of shrinkflation &#x2F; cost fuckery here is cheese. We buy a kilo of it every time, but they&#x27;ve changed it so you get e.g. 920 grams. Looks the same size, but it&#x27;s slightly different, thus hard to make comparisons. Still up 30% since before the Ukraine thing though. reply eru 18 hours agorootparentYou can already shop at Aldi if you like things to come in standardised sizes.(I love Aldi! But I think such regulation would be pretty silly. But we already have such regulation in many parts of the world for many goods. Eg publ in the UK can&#x27;t just sell you 500ml of beer, they need to give you a pint.) reply usrusr 18 hours agorootparentprevGermany used to have that legislation, removed in 2009. Legal packaging sizes were e.g. 100g, 250g, 500g, 750g, 1000g.Removed because it was, unsurprisingly, not the lowest common denominator EU wide. It&#x27;s almost universally considered a tragic loss, I guess the only exception are those whose job description includes getting creative with packaging size. reply RunSet 18 hours agorootparentprev> I wish there was legislation in place that sets legal standard sizes;Those extracting profit from deceptive packaging would do better to extract a moral lesson from the provenance of the baker&#x27;s dozen.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Vantage_loaf reply mytailorisrich 17 hours agorootparentprevEnforcing legal standard weights&#x2F;sizes for everything that businesses cannot deviate from would be ridiculous... and that wouldn&#x27;t reduce inflation, either.List the price per litre or per kg, for instance, for every item in addition to the item&#x27;s price and people can then compare between different brands on the shelf. This is already done in many cases though I do not know if there is a legal obligation.People are not stupid by the way, they notice when an item they are used to buy shrinks. reply mitthrowaway2 18 hours agorootparentprevI&#x27;ve been saying this for ages. There are so many second-order benefits. For example in Japan, books are virtually all a standard size, and so bookshelves are built to match. Lets you fit more books in a small home.When packages are random sizes and always varying, it&#x27;s impossible for anyone in adjacent industries to develop synergies. reply somsak2 18 hours agorootparentprevAs sibling comment said, I think this is bound to cause unintended side-effects. I think it would be simpler to require per-unit pricing alongside overall cost, and regulate that amount. Nothing more frustrating than seeing a per ml or oz cost on one item and a per-count cost on one right next to it. reply JuanPosadas 7 hours agorootparentAt my Kroger, almost half the times I try to compare unit price bergen two products, the units are different (e.g. $&#x2F;oz or $&#x2F;lb or $&#x2F;g). And these are always products right next to each other on the shelf. reply bombela 18 hours agorootparentprevIn France, there is always the price per unit. And since the units are not in grain of barley nor a game of guess work (is this ounce dry or wet today?), it&#x27;s obviously much easier to compare. reply kergonath 17 hours agorootparentIsn’t this a European regulation? In any case, it is obviously a good thing for consumers and it is difficult to argue against this. reply erulabs 16 hours agorootparentprevBe wary of engineering society as you would a machine. You don’t know which efficiency you’re destroying in favor of whatever efficiency you may or may not be getting.A grocery story where all the isles are filled with identically sized boxes full of standardized products sounds pretty depressing, for one thing. reply ochoseis 18 hours agorootparentprevIf you regulate packaging sizes it’ll just cause unintended side effects, like weird fillers in your food. reply MAGZine 18 hours agorootparentwhat, like all of the palm oil that&#x27;s now in chocolate? reply kergonath 17 hours agorootparentprevEven with unregulated sizes, Amazon’s boxes contain mostly filler. (I wrote Amazon, but it is common for other online stores as well). reply WalterBright 19 hours agoparentprev> Corporate profits are high.Inflation increases profits, too (but not in real dollars).> This is one of the reasons why.The reason why is inflation. reply mitthrowaway2 18 hours agorootparentInflation can allow corporations to be less price-competitive, because it gets harder for consumers to judge price competitiveness. For example, you sit down at your favourite burger restaurant and see on the menu the price is now $12 instead of $8. Are they just passing on increased costs? Or are they taking the opportunity to pad their profits? I can&#x27;t really tell, not without seeing if prices have gone up comparably at similar restaurants, but I&#x27;m here now and I&#x27;m hungry.The price used to be $8 because they were in a tight battle with other burger joints, and that was as low as they could get it. Now they have to fight their suppliers, but not so much with their competition.This is one of the reasons why high inflation creates unstable inflation, and why central banks like to keep inflation low. reply WalterBright 12 hours agorootparentThat is called the \"cost-push\" theory of inflation, and its giant problem is it doesn&#x27;t explain where the extra money comes from that is necessary for sustained price increases across the economy.It&#x27;s sibling is \"demand-pull\" where customer demand causes inflation, but it equally does not explain where the extra money comes from.A theory that does explain it is the government dumping cash into the economy - inflation consistently picks up about a year after this is done. reply mitthrowaway2 12 hours agorootparent(I&#x27;m sure you&#x27;re aware of this, but price increases only require increased spending from customers if transaction volume is held constant. It&#x27;s entirely possible for prices to rise to arbitrary heights even as the economy contracts and customers become poorer, either because supplies dry up, or because high-volume demand dries up and companies are forced to shift to a smaller but wealthier customer base with high spending power.)More importantly, this is why I said that inflation becomes more unstable when it is higher. Dramatic price increases can happen as companies become less competitive, and then price collapses can happen as well as consumers tap out and companies are forced to compete for a shrinking pie. Economists generally prefer low inflation rather than high inflation, even if all else is equal in real terms, because higher inflation brings higher volatility.Lastly, this isn&#x27;t necessarily the driver that initiates inflation, but it is a feedback loop that can propel it to overshoot an increase in the volume of money. reply WalterBright 10 hours agorootparent> I&#x27;m sure you&#x27;re aware of this, but price increases only require increased spending from customers if transaction volume is held constantReduced demand reduces prices. It&#x27;s the Law of Supply & Demand at work.The Law is always at work, even money is subjected to it. Increase the supply of money, and the value of a dollar drops accordingly. We see this effect as inflation.In physics, we know that momentum is conserved. Any theory that deviates from that is wrong, even if we can&#x27;t figure out why it is wrong.Analogously, any economic theory that results in a \"free lunch\" is wrong. Any economic theory that denies the Law of Supply & Demand is also wrong. Bad government economic policies are nearly always the result of denying the existence of the Law of Supply & Demand, which is as doomed as denying the Law of Gravity.Nothing stops the government from pretending that deficit spending is a free lunch, and they sell that notion at every opportunity. But the Law of S+D still applies.The elephant in the room is the sheer size of the several trillions in deficit spending. There&#x27;s just no way to ignore it and explain inflation away by suddenly every business is price gouging. It&#x27;s not a compelling explanation at all. reply mitthrowaway2 9 hours agorootparent> Reduced demand reduces prices. It&#x27;s the Law of Supply & Demand at work.You have to be careful when asserting this though, because demand does not mean what most people think it means. In particular, it does not refer to the number of people demanding a good, nor does it refer to a volume of goods purchased. A declining sales volume occurring together with rising prices does not violate the law of supply and demand. reply WalterBright 8 hours agorootparentRising prices reduce demand. But there are competitors. That&#x27;s why a company cannot just raise prices. reply mitthrowaway2 7 hours agorootparentYes, rising prices reduce demand. But rising volumes also create economies of scale and allow low prices. There&#x27;s a delicate balance and sometimes an equilibrium of large volume, low price can transition to a new equilibrium of low volume, high price, or vise-versa. For example, if you are a software company and you sell software to a small group of professionals, like a CAD program, your price is probably around $1000 ~ $5000 per seat, per year. And competition will not lower it, because your competitors face the same economic situation you do: it&#x27;s a niche product, you have to amortize a high development cost over a small number of customers, and those customers have money and are willing to pay.However, there is also a stable equilibrium for a company to turn a similar profit shipping software of equal quality to a very large number of people for a very low price. Something like a spreadsheet or word-processing software. Now your software is cheap, or supported by ad revenue, and yet you can still remain highly profitable. If, however, your userbase started to shrink for whatever reason, you might have to charge the remaining users a large amount. Most will leave, but a few of those users may derive a lot of value from your software and are willing to pay, and you end up with the same economics as the CAD developer.Software is of course an extreme example, where the marginal cost of production is approximately zero, but most industries outside of resource extraction have declining marginal costs with scale. That&#x27;s why you can end up with high-quality cheap components (like cameras, etc) that are used in smartphones, where they have high-volume production, and very expensive specialty cameras for eg. microscopes, even though the specialty camera required much less investment of R&D to produce. It can only be sold at a high price because there is not enough demand to reach economies of scale that would allow a lower price.So if for whatever reason, money was sucked out of the economy and the average person suddenly became very poor and could not afford a smartphone, it&#x27;s possible that smartphone companies would compete hard to keep those customers and drop their prices. But if that doesn&#x27;t make for a sustainable business, the smartphone makers have to drop production to sell only to a few wealthy buyers, the remaining phones will get much more expensive, because their components will be made in expensive fabs at smaller volumes. The total revenue will be lower, the GDP would be lower, but the average price of goods can still be higher. Especially when there&#x27;s a large wealth disparity to make that high-price low-volume equilibrium stable. reply WalterBright 6 hours agorootparentInflation isn&#x27;t a price increase in one item. It&#x27;s a price increase across the economy, including wages.Your theory of inflation does not explain why it isn&#x27;t continuous, and tends to follow periods of enormous deficit spending. That&#x27;s a common factor to inflationary episodes, not some industry figuring out how to gouge. replylesuorac 18 hours agorootparentprevInflation is a disease not a virus.Inflation does nothing on its own; it does not have agency. It&#x27;s just a description of a symptom (increase in price). Whether that set of symptoms (Disease) is caused by price gauging or labor price increases or resource prioritization is not known just from inflation.Although if you see that profits are way up then you know its not due to labor price increases as that company&#x27;s revenue and expenses would both be up and not just revenue. reply WalterBright 18 hours agorootparentIf inflation is 10% and profits go up 10%, most likely that&#x27;s inflation&#x27;s effect. reply lesuorac 16 hours agorootparentI don&#x27;t think you get it yet.If I pour water into a cup and the line says 100 ML there&#x27;s 100 ML of water. That measurement of 100 ML is a descriptor of how much water that is.Inflation is a descriptor of how much prices have increased.If we measure the line a second time and it says 120 ML then the water level has increased (i.e. inflation occurred). But why inflation occurred is not know _just_ by measuring the water level.If firms increase their prices by 10% then the firm is causing inflation (prices have increased). If said firm also gets a 10% increase in their profits then we people would say inflation is entirely driven by profits (although probably strictly inaccurate). However at no point does \"inflation\" cause something. Inflation is _just_ a measurement.--Sticking with the incorrect math, if your prices go up 10% and your profits go up 10% you are the cause of inflation.If your suppliers increased their prices by 10% so you increased your prices 10% then your profit goes up 0% and if your suppliers profit went up 10% then they&#x27;re the cause of inflation.This second example is why people are getting upset. Companies are all complaining they need to raise prices \"due to inflation\" but since their profit margins are just getting better people are suspicious of how much of the price increase is dictated by their supplier&#x27;s price increases versus greed (value pricing). reply WalterBright 13 hours agorootparent> I don&#x27;t think you get it yet.Au contraire. Inflation comes from too much money chasing too few goods and services. How does too much money come about? The government prints money to deficit spend. Why does this cause inflation? The Law of Supply and Demand. Too much money means the money is worth less.Individual companies cannot cause inflation, because they cannot increase the money supply. reply lesuorac 12 hours agorootparent> Individual companies cannot cause inflation, because they cannot increase the money supply.No, you really don&#x27;t know what the word inflation means in the economic sense.>> https:&#x2F;&#x2F;www.google.com&#x2F;search?q=define+inflation>> ECONOMICS>> a general increase in prices and fall in the purchasing value of money.Also companies can 100% increase their prices and if a singular company such as Exxon does it then pretty much every company will also increase their prices because their cost of revenue went up. reply WalterBright 12 hours agorootparentWhere does the extra money come from, lesuorac?> companies can 100% increase their pricesOnly if the consumers have the money, and are willing to pay it and not their competitor.Where do they get the extra money? replyeffingwewt 19 hours agorootparentprevNo, the reason why is price gouging.Or as companies like to call it &#x27;not leaving money on the table&#x27;.Prices have outpaced inflation. Everything has, except worker pay and minimum wage.Profits are record-breaking while laying off workers. CEO compensation and bonuses are insane. Housing prices are out of control. Gas is still $5&#x2F;gallon where I&#x27;m at.It all boils down to one word: GREED. reply WalterBright 13 hours agorootparent> Prices have outpaced inflation.Or, as many people suspect, the government calculation of inflation is deliberately under representing it. The government doesn&#x27;t like to admit it is the cause of inflation, hence all the excuses for it coming from the government, like \"Putin&#x27;s Price Hike\" and all that other economically illiterate nonsense.Companies can raise their prices at any time. So why don&#x27;t they? Why do they do it only after the government dumps trillions of newly printed money into the economy? reply mannerheim 19 hours agorootparentprevLooks like we&#x27;re in the &#x27;blaming suppliers for being greedy&#x27; stage of inflation. Haven&#x27;t seen that one before. reply yoyohello13 18 hours agorootparentIt’s not irrational to be mad. All the poor see is that they are getting screwed and the rich are doing fine (sometime thriving) no platitudes about “economics” are going to make them feel better. reply astrange 17 hours agorootparentWages by definition also increase with inflation. (Inflation is a general increase in prices and wages are a price.) Though you can have both unemployment and inflation at once, called stagflation.Also in the US, the lowest 10% of real wages has grown significantly since 2020, lowering income inequality vs the middle class. reply effingwewt 17 hours agorootparentI&#x27;ll need some citations on those numbers.In states like Texas minimum wage is still $7.25&#x2F;hr and many places pay just that.How do you reconcile your numbers with that?Bills have outpaced wages to the point nearly a whole generation of young adults have given up on home ownership and have had to move back home.Mortgages are increasing in years and rates, even new cars have.Income inequality has never been higher and you&#x27;re seriously saying it&#x27;s gotten better since the greatest wealth transfer in history?! reply astrange 16 hours agorootparent> How do you reconcile your numbers with that?https:&#x2F;&#x2F;www.nber.org&#x2F;system&#x2F;files&#x2F;working_papers&#x2F;w31010&#x2F;w310...It doesn&#x27;t matter what the minimum wage is though, it matters what people are actually paid. Denmark doesn&#x27;t have a minimum wage and they&#x27;re doing okay.> Bills have outpaced wages to the point nearly a whole generation of young adults have given up on home ownership and have had to move back home.Not true, and Texas is fairly affordable. (It&#x27;s blue states that aren&#x27;t because they all refuse to build homes.)https:&#x2F;&#x2F;www.redfin.com&#x2F;news&#x2F;gen-z-millennial-homeownership-r...> Mortgages are increasing in years and rates, even new cars have.Rate increases theoretically don&#x27;t affect the total price of a new mortgage because you can negotiate the sale price down to make up for it. Supply and demand is what controls the total price. Higher rates do reduce new construction though.Cars got more expensive because they stopped making cheap new cars, which is bad, but it&#x27;s not 100% of CPI any more than rent is.> Income inequality has never been higher and you&#x27;re seriously saying it&#x27;s gotten better since the greatest wealth transfer in history?!No, income (wage) inequality peaked in 2014 and has been flat since, then decreased since 2019.https:&#x2F;&#x2F;www.noahpinion.blog&#x2F;p&#x2F;inequality-might-be-going-down...The real great wealth transfer in history was the 2020 CARES act giving a lot of money to the poor. We should do it again. (This is the one that a lot of people online like to say \"we only got $600\" about which is a straight up lie. It was up to $2400&#x2F;month for an unemployed mother with children.)The one that went up is wealth inequality, meaning value of unrealized assets like stock portfolios. But that&#x27;s not nearly as real as cash. (Also, our top tech billionaires Gates&#x2F;Bezos&#x2F;Musk helped inequality out by losing half of their wealth by cheating on their wives or buying Twitter.) reply yladiz 12 hours agorootparent> Denmark doesn&#x27;t have a minimum wage and they&#x27;re doing okay.It’s more complicated than that, and you know it, or you’re using that fact to further your point somewhat disingenuously. Yes, there in no minimum wage defined by law, but in practice it’s around €20 due to the collective bargaining agreements (read: unions) in most industries. reply astrange 10 hours agorootparentSo it doesn&#x27;t have a minimum wage.There&#x27;s nothing to hide here. Just look at the median wage in both places. Or in this case, the lowest 10% wage.I prefer Australia&#x27;s wage board system, but I think nobody knows how it works because they&#x27;re Australian so they&#x27;ve given stupid names to everything. Try and guess what \"award\" and \"casual loading\" mean. reply yladiz 10 hours agorootparentIt doesn’t have a de jure minimum wage, but it does have a de facto one, and just saying it doesn’t hides the subtlety of that. reply mannerheim 9 hours agorootparentPlenty of Danes make less than that. Stages at Noma used to make absolutely no money at all. replymannerheim 16 hours agorootparentprevhttps:&#x2F;&#x2F;equitablegrowth.org&#x2F;u-s-income-and-wealth-inequality...> In states like Texas minimum wage is still $7.25&#x2F;hr and many places pay just that.> How do you reconcile your numbers with that?&#x27;Assistant Commissioner for Regional Operations Stanley W. Suchman noted that the 196,000 workers earning the federal minimum wage or less made up 3.1 percent of all hourly paid workers in the state. Nationwide, those earning the federal minimum or less accounted for 2.3 percent of the hourly paid workforce.&#x27;And that&#x27;s only those paid hourly, not salaried. reply mannerheim 18 hours agorootparentprevThat&#x27;s all very fine. But it ends the same way every time. reply Dylan16807 17 hours agorootparentprevI don&#x27;t see how \"they have increased prices more than inflation\" is blaming them for inflation.Though that assumes the \"everything\" in the post is an exaggeration because I think the price of \"everything\" is inflation. reply WalterBright 12 hours agorootparentThe way inflation is measured is debatable. It&#x27;s in the government&#x27;s best interests to measure it in such a way as to make the number as small as possible. reply malfist 19 hours agorootparentprev> Inflation increases profits, too (but not in real dollars).[Citation needed]I find it hard to believe that corporate profits rise exactly proportional or less than the inflation rate. reply myrmidon 18 hours agorootparentJust compare corporate profits before and after Covid, see e.g.https:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;CA.PA&#x2F;financials?p=CA.PANot much of a difference. Certainly nothing that looks outright malicious. reply drawkward 17 hours agorootparentThat&#x27;s Carrefour, not the product manufacturers. In fact, the evidence you present is completely consistent with Carrefour&#x27;s assertion that they have been doing what they can to absorb the price increases taken by the product manufacturers. reply WalterBright 12 hours agorootparentprevProfit margins stay roughly the same for the last century. reply BlueTemplar 19 hours agoparentprevWell, you can (and should!) check the (mandatory) price&#x2F;mass or price&#x2F;volume, but of course there are very smart people being paid a lot to design the packaging so that it&#x27;s sufficiently compelling for you to still put a higher value on the product... reply hedora 19 hours agorootparentExpecting people to memorize the per-unit price of everything they buy and compare week to week is unrealistic.Also, at least in the US, the price&#x2F;weight for the same type of item is often in different units. ($&#x2F;oz for brand A; $&#x2F;lb for brand B, etc) reply Symbiote 19 hours agorootparentThe EU does have some rules about this [1], \"The unit price shall refer to a quantity declared in accordance with national and Community provisions\", but I&#x27;ve still seen similar products priced per 100g and a different brand priced per \"item\".[1] https:&#x2F;&#x2F;commission.europa.eu&#x2F;law&#x2F;law-topic&#x2F;consumer-protecti... reply nebula8804 18 hours agorootparentprevSounds like a great opportunity for an AR app that can compute and overlay differences in your field of view. It would be cool to run this on the Apple Goggles. (I am not ready to see people walking around wearing those things in real life). reply dustincoates 18 hours agorootparentprevThis isn&#x27;t my experience, so I went looking and found this:> Uniform Unit Pricing Regulations apply only when stores voluntarily provide unit pricing information. The unit of measure chosen must be consistent across like items within the category.So if a store offers unit pricing it must be consistent within a category.https:&#x2F;&#x2F;www.nist.gov&#x2F;pml&#x2F;owm&#x2F;laws-and-regulations&#x2F;us-retail-... reply hedora 14 hours agorootparentStrange. I&#x27;ve never seen a store in California (which they list as requiring such things) that uses consistent units of measure.Too bad there&#x27;s not an obvious way to report violations. reply iteria 19 hours agorootparentprevI don&#x27;t think I&#x27;ve ever seen the price per unit unit not be the across brands of the same packaging type. Now this does get dicy for individual wrapped things, but outside of that everything uses the same unit in the same range.Even still, this is not a reasonable approach to tracking shrinkflation because I know I don&#x27;t keep a running log of prices from week to week. I do sometimes notice package shrinking, but only because I buy weekly. If I wad a bulk buyer I&#x27;m not sure I&#x27;d notice as fast reply kvdveer 19 hours agorootparentprevHere in the Netherlands, all units are metric (g, ml, g, kg). Liquid products are advertised by volume, but is they&#x27;re watery (ie. most products), you can just assume litres are kilograms.Fatty or very sugary liquid products (e.g. cream, syrup) are the only things that can&#x27;t easily be compared to kg price. I&#x27;ve only seen those advertised by volume, so they can still be compared to their peers. reply darrylb42 16 hours agorootparentprevOr in Canada, BC. Things like meat can be priced in $&#x2F;lb or $&#x2F;100g in the same cabinet. Makes the mental math tricky and you can think something is cheap when it is not. reply flir 19 hours agorootparentprevSame in the UK, except 10g&#x2F;100g&#x2F;1000g so it&#x27;s a bit easier to work out. Still an antipattern though. reply malfist 19 hours agorootparentprevIt&#x27;s even worse when the products you are trying to compare unit prices for when one of them shares a volume unit price and the other a weight unit price and another is in counts.These things should really be standardized. reply BlueTemplar 11 hours agorootparentprevWell, after a while I do roughly memorize it for the things I buy the most, don&#x27;t you roughly remember the non-per-unit price if that is what you are looking at ?But that was not my point, the price per unit is to compare similar products with each other in the span of a minute or so.Because if they are ALL going up (or down), then there are clearly external factors to that price change. At worst it&#x27;s the fault of the supermarket (and here remembering the rough price&#x2F;unit comes handy, for comparisons in others), or an issue with a monopoly&#x2F;cartel collusion, in which case hopefully consumer associations are going to start whistleblowing, leading to government handing out punishments. reply badcppdev 18 hours agorootparentprevAnd then I find myself checking the packaging of a frozen pizza (please don&#x27;t judge me). There is a small plastic window on the front and I can tell that there is a pizza inside and from tipping it I can tell that the pizza is smaller than the box. The label says that the pizza is 500g (20 oz) which is totally useless to me because I can&#x27;t remember if the box said 500, 550, or 600g when I bought it 3 months ago. reply stilley2 19 hours agorootparentprevBut as a consumer I don&#x27;t want to have to check the price&#x2F;mass in every product everything I shop, especially if I&#x27;m buying the same brand every week. reply rhaway84773 19 hours agorootparentprevThe price per unit in US groceries is ridiculous.You will literally have 3 packages of soda all of the same size listing the price per unit in completely different units. Some in ml, some in oz, some in pts. reply flaviut 19 hours agorootparentI&#x27;ve made a userscript for this! https:&#x2F;&#x2F;greasyfork.org&#x2F;en&#x2F;scripts&#x2F;429539-unit-prices-on-krog...Kroger doesn&#x27;t publish unit prices on their websites, but they do publish quantities. They&#x27;ll sometimes mix the units up (L, floz, see mapUnit() https:&#x2F;&#x2F;greasyfork.org&#x2F;en&#x2F;scripts&#x2F;429539-unit-prices-on-krog...), but generally they&#x27;re OK.The script will normalize everything to a specific metric unit & present a unit price on the page.Why stores have this horrible setup? Probably weaponized incompetence. Would be nice to have the FTC step in with some regulation. reply thfuran 19 hours agorootparentprevWe don&#x27;t even have standardization on the nutrition labels. The serving size is different for everything. reply cobbzilla 19 hours agorootparentI had a bag of salad croutons that measured a serving as “2 Tablespoons” — are they expecting me to crush the croutons to measure a serving? Or just “eyeball” it to convert rectangular things into hemispherical things? reply hansvm 17 hours agorootparentprevIt&#x27;s worse than that. The serving size changes the resulting label. A lot of the high-protein breads have the same composition and are sliced slightly thicker to hit the 3.5g mark so they can round up to 4g per slice and appear to be more protein rich in composition. reply thfuran 17 hours agorootparentI&#x27;ve seen oil with zero calories and over 1,500 servings per container. reply nebula8804 18 hours agorootparentprevJust be happy they haven&#x27;t switched over to butts (yet):https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Butt_(unit)Maybe we&#x27;ll be going back to hogsheads (or more likely a rundlet) though:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hogshead reply oh_sigh 18 hours agorootparentprevIt seems extremely burdensome to do that every time you go shopping. Also, it requires people to remember the unit price of the same product across multiple trips - whereas most people who do check the unit price do so in a side by side comparison with a different brand of the same type of product. reply mytailorisrich 19 hours agoparentprevThis is a cynical move because, as the article mentions right at the top, this is just to apply pressure on suppliers before contracts renegotiations. Tesco in the Uk does not sort of stunt as well and for the same reasons.> In the UK many people rely on Food banks and parents skip meals to feed their children.A small minority, not &#x27;many&#x27;... reply tyingq 19 hours agorootparentIf this[1] is correct, one part stands out to me:\"2.1 million people in the UK lived in household which had used a food bank in the previous 12 months, a rate of 3%. This includes 6% of children, 3% of working-age adults, and around 0% of pensioners.\"6% of children feels not great, though other stats say the US is much worse, with 6+% of all households, not just children...and I&#x27;ve seen higher estimates.[1] https:&#x2F;&#x2F;commonslibrary.parliament.uk&#x2F;research-briefings&#x2F;cbp-... reply mytailorisrich 17 hours agorootparentThat&#x27;s a small minority that has used a food bank at least once in 12 months. The number of people &#x27;relying&#x27; on them has to be even lower. We also can&#x27;t discount that some people could have bought food but chose the food bank instead because it is free.My point was that writing &#x27;many&#x27; suggests something common and widespread like if there were breadlines everywhere. It is not (but The Guardian likes to dramatise on this).In fact, I suspect that poorer people in the UK have a much higher chance of being obese than of being actually hungry. reply mholm 19 hours agorootparentprevA small minority of the UK can still be hundreds of thousands, even millions of people. Don&#x27;t underestimate volume just because the % is low. reply mytailorisrich 17 hours agorootparentA small minority is a small minority whatever the absolute number and that is not &#x27;many&#x27;, which suggests something common and widespread.Also, using a food bank at least once and &#x27;relying&#x27; on them are not the same thing. reply bearmode 19 hours agorootparentprev3 million people used them between last year and this year. About 4.5% of the population. That&#x27;s a lot of people. reply programmertote 19 hours agoprevThe worse combo is shrinkflation with significantly increased price. I used to buy Arm and Hammer detergent (250 FL OZ) from Costco for ~$11 about a year ago. Last week, I went to Costco and saw that they have reduced the size of the container (in a very subtle way so it is hard to notice) with 200 FL OZ and charges $14.89. That is like double rip-off.My salary did not increase 35% between this and last year. For Church & Dwight (Arm and Hammer brand manufacturer) to not only increase the price by at least 35% with shrinkflation, I wonder where the extra profit are going toward.When I just immigrated 20 years ago, I used to be in awe at the size of commodities and food portions in the US. Nowadays, things are shrinking noticeably and eventually, stuff bought in the US would look just the same in terms of size as what&#x27;s available in Burma (Myanmar), which is my home country. That observation makes me feel like the US (and probably all of the affluent western nations) is approaching the end of the era of abundance, and life for the future generation would be tougher. Pretty sad&#x2F;concerning to think about it. reply mikrl 19 hours agoparentI bought a jar of some new Nutella type spread and while the lid is round, the jar footprint is lozenge shaped.From the front it looks like a normal jar, from the side I actually started laughing at this skinny little thing with a giant overhanging lid. reply Dunedan 18 hours agorootparentI had a similar experience recently. The jar looked the same, but as it turned out they simply used significantly thicker glass to hide the weight difference caused by the reduced content. reply mgkimsal 18 hours agoparentprev> For Church & Dwight (Arm and Hammer brand manufacturer) to not only increase the price by at least 35% with shrinkflation, I wonder where the extra profit are going toward.That assumes there&#x27;s extra profits. They also have to pay for materials, labor, etc. which have also gone up recently. Perhaps they&#x27;re making the same profit (amount or percent) they were 4 years ago at that size&#x2F;price? reply programmertote 18 hours agorootparentYour question is very legit. I have been researching on that too and the best I found is this: https:&#x2F;&#x2F;finbox.com&#x2F;NYSE:CHD&#x2F;explorer&#x2F;gp_marginBUT, we don&#x27;t really know how these gross margins are actually calculated (meaning, the reporting is all done by these corporations with very complicated accounting methodologies). All things considered though, 41.9% gross profit margin for 2022 is still pretty good. With the supply chain easing, I am very curious to see how that profit margin looks like in 2023.My totally unsubstantiated guess is like this: labor probably got a 10% bump since COVID; raw materials and oil&#x2F;gas (for transportation) probably also had like 10-20%% bump in total. Then the remaining 5% (from 35% increase in just the price, NOT including the profit from shrinking) is probably going toward the extra coffers of the corporations. reply ericpauley 18 hours agoparentprevFYI on the detergent point: the new bottle may be more concentrated. I saw this too but when I compared the two bottles closely the dose size was also reduced (and I suppose the detergent more concentred, though hard to verify). reply programmertote 18 hours agorootparentThe old one is 195 loads and the new one is *supposedly* 200 loads. I never really paid attention to those load numbers because in the end, I just use the measure cup (that comes with the container).Thanks for raising this subtle point though. :) reply ericpauley 18 hours agorootparentTurns out (in my case) both cups were identical, but the old bottle said to use the B line and the new one said to use the A line.Clearly I spent far too much time overanalyzing this… reply canucker2016 14 hours agoparentprevEven worse is the shrinkflation with stealth price increase.Haagen Dazs recently reduced the size of their ice cream containers from 500ml to 450 ml while keeping the price the same.Fine. They succumbed to shrinkflation.But it&#x27;s only at the checkout counter where you get hit with the stealth price increase.In Canada, they tax individual items of certain foods but don&#x27;t tax family-size portions of those foods.It turns out that 500ml is the limit for family-sized portion of ice cream container. Buying less than 500ml results in the store charging tax on the item (Ontario HST is 13%).So Haagen Dazs is getting a bit more and the government gets some where before they got nothing.see https:&#x2F;&#x2F;nationalpost.com&#x2F;news&#x2F;canada&#x2F;shrinkflation-canada-ta... reply transcriptase 19 hours agoprevIt’s incredible to me that MBAs are still able to pitch “what if we made the product deceptively smaller but charged the same price?”, and don’t get thrown out a window. As if that’s a novel sustainable long-term strategy in CPG. reply Cerium 19 hours agoparentDon&#x27;t worry, in a few months they will make a package that says \"Now with 20% more\". reply speedgoose 19 hours agorootparentThe barely legal \"20% free\" packages.https:&#x2F;&#x2F;www.cdiscount.com&#x2F;au-quotidien&#x2F;alimentaire&#x2F;nestle-cr... reply TeaDude 19 hours agorootparentYou&#x27;ve just given me a wonderful flashback to Adam and Joe. (Hopefully not region locked by Channel 4!)https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=JWtQW8vAslc reply BlueTemplar 19 hours agorootparentprevLook what you did, the hn hug of death, and now they are sold out ! :( reply darrylb42 16 hours agorootparentprevNow with 20% more**** than a box with 20%less no change in package size required. This was on a thing of Oldspice antiperspirants. reply wredue 19 hours agorootparentprevIn Canada, they call it a “Party Size” or a “Family Size” box. reply Foobar8568 19 hours agorootparentWe often see larger packages being more expensive per unit as the volume of sales is lower. reply passwordoops 19 hours agorootparentprevAnd bump up the prices 15% reply pjmorris 19 hours agoparentprevThey&#x27;re not pitching to consumers in the grocery store aisles, they&#x27;re pitching to corporate executives in board rooms. The world looks different in each of these places. reply julienfr112 19 hours agoparentprevMBA people can also be shrinked : We only need 80% of you sales people, with chatgpt and co ... reply nebula8804 18 hours agorootparentThe C suite and MBAs will be the last to be outsourced to ChatGPT. What we need is more new companies entering the fray. The problem is why would you enter this industry with its terrible margins when you could start a tech company instead? reply mrguyorama 19 hours agoparentprevWhat are you talking about though, it absolutely is \"sustainable\", and businesses have been doing it at least a couple decades, so why would they stop? It makes the profit line go up, which is all that matters. reply the_other 19 hours agorootparent> It makes the profit line go up, which is all that matters.I think \"all that matters\" needs qualifying to \"all that matters to some people\". reply hotsauceror 19 hours agorootparentIt is \"all that matters\" to the people who are \"all who matter\". reply mrguyorama 16 hours agorootparentprevIt&#x27;s all that matters to the people hiring CEOs and on their boards. reply mortenjorck 19 hours agoprevA brand of laundry detergent I use recently decreased the size of its 36oz bottle to 28oz. The kicker, however, is the approximate number of loads listed on the bottle changed from 27… to 28. The instructions on the back now recommend filling the cap to a lower bar for “medium” loads.I’ve been meaning to write to the manufacturer to ask if they’ve quietly changed their formulation to something more concentrated, though I have a pretty good idea of the canned response I&#x27;d receive. reply secretsatan 19 hours agoparentI recently discovered detergents and powders regularly overstate how much is required for a wash, and it even leads to worse results, I&#x27;m normally sceptical (or just ignorant) of such articles but I halved how much I used and it seemed to be pretty much true for day to day washing (Don&#x27;t know about massively dirty clothes, but talking weekly wash here)https:&#x2F;&#x2F;www.nytimes.com&#x2F;wirecutter&#x2F;blog&#x2F;stop-using-so-much-l... reply orev 17 hours agorootparentNot to defend the recommendation as they clearly have an interest in trying to get people to use as much as possible, there is a potentially valid reason for this, which is that it depends on the type of water you have.Water from a municipal supply is generally well-treated and usually soft, in which case you can get by using less detergent. However with hard water (often sourced from wells), more detergent is needed to get the same cleaning effect.Maybe they could try to explain this, or maybe they just ignore it for the sake of simplicity (of the instructions on the bottle), and the increased sales is just a nice side effect. reply malfist 18 hours agorootparentprevI learned this a long time ago when talking with some of my appliance repair friends. Lots of washers break because they&#x27;re gummed up with excess soap.I&#x27;ve been running my loads at 1&#x2F;4 or less of the soap recommended by the manufacturer for years and years and I&#x27;ve never had any issues out of my washer, mechanical or clean wise. Once or twice a year, something will need a second wash or spot treatment, but otherwise everything is pristine. reply Ylpertnodi 19 hours agoparentprevWhy keep it a secret? Name and shame. reply mortenjorck 16 hours agorootparentIt&#x27;s Arm & Hammer, though I presume the branding is a more or less interchangeable packaging detail from the other detergent brands produced by CPG giant Church & Dwight. reply whymauri 18 hours agorootparentprevAt this point it feels like most brands are ripping me off; I&#x27;d be more interested in finding out which ones aren&#x27;t, lol.Edit: this is what Carrefour is doing to an extent, but we don&#x27;t have them in the US. reply marcosdumay 18 hours agoparentprevWell, you shouldn&#x27;t be using the recommended amount anyway. It is probably closer to reality now, but still way more than you should use.Personally, I use a bit less than 1&#x2F;3 of the recommended amount of the laundry detergent I buy. It&#x27;s plenty, and maybe it is still too much. reply Symbiote 19 hours agoparentprevI doubt they&#x27;ve have done this quietly, as it gives the opportunity for some greenwashing. \"More concentrated, so less CO₂ used in transport!\" reply Dylan16807 17 hours agorootparentIf it&#x27;s true, and has no downside, then it&#x27;s not greenwashing. reply charles_f 19 hours agoprevThis is great, shrinkflation is one of these disgusting practices that play on the human psyche to trick people.But also carrefour (and large retailers like them) are notorious for abusing their power when buying, and are a large part of the systemic problem. I don&#x27;t know how much this is negotiating technique. reply jakub_g 18 hours agoparentI watched a documentary on this a few weeks ago. In France, there&#x27;s 2 big groups which control outsized % of whole market. They squeeze producers really hard.They have a lot of abusive rules in contracts which are unrealistic. Like, you must deliver your stuff to market X precisely at 2AM, not before not after, and for every minute of delay you pay a large fine. Now, when trying to deliver to N markets during same night, there&#x27;s always delays in some of the places because the recipients in market Z are slow - fines are on the producers.All the extra promos etc in supermarkets (buy 2 get 3) are funded by the producers as well. reply krisoft 19 hours agoparentprev> I don&#x27;t know how much this is negotiating technique.100%. What else would it be? reply fatfingerd 19 hours agorootparentReputation. When you see a different size for the first time at big chains they sometimes are not a change to the manufacturers normal lines.(If you have much faster turn over than other places your customer&#x27;s shop that could also reinforce the perception that you are complicit.) reply monooso 19 hours agorootparentprevIt could be a marketing tactic. reply CptKriechstrom 19 hours agorootparentideally serves as both reply gniv 19 hours agoparentprevI don&#x27;t know anything about them as a corporate citizen, but out of the (many) supermarket chains here in France I like them the best. They are not the cheapest, but the quality&#x2F;price ratio is usually correct and the store branded items are very good. reply charles_f 15 hours agorootparentAs a buyer, they have a reputation to be driving producers to the ground. Their buying power is so large that they can pretty much dictate the costs, which drives all sorts of issues - brankrupting the smaller ones, lowering the quality across the board, forcing them to take shortcuts, cheating, shrinkflating, etc. reply kergonath 17 hours agorootparentprevTheir store brand is good, but their practices with their suppliers are disgusting, just like the others. reply robjan 19 hours agoparentprevThere&#x27;s a general push in supermarkets to move consumers towards own-brand goods as the profit margin is higher. It wouldn&#x27;t surprise me if this was a marketing tactic to push people in this direction. reply Foobar8568 19 hours agorootparentAnd carrefour is among the worst offenders on this topic. reply waihtis 19 hours agoparentprevDoes it matter if the customer benefits? reply jader201 19 hours agorootparentIt’s like Yelp, though.If they’re just wielding power over manufacturers, they also have the power to give into negotiations to remove the labels if manufacturers pay enough.Which means it’s ultimately no longer about benefiting the customers, but squeezing as much as they can from manufacturers, and we end up with only get part of the truth. reply oconnor663 19 hours agorootparentprevI suppose hypothetically if they were murdering their suppliers&#x27; employees then we&#x27;d need to put a stop to that. But otherwise yeah, all the more power to them. reply BlueTemplar 19 hours agorootparentAh, the \"sicilian haircut\" ? reply charles_f 19 hours agorootparentprevIt does, I won&#x27;t applaud Putin if he switches to electric tanks. (not that Carrefour is Putin, but you get the point - a marginal fix from someone who is a nontrivial cause of a problem is not a triumph)This is a good idea, shame drives change, and it&#x27;s good that customers get better information.But also, the customer rarely benefits from large monopolies leveraging their power. Somehow they&#x27;re always the losing bystander in these battles. I&#x27;m suspecting that the real motive is different, and I don&#x27;t know the long term consequences of how they&#x27;re gonna leverage that new negotiation tool. (maybe they won&#x27;t display it if the manufacturer gives them a discount?). And then maybe it&#x27;s just marketing, maybe there&#x27;s no motive, and they want to show they are supportive of their customers. But then once a buyer realizes the tool they have to leverage an extra discount, it may change.Forgive for being suspicious when an actor that has historically always been acting on their own capitalistic interests starts doing something that is not. reply marcosdumay 18 hours agorootparentThat&#x27;s hardly abuse of economical power. Wake me up if they decide to remove some label due to a negotiation. Otherwise, that&#x27;s the slippery slope fallacy, that is false on practice about as often as it&#x27;s true. reply charles_f 15 hours agorootparentIt is not the slippery slope fallacy, it&#x27;s the proposition that everything that can be used for nefarious purposes eventually will. Someone who repeatedly abuses their economical power doesn&#x27;t deserve the benefit of the doubt, is my point. reply marcosdumay 13 hours agorootparentThey are doing a good thing, but it&#x27;s bad because that good thing may allow them to do something bad later?Sorry, but I&#x27;ll ask for them to be punished when they try to do the bad thing. Not earlier.They can do nefarious things whenever they want. They don&#x27;t need to normalize a good thing first, there are all kinds of anticompetitive actions they can do right now without complex scheming. (And yeah, they constantly do many of those, but still, without any complex scheming.) replycoldtea 19 hours agoprevWe need laws to require special labelling with the price per net pound or price per net kiloggram clearly shown, and the previous price. Something like: $2.99&#x2F;Kg (since 18&#x2F;09&#x2F;2023) $2.79&#x2F;Kg (previous price) reply FireBeyond 19 hours agoparentSafeway is somewhat insidious with things like this. They&#x27;ll have a relative price (per pound&#x2F;oz) for one size of an item, and then for the same item, different size, they&#x27;ll use a different metric (per packet&#x2F;slice, etc.) to make them not (easily) directly comparable. reply tivert 19 hours agorootparent> Safeway is somewhat insidious with things like this. They&#x27;ll have a relative price (per pound&#x2F;oz) for one size of an item, and then for the same item, different size, they&#x27;ll use a different metric (per packet&#x2F;slice, etc.) to make them not (easily) directly comparable.Unless there is a really strong pattern, I think that might be a situation were you shouldn&#x27;t assume malice when stupidity will do.I think it&#x27;s quite likely they get the data from that from some feed who&#x27;s ultimate source (or sources!) is someone keying in whatever&#x27;s most convenient without any organizational consistency controls between items.IIRC, every package has to have a weight&#x2F;volume measure, but that doesn&#x27;t make the most sense as the \"unit\" for many products, and there&#x27;s even room for legitimate disagreement on what the right measure should be (e.g. should you list a package of sliced cheese by the slice, to use the unit the consumer is probably thinking in, or by the oz, to make it comparable to non-sliced cheese). reply paulmd 19 hours agorootparentSuch ”incompetence, not malice” errors can be trivially solved by defaulting to the consumer receiving a discount on the item in the event of variations in how the items on the shelves are labeled. Boom, you now have an army of validation specialists going around checking the consistency of your labeling. A very low-cost solution if your errors are truly good-faith and infrequent, you are paying pennies per person-hour!Some states offer a “scanner bounty” when items transitioned from sticker labeling to scanner pricing with only shelf tags, because vendors would often not update the shelf tags or item tags appropriately when they changed the scanner database. Find an error and receive 10x the difference up to $5.https:&#x2F;&#x2F;www.michigan.gov&#x2F;ag&#x2F;consumer-protection&#x2F;consumer-ale...You will rapidly find stores becoming less incompetent overnight once they have an incentive to be. It’s not that they’re not capable of being competent, there just isn’t a legal requirement or a market incentive to be competent. A law without a penalty for (knowing or un-knowing) noncompliance is just a polite request.They are profiting and thriving off the tendency for good-natured people to adopt the “incompetence, not malice” mindset and then accept that as a normal standard of behavior. After all, what can be done? Sho ga nai. reply hedora 19 hours agorootparentprevMost stores in the US do this, and have for decades. It is definitely intentional.Presumably the people that write the integrations shop in grocery stores, and have noticed the issue. reply InitialLastName 15 hours agorootparentYou would think so; on the other hand, I just met someone who works for the search team of a major search engine but hadn&#x27;t noticed that their results listings had turned to garbage over the last few years. reply rhaway84773 19 hours agorootparentprevThese companies negotiate everything, including where the boxes will be located on the shelves, the angles they will be placed at, which competitors will be allowed, the pricing schemes, etc. They will never go “well for the price per unit, let’s just go with whatever random unit our internal systems spit out”.Its extremely convenient that the mandated data that helps customers cut through the millions they spend on marketing and pricing schemes is the one that is completely uncared for. reply dwighttk 19 hours agorootparentprevKroger&#x2F;HarrisTeeter too…It is definitely malice because they use every unit imaginable to avoid allowing you to compare within an item type (kg, lbs, oz, g, fl oz, “unit” (where unit = package)) reply coldtea 19 hours agorootparentNothing that a law to stick to single unit can&#x27;t fix! reply dwighttk 18 hours agorootparentYeah I’m guessing there must be a law about putting the unit prices already or else why would they even have them, so it seems an update might be useful.I can remember using them like 10 years ago… reply dwighttk 18 hours agorootparentprevThinking about it a little more I bet it is very difficult to legally define a product type. reply Dylan16807 17 hours agorootparentThey manage to do it for sales tax. replynicolas_t 19 hours agoparentprevIn France, at least the law requires showing the current price per kilogram. So what Carrefour is doing is highlighting that this has changed compared to the previous price. reply morsch 19 hours agorootparentThis has been harmonized across the EU for, I think, 25 years.https:&#x2F;&#x2F;eur-lex.europa.eu&#x2F;legal-content&#x2F;EN&#x2F;TXT&#x2F;HTML&#x2F;?uri=CEL... reply rpastuszak 19 hours agoparentprevI think the former is the default in the EU&#x2F;UK. I do find it really helpful, especially when comparing different brands or sizes.It also allowed me to spot some shady pricing practices, the recent one: dishwasher tablets are 10% cheaper when buying a bunch of smaller packages, rather than a big one. I still buy the latter as it results in less waste but it pisses me off to know how unnecessary and bad for the environment these practices are. reply BlueTemplar 19 hours agorootparentBe careful to double check, in my experience, most of the time it&#x27;s a labeling mistake... reply rpastuszak 18 hours agorootparentnope, not in that case! reply AlexandrB 19 hours agoparentprevOntario (and maybe all of Canada?) has the former. Adding the previous price would be nice, but I wonder if it can be games by changing prices frequently. reply patall 19 hours agorootparentIn EU, by law you are supposed to show the reference price (lowest price in last 30 days pre reduction) in small print. Different implementations in different countries but, at least for me, it does what is supposed to do. reply coldtea 19 hours agorootparentprev>but I wonder if it can be games by changing prices frequently.Could change it to \"show last year of price info\". In fact, make it a lineplot (with standardized design). reply notpublic 19 hours agorootparentprevIn US as well.. reply vhcr 19 hours agoparentprevOr a graph of the price per unit over the last 1-3 years.They would probably change the SKU so the comparison is harder. reply coldtea 19 hours agorootparentThat would manifest as a \"price per unit\" starting only recently, so immediately appear sus if you were buying the same product for a while.Forcing an SKU change to have to translate to a \"clearly labeled name change as well\" would also help. reply unsupp0rted 19 hours agoparentprevI get annoyed for similar reasons when nutritional information on a product is “per serving” and the serving size is arbitrary.Oh, it’s only 4 grams of sugar per serving. Oh, a serving is 1 bite. reply hedora 19 hours agorootparentIn theory, the serving side is supposed to be standard across brands and package sizes, so that you can compare brands.I wish they would require a second column that is per ounce (for everything) so you could compare different foods.Also, they should have to write everything to two significant figures. There are massive rounding errors on most labels. reply coldtea 19 hours agorootparentprevRequired viewing:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=YRMcZhqlVpEhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=grc_pFJG8T0 reply Dylan16807 17 hours agorootparentprev2.5 servings per container. reply severino 17 hours agoparentprevSome would just raise it to $2.98 on September 17th. reply hotnfresh 19 hours agoparentprevSome US states do this. I think Connecticut does, for one. reply matthewfelgate 19 hours agoparentprevLots of UK supermarkets like Tesco, Sainsburys have Price&#x2F;Kg for different packages and products.It makes comparing between products much easier. reply klondike_klive 19 hours agorootparentEspecially that all-important \"price per 100 sheets\" for toilet paper! reply guyzyl 2 hours agoprevIn Israel there’s actually a law to protect consumers from such cases.It requires food manufacturers to add a notice on the package if they decreased the amount of content inside without making major changes to the look of the packaging. reply hnarn 19 hours agoprevI don’t know what the correct term is in English but in my country, “comparative pricing” is mandatory, so when you’re buying coffee for example there’s a secondary price listed that tells you what the cost is per kilogram or whatever other unit makes sense.For me this already solves the problem, because what I really care about isn’t whether I get 500g or 400g of coffee, I care about the real price compared to the other options on the shelf. reply Onawa 19 hours agoparentThis needs to be regulated properly in the US, because the stores constantly mess with the units for similar items, making it much more difficult to compare at a glance. You&#x27;ll see a random assortment of measurements for the same product, for example my favorite is shopping for toilet paper and paper towels. You&#x27;ll see everything from &#x2F;sheet, &#x2F;roll, and the best when they just consider the package an entire &#x27;unit&#x27;... reply tyingq 19 hours agoparentprevYou do miss though, those situations where every supplier took advantage of inflation to stack extra margin on. Seeing that diff to the last price is helpful. reply Gigachad 11 hours agorootparentHelpful in what way? The prices 6 months ago are no longer available so how does it help to see them? reply tyingq 11 hours agorootparentCan&#x27;t tell if you&#x27;re serious. People on a budget want to know which line item increases are driving the overspend in the \"grocery\" category. So they can take some action to counteract it. Source that item elsewhere, consider store brands for that item, do without that item, etc. reply BlueTemplar 7 hours agorootparentprevThis either means that they have a cartel (which is illegal), or they effectively had no choice for some reason or another. (\"Inflation\" is such a nebulous concept...) reply claviola 19 hours agoprevThis has been going on in Brazil for so long that for two years now companies must, by law, disclose any reduction in weight.Examples: https:&#x2F;&#x2F;i0.wp.com&#x2F;sfnoticias.com.br&#x2F;wp-content&#x2F;uploads&#x2F;2022&#x2F;... reply WirelessGigabit 18 hours agoparentIs Brazil also the country where you must disclose when you change something in the recipe of the product? reply 108 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Carrefour, a French supermarket chain, has introduced labels warning shoppers of \"shrinkflation,\" a situation where manufacturers reduce pack sizes rather than raising prices.",
      "It has implemented this strategy to pressure major suppliers like Nestlé, PepsiCo, and Unilever before contract negotiations. Carrefour identified 26 products to exhibit this practice, with plans for similar labeling if the suppliers don't agree to price cuts.",
      "Carrefour's CEO, Alexandre Bompard, critiqued these companies for not assisting in lowering prices, considering the drop in raw material costs."
    ],
    "commentSummary": [
      "Major supermarket chain Carrefour is tagging products impacted by \"shrinkflation\", a phenomenon where packaging sizes are diminished while prices stay constant, to highlight the brands responsible.",
      "The ongoing debate about inflation in Europe involves discussions around whether it's a result of companies inflating profit margins or due to other elements like supply chain complications.",
      "The discourse extends to price gouging in natural disasters, the effect of legislation to standardize packaging sizes, pricing strategies, income inequality, and the necessity for clear unit pricing on products."
    ],
    "points": 470,
    "commentCount": 359,
    "retryCount": 0,
    "time": 1694785487
  },
  {
    "id": 37521710,
    "title": "TikTok fined €345M for breaking EU data law on children’s accounts",
    "originLink": "https://www.theguardian.com/technology/2023/sep/15/tiktok-fined-345m-for-breaking-eu-data-law-on-childrens-accounts",
    "originBody": "Skip to main content Skip to navigation Skip to navigation Print subscriptions Sign in Search jobs Search UK edition The Guardian - Back to home Support the Guardian Fund independent journalism with £5 per month Support us News Opinion Sport Culture Lifestyle Show More World Europe US Americas Asia Australia Middle East Africa Inequality Global development The Irish Data Protection Commission said users aged between 13 and 17 were steered through the sign-up process in a way that set their accounts to public. Photograph: Omar Marques/SOPA Images/Shutterstock TikTok TikTok fined €345m for breaking EU data law on children’s accounts Irish data regulator says platform put 13- to 17-year-old users’ accounts on default public setting, among other breaches Dan Milmo Global technology editor Fri 15 Sep 2023 13.00 BST TikTok has been fined €345m (£296m) for breaking EU data law in its handling of children’s accounts, including failing to shield underage users’ content from public view. The Irish data watchdog, which regulates TikTok across the EU, said the Chinese-owned video app had committed multiple breaches of GDPR rules. It found TikTok had contravened GDPR by placing child users’ accounts on a public setting by default; failing to supply transparent information to child users; allowing an adult accessing a child’s account on the “family pairing” setting to enable direct messaging for over-16s; and not properly taking into account the risks posed to under-13s on the platform who were placed on a public setting. The Irish Data Protection Commission (DPC) said users aged between 13 and 17 were steered through the sign-up process in a way that resulted in their accounts being set to public – meaning anyone can see an account’s content or comment on it – by default. It also found that the “family pairing” scheme, which gives an adult control over a child’s account settings, did not check whether the adult “paired” with the child user was a parent or guardian. TikTok under investigation over child data use Read more The DPC ruled that TikTok, which has a minimum user age of 13, did not properly take into account the risk posed to underage users who gained access to the platform. It said the public-setting-by-default process allowed anyone to “view social media content posted by those users”. The Duet and Stitch features, which allow users to combine their content with other TikTokers, were also enabled by default for under-17s. However, the DPC found there had been no infringement of GDPR in terms of its methods for verifying users’ ages. The DPC decision comes after TikTok was fined £12.7m in April by the UK data regulator for illegally processing the data of 1.4 million children under 13 who were using its platform without parental consent. The information commissioner said TikTok had done “very little, if anything” to check who was using the platform. TikTok said the investigation looked at the company’s privacy setup between 31 July and 31 December 2020 and said it had addressed the problems raised by the inquiry. All existing and new TikTok accounts for 13- to 15-year-olds have been set to private – meaning only people approved by the user can view their content – by default since 2021. skip past newsletter promotion Sign up to Business Today Free daily newsletter Get set for the working day – we'll point you to all the business news and analysis you need every morning Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion TikTok said: “We respectfully disagree with the decision, particularly the level of the fine imposed. The DPC’s criticisms are focused on features and settings that were in place three years ago, and that we made changes to well before the investigation even began, such as setting all under-16 accounts to private by default.” The DPC also acknowledged it had been overruled by the European Data Protection Board, a body comprising EU member state data and privacy regulators, on some aspects of its decision. This meant it had to include a proposed finding by the German regulator that the use of “dark patterns” – the term for deceptive website and app designs that steer users into certain behaviours or making particular choices – breached a GDPR provision on fair processing of personal data. Explore more on these topics TikTok Social media Data protection GDPR Digital media Children Children's tech news Reuse this content Most viewed World Europe US Americas Asia Australia Middle East Africa Inequality Global development News Opinion Sport Culture Lifestyle Original reporting and incisive analysis, direct from the Guardian every morning Sign up for our email About us Help Complaints & corrections SecureDrop Work for us Privacy policy Cookie policy Terms & conditions Contact us All topics All writers Modern Slavery Act Digital newspaper archive Facebook YouTube Instagram LinkedIn Twitter Newsletters Advertise with us Guardian Labs Search jobs Patrons Back to top © 2023 Guardian News & Media Limited or its affiliated companies. All rights reserved. (modern)",
    "commentLink": "https://news.ycombinator.com/item?id=37521710",
    "commentBody": "TikTok fined €345M for breaking EU data law on children’s accountsHacker NewspastloginTikTok fined €345M for breaking EU data law on children’s accounts (theguardian.com) 367 points by robin_reala 22 hours ago| hidepastfavorite298 comments Footnote7341 14 hours agoWe&#x27;re going to have state I.D to use any popular website alongside remote attestation and you guys are cheering us along the path there with cases like this reply parl_match 13 hours agoparentAt this point, maybe we should reduce anonymization? We&#x27;ve had this idea since the 90s that an anonymous internet with signal amplification is a net good, but that&#x27;s been turning out to be less and less true. If you want to self publish anonymously, you are not entitled to use of one of the big 5 platforms.Maybe this causes fragmentation of large platforms, that&#x27;d also be a net good imo. reply mpalmer 13 hours agorootparentYou can&#x27;t really conclude that de-anonymization is good just by asserting that the status quo is bad. One has to make the positive case for de-anonymization on privately owned platforms. What are the trade-offs?Society certainly didn&#x27;t anticipate a lot of the drawbacks of anonymous presence. reply 2OEH8eoCRo0 13 hours agorootparentWhy do we automatically assume that anonymization is good? Where are the anonymous town squares? reply mpalmer 9 hours agorootparentI dunno, I was pretty careful not to assume that in my comment.The town square metaphor is really not a great one for the internet. You don&#x27;t run nearly as high a risk of getting doxxed or swatted for speaking your mind in a physical public place.And if the unspoken suggestion is that anonymous doxxing would be impossible or too costly&#x2F;risky in a hypothetical de-anonymized world, I&#x27;d call BS. Even if it worked, that would require some kind of \"panopticon internet\". Sounds bad... reply roncesvalles 8 hours agorootparentAlso, the town square is ephemeral. Sure, maybe it&#x27;s written down somewhere, heck maybe the local scribe even publishes it in the next day&#x27;s paper. But it won&#x27;t show up 7 years later as the third Google search result when someone searches your name.You either need the right to be forgotten, or the right to be anonymous. reply johnfernow 12 hours agorootparentprevI guess in theory a government could strongly guarantee freedom of speech while not guaranteeing anonymity — you could say whatever you want, but you couldn&#x27;t do so anonymously. I suppose until recently in history there was a limited number of methods of making public messages anonymously.I think Internet anonymity has some benefits though: it&#x27;s certainly helpful for whistleblowers revealing crimes committed by a company, government or other organization. While you could in theory still drop folders containing documents or a USB drive to different news organizations, with how widespread CCTVs are, so I think that path may become more difficult. In countries with oppressive regimes, that&#x27;s even less of an option.I&#x27;m also not sure that the lack of anonymity is a sure-fire way to improve public discourse: just look at Facebook comments (which are rarely anonymous.)As you mention, perhaps anonymity could be allowed on the Internet, but not on the big 5 platforms — that could be a balancing act between chaos and oppression.Though, while a policy like that might be a net good for someplace like the EU, the precedent of requiring government IDs for Facebook etc. could set a dangerous precedent for places that are less free. Not every country is a full-on liberal democracy OR an authoritarian state where Facebook etc. is outright banned — there are places in-between, where the government oppresses people but still has elections and some degree of dissent is permitted. It&#x27;s in those places that I see government IDs being required to post on major platforms being a major issue. Being able to share instances of government oppression on major platforms is crucial for those places, but if the identity of those sharing it is revealed, then fewer people may speak up and share such instances.It&#x27;s a complex issue to say the least. reply paulddraper 9 hours agorootparentprevI&#x27;m sorry, what?Wouldn&#x27;t whatever \"signal amplification\" downsides happen just as much with decentralized services reply ana_winters 11 hours agorootparentprevYou would do well to remember why anonymization is necessary. reply turquoisevar 4 hours agoparentprevHave you read the article?This isn’t a case of “oops we didn’t know the age”, this is about accounts that had an underage DOB set. reply cmilton 13 hours agoparentprevThe state cured my porn habit with this method. reply gdprwhat 16 hours agoprev> It also found that the “family pairing” scheme, which gives an adult control over a child’s account settings, did not check whether the adult “paired” with the child user was a parent or guardian.How exactly are TikTok meant to be verify parents? Are other tech companies expected to verify parents? It seems like no one else is being fined for this? reply hwillis 15 hours agoparentInstagram was just fined even more for the same thing.https:&#x2F;&#x2F;techcrunch.com&#x2F;2022&#x2F;09&#x2F;05&#x2F;instagram-gdpr-fine-childr... reply gdprwhat 15 hours agorootparent1. How do regulators expect tech companies to verify the real age of users (without further intrusions of privacy)?2. How do the regulators expect tech companies to verify the parents of child users?3. Do regulators want tech companies to collect every child&#x27;s birth certificate? reply orf 12 hours agorootparentUse one of the many companies in this space to verify the users ID? Or push some development in this space to find a better way?Or like, basically anything except pretending it’s not an issue and externalising the cost + issues onto everyone else while you reap fantastic profits? reply esotericimpl 13 hours agorootparentprev1. How do regulators expect Airlines to verify the real age of users (without further intrusions of privacy)?2. How do the regulators expect Airline companies to verify the parents of child users?3. Do regulators want airlines to collect every child&#x27;s birth certificate?See how silly this sounds when you compare to any other industry?Oh but tech is different! reply TeMPOraL 1 hour agorootparentIndeed. I mean, on the one hand, all that tech is indeed different - but on the other hand, it&#x27;s not the law of physics that it has to exist in a form that makes compliance difficult. A service not existing, or existing in a vastly different form, are options too - options the tech industry doesn&#x27;t want to talk about.And FWIW, it&#x27;s third-generation mobile-first social media platforms we&#x27;re talking about. It&#x27;s hard to make a case they&#x27;re not a huge net negative for society. In any other thread, people would happily agree they shouldn&#x27;t exist in the current form in the first place. replylakomen 21 hours agoprevI was wondering, I&#x27;ve recently picked up Tiktok and on the live streams, despite it saying that you need 1000 followers and be 18 years old, I saw so many kids, live streaming. I was wondering why they didn&#x27;t enforce their own rules. I&#x27;m guessing, too large amount of streamers, but even if you had only one dedicated person, you&#x27;d certainly find enough teens or children live streaming.So this is quite the timely ruling.However why would people between 13 and 18 be prohibited from streaming? If you say \"the lurking perverts\", that argument doesn&#x27;t work for chat control, so why should it work here? It&#x27;s a moot point. Sexual content is not allowed on Tiktok. You can see women in bikinis, but you can see them, even topless, in real life on public beaches too. So what other reason would there be? reply pjc50 19 hours agoparent> why would people between 13 and 18 be prohibited from streaming?The parasocial relationship with an audience, especially a large one, does weird things even to adults. reply jncfhnb 21 hours agoparentprevIn one case you’re seeing a topless woman on the beachIn the other case you have anonymous strangers rewarding children for edging closer to sexual performances reply martin_a 20 hours agorootparentYouTube Shorts are also full of underage kids talking about their life, dancing and whatnot. Does not feel right to me, but I guess it is for YouTube. reply 5045444f 12 hours agorootparentInstagram reels are even worse in this regard. Really, TikTok seems to actually be doing the best to keep kids safe in this space, despite constant criticism to the contrary. reply tgv 17 hours agoparentprevIt has nefast influence on the mind. Children are very susceptible. reply InTheArena 20 hours agoprevThis is a good start, but I&#x27;m going to be very curious to see if EU data law ever starts getting enforced against european companies at scale, as opposed to international companies. reply FirmwareBurner 20 hours agoparentIt does get enforced against European companies, they just don&#x27;t make HN headlines because they&#x27;re not big-tech so nobody here would have heard of them.Also EU companies tend to be more mindful and take data protection very seriously, even before GDPR was a thing, so finding gross offenders is a rare occurrence anyway. reply wincy 20 hours agorootparentIsn’t SAP absolutely massive? Surely they count as big tech.Edit: for anyone wondering SAP has ~110,000 employees worldwide, Google has ~180,000, so comparably mega scale tech company. reply mymac 17 hours agorootparentIf you are aware of SAP breaking the GDPR and it&#x27;s being swept under the carpet or if enforcement is lackluster given the scope of the problem then please supply some evidence. That SAP is large doesn&#x27;t matter, what matters is if they are breaking the law. reply TeMPOraL 1 hour agorootparentprevSAP is the company you go to to help you with potentially GDPR-affected processing. It would be quite a thing if they were doing any kind of non-accidental violation of GDPR. reply izietto 20 hours agorootparentprevSAP isn&#x27;t a social platform, it isn&#x27;t even B2C, so they don&#x27;t really relate to GDPR reply esarbe 19 hours agorootparentThe GDPR applies to all companies, social network platforms or not. It&#x27;s not even about the internet in particular, it&#x27;s about how companies can store and process private information of EU citizens. reply hef19898 19 hours agorootparentSAP is B2B, the vast majoritybof personal data is professional (supplier and customer business contacts) and emoloyee data (payroll and such). Not much to fine here. Also, since SAP as a company isn&#x27;t handling any of that data, SAP isn&#x27;t really affected. reply generic92034 18 hours agorootparent> Also, since SAP as a company isn&#x27;t handling any of that data, SAP isn&#x27;t really affected.I am not sure that is completely correct, considering SAP&#x27;s cloud offerings. reply hef19898 18 hours agorootparentWith EU based servers? Sure, GDPR applies. But so far I didn&#x27;t hear anything about SAP not being compliant. reply generic92034 15 hours agorootparentThat is correct, as far as I know. I was just objecting to SAP not being responsible for any PII data of their customers, in all cases. reply latortuga 15 hours agorootparentprevI don&#x27;t think the location of servers is relevant to GDPR. It&#x27;s about storing and processing data of citizens of any EU member country. reply hef19898 14 hours agorootparentServer location matters a lot. reply throwaway74902 18 hours agorootparentprevIf I run my app on Azure, is Microsoft responsible for me breaking GDPR?SAP runs your instance, but isn&#x27;t responsible for what you do with it. reply generic92034 16 hours agorootparenthttps:&#x2F;&#x2F;www.sap.com&#x2F;about&#x2F;trust-center&#x2F;data-privacy.html#act... reply adra 17 hours agorootparentprevIf they&#x27;re deemed a data processors then yes in fact they do need to care about the application of the laws. SAP has user management at least in terms of companys&#x27; own users which will likely have PII. reply hef19898 16 hours agorootparentThe personal data handled by SAP, the ERP system not the company, is very well compartementalized and accessible only need-to-know. Assuming proper user rights policies and roles are in place, but that is on SAPs client, amd not SAP themselves. replyrsynnott 19 hours agorootparentprevSure, but SAP&#x27;s business model doesn&#x27;t depend on doing as much privacy violation as they can get away with (this is basically the business model of all adtech) so they&#x27;re far less likely to fall afoul of the GDPR. The main risk to a company like SAP would be _accidentally_ falling afoul of the law; this tends to happen where companies are grossly negligent in their handling of personal data, and this is then exposed in a major leak. reply esarbe 18 hours agorootparentYou are absolutely correct with this.I&#x27;m absolutely in favor of making it impossible for adtech to make any profit at all as long as they build their business on monetizing user data and exposing their users to all kinds of hazards.I find it funny that so few people here see a problem with that kind of behavior. It&#x27;s as if they expect society to serve the market, instead of the other way around. reply generic92034 14 hours agorootparentTemporarily embarrassed millionaires or not yet exploded adtech unicorns, the same mindset. ;) replyFirmwareBurner 20 hours agorootparentprevWhen did SAP breach GDPR? reply personomas 20 hours agorootparentprevWhich ones? reply _puk 19 hours agorootparenthttps:&#x2F;&#x2F;www.enforcementtracker.com&#x2F;Ironically, currently 2023 entries. replynoirscape 19 hours agoparentprevThey kinda are but most EU companies just avoid it by not really collecting your data to begin with beyond what they need for service operation.At least in my experience, when I deal with a service in the EU, their privacy policy fits on a few A4s, with the important bits frontloaded and written in an easily understandable way. Even most banks don&#x27;t really hide what they collect on you and they explain why they collect it.It&#x27;s only foreign companies that tend to insist on massive privacy policies that border on being incomprehensible and use them to skirt the law. Seriously, just look at Googles privacy page for example - it&#x27;s a single giant page that mostly just restates over and over \"Google may collect info about you\". It&#x27;s unclear what the data is being used for, it&#x27;s extremely reliant on other pages to detail what&#x27;s being used and your average person has probably lost the plot by now.It&#x27;s difficult to put it in any other way, but foreign companies are the ones who think they can get away with breaking the law and make it as difficult as possible to trace what they&#x27;re doing with your data. European companies just tend to actually follow the law. That&#x27;s why all the landmark cases are against foreign tech giants. reply Scarblac 17 hours agorootparentAnd every organization in the EU has had to deal with the fact that this is now law, and had to think what they needed to change to comply with it. All companies, but also e.g. tiny volunteer run organisations (my local scouts group asks for health insurance, medical information, allergies etc of the kids again and again for every camp they go on because they don&#x27;t keep the forms around anymore for the next one like they used to) .It&#x27;s probably different for organisations coming from outside the EU who get EU customers over the Internet. reply johnchristopher 14 hours agorootparent> (my local scouts group asks for health insurance, medical information, allergies etc of the kids again and again for every camp they go on because they don&#x27;t keep the forms around anymore for the next one like they used to) .A lot of people were wrongly influenced by DPD consulting wannabes on their first gig. I have seen small org burn years of contacts they could have kept or easily manage in respect with the provisions of the law. reply scyzoryk_xyz 18 hours agorootparentprevThe boardroom can’t argue about whether or not to steal from the cookie jar when there is no cookie jar to begin with.These are the moments I’m grateful to be living in the EU. GDPR was a huge circus of blame on EU bureaucracy back when it was introduced. A lot of hate poured out that every single paper you sign now needs to have a second separate GDPR thing for you to sign. Stupid Brussels making your life more complicated! But now everyone seems to be used to it. reply rsynnott 19 hours agoparentprevLots of European companies have gotten fined.But also, primarily European companies did generally take it a lot more seriously than multinationals. (Sometimes too seriously; while this has calmed down a bit, you&#x27;ll sometimes see companies enforcing absolutely absurd policies around data on the basis that they incorrectly think they&#x27;re required for compliance). reply InTheArena 17 hours agorootparentIn my experience, this is absolutely not true. Sometimes mind-boggling so.For example, it was US companies that stopped serving ads until they had GDPR infrastructure in place, while some very bad actors in the UK where not collecting consent at all. reply rsynnott 16 hours agorootparentAh, well, the UK. The UK is special. reply PurpleRamen 20 hours agoparentprevIs there any reason to do that? European companies are more likely to follow the laws already, and taking less liberty in bending or even ignoring them. Mostly because the people working there have a better understanding and focus of them.On the other side, European companies are usually smaller, so their get lower fines, which won&#x27;t make the headlines. Which is, why you might not hear so often about the fines against European companies, which still happen. And if we are honest, we usually only hear about the super-penalties anyway. reply layer8 19 hours agoparentprevSee for yourself here: https:&#x2F;&#x2F;www.enforcementtracker.com&#x2F; reply lucideer 14 hours agoparentprevThere&#x27;s plenty of EU companies getting fined: on top of the fact HN will naturally bias toward reportage on well-known US unicorns, there&#x27;s also a language barrier: most reportage of fines outside of Ireland won&#x27;t be in the English language.The Irish DPC is also reportedly quite busy, by virtue of shouldering a disproportionate amount of the enforcement work for non-EU companies (due to tax-driven HQing there). They have taken cases against European entities as well however: notably they even even taken cases against the Irish government for violations around mandating biometric public service ID cards. reply izacus 20 hours agoparentprevIt&#x27;s absolutely trivial to confirm that EU countries get fined all the time: https:&#x2F;&#x2F;www.privacyaffairs.com&#x2F;gdpr-fines&#x2F; reply jdminhbg 15 hours agoparentprev> european companies at scaleSuch a thing would need to exist before the EU would be able to fine it. reply corbezzoli 21 hours agoprevThat&#x27;s quite a fine for a single-country ruling, it&#x27;s like 2.6% of a year of revenue — or 10 days. reply hjnilsson 21 hours agoparentThe fine is for the entire EU, it was only handled by the Irish authority because TikTok headquarters are there. reply hnbad 21 hours agoparentprevThe article says the Irish agency is enforcing this for the entire EU. I think this is called the \"one stop shop\" solution which a lot of large foreign companies and Twitter use to avoid being fined by each member state individually. It also involves some closer oversight I think.I&#x27;m explicitly saying Twitter not X Corp because Musk in his infamous wisdom fired everyone at Twitter Ireland who was involved in ensuring they remained compliant. I think part of the requirement was also that every feature launch is run past the Ireland team to make sure it doesn&#x27;t violeate EU data laws. Musk has not done that for any of the changes he introduced since the leveraged buyout. reply swader999 14 hours agoprevIn addition to fines, put them in a penalty box for x months. No operation in an jurisdiction for a period of time. reply toasted-subs 14 hours agoprevSeems like not a lot money in the grand scheme of things. Wouldn&#x27;t have minded a relatively hefty fine, but maybe I don&#x27;t know all the details... reply throwaway5959 12 hours agoprevAh looks like the EU is going to start taxing China as well. reply spandextwins 21 hours agoprevWhere does the money go? reply baobabKoodaa 19 hours agoparentGod damnit. You presented a simple question, and at this time 3 different people have answered your question with contradictory answers \"General government budget\", \"The country issuing the fine\", and \"Into the EU budget\".If you don&#x27;t know the answer, don&#x27;t just make up fictions and present it as fact. reply inamorty 20 hours agoparentprevThe country issuing the fine. Previously for Meta it was Ireland and Amazon it was Luxembourg. reply ipaddr 14 hours agorootparentIn this case Ireland will collect but this is on behalf of the entire EU. Where does it go after? reply LordDragonfang 11 hours agorootparentIt generally stays in the country issuing the fine, and it&#x27;s up to that country what to do with it:>“While the GDPR determines which infringements can lead to the imposition of a fine and which DPA [data protection administration] in the EU&#x2F;EEA has the power to impose a fine for infringements, the GDPR does not determine what happens to administrative fines [my emphasis]. This is determined by national law and differs between member states. For all aspects of enforcement not governed by the GDPR, national law applies.”https:&#x2F;&#x2F;cybernews.com&#x2F;editorial&#x2F;who-keeps-gdpr-fine-money&#x2F;#:....As for where specifically in Ireland, it seems to just go to the general government budget. reply lakomen 20 hours agoparentprevI&#x27;d like to know that as well.Where do all those fines go? reply PeterisP 20 hours agoparentprevGeneral government budget. reply mtmail 21 hours agoparentprevInto the EU budget https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Budget_of_the_European_Union reply meghan_rain 19 hours agoprevAt what point will armchair CEOs stop with the \"lmao x is just a blip in y&#x27;s revenue\"?Do you think 345M grow on trees? reply vorticalbox 19 hours agoparentThey are expected to have $13.2 billion this year. reply karaterobot 18 hours agorootparentI think that number is their revenue rather than their profit, which is probably closer to $3 billion. So, this fine would be (very roughly) 10% of their profits for the year. reply c-hendricks 17 hours agorootparentFines against companies should be revenue based instead of profit based. Companies have too much wiggle room from revenue to profit. reply karaterobot 14 hours agorootparentI think they should be based on guidelines that take into consideration the damage the company did, irrespective of the amount of money they make or have in the bank. That&#x27;s how it works for the likes of you and me. reply kevin_thibedeau 12 hours agorootparentNot in Finland. reply karaterobot 12 hours agorootparentDoes this comment in any material way relate to either my comment or the comment to which I was responding? I&#x27;d love to know more about how it works in Finland, but I can&#x27;t figure out why you left this message. reply TeMPOraL 53 minutes agorootparentI think the point was that, in some countries, fines are scaled to wealth level. The typical example case is traffic violation: a $100 speeding ticket can be life-destroying for a poor person, and a pocket change for a wealthy person. The intent of the law is neither, so by scaling the fine by wealth of the offender, you can achieve the designed level of pain&#x2F;annoyance regardless of one&#x27;s material status.An alternative to that, used e.g. in my country - Poland - is to create a \"secondary currency\" of penalty points. Rich or poor, you only have 24 of them, and if you lose them all, kiss your driving license goodbye.One would think that penalty points could work here too, instead of scaling revenue, but the problem is, companies can rapidly split, merge, or otherwise shed their legal identity, so there&#x27;s nothing to pin those penalty points to. reply jimbob45 12 hours agorootparentprevWhy would you punish success? Do you not want successful companies? reply roncesvalles 8 hours agorootparentNot in the EU! replymkl95 15 hours agoprevSweet. But as long as the EU doesn&#x27;t have a big company in the social media market, the Asia&#x2F;US giants will get away with it. reply xchip 15 hours agoprevHow much are they paying per kid? reply rvz 18 hours agoprevThis is a good start as a starting fine as I said and have been calling for instead of a ban.Increase the fines into the billions of dollars if they repeatedly continue to violate the privacy of their users. This has happened with Facebook before.There is no defense in large compaines getting away with this and all social media companies with over hundreds of millions of users that violate their users privacy should be fined, as found with TikTok. No more exceptions or excuses.So that concludes that TikTok is no different to Meta when they screw over their own users privacy. reply mym1990 19 hours agoprevAny breaking of the law in regards to children needs to absolutely incinerate the offending party, this fine seems like a drop in the bucket. Kids these days are bombarded by terrible industry practices because companies know if they can get a child hooked, they could be a customer for life(or at least a period of time in their adulthood). In the US, kids are advertised to at literally every corner of their life...in their apps, when they go to school, TV, etc...it is actually WILD that this kind of stuff is legal. reply SeanAnderson 18 hours agoparentWhat sort of fine would you consider not to be a drop in the bucket?This fine looks to be an estimated 1&#x2F;8 of TikTok&#x27;s profit in 2022. reply wooger 18 hours agorootparentAn appropriate punishment would be: All children&#x27;s accounts must be deleted and no new ones for minors allowed to exist for 2 years.Any further infringement and the App is banned from the EU. reply SeanAnderson 18 hours agorootparentThis would require all TikTok users to submit selfie + ID for verification and all those who don&#x27;t would need to be assumed to be children and have their accounts deleted, right? reply logicchains 17 hours agorootparentThat&#x27;s the end goal, so anonymity is basically destroyed on the internet, and people are condemned to digital dystopia and inescapable surveillance under the guise of \"protecting the children\". reply jiofj 15 hours agorootparentprevThat&#x27;s how it already works for youtube. The EU mandated you need to prove to google that you are of age to watch certain videos. reply BeFlatXIII 17 hours agorootparentprevHow&#x27;s that supposed to be enforced if the kids lie about their ages? reply mym1990 12 hours agorootparentprevLet&#x27;s be real, the actual money paid out will be much less, and over a long period of time most likely. The number needs to be big enough to make other companies do everything they can to not let this kind of stuff happen. In current state these kinds of fine are probably just line items to account for if these companies get caught.How about 100% of TikTok&#x27;s profit in 2022, and go from there. reply rhyme-boss 18 hours agorootparentprevIf you make $100k in a year in wages, and after all your expenses you net $16k in savings, 1&#x2F;8 of that is $2k. Imagine violating some law that harms children and your fine is $2k. reply logicchains 17 hours agorootparent>Imagine violating some law that harms children and your fine is $2k.\"Harms children\". To make the analogy fair, imagine you&#x27;re keeping a diary, and recording the observable information of every child that walks past your house. $2k seems like a reasonable fine. reply ipaddr 14 hours agorootparentI&#x27;ve seen people walk past news reporters with children. They even asked them questions about Santa Claus. Then they sold advertising to display before and after that event. Then they showed it to the public. What fine should we impose? 10% reply feoren 14 hours agorootparentprevTaking pictures of every child that walks past your house and selling access to those pictures online? $2k still seems fair to you? reply ipaddr 14 hours agorootparentIn your opinion is it too high, lower or someone not understanding what it means to be in public? reply mym1990 12 hours agorootparentFuture CEO material right here. replyyumraj 18 hours agorootparentprev25% of Annual Revenue and firing of all CxOs (CEO, COO, CTO etc) reply varenc 17 hours agorootparentAssigning blame to the CxOs can be tricky. In this case the actual violations were from 2020, well before the EU even began its investigation, and some of the C-suite staff has changed.Should it be the current C-suite that’s fired or the ones in charge when the violation occurred? Or maybe the ones in charge when the original policy at TikTok was created? Or what if the current C-suite was in charge, briefly, for the violating period but they’re also they ones that changed things to be in compliance before the investigation began, should they still be fired?The diffuse responsibility makes this stuff tricky to implement. reply bragr 18 hours agorootparentprevThey&#x27;ll just write bigger golden parachutes into their contacts to offset the risk. That or suddenly everyone is an EVP and the C levels all are just paid fall guys.But 25% revenue might work. reply yumraj 18 hours agorootparentWell add a 3 strikes law [0], after all corporations are supposed to be person, from a legal standpoint.3 strikes, and the company is dissolved. In fact, this should definitely happen for US credit rating companies which keep on leaking data.[0] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Three-strikes_law reply DSingularity 18 hours agorootparentThis is an EXCELLENT proposal. They would fight just as hard to ensure they never receive the second strike to avoid the forever-doom that will loom over investors. reply silvestrov 18 hours agorootparentprevI think a 3 strike against the CxO as a person will be more effective.1st strike blocks you from working as CxO for 5 years, 2nd strike for 10 years, 3rd strike is forever.Right now too many bad CxO jump from one ship to the next again and again. reply autoexec 17 hours agorootparentWhen a CxO gets their 2nd or 3rd company broken up they&#x27;ll find it very hard to find a ship willing to let them on board.If you let the company get away with crimes over and over and only punish a CxO the company will simply hire a guy to take the fall for them. There&#x27;s an endless number of people working minimum wage who would happily take a CxO title and salary for years knowing full well that there&#x27;s a chance they might get fired eventually. reply silvestrov 12 hours agorootparent#1: If a guy breakes the rules so much he gets a 3rd strike, I think it is perfectly reasonable he should never have a CxO job again. It is too easy getting away with serial white-collar crimes.#2: It is not the company to decide who to take the fall. It is the court&#x2F;judge. reply BeFlatXIII 17 hours agorootparentprevThen you retitle yourself to EVP during the timeout. reply dahfizz 17 hours agorootparentprev3 strike laws usually only apply to violent felonies. You don&#x27;t go to jail for life after getting 3 speeding tickets.I&#x27;d be down with this, but we need to decide which kinds of violations are speeding tickets and which are serious felonies. reply logicchains 17 hours agorootparentprevMake such larges fines you end up with even fewer companies and the European Union gets even poorer, people keep wondering why their standards of living keep getting worse and GDP hasn&#x27;t increased in over a decade. There&#x27;s a reason European companies have such low tech salaries; even places like Singapore, Shanghai and the gulf countries have higher average tech salaries now than e.g. France or Germany. reply lijok 17 hours agorootparentprev10 years of gross revenue, 4 years in jail for the CEO and any other liable individuals. reply NegativeK 16 hours agorootparent10 years of gross revenue is an actual death penalty for a company.Why go that route instead of claiming its assets in the jurisdiction and revoking its right to operate? reply lijok 16 hours agorootparentThat would work too ! reply paulddraper 16 hours agoparentprevWhat is your frame of reference for considering 300+ million euro a drop?? reply feoren 14 hours agorootparentThe frame of reference is a revenue of $13.2 billion dollars. What is 2.6% of your annual revenue? Does that seem like a fair fine for illegally violating the privacy of children? reply paulddraper 13 hours agorootparentTiktock global revenue was $9.4 billion last year.EU is like, what, a fifth of that at most? reply mym1990 12 hours agorootparent2.6 billion in 2022, up from 1 billion in 2021, and surely more for 2023. reply paulddraper 10 hours agorootparentOkay, so drop in the bucket where the bucket holds ten drops reply mym1990 12 hours agorootparentprev% of a certain year of revenue, % of a certain year of profit, market cap...I can go for a while. reply mchanson 21 hours agoprevThis is pretty interesting time with the social media &#x2F; data companies. Will this be the new normal? Where, like clock work, another fine gets announced? Or will we transition through this period into one where they know how to, and also do, comply and the regulations don&#x27;t change a ton? reply jdietrich 20 hours agoparentThese are serious, proportionate fines that meaningfully affect the bottom line. These companies are demonstrably making big changes in order to comply. They have been testing out the boundaries and seeing how close to the wind they can sail, but I think that&#x27;s coming to an end now that they&#x27;re seeing the impact of the new approach to enforcement.The clearest sign for me was Meta&#x27;s decision to delay the launch of Threads in the EU. Even for a company with the financial might of Meta, two billion euros in fines in the past two years has put the brakes on the \"move fast and break stuff\" mentality. Of course that creates the possibility of a two-tier internet where EU customers simply don&#x27;t get access to products that are inherently intrusive, but I think that&#x27;s a feature rather than a bug - either respect the privacy of our citizens, or take your seedy surveillance business elsewhere. reply kmlx 20 hours agorootparent> Of course that creates the possibility of a two-tier internet where EU customers simply don&#x27;t get access to productsthis has already happened. google’s bard took it’s time to launch in europe.the young kid in me that always thought we finally have a piece of tech that is beyond what politicians can control, that transcend borders and nationalities is saddened. but it is what it is, and without some breakthroughs (a system that cannot be controlled, censored etc by design) i don’t think there’s going back. reply bad_user 19 hours agorootparentIt&#x27;s very naive to think that the Internet can transcend in any way law enforcement. You may have distributed protocols and crypto, but the state has a monopoly on violence, it controls all infrastructure, and therefore can control all inputs and outputs.You can&#x27;t change the world just with technology, as society is a \"social construct\". And if people want regulation, that&#x27;s what they are going to get.Speaking of EU&#x27;s data protection regulations, it&#x27;s funny because many people here claim that it doesn&#x27;t work, and then are shocked to see that it does.For what is worth, I think EU&#x27;s data protections are a good thing. Big Tech acted irresponsibly for too long. reply kmlx 18 hours agorootparent> It&#x27;s very naive to think that the Internet can transcend in any way law enforcement.agree, it is naive. but for a while it did feel liberating to a lot of people. reply rsynnott 19 hours agorootparentprevOh, huh, I actually didn&#x27;t realise Bard _had_ launched here.> without some breakthroughs (a system that cannot be controlled, censored etc by design)This isn&#x27;t really a technical issue; some small criminal entity could run an AI bot on Tor (or even, realistically, on the open internet) which forwarded all your personal data directly to the North Korean government and the Mafia or whatever, and realistically they&#x27;d get away with that. But if there&#x27;s a large company behind the service, then that company is going to have to _obey the law_, and no amount of technology will change that. reply kmlx 18 hours agorootparent> But if there&#x27;s a large company behind the service, then that company is going to have to _obey the law_, and no amount of technology will change that.i agree on the first part. but that second part could probably also be reinvented by new tech, futuristically speaking. reply mackrevinack 15 hours agorootparentprev\"a system that cannot be controlled, censored\"sounds like the Safe Network! too bad it will never be finished in our lifetimes reply skilled 20 hours agoparentprevInteresting, right? It&#x27;s like they can make so much money from tracking people in other countries&#x2F;jurisdictions that paying a fine to the EU once in a while is just part of the payroll. reply pomtato 20 hours agorootparentTruly, I&#x27;m starting to think they think of it as opportunity cost then an actually fine. reply waihtis 20 hours agorootparentYou&#x27;d be correct. Anyone that actually has to deal with regulators quickly understands how easy it is to game the regulations if you&#x27;re someone of Meta&#x27;s stature. reply joe__f 20 hours agorootparentprev€345M is a pretty huge amount of money reply yard2010 20 hours agorootparentThat&#x27;s monopoly money. Put the ones in charge behind the bars, that&#x27;s something that might make them think twice before breaking the law again reply logicchains 17 hours agorootparentOr people will think twice about opening companies in your jurisdiction. There&#x27;s a reason pretty much all the new fortune 500 companies created in the last few decades are not from the EU. reply skummetmaelk 16 hours agorootparentWhy exactly is it that the quality of a society is measured by how many big companies they have? Does Philip Morris contribute to society or detract from it? Can we dispense with the notion that big companies inherently improve society? Letting go of this does not imply you are a communist, regardless of how many seem to think so. You can believe that society achieves better outcomes by having tighter rules of play, rather than an anything goes mentality. Yes it makes it harder to create megacorps with billions upon billions of revenue. And so what? reply personomas 20 hours agorootparentprevEspecially when you consider that it was stopped 3 years ago. reply firesteelrain 20 hours agorootparentExcept it didn’t. My daughter in the US created an account and it didn’t require any family pairing or verification that the adult paired with her was her parent reply personomas 20 hours agorootparentThese are EU laws that only pertain to the EU. US has different laws. reply firesteelrain 15 hours agorootparentI guess TikTok has different software policies per country reply rsynnott 19 hours agorootparentprevIt&#x27;s pretty normal for these things to take a while; most fines (and for that matter most prosecutions) would related to historic offences, not ongoing ones. reply hef19898 20 hours agorootparentprevYour honour, clearly you cannot convict my client since the crime was committed years ago.&#x2F;sYou don&#x27;t work for TikTok by amy chance? reply personomas 20 hours agorootparentI definitely don&#x27;t work for TikTok. I don&#x27;t know the details. But the fine is way too much regardless. reply dylan604 19 hours agorootparentyou know how it&#x27;s not too much? they can afford it. reply logicchains 17 hours agorootparentWhat a deranged idea, you&#x27;re implying it&#x27;s okay to bankrupt a company just for a minor privacy violation. reply hef19898 17 hours agorootparentOh, I think it is totally ok to bankrupt a company for not following the law. reply dahfizz 17 hours agorootparentFor any violation at all? If one single McDonalds employee in Dublin breaks the health code, you think all of McDonalds should go bankrupt?I assume you also support the death penalty for J walking? reply hef19898 16 hours agorootparentIf it is a single McD employee, fine said restaurant (which is already the case, but you onow that don&#x27;t you?). If it is a general issue with a franchise chain (McD is running a franchise, so the company to go bankrupt is most likely a franchise in your example), fine them. And yes, that can lead to bankruptcy, as happened a couple of years ago with a Burger King franchise chain in Munich.If McD is knowlingly selling carcinogenic burgers world wide and reguses to stop, sure, bankcrupt McD. reply dylan604 17 hours agorootparentprevi think it&#x27;s deranged that you feel privacy violations are minor in any form. also, this isn&#x27;t a first offense reply personomas 17 hours agorootparentData privacy violations are certainly minor. Until we get that through, our companies are going to suffer. We have far, far, far greater problems in the world than privacy issues of usually meaningless data. reply hef19898 16 hours agorootparentData privacy is a paramount concern in free democracies. But of course you don&#x27;t get that. reply malermeister 14 hours agorootparentprevA privacy violation is never minor. replypiva00 20 hours agorootparentprevConsider that GDPR has been in effect since 2016, with a grace period until 2018 before the EU started to hand out fines.It&#x27;s been 7 years that every company operating in the EU knows about these rules, 3 years ago it was already 4 years into effect. There&#x27;s no excuse, they broke the law, pay the fine. reply malermeister 20 hours agorootparentprevI think if that&#x27;s the case, the fines will have to be increased until we reach a point where they succeed at their task of disincentivizing this behavior. reply riffraff 20 hours agorootparentGDPR already has a provision for this (it accounts for repeated violations and collaboration), and a ceiling of 4% of global revenue is quite high. reply personomas 20 hours agorootparent\"quite\" high? Are you serious. These fines are unbelievable. reply ceejayoz 20 hours agorootparentThat&#x27;s the point, and it&#x27;s the maximum. 4% is there as the nuclear option for repeat offenders. reply malermeister 20 hours agorootparentprevGood, they might actually work then! reply dylan604 19 hours agorootparentprevUnbelievably low. It&#x27;s really pathetic at how not serious these fines are reply rsynnott 19 hours agorootparentprevAnd yet apparently not enough of a deterrent, because it keeps happening. reply personomas 19 hours agorootparentThis was a one occurrences, and TikTok stopped it 3 years ago. The laws are getting tighter and tighter (and vaguer and vaguer), that&#x27;s why \"it keeps happening\". replyta1243 21 hours agoparentprevThey know how to comply, but that would hurt their bottom line. reply jtode 21 hours agoprevnext [4 more] [flagged] yladiz 21 hours agoparentWhat? reply ekabod 21 hours agoparentprevWrong thread or too much wisdom. reply jtode 18 hours agorootparentEh, I&#x27;m getting a bit too close to 1000 points for comfort. I hear you implode or something. reply darthrupert 20 hours agoprevIs EU the only significant power on this planet that isn&#x27;t ... for a lack of better word, evil? reply pteraspidomorph 20 hours agoparentWe have our own issues, including voter apathy, political corruption, unsustainable economic policies, extreme inefficiency and the occasional batshit crazy tech laws being pushed by politicians who probably never touched a device with more than two transistors. But I still love it here. reply dahfizz 20 hours agoparentprevI would say least evil significant power... I believe their intentions are mostly good but that kind of paternalism in such a powerful entity can be a kind of evil.The EUs fight against encryption is a good example reply miohtama 19 hours agoparentprevThe EU is about to vote banning on end-to-end encryption which makes them quite evil in my books.https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;europe-break-encryption-leaked-d... reply cbg0 19 hours agorootparentThat&#x27;s the whole point of a democracy, you vote on things like this. The flip side is that anyone can put to a vote all sorts of stupid things they don&#x27;t understand. reply NegativeK 16 hours agorootparentDemocracy doesn&#x27;t prevent evil. reply pjc50 19 hours agoparentprevThe EU is ridiculously pluralist and consensus-driven. This makes it a sort of small-c conservative; it&#x27;s not prone to whimsical bad ideas and grandstanding. Its failure mode is in the opposite direction of just gradually over-regulating small business out of existence. reply jeroenhd 17 hours agoparentprevIt&#x27;s a mixed bag, really. They come up with great legislation I wouldn&#x27;t have thought possible like the GDPR, but then they go and try to ban E2EE messengers. They set up accountability for tech giants, but then add upload filters. They try to ban ICE cars, but extend the deadline for many years because of automotive lobbyists.Every good EU idea seems to come with a terrible idea. On average things seem to get better, but it&#x27;s a two-steps-forward-one-step-back kind of progress. It&#x27;s better than an all-bad government, but they do plenty of shitty things. I&#x27;m very happy to live in the EU, but it&#x27;s certainly not for everyone. reply DiogenesKynikos 19 hours agoparentprevThe EU&#x27;s behavior during the Greek debt crisis was pretty evil.Imagine if a US state were in serious debt, and the US federal response were to slash Social Security, Medicaid and Medicare benefits to the state. The EU view was that Greece should get out of debt by massively slashing government spending, including on virtually all social services, which sent the country spiralling into a Great-Depression-level economic collapse. That made repaying the debt even more difficult, which necessitated even deeper cuts, which made the economy collapse even further, and so on for years. Greece endured years of 20+% unemployment, and GDP&#x2F;capita has fallen to the level it was 20 years ago. reply jeroenhd 17 hours agorootparentI agree that European lenders went overboard, but I can&#x27;t blame them for requiring strict measures after the corrupt government of one member state threatened the economic stability of the entire EU bloc.Years of government mismanagement and fraudulent reports had put Greece in a state where nobody reputable would lend them money, in extreme debt, and without an economy to recover by itself any time soon.Greece could&#x27;ve decided not to take up the bailouts, of course. All austerity packages were passed by the democratically elected Greek parliament.The EU would&#x27;ve liked Greece to magically go out of debt, but it&#x27;s not like they were just going to hand the Greek government hundreds of billions of gifts and a pat on the back with a quick \"try not to go bankrupt again, OK?\". If you lend someone money, you want some kind of guarantee that you&#x27;re going to get it back. The EU wasn&#x27;t being evil, it was watching its own back while the worldwide economy took a hit. They weren&#x27;t alone either; the IMF also demanded reforms to ensure their loans got paid back down the line.At every step along the way, the Greek government was involved, including causing the instability in the first place. There are plenty of evil things the EU and its many bodies do, but this wasn&#x27;t a good example. reply DiogenesKynikos 9 hours agorootparent> Greece could&#x27;ve decided not to take up the bailouts, of course. All austerity packages were passed by the democratically elected Greek parliament.When the elected Greek government put the Nth austerity package to a popular referendum, the EU began cutting Greece off from the international banking system (one effect was that people were unable to withdraw more than a tiny amount from ATMs), in order to put pressure on the population to vote \"yes.\" The population voted \"no\" anyways, because Greeks were massively against austerity by that point. The EU then put enormous pressure on the Greek government to ignore the result of the referendum, threatening to intentionally destroy the Greek economy. The Greek government caved and agreed to the new austerity package. This was extremely undemocratic: a popular referendum was simply ignored, and the government - which had been elected specifically to reject austerity - basically had a gun to its head.> The EU would&#x27;ve liked Greece to magically go out of debt, but it&#x27;s not like they were just going to hand the Greek government hundreds of billions of gifts and a pat on the back with a quick \"try not to go bankrupt again, OK?\".If this were an American state, the citizens of the state would have received massive Federal transfers, in the form on Social Security, Medicare, Medicaid and unemployment payments. Instead, the equivalent of all of those things were massively slashed in Greece. This is the equivalent of throwing debtors in prison. In punishing them, you destroy their ability to pay back their creditors. It&#x27;s an insane thing to do, even from the point of view of the creditors.What the newly elected Greek government (not the old, corrupt government) was proposing was for the creditors to take a hit, and for stricter tax enforcement (particularly on the wealthy). It wasn&#x27;t just saying, \"Give us money and we&#x27;ll do nothing.\" It was saying, \"Don&#x27;t force us into an artificial economic depression, and give us breathing space to reform the corrupt system we inherited.\"The Greek government specifically asked the EU not to keep lending Greece money for the purpose of paying back creditors. The Greek government correctly pointed out that the inherited debt was unsustainable, and that you don&#x27;t lend a bankrupt person money: you force the creditors to take a hit and create a realistic payment plan.> There are plenty of evil things the EU and its many bodies do, but this wasn&#x27;t a good example.Imposing a completely unnecessary Great-Depression-level event on a member state - while running roughshod over that country&#x27;s democratic system - was pretty evil. Greece went through years of massive unemployment, people&#x27;s pensions and healthcare were slashed, and young people left the country in droves as practical economic refugees. The reason why the EU took this hard line was that some of the member states (like Germany and the Netherlands) wanted to send a message to the other financially weak states (like Portugal, Spain and Italy). In Germany, there was also a lot of populist politics involved: bashing \"lazy Greeks\" was good politics, and plenty of politicians made a lot of hay over being tough on the Greeks. reply pjc50 19 hours agorootparentprevIt&#x27;s interesting that post-New Deal US is much more redistributive between the states than the EU has yet managed to achieve. Probably due to not having any direct taxation power of its own either.EU \"fiscal discipline\" combined with bank bailouts looks so harmful in retrospect. reply tgv 17 hours agorootparentprevGreece has not been treated well, but you should also admit that Greece really fucked up. They even falsified their stats to adopt the Euro.> Imagine if a US state were in serious debtExcept the EU is not responsible for and does not control their member states&#x27; finances. The EU has a limited jurisdiction. E.g. taxation, education and defence are not part of it. Being part of the Euro zone does bring certain obligations. reply DiogenesKynikos 7 hours agorootparent> They even falsified their stats to adopt the Euro.\"They\" is ill defined here. The people who falsified the finances were not the people who suffered under austerity.> Except the EU is not responsible for and does not control their member states&#x27; finances.During austerity, the \"troika\" (which included the European Commission and the European Central Bank) micromanaged Greece&#x27;s finances. The Greek government was basically held hostage and forced to take very specific measures, down to which tax to change by which amount and which state assets to privatize in which way. The EU publicly aspires to be much more than just some soulless customs and currency union, and throwing a member state under the bus in this way and immiserating its population goes against what the EU supposedly stands for. reply WeylandYutani 18 hours agoparentprevhttps:&#x2F;&#x2F;www.aljazeera.com&#x2F;news&#x2F;2023&#x2F;7&#x2F;14&#x2F;black-refugees-stra...The EU is rich and safe and will commit whatever atrocities to maintain it. reply tgv 17 hours agorootparentThat link is only related to the EU in so far as that those people were probably trying to enter it, illegally. reply itishappy 17 hours agorootparentprevI&#x27;m confused. What&#x27;s the connection? reply jeroenhd 17 hours agorootparentThe EU has made a deal, investing massive amounts of money into North African countries to keep refugees from crossing the sea. The EU representatives negotiating the deal knew exactly what was going on, even before the deal was happening.There&#x27;s no easy solution to the mass immigration problem, but this \"solution\" makes things worse for everyone. reply itishappy 14 hours agorootparentThanks for the explanation! reply Sacho 17 hours agorootparentprevTunisia and Libya are not part of the EU. reply jeroenhd 17 hours agorootparentNo, but the EU did make a deal with Tunisia: https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;world-africa-66222864We&#x27;re massively cutting back on our business with Russia over their atrocities in Ukraine, but when it comes to human rights in Tunisia, we&#x27;re willing to let this stuff slide. Sure, there&#x27;s no war, but handing a country money to enforce their deadly anti-refugee violence is very bad. reply33 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "TikTok has been penalized €345m (£296m) by the Irish Data Protection Commission (DPC) for breaching EU data laws concerning child users' accounts.",
      "The violations include defaulting child accounts to public settings, lack of transparency in providing data information to children, granting adults access to child users' accounts, and negligence in evaluating risks to underage users.",
      "Prior to this, TikTok had also been fined £12.7m by the UK data regulator for illegally processing the data of 1.4 million children under 13 without parental consent."
    ],
    "commentSummary": [
      "TikTok has received a €345 million fine from the European Union for breaching data protection regulations concerning children's accounts.",
      "Debates following this decision revolve around the efficacy of fines as disciplinary measures, the enforcement of privacy laws, and the obligation of tech firms to guarantee data security.",
      "Some discussions veer off-topic and delve into the EU's handling of the Greek financial crisis and the refugee situation - issues not directly related to the primary news."
    ],
    "points": 367,
    "commentCount": 298,
    "retryCount": 0,
    "time": 1694779347
  },
  {
    "id": 37522106,
    "title": "Akiyoshi’s Illusion Pages",
    "originLink": "https://www.ritsumei.ac.jp/~akitaoka/index-e.html",
    "originBody": "Akiyoshi's illusion pages Akiyoshi KITAOKA, Professor, Psychology, Ritsumeikan University, Osaka, Japan studying visual perception, visual illusion, optical illusion, trompe l'oeil, 3D, etc. ORCID Since May 18, 2002; Updated May 19, 2023 Japanese, Serb, Portuguese, Chinese; Illusion calender 2021 This work was partly supported by JSPS KAKENHI Grant Number 21H04426 awarded to Akiyoshi Kitaoka. Warning: Commercial abuse of my illusion images is prohibited. This page contains some works of \"anomalous motion illusion\", which might make sensitive observers dizzy or sick. Should you feel dizzy, you had better leave this page immediately. More Latest works (May 19, 2023) --- Newest page (December 23, 2021) --- Updated page (August 16, 2022) --- Illusion catalogue (June 3, 2014) Page list of this site --- Books (September 23, 2019) --- Papers (February 11, 2021) --- Illusion news (November 25, 2020) --- Photos (Nov 1, 2014) The Journal of Illusion welcomes your submissions. \"Rotating snakes\" Circular snakes appear to rotate 'spontaneously'. Copyright A.Kitaoka 2003 (September 2, 2003) Explanation of the elemental illusion (optimized Fraser-Wilcox illusion) (PDF) How this work was created (PDF) (Trick Eyes Graphics p.78) Gray-scale version (jpg) The commercial use of this image is not free of charge. Modification of this image for commercial purpose is usually declined. Educational or research use or modification is welcome. \"Rotating rays\" The outer ring of rays appears to rotate clockwise while the inner one counterclockwise. Copyright A.Kitaoka 2004 (June 12) \"The autumn color swamp\" The inset appears to move. Copyright A.Kitaoka 2000 \"A bulge\" The floor appears to bulge out, though this image consists of only squares. Copyright A.Kitaoka 1998 \"Primrose's field\" This checkered background consists of squares but appears to wave. In addition, this figure also shows a waving motion illusion. Copyright A.Kitaoka 2002 \"Uzumaki ampan\" Concentric gray circles appear to be spirals. Copyright A.Kitaoka 1998 \"Rollers\" Rollers appear to rotate without effort. On the other hand, they appear to rotate in the opposite direction when observers see this image keeping blinking. Copyright A.Kitaoka 2004 (April 20) All my illusion pages The latest works 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 54 53 52 51 50 49 48 47 46 45 44 43 42 41 40 39 38 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0Anomalous motion illusion 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 Rotating illusion 37 36 35 34 33 32 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 Expansion and contraction 17 16 15141312 11 10 9 8 7 6 5 4 3 2 1 --- Black holes Rotating snakes 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 --- Rotating snakes: test and control images Movie illusion 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 --- Barber-pole illusion --- Revesible apparent movement (jpn) --- Rotating Mona lisas Reversed phi Waves 9 8 7 6 5 4 3 2 1 Explanation of waving illusion Heat shimmer illusion 3 2 1 Autumn color swamps 2 1 Cherry blossom 3 2 1 Motion aftereffects 2 1 Koma (tops) 2 1 Expanding cushions \"Optimized Fraser-Wilcox illusion Type V\" (\"red optimized Fraser-Wilcox illusion\") Fraser-Wilcox illusion Fluttering heart illusion Blurry heart illusion Motion contrast and motion assimilation (motion capture) Second-order footsteps illusion demos Footsteps illusion 2021 Journal of Illusion Drifting spines illusionColor illusion 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 Lightness illusion 7 6 5 4 3 2 1 Illusory staircase Gelb effect etc Op art 12 11 10 9 8 7 6 5 4 3 2 1 Chromostereopsis 3 2 1 Color constancy 8 7 6 5 4 3 2 1 Vein illusion (in Japanese) --- Explanation of the vein illusion (in English) ECVP2021: \"A Javascript program to create images of color illusion by histogram compression in RGB\" Two-color method Afterimage works 2 1 Color illusion: Special Color change illusion Subjective color Umbrella (Munker illusion) Fluorescent color 2 1 Benham tops 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1Color samples --- Isoluminance images --- Isochroma images --- Isohue images --- Color sets --- color space list HCV color space --- Its exterior view (cHCV): details --- Its exterior view (hHCV): details CIE Yxy color space --- Its exterior view: details L*a*b* color space --- Its exterior view: details DKL color space --- Its exterior view: details HSV color space u' v' color space L*u*v* color space MacLeod-Boynton color space LMS color space XYZ color space RGB color space Yrg color space Color solids 2 1Classic geometrical illusion 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 Bulging geometrical illusion 6 5 4 3 2 1 Spiral illusion 10 9 8 7 6 5 4 3 2 1 --- Explanation of spirals --- Spirals 2 --- Spirals 3 --- Tunnels Face illusion 10 9 8 7 6 5 4 3 2 1 --- Illusions of eye direction --- A review of the face illusion (Talk in 2012) Cyanophyceae --- Turtles --- Café Wall illusion --- Zöllner illusionVisual completion 2 1 Extinction illusion 4 3 2 1 Visual phantoms (ECVP2005) Pincushion grid illusion of neon color spreadingAmbiguous (Reversible) figures 7 6 5 4 3 2 1 Impossible figures 2 1 Upside-down faces Hidden images 2 1 Stationary slit vision Anamorphosis Trompe l'oeil Illusion pop art 5 4 3 2 1 Reversible images (not mine) Illusion Museum --- Trick Art Museums ReverspectivesSlope illusion 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 Stereograms 5 4 3 2 1 Perceptual transparency 2 1 --- Transparent mountains Sanrakutei (a triangular prism-shaped house) Luminostereopsis Leaning-Tower illusion works 2 1 Crater illusion 2 1 --- Footprint illusion Depth mapsMiscellaneous 9 8 7 6 5 4 3 2 1 Illusions observed outdoors 7 6 5 4 3 2 1 Kyoto illusion design 3 2 1 Applied illusionolgy 2 1 Illusion therapy 2 1 Wallpapers 3 2 1 No-illusion works 4 3 2 1 Glasses-dependent illusion 2 1 Coloring images Okazaemon works Collaboration with Kyo-yuzen Illusion calendar 2022 2021 2020 2019 2018 2017 Uchiwa (handy fan) (in Japanese) Let's make an illusion image 5 4 3 2 1 One-phrase comments Sample imagesPhysical illusion 2 1 Sun-in-clouds illusion Akiyoshi's books --- Illusion catalogue --- Akiyoshi's nengajo --- Akachochin --- Koinobori --- Cherries ---A page of background motion --- Ritsumeikan's illusion --- U-zu-maki (Rabbits' spirals) --- 2003: An illusory space odyssey --- Kochi illusion design --- Toys of illusion --- Illusion personality tests --- Illusion quizzes --- Window of illusion --- Classification of anomalous motion illusion --- Comprehensive classification of illusions --- Exhibition of illusion designs 2004 --- Works of sinusoidally modulated radials --- Explorer --- TEG --- TEE --- ECVP waves --- Expanding flower --- Shadow-shade stereopsis --- Star arts--- Girl of blue eyes 3 2 1 --- Popple illusion --- \"The four seasons in Japan\"--- Illusion design \"Lipsticks\"--- L'ORÉAL Art and Science of Color Prize, Gold Prize 2006--- Tie designs--- Gestalt psychological works --- Newton Press book --- Illusion erasers --- TEM --- Illusory signs --- Illusion mugs --- Professor McCourt in Ritsumeikan --- Overview of brightness illusions --- Illusion of figure --- AIC2009 talk --- Drag \"Fluttering hearts\" --- IllusoriaMente Show Time 2012 in Alghero --- 4-stroke tilt illusion and motion--- ICP2016 Informal Illusion Designs --- Cats see Rotating snakes movies --- Fukushima as the Fruit Kingdom --- Illusion jigsaw puzzles --- APCV2014 Best Presentation Prize --- Professor Shapiro's talk in Ritsumeikan 2019 Memos of references of visual illusions Submission from friends Illusion designs from friends 11 10 9 8 7 6 5 4 3 2 1 Illusion news Illusion news 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 Illusion contest Illusion Contest in Japan (February 20, 2014) Photos Today's Kyoto 13 12 11 10 9 8 7 6 5 4 3 2 1 Kyoto --- Japan --- World --- Ritsumeikan University Illusions I encountered in England --- I visited Sarasota in May, 2005 --- I visited Serbia in 2014 --- I visited England in 2015 ICP2016 Informal Photos Nagoya City Science Museum's illusion exhibition in 2015 Visiome, ICP 2016, ICP 2016 facebook, ICP 2016 illusion works Links to outside websites (February 20, 2018) Recommended books Trick eyes My pages \"Trick Eyes Graphics NEO\" (written in English and Japanese) has been published! (The right book is an academic one entitled \"Introduction to visual illusions\") For details, click here. DISCLAIMER Most of the material contained within these pages was created by Akiyoshi Kitaoka and is not copyright-free. If you wish to use any of the material for research purposes, personal purposes, or educational purposes, you may do so only if you include a citation. To cite my work, use my name, my site address, the title of my book, or the titles of my papers. For commercial or professional use, please contact the publisher \"Kanzen\"* who manages my published material. If you are a journalist and wish to use my material, only I can grant you permission to use my work. *For the response from Kanzen, please wait about one week because it takes time to translate languages in the company. For commercial customers, we can send image files in Adobe Illustrator format (ver. 8 or higher) or in bitmap (jpeg) format of any size. We also have files available in PDF, CorelDRAW, MS-Word, and related formats.I have received a number of requests asking for permission to upload some of my illusion designs to webpages and I have granted such permission on an individual basis. Hereafter, I grant permission to upload to your webpage up to three (3) images if your webpage is to discuss the science of illusion or vision, is not a commercial site, and does not contain indecent, obscene, or illegal content. Religious or political sites would be declined. The sites that I cannot reach would be declined, either. My name and the address of my webpage (a link is OK) should be cited. Moreover, a cautionary message or warning like \"These images might make observers feel sick\" is necessary if they are anomalous motion illusions. Please withdraw my works from the sites if they do not satisfy the conditions shown above.The \"Download\" page was closed because of too much illegal use of my material. Please do not use them for commercial purpose without permission. For educational or research use of my high quality material, please send your request to me. I am sorry that original vector files or large bitmap files will not be provided for personal use.If you send me an e-mail, please do not attach any files because I might erroneously delete the e-mail thinking that a virus is hidden in the file.If you sent me an e-mail but have not heard from me within a week, I might possibly remove it in error. Then, please send it to me again with a clear title, e.g. \"about illusion\". It is my pleasure to grant permission for the use of my illusion material for papers, articles, or books if they are for educational or research purposes. In this case, I would like the authors to request permission. Requests from publishers or other agencies are not welcome. Requests for written permission are not welcome either, because it takes time to check, sign, and send it back, though I will do so if it is absolutely necessary. Of course, I give written permission if it is a commercial gift.Links to my website are welcome. Please link to this top page so that we can avoid overworking the Ritsumeikan University servers.Do not worry or become upset if you cannot see the illusions. I must confess that even I do not see some illusions. For instance, the Ponzo illusion, if the image is the upper-converging version, is difficult to see.Thanks to DavidAnnouncement: A website \"Test online the level of stress a person can handle using stress pictures: are they animated, moving?\" abuses three of my illusion works as well as claims an unscientific idea. To my knowledge, stress has nothing to do with visual illusion.all right reserved (except some) RIKEN Library for vision science Illusion catalogue Akiyoshi's biography (April 13, 2020) email to: akitaoka@lt.ritsumei.ac.jp Access since June 3rd, 2002 Acknowledgments (July 14, 2008)",
    "commentLink": "https://news.ycombinator.com/item?id=37522106",
    "commentBody": "Akiyoshi’s Illusion PagesHacker NewspastloginAkiyoshi’s Illusion Pages (ritsumei.ac.jp) 351 points by robin_reala 21 hours ago| hidepastfavorite56 comments susam 13 hours agoOne of Akiyoshi Kitaoka&#x27;s recent work that I found absolutely stunning is the following illusion where a ring of one colour appears to be either in front of or behind two rings of another colour:https:&#x2F;&#x2F;twitter.com&#x2F;AkiyoshiKitaoka&#x2F;status&#x2F;16812686184854568...https:&#x2F;&#x2F;nitter.net&#x2F;AkiyoshiKitaoka&#x2F;status&#x2F;168126861848545689...To my perception, the blue ring appears to float above the red rings. It feels a bit like an autostereogram where a 3-dimensional image emerges out of a 2-dimensional image. However, there is no autostereogram in this image and there is no crossing of eyes involved. The 3-dimensional image arises out of an otherwise plain image of differently coloured rings on a dark background.An analysis of this illusion is available here: http:&#x2F;&#x2F;www.psy.ritsumei.ac.jp&#x2F;~akitaoka&#x2F;Kitaoka2015_Referenc... reply albert_e 19 minutes agoparentfirst few seconds : nothing special, just flatthen: blue ring appeared \"closer\" to me (very similar to a stereogram - yes)I was able to \"force\" the blue ring to snap to being \"behind\" the red rings by rapidly blinking but the effect wouldnt stick .... the perception would slowly snap back to my default - blue in the front reply coda_ 6 hours agoparentprevIf you wear glasses I suggest trying both with and without your glasses on while moving your head. For me, there is almost no effect without my glasses on. But with glasses, it is quite strong... but I&#x27;m not even sure if what I&#x27;m seeing when I have my glasses on is actually the intended effect. I&#x27;ve become used to that effect with blue and red light moving in opposite directions relative to each other when I move my head. reply hippari2 2 hours agorootparent-3.5 here, the illusion is both effective with or without glasses reply Tao3300 7 hours agoparentprevI see the red rings in the front, but if I close one eye, they look flat. That was confusing, but the paper explains it nicely. reply smeej 6 hours agoparentprevI&#x27;ve noticed the same effect with stained glass, that blue tends to recede for me and red comes forward.I spend a lot more time in churches, especially ones with stained glass, than most people, but I hadn&#x27;t thought to ask if it happens to other people too. reply epiccoleman 8 hours agoparentprevThat one, for me, is sorta like the ballerina thing, in that with a small mental effort I can make it switch between the two states. But honestly my first glance at it, they look largely \"flush\" - not a super strong 3d effect in either direction. reply Proziam 7 hours agorootparentEven with effort I couldn&#x27;t make them not appear &#x27;flush&#x27; and I&#x27;m beginning to question my sanity reply magic_hamster 11 hours agoparentprevThat&#x27;s a very cool illusion. First time I see it. I wonder if the color patterns on the different rings have something to do with it. reply grilledchickenw 16 hours agoprevThe second black hole one \"Approaching black hole: yesterday\" is stunning. I cannot believe it&#x27;s a still image. http:&#x2F;&#x2F;www.psy.ritsumei.ac.jp&#x2F;~akitaoka&#x2F;saishin69e.html reply Solvency 16 hours agoparentAm I alone in not understanding this black hole one... it&#x27;s a sequence of three obviously distinct still images in which the black center is larger than the previous image.Meanwhile, each image on its own is offering no kind of perceptive illusion to me... reply albert_e 7 minutes agorootparentYes each image independently shows the illusion -- different images are only to provide a variation i guess, since some proportions work better for some people than othersI personally found the illusion not strong though definitely presentThis similar illusion but done with different colors and patters was much more vivid and strong for me ...check this out:\"Expanding Pupils\" second image onwardshttp:&#x2F;&#x2F;www.psy.ritsumei.ac.jp&#x2F;~akitaoka&#x2F;motion35e.html reply block_dagger 15 hours agorootparentprevStaring at any of them individually makes the central circle appear to grow. Bottom one is most effective for my eyes. Creepy! reply kazinator 15 hours agorootparentprevI don&#x27;t intuitively understand any illusion. I don&#x27;t have conscious introspection into what the layers of neurons are doing between the retina and conscious visual perception. The layers of neurons use certain indirect cues in order to detect size, depth and movement. Those cues do their job in most circumstances, but test cases can be constructed which falsely trigger those cues. That&#x27;s just an intellectual generality that doesn&#x27;t explain anything specific. reply btilly 14 hours agorootparentYou should add shadow to the list of important cues. Something light in shadow can be the same color as something white in direct light. You can see that optical illusion in https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Checker_shadow_illusion.My favorite example of where shadow matters is \"the dress\". As https:&#x2F;&#x2F;slate.com&#x2F;technology&#x2F;2017&#x2F;04&#x2F;heres-why-people-saw-th... explains, those whose brains assumed it was in shadow saw it as white and gold. Those whose brains thought it was in light saw it as blue and black. (It was actually a blue and black dress, in light. But the photo was taken in such a way that most people thought it was in shadow.) reply smeej 6 hours agorootparentThis one drives me crazy because even having seen a picture of the same blue and black dress in direct light, my brain simply will not see this as anything but white and gold. I know I&#x27;m seeing it wrong and still can&#x27;t see it right. reply phatskat 2 hours agorootparentMine has changed over the years - usually I see blue and black, but occasionally I see white and gold. reply qwertywert_ 8 hours agorootparentprevOpen the image and F11 to full screen then just stare at the center. reply gowld 15 hours agorootparentprevThe intent is that the black hole grows while you stare at it.Not all illusions work on everyone in every environment. reply tstrimple 16 hours agorootparentprevFor me it doesn’t seem to grow. But the blurred edges definitely show movement from my perception with both eyes open. If I close one eye the effect goes away altogether. reply willmeyers 18 hours agoprevCan these affect your vision (long-term) if you stare at them for too long? I feel like many of these images produce similar effects to the McCollough effect. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;McCollough_effect reply JKCalhoun 18 hours agoparentWhen I was young (maybe 8 or so?) my mom got me a book of B&W moiré patterns. It consisted of a book of B&W patterns and a clear plastic sheet also with similar patterns. When you overlaid the plastic sheet over the patterns in the book is when you got the moiré patterns.Besides seeing yellows and other fringe colors appear from the moiré, I always wondered if the patterns were linked to ocular migraines I would have for some decades after.(Edit: yeah, this book: https:&#x2F;&#x2F;www.goodreads.com&#x2F;book&#x2F;show&#x2F;2446119.Optical_Designs_...) reply rqtwteye 18 hours agoparentprevI could imagine that it will change the way you perceive things. There are experiments where people got goggles that switched the left and right eyes and people adjusted after a few days. reply davchana 17 hours agorootparentOr even simple glasses which turn the view upside down. Human eyes were able to adjust itself (or the image) correct way after few hours. reply smeej 6 hours agorootparentDon&#x27;t we all actually go through this as babies? Where our mental image flips?I don&#x27;t understand why it would make any difference, from an evolutionary perspective, but apparently it does? reply d-lisp 13 hours agorootparentprevI had a copy of some Merleau-Ponty work in which this experiment was commented, IIRC the experimenter did really think his brain was damaged when the world appeared upside down to him without the glasses. reply david422 18 hours agorootparentprevThat&#x27;s pretty wild. reply joshspankit 18 hours agoparentprevThis is an interesting question and one that we’re possibly just on the leading edge of being able to ask correctly.The answers are likely to be varied and along multiple axis:- Do they affect the muscles of the eye, especially the ones that affect the lens- Do they affect the rods&#x2F;cones (and do they equally affect people with genetic differences)- Do they affect the way the signals are sent to the brain- Do they affect the visual cortex itselfand- Do they affect the brain’s processing of visual input in some wayIn my personal experience, I’d say we’d need to look at someone for a minimum of 3 years, and ideally 5 or more. reply notsahil 20 hours agoprevAkiyoshi&#x27;s twitter also has cool illusions:- https:&#x2F;&#x2F;twitter.com&#x2F;AkiyoshiKitaoka- https:&#x2F;&#x2F;nitter.net&#x2F;AkiyoshiKitaoka reply bhtru 19 hours agoparentNitter is dead no? reply pbhjpbhj 18 hours agorootparentIt worked for me. reply aimor 19 hours agoprevThis one almost hurts, forget the approaching black hole I get dazzling speckles of white light. : http:&#x2F;&#x2F;www.psy.ritsumei.ac.jp&#x2F;~akitaoka&#x2F;Plaid-tunnel02-040-b... reply GolfPopper 7 hours agoparentOof. Yes. I don&#x27;t get the speckles, but the middle portions of the tunnel \"shudder\" like looking a something slightly out of focus at extremely high power through a telescope, and it feels like I&#x27;m about to get a migraine. reply btilly 14 hours agoprevI used to have a high quality printout of the rotating snakes illusion by my desk.I had people who refused to be at my desk because it creeped them out that they absolutely knew the paper couldn&#x27;t be moving, but their brains kept seeing the snakes rotate. reply thanatos519 14 hours agoparentWhat a great filter that must be! reply dang 11 hours agoprevRelated:Akiyoshi&#x27;s Illusion Pages - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25785081 - Jan 2021 (17 comments)Akiyoshi&#x27;s Illusion Pages - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=13793715 - March 2017 (32 comments)Akiyoshi&#x27;s illusion pages - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=5697783 - May 2013 (15 comments) reply tempaway75751 20 hours agoprevThe most mind blowing optical illusion I&#x27;ve seen are Kokichi Sugihara&#x27;s Ambiguous Objects:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KtA6u1HIqbg reply nojs 17 hours agoparentA similar one that I like, and you can easily make yourself:https:&#x2F;&#x2F;www.moillusions.com&#x2F;dragon-illusion&#x2F; reply catbird 12 hours agorootparentThat was a fun little project. It looks even better in person! reply kazinator 15 hours agoprevSome of the movement illusions really pop out if you slowly move your finger across the image and track it with your eyes. Or use a mouse pointer similarly if you&#x27;re on desktop. reply alberto_ol 20 hours agoprevPrevious submissions, only the older ones have commentshttps:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=Akiyoshi%E2%80%99s+Illusion+Pages+... reply lisper 16 hours agoprevIt&#x27;s possible to create \"impossible\" shapes in real life:https:&#x2F;&#x2F;flownet.com&#x2F;ron&#x2F;trips&#x2F;Europe2023&#x2F;pause&#x2F;206.html reply gowld 15 hours agoparent2D projections of 3D impossible shapes, yes. reply moritzwarhier 14 hours agoprevI was really happy about the first one, \"spontaneously\", including the quotes, this is such an apt description!Alas, for me it seems to occur mostly on eye movement&#x2F;focus change.. which happens to happen... spontaneously reply ayx 14 hours agoprevI can never see these illusions :&#x2F; Only the bulge works. Movement I can’t see at all.Am I supposed to look at it a certain way? I tried at different distances. I’ve tried using larger screens. Nothing.. reply pvg 14 hours agoparentA lot of the movement ones are more noticeable with actual movement so scrolling a little bit could help. I notice them popping more when I scroll through his twitter feed. reply 3seashells 15 hours agoprevPersistent Visual cortex defects. Now imagine the brain riddled with similar defects, when it&#x27;s comes to reasoning and learning. If there was one creature not defect, the whole rest of the zoo would be sad. reply dr_dshiv 20 hours agoprevMy mind is blown.I wonder whether the “Rauschenberg Illusion” would count. Named after Robert Rauschenberg’s blank white canvases which show that big white fields are filled with illusions of color and form from our visual system. (Or at least, they are for me. I’m not nuts, am I?) reply weirdkid 10 hours agoprevThis is great stuff. I’ve had this bookmarked in my browser for almost 20 years!I should see what else I have in there… reply joshu 16 hours agoprevHe posts regularly here: https:&#x2F;&#x2F;twitter.com&#x2F;AkiyoshiKitaoka reply ceddec 15 hours agoprevA lot of graphic illusions are used commercially e.g for product advertising like here: https:&#x2F;&#x2F;www.shapeshiftermedia.com reply fny 18 hours agoprevAre there rules for creating these illusions? reply guyomes 16 hours agoparentMark Changizi had an interesting insight on how some illusions work [1].What we see is a reconstruction by the brain interpolated from our sensors. The idea of Mark is that the image is not only an interpolation of the present, but actually also an extrapolation of what the image will be in the next tenth of a second. For tasks such as catching a ball, this would allow us to compensate for the delay of the signal between our brain and our muscles.Based on this idea, he wrote a classification of many illusions [2].[1]: https:&#x2F;&#x2F;www.livescience.com&#x2F;4950-key-optical-illusions-disco...[2]: https:&#x2F;&#x2F;onlinelibrary.wiley.com&#x2F;doi&#x2F;full&#x2F;10.1080&#x2F;03640210802... reply gowld 15 hours agoprev> Caution, continued> Some of the pictures on this website can cause dizziness or might possibly epileptic seizures. The latter happens when the brain can&#x27;t handle the conflicting information from your two eyes. If you start feeling unwell when using this website, immediately cover one eye with your hand and then leave the page. Do not close your eyes because that can make the attack worse. reply xwdv 17 hours agoprevI wonder if any 8-bit era games used these kinds of illusions to simulate advanced shader effects. reply TeaDude 19 hours agoprev [–] I&#x27;m very shocked that these were only discovered so recently (Well. If you consider the early 2000&#x27;s to be \"recent\". I&#x27;d have assumed that we&#x27;d have found these out earlier)I suppose that&#x27;s why they were all the rage in childrens&#x27; books and museums around that time. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The website developed by Akiyoshi Kitaoka provides a compilation of illusion imagery and designs, presented with accompanying explanations and contextual background.",
      "Apart from the core content, the site also hosts news, contests, and photos related to the topic of optical illusions.",
      "Use restrictions are in place, specifically prohibiting commercial applications, and users are forewarned that the content could induce dizziness."
    ],
    "commentSummary": [
      "The article discusses a recent illusion by Akiyoshi Kitaoka, demonstrating how people perceive colored rings differently, with variables like glasses and head movement influencing the effect.",
      "Forum participants share personal experiences and discuss the impact of optical illusions on the brain, exploring the broader realm of illusion artistry.",
      "There's an emphasis on the potential use of illusions in fields like advertising and gaming, underscoring the ongoing fascination with optical illusions."
    ],
    "points": 349,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1694781832
  },
  {
    "id": 37527773,
    "title": "Building an economy simulator from scratch",
    "originLink": "https://thomassimon.dev/ps/4",
    "originBody": "THOMAS SIMON> your data used: 32.8kB secrets found: 0/3 posts seen: 1/4 Building an economy simulator from scratch #simulation #economy Thomas SIMON 2023-09-15 Step by step simulation Let's build an economy from zero. Starting with 1 person: Simulation 1 Day 0 ⌛ step 0 🧑🌾 Reset step Click to start the simulation x4 x200 Nothing happens! That is because we did not make any assumptions yet. We should introduce at least one hypothesis: - A person consumes 1 🍎 (food) every day. Do not worry about the technical aspects, each time we add an hypothesis, imagine I am writing a dozen lines of code or so. Let's give our simulated person some 🍎 to see how he does. Simulation 2 Day 0 ⌛ step 0 🧑🌾 🍎3 + - Reset step Click to start the simulation x4 x200 Oh no, after 3 days, his stock ran out. I sneaked in a death by starvation clause. New hypothesis: - A farmer produces 10 🍎 per day (self consumption included) Simulation 3 Day 0 ⌛ step 0 🧑🌾 🍎3 + - Reset step Click to start the simulation x4 x200 That seems too easy, he probably needs some other resources to produce this food. - A person consumes 1 💧 (water) every day. What are those units ? They represent the normalized minimum average consumption for one person for one day. For example, you could say that: 1🍎 = 2500 calories. 1💧 = 3L of water (or 100L for a farmer with 1 cow). For the purpose of this simulation, the exact number does not matter, pick one that suits you. Simulation 4 Day 0 ⌛ step 0 🧑🌾 🍎3 + - 💧3 + - Reset step x4 x200 This farmer died due to lack of 💧. We could make him a producer of this new resource too, but let's take a more realistic approach. We add another worker, specialized in water production. - A water worker produces 10 💧 per day (self consumption included). Simulation 5 Day 0 ⌛ step 0 🧑🌾 🍎3 + - 💧3 + - 🧑🌾 🍎3 + - 💧3 + - Reset step x4 x200 The necessary resources for everyone's survival exist. They just have to be shared somehow. - Introducing 💰 (money). A tool to account for shared resources. - Every resource (🍎 or 💧) cost 10 💰. - People starved of a resource (stockShowcase ↖ RemoteCam Phone's camera stream on desktop #android #kotlin #app ↖ Oxidator Real time strategy game #rust #webgpu #game ↖ Natify The coder's sound synthesizer #js #audio ↖ Fomos Experimental OS for modern hardware #os #exokernel #rust ↖ Top Down Battleground Multiplayer arena shooter game #game #webgl #pvp I have availabilities Contact me",
    "commentLink": "https://news.ycombinator.com/item?id=37527773",
    "commentBody": "Building an economy simulator from scratchHacker NewspastloginBuilding an economy simulator from scratch (thomassimon.dev) 352 points by Ruddle 15 hours ago| hidepastfavorite145 comments neilwilson 7 minutes agoI’d love to work on this more. Definitely would like to see it on GitHub.If we’re talking about money printing then we need to talk about money shredding as well.If government prints money to buy thing then taxation feeds old money into the shredder.Print is always matched with a shred.Even bank loans are paid off (shredded) reply denton-scratch 1 hour agoprevIn the late 80s, I typed in a BASIC economy simulator I found in some computer magazine. It ran to two or three closely-typed pages (sides).As Chancellor of the Exchequer, you set the tax-rate, interest rate, level of public spending and so on; then you ran a cycle. I can&#x27;t remember whether a cycle was a month or a year. After about three years, the workers would be on strike and there would be rioting in the streets. Every time.I wasn&#x27;t particularly interested in macroeconomics at the time; I certainly had no idea how to run an economy. I have no idea how realistic the economic model was. I assume it was just a bit of fun.But I&#x27;d like to tinker with a realistic economic model that is flexible enough to, for example, model Modern Monetary Theory. reply nonrandomstring 23 minutes agoparentIf you like playing this sort of thing I must recommend NetLogo [0].It&#x27;s an \"agent\" based modelling environment, so you have to \"discretize\" (yuck) your problem first.I learned about it because Scott Page uses it for his \"Model Thinking\" class [1].[0] https:&#x2F;&#x2F;ccl.northwestern.edu&#x2F;netlogo&#x2F;[1] https:&#x2F;&#x2F;modelthinker.wordpress.com&#x2F;There is also the MIT \"systems modelling for a complex world\" reply bagpuss 12 hours agoprevThe MONIAC built in the 1950s by Bill Phillips (of Phillips curve fame) attempted to model economic processes with coloured water (fluidic logic)https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;MONIAC reply JellyBeanThief 5 hours agoparentI just love whenever the roundworld equivalent of something I first encountered on the discworld pops up in front of me. reply _the_inflator 3 hours agoparentprevVividness has its advantages. You could call it a simulator as well as one of the world&#x27;s first dashboards as well. reply neilwilson 4 hours agoprev\" tax works by pooling a percent of sellers revenue.\"What the public servant actually does is impose a tribute on the workers in a denomination the public servant determines. If you don&#x27;t provide the denomination then the public servant confiscates your assets by force.The population then offers their goods and services in return for the denomination the public servant issues. The public servant then determines the level of the tribute required by how much of its own denomination it gives in exchange for the tribute.That&#x27;s the source of money, and the source of the price level.There is no &#x27;universal exchange commodity&#x27;. Money is really just promises between people.Fred would say to Jim: \"here&#x27;s a pig, owe me one\". Fred now has Jim&#x27;s IOU as an asset which he could give to Bob in exchange for something Bob made so Bob can claim a pig from Jim. reply nvy 4 hours agoparent>That&#x27;s the source of money, and the source of the price level.The vast majority of money in the modern economy is created by banks, not by the tax agencies or even the mint. When the bank lends you $1000 they just create it out of thin air and credit your account by $1000. reply neilwilson 13 minutes agorootparentUsing what for collateral?Yes banks create money but all they do is discount what already exists.As every budding entrepreneur finds out when they try to get a loan at 17 years old.Banks provide liquidity after the fact. They don’t kick the system off. reply mordae 3 hours agorootparentprevThey still have to borrow the money from the central bank. Fractional reserves mean that the credited account&#x27;s bank must deposit a portion of the money bank at central bank.So there is a limit to how much money can the bank create. reply neilwilson 12 minutes agorootparentThey don’t. Reserves are irrelevant for bank lending.They are nothing more than a centralised optimisation of what would otherwise be a full mesh network of point to point exchanges reply tomatocracy 36 minutes agorootparentprevMostly banks borrow from depositors and from the capital markets.Reserve requirements of that type still do exist in some places (though in some places they&#x27;ve been abolished) but don&#x27;t really play much of a role in determining how quickly money supply grows any more.Control over money supply growth is mostly down to interest rates these days.Similarly, the role reserve requirements used to play in protecting depositors has been replaced by the various \"Basel\" rules which determine what sources of funding banks can use to fund their loans which depend on the loan book&#x27;s credit quality, tenor etc. reply neilwilson 11 minutes agorootparentBanks don’t borrow from depositors.Loans create deposits and the deposits just change ownership tag from then on. reply threatripper 3 hours agorootparentprevThey must only borrow the money (or get it from somebody else who got it from somebody who borrowed it from the central bank) that they need to pay you out in paper or digital cash and the money they have to keep in reserve. They do not have to borrow the whole credit value. The credit itself is created out of thin air but with some strings attached, so banks can&#x27;t just create infinite amounts of credit and they cannot just pay out arbitrary sums of created credit. (Source: Some books I read a long time ago.) reply robertlagrant 2 hours agorootparent> The credit itself is created out of thin air but with some strings attachedYes - via the central bank, right? I thought that was how quantitative easing worked. reply imtringued 1 hour agorootparentprevThe bank acts as an intermediary, but not the way economists tell you. They say that the bank is an intermediary of loanable funds between debtor and creditor. That is, money exists outside the system and the bank is just efficiently distributing it, kind of like eBay.Except the bank is an intermediary of a completely different kind between creditor and lender. What the bank does is aggregate illiquid credits and debts to create liquid credit and debt.You have a coupon that says you are owed X products by person A. Person B has a coupon that says he is owed Y by person C. The bank takes these coupons and transforms these illiquid promises into a liquid promise that lets you buy both X and Y products from person A and C. Think of it as a many to many relationship. The bank essentially acts as a blender that takes many things of non uniform quality and it produces a product of uniform quality.When you go to the bank and bring a stack of coupon that says \"I will work for one hour for you\" and the bank puts a stamp on the coupons that says \"Bank B vouches for this coupon\". Except this is inconvenient. What the bank does instead is print its own coupons that everyone recognizes and it deposits your coupons in its bank vaults. The bank writes down that you owe it all the coupons representing your labor time that you deposited as debt. Except this again is inconvenient, we can do away with the individual coupons entirely. Since paying your own coupon debt requires you to withdraw the coupons using bank coupons, we can just decide that you owe the debt in bank coupons instead. reply lottin 2 hours agoparentprev> That&#x27;s the source of money, and the source of the price level.What do you mean? reply zwieback 12 hours agoprevThis is so cute, love the animation and idea behind it.Just yesterday I listened to Planet Money talk about how Bill Phillips got a position at the London School of Economics on the strength of his hydraulic computer simulating the economy: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;MONIAC reply Terr_ 11 hours agoparentMONIAC was also featured&#x2F;satirized in the Terry Pratchett book \"Making Money\":__________________> \"Mr. Hubert believes that this... device is a sort of crystal ball for showing the future,\" said Bent, and rolled his eyes.> \"Possible futures. Would Mr Lipstick like to see it in operation?\" said Hubert, vibrating with enthusiasm and eagerness. Only a man with a heart of stone would have said no, so Moist made a wonderful attempt at indicating that all his dreams were coming true.> \"I&#x27;d love to,\" he said, \"but what does it actually do?\"> Too late, he saw the signs. Hubert grasped the lapels of his jacket, as if addressing a meeting, and swelled with the urge to communicate, or at least talk at length in the belief that it was the same thing.> \"The Glooper, as it is affectionately known, is what I call a quote analogy machine unquote. It solves problems not by considering them as a numerical exercise but by actually duplicating them in a form we can manipulate: in this case, the flow of money and its effects within our society become water flowing through a glass matrix--the Glooper. The geometrical shape of certain vessels, the operation of valves and, although I say so myself, ingenious tipping buckets and flow-rate propellers enable the Glooper to simulate quite complex transactions. We can change the starting conditions, too, to learn the rules inherent in the system. For example, we can find out what happens if you halve the labour force in the city by the adjustment of a few valves, rather than by going out into the streets and killing people.\"> \"A big improvement! Bravo!\" said Moist desperately, and started to clap. reply motohagiography 7 hours agoprevThe game \"Captain of Industry\" might be a more complete simulation: https:&#x2F;&#x2F;store.steampowered.com&#x2F;app&#x2F;1594320&#x2F;Captain_of_Indust...Big thread on it from last year here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31586833 reply bavell 6 hours agoparentI bought it after seeing that post at the time, great game of you&#x27;re a fan of games like Factorio. Very well designed and tons of fun! reply Workaccount2 12 hours agoprevI&#x27;ve long had the fantasy of an economics simulator given dwarf fortress levels of dedication and attention to detail. This might not be it, but it does warm my soul a bit. reply dragontamer 11 hours agoparentTropico series is simple but fun.The bulk of it is obvious Capitalism vs Communism political jokes though, so I wouldn&#x27;t consider it a very serious economic simulator. But its better than most IMO. reply bavell 6 hours agoparentprevWorkers and resources: Soviet Republic is a super fun economic and transportation logistics sim that shines in \"Realistic mode\". Highly recommended for fans of the genre. Tiny bit like a hardcore version of City Skylines. reply 0cf8612b2e1e 11 hours agoparentprevEve Online? They even used to employ an economist to monitor the state of the game. reply theptip 9 hours agorootparentNot really a \"simulator\" since it&#x27;s driven by real humans interacting. I&#x27;d say it&#x27;s just a virtual world with its own real economy.An interesting thing you can do with a simulator is pause, rewind, make arbitrary experiments, run counterfactuals, etc -- all of which are prohibited in Eve since it needs to respect the users who are there to have fun, not be test subjects. reply Ruddle 8 hours agoparentprevThanks, and agreed. How ironic though, working on that fantasy is near certainly not economically viable. This blog post is merely procrastination that preempted job seeking. reply ilyt 12 hours agoparentprevI had hopes for Victoria 3 but it didn&#x27;t exactly stick the landing reply andrewmutz 11 hours agorootparentIt&#x27;s not perfect, but they are investing a lot of time on improvements. Paradox games tend to get better over time. 1.5 introduces province-level prices, which make supply chains more interesting. reply michael_j_x 12 hours agoparentprevstar citizen with its quantum economic simulator is close enough: https:&#x2F;&#x2F;www.boredgamer.co.uk&#x2F;2020&#x2F;04&#x2F;24&#x2F;star-citizens-quantu... reply gsuuon 7 hours agoparentprevSame. Dwarf fortress used to have an economy but they took it out. I tried to make something like this and burnt out, though I expect I&#x27;ll pick it back up again at some point. reply londonReed 5 hours agorootparentI believe that the economy aspect is going to be (eventually) re-worked entirely for a better simulation and to interact better with the existing game. The current development arc is going on several years at this point, so who knows when that might get addressed. reply WalterBright 6 hours agoprevMay I present HAMURABI:https:&#x2F;&#x2F;www.atariarchives.org&#x2F;basicgames&#x2F;showpage.php?page=7...I had a lot of fun playing and modifying that game. Learned a lot about programming with it. reply tnecniv 6 hours agoparentWas not expecting to see an Atari game produced in my home town today reply 0xADADA 13 hours agoprevdont&#x27; mistake a beautiful map for the territory, you&#x27;ll find yourself lost amongst lines that aren&#x27;t a real place. reply sunday_serif 12 hours agoparentOn Exactitude in Science By Jorge Luis Borges…In that Empire, the Art of Cartography attained such Perfection that the map of a single Province occupied the entirety of a City, and the map of the Empire, the entirety of a Province. In time, those Unconscionable Maps no longer satisfied, and the Cartographers Guilds struck a Map of the Empire whose size was that of the Empire, and which coincided point for point with it. The following Generations, who were not so fond of the Study of Cartography as their Forebears had been, saw that that vast Map was Useless, and not without some Pitilessness was it, that they delivered it up to the Inclemencies of Sun and Winters. In the Deserts of the West, still today, there are Tattered Ruins of that Map, inhabited by Animals and Beggars; in all the Land there is no other Relic of the Disciplines of Geography.source: https:&#x2F;&#x2F;kwarc.info&#x2F;teaching&#x2F;TDM&#x2F;Borges.pdf reply The_Blade 11 hours agorootparentnice, you beat me to this gem (with a side of Lewis Carroll and Baudrillard) because I was finishing workthe lesson is, never tryedit OH and the other part is that it was staged literary forgery by \"Suarez Miranda, Viajes de varones prudentes, Libro IV, Cap. XLV, Lerida, 1658.\" Borges overclocked the meta reply barrysteve 9 hours agorootparentprevBut a massive precise map is the perfect seed for a useful simplified map.Simplifying from a non-complex source is a waste of time. reply dclowd9901 11 hours agoparentprevIt sounds like you take issue with this simulation? It applies heavily academic and simplistic rules around behavior. I like build up of it all to illustrate _simulating things_, but I think almost any traditional economics theory outside behavioral economics ought to be shelved for good. reply cgio 11 hours agorootparentI would agree up until recently. I am starting to think, though, that behavioral is only relevant in an economy of choice. With choice I keep it simple to having the option to spend or not wealth (including consuming&#x2F;selling some of your stock). The less choice in the market, the more the classical models will be reasonable and efficient approximations as they can accommodate one sided choices. Complex dynamics are not what we experience now. There is a market direction, the power to impose it and its application at clear sight. reply WillPostForFood 9 hours agorootparentprevI&#x27;d go the other way, behavioral economics ought to be shelved for good. Classic econ should come back, but with a stamp on its forehead that is is not science or a practice.https:&#x2F;&#x2F;www.thebehavioralscientist.com&#x2F;articles&#x2F;the-death-of... reply dclowd9901 6 hours agorootparentSo what, we have no ground truth about economics? Is it just a close cousin of psychology? reply goblin89 4 hours agorootparentEconomy is not that different from psychology, physics, or indeed any natural science. All try to predict how they would change depending on various factors and invent explanatory models that are never perfectly correct.It’s just that some have had more apparent prediction success than others (non-coincidentally, it’s those that don’t directly involve humans as subjects), while some are liable to affect people’s lives in more direct and drastic ways (non-coincidentally, it’s those that do directly involve humans as subjects). reply jmopp 3 hours agorootparentprevEconomics sits at that intersection between the social sciences and the exact sciences: you can get some useful quantitative predictions out of it, but that is discounted by the fact that people are messy, and become even messier where money is concerned. reply dboreham 3 hours agorootparentprevEconomics is bulk effect Psychology. reply rsrsrs86 8 hours agorootparentprevBoth have been shelved; the state of the art in economic modeling is far, far more sophisticated. It goes way beyond the limitations of economics’ loan from XIX century physics (static mechanics).Economic modeling based on game theory with extensions (say, requiring that certain agent choices are computable and are so under a limited computational budget, or non determinism, or learning) you still get sensible results under much weaker hypothesis. reply Nezteb 13 hours agoprevIs the source code for this simulator available anywhere? The post&#x27;s code itself is minimized&#x2F;obfuscated: https:&#x2F;&#x2F;thomassimon.dev&#x2F;assets&#x2F;cashloss.1fca21f6.jsI couldn&#x27;t find anything on the author&#x27;s GitHub. I&#x27;m mostly just curious how it&#x27;s built. reply Ruddle 13 hours agoparentAuthor here, if there is enough interest I can clean the code up and put it on GitHub. It is basically a state machine. reply coderintherye 12 hours agorootparentI&#x27;d love to see it, even in unpolished state.It&#x27;d go well as comparison vs. this code I&#x27;ve been playing around with from Phillip Rosedale (Founder of Second Life) where he&#x27;s simulating economy for purposes of determining wealth distribution scenarios: https:&#x2F;&#x2F;editor.p5js.org&#x2F;PhilipRosedale&#x2F;sketches&#x2F;odl5elMWy reply jll29 11 hours agorootparentprevWould be nice to see a post written about the high-level design and then about the implementation. reply _false 11 hours agorootparentprevJust to add to others; I&#x27;d be interested to take a look at the source, particularly for animations. reply Nezteb 11 hours agorootparentprevI&#x27;d appreciate it. :D reply xwdv 12 hours agorootparentprevState machine? Why not entity component system? reply teo_zero 2 hours agoprevAm I the only one to find the simulation deviate from the description starting from Simulation 8?For example, I see a farmer with 7 food, 7 water and 7 wood, buying water. According to the description, their QoL would be 7 both before and after the transaction, so they are not supposed to buy because there wouldn&#x27;t be an increase of their QoL:> People are potential buyers of the resources that increase their quality of lifeAdditionally the average QoL indicator seems wrong. This is what I see at step 72: Farmer 1: 50$ 6 6 5 => QoL 5 Farmer 2: 90$ 4 4 5 => 4 Farmer 3: 10$ 7 7 7 => 7 Avg QoL 3.0How can 3.0 be the average? reply gsuuon 7 hours agoprevThat&#x27;s one of the most entertaining posts I&#x27;ve seen in a while. Would very much like to see a part 2. Also, as an aside, wow are those some tasteful gradients on the recent post links. reply SpaceManNabs 12 hours agoprevThis website is really cool (not just the post). Thomas must have put a decent amount of work. How to find the secrets? reply jfantl 5 hours agoprevI did something similar, but started somewhere different: The individuals personal value of a good. You might find it interesting as a different approach to a similar project. https:&#x2F;&#x2F;jasonfantl.com&#x2F;posts&#x2F;Simulated-Economy-(1)&#x2F; reply js8 9 hours agoprevFirst, I really appreciate author trying to understand economy better in this way, even though this simulation is quite naive. I think everybody should do that.But as others have noted, it has no concept of capital, private property, and labor market. Therefore, it&#x27;s not capitalism. It&#x27;s not anarchism or communism either - it lacks flexibility of workers to do something else, or state planning telling workers to do something else. At best, it could be a model of a feudal society (where the \"state servants\" are the landed nobility).Furthermore, it has no concept of natural resources, energy, labor and goods. That has to be there before we even get to things like money.Also, the money definition is problematic. Money is essentially a contract, and can be created even between three private parties as resoldable bonds. This isn&#x27;t there.I would also suggest, if the author (or anybody else) is interested, look at Steve Keen&#x27;s work in economic simulation and his Minsky program. This guy is far ahead of everybody else in actually trying to understand how real economies work.To people who wonder why don&#x27;t we have good economy simulators that would reflect a real world. Well, I think the answer is pretty simple - rich people don&#x27;t want that. They don&#x27;t want plebes to understand what it means to be rich, most rich people know they wealth is undeserved, and don&#x27;t want other people to see it flaunted openly. So they prefer hegemony (in Gramsci terms) of neoliberal economics, which is misleading about what is happening in reality. reply 01100011 8 hours agoparent> rich people don&#x27;t want thatYou had a great comment until you went off the rails. Sadly, economic ignorance is much more easily explained by apathy and the rarity of systems level thought in the general population. reply js8 8 hours agorootparentThat wouldn&#x27;t be a problem, just look at climate science, it has decent models of very complicated systems, grounded in real-world understanding. But it requires lot of data to be collected and made available for people who do these simulations. reply kamel3d 8 hours agoparentprevWould rich people be able to stop you from creating a good economy simulator? At the end of the day, it&#x27;s programming. Someone who has studied economics could make that without rich people coming after him. I argue that no one would come after you if you were to do so. reply js8 8 hours agorootparentYeah, but you also need to compare it with real world data. Without grounding, the simulation will be very limited.So you need to understand the real-world monetary flows to a sufficient level of detail. You need to understand who actually owns what, and how the power is exerted. And the rich people are against that, for example, in most developed countries (with IIRC notable exception of Norway and Sweden) the tax fillings are private.Also, it&#x27;s kind of difficult to understand actual production, because private companies keep the data on production costs secret.On top of that, there is little culture of data sharing in economics profession. Again, mostly because the data are very valuable to companies and individuals, profit takes precedence to public understanding.So the fact of the matter is, lot of powerful people (and perhaps most middle class as well) don&#x27;t want the level of transparency required to build a meaningful model.It&#x27;s true that nobody will come after you if you try to program it. But also, you won&#x27;t get much support from the existing, mostly neoliberal, institutions. reply stevenjgarner 2 hours agoparentprevSo if you feel that way, why not program your own model introducing the \"concept of capital, private property, and labor market\"? reply js8 1 hour agorootparentHonestly, I&#x27;d love to, it&#x27;s on my list. I really like what Steve Keen is doing. But I am currently amusing myself with a math problem, and that&#x27;s more important. reply xpe 7 hours agoparentprev> To people who wonder why don&#x27;t we have good economy simulators that would reflect a real world. Well, I think the answer is pretty simple - rich people don&#x27;t want that.The comment above is an example of an explanatory theory [1]> An explanatory analysis will try not only to describe the information but also to provide causal relationships between the various data presented.Simple, yes, but also too simplistic. It isn&#x27;t very persuasive. For the theory to be useful, then \"rich people not wanting that\" would have to be causally relevant. The comment above only provides an implied incentive (e.g. rich people would benefit by preventing knowledge dissemination that undermines their status). However, there is no convincing argumentation showing how such incentives play out, much less that they are significant enough to be causally important.I don&#x27;t want to reject the entirety of what the commentor above might be trying to say. There are probably aspects that are interesting, surprising, or maybe even troubling. Perhaps there have been documented cases of influential elites shaping economic theories and how they get communicated. Maybe; I haven&#x27;t studied the history of bias in the field of economics per se. I know of many biases, but so far I&#x27;ve tended to think about them as being largely intellectual oversimplifications rather than designed misdirections.Let&#x27;s look to some other &#x27;simple&#x27; explanations. One competing theory would be that economists and modelers want to earn status and earn a living. There doesn&#x27;t have to be any malicious nor coordinated action to explain such behavior. There are many levels of systemic behavior that align with powerful interests without any causal chain. This is sometimes referred to as co-evolution or co-adaptation.I do want to reject the whole family of (not so good) explanatory theories that fail to give sufficient argumentation for causality.[1] https:&#x2F;&#x2F;philosophy.stackexchange.com&#x2F;questions&#x2F;30827&#x2F;what-is... reply tomcam 5 hours agoparentprev> rich people don&#x27;t want thatWhere does this sentiment come from? And what do you define as rich? I have been acquainted with rich people for decades now and many of them seem pretty darn open to me. reply dools 7 hours agoprevThis adds money in before it adds the state, or taxation. Money is created through taxation by the state to provision resources away from the private sector to the public purpose. reply kamel3d 8 hours agoprevIn this day and age of AI, I think it&#x27;s worth trying to build a better economy simulator without having any existing economic models in mind. Addressing this from a programming point of view could lead to interesting results. reply Galanwe 8 hours agoparentThat&#x27;s more or less what every quantitative hedge fund out there is doing. reply rsrsrs86 8 hours agorootparentWith no reports of funds consistently beating the market in a surprising way.There’s no consistent way to make money. You can exploit small details about how each market works, but in a short time everyone will notice and copy you. It’s like a market without patents. People talk, the trade ideas spread. Like wildfire. Too fast even for a quant to make sense - good managers can tell if a piece of info is hot. No manager will ever be able to tell whether a stock will outperform. reply Galanwe 7 hours agorootparentWow, you have to be the super expert that unveiled the whole hedge fund scam. Thanks for your enlightening opinion. reply rsrsrs86 8 hours agoparentprevThat has been done uncountable times…It’s just really hard to get precise predictions. Really hard. Not like settling P=NO hard, but like moto perpetuo hard. reply Supply5411 13 hours agoprevSimulation 16 is hilarious. By the state dynamically scaling how much they print money in order to support government workers, government workers accumulate more wealth than the producers of goods. reply ta1243 12 hours agoparentThose that actually produce goods are very far down the wealth pecking order reply dclowd9901 11 hours agorootparentAnd the social pecking order, it would seem. reply epicureanideal 13 hours agoparentprevSounds like state workers in California reply vanrysss 13 hours agorootparentSee LA lifeguards making $300k&#x2F;yr https:&#x2F;&#x2F;lamag.com&#x2F;news&#x2F;the-highest-paid-lifeguard-in-l-a-mak... reply mapmap 12 hours agorootparentHow does this happen? reply lotsofpulp 12 hours agorootparentEvery single government employee and their family&#x2F;friends vote in local elections, and other people do not. You will not win an election without their votes, and you can use opaque compensation like DB pensions and whatnot to hide and punt forward the costs of the compensation.You will never find a non taxpayer funded entity promise something like this:>After 30 years of service, LA lifeguards can retire as young as 55 on 79-percent of their pay.Go ask an insurance company how much an annuity for even $80k would cost starting at age 55 until death. It would be $1M+.Social Security averages out your earnings for your whole lifetime to calculate the benefit, and that is with the power of the federal government. City and state governments regularly promise employees final average 1, 3, 5, and at best 10 pay formulas. So you see cops&#x2F;firefighters&#x2F;lifeguards&#x2F;etc spiking their overtime and working 80 hours per week for the last few years, doubling and tripling their DB pension benefit.And you simply will not see this outside of taxpayer funded entities. reply theptip 9 hours agorootparentAnother part of the challenge is overtime -- it ends up costing a lot to pay out time-and-a-half on an already fat paycheck. I think we should figure out some binding pre-commitment to forbid or at least minimize regular overtime. Something like \"if > 50% of one employee&#x27;s worth of overtime is required a new role must be opened instead of paying overtime\".I understand that unions like OT for their members (of course they would!) but as an employer it&#x27;s insane to be handing it out as regularly as government employees get it. reply willsmith72 11 hours agorootparentprevso you mean the solution to that would be mandatory voting? reply lotsofpulp 11 hours agorootparentNo, I think it is still too complicated of an issue to burden voters with understanding. The better solution would be restricting all employer employee compensation arrangements to cash only.That would solve politicians being able to pay with unaccounted for benefits that become a burden decades later, and increase labor price transparency and result in better functioning markets once employers are out of the health&#x2F;vision&#x2F;dental&#x2F;public transport&#x2F;retirement benefit business.And a third bird it kills is reducing the advantage big businesses have over small businesses. reply OkayPhysicist 9 hours agorootparentprevThese waterfront lifeguards have a lot more in common with EMTs and firefighters than have with the teenager who watches septagenarians do laps at your local pool, and they&#x27;re compensated as such.No CEO or programmer dies in the line of duty, yet you can&#x27;t throw a rock on this site without hitting thkse kinds of compensation. reply NotSuspicious 5 hours agorootparentExactly, the average techbro&#x27;s output working at a FAANG company likely ruins more lives than the average lifeguard saves. The compensation is clearly just. reply mindslight 10 hours agorootparentprevMore like bankers everywhere. reply keskival 11 hours agoprevThe simulation only has workers&#x2F;producers and it has a free market – it is missing capitalism. To make it realistic you need a subset of people owning the labor output of others, taking out all the surplus, using it to buy stakes of more economic activity, diverting profits to themselves, thus creating the loop of concentration of wealth which removes the surplus wealth from the producers and assigns it to ever decreasing number of ever wealthier individuals. reply smitty1e 11 hours agoparentThe \"good\" news is that gravity hates the Tower of Babel that every society inevitably produces. reply jeezfrk 10 hours agorootparentNo. Gravity and a flat surface doesn&#x27;t exist in money-power.It is buoyancy. It lifts few people up very high as they push down more that go down under the waves. reply vkou 10 hours agorootparentprevThe \"bad\" news is that this kind of gravity tends to get called things like \"The Reign of Terror\". reply rsrsrs86 8 hours agoprevOne way to make this realistic is to add game theory to the simulation. Otherwise, the most important assumption in economics will be left out: rationality in decision making. reply Galanwe 8 hours agoparentI don&#x27;t think the objective is realism here, but rather education.Also, I&#x27;m not convinced \"rationality\" is key in reaching realism. reply JoshMBN 8 hours agoprevI&#x27;m currently in my second year of my Bach degree for Information Technology and I have had this exact same idea but never really knew how to go about it. But I think I might attempt it next year during my A.I. and Data Science paper. Just as proof of concept for neural network practice and learning. reply Calamitous 8 hours agoprevI did not expect to read through and run every simulation. But I did. reply Ruddle 8 hours agoparentThe symmetry is nice. I did not expect to write, or code most of it. We were both taken by serendipity. reply nologic01 11 hours agoprevBeautifully made and illustrative of a currently non-existing branch of economic education, if not economic theory itself.While people get to be force-fed all sorts of complex subjects at school, economics does not feature prominently.The result of this widespread economic illiteracy is easily seen at the quality of political discourse. reply lainga 13 hours agoprevConsider examining different utility functions and substitutable goods reply rsrsrs86 8 hours agoparentThis. At least a general equilibrium model. reply imathew 7 hours agoprev\"If you wish to build an economy simulator from scratch, you must first invent the universe.\" reply blamestross 7 hours agoprevBeware optimizing for \"average\" quality of life, we did that and it worked. Turns out it is more efficient to have a super-minority with a very high QoL. Median is a better target. reply amelius 12 hours agoprevSounds like something an LLM could help with. You could write rules in natural language, and the system would automatically convert it into simple code. reply throwaway290 5 hours agoprevTo simulate economy, you need to simulate individuals with their wants and needs and relationships and the environment, as simple (complex) as that. reply rsrsrs86 8 hours agoprevThis is cute but very different from what an economist would consider interesting. reply orangepurple 13 hours agoprevGreat start! Some things to consider for future versions: more sophisticated tax code, financial regulations, monopsonies, monopolies, collusion, corruption, oligarchies, demand elasticity, cascading effects from supply chain disruptions, central bank quantitative easing. reply nylonstrung 13 hours agoparentA lot of this is Macroeconomics- Microeconomics (what this focused on) is effectively a different discipline. You can&#x27;t really model both of them within the same frameworkSource: econ major reply rsrsrs86 8 hours agorootparentUndergrad Econ courses still present micro and macro economics as two disciplines, but that’s theory from the 70s at best.Graduate level economics packs a lot of economic models where for example the interest rate depends on the intertemporal preferences of different types of agents.It just gets terribly complicated. reply econorew 13 hours agoparentprevAll of this is emergent behaviour. Agents need to be smarter and the networks need to be larger and information needs to have a cost. reply rsrsrs86 8 hours agorootparentOne really cool thing to do is consider the agents to have limited computational capacity. There are a few NP economic problems, and you can’t expect agents to really be solving enormous computational problems in their heads. reply JoeyBananas 10 hours agoprevI have also implemented greedy algorithms. reply logicallee 9 hours agoprevGreat set of simulations!Can someone explain why in Simulation 16, 4 producing workers can support 3 non-producing workers consuming just as much as them with just 10% taxation and yet they have similar QOL? It doesn&#x27;t make sense to me intuitively.If we ignore money and just look at goods this implies 3 people can do \"nothing\" (the government workers don&#x27;t buy from anyone in this simulation) and yet consume as much as 4 people who do produce, and the 4 taxed people only have to pay 10% taxes while everyone enjoys similar quality of life as 60% taxation.It would be like imagine you have four cartons of ten eggs and you tax 10% of each one. How can you end up with 3 whole cartons just from that taxes, it would only be four eggs, less than half of one carton rather than three extra cartons of the same size as the new reduced carton size of 9. reply Ruddle 9 hours agoparentAuthor here, simulation 16 shows that money printing, and tax have common effects. The state can replace one with another. Here the 65% tax is replaced with 10% tax plus inflation, i.e., giving new money to public servants. The new money creation decreases the value of money owned by producing workers.We could even remove the tax entirely, and still support the 3 public servants. To be convinced you can look at each unit transaction and see that all resource are accounted for.Another way to look at it, is that the QoL of producing workers is lower than if there was no public servants. Every resource a public servant has, is bought from a worker at some point, whether the money for the purchase comes from taxation or inflation. reply keithalewis 10 hours agoprevhttps:&#x2F;&#x2F;www.nobelprize.org&#x2F;prizes&#x2F;economic-sciences&#x2F;1973&#x2F;leo... His ideas might finally become practical to implement. Then again, von Neumann thought weather prediction would be solved in short order after the invention of the computer. reply NoMoreNicksLeft 13 hours agoprevThis is interesting, in that I&#x27;ve tried to come up with simple simulations like this for strategy games before. But I was a little \"eww\" when he kicked the number of government workers up to 40% of the workforce. Looks like it goes all the way up to 50%.On simulation #13, where tax is fixed at 10%, the government workers all eventually starve. Surprisingly, the libertarians are correct because at this point the quality of life index abruptly rockets up to twice what it used to be. But there&#x27;s some sort of robotic overlord AI going on, it still collects the tax.But then in simulation #18, things become a little insane. I call this one the Massachusetts simulation... only 3 workers, but 9 government employees. For a 3:1 ratio. The simulation suggests that some sort of economic meltdown occurs and they all starve, but I suspect that things were a little more violent than that.After, the developer then introduces ration tickets. This is simulation #20, and I&#x27;m pretty sure it&#x27;s Zimbabwe. But it&#x27;s not the real world Zimbabwe, it somehow works. That is, if you&#x27;re ok printing trillion dollar bills.Simulation #21 takes a new direction entirely. FDR has been elected, and tries to stamp out competition... but he is too late, evil capitalist farmers have grown too many apples, which perversely leads to starvation. Careful apple quotas are needed. The government has disappeared though, probably because late stage capitalism destroyed it. Only the corporations survive.Surprisingly, no farm subsidies yet. I predict the introduction of a new private sector worker, the ConAgra lobbyist. We&#x27;ll see if he shows up in a later simulation. That is, assuming another government is elected.In simulation #25, one of the warlords has settled down and become a government again. But this is the last of the simulations. No lobbyists, though the central bank has returned. This might be because Andrew Jackson has died. I did not like the man, he will not be missed. But quite clearly the inflation is through the roof again, and 30% taxes are here to stay.What I&#x27;ve learned from these is that history is a lie. Rhodesia probably never existed, and Zimbabwe happened before the US civil war. reply marcosdumay 13 hours agoparent> at this point the quality of life index abruptly rockets upThat&#x27;s because on this simulation the government isn&#x27;t doing any useful work.The ration tickets work because the people were programed to actually follow the law. It fails every time on the real world because real people aren&#x27;t.And the simulation #20 works because the simplistic model actually works. At a first approximation, inflation isn&#x27;t a problem at all. Things only start to fail after you have competition, corruption, very limited resources, etc.Simulation #21 is a great visualization of why people must be able to set prices with enough freedom, and why forced price-fixing bankrupts countries. reply dclowd9901 11 hours agorootparentThe \"useful work\" was implied. That is, the assumption was the government was perfectly valuable to society with relation to the cost it incurred. It might&#x27;ve been interesting to see the government throw money at the farmers every year or so, though. reply gus_massa 9 hours agorootparentI think it&#x27;d be interesting to a more in-game useful work of the government. For example that the homes of the producer may catch fire randomly. If there is at least a firefighter there is no problem, but once all firefighter die, then there is a 1% chance per day that each producer may burn and die.At the beginning of #13 eve thing is fine, until all firefighter die and the quality of life index abruptly rockets for a while. Then for example the apple producer dies, and after a few days everyone starves and dies.It may be a more complicated criteria, like each firefighter can protect only 2 or 3 producers, so the ratio of producers to government workers must be always not too high. reply NoMoreNicksLeft 12 hours agorootparentprev> the people were programed to actually follow the law. It fails every time on the real world because real people aren&#x27;t.Is anyone working on the problem of programming people? Or are we just hoping for a solution to that to fall into our laps?> and why forced price-fixing bankrupts countries.Ah ha! On this one I paid very close attention. No secret libertarians hiding in woodpiles, and sneaking out at night (or any other time) and stealing from the people. The only rational conclusion is that the simulation was set up to fail as some sort of propaganda.Besides, only a few people died anyway, which for any socialist country is miraculously impressive success. So maybe not propaganda.I&#x27;m beginning to think these simulations don&#x27;t offer any insight into the real world at all. reply vkou 10 hours agorootparent> Is anyone working on the problem of programming people?We gave The New Soviet Man[1] a try for a couple of decades, but it didn&#x27;t really stick.As the late-20th, early 21st century has shown, programming that seeks to amplify our vices[2], as opposed to turn us against them turned out to be far more effective.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;New_Soviet_man[2] Don&#x27;t think, just buy. reply dclowd9901 11 hours agoparentprev> After, the developer then introduces ration tickets. This is simulation #20, and I&#x27;m pretty sure it&#x27;s Zimbabwe. But it&#x27;s not the real world Zimbabwe, it somehow works. That is, if you&#x27;re ok printing trillion dollar bills.In a cashless society, I suspect the zimbabwe method would actually probably work. The only hangup was \"Now I need to crate around boatloads of money\". In a cashless society, we can just move the decimal point every so often. reply jameshart 8 hours agorootparentIt&#x27;s definitely important, when analyzing the impact of policies on an economy, not to get hung up on things like &#x27;what the numbers on the banknotes look like&#x27; rather than important things like &#x27;how well the population&#x27;s wants and needs are satisfied&#x27;. Certainly it&#x27;s not inherently a problem to continually have to revalue your currency if the net effect of your economy is it makes a lot of happy people, and it&#x27;s certainly not impossible to imagine that a functional stable productive economy might coexist with a rapidly inflating - or deflating - currency.But the simulation doesn&#x27;t do much to validate that concept. It introduced inflation to a group of agents who never think about the future value of their goods or money.In a runaway inflation situation, some producers of apples aren&#x27;t going to sell you apples today for 1,000 Simoleons, when they know tomorrow those apples will fetch 1,100 Simoleons... and by Friday they&#x27;ll be worth 10,000. And some holders of Simoleons will think &#x27;These 10,000 Simoleons could buy be ten apples today, but tomorrow they&#x27;ll only buy me 9, and by Friday they&#x27;ll only buy me one... so I should buy 10 apples today, then sell them on Friday&#x27;.Without capital accumulation, time valued money, or investment, this simulation barely scratches the surface of what effects inflation has on an economy. reply econperplexed 13 hours agoprevOT: I see economists of various ideological tilts constantly arguing about how macroeconomic variables will respond to specific government policies. You know: \"this new tax will increase inflation; no it will not, it will increase unemployment\".What I don&#x27;t get is why there are no readily available online macroeconomic simulators with real world data that make these sort of predictions. For a lot of countries, up-to-date macroeconomic and demographic is readily available.Surely, economists of every ideological tilt have their own standard model of macroeconomics [1] which they use to make rough predictions? If not, how complicated is it really?[1] Much like the standard model of particle physics or of cosmology. Fairly dirty and complicated models with lots of tunable parameters. reply logicchains 13 hours agoparent>[1] Much like the standard model of particle physics or of cosmology. Fairly dirty and complicated models with lots of tunable parameters.Anyone capable of making models that can predict the future with a reasonable degree of accuracy is probably in finance, making 5-10x what they could in economics. The economy is an incredibly complex system, subject to emergent behaviour and chaotic effects, much more so than in physics. You&#x27;ll see papers from the large hadron collider where they prove stuff to within p=0.000001; it&#x27;s impossible to prove anything to that degree of confidence in economics. Especially because it&#x27;s not possible to create true controlled experiments: you can&#x27;t have two otherwise identical societies that differ by just one factor, rather there will always be other ways in which they differ to, and how these are accounted for can have a big effect on the output of models. reply econperplexed 12 hours agorootparentAny model has some precision associated with it. I am not asking for 5 sigma level of precision. But if the economists are fighting about what will happen to a particular macroeconomic variable, they are making a prediction even if it is a log_2(3) bit prediction [1]. There must be some math that is backing that. I want to see it explicitly put into a computational model that runs on live data. Otherwise is there any real content to the arguments that economists are having?> Especially because it&#x27;s not possible to create true controlled experimentsCosmology has zero-experiments. It is a completely observational science [2]. And in fact, has very bad data. Basically a time-frozen snapshot of the universe from a particular point in space. They can&#x27;t even make predictions about the future, only about what some new dataset of that same time-frozen universe will say. Economics on the other hand has the benefit of lots data about interventions and their consequences. There is so much opportunity to develop models by making predictions and checking what happens.[1] variable goes up or down or stays the same.[2] The fact that the roots of modern science lie in a purely observational no-experiment discipline of astronomy is lost on many. reply Aeolun 2 hours agorootparent> I want to see it explicitly put into a computational model that runs on live data.I _also_ want to see it. But I do not want to build it, since it seems incredibly boring. reply logicchains 11 hours agorootparentprev> But if the economists are fighting about what will happen to a particular macroeconomic variable, they are making a prediction even if it is a log_2(3) bit prediction [1]. There must be some math that is backing that. I want to see it explicitly put into a computational model that runs on live dataThis is what (some) people in finance do: make models to predict things, because if something about the future can be predicted to a sufficient degree of accuracy, it&#x27;s generally possible to make money from it. In economics, the incentives are slightly different; in academia, the incentives are to publish interesting&#x2F;novel&#x2F;topical papers, like with other social sciences, not necessarily to make repeatable predictions. In social science nobody gets punished for making an interesting model that hasn&#x27;t been rigorously proven to make repeatable predictions, while in finance on average better models make more money and get rewarded more. But sharing an effective model means other people can use the predictions too, meaning you capture less value from the predictions yourself, so people with an effective model have an incentive not to share it reply rsrsrs86 8 hours agorootparentFew scientific hypothesis have been tested by so much money as that there is no alpha in the market. I mean, the amount of money that goes into proving that wrong is perhaps larger than what went into finding the Higgs boson. reply rsrsrs86 8 hours agorootparentprevBest you can get is some bounds for whatever effect you want to predict and those bounds will open wide very fast.As for lots of data, doing proper econometric models requires really well gathered data. Data is published quarterly or yearly, so you do have comparable series for international country level macroeconomics, but those are actually short considering how many variables must interact. reply HDThoreaun 10 hours agoparentprevThe only real rule in economics, other than simple accounting identities, is that people will do what they think is best for themselves. But everyone&#x27;s utility curve is different, let alone their perception of their utility curve. It&#x27;s incredibly difficult to rigorously model. reply Aeolun 2 hours agorootparentAt sufficiently large scale we should be able to model certain personalities though. reply ch4s3 13 hours agoparentprev> What I don&#x27;t get is why there are no readily available online macroeconomic simulators with real world data that make these sort of predictions.You aren&#x27;t the first person to have this thought. It just turns out to be incredibly difficult. reply mikhailfranco 3 hours agorootparentSounds like we need wikiconomy crowd-sourced model building over two open-source platforms:- mathematical macro-economic simulation run by differential dependencies (like Minsky)- agent-based Monte-Carlo platform for behavioural experiments to find or validate the macro rulesThere would be a core set of models, with parametrized instances running for each country, loosely coupled through trade flows, capital flows, FX markets and migration. reply ttymck 13 hours agoparentprevWhy do you think economics is as deterministic as particle physics? Why should a simulation be any more informative than an economist&#x27;s assumptions? reply KRAKRISMOTT 13 hours agorootparentParticle physics isn&#x27;t that deterministic either. It uses a lot of statistical tricks and hard engineering to reach its results. That&#x27;s why there are so many physicists working as quants. reply rsrsrs86 8 hours agoparentprevEconomics is a science and what an economist calls economics is not what the market things an economist knows.In a science you are interested in testing hypothesis.Econometric&#x2F;statistical models will generally serve to test general hypothesis. What happens if we raise interest rates? Will inflation go down? This can be tested in many ways. But it is not a concern to actually predicate the values of macroeconomic variables. It’s really not interesting academically and basically impossible to do right.This is of course completely out of vogue since ML wiped out the scientific method education of us all. reply amelius 11 hours agoparentprevBecause a good model would be like a self-defeating prophecy. reply jl6 11 hours agoparentprevAn “economy” is composed of people, so maybe we can do this once we’ve cracked simulating people. reply sdfghswe 12 hours agoparentprev> What I don&#x27;t get is why there are no readily available online macroeconomic simulators with real world data that make these sort of predictions.Are you high or what?The problem is so complex that people don&#x27;t even agree how to take a measurement, let alone how to simulate the system. If nowadays people disagree when looking at the same numbers, imagine if each one could point to the numbers in his own simulator. reply econperplexed 10 hours agorootparentLets take a very particular variable. Every month or so, central&#x2F;state banks in every country have a meeting to decide the policy rate. They look at some data and the output of some models, then wave some political magic wand over it and make a decision about which direction to move the rate. Then they make a statement like, \"our decision will decrease inflation over the next three quarters by this much.\"The data they use is usually publicly available, the models used by these must not be very secret. Is it not possible to hook this all up into a nice package, where I can go in and tune some knobs to my liking (there will always be knobs) to get a prediction on the inflation over the next three quarters.Then, I can publicly claim, \"Given this data, and this model, and my knob settings, here are my prediction.\" Then some other economist can come and dispute the data, model and the knob settings. They select a different data source, model and their own knobs.Then three quarters later we check who made the right prediction.Notice, I am not asking for the correct model of reality. Only a playground where people can argue using concrete data, models and knobs. reply mathiasgredal 9 hours agorootparentThe Danish Ministry of Finance has a public model they use to forecast the economic impact of certain policy decisions called MAKRO: https:&#x2F;&#x2F;github.com&#x2F;DREAM-DK&#x2F;MAKRO&#x2F;tree&#x2F;main reply redandblack 13 hours agoparentprevbut but ... you cannot have data get in the way of good theory. reply Supply5411 13 hours agoprevWhere are the bad actors who exploit the system to steal from everyone? No economic simulator is complete without this.Edit>> It appears to be the state. reply jampekka 13 hours agoprev [–] No banks, no capital, no capitalists living off the workers&#x27; labour. This is not even close how the economy works. reply random3 11 hours agoparent [–] You know banks exist outside of capitalism, no? reply jampekka 2 hours agorootparentYes. reply vkou 10 hours agorootparentprev [–] While it&#x27;s true that banks can exist outside capitalism, capitalists generally can&#x27;t.---The parent&#x27;s point is that an economic simulator that does not include them is probably not something that&#x27;s useful to draw conclusions about capitalist societies from.It is a fun toy, though. reply dragonwriter 10 hours agorootparent [–] > While it&#x27;s true that banks can exist outside capitalism, capitalists generally can&#x27;t.That&#x27;s not really true; people who own and profit from their ownership of the means of production exist in feudal economies; the fact that their ownership of the means of production is a sonetimes a consequence of rights associated with land tenure and, whether or not that is the case, not marketable or less freely so than under capitalism the capital, makes the system not capitalism, but doesn&#x27;t make the owners of capital not capitalists.Capitalists qua capitalists aren’t the ruling class outside of capitalism (though being a capitalist was also a subordinate part of being part of the labded aristocracy, and control of certain elements of the means of production was connected to land tenure), but they still can exist. Capitalism as a system is mostly a result of the non-landholding capitalists progressively leveraging their existing wealth to gain more systemic advantage (at the express of the landed aristocracy) than they enjoyed in pre-capitalist economies. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author is creating an economy simulation from the ground up and recording their progress.",
      "They start with a single entity and introduce theories about resource utilization and production, and gradually incorporate more workers specialized in water production.",
      "They introduce money as a mechanism to account for shared resources, providing an interesting dynamic to their simulation."
    ],
    "commentSummary": [
      "The Hacker News discussion focuses on the creation of an economy simulator and explores its relationship with economics, psychology, and real-world data.",
      "Participants highlight the challenges of accurately modeling and simulating complex economic systems, stressing the importance of incorporating real-world data and accounting for bad actors and exploitation.",
      "The debate also touches on the existence and roles of capitalists outside of capitalist economic systems. The discussion underlines key issues such as the concentration of wealth and the limitations of economic models."
    ],
    "points": 348,
    "commentCount": 144,
    "retryCount": 0,
    "time": 1694804772
  },
  {
    "id": 37524202,
    "title": "Shrinkflation Tracker",
    "originLink": "https://www.shrinkflation.io/",
    "originBody": "🔎 shrinkflation.io Search log in products brands Tired of products getting smaller, while their prices remain the same? We're on a mission to stop Shrinkflation. Cadbury Dairy Milk 110g▼ 10% Mars Maltesers 37g▼ 5% Bassett's Jelly Babies 190g▼ 15% Cadbury Flake 32g▲ 2% Maynards Bassetts Wine Gums 190g▼ 10% Nestlé Kit Kat 41.5g▼ 3% Nestlé Aero 27g▲ 1% Cadbury Curly Wurly 26g▼ 0% Wrigley's Skittles 55g▲ 4% Nestlé Smarties 38g▼ 2% Rowntree's Fruit Pastilles 150g▼ 8% Nestlé Lion Bar 50g▼ 6% McVitie's Caramel Digestive 267g▼ 18% Cadbury Double Decker 54.5g▲ 3% Terry's Chocolate Orange 157g▼ 14% Nestlé Walnut Whip 34g▼ 1% Mars Galaxy Minstrels 42g▼ 3% Barratt Sherbet Fountain 25g▼ 2% Cadbury Dairy Milk 110g▼ 10% Mars Maltesers 37g▼ 5% Bassett's Jelly Babies 190g▼ 15% Cadbury Flake 32g▲ 2% Maynards Bassetts Wine Gums 190g▼ 10% Nestlé Kit Kat 41.5g▼ 3% Nestlé Aero 27g▲ 1% Cadbury Curly Wurly 26g▼ 0% Wrigley's Skittles 55g▲ 4% Nestlé Smarties 38g▼ 2% Rowntree's Fruit Pastilles 150g▼ 8% Nestlé Lion Bar 50g▼ 6% McVitie's Caramel Digestive 267g▼ 18% Cadbury Double Decker 54.5g▲ 3% Terry's Chocolate Orange 157g▼ 14% Nestlé Walnut Whip 34g▼ 1% Mars Galaxy Minstrels 42g▼ 3% Barratt Sherbet Fountain 25g▼ 2% Track offending products and brands sadly made by sam lader about privacy policy contact",
    "commentLink": "https://news.ycombinator.com/item?id=37524202",
    "commentBody": "Shrinkflation TrackerHacker NewspastloginShrinkflation Tracker (shrinkflation.io) 305 points by samlader 19 hours ago| hidepastfavorite211 comments hinkley 12 hours agoI was just talking today to someone about how they don&#x27;t like food from a certain global coffee chain anymore because their food has gotten kinda crappy.Shrinkflation generally means same price for less product (grams, fluid ounces), but enshitification by slowly decreasing the quality of the ingredients is also a problem.Do we put that under the shrinkflation umbrella or track it as a separate problem? Since they are both unwanted solutions to the same problem, seems like they should be kept together (to avoid a Goodhart&#x27;s Law fiasco)I recall eating an Oreo after fifteen years of not having one. At first I just thought I&#x27;d forgotten what they actually tasted like, but the more I thought about it, the more I could see a long chain of focus groups asking customers if cookie A and cookie B taste the same, if one tastes better, and slowly changing the formula to only alienate 0.2% of the customers each time until one day I wander up and find I&#x27;m part of the 10% they&#x27;ve cumulatively alienated.See also how only some of us can taste certain artificial sweeteners as sugary toxic waste instead of sugar (saccharin tastes to me like drinking soda after licking a 9 volt battery) reply cogman10 11 hours agoparentJust one more factor to consider, some ingredients are no longer available.Trans fats are a good example of this. They used to be the prime replacement for saturated fats. Now, in the US, they are effectively banned.This hit oreos. [1][1] https:&#x2F;&#x2F;www.orlandosentinel.com&#x2F;2006&#x2F;01&#x2F;02&#x2F;manufacturers-tri... reply hinkley 11 hours agorootparentFair point. Were oreos always palm oil or were they lard back in the day?The fracking industry has made guar gum too expensive to use as a food emulsifier. I know someone who reacts to xanthan gum (which has all but replaced guar) and she&#x27;s not a happy camper, because it&#x27;s in fucking everything. reply smnrchrds 5 hours agorootparent> Were oreos always palm oil or were they lard back in the day?They did use lard till mid 90s.https:&#x2F;&#x2F;news.cornell.edu&#x2F;stories&#x2F;2008&#x2F;02&#x2F;getting-lard-out-ko... reply skyyler 11 hours agorootparentprevNo, they were partially hydrogenated soybean oil back in the day.Palm oil is thick at room temp, like partially hydrogenated oils are. reply aequitas 11 hours agoparentprev> but enshitification by slowly decreasing the quality of the ingredients is also a problem.Every time you see a package with “new and improved recipe” you can bet it only improved their margins by using cheaper ingredients, not the actual taste. reply hinkley 10 hours agorootparentThey didn&#x27;t say who the recipe was improved for... reply shostack 8 hours agorootparent\"Amazon&#x27;s Choice\" comes to mind, though at least they are a bit more direct in the wording of it in terms of whom it benefits. reply amelius 11 hours agorootparentprevHow is that possible if the rock solid theory underlying the free market promises us better products? &#x2F;s reply shaftoe 10 hours agorootparentActually, free markets do lead to better products. But they cost more than the worse products.Look at coffee. The gradual shift from Arabica to more Robusta beans over a generation. Each year, an imperceptible shift was taken that, over decades, lead to coffee that tastes terrible. Opening the door for companies like Starbucks and a ton of gourmet roasters to compete.But properly roasted, single origin coffee costs more than Chock-full-o&#x27;nuts. So you have options. reply hinkley 10 hours agorootparentI react poorly to some coffees and not others. I&#x27;ve been told by people who claim to know that some people can&#x27;t stomach Robusta as well as they can Arabica. And I&#x27;ll be damned if I know how to track which one I&#x27;m actually getting.I&#x27;ve surrendered and just drink tea and chai now. reply amelius 10 hours agorootparentprevThe only thing that Starbucks did for coffee was that children now also love to drink it.In fact their coffee doesn&#x27;t taste like coffee, but more like mocha&#x2F;hazelnut ice cream. reply Retric 9 hours agorootparentToday’s Starbucks is well removed from its origins. Starbucks was never great coffee, but I’ve heard it started out pretty decent.Much like how McDonalds, KFC, etc started by making decent food so did Starbucks. Add 40+ years of optimizing for the bottom line and the average person’s pallet and you get a very different product. reply bobthepanda 5 hours agorootparentAnecdotally I believe McDonald’s actually does very well on blind taste tests. reply noirbot 6 hours agorootparentprevAre you talking about their black coffee? Or their other sorts of drinks that are often less than 50% actual coffee? Because if anything, the usual complaint about literal coffee at Starbucks from people who like coffee is it tastes too much like coffee, in the sense of being over-roasted and uninteresting. Even their blonde roast is still at best a medium roast at any other modern roaster. reply hinkley 2 hours agorootparentThe thing that surprised me about burnt coffee beans is that people assume that the heavier the taste the more caffeine is there and that’s not true of over-roasting. It’s less available caffeine, not more. So it tastes terrible for no practical reason. reply Gud 10 hours agorootparentprev\"better\" doesn&#x27;t necessarily mean higher quality. It can mean faster delivery, cheaper, lighter, etc. Many parameters goes into better. reply amelius 10 hours agorootparentYet every time I see a product advertised with \"new and improved recipe\", I can rarely tell along which axes it has actually improved. Usually I want the old product back. reply amelius 11 hours agoparentprev> Do we put that under the shrinkflation umbrellaNo we call it just that, enshittification. reply krapp 11 hours agorootparent>No we call it just that, enshittification.I&#x27;ll be glad when this juvenile meme finally passes out of Hacker News&#x27; system. reply londonReed 5 hours agorootparentI&#x27;ll do my best to keep it going, unless you have a better term. Enshittification clearly communicates the point trying to be made. reply hinkley 10 hours agorootparentprevIt&#x27;s basically &#x27;race to the bottom&#x27; but that term is not very inspirational. It&#x27;s not evoking any kind of reaction in the masses. reply krapp 8 hours agorootparentNeither is \"enshittification.\" Only HN and some tech bloggers even use it as far as I know, and mostly just to be able to imply something is \"turning into shit\" while pretending to use a precise term of art. But it isn&#x27;t, it&#x27;s a poop joke. reply Cincinnati2 8 hours agorootparentI agree with Krapp. replyzerd 5 hours agoparentprevI&#x27;ve been buying the exact same pair of boxers for years. This year I noticed that they were actually smaller, by almost an inch. Elastic band is smaller and the actual length, so it started chafing. Shrinkflation even on clothes. reply pcthrowaway 3 hours agorootparentHeh.. I&#x27;d like to blame my boxers getting tighter on the same thing but I&#x27;m pretty sure it&#x27;s just my waistline that&#x27;s grown reply hinkley 2 hours agorootparentWhen Levi’s moved to Mexico it wasn’t that the sizes got smaller, it was that they got inconsistent. Before I started shopping around for more responsible brands, I enjoyed the privilege of being able to walk into a department store and simply buy jeans based on the label. No dressing room. After I had three pairs of the same sized jeans that varied from uncomfortable to comfortable. Tolerances matter. reply _sys49152 7 hours agoparentprevmy sensory skills are on point. its beyond infuriating when i notice a change in a food or drink product, hop online and search for the others with the pitchforks to join in with - only to find crickets.wav. reply ajsnigrutin 12 hours agoprevIn an ideal world, one UPC code would identify only one product with one set of ingredients and one weight. Want to make a \"+20% free!\" package? New UPC! Want to change the contents from 16% cacao to 14% cacao and some more sugar? Sure, new UPC.The manufacturers would have to publish the contents for each UPC in a machine readable format.Then the retailers would have to publish daily prices, again in a machine redable format....and the world would be a much nicer place for the consumer. Everyone could build apps on top of that, you could compare retailers, comparable items could be crowdsourced (eg, 1L of 3.5% fat milk and a list of all UPCs for that), shopping list apps could calculate the cheapest options to choose the cheapest store, or in cases with multiple stores in a cluster, tell you what to buy where, etc.And the best thing is, that nobody actually regulates any prices or item sizes, just the consumer gets more informed. reply rendaw 7 hours agoparentI thought this too, re: for Amazon review farming, but products are never homogeneous from the start.All products have multiple component suppliers, with different tolerances&#x2F;varieties, where the components are judged \"close enough\". Suppliers come and go. And even if it&#x27;s a single large supplier, they may have different farms&#x2F;factories&#x2F;etc so you won&#x27;t even be getting homogeneous components from them. reply saulrh 6 hours agorootparentThen extend product codes until every single individual batch - or even every single individual item - has a unique ID. Store information hierarchically if you have to to save space, but we have the technology today to track every single component of our entire supply chain. The automotive, aerospace, and defense industries already do this. The food industry even has the processes in place, they just only do the bare minimum to execute a recall when the FDA calls them on their shit. Even pet food can pull it off! All we have to do is make manufacturers go that rest of the way. reply acover 9 hours agoparentprevThe business just make store specific upcs like mattresses. Same cookies, different number reply Horffupolde 12 hours agoparentprevYou are free to do that. UPC is a private standard. reply phailhaus 16 hours agoprevSuper cool! Very clean, nice font. Some UX things I noticed:1. In the scrolling feed on the homepage, a 0% change is shown as negative with a red down arrow2. In the tracker page, 0% is grey (good!) but still with a down arrow, which isn&#x27;t accurate3. Might be a good idea to highlight egregious offenders over small decreases. Maybe bold the value if it&#x27;s greater than 10-15%?4. Would be cool to be able to sort to see the worst offenders! reply boxed 16 hours agoparentI wonder why 0% items are shown on the big list at all. Like having a page of murderers with random innocent people with a text label under \"not a murderer\" :P reply herpderperator 15 hours agorootparentIt could be greater than 0% but less than 0.5%, ending up rounded down when displayed. The value getting checked might be against the raw value rather than the rounded one. Which, of course, is a bug. reply seabass-labrax 16 hours agorootparentprevThat would actually be beneficial to the innocent people if it gave them indemnity to prosecution! It&#x27;s better to be cleared of a suspected crime than never prosecuted, in my opinion*.* assuming the availability of pro bono legal aid as part of social welfare, a key part of any judicial system. reply kepano 15 hours agoprevIn a high-inflation environment your profits are constantly shrinking. The problem also affects small and independent makers of all kinds.If you are an indie maker and priced your product at $10 in 2020, you&#x27;re now effectively making $8.38 USD[1]. Assuming inflation will remain elevated and you want to maintain the same margins, you need to either:1. increase prices2. reduce quality&#x2F;quantity&#x2F;features3. reduce supplier costs4. reduce service costsCustomers are very sensitive to increases in prices. This is a case where none of the options are great.[1]: https:&#x2F;&#x2F;twitter.com&#x2F;kepano&#x2F;status&#x2F;1702401372661096477 reply imglorp 15 hours agoparentThere&#x27;s more malfeasance here.5. They expansively tier their product line with minor variation to remove the idea of a standard offering. Eg there are some 33 sizes of M&Ms so nobody could say \"get me a bag of M&Ms\" any more. Forget comparing cell service plans. * https:&#x2F;&#x2F;www.measuringhow.com&#x2F;m-and-m-bag-sizes-guide&#x2F;6. They generate different model names for sale at different retailers to obstruct comparison shopping. The TV, appliance, and mattress industries are dirty here. * https:&#x2F;&#x2F;www.quora.com&#x2F;Why-are-model-numbers-for-the-same-appliance-all-different-in-each-store-you-visit?share=17. They attempt to detect when comparison shopping is happening and intervene. * https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;news&#x2F;innovations&#x2F;wp&#x2F;2017&#x2F;06&#x2F;16&#x2F;amazon-has-a-patent-to-keep-you-from-comparison-shopping-while-youre-in-its-stores&#x2F; * https:&#x2F;&#x2F;www.patriotsoftware.com&#x2F;blog&#x2F;accounting&#x2F;discouraging-price-shopping&#x2F; reply consp 12 hours agorootparentAnd onther method is offering a new product in the same category with less content for a higher price, eventually switch over all products and level the price, now you have less at the same or higher prices for all products (looking at you teisseire as a latest example) reply masfuerte 14 hours agorootparentprevShoe and boot manufacturers also do 6. reply dweinus 14 hours agoparentprevThat&#x27;s a good explanation, but problems with silently reducing quantity are: - It attempts to trick the customer - As a customer, it makes it harder to depend on your product or buy predictably (a box of cereal used to last me through the week, now suddenly it doesn&#x27;t) - It is now harder for me to comparison shop because I need to calculate cost per volume&#x2F;weight - It is often done at a rate higher than inflationThis site is great, people need more transparency and companies need to be called out reply n8cpdx 14 hours agoparentprevMost of the products on the site appear to be candy&#x2F;junk that shouldn’t be consumed in large quantities anyway. There is probably substantial social good being done by making the default portions of pringles and chocolate smaller. reply djmips 8 hours agorootparentWhat if people just buy more and now there is more package waste? reply ImPostingOnHN 15 hours agoparentprevthis is an accurate description of shrinkflation, though not a good justification of itif companies were honest, they&#x27;d put\"29% less, but the same price! Inflation, you know?\", and more-informed consumers could make more-informed choicesindeed, \"Customers are very sensitive to increases in prices\" is a nicer way of saying \"shrinkflation makes it easier to hide from consumers that they are receiving less value for their money\"Thank you for this site, if the author is here, it&#x27;s something I felt we needed to make markets more informed and more efficient. I&#x27;ll be submitting content. reply kepano 15 hours agorootparentI&#x27;m not defending CPG companies. I&#x27;m pointing out that if you&#x27;re an indie maker inflation is a problem you need to contend with in your own pricing. Once you start thinking about it from that perspective, you realize how difficult of a problem it is to solve in a way that feels fair to customers.In theory software is easier because you could more easily change your pricing every month. With CPG these products sit on store shelves and the manufacturers have less direct control over the pricing. reply ImPostingOnHN 15 hours agorootparentThe issue most people have with shrinkflation isn&#x27;t that the manufacturers made a tough call when all the options were tough, it&#x27;s that manufacturers do so in a manner deliberately calculated to hide information from the consumer, and in some cases outright deceive them (if they didn&#x27;t, this shrinkflation tracker wouldn&#x27;t exist)To reiterate, a company honest with consumers would inform them they were getting less for the same price, and try to make the case you&#x27;re making now: \"hey, sorry about this, but times are tough, and we can&#x27;t raise prices\"Less scrupulous and deceptive companies don&#x27;t reply kepano 15 hours agorootparentNot sure if this fits under shrinkflation, but the practice of substituting quality ingredients for cheaper ones is even worse IMO. When Nutella did it, it caused a huge kerfuffle, but it&#x27;s virtually impossible for a consumer to track this across all the products they buy.An upstream problem is the money printing that causes some of these incentives in the first place. reply robertlagrant 15 hours agorootparentprev> To reiterate, a company honest with consumers would inform them they were getting less for the same price, and try to make the case you&#x27;re making now: \"hey, sorry about this, but times are tough, and we can&#x27;t raise prices\"How do they do this? They make a chocolate bar that a shop buys and puts on a shelf. reply ImPostingOnHN 15 hours agorootparentThey have to alter the packaging to account for the changes. They can either do so in a way that makes apparent to the customers that they&#x27;re receiving less value for their money, making sure they&#x27;re aware of it, or they can do so in a way that attempts to deceive consumers and hide this information.An example of messaging for the former is described in the quote you quoted. Another would be to use different-looking packaging, to indicate that it is not what it was before. If a consumer will still buy the item when properly informed of the lower value, then this apparent labeling should not have any effect on sales. If it does, it means the information hiding was material, which makes it bad.tl;dr: companies hide this information because being deceptive increases sales, if it didn&#x27;t, they wouldn&#x27;t reply robertlagrant 2 hours agorootparent> If a consumer will still buy the item when properly informed of the lower value, then this apparent labeling should not have any effect on sales.If it looks different, consumers might not know it&#x27;s the same thing just smaller. E.g. if I buy a box of Celebrations, I know what each little sweet is because it shares the same packaging as its normal-sized equivalents. I know it&#x27;s smaller because...it&#x27;s smaller. replyadamc 15 hours agorootparentprevBeing honest doesn&#x27;t pay as well. If it did, they would just raise the price.They are hoping you don&#x27;t notice. reply wppick 14 hours agoprevAnother source of shrinkflation is changing ingredients. Something that used to be 50% water is now 75% water as an example. Another is changing from olive oil to canola or palm or, and things like that. reply chongli 13 hours agoparentOne of the worst offenders in this regard is packages of frozen meat products such as chicken wings, chicken fingers, nuggets, etc. They used to just contain the breaded meat with the net weight printed on the box (usually 2 lb).Now they&#x27;ve started including frozen sauce packets as well. I&#x27;ve weighed some of these and found, for example, a 2 lb box of chicken wings that comes with more than half a pound of buffalo sauce. The net weight stays the same (2 lb) but if you weigh the chicken you&#x27;re getting less than 1.5 lb of meat! The rest is all sauce! reply djmips 8 hours agorootparentSort of related is chocolate. I feel like &#x27;pure&#x27; chocolate is a loss leader and all of the other types with mixed in caramel bits etc are a way of selling you a bunch of cheaper stuff for the same weight and price! Better to just buy the least adulterated chocolate for the best deal. reply chongli 8 hours agorootparentOr how about bread? I’ve seen some breads manage to increase the water content dramatically. You throw a slice in the toaster and it comes out weighting nothing at all, like a cracker! reply freeqaz 10 hours agorootparentprevThat&#x27;s amazing that it isn&#x27;t illegal to do that. I wonder if the laws will force companies to list out how much weight each component is like that.But then again if there is no health impact (like with Trans fats) then is there any incentive for the regulators to change this?Has the FDA ever done any work to protect consumers from sketchy marketing&#x2F;labeling of products?(I asked ChatGPT and it gave me a few bits. Apparently the term \"Healthy\" is regulated. And serving sizes are another that seem to be regulated. Maybe there is an angle within there that would make sense.) reply yoyoyo1122 12 hours agoparentprevYeah, people call it skimpflation: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Shrinkflation#Skimpflation reply spaceman_2020 7 hours agoparentprevI’ve also seen a change in packaging, example: changing from a glass bottle to a plastic bottle. reply purplecats 13 hours agoparentprevwe need github tracking for the changes in metadata for products, like we do for legislation or the terms of use (like the one that unity deleted) reply bjfish 12 hours agoparentprevI think the toilet bowl cleaner used to be more viscous and last a long time. reply mkoubaa 12 hours agoparentprevI mind this much more than I mind shrinkflation reply djmips 8 hours agorootparentYes because it makes it potentially less healthy and often worse tasting &#x2F; useful. reply abeppu 17 hours agoprevOddly, search only covers brand names?https:&#x2F;&#x2F;www.shrinkflation.io&#x2F;search?query=soap Why would this benefit society?To put factual and open information out there of how companies consistently just fuck with all of us and get away with every little thing they can because \"profits!\" and \"their duty to investors!\". e.g., the biggest lies our societies ever came up with reply lotsofpulp 16 hours agorootparentIt is already open information that pretty much every seller of everything in the whole world tries to sell for as high of a price that they think can get.And that purchasing power of currencies will go down over time. reply Vicinity9635 10 hours agorootparent>And that purchasing power of currencies will go down over time.This is only true when you keep printing more of it. The creation of currency outpacing the creation of value is inflation. reply c0pium 6 hours agorootparentInflation existed for currencies that were on the gold standard too.There was over a decade of QE which the rainmakers said would totally cause inflation. It didn’t.Then there were supply side shocks which would definitely only cause transitory inflation. Also wrong.Then we learned that sentiment causes it, and in the middle of terrible sentiment inflation went down.Every complex problem has a simple, intuitive, easy to understand wrong answer. It is not an exaggeration to say that we do not know what causes inflation. reply read_if_gay_ 16 hours agorootparentprevi can&#x27;t believe the sole use you could think of is timing the market on junk food replyhhthrowaway1230 16 hours agoprevWould be nice to have the actual owning organisations in there. i bet these are largely subsidiaries of the same mother company. reply karim79 16 hours agoparentI remember using this app[0] on my phone years ago, I just checked and they have an API. I&#x27;m not sure, but if I recall correctly this allowed you to scan barcodes of things and warn you if they are sub-brand or subsidiary of [evil company you wish to avoid].[0] https:&#x2F;&#x2F;www.buycott.com&#x2F;api reply Vicinity9635 10 hours agorootparentIs this the one that explicitly won&#x27;t let you boycott products by Israeli companies?edit: Yep https:&#x2F;&#x2F;honestreporting.com&#x2F;fighting-bds-with-buycotts&#x2F;You can use it to boycott anything (perceived as conservative or neutral) you like as long as it&#x27;s not progressive or Israeli.So, useless. reply karim79 10 hours agorootparentWasn&#x27;t aware of that, also my use-case during the brief time I messed with it was trying to see how clever it was at identifying companies which use animal testing to develop their products.Thank you for the link. reply doubled112 15 hours agorootparentprevWas it just based on that chart about the illusion of choice? reply corinroyal 16 hours agoparentprevThis was my reaction too. I&#x27;d like to see which conglomerates and their divisions are the worst offenders. To break it down by brands alone makes it hard to identify who to name and shame. reply Fatnino 9 hours agoprevI have an original Pringle&#x27;s can from the late 70s or whenever it was. (yes, it used to have an apostrophe in the name).It contained 4.5 ozs of \"newfangled potato chips\" (I think they legally can&#x27;t call them chips anymore). That works out to about 125grams give or take.This site is kvetching that they are at 200 grams now.Ps, my can doesn&#x27;t have a UPC barcode on it because they hadn&#x27;t been invented yet. reply MikusR 15 hours agoprevIn EU prices for food stuff have to also list price per KG. reply Crunchified 13 hours agoparentHere in the US, while unit pricing is commonly displayed, I frequently find that a store will use a wide variety of units, thereby negating the ability to easily compare items in this way. For the same type of product I may see cost per ounce, cost per pound, cost per each, cost per dozen, etc. for various sizes and brands. It&#x27;s maddening, insulting, and probably in most cases malicious. reply ftyers 11 hours agorootparentYeah, this is insane e.g. I&#x27;ve seen cents&#x2F;fl.oz, dollars&#x2F;litre, cents&#x2F;ml, dollars&#x2F;unit. For the same product. And yes, totally malicious. Fresh Thyme does this. It&#x27;s ugly. reply cj 15 hours agoparentprevThis is also common in the US.Example below. Top row is blurry but bottom row shows “per ounce” price on the bottom right. Tiny print and I imagine barely anyone actually shops that way.I’m guessing there must be some US requirement for this otherwise I’m not sure why it’s commonplace.https:&#x2F;&#x2F;supersafeway.com&#x2F;wp-content&#x2F;uploads&#x2F;2016&#x2F;08&#x2F;Screen-S... reply ericpauley 14 hours agorootparent> I imagine barely anyone actually shops that way.This feels so foreign to me; I largely ignore the overall price and shop by unit prices within a reasonable size range. reply belval 14 hours agorootparentI think the commenter you are responding to does not have enough faith in humanity. Most people I know (anecdotal and biased sampling I know) do check that number when shopping, especially for interchangeable items that don&#x27;t have a well-know brand such as flour or baking powder. reply gen3 13 hours agorootparentprevAncidotal, but myself and many of my friends shop this way. I&#x27;ve found that sometimes the larger bottle isn&#x27;t cheaper per unit reply sebazzz 15 hours agoparentprevYes, but no history. reply imbusy111 11 hours agoprevA lot of it looks like candy, so it could be a good thing. reply furyofantares 11 hours agoprevI don&#x27;t like that it&#x27;s sneaky, but I would rather candy servings get smaller rather than prices get higher, if those are the options. reply syassami 16 hours agoprev@samlader - now overlay the graphs with EPS growth * -1 to see correlation reply wackget 9 hours agoprevWhen submitting a weight, the site should allow you to submit a reference such as a newspaper article, an archived website, or other form of proof. And the proof should be publicly visible. reply nowooski 15 hours agoprevI ticker arrows could use explanation. I assume green is good and red is bad, but it&#x27;s not immediately clear what the units are ect. reply smath 14 hours agoprev% change is over what time frame? YoY? reply IAmGraydon 12 hours agoprevThe worst part of shrinkflation is restaurants who have reduced the sizes of their meals, in my opinion. I’ve seen this quite a lot in everything from fast casual places like Cava to locally owned establishments. reply jacquesm 11 hours agoparentThat may not be a bad thing per se. In plenty of restaurants the amount of food in a serving is way too large for me and the alternative probably was to raise prices. In restaurants food isn&#x27;t usually the high margin product, that&#x27;s alcohol. reply c0pium 6 hours agorootparentMost fast casual places don’t sell much alcohol. reply steine65 11 hours agoprevVery cool. Looks like it could use some more controls to reduce bad data. For example the Dove year 9999 data point.I would love to see a list of Parent companies. Single brands will be hard to remember. reply zamadatix 12 hours agoprevFor some reason the same product often shows up multiple times in the list. And I don&#x27;t mean \"the product looks the same\" I mean \"the URL it links is even the exact same\" . reply Koeniggimeno 15 hours agoprevGreat Idea! Perfectly executed, great site to give some awareness to the average consumer. reply _aavaa_ 14 hours agoprevOn mobile some of the prices show up as 8E210, which is a hilarious bug reply kardos 13 hours agoparentOr someone added a bogus &#x27;observation&#x27; reply jacquesm 11 hours agoparentprevSame on FF. reply lucb1e 10 hours agoprevWanted to add a product, but you can&#x27;t sign up for the site: you need to go sign up to Google first... reply patrickwalton 13 hours agoprevWe saw shrinkflation with our apartments when they went from a central dumpster to expecting everyone in an 8-unit complex to line up cans on the road reply robertheadley 11 hours agoprevGreat, but manual input and seems to be focused on the UK. I think someone needs to brute force this problem. reply alex_young 13 hours agoprevI don&#x27;t really understand the recent focus on this. Shrinkflation has always been a thing, and it seems like it shouldn&#x27;t be strongly correlated with actual inflation, since the critical equation is something like how much material should a given product contain to provide enough value to consumers, or in other words it&#x27;s equally advantageous to optimize the value of your product in times of low or high inflation and thus optimize margins.Maybe we just care more about it when we see prices raising in general? IDK. reply prepend 12 hours agoparentIt’s not a recent focus, it’s a continual focus.Shrinkflation is important for understanding true price increase. It’s not enough to say “toothpaste went up 20%” in price because you really want to know “toothpaste went up 35% based on weight.”It’s also frustrating because it’s just another level of bullshit to sift through when shopping. It would be nice if manufacturers and retailers didn’t do this. reply c0pium 8 hours agorootparentYou don’t need to sift through it, though. There’s no prize for catching companies in the act. Figure out which toothpaste you want, decide whether youre willing to spend the money, then buy it or don’t.They do it because otherwise people will complain incessantly about price increases and this way people only complain intermittently about shrinkflation. reply pazimzadeh 13 hours agoprevRecently I noticed that the baguettes at Whole Foods (in St. Louis) are about 2 inches shorter than before. They are the same price. reply willio58 12 hours agoprevI&#x27;ve definitely experienced this with colgate toothpaste and sure enough it&#x27;s on this list! reply thatxliner 5 hours agoprevCrowdsourced data? reply playerm1 9 hours agoprevWerther&#x27;s Original did not betray us. reply jacobsenscott 11 hours agoprevWhat&#x27;s the problem? You want to keep everything the same size and pay more? That&#x27;s the other option. You know it works out to the same amount of stuff for the same amount of money, right? reply DoughnutHole 11 hours agoparentYes, because it’s easier to notice and adjust your purchasing decisions accordingly.The point of shrinkflation is to obfuscate the price increase and hope that some consumers don’t notice. reply lwansbrough 13 hours agoprevI would like to be able to sort by change delta. Cool site! reply kamikaz1k 14 hours agoprevseeing \"Do not know how to serialize a BigInt\" reply salawat 5 hours agoparentThat&#x27;s just a sign they knocked a few bits off datatype but are still trying to pass it off as the same thing. Serializers, however, are onto them. reply kernx16 16 hours agoprevitd be interesting if tracking price is also included, although I can imagine that would be insanely difficult to keep track of for many reasons. I love this idea and hope it continues to grow. reply spandextwins 13 hours agoprevRonald Reagan used to have the misery index reply eppsilon 13 hours agoparenthttp:&#x2F;&#x2F;www.miseryindex.us&#x2F;indexbymonth.aspx reply DanHulton 13 hours agoparentprevI feel like Reagan used to _cause_ the misery index. reply spandextwins 13 hours agorootparentThey all do reply Hard_Space 16 hours agoprevI have thought about developing this site for the last 3-4 years! This is exactly what it would have looked like. Thanks for saving me the trouble (if I ever had got round to it). reply maxbond 15 hours agoprevVery cool! Where are you sourcing data from? reply akomtu 11 hours agoprevWhy does it track some irrelevant products? It should track things that matter: milk, bread, meat, fish, fruits and so on. reply c0pium 4 hours agoparentIt tracks things people actually buy. reply jqjqjqjq 13 hours agoprevShould be able to sort by highest to lowest. Name and shame&#x27;em! reply purplecats 11 hours agoprevcan you automate this with amazon parsing? reply incrudible 9 hours agoprevShrinkflation of these products is better than increased prices, because you should not eat&#x2F;drink so much of this crap anyway. reply ShadowBanThis01 15 hours agoprevLove the idea, but how far back do the data go?And someone pointed out the preponderance of junk food; I want to see core items that are often used in recipes. To me this is the most offensive aspect of these scams: You know your favorite recipe takes four cans of tomatoes, cans that have been the same size for decades. Now... WHOOPS, your meal is messed up because the manufacturer is too gutless to simply raise the price.The one example I see on the site is butter: https:&#x2F;&#x2F;www.shrinkflation.io&#x2F;search?query=butterThese jagoffs reduced the quantity by 20%, which is definitely enough to mess up recipes. reply KomoD 13 hours agoparent> but how far back do the data go?Anywhere from 1297 to 9248 apparently, I guess he must have some kind of time traveler reply ClumsyPilot 16 hours agoprevSo is shrinkflation actually included in official inflation numbers? If all bars of soap in the country become smaller by 10%, does &#x27;official&#x27; inflation number go up? Are the folks tracking official inflation index equipped to measure all the various products per kilo, etc? reply hankchinaski 14 hours agoparentin the uk we measure the price of a basket of goods, which includes quantity adjustment. So packaging size is irrelevant. https:&#x2F;&#x2F;www.ons.gov.uk&#x2F;economy&#x2F;inflationandpriceindices&#x2F;meth...>The simplest form of direct adjustment is quantity adjustment, which is used when there is a permanent size change in an item. reply vuln 15 hours agoparentprev“Inflation? There’s no inflation, we’ve created millions of jobs and pay has increased!” - Current Administration reply vuln 14 hours agorootparentThe truth hurts more than the downvotes. reply realjohng 15 hours agoprevFabulous… I heart data reply xwdv 14 hours agoprevI don’t get it, would people rather pay higher prices up front?A lot of times people don’t even use the entirety of a product they pay for. Shrinkflation can essentially just cut that part out. Even if you eat 100% of something, your brain was probably satiated after eating 80%, the rest is excess.For stuff like candy you won’t notice a missing gummy bear or two. You’ll get the same satisfaction. reply daveoc64 14 hours agoparentA lot of people resent how sneaky shrinkflation feels.Manufacturers would gladly boast about increasing the size of their product if they did so, but do everything they can to hide when they&#x27;ve shrunk it.Manipulative tricks like oddly shaped packaging or plastic fillers to take up the space that was previously product are examples of why people hate shrinkflation.If something goes up in price but the quantity and quality stayed the same, people wouldn&#x27;t feel like they&#x27;re being tricked. reply xwdv 14 hours agorootparentThey wouldn’t feel tricked, but then they’d be pissed off at the rising prices, which affects their ability to enjoy the product.If someone sells you a bag of chips but they’ve already eaten two of the chips, your enjoyment of the bag will still be the same as if you had the whole bag. If they reveal that fact to you though, then your experience will be soured.This is for the consumer’s own benefit. reply lotsofpulp 13 hours agorootparentPeople just like to feel outraged, apparently. reply chucksmash 10 hours agorootparentIf you&#x27;ve always been sold a dozen eggs in a package that can hold twelve eggs, but suddenly the same package is relabelled and used to sell you only ten eggs, who in the world looks at that situation and says \"as a rational market participant, I can&#x27;t be mad because the package has indeed been updated to say &#x27;ten eggs&#x27; and I just failed to take notice (yolk&#x27;s on me).\"People like to be dealt with fairly. When they occasionally notice things that make them realize there are rooms full of people whose entire job is to trick them, they don&#x27;t like it. Where&#x27;s the mystery? reply c0pium 4 hours agorootparentReading isn’t hard. People should try it. reply c0pium 4 hours agorootparentprevSo much of modern life boils down to this. reply vmilner 11 hours agoparentprevWhen I see perceivable sneakiness, I assume non-perceivable sneakiness is there too. (E.g. Poor product standards, worker abuse) reply waffleiron 14 hours agoparentprevIf it’s two gummy bears a year, a decade later it’s an empty bag. reply sgu999 13 hours agoprevNice project, very clean etc.Now about that shrinkflation thing... There isn&#x27;t a single product in that list that is actually healthy. Highly processed food is horrible for us and our environment, and the gigantic conglomerates making and selling them are a plague to our economies.Veggies at my local farmers&#x27; market didn&#x27;t shrink in size, prices went up slightly for some and it&#x27;s very visible from the tag. Same goes for the bread I buy at the bakery, and the pasta I get in bulk in a small store nearby. If you have no choice but to rely on these products bought in a supermarket, you&#x27;ve been conned way before shrinkflation hit. reply prepend 13 hours agoparentI don’t rely on candy. I enjoy it a few times per year.It sucks that Cadbury eggs get smaller and smaller. Not because I need their nutrients to survive. reply camhart 12 hours agorootparentDid they get smaller or just fewer in the pack? reply prepend 11 hours agorootparentThe eggs got smaller. BJ Novak did the research, https:&#x2F;&#x2F;youtu.be&#x2F;TlXLCrzpToo?si=0i6G9NFSbr9aKiaN reply hackernudes 5 hours agorootparentLink with story cued (at 4:21): https:&#x2F;&#x2F;youtu.be&#x2F;TlXLCrzpToo?t=261 reply throwanem 13 hours agoparentprevToothpaste and soap aren&#x27;t healthy? reply sgu999 12 hours agorootparentFair enough, but let&#x27;s not pretend this is what shrinkflation is all about... reply bumby 12 hours agorootparentprevSome toothpaste can be a net-negative, like those with abrasives. It&#x27;s actually the mechanical aspect of brushing that does most of the hygiene. Frothing and minty taste of toothpaste are mostly marketing. Maybe there&#x27;s a case for fluoride, but there are other sources like tap water (and that&#x27;s a whole digression of it&#x27;s own). reply Sohcahtoa82 12 hours agorootparent> Some toothpaste can be a net-negative, like those with abrasivesYup. Those toothpastes with extra whitening are wreaking havoc. It&#x27;s effectively liquid sandpaper.> Frothing and minty taste of toothpaste are mostly marketingThe frothing, sure. The mint? I mean, I like some kind of flavoring. Mint is nice.> Maybe there&#x27;s a case for fluoride, but there are other sources like tap water (and that&#x27;s a whole digression of it&#x27;s own).There&#x27;s definitely a case for the fluoride. Your tap water isn&#x27;t enough. reply bumby 11 hours agorootparent>The mint? I mean, I like some kind of flavoring. Mint is nice.I’m saying it’s a subjective nice, it’s not adding to the hygienic effect of toothpaste. Its was added to feel clean, not because it actually does any cleaning.Fluoride works, but the concentration in toothpaste is usually too low to be effective. reply mauvehaus 12 hours agorootparentprevThose of us on well water don&#x27;t get fluoride in our drinking water. reply bumby 11 hours agorootparentHopefully you get it from a dentist visit because unless you use a prescription toothpaste, it probably doesn’t have much effect. reply mauvehaus 9 hours agorootparentHow does the effectiveness compare of a twice yearly dosing at the dentist vs constant low-level exposure via municipal water?My (very) lay understanding is that the constant low level fluoride was what&#x27;s important for long-term dental health. reply cactusplant7374 12 hours agorootparentprevMostly marketing or people actually enjoy these things and they encourage good oral hygiene? reply bumby 11 hours agorootparentI guess, yes, from a behavioral change standpoint they’re effective, even if they don’t objectively contribute to hygiene themselves. reply cactusplant7374 12 hours agoparentprevBread wouldn&#x27;t be bread if it wasn&#x27;t processed. We would be eating the wheat kernels. reply lq9AJ8yrfs 12 hours agorootparentNot all bread has* added sugar* preservatives* texturizersCut these out and you&#x27;re on the right side concerning processed foods. reply cactusplant7374 12 hours agorootparentAll bread cuts out most of the fiber of the wheat kernel. That&#x27;s more of a net gain than removing the items you listed. reply sgu999 12 hours agorootparentprevI wrote highly processed, not processed reply not_the_fda 16 hours agoprevThe idea is nice, but it seems to be tracking junk food, which you probably shouldn&#x27;t eat and can easily avoid.I&#x27;d be more interested in home goods such as soap, detergent; and food staples. reply Koeniggimeno 15 hours agoparentThere’s a listing for soap on the front page, I don’t think it’s confined to just junk food reply KomoD 15 hours agorootparentI searched soap and got no result reply dfgasdgsd 15 hours agorootparentI don&#x27;t think the search works, but it&#x27;s here: https:&#x2F;&#x2F;www.shrinkflation.io&#x2F;products&#x2F;535 replyswitch007 14 hours agoprevWarning: rant about brandsThe sadistic think about brands is that people are paying for marketing team to continue to lie to them and brainwash them, to convince them to continue buying their products!Media is full of brands - gosh I wonder how they have all that budget for expensive marketing campaigns !It&#x27;s so incredibly hard to wean someone off brands. I&#x27;ve been campaigning my family for years, but they still seem allergic to Aldi&#x2F;Lidl etc.Take cereal (eww):Aldi Corn Flakes (500g) - £0.75 ($0.93)Kellogs Cornflakes (500g) - £2.25 ($2.79)3x more expensive! THREE. (some people might be thinking that $2.79 is nothing but just think in relative terms)Yes Kellogs Cornflakes taste a bit nicer but that&#x27;s not the comparison to make: a small serving of oats with some fruit is a MUCH better breakfast meal. Oats are roughly same amount of calories per gram but much more filling and less sugar, salt, fat etc and double the protein. But we&#x27;re all addicted to cereal because the adverts brainwashed our parents in to thinking it&#x27;s a healthy meal to have in the morning.(EDIT: oops guess I&#x27;m a hypocrite) And has anyone tasted a McVities Digestive biscuit recently? (similar to a graham cracker, a distant relative of the shortbread - very very popular in the UK)? Absolutely vile. If you&#x27;re still buying them you&#x27;re literally an idiot and COVID must have destroyed your taste buds. Aldi own brand digestives taste like the old recipe of McVities Digestives at 1&#x2F;3 of the price! reply ravenstine 12 hours agoparentBut sugary cereal is heart-healthy!Oh wait, that&#x27;s horseshit that even Kellogg can&#x27;t get away with anymore.https:&#x2F;&#x2F;thecounter.org&#x2F;kellogg-sugary-cereal-healthy-label&#x2F;Breakfast cereal, namely corn flakes, is a mass psychosis. Have them sometimes if you like as a treat, but even then you might as well eat a bowl of ice cream. The idea of eating cornflakes was invented by a guy who gave his \"patients\" yogurt enemas. Why in 2023 are we still taking his advice? reply KomoD 14 hours agoparentprev> but that&#x27;s not the comparison to makeIt is one a lot of people make, also... you make that comparison literally one line down. reply hankchinaski 14 hours agoparentprevthe choice as you say it&#x27;s not between kellogs vs aldi cereals. But between highly processed and industrially produced crap and organic high quality raw foods. I personally don&#x27;t buy any of the products on this list. But for a lot of people, there isn&#x27;t a lot of choice but to go to a discount because that&#x27;s literally only thing they can afford unfortunately. reply jstanley 14 hours agoparentprevI also find the Lidl Ginger Nut biscuits are vastly superior to the McVities ones, which taste burnt. I don&#x27;t understand why McVities aren&#x27;t better. reply vmilner 11 hours agorootparentI bought Lidl Tower Gate Chocolate Digestive Biscuits because of the annoying look-like-mcvities-packaging thing, but they&#x27;re actually pretty good...https:&#x2F;&#x2F;cdn.images.express.co.uk&#x2F;img&#x2F;dynamic&#x2F;14&#x2F;590x&#x2F;seconda... reply switch007 14 hours agorootparentprev> I don&#x27;t understand why McVities aren&#x27;t better.People pay McVities to brainwash them in to thinking they&#x27;re better, so they don&#x27;t need to be better LOL reply elurg 15 hours agoprevMost of these products are extremely unhealthy so shrinking portions should be considered a public service. reply m3kw9 17 hours agoprevFor junk food which is what this mostly tracks, shrinkflation is good for people’s healths. reply read_if_gay_ 16 hours agoparent>inflation is a good thing and here&#x27;s why reply corinroyal 16 hours agorootparentInflation Could Save Your Life! The reasons why may shock you. reply shmatt 16 hours agorootparentLipids HATE this one trick reply read_if_gay_ 15 hours agorootparentclickbait is not what i meant, why are we having a reddit-tier comment chain? reply rexpop 15 hours agorootparentprevIt&#x27;s not lipids you should be worried about, it&#x27;s emulsifiers:> celluloses, mono and diglycerides of fatty acids, modified starches, lecithins, carrageenans, phosphates, gums, and pectins. Some recent studies have indicated that emulsifiers can disturb gut bacteria and promote inflammation, potentially increasing susceptibility to cardiovascular issues.[0]0. https:&#x2F;&#x2F;studyfinds.org&#x2F;food-e-numbers-heart-disease&#x2F; reply ilyt 16 hours agoparentprevWell, till you need to get 2 burgers instead of one to feel full... reply lotsofpulp 16 hours agorootparentThat is the point, people eat fewer burgers because they cannot afford more. reply chongli 13 hours agorootparentThis has not worked out so well for other products. I live in Canada where cigarettes are enormously expensive due to taxes. Yet I know people who continue to smoke.They&#x27;re a lot poorer now, and so they have less money to spend on healthy food. So not only are they destroying their health by smoking, they&#x27;re stuck eating crappy food as well. reply lotsofpulp 11 hours agorootparentI would not expect a higher price to stop every single person from buying the item immediately, especially not at at a price that is still obviously affordable.https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;434150&#x2F;share-of-canadian... reply tristor 16 hours agorootparentprevYes, GP is absolutely correct, all the people in the developing world who can&#x27;t afford food are much healthier than those of us in the West, that live long enough and eat enough to deal with diseases of obesity that primarily affect one after 60 years of age. &#x2F;s reply seabass-labrax 16 hours agorootparentYou put &#x2F;s, but that to an extent is sort of true. Diseases can&#x27;t be cured as effectively where remedies or mitigations are too expensive, but the same first world locations where medicine and care is most available also have a litany of factors working against health.I don&#x27;t believe though that this is inevitable, and I hope that the first world will continue to improve its situation, and that less well-equipped areas will somehow avoid making the mistakes and leapfrog these uncomfortable middle periods. We see this for instance with the Industrial Revolution, where those that can be credited with facilitating it generally did pretty poorly for themselves, but those who industrialised later were substantially better off. reply lotsofpulp 16 hours agorootparentprevThe context is not affording junk food, not not affording food. Most burgers qualify as junk food. reply tristor 16 hours agorootparentSure. Starvation is more deadly than obesity however, and globally more prevalent. reply lotsofpulp 16 hours agorootparenthttps:&#x2F;&#x2F;www.who.int&#x2F;news-room&#x2F;fact-sheets&#x2F;detail&#x2F;obesity-and...>In 2016, more than 1.9 billion adults, 18 years and older, were overweight. Of these over 650 million were obese.>39% of adults aged 18 years and over were overweight in 2016, and 13% were obese.https:&#x2F;&#x2F;www.who.int&#x2F;news&#x2F;item&#x2F;06-07-2022-un-report--global-h...>The number of people affected by hunger globally rose to as many as 828 million in 2021I would bet the obesity numbers have greatly increased since 2016. reply waffleiron 14 hours agorootparentAnother statistic from your source> Around 2.3 billion people in the world (29.3%) were moderately or severely food insecure in 2021It’s easy to talk on a forum like this, where the median salary is massive compared to global&#x2F;country median, that poor people shouldn’t be able to afford as much bad food. I think when you do so you’ve lost touch with the average person who is affected by things like shrinkflation. reply lotsofpulp 14 hours agorootparentI never meant to imply poor people, as in starvation poor, should not be able to afford as much bad food.But generally, the people eating burgers in developed countries have a choice of eating healthier foods, and choose to eat burgers instead. reply tristor 16 hours agorootparentprevWhat wonder, we&#x27;ve nearly conquered hunger if obesity has finally become more prevalent than starvation. I stand corrected. Nonetheless, starvation is more directly harmful&#x2F;deadly. Obesity may kill you eventually, starvation will kill you in relatively short order. reply lotsofpulp 15 hours agorootparentSure, but this thread is about the price of processed junk foods going up, including burgers, the sat fat laden mayo, and the bread enveloping it.Price increases in healthy lentils, grains, nuts, fruits, vegetables, dairy, and healthier meats&#x2F;poultry&#x2F;fish is a concern for the global poor, but that is not what is talked about here. replydrivers99 14 hours agoparentprevTo OP&#x27;s point, would be interesting to have an option to filter out junk food. reply mitthrowaway2 16 hours agoparentprevGood news everyone! You can&#x27;t afford snacks anymore. reply M3L0NM4N 16 hours agoprev [–] I don&#x27;t particularly care about shrinkflation. It gets calculated in the CPI (obviously) and most of the time it&#x27;s goods that are unhealthy and overpriced to begin with. reply phreeza 16 hours agoparentIt&#x27;s basically a dark pattern. Not illegal or anything, but designed to mask relevant information from the consumer. reply andy_ppp 16 hours agoparentprevSure, most of these items also cost next to nothing to make too and costs to actually make have barely risen (as a percentage of the item cost). So mostly it’s companies using inflation to squeeze more money out of people. reply M3L0NM4N 16 hours agorootparentI agree that material cost is not a major component of the cost in a lot of these products.It&#x27;s marketing, distribution, etc. I don&#x27;t think inflation is their excuse to squeeze more money out of you as it is to spend more in other areas of the business, as they should. reply ClumsyPilot 16 hours agoparentprev> most of the time it&#x27;s goods that are unhealthy and overpriced to begin withLike British housing, horribly overpriced and half of it has mould. reply cactusplant7374 16 hours agoparentprev [–] But a lot of us enjoy eating unhealthy foods. And as long as we don&#x27;t have diabetes, heart disease, high blood pressure, etc then it&#x27;s not a problem. reply switch007 14 hours agorootparent [–] I think it&#x27;s just a wild theory at this stage, but some doctors are saying that eating unhealthy food leads to diabetes, heart disease and high blood pressure reply cactusplant7374 13 hours agorootparent [–] If one is sedentary and obese, yes. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Shrinkflation.io is a website designed to combat shrinkflation, a phenomenon where the size of products decreases while the prices stay constant.",
      "The site maintains a search log of different products and brands known to have undergone shrinkflation, including Cadbury Dairy Milk, Mars Maltesers, and Nestlé Kit Kat.",
      "Users have the ability to monitor these products and brands directly from the website."
    ],
    "commentSummary": [
      "The Hacker News forum hosts diverse discussions centered around shrinkflation, focusing on its effect on product quality, deceptive practices by businesses, the demand for transparency and improved labeling, and associated ethical dilemmas.",
      "Other topics include mechanisms for tracking shrinkflated goods, issues related to animal testing, and the affordability and health impacts of junk food.",
      "Shrinkflation refers to the process where companies reduce the size or quantity of their products while maintaining or increasing the price, often without clearly informing consumers."
    ],
    "points": 305,
    "commentCount": 211,
    "retryCount": 0,
    "time": 1694790402
  },
  {
    "id": 37526477,
    "title": "Kopia: Fast and secure open-source backup software",
    "originLink": "https://kopia.io/",
    "originBody": "This website uses cookies to ensure you get the best experience on our website. Read more Got it! KOPIA Features Getting Started Download GitHub Fast and Secure Open-Source Backup Software Learn More Download User Support Forum Developer Discussion Encrypted, Compressed, and Deduplicated Backups Using the Cloud Storage You Pick. Supports GUI and CLI on Windows, macOS and Linux. Demo of Kopia's Command-Line Interface View a recorded demo of Kopia using Google Cloud Storage with pluggable encryption and compression. Demo of Kopia's Graphical User Interface Kopia comes with a user-friendly desktop app for Windows, macOS, and Linux which allows you to create snapshots, define policies, and restore files quickly. Fast and Encrypted Backups With a secure and scalable architecture, Kopia can back up everything from small laptops to large servers. Contributions Welcome! We use a Pull Request contributions workflow on GitHub. New contributors and bug reports are always welcome! Read more … Join The Conversation Find us on Slack to get started with using Kopia, discuss features and issues, meet the team, and more. © 2023 Kopia Project All Rights Reserved Privacy Policy",
    "commentLink": "https://news.ycombinator.com/item?id=37526477",
    "commentBody": "Kopia: Fast and secure open-source backup softwareHacker NewspastloginKopia: Fast and secure open-source backup software (kopia.io) 272 points by thunderbong 16 hours ago| hidepastfavorite104 comments chenxiaolong 11 hours agoKopia is great, though it&#x27;s worth noting for folks on Linux: non-UTF-8 paths aren&#x27;t stored correctly [1] and xattrs aren&#x27;t stored [2]. While most folks probably won&#x27;t care about the former, the latter can could cause issues (eg. losing SELinux labels makes it difficult to restore a backup of the root filesystem on distros that use SELinux).[1] https:&#x2F;&#x2F;github.com&#x2F;kopia&#x2F;kopia&#x2F;issues&#x2F;1764[2] https:&#x2F;&#x2F;github.com&#x2F;kopia&#x2F;kopia&#x2F;issues&#x2F;544 reply spindle 4 hours agoparentI wish I could upvote this more than once. Those are omissions that could lead to important information being lost in a way that you probably wouldn&#x27;t notice when checking your backups. reply KennyBlanken 3 hours agoparentprevMacOS X makes heavy use of xattrs, too.> Yes, there&#x27;s a whole bunch of things currently not captured at the filesystem level, including setuid&#x2F;gid, hardlinks, mount points, sockets, xattr, ACLs, etc.That was three years ago and it sounds like things are only slightly better.These people are incompetent at making backup software. reply xgbi 12 hours agoprevWe are trying to use it for large backups of a production item, and it has not been a complete smooth ride all along.We have many files (millions) and lots of churn over ~80Tb total.Kopia has exhibited some issues:- takes about 120GB (!) of ram to perform regular maintenance & takes about 5hrs to do so. There are ideas floating around to cherry pick the large inefficiencies in the GC code but it’s yet to be worked on. I’ll try to have a internship accepted to work on this in my company.- there’s a good activity on the repository but the releases are not quick to come and the PRs are not very fast to be examined- the local cache gets enormous and if we try to saddle it, we have huge download spikes (>10% of repo size) during maintenance. Same as above: pb is acknowledged but yet to be solved- the documentation is very S3 centric, and we discovered too late that the tiered backup (long term files go into cold storage on s3) is only supported on S3, while we use azure. We contributed a PR to implement it in June, yet to be merged (see point 2)So, not too bad, especially for a small-ish project maintained by mainly one person (from the looks of my interactions on slack and seeing the commit log). The maintainer is easy to reach and will answer, but external prs are slow. If I could use zfs cheaply on azure via s3, I’d use it over kopia, but as of now, it works. reply jiggawatts 11 hours agoparent“ZFS on Azure via S3” is missing just an Apple technology to win the “mixing vendors randomly” bingo. reply infogulch 9 hours agorootparentWell if you drop the Azure part (which really just means the Azure Storage S3 compatibility layer), that&#x27;s a thing. Or at least some people were trying to make ZFS on object storage a thing. It&#x27;d be good as an offsite backup. reply Dylan16807 3 hours agorootparentprevZFS with an object store backend, is that better. reply djbusby 7 hours agoparentprevIf you&#x27;re looking for ZFS backed why not rsync.net?Am I dumb for just doing some rclone+rsync.net? reply Gud 1 hour agorootparentNo, you are keeping it simple.I am using rsync to rsync.net from multiple different hosts with different configurations. I run the same command on every host running variations of *nix, no messing about with different tools needed. reply ntolia 15 hours agoprevI&#x27;ve been using Kopia for my personal use and for products I have helped build at a couple of enterprise backup companies! It&#x27;s also used by other open-source backup projects that focus on specific ecosystems (Velero and Kanister for Kubernetes, Corso for Microsoft 365 backup).I am obviously biased but it&#x27;s pretty amazing. AMA. reply x0x0 14 hours agoparentCan you compare vs eg Duplicati?Do you (sorry, but just checking) repeatedly test backups? Eg pull monthly and bit verify that they&#x27;re correct? Are you aware of anyone testing in this way?Thanks so much! reply Ayesh 2 hours agorootparentNot the previous poster, and I don&#x27;t use Kopia, but after reading Kopia features and docs, they seem to be in par. I use Duplicati quite extensively for personal backups, and didn&#x27;t really have any issues.Duplicati has a web interface, so with a proper authentication in place, you can use it to remotely monitor and manage backups.Duplicati doesn&#x27;t keep a local cache. It uses SQLite files for file meta data, but not for the content themselves.I like Duplicati&#x27;s snapshotting mechanism. You can specify how long or how many snapshots to keep, and my anecdotal evidence is that it&#x27;s archival storage-friendly. I imagine S3 and it&#x27;s lifetime management rules can bring a decent and cost effective backup solution.I&#x27;m using Google Drive 2TB plan, and I didn&#x27;t see Kopia supporting Google drive out of the box. reply x0x0 1 hour agorootparentHmm. I&#x27;m asking because I&#x27;ve had some trouble with Duplicati. I use it on a laptop, and it does not like being interrupted during a backup. It also doesn&#x27;t fail the backup, which would be fine; instead, it gets jammed on files, particularly the large (multigb sqlite) file it generates to track state. It remains jammed, even once network is restored, and measures upload speeds at single-digit bytes per second. I end up having to force kill it after multiple abort requests fail to stop the jammed backup, and there&#x27;s multiple warnings that this can corrupt data &#x2F; you shouldn&#x27;t kill the process...So anyway, I&#x27;m looking for alternatives.Duplicati also, somewhat annoyingly, nails 100% cpu for a while during backup which spins up the fans and gets my laptop very hot. I&#x27;ve been meaning to see if there&#x27;s a simple way to modify the code to prevent this, but I&#x27;m very unfamiliar with C#. reply riedel 14 hours agorootparentprevI can only compare it from a user experience point of view. I tried duplicati for my windows laptop and was never quite happy. Kopia just worked from day one. The front-end still has a few bugs here and there particularly if you on windows electron eating sockets, WebDAV mounts not always working), however the backend seems very reliable (only did one full restore, but I also did not note any reports).It still has a lot of potential, IMHO. You e.g. find some hints how to use it with AWS storage tiering in the docs.I am just a very happy user! reply ntolia 12 hours agorootparentprevI haven&#x27;t looked at duplicati in a while and, it has evolved. While Duplicati&#x27;s feature set looks similar now, I would need to benchmark it both for efficiency and final backup sizes.And, while not directly, I know a number of companies, including mine, do test restores all the time. reply ntech 4 hours agorootparentprevOne difference I noticed some time ago is Duplicati allows encryption with GPG keys but Kopia afaik doesn&#x27;t provide that. reply FieryTransition 10 hours agoprevUsed it for a while, recently tried to restore some things and it failed, taking a really long time to restore some snapshots compared to other things I&#x27;ve tried. Switched to restic instead. Really like what kopia is but I&#x27;ll wait a few more years before considering it for something, but right now I&#x27;m happy with restic.Too bad no one besides kopia does ecc, which is the reason I switched, but when I checked out why restic didn&#x27;t do it, it was because they saw what other people did and apparently it&#x27;s way too easy to make a bad implementation. reply JoshuaEN 7 hours agoparentThis has been my experience too with Kopia.I tried to restore a ~200 GB file (stored remotely on a Hetzner Storage Box), and it failed (or at least did not finish after being left for ~20 hours; there was also no progress indicator or status I could find in the UI).I also tried to restore a folder with about ~32 GB of data in it, and that also failed (the UI did report an error, but I don&#x27;t recall it being useful).Also, in general use, the UI would get disconnected from the repository every few days, and sometimes the backup overview list would show folders as being size 0 (which maybe indicated they failed; they showed up with an \"incomplete\" [or similar] tag in the UI). reply throwing_away 15 hours agoprevI noticed this project while comparing restic&#x2F;borg and am thinking about trying it.Initially I thought this was a corporate project and was looking for the monetization model, but then I found https:&#x2F;&#x2F;github.com&#x2F;kopia&#x2F;kopia&#x2F;blob&#x2F;master&#x2F;GOVERNANCE.mdI feel like the project might benefit from making their governance model more prominent on the website. reply OccamsMirror 8 hours agoparentHow did it fare against Restic? reply pdimitar 6 hours agorootparentI found Restic slower in general, though Kopia is not super fast either when you have many backup sources (in my case I have 30+ separate directories I am backing up; Kopia works amazingly fast per single directory but make them 30+ and it&#x27;s not as fast because it&#x27;s basically going through them one by one and it&#x27;s NOT going through them in one pass, sadly). reply bhaney 16 hours agoprevAny comparisons to Restic? Looks like basically the same thing but with a GUI available.Edit: Found this very ad-hoc \"benchmark\" from over a year ago claiming that Kopia managed significantly better deduplication than Restic after several backups (what took Restic 2.2GB, Kopia did inKopia managed significantly better deduplication> ... was from before Restic supported compression, which is the why its size is so much largerdeduplication != compression...So we don&#x27;t actually know which has better deduplication? Compression algorithms are well-established and you can find a million people who benchmarked them all for different purposes, but deduplication algorithms I never saw a comparison of. I don&#x27;t even know if these things have proper names or if people just refer to them as \"rsync-like\" reply e12e 9 hours agoparentprevI&#x27;d be interested in comparison with:https:&#x2F;&#x2F;relicabackup.com&#x2F;featureshttps:&#x2F;&#x2F;github.com&#x2F;netinvent&#x2F;npbackupWhich is my current short-list for cross platform backup... reply SomeoneOnTheWeb 16 hours agoprevI&#x27;ve been using Kopia for about a year to backup sensitive data multiple times a day into an off-site encrypted storage and it&#x27;s worked like a charm so far.The presence of a WebUI is so nice compared to CLI-only tools. reply guerby 14 hours agoprevReplaced borg by kopia a while ago, I have \"kopia snapshot create &#x2F;\" on most of the machines I manage, just works. reply izoow 11 hours agoparentWhy did you switch? reply AnonHP 4 hours agoprevBorg 2 has been in development for nearly a year and a half [1] and may probably be released early next year, i.e., early 2024 (just a guess, seeing that even RC1 is not yet released and seems to have a lot of work to be done).Does anyone know how Borg 1.x and 2 would compare to Kopia?[1]: https:&#x2F;&#x2F;github.com&#x2F;borgbackup&#x2F;borg&#x2F;issues&#x2F;6602 reply justin_oaks 14 hours agoprevI use Restic for personal backups and at work, but I thought I&#x27;d try Kopia to see if it&#x27;d be a good fit for my less techie relatives. This was about a year ago.The UI didn&#x27;t seem like a good fit for those who are less technical. I don&#x27;t remember the specifics.Does anyone have recommendations for backup services for the average user? reply lucb1e 7 hours agoparent> I thought I&#x27;d try Kopia [for] my less techie relatives. This was about a year ago.> The UI didn&#x27;t seem like a good fitDidn&#x27;t seem like, or wasn&#x27;t based on your trying it? Did you end up trying it? If not, what do your relatives use currently, is that better (even if not ideal, since you&#x27;re still asking for recommendations)? reply e12e 9 hours agoparentprevPossibly these two - though I&#x27;ve yet to try them:https:&#x2F;&#x2F;relicabackup.com&#x2F;featureshttps:&#x2F;&#x2F;github.com&#x2F;netinvent&#x2F;npbackup reply remisharrock 15 hours agoprevI have also used it for a year or so and restored some files individually without any problem. I use a remote ssh storage through tailscale, just very stable interestingly! Only small problem was that my server broke during an uptade because I created a systemd service to start it and the parameters changes to start it. Apart from that, very stable for now. reply unwind 16 hours agoprevHm interesting name, I spent a few seconds on the site to figure out origin but no luck.\"Kopia\" means \"copy\" in Swedish and probably more Nordic languages, too. Very hard to pronounce in English so it would be interesting to hear it said. reply trwired 15 hours agoparentKopia also means a copy in Polish and the author is Polish. The first paragraph in the software&#x27;s Github page also confirms the Polish origin of the name: https:&#x2F;&#x2F;github.com&#x2F;kopia&#x2F;kopia&#x2F;Tangentially, as far as OSS names of Polish go, kopia is pretty tame. A popular deduplicating app is named czkawka (hiccup). Now that choice is just mean towards non-Polish speakers. :) reply semi-extrinsic 15 hours agorootparentOh my, this is a fantastic view of life - from the czkawka github page: Czkawka is a Polish word which means hiccup. I chose this name because I wanted to hear people speaking other languages pronounce it, so feel free to spell it the way you want. This name is not as bad as it seems, because I was also thinking about using words like żółć, gżegżółka or żołądź reply vladgur 15 hours agorootparentI had to google pronounciation of czkawka and to me it sounds exactly how i would pronounce it - chkavka or чкавка in Russianhttps:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;czkawka reply turtles3 12 hours agorootparentprevThis sounds very much in the spirit of Grzegorz Brzęczyszczykiewicz[0][0] https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=AfKZclMWS1U reply traceroute66 12 hours agorootparentprev> as far as OSS names of Polish go, kopia is pretty tameWell indeed.There&#x27;s a project on GitHub with 1.7k stars called GitKurwa[1].Now that&#x27;s proper untame Polish. ;-)[1] https:&#x2F;&#x2F;github.com&#x2F;jakubnabrdalik&#x2F;gitkurwa reply rags2riches 7 hours agoparentprevTo be more precise it means \"copy\" in the noun sense, not the verb. It&#x27;s a distinction that a lot of bad translations from English fail to make, like when X changed \"tweet\" to \"post\". reply j1elo 15 hours agoparentprevMy first impression was that it could have also been spanish \"Copia\" (copy), but built for KDE (thus following the naming trend of those apps) reply rodolphoarruda 10 hours agorootparentOr even Portuguese, \"cópia\". reply fishnchips 15 hours agoparentprevAlso in Polish and other Slavic languages probably, too. reply fishnchips 15 hours agorootparentAh, just noticed. The founder is Polish. That explains the name.As a Pole, I actually greatly appreciate these Slavic names in tech. reply haunter 15 hours agoprevLove the asciinema demo. More projects should use it. Sometimes I have the urge to make a pull request on Github projects without any screenshot or video. reply candiddevmike 14 hours agoparentI personally don&#x27;t see the point of CLI videos like asciinema, just let me scroll through the damn CLI history. reply xpe 6 hours agorootparentYeah. &#x2F; An ideal tool IMO would provide searching, skimming, and playback. reply rsync 11 hours agoprevKopia runs over plain old sftp and can be pointed at any old sftp endpoint:https:&#x2F;&#x2F;twitter.com&#x2F;rsyncnet&#x2F;status&#x2F;1643361320534953984 reply anotherevan 8 hours agoprevI use Kopia to backup the kids Windows laptops to the home file server over SFTP. The advantages over other options I&#x27;ve found so far:* Can run in a \"I haven&#x27;t done a backup for a while, so I&#x27;ll do one now\" mode when the laptop is awake.* Both laptops can be writing to the same repository at the same time, sharing common files, dedup, etc.Missing:* Only supports VSS via a couple of scripts I couldn&#x27;t get working. (Restic is nice with that.) reply CrendKing 6 hours agoparent> Only supports VSS via a couple of scripts I couldn&#x27;t get working.Is https:&#x2F;&#x2F;kopia.io&#x2F;docs&#x2F;advanced&#x2F;actions&#x2F;#windows-shadow-copy not working for you? reply anotherevan 5 hours agorootparentNo. Didn&#x27;t seem to be amenable to setting it via the GUI, and all in all just a lot of frigging around. Haven&#x27;t personally had to use Windows for a decade or so, so argh. reply t0bia_s 2 hours agoprevHow is it compared to Bvckup2? reply amarshall 13 hours agoprev> Kopia does not currently support cloud storage that provides delayed access to your files – namely, archive storage such as Amazon Glacier Deep Archive. Do not try it; things will break.Sigh… and unfortunately all too common for there to be no cold storage support. reply ntolia 12 hours agoparentHowever, you should be able to use Glacier Instant Access. It will get you a bunch of the way there. reply Veserv 10 hours agoprev“Secure”. So what audits or certifications do they have verifying it is secure? What is the operational domain and against what threat models?I see no mention of any of that anywhere obvious. Do you get to just make up core properties of your software because it feels good? reply monlockandkey 14 hours agoprevCan someone please help decide what is the \"best\" backup software?- Restic (https:&#x2F;&#x2F;restic.net&#x2F;)- Borg backup (https:&#x2F;&#x2F;www.borgbackup.org&#x2F;)- Duplicati (https:&#x2F;&#x2F;www.duplicati.com&#x2F;)- Kopia (https:&#x2F;&#x2F;kopia.io&#x2F;)- Duplicay (https:&#x2F;&#x2F;duplicacy.com&#x2F;)- Duplicity (https:&#x2F;&#x2F;duplicity.us&#x2F;) reply mekster 3 hours agoparentDo yourself a favor and use zfs as your primary backup, even though it means you&#x27;ll have to replace your filesystem, it&#x27;s just that good.Faster than any other backup software (because it knows what&#x27;s changed from the last snapshot being the filesystem itself but external backup tools always have to scan the entire directories to know what&#x27;s changed), battle tested reliability with added benefit like transparent compression.A bit of explanation on how fast it can be than external tools. (I don&#x27;t work for the said service in the article or promote it.)https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2015&#x2F;12&#x2F;rsync...Then you&#x27;ll realize Borg is the one with least data corruption complaint on the internet which is good as your secondary backup.Easily checked with, \"[app name] data corruption\" on Google.And see who else lists vulnerability and corruption bugs upfront like Borg does and know the developers are forthcoming about these important issues.https:&#x2F;&#x2F;borgbackup.readthedocs.io&#x2F;en&#x2F;stable&#x2F;changes.htmlThe term \"best\" apparently means reliable for backup and also they don&#x27;t start choking on large data sets taking huge amount of memories and roundtrip times.They don&#x27;t work against your favorite S3 compatible targets but there are services that can be targeted for those tools or just roll your own dedicated backup $5 Linux instance to avoid crying in the future.With those 2, I don&#x27;t care what other tools exist anymore. reply donmcronald 2 hours agorootparentI use ZFS + Sanoid + Syncoid locally and Borg + Borgmatic + BorgBase for offsite. reply Linux-Fan 11 hours agoparentprevBupstash (https:&#x2F;&#x2F;bupstash.io&#x2F;) beats Borg and Kopia in my tests (see https:&#x2F;&#x2F;masysma.net&#x2F;37&#x2F;backup_tests_borg_bupstash_kopia.xhtm...). It is a modern take very close to what Borg offers regarding the feature set but has a significantly better performance (in terms of resource use for running tasks, the backups were slightly larger than Borg&#x27;s in my tests). reply ajvs 4 hours agorootparentLacks features like mounting a filesystem as read-only to restore though. I find that makes restoring files much simpler. I&#x27;ll look into bupstash some more perhaps but right now am very happy with Vorta&#x2F;Borg. reply dsissitka 10 hours agorootparentprev> Borg ... multiple hosts backup to same target ... YesIt might be worth adding an asterisk there.https:&#x2F;&#x2F;borgbackup.readthedocs.io&#x2F;en&#x2F;stable&#x2F;faq.html#can-i-b... reply bhaney 13 hours agoparentprevI can&#x27;t give you a meaningful comparison between all of those, because I haven&#x27;t used all of them, but I can say that I&#x27;ve been pretty happy with Restic in the time I&#x27;ve been using it.Do you have any odd requirements that one might serve better than the rest? If you just want bog-standard backups, any of them will probably do. reply keep_reading 13 hours agoparentprevBaculaI&#x27;ve tried all of these, and none are as reliable or powerful as Bacula.It&#x27;s way more complex at first, but you will have peace of mind. And backup&#x2F;restore speed is way faster.You can even easily setup automatic restore jobs to prove your backups work! reply MenhirMike 13 hours agorootparentDo you know how Bacula compares to Bareos? Bacula is on my to-do list to look at (also because I need tape backups), but the Bareos fork seems to have a more modern interface - but I&#x27;ve not stress tested either solution. The fact that Bacula has a Debian package and Bareos does not pretty much settles it already, but just curious if someone has actually tried both. reply keep_reading 5 hours agorootparentThey&#x27;re nearly identical otherwise, so just choose what works for you reply hsshah 13 hours agoprevHow does it compare with Arq Backup (for Mac)? It&#x27;s a bummer that Arq has still not added support for Azure. reply havaloc 16 hours agoprevI was using Vorta&#x2F;Borgbase until I discovered that Vorta had an issue with restores. Kopia is pretty neat, but make sure you test as always. reply ajvs 4 hours agoparentHow&#x27;s that? I&#x27;ve restored lots of files and had no issues. reply johnchristopher 11 hours agoparentprev> I was using Vorta&#x2F;Borgbase until I discovered that Vorta had an issue with restores.Such as ? reply trailbits 13 hours agoparentprevWhat was the problem with restores? reply jopsen 14 hours agoparentprevI&#x27;ve been happy with kopia for a while now...But I probably ought to double check that restoring works :) reply SillyUsername 13 hours agoprevNo mention on the website, is it possible to schedule backups? reply vladgur 15 hours agoprevIm curious if its able to use NAS Storage or a combination of offline&#x2F;online storageI got a Synology in my house that could be utilized reply viciousvoxel 14 hours agoparentYes, it can. If your Synology model can run docker, running a minio instance is a good option.https:&#x2F;&#x2F;kopia.io&#x2F;docs&#x2F;repositories&#x2F; reply Unfrozen0688 12 hours agoprevCompared to Veeam how is it? reply ntolia 12 hours agoparentVery different products and can&#x27;t compare them. Veeam is enterprise-grade and used for a larger variety of mission-critical workloads. Kopia is meant for end-user backups (though folks use it for a bunch of other things too).Note that Veeam contributes to Kopia - https:&#x2F;&#x2F;www.veeam.com&#x2F;sys451 reply halfcat 10 hours agorootparentI’ve used Veeam’s free community edition [1] to backup personal computers. I’ve only used it on Windows, but they have agents for Linux, and Mac.[1] https:&#x2F;&#x2F;www.veeam.com&#x2F;agent-for-windows-community-edition.ht... reply aborsy 4 hours agoparentprevVeeam does both file and full system backups. Kopia is meant to do only file backups.Veeam is an enterprise solution, and popular among sysadmins. reply momirlan 15 hours agoprev+1 happy customer, for my laptop documents reply proxyon 12 hours agoprevWhere does one even acquire a VPS that makes this worth it? Most VPS pricing I&#x27;ve looked at is significantly more expensive than something like BackBlaze or IDrive. So what even is the point of rolling your own backups if you can&#x27;t get cheap terrabytes in the cloud? And no I&#x27;m not going to consider something like S3 because Amazon&#x27;s pricing is obnoxious and confusing. Edit: $70 &#x2F; month for 3TB of S3. Significantly more expensive than all of the managed SaaS backup providers. reply cycomanic 12 hours agoparentAFAIK kopia has a S3 backend so can backup to idrive E2. That said I have a vps from greencloud with 2 TB (and 4 cores) for $80 a year which is very price competitive. There are actually lots of smaller vps providers that offer cheap storage vps. Lowendtalk.com is a good place to find out about offers in particular around black Friday. reply danielhep 12 hours agoparentprevI haven&#x27;t tried it but it should work with Hetzner Storage Boxes over SFTP. Extremely price competitive. reply wmf 11 hours agoparentprevS3 is the most expensive object storage; there are plenty of cheaper options like B2, Wasabi, or Coldline. reply baal80spam 15 hours agoprevWhy not just use rclone? reply cpach 12 hours agoparentAFAIK rclone is a sync tool. A backup tool is not the same as a sync tool. reply wmf 15 hours agoparentprevCompression is still experimental. Can rclone pack small files to reduce API calls and storage space? reply freedomben 14 hours agoparentprevrclone is way underrated and should be used by a lot more people. But the various UIs are still a bit technical. Though if I were writing backup software nowadays, I&#x27;d probably write a skin over rclone. reply fortran77 9 hours agoprevUranium backup charges extra for windows shadow copy support, so I always assumed it was tricky to do. Kopia seems to do it with a “policy” that runs a little PowerShell script before and after entering a directory. Does it work without problems? (I just need to try it myself!) reply IshKebab 14 hours agoprevHow does this compare to Rustic? reply anderspitman 14 hours agoprevThe state of backup tech is surprisingly bad, and runs OS deep. Even with modern solutions like restic, you have no guarantee of a consistent backup[0] unless you pair it with a filesystem that supports snapshots like btrfs, ZFS, etc, which basically no one other than power users are even aware of. Interestingly, Windows ships snapshot support by default[1], but you need admin privileges to use it.Also, it&#x27;s unclear to me what happens if you attempt a snapshot in the middle of something like a database transaction or even a basic file write. Seems likely that the snapshot would still be corrupted. So for databases you&#x27;re stuck using db-specific methods like pg_dump.All this complexity makes it very difficult to make self-hosting realistic and safe by default for non-experts, which is the problem I&#x27;m having.[0]: https:&#x2F;&#x2F;forum.restic.net&#x2F;t&#x2F;what-happens-if-file-changes-duri...[1]: https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;windows-server&#x2F;storage&#x2F;fil... reply asmor 13 hours agoparentThe advantage and disadvantage of Linux simultaneously is that you need to pick such a filesystem or work around the limitations, but it&#x27;s your choice. The OS underneath really should not be responsible. Apple solves it with APFS snapshots and Microsoft has Volume Shadow Copy (which requires NTFS or ReFS).I personally use compose for all my services now and back up my compose.yaml by stopping the entire stack and running a restic container that mounts all volumes in the compose.yaml.[1] It&#x27;s not zero downtime, but it&#x27;s good enough, and it&#x27;s extremely portable since it can restore itself.[1]: https:&#x2F;&#x2F;gist.github.com&#x2F;acuteaura&#x2F;61f221ada67f49193bc1f93955... reply adobrawy 13 hours agoparentprevFilesystem snapshot for database is not different than database crash. Databases are designed to handle crashes well (WAL etc.). reply ntolia 12 hours agorootparentUnfortunately, this is not true. You need to grab all the DB files (WAL, etc.) in a consistent manner. You can&#x27;t grab them while writes are in progress. There are ways though. Look at what Kanister does with its recipes to get consistent DB snapshots to get a sense of the complexities need to do it \"right.\" reply Freaky 6 hours agorootparent> Unfortunately, this is not true. You need to grab all the DB files (WAL, etc.) in a consistent manner. You can&#x27;t grab them while writes are in progress.Perhaps you could be more specific, because the former is exactly what a filesystem snapshot is meant to do, and the latter is exactly what an ACID database is meant to allow assuming the former.> Look at what Kanister does with its recipes to get consistent DB snapshotsI looked at a few examples and they mostly seemed to involve running the usual database dump commands. reply donmcronald 2 hours agorootparentprevI’ve always assumed a snapshot is no worse than power loss and that any decent database should handle it ok. Is that wrong? reply thesh4d0w 13 hours agoparentprev> Also, it&#x27;s unclear to me what happens if you attempt a snapshot in the middle of something like a database transaction or even a basic file write. Seems likely that the snapshot would still be corrupted.You just quiesce the database first. Any decent backup engine has support to talk to a DB and pause &#x2F; flush everything. reply cientifico 14 hours agoparentprevFor database, in my experience, is better to dump the whole database and backup the dump for the reasons you explained reply viraptor 13 hours agorootparentDepends on your database size, type, change rate, etc. Dumping the database to a file is fine for toy and small cases, but not for a 1+TB store that&#x27;s under heavy writes. reply MenhirMike 13 hours agoprev [–] CTRL+F \"tape\" \"lto\" - 0 results.I know that Tape Backups are not hip and sexy, but CloudNordic showed us just last month why they still matter even in 2023 and beyond, so you&#x27;d definitely want to look at an additional solution for your large servers, with a proper rotation&#x2F;retention strategy (e.g., GFS). You _need_ offline backups, if you think you don&#x27;t, you just got lucky for now - or have data that can be recreated from other sources.For an online hot&#x2F;warm solution, I&#x27;d use sending ZFS Snapshots into a backup server to then compress and encrypt them there, though keep in mind that for running systems, it may still not be enough (e.g., backing up a running Postgresql server through a file system snapshot may not be enough - there&#x27;s an entire section in the documentation about backup options).That said, it&#x27;s good to have more options, and you really want to use something for your personal stuff as well, so the more options there are, and the more user-friendly&#x2F;turnkey they are, the better!Just be aware that backup solutions in a corporate&#x2F;network environment are more complicated than just copying some files across. And also remember: Good companies test their backups - but great companies test their restores. reply donmcronald 2 hours agoparent [–] > backing up a running Postgresql server through a file system snapshot may not be enough - there&#x27;s an entire section in the documentation about backup optionshttps:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;16&#x2F;backup-file.html> An alternative file-system backup approach is to make a “consistent snapshot” of the data directory, if the file system supports that functionality (and you are willing to trust that it is implemented correctly). The typical procedure is to make a “frozen snapshot” of the volume containing the database, then copy the whole data directory (not just parts, see above) from the snapshot to a backup device, then release the frozen snapshot. This will work even while the database server is running. However, a backup created in this way saves the database files in a state as if the database server was not properly shut down; therefore, when you start the database server on the backed-up data, it will think the previous server instance crashed and will replay the WAL log. This is not a problem; just be aware of it (and be sure to include the WAL files in your backup). You can perform a CHECKPOINT before taking the snapshot to reduce recovery time.It sounds like enough to me. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The website introduces an open-source backup software, Kopia, boasting speed, security, and compatibility with multiple operating systems via GUI (Graphical User Interface) and CLI (Command Line Interface).",
      "Kopia facilitates encrypted, compressed, and deduplicated backups using the user's preferred cloud storage and features a desktop app to manage snapshots, policies, and file restoration.",
      "The website invites contributions and bug reports for Kopia through a Pull Request workflow on GitHub, and engages user discussions about Kopia features and issues on Slack."
    ],
    "commentSummary": [
      "Kopia, a fast and secure open-source backup software, is under discussion due to some drawbacks including incorrect storage and slow release updates.",
      "Users have experienced challenges with Kopia including inability to complete backups, inaccurate progress indicators, and issues with restoring large data sets.",
      "Alternatives to Kopia, the advantages of offline backups, and the need for comprehensive testing for backup services in a corporate setting were also discussed."
    ],
    "points": 268,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1694799145
  },
  {
    "id": 37521240,
    "title": "How does Linux start a process",
    "originLink": "https://iq.thc.org/how-does-linux-start-a-process",
    "originBody": "Knowledge Base Follow How does Linux start a process ...and how to ptrace the entry point and m3ss w1th da stack. root · Sep 14, 2023 · 8 min read In this article, you will learn what happens inside the Linux Kernel when a process calls execve(), how the Kernel prepares the stack and how control is then passed to the userland process for execution. I had to learn this for the development of Zapper - a Linux tool to delete all command line options from any process (without needing root). Overview The Kernel receives SYS_execve() by a userland program. The Kernel reads the executable file (specific sections) into specific memory locations. The Kernel prepares the stack, heap, signals, ... The Kernel passes execution to the userland program. Examining a binary Let us start with a simple Linux C program: COPY COPY int main(int argc, char *argv[0]) { return 0; } Compile it with gcc -static -o none none.c and find out some details: COPY COPY $ readelf -h none ELF Header: Magic: 7f 45 4c 46 02 01 01 03 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - GNU ABI Version: 0 Type: EXEC (Executable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x4014f0 Start of program headers: 64 (bytes into file) Start of section headers: 760112 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 10 Size of section headers: 64 (bytes) Number of section headers: 30 Section header string table index: 29 The first instructions start at the 'Entry Point' at 0x4014f0. These instructions were created by the compiler (gcc, go, etc). They differ by compiler. Let's load the binary into gdb and disass 0x4014f0 the instructions. The instructions perform a bit of housekeeping but eventually will call main() (or the GoLang equivalent). Let's set a break-point at the Entry Point (0x4014f0)and run the app with two command line options (firstarg and secondarg): COPY COPY gdb ./none pwndbg> disass 0x4014f0 pwndbg> br *0x4014f0 pwndbg> r firstarg secondarg ► 0x4014f0xor ebp, ebp 0x4014f2mov r9, rdx 0x4014f5pop rsi [...] ──────────────────────[ STACK ]────────────────────── 00:0000│ rsp 0x7ffca4229540 ◂— 0x3 01:0008│ 0x7ffca4229548 —▸ 0x7ffca422a4b3 ◂— '/sec/root/none' 02:0010│ 0x7ffca4229550 —▸ 0x7ffca422a4c2 ◂— 'firstarg' 03:0018│ 0x7ffca4229558 —▸ 0x7ffca422a4cb ◂— 'secondarg' 04:0020│ 0x7ffca4229560 ◂— 0x0 05:0028│ 0x7ffca4229568 —▸ 0x7ffca422a4d5 ◂— 'BASH_ENV=/etc/shellrc' [...] (If you are using gdb without pwngdb then you may need to x/64a $rsp to list the first 64 entries from the stack.) The Stack Pointer rsp is at 0x7ffd4f48bd10. Let's find out the end of the stack with grep -F '[stack]' /proc/$(pidof none)/maps: COPY COPY 7ffd4f46c000-7ffd4f48d000 rw-p 00000000 00:00 0 [stack] The Kernel has allocated the stack memory from 0x7ffd4f46c000 to 0x7ffd4f48d000 - a total of 132 KB. It will grow dynamically up to 8MB (ulimit -s kilobytes). Our program (so far; see rsp) only uses the stack from the rsp address (0x7ffd4f48bd10) down to the same end of the stack (0x7ffd4f48d000) - a total of 4,848 bytes (echo $((0x7ffd4f48d000 - 0x7ffd4f48bd10)) == 4848). This is the 'birth' of the execution: The Kernel, in all its braveness, has passed control to our program. Our program is about to execute its very first instruction - to take its very first step (so to say). What is on the stack right now is all the information the program gets from the Kernel to run. It contains the argument list, the environment variables and a lot of other interesting information. For Zapper we had to manipulate the argument list, move stack values around, adjust the pointers and then pass control back to the program - without it falling over. It was prudent to understand a bit better what the Kernel had put on the stack. Let's dump the stack: COPY COPY pwndbg> dump binary memory stack.dat $rsp 0x7ffd4f48d000 and load it into hd filename) is thus at the largest address on the stack (the bottom) and above it (e.g. smaller addresses) comes the envp and then the argv. We follow to bprm_execve() where some checks are completed before calling exec_binprm(). From there into search_binary_handler() where the Kernel checks if the binary is ELF, a shebang (#!) or any other type registered via the binfmt-misc module. The kernel then calls the appropriate function to load the binary. In our case, it's an ELF binary and so load_elf_binary() is called. The kernel creates the memory and thereafter maps the sections from the binary file into memory. It calls begin_new_exec() to set all credentials and permissions for the new process. The kernel then checks if the ELF binary should be loaded by an interpreter (ld.so): or, in the case of a static binary like ours, loaded directly without an interpreter: Finally, create_elf_tables() is called. This is where all the stack magic happens that we are interested in. First, the function arch_align_stack() adds a random amount of zeros to the stack (e.g. stack randomization) to make (some) buffer overflow exploits work (a little) less reliably. It then aligns the stack to 16 bytes (e.g. sets the stack pointer to the next lower address that is aligned to 16 bytes with & ~0xf). The kernel then puts x86_64\\0 onto the stack and next adds 16 bytes of random data on top (which libc uses as a seed for its PRNG): The kernel then creates the elf auxiliary table: A collection of (id, value) pairs that describe useful information about the program being run and the environment it is running in, communicated from the kernel to user space. The list ends with a Zero Identifier and Zero value (e.g. 16 bytes of 0x00). There are about 20 entries (320 bytes) in the list. The table starts with ARCH_DLINFO (which expands to AT_SYSINFO_EHDR + AT_MINSIGSTKSZ). The 'Identifiers' are defined in auxvec.h: In gdb the elf auxiliary table from our program's stack looks like this (Note: The 'Identifier' values above are in decimal but gdb shows them in hex): COPY COPY [... above is argc ...] [... above is argvp ...] [... above here is envp ...] 0x7ffca42296a8: 0x21 0x7ffca4351000 <-- AT_SYSINFO_EDHR 0x7ffca42296b8: 0x33 0xd30 <-- AT_MINSIGSTKSZ 0x7ffca42296c8: 0x10 0x178bfbff <-- AT_HWCAP 0x7ffca42296d8: 0x6 0x1000 <-- AT_PAGESZ 0x7ffca42296e8: 0x11 0x64 0x7ffca42296f8: 0x3 0x400040 0x7ffca4229708: 0x4 0x38 0x7ffca4229718: 0x5 0xa 0x7ffca4229728: 0x7 0x0 0x7ffca4229738: 0x8 0x0 0x7ffca4229748: 0x9 0x4014f0 <-- Our entry point 0x7ffca4229758: 0xb 0x0 0x7ffca4229768: 0xc 0x0 0x7ffca4229778: 0xd 0x0 0x7ffca4229788: 0xe 0x0 0x7ffca4229798: 0x17 0x0 0x7ffca42297a8: 0x19 0x7ffca42297f9 <-- Ptr to Random 0x7ffca42297b8: 0x1a 0x2 0x7ffca42297c8: 0x1f 0x7ffca422afe9 <-- Ptr to filename 0x7ffca42297d8: 0xf 0x7ffca4229809 <-- Ptr to x86_64 0x7ffca42297e8: 0x0 0x0 <-- NULL + NULL [... ELF table stops here ...] 0x7ffca42297f8: 0xe8e8de3a49831f00 0xdfbf9ede0185cb4 <-- RND16 0x7ffca4229808: 0x34365f363878af 0x0 <-- \"x86_64\" + '\\0' [... below is empty space from stack randomization ...] [... below are argv strings ...] [... below are env strings ...] [... last is the filename (/root/none) ...] Thereafter the kernel allocates stack memory to store the elf-aux-table, the argv- and env-pointers and the argc value (+1) and aligns the top of the stack to 16 bytes. (It does not yet copy the elf-aux-table onto the stack just yet. This happens later): ...and then puts the argc, argv-pointers and env-pointers onto the stack: ...and then copies the elf-aux table (elf_info; from above) on the stack (aligned; below the env pointers). (The clever reader may have noticed that 'RND16' does not start at an aligned address - 0x7ffca42297f9: It is because RND16 was put on the stack before the STACK_ROUND() call to put the elf-info table and env/argv pointers). Now back in load_elf_binary(), the kernel sets the registers, clears some stuff and finally (!) calls START_THREAD() to start the program. Afterthought: Someone pointed https://lwn.net/Articles/631631/. Their ASCII art is superior to mine 🫶. It shows the layout of the stack just before execution (but they drew it the other way around; starting with the largest address at the top and the smallest addresses at the bottom): How to Zapper Wheeee. What a ride. For Zapper we ptrace() at the entry-point, increase the stack to make a copy of argv/env-strings, adjust all the pointers to point to 'our' copy of the argv/env-strings and ZERO the original ones to 0x00. The kernel does not know about it and still references the now zero'd argv/env-strings and ...wush..they are gone from the process list. Telegram: https://t.me/thcorg 👈 Releases published here 1 day earlier. 👻 Mastodon: @thc@infosec.exchange Twat: https://twitter.com/hackerschoice 2 hacking Linux coding exploit MORE ARTICLES root WireGuard into a private LAN via CloudFlare Tunnels TL;DR: The era of only filtering ingress traffic has come to an end. Differentiating between legitim… root Free Linux Cloud Root Shells A short selection of Cloud-based Linux Root Shells and their resource limits. Overview: … root Tunnel via Cloudflare to any TCP Service Cloudflare's cloudflared tunnels are commonly used to 'publish' a web server that runs behind a fire… ©2023 Knowledge Base Archive · Privacy policy · Terms Publish with Hashnode Powered by Hashnode - Home for tech writers and readers",
    "commentLink": "https://news.ycombinator.com/item?id=37521240",
    "commentBody": "How does Linux start a processHacker NewspastloginHow does Linux start a process (thc.org) 265 points by 10xJobs_net 23 hours ago| hidepastfavorite28 comments bluetomcat 20 hours agoA good walkthrough, but it doesn&#x27;t mention how the ELF headers are interpreted and how the corresponding file sections (code, data, rodata) are mapped into the virtual address space of the process. It only covers the setup of the stack and the invocation of main. reply mananaysiempre 18 hours agoparentThe first thing I thought of when I saw the article title here was “How programs get run”[1], a series on LWN; the second installment[2] describes the ELF parts of the story.(The exposition in his two-parter “Anatomy of a system call”[3,4] is similarly brilliant.)If all you want is a non-Linux-specific description of how to write a static ELF loader (which is surprisingly simple), you can also take a look at the description on the OSDev Wiki[5] (but be mindful of the somewhat uneven code quality on that website) and at Libelf by example[6] (but libelf may be a bit too much abstraction than you really need if you’re trying to understand the format itself).[1] https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;630727&#x2F;[2] https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;631631&#x2F;[3] https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;604287&#x2F;[4] https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;604515&#x2F;[5] https:&#x2F;&#x2F;wiki.osdev.org&#x2F;ELF[6] https:&#x2F;&#x2F;sourceforge.net&#x2F;projects&#x2F;elftoolchain&#x2F;files&#x2F;Document... reply 22SAS 20 hours agoparentprevAny good resources to learn about that? reply emidln 19 hours agorootparentThe source code to the kernel&#x27;s elf \"binfmt\"[0] is very readable. The elf binfmt is registered (along with a few others like `binfmt_misc`) and you get dispatched there via `exec_binprm`[1] which is invoked by the `execve` syscall[2]. When loading a shared library, you also dispatch to a binfmt via the `uselib`[3] syscall.[0] https:&#x2F;&#x2F;github.com&#x2F;torvalds&#x2F;linux&#x2F;blob&#x2F;9fdfb15a3dbf818e06be5...[1] https:&#x2F;&#x2F;github.com&#x2F;torvalds&#x2F;linux&#x2F;blob&#x2F;9fdfb15a3dbf818e06be5...[2] https:&#x2F;&#x2F;github.com&#x2F;torvalds&#x2F;linux&#x2F;blob&#x2F;9fdfb15a3dbf818e06be5...[3] https:&#x2F;&#x2F;github.com&#x2F;torvalds&#x2F;linux&#x2F;blob&#x2F;9fdfb15a3dbf818e06be5... reply dharmab 18 hours agorootparentprevCPU Land is an accessible introduction. This chapter covers ELF https:&#x2F;&#x2F;cpu.land&#x2F;becoming-an-elf-lord reply duped 20 hours agorootparentprevThe book \"Linkers an Loaders\" by Levine is the Bible on the subject reply ndesaulniers 11 hours agorootparentYes; but there&#x27;s also descriptions of legacy container formats no one cares about any more. I still recommend it and have my own copy, I just recall skipping over quite a bit of material. reply Findecanor 18 hours agorootparentprevIt used to be available online for free at , but isn&#x27;t any more. You could get it from archive.org though, and I think I&#x27;ve seen mirrors in other formats on Hacker News in previous discussions about the book. reply mimimi31 19 hours agorootparentprevThere&#x27;s a great summary from LWN[1] with lots of references and links to other articles for further reading.[1] https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;631631 reply proto_lambda 18 hours agorootparentprevIf you&#x27;re interested in or already comfortable with Rust, Amos (fasterthanlime) has a nice long-form series that goes into this, basically building a custom ELF loader in the end. The writing style isn&#x27;t everyone&#x27;s cup of tea, but maybe you like it: https:&#x2F;&#x2F;fasterthanli.me&#x2F;series&#x2F;making-our-own-executable-pac... reply bluetomcat 19 hours agorootparentprev\"man 5 elf\" should be the ultimate source of truth :-) reply convolvatron 17 hours agorootparentthe elf specification is: https:&#x2F;&#x2F;refspecs.linuxfoundation.org&#x2F;elf&#x2F;elf.pdf reply yrro 19 hours agorootparentprevI&#x27;ve found that searching for stories with ELF in the title then trawling through the comments for the links is really informative. reply eddtests 18 hours agorootparentI just hope they catch this Sauron before it’s too late… reply i4k 20 hours agoprevInstead of only hiding the arguments, is it also possible to change them? and even change argv[0]? reply hakre 19 hours agoparentsee exec builtin in the bash shell. otherwise man execvp etc. reply abhishekjha 19 hours agoprevNo reference to fork anywhere? reply CodeL 18 hours agoparentThis could be deliberate. Either to not derail focus from `execve` or perhaps the author assumed that the readers are already well-versed with `fork`. reply jklinger410 20 hours agoprev [11 more] [flagged] edgyquant 20 hours agoparentCan we not, “Dude weed lmao,” here? Have something substantial to add please reply ot 19 hours agorootparent> Have something substantial to add pleaseThe comment was indeed about a matter of substance reply jklinger410 20 hours agorootparentprevLet&#x27;s compromise and make sure all the weed jokes fall under the replies to my top level comment. reply castis 20 hours agorootparentprevIs denouncing that which is not your personal brand of humor a substantial addition? reply edgyquant 14 hours agorootparentIt’s not about my brand of humor, any comment that is just a quip is unsubstantial and against community guidelines here. What exactly is the point of your comment other than to try and make us more like Reddit, the website HN was designed to not be. reply SanderNL 19 hours agorootparentprevThis creates noise. Regular users shouldn’t be commenting on the quality and usefulness of other people’s comments.Oh wait.. reply mpalmer 19 hours agorootparentprevPerhaps just downvote and&#x2F;or move on. reply fullspectrumdev 18 hours agoparentprevThe THC group has been around since basically the very early days of www so… No. Not waste.Although, I do believe some of the people involved in THC were also involved in creation of the Joint Routing Protocol :) http:&#x2F;&#x2F;darklab.org&#x2F;jrp.txt reply openthc 20 hours agoparentprevSeems apt: The Hacker&#x27;s Choice reply ghuroo1 18 hours agoparentprev [–] let’s not turn this into reddit replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article delves into the mechanism by which Linux starts a process and prepares the execution stack, particularly focusing on when a process calls execve().",
      "It provides an in-depth examination of a binary file's details, using gdb (GNU Debugger) for the analysis of instructions and program stack.",
      "The piece also illustrates how the Linux kernel allocates and populates the stack with information including argument lists and environment variables, providing insights useful for tools like 'Zapper'."
    ],
    "commentSummary": [
      "The discussion thread on Hacker News is centered on understanding how Linux initiates a process and the interpretation of ELF (Executable and Linkable Format) headers.",
      "Multiple resources and references are shared for further in-depth learning on this subject matter.",
      "Part of the discussion includes critique and feedback on the quality of comments and information shared by other users in the thread."
    ],
    "points": 265,
    "commentCount": 28,
    "retryCount": 0,
    "time": 1694776086
  },
  {
    "id": 37523992,
    "title": "Google to pay $93M in settlement over deceptive location tracking",
    "originLink": "https://www.theguardian.com/technology/2023/sep/14/google-location-tracking-data-settlement",
    "originBody": "Skip to main content Skip to navigation Skip to navigation Print subscriptions Sign in Search jobs Search UK edition The Guardian - Back to home Support the Guardian Fund independent journalism with £5 per month Support us News Opinion Sport Culture Lifestyle Show More UK World Climate crisis Newsletters Football Business Environment UK politics Education Society Science Tech Global development Obituaries California attorney general’s office also alleged Google ‘deceived users about their ability to opt out of advertisements targeted to location’. Photograph: Andre M Chang/ZUMA Wire/REX/Shutterstock Google Google to pay $93m in settlement over deceptive location tracking Tech giant ‘continued to collect and store a user’s location data’ even if users turned off their location history, according to suit Johana Bhuiyan Fri 15 Sep 2023 00.38 BST Google will pay $93m to settle accusations of misleading consumers on how and when their location information was being tracked and stored, a considerable payout for the tech giant that following a years-long investigation into its data practices. The settlement stems from a lawsuit brought by the California attorney general, Rob Bonta, that concluded the company misled consumers into believing they had more control over their location information than they actually did. Google accused of spending billions to block rivals as landmark trial continues Read more “Our investigation revealed that Google was telling its users one thing – that it would no longer track their location once they opted out – but doing the opposite and continuing to track its users’ movements for its own commercial gain,” Bonta said in a statement announcing the settlement. “That’s unacceptable, and we’re holding Google accountable.” The complaint rests on a central discrepancy between how Google represented its handling of user location data and how the attorney general’s office alleged it actually handled it. While Google gave people the option to turn off their “location history” and explicitly stated the company would not track the places they went if they chose this option, the company “continued to collect and store that user’s location data through other sources”, including through a user’s “web and app activity” tracker, which the attorney general said continues to be on by default. The AG’s office further alleged that Google “deceived users about their ability to opt out of advertisements targeted to their location”. While Google is not admitting any fault as part of the settlement, the company did agree to several other terms in addition to paying $93m. Those conditions include being more transparent about its location tracking practices; notifying users before location information is used to build ad profiles to target specific people; and getting approval from Google’s internal privacy working group before making any material changes to privacy. José Castañeda, a Google spokesperson, told the Guardian: “Consistent with improvements we’ve made in recent years, we have settled this matter, which was based on outdated product policies that we changed years ago.” skip past newsletter promotion Sign up to First Thing Free daily newsletter Our US morning briefing breaks down the key stories of the day, telling you what’s happening and why it matters Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy. We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion Google previously settled a similar lawsuit brought by 40 states’ attorneys general, which levied the same allegations about its deceptive location privacy practices, for nearly $392m in 2022. Explore more on these topics Google Alphabet California news Reuse this content Most viewed UK World Climate crisis Newsletters Football Business Environment UK politics Education Society Science Tech Global development Obituaries News Opinion Sport Culture Lifestyle Original reporting and incisive analysis, direct from the Guardian every morning Sign up for our email About us Help Complaints & corrections SecureDrop Work for us Privacy policy Cookie policy Terms & conditions Contact us All topics All writers Modern Slavery Act Digital newspaper archive Facebook YouTube Instagram LinkedIn Twitter Newsletters Advertise with us Guardian Labs Search jobs Patrons Back to top © 2023 Guardian News & Media Limited or its affiliated companies. All rights reserved. (modern)",
    "commentLink": "https://news.ycombinator.com/item?id=37523992",
    "commentBody": "Google to pay $93M in settlement over deceptive location trackingHacker NewspastloginGoogle to pay $93M in settlement over deceptive location tracking (theguardian.com) 230 points by Brajeshwar 19 hours ago| hidepastfavorite69 comments evolve2k 14 hours ago“To the rich, parking fines are just price tags” [1]While annoying for Google, this is a mosquito bite.Google Annual Revenue: $279,800 MillionAnd today they’ll be fined: .. .. $93 MillionIt’s about “an hour” of their annual income.At these prices it’s pretty much worth it to be pulling all sorts of unethical moves. This is not even the price to play but rather the price if you get caught.1. https:&#x2F;&#x2F;i.pinimg.com&#x2F;564x&#x2F;a6&#x2F;06&#x2F;ec&#x2F;a606ec5c539472182cf126226...2. https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;266206&#x2F;googles-annual-gl... reply _jab 14 hours agoparentComparing the entire company&#x27;s revenue to the fine is a bit misleading. Arguably, the more relevant comparison is to consider how much marginal revenue the violating feature actually produced. Granted, probably no one besides Google knows that number, but it&#x27;s surely orders of magnitude lower. If those numbers are comparable, this starts to look like a reasonable penalty. reply sodality2 13 hours agorootparentI definitely don’t ascribe to the notion that crimes should be punished equally to their benefit to the party. Otherwise bank thieves would just give it all back when caught, and the risk to reward is minimal. It should be enough to dissuade a company from ever doing these illegal acts reply tomComb 13 hours agorootparentI don’t think you’re understanding the meaning of proportional. You could make the penalty 50 times the benefit. reply sodality2 13 hours agorootparentYou’re right, edited for clarity reply everforward 11 hours agorootparentprevI don&#x27;t think the marginal revenue is directly relevant. The relevant question is how big does the fine have to be to discourage illegal behavior in the future? The marginal revenue of the behavior is somewhat relevant because the fine should obviously be at or higher than that amount, but that&#x27;s really a lower bound.They lost a similar case in 2012 about lying to Safari users about privacy settings and were fined $22.5M (~$31M today). They lost one in 2010 about violating the Wiretap Act for collecting packets from unencrypted wifi networks. They lost another one in 2010 for Google Buzz. Some of those were settled, but I would consider it roughly equivalent to losing if they&#x27;d rather buy their way out than have to present a case.Given that they previously lost a case (to California, again, no less) with similar underlying issues, I would consider this to be flagrant flouting of the law and it should be punished proportionally to that flagrancy. Roosevelt said to \"speak softly and carry a big stick\". Google didn&#x27;t listen to the soft speaking, so California should hit them with the big stick hard enough to remind them that they only exist in California at the pleasure of the people of California.My proposal would be a fine equal to 100% of revenue derived from Californians for the period they were violating the law. They need a fine big enough that the C-levels start asking legal whether they can use the bathroom or not, and a promise that all future violations will be treated the same way. For pity&#x27;s sake, California has a 3 strikes system for individuals. It&#x27;s not like the state doesn&#x27;t do disproportionate punishment. If Google were a person, they would&#x27;ve been in jail a decade ago and probably staring down California&#x27;s 3-strike law and life in prison. reply wuiheerfoj 13 hours agorootparentprevNot defending the comparison against revenue, but we’d need to compare the value produced by the illegal tracking against the probability of getting caught and fined. Given google are unlikely to be the only one doing this, the expected value of breaking the law could still be quite high reply hankchinaski 14 hours agorootparentprevexactly - people each time there is a fine they continue to regurgitate the usual \"but what bout their revenue\" - people on the orange site thinking they know better than a panel of expert regulators reply ClumsyPilot 13 hours agorootparentYou mean like the panel of expert regulators that has sent noone to jail for collapsing the global economy in 2008, or for Boeing Max debacle? reply jasonfarnon 12 hours agorootparentprevI don&#x27;t know what the orange site is. But I know a panel of \"expert regulators\" did not decide on this fine. This was a negotiated legal settlement. reply wnoise 12 hours agorootparentThis is the orange site, the one you&#x27;re on right now. reply hnav 14 hours agoparentprevGoogle&#x27;s net income is something like 60b, so more like half a day which is a bit more significant. Multiply that by all the different angles regulators are going to be coming for big tech and it might start to add up enough that it shapes internal policy further. reply hedora 14 hours agorootparentSince almost all of their revenue is from tracking users, that implies we&#x27;ll need over of these rulings per day if we want it to be economically rational for them to stop violating people&#x27;s privacy. reply evolve2k 14 hours agorootparentprevWhen we as externals are at “if enough fines are issued it might start to shift behaviour” we’re very much dealing with a party for whom this is a mere inconvenience. reply robocat 12 hours agoparentprev> Revenue: $279,800 Million > about “an hour” of their annual incomeNitpick: mistaking revenue for income(profit) is a very common error most of us make when talking about businesses. If you wish to own a business or invest, it is well worthwhile to program the difference into your head. It matters less for high margin businesses, but it is crucial to delineate the difference for low margin businesess (such as retail). reply devindotcom 17 hours agoprevFolks talking about how easy it is to see and change these settings, remember that many of the patterns and practices being litigated go back years to when these settings were less clearly stated, if they were stated at all. The reason there is such transparency now is because of years of pressure from lawsuits, regulators, and reporting. reply gustavus 16 hours agoparentFor me it&#x27;s less about knowing how to turn them off and the constant worrying fear they&#x27;ll be reset with the latest update, or some random feature that I actually need will get turned off along with it. reply chrsig 16 hours agorootparentWhen considering bad faith actors, I tend to consider taking extreme: I worry that the toggles don&#x27;t actually do anything at all. Or there&#x27;s some other means of exfiltration in use that&#x27;s not covered by the existing controls. reply bornfreddy 14 hours agorootparentExactly this. If you want to avoid being tracked, you should not use BigTech solutions. They are convenient though. reply godelski 16 hours agorootparentprev> the constant worrying fear they&#x27;ll be reset with the latest updateWhich happens a lot and is very annoying.A fantastic example is how Twitter defaulted everyone&#x27;s DMs to only allow them from people that pay for subscriptions. It is also buried. Settings > Privacy and Safety > Direct Messages. What a fucking crazy dark pattern. It&#x27;s so bad I see recruiters routinely post \"DM me\" and they have their inbox closed. reply djmashko2 15 hours agorootparentSeems like something that will continue unless people vote with their feet and switch to a different platform. reply godelski 12 hours agorootparentProbably. Though they can also change their settings.While I agree with you, at the same time I think we need to recognize that most people are very uncomfortable with switching platforms. There&#x27;s a lot of opportunity costs to most people. People tend not to be long term thinkers and aren&#x27;t considering the consequences of their actions. For example, look at how many people here on HN -- where tech literacy is high as well as capabilities -- complain about Google&#x27;s domination of the internet yet at every turn are quick to go after Mozilla and Firefox. The main alternatives are still Chromium based browsers. Same is true about Apple&#x27;s walled garden. The sad truth is that things won&#x27;t change unless we can convince the __average__ person, not __a__ person. Hell, I can&#x27;t even get the most paranoid big brother boomer to use Signal despite it being rather trivial. I just don&#x27;t know anymore tbh. reply ethbr1 16 hours agorootparentprevAgreed. It&#x27;d be nice to have a tiered, single-point consent system, where user-preference was cascaded down to preclude auto-opt-in.E.g. \"Do you want to be tracked?\"If you answer no, then no feature which tracks you can be default opt-in, even if subsequently shipped. reply Justsignedup 17 hours agoparentprevAlso to add.Many people don&#x27;t understand this in the same way that many people don&#x27;t understand the tweaks you can make to your car engine.Sometimes they make changes which undoes the settings and sometimes settings are per device. It is quite difficult to keep track of it all.And sometimes turning off an ad feature cuts out a ton of non ad features. Example I can&#x27;t turn off Google location tracking ad features without turning off googles ability to show me recent locations I drove to which I find quite helpful. reply julianlam 16 hours agoprev> While Google is not admitting any fault as part of the settlement, the company did agree to several other terms in addition to paying $93m. Those conditions include being more transparent about its location tracking practices; notifying users before location information is used to build ad profiles to target specific people; and getting approval from Google’s internal privacy working group before making any material changes to privacy.That last line is oddly reminiscent of the government delegating safety audits to the airplane manufacturers themselves. reply hedora 14 hours agoparent> is used to build ad profiles to target specific peopleI was wondering how they&#x27;d comply for logged out users. I&#x27;ll bet the phrase \"specific people\" explicitly excludes pseudonymous profiles (which are trivial to de-anonymize) and explicitly allows them to use clustering algorithms with arbitrarily fine granularity. (\"This isn&#x27;t a profile for a specific user. It&#x27;s a cluster that could contain an arbitrary number users. It currently only contains one, but that&#x27;s bound to happen, given the number of clusters...\") reply M3L0NM4N 16 hours agoparentprevYeah, but it makes me wonder if an internal privacy working group already existed, and they weren&#x27;t approving changes in privacy rules, what were they actually doing? reply jvolkman 15 hours agorootparentIt&#x27;s not as if privacy teams are reviewing each code change at Google. The teams making changes are generally responsible for knowing if and when to seek out approval&#x2F;advice. reply sa-code 16 hours agorootparentprevBeing employed, so that Google can say they employ them reply nologic01 15 hours agoprevYou can find hordes of shills to state otherwise but alas tech has become an industry that is based on deception.Its a fateful turn of events. It means that the fundamental and very powerful information engineering skill, something that is in-principle vital, neutral and promising, is lost to the world as a force for good.You cant put lipstick on a pig. That moral deficit at the core of the industry is fatal. Nothing good or lasting will be built on it. reply JohnMakin 17 hours agoprevThey likely made way more than $93M doing this, which means this is just a cost of business, and does nothing for consumer protections going forward, nor does it discourage google from continuing this behavior.You need fines with real teeth or pass laws that make this illegal. reply njovin 17 hours agoparent$93m is approximately 172 minutes worth of revenue for Google. reply pxoe 18 hours agoprevthis location timeline page https:&#x2F;&#x2F;timeline.google.com&#x2F;maps&#x2F;timeline should be included up along in there. if not deceptive, it&#x27;s certainly badly designed and confusing enough for you to overlook what options are available to you. in dark mode, these little buttons (that actually manage your data and obscure important options) are almost unnoticeable. and this is somehow the only way to delete your location data, both web and mobile. even on android it&#x27;s still just a redirect to that same web page. there is no native &#x27;delete location history&#x27; button. (and if you do open that page on android, you might have to sign in to your account again before even seeing anything lol. as always, burying and obscuring controls. it couldn&#x27;t be that hard to implement a &#x27;delete all&#x27; button on activity controls page right before, but oh nooo, what if people would actually deprive google of location data.) reply lkbm 17 hours agoparentFor me there&#x27;s a big \"Manage Location History\" button on the main page, which has a clear option to turn off or turn off and delete, as well auto-delete setting. Not sure how dark mode would affect how visible it is, but in the default view, it&#x27;s pretty in your face.I&#x27;d say the trickiest bit is probably finding your timeline in the first place if you don&#x27;t regularly make use of it, but I get periodic emails about it — at least a monthly summary.EDIT: Looks like, at least in Firefox, the page doesn&#x27;t respect Dark Mode at all.EDIT 2: Here&#x27;s the top and bottom of my monthly email from them: https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;oUez8ZC — multiple direct links to the page to turn off and delete location data. reply ethbr1 16 hours agorootparentAlso, on Firefox Android Mobile, it flags private mode as an unsupported browser, and only displays the \"Delete All\" button at the bottom. reply jeffbee 17 hours agoparentprevThis has to be the most visible privacy control Google offers. Nobody is in Location History unless they turned it on, and if you have it turned on you get a reminder every month by email that says right at the top, in the snippet, \"You&#x27;re receiving this email because you turned on Location History, a Google Account-level setting that creates Timeline, a personal map of your visited places, routes, and trips. You can view, edit, and delete this data anytime in Timeline.\" reply pxoe 13 hours agorootparentwell, try going for deletion of all location history and see how that goes for &#x27;the most visible control&#x27; reply eks391 10 hours agorootparentI deleted my history several times back when I used a google account. It can be done in two places, but the easier is, starting from any google application, click ProfileImage > Manage your Google Account > Data and Privacy. On that page is Location History, in the Things you&#x27;ve done and places you&#x27;ve been category. In there your options are Delete all, or Delete activity older than . And it can be recurring deletion as well.In the same Privacy page, you can easily delete or download anything you want. reply AlbertCory 17 hours agoprevI don&#x27;t know if this was already mentioned, but I am getting pissed off at how often my Settings get changed without my doing anything.Auto-rotate: goes off, have to reset.Screen timeout: gets reset to 15 seconds.Some programs are able to change your Settings without explicit permission from you. This should be just plain impossible. reply hotstickyballs 17 hours agoparentAre you on android? reply doctor_radium 17 hours agoprevI&#x27;m confused. What is the Android or app configuration necessary to enable this tracking? \"Web and app activity\", the only setting mentioned in the article, doesn&#x27;t ring a bell. Is it all assuming the creation and use of a Google account? reply eks391 10 hours agoparentYes, however most people have google accounts. For example, with an android, it is impossible to download an app from the Play Store without a google account (assuming you aren&#x27;t using a mirror, and other stipulations), so that alone encapsulats half of Americans, and google has several other products unrelated to android you could be using.The people in developed countries who this doesn&#x27;t affect could be negligible. reply doctor_radium 4 hours agorootparentThanks for explaining. Happy (for once) to hear that I&#x27;m negligible. reply dehrmann 17 hours agoprevAnd they tie your location history to ad views and surface this to advertisers.https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2018&#x2F;aug&#x2F;13&#x2F;google-lo... reply entropicgravity 15 hours agoprevWow $93m for each of us! I can hardly wait to open my mailbox. reply stuff4ben 17 hours agoprevWonder how much they made selling that data instead? reply booleandilemma 17 hours agoprevWhere do all these millions go exactly? reply predkambrij 16 hours agoparentDo fooled people get any of that? reply trollerator23 16 hours agoprevNice drop in the bucket. reply CrzyLngPwd 17 hours agoprevThat fine is so small that it is just another cost of doing business. reply jeffbee 17 hours agoparentThe fine reflects the weakness of the state&#x27;s case. The defendants whittled it down to where the expected value of litigating it was equal to the cost of settling it. reply eternal_braid 18 hours agoprev\"a considerable payout for the tech giant that following a years-long investigation into its data practices.\" reply rvz 18 hours agoprevThat isn’t good enough. It should be $9.3B dollars since Google does this on a repeated basis.A slap on the wrist like this will make them continue their actions and nothing will change. reply dahfizz 15 hours agoparentThe behavior in question has already changed reply jacquesm 14 hours agorootparentSo? No reason not to royally fine them. Because it isn&#x27;t just about this particular action, it is also about all the other abuses, past and present. reply dahfizz 14 hours agorootparentI am responding to this assertion:> A slap on the wrist like this will make them continue their actions and nothing will change.If this \"slap on the wrist\" does indeed change the bad behavior in question, then it seems like the system is working. reply jacquesm 14 hours agorootparentNo, this slap on the wrist only changed this bad behavior, so they&#x27;ll try again with something else.What needs to be done is not a slap on the wrist but a whack over the head with a cluebat that it&#x27;s been enough and that the next fine will put them out of business so we can stop this endless game of whackamole. replycolesantiago 18 hours agoprevnext [6 more] [flagged] havnagiggle 18 hours agoparentThis was just CA. There was a similar lawsuit by other states last year settled for $300-400 million. reply scottyah 18 hours agoparentprevJust keep funneling all the tech (big business marketing budget) money straight past workers and right to lawyers and politicians.The article didn&#x27;t mention- where does this money actually end up? reply sitkack 17 hours agorootparentFalse dichotomy. That money wouldn’t have made it to workers anyway. reply jonhohle 17 hours agorootparentBut it shouldn’t make it to lawyers and politicians, either. reply sitkack 8 hours agorootparentThe money goes to the people, if you want it to go towards a specific thing instead of the general budget, talk to your representative. replyvoytec 18 hours agoprevnext [4 more] [flagged] andrewxdiamond 18 hours agoparentGoogle does not control moderation on HN reply sitkack 17 hours agorootparentA significant number of HN visitors work at Google. reply voytec 17 hours agorootparentprevHN posts visibility is easily manipulated by just few users flagging them. reply distant_hat 16 hours agoprevSo like an hour of revenue. reply hk1337 16 hours agoprevShould be $93M&#x2F;person reply arpowers 17 hours agoprev [–] Two weeks ago i was in San Francisco with a friend that works in \"big tech\" discussing \"profit motives\" in technology.They told me that the lobby behind their company had all sorts of tricks to help government \"ignore\" all the clearly negative things they are doing in the name of revenue. Lobbying, anonymous stock trading \"tips\" (see Pelosi), influence pedding, etc..Modern technology companies are all doing what the Tobacco companies did, only they have more plausible deniability. reply jacquesm 14 hours agoparent [–] So a friend of yours told you that Pelosi accepted insider information to make a bundle and both you and your friend did nothing about it? Are you aware that the SEC will reward you for such information assuming it is true? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google has agreed to pay $93 million in a settlement over allegations of misleading consumers about its location tracking practices.",
      "The California attorney general filed the lawsuit, accusing Google of continuing to gather and store user location data even when users disabled their location history.",
      "The settlement also includes terms for Google to be more transparent about its tracking methods and to require consent before making changes to privacy settings."
    ],
    "commentSummary": [
      "Google has agreed to a $93 million settlement over allegations of deceitful location tracking practices, which has been criticized as insufficient to prevent future violations considering Google's annual revenue.",
      "Discussions are emerging regarding the necessity for stricter penalties and legislation to safeguard privacy as well as criticism over Google's internet dominance and the effectiveness of the settlement remedies.",
      "Concerns were raised about the complex management of location history settings, unpermitted alteration of device settings by some apps, and the requirement of a Google account to activate location tracking."
    ],
    "points": 230,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1694789636
  },
  {
    "id": 37528816,
    "title": "“Inverse vaccine” shows potential to treat MS and other autoimmune diseases",
    "originLink": "https://pme.uchicago.edu/news/inverse-vaccine-shows-potential-treat-multiple-sclerosis-and-other-autoimmune-diseases",
    "originBody": "Skip to main content Current StudentsIndustryPublicationsIntranet Home AboutThemesAcademicsPeopleLab GroupsNewsEventsGiveApply Now Search NEWS “Inverse vaccine” shows potential to treat multiple sclerosis and other autoimmune diseases September 11, 2023 In a new study, Prof. Jeffrey Hubbell and fellow researchers describe a new “inverse vaccine” that in a lab setting can stop autoimmune reactions which attack a person’s healthy tissues, as seen in diseases multiple sclerosis, type I diabetes, or rheumatoid arthritis. (Image copyright shutterstock.com) By Sarah C.P. Williams Facebook Twitter LinkedIn Email Print Related content ‘Masked’ cancer drug sneaks through body to deliver anti-tumor treatment with fewer side effects Exploiting cancer cells to aid in their own destruction Big Brains podcast: Engineering a cure for cancer, with Jeffrey Hubbell and Melody Swartz Marine Biological Lab-UChicago collaboration takes aim at cancer immunotherapy A new type of vaccine developed by researchers at the University of Chicago’s Pritzker School of Molecular Engineering (PME) has shown in the lab setting that it can completely reverse autoimmune diseases like multiple sclerosis and type 1 diabetes— all without shutting down the rest of the immune system. A typical vaccine teaches the human immune system to recognize a virus or bacteria as an enemy that should be attacked. The new “inverse vaccine” does just the opposite: it removes the immune system’s memory of one molecule. While such immune memory erasure would be unwanted for infectious diseases, it can stop autoimmune reactions like those seen in multiple sclerosis, type I diabetes, or rheumatoid arthritis, in which the immune system attacks a person’s healthy tissues. The inverse vaccine, described in Nature Biomedical Engineering, takes advantage of how the liver naturally marks molecules from broken-down cells with “do not attack” flags to prevent autoimmune reactions to cells that die by natural processes. PME researchers coupled an antigen — a molecule being attacked by the immune system— with a molecule resembling a fragment of an aged cell that the liver would recognize as friend, rather than foe. The team showed how the vaccine could successfully stop the autoimmune reaction associated with a multiple-sclerosis-like disease. “In the past, we showed that we could use this approach to prevent autoimmunity,” said Jeffrey Hubbell, the Eugene Bell Professor in Tissue Engineering and lead author of the new paper. “But what is so exciting about this work is that we have shown that we can treat diseases like multiple sclerosis after there is already ongoing inflammation, which is more useful in a real-world context.” Photo by Matt Marton Unwinding an immune response The job of the immune system’s T cells is to recognize unwanted cells and molecules — from viruses and bacteria to cancers — as foreign to the body and get rid of them. Once T cells launch an initial attack against an antigen, they retain a memory of the invader to eliminate it more quickly in the future. T cells can make mistakes, however, and recognize healthy cells as foreign. In people with multiple sclerosis, for instance, T cells mount an attack against myelin, the protective coating around nerves. Hubbell and his colleagues knew that the body has a mechanism for ensuring that immune reactions don’t occur in response to every damaged cell in the body — a phenomenon known as peripheral immune tolerance, which is carried out in the liver. They discovered in recent years that tagging molecules with a sugar known as N-acetylgalactosamine (pGal) could mimic this process, sending the molecules to the liver where tolerance to them develops. “The idea is that we can attach any molecule we want to pGal and it will teach the immune system to tolerate it,” explained Hubbell. “Rather than rev up immunity as with a vaccine, we can tamp it down in a very specific way with an inverse vaccine.” “We have shown that we can treat diseases like multiple sclerosis after there is already ongoing inflammation.” Prof. Jeffrey Hubbell Prof. Jeffrey Hubbell In the new study, the researchers focused on a multiple-sclerosis-like disease in which the immune system attacks myelin, leading to weakness and numbness, loss of vision and, eventually mobility problems and paralysis. The team linked myelin proteins to pGal and tested the effect of the new inverse vaccine. The immune system, they found, stopped attacking myelin, allowing nerves to function correctly again and reversing symptoms of disease in animals. In a series of other experiments, the scientists showed that the same approach worked to minimize other ongoing immune reactions. Toward clinical trials Today, autoimmune diseases are generally treated with drugs that broadly shut down the immune system. “These treatments can be very effective, but you’re also blocking the immune responses necessary to fight off infections and so there are a lot of side effects,” said Hubbell. “If we could treat patients with an inverse vaccine instead, it could be much more specific and lead to fewer side effects.” “Rather than rev up immunity as with a vaccine, we can tamp it down in a very specific way with an inverse vaccine.” Prof. Jeffrey Hubbell Prof. Jeffrey Hubbell Initial phase I safety trials of a glycosylation-modified antigen therapy based on this preclinical work have already been carried out in people with celiac disease, an autoimmune disease that is associated with eating wheat, barley and rye, and phase I safety trials are under way in multiple sclerosis. Those trials are conducted by the pharmaceutical company Anokion SA, which helped fund the new work and which Hubbell cofounded and is a consultant, board member, and equity holder. The Alper Family Foundation also helped fund the research. “There are no clinically approved inverse vaccines yet, but we’re incredibly excited about moving this technology forward,” says Hubbell. Citation: “Synthetically glycosylated antigens for the antigen-specific suppression of established immune responses,” Tremain et al, Nature Biomedical Engineering, September 7, 2023. DOI: 10.1038/s41551-023-01086-2 Funding: Chicago Immunoengineering Innovation Center, Alper Family Foundation and Anokion SA. Facebook Twitter LinkedIn Email Print The University of Chicago Pritzker School of Molecular Engineering 5640 South Ellis Avenue Chicago, IL 60637 773.834.2943 © 2023 The University of Chicago About People Academics Accessibility Job Opportunities News Non-discrimination Privacy notice Give",
    "commentLink": "https://news.ycombinator.com/item?id=37528816",
    "commentBody": "“Inverse vaccine” shows potential to treat MS and other autoimmune diseasesHacker Newspastlogin“Inverse vaccine” shows potential to treat MS and other autoimmune diseases (uchicago.edu) 202 points by manicennui 13 hours ago| hidepastfavorite69 comments jvdvegt 7 minutes agoI can see how this works for slow autoimmune diseases mentioned in the article. But I suppose using it for fast autoimmune diseases is more difficult (thinking about Guillaume Barré Syndrome in particular, which can get you to an IC in 48 hours). reply manicennui 13 hours agoprev\"A typical vaccine teaches the human immune system to recognize a virus or bacteria as an enemy that should be attacked. The new &#x27;inverse vaccine&#x27; does just the opposite: it removes the immune system’s memory of one molecule. While such immune memory erasure would be unwanted for infectious diseases, it can stop autoimmune reactions like those seen in multiple sclerosis, type I diabetes, or rheumatoid arthritis, in which the immune system attacks a person’s healthy tissues.\" reply l33t7332273 9 hours agoparentCan anyone weigh in with information as to how insulated this is from being overbearing and giving someone some form of immune deficiency syndrome? reply DubiousPusher 6 hours agorootparentWell, considering that current treatments for these diseases involve a broad based suppression of the immune system which lead to substantial increases risk from routine infection, they would have to be pretty bad to do worse than the current standard of care.For example, the near state-of-the-art in immune suppression is the IL-17 inhibitor. IL-17 itself is a crucial signaller for Cytokine production. And it signals a broad array of Citokines. Citokines are essential in fighting most forms of infection. So, to have side effects as bad as a modern immune suppressant, an \"inverse vaccine\" would have to have a generalized effect as bad as global Citokine suppression. That would be an extraordinary leap for a drug which is meant to tell T cells to ignore one specific molecule. reply refurb 5 hours agorootparentprevThis is using the body’s own mechanism to develop tolerance to an antigen that is recognized as “self”. Nothing would stop the body from developing an immune response at a later time. reply DoreenMichele 6 hours agorootparentprevI&#x27;m personally skeptical of the entire concept of autoimmune disease. I think something else is going on -- something other than the immune system losing its mind and attacking healthy tissue for no real reason.If autoimmune disease is a flawed concept, then treating it this way could potentially go very bad places. reply l33t7332273 6 hours agorootparentThat’s a pretty fringe belief from my (limited!) understanding of the human immune system.Why do you think that? reply DoreenMichele 4 hours agorootparentI have a genetic disorder. I&#x27;ve seen lots of weird ideas about what the body is supposedly doing that simply don&#x27;t make sense. reply bdlowery 40 minutes agorootparentprevTell me you don’t know anyone with an autoimmune disease without telling me.Go talk to people with autoimmune diseases and then report back. There’s a good chance you’ll end up deleting your comment reply mjan22640 2 hours agorootparentprevAutoimmune is studied and understood deeply enough to be believable. reply DubiousPusher 5 hours agorootparentprevYou can have people with Psoriatic Arthritis creating legions on their skin. You give them an immune suppressant and the legions go away. Please explain to me your alternative hypothesis for this mode of action. reply alfor 5 hours agorootparentOur immune system is dysfunctioning because of something (not natural occurrence)What is that something? - vaccines - toxins, pesticides? - lack of vitamin D, infrared? Something else?Our modern medicine (pharma companies) are succeeding at making us chronically sick as that is what is more lucrative, it’s literally the matrix, we are serving the machine, not the other way around.Whatever is causing immune problems is at the same time creating a lot of shareholder value. reply onethought 4 hours agorootparentBut we spot these diseases the world over, not just in the US where it is lucrative.A lot of countries this medication is purchased and bargained for at the government level and then provided to individuals for low cost&#x2F;no cost (outside of tax).It’s also assessed at the total population level. So I don’t know how you could convince a country (say) to buy something that makes them ill then sell them the cure. They have the efficacy data of both things.Or are you suggesting that it is a cross industry collision, like shampoo that create diabetes, and then they sell us diabetes cures? reply Etrnl_President 3 hours agorootparentprev> If autoimmune disease is a flawed conceptThen testing this technology might prove your hypothesis. reply DoreenMichele 3 hours agorootparentPerhaps.Except a lot of studies are poorly done, humans are prone to confirmation bias, \"serious\" medical experiments can be awful stuff of a sort that won&#x27;t get approved -- and rightly so.Trying to get buy-in on new ideas can be shockingly hard. reply flangola7 11 hours agoparentprev>The new &#x27;inverse vaccine&#x27; does just the opposite: it removes the immune system’s memory of one molecule. While such immune memory erasure would be unwanted for infectious diseasesNew bioweapon just dropped reply forgetfreeman 3 hours agorootparentBecause creating a substance that when injected selectively turns off immune response to a single molecule is going to be way easier to administer, cheaper to manufacture, and more effective than say airborn anthrax spores... reply mjan22640 2 hours agorootparentDid any person in the world send the container of the mandatory vaccine to a lab to find out what they were actually administered? reply mabbo 10 hours agoprevIf there&#x27;s such an easy biological mechanism to indicate \"this one is fine\", then I&#x27;m surprised it isn&#x27;t being exploited by infectious agents already.Imagine a virus that causes cells to also produce proteins that tell the immune system the virus is a friend. reply pazimzadeh 10 hours agoparentThere are many such signals and they are already being exploited by pathogens. Such things are also exploited by tumors. That&#x27;s why figuring out hard basic immunology problems like transplantation (while managing associated infections) will probably generate knowledge that is likely to help cure cancer, and vice versa. A lot of the time glycans (sugars) are a key part of what makes something look like self vs non-self.Regulatory T cells and infection: a dangerous necessity https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;nri2189Sialic acid utilization by bacterial pathogens https:&#x2F;&#x2F;www.microbiologyresearch.org&#x2F;content&#x2F;journal&#x2F;micro&#x2F;1...Hallmarks of glycosylation in cancer https:&#x2F;&#x2F;www.oncotarget.com&#x2F;article&#x2F;8155&#x2F;text&#x2F; reply EwanG 10 hours agoparentprevI seem to recall that this is a known \"side effect\" of measles where it removes many immunities if you catch it. reply ccooffee 10 hours agorootparentHere&#x27;s a 2019 article, \"Study suggests how measles depletes body’s immune memory\"[0] which (despite the title) seems to quantify the percentage of antibody arsenal that is lost after a measles infection. Sadly, I haven&#x27;t had luck finding resources to answer \"by what mechanism does measles cause antibody memory to be lost?\", but I&#x27;ve got a good thing to ponder for the weekend. Thanks. :)[0] https:&#x2F;&#x2F;news.harvard.edu&#x2F;gazette&#x2F;story&#x2F;2019&#x2F;10&#x2F;how-measles-w... reply Izkata 9 hours agorootparentHere you go: https:&#x2F;&#x2F;asm.org&#x2F;Articles&#x2F;2019&#x2F;May&#x2F;Measles-and-Immune-AmnesiaVery short version: it infects the tissue that create the cells that contain or immune memory, replacing them with versions that only know about the measles virus. Sounds like it&#x27;s not permanent, though the article doesn&#x27;t make it clear whether it&#x27;s recovery or re-learning. reply simondotau 5 hours agorootparentOur immune system is quite aggressive with garbage collection and can picky about what pathogens it chooses to remember. This behaviour makes sense on the hypothesis that our immune system has a \"storage limit\" for immunities. It doesn&#x27;t make sense if the immunity memory is unlimited.(The reason why many vaccines require boosters is that without the repeat exposure, our immune system decides it doesn&#x27;t need to remember about that particular pathogen.) reply pazimzadeh 10 hours agorootparentprevAlso, HIV depletes your T cells reply ianlevesque 8 hours agorootparentAnd SARS-CoV-2, unfortunately. reply ekianjo 5 hours agorootparent?? 99.9% of people recover just fine and surely they still have their T cells reply forgetfreeman 3 hours agorootparentHow confident are you in your position? Literally 30 seconds spent searching: https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41418-022-00936-x reply ianlevesque 5 hours agorootparentprevIt’s probably a waste of breath on this forum at this point, but look it up, and how long it takes even HIV infected individuals to become clinically immunodeficient. replyjokowueu 1 hour agoparentprevSome gut parasites release immunosuppressants to protect themselves , it&#x27;s also actively being traild on humans who suffer from autoimmune gut diseases reply DoreenMichele 6 hours agoparentprevTrypanosomas change their protein markers to hide from the immune system. My recollection is this is why you can&#x27;t create a vaccine for them. reply refurb 5 hours agoparentprevThere already are diseases that hide from the immune system, things like hepatitis B, herpes, shingles.It’s nothing new. reply Etrnl_President 3 hours agorootparentCould we vaccinate Herpes to forget how to latch on to cells? reply refurb 2 hours agorootparentNot really.The current approach is to try and find an antigen on the herpes virus that the virus can&#x27;t stop the immune system from recognizing.Or use antivirals to stop the reproduction process, and the virus eventually dies. That&#x27;s the approach with hepatitis C. reply tcbawo 10 hours agoprevI hope this will be useful in treating food allergies. It also seems to be potentially scary to be attempting inverse vaccines while our understanding of the mechanics of immunity are so limited. reply db1234 5 hours agoparentLooks like the same team is already looking into treating food allergies with inverse vaccine https:&#x2F;&#x2F;foodallergyfund.org&#x2F;research-1&#x2F;2021&#x2F;2&#x2F;15&#x2F;inverse-foo.... reply dhbradshaw 7 hours agoprevWow, if this is real and practical it could be huge! Right up there with sanitation, nutrition, antibiotics and vaccines. reply qvrjuec 7 hours agoprevI remember reading discussions about mRNA vaccines being created to sensitize against immune system molecules, like in the way that Dupixent is just a monoclonal antibody that works against certain interleukins. So many interesting things out there for people with autoimmune diseases! reply tasty_freeze 5 hours agoprevI can already hear keyboards clacking away of fiction authors writing books of intrigue about this technology coming to fruition. Russia weaponizes it by creating a virus that has been engineered to emit variations of this knock-out molecule, making the recipient able to get sick again from a host of common illnesses. All Russian citizens have been given immunity from this new virus before it is unleashed on the world. Within weeks, nobody is immune from measles, chicken pox, mumps, etc. A huge wave of sickness envelops the world, giving Russia the upper hand as the militia of all its enemies are desperately ill. reply prvc 6 hours agoprevAnother application: erasing original antigenic sin. reply thenerdhead 12 hours agoprevAnyone have context as to how the name came to be? When I think of inverse vaccine, I think of something that gives you a disease. This is suggestive of erasing memory instead.Super exciting work nonetheless. reply pazimzadeh 12 hours agoparentBecause immune tolerance is the opposite of immune protection, when it comes to the adaptive immune system, whose business is deciding what to do the next time it encounters an antigen (it&#x27;s a memory response either way).But really what they found here should maybe be called an inverse vaccine adjuvant (the part of the vaccine which tells your immune system that the associated antigen is dangerous, and a protective response should be mounted to it) reply rockinghigh 7 hours agoparentprevVaccines activate the immune system. Inverse vaccine suppress it. reply rendleflag 11 hours agoprevI wonder if this could be used to address allergies as well. reply bawolff 9 hours agoparentIsn&#x27;t this already how we address allergies? reply Riseed 7 hours agorootparentAllergy shots include the small amounts of the allergen, given in such doses as to allow the immune system to build a tolerance to the allergen. [0][1] It reminds me of psychology&#x27;s \"exposure therapy\". [2] In layman&#x27;s terms, allergy shots teach the immune system to chill, whereas this \"inverse vaccine\" (as I understand it) deletes a substance from the immune system&#x27;s memory.[0] https:&#x2F;&#x2F;www.mayoclinic.org&#x2F;tests-procedures&#x2F;allergy-shots&#x2F;ab...[1] https:&#x2F;&#x2F;my.clevelandclinic.org&#x2F;health&#x2F;treatments&#x2F;25194-aller...[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Exposure_therapy reply jjcon 2 hours agorootparentIn less layman&#x27;s terms from someone that is still a layman - isn&#x27;t it less akin to exposure therapy and more that it modulates the immune response from one type to another (IgE to IgG4), the second response being less associated with the traditional symptoms of allergies but for which we are not entirely sure what the full impacts are? In other words the body still responds abnormally but with a different mechanism. Furthermore we aren&#x27;t entirely sure why high levels of exposure shift the response from one IG to another? reply rockinghigh 7 hours agorootparentprevI think the commenter was referring to immunosuppressive therapy. reply refurb 5 hours agorootparentprevYes, the approach in the article is very similar. The difference is that the antigen is tagged with molecules that heighten the recognition of the antigen as “self”.So same concept, just an improved approach. reply XorNot 11 hours agoprevWow. This is a big deal: autoimmune diseases are one of the hardest to treat.The same strategy presumably could be applied for something like Crohn&#x27;s disease. And I guess at a long shot, might work if IBS has an autoimmune component. reply malfist 11 hours agoparentWonder if it could treat arthritis? It like another commenter said, allergies. reply abracadaniel 10 hours agorootparentAnother article on this mentioned both as possible uses for this. They called out rheumatoid arthritis in particular. There&#x27;s lots of diseases with autoimmune components, that this could be a game changer for. I&#x27;m cautiously optimistic. reply sputr 1 hour agoprevAs an owner of a rare \"MS-like disease\" aka MOGAD I cant wait. The point of this treatment is that if you know which protein is the trigger you can stop it. It&#x27;s probably not a cure, but an even better alternative to the current treatments that all cause at least some side effects or are not entirely effective.I should note that I know of active phase 2 trials by other campanies for type 1 diabetes. reply consp 50 minutes agoparent> I should note that I know of active phase 2 trials by other campanies for type 1 diabetesFor those less informed and unfortunate owners of this malice, can you elaborate? reply tomohawk 12 hours agoprev> The new “inverse vaccine” does just the opposite: it removes the immune system’s memory of one moleculeVery cool, but what would happen if that molecule was small pox? reply dogsgobork 12 hours agoparentSince smallpox was eradicated over 40 years ago and most people alive today have not been vaccinated against it, I doubt it would matter much. reply bitwize 7 hours agorootparentSmallpox is one heist away from being unleashed on the world again, if that. And with most people unvaccinated, well... there&#x27;s your bioweapon. reply Dylan16807 5 hours agorootparentThen you don&#x27;t need to remove any immunity, right? reply JonathonW 12 hours agoparentprevThe US and Europe haven&#x27;t vaccinated for smallpox since the early &#x27;70s and routine vaccination wrapped up globally in the mid-&#x27;80s, so, for many... absolutely nothing. reply hinkley 12 hours agorootparentI used to be amused when period pieces would show actresses (particularly European) in sleeveless attire with their smallpox vaccine scar, three feet tall in the closeup shots.Turns out smallpox vaccines are a lot older than I thought. They might have not looked exactly like that in Victorian England, but an iteration of it did already exist. Guess that&#x27;s why they cover up tattoos but not smallpox scars. reply arcticbull 9 hours agorootparentYeah the first effective Smallpox vaccines were almost 230 years ago, and actually predates the Victorian era by a couple of decades.Vaccination through exposing healthy people to smallpox to build immunity goes back to like 200 BCE. [1][1] https:&#x2F;&#x2F;www.who.int&#x2F;news-room&#x2F;spotlight&#x2F;history-of-vaccinati... reply jiofj 11 hours agorootparentprevI know many people in my country, Spain, who are 60+ and have smallpox vaccine scars. reply hinkley 11 hours agorootparentYeah the movies I&#x27;m thinking of, those people would be 40-60 today, maybe a little bit older. reply gweinberg 11 hours agorootparentprevI used to have a smallpox scar but it eventually faded away. I am in my 50s. reply BurningFrog 10 hours agoparentprevMore generally, if you told the immune system to ignore a still existing disease, it would probably be defenseless if&#x2F;when you actually got infected by it.Or could the immune system maybe override this if you got really sick? reply samus 1 hour agorootparentAdd I understand it, it&#x27;s not about actively ignoring something. Rather, the immune system somehow learned to react more strongly to specific antigens, and undoing that. The natural immune reaction should still happen when encountering diseases, and not when encountering normal body tissues.It&#x27;s possible to use such tricks to actively shut down the immune system, but you either have to incorporate it into the disease (which actually happens in nature) or take that medicine continuously. reply h2odragon 10 hours agoparentprevsmallpox is a bit more than a molecule. reply readthenotes1 12 hours agoparentprevGood question!s&#x2F;small pox&#x2F;a marker for a harmful agent&#x2F; reply dkqmduems 8 hours agoprev [–] This is antivax. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers from the University of Chicago's Pritzker School of Molecular Engineering have created an 'inverse vaccine' to potentially cure autoimmune diseases, including multiple sclerosis and type I diabetes.",
      "Contrary to traditional vaccines that train the immune system to identify and combat viruses or bacteria, this new vaccine eliminates the immune system's recognition of a specific molecule, avoiding autoimmune reactions.",
      "The 'inverse vaccine' uses the liver's process to flag molecules from deteriorating cells with 'do not attack' labels. Preliminary lab tests show the vaccine effectively reversed multiple sclerosis-related autoimmune reactions, and safety trials have already commenced."
    ],
    "commentSummary": [
      "Researchers at the University of Chicago have developed an \"inverse vaccine\" aimed at treating autoimmune diseases by eliminating the immune system's memory of problematic molecules.",
      "This vaccine provides a more precise alternative to current immune suppression therapies, promising more effective results.",
      "There remain concerns regarding potential side effects as well as the broader understanding of autoimmune diseases. The role of the smallpox vaccination and the significance of maintaining immunity are also being debated."
    ],
    "points": 198,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1694810351
  },
  {
    "id": 37524158,
    "title": "California passes bill to make it easier to delete data from data brokers",
    "originLink": "https://www.latimes.com/politics/story/2023-09-14/california-bill-delete-online-personal-data",
    "originBody": "Sections LOG IN Show Search ADVERTISEMENT POLITICS California lawmakers pass bill to make it easier to delete online personal data California lawmakers say they want to make it easier for people to delete personal information held by data brokers. (Rick Bowmer / Associated Press) BY QUEENIE WONGSTAFF WRITER SEPT. 14, 2023 11:25 PM PT Facebook Twitter Show more sharing options Erasing your digital footprint could get a lot easier by 2026. California lawmakers on Thursday passed a bill known as the Delete Act that would allow consumers, with a single request, to have every data broker delete their personal information. Data brokers include a variety of businesses that gather and sell people’s personal information, such as their address, marital status and spending habits. Those companies include credit reporting agencies, people-search sites and data analytic firms that work with political campaigns. The Senate approved the legislation Thursday, a day after it was passed by the Assembly. The bill heads to the governor’s desk for consideration. ADVERTISEMENT Under Senate Bill 362, the California Privacy Protection Agency by January 2026 would create a way for consumers to ask that their records be erased through a single request. Roughly 500 data brokers are registered in California, so reaching out to every single broker can be time-consuming. Currently, it’s not always clear what information consumer data companies have or share. Businesses also might deny deletion requests or not respond. The passage of SB 362 builds upon a sweeping data privacy bill lawmakers passed in 2018 with the California Consumer Privacy Act, which gave consumers the right to ask businesses to delete their personal data but through an unwieldy process. Sen. Josh Becker (D-Menlo Park) said on the Senate floor that the bill would allow consumers to get sensitive information held by data brokers, including about reproductive health care and geolocation, erased. “This bill will help Californians actually exercise the right to delete their information from data brokers and protect our right to privacy,” Becker said. The California attorney general’s office sent a letter to Becker on Tuesday expressing support for the bill. In the letter, the office said the right to delete information from businesses is limited to data collected from the consumer. Data brokers might not always collect data directly from the consumer, creating a loophole in California’s privacy law. Businesses, including advertisers, lobbied aggressively against the legislation, saying it would “destroy California’s data-driven economy.” Businesses use data to serve personalized ads, and credit bureaus use personal information to verify people’s identities. Dan Smith, president and chief executive of the Consumer Data Industry Assn., said in a statement that the bill could have “unintended consequences.” The association represents credit bureaus and background-check companies. “The bill undermines consumer fraud protections, hurts small businesses’ ability to compete, and solidifies the big platforms’ data dominance,” Smith said. “It also empowers third parties to request to delete consumers’ data with no guardrails.” ADVERTISEMENT The bill’s supporters say consumers would have more control over their personal data online, which data brokers often collect without their consent or knowledge. They also point to scenarios in which people’s personal data could end up in the hands of scammers and other bad actors. Amid resistance from businesses, Becker made changes to the bill. Consumers could exclude certain data brokers from their deletion request and there are exemptions. Starting in August 2026, data brokers would be required to delete all personal information of the consumer at least once every 45 days. An earlier version of the bill gave data brokers 31 days to do this. They would also be barred from selling or sharing new personal data. If a data broker denies a deletion request because it can’t verify it, the request would be processed “as an opt-out of the sale or sharing of the consumer’s personal information.” POLITICSTECHNOLOGY AND THE INTERNETCALIFORNIA POLITICS Newsletter Get our Essential Politics newsletter The latest news, analysis and insights from our politics team. Enter email address SIGN ME UP You may occasionally receive promotional content from the Los Angeles Times. Queenie Wong Twitter Instagram Email Facebook Queenie Wong is a state politics reporter covering tech and entertainment policy for the Los Angeles Times. Previously, she wrote about social media companies for CNET and the Mercury News. She also covered politics and education for the Statesman Journal in Salem, Ore. Growing up in Southern California, she started reading The Times as a kid and took her first journalism class in middle school. She graduated from Washington and Lee University, where she studied journalism and studio art. MORE FROM THE LOS ANGELES TIMES CALIFORNIA Lawmakers approve measures to require independent redistricting for L.A. 16 minutes ago CALIFORNIA Studio City Neighborhood Council members resign after appointing sex offender to panel Sept. 15, 2023 CALIFORNIA California lawmakers approve key changes to landmark mental health law Sept. 15, 2023 CALIFORNIA California lawmakers pass reforms to doctor discipline cases, giving patients a voice Sept. 15, 2023 SUBSCRIBERS ARE READING FOOD FOR SUBSCRIBERS Welcome to L.A.’s golden era of pizza: Try 21 of the best slices at these pizzerias CALIFORNIA FOR SUBSCRIBERS $750,000 in overtime: How a group of LAUSD employees abused extra-pay practices MUSIC Maren Morris is getting the hell out of country music: ‘I’ve said everything I can say’ SPORTS NFL Week 2 picks: Can Rams upset 49ers? Chargers or Titans, who will remain winless? CALIFORNIA Can licensed tent villages ease California’s homelessness epidemic? This nonprofit thinks so ADVERTISEMENT LATEST POLITICS CALIFORNIA California lawmakers pass bill requiring schools to test for lead in drinking water 16 minutes ago WORLD & NATION Prosecutors in D.C. election case seek order barring Trump’s ‘inflammatory,’ ‘intimidating’ comments Sept. 15, 2023 POLITICS Conservatives’ interpretation of 2nd Amendment could help Hunter Biden beat criminal charges Sept. 15, 2023 POLITICS Texas Senate deliberates at Republican attorney general’s impeachment trial Sept. 15, 2023 CALIFORNIA Arthritis from scrubbing, asthma from chemicals. California housekeepers want in on OSHA protections Sept. 14, 2023 ADVERTISEMENT ADVERTISEMENT Subscribe for unlimited access Site Map Follow Us Twitter Instagram YouTube Facebook eNewspaper Coupons Find/Post Jobs Place an Ad Media Kit: Why the L. A. Times? Bestcovery Crossword Obituaries Recipes L.A. Times Compare L.A. Times Store Wine Club About/Contact For the Record L.A. Times Careers Manage Subscription Reprints and Permissions Site Map Copyright © 2023, Los Angeles TimesTerms of ServicePrivacy PolicyCA Notice of CollectionDo Not Sell or Share My Personal Information",
    "commentLink": "https://news.ycombinator.com/item?id=37524158",
    "commentBody": "California passes bill to make it easier to delete data from data brokersHacker NewspastloginCalifornia passes bill to make it easier to delete data from data brokers (latimes.com) 188 points by pseudolus 19 hours ago| hidepastfavorite70 comments neonate 16 hours agohttp:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230915153457&#x2F;https:&#x2F;&#x2F;www.latime...https:&#x2F;&#x2F;archive.ph&#x2F;1ebn0 qwerty456127 15 hours agoprevI want a bill which would let me just ban all data brokers forever. I don&#x27;t mind first parties to save some relevant data necessary for them to do their job, I can even understand 3rd parties like Google Analytics involved, but data brokers - I really don&#x27;t want any of them to have any data about me ever. reply willio58 12 hours agoparentYeah this is it. I want to have full knowledge over who has my data and for what purpose. I think we&#x27;ll get there eventually but it&#x27;ll take a while. reply qwerty456127 7 hours agorootparentHonestly, I don&#x27;t really care who as long as I can block them altogether. It was curious to find out how many weird companies do. Thanks to the GDPR we now can see the lists. Do I read them? Not anymore, I just make sure all the switches are off.It can be reasonable for a particular website I visit to save some data (not fingerprinting though) on who visits it. It can be reasonable for Google Analytics or Facebook or a similar system to process the data so they can target ads which make so many good small businesses possible nowadays. Sharing the data with other parties makes no sense I would ever want. reply pauldenton 12 hours agoparentprevDo you want to ban Manual Data Brokers. Private Investigators? reply ofjcihen 9 hours agorootparentSure. Is there a counter argument to this? reply TheCaptain4815 13 hours agoprevVery few things I&#x27;m jealous of in blue states, but their online privacy protection is up there. I&#x27;ve pondered why no party has made this a major priority, but the reality is the vast majority of Americans simply don&#x27;t care.I would love to tell these big tech companies I want all traces of myself removed from their search engines. I understand it gets a bit nuanced with first amendment n such (what about a news article of me committing \"x crime\"), but give citizens SOME protection. At least Europe tries and pushes back. reply fossuser 13 hours agoparentI&#x27;m in California - reality is even with this stuff it&#x27;s hard. I&#x27;d say maybe 20% companies you send CCPA request emails to don&#x27;t know what to do, have broken forms, etc. It does work probably 80% of the time though.I also use this which seems to work, but it&#x27;s hard to know how effective it is really: https:&#x2F;&#x2F;joindeleteme.com&#x2F; reply rabeener 7 hours agoparentprevThe first sentence of your comment is unnecessary to make your point and I’m curious why you chose to post it. reply TheCaptain4815 6 hours agorootparentThere’s a clear distinction, from my understanding, between red and blue states on this and it’s an interesting point to discuss. Why don’t the democrats go further? Is it because so many of the tech companies lean towards their ideology? Why don’t red states punish these mostly California tech companies by imposing strict privacy laws? Etc reply c420 13 hours agoparentprevI&#x27;d wager that lobbyist$ play a larger role than citizen apathy for the lack of legislation. reply TrendyCPU 18 hours agoprevThe legislation appears to be limited to data brokers. While this is nice and welcomed, this also means it doesn&#x27;t cover entities like Google or Facebook. reply theptip 14 hours agoparentCCPA already requires Google to delete your data on request. Though AFAIK CCPA didn&#x27;t produce any changes as Google already allowed you to do that.The same applies to any non-small business that you have a direct relationship with and provide your information to; CCPA requires that business to delete the info if you request it.Data brokers are a special case because they don&#x27;t get their information directly from you, instead they slurp up whatever public and private data they can scrape or buy, and then resell that to other companies. Given you don&#x27;t have a direct relationship with the data brokers, it&#x27;s hard to even figure out who has your information.Note, CCPA seems to have excluded the credit bureaus from designation as data brokers, even though those guys are responsible for leaking SSN and full personal information on the majority of US citizens.The US system of credit surveillance is pretty unusual (EU countries don&#x27;t do anywhere near that much stalking and they have functioning debt markets) so I&#x27;d love to learn what would actually break if people were allowed to opt out of that tracking. Presumably there are some government records you can&#x27;t opt out of like UCC filings and bankruptcy, and any potential creditor could just look up the primary sources themselves. reply CharlesW 17 hours agoparentprevI&#x27;m astounded that they aren&#x27;t considered data brokers in the eyes of U.S. law. reply 0xcde4c3db 17 hours agorootparentThe standard answer (at least for Google, not sure about Facebook) is that they&#x27;re not considered data brokers because they only sell ad placement based on the data, not the data itself. reply hef19898 17 hours agorootparentOne could make a case for splitting the data collection activities from the ad sales business as part of an anti trust case. Or pass regulations and laws to that effect. reply vineyardmike 14 hours agorootparentThat would be a pretty weird case to make. Typically anti trust is used to prevent a business from using market dominance in one market from entering another market. Considering they don’t participate in the data sales business it’d be a weird scenario to force them to start. I’d prefer we don’t force them to start.Gmail with ads seems way preferable to Gmail who sells your data to others. reply hef19898 14 hours agorootparentWell, I m affraid it is both, ads and data selling... reply chimeracoder 16 hours agorootparentprev> One could make a case for splitting the data collection activities from the ad sales business as part of an anti trust case. Or pass regulations and laws to that effect.That would be a net negative for privacy, because it would mean more parties having access to your data (without your consent or even knowledge). And given the state of security in ad-tech aside from Google, that means the chances of your data getting breached and leaked would increase exponentially. reply hedora 15 hours agorootparentprevGoogle helped craft these laws. This is classic regulatory capture.In particular, it is banning horizontally integrated surveillance capitalism (which requires the sale of data between the data gathering companies and the people using it), but not vertically integrated surveillance capitalism.In all likelihood, some companies in this ecosystem will be forced to sell at fire sales to conglomerates (like Google) simply to avoid having to comply with this law. Of course, this benefits organizations that are large enough to acquire the companies, and no one else.So, people with financial conflicts of interest are picking winners and losers, which is pretty much standard practice in US politics these days.I personally think this whole consumer tracking industry should be shut down. It should be illegal to gather the types of information that this bill regulates. reply paulddraper 14 hours agorootparentYou do understand that there is a real difference between selling ad placement and selling personal data, right?Maybe you hate both, but there is a meaningful difference. reply musicale 8 hours agorootparentExactly, for data sales, the advertiser gets the information up front.For ad placement, they only get it after you click on the ad, and it&#x27;s only linked to you personally by your IP address and browser fingerprinting, or more directly if you log in or buy something. replyadrr 15 hours agoparentprevThey don’t sell your data. reply noizejoy 14 hours agorootparent> They don’t sell your data.... except when they sell their domain registration business.And yes, I realize that there&#x27;s a (technical) difference between selling data and selling a business including its data assets.But then again, maybe a really big chunk of the value of that business is its customer data.For some business acquisitions special terminology like \"aqui-hiring\"[0] has evolved so it&#x27;s understood that not every sale of a business is of the same nature.And since the value of data has arguably become much higher than ever before, the distinction of selling data by itself and selling the entire business is becoming smaller as time goes on.[0]https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Acqui-hiring reply majormajor 14 hours agorootparentprevThey don&#x27;t sell your data TODAY.Who knows what they&#x27;d sell if their business declined for a while and there was a hostile takeover or they otherwise got desperate for new revenue streams.And then if you were paying attention you could make a new one of these requests... but maybe you&#x27;d miss it for a bit, and then it would be too late.The law should be based on what you collect instead of what you sell to better protect against this sort of thing. reply adrr 13 hours agorootparentThats not relevant of what they could do. This laws covers what you are doing and applies to entities selling your data. Big ad players don&#x27;t sell their data because that is their secret sauce in ad targeting.Companies selling your data are your bank(credit card purchases), mobile carriers(location), your DMV(photos, driving record, misc PII including address, dob etc), state&#x2F;county government(public records like marriage licenses). Its weird everyone bashes on google and FB for something they don&#x27;t even do. reply TrendyCPU 8 hours agorootparentprevThis misses the point. The issue is not whether or not Google&#x2F;Facebook should be classified as data brokers or not. The issue is that they are data collectors who invade our privacy.I want the means to tell companies \"Do not collect information on me.\" And I want that to be enforceable by law. reply azinman2 18 hours agoprevCurious about the issues surrounding credit scores and how much this gets into it. reply hedora 15 hours agoparentBack when interest rates were low, Rocket Mortgage incorrectly tanked my credit score. They refused to fix it, which means they were liable for whatever economic damage that causes.When I refinanced, I explained the situation to the other bank&#x27;s loan agent. They emailed their underwriting division, and the underwriters simply issued an override.Not sure if that works these days or not, but my point is that credit scores are complete bullshit. Hopefully most people will push the button, inadvertently opting out of credit reporting, and that corner of the industry will simply stop existing.Lenders already do more due diligence than the credit agencies do.If you default on a loan, there could be a central record (say, at the court house) of this, and lenders could consult that. That would fill in the remaining missing functionality of the score (and do so in a way that is transparently free of institutional racism, etc). reply adrr 15 hours agorootparentBesides defaults how would you get precision in a model without any other data? Payment history and total outstanding credit wouldn’t be there. You would have to trust the customer to provide you with all these details.Without precision in the risk model, cost to the consumer will go up to mitigate risk. Someone who has paid all their credit lines for 10 years but and has never defaulted has the same risk profile as a person who has frequently missed payments. reply JumpCrisscross 14 hours agorootparentprev> credit scores are complete bullshitYou can also juice it up or down by over a hundred points by accumulating and then rapidly paying down balances. reply galoisscobi 14 hours agorootparent> juice it up or downSo what here determines if the score goes up instead of down? I’m planning on getting a mortgage soon but wife’s credit score is in high 600s. If we can make it past, 720, we are told we’ll get a better rate. So I’m curious as to how to bump up the score. reply toast0 13 hours agorootparentThere&#x27;s lots of articles everywhere, but the basics are: make sure everything is paid on time; if you have any earned negative items, see if you can get them removed by asking nicely etc.Then there&#x27;s things like age of oldest account, average age of accounts, etc. You may be able to add her to your accounts to improve this factor, if your accounts are older than hers.Then balances. You get dinged for having a balance on too many accounts. I think you also get dinged for having zero balance everywhere. I think &#x27;ideal&#x27; is 3ish cards with balances (you can (and should) pay the whole balance every statement, reporting is usually done just after the statements). Highest ever balance should be less than credit available or you get dinged; ask for credit increases on cards where you ever went over the limit. Total balance shouldn&#x27;t be more than some % of total credit, I think 35%? You also get dinged for high % current balance on any one card. Again, you can add her on high limit, low usage cards to help her score. She&#x27;ll get more score points as a joint account holder than an authorizer card holder.You get dinged for recent (6 month?) credit inquiries, but inquiries are grouped, so if you apply for new credit, try to get it all done in a few days; mortgage inquiries have longer to be grouped.If you know when your creditors do reporting, you can adjust your payment dates to tweak things. You might make a payment to your credit card before the statement closes even in order to show a lower utilization % and that could move your score a lot depending on details. reply JumpCrisscross 10 hours agorootparentprev> I’m curious as to how to bump up the scoreFind a way to pay down revolving balances to zero.If you have cash sitting around, great. Otherwise borrow from a 401(k), friends or family, send non-reporting payments in late et cetera. Running balances rapidly to zero tends to cause a 50 to 100 point bump. After you’ve got approval, rebuild the balance and use that credit to repay the loan. In summary: transfer the debt from reporting to non-reporting sources.If you’re thinking longer term, find bullshit collateralised reporting loans and take them out. Securities-based loans, HELOCs. Low rate. Manufactured borrowing. But it’s a credit line paid back on time. The algorithm likes those. reply PascLeRasc 13 hours agorootparentprevThere are communities where you can rent someone else&#x27;s credit score as an authorized user. reply TrendyCPU 17 hours agoparentprevI would also be curious to learn how it impacts Early Warning Services which collects&#x2F;reports data on bank accounts and transactions.The Privacy, Security, & OSINT Show did a podcast on it.[0]0. https:&#x2F;&#x2F;inteltechniques.com&#x2F;blog&#x2F;2022&#x2F;04&#x2F;15&#x2F;the-privacy-secu... reply AJ007 15 hours agoparentprevI assume it would be similar to declaring bankruptcy reply hackncheese 14 hours agoprevThis reminds me of a company my friend used to work for, Ketch [1]. Basically described their service as automation that fulfills this exact requirement on customers databases. Sounds like they were ahead of the game.[1] https:&#x2F;&#x2F;www.ketch.com&#x2F; reply NelsonMinar 17 hours agoprevI&#x27;ve been grateful as a Californian for our regulations of online businesses. I regularly invoke our right-to-unsubscribe and the CCPA gives us something similar to the GDPR in various ways.To what extent do companies extend these rights to all Americans because it&#x27;s easier than building a California-specific version of a website or online product? reply nolroz 17 hours agoparentI would think a lot. Everyone would rather not have wait for legal to answer a new set of questions every time a state changes their laws. Easier to align on the strictest legislation and go from there, IMHO. reply gochi 16 hours agoparentprevLikely depends on the scale of the company. The likes of Google (I know they aren&#x27;t specifically on the line for this law anyways) will have more than enough resources to ensure you&#x27;re a California resident before allowing such. Hard to see others caring and just adhering your request as a non-California resident when it&#x27;s always a small margin of people that even take advantage of privacy respecting laws. reply Alupis 16 hours agorootparentExactly. The Parent comment strikes me as being very naïve.Right to Unsubscribe? Gmail and other email providers do this for you even if you are not a CA resident and even if the Marketer does not have a built-in Unsubscribe link. From a Marketer perspective, you cost money to send emails to, and if you are not going to open, they kind of don&#x27;t want you on the list anyway.CCPA == GDPR? Not even close. Majority of CA businesses do not reach the compliance threshold and therefore do not have to or will not comply with requests. Additionally, you have no way to validate if the request was actually carried out. The company&#x27;s \"best efforts\" to remove data from their systems is all that&#x27;s required at best - and a lot of data can be retained for valid business reasons.Lastly - despite what CA residents believe (and similar to EU residents with GDPR) - CA laws do not apply to the rest of the country simply because they are unenforceable except in the most egregious cases - and even then it would have to be a very large business anyway.> because it&#x27;s easier than building a California-specific version of a website or online productNobody is doing this in practice. At best, they use some GeoIP thing or if you are logged into an account (which means they have your data anyway). The law does not require them to validate the user anyway, so it&#x27;s all \"best effort\" again which usually means low effort.But hey, if it makes you feel warm and fuzzy believing these things - more power to you. reply callalex 16 hours agorootparentThe right to unsubscribe being discussed here has nothing to do with emails. It states that if you paid for a subscription online, you must be able to cancel it online within a few clicks as well. No “call us” or “send a registered letter during a full moon and low tide only” nonsense. It’s really great. reply NelsonMinar 14 hours agorootparentThere are numerous summaries of that right available here: https:&#x2F;&#x2F;www.google.com&#x2F;search?q=california+right+to+unsubscr... reply Alupis 16 hours agorootparentprev> No “call us” or “send a registered letter during a full moon and low tide only” nonsense. It’s really great.I am very skeptical even this is as great as some think. Outside CA, most companies can simply ignore these \"viral\" style laws with no consequences. reply r00fus 14 hours agorootparentAs another Californian, I&#x27;d love examples of where this is ignored, or where non-californians also benefit from these.I also gladly unsubscribe easily without frustration - just not sure if this is common in other states. reply Alupis 12 hours agorootparentHow about a concrete example of a big business that did not allow you to cancel online prior to this law?Netflix? Nope. Comcast? Nope. Google? Nope. Verizon? Nope. AT&T? Nope. Apple? Nope. PG&E? Nope...Where is this mythical renaissance of new online cancellations?Turns out - most big businesses did this already... oh, but now it&#x27;s the law but who&#x27;s enforcing? Lawyers who gain private settlements? That&#x27;s not enforcement, that&#x27;s a racket. reply rahimnathwani 10 hours agorootparentNew York Times reply callalex 16 hours agorootparentprevI can assure you as a Californian that this law is not ignored. They are taking payment from my credit card so they can’t claim ignorance of my California address. reply Alupis 16 hours agorootparentThere&#x27;s no citizen enforcement clause for most of these laws and therefore this mostly means nothing - and where there is it just turns into a money grab&#x2F;shakedown by bottom feeding lawyers (see existing FAL & P65 suits). Suits get settled, lawyers get paid, plaintiff gets a cut, no wrongdoing is admitted, and nothing changes.It&#x27;s not about claiming ignorance. It&#x27;s about not caring about CA viral laws and CA&#x27;s inability to effectively enforce them around the world.Much like how most companies laugh when some EU citizens tries to flex GDPR in the US... hilarious unless you&#x27;re Google...People lock-in on the intent and names of these things and believe they&#x27;ve \"won\" the privacy war. Just like the \"Inflation Reduction Act\" these laws do very little if anything for their namesake. reply callalex 16 hours agorootparentIt’s really odd to me that you are telling me that my lived experience is false and impossible. Every subscription I have made since this law passed, I have been able to cancel online. This includes newspapers, store club memberships, random podcasts and other online entertainment, educational software, and more.Sometimes the government really does work for the people. It is actually possible. reply Alupis 15 hours agorootparentOverwhelming majority of those things you listed could already be cancelled online.You can read the laws yourself. There&#x27;s not a lot of teeth for small businesses to comply.Go look at the state AG website for P65 complaints (they are all by law published). 99% are privately settled without wrongdoing (you can see this on AG website too), and some fee is paid to the plaintiff&#x27;s attorneys. Sometimes the math says it&#x27;s cheaper to comply, but often not. Small (and even big) businesses around the country freely ignore P65 despite the law having citizen enforcement. If you search on the AG website you will find many repeat offenders. P65 laws have been around for decades...There&#x27;s a difference between what people believe should happen and what actually happens. If you believe these laws have \"won\" the privacy war - you are mistaken. reply r00fus 14 hours agorootparentWhy are you conflating right-to-unsubscribe with P65? They are different laws with different enforcement mechanisms. Also consumers don&#x27;t find P65 useful whereas we see benefit from unsubscribing. reply Alupis 12 hours agorootparentThe point was we have these sort of consumer protection laws and nothing has changed. The enforcement mechanisms are weak and designed to make lawyers money more than actually gain compliance.Given the decades of P65 enforcement - and given the prevalence of \"harmful\" chemicals imported into this state every day, we have no reason to believe this unsubscribe law will be any different.Having this law makes people feel like something was accomplished, despite reality. reply r00fus 12 hours agorootparentThe unsubscribe law has been on the books for nearly 2 years. Most vendors have changed their processes. I have personally benefited.I expect nothing less for this law. Show me an example for a relevant law not the P65 BS. reply maaand 14 hours agoprevQuestion is what are the loop-holes available for the databrokers to ignore data deletion requests? reply kepler1 18 hours agoprevAre we talking actual data deletion, or just \"not serving it up when queried\" or attaching a \"do not use\" flag to the data but keeping it?Because if there&#x27;s one thing I&#x27;ve almost never seen, it&#x27;s data being deleted from a db. reply striking 18 hours agoparentFrom the bill:> The bill would, beginning January 1, 2028, and every 3 years thereafter, require a data broker to undergo an audit by an independent third party to determine compliance with these provisions and would require the data broker to submit an audit report to the agency upon the agency’s written request, as specified.https:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;billTextClient.xhtm... reply d3w4s9 18 hours agorootparentI don&#x27;t think that section answers the question. reply kepler1 18 hours agorootparentThanks, that spurred me to read about it given the link above.> \"This bill would require the agency to establish, by January 1, 2026, an accessible deletion mechanism that, among other things, allows a consumer, through a single verifiable consumer request, to request that every data broker that maintains any personal information delete any personal information related to that consumer held by the data broker or associated service provider or contractor. The bill would specify requirements for this accessible deletion mechanism, and would, beginning August 1, 2026, require a data broker to access the mechanism at least once every 45 days and, among other things, process all deletion requests, except as specified. Beginning July August 1, 2026, after a consumer has submitted a deletion request and a data broker has deleted the consumer’s data pursuant to the bill’s provisions, the bill would require the data broker to delete all personal information of the consumer at least once every 45 days, as specified, and would prohibit the data broker from selling or sharing new personal information of the consumer, as specified....> \"This bill would provide that a data broker that fails to comply with the requirements pertaining to the accessible deletion mechanism described above is liable for civil penalties, administrative fines, fees, and costs, as specified, and would raise the amount of the existing civil penalty provisions described above....\"I guess it all comes down to the implementation level how specific and \"actually deleting\" they will be. And whether the new agency (ugh) charged with enforcing this will actually have teeth in the details.And I don&#x27;t know why such a long 45 day period is required. For reasons we&#x27;re all too familiar with, people are quite able to gather data within seconds, but somehow need 45 days to delete it? reply addaon 16 hours agorootparentDeleting data from backups (or, more often, aging out backups and deleting them wholesale) is usually a batch process. You really don&#x27;t want to have to do online modification of backups... they&#x27;re not really backups at that point. 45 days doesn&#x27;t seem unreasonable. reply callalex 16 hours agorootparentIf it’s so much work to handle the data responsibly, maybe it shouldn’t be collected in the first place. reply kepler1 12 hours agorootparentprevWell... doesn&#x27;t that circumvent the point of backups? Backups in my mind are supposed to be like read-only, can never be modified so that the system that was corrupted can&#x27;t do anything harmful to the safe previous checkpoint.I guess it has to have some method of what you mention then. If someone wants their data deleted, yes, what about the backups? replyyieldcrv 18 hours agoprev [–] or else what? reply striking 18 hours agoparentFrom the bill:> This bill would provide that a data broker that fails to comply with the requirements pertaining to the accessible deletion mechanism described above is liable for civil penalties, administrative fines, fees, and costs, as specified, and would raise the amount of the existing civil penalty provisions described above. The bill would require that moneys collected or received by the agency and the Department of Justice under these provisions be deposited in the Data Brokers’ Registry Fund, which the bill would require to be administered by the agency, instead of the Consumer Privacy Fund and would expand the specified uses of moneys in the Data Brokers’ Registry Fund to include the costs incurred by the state courts and the agency in connection with enforcing these provisions and the costs of establishing, maintaining, and providing access to the accessible deletion mechanism described above.https:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;billTextClient.xhtm... reply JumpCrisscross 14 hours agorootparentIs there a route for private action? As in, could my parents sue a data broker for not complying? Or is this only enforced by California? reply coding123 18 hours agoparentprev [–] Hopefully we get to sue them out of existence this time reply jhart99 18 hours agorootparent [–] Doesn&#x27;t look like it will be a private action. We will still need to get the State Attorney General to initiate it which will mean nothing will happen. reply smcin 11 hours agorootparent [–] DC Attorney General Karl Racine has been the most impressive on data privacy. More than CA, WA, NY, MA.It probably keeps him pure that he represents a district that mainly feels the impact of the credit industry, and doesn&#x27;t proportionately have that many tech jobs (as CA). reply yieldcrv 8 hours agorootparent [–] Did they pass a specific data privacy law in the district? Or are they just strong arming under consumer protection statutes or somethingFlew under my radar reply Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The California legislature has passed the Delete Act, a bill aimed at simplifying the process of deleting personal information from data brokers for consumers.",
      "The California Privacy Protection Agency would be tasked with creating a system for consumers to request the removal of their records from data brokers in a single request, increasing transparency and control over personal data.",
      "Some businesses and industry associations expressed opposition to the bill, citing potential unintended consequences and potential harm to small businesses. The bill is now pending approval from the governor."
    ],
    "commentSummary": [
      "California has passed a legislation focused on empowering individuals to easily erase their data from data brokers, although it exempts companies like Google and Facebook already obligated to delete data upon request.",
      "The main goal of the bill is to enhance personal data control and privacy protection, yet concerns have been raised regarding its effectiveness and the exemption of specific businesses.",
      "The discussion also introduces topics like data selling, credit scores, and existing regulations' effectiveness. The California Consumer Privacy Act (CCPA), its implications, potential loopholes and the complexity of data deletion are further explored. The bill mandates agencies to create a deletion mechanism and penalizes non-compliance."
    ],
    "points": 188,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1694790212
  },
  {
    "id": 37532355,
    "title": "How Instagram scaled to 14 million users with only 3 engineers",
    "originLink": "https://engineercodex.substack.com/p/how-instagram-scaled-to-14-million",
    "originBody": "The Engineer’s Codex Subscribe Sign in Discover more from The Engineer’s Codex Lessons from real-world software engineering and engineers. Over 1,000 subscribers Subscribe Continue reading Sign in How Instagram scaled to 14 million users with only 3 engineers Instagram's guiding principles and tech stack explained simply SEP 14, 2023 32 2 Share Instagram scaled from 0 to 14 million users in just over a year, from October 2010 to December 2011. They did this with only 3 engineers. They did this by following 3 key principles and having a reliable tech stack. Instagram’s Guiding Principles Keep things very simple. Don’t re-invent the wheel. Use proven, solid technologies when possible. Subscribe The Stack Explained Simply Early Instagram’s infrastructure ran on AWS, using EC2 with Ubuntu Linux. For reference, EC2 is Amazon’s service that allows developers to rent virtual computers. To make things easy, and since I like thinking about the user from an engineer’s perspective, let’s go through the life of a user session. (Marked with Session:) Frontend Session: A user opens the Instagram app. Instagram initially launched as an iOS app in 2010. Since Swift was released in 2014, we can assume that Instagram was written using Objective-C and a combination of other things like UIKit. Load Balancing Session: After opening the app, a request to grab the main feed photos is sent to the backend, where it hits Instagram’s load balancer. Instagram used Amazon’s Elastic Load Balancer. They had 3 NGINX instances that were swapped in and out depending on if they were healthy. Each request hit the load balancer first before being routed to the actual application server. Backend Session: The load balancer sends the request to the application server, which holds the logic to process the request correctly. Instagram’s application server used Django and it was written in Python, with Gunicorn as their WSGI server. As a refresher, a WSGI (Web Server Gateway Interface) forwards requests from a web server to a web application. Instagram use Fabric to run commands in parallel on many instances at once. This allows to deploy code in just seconds. These lived on over 25 Amazon High-CPU Extra-Large machines. Since the server itself is stateless, when they needed to handle more requests, they could add more machines. Subscribe General Data Storage Session: The application server sees that the request needs data for the main feed. For this, let’s say it needs: latest relevant photo IDs the actual photos that match those photo IDs user data for those photos. Database: Postgres Session: The application server grabs the latest relevant photo IDs from Postgres. The application server would pull data from PostgreSQL, which stored most of Instagram’s data, such as users and photo metadata. The connections between Postgres and Django were pooled using Pgbouncer. Instagram sharded their data because of the volume they were receiving (over 25 photos and 90 likes a second). They used code to map several thousand ‘logical’ shards to a few physical shards. An interesting challenge that Instagram faced and solved is generating IDs that could be sorted by time. Their resulting sortable-by-time IDs looked like this: 41 bits for time in milliseconds (gives us 41 years of IDs with a custom epoch) 13 bits that represent the logical shard ID 10 bits that represent an auto-incrementing sequence, modulus 1024. This means we can generate 1024 IDs, per shard, per millisecond (You can read more here.) Thanks to the sortable-by-time IDs in Postgres, the application server has successfully received the latest relevant photo IDs. Photo Storage: S3 and Cloudfront Session: The application server then gets the actual photos that match those photo IDs with fast CDN links so that they load fast for the user. Several terabytes of photos were stored in Amazon S3. These photos were served to users quickly using Amazon CloudFront. Caching: Redis and Memcached Session: To get the user data from Postgres, the application server (Django) matches photo IDs to user IDs using Redis. Instagram used Redis to store a mapping of about 300 million photos to the user ID that created them, in order to know which shard to query when getting photos for the main feed, activity feed, etc. All of Redis was stored in-memory to decrease latency and it was sharded across multiple machines. With some clever hashing, Instagram was able to store 300 million key mappings in less than 5 GB. This photoID to user ID key-value mapping was needed in order to know which Postgres shard to query. Session: Thanks to efficient caching using Memcached, getting user data from Postgres was fast since the response was recently cached. For general caching, Instagram used Memcached. They had 6 Memcached instances at the time. Memcached is relatively simple to layer over Django. Interesting fact: 2 years later, in 2013, Facebook released a landmark paper on how they scaled Memcached to help them handle billions of requests per second. Session: The user now sees the home feed, populated with the latest pictures from people he is following. Master-Replica Setup Both Postgres and Redis ran in a master-replica setup and used Amazon EBS (Elastic Block Store) snapshotting to take frequent backups of the systems. Subscribe Push Notifications and Async Tasks Session: Now, let’s say the user closes the app, but then gets a push notification that a friend posted a photo. This push notification was sent using pyapns, along with the billion+ other push notifications Instagram had sent out already. Pyapns is an open-source, universal Apple Push Notification Service (APNS) provider. Session: The user really liked this photo! So he decided to share it on Twitter. On the backend, the task is pushed into Gearman, a task queue which farmed out work to better-suited machines. Instagram had ~200 Python workers consuming the Gearman task queue. Gearman was used for multiple asynchronous tasks, like pushing out activities (like a new photo posted) to all of a user’s followers (this is called fanout). Monitoring Session: Uh oh! The Instagram app crashed because something erred on the server and sent an erroneous response. The three Instagram engineers get alerted instantly. Instagram used Sentry, an open-source Django app, to monitor Python errors in real-time. Munin was used to graph system-wide metrics and alert anomalies. Instagram had a bunch of custom Munin plugins to track application-level metrics, like photos posted per second. Pingdom was used for external service monitoring and PagerDuty was used for handling incidents and notifications. Final Architecture Overview Subscribe to the Engineer’s Codex for more visual architecture breakdowns! Like early Instagram, I keep things very simple. Subscribe Sources: What Powers Instagram: Hundreds of Instances, Dozens of Technologies Storing hundreds of millions of simple key-value pairs in Redis Sharding IDs at Instagram 32 Likes · 3 Restacks 32 2 Share Previous 2 Comments Jordan Cutler Writes High Growth Engineer Sep 14 Liked by Leonardo Creed This was a really nice read that helps really solidify some system design theoretical concepts seeing how it's applied in the real-world. I also appreciated the diagram at the end too to help piece it all together. Thanks for the article! LIKE (2) REPLY SHARE 1 reply by Leonardo Creed 1 more comment... Top New Community 7 simple habits of the top 1% of engineers How elite coders outperform the rest SEP 10 77 4 Ready for more? Subscribe © 2023 Engineer Codex Privacy ∙ Terms ∙ Collection notice Start Writing Get the app Substack is the home for great writing",
    "commentLink": "https://news.ycombinator.com/item?id=37532355",
    "commentBody": "How Instagram scaled to 14 million users with only 3 engineersHacker NewspastloginHow Instagram scaled to 14 million users with only 3 engineers (engineercodex.substack.com) 187 points by thunderbong 4 hours ago| hidepastfavorite110 comments imadj 2 hours ago> we can assume that Instagram was written using Objective-C and a combination of other things like UIKit.How can they know the internal infrastructure but have to assume the app language?Edit: So the entire piece is taken almost verbatim as-is from a couple old articles on instagram engineering blog.It might as well just redirect to: https:&#x2F;&#x2F;instagram-engineering.com&#x2F;what-powers-instagram-hund...This is against the guidelines:> Please submit the original source. If a post reports on something found on another site, submit the latter. reply rmetzler 2 hours agoparentInstagram engineers themself wrote a bit about their backend infrastructure. One of the more important topics was how they shard the data [0] and this is also linked to in this blog post.[0]: https:&#x2F;&#x2F;instagram-engineering.com&#x2F;sharding-ids-at-instagram-... reply Sparkyte 2 hours agorootparentIf it wasn&#x27;t just an image site the potential for hotspotting would be insane!Size isn&#x27;t a bad thing anymore since price has dropped exponentially since the inception of Instagram.I am positive they would use another modern technology today if it was present in the past.Fantastic read though. reply coldtea 1 hour agoparentprevIt IS an original source. It&#x27;s not just a repost or a report on another older article. It&#x27;s a reworking of those articles. reply danparsonson 2 hours agoparentprevThey had a different person&#x2F;team working on the front end and&#x2F;or they don&#x27;t remember? reply imadj 2 hours agorootparentThe article is just recycling material written by others. Taken almost verbatim from a couple Instagram engineering articles.which is against the rules: > Please submit the original source. If a post reports on something found on another site, submit the latter. reply coldtea 1 hour agorootparentEnough with the \"rules\" just because you don&#x27;t find it novel enough.The author is on HN and says \"Just my own brain reading through old talks and articles from Instagram engineering and Excalidraw for the diagrams. I did my best to put together all the info I learned from them into a comprehensive and simple manner\".You can take it with them. reply blackoil 1 hour agorootparentprevIf it was compiled from more than 1 article, it becomes an original article. The post should have only novel idea and info. is an arbitrary requirement and not the meaning of that rule.Though I would add if author were taking anything verbatim, that should be highlighted as a quote with the original source. (edit: reading more, author has already done that.) reply surfingdino 2 hours agoparentprevLooks like someone may have been using ChatGPT to produce that post. reply engineercodex 2 hours agorootparentAuthor here. No ChatGPT was used.Just my own brain reading through old talks and articles from Instagram engineering and Excalidraw for the diagrams.I did my best to put together all the info I learned from them into a comprehensive and simple manner. reply teakie 1 hour agorootparentah nostaglia. did they implement e2ee? cause the alternativ is to use mastodon I&#x27;d guess, which should have e2ee for PMs (right now they are just toots, moderated,in plaintext) maindevs sag its to complicated. We know better. it&#x27;s satureday morning. some are at a con other still sleep, i hope this gains traction the next few hours. the concept is easy. a workaround could would be cosmetical, but we need poc, push it onto one instance spread the word, enough pressure to copy paste that tested code. everyone wellcome to contribute, just ping me first so we work a little more efficient reply Octabrain 1 hour agoprevI find the simplicity of the stack brilliant. It makes me to think now, to which extent, the industry nowadays simply suffers from a mix of lack of knowledge, CV driving design and big players in the game trying to sell you overkilling solutions and approaches for their own economical benefit. Have we perhaps, felt into a big enchant and, at the end of the day, 99% of companies out there could just use a classic LAMPish kinda stack managed by 3 or 4 dudes? reply ahoka 20 minutes agoparentI just imagined trying to sell this architecture for a new product in an imaginary company, an amalgamation of every place I have ever worked:You have to change to Azure, because we are Microsoft partners and we have free credit.The credit is not too much though and we have to spend the same money on useless trainings so we keep being partners.4 core and 8GB should be plenty for your dev VMs, that’s the largest we can run on free MSDN accounts.Have you tried the managed API gateway? Why not?You should use managed caching on the edge.We already have an on-prem SQL Server, use that to cut costs. Yeah it runs on Vmware and network storage.Do we have support contracts for Nginx, Ubuntu? We have RHEL licenses, so you should use that.Can we run this in our OpenShift cluster instead? To cut license cost it will be co-deployed with the developer envs of other product, but just set resource limits. Yeah, we only have NFS storage.S3? Just use a PVC, it’s the same.We decided on Datadog for unrelated product A and B, so you must use that. The license is expensive, so only log errors please.We use Kafka for the workqueue, but limited to 2 cpu cores to make it cheap, so please make sure not to send too many notifications.Python is not for production things, we will assign an offshore team to rewrite it in Spring Boot. We target Java 11, because our productivity increasing libraries are not yet updated.Minor change needed for deploy: every service should build it’s own RPM package in it’s dedicated git repository.You need to submit the architecture diagrams and service documents next week, thanks for the meeting.What did I miss? reply stock_toaster 4 minutes agorootparent> What did I miss?The security team is getting weird reports from their internal nmap scanner that is constantly scanning this network. No, they don&#x27;t know which of their vendor automated scanners are doing it, no they can&#x27;t turn it off, so please add code to specifically ignore those scans.Our VMware cluster has plenty of compute left, but it is out of storage space because there are hundreds of VMs from other teams and nobody knows what is still being used, so you can&#x27;t get any more dev instances until we get more storage added to the NAS (in the next quarter&#x27;s budget).Any unrelated director somehow ended up seeing this diagram and had some \"suggestions\". Please implement these changes asap. reply lijok 16 minutes agoparentprevGive me a cpu, some memory and an S3 bucket, and I&#x27;ll build you (almost) anything you want. reply tiffanyh 3 minutes agoprevSource: https:&#x2F;&#x2F;instagram-engineering.com&#x2F;what-powers-instagram-hund... reply kristopolous 2 hours agoprev\"When you choose the right people you&#x27;ll need only a few. When you don&#x27;t, you&#x27;ll need them all\" reply Sparkyte 2 hours agoparentI think this idea hurts the industry. Don&#x27;t get me wrong. I think it is important to hire the right people, but if you don&#x27;t hire enough people this 3 man job is 80-100 hours a week per for months to years.Look how X has diminished in quality as Elon started slashing team sizes.Then when you design more features, security and other various systems to serve the customers it will creep in complexity. You can not escape that no matter what you do. reply teakie 1 minute agorootparentthis is what work is.efficiency shrinks by more team also you get other people. if you are working on something you stay alive until it&#x27;s done.≠ a job but job can be to work reply EspressoGPT 2 hours agorootparentprev> Look how X has diminished in quality as Elon started slashing team sizes.He had a point there though: He said that there seem to be \"3 managers &#x27;managing&#x27; one engineer\", and I believe this is a common problem in the industry. VC-funded startups are terribly overstaffed and over-inflated. reply mk89 45 minutes agorootparentWhen you own a company and fire someone to cut costs nobody is gonna say anything, of course. It&#x27;s the sad reality.When you cut the company to 1&#x2F;3 and keep foreigners because of their visa status, nobody is gonna say anything of course, but that says a lot about you!I do not believe that half the company was just \"overstaff\". I have been in situations where 1 manager had 1 reporter&#x2F;reported, but they were single cases - it can&#x27;t be spread to the entire company and nobody does anything. reply rhuru 1 hour agorootparentprevMusk&#x27;s actions have certainly damaged Twitter and its engineering. When you set the house on fire of course some termites will get killed but then you might also kill some babies and the family dog.A lot of tech companies have bloat in the form of AI ethics people, DEI people and so on. They need to go. But Musk probably hurt twitter a lot in short term by firing a lot of engineers and making it a place that made people unhappy. reply csomar 1 hour agorootparent> AI ethics peopleThese do actually have a proper job. They do ethics laundering for the tech companies and are very valuable. reply mk89 58 minutes agorootparentprevHe is squeezing everything as much as he can.Introduced failing ideas that made him ridiculous world wide, ... to finally hire a CEO.And now he is using the platform to influence elections and events - free for all. Sure. reply thebears5454 1 hour agorootparentprevThere is not a single VC that is three managers to one engineer reply GaelFG 30 minutes agorootparent\"I won&#x27;t give names but trust me\", VC funded tech companies with 3-10 bros &#x27;who have or not a vague technical background but more see themselves as high level thinkers&#x27; between founders and their first hires for &#x27;key strategic roles&#x27; followed by an engineer and one to three interns to fill production role are a common reality, at least on startup scenes I attended. In the startup process &#x27;marketing&#x27; is also glorified (not that i disagree it&#x27;s importance) so once you have one or two guy who can make demos, hiring marketing people is often the next priority. reply dijit 38 minutes agorootparentprevTeam Lead, Scrum Master and Director.Not to mention HR managers.I have seen situations where there are 10% engineers to 50% \"assorted management\" in tech companies. (the remaining 40% being a mix of sales and support staff such as office management). reply frenchman99 2 hours agorootparentprevI have noticed absolutely no difference with Twitter&#x2F;X. I am a casual user, sure, but for me it seems to work well. reply andrewinardeer 2 hours agorootparentThere was a bit of downtime and some bugs did make it into their prod env after the restructure. These bugs were rectified fairly quickly too.I generally agree with you on your comment. I am a casual user of X these days and the site seems to be humming along without any user facing engineering issues.With his products such as Tesla, X and Starlink touching millions of people daily Elon is an easy to reach punching bag.Even if he is somehow instrumental in solving the massive feat of putting humans safely on Mars there will always be people on the side lines having shots at him. reply majani 1 hour agorootparentprevFunny enough, where I&#x27;ve noticed the most bugs is in the ad buying process. They want an active account (which many corporate accounts wouldn&#x27;t qualify as), then they want you to be a Twitter Blue member(which requires a verified phone number), then my company&#x27;s phone number wasn&#x27;t accepted. I gave up after that reply rpastuszak 2 hours agorootparentprevAnecdata for sure, but I use Twitter every day and features such as video upload just stopped working for me (failing silently), not to mention the site crashing or becoming completely unresponsive every week or so. reply iLoveOncall 1 hour agorootparentprevI&#x27;m not even a casual user, I just go there when a friend sends me a funny tweet or an article point to one, and even I have noticed major bugs like comments not loading or other functionalities not working. reply NavinF 53 minutes agorootparentThat&#x27;s not a bug. If you&#x27;re not logged in or your account looks like a bot, you can&#x27;t see comments reply kristopolous 57 minutes agorootparentprev> You can not escape that no matter what you do.The point is you can.Choosing not to do is probably more important than being able to do.Organizations are reflected in the products they create. We shape our teams and thereafter they shape us.This doesn&#x27;t mean brain teasers or other arbitrary metrics with standard bell curve distribution so you can pick the statistical outliers and claim you&#x27;ve done this. That&#x27;s totally completely horrendously wrong because that&#x27;s not what you&#x27;re fitting.Those are filters that produce stochastic results with merely the statistical properties of these rules of thumb.If you&#x27;re looking for a programmer, here&#x27;s a better test: think if some famous programmer walked in and sat down to do your process. Could they pass? If the answer is \"dice roll\", meaning you&#x27;d say, turn down Rob Pike or Larry Wall, then you&#x27;re doing it wrong reply gumballindie 1 hour agorootparentprev> 3 man job is 80-100 hours a week per for months to years.Is it though? Small, lean, teams have fewer processes, less distractions, better communication, and more flexibility in what they can do. I&#x27;ve been in such teams and built such scalable systems and there was nothing 80-100 hours about it. It turned worse once the company was acquired and management and \"specilised\" workers were brought in. reply ben_w 35 minutes agorootparentprev> Look how X has diminished in quality as Elon started slashing team sizes.True but different: even ignoring how many of them were customer support and moderation, once the tech stack gets complex, you can&#x27;t just snap your fingers and act like it&#x27;s a simpler stack.Even if a fresh 3-good-graduates team can reach feature parity with your now-1000-person team, when they&#x27;ve had 6 months from `git init` and you&#x27;ve been at it since the new team were in Kindergarten, the only way for the big corp to do the same is to buy out the new team and then leave them alone. reply coldtea 1 hour agorootparentprev>Look how X has diminished in qualityIdeologically or from a service perspective? I don&#x27;t see any noticable drop in the latter. Some disruption is expected as huge parts of the team is fired&#x2F;leaves, but I see it going on in business as usual otherwise. reply Aeolun 2 hours agorootparentprevHaving only 3 people forces you to be very judicious about what you do. For most companies that’s a good thing. reply pcchristie 1 hour agorootparentprev> Look how X has diminished in quality as Elon started slashing team sizes.Has it? I&#x27;ve had the exact same experience. reply weird-eye-issue 2 hours agorootparentprev> Look how X has diminished in quality as Elon started slashing team sizes.what happened? reply Sparkyte 2 hours agorootparentBack when he acquired twitter he fire 2&#x2F;3rds the company. reply falcor84 2 hours agorootparentI think the interesting \"what happened\" is about the consequences - has there been some objective drop in uptime&#x2F;performance&#x2F;errors or some other technical metric? reply Sparkyte 2 hours agorootparentYes actually.And one massive security breach. reply andrewinardeer 2 hours agorootparentEven before he acquired the company they had security issues. Someone even managed to tweet from his account with a BTC scam. reply leereeves 2 hours agorootparentprevCould you be more specific? reply Sparkyte 2 hours agorootparentprev@falcor84We hit maximum reply lengths but yes there has been. And a massive security breach. reply wfme 2 hours agorootparentWhich security breach are you referring to? I&#x27;m not aware of any major ones that have happened since the acquisition, but this one seems to be the one people point to even though it happened prior. https:&#x2F;&#x2F;privacy.twitter.com&#x2F;en&#x2F;blog&#x2F;2023&#x2F;update-about-an-all... reply drno123 2 hours agorootparentprevNo, what is the consequence, how has quality of Twitter diminished? As a “normal” user I can not observe any degradation of Twitter service. reply thebears5454 1 hour agorootparentVery famously he had Ron DeSantos on to announce his presidential campaign, but his website didn&#x27;t work at all. reply Sparkyte 2 hours agorootparentprevSure, but I feel like this was because of feature creep more than anything else.Most common thing people use it for is posting and reading. If you fake feeds as if they are real-time then the viewer will never know there was a system outage.I am almost positive there was a massive security breach too. reply blackoil 1 hour agorootparent> I am almost positive there was a massive security breach too.That&#x27;s a very serious allegation, as it would be illegal to not report it. Can you add some details? replythilog 2 hours agorootparentprevTwitter most likely hasn&#x27;t been able to retain the \"right\" people. reply yieldcrv 2 hours agorootparentOnly people that don&#x27;t want to get deported during a tech hiring slowdown reply Sparkyte 2 hours agorootparentprevThis is true. reply exitb 35 minutes agoparentprevAlso, the fastest way to get rich is to win the lottery. Doesn’t mean it’s a sound investment advice for everyone. reply quickthrower2 2 hours agoparentprevThe right idea too. reply ksec 54 minutes agoprevI wonder how far they could scale with modern technology with the same architecture and 3 engineers. Not only are Django, Postgres, Redis so much better now. The hardware per server is also at least 3-5 times faster. reply rich_sasha 2 hours agoprevStories like this kind of make sense to me. 3 people is very few but I guess they really knew what they are doing.Meanwhile, all these orgs with essentially a CRUD app, with 1,000s of engineers..? That I never understood. reply onurcel 1 hour agoparentThese CRUD apps need complex business rules, requiring expertise in the domain and making them configurable on the application level for customer while trying to keep the app not bloated.Scaling is not the only challenge engineers face, but somehow it&#x27;s the one that is mostly praised. reply throwaway290 32 minutes agorootparentThey also need to respond to customer requirements, which IG never needed to do while they had no actual customers. And as soon as fun was up and IG had actual customers (spoiler alert, advertisers) what a surprise 3 devs was not enough.They also need to quickly respond to downtime, because unlike IG if some of those CRUD apps go down in B2B world you are often losing customers actual money not just ad views reply lovich 2 hours agoparentprevNot engineer driven orgs _and_ their product people don’t know how to drive the product or set requirements, or engineer driven by the type of engineers who love to tinker without making any real progress business wise reply rapnie 30 minutes agoprevHere&#x27;s recent insiders experience on developing Meta&#x27;s Threads app on top of Instagram infra: https:&#x2F;&#x2F;newsletter.pragmaticengineer.com&#x2F;p&#x2F;building-metas-th...> In July of this year, Meta launched its latest mobile app, Threads, a microblogging service and new rival to X, formerly Twitter. In the first five days following its launch, the app achieved 100M downloads – a new record for the company by some margin. Meta’s previous record for new app installs in the first 5 days after launch was 1M.Built with a slightly larger team, considered an agile team: 3 product managers, 3 designers, about 60 engineers. reply djtango 18 minutes agoparentI tthink the reality of modern development, especially one plugged into the Meta ecosystem is that there is probably a tonne of integration work to be done.- monetization- finance- analytics- ad placement- ad bidding- android client- apple client- browser clientJust off the top of my head in 2 mins that&#x27;s a few of the extra concerns I can come up with...I remember meeting someone who was responsible for writing an ultra performant JS WhatsApp client for firefox OS. When you have 2B users, the long tail is long...OG Instagram was pre-monetisation. So yeah maybe a simple image hosting service needs fewer engineers but maybe a profitable business that can monetise the service needs more... reply 0wis 2 hours agoprevInteresting I wonder if its seems easy because it’s explained simply or if it really is simple to put in place. I want to make a clone now, just to try. At least for this inspiration, this article was well worth the read. Thanks ! reply jalk 2 hours agoparentIt looks fairly standard tbh. A lot of the heavy lifting is done by AWS. They likely didn’t start out with this exact architecture in mind, but adapted along the way. I.e. something like: The timestamped key format improved poor performance. Redis was introduced when Postgres was getting swamped. Didn’t replace the existing memcached with Redis as it worked as it should. And ofc there surely were a ton of oddities&#x2F; issues with their AWS setup that they spent time fixing. The nginx description is a bit vague, but could be some “hack” to work around some ELB scaling behavior that wasn’t to their liking. reply adamauckland 36 minutes agoparentprevIt&#x27;s pretty simple if your goal is using boring, stable technologies. Django&#x2F;Postgres&#x2F;Memcached&#x2F;Redis&#x2F;Nginx are all really stable.I&#x27;ve built quite a few projects using almost exactly the same stack over the last 15 years. Almost all are still running, those that aren&#x27;t are for business reasons not technical.The problem is, they&#x27;re not exciting The Next Thing real-time javascript somethings, so a lot of devs won&#x27;t want to use it. reply engineercodex 1 hour agoparentprevAuthor here. Comments like this make my day, so thank you!I’m trying to find old software engineering gems and explain them as simply as possible, so I’m glad you found it simple to understand.Also, it’s definitely possible to make a clone, but the hard part is getting the users :) reply 0xFF0123 37 minutes agorootparentDo you have a link to Fabric? My Google Fu is failing me, looks like it might be dead? reply thruflo 11 minutes agorootparenthttps:&#x2F;&#x2F;www.fabfile.org reply 0wis 1 hour agorootparentprevOf course, I do not envision getting users. Only for fun and training - I think having examples of simple solutions to seemingly hard problems in mind makes it easier to come up with one in the future. reply rmetzler 2 hours agoparentprevInstagram engineers found some remarkable simple solutions to some hard problems. It&#x27;s not easy to come up with these solutions. Designing the IDs for example is no small feat, but since this is now common knowledge it&#x27;s probably not too hard to build a similar system.To get traction from users is the real challenge. reply koonsolo 1 hour agorootparent> To get traction from users is the real challengeUnfortunately yes. Scaling is a problem I would love to have :D. reply BoorishBears 1 hour agorootparentprevWhich makes things like Vercel so depressing to me.You&#x27;ve got a company paying off influential people in a space where people are looking for guidance, convincing them that they too have hard problems that cannot settle for simple solutions.Selling the narrative that developers need to be all in on the most irrelevant aspects of building a product, and ignoring the fact that if you instead focus on building simple, easy to maintain software, the fact your LCP isn&#x27;t hyper optimized by some newly invented mental model for app development won&#x27;t matter: Google (or any search engine for that matter) will not ignore the fact people just actually want your content.They do not care how great your web core vitals are if you waste a bunch of time bending over for some irrelevant bullshit problem instead of talking to users and iterating. reply prakhar897 2 hours agoprevI&#x27;m more interested in how they got 14 million users with only 4-5 people. what marketing tactics did they use? I assume those should be milked to death by now. reply eviks 39 minutes agoparentluck is being milked to death, but it only favors the living reply dboreham 1 hour agoparentprevLuck. reply luismedel 2 hours agoprevI have chills thinking about the oncall schedule of these 3 colleagues... reply TeMPOraL 2 hours agoparentWhat on-call? Was there even anything needing 24h support back then? reply yokoprime 4 minutes agorootparentBeauty of a free app with no advertisers is there&#x27;s no SLA&#x27;s. reply tiffanyh 30 minutes agoprevThreadsI find it interesting that Meta choice largely this same tech stack for their newly created Threads service. reply Sparkyte 2 hours agoprev14 million doing not so complex things is an easy achievement. When you get into a lot of microservices providing tons of features your teams will balloon. reply Scarblac 2 hours agoparentThat&#x27;s why it&#x27;s important to keep the number of devs low, it makes it less likely that one starts talking about microservices. reply sleiben 2 hours agorootparentWe use the microservices architecture as a single team and don’t have any issues with this for many years. The key is to have a monorepo and stay consistent by following strict coding guidelines.In my opinion it makes the backend way more resilient than a monolith.Don’t kill me for this opinion please ;) reply BoorishBears 1 hour agorootparentHow does it make the backend more resilient than a monolith? Do you not realize you have multiple instances of a monolith or something? reply ahoka 7 minutes agorootparentBad input crashes app, monolith fails over, other instance crashes. Full outage. Assuming proper vertical separation, this risk can be reduced by microservices. reply pestaa 2 hours agorootparentprevIt&#x27;s more important to keep the number of features low. Good devs talk about aligning the architecture to requirements, and that sometimes includes microservices. reply Sparkyte 2 hours agorootparentThis is true. I completely agree with the minimized scope. However a dev needs to be careful to not let their service just sit unmaintained. New teams will always need engineers to maintain and improve. reply Sparkyte 2 hours agorootparentprevYou talk as if monolithic apps are vastly superior. To be forward it depends entirely on the purpose and life of the application. It is about whatever shoe fits the design. reply Aeolun 2 hours agorootparentSure. It’s just that 99% of applications work fine (or better) as a monolithic design. reply Sparkyte 2 hours agorootparentDepends on the purpose of the application though. Monolithic is a good architecture when you have a few purposeful features and functions.But when your design relies on many services to provide a wide variety of features you need to break out this design to allow teams to operate independently.Mini monoliths are more popular today than traditional monoliths of the old. reply qaq 1 hour agorootparentYou can split things up you don&#x27;t have to though. Teams operating independently is fairly orthogonal to this. reply wiseowise 1 hour agorootparentprevAnd you of course have data to prove it, right? reply rjh29 1 hour agorootparentExperience. reply devjab 1 hour agorootparentprevIn two decades of development I&#x27;ve never once seen a monolithic architecture that with some form of shared database not be terrible for the business it powered. I certainly understand why it&#x27;s very common, it&#x27;s what&#x27;s still being taught to most CS students in my country after all, and, it&#x27;s frankly a lot easier to implement. The result, however, is always the same. It ends up being a mess where nobody can do anything because the data structures are so intertwined (and undocumented) that nobody knows how it&#x27;s actually used. What happens is that monoliths become magnets for business logic, and then you bottleneck every change into requireing a select few members of your organisation. As time goes by, you end up with a giant turd that stagnates and directly hurts your business. Not by intention, but because that&#x27;s exactly what happens when you make things complicated.It&#x27;s important to keep in mind that this isn&#x27;t a technical problem. It&#x27;s an organisational problem. In fact, there is no technical reason why monoliths would be an anti-pattern, which is likely why they are still being taught as though they weren&#x27;t at many universities where professors still naively think that the MBA&#x27;s aren&#x27;t going to cost-cut IT at every opportunity even though their entire organisation is made up of employees who spend 100% of their working time on IT devices of some form. Similarily, Microservices, aren&#x27;t really the \"technical\" response to this. It&#x27;s how IT and digitalisation had to evolve to keep up with business demands and better generate value. The simpler and more decoupled you keep things, the better you&#x27;ll be able to respond to business needs. Sure, there are a gazillion different ways to do Microservices wrong, and if you do it wrong, then you&#x27;ll likely be in the same mess that you would be with a monolith, only so much worse, because now you have 9 million tiny monoliths and shared databases.Luckily we still live in a world where everyone is somehow still OK with IT not working. We went to an appointment that isn&#x27;t relevant the other day, and they had a tablet where you could register your license plate to avoid getting a parking ticket. It didn&#x27;t work, so we talked with the receptionist who was like \"yeah, it does that all the time, don&#x27;t worry, if the systems are down then they can&#x27;t give out tickets\"... Fine for us, but think about that... It turned out the system was down in my entire city, which means that all those hundreds of employees who are out handing out tickets had nothing to do while their IT system was being fixed, hell, the entire company wasn&#x27;t generating income for my city while their IT was down, and this was a regular occurrence? What my point with this is, is that you can do things really wrong, and still be a \"successful\" company, it&#x27;s just that the companies who manage to generate value better (which is frankly always microservices of some form) tend to simply do better. But like I said. You can do \"microservices\" in a million different ways. Running two different django backends to handle different parts of Instagram could be considered having two microservices after all. The importance is how you deal with the needs of your organisaiton in a rapid fashion. reply nickserv 20 minutes agorootparentAgree with most everything you&#x27;ve said. Just want to point out that IT stuff not working properly is only grudgingly accepted when users are captive. Could be a government service (as in your example), corporate monopoly, or a work mandated application. If it doesn&#x27;t work properly, users are stuck with it no matter what.But for anything where there&#x27;s healthy competition, this completely changes. Errors, bugs, conceptual problems, etc absolutely will have an extremely negative impact.As an example I once worked for a company selling tickets online, but there were numerous bugs, and the system would often crash under load. Long story short, we lost many users to competitors, that company is no longer independent, and all that code is now legacy.Compare with the monopoly situation of Ticketmaster, they are far worse than this company ever was, and are quite successful, with a large user base. That hates them ;-) reply koonsolo 1 hour agoparentprevHonest question: what justifies microservices in the popular companies compared to instagram?Twitter: just sharing a bunch of text.Netflix: platform with static content, where sharing isn&#x27;t even possible.TikToķ: Instagram for video, so basically just bigger files.WhatsApp: they also pulled it off with a small team.If you talk about Roblox, now there&#x27;s a challenge! And they pulled it off with way less engineers than Twitter. reply the-smug-one 2 minutes agorootparentFor Twitter and TikTok, I bet that the reasons are B2B offerings and not their B2C offerings. reply qaq 2 hours agoparentprevWell it&#x27;s not like you have have to get into microservices reply IndySun 2 hours agoprevrelated&#x2F;mentioned - https:&#x2F;&#x2F;engineering.fb.com&#x2F;2013&#x2F;04&#x2F;15&#x2F;core-data&#x2F;scaling-memc... reply siva7 2 hours agoprevCan someone confirm this story who has inside knowledge? reply engineercodex 2 hours agoparentSources are linked at the bottom of the article! reply systemvoltage 2 hours agoprev [–] I presume this architecture would look very different today? With supabase, spanner, cloudflare, etc? When scaling, the database bit is the least clear to me. How do you create an \"isolated\" database per customer? reply kgeist 1 hour agoparent [–] I can&#x27;t find where it says it&#x27;s per customer. It says they have \"a few physical shards\". From what I understand, they had a few physical DB servers which stored their own subsets of data. When a request came in, the appropriate DB server was selected based on photo or user ID.P.S. Here&#x27;s more information: https:&#x2F;&#x2F;instagram-engineering.tumblr.com&#x2F;post&#x2F;10853187575&#x2F;sh... replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Instagram achieved significant growth, reaching 14 million users in a little over a year, with a small team of only three engineers.",
      "They accomplished this by adopting three guiding principles and a reliable tech stack, including technologies like AWS, Ubuntu Linux, EC2, NGINX, Django, Gunicorn, Postgres, S3, Redis, Memcached, pyapns, and Gearman.",
      "They also took advantage of monitoring tools like Sentry, Munin, Pingdom, and PagerDuty to ensure their infrastructure's effectiveness and reliability."
    ],
    "commentSummary": [
      "The article tackles Instagram's impressive feat of scaling to 14 million users with a small team of only three engineers, illustrating the potential efficiency of small team sizes in startups.",
      "It highlights Instagram's simple but effective architecture and discusses the use of microservices in application development, with reference to their benefits and challenges.",
      "The text also delves into practical implications of scaling databases and Instagram's database architecture, and mentions the challenges faced by Roblox in implementing microservices."
    ],
    "points": 177,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1694843484
  },
  {
    "id": 37531801,
    "title": "Subdomain.center – discover all subdomains for a domain",
    "originLink": "https://www.subdomain.center/",
    "originBody": "Subdomain Center 💀 A Research Project by ARPSyndicate Subdomain Center utilizes Apache's Nutch, Calidog's Certstream, OpenAI's Embedding Models & a few of our proprietary tools to discover more subdomains than anyone else. To avoid abuse of this service, we have rate-limited to 3 requests/minute. And we apologize in advance for any unexpected downtime & delays. Our servers are often caught in a tug-of-war between an army of demanding users and a potato-powered hamster. Command Line Utility ------------------------ Repository: https://github.com/ARPSyndicate/puncia Installation: pip3 install puncia Usage: puncia subdomain ------------------------ More From ARPSyndicate Exploit Observer Attack Surface Management Platform Free Vulnerability Scan for Enterprises Open-Source Intelligence Resources",
    "commentLink": "https://news.ycombinator.com/item?id=37531801",
    "commentBody": "Subdomain.center – discover all subdomains for a domainHacker NewspastloginSubdomain.center – discover all subdomains for a domain (subdomain.center) 177 points by adam_gyroscope 6 hours ago| hidepastfavorite80 comments SushiHippie 0 minutes agoNote, if you looked up a domain and it had no results, you should check back again after some minutes. I looked my domain up and had zero results, which was weird as it should at least find some in the ct logs, but a few minutes later it showed some subdomains. reply gnyman 3 hours agoprevYou cannot hide anything on the internet anymore, the full IPv4 range is scanned regularly by multiple entities. If you open a port on a public IP it will get found.If it&#x27;s a obscure non-standard port it might take longer, but if it&#x27;s on any of the standard ports it will get probed very quickly and included tools like shodan.ioThe reason why I&#x27;m repeating this, is that not everyone knows this. People still (albeit less) put up elastic and mongodb instances with no authentication on public IP&#x27;s.The second thing which isn&#x27;t well known is the Certificate Transparency logs. This is the reason why you can&#x27;t (without a wildcard cert) hide any HTTPS service. When you ask Let&#x27;s Encrypt (or any CA actually) to generate veryobscure.domain.tld they will send that to the Certificate Transparency logs. You can find every certificate which was minted for a domain on a tool like https:&#x2F;&#x2F;crt.shThere are many tools like subdomain.center, https:&#x2F;&#x2F;hackertarget.com&#x2F;find-dns-host-records&#x2F; comes to mind. The most impressive one I&#x27;ve seen, which found more much more than expected, is Detectify (which is a paid service, no affiliation), they seem to combine the passive data collection (like subdomain.center) with active brute to find even more subdomains.But you can probably get 95% there by using CT and a brute-force tool like https:&#x2F;&#x2F;github.com&#x2F;aboul3la&#x2F;Sublist3r reply fuzzy2 1 hour agoparentThe Certificate Transparency Log is very important. I recently spun up a service with HTTPS certs by Let&#x27;s Encrypt. By coincidence I was watching the logs. Within just 80 seconds of the certificate being issued I could see the first automated \"attacks\".If you get a certificate, be ready for the consequences. reply tikkabhuna 1 hour agorootparentThis is really interesting. For my Homelab I&#x27;ve been playing around with using Lets Encrypt rather than spinning up my own CA. \"What&#x27;s the worst that could happen?\"Guess I&#x27;ll be looking to spin up my own CA now! reply dspillett 18 minutes agorootparentGetting a wildcard certificate from LE might be a better option, depending on how easy the extra bit of if plumbing is with your lab setup.You need to use DNS based domain identification, and once you have a cert distribute it to all your services. The former can be automated using various common tools (look at https:&#x2F;&#x2F;github.com&#x2F;joohoi&#x2F;acme-dns, self-hosted unless you are only securing toys you don&#x27;t really care about, if you self host DNS or your registrar doesn&#x27;t have useful API access) or you can leave that as an every ~ten weeks manual job, the latter involves scripts to update you various services when a new certificate is available (either pushing from where you receive the certificate or picking up from elsewhere). I have a little VM that holds the couple of wildcard certificates (renewing them via DNS01 and acmedns on a separate machine so this one is impossible to see from the outside world), it pushes the new key and certificate out to other hosts (simple SSH to copy over then restart nginx&#x2F;Apache&#x2F;other).Of course you may decide that the shin if your own CA is easier than setting all this up, as you can sign long lived certificates for yourself. I prefer this because I don&#x27;t need to switch to something else if I decide to give friends&#x2F;others access to something.Your top level (sub)domain for the wildcard is still in the transparency logs of course, but nothing under it is. reply KronisLV 59 minutes agorootparentprev> Guess I&#x27;ll be looking to spin up my own CA now!I was looking for a lazy&#x2F;easy way to do this manually and settled on KeyStore Explorer, which is a GUI tool that lets you work with various keystores and do everything from making your own CA, to signing and exporting certificates in various formats: https:&#x2F;&#x2F;github.com&#x2F;kaikramer&#x2F;keystore-explorer (to me it feels easier than working with OpenSSL directly, provided I trust the tool)In addition, I also setup mTLS or even basicauth at the web server (reverse proxy) level for some of my sites, which seems to help that little bit more, given that some automated attacks might choose to ignore TLS errors, but won&#x27;t be able to provide my client certs or the username&#x2F;password. In addition, I also run fail2ban and mod_security, though that&#x27;s more opinionated. reply ahoka 43 minutes agorootparentprevDidn’t you read the original comment? It’s just a matter of time until someone starts to poke your IPs. Your own CA will be harder to get right. reply implements 3 hours agoparentprevRecently, I opened 80 and 443 so I could use LetsEncrypt’s acme-client to get a certificate (and then test it). Tightening up security a bit, I configured an http relay to filter people accessing 80 by ip address rather than domain name - some scanners are still trying domain and sub-domain names I was using weeks ago - which goes to show how organised hackers are about attacking targets. reply BoberMod 1 hour agorootparentYou can use DNS-01 challenge [1] to get certificate. You just need to add temporary TXT record to your DNS. It also supports wildcart certificates.Most popular DNS providers (like Cloudflare) has API, so it can be easily automated.I&#x27;m using it in my local network: I have publicly available domain for it (intranet.domain.com) and I don&#x27;t wont to expose my local services to the world to issue certificate trusted by root CA on all my devices. So, this method allows me to issue valid Let&#x27;s encrypt wildcard cert (*.intranet.domain.com) for all my internal services without opening any ports to the world.[1]: https:&#x2F;&#x2F;letsencrypt.org&#x2F;docs&#x2F;challenge-types&#x2F;#dns-01-challen... reply intothemild 1 hour agorootparentprevOnce you expose something long enough to get scanned. It&#x27;s going to continue to get scanned pretty much forever.I self host a couple web services, but none are open, you need strong authentication to get in.It&#x27;s not ideal, ideally I&#x27;d close the https web traffic and use some form of VPN to get in. But sadly that&#x27;s just not feasible in my use case. So strong auth it is. reply pid-1 14 minutes agoparentprev> full IPv4 range is scanned regularly by multiple entities.Yet another good reason to use IPv6 reply fragmede 3 hours agoparentprevnot to underestimate the power of shodan, and oh god don&#x27;t spin up a default mongo with no auth, but port knocking would seen to counteract this to enough of a degree, not to mention having a service only accessible via Tor.https:&#x2F;&#x2F;wiki.archlinux.org&#x2F;title&#x2F;Port_knocking#:~:text=Port%.... reply gnyman 2 hours agorootparentYes, you can hide with a little bit of effort. Port knocking or Tor will stop almost any thing (but don&#x27;t rely on it as the sole protection, just as another layer).I like to prefix anything \"I don&#x27;t want scraped\" with a random prefix, like domain.com&#x2F;kwo4sx_grafana&#x2F; and nobody will find it (as long as you don&#x27;t link to it anywhere). But I still have auth enabled, but at least I don&#x27;t have to worry about any automated attacks exploiting it before I have time to patch.Something as simple as moving SSH on a non standard port reduces the amount of noise from most automated scanners 99% (made up number, but a lot). reply sgjohnson 3 hours agoparentprevYou don&#x27;t even need \"multiple entities\". Absolutely anyone can do that. Scanning a single port on the entire IPv4 internet takes about 40 minutes. reply blueflow 2 minutes agoprevI entered my own domains and i got so many garbage entries. It feels like an AI reading letsencrypt logs and then adding made up shit to it. reply banana_giraffe 5 hours agoprevCute, it managed to find 121486 subdomains for amazonaws.com [1], and somehow I suspect that&#x27;s a tiny fraction of what&#x27;s in use.https:&#x2F;&#x2F;gist.githubusercontent.com&#x2F;Q726kbXuN&#x2F;bf8a9a22b81fe65... reply hankchinaski 6 hours agoprevI would be keen to know what techniques are used. Usually subdomain discovery is done with dns axfr transfer request which leaks the entire dns zone (but this only works on ancient and unpatched nameservers) or with dictionary attacks. There are some other techniques you can check if you look at the source code of amass (open source Golang reconnaissance&#x2F;security tool), or CT logs. Dns dumpster is one of the tools I used alongside pentest tools (commercial) and amass (oss) reply cobertos 6 hours agoparentI mean, doesn&#x27;t it say right on the front page?* Apache Nutch - So they&#x27;re crawling either some part of the root itself or some other websites to find subdomains. Honestly might help to query CommonCrawl too.* Calidog&#x27;s Certstream - As you said, you can look at the CT logs* OpenAI Embeddings - So I guess it also uses LLM to try to generate ones to test too.* Proprietary Tools - your guess is as good as mineProbably a common list of subdomains to test against too.Seems like multiple techniques to try to squeeze out as much info as possible. reply piffey 4 hours agorootparentProprietary tools means passive DNS. reply smarx007 1 hour agorootparentHow can one avoid their browsing ending up in the passive DNS logs? For example, is using 1.1.1.1, 8.8.8.8, or 9.9.9.9 (CF, Google, and Quad9, respectively) good or bad in this regard?For example, where does Spamhaus get their passive DNS data? They write [1] that it comes from \"trusted third parties, including hosting companies, enterprises, and ISPs.\" But that&#x27;s rather vague. Are CF, Google, and Quad9 some of those \"hosting companies, enterprises, and ISPs\"?[1]: https:&#x2F;&#x2F;www.spamhaus.com&#x2F;resource-center&#x2F;what-is-passive-dns... reply Zuiii 5 hours agorootparentprevI&#x27;d also add insecure DNSSEC implementations that allow you to \"walk\" the entire record chain for the domain. reply derefr 6 hours agoprevInteresting. Our domain has some subdomains with a numeric suffix; and the API response here has entries in that pattern for not only the particular subdomains that exist or ever existed, but also for subdomains of the same pattern that go beyond any suffix number we&#x27;ve ever actually used.You&#x27;d think they&#x27;d at least be filtering their response by checking which subdomains actually have an A&#x2F;AAAA&#x2F;CNAME record on them... reply cm2187 5 hours agoparentIn fact my suspicion is that they would also cheat by looking into the dns cache of the current machine. reply ornornor 2 hours agoparentprevMaybe that’s the Open AI part of their secret sauce hallucinating subdomains? reply internet2000 5 hours agoprevFor my personal domain: it got the ones I have on the SSL cert alternative subject names, made up three, returned one I deleted more than a year ago, and didn&#x27;t find two. Very curious. reply DaiPlusPlus 4 hours agoparentThose SAN and CN names will appear in publicly visible certificate transparency lists ( https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Certificate_Transparency ): so if you ever get a TLS certificate for a super-seeekret internal sub-sub-sub-domain-name from a major CA then it won&#x27;t be secret for long. The only way to keep a publicly-resolvable DNS subdomain confidential is to either get a wildcard cert for the parent domain or find a dodgy (yet somehow widely-trusted) CA that doesn&#x27;t particiate in CT - or use a self-signed cert.This subdomain.center database returned one of my \"private\" sub-sub-domains (which just points to my NAS) for which I did get a cert from LetsEncrypt, but it doesn&#x27;t have any of my other sub-sub domains listed (despite resolving to the same A IPv4 address as the listed subdomain) because those subdomains have only ever been secured by a wildcard cert. reply Brananarchy 4 hours agoprevAs others have said, certificate transparency seems to be doing some heavy lifting here. It reports subdomains for me that have never had a public CNAME or A record, but have had let&#x27;s encrypt certs issued for internal use.It&#x27;s also missing some that have not had certs issued, but that are in public DNS reply Symbiote 52 minutes agoparentAt work we have a wildcard certificate for most services we host on our own infrastructure. Most public websites have been detected, and some internal ones which have probably been referenced in public GitHub issues and so on.They&#x27;ve done simple reverse DNS lookups on our public IP range and indexed all those hostnames.Certificate transparency logs have found names used for externally hosted websites.There are some pretty old hostnames which haven&#x27;t been used for 5 years or more, and were probably found with reverse DNS at the time. reply TekMol 4 hours agoparentprevThat&#x27;s why HTTPS is still a pain in the butt. 30 years after it was invented.I don&#x27;t want internally used subdomains to be public. Because of certificate transparency, the only way to achieve that is via wildcard certs.Let&#x27;s encrypt only supports cumbersome validation methods for those. Like changing DNS records every time you need to renew the cert.Pretty annoying. reply proto_lambda 4 hours agorootparentIf the subdomains aren&#x27;t supposed to be public, the public also doesn&#x27;t need to trust the TLS certs. Sign them with your own CA and trust it on the devices that should be able to access the domains. reply paranoidrobot 3 hours agorootparentAdding CAs to trust stores on devices and in apps is a major pain.If you have unmanaged devices this becomes even more painful.\"Oh, hi, welcome to the company, please install this Root CA onto your machine to access \"Because you can&#x27;t scope CAs to specific domains, this causes everyone with any idea about security to start being concerned. reply tgsovlerkhgsel 3 hours agorootparentYou can scope CAs with name constraints. However, I believe many implementations ignore constraints on root CAs. Not sure if there is some practical way with cross-signing around that (giving users the choice between trusting your CA and creating their own and cross-signing your CA with that). reply bostik 2 hours agorootparentprevAs sibling poster already wrote, technically you can scope a CA to a set of subdomains only. Or try. The spec entry is \"nameConstraints\" but for a number of reasons it may not be well supported.Some of those reasons are absolutely hilarious. I needed to set up an internal CA back in 2015, and wanted to limit the blast radius in case the private key was leaked. (Usually a \"when\", not \"if\" scenario.) I learned about the nameConstraints field and tried to use it. OpenSSL would ignore the key in a CSR input file. Okay, fine, the spec has an OID for the field so I reached for the nearest ASN.1 library to construct a modified CSR with the field in place.OpenSSL broke trying to parse the file. Go&#x27;s implementation blew up with a magnificent trace. I gave up and the internal CA was generated with a global validity scope.I later learned that apparently Microsoft&#x27;s PKI libraries had support for scope limits, but the feature was not used in real life. Likely because if such a thing came into contact with anything else in the wild, the underlying libraries would just implode.If you had a self-signed client cert with a nameConstraints in the supplied CA chain, you could probably still crash a non-trivial fraction of web servers. reply tikkabhuna 1 hour agorootparent> OpenSSL would ignore the key in a CSR input file.OpenSSL by default ignores many (&#x2F;all?) extensions for security. You can still manually add the nameConstraints when signing the CA cert.https:&#x2F;&#x2F;security.stackexchange.com&#x2F;a&#x2F;150175 reply layer8 1 hour agorootparentprevWhere I work, having internal services be accessed by employees’ own, unmanaged devices would be a no-go anyway. It would be considered a huge security loophole. reply numpad0 3 hours agorootparentprevWill HSTS on a random cert work? Click to accept once, pinned thereafter, or do browsers ignore that for untrusted certs? reply Thorrez 3 hours agorootparentThat&#x27;s not HSTS, that&#x27;s TOFU.HSTS is about remembering to do an http:&#x2F;&#x2F; -> https:&#x2F;&#x2F; redirect. It&#x27;s not about remembering a cert.The downside of TOFU in browsers, is that it trains users to always click through cert warnings. Train them to do it once, and they&#x27;ll click through it again when there&#x27;s a real attack. The warning is the same on the first time visiting the site and on a later time visiting it if the cert has changed.The TOFU UX in SSH is better, because it displays a different warning for when SSHing to a site for the first time vs SSHing to a site again and the cert has changed.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trust_on_first_use reply dspillett 6 minutes agorootparentMany of our clients send automated updates for our systems for data managed in other services via SFTP. It surprises me that few seem to bother verifying the host fingerprints, just blindly accepting them on first connection, given how paranoid they are (quite rightly, the data contains staff and customer information) otherwise. eastbound 3 hours agorootparentprevEvery single company does it. The 3 of them: Asking employees to install a CA, using it for “.internal” resources, then ask employees to use a web proxy and MITM their connections. And optionally, leak the CA’s pk to get pawned. It’s the standard operating procedure of any well-run business. reply Figs 3 hours agorootparentprevNon-public usage doesn&#x27;t necessarily mean that only devices under your direct control need access. Slack needs access to some of my organization&#x27;s systems, for example, to support the way we collaborate on our projects -- but the general public doesn&#x27;t and would likely just be confused if they stumbled into one of our infrastructure subdomains instead of visiting our public website. reply withinboredom 3 hours agorootparentprevYeah. In that case, it&#x27;s just easier to get a really cheap wild-card cert signed by a low-cost reseller forservice1.home.domain.com etc.) for my personal, but externally reachable domain, and I get the same results. I went the wildcard route just due to a bit of paranoia, nice to see that it actually worked out in this case.As this (I expect) heavily uses cert transparency in the background, I want to point out another use case for that service. You can search the CT logs with wildcards to find your domain \"neighbors\" on other TLDs: https:&#x2F;&#x2F;crt.sh&#x2F;?Identity=google.%25&match=ILIKE This usually gives you somewhat more active websites compared to just checking whether you can register the domain and somewhat weeds out squatted domains. I found that for our company one TLD contained a NSFW games store that way. reply donatj 3 hours agoprevInteresting. It only found less that a quarter of the subdomains of the site I work on, and everything it did find is public facing. I wonder if that’s maybe something to do with how we set up certificates for public vs internal subdomains? It even missed “staging.” which should be nearly identical in configuration to www reply RockRobotRock 6 hours agoprevThis is certificate transparency doing most of the work, right? reply zootboy 6 hours agoparentI would assume so. I tested on one of my private domains that generally isn&#x27;t linked to anywhere, and it just returned the few domains that I generate Let&#x27;s Encrypt certs for, plus my nameservers.Interestingly, I did not receive any DNS queries on my authoritative nameservers during the query, so they don&#x27;t seem to be doing any active DNS probes. reply out-of-ideas 6 hours agoparentprevit may utilize a few techniques as there are subdomains I am aware of that&#x27;ve never been published other than in the zone config on my registrar that are returned from api query reply RockRobotRock 6 hours agorootparentI use Cloudflare for DNS and the only ones it found had LE certs. It&#x27;s not doing a simple brute-force on common names, I don&#x27;t think. Otherwise it probably would have found a lot more. Curious about how it works. reply p4bl0 3 hours agoprevIt gave me empty results for some of my domains that have multiple subdomains that have TLS certificate associated with them so that must appear in the certificate transparency log.I guess it should be \"discover some subdomains for some domains\". reply Semaphor 1 hour agoparentEmpty for all my and my work’s domains. Then I tested random .com domains and got results. Seems pretty useless. reply ohuf 4 hours agoprevThe subdomain explorer may be fun, but their Exploit Observer is really useful: https:&#x2F;&#x2F;www.exploit.observer&#x2F; reply g147 1 hour agoparentthanks! reply keepamovin 5 hours agoprevThis is fantastic!!!What kind of security considerations are there to having multi-tenant user applications on subdomains and then having them exposed like this?I&#x27;m building a SaaS right now, and I guess one thing is that a given username can then be discovered as a valid login for the system...but obviously that&#x27;s only part of the login credential.Maintaining a list of mappings to opaque subdomains seems to reduce targeting, and conceal login partial credentials, but doesn&#x27;t seem to offer much besides.Analysis? reply thorum 4 hours agoparentIt doesn’t seem to detect subdomains set up with Kubernetes ingresses, based on results for one of my domains, so that might be a place to start research. reply davidkuennen 4 hours agorootparentIt also doesn&#x27;t find any subdomains for my domain.In my case I use Google Cloud DNS. Maybe they have some sort of protection in place (I wouldn&#x27;t be surprised). reply weird-eye-issue 4 hours agoprevI got back an empty list for my domain on Cloudflare with several subdomains (non wildcard)edit: I retried on my computer (was on my phone earlier) and now it returns all of our subdomains, even picking up our test R2 bucket. In guessing I was rate limited because I accidentally loaded the example file a few times reply cm2187 5 hours agoprevOne thing I noticed looking at my logs is that there is almost no unsolicited traffic (i.e. failed authentication attempts, exploits of various worldpress bugs, etc) through ipv6. I think it&#x27;s a function of 1) those coming from networks (compromised home devices, etc) that don&#x27;t support v6, 2) the v6 address space being too large to scan (the size of an encryption key), so good security by obscurity. This would nullify 2). reply asmor 3 hours agoprevhttps:&#x2F;&#x2F;github.com&#x2F;projectdiscovery&#x2F;subfinder does this, but it explains all the methods and lets you choose to only do a passive scan. reply hbcondo714 5 hours agoprevSeems similar yet still useful to Wolfram Alpha; just enter a domain and click on the \"Subdomains\" button:https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i=ycombinator.com reply franky47 5 hours agoprevSublist3r [1] does a similar job, as long as you have the authorisation to use it on a particular domain, as it uses more aggressive discovery techniques.[1] https:&#x2F;&#x2F;github.com&#x2F;aboul3la&#x2F;Sublist3r reply pabs3 5 hours agoprevMore options here: https:&#x2F;&#x2F;wiki.archiveteam.org&#x2F;index.php&#x2F;Finding_subdomains reply johntiger1 5 hours agoprevTook a while, but was impressed it detected all of ours: https:&#x2F;&#x2F;api.subdomain.center&#x2F;?domain=radiantai.health reply DistractionRect 5 hours agoparentCertificate transparency does a lot of the heavy lifting:https:&#x2F;&#x2F;crt.sh&#x2F;?q=radiantai.health reply Semaphor 1 hour agorootparentOnly that actually works. I get hundreds of entries for my domain there, including entries before Lets Encrypt was a thing, while the subdomain checker returns an empty array. reply judge2020 5 hours agoprevhttps:&#x2F;&#x2F;dnsdumpster.com reply TechBro8615 4 hours agoprevI get a rate limit error when I click the text input (I&#x27;m on a VPN). reply 867-5309 25 minutes agoparentuse an obscure country like North Macedonia reply mmarquezs 4 hours agoprevNice, last time I used Wolframalpha for this. reply webprofusion 5 hours agoprevThis is a CT log search right? reply Ocha 5 hours agoprevMissed some for me reply Ocha 5 hours agoparentMaybe because I use wild card certs with let’s encrypt reply ThePowerOfFuet 3 hours agorootparentInstead of replying to yourself, try editing your first comment! reply zX41ZdbW 5 hours agoprevHow can I download the entire dataset from this service? reply perryizgr8 5 hours agoprevIt detects only some of mine. To be precise, it does not detect subdomains being served by a service behind a CloudFlare tunnel. reply tobinfekkes 5 hours agoprev [–] This is crazy, I was just looking for this exact thing a couple days ago. Thank you for sharing. Brilliant work. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Subdomain Center is a research project developed by ARPSyndicate that employs tools like Apache's Nutch and OpenAI's Embedding Models to discover more subdomains than any other service.",
      "To avoid misuse, the service restricts users to a maximum of three requests per minute, and potential downtime might occur due to increased demand.",
      "Along with Subdomain Center, ARPSyndicate offers a command line utility tool, Puncia, and other resources pertaining to exploit observation, attack surface management, vulnerability scanning, and open-source intelligence."
    ],
    "commentSummary": [
      "The forum discusses the vulnerabilities and risks tied to subdomains, and users share different discovery methods, such as scanning the IPv4 internet, leveraging certificate transparency logs, and using proprietary tools.",
      "There is apprehension about privacy and security issues of publicly visible subdomains and the difficulty of securing internal subdomains, with advice to practice caution when opening ports and exposing services for additional safety.",
      "Implementing port knocking or using Tor are suggested for enhanced security, along with the advantages of using IPv6 over IPv4 in these contexts."
    ],
    "points": 173,
    "commentCount": 75,
    "retryCount": 0,
    "time": 1694835147
  },
  {
    "id": 37521931,
    "title": "Yes, Android 14 still allows modification of system certificates",
    "originLink": "https://www.g1a55er.net/Android-14-Still-Allows-Modification-of-System-Certificates",
    "originBody": "g1a55er::blog Archive About RSS Android 14 Still Allows Modification of System Certificates 15 Sep 2023 Tim Perry recently claimed in an article that “Android 14 blocks all modification of system certificates, even as root”. This sparked significant discussion on Hacker News. Thankfully my tests show that it is still possible to adjust the system certificate store in Android 14. Update Sept. 15 2023, 6:34 AM Pacific: After I’d already written this post but before I posted it, it looks like Perry already discovered that he can solve this problem for his purposes by bind mounting the /apex/ mount back to the /system/ partition in the namespace of zygote and the children of zygote. The core of the idea came from a Mastodon thread with @tbodt and @tmw. This post still provides a slightly alternative method, so it is still relevant, as well as still being relevant to the broader discussion. Users Can Still Revoke System Certificate Trust Through the Settings App The headline of Perry’s article asserts that even root users cannot “modify” the system certificates at all. In fact, even in Android 14, all users can still remove certificate authorities (CAs) from the list of trusted CAs in the Settings app, just like they could in previous versions of Android. To confirm that the Settings app still works, I used an Android 14 emulator to revoke trust from all the Amazon and Starfield Technologies CAs. I then accessed Amazon Trust Services Repository’s test pages using Chrome. They failed to load due to an untrusted CA. I also confirmed the revocation of trust persists across reboots. Based on this, I think the headline of Perry’s article is overly strong. Most of the more impassioned comments on Hacker News took the headline’s strong claim at face value. It is important to be clear: users still retain ultimate control over the trust anchors in Android 14. Developers Can Still Add Trusted System Certificates via ADB When I revisited the article after reading Perry’s comments on HN and Mastodon, it became clear that his primary concern was the inability to easily add temporary system CAs via ADB. This feature is critical for his product, HTTP Toolkit. It is also critical for many other security researchers and app developers, myself included. While Perry correctly notes that the traditional method no longer functions with Android 14, the feature hasn’t been discarded. I initially anticipated a deep dive into APEX and its signing intricacies. Thankfully, a simpler, albeit somewhat crude, workaround exists for this as a proof-of-concept. This is not suitable for production use. For a production environment, it’s crucial to carefully limit SELinux and tmpfs security options to grant only the minimal privileges. Alternatively, one can construct a properly signed repacked APEX. # These commands assume a root shell. # # Deal with the fact that there will be executables on the /apex tmpfs # !! Not suitable for production usage !! setenforce 0 mount -o remount,exec /apex # Make a copy of the current conscrypt APEX contents cp -r -p /apex/com.android.conscrypt /apex/com.android.conscrypt-bak # Lazily unmount because conscrypt might be in active use umount -l /apex/com.android.conscrypt rm -rf /apex/com.android.conscrypt # Put contents of conscrypt APEX on /apex tmpfs mount mv /apex/com.android.conscrypt-bak /apex/com.android.conscrypt # Soft userspace reboot to get everything back into a consistent state killall system_server # Clear system trust anchors, if desired mv /apex/com.android.conscrypt/cacerts /apex/com.android.conscrypt/cacerts-bak Executing these steps clears the system CA list in the “Trusted credentials” section of the Settings app - the result desired in the original post. This breaks through the mount namespaces by re-writing the directory entry for /apex/com.android.conscrypt on the /apex tempfs. The actual filesystem is shared between all namespaces, so overwriting this mount point has an immediate effect visible from all namespaces, even though the unmount event itself is not propagated. Hat tip to @tbodt on Mastodon for pushing me to dig into this until I fully understood it. After this setup, adding trusted certificates is almost identical to prior versions. The only change is using /apex/com.android.conscrypt/cacerts as the destination path. I confirmed this by adding my personal CA as a system trust anchor. This process only necessitates root access and doesn’t require altering /system. If you need persistence beyond a single boot, you’ll need to modify the /system partition, just as in older Android versions. Be prepared for the slight complexity of either deleting or repacking the com.android.conscrypt APEX. I leave that as an exercise to the reader. Verdict: All Is Well That Ends Well Yes, Android 14 has altered the behavior of its system certificate store. But users’ freedoms remain intact. The modifications just add a layer of indirection facilitating over-the-air updates to the certificate store. Given Android’s update delays have previously hurt CAs like LetsEncrypt, this is a positive move. I can see how the new layer may seems complicated at first, but it does have to meet some pretty tough constraints1. Kudos to Perry for highlighting this change. Various tools will need to be updated to work with Android 14. Once that is done, I am optimistic that security researchers, developers, and reverse engineers will retain their previous capabilities to tinker and make. Disclosures I am friends with Googlers and former Googlers, but I have never worked for Google. I have previously worked as a security-focused developer for a small Android OEM, which is why this caught my attention. I do not currently work for anyone, so these opinions can only be my own. Most notably, it must maintain security while allowing for different organizations in different positions in the physical smartphone supply chain to sign different parts of the Android system image. If you’re curious about theses trade-offs, Google discusses the alternative designs they considered here. ↩ g1a55er © 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37521931",
    "commentBody": "Yes, Android 14 still allows modification of system certificatesHacker NewspastloginYes, Android 14 still allows modification of system certificates (g1a55er.net) 164 points by g1a55er 16 hours ago| hidepastfavorite64 comments maven29 14 hours agoThere are ways to bypass any of these restrictions imposed by the Android system, even if they were real. Android ships with eBPF, so you just need root.https:&#x2F;&#x2F;github.com&#x2F;gojue&#x2F;ecapture reply kelnos 14 hours agoparent\"Just\" is doing a lot of work there. Getting root isn&#x27;t always possible or easy, depending on your device manufacturer. And if you do manage to get root, your phone will likely stop passing SafetyNet, and you&#x27;ll lose access to a bunch of apps that you may care about. SafetyNet can be spoofed in some situations, but not all, and even when spoofing does work, it all seems very brittle to me.Yes, of course, you can do this, but let&#x27;s not pretend there aren&#x27;t trade offs. reply matheusmoreira 10 hours agorootparentYeah. Android has become as hostile as Apple devices due to hardware remote attestation. Might as well buy an iPhone at this point. Only reason I didn&#x27;t is I discovered the existence of Termux which turned into something of an Android killer app for me. Who knows what Google&#x27;s gonna kill next though? Termux is already incompatible with the official store due to system call restrictions. Maybe it&#x27;ll be straight up impossible to run it in a future version of Android. reply selfhoster11 25 minutes agorootparentI bought an iPhone a year ago for this exact reason. Both are user-hostile platforms now, so I might as well pick one that respects my attention more and treats me more acceptably. In addition, it looks like a near-future version of iOS will allow sideloading, which would make iOS an overall better mobile OS than Android.Sent from my iPhone (after 13 years of using Android) reply WeylandYutani 1 hour agorootparentprevIt&#x27;s true that Google is unpredictable but as it stands Android still allows me to install apps outside of the approved store. reply jeroenhd 13 hours agorootparentprevIn the context of \"changes to Android 14\", \"just\" is right. Android has required root access for modifying random apps since before Android 6, and that&#x27;s only because many apps didn&#x27;t bother implementing certificate pinning (which was already known advice at that point).Alternatively, you can use ADB + Frida to pull an APK from the device, inject a binary, and inject code at runtime using Javascript or Python. That&#x27;s much easier for intercepting traffic than messing with certificate stores or eBPF ever was in my opinion. reply ungamedplayer 7 hours agorootparentDo you have any kind of docs on doing this. I want to get some stats from a game I&#x27;m playing and think that the server fudges the number to keep whales happy.Any quality documentation on how to do this would be great. reply 1vuio0pswjnm7 11 hours agorootparentprev\"Yes, of course, you can do this, but let&#x27;s not pretend there aren&#x27;t trade offs.\"Are there some words in the parent comment that \"pretend there aren&#x27;t tradeoffs\". Is it that he did not include a warning about \"SafetyNet\". What would this \"pretending\" look like.Losing access to \"a bunch of apps you may care about\" seems to be dependent on an assumption: that the reader cares about certain unnamed apps. Yet we cannot even name these apps. We cannot know what apps a user cares about unless the user tells us. I know Android users that do not use any apps that rely on SafetyNet.Nor do we know what device manufacturer the reader may be dealing with. It might be one where it&#x27;s relatively easy to the computer owner to have root privileges.Perhaps we can refrain from making assumptions about readers. reply Dylan16807 7 hours agorootparent> Are there some words in the parent comment that \"pretend there aren&#x27;t tradeoffs\"Yes. They quoted it! \"you just need root\". Especially the word just. That kind of phrasing implies that it&#x27;s not flat-out impossible on many devices and that it doesn&#x27;t break major functionality.\"I know users that don&#x27;t use that feature\" is praising with faint damnation. reply 1vuio0pswjnm7 12 hours agoparentprevhttps:&#x2F;&#x2F;github.com&#x2F;gojue&#x2F;ecapture&#x2F;releases&#x2F;expanded_assets&#x2F;v...Anyone know why there is an aarch64 nocore but not an x86_64 nocore. reply RockRobotRock 13 hours agoparentprevVery cool. Does this work better than a Frida hook for capturing encrypted HTTP calls while bypassing cert pinning? reply post_break 14 hours agoparentprevHow many normal phones can you root these days? reply modeless 14 hours agorootparentEvery Pixel phone purchased from the Google store reply downWidOutaFite 14 hours agorootparentAfter wiping all data and losing access to a bunch of features and apps. reply AshamedCaptain 13 hours agorootparentIncluding everything I could possibly ever want an Android device for, like my bank&#x27;s 2FA program.It&#x27;s all been slowly cooking for a decade, yet people will still claim \"but you can still do it with root, so it&#x27;s as free as before!\" (or some other ridiculously complicated workaround with lots of nasty side-effects) reply hackermatic 12 hours agorootparentYup. When I updated my company&#x27;s secure development requirements, and compared them to others, I was confronted with a lot of choices that would increase security somewhat, but at the expense of user control of their own devices, like refusing to function if the device was jailbroken, or requiring the use of the system keyboard only (which is also an accessibility problem).These are tempting choices, but they go a lot further than, for example, requiring only modern TLS ciphersuites to be used to communicate with my servers. They dictate the state of your entire device, and no one app or company should have that power, unless you work for the company and they issue you the device -- but even then, modern MDM&#x2F;MAM can and should sandbox company apps from the rest of the device. reply a_t48 12 hours agorootparentWhen I worked on iOS games, I ended up having to ban all jailbroken devices. I didn’t like doing it, but basically - every cheater we found was using a jailbroken phone, the number of non cheaters with jailbroken phones was tiny, and it would have basically taken up all my time to deal with cheaters rather than implement fun features. I’d have just ignored them if it wasn’t for the fact that they made the leaderboards look really fake. reply _silicon 6 hours agorootparent“I didn’t like doing it” doesn’t make this any better. It’s just hammering another nail in the coffin of device ownership. reply a_t48 6 hours agorootparentPlease, our mediocre AA gatcha game did nothing to you nor the overall jailbreaking ecosystem. Don’t you think that’s being a bit dramatic? reply jsight 8 hours agorootparentprevAs much as I want to agree with you, I can&#x27;t blame Google here. Corporate security departments have bought into the idea that mobile is different and you can&#x27;t trust the user with root.Google has little choice but to provide them with the tools to detect root access. reply ori_b 8 hours agorootparentWhy? If Google didn&#x27;t implement it, what would they do? reply BlueTemplar 6 hours agorootparentprevExactly, you shouldn&#x27;t waste your time with Android any more than with iOS at this point (same for banks that only provide 2FA on iOS&#x2F;Android).And while for years the alternatives have been almost nonexistent, we do have at least two now : PinePhone and Librem 5. reply mintplant 13 hours agorootparentprevMagisk [0] + safetynet-fix [1] can work around that.[0] https:&#x2F;&#x2F;github.com&#x2F;topjohnwu&#x2F;Magisk[1] https:&#x2F;&#x2F;github.com&#x2F;Displax&#x2F;safetynet-fix reply Novosell 1 hour agorootparentAs far as I&#x27;ve understood, the safetynet fix makes use of a feature which only exists for comparability reasons, so that old devices don&#x27;t get locked out entirely. When there aren&#x27;t enough old devices around anymore, it will likely stop working. reply Dylan16807 7 hours agorootparentprevIt&#x27;s quite doubtful it will keep working. reply curiousgal 1 hour agorootparentWell people keep saying this for years now. When it stops working we&#x27;ll make statements like \"root breaks access to Netflix and Banking apps\". But since it doesn&#x27;t at the moment, everything is good. reply garciansmith 11 hours agorootparentprevYou do have to unlock the bootloader to root a device, hence wiping the data, but that doesn&#x27;t matter if it&#x27;s the first thing you do when you get the phone.Features though? Maybe I don&#x27;t realize all the great things I&#x27;m missing out on since I&#x27;ve only ever used rooted phones since I got my first Android device many years ago.As for apps, I&#x27;ve only heard of certain games (I don&#x27;t play games on my phone) and banking apps (thankfully mine doesn&#x27;t care, though I&#x27;d rather use a desktop web interface for financial stuff). reply Dylan16807 7 hours agorootparentNetflix is a big one. reply orangepurple 14 hours agorootparentprevAnything that LineageOS supports https:&#x2F;&#x2F;wiki.lineageos.org&#x2F;devices&#x2F; reply inetknght 14 hours agoprevAllowing a user to add system certificates a good thing. The user owns the device. reply __MatrixMan__ 13 hours agoparentI agree with your first sentence. The second seems to get less and less true all the time. reply userbinator 7 hours agorootparentThe former is a necessary condition of the latter. reply shadowgovt 14 hours agoparentprevEverything in the category \"the user owns the device\" is tricky.For a lot of users, \"It&#x27;s really hard to break\" is a value-add. Every capacity the user has to modify permissions is an opportunity for an attacker to compromise a device. You can see an example of this in web browsers these days, where sites have to `log` a big scary \"Don&#x27;t paste anything someone tells you to paste into here\" message into the built-in developer tools because no matter how many safety features get added to the browser security model, the dev tools can bypass them.It is definitely important that the purchaser knows what kind of phone they&#x27;re getting (whether it&#x27;s easy or hard to crack open all the layers of its protection model), but \"The phone&#x27;s protection model is easily broken by the owner\" as a universal absolute applied to all devices should be considered harmful. reply amalcon 11 hours agorootparent\"Easily, but there&#x27;s a big scary warning that the person asking you to do this might be trying to hack you\" is still \"easily\". That obviously seems more consumer friendly than either extreme. reply shadowgovt 8 hours agorootparentThose warnings only go so far against a talented social engineer. reply 3np 3 hours agorootparentAt some point, you can not protect people from themselves. reply inetknght 9 hours agorootparentprev> For a lot of users, \"It&#x27;s really hard to break\" is a value-add.\"It&#x27;s really hard to break\" should not be conducive to the dumbing down of the populace. Enabling power users is therefore more desirable.And importantly, the two do not have to be mutually exclusive. reply simondotau 5 hours agorootparentI agree with you in theory, but in practice half the population are never going to become security experts and it&#x27;s impractical to force them to learn through necessity. If a hacker can get root on your smartphone, they can probably get access to your bank account (and the 2FA), your email, your private&#x2F;intimate photos, your medical issues, your sexual secrets, and so on. A smartphone is far higher stakes than anything else which has come before it.To be clear, I think our right to have a smartphone we control is an absolute. It&#x27;s extremely important. I would march on the street to protect that right. But I&#x27;m equally protective of my right to have a smartphone I cannot control no matter what button I press. I&#x27;m glad for devices like the iPhone where the manufacturer works damn hard to make sure that it&#x27;s always under the manufacturer&#x27;s control. reply loa_in_ 10 hours agorootparentprev> sites have to `log` a big scary \"Don&#x27;t paste anything someone tells you to paste into here\" message into the built-in developer tools because no matter how many safety features get added to the browser security model, the dev tools can bypass them.That doesn&#x27;t seem all that much work. Hardening things like that should be a dedicated job, but of course it doesn&#x27;t \"create value\" so it&#x27;s mostly left to rot until it&#x27;s a source of bad PR. reply Spivak 11 hours agorootparentprevI don&#x27;t think you deserve the downvotes, this is exactly right and is incredibly frustrating. Programmers, and increasingly folks who don&#x27;t consider themselves to be writing malware, have no concept of a thing that should never be done by an application and only by the end user. If it&#x27;s possible to do I should be allowed to do it! If they didn&#x27;t want me doing it they should have stopped me! The amount of guides on the internet not targeted toward developers that teach users to go through the \"create an application\" flow and grant some random app access to their account in a more privileged way than would be allowed by the app itself is embarrassing for our industry. \"Just add this configuration profile!\", \"Just paste in your API key.\"The moment you allow users to add custom root certs ad blocker apps are going to ask users to add one for \"advanced\" network level ad blocking. You can&#x27;t win with this crap. Nobody considers themselves a \"not advanced\" user so no amount of warning will ever work. Have you ever tried doing something, saw some warning that said this was for advanced users in your way to do the thing, and stopped? Me neither. reply michaelmrose 13 hours agorootparentprevHow do you make something that isn&#x27;t trivially turned to oppression without allowing users a trivial escape from the devices protection model?Isn&#x27;t installing your own OS on your general purpose computer a trivial out? Shall we likewise disable that ability on all general purpose computers? reply paulmd 3 hours agorootparentApple honestly did a pretty good job. You can sideload your own code with a free developer account, but you have to jump through some minor hoops to get “developer” mode set on your account (I went through this to get the tvOS 17 beta). And the app signing expires in 7 days, so it’s really painful for a normal user who isn’t actually developing and testing an app to use like that for a long term thing.If you want more than that, you can pay $99 for a real developer account and that will let you sign apps for up to a year. And that’s a sufficient barrier that Facebook can’t be like “you have to sign up for a dev account if you want to use Facebook!” and expect the average user to just blindly comply.Cause that’s the problem with the EU approach, it works ok when it’s only the EU, but Facebook really wants to bypass those permissions (they’ve already bribed users to install dev credential builds that have full permissions, so they could datamine more effectively), and the moment they can lever open the app-review process with “third party app stores” is the moment the “doesn’t work on iOS, please sideload the native app” banner goes up on Facebook.com.It doesn’t have to be financial but the only alternatives would be some kind of credential verification thing like looking at your LinkedIn or a college transcript or a GitHub account to validate that you’re actually a bona fide developer and not just grandma who got an iTunes gift card to install the spyware build (real example from Facebook).https:&#x2F;&#x2F;techcrunch.com&#x2F;2019&#x2F;01&#x2F;30&#x2F;apple-bans-facebook-vpn&#x2F;am... reply JimDabell 1 hour agorootparent> Apple honestly did a pretty good job.They did. Over here, there are regular news articles and warnings from the government as yet more Android users get conned into installing fake banking app APKs that let attackers steal all their money. It’s always the same news article and the same warning – only Android users affected.Elsewhere in this thread, people are saying that you can’t protect people from themselves… but Apple seem to be doing a good job of it. When was the last time a side-loaded IPA stole bank credentials from iPhone users?I personally think that Apple should be a little more open. Having some sort of developer mode with plenty of warnings would be better. But the idea that Apple’s approach doesn’t improve security in meaningful ways to the average user is wishful thinking based more in ideology than what actually happens in the real world. reply ori_b 8 hours agorootparentprev> Shall we likewise disable that ability on all general purpose computers?It&#x27;s being worked on with web attestation. reply shadowgovt 8 hours agorootparentprevSometimes oppression could come from a central authority, and sometimes it can come from a rampant criminal element taking advantage of exploitable human behavior.We have to balance defending against both.> Shall we likewise disable that abilityNot on all computers, no. But I should have the option of buying my grandmother one which is very, very hard for someone to convince her to give them admin rights. reply michaelmrose 4 hours agorootparentThis use case is well served by a non admin user as opposed to a machine where Dell is the root user. Furthermore what you desire for your grandmother is liable to be imposed on the rest of us if we want the privilege of banking or Netflix and in many cases grossly abused especially in less free countries including ours should we in the US fall into fascism.You would build chains for millions of people so that granny will have to give scammers her money some less convenient way.I&#x27;d rather not. replytwleo 14 hours agoprevLooks good. I hate how IOS does, especially with certificate pinning, so I cannot use my ad-block http mitmproxy to block ads in Apps.EDIT: thanks for people clarifying that pinning is done by Apps and not by IOS. reply kelnos 14 hours agoparentThat&#x27;s not necessarily specific to iOS. Certificate pinning is usually done inside an app, not at the OS level. An app can choose to ignore the system certificate store and, for example, pin the cert used to talk to its private API. This is possible both on iOS and Android. reply jeroenhd 13 hours agoparentprevAnother note: cert pinning is made very easy by Android as well (just needs a fingerprint in an XML file).It&#x27;s a good feature for security (stalkerware remains a huge problem) but it does suck from a reverse engineering standpoint. reply ShrimpHawk 14 hours agoparentpreviOS is even easier than Android to add system certificates and can be done without rooting or jailbreaking the device unlike android. cert pinning is done by the apps not the system. reply WirelessGigabit 12 hours agoparentprevWould you mind sharing your setup? reply twleo 9 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;epitron&#x2F;mitm-adblockorhttps:&#x2F;&#x2F;github.com&#x2F;barre&#x2F;privaxy reply jiofj 14 hours agoparentprevcert pinning is done by the apps, not by the OS reply rwmj 14 hours agorootparentThat&#x27;s a distinction without a difference in these tightly controlled ecosystems. reply ladberg 13 hours agorootparentAndroid apps could also do certificate pinning with the same effect though? In this case there isn&#x27;t any difference between Android and iOS in functionality. reply hospitalJail 14 hours agoprevGosh I love linux&#x2F;root.I havent needed it on recent androids due to WFH and spending more time on my laptop, but back when I was flying more for work, I was much more into my phone.Cant remember if it was my motorolla or nexus, but I felt like I had a full fledged laptop in my pocket back then.Meanwhile, one of the straws that broke the camels back for Windows was the insane difficulty&#x2F;impossibility of remove bloatware&#x2F;malware that comes preinstalled with windows 11. In 2023, its mind boggling to think you have easier access to modify a cellphone OS than a desktop OS. reply __MatrixMan__ 13 hours agoparentI recently got tired of trying to hack together a sane workflow on the windows computers in the lab at my university, so installed nix-on-droid and gotty on my phone.Now I just open a tab to my phone&#x27;s IP address and benefit from the big screen and full sized keyboard while still having exactly the tools I&#x27;m used to having elsewhere. When I get home and want to resume work on beefier hardware, I just push from my phone, pull from my desktop, and I&#x27;m just where I left off, except now with more resources.You have to be a bit austere about your tool choices to make the similarity happen (sorry VSCode), but it feels like a bit of a superpower just the same. reply assassinator42 13 hours agoprevCan&#x27;t you still install a CA certificate through Settings like you always could? https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;65319223 reply jeroenhd 13 hours agoparentYou can, but that&#x27;s not the system certificate store.Android has two certificate stores (the user store and the system store). The user store can be altered through the method you linked. The system store used to be part of the system image (you could always disable certificates, of course) and will now be moved to an APEX location that Google can update (to prevent the Let&#x27;s Encrypt issue in the future).To alter the system store, you need root access. At the moment it&#x27;s just a matter of dropping a file with the right name and encoding at &#x2F;etc&#x2F;system&#x2F;cacerts (through Magisk style overlays, or by modifying the system image) but that will change soon. reply netheril96 5 hours agorootparentWhat&#x27;s the practical difference between system store and user store? Do some apps or system operations only trust the system store and not the user store?Not rhetorical questions. reply mvnuweucxqokii 5 hours agorootparentI don&#x27;t know the difference between the user and system store, but I do know that apps can choose not to trust certs installed by the user and instead only trust their own that they bring with them. Was frustrated to find this when I was trying to MITM an app to see what it was up to on the wire. reply aqfamnzc 5 hours agorootparentprevCan you expand more on the Let&#x27;s Encrypt issue? What do you mean by that? reply kristopolous 13 hours agoparentprevI&#x27;ve used this to sniff traffic on my phone to great success.The MITM attacks by manipulating the keys was a godsendInvaluable debugging toolsWe need some new tact, pro-user AND pro-security - those are often seen as in conflict with each other. reply teakie 13 hours agoprev [–] disable CAs is a thingor can you add your own for every domain or something? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post challenges Tim Perry's assertion that Android 14 restricts all changes to system certificates, providing evidence that adjustments can still be made and users can revoke system certificate trust.",
      "The author asserts that developers are able to add trusted system certificates through ADB (Android Debug Bridge), a versatile command-line tool used for communicating with a device that runs on Android.",
      "While acknowledging changes with Android 14, it is concluded that user freedom is preserved, and these alterations aid over-the-air updates to the certificate store, thus implying an expected update to tools compatible with Android 14."
    ],
    "commentSummary": [
      "The discussion highlights system certificate modifications on Android 14 and the implications and potential benefits of rooting devices, including gaining access to certain features and apps at the expense of others.",
      "Users are assessing alternative methods, such as ADB + Frida or Magisk + safetynet-fix, for making modifications and balancing user freedom with device protection.",
      "The post underscores the importance of user ownership in the face of growing hostility from Android and Apple devices. It commends Apple's security measures while suggesting the incorporation of a developer mode with warnings."
    ],
    "points": 164,
    "commentCount": 64,
    "retryCount": 0,
    "time": 1694780823
  },
  {
    "id": 37528453,
    "title": "The first week of US v. Google – Defaults are everything and nobody likes Bing",
    "originLink": "https://www.theverge.com/2023/9/15/23875342/justice-department-google-antitrust-search-trial-week-one-recap",
    "originBody": "Skip to main content The Verge homepage / Tech/ Reviews/ Science/ Entertainment/ More Menu POLICY In the Google antitrust trial, defaults are everything and nobody likes Bing The first week of US v. Google begins with arguments over the power of deals and data. By Adi Robertson, a senior tech and policy editor focused on VR, online platforms, and free expression. Adi has covered video games, biohacking, and more for The Verge since 2011. Sep 15, 2023, 1:01 PM CDT|11 Comments / 11 New Share this story Illustration by Cath Virginia / The Verge Google is one of the biggest tech companies in existence, but its empire is built on one little white search bar, and the US Justice Department has just launched what might be one of the biggest challenges it’s ever faced. In one of the largest antitrust trials in recent memory, the government argues that Google owes its dominance not simply to a good design but to a series of coercive deals that have let the search engine market stagnate — while Google complains it’s being punished for success. For all that, the trial began quietly. I got to the courthouse around sunrise for the start of US v. Google, worried I’d find a line around the corner. Instead, the sidewalk was nearly empty, populated by a handful of similarly cautious early arrivals. “I thought there’d be more people,” one said while we waited in the muggy DC air. In the hours that followed, a small crowd emerged — filling the courtroom and spilling into an overflow room and two dedicated media rooms for journalists. A man in an Uncle Pennybags-style top hat, fake mustache, and monocle wandered the halls of the courtroom; “I’m here to highlight Google’s monopoly and provide moral support as a fellow billionaire,” he told me between mustache twirls. He admitted he might not be there to keep up the joke every day — it’s a 10-week trial, he conceded, and “I have a job.” The case against Google is relatively straightforward and also potentially explosive. The Justice Department argues that around 2010, Google began using anti-competitive tactics to maintain an overwhelming search engine monopoly. Already dominant over alternatives like Bing and Yahoo, it cemented its position with the “power of defaults,” striking deals that put Google’s product front and center. That included paying Apple and Mozilla to make Google the default engine in Safari and Firefox and requiring that Android manufacturers prominently display a Google search widget on phones. (That agreement is called the Mobile Application Distribution Agreement or MADA, and it’s been legally contentious in Europe for years.) As it grew, it used vast quantities of search data to improve its engine, creating a feedback loop that — the Justice Department alleges — has made it almost impossible to beat. “This case is about the future of the internet and whether Google Search will ever face meaningful competition,” said attorney Kenneth Dintzer in opening statements. “This is a monopolist flexing.” US v. Google follows a series of abortive legal attempts to limit the power and growth of America’s biggest tech companies. It’s the Justice Department’s most aggressive action since its 1990s antitrust lawsuit against Microsoft, which established it had shut down competition for web browsers on its dominant Windows system. But this trial kicks off two years after a district judge found Apple could maintain its locked-down iOS ecosystem and two months after Microsoft won a ruling letting it buy Activision Blizzard, continuing a rapid consolidation of the games industry. In both battles, the companies convinced a judge that they weren’t simply trying to lock up a market — they were making decisions that helped consumers, too. They also painted the allegations as disingenuous complaints from fellow tech companies who couldn’t compete fairly: in Apple’s case, the Fortnite publisher Epic, and in Microsoft’s, the rival console maker Sony. Google has taken a similar approach. “If Google is prevented from competing, that won’t make Yahoo or DuckDuckGo run faster,” attorney John Schmidtlein said in the company’s opening statement. While the Justice Department has drawn parallels between ’90s Microsoft and modern-day Google, Schmidtlein said that the facts in US v. Google and the antitrust fight over Microsoft’s unloved Internet Explorer browser “could not be more opposite and different,” arguing that people overwhelmingly and proactively choose Google even when they’re given alternatives. Separately, he argued that Google’s default search deals give web browsers much-needed revenue and that its Android agreements help create a viable mobile competitor to iOS. Follow this case with The Verge’s Tech Cases Bot on X / Twitter or Mastodon. So far, the Justice Department is combating this argument by focusing on reams of internal communications it obtained during its investigations. It’s zeroed in on memos and emails where Google nakedly lays out the value it gets from being a default search option, as well as messages that allegedly dictate precise terms for how Apple and others could use any non-Google Search-adjacent service. (“Your honor, this is a monopolist flexing,” intoned Dintzer.) Schmidtlein has derided the excerpts as cherry-picked and “out of context.” But whatever they ultimately reveal, the Justice Department’s goal so far is clear: keep the focus on executives talking about how Google’s actions benefit Google, not the consumers it says it’s trying to serve. The Justice Department is also drawing direct parallels to the Microsoft antitrust case but in a complicated way. Some of the most damning allegations included Microsoft making unvarnished and rhetorically violent statements about “cut[ting] off Netscape’s air supply” in the browser wars. This time around, government attorneys are pointing to communications in which Google employees carefully avoid terms that could raise antitrust watchdogs’ ire. (Don’t) cut off their air supply Before the trial, the Justice Department sought to sanction Google for deliberately (and allegedly) deleting conversations that could illuminate how it approaches competition. In the first week, it’s focused on the tech giant’s judicious use of language. Its first witness was Google chief economist Hal Varian, whom Dintzer led through a series of email chains about Google’s search business. In one, Varian takes issue with Marissa Mayer (who at that point oversaw Google’s homepage) referring to the company’s “market share” — a term that could indicate overall market dominance. “Let’s make sure we are consistent in calling this ‘query share’ rather than ‘market share,’” Varian told another Google employee, Penny Chu. “Absolutely, I’m aware of not using the word ‘market,’” Chu replied. “The one big thing I remember from all that Legal training.” Varian responded that “query share” was simply the more accurate term. And he professed unfamiliarity with a 2011 presentation that laid out more rules for avoiding touchy language, including terms like “network effects,” “scale,” “bundle,” or “tie.” The concerns go back to at least 2003, when Varian urged Googlers in a memo to be “sensitive” about perceptions of monopolistic behavior, citing the “air supply” comment as an example of what to avoid. The Justice Department also dissected claims Varian made in 2009 about data from user searches being less than vital to search engine quality — a tortuously drawn-out process that drew multiple objections from Google’s lawyers. In an email chain from later that year, then-Google engineer Udi Manber argued that Varian had been “factually wrong” to dismiss the importance of data-sharing in a Microsoft-Yahoo pact. “It’s absolutely not true that scale is not important. We make very good use of everything we get,” Manber said. “If Microsoft had the same traffic we have, their quality will improve significantly, and if we had the same traffic they have, ours will drop significantly. That’s a fact.” Varian, again, argued the Justice Department was overplaying the importance of the disagreement; he said he acknowledged scale mattered, just that it produced diminishing returns. And Varian and Google’s attorneys alike were visibly irritated at the approach — which involved reading paragraphs of emails out before Judge Amit Mehta without giving Varian much room to rebut them. It’s a strategy that highlights Google’s internal rhetoric rather than its public-facing explanations for why it makes deals like MADA or the Safari agreement, to the company’s clear frustration. (Former White House official Tim Wu, who visited the trial on Wednesday, compared Varian’s prickly demeanor to “Bill Gates circa 1998.”) The power of defaults With Varian and other witnesses, the Justice Department returned again and again to the importance Google has placed on default settings. It called up former Google employee and Shazam founder Chris Barton to discuss the importance of striking deals with mobile phone makers and carriers. “We need to incentivize carriers to ship Google,” Barton said in a 2011 email. “Without an exclusive search deal, a large carrier can and will ship alternatives to Google … You can bet that Microsoft and Yahoo will enter contracts for search on Android through carrier deals if we do not.” Google’s consistent counterpoint is that this indicates a kind of entirely legal competition that other companies like Microsoft engage in regularly. Among other things, its attorneys have pointed out that Microsoft sets Bing as the default search option on Windows computers, which have a billion-plus users — and that this hasn’t stopped Google Search from dominating the market anyway. In opening arguments, Schmidtlein showed instructions for switching from Google to another search engine, comparing it to the days of slotting in software floppy disks or downloading programs over dial-up internet. So far, the Justice Department has fought this argument with an early expert witness: CalTech behavioral economics professor Antonio Rangel. Rangel was one of the few non-Google employees to make an appearance on the witness stand in the first week, arguing in a presentation that search engine defaults produce a “sizable and robust bias” toward the preselected option. Rangel cited other cases where a default option has dramatically shifted how people make choices, like opt-in organ donor programs and instances where Google has acknowledged the importance of being the default option — including cases like Apple Podcasts where it doesn’t occupy that space. In cross-examination, Google called Rangel’s conclusions into question, pointing out that Bing’s default placements, for instance, don’t seem to have helped Microsoft nearly as much. Google obviously can’t argue that defaults don’t matter at all — given how much money it’s spent on them — but it contends that they’re not enough to tip the scales in favor of an inferior product. Google getting more antitrust scrutiny is a good thing for Microsoft, but it’s almost impressive what a punching bag Bing has become in this trial. What about the consumers? As reporter Yosef Weitzman, who’s been appearing in court daily, notes, Judge Mehta seems to be probing exactly how this all fits with America’s consumer harm standard for antitrust judgments. Nothing, here, is more expensive for the average person. Google Search is free, after all — so does the average user really suffer from having to work slightly harder to reach an alternative? The Justice Department argues that unfair, pay-for-play competition strategies have let Google avoid making Search better in ways that do cause real harm. The first week of testimony hasn’t fully explored this yet, but one of its prime examples is lax privacy standards — if Google had to seriously compete instead of buying its way into your search bar, Dintzer said, it might have to do a better job of safeguarding your data. There’s also another group of consumers: advertisers who pay for placement through Google’s highly lucrative advertising system. Advertising isn’t the core focus of this case; it will be front and center in a later suit. But ads are the whole reason Google Search makes money, and one of the arguments against Google is that it’s obtained a level of power that lets it dictate prices unfairly to advertisers who use its tools. We’ll likely hear more about that from a coalition of states that piggybacked on the Justice Department’s case to add their own allegations — and who will make their case later in the trial. What’s next? The Justice Department is expected to make its case over the rest of September and early October, and we’ll likely hear from a bevy of current and former Google employees, including CEO Sundar Pichai. We’re also expecting testimony from Eddy Cue and other Apple executives, as well as Neeva co-founder Sridhar Ramaswamy, whose doomed search engine was mentioned in opening arguments. Google will get a chance to cross-examine the witnesses and poke holes in the department’s arguments, but we likely won’t see its side of the story laid out in full until late October, following arguments from the state attorneys general. All the companies involved here have done their best to limit sensitive information leaking, so it’s hard to say whether we’ll see revelations around things like just how much Google is paying Apple — but it’s always possible. The question that matters most, though, is whether Judge Mehta can be convinced that consumer harm applies to free products like search engines. In recent years, it’s seemed almost impossible to pin a tech company down on antitrust allegations, and Google has plenty of defenses on hand. Where Microsoft won its recent Activision Blizzard case by arguing that it was being left in the dust by competitor Sony, Google is saying that it’s simply the best option on the market. Does that mean it’s good or — as the Justice Department has argued — barely good enough? We’ll be watching that fight play out for months to come. 11 COMMENTS11 NEW FEATURED VIDEOS FROM THE VERGE What’s next for Microsoft’s giant Activision Blizzard $68.7 billion deal? UK regulators have dealt a blow to Microsoft’s giant $68.7 billion acquisition of Activision Blizzard. Microsoft will now have to fight to keep the deal alive, with a key EU decision in the coming weeks. Most Popular Bike tires made from NASA’s bizarre shape-shifting metal are now available to buy In Final Fantasy VII Rebirth, you can’t use your old Remake save Media mogul Byron Allen offers $10 billion to acquire ABC from Disney Google won’t repair cracked Pixel Watch screens Bose just overhauled its entire lineup of headphones and earbuds Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily. Email (required) SIGN UP By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. More from this stream US v. Google: all the news from the search antitrust showdown Breaking down the Google antitrust trial. Sep 12, 2023, 5:40 PM CDT Opening arguments in US v. Google just ended! Only ten weeks left to go. Sep 12, 2023, 12:37 PM CDT “We don’t have good data on actual user switching.” Sep 12, 2023, 10:50 AM CDT Bing is already Google’s punching bag for the trial. Sep 12, 2023, 10:36 AM CDT SEE ALL 12 STORIES SPONSORED CONTENT Most Windows Users Didn't Know This Simple Trick Safe Tech Tips Read more Seniors Love These Small Electric Cars In 2023 (Surprisingly Affordable) Small Electric CarsSearch Ads Click Here New Cadillac's Are Turning Heads And Finally On Sale All Things AutoSearch Ads Learn More Top 5 Wealth Management Firms in The United States SmartAsset Learn More Forget The Blue Pill, Use This Household Food To Fight ED urologytip.pro Chuck Norris Says: Do This Daily For More Energy, Even if Your 80 americamorningsupply.com TERMS OF USE PRIVACY NOTICE COOKIE POLICY DO NOT SELL OR SHARE MY PERSONAL INFO LICENSING FAQ ACCESSIBILITY PLATFORM STATUS HOW WE RATE AND REVIEW PRODUCTS CONTACT TIP US COMMUNITY GUIDELINES ABOUT ETHICS STATEMENT THE VERGE IS A VOX MEDIA NETWORK ADVERTISE WITH US JOBS @ VOX MEDIA © 2023 VOX MEDIA, LLC. ALL RIGHTS RESERVED",
    "commentLink": "https://news.ycombinator.com/item?id=37528453",
    "commentBody": "The first week of US v. Google – Defaults are everything and nobody likes BingHacker NewspastloginThe first week of US v. Google – Defaults are everything and nobody likes Bing (theverge.com) 166 points by mgreg 14 hours ago| hidepastfavorite138 comments AlbertCory 10 hours ago> Schmidtlein has derided the excerpts as cherry-picked and “out of context.”\"out of context\" is the standard BS answer to anything. \"What context, exactly, is missing?\" should be the followup question.Odd that they don&#x27;t mention that Sridhar Ramaswamy is not merely the \"founder of Neeva\" but he was head of Google AdWords for almost 10 years! I guess you can&#x27;t expect these reporters to read their own site.https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;5&#x2F;20&#x2F;23731397&#x2F;neeva-search-eng... reply bawolff 9 hours agoparent> \"out of context\" is the standard BS answer to anything. \"What context, exactly, is missing?\" should be the followup question.Quoting things out of context is also the standard BS way to smear someone. In any case, i agree that the person asking the questions should expect this response. If they&#x27;re prepared for that response and the quote really wasn&#x27;t taken out of context, it shouldn&#x27;t be too hard to make the person using it look like an idiot. reply AnthonyMouse 9 hours agorootparentThe problem with all of this is that it&#x27;s a performance.Google does something actually anti-competitive, but it&#x27;s subtle and requires a thorough understanding of industry dynamics to fully understand. But one of their employees said something that sounds bad, so guess what the headline is.Whether the quote was taken out of context or not isn&#x27;t even the interesting question, because it&#x27;s independent of whether they&#x27;re actually doing something wrong.The quote could be completely in context and the employee was a fool who didn&#x27;t know what they were talking about, or it could be completely out of context even though they actually did the bad thing. reply Aunche 6 hours agorootparentWhat exactly is so hard to understand? It&#x27;s a well known fact that they pay to be the default search engine. Either that&#x27;s against the rules or it is not. It sounds like the DOJ doesn&#x27;t want to be blamed for any potential negative consequences for establishing clear rules, so instead they&#x27;ll bully Google into settling so that they can get an easy win. reply bell-cot 3 hours agorootparent> Either that&#x27;s against the rules or it is not.If the rules were actually that simple, the world would need far fewer lawyers.But - whether you say \"rules that simple can&#x27;t work when the world is vastly more complex\", or \"rules-writing lawyers aren&#x27;t stupid enough to write their own kind out of their jobs\" - the rules are definitely not that simple. reply AnthonyMouse 6 hours agorootparentprevThe Department of Justice isn&#x27;t a rulemaking entity, it&#x27;s the federal prosecutor&#x27;s office. The antitrust laws we have are quite old and passed during the era of robber barons in order to do something about them, with extremely broad language that by its terms would prohibit not only anything you might like them to but a lot of things you might not.The result is that the courts get to make something up about when they apply, and have made a bit of a mess of it.Sure, it says, \"Every contract, combination in the form of trust or otherwise, or conspiracy, in restraint of trade or commerce among the several States, or with foreign nations, is declared to be illegal.\" But that doesn&#x27;t mean Sprint can&#x27;t merge with T-Mobile. Or maybe it does. Anybody have a coin to flip?What the DoJ can do is dump a bunch of allegations into an indictment and hope some of them sound plausible enough to induce a settlement. Which will ideally actually promote competition and not be some political quid pro quo. reply dragonwriter 5 hours agorootparent> The Department of Justice isn’t a rulemaking entityYes, it is. [0]> it’s the federal prosecutor’s office.That is among its functions, yes.> The antitrust laws we have are quite old and passed during the era of robber barons in order to do something about them, with extremely broad language that by its terms would prohibit not only anything you might like them to but a lot of things you might not.Among the antitrust laws we have are:* the Antitrust Criminal Penalty Reform and Enhancement Permanent Extension Act (2020); whose main effect was, as the names suggests, to make permanent the provisions of the Antitrust Criminal Penalty Reform and Enhancement Act (2004).* the Criminal Antitrust Anti-Retaliation Act (2020)* the antitrust provisions of the Competitive Health Insurance Reform Act of 2020 (oddly enough, 2021)Some of our antitrust laws were written in the so-called “age of robber barons”, but antitrust law (even purely statute law) hasn’t been static since.[0] for illustration, https:&#x2F;&#x2F;www.justice.gov&#x2F;opa&#x2F;pr&#x2F;justice-department-advances-p... ; you probably mean, though, that its not the rulemaking entity with regard to competition, since that’s mostly the FTC. reply AnthonyMouse 5 hours agorootparent> you probably mean, though, that its not the rulemaking entity with regard to competition, since that’s mostly the FTC.I actually wasn&#x27;t aware that they issued rules at all and now that I know that they do I kind of wish they would stop.Sometimes we separate government functions for a reason.> Some of our antitrust laws were written in the so-called “age of robber barons”, but antitrust law (even purely statute law) hasn’t been static since.It&#x27;s not that Congress hasn&#x27;t passed a law since then, but I believe they&#x27;re being accused of violating[0] the Sherman Anti-Trust Act of 1890.[0] https:&#x2F;&#x2F;www.justice.gov&#x2F;d9&#x2F;2023-09&#x2F;416366.pdf reply dragonwriter 2 hours agorootparent> It&#x27;s not that Congress hasn&#x27;t passed a law since then, but I believe they&#x27;re being accused of violating[0] the Sherman Anti-Trust Act of 1890.All three of the “core” anti-trust laws (the Sherman Act, the Clayton Act of 1914, and the FTC Act of 1914) have been amended several times since by later acts. They aren&#x27;t ancient relics that haven&#x27;t been reconsidered and adjusted based on experience and changing conditions. reply AnthonyMouse 1 hour agorootparentI feel like the problem with them is actually the modern courts rather than the old law. These rules were meant to have teeth, but they&#x27;re also targeting entities that by their nature have power, and then you&#x27;re consistently going to have trouble with vigorous enforcement being debased through political influence.What we need is something that prevents market concentration to begin with rather than trying to claw it back once it&#x27;s already entrenched. reply nickserv 12 minutes agorootparentConsolidation of power has been happening at least since the agricultural revolution 10000 years ago.Doesn&#x27;t mean we shouldn&#x27;t try to limit it, and there have been periods of relative equality. Just that it&#x27;s always going to be a battle, there isn&#x27;t something we can do to change this behavior once and for all. AlbertCory 4 hours agorootparentprevSo you think there&#x27;s an automatic sunset on all laws? News flash: there isn&#x27;t. reply AnthonyMouse 4 hours agorootparentThe problem is that it was written to smash trusts to smithereens but has had a century of being eroded by well-funded monopolists with expensive lawyers.If it was working the way it was supposed to, none of these companies would be this big. reply AlbertCory 4 hours agorootparentprevThere are entire books and law review articles written about antitrust law since the Sherman Act. Maybe you&#x27;ve read some of them?Being \"quite old and passed during the era of robber barons\" is not quite the killing argument you think it is. The 13th Amendment is even older. So is Marbury vs. Madison. reply unyttigfjelltol 2 hours agorootparentprevAs has been said so many times on HN, individual users of Google resources are not the customer, they are the product. Browser defaults are an annoying way that Google exerts pressure on everyone to be their product, but I&#x27;m more annoyed by their stupid Captcha API integrated into many pages Google has no business monitoring.I feel harmed every day being coerced to be an unwilling and unhappy product of Google&#x27;s adtech leviathan. I don&#x27;t know what that means for this particular case, but hopefully Google gets the message and builds a better off-ramp. reply nonrandomstring 9 minutes agorootparent> I feel harmed every day being coerced to be an unwilling and unhappyYou are harmed. The question now is how to obtain remedy for that objective harm and injunction against further actual harms. reply tiffanyg 8 hours agorootparentprevI would suggest that since this is a court case, the rhetorical &#x2F; commentary-like (aspects of) statements made by the attorneys in court will (especially at this level) almost certainly be &#x27;parsed out&#x27; in facts.You&#x27;re both right that this kind of language is used non-stop by people in certain roles today - especially politicians. Of course, that has always been the case in politics at any point in history I have any real knowledge about. In a courtroom, there are some real differences.First, certain types of statements may be considered impermissible, and challenges are possible in various forms during various phases of a trial or hearing. Further, people who work in these environments tend to acquire a sort of \"rhet-dar\" (and a rather explicit form) that too many who don&#x27;t get this kind of &#x27;practice&#x27; every (work) day don&#x27;t. And, of course, instructions can be provided to juries to disregard certain statements &#x2F; evidence depending on challenges &#x2F; various issues with something brought into a legal proceeding. Finally, at actual decision time, while rhetoric can influence, whether the decision is made by a judge or jury, the emphasis will be on facts, laws, interpretations of laws, etc.Fluff rhetoric like \"out of context\" in an opening statement is quite empty, especially by the time a proceeding is wrapping up. Always makes a good sound bite for the external world though.I can&#x27;t personally be much more specific since my own legal experiences (of various types) have been ad hoc and infrequent. I considered pursuing a degree several times, never did. In particular, anyone reading would be right to not consider this in any way an authoritative comment. I will provide one ref though that has some pretty good additional info from what I had a chance to skim when looking for a bit more to give y&#x27;all. I&#x27;m sure there are others here far more expert than I, perhaps one will flesh things out better than I may have - but, giving at least a sense of the role that that kind of journalist-bait might play in an actual legal proceeding seemed worth something...https:&#x2F;&#x2F;law.temple.edu&#x2F;aer&#x2F;2019&#x2F;03&#x2F;23&#x2F;opening-statement-v-ar... reply photonthug 5 hours agorootparentSigh, it&#x27;s bad enough listening to lawyers play at this game of rigor&#x2F;formality&#x2F;objectivity, so it&#x27;s even more tiresome to listen to others make their excuses&#x2F;apologies for them. Lawyers and judges ARE politicians, not some scholars or scientists, and our courts do a bunch of batshit arbitrary stuff every day. Appealing to facts and \"words mean things\" and defending the profession as even meaningfully skilled, much less noble, seems silly these days when you take a look at most stuff in the real world. Roe v Wade comes to mind here- there&#x27;s no esoteric and learned moral calculus going on, and we see that precedent matters only up until it does not. Judges invent the rules and ignore them when convenient. At least the other opinion engineers and spin doctors in society aren&#x27;t as hypocritical about it. The outcome of this case is probably already decided, and the rest is theater.. reply AlbertCory 4 hours agorootparentEverything is politics, then, you&#x27;re saying?Funny, because even Hammurabi thought it was worth writing down what was legal and what was not, so people would know. reply AlbertCory 8 hours agorootparentprevSo what is the \"context\" on this? reply hn_throwaway_99 8 hours agoparentprevI don&#x27;t really agree with that - I&#x27;ve seen plenty of things that have been taken out of context, and portrayed actions in a really false light. It&#x27;s really not hard to take some off the cuff email or Slack remark and present it as something like official company policy.More importantly, though, I think anything a company says internally should be 100% irrelevant in an antitrust case. It&#x27;s like the famous advice parents should give their kids when it comes to relationships: \"Just ignore everything a potential partner says, and only focus on what they do.\"I mean, it&#x27;s not like corporations need to have any sort of \"mens rea\" to be found a monopoly abuser. IMO all that should be evaluated are the actual actions a corporation took to stifle competition. I don&#x27;t really see why internal communications are relevant at all in these trials. reply willsmith72 7 hours agorootparentdon&#x27;t agree at all, internal communications are absolutely relevant reply hn_throwaway_99 7 hours agorootparentCare to explain why? When evaluating whether a company has abused its monopoly, why isn&#x27;t it enough to simply look at its actions?To be clear, I don&#x27;t feel this way to give companies a break. I feel this way because whatever employees were thinking behind the scenes shouldn&#x27;t matter. If a company locks up the defaults on pretty much all browsers, why isn&#x27;t that fact alone enough to come to a conclusion? reply mongol 6 hours agorootparentOn some level, I don&#x27;t think a company has actions. Everything a company does are effects of what their employees do. Then it boils down to, is the action of an employee sanctioned by management? This you can only tell by looking at the internal communication. reply edgyquant 4 hours agorootparentEverything a human does are the effects of what its cells do. This logic doesn’t hold, we treat the entity as an entity and acknowledged that it’s intentions are often beyond the scope of its individual parts. Just as the grouping of cells have goals independent of any one, so does a group of men. reply mongol 3 hours agorootparentYes it is a legal entity, but it does not have own motives. It is just a vehicle for human activities. You can&#x27;t call a company to the witness stand, and you can&#x27;t put it in jail. Even if you could, it would not suffer. reply rapind 7 hours agorootparentprevI imagine it has to do with intent and willfulness.Not sure if that’s relevant or not in a monopoly case though. reply patmorgan23 5 hours agorootparentprevIntent(like possession) is 9&#x2F;10ths of the law. reply FireBeyond 4 hours agorootparentI believe the original was “possession is 9 points of the law” and over time it has been bastardized into “nine tenths”. reply AlbertCory 6 hours agorootparentprevsince Discovery is used in almost all civil and criminal actions:You&#x27;re proposing abolishing it but only in antitrust cases? reply netheril96 5 hours agorootparentThe materials found during discovery are not always relevant. You can discover all of them, but then some of them shouldn&#x27;t be presented to the court or jury. reply delecti 6 hours agorootparentprev> I&#x27;ve seen plenty of things that have been taken out of context, and portrayed actions in a really false lightAnd in those situations, the answer to \"What context, exactly, is missing?\" would be exculpatory. If it is out of context, the context would demonstrate that. If it&#x27;s as damning as it seems, then \"you&#x27;re taking that out of context\" will be demonstrated to be BS when context is provided. reply lazide 5 hours agorootparentAnd LA didn’t burn after the Rodney King verdict?A lot of people don’t bother before deciding, despite the procedures. reply ekianjo 5 hours agoparentprev> \"out of context\" is the standard BS answer to anything.You are completely wrong on this one. People routinely take things out of context on purpose to defame others. Thats so common I am surprised you can make the opposite claim. reply AlbertCory 4 hours agorootparentI&#x27;ve asked in a bunch of places here \"what IS the &#x27;context&#x27;, then?\" No one has an answer. reply murderfs 1 hour agorootparentWhy do you expect anyone here to answer you? You&#x27;re not the judge, and presumably no one posting in this thread is an attorney representing Google in this case. reply AnthonyMouse 8 hours agoprevI have to say I&#x27;m disappointed with the focus on defaults here. Defaults are important, but they&#x27;re also mostly a bidding war. It&#x27;s not like Microsoft has no money.The real issue is the tying. They build this conglomerated system that all comes together as one blob, and get third parties to depend on various parts of it to prevent them from being swapped out individually. Then to replace one of them you have to be able to replace the others, which makes it very hard for any but the largest corporations to compete.Capturing the search default on Android is a tiny piece of what they do with it, and the part that would barely make any difference to the search market when the alternative would be that they just pay for it. Or let people choose them, since that&#x27;s the market where they have the strongest brand and it&#x27;s all the ancillary markets that they might not have dominated where the consequences are greater.And then they wouldn&#x27;t have to deal with this:> The question that matters most, though, is whether Judge Mehta can be convinced that consumer harm applies to free products like search engines.Because they could get them for the 30% cut on Google Play.Advertising isn&#x27;t a dissimilar tack when you cast the advertiser as the customer, but then you&#x27;re stuck trying to prove that Google wouldn&#x27;t have had a dominant search engine without doing this, when they had one before doing this. reply fallingknife 7 hours agoparent> They build this conglomerated system that all comes together as one blob, and get third parties to depend on various parts of it to prevent them from being swapped out individually. Then to replace one of them you have to be able to replace the others, which makes it very hard for any but the largest corporations to compete.The case doesn&#x27;t focus on this because it&#x27;s not illegal. There are definite benefits to the user in terms of convenience here. And building a product that people want more is not anti-competitive behavior just because it requires a larger company to compete. Anti-competitive behavior is when you get customers by means other than building a product they want more. reply AnthonyMouse 7 hours agorootparentThe entire point is that it isn&#x27;t something the customer wants more, but they get stuck with it because they need a subset of it and it&#x27;s all glued together.This is quite distinct from providing two products together. You can go to the store and buy an entire PC with Microsoft Windows and Microsoft Edge. Then you can install Firefox on it, or remove Windows entirely and install Linux. The trouble comes when you can&#x27;t separate them anymore.Then in order for a competitor, and therefore the customer, to replace the banana the customer wants to replace, and which would otherwise be easy to replace, the competing product also has to replace the gorilla holding the banana and the entire jungle. Which is bad for the customer.And tying is illegal. Typically it was in the context of a company with a dominant market position requiring you to buy products in a related market if you want the product you had to get from them, but now they&#x27;re doing a new thing. Not only can you not buy them separately, you can&#x27;t even separate them after you&#x27;ve bought them -- which should be a violation regardless of what kind of market position you had to begin with, because its primary effect is to harm competition. But this stuff is pretty much invented by judges as they go along, so who knows what they&#x27;re going to do. reply fallingknife 6 hours agorootparentWhat do you mean that you can&#x27;t separate them? Seems to me that \"tying\" has no meaning for free services. You have access to the whole thing, but you are free to pick and choose exactly what parts you use. It&#x27;s one thing when you want a banana that costs $1, but you have to pay $100 for the gorilla&#x2F;banana combo. But if the banana + gorilla is free, then it&#x27;s hard to complain that you are being abused because you got a free gorilla with your banana. reply lozenge 2 hours agorootparentHow the start menu search always uses Bing with Edge? And every couple months you get a new notification or modal welcome screen trying to switch you back to Edge? And they add new features that insist on launching Edge. Oh, and the idea of uninstalling Edge has gone way out of the Overton window.Same with Chrome, you can go without it but you will need to dismiss hundreds of nagboxes on Google sites. reply AnthonyMouse 6 hours agorootparentprev> It&#x27;s one thing when you want a banana that costs $1, but you have to pay $100 for the gorilla&#x2F;banana combo. But if the banana + gorilla is free, then it&#x27;s hard to complain that you are being abused because you got a free gorilla with your banana.A phone is $100 (or $1000) and an app is $1.Or to take it from the perspective of the device OEM, the price isn&#x27;t the money, it&#x27;s having to agree to take the apps and services the customers might prefer alternatives to as a bundle with the services the customers demand you include with your product. Which has market value in the same way as paying for the default search engine does, and could have reduced the price of the device for the end user. Or increased competition for those services (like Google Play) that currently operate with high margins. reply posix86 5 hours agorootparentYou&#x27;re talking about tying things together like Microsoft Word with onedrive etc.? This sounds backwards to me. The \"tying together\" only feels like \"tying\" because you get used to the extent the services interact with each other, which is very convenient, and feel like you&#x27;re unable to change, because you&#x27;re unwilling to let go of those easy ways of interacting with other services.But that doesn&#x27;t make the interaction anti-competitive; it makes them a nice product. It wouldn&#x27;t make sense for MS to allow, say, other clients to MS Word to interact with their cloud, that would be anti-competitive in that they&#x27;re actively shooting themselves in the foot while doing it. I don&#x27;t see why this is a bad thing.And in general, the fact that we&#x27;re even converging from multiple services towards one is purely historical. The reason MS word & excel are two separate programs rather than one is due to the tech landscape on the past. Google Docs or Notion or Coda are all supersets ot Word vs Excel, using newer tech & hardware to provide a more unified experience, which IS in the interest of the user. reply AnthonyMouse 4 hours agorootparent> The \"tying together\" only feels like \"tying\" because you get used to the extent the services interact with each other, which is very convenient, and feel like you&#x27;re unable to change, because you&#x27;re unwilling to let go of those easy ways of interacting with other services.The tying together is tying together because you can sensibly separate them and the customer might like to use Microsoft Word with Google Drive or LibreOffice with OneDrive.> It wouldn&#x27;t make sense for MS to allow, say, other clients to MS Word to interact with their cloud, that would be anti-competitive in that they&#x27;re actively shooting themselves in the foot while doing it.It would be anti-competitive in that it would make it easier to compete with them?> Google Docs or Notion or Coda are all supersets ot Word vs Excel, using newer tech & hardware to provide a more unified experience, which IS in the interest of the user.The problem with the \"unified experience\" argument is that it only justifies putting them together, not inhibiting the customer from separating them. If the \"unified experience\" is actually in the interest of the customer then they&#x27;ll choose it even when the alternative is available. reply fallingknife 4 hours agorootparent> The tying together is tying together because you can sensibly separate them and the customer might like to use Microsoft Word with Google Drive or LibreOffice with OneDrive.They might like to, but those options are just not available in the market, and that&#x27;s not an anti-trust issue. I might like to have a Tesla with Apple Car play. I might like to have Ford Ranger with an engine made by Toyota. But these companies are under no obligation to satisfy my desires. I am free to make those combinations happen at great inconvenience to myself, but those companies are in no way expected to help me do that. reply AnthonyMouse 1 hour agorootparentThe issue is not the inconvenience unless they took action to make it inconvenient on purpose. It&#x27;s when they do take action to make it inconvenient on purpose, or prohibit it through contracts or DRM. replyhughesjj 6 hours agorootparentprevMy 2c is that banning products from competing app stores or forcing the same price on your platform is definitely anti competitive reply ralph84 10 hours agoprevIt’s all so ridiculous. Microsoft got nailed for talking about beating the competition. They’re trying to nail Google for training employees to not talk about beating the competition. What is competition supposed to be if it’s not beating the competition.Just have extremely progressive taxation on companies as they get larger and stop approving megamergers if you believe large companies are harmful. reply AlbertCory 10 hours agoparentThey are not being prosecuted for \"training employees to not talk about beating the competition.\" They&#x27;re being prosecuted for restrictive deals on the search engine default, which prevents competition from gaining the data they need to compete. Udi Manber himself said that&#x27;s what they&#x27;re for.The training bit: personally I think it&#x27;s a mistake for the government to dwell on that too much. It would be nice if they had a smoking gun email about \"cutting off their oxygen,\" but they don&#x27;t, so move on. Explaining why you don&#x27;t have the smoking gun is something you should do only in passing. reply edgyquant 10 hours agoparentprevI don’t think “progressive tax on companies as they get larger,” would be at all helpful. For one thing companies can skirt this with subsidiaries but also there are capital intensive industries where such a system could punish the average company. I agree they shouldn’t allow mergers, this should be very rare and there should have to be a very good case for it, but also just breaking up companies should be a lot more normal.I also agree there has to be some kind of answer based on company profit, but I think that taxation is not the best answer. It would be much better if there was a way to funnel that money into R&D at other companies and even industries; but admittedly I have no idea how such a system would work or if it’s even possible. Just sounds good in my head. reply wayfinder 10 hours agoparentprevThe government isn’t pursuing this because of the language. It’s because they think Google legitimately did anti-competitive things.They took down Al Capone not because of the tax evasion but rather because he was a crime lord. Tax evasion was merely the means to the end. reply yjftsjthsd-h 10 hours agoparentprev> What is competition supposed to be if it’s not beating the competition.It&#x27;s supposed to be fair. Microsoft didn&#x27;t get nailed because they were winning, they got nailed because they were winning by abusing one monopoly to try and create another. reply lazide 9 hours agorootparentBwahaha. Since when is business, or hell life in general fair?Maybe ‘not doing illegal things’ should be the bar? At least they’re written down in advance (hopefully) instead of retroactively defined by folks who didn’t win? reply yjftsjthsd-h 8 hours agorootparent> Maybe ‘not doing illegal things’ should be the bar? At least they’re written down in advance (hopefully) instead of retroactively defined by folks who didn’t win?...yes, allow me to introduce you too this little thing called the Sherman Antitrust Act, which has been the law for ~130 years. reply lazide 7 hours agorootparentOh that I had no issues with, as you see in my comment history. That’s not what the parent poster I was responding to was implying though. reply yjftsjthsd-h 7 hours agorootparentYou replied to me; what did you think I was implying? reply lazide 6 hours agorootparentThat you first led with if it was fair or not, then tacked on the law as a penalty for it not being fair (seemingly in your opinion, as you provided no particular specifics).Which is what you wrote.As it’s hard to find a company that doesn’t at least attempt tactics like this named in the complaint (or much worse), it seemed to leave the implication clear.They deserved to have the law applied because you felt it was unfair. reply AlbertCory 9 hours agorootparentprevWhat is being \" retroactively defined\"? And how much about antitrust law do you know? reply AnimalMuppet 9 hours agorootparentprevWell, yeah, that was exactly it. It&#x27;s not that Microsoft was unfair, it was that Microsoft was unfair in ways that were illegal under the current law. reply flangola7 8 hours agorootparentprev> Bwahaha. Since when is business, or hell life in general fair?The entire purpose and objective of the law is to make society just and fair. It is far from perfect, but it is well superior to the selfish mayhem you speak of.Laws are also not retroactive. reply lazide 7 hours agorootparentHo man. Have you ever actually sat in a court room before?Or been involved in cases?This is so far from the actual application of the law it’s hilarious.The purpose of the law is keeping problem cases under control, providing a degree of predictability necessary for social stability, and mediating disputes in a way they don’t escalate into socially disruptive violence.‘Keeping the peace’.All the rest is window dressing&#x2F;PR.The reason why Google is getting this case thrown at it is not because what it was doing was unfair - but because they were too damn good at doing it.If they went bankrupt trying or it didn’t work, no one would care. Same if they were only middling successful (but didn’t get so obscenely rich and high profile off it). There are hundreds of examples of this right now in a number of industries, from meat packing to RAM, that will continue to be ignored.And because they’ve been so good at it, it’s stirring up a lot of anger and resentment that will cause problems. So they need to be “brought back under control”. Just like Microsoft was back in the day.We’ll see what happens. reply hot_gril 8 hours agoparentprevAbout the training: Suppose GCP or Gmail accidentally steps on the toes of a user who happens to compete with Google in some other way, and during some anti-competition lawsuit&#x2F;hearing, they dig up a message between employees dissing that particular competitor. Maybe things like \"let&#x27;s make X feature better than Y company\" are fine, but it can easily slide to less innocent-looking things. reply tennisflyi 10 hours agoparentprev> What is competition supposed to be if it’s not beating the competition.Wrong question. How about “how can we make our product&#x2F;service better”? Not, let’s just push the other company over. reply SpicyLemonZest 9 hours agorootparentIt doesn’t really seem like there’s any evidence for a story where Google went out of their way to destroy any competing search engines. The worst thing the article references is an engineer who argued that search engine quality is directly proportional to search volume, which if true would imply that making Google better necessarily implies other search engines will be worse. reply AlbertCory 9 hours agorootparentWrong. The assertion is, they got the volume by buying it, not by becoming better. reply BytesAndGears 9 hours agorootparentprevI think paying Apple and Mozilla to be the default search engine, as well as within Chrome, counts as intentionally crippling other search engines.If Apple made them default because they’re the best, then that’s fine. But spending a ton of money to keep themselves as the default, when they already have the vast majority of market power, seems like an artificial barrier to competition.Unless another search engine is so much better that Apple is willing to forfeit billions of dollars of pure profit, then nobody else has a chance to be the default. reply karpierz 8 hours agorootparentApple made them the default because they are the best at monetization of large volumes of search queries from iOS devices. If another company was better at it, they&#x27;d put in a higher bid and rake in the profits. reply Regnore 8 hours agorootparent> If another company was better at it, they&#x27;d put in a higher bid and rake in the profits.The point is that there is no world in which any other company can outpay Google, regardless of whether or not they are better at search. reply pgeorgi 3 hours agorootparentI&#x27;m not sure if \"outpay Google\" is necessary for that. Apple and Google are competitors, in some aspects this seemed almost personal (Steve Jobs mentioned \"thermonuclear war\", see https:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;ewanspence&#x2F;2015&#x2F;01&#x2F;31&#x2F;how-apple...)Another search engine that is 90% there and can offer only 10% of payments might have been good enough (at least in a certain time frame) if it gave Apple an opportunity to snub Google. reply ummonk 8 hours agorootparentprevThey aren’t specifically trying to kill other search engines though. They’re just trying to acquire more users, by being the default service. reply fallingknife 7 hours agorootparentprevThat makes a strange legal argument, though. You can&#x27;t say that Apple putting the default up for bid is anti-competitive behavior by Google. So would you say that Google can&#x27;t bid in the auction because that in itself is anti-competitive? That also seems like a tough legal argument to make (though I am not an expert on this) because it means that basically everybody is allowed to be in the auction except for Google.You could definitely say it was anti-competitive if Google was paying more than they earned from this search traffic. But I seriously doubt they are doing that. replycandiddevmike 10 hours agoprevSurprised there&#x27;s not much coverage on this on HN. I suspect this is the first of many legal cases against the tech empires, and if this goes south you may be able to conclude the rest will as well.How much power and influence can Google buy (absolute best attorneys, call in favors...) vs the power of the US government? If the US government can&#x27;t do anything, what does that mean? reply gochi 10 hours agoparentIt&#x27;s a monumental case, but hard to get people to care without intense clickbait and there hasn&#x27;t been much that can be used as clickbait. reply nazgulsenpai 9 hours agoparentprevSome of us lived to see Microsoft be found to be in violation of antitrust statutes and forced to break up only for them to become the behemoth they are today. Its hard to get excited about the Google since its already been proven with enough power and influence, not too much of this matters a whole lot.I&#x27;m optimistic but quite jaded. reply bawolff 9 hours agorootparentBesides everyone else pointing out that they werent forced to break up - i think the more saliant point is they aren&#x27;t the behemoth they once were.Maybe its chance or maybe it really did work, but MS is not the evil monopoly it once was. Still very succesful but not a monopoly. reply safety1st 7 hours agorootparentIt worked. The lawsuit had a tremendous impact on Microsoft&#x27;s culture and had them running scared from the government for years. It made them less ambitious, more bureaucratic and reluctant to just buy up any Internet startup that posed a threat. Source: I was working there at the time. reply umanwizard 9 hours agorootparentprevMicrosoft was never forced to break up, they just had to change some of their business practices. reply AlbertCory 8 hours agorootparentto be pedantic: the trial judge did order a breakup. On appeal, that penalty was struck down. reply CSMastermind 6 hours agorootparentWhich is honestly a shame. Even as a budding software engineer I didn&#x27;t really understand the Microsoft anti-trust case at the time. It&#x27;s only now that I appreciate the problem and do think it would have been better for everyone, Microsoft included, had they been broken up. reply Retric 8 hours agorootparentprevThat’s the joke. reply Aunche 8 hours agorootparentprevIt wasn&#x27;t exactly intentional but the results were great for competition. They were forced to invest in Apple and to stop bullying them, and now Microsoft is completely dominated by them in terms of personal computing. reply AnimalMuppet 9 hours agorootparentprevMicrosoft was forced to limit their behavior. I don&#x27;t recall them being forced to break up.Did I miss something? reply dmoy 7 hours agorootparenthttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;United_States_v._Microsoft_C....> On June 7, 2000, the District Court ordered a breakup of Microsoft as its remedy.Then> Ultimately, the Circuit Court overturned Jackson&#x27;s holding that Microsoft should be broken up as an illegal monopoly. However, the Circuit Court did not overturn Jackson&#x27;s findings of fact, and held that traditional antitrust analysis was not equipped to consider software-related practices like browser tie-ins. reply majormajor 6 hours agoparentprev> If the US government can&#x27;t do anything, what does that mean?It means the US people would need to - if they wanted to - pass new laws specifically to target tech company&#x27;s anti-competitive behaviors because they aren&#x27;t exactly the same thing as what was being done by the companies the laws originally targeted.I&#x27;m not convinced there is broad >60% popular support for expanded antitrust laws, so you&#x27;d really have to start with that in terms of what it means. reply AlbertCory 10 hours agoparentprevIt&#x27;s not very dramatic, so far. Compare to David Boies making Gates look like an arrogant little dweeb, as he did in 1998. reply ndesaulniers 9 hours agorootparentGot a link? reply AlbertCory 8 hours agorootparentJust search YouTube. They&#x27;re all there. reply tiffanyh 7 hours agorootparentPlot twist, you have to use a Google product to find & watch the video. reply Mistletoe 7 hours agorootparentprevGates looking like an arrogant little dweeb will have a lot of results. reply patmorgan23 5 hours agorootparent\"Bill gates Microsoft anti trust deposition\" reply AlbertCory 6 hours agorootparentprevso you need instructions on how to search? reply Mistletoe 1 hour agorootparentI’m sorry, it was just a joke. replyThrowawayR2 6 hours agoparentprevThere are a lot fewer FOSS diehards and old school hackers than there were in 2001. And those that are still around are not going to be that anxious to admit that their darling Google, their ally and great hope for destroying \"M$\", turned out to be an even more heinous monopolist than them. reply rvz 8 hours agoparentprevLooks to me that Googlers reading the news of this are quite concerned about their employer being held to account for not only their monopolistic actions, but as a result of that and retaining 90% of the market share, also having virtually close to no serious competition to challenge their monopoly.It appears that this is the beginning of the end of the big tech party. reply daft_pink 8 hours agoprevI would love to switch search engines, but no matter what when I switch my browser to bing or duckduckgo, I always find myself back at google.Especially recently as with their anti-privacy policies, I would really prefer to use a different service, but they really are the best. reply lolinder 8 hours agoparentI can second Kagi. Paid search is the only model that isn&#x27;t going to end up awful in the end, and Kagi is far better than Google already.Recently discussed on HN is the feature to block and boost domains, which is the feature I find makes the biggest difference in their results:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37006082 reply Spivak 8 hours agorootparentI don&#x27;t think free&#x2F;paid is the thing that will stop the decline because the downfall is adversarial input. If Kagi got huge people would start trying to SEO against them and they would end up like Google. Because I really don&#x27;t think Google is bad because of the ads, it&#x27;s bad because people desperately want their shitty site to be the first organic result rather than pay for the ad spot.Having a huge behemoth that competitors like Kagi can fly under the radar with might be the only way for any search engine to maintain quality. reply lolinder 8 hours agorootparentIt&#x27;s mostly an academic exercise since paid search will always be small, but I think both ads and SEO are at fault here.Google profits from ad impressions and ad clicks. That is what they&#x27;re incentivized to maximize, which means that for Google the ideal mix of search results is a few high quality ads on top of a lot of pages that are loaded with Google advertising. Far from having an adversarial relationship with SEO content farms, Google is symbiotic with them: the more time people spend on the content farms, the more ad impressions Google gets to sell. If the content farm doesn&#x27;t actually answer the user&#x27;s query and they return to Google for another round of first party ads, all the better.They only need to provide relevant enough searches to keep people from trying a different search engine, which as we&#x27;ve seen isn&#x27;t difficult. reply freediver 8 hours agorootparentprevWhat would be an adverserial tactic against Kagi and its business model? What would be the motive? reply CSMastermind 6 hours agorootparentPresumably the same as it is for Google?SEO spam doesn&#x27;t exist because Google sells ads. SEO spam exists because there&#x27;s money in getting people to visit your site and Google is the largest search engine.SEO spam is also something Google themselves are already generally incentivized to eliminate. It&#x27;s not like their ad model does better if users lose faith in their results. reply squeaky-clean 4 hours agorootparentprevMake a ton of test websites to try and reverse engineer how Kagi ranks websites, and then prioritize that over actual good content. The same way people manipulate Google results through SEO.I&#x27;ve been at a job where we did this with Google. We had about 20 websites and 40 ad campaigns on adwords for fake companies where you could buy used dirty dishes. We wanted a topic that would have zero real-world results aside from us so we could easily compare our hypotheses and someone suggested pre-dirtied dishes. It was hilarious and had almost no search results so we went with that.Strangely enough after a few weeks we noticed eBay and Amazon were buying the top ad slot for those queries. They probably had some automated way of tracking new trending Google search keywords matching \"Buy ____\" or \"____ for sale\".Seeing \"Amazon is the best place to buy Dirty Dishes\" as a top ad was also hilarious. In fact if you Google \"Buy Dirty Dishes\" right now, Etsy is the top result. \"Check out our dirty dishes selection for the very best in unique or custom, handmade pieces from our dining & serving shops\"We took our findings from that \"research\" and applied them to our real customers websites. reply gwd 2 hours agorootparent> I&#x27;ve been at a job where we did this with Google. We had about 20 websites and 40 ad campaigns on adwords for fake companies where you could buy used dirty dishes. We wanted a topic that would have zero real-world results aside from us so we could easily compare our hypotheses and someone suggested pre-dirtied dishes. It was hilarious and had almost no search results so we went with that.But... is that manipulation or genuine optimization? I mean, if there were people who wanted dirty dishes, and you were selling them, then helping Google help dirty-dish searchers find you is making Google better (and overall making the world a better place).SEO is a problem when it causes mediocre, crappy, or completely irrelevant sites to be promoted over actually good sites. replypdlozano 8 hours agoparentprevThe nice thing about DDG is that you can always use !g to go to Google. But even after using them for years, I still find myself using !g 30-40% of the time. reply pcurve 7 hours agoparentprevme too. Google search result is low quality, but the overall quality of searchable text content has declined. I do most of my information search on Reddit or Youtube.However.Lately, I&#x27;m enjoying the integration of the generative AI at the top of the search result. reply dustingetz 8 hours agoparentprevkagi.com reply iamacyborg 2 hours agoprevI’m currently reading Michael Lewis’ New New Thing and it’s interesting contrasting this reporting with the reporting in the book of the US vs Microsoft case. An excerpt of which can be read here https:&#x2F;&#x2F;slate.com&#x2F;news-and-politics&#x2F;1998&#x2F;10&#x2F;the-microsoft-tr... reply mkoubaa 10 hours agoprevBing and Google search are equally awful at finding what I need and I hope they both become irrelevant. reply endisneigh 9 hours agoparentWhy do you hope they’re irrelevant? I hope they become better reply lxnn 8 hours agorootparentI hope they are out-competed by a better alternative. reply owlninja 6 hours agorootparentAnd we strike them down for being too good? reply geraldwhen 9 hours agorootparentprevThey get worse as time goes on. I’ve never seen them get better. reply gsich 9 hours agorootparentprevSeeing at how non-tech people use Google I doubt that.Also cancerous SEO sites (with affiliate links) pop up all the time if you search for product info or comparison. reply romusha 10 hours agoparentprevYep. These days I use multiple tools to find what I need reply seeknotfind 10 hours agoprevEven though Bing was made the default search for Windows start menu, I don&#x27;t use it much. reply Galanwe 10 hours agoparentYou should start your comment with \"As a top 5% computer-literate HN reader\".To my parents, double clicking on \"Internet Explorer\" means \"opening the internet\". reply seeknotfind 9 hours agorootparentTaking this to mean, Bing has still achieved significant market share via start menu integration. Yeah. reply lucb1e 10 hours agorootparentprevI sure hope not. What OS version are they running?! reply psunavy03 9 hours agorootparentThis is not unusual; my 70-something dad still runs an ancient Windows 7 machine. reply Tyr42 6 hours agorootparentprevThat sounds like you&#x27;re prompting an AI there. reply hot_gril 8 hours agorootparentprevChrome&#x27;s market share alone is a lot more than 5%. reply Galanwe 7 hours agorootparentGetting a meaningful market share of browser usage is very hard.First, because most statistics are based on self reported user agent metrics from the top websites. But my parents don&#x27;t go to Reddit, PornHub, YouTube or LinkedIn, etc.Second, culturally speaking, I don&#x27;t think we have accurate reporting of non-western websites. I bet most of China, India and Russia websites don&#x27;t care about reporting their metrics publicly.And last, internet usage distribution is very skewed. I myself probably generate 1000x more internet traffic as my parents, so I probably count as 1000x more market share than them. Yet, in terms of \"users\", I would count the same as they do. reply user3939382 6 hours agoprevThe result I want is that Chromium becomes an independent foundation with Google having no more than 20% contribution and other major users (Microsoft, Opera, Brave, etc) making up the rest. reply ceva 1 hour agoprevgood job US, imagine google moving its whole business to another country :) reply 1vuio0pswjnm7 6 hours agoprevInteresting that Google has no data on the number of users who switch. Meanwhile it argues \"competition is just a click away.\" reply exodust 1 hour agoprevI want to see Google slapped for being naughty, but this case is weak.Defaults are defaults. What matters to users is choice. The choice is there to use a different search engine. Google widgets can be removed from phones.Much worse is when Big Tech removes choice. Recent example: Microsoft mandating their Authenticator App as MFA, removing other options like SMS. If my workplace doesn&#x27;t pay for my phone, and I don&#x27;t want to install Microsoft crap on my phone, I&#x27;m in a bizarre predicament where I could be locked out of work because I refuse to install Microsoft apps on my personal device. This is wrong, much worse than \"Google paid someone to be the default\". reply sylware 51 minutes agoprevyep, bad defaults are really hard to get rid off once people are used to them.One of the worst: default mass pre-installation on PC of windows. reply adolph 8 hours agoprevDid the DOJ provide evidence that Google paid Microsoft to make Bing terrible? reply lakomen 8 hours agoprevGoogle has turned evil and there&#x27;s not much more to say than break it apart.But don&#x27;t end at Alphabet, continue with Microsoft and Apple, Meta.All evil players. reply nathias 3 hours agoprevGoogle&#x27;s strategy has been obvious for decades, slowly become the infrastructure, make yourself into a dependancy and then start to squeeze out profits. Too bad corporations won and monopolies aren&#x27;t broken up anymore. reply rvz 9 hours agoprev [–] Mozilla is in a rock and a hard place since their #1 revenue source is getting scrutinised with a significant anti-trust suit in decades.We need to admit that not even a new so-called AI tool called ChatGPT could compete and make a dent on Google&#x27;s 90% market share [0] as a &#x27;search engine&#x27; [1]. The new Bing made no significant change to challenge Google [2][3] and Neeva (by former Google employees) believed they could challenge them and failed. [4]No contest on competition since there is little to no competition against Google in search.[0] https:&#x2F;&#x2F;www.similarweb.com&#x2F;engines&#x2F;[1] https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;chatgpt-traffic-slips-aga...[2] https:&#x2F;&#x2F;searchengineland.com&#x2F;new-bing-google-market-share-si...[3] https:&#x2F;&#x2F;www.wsj.com&#x2F;tech&#x2F;ai&#x2F;microsoft-bing-search-artificial...[4] https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;5&#x2F;20&#x2F;23731397&#x2F;neeva-search-eng... reply acdha 8 hours agoparentMozilla is one of the parties most damaged by Google’s anti-competitive efforts, though. If Chrome had to be self-sufficient and couldn’t rely on paid promotion on Google sites, not to mention other Google apps “accidentally” having bugs or performance issues in Firefox, the browser market would be a lot more competitive. Mozilla has already been in a bad place since Google decided to keep them just viable enough to serve as an antitrust defense, breaking the stranglehold would be tumultuous but also the first chance of getting into a better position for the first time in years.I also wouldn’t read too much into Bing’s first AI round. It’s better than Google Bard but neither is trustworthy and the search market isn’t going shift to treacherous chat bots. The general quality of the regular search has been improving, however, and they seem to be getting better at least as quickly as Google is making their service worse. When I’ve done side-by-side comparisons they’re a lot closer than used to be the case - Google updates their index notably faster, but has less spam control and neither is as good as Google was half a decade ago. reply fallingknife 7 hours agorootparentHow can you ban cross promotion, though? It&#x27;s such a common practice across most industries. Chains like CVS put their generic versions right next to the name brands on the shelf, and even have signs that say \"compare to .\" And it would actually be terrible for consumers if that were banned.> Google apps “accidentally” having bugs or performance issues in FirefoxI would bet everything I own that this isn&#x27;t happening. Would not be remotely worth the risk to Google. Besides, these bugs are rare enough and small enough impact that I don&#x27;t even really notice them, and have never considered switching off of Firefox because of them, and I am a software engineer who is much more likely to notice this stuff than 99% of users. reply acdha 6 hours agorootparentRe:cross promotion, I think the big thing would requiring it to be open to anyone and&#x2F;or paid. When CVS says “compare to Tylenol” they still have the name brand right there and don’t pretend their generic is somehow better. The web is different but I think it’d be useful to have a rule that, say, they can’t put Chrome ads in Gmail unless Microsoft can buy the same spot at the same price for Edge ads.> I would bet everything I own that this isn&#x27;t happeningAs a daily Firefox user they’re pretty common - there was a long period where Meet, and only Meet, dropped Firefox calls frequently, GCP would get stuck in a redirect loop at login if you used a browser other than Chrome, etc.I would be surprised if there was a smoking gun “break Firefox” instruction - more that it’s not a testing priority, they jump use Chrome proprietary APIs as quickly as possible and delay switching to the standard versions (like they did with YouTube with that slow web component polyfill), etc. reply lolinder 8 hours agoparentprevMozilla needs to outgrow its dependence on Google anyway—it cannot effectively guard against Chrome&#x27;s monopoly in the browser space while being wholly dependent on Google, any more than Google can be a good search engine while being wholly dependent on ads—the monetary incentives are off.Give me a Firefox subscription and I&#x27;ll pay for it in a heartbeat. reply cmcaleer 6 hours agorootparent> Give me a Firefox subscription and I&#x27;ll pay for it in a heartbeat.I want to do this but I can&#x27;t support Mozilla until the board stops giving Baker raises at mind-boggling rates and make a commitment to never do anything like acquiring Pocket again, as well as generally make a strategic shift to lessen reliance on one competitor who is obviously massively overpaying them.They need to call Baker&#x27;s bluff about her saying that her compensation (now an eye-watering $5.6MM - $4.8MM of which is bonus for... something[0], I&#x27;m sure she&#x27;s paid even more now) is under market value before she continues her mission of driving Mozilla&#x27;s userbase down so much that the two do indeed match in her eyes. It was extremely obvious how vulnerable Mozilla was by having their primary competitor also be their main source of revenue from the moment Chrome released. It is now 15 years since then and Google are still[1] 75% (!) of their annual revenue.2021 was a decent year for contributions for Mozilla, yet it would take 46 years of 2021-level contributions (excluding all other revenue streams e.g. VPN) to pay for 1 year of 2021-level (after significant layoffs) annual expenses at Mozilla. If we include subscriptions that goes up to a &#x27;measly&#x27; 5.3 years at 2021 levels for 1 year of 2021 expenses. They&#x27;ve got assets, but not enough to keep a 9 figure annual burn rate for more than a few years.I&#x27;m not entirely opposed to their VPN service as a way to generate money, it makes more sense than buying Pocket. What doesn&#x27;t make sense is how they treat security researchers and deal with critical bugs[2], committing the fixes on GitHub before the patch goes live - always a great idea with sensitive applications[3].I still use Firefox sometimes, I still prefer it on my phone, but it&#x27;s clear there&#x27;s a poisonous culture within the company that makes it simply not the company it was in the 00s. I want to see it back to its glory days, but at the moment all it takes is for Google to start the squeeze and it&#x27;ll all be over.I&#x27;m not ready to support Mozilla. I&#x27;m ready to support a Mozilla revolution.[0]: https:&#x2F;&#x2F;assets.mozilla.net&#x2F;annualreport&#x2F;2021&#x2F;mozilla-fdn-990...[1]: https:&#x2F;&#x2F;assets.mozilla.net&#x2F;annualreport&#x2F;2021&#x2F;mozilla-fdn-202... Total revenue $600MM, $450MM figure from https:&#x2F;&#x2F;www.androidheadlines.com&#x2F;2020&#x2F;08&#x2F;mozilla-firefox-goo...[2]: https:&#x2F;&#x2F;www.openwall.com&#x2F;lists&#x2F;oss-security&#x2F;2023&#x2F;08&#x2F;03&#x2F;1[3]: https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;2&#x2F;3&#x2F;22916111&#x2F;wormhole-hack-git... reply amf12 8 hours agoparentprev [–] Neeva also failed because of their business model. Turns out, not many people want to \"pay for search\". reply acdha 8 hours agorootparentThey also did almost no promotion - I’m assuming the plan was to push the product further ahead and then start a big campaign but the VC money drying up killed that. reply ummonk 8 hours agorootparentprev [–] I was disappointed Apple didn’t buy them out to contribute to Siri. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The US government has started an antitrust trial against Google, accusing the tech giant of establishing its search engine market dominance through forceful deals rather than through fair competition.",
      "The case will revolve around Google's practices involving defaults and data usage in maintaining its monopolistic position, and also scrutinize whether these actions are beneficial to the consumers or only serve Google's interests.",
      "The trial will explore the potential harm to consumers and advertisers due to Google's dominance, and the crux of the judge's decision will be determined by whether free products like search engines can indeed cause consumer harm."
    ],
    "commentSummary": [
      "The U.S. v. Google trial investigates whether paying to become the default search engine breaks competition rules, aiming to set clearer guidelines.",
      "Critics suggest that employee statements are being misused, diverting from real anti-competitive practices. Key concerns raised are Google's dominance, a dearth of effective competition, and the consequent impact on other search engines like Bing and Mozilla.",
      "Users express dissatisfaction with current alternatives, voicing a demand for better search engine options. Other discussed topics encompass internet usage, Chromium's independence, and Mozilla's financial viability."
    ],
    "points": 163,
    "commentCount": 136,
    "retryCount": 0,
    "time": 1694808221
  },
  {
    "id": 37525348,
    "title": "How to store a chess position in 26 bytes using bit-level magic (2022)",
    "originLink": "https://www.ezzeriesa.com/index/Writing%20efa7772a3ae64a8193c7ef981ac619fc/Compressing%20chess%20positions%20for%20fun%20and%20profit%20df1fdb5364eb42fdac11eb23b25e9605.html",
    "originBody": "How to store a chess position in 26 bytes using bit-level magic Author's note: This post was adapted from a presentation at the Recurse Center. This excursion started with Nicole Tietz-Sokolskaya’s blog post. I couldn’t help but wonder - is this really the case? Easy mode There are 32 pieces on a chess board. Here we line them up side-by-side. Each piece can occupy one of 64 squares. Let’s denote each piece by a number between 0 and 63 to represent the respective square. Since each position takes up 6 bits ( 2 6 = 64 2 6 =64), multiplying 6 bits by 32 pieces gives us 192 bits / 24 bytes (1 byte = 8 bits). Not so fast Of course, it’s rarely that simple [1]. Captures In addition to positions, we need to keep track of captured pieces as these pieces do not appear on the board. Castling availability We need to track if castling is available on the king’s side, on the queen’s side, or both. In particular, castling is not permitted if the king or the rook has previously moved. En passant target The en passant capture is permitted on the turn immediately after the opposing pawn makes the double move. The capturing pawn moves to the square behind the opposing pawn; this square is called the en passant target. Promotions A promotion takes place when a pawn makes it to the final rank, and is then replaced with a knight, bishop, rook or queen. We can track captures with a bitmap of 32 bits, each bit representing a piece. We can similarly use bitmaps for castling availability and en passant targets with 4 and 16 bits respectively (1 bit for each rook and 1 bit for each pawn) [2]. Promotions take a bit more space. For each pawn we need 3 bits: 1 bit for whether or not its been promoted, plus 2 bits for what piece its been promoted to. That’s 48 bits altogether. In summary: 🔴 1 bit x 32 (for captures) + 1 bit x 4 (for castling) + 1 bit x 16 (for en passant) + 3 bits x 16 (for promotions) = 100 bits / ~12 bytes Can we do better? No two pieces occupy the same square The first observation is that no two pieces can occupy the same square on the board. We can apply this to captures by using the opposing king’s position to represent the capture of that piece. Adam Kelly noted how we can take this further by using our own king’s position. For castling, we simply replace the rook’s position. Since castling is available only if the rook has not moved, we know that the rook would be at its original position. For en passant, we know that the pawn that just made the double move is at its home file and at a specific rank (4 for white or 5 for black). We similarly replace the pawn’s position with our own king’s position. By using this trick, we can store captures, castling availability and the en passant target for free! 🟡 free! (for captures) + free! (for castling) + free! (for en passant) + 3 bits x 16 (for promotions) = 48 bits / 6 bytes Let’s take a closer look at promotions. Ordering of promotions can be unique The second observation is that the ordering of promoted pawns can be made unique. In this illustrative example, one pawn is promoted to a queen and another to a rook. The top line on the right represents white pawn positions, while the bottom lines represent the promotion encoding (3 bits for each white pawn) [3]. Now let’s do the following: Represent non-promoted pawns by 0 and the promoted pawns by 1 to 4. Sort the representation in ascending order and reorder the positions accordingly [4]. This gives us the string 00000034 to uniquely represent this specific set of promotions, without information loss. How many possible strings are there? Generating this by brute force, we end up with 495 distinct strings [5]. len( set( [ tuple(sorted((a, b, c, d, e, f, g, h))) for a in [0, 1, 2, 3, 4] for b in [0, 1, 2, 3, 4] for c in [0, 1, 2, 3, 4] for d in [0, 1, 2, 3, 4] for e in [0, 1, 2, 3, 4] for f in [0, 1, 2, 3, 4] for g in [0, 1, 2, 3, 4] for h in [0, 1, 2, 3, 4] ] ) ) This can be stored in 9 bits for each side [6]. 🟢 free! (for captures) + free! (for castling) + free! (for en passant) + 9 bits x 2 (for promotions) = 18 bits / ~2 bytes We add this to the 24 bytes for positions and end up with a total of ~26 bytes! Next steps Feel free to try this out on Replit here! The code can be found on Github here. Chess encoding (and compression in general!) is a deep and fascinating topic. This post discusses the use of Huffman coding to efficiently store chess games. If this sounds like fun, you should apply to Recurse Center! The next batch starts on Jan 3 2023, with an information session on Dec 9 2022. If you’re curious about my take, I’m reachable here. Other RC posts can be found here and here. [1] The Forsyth-Edwards Notation stores the positions, active color, castling availability, target square, the half-move clock and full-move number. [2] Since at most 1 pawn is available for en passant capture, we can actually make this more compact. We need 1 bit for whether or not it’s available, plus 4 bits to represent 16 pawns, for a total of 5 bits. [3] We use n, b, r and q to represent the promotions to knight, bishop, rook and queen respectively. This is purposely chosen, as a contrast to the 0 - 4 representation that follows. [4] For en passant we need the pawn to remain on its home file. Hence we exclude the pawn from this step if it can be captured en passant. Captures can appear on any file. [5] Ben Zinberg uses a balls-and-urns argument to come up with 495. For each string of 0s, 1s and 2s having length 3 in weakly ascending order as you describe, you can imagine writing the string on 5 blank spaces, where there is a ‘divider’ space any time the digit changes. For example, the string 012 would be written 0 _ 1 _ 2 where the _s are divider spaces. The string 000 would be written 0 0 0 _ _ with a string of zero 1s after the first divider and a string of zero 2s after the second divider. The digits to write on the non-divider spaces are uniquely determined by where you place the dividers. Thus, the strings you describe are in one-to-one correspondence with choices of how to place the 2 dividers, and the number of ways to do that is the binomial coefficient ( 5 2 ) ( 25 ) ( 2 5 )(25). This argument generalizes to say, the number of weakly-ascending sequences of integers in { 0 , … , 𝑘 − 1 } {0,…,k−1} having length 𝑛 n is equal to the number of ways to place 𝑘 − 1 k−1 divider spaces among 𝑛 + 𝑘 − 1 n+k−1 blank spaces, which is equal to ( 𝑛 + 𝑘 − 1 𝑘 − 1 ) ( k−1 n+k−1 ). [6] With a limit of 8 bits for each side, we can fully track at most 4 promoted pawns. Alternatively we note that promotions always involve a capture; we can potentially reclaim 1 bit by convention of denoting captures either left-most or right-most.",
    "commentLink": "https://news.ycombinator.com/item?id=37525348",
    "commentBody": "How to store a chess position in 26 bytes using bit-level magic (2022)Hacker NewspastloginHow to store a chess position in 26 bytes using bit-level magic (2022) (ezzeriesa.com) 161 points by kurinikku 18 hours ago| hidepastfavorite169 comments Scarblac 17 hours agoStoring a chess position in 26 bytes.Storing a game is also interesting. The number of legal moves varies depending on the position. You could try to define a variable length encoding by giving more likely moves a shorter encoding, but the ordering would need to be deterministic so it could be decoded (running Stockfish for a second isn&#x27;t). reply ThomasCM 17 hours agoparentSurprisingly, storing a game (with all moves) can take less space than encoding a single board. This is because you can effectively encode a move in a single byte (as there are less than 255 moves possible in each position). Applying compression to the resulting binary string will allow you to reduce the space even more.Check out this great blog post of Lichess for more information: https:&#x2F;&#x2F;lichess.org&#x2F;blog&#x2F;Wqa7GiAAAOIpBLoY&#x2F;developer-update-2...And shameless plug: Using this encoding, I&#x27;m storing millions of games on https:&#x2F;&#x2F;www.chessmonitor.com&#x2F; There you can link your Chess.com or Lichess account and view all kind of statistics of your games. reply seabass-labrax 16 hours agorootparentThat is a beautifully designed website. I don&#x27;t think I&#x27;ve ever used an OAuth authentication flow as smooth as the one that your site uses to access my Lichess credentials (same as my HN name, btw, in case you want to beat me at a correspondence game).ChessMonitor is practically a work of art! reply robertlagrant 14 hours agorootparentI created an account just to see that flow, and it did not disappoint! How&#x27;s it this fast? reply ThomasCM 14 hours agorootparentprevThanks for your feedback!I guess OAuth is relatively fast as I don&#x27;t have a middleman (like Auth0) in there. It&#x27;s just Passport.js. reply foota 3 hours agorootparentprevHeh, I guess there are board states that are not possible to reach through a valid sequence of moves, but I guess otherwise it&#x27;s not possible that games are more compressable by definition, since any valid board state could be represented as a sequence of moves.This does raise the question of the efficiency of reverse engineering a series of minimal moves for some board state. reply omoikane 15 hours agorootparentprevChessMonitor looks very nice, I like how you can link to a particular opening:https:&#x2F;&#x2F;www.chessmonitor.com&#x2F;u&#x2F;XqaFNTHcR61WpiMfOhEY&#x2F;games?po... reply gowld 15 hours agorootparentprevAre you saying that, to encode a valid position, ignoring the cost to encode both the starting position and the move definitions, you can encode the move sequence using less information than encoding a single position? reply ThomasCM 14 hours agorootparentYes, ignoring compression each (half-)move takes up one byte. So if you want to store a sequence of 10 (half-)moves it would take only 10 bytes. reply SideQuark 13 hours agorootparentAverage game length seems to be around 80 half moves though.https:&#x2F;&#x2F;chess.stackexchange.com&#x2F;questions&#x2F;2506&#x2F;what-is-the-a...I&#x27;d expect that ordering moves by popularity at each half move index, using say the above dataset, would allow you to select lower indexed values at each step, allowing a nice context based arithmetic compression to really shrink them well. reply ThomasCM 12 hours agorootparentYes, in contrast to storing the board (which can be a fixed size), this depends on the length of the game of course.That said, there are some optimizations you can apply that will compress moves even further (for example the order of the moves as explained in the Lichess blog post is important). In the end it&#x27;s a tradeoff between (de)serializing the game fast and reducing the size (even more). replyesrauch 17 hours agoparentprevThat suggestion seems very reminiscent of the notion that optimally compressing wikipedia is the same problem as what generative LLMs are doing, by virtue of predicting the next letter&#x2F;word&#x2F;segment with high precision lets you compress it extremely well.I think for chess you could get most of the benefit with a relatively naive engine; chessbase has a weak engine built in where you can hit space bar and it does a move which is incredibly useful since there&#x27;s just one obvious move for a lot of positions anyway; if the move was especially tricky&#x2F;nonobvious than it&#x27;s also not what you would want when hitting spacebar to just predictably proceed anyway). reply TylerE 17 hours agoparentprevI suspect it would be hard to beat pgn run through a good compression algorithmn.Or similarly essentially a binary version of pgn. Probably the optimalist of optimal is a binary specifying the starting square (6 bits), and then a minimal-width for the specified piece number that indexes against a standard set of move offsets.So, for instance, a knight has (ignoring potential exposed checks, board boundaries, etc, 8 possible moves, so to fully encode a knight move you need 6+3=9 bits. 8 also works for pawns (and annoying due to e.p. 4 doesn&#x27;t). Bishops, queens, and rooks would need a 4&#x2F;5 bit field. Encode castling as starting from the rook as they have &#x27;spare&#x27; moves in their bit set, and kings don&#x27;t. Encode the end state at the begining.This is going to use 2 bits for the end state, and then either 9, 10, or 11 bits per move. reply thechao 16 hours agorootparentYou only need 5b to encode the piece to move: you know whose turn it is. Also, as the game progresses, you can reindex to reduce the number of bits to define which piece is moving. reply thaumasiotes 7 hours agorootparent> You only need 5b to encode the piece to move: you know whose turn it is.If you want to encode the piece (rather than the square), and you&#x27;re comfortable not counting \"whose turn is it?\" against the information requirement, you don&#x27;t need 5 bits. Each player has only 16 pieces, so you can give them all four-bit names.You won&#x27;t know what kind of piece they are, though. reply robertlagrant 14 hours agorootparentprev> I suspect it would be hard to beat pgn run through a good compression algorithmn.I once[0] tried to spread this message :)[0] https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;1831841&#x2F;61938 reply TylerE 13 hours agorootparentA standard archiver like 7zip is probably a loss due to the metadata&#x2F;format headers etc. When your plain text is only a few hundred bytes to start with...I suspect the winner would be something like an LZMA derivative with a fixed dictionary. I doubt not using an adaptive encoder would be a big loss as PGN (exlcuding the metadata) is quite far from random bytes. reply thaumasiotes 7 hours agorootparentprev> Bishops, queens, and rooks would need a 4&#x2F;5 bit field.Ignoring board boundaries, a queen has 56 possible moves requiring 6 bits. At any given position on the board, most of those aren&#x27;t possible because the board is too small, but cramming that into 5 bits will make the encoding much more annoying.Same thing goes for rooks; ignoring board boundaries there are 28 possible moves, but including the board boundaries there are 14. You can fit that in four bits, but you pick up some context sensitivity.> 8 also works for pawns (and annoying due to e.p. 4 doesn&#x27;t)I don&#x27;t see the problem? A pawn can move forward two spaces, it can move forward one space, it can capture diagonally to the left, or it can capture diagonally to the right. Those are the only possibilities and they fit into two bits.En passant enables a pawn to capture a piece that isn&#x27;t located on the space being captured, and you need to know the state of the board on the previous turn (or, equivalently, what the previous move was) in order to know whether en passant is a legal move... but to encode that it happened, you don&#x27;t need anything you didn&#x27;t already have. reply TylerE 6 hours agorootparentHours forgetting pawns capturing en passant. reply thaumasiotes 5 hours agorootparentWhat? reply dang 9 hours agoparentprevOk, we&#x27;ve positioned the title above. Thanks! reply kurinikku 8 hours agorootparentThank you! reply zeagle 17 hours agoparentprevFinally, a good use case for blockchain technology! reply r3trohack3r 17 hours agorootparentI can&#x27;t tell if this is in jest or not but blockchains are prolific in software.Nearly every company uses them to prove the authenticity of deployments in production at one or more layers. reply l33t7332273 17 hours agorootparentI feel like signatures and maybe even Merkle trees are used, but not blockchain. reply episteme 14 hours agorootparentprevNearly every company, what is your source for that? I&#x27;ve never even heard of this before. reply flangola7 8 hours agorootparentprevNo, no they do not. reply r3trohack3r 6 hours agorootparentIIUC a blockchain is a structure where each node has a content addressable hash that includes the hash of the previous node in the chain. If you change any historical node, every subsequent hash is updated.This structure is used inside your .git directory, your docker manifest, etc.Blockchains are incredibly useful structures. reply rcxdude 3 hours agorootparentThat&#x27;s a Merkle tree. Blockchains are a Merkle tree plus some form of consensus algorithm, often a trustless one. It&#x27;s the usefulness of the consensus algorithm which is usually called into question by critics (generally because it&#x27;s often expensive and cannot reference anything outside the system). reply JambalayaJim 4 hours agorootparentprevIn context blockchain is referring to a distributed set of hash structures + a consensus algorithm replytimerol 17 hours agoprevI played with this in the past (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34461113#34462521), but am willing to take another stab at it.Store one 64 bit bitboard - a set bit means that a piece is present at that place. An unset bit means that no piece is after that position. After the bitboard, store a list of 32 4 bit integers, where the order of the pieces in the list corresponds to the order of the bits set. If there are less than 16 bits set in the bitboard, ignore the last items in the list. 0000 - 0x0 - black pawn 0001 - 0x1 - black pawn (can be en-passant&#x27;d) 0010 - 0x2 - black knight 0011 - 0x3 - black bishop 0100 - 0x4 - black rook (castling unavailable) 0101 - 0x5 - black rook (castling available) 0110 - 0x6 - black king 0111 - 0x7 - black queen 1000 - 0x8 - white pawn 1001 - 0x9 - white pawn (can be en-passant&#x27;d) 1010 - 0xA - white knight 1011 - 0xB - white bishop 1100 - 0xC - white rook (castling unavailable) 1101 - 0xD - white rook (castling available) 1110 - 0xE - white king 1111 - 0xF - white queenI think that covers all possibilities to store a chess position in 64 + 32 * 4 = 192 bits, or 24 bytes exactly.The starting position would be represented with a bitboard of 0xFFFF00000000FFFF, with a list of [0xD, 0xA, 0xB, 0xF, 0xE, 0xB, 0xA, 0xD, 0x8, 0x8, 0x8, 0x8, 0x8, 0x8, 0x8, 0x8, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x5, 0x2, 0x3, 0x7, 0x6, 0x3, 0x2, 0x5], using the same position-to-number scheme in the blog postEdit: 32 pieces, not 16. Thanks to the peanut gallery for catching it quicklyEdit2: To store which player is next: do nothing for white. For black, if there are 32 pieces, flip the bitboard upside down. (To check if it&#x27;s black&#x27;s turn, verify that black pawns are \"below\" white pawns, which is illegal before captures are made.) If there are less than 32 pieces and it&#x27;s black&#x27;s turn, invert the bitboard. (To check, count the number of set bits.) This is entirely taken from https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37526484 reply penteract 16 hours agoparentTo cut 2 bytes off (while making it much less elegant), huffman coding could be used to store pawns in 3 bits - to guarantee a space reduction, this relies on the fact that if there are n promoted pawns, there must have been at least ceil(n&#x2F;3) captures, freeing up space for the longer representation of promoted pawns.It is necessary to find another way to represent en-passant opportunities (swap an en-passantable pawn with the piece in the 1st or last rank as mentioned https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37526523 ).2 rook representations aren&#x27;t needed (encode a king with castling opportunities as a knight, bishop or rook, and when decoding, if there are no kings of a given color, look at the piece in the king&#x27;s starting position) so another 4 bits could be saved by making rook, bishop or knight representations shorter. reply timerol 15 hours agorootparentA Huffman code like this can also represent knights (or any single other piece) in 3 bits. 000 - black pawn 001 - black knight 0100 - black bishop 0101 - black rook 0110 - black king 0111 - black queen 100 - white pawn 101 - white knight 1100 - white bishop 1101 - white rook 1110 - white king 1111 - white queenGoing with \"a pawn in the first row is actually en-passantable, and should be swapped with the piece in the appropriate position if it exists\", and \"kings are represented as knights when they can castle in either direction, bishops when they can only castle kingside, and rooks when they can only castle queenside\", that gets the initial representation down to 64 + 16 * 3 (pawns) + 6 * 3 (knights and kings) + 10 * 4 = 170 bits, with a worst case of 172 bits (when kings lose some castling rights), if I understand it correctly.Huffman encoding for 21.5 bytes seems to win the day. reply alexb_ 16 hours agorootparentprev> To cut 2 bytes off (while making it much less elegant), huffman coding could be used to store pawns in 3 bits - to guarantee a space reduction, this relies on the fact that if there are n promoted pawns, there must have been at least ceil(n&#x2F;3) captures, freeing up space for the longer representation of promoted pawns.Can you explain this in more detail? Curious as to how you could save space with this. reply Dylan16807 15 hours agorootparentYou read the piece data bit by bit. If you see 100 or 000 then you stop right there. You have a pawn, and the next piece starts with the next bit. There&#x27;s no ambiguity.Here&#x27;s a good example image for huffman coding: https:&#x2F;&#x2F;i.ytimg.com&#x2F;vi&#x2F;hOabRMHzpo8&#x2F;hqdefault.jpgSo before any captures are made, you have 32 pieces, half of which use 3 bits and half of which use 4 bits. 14 bytes, plus the 8 bytes storing the bitboard.When you promote a piece it goes up in size from 3 to 4 bits, but you can guarantee there have been enough captures to offset that, so you never need more space than you started with. reply alexb_ 15 hours agorootparentI see - so you can use the bits you saved by not having separate rook pieces to denote En Passant pawns.I like the \"no kings\" idea for castleable kings - though I think with smaller pawn sizes, that gives another opportunity for compression:- king that can&#x27;t castle: king- king that can castle queenside: any other piece in king&#x27;s position, no king of that color on board- king that can castle kingside: black pawn on 1st or 8th rank- king that can castle: white pawn on 1st or 8th rankBecause you are often going to have positions where the king can castle kingside and positions where the king can castle either way, this should maximize how often you manage to save space w&#x2F; the pawns.Another thought I had (which might contain other problems, not sure yet) is to use pawns on the 1st or 8th rank to denote pieces which are in their starting position - the decompression algorithm can then derive what piece it is based on the known starting position. Once we start having data saving because of pawns taking less bits, we want to be able to use them as much as possible to save space. reply Dylan16807 15 hours agorootparent> I see - so you can use the bits you saved by not having separate rook pieces to denote En Passant pawns.You could do it that way, but the particular comment was suggesting two entirely separate ways to save bits, one for pawns and one for rooks.Specifically, the suggestion in that post is to use 1st&#x2F;8th rank to show en passant, and to show castling by replacing an unmoved king with a different piece. But there&#x27;s lots of ways to cleverly encode that information. reply alexb_ 15 hours agorootparentFor what piece to replace the unmoved king with, you can actually use both white AND black pieces, since the starting rank can decode what color the king is:- White Knight on E1 and no king: Replace with white king that can castle both ways, E4 pawn can be taken En Passant- White Bishop on E1 and no king: Replace with white king that can castle kingside, E4 pawn can be taken En Passant- White Rook on E1 and no king: Replace with white king that can castle queenside, E4 pawn can be taken En Passant- Black Knight on E1 and no king: Replace with white king that can castle both ways, E4 pawn cannot be taken En Passant- Black Bishop on E1 and no king: Replace with white king that can castle kingside, E4 pawn cannot be taken En Passant- Black Rook on E1 and no king: Replace with white king that can castle queenside, E4 pawn cannot be taken En PassantIt&#x27;s the same for E8, just put a black king and not a white king. Sorry if this is repetitive, I could have probably just explained it and let you figure it out, but I put the cases down here for clarity. This should also be combined with the Knight huffman encoding that was talked about here https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37527350 reply alexb_ 14 hours agorootparentprevI&#x27;m actually realizing - you can simply have a case where if a white&#x2F;black pawn is on the 4th&#x2F;5th rank, have the next bit be a flag for en passant. This makes all en passant rules stored in 8 bits at max. Since only 1 pawn can be in a status of \"en passantable\" at a time, we can make it stop assigning a flag bit for future pawns if the answer is ever \"yes\". reply LorenPechtel 14 hours agorootparentYou can have only one en passant situation on the board at once. This means you can use 3 bits to encode the column for en passant, you check the board to evaluate the legality of the solution and discard if it isn&#x27;t legal (this means you don&#x27;t have to use a bit to encode whether it&#x27;s possible as the encoder is guaranteed to be able to pick a column that it&#x27;s not possible.) reply Dylan16807 12 hours agorootparentYou can have two pawns in the same column in plausible en passant position after pawns cross over via capture.Of course after a capture you have more bits free, but you need to do something more complex than encoding the column. reply alexb_ 12 hours agorootparentThat&#x27;s just not true. Pawns can only be captured en passant on one rank for each color. reply Dylan16807 12 hours agorootparentYes for each color. That means two pawns for each column can be in position to be captured en passant. And also two pawns can be in capturing position.Edit: Column combined with whose turn it is will work, but not just column. reply mlyle 8 hours agorootparentPart of a chess position is whose turn to move. That has to be encoded anyways. reply Dylan16807 8 hours agorootparentI guess, but the article wasn&#x27;t trying to do so. replyDylan16807 14 hours agorootparentprev8 flag bits is a lot though when we&#x27;re trying to shave down 20-ish bytes! And we&#x27;re only worried about the worst case scenario, so assume it&#x27;s the last pawn in the list. Also you can have at least 10 pawns visibly at risk of en passant at once. If you base it on rank alone, you can have all 16 pawns in position at the same time, wasting 16 bits.If you&#x27;re going to explicitly store it, at least squeeze down to 4 bits to pick a specific pawn (and picking one visibly not at risk if no pawn is at risk).But using clever piece rearrangements is a lot better than spending flag bits. replysufianrhazi 17 hours agoparentprevNice! Though there are max 32 pieces on a board, not 16; so this scheme is 64 + 32 * 4 = 192 bits, or 24 bytes.The bit to indicate whose turn it is isn&#x27;t accounted for here. But it probably could probably represented by the binary negation of the bitboard -- if there are 32 or fewer bits set, then it is white&#x27;s turn; if there are 33 or more bits set, then it is black&#x27;s turn and you can negate the bitboard prior to determining which squares are occupied.Taking things further, it probably can be compressed even more with (much) more complex logic, as the castling available bit must only be present on the corner positions, and the pawn en-passant capabilities are only available on the middle rows, so those bits are meaningless in other positions. reply timerol 16 hours agorootparentI like the bitboard inversion idea. (Requires flipping logic as well from https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37526484, since 32 is a special case.) Note that the en-passantable pawns and castle-able rooks came from options that were unused in my first pass (linked comment). I could use 0x1 as \"castleable rook or en-passantable pawn, determined from where it is\" and then store 32 integers with 13 options in 119 bits[1], saving 9 bits. But I&#x27;m kinda attached to the simplicity here.(The 16->32 was edited as you wrote this comment.)[1] log(13^32)&#x2F;log(2) = 118.4 reply penteract 16 hours agorootparentprev> if there are 32 or fewer bits set, then it is white&#x27;s turn; if there are 33 or more bits set, then it is black&#x27;s turn and you can negate the bitboard prior to determining which squares are occupied.This doesn&#x27;t quite work because if there are exactly 32 bits set, inverting it leaves 32 bits set. You could fix this by marking all pawns belonging to the player who&#x27;s turn it is as capturable via en-passant (if a player has no pawns left, at least 1 piece has been captured, so inverting the bitboard works). reply LorenPechtel 13 hours agorootparentNow you have me thinking of bughouse chess. reply sufianrhazi 16 hours agorootparentprevOh you&#x27;re right, nice catch! reply 6510 16 hours agorootparentprevThere is never a pawn at the 8th row, one might \"insert\" an en-passant row into the board. reply skupig 16 hours agoparentprevYou can use duplicate king identifiers to represent castling available, and replace the extra rook identifiers with \"black king (my turn)\" and \"white king (my turn)\" to store the turn in the same amount of space.edit: You can then use the inverted&#x2F;flipped board trick to store one bit of your piece list, down to 191 bits.edit2: You only need one \"king (my turn)\" ID, which represents the whichever color you didn&#x27;t use for the other king. You can use the extra value for another \"my turn\" piece that also sets a bit. 190 bits! reply xpe 7 hours agorootparentIt is necessary to store the ability-to-castle state with each rook; attempting to keep it only attached to each king is insufficient. reply skupig 3 hours agorootparentThat&#x27;s not what I wrote, you duplicate the king ID in the position of each castle-able rook. reply seanhunter 16 hours agoparentprevAs the article discusses, there&#x27;s a bit more than that to store in a position. Specifically you have to store whether or not castling is available for the two sides and also whether any pawns are en passant targets, since both of those moves are available (or not) conditionally in a given position based on previous moves in the game. reply timerol 16 hours agorootparentThere are specific types mentioned to denote rooks that the king is allowed to castle towards, and pawns that can be en passanted reply hinkley 15 hours agorootparentprevI don’t think that’s true. Or rather, it’s only true for storing board position not for storing the move history. If you have the entire move history you know that status of each piece. reply kpozin 15 hours agorootparentIf you have the entire move history, then you probably don&#x27;t need to store partial board positions. reply hinkley 11 hours agorootparentOf course it depends on what you&#x27;re doing with the information. If you&#x27;re compressing it in order to sort 100 million board positions for a minmax algorithm, it might make sense to use a representation that makes queries cheaper at the cost of size.If instead you&#x27;re trying to store every competition chess game in history, then it depends on what you&#x27;re trying to do with them. Look for similar board positions?If you&#x27;re trying to allow inmates in a Dumas-inspired prison secretly play chess against each other over a covert channel, then detection is the problem. Which might mean compression (fewer signals to hear) or masking the signal as random noise. reply penteract 17 hours agoparentprevThere are at most 32 pieces on a chessboard (16 of each color), so I think you need 24 bytes. reply timerol 17 hours agorootparent... right. I thought 16 felt a little small. Thanks for the catch, updated reply jenscow 15 hours agoparentprevsmall shavings:* If there are less than 32 bits set in the bitboard, the item list is shorter (rather than ignored).* Probably not worth it, but: When there are 32 bits set on the bitboard, stop processing the bit-board.. however, if you adjusted the ordering of the lines (0,7,1,2,...), it&#x27;s optimised for the first 1 or 2 positions* Maybe this is cheating, but if the size of the game data will be known ahead of processing, then you could leave off the last item in the list if it&#x27;s a king or a rook* Starting the item list with 2 white kings can be a special case for \"starting position\", and if the items are listed before the board then only 1 byte is needed :) reply elteto 17 hours agoparentprevMaybe a silly question, how do you know which side of the board is white vs black? reply timerol 17 hours agorootparentConvention - use the same bit-to-number scheme in the blog post. Bit 0 is a1, bit 7 is h1, bit 8 is a2, bit 56 is a8, bit 63 is h8. reply k1t 17 hours agoparentprevWhat if there are 32 pieces on the board? reply tromp 17 hours agoparentprevA position, as stored in FEN notation, also includes side-to-move. reply devit 16 hours agorootparentThere&#x27;s a simple trick to encode it: if there are less than 32 pieces, invert the bitboard (easily decoded since boards can&#x27;t have more than 32), while if there are 32 pieces flip the board vertically (easily decoded because white pawns can&#x27;t be after black pawns with no captures). reply 6510 16 hours agoparentprevMy thought was to have additional schemes depending on the length of the byte array. For example, if the position is an empty array it is the beginning position, if it is 1 byte it represents the most common positions.\"\" is the beginning position\"0\" is E4\"1\" is D4\"2\" is C4\"3\" is E4 E5\"4\" is D4 D5\"5\" is G3One could do a multi byte version where the order of popular positions is replaced with a crappy chess computer.If there is no en-passant, no promoted pawn and castling is allowed you can use representations slightly shorter than 24. reply bhelkey 17 hours agoparentprevA nitpic, to castle, the king AND the rook must not have moved from their starting squares.Using this approach, you would need to store castling available&#x2F;unavailable for the kings as well. reply ianferrel 17 hours agorootparentNo you don&#x27;t. If the king moves, you update both rooks to be unavailable for castling. reply penteract 17 hours agorootparentprevIf the king has moved, you can just mark both rooks as castling unavailable. reply jade-cat 17 hours agoprevThere are two more things that should be considered. Both of them unlikely to influence a position, but they can matter - just like the en passant target.The fifty move rule[0] is quite simple, just store a number, fits in five bits. But the threefold repetition rule[1] is quite a pickle - it basically means that to know everything about a position you need to know every position that occurred before it.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fifty-move_rule [1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Threefold_repetition reply thdc 17 hours agoparentYeah, it seems like the author is storing more information than just the position but not enough to figure out all of the possible next states of the game.Another straightforward thing missing is the player&#x27;s turn; this could determine whether the position is a stalemate or not. reply Scarblac 17 hours agoparentprevNot all previous positions, only the ones with the same pieces, pawn positions, castling rights and en passant rights.But the standard, FEN, doesn&#x27;t store that either. It&#x27;s used more in the context of a full game than with individual positions. reply jade-cat 17 hours agorootparentFair enough. Still up to 50 board states that can influence the current one (the 50 move rule is coming to help here)FEN doesn&#x27;t store previous states, but EPD can. It just goes to show how meanings and requirements change depending on context, which is super interesting in and of itself :P reply Scarblac 17 hours agorootparentAlso, database software gets so clever with storing games that they often can&#x27;t save games that have illegal moves in them. But there are plenty real games from real tournaments that had illegal moves in them that nobody noticed... reply LorenPechtel 13 hours agorootparentYeah, I was trying to send a chess puzzle to someone on Gameknot.com. White to mate in 1--except there was no black king. (The objective was to mate anyway--find the move that would mate the black king no matter where it was.) Their encoder created the king. reply duskwuff 16 hours agorootparentprevWhat&#x27;s the proper notation for \"while White closes his eyes to think about his next move, Black quietly moves one of his pawns over a square\"? :) reply bjourne 14 hours agorootparentprevThat&#x27;s a very good point. Similar issues affect file systems that has to store files with invalid filenames and parsers that have to gracefully handle invalid parse trees. reply hinkley 15 hours agoparentprevI prefer the Ko rule of Go.You can’t repeat the last position. But repeating a pattern of part of the board every two turns can force progress to resolution. The entire board never repeats, but it also stops the loop earlier. reply drivers99 17 hours agoparentprevThey&#x27;d also need to store whose turn it is, so I&#x27;m guessing the article is strictly about \"positions\" and not game state. reply pfooti 17 hours agoprevAn interesting cognitive phenomenon: if you ask chess experts and novices to memorize and recall an arbitrary chessboard, the experts are significantly better than the novices _only if_ the board is a legal board that can be arrived at during play. If it is not a legal board, there&#x27;s no particular difference between novices and experts. Original ref: Chase & Simon 1973, Perception in Chess.This is usually taken to mean that the brains (or whatever) of experts see structure that can be used for compression that novices don&#x27;t, but that compression has assumed invariants you cannot break. reply tylerhou 14 hours agoparentThis isn&#x27;t just for chess -- it&#x27;s practically any knowledge task that you can build expertise in.E.g. take programming. Suppose I sat down an experienced programmer and a novice and gave them the same small (~10-20 line) function to reproduce from memory. If the function is a \"reasonably written function\" I&#x27;m willing to bet that the experienced programmer could reproduce the function with just one or two \"peeks\" -- once you have enough experience, you can better recognize patterns &#x2F; chunk your knowledge. A novice doesn&#x27;t have this ability, so it would likely take them many more peeks.On the other hand, if the function is some random gibberish with little structure, you could imagine that it&#x27;s probably equally difficult for both the experienced programmer and the novice to reproduce the function from memory.For chess, one reason why masters can better recall positions is because they know what typical positions look like (e.g. a position typical of the \"London\" opening). Then, they only need to store a \"diff\" of the given position and a typical position. (\"It&#x27;s a typical London setup for White, except White also played a3 and b4.\") A novice doesn&#x27;t have this knowledge, so they have to store the whole position. reply jiggawatts 13 hours agorootparentThe opposite of this is non-expert customers demanding detailed documentation for common patterns in industry.“Can you please provide more content to explain what a load balancer does?” reply dmurray 17 hours agoparentprevNot a \"legal\" board, but a typical board. Both this and the original de Groot study picked positions from real games played by strong players. Experts don&#x27;t do retrograde analysis on the positions, but they do recognise typical patterns that often occur in real play. reply Scarblac 17 hours agoparentprevIt&#x27;s not really about whether it&#x27;s legal, but whether it looks normal. Very bizarre positions can easily be legal, but they&#x27;re hard to remember for everyone. reply hinkley 15 hours agorootparentI’ve heard this corroborated by exhibition players who play ten or fifteen opponents at once. They do better with moderately skilled opponents than random people. reply Scarblac 14 hours agorootparentI don&#x27;t know what you mean with \"exhibition\" precisely; I&#x27;d expect that to be true for blindfold chess (where you have to keep all the games in memory the whole time), but not for normal simultaneous as the strong player hardly has to think to find moves good enough to beat random players. reply HALtheWise 17 hours agoprevFor what it&#x27;s worth, this definitely isn&#x27;t the theoretical limit for compressing a chess board position, which I would probably resort to calculating mathematically. In particular, (simplifying to boards with no pieces captured) this scheme uses 24 bytes for representing piece positions, but the constraint that no two pieces are in the same square means you should actually need only log2(64!&#x2F;32!) = 22.3 bytes for that case, with 13 bits of savings. The scheme proposed here reclaims some of that overhead by granting special meaning when a piece&#x27;s location overlaps with the king, but still is capable of representing other illegal positions where non-king pieces occupy the same square.Unfortunately, decoding a mathematically optimal encoding quickly devolves to making a list of all possible board configurations and indexing into it, so I&#x27;d definitely believe that the proposal here is close to the smallest practically useful representation. reply ToValueFunfetti 17 hours agoparentThe upper bound on the number of legal chess positions given in https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Shannon_number is 8.7 * 10^45, which gives a lower bound of ln(8.7 * 10^45) = ~106 bits or 14 bytes. reply tromp 16 hours agorootparentYou need the 2-logarithm rather than the natural logarithm. That gives ~ 152.6 bits, or ~ 19.1 bytes. reply ToValueFunfetti 16 hours agorootparentThanks, don&#x27;t know what I was thinking there reply xpe 7 hours agorootparentDon&#x27;t worry, that&#x27;s actually quite a natural error to make reply xpe 7 hours agorootparentprev> Recent results improve that estimate, by proving an upper bound of 8.7x10^45, and showing an upper bound 4×10^37 in the absence of promotions. - Wikipedia (link above)You can save 28 bits!... Use log2(4e37) = 124.9 bits for games without piece promotions. Then switch to log2(8.7e45) = 152.6 bits for games with them. reply Scene_Cast2 17 hours agoparentprevCouldn&#x27;t you make it practical by assuming all possible positions (64) for the first piece, then 63 for the second, and so on, and encode one piece at a time? (Arithmetic coding piece by piece) reply HALtheWise 17 hours agorootparentYes, although1. You&#x27;d definitely want to deduplicate positions of identical pieces for even more savings 2. That only handles the case where no pieces have been captured, and the full arithmetic coding would probably need separate \"sections\" of the integer range for different cases, and the number of sections is also quite high. 3. There&#x27;s extra nuanced things you might want to handle in the coding, like that pawns can&#x27;t be on their own back row. That is significantly harder.It looks to me like https:&#x2F;&#x2F;github.com&#x2F;tromp&#x2F;ChessPositionRanking has resolved these sorts of issues, but I haven&#x27;t dug into exactly how. reply ComplexSystems 9 hours agoprevYou can get this even lower, without the need for the extra promotion bits, if you make a note of a few things:1. There is still redundancy in that there are multiple pieces of the same type, and if you permute their locations you get another representation of the same state. 2. You don&#x27;t need to say that some pawn&#x27;s location is the king if it&#x27;s en passant. You can just use the back row, which pawns can&#x27;t get to.Using this, you can use the permutations of the pawns to store extra information. For instance, all of the pawns will be on the board at squares #a, #b, ... . Since pawns themselves have numerical indices, you could say that the \"canonical\" representation of the board state has all of the pawn locations sorted in ascending order. Then, different permutations of that can carry information about promotions and which of the \"pawns\" are really queens, etc. reply samwillis 17 hours agoprevWhen I was building my multiplayer Sudoku app, I had fun experimenting with how small I could pack a sudoku grid into a URL. I came up with a scheme combining bit packing with the knowledge of how the grid works. So as you move through the grid, based on the knowledge of what&#x27;s been placed where and the remaining digits you have a fewer options.Was fun, I was playing code golf with myself. Sadly seem to have lost the code and I didn&#x27;t use it in the end.It would probably have been possible to go smaller than I got it by combining it with a sudoku solver, so stop packing positions once it&#x27;s solvable. But life moved on. reply jprete 17 hours agoparentI think for Sudoku there are a lot fewer legal board configs than there are arrangements of the numbers. There’s probably a way to store the solved state as a single number and then just use 27 bits to specify which numbers are revealed. I don’t know what that single number looks like, though, and you’d have to check that there was only one legal solution to the revealed numbers. reply tromp 17 hours agoprevHow to store a legal chess position in log_2(8726713169886222032347729969256422370854716254) ~ 152.6 bits ~ 19.1 bytes using rankings:https:&#x2F;&#x2F;github.com&#x2F;tromp&#x2F;ChessPositionRankingBut the major point of this project is to allow for random sampling of positions with a decent likelihood of getting a legal one, which allows for accurate estimation of the number of legal positions. reply DesiLurker 17 hours agoparentI consider any reduction past the cache-line size (32B) to have diminishing returns as far as processing is concerned. unless of course if you can fit 2 of these in one. reply bumbledraven 14 hours agoparentprevAmazing work. This should be the top comment on this page. reply OJFord 17 hours agoprevOriginal title is:> Compressing chess positions for fun and profitWhich unlike that here is correct: you can store a board, the positions, in 26B; not an arbitrary length game! reply petters 17 hours agoparentMost games could possibly be encoded in less than 26 bytes. There are not that many legal moves each time and if you sort them by probability it may not require many bits to describe which one the players chose. reply lainga 17 hours agorootparentA Huffman code ...? The starting board is 0, 1.e4 is 1, etc... reply OJFord 15 hours agorootparentYou could probably do something to compress algebraic chess notation in such a way, and even without it as GP says it might cover a decent number of games. My point was you couldn&#x27;t guarantee a fixed length in 26B, afaik.(That was the article I expected from the malformed title here: a combination of an efficient encoding and it can it can only get longer than this by repetition so here&#x27;s a very clever thing we can do, or something.) reply NelsonMinar 17 hours agorootparentprevthat may be but it&#x27;s not what the article is about. reply IshKebab 17 hours agorootparentprevI doubt it. You could maybe get as low as 1 bit per move, but how many games are only 26 moves? Would be interesting to find out though!Maybe this paper says. I didn&#x27;t read it.https:&#x2F;&#x2F;www.researchgate.net&#x2F;figure&#x2F;Entropy-and-distribution... reply OJFord 15 hours agorootparent1 bit per move would allow you a 26x8 move game in 26 bytes, not just 26. reply aimor 17 hours agoprevWhat about bishops?The bishops are limited to half the board so only need 5 bits for position. This frees up 4 bits, but you lose the capture state (can&#x27;t use King&#x27;s position for capture state). Well, you CAN use the king&#x27;s position for capture state for two of the bishops at any given time. Then for the other two bishops use a bit to store their capture state. This saves 2 bits overall, bringing the total down to exactly 26 bytes.Gonna have to think that through for awhile, not sure if it works out.Update: I see a comment below that does this but uses 21 bits (instead of 22) by storing bishop position and capture state as a base-33 number. reply NextHendrix 16 hours agoparentIt&#x27;s possible to gain bishops via promotion which may scupper this plan reply solardev 17 hours agoprevMeanwhile the non-comp-sci dev in me is like, \"why not just store every position in a simple JSON so everyone can read it and everything can parse it\". Yeah, it might be half a kB, but you don&#x27;t have to run through mental gymnastics just to render the pieces... reply VyseofArcadia 17 hours agoparentI feel like we have an interesting tragedy of the commons situation of software engineering.On the one hand, storing positions on JSON is quick to implement, easy to understand, easy to read, easy to hack on, and junior engineers and the people who have to deal with your code later will be able to pick it up and run with it easily.On the other hand, when just about everyone is making this same ease-of-use&#x2F;performance tradeoff, software bloat happens. Our computers are so much faster and beefier, but we never actually seem to be able to enjoy the benefits of that, in part because software engineers keep optimizing for quick and easy.Maybe we shouldn&#x27;t dogmatically reach for the easy no-nonsense solution every time, and instead consider whether maybe a little nonsense might, over time, save people a lot of time. reply thriftwy 15 hours agorootparentYou can compress that JSON with a pre-trained dictionary and get a massive discount. reply jiggawatts 12 hours agorootparent“This Kafka queue collects the zstd-compressed BSON chess messages encoded as base-64 and distributes it to the chess engine VM scale set worker pool for processing… what? Everyone knows chess AIs need large scale and programmer time is expensive! Anyway, the Databricks cluster for move analysis is over here, and…” reply x86x87 17 hours agoparentprevIy&#x27;s not meant for humans to read directly. The compact representation helps performance amd storage a lot when it comes to looking at a lot of positions. If you were to store it as a json most of your time would be spent parsing. reply Timon3 17 hours agorootparentThis is illustrated very well in Sebastian Lague&#x27;s video \"Coding Adventure: Making a Better Chess Bot\" (https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_vqlIPDR2TU). reply catapart 17 hours agorootparentAwesome video and, I&#x27;ll admit, the timing makes me curious to know if that video maybe inspired some devs to either pick up this kind of encoding work, or maybe just to finish up some encoding work that they had already started.Most likely unrelated, I know! Just a wondering in passing. reply Timon3 17 hours agorootparentIt&#x27;s definitely possible! Even more so considering Sebastian also started a Coding Challenge for Tiny Chess Bots: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iScy18pVR58 reply astrobe_ 17 hours agoparentprevIn the early 90ies, we used to have pocket electronic chess games. I used to have myself one that was about the size of a pocket calculator (it actually was also a pocket calculator), which included a tiny board with tiny, tiny chess pieces. Not a strong opponent and quite slow, but good enough for casual games on the road.I doubt you could fit that JSON file in its NVRAM. Sometimes I wonder how much sooner we could have had what smartphones offer us today if some technical choices had been made more... wisely.But that&#x27;s the endless conundrum Worse is better [1].[1] https:&#x2F;&#x2F;dreamsongs.com&#x2F;RiseOfWorseIsBetter.html reply kaashif 16 hours agorootparent> 90iesI&#x27;ve only seen 90s (nineties), never 90ies (ninety-ies). I am imagining the second one pronounced differently. reply astrobe_ 16 hours agorootparentI might have seen it somewhere, but probably written by a non-native as well ;-) Thanks for the correction. reply catapart 17 hours agoparentprevMostly for automation. Bots don&#x27;t need to read and they are very happy to parse data.People like to use bots to run thousands or millions of simulated games to test how good their bot is at chess and have it ranked.Other people like to use the bots that were created to play chess as practice toward a certain skill level. Beginners can pick bots that are proven to be beginner level, through thousands or millions of simulated games.The smaller the data footprint for the games, the faster and more efficiently the bots can play, which reduces cost and time. In a more practical sense, AI&#x2F;ML algorithms can be more efficient with tiny data sizes for a bunch of complicated reasons.So, overall, this is \"nerd sniping\" to develop better chess players, both human and automated. It&#x27;s not the most extensible presentation, I&#x27;ll grant you, but I&#x27;m sure it&#x27;s as fun as Regex Golf, or any other data-packing stuff.P.S. I&#x27;m sure the comp-sci dev in you already knew all this; this is just a bill in case anyone read your comment and truly didn&#x27;t already know all of this. reply awegio 17 hours agoparentprevYou need a compact encoding for chess engines that explore billions of states as fast as possible to plan the best move. reply solardev 17 hours agorootparentWell, this is arguably a kind of compression, right? So you&#x27;d be trading CPU time for fewer bytes? Is that a desirable tradeoff at chess engine scales? reply hotnfresh 17 hours agorootparentBit packing&#x2F;mapping et c. isn’t compression the way you’re thinking. What it is, is concise. It requires that the program know what each bit means, rather than telling the program what a value means (as a json structure might), so it shifts where meaning is assigned strictly to the program—a convention must be encoded in the program, not figured out at runtime, though technically you could turn this back into a form of config if you wanted, it just wouldn’t be jumbled up with your data—but it doesn’t really compress the data itself. It’s just efficient at representing it.[edit] shorter version of the above: it stores the values, but doesn’t store what they mean. reply somenameforme 17 hours agorootparentprevIt&#x27;s not compression in the normal sense of the word. Most parsing is directly to data. So e.g. you know the square of some piece is the next 5 bits. In languages that allow it you can cast directly from the next bit offset to an e.g. byte. This is going to dramatically faster than parsing much more loosely structured JSON. As database sizes increase you also get worse performance there, so it&#x27;s a double hit. So with these sort of representations you get orders of magnitude faster and smaller. Sometimes there really is a free lunch!Also I&#x27;d add the sizes involved here are kind of insane. I wrote a database system that was using a substantially better compression that averaged out to ~19 bytes per position IIRC. And I was still getting on the order of 15 gigabytes of data per million games. Ideally you want to support at least 10 million games for a modern chess database, and 150 gigabytes is already getting kind of insane - especially considering you probably want it on an SSD. But if that was JSON, you&#x27;d be looking at terrabytes of data, which is just completely unacceptable. reply MenhirMike 17 hours agorootparentprevTo give you an example, the Syzygy tablebase for all endgame positions with 7 pieces remaining is 18.4 TB. The estimated size for 8 pieces is 2 PB.There are different applications for different things: If you want to host a website with real-world tournament results involving only humans, you probably can get away with using more bytes. But if you&#x27;re writing an engine that uses pre-computed positions, you want to be as compact as possible.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Endgame_tablebase#Computer_che...I did laugh a bit at this bit because \"conventional server\" and \"64 TB RAM\" is hilarious to think about in 2023, but will probably be the base config in a Raspberry Pi in 2035 or so:> In 2020, Ronald de Man estimated that 8-man tablebases would be economically feasible within 5–10 years, as just 2 PB of disk space would store them in Syzygy format, and they could be generated using existing code on a conventional server with 64 TB of RAM reply dekhn 17 hours agorootparentprevCPUs excel at decompression; more than one engineer has remarked to me that the fastest way to populate a cache is to decompress data in-line. reply cylon13 17 hours agorootparentprevIs your assertion that it takes more time for a CPU to read values out of a 30 byte struct and do a couple shifts and branches than to parse a JSON representation? reply hutzlibu 17 hours agorootparentThe JSON needs to be parsed only once. Then it is (or can be) just any object to your liking.JSON is for storing data as text. Not work with that text all the time. reply croes 17 hours agorootparentprevIt&#x27;s not just reading, you need to process the data to get castling availability, en passant target etc. reply personjerry 17 hours agoparentprevWhile we&#x27;re at it, just take a screenshot of the board reply DesiLurker 17 hours agoparentprevin C&#x2F;C++ code you dont really need to do mental gymnastics either. I can imagine writing a struct with some clever unions to decode this all in one shot. the main benefit as others have point out is 1) to store large number (think billions) of such game positions & searching through them. Also if you are developing for cloud deployment you probably want to use minimal storage needed for space & egress b&#x2F;w reasons. last reason is something that may not be obvious but if you have some algos that can run efficiently on gpus then you probably want to lay the data out such that its easy(ier) to load in SIMD engines. overall not a bad idea. reply treyd 17 hours agoparentprevNow try building a chess site to store millions of games with hundreds of millions of game states to search over. It&#x27;s nice that you can very cheaply fit a board into a fixed size column on a database and store the entire game history into around a kilobyte.You&#x27;d write a wrapper to extract our the dense form to something with a nice interface. reply umanwizard 17 hours agoparentprevBecause easy readable code is less important for competitive modern chess engines than maximum speed and memory efficiency. reply Scarblac 17 hours agoparentprevMy lazy brain says \"just take the FENs, remove the slashes etc that are just for human readability, and compress the result with Gzip or do. Bound to be smaller in practice.\" reply alexyz12 17 hours agoparentprevYou’ll never get to the moon on 4kb Apollo computers like that reply about3fitty 17 hours agoparentprevYep, everyone’s happy until the cosmic rays hit reply jepler 16 hours agoprevIgnoring whose turn, castling & en passant, a static huffman table isn&#x27;t terrible: 0 - empty (1*32=32) 10y - pawn (color) (3*16=48) 11xxxy - piece (color) (6*16=96)The initial board takes 176 bits (22 bytes) to describe. In most games, the definition length would decrease. A game position is self-delimiting as it always has exactly 64 entries (no need to store the variable length)one of the extra 3 non-pawn piece values can be used to encode &#x27;rook (castling unavailable)&#x27; without spending extra bits. a scheme for storing en passant without any additional bits is less clear (but doing it with 3 extra bits is, so 22.375 bytes for positions that would regularly be reached in play).I think it COULD increase in at least one specific circumstances: two promoted pawns (+6 bits total) with only 1 taken pawn (-3 bits). I think the maximum is 12 promoted pawns and 4 taken pawns which would make some hypothetical board take 204 bits (25.5 bytes) in this encoding.A static arithmetic encoding (rather than a huffman encoding) of the same values should take a hair less space. reply soamv 17 hours agoprevA chess position, not a game (still very interesting though!) reply madacol 17 hours agoparentto be more specific a snapshot of the board reply calvinmorrison 17 hours agoparentprevStoring the game would give you the position though reply WithinReason 17 hours agorootparentIt took me a moment to see your point: it might take less information to store the entire game using a chess engine by entropy coding than a single position reply jiggawatts 12 hours agoprevPeople have pointed out that due to rules about no repeats, the full state requires storing previous moves.I’m fairly convinced that the most efficient encoding would be keeping only the move history and then playing that forward to obtain the board state.E.g.: there are only 32 distinct pieces so a 5-bit number can select one uniquely. Each piece has a maximum of about 32 positions it can move to. Then the encoding is just 10 bits per ply. Typical games are 40 moves (80 ply) and hence require just 800 bits or 100 bytes for the whole game history.Then you could get clever with Huffman coding or the like, since some moves are more common than others. reply paxys 8 hours agoparentAs the game goes on the space needed to store the list of moves increases while space needed to store a snapshot of the board decreases. It would be interesting to figure out where on average the strategies meet. reply verteu 11 hours agoparentprevI agree with this for a typical-length game. But I&#x27;d guess its worst-case is inferior due to some pathologically long games. reply jiggawatts 8 hours agorootparentYes, but pathological games are statistically rare. At scale, the average is what matters… reply yewenjie 7 hours agoprevReading this I realized chess is not fully Markovian (you cannot know everything about the game by just looking at the board at any point), specifically because whether determining if castling and en passant are valid moves depend on the history of the board. reply phkahler 7 hours agoparentThe author of the post forgot a bit to indicate which sides turn it is. That&#x27;s another piece of state you don&#x27;t get by looking at the board. reply Tommah 14 hours agoprevFor my chess tactics trainer at https:&#x2F;&#x2F;www.checkmatechamp.net&#x2F; , I tried a lot of different techniques to compress a small set of positions (about 800). I was not concerned with storing the positions in a fixed size, so I was mainly trying things that would make the entropy of each compressed position smaller. I eventually fit these into a file that is about 14 KB in size when gzipped. Each position takes about 17.5 bytes, excluding the HTTP headers. If you go to the page and scroll through the positions, you&#x27;ll see that each position loads instantly. That&#x27;s because all the positions are in that 14 KB file which is loaded initially. I didn&#x27;t include the castling or en passant info in that file, but I suspect it wouldn&#x27;t add more than one byte per position on average.I only considered techniques that would not cause the decoder to become overly complicated. One \"non-standard\" technique that I used was inverting the color of all the pieces on one side of the board. Specifically, on the lower half of the board, I change all the white pieces to black and vice versa. This greatly lowers the average entropy of a typical position, since for most of the game, each player keeps most of his pieces on his side of the board. It is also easy to handle in the decoder in one line (if rowArticle 9: The Drawn Game> ...> 9.2 The game is drawn, upon a correct claim by a player having the move, when the same position for at least the third time (not necessarily by a repetition of moves) [happens and a draw is claimed]> 9.3 The game is drawn, upon a correct claim by a player having the move, if: ... 9.3.2 the last 50 moves by each player have been completed without the movement of any pawn and without any capture.> ...> 9.6 If one or both of the following occur(s) then the game is drawn:> 9.6.1 the same position has appeared, as in 9.2.2 at least five times.> 9.6.2 any series of at least 75 moves have been made by each player without the movement of any pawn and without any capture. If the last move resulted in checkmate, that shall take precedence.This means that, in order to store a full chess game-state, you also need to keep track of how many moves since the last pawn move or capture (for the 50 and 75 move rule (9.3.2 and 9.6.2 respectively)) and also what positions have previously occurred (for the 3 &#x2F; 5 position repeats, (9.2 and 9.6.1 respectively)).The maximum number of moves from any chess position is 218 according to this post[2], so each move in the history can be uniquely identified by a single byte. You only need to store the moves since the last capture (since you can&#x27;t repeat an earlier position), and you _definitely_ can&#x27;t have more than 112 pawn moves without a capture (because there are only 16 pawns and they can only move forward, except in the case of en-passant which requires a different pawn to move forward twice).But that gives an upper bound of 8400 moves -- this bound is probably much higher than it needs to be though.----[1] https:&#x2F;&#x2F;handbook.fide.com&#x2F;chapter&#x2F;E012023[2] https:&#x2F;&#x2F;www.chess.com&#x2F;forum&#x2F;view&#x2F;fun-with-chess&#x2F;what-chess-p... reply Dylan16807 15 hours agoparentIf a pawn moves then you can&#x27;t repeat a state either, can you? So track the last 75 \"moves\".> they can only move forward, except in the case of en-passantEn passant still attacks forward, into the space the enemy pawn just moved through.> 112 pawn moves without a capture (because there are only 16 pawns and they can only move forwardBut pawns can&#x27;t move through pawns. ~~At most I think you can have 4 of the pawns march all the way forward and get captured, leaving you with with 4 pawns that can move 6 spaces and 8 pawns that can move 7 spaces, for a total of 80 pawn moves without a capture.~~Okay, if you sacrifice a bunch of other pieces to pawns, then you can get them to pair up without losing any. So that&#x27;s 8 pawns moving 6 spaces, and 8 pawns moving 7 spaces. 104 pawn moves in a row without a capture. reply JoshuaDavid 8 hours agorootparent> If a pawn moves then you can&#x27;t repeat a state either, can you? So track the last 75 \"moves\".You are correct.So the board state from 75 moves previously plus 75 bytes to store the last 75 moves is sufficient to store a chess game state. reply Dylan16807 6 hours agorootparent150 bytes because \"moves\" is defined in a very bad way here. reply omoikane 16 hours agoprevThis reminds me of how Oscar Toledo disassembled Video Chess, which ran in just 128 bytes of memory:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36431917It uses lower 4 bits of 64 bytes to store the board positions (upper 4 bits is used to store other data). 64 nibbles is 32 bytes, not too far off from the 26 bytes here. reply svnt 17 hours agoprevIt’s been a minute since I did this seriously so maybe my magic is out of date but I don’t think this is how bits to bytes works:> 100 bits &#x2F; ~12 bytes> 18 bits &#x2F; ~2 bytesI didn’t want to spend a whole lot of effort tracking the arithmetic after this. Was it actually 28 bytes? 27 because I can squeeze those extras into one shared byte? reply billfruit 17 hours agoprevThere is also the Forsyth-Edwards Notation which is in text, can be quite brief if there are only few pieces on the board. reply mrb 17 hours agoprevIt&#x27;s as long as my comment reply justinzollars 17 hours agoprev [–] oh fuck. I feel like this is going to become an interview question. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article presents an innovative technique for storing a chess position compactly in 26 bytes.",
      "The method leverages the unique placement of kings and pawns to represent captures, castling ability, and en passant target, alongside a distinctive encoding for promotions, thus reducing the necessary storage space.",
      "The storage technique includes the use of bitmaps and sorting for efficiently characterizing different aspects of the position, thereby enabling storage of a chess position in just approximately 26 bytes."
    ],
    "commentSummary": [
      "The articles delve into methods of compressing and storing chess positions more compactly and efficiently to reduce data requirements while maintaining crucial information.",
      "It covers various strategies like bit-level magic, use of blockchain technology, storing move history, memory recall and compact encoding specifically for chess engines. It also highlights the advantage of compressed formats over JSON.",
      "The aim is to enhance performance, storage, and processing efficiency in chess databases and applications."
    ],
    "points": 161,
    "commentCount": 169,
    "retryCount": 0,
    "time": 1694794554
  },
  {
    "id": 37527928,
    "title": "Books for Game Developers",
    "originLink": "https://mrelusive.com/books/books.html",
    "originBody": "Books For Game Developers Computer Graphics Computer Graphics C version Donald Hearn, M. Pauline Baker Prentice Hall; 2nd edition (May 24, 1996) ISBN: 0135309247 Real-Time Rendering Tomas Akenine-Moller, Eric Haines A K Peters Ltd; 2nd edition (July 2002) ISBN: 1568811829 Physically based Rendering Matt Pharr, Greg Humphreys Morgan Kaufmann; Bk&CD-Rom edition (August 4, 2004) ISBN: 012553180X Graphics Gems I preface by Andrew S. Glassner Morgan Kaufmann; 1st edition (June 1, 1990) ISBN: 0122861663 Graphics Gems II edited by James Arvo Morgan Kaufmann; 1st edition (October 1992) ISBN: 0120644819 Graphics Gems III edited by David Kirk Academic Press; Book and Disk edition (January 1993) ISBN: 0124096735 Graphics Gems IV edited by Paul S. Heckbert Morgan Kaufmann; Book and Disk edition (January 15, 1994) ISBN: 0123361559 Graphics Gems V edited by Allan W. Paeth Morgan Kaufmann; Book and Disk edition (January 15, 1995) ISBN: 0125434553 GPU Gems edited by Randima Fernando Addison-Wesley Professional; Book & CD-Rom edition (March 22, 2004) ISBN: 0321228324 GPU Gems 2 edited by Matt Pharr, Randima Fernando Addison-Wesley Professional; Book & CD-Rom edition (March 3, 2005) ISBN: 0321335597 GPU Gems 3 edited by Hubert Nguyen Addison-Wesley Professional; 1 Har/Cdr edition (August 2, 2007) ISBN: 0321515269 Direct3D ShaderX: Vertex and Pixel Shader Tips and Tricks Wolfgang Engel Wordware Publishing; Bk&CD-Rom edition (June 30, 2002) ISBN: 1556220413 ShaderX2: Introductions and Tutorials with DirectX 9.0 Wolfgang Engel Wordware Publishing, Inc.; Pap/Cdr edition (November 2003) ISBN: 155622902X ShaderX2: Shader Programming Tips and Tricks with DirectX 9.0 Wolfgang Engel Wordware Publishing, Inc.; Bk&CD-Rom edition (October 25, 2003) ISBN: 1556229887 ShaderX3: Advanced Rendering with DirectX and OpenGL Wolfgang Engel Charles River Media; 1 edition (November 2004) ISBN: 1584503572 ShaderX4: Advanced Rendering Techniques Wolfgang Engel Charles River Media; 1 edition (January 12, 2006) ISBN: 1584504250 ShaderX5: Advanced Rendering Techniques Wolfgang Engel Charles River Media; 1 edition (December 14, 2006) ISBN: 1584504994 Game Programming 3D Game Engine Design David H. Eberly Morgan Kaufmann; Book and CD-ROM edition (September 2000) ISBN: 1558605932 3D Game Engine Architecture: Engineering Real-Time Applications with Wild Magic David H. Eberly Morgan Kaufmann; Book and CD-ROM edition (December 17, 2004) ISBN: 012229064X 3D Games Volume 1: Real-Time Rendering and Software Technology Alan Watt, Fabio Policarpo Addison-Wesley Pub Co; Book and CD-ROM edition (December 15, 2000) ISBN: 0201619210 3D Games, Volume 2: Advanced Real-time Rendering and Animation Alan Watt, Fabio Policarpo Addison-Wesley Publishing; Book and CD-ROM edition (January 17, 2003) ISBN: 0201787067 Game Programming Gems edited by Mark DeLoura Charles River Media; Book and CD-ROM edition (August 2000) ISBN: 1584500492 Game Programming Gems 2 edited by Mark DeLoura Charles River Media; Book and CD-ROM edition (October 1, 2001) ISBN: 1584500549 Game Programming Gems 3 edited by Dante Treglia, Mark DeLoura Charles River Media; Book and CD-ROM edition (July 2002) ISBN: 1584502339 Game Programming Gems 4 edited by Andrew Kirmse Charles River Media; Book and CD-ROM edition (March, 2004) ISBN: 1584502959 Game Programming Gems 5 edited by Kim Pallister Charles River Media; Book and CD-ROM edition (February, 2005) ISBN: 1584503521 Game Programming Gems 6 edited by Mike Dickheiser Charles River Media; 1st edition (March, 2006) ISBN: 1584504501 Mathematics for 3D Game Programming & Computer Graphics Eric Lengyel Charles River Media; (December 18, 2001) ISBN: 1584500379 Essential Mathematics for Games and Interactive Applications: A Programmer's Guide James M. Van Verth, Lars M. Bishop Morgan Kaufmann; Bk&Cdr edition (March 25, 2004) ISBN: 155860863X Tricks of the 3D Game Programming Gurus - Advanced 3D Graphics and Rasterization André LaMothe Sams; Book and CD-ROM edition (June 2, 2003) ISBN: 0672318350 Networking / Multiplayer Massively Multiplayer Game Development Thor Alexander (Editor) Delmar Thomson Learning; Book & CD-Rom edition (February 14, 2003) ISBN: 1584502436 Massively Multiplayer Game Development Thor Alexander (Editor) Delmar Thomson Learning (February, 2005) ISBN: 1584503904 Networking and Online Games: Understanding and Engineering Multiplayer Internet Games Grenville Armitage, Mark Claypool, Philip Branch John Wiley & Sons (June 5, 2006) ISBN: 0470018577 Algorithms and Networking for Computer Games Jouni Smed, Harri Hakonen John Wiley & Sons (July 11, 2006) ISBN: 0470018127 Artificial Intelligence On Intelligence Jeff Hawkins Times Books (October 3, 2004) ISBN: 0805074562 Artificial Intelligence, A Modern Approach (2nd Edition) Stuart Russel, Peter Norvig Prentice Hall, 2nd edition (December 20, 2002) ISBN: 0137903952 AI Game Development Alex J. Champandard New Riders Publishing; 1st edition (October 31, 2003) ISBN: 1592730043 AI Game Engine Programming Brian Schwab Delmar Thomson Learning, Book & CD-Rom edition (September, 2004) ISBN: 1584503440 Artificial Intelligence for Games Ian Millington Morgan Kaufmann, Bk & DVD edition (June 21, 2006) ISBN: 0124977820 Artificial Intelligence For Computer Games: An Introduction John David Funge Peters Corp. (July 29, 2004) ISBN: 1568812086 Programming Game AI by Example Mat Buckland Wordware Publishing, Inc. (November 2004) ISBN: 1556220782 AI Game Programming Wisdom Edited by Steve Rabin Charles River Media ISBN: 1584500778 AI Game Programming Wisdom 2 Edited by Steve Rabin Charles River Media ISBN: 1584502894 AI Game Programming Wisdom 3 Edited by Steve Rabin Charles River Media; 1 edition (March 9, 2006) ISBN: 1584504579 AI Game Programming Wisdom 4 Edited by Steve Rabin Charles River Media; 1 edition (February 20, 2008) ISBN: 1584505230 Game AI Pro: Collected Wisdom of Game AI Professionals Edited by Steve Rabin A K Peters/CRC Press; 1 edition (September 11, 2013) ISBN: 1466565969 Principles of Robot Motion H. Choset and all Englewood Cliffs and New Jersey: MIT Press, 2005 ISBN: 0262033275 Physics / Dynamics Simulation Robot Dynamics Algorithms Roy Featherstone The Kluwer International Series in Engineering and Computer Science Kluwer Acedemic Series, June 1987 ISBN: 0898382300 Physically-Based Modeling for Computer Graphics: A Structured Approach Ronen Barzel, Foreword by Alan H. Barr October 1992 ISBN: 01207988008 Computational Dynamics Ahmed A. Shabana Wiley-Interscience, 2nd edition, February 2001 ISBN: 0471371440 Dynamics of Multibody Systems Ahmed A. Shabana Cambridge University Press, 2nd edition, April 1998 ISBN: 0521594464 Dynamic Simulations of Multibody Systems Murilo G. Coutinho Springer Verlag, July 2001 ISBN: 038795192X Physics based Animation Kenny Erleben, Jon Sporring, Knud Henriksen, Henrik Dohlmann Charles River Media (August 9, 2005) ISBN: 1584503807 Game Physics David H. Eberly Morgan Kaufmann, Book & CD-Rom edition (December 8, 2003) ISBN: 1558607404 Game Physics Engine Development Ian Millington Morgan Kaufmann (March 5, 2007) ISBN: 012369471X Beginning Math and Physics for Game Programmers Wendy Stahler New Riders Games, Bk&CD-Rom edition (March 22, 2004) ISBN: 0735713901 Physics for Game Developers David M. Bourg O'Reilly & Associates, November 2001 ISBN: 0596000065 Physics for Game Programmers Grant Palmer Apress; 1 edition (April 20, 2005) ISBN: 159059472X Collision Detection in Interactive 3D Environments Gino van den Bergen Morgan Kaufmann, Book & CD-Rom edition (October 27, 2003) ISBN: 155860801X Real Time Collision Detection Christer Ericson Morgan Kaufmann, Book & CD-Rom edition (December 22, 2004) ISBN: 1558607323 Vehicle Physics Fundamentals of Vehicle Dynamics Thomas D. Gillespie SAE International (March 1992) ISBN: 1560911999 Motor Vehicle Dynamics - Modeling and Simulation Giancarlo Genta World Scientific Publishing Company (March 1997) ISBN: 9810229119 Automotive Transmissions - Fundamentals, Selection, Design and Application Gisbert Lechner, Harald Naunheimer, J. Ryborz Springer; 1 edition (November 15, 1999) ISBN: 354065903X The Multibody Systems Approach to Vehicle Dynamics Michael Blundell, Damian Harty Butterworth-Heinemann (July 14, 2004) ISBN: 0750651121 Start Your Engines: Developing Driving and Racing Games Jim Parker Paraglyph Press; 1 edition (July 1, 2005) ISBN: 1933097019 Linear Algebra Linear Algebra and its Applications David C. Lay Addison Wesley; 3 edition (July 18, 2002) ISBN: 0201709708 Matrix Computations by Gene H. Golub, Charles F. Van Loan Johns Hopkins University Press; 3rd edition (November 1996) ISBN: 0801854148 Fundamentals of Matrix Computations by David S. Watkins John Wiley & Sons; 2nd edition (May 15, 2002) ISBN: 0471213942 Practical Methods of Optimization R. Fletcher John Wiley & Sons, 2nd edition, May 2000 ISBN: 0471494631 Linear Complementarity, Linear and Nonlinear Programming Katta G. Murty Heldermann Verlag, 1988 web: http://ioe.engin.umich.edu/books/murty/linear_complementarity_webbook/ The Linear Complementarity Problem Richard W. Cottle, Jong-Shi Pang, Richard E. Stone Academic Press, February, 1992 ISBN: 0121923509 Finite-Dimensional Variational Inequalities and Complementarity Problems, Volume I Francisco Facchinei, Jong-Shi Pang Springer Verlag; (February 6, 2003) ISBN: 0387955801 Geometry Computational Geometry: Algorithms and Applications Mark de Berg, M. van Krefeld, M. Overmars, O. Schwarzkopf Springer; 2 edition (February 18, 2000) ISBN: 3540656200 Computational Geometry in C Joseph O'Rourke Cambridge University Press; 2000 edition (February 15, 2001) ISBN: 0521649765 Geometric Tools for Computer Graphics Phylip J. Schneider, David H. Eberly Morgan Kaufmann Publishers; (September 2002) ISBN: 1558605940 Geometric Data Structures for Computer Graphics Elmar Langetepe, Gabriel Zachmann A K Peters Ltd (February 1, 2006) ISBN: 1568812353 Misc Signal Processing With Lapped Transforms Henrique S. Malvar Artech House Publishers (January 1992) ISBN: 0890064679 Visualizing Quaternions Andrew J. Hanson Morgan Kaufmann (January 31, 2006) ISBN: 0120884003 Computer Animation, Second Edition: Algorithms and Techniques Rick Parent Morgan Kaufmann; 2 edition (October 1, 2007) ISBN: 0125320000 General Programming Computational Complexity Christos H. Papadimitriou Addison Wesley, Reprinted with corrections August 1995 ISBN: 0201530821 Introduction To Algorithms Thomas H. Cormen, Charles E Leiserson, Ronald L. Rivest, Clifford Stein The MIT Press; 2nd edition (September 1, 2001) ISBN: 0262032937 Numerical Recipes in C++ William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery Cambridge University Press; 2 edition (February, 2002) ISBN: 0521750334 Numerical Recipes Example Book (C++) William T. Vetterling, William H. Press, Saul A. Teukolsky, Brian P. Flannery Cambridge University Press; 2 edition (March 1, 2003) ISBN: 0521750342 Write Portable Code Brian Hook No Starch Press; 1 edition (July 15, 2005) ISBN: 1593270569 Write Great Code: Volume 1: Understanding the Machine Randall Hyde No Starch Press; 1 edition (October 25, 2004) ISBN: 1593270038 Write Great Code: Volume 2: Thinking Low-Level, Writing High-Level Randall Hyde No Starch Press; 1 edition (March 18, 2006) ISBN: 1593270658 C++ Language The C++ Standard : Incorporating Technical Corrigendum No. 1 (Hardcover) Bjarne Stroustrup John Wiley & Sons; 2nd edition (December 5, 2003) ISBN: 0470846747 The C++ Programming Language (Special Edition) Bjarne Stroustrup Addison-Wesley Professional; 3 edition (February 15, 2000) ISBN: 0201700735 The Annotated C++ Reference Manual Margaret A. Ellis, Bjarne Stroustrup Addison-Wesley Professional (January 1, 1990) ISBN: 0201514591 The Design and Evolution of C++ Bjarne Stroustrup Addison-Wesley Professional; 1st edition (March 29, 1994) ISBN: 0201543303 C++ Coding Standards Herb Sutter and Andrei Alexandrescu Addison-Wesley Professional (October 25, 2004) ISBN: 0321113586 Imperfect C++ Matthew Wilson Addison-Wesley, 2004 ISBN: 0321228774 Effective C++ (third edition) Scott Meyers Addison-Wesley Professional; 3 edition (May 12, 2005) ISBN: 0321334876 The Elements of C++ Style Trevor Misfeldt, Gregory Bumgardner and Andrew Gray Cambridge University Press; 1st edition (July 15, 2002) ISBN: 0521893089",
    "commentLink": "https://news.ycombinator.com/item?id=37527928",
    "commentBody": "Books for Game DevelopersHacker NewspastloginBooks for Game Developers (mrelusive.com) 161 points by Decabytes 15 hours ago| hidepastfavorite50 comments i_c_b 13 hours agoWow. This post gave me emotional whiplash.I opened the collection of links, which is quite good if a bit old. But then I had a subconscious mental itch, and thought, wait... where had I heard the name mrelusive before? That sounds _really_ familiar.And then I remembered - oh, right, mrelusive, JP-what&#x27;s-his-name. I&#x27;ve read a huge amount of his code. When I was working on Quake4 as a game programmer and technical designer, he was writing a truly prodigious amount of code in Doom 3 that we kept getting in code updates that I was downstream of.And he was obviously a terrifically smart guy, that was clear.But I had cut my teeth on Carmack&#x27;s style of game code while working in earlier engines. Carmack&#x27;s style of game code did, and still does, heavily resonate with my personal sensibilities as a game maker. I&#x27;m not sure if that particular style of code was influenced by id&#x27;s time working with Objective-C and NeXTStep in their earlier editors, but I&#x27;ve long suspected it might have been - writing this comment reminds me I&#x27;d been meaning to explore that history.Anyway, idTech4&#x27;s actual game (non-rendering) code was much less influenced by Carmack, and was written in a distinctly MFC-style of C++, with a giant, brittle, scope-bleeding inheritance hierarchy. And my experience with it was pretty vexed compared to earlier engines. I ultimately left the team for a bunch of different reasons a while before Quake4 shipped, and it&#x27;s the AAA game I had the least impact on by a wide margin.I was thinking about all this as I was poking over the website, toying with the idea of writing something longer about the general topics. Might make a good HN comment, I thought...But then I noticed that everything on his site was frozen in amber sometime around 2015... which made me uneasy. And sure enough, J.M.P. van Waveren died of cancer back in 2017 at age 39. He was a month younger than me.I didn&#x27;t really know him except through his code and forwards from other team members who were interacting with id more directly at the time. But what an incredible loss. reply wk_end 8 hours agoparentJust wanna say that I loved Soldier of Fortune. Lots of FPSs around that time felt really like and plastic-y. SoF was one of the few that made shooting a gun feel satisfying and visceral (and I’m not even talking about the gore, I played the censored version). reply i_c_b 5 hours agorootparentThanks! That&#x27;s really cool to hear, 20+ years later.I actually did all the effects work on the weapons (muzzleflashes, smoke, explosions, bullet holes and surface sprays, and all the extensions to Quake2&#x27;s particle systems to make that content possible) and all the single player weapons system game balancing, as a matter of fact. Both the sound design and animation &#x2F; modelling on the weapons went through a number of iterations to get them really over-the-top and delightfully powerful &#x2F; ridiculous, too - I was lucky to work closely with a great sound designer and a really talented animator on that. reply mentos 12 hours agoparentprevMy biggest takeaway from my time programming in Objective-C was not being afraid to name functions and variables more verbosely.Curious to hear what aspects of Objective-C you feel influenced id? reply i_c_b 12 hours agorootparentWell, as I say, I&#x27;d been meaning to look into this in more detail because it&#x27;s something I&#x27;d been long curious about. But I don&#x27;t think I have time right now to dig into it. reply dang 11 hours agorootparentIf and when you do, I hope you&#x27;ll write about it and post it to HN! reply musicale 8 hours agorootparentprev> Curious to hear what aspects of Objective-C you feel influenced id?Well, &#x27;id&#x27; is the generic object type in ObjC. ;-) reply BigHatLogan 9 hours agoparentprevReally enjoyed this comment--thanks for sharing. Game development really sounds like such a different beast from standard line-of-business programming. Always enjoy hearing stories about it and reading books about it (Masters of Doom comes to mind). reply i_c_b 6 hours agorootparentThanks! I&#x27;ve been thinking a lot recently about maybe getting some of my own stories down. The late 90&#x27;s were a really fascinating time to be in games.And I loved Masters of Doom, too, although it was weird reading it and occasionally seeing people I knew show up in it, briefly. reply BigHatLogan 5 hours agorootparentYou should write them down. I would love to read them, and I&#x27;m positive many others would, too. The 90s gaming scene is incredibly fascinating to read about, especially as it started to shift from the cowboy ethic to the corporate ethic (both have their pros and cons). I think I speak for a lot of us when I say we&#x27;d love to hear what you have to share. reply xeonmc 9 hours agoparentprevDid you know where the idea of crouch sliding came from? reply i_c_b 6 hours agorootparentI ... hmm. My memory is really, really dusty on that.I remember I had a handful of conversations with Bryan Dube during development about Q4 deathmatch. He was a super sharp game programmer &#x2F; technical designer who had done a ton of the work on Soldier of Fortune 2 deathmatch previously, and had worked on the Urban Terror mod for Quake 3 before that. And he was much more focused on multiplayer than I was.We talked a lot about weapons (as I had done most of the code side work on weapons in Soldier of Fortune), but I&#x27;m now remembering him being really keen at the time on adding more high skill play to Q4 deathmatch. We all loved rocket jumping, and I remember him really wanting to add other kinds of high skill movement.So that much I definitely remember. More than that and my memory is kind of fuzzy. To be honest, lots of team members loved deathmatch and Quake, and all of us were of course talking about gameplay possibilities all the time, so it&#x27;s possible the idea originated somewhere else on the team. reply xeonmc 1 hour agorootparentnext [–]&#x2F;&#x2F; RAVEN BEGIN &#x2F;&#x2F; bdube: crouch slide, nick maggoire is awesomehttps:&#x2F;&#x2F;github.com&#x2F;bc85&#x2F;quake4&#x2F;blob&#x2F;master&#x2F;game&#x2F;physics&#x2F;Phys... reply wormius 13 hours agoprevHuh - went to the main page to see who \"Mr Elusive\" was and found out that he was a Doom programmer and authored a lot of papers.https:&#x2F;&#x2F;mrelusive.com&#x2F;publications&#x2F;pubs_bytype.htmlHis ACM contributions: https:&#x2F;&#x2F;dl.acm.org&#x2F;profile&#x2F;81504687994And he died in 2017 :( \"Carmack paid tribute to him with the comment that he was \"the best developer I ever worked with, my right hand, and a good friend. It was an honor.\"\"https:&#x2F;&#x2F;www.gamedeveloper.com&#x2F;programming&#x2F;obituary-jan-paul-... reply okaleniuk 40 minutes agoprevWhat do you think about Geometry for Programmers? https:&#x2F;&#x2F;www.manning.com&#x2F;books&#x2F;geometry-for-programmersIt has been recently published (April 2023) and not yet in any lists. reply meheleventyone 13 hours agoprevMissing any Game Design books so my picks:Game Feel - Steve Swink - 2008The Art of Game Design a Deck of Lenses - Jesse Schell - 2014101 Things I Learned in Architecture School - Matthew Frederick - 2007Writing for Games: Theory & Practice - Hannah Nicklin - 2022Procedural Generation in Game Design - Tanya Short&#x2F;Tarn Adams - 2017Procedural Storytelling in Game Design - Tanya Short&#x2F;Tarn Adams - 2019A Theory of Fun - Raph Koster - 2013 reply jaaron 12 hours agoparentJust want to add a +1 for these, particularly Art of Game Design, A Theory of Fun, and the Tanya Short&#x2F;Tarn Adams books.To add to your list: I have a copy of Designing Games: A Guide to Engineering Experiences that I recently started reading. reply anttiharju 3 hours agorootparentAlso want to add +1 for A Theory of Fun by Raph Koster. It&#x27;s a very lightweight read with pictures, yet still changed the way I think about what is fun, and learning in general. reply mikro 11 hours agoparentprevI enjoyed this book to practice game design:Challenges for Games Designers: Non-Digital Exercises for Video Game Designers - Brenda Romero &#x2F; Ian Schreiber reply Cognitron 12 hours agoparentprevAnother good one on the game design side of things:Designing Games: A Guide to Engineering Experiences by Tynan Sylvester (RimWorld) reply jaaron 12 hours agorootparentHa! I must have been editing my comment as you were writing yours. I just started into Sylvester&#x27;s book. reply mentos 12 hours agoparentprev+1 for A Theory of FunRaph illuminated things about the psychology of what makes games fun that Id never realized nor seen before. reply jessetemp 13 hours agoprevCirca 90s and early 2000s.I like how there&#x27;s a whole book on quaternions. I&#x27;ve never understood them and I&#x27;m convinced every definition I&#x27;ve read was written by someone who also didn&#x27;t understand them. I might try to find a copy if I ever dabble in 3d againEdit: To clarify, I understand the need for quaternions (to avoid gimbal lock), just not how to use them manually. Euler angles are simple enough, I can change whichever axis by some degrees or radians. But with quaternions I never understood what was going on under the hood reply okaleniuk 31 minutes agoparentWe used quaternions in our engine back in 2005-2008. Compared to matrix multiplications, multiplying quaternions was cheaper so we could save a few instructions here and there. But I never used them since.One reason being, I suppose, processors are now much more superscalar-friendly so a matrix multiplication doesn&#x27;t take much more time than a quaternion multiplication does. And with matrices, you get the whole package: not only rotations, but translations, scalings, and even projections, - all in one go. So you have simpler code, simpler data structures, and you don&#x27;t lose performance so... why bother?I didn&#x27;t even include quaternions in my book. Well, not that I didn&#x27;t want to. We had a whole discussion with the publisher about whether we should keep the whole chapter (complex numbers, conformal transformations, non-commutative 3D rotations, and quaternions) and I lost. reply smcameron 12 hours agoparentprevOne thing to know about quaternions is that you do not need to understand them in order to know how to use them, much as you do not need to understand how an automatic transmission works in order to drive a car. The knowledge of how to use them is completely separable from the knowledge of why they work, and if you concentrate on the former, and don&#x27;t worry about the latter, much progress can be made.Edit to add: When I say \"you don&#x27;t need to understand how they work to use them\", I mean, you can literally implement all the math to multiply, conjugate, scale and invert quaternions from basic math operators and floating point numbers in C, and use those operations to rotate 3d objects around in your program successfully, all without having any idea why they work. I know this, because I have done it.The basis for my understanding how to use quaternions, and how to build the basic operations on them comes from this site, which is quite concise and dense, but contains the necessary information if you can beat your head against it persistently: http:&#x2F;&#x2F;www.tutis.ca&#x2F;Rotate&#x2F;7quaternions.htm reply dragontamer 13 hours agoparentprev> quaternionsInstead of representing a rotation by roll, pitch, and yaw... you represent rotations by a 4x4 matrix. As this is a 3-dimension problem being represented in a 4-dimensional matrix, you have some weirdness to the math (IE: you need an additional constraint) but otherwise things get easier.---------\"Why is it easier?\" Because roll &#x2F; pitch &#x2F; yaw systems have Gimbal Lock.That&#x27;s... pretty much all you need to know as far as I&#x27;m concerned. Its a different system of representing rotations for reasons that the \"classic\" system messes up in.------------The math for quaternions is hard, but... who uses math these days? Just go into Blender, click the Quaternion button, and click the up&#x2F;down buttons on the Quaternion matrix to see how the different values rotate the object.Once you practice both \"classic\" (pitch&#x2F;yaw&#x2F;roll) vs \"quaternions\" for... I dunno... 10 minutes? It becomes blatantly obvious that quaternions are easier to use. Its not even close. And I&#x27;m not sure if anyone has to implement the math of them anymore in any circumstances, so its just a matter of practicing them inside a 3d modeling program to see how to use it.After you&#x27;ve learned how to use quaternions, then you go back and learn the math behind it. If you care to. Or don&#x27;t, its not like you need to know what the matrix represents exactly...---------EDIT: Consider animation. If you&#x27;ve got an object that&#x27;s rotating from (roll: 90-degrees, pitch: 90-degrees, yaw: 0-degrees), into (roll: 0-degrees, pitch: 180-degrees, yaw: 90-degrees), and you change this by going...(90, 90, 0)(89, 91, 1)(88, 92, 2)...(2, 178, 88)(1, 179, 89)(0, 180, 90)Did the object rotate and \"look\" correct in all frames?Now do the same with the 4x4 matrix quaternion. This is all just a simple click in Blender + animation keyframes. Does the object look better?Weird crap happens in the roll&#x2F;pitch&#x2F;yaw form. Weird in ways that&#x27;s difficult to describe in words, but easy as crap to see in 30-seconds of Blender. So just pull out a 3d modeling program and look at the damn thing, its really obvious. reply andersa 12 hours agorootparentA quaternion is not a 4x4 transformation matrix. In game development context, it usually refers to a structure consisting of 4 floats and is always assumed to be normalized.Maybe reading this comment helps: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37527928#37529562 reply lobf 5 hours agorootparentI love that the replies are kind of reinforcing OPs point that nobody seems to understand reply meheleventyone 13 hours agoparentprevWhilst a lot of those books are old, some are covering subjects like Quaternions that have been well understood for hundreds of years if not much longer. They&#x27;re not necessarily lacking in value. There&#x27;s a lot there that&#x27;s pretty evergreen. reply eestrada 12 hours agoparentprevMy (poor) understanding of quaternions is they are like a vector with a rotation angle around the axis of the vector. This is probably incorrect on many levels. But it was a simple enough explanation that it made sense to my brain why this would work better than simple SRT transform parameters for avoiding gimbal lock. It&#x27;s been several years since I needed to deal with 3D transformations of any sort, so I&#x27;m a bit rusty on all this. reply xeonmc 11 hours agorootparentUltimately, the “canonical” representation of rotation state is still axis-angles, thanks to Euler’s rotation theorem (any combo of rotation results in just one rotation around some final axis)(normalized) Quaternions are just the intermediate representation of axis-angles, they describe the component-wise algebra of combining axis-angle rotations [Euler-Rodrigues formula](https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Euler–Rodrigues_formula)Game engines just leaves them as quaternions for performance reasons.A 2D analogy would be “angle”[quaternion] “45deg”[sqrt2 , sqrt2]The [ Re , Im ] form is convenient for manipulating by coordinates, but the “final” succinct representation is still “angle”, because the component-wise form has more degrees of freedom than necessary.Summary: Quaternion = sqrt( exp(axis_angle) ) = exp(axis_angle&#x2F;2) = cos(angle&#x2F;2) + axis*sin(angle&#x2F;2)And (lw,lx,ly,lz)*(rw,rx,ry,rz) = (w,x,y,z) where w = ww-xx-yy-zz x = wx+xw+yz-zy y = wy+yw+zx-xz z = wz+zw+xy-yx where ww,wx,wy,wz = lw*rw,lw*rx,lw*ry,lw*rz xw,xx,xy,xz = lx*rw,lx*rx,lx*ry,lx*rz yw,yx,yy,yz = ly*rw,ly*rx,ly*ry,ly*rz zw,zx,zy,zz = lz*rw,lz*rx,lz*ry,lz*rz reply zerr 13 hours agoparentprevInstead of Euler angles, you use one axis and one angle, because the former has a limitation named as \"gimbal lock\". reply hknapp 13 hours agoparentprevmakes it easier when you understand complex numbershttps:&#x2F;&#x2F;www2.clarku.edu&#x2F;faculty&#x2F;djoyce&#x2F;complex&#x2F; reply alex_lav 13 hours agoparentprevSounds like they&#x27;re the gamedev equivalent of a Monad? Which I only vaguely understand as a result of a poster on this forum&#x27;s \"Everyone explains it wrong\" style post. Hoping you get a similar response with this. reply Animats 12 hours agorootparentQuaternions tend to be over-complicated.Basic concept, 1 dimensional form: you want to represent a direction in a 2D plane. You can use one number, a heading angle, but at some point you reach a full circle and the number has to wrap. This creates annoying special cases. So another approach is to use a 2D vector, a point on a circle. Those are usually normalized so that x^2 + y^2 = 1. No angle is \"special\". You can average and filter such vectors without problems, for example. This is called a homogeneous representation, because it behaves the same everywhere in its space.Now upgrade to 2D - latitude and longitude. Near the poles, small positional changes cause huge latitude changes, and computation error increases. This is a serious problem in navigational systems. So it&#x27;s common to represent latitude and longitude inside of GPS systems as a 3-component vector, a point on a sphere, in what&#x27;s called \"Earth-centered, earth fixed\" form. Now you can average or difference measurements without special cases. (Yeah, WGS-84 to compensate for planet not being a perfect sphere, etc.)Now upgrade to 3D orientation. That&#x27;s a quaternion. It&#x27;s a point on a 4-dimensional hypersphere. This can be mapped to a 3D vector pointing in space and a roll around that vector, or to pitch-roll-yaw, etc. As above, a quaternion is a unit vector. It&#x27;s hard to visualize this, so just shut up and calculate. reply pclmulqdq 10 hours agorootparentI am going to be the HN pedant here, and for that I apologize.Quaternions don&#x27;t specifically need to be unit vectors or points on a 4-D hypersphere. They are any number with 3 imaginary parts and 1 real part. Being a unit operator is a property of a rotation (this holds true even if you aren&#x27;t using quaternions or if you extend to n-dimensional rotations), not a property of quaternions. reply andersa 9 hours agorootparentIn the context of game development, \"quaternion\" almost always refers to a normalized one that represents a rotation. Many engines aren&#x27;t even capable of representing anything else with their quaternion types and enforce this automatically. reply andersa 12 hours agorootparentprevWow, I had never seen this explanation before. That makes so much sense! Now I finally understand why we always normalize the quaternions and why that is a sensible operation... reply dang 12 hours agoprevRelated:Books For Game Developers - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=6309464 - Sept 2013 (32 comments)Normally we downweight lists (see https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37518838 from yesterday) but the top comments in this thread are so good, I&#x27;m exempting this one. reply vishaalk 2 hours agoprevDoes anyone know if the books in this list cover \"gameplay systems\"? I am 9 months into my game dev job after 7 years of experience at SaaS, and I looked a lot for examples of how to design something like a buff&#x2F;debuff system or passives and came up short. Would appreciate some literature in this space because I feel like so many games have them that I don&#x27;t want to re-invent the wheel each time. reply OCASMv2 13 hours agoprevDo magazines count?https:&#x2F;&#x2F;www.gdcvault.com&#x2F;gdmag reply pengaru 12 hours agoparent+1Many toilet hours were spent reading dead-tree versions gdmag and ddj back in my youth. reply Electrified 5 hours agoprevIt took awhile, but I finally found all of the books in the &#x27;Game Development Essentials&#x27; series by Jeannie Novak (https:&#x2F;&#x2F;www.jeannie.com&#x2F;gde)• Game Development Essentials: An Introduction (3rd Edition) • Game Interface Design (2nd Edition • Mobile Game Development • Game Industry Career Guide • Game QA & Testing • Game Audio Development • Game Level Design • Online Game Development • Gameplay Mechanics • Game Simulation Development • Game Artificial Intelligence • Game Project Management • Game Story & Character Development reply tester457 13 hours agoprevGood selection of older books.I didn&#x27;t see [1] Game Programming Patterns.[1]: https:&#x2F;&#x2F;gameprogrammingpatterns.com&#x2F; reply shepherdjerred 10 hours agoparentGame Programming Patterns was so helpful when I wrote a game engine! Both that book and Crafting Interpreters [0] by the same author are masterpieces.[0]: https:&#x2F;&#x2F;craftinginterpreters.com&#x2F; reply keyle 2 hours agorootparentRead the game programming one, and reading this at the moment and completely agree. reply OnlyMortal 13 hours agoparentprevI assume, given the headings there, it talks about Model&#x2F;View&#x2F;Controller as the way to organise a game (and an application as a whole)?If you’re interested in how to put a game together, MVC is an obvious model to follow.For those who don’t understand what I mean, you firstly worry about data and have a way to represent that. That data only been the “actors” state and position in the game. Nothing graphics related. Nothing to do with how they interact. This is the “model”.You then have completely separate code that can move those actors around by changing the values in the model. This will include state changes like collisions. No graphics involved.You then have separate code that draws the actors in the model based on their state.It isn’t obvious to many but this allows you to concentrate on the various areas that need coding. It also allows you to, say, easily change parts of the code as needs be. reply richardjam73 11 hours agoprevSome of these are available to be borrowed from the Internet Archive. Some are free to download. reply chem83 13 hours agoprev [–] Any good books on ECS? reply Dudester230602 12 hours agoparent [–] Given that ECS is just procedures (systems) mutating structured state (components, entities) any older book on Pascal programming should do. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post presents a detailed list of recommended books for game developers, encompassing numerous subjects pertinent to the field.",
      "These books provide valuable insights into computer graphics, game programming, artificial intelligence, as well as physics and dynamics simulation.",
      "Other topics covered in these volumes include design and application, linear algebra, optimization, and algorithms, providing a comprehensive knowledge base for aspiring and established game developers."
    ],
    "commentSummary": [
      "The forum discussion surrounds a collection of game development books, involving recommendations for further reading.",
      "There's a tribute and reminiscing section for a respected, deceased game developer, suggesting his influence in the field.",
      "The discussion places emphasis on quaternions; a complex number system users find beneficial in game development for representing 3D rotations."
    ],
    "points": 158,
    "commentCount": 50,
    "retryCount": 0,
    "time": 1694805518
  },
  {
    "id": 37529359,
    "title": "Johnny Cash Has Been Everywhere (Man)",
    "originLink": "http://www.johnnycashhasbeeneverywhere.com/",
    "originBody": "Johnny Cash Has Been EVERYWHERE (Man)! Play Pause Hurry up! Skip to End Distance travelled:0 km A hack by Iain Mullan for Music Hack Day London 2012 using MusixMatch , Toma.HK and Johnny Cash I've Been Everywhere on Covers FM 지도 위성 단축키 지도 데이터 ©2023 Google, INEGI 약관",
    "commentLink": "https://news.ycombinator.com/item?id=37529359",
    "commentBody": "Johnny Cash Has Been Everywhere (Man)Hacker NewspastloginJohnny Cash Has Been Everywhere (Man) (johnnycashhasbeeneverywhere.com) 160 points by haunter 11 hours ago| hidepastfavorite29 comments harry8 7 hours agohttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;I&#x27;ve_Been_EverywherePlacenames were all originally in Australia, adapted for the north american market. reply singingfish 5 hours agoparentAlso shout out to the Farrelly Brothers version https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Aunty_Jack_Sings_Wollongong reply rcme 6 hours agoprevAs computer scientists, we really should assume he took the shortest path between the final set of destinations rather than travel between them sequentially. reply gnfargbl 22 minutes agoparentJohnny Cash spent much of the 1950s and 1960s addicted to alcohol, barbiturates and amphetamines. Whilst we should assume he was probably familiar with contemporary work on finding shortest paths in weighted graphs, and almost certainly read the papers etc, it is likely that his addiction kept him from paying the proper attention that he would otherwise surely have done. Who knows how different the landscape of theoretical computer science might have been, had Cash spent more energy on algorithms and less on setting fires inside camper vans? reply M3L0NM4N 1 hour agoparentprevDijkstra&#x27;s been everywhere, man. reply taylorius 4 hours agoparentprevWas thinking the same thing - travelling salesman problem, no? reply 0x6c6f6c 6 hours agoparentprevAssume, or optimize for. reply CSMastermind 9 hours agoprevIt is delightful that people make things like this and I hope that we never reach a point where this type of things ceases to be possible. reply zeristor 1 hour agoprevOf this ilk Lemon Jelly released “Ramblin’ Man” a bloke reflecting on his past.Going through a list of places he’s been to:https:&#x2F;&#x2F;genius.com&#x2F;Lemon-jelly-ramblin-man-lyricsOf note, the first letters some way down spells out BAGPUSS SEES ALL THINGSWhich dates both it, and me. reply logbiscuitswave 8 hours agoprevThat was delightful. Reminds me of a Google Maps hack from back in the day that tracked Sir Mix-a-Lot’s trip through the Seattle area as documented in the song Posse on Broadway. reply figbert 5 hours agoparentIs there a link to a version of this that&#x27;s still live? Would love to check it out. reply mixdup 7 hours agoprevThere were a lot of places that didn&#x27;t map--some that were transcribed correctly and exist as places in the US, and some that didn&#x27;t map because they were transcribed incorrectly reply roflchoppa 5 hours agoprevThere’s a great bar in San Jose, “Cash Only”, get the frozen Irish coffee you won’t be disappointed. reply dang 9 hours agoprevRelated:Johnny Cash Has Been Everywhere (Man) (2012) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30830222 - March 2022 (54 comments) reply laen 8 hours agoprevDevil&#x27;s Lake didn&#x27;t populate, not sure why, maybe too difficult to disambiguate? It&#x27;s a city in North Dakota, but state parks in Oregon and Wisconsin. reply anonu 8 hours agoparentThe data in the javascript indicates it in ND:{ \"name\": \"Devils Lake\", \"full_name\": \"Devils Lake, ND 58301, USA\", \"lat\": 48.112779, \"lng\": -98.8651202 }, reply NoZebra120vClip 7 hours agorootparentpopulatedisambiguatestateindicateDevil&#x27;s Lakehttps:&#x2F;&#x2F;youtu.be&#x2F;Pr-Vfnd7Yno?si=ivrE5_ph4WPrzWdD reply dmurray 2 hours agoprevI&#x27;m also a fan of this map of Area Codes in Which Ludacris Claims to have Hos.https:&#x2F;&#x2F;archive.ph&#x2F;fwcw7 reply dboreham 49 minutes agoprevIncluding Kinghorn. reply pentagrama 7 hours agoprevDelightful! This small ideas bring joy to the internet.Wondering what will happen if this where made with a song of a current mainstream popstar baked by a big label and go viral. Will be shut down or will be allowed as a marketing strategy? reply pentagrama 6 hours agoprevAs viewing this on my phone, will like to enlarge those buttons a bit and make it more mobile friendly. Send it to my father but not sure if he will be able tap on that small things on even understand what is about :( reply karim79 9 hours agoprevIncredible site which I&#x27;ll celebrate by posting this highly addictive cover:https:&#x2F;&#x2F;youtu.be&#x2F;Uk2aHGjOdlQ?si=mIodxFSxrn7-t8Qj reply xeromal 7 hours agoparentThis is for folsom blues reply pentagrama 7 hours agoprevWith Open Street Map is possible to self host a project like this?Like download a static full map and host it, for this project doesn&#x27;t matter that will not get updated. reply butz 3 hours agoparentYou can download map tiles or build them yourself at required zoom level. But what might be even more interesting, especially for historical project, to use an era appropriate map. reply joelrwilliams1 6 hours agoprevThis is the Internet content I live for. reply aidenn0 9 hours agoprevWhat about the Geoff Mack version? reply te 3 hours agoparentStarts slow, but really gets going.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=1OZWi-mTkNU reply vlark 9 hours agoprev [–] This is the best link on this site today. Thank you. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Iain Mullan utilized MusixMatch, Toma.HK, and Covers FM during Music Hack Day London 2012 to create an innovative hack featuring Johnny Cash's song \"I've Been Everywhere.\"",
      "The hack entails a map showcasing the geographical span the legendary artist, Johnny Cash travelled, as described in his song.",
      "This creative geographical representation is visualized using Google's and INEGI's mapping data."
    ],
    "commentSummary": [
      "The article highlights a website named \"Johnny Cash Has Been Everywhere (Man)\" that charts all the locations mentioned in Johnny Cash's song \"I've Been Everywhere.\"",
      "User discussions in the article centre around related topics, including the shortest path between mentioned destinations.",
      "The discussion also touches on personal subjects such as Johnny Cash's addiction issues."
    ],
    "points": 156,
    "commentCount": 28,
    "retryCount": 0,
    "time": 1694813409
  },
  {
    "id": 37524890,
    "title": "Optimizing LLMs from a Dataset Perspective",
    "originLink": "https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html",
    "originBody": "Sebastian Raschka AI Magazine / Blog Books Courses Research Talks Contact Resources RSS Optimizing LLMs From a Dataset Perspective Sep 15, 2023 by Sebastian Raschka This article focuses on improving the modeling performance of LLMs by finetuning them using carefully curated datasets. Specifically, this article highlights strategies that involve modifying, utilizing, or manipulating the datasets for instruction-based finetuning rather than altering the model architecture or training algorithms (the latter will be topics of a future article). This article will also explain how you can prepare your own datasets to finetune open-source LLMs. Note that the NeurIPS LLM Efficiency Challenge is currently underway, aiming to train a Large Language Model on a single GPU within a 24-hour period, which is super interesting for practitioners and researchers interested in LLM efficiency. The techniques discussed in this article have direct relevance to this competition, and we will delve into how these dataset-centric strategies could potentially be applied within the challenge setting. Additionally, the article will offer suggestions for new experiments you might consider trying. This article is a cross-post that originally appeared here on the Lightning AI Blog. Supervised Instruction Finetuning # What is instruction-finetuning, and why should we care? Instruction finetuning is a method used to improve the performance of language models like ChatGPT and Llama-2-chat by having the model generate outputs for a range of example inputs paired with desired outputs. It allows for more controlled and desired behavior of the model in specific applications or tasks. Also, it can enhance the reliability, specificity, and safety of AI systems in real-world use cases. Annotated figure from InstructGPT paper Instruction finetuning uses a dataset consisting of instruction-response pairs to improve an LLM’s instruction-following capabilities. Such a dataset for instruction finetuning typically consists of three components: Instruction text Input text (optional) Output text The example below lists two training examples, one without and one with an optional input text: LLMs are then finetuned on these instruction datasets via next-token prediction (similar to pretraining). The difference from pretraining is that the model sees the whole instruction and input text as a context before it’s tasked to carry out the next-token prediction to generate the output text in an autoregressive fashion, illustrated below. This above-mentioned process for finetuning an LLM to generate the desired output in an iterative, token-wise fashion is also referred to as supervised finetuning. In practice, there is an additional optional finetuning stage following supervised finetuning, which uses additional preference data and ranking labels from human annotators who compare responses generated by LLMs. This process is also known as reinforcement learning with human feedback (RLHF), but it is out-of-scope for this article, which focuses on the instruction datasets themselves. (However, I have an optional article on RLHF here if you want to learn more.) The Finetuning Pipeline and Dataset Origins # When finetuning LLMs, datasets for instruction finetuning can be sourced in multiple ways: 1. Human-created: Expert annotators can provide explicit instructions and feedback, creating datasets for instruction finetuning. This is particularly useful for domain-specific tasks or for reducing particular biases or unwanted behaviors. 2. LLM-generated: We can generate a vast amount of potential input-output pairs using an existing LLM (if the terms of service permit). These can then be refined or rated by humans for quality and then used to finetune a new LLM. This method is usually more efficient than the abovementioned human-created approach because an available LLM, such as GPT-4 (via the API interface), can generate a large number of potential examples in a short time. The LLM finetuning pipeline using human-created or LLM-generated data is summarized in the recent and excellent Instruction Tuning for Large Language Models survey: Figure from Instruction Tuning for Large Language Models paper Additionally, we can also potentially combine both human-created and LLM-generated instruction data to get the best of both worlds. The upcoming sections will discuss LLM-generated and human-created datasets for instruction finetuning in more detail, including the recent research highlights. LLM-generated datasets # Dataset labeling has been a bottleneck in machine learning ever since. As a human annotator, simple labeling tasks like categorizing an image as “cat” or “dog” are already considered laborious when it has to be done at scale. Tasks requiring long-form text annotations can be even more time-consuming and challenging. So, a lot of effort has been devoted towards generating datasets for instruction finetuning automatically using existing LLMs. Self-Instruct One of the most prominent and widely used methods for LLM-generated datasets is Self-Instruct. So, how does it work? Briefly, it involves four stages: Seed task pool with a set of human-written instructions (175 in this case) and sample instructions; Use a pretrained LLM (like GPT-3) to determine the task category; Given the new instruction, let a pretrained LLM generate the response; Collect, prune, and filter the responses before adding them to the task pool. An early popular application of Self-Instruct was the Alpaca dataset, which consists of 52k LLM-generated instruction-response pairs. Alpaca was used to create the first finetuning Llama v1 model earlier this year. Backtranslation Another interesting type of approach involves working backward from the responses and generating the corresponding instructions via LLMs. In other words, rather than gathering datasets for instruction finetuning from human writers, it’s possible to employ an LLM to produce instruction-response pairs (also known as distillation). In a paper titled Self-Alignment with Instruction Backtranslation, researchers refined LLMs via “instruction backtranslation” and found that this method surpasses those trained on distillation datasets like Alpaca. NeurIPS Efficiency Challenge Rules Note that the NeurIPS LLM Efficiency Challenge, which is centered around training 1 LLM for 1 Day on 1 GPU, does not permit LLM-generated datasets. So, in the next section, High-Quality Datasets, we will focus on human-generated instruction datasets that we can use as an alternative. If you are interested in participating in the NeurIPS LLM Efficiency Challenge, I’ve written a quick starter tutorial here. A Note About LLM-generated Datasets and Imitation Models Before we jump into the discussion of human-generated datasets for instruction finetuning, I wanted to share a brief word of caution regarding LLM-generated datasets. Yes, generating datasets via LLMs may sound too good to be true, so it is important to evaluate LLMs finetuned on LLM-generated datasets extra carefully. For instance, in a recent The False Promise of Imitating Proprietary LLMs paper, researchers observed that crowd workers gave high ratings to LLMs trained on LLM-generated data. However, these so-called “imitation models” primarily replicated the style of the upstream LLMs they were trained on rather than their factual accuracy. High-quality Datasets: Less May Be More # In the previous section, we discussed datasets generated by LLMs. Now, let’s switch gears and examine a high-quality, human-generated dataset, which is also allowed in the NeurIPS LLM Efficiency Challenge. LIMA The LIMA: Less Is More for Alignment paper shows that quality trumps quantity when instruction finetuning datasets. In this study, researchers carefully selected 1,000 instruction pairs to finetune the 65-billion-parameter Llama-v1 model, known as LIMA, using supervised finetuning. Notably, other finetuned Llama models, such as Alpaca, were trained on a considerably larger dataset of 52,000 LLM-generated instruction pairs. In selected benchmarks, LIMA outperformed models that employed Reinforcement Learning with Human Feedback (RLHF) methods, including ChatGPT and GPT-3.5. Annotated figure from the LIMA paper The next section will show you how to get started with open-source LLMs and finetune these models on LIMA. Finetuning LLMs on LIMA # This section explains how to finetune open-source LLMs on instruction datasets like LIMA using the Lit-GPT repository. (Note that the NeurIPS LLM Efficiency Challenge organizers cleared LIMA for the competition. The NeurIPS LLM Efficiency Challenge organizers also selected Lit-GPT as the starter kit since the code is relatively easy to use and customize, which is an essential prerequisite for exploring new research directions.) As of this writing, the currently supported models in Lit-GPT are the following: Model and usage Reference Meta AI Llama 2 Touvron et al. 2023 Stability AI FreeWilly2 Stability AI 2023 Stability AI StableCode Stability AI 2023 TII UAE Falcon TII 2023 OpenLM Research OpenLLaMA Geng & Liu 2023 LMSYS Vicuna Li et al. 2023 LMSYS LongChat LongChat Team 2023 Together RedPajama-INCITE Together 2023 EleutherAI Pythia Biderman et al. 2023 StabilityAI StableLM Stability AI 2023 Platypus Lee, Hunter, and Ruiz 2023 NousResearch Nous-Hermes Org page Meta AI Code Llama Rozière et al. 2023 For this brief walkthrough, we will use the 7B parameter Llama 2 base model and finetune it on LIMA. Assuming you have cloned the Lit-GPT repository, you can get started via the following three steps: 1) Download and prepare the model: export HF_TOKEN=your_token python scripts/download.py \\ --repo_id meta-llama/Llama-2-7b-hf python scripts/convert_hf_checkpoint.py \\ --checkpoint_dir meta-llama/Llama-2-7b-hf 2) Prepare the dataset: python scripts/prepare_lima.py \\ --checkpoint_dir checkpoints/meta-llama/Llama-2-7b-hf 3) Finetune the model using low-rank adaptation (LoRA): python finetune/lora.py \\ --checkpoint_dir checkpoints/meta-llama/Llama-2-7b-hf \\ --data_dir data/lima Note that the –checkpoint_dir argument is required for preparing the dataset in step 2 because the dataset preparation is model-dependent. Different LLMs may use different tokenizers and special tokens, so it’s important to prepare the dataset accordingly. I am skipping a detailed explanations of the LoRA finetuning procedure to keep this article focused on the dataset perspective. However, if you are interested in learning more, you can see my article Finetuning Falcon LLMs More Efficiently With LoRA and Adapters. In addition, you may also find my NeurIPS 2023 LLM Efficiency Challenge Quickstart Guide article helpful, where I walk through the setup, finetuning, and model evaluation step by step. Tip According to the official competition rules, the maximum context length used for the evaluation is 2,048 tokens. Hence, I recommend preparing the dataset with a maximum length of 2,048 tokens: python scripts/prepare_lima.py \\ --checkpoint_dir checkpoints/meta-llama/Llama-2-7b-hf \\ --max_seq_length 2048 Alternatively you can edit the finetune/lora.py file and change override_max_seq_length = None to override_max_seq_length = 2048 to reduce the GPU memory requirements. In addition, I also suggest modifying the set max_iter setting and change it to max_iter = 1000 to finetune for ~1 pass over the LIMA dataset, which consists of 1k training examples. For reference, finetuning a 7B parameter model on 52k instruction pairs, such as in Alpaca, takes about 1 hour on an A100 GPU when using LoRA with default settings. Note that LIMA is 50x smaller than Alpaca, so finetuning will only take a few minutes. Title: Finetuning a 7B model on 52k data points via Finetuning Falcon LLMs More Efficiently With LoRA and Adapters (https://lightning.ai/pages/community/finetuning-falcon-efficiently/) Available Models and Datasets in Lit-GPT # As of this writing, there are currently multiple finetuning datasets supported in Lit-GPT. The Dolly and LIMA datasets are human-generated and should thus be fine for use in the NeurIPS LLM Efficiency Challenge. Additionally, if you are interested in using different datasets to customize LLMs for your projects, the next section will briefly explain how this works. Preparing New and Custom Datasets # In addition to the existing datasets mentioned above, you might be interested in adding new datasets or using your own datasets to finetune custom open-source LLMs. There are two main ways to prepare a dataset for the LLMs in Lit-GPT: Using the scripts/prepare_csv.py script to read an instruction dataset from a CSV file. Creating a custom scripts/prepare_dataset.py script similar to LIMA, which we used earlier. The easiest way to prepare a new dataset is to read it from a CSV file using the scripts/prepare_csv.py script in Lit-GPT. All you need is a CSV file that has the three column headers as shown below: Assuming you exported this dataset as MyDataset.csv, you can then prepare and finetune the model as follows: 1) Prepare the dataset: python scripts/prepare_csv.py \\ --csv_dir MyDataset.csv \\ --checkpoint_dir checkpoints/meta-llama/Llama-2-7b-hf 2) Finetune the model using low-rank adaptation (LoRA): python finetune/lora.py \\ --data_dir /data/csv \\ --checkpoint_dir checkpoints/meta-llama/Llama-2-7b-hf There are additional options for determining the random seed or train/split available that you can access via python scripts/prepare_csv.py --help If you are interested in the second option, creating a prepare_dataset.py script similar to LIMA, I added an explanation to the Lit-GPT documentation here. Additional Datasets to Consider # The previous section covered how to prepare custom datasets for open-source LLMs in Lit-GPT. If you don’t have your own dataset you want to experiment with but want to experiment with existing datasets (for example, the NeurIPS LLM Efficiency Challenge is restricted to publicly available datasets), here are a few pointers for datasets to explore. With the NeurIPS LLM Efficiency Challenge in mind, the list focuses on human-generated English datasets, not LLM-generated datasets. Open Assistant (multi-lingual) is a collection of assistant-like conversations created and annotated by humans. It contains 161,443 messages in 35 languages, enriched with 461,292 quality evaluations, resulting in more than 10,000 comprehensively annotated conversation trees. This dataset results from a global crowdsourcing initiative that engaged over 13,500 volunteers. Natural Instructions is an English instruction dataset handcrafted with 193K entries, spanning 61 unique NLP tasks. P3 (Public Pool of Prompts) is an instruction finetuning dataset constructed using 170 English NLP datasets and 2,052 English prompts. Prompts, sometimes named task templates, map a data instance in a conventional NLP task (e.g., question answering, text classification) to a natural language input-output pair. Flan 2021 is an English instruction dataset compilation created by converting 62 popular NLP benchmarks (including SNLI, AG News, and others) into pairs of language inputs and outputs. Research Directions to Explore # Now that we have covered the why and how related to instruction-finetuning, what interesting research directions can we explore to boost the performance of open-source LLMS? Merging Datasets Besides the P3 and Flan 2021 datasets mentioned above, I have not seen attempts to create larger datasets by combining datasets from multiple sources. For instance, it could make sense to experiment with combinations of LIMA and Dolly, and so forth. Dataset Ordering Following up on the dataset merging idea mentioned above, it could be interesting to explore the role of visiting different data points in different orders (for example, sorted or shuffled by the type of instruction). Besides the pretraining experiments done in the Pythia paper, I have not seen any studies on dataset ordering in the context of instruction finetuning. Multiple-Epoch Training Due to the large dataset size requirements, LLMs are usually pretrained for less than one epoch, which means that they don’t revisit data points multiple times. While computational costs are one reason for this, another is that LLMs can be prone to overfitting. Nonetheless, with many overfitting-reduction techniques at our disposal, studying multi-epoch training in the context of LLMs would be interesting. For instance, it’s possible to train LLMs on a small dataset like LIMA in a few minutes. Would it make sense to iterate over the dataset multiple times? Automatic Quality-filtering Does it make sense to adopt dataset filtering as a default? Related to the LIMA study discussed earlier, the AlpaGasus: Training A Better Alpaca with Fewer Data paper also emphasizes that a larger dataset isn’t necessarily advantageous for finetuning LLMs. In the AlpaGasus study, the researchers employed ChatGPT to pinpoint low-quality instruction-response pairs in the original 52,000-instance Alpaca dataset. They discovered that reducing this to just 9,000 high-quality pairs actually enhanced performance when training Llama-v1 LLMs with 7 billion and 13 billion parameters. Annotated figure from the AlpaGasus paper However, as mentioned earlier, the NeurIPS LLM Efficiency Challenge does not permit LLM-generated datasets. So, this Alpaca-based Alpagasus dataset would not be useful for this competition. A viable alternative to AlpaGasus might be to use an LLM to filter human-generated (instead of LLM-generated) datasets. However, I’m uncertain if using LLM-based dataset filtering is allowed, so it would be important to confirm with the organizers on their Discord channel before using such datasets in the competition. The upcoming sections will explain how to use datasets such as LIMA for training the latest open-source LLMs. Additionally, I will also highlight interesting research directions to try in the NeurIPS LLM Efficiency Challenge. Conclusion # This article covered instruction finetuning and explained the advantages of LLM-generated and human-generated datasets. We also went over a quick tutorial explaining how to finetune open-source LLMs with different datasets and how to use our own datasets to create custom LLMs. Compared to proprietary APIs and services, such custom LLMs can help leverage specific datasets at your company, improve LLMs on certain use cases, and give you full privacy control. If you have any questions, please don’t hesitate to reach out: If you have any suggestions, feedback, or problems with Lit-GPT, please consider filing an Issue on GitHub if you think it is a bug. Furthermore, Lit-GPT pull requests with improvements and implementations of new techniques would be very welcome! If you are participating in the NeurIPS LLM Efficiency Challenge, I hope you find this competition as useful and exciting as I do. I suggest starting with the Quick Starter Guide I compiled here. For questions about whether a particular dataset is allowed in the competition, I recommend double-checking with the organizers via their Discord channel. For Lit-GPT-related questions about the challenge, my colleagues at Lightning AI also maintain a Discord channel here. Happy learning, coding, and experimenting! If you liked this article, you can also find me on Twitter and LinkedIn where I share more content related to machine learning and AI. If you are looking for a way to support me and my work, consider purchasing one of my books or subscribing to the paid version of my free AI newsletter. If you find it valuable, I would really appreciate it if you could spread the word and recommend it to others. © 2013-2023 Sebastian Raschka",
    "commentLink": "https://news.ycombinator.com/item?id=37524890",
    "commentBody": "Optimizing LLMs from a Dataset PerspectiveHacker NewspastloginOptimizing LLMs from a Dataset Perspective (sebastianraschka.com) 129 points by alexmolas 18 hours ago| hidepastfavorite23 comments philipkglass 17 hours agoI have wondered if the very big models trained on a Big Pile of Everything can be used to curate smaller, higher quality data sets that lead to high performing models with smaller parameter counts. Not only are smaller models easier to distribute and faster at inference time, but it offers a licensing escape hatch if future copyright law changes or court rulings make it hard to publicly offer models trained on non-permissively licensed material.1) Train an initial big model on everything you can get, yielding a capable but tainted-in-some-jurisdictions model. Keep that model private.2) Use the big tainted model to narrow or distill the source data. One way is by identifying the document subset that can be used freely (old public domain works, user generated content uploaded to your own service that users already assented to your own company&#x27;s ToS on, government documents, things with unrestricted Creative Commons licensing...) The other way is by using it to build \"just the facts\" distillations from restrictively licensed material.3) Train an untainted model using just the factual distillations and&#x2F;or the permissively licensed material. reply theptip 7 hours agoparentSounds vaguely like the paper “textbooks are all you need”? Though they are not explicitly trying to remove the copyright taint.https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2306.11644 reply IanCal 16 hours agoparentprevNot sure on the licensing but yes you can do that technically.Phi-1 and therefore phi-1.5 are partially trained on gpt3.5 generated synthetic textbooks. reply saurik 12 hours agorootparentThe premise here is specifically not to train it on generated output of the bigger model but to merely use the bigger model to better curate non-generated (and thereby untainted) inputs for the training set of the smaller model. reply castles 5 hours agoparentprevI have also wondered if OpenAI are going to train a private model with all the ChatGPT history, and then use that to train a public model. reply 3abiton 11 hours agoparentprevDoesn&#x27;t that lead to model collapse? reply kordlessagain 10 hours agorootparentThe trick is training a little, then augmenting with documents using RAG. The idea that a model alone can handle complex use cases is common, but usually wrong. reply bordercases 6 hours agorootparentRAG? reply jdkee 6 hours agorootparentRetrieval augmented generation.See https:&#x2F;&#x2F;research.ibm.com&#x2F;blog&#x2F;retrieval-augmented-generation... reply nickpsecurity 7 hours agoparentprevThat&#x27;s what I proposed in my article in Alternative Models. Except, I wanted to use public-domain works (eg Gutenberg) for the base model so it&#x27;s legally clear. Then, for one with proprietary content, K-12-college textbooks, encyclopedias, and specialist works licensed for that purpose. Train the base like we train kids. Then, use it to generate or evaluate the rest.https:&#x2F;&#x2F;heswithjesus.com&#x2F;tech&#x2F;exploringai&#x2F;index.html reply packet_nerd 17 hours agoprevWhat would a good fine-tuning dataset for language translation look like?I want to try fine-tuning to machine translate to and from a fairly niche language (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;S&#x27;gaw_Karen_language). How much text would I need, and what format would be ideal?I have a number of book length texts, most only in the target language, and a few bilingual or multilingual. For the bilingual and multilingual texts, I can script out probably several thousand pairs of \"translate the following text fromto :\". Do I need to vary the prompt and format, or can I expect the LLM to generalize to different translation requests? Is there value in repeating the material in different lengths? One set of sentence lengths, another paragraph, and another page or chapter length? Also what should be done with the monolingual texts, just ignore them? reply kordlessagain 10 hours agoparentIf you want to fine tune Llama 2 or similar, then embed each pair together and separately and store them. Then, use the unlabeled data (the source text without translation) to query the embeddings for similar matches. You then send in the necessary prompt text with the matches, plus the text to translate. You&#x27;ll want to do this with a foundational model, like GPT-x.As noted below, extracting words or keyterms would maybe be a good idea, as they could be included in the training set.The training set would the be comprised of the prompt, the translation, and keyterms. As you will want to vet the generated texts anyway, you could then decide if the foundational model was working enough. You could also try to run the largest \"open\" model you could find on the prompts, to see if those needed training as well. There are many different Llama models trained on HuggingFace for language pairs, so see if your languages are already built and test those.I&#x27;m building a simple, Open Source ML pipeline manager at https:&#x2F;&#x2F;ai.featurebase.com&#x2F;. I&#x27;d be down to help you with this! reply soultrees 16 hours agoparentprevLanguage translation can be tricky because of the underlying nuances in each language so more context would probably be better, but using multiple steps to evaluate its performance on a key level would be a good way to improve the confidence.It might be beneficial to start your dataset at the key (word) level, generate some embeddings of the key pair in the source and target and stash them, then do the same for sentence level and just for fun, paragraph level. (I believe you could get enough context from the sentence level as a paragraph is just a group of sentences but it would still be interesting to generate paragraph level key pairs I think).From there you’d have a set of embeddings of each word src:tgt that also has context of how it fits in a sentence level and paragraph level with the respective nuances of each language.Once you have that dataset then you can augment your data with prompts like you’re using but also including some contextual references of word pairs, and sentence pairs in your prompt which should corner the LLM into the right path.Edit: not an expert so will heed if someone smarter comes along. reply packet_nerd 16 hours agorootparentOh, yes, pairs of words is a good idea. I also have a bilingual dictionary and can generate a prompt for each entry something like \"here&#x27;s a word in , write a dictionary definition for it in : : <lang_b_definition\". reply Philpax 17 hours agoprevI was hoping that this would go more into the details of dataset selection and what makes for high-quality data, but it seems to be more a prelude to a Lit-GPT advertisement :&#x2F; reply kordlessagain 10 hours agoparentI speculate high quality data can be compared to be similar via embeddings comparisons. By organizing the dataset using features, grouping the vectors by them, and ensuring the dataset relates to itself in a given domain by quality tags, we can speculate the data becomes better as we are more specific with our queries to it.I need to train more models to see if this is an accurate claim, but I&#x27;ve been finishing up the storage layer and haven&#x27;t gotten to that yet. reply pplonski86 17 hours agoprev [–] What are other than fine-tuning methods to make LLM smarter? Im familair with RAG - Retrival Augumented Generation. reply kordlessagain 10 hours agoparentEnsembles, for one. We might ask the same question of keyword extraction, for example, and then aggregate the results. Here&#x27;s a horrible example, but it works and runs on a GPU box: https:&#x2F;&#x2F;github.com&#x2F;FeatureBaseDB&#x2F;Laminoid&#x2F;blob&#x2F;main&#x2F;sloth&#x2F;sl...Keyterms can be used in the prompt to drive the LLM to better grounded responses as well as helping locate relevant embeddings for RAG, when vector search isn&#x27;t enough.Another consideration is writing code for processing things that look similar. For example, one might have the LLM write regex code which is then tested to work and put into production in a pipeline to parse log files, or write SQL off conversational queries, which are then run against a database. reply omneity 13 hours agoparentprevOther than fine-tuning and RAG, Guidance allows you to constrain the output of an LLM within a grammar, for example to guarantee JSON output 100% of the time.Here&#x27;s one library to do this https:&#x2F;&#x2F;github.com&#x2F;guidance-ai&#x2F;guidance reply heliophobicdude 17 hours agoparentprevPerhaps not smarter but filtering seemingly computed or non-derived answers in demonstration data. Also include demonstrations that show steps leading up to a computation in a format for a runtime to parse and execute the computation. Similar to the Code Interpreter or Advanced Data Analysis in ChatGPT.Taking it a step further, I would include in the demonstration a test harness set up with a test suite to prove the proposed implementation.I would go through each demonstration which a fixed set of criteria measuring only passing tests but ones that also show a level of complexity and usefulness.Why? I was looking through CodeLlamas demonstration data for fine tuning and saw answers that were not even checked for correctness or usefulness. reply rasbt 16 hours agoparentprev [–] RLHF is a popular candidate, but the focus is more on \"helpfulness\" and \"safety\" -- I don&#x27;t think it necessarily improves LLMs on reasoning benchmarks reply behnamoh 15 hours agorootparent [–] if anything, RLHF makes the model dumber, not smarter. reply rasbt 15 hours agorootparent [–] I think it could potentially make the model smarter, but it&#x27;s up to how you collect the data to train the reward models. Currently, companies & papers that use RLHF focus on \"safety\" rankings, for example. But you could potentially collect labels \"smartness\" or \"correctness\" instead and train the the reward model one these. (And then use that reward model to finetune the LLM you want to improve.) replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explores the strategy of optimizing large language models (LLMs) using fine-tuning with carefully selected datasets.",
      "It details the process of instruction fine-tuning a 7B parameter language model on the LIMA dataset and mentions the potential of auto quality filtering.",
      "The article also refers to the NeurIPS LLM Efficiency Challenge and emphasizes the significance of both LLM-generated and human-curated datasets."
    ],
    "commentSummary": [
      "The article examines the concept of refining large language models (LLMs) by utilizing them to formulate smaller, superior quality datasets.",
      "The process entails training a broad model on diverse data, using it to distill the source data into untarnished datasets, and subsequently training smaller models on them. The aim is to develop models that are more accessible, faster in making inferences, and possibly free from copyright issues.",
      "Other techniques to enhance the intelligence of LLMs, like retrieval augmented generation (RAG) and the utilization of fine-tuning datasets for language translation, are also discussed."
    ],
    "points": 129,
    "commentCount": 23,
    "retryCount": 0,
    "time": 1694792949
  }
]
