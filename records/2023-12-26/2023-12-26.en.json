[
  {
    "id": 38765627,
    "title": "Stirling-PDF: A Feature-Packed PDF Manipulation Tool for Local Use",
    "originLink": "https://github.com/Frooodle/Stirling-PDF",
    "originBody": "Stirling-PDF This is a powerful locally hosted web based PDF manipulation tool using docker that allows you to perform various operations on PDF files, such as splitting merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application started as a 100% ChatGPT-made application and has evolved to include a wide range of features to handle all your PDF needs. Stirling PDF makes no outbound calls for any record keeping or tracking. All files and PDFs are either purely client side, in server memory only during the execution of the task or within a temporay file only for execution of the task. Any file which has been downloaded by the user will have already been deleted from the server by that time. Feel free to request any features or bug fixes either in github issues or our Discord Features Dark mode support. Custom download options (see here for example) Parallel file processing and downloads API for integration with external scripts Optional Login and Authentication support (see here for documentation) PDF Features Page Operations View and modify PDFs - View multi page PDFs with custom viewing sorting and searching. Plus on page edit features like annotate, draw and adding text and images. (Using PDF.js with Joxit and Liberation.Liberation fonts) Full interactive GUI for merging/splitting/rotating/moving PDFs and their pages. Merge multiple PDFs together into a single resultant file. Split PDFs into multiple files at specified page numbers or extract all pages as individual files. Reorganize PDF pages into different orders. Rotate PDFs in 90-degree increments. Remove pages. Multi-page layout (Format PDFs into a multi-paged page). Scale page contents size by set %. Adjust Contrast. Crop PDF. Auto Split PDF (With physically scanned page dividers). Extract page(s). Convert PDF to a single page. Conversion Operations Convert PDFs to and from images. Convert any common file to PDF (using LibreOffice). Convert PDF to Word/Powerpoint/Others (using LibreOffice). Convert HTML to PDF. URL to PDF. Markdown to PDF. Security & Permissions Add and remove passwords. Change/set PDF Permissions. Add watermark(s). Certify/sign PDFs. Sanitize PDFs. Auto-redact text. Other Operations Add/Generate/Write signatures. Repair PDFs. Detect and remove blank pages. Compare 2 PDFs and show differences in text. Add images to PDFs. Compress PDFs to decrease their filesize (Using OCRMyPDF). Extract images from PDF. Extract images from Scans. Add page numbers. Auto rename file by detecting PDF header text. OCR on PDF (Using OCRMyPDF). PDF/A conversion (Using OCRMyPDF). Edit metadata. Flatten PDFs. Get all information on a PDF to view or export as JSON. For a overview of the tasks and the technology each uses please view Endpoint-groups.md Hosted instance/demo of the app can be seen here hosted by the team at adminforge.de Technologies used Spring Boot + Thymeleaf PDFBox LibreOffice for advanced conversions OcrMyPdf HTML, CSS, JavaScript Docker PDF.js PDF-LIB.js How to use Locally Please view https://github.com/Frooodle/Stirling-PDF/blob/main/LocalRunGuide.md Docker / Podman https://hub.docker.com/r/frooodle/s-pdf Stirling PDF has 3 different versions, a Full version, Lite, and ultra-Lite. Depending on the types of features you use you may want a smaller image to save on space. To see what the different versions offer please look at our version mapping For people that don't mind about space optimization just use the latest tag. Docker Run docker run -d \\ -p 8080:8080 \\ -v /location/of/trainingData:/usr/share/tesseract-ocr/5/tessdata \\ -v /location/of/extraConfigs:/configs \\ -v /location/of/logs:/logs \\ -e DOCKER_ENABLE_SECURITY=false \\ --name stirling-pdf \\ frooodle/s-pdf:latest Can also add these for customisation but are not required -v /location/of/customFiles:/customFiles \\ Docker Compose version: '3.3' services: stirling-pdf: image: frooodle/s-pdf:latest ports: - '8080:8080' volumes: - /location/of/trainingData:/usr/share/tesseract-ocr/5/tessdata #Required for extra OCR languages - /location/of/extraConfigs:/configs # - /location/of/customFiles:/customFiles/ # - /location/of/logs:/logs/ environment: - DOCKER_ENABLE_SECURITY=false Note: Podman is CLI-compatible with Docker, so simply replace \"docker\" with \"podman\". Enable OCR/Compression feature Please view https://github.com/Frooodle/Stirling-PDF/blob/main/HowToUseOCR.md Want to add your own language? Stirling PDF currently supports 20! English (English) (en_GB) English (US) (en_US) Arabic (العربية) (ar_AR) German (Deutsch) (de_DE) French (Français) (fr_FR) Spanish (Español) (es_ES) Chinese (简体中文) (zh_CN) Catalan (Català) (ca_CA) Italian (Italiano) (it_IT) Swedish (Svenska) (sv_SE) Polish (Polski) (pl_PL) Romanian (Română) (ro_RO) Korean (한국어) (ko_KR) Portuguese Brazilian (Português) (pt_BR) Russian (Русский) (ru_RU) Basque (Euskara) (eu_ES) Japanese (日本語) (ja_JP) Dutch (Nederlands) (nl_NL) Greek (el_GR) Turkish (Türkçe) (tr_TR) If you want to add your own language to Stirling-PDF please refer https://github.com/Frooodle/Stirling-PDF/blob/main/HowToAddNewLanguage.md And please create a PR to merge it back in so others can use it! How to View Open a web browser and navigate to http://localhost:8080/ Use the application by following the instructions on the website. Customisation Stirling PDF allows easy customization of the app. Includes things like Custom application name Custom slogans, icons, images, and even custom HTML (via file overrides) There are two options for this, either using the generated settings file settings.yml This file is located in the /configs directory and follows standard YAML formatting Environment variables are also supported and would override the settings file For example in the settings.yml you have system: defaultLocale: 'en-US' To have this via an environment variable you would have SYSTEM_DEFAULTLOCALE The Current list of settings is security: enableLogin: false # set to 'true' to enable login csrfDisabled: true system: defaultLocale: 'en-US' # Set the default language (e.g. 'de-DE', 'fr-FR', etc) googlevisibility: false # 'true' to allow Google visibility (via robots.txt), 'false' to disallow customStaticFilePath: '/customFiles/static/' # Directory path for custom static files #ui: # appName: exampleAppName # Application's visible name # homeDescription: I am a description # Short description or tagline shown on homepage. # appNameNavbar: navbarName # Name displayed on the navigation bar endpoints: toRemove: [] # List endpoints to disable (e.g. ['img-to-pdf', 'remove-pages']) groupsToRemove: [] # List groups to disable (e.g. ['LibreOffice']) metrics: enabled: true # 'true' to enable Info APIs endpoints (view http://localhost:8080/swagger-ui/index.html#/API to learn more), 'false' to disable Extra notes Endpoints. Currently, the endpoints ENDPOINTS_TO_REMOVE and GROUPS_TO_REMOVE can include comma separate lists of endpoints and groups to disable as example ENDPOINTS_TO_REMOVE=img-to-pdf,remove-pages would disable both image-to-pdf and remove pages, GROUPS_TO_REMOVE=LibreOffice Would disable all things that use LibreOffice. You can see a list of all endpoints and groups here customStaticFilePath. Customise static files such as the app logo by placing files in the /customFiles/static/ directory. An example of customising app logo is placing a /customFiles/static/favicon.svg to override current SVG. This can be used to change any images/icons/css/fonts/js etc in Stirling-PDF Environment only parameters SYSTEM_ROOTURIPATH ie set to /pdf-app to Set the application's root URI to localhost:8080/pdf-app SYSTEM_CONNECTIONTIMEOUTMINUTES to set custom connection timeout values DOCKER_ENABLE_SECURITY to tell docker to download security jar (required as true for auth login) API For those wanting to use Stirling-PDFs backend API to link with their own custom scripting to edit PDFs you can view all existing API documentation here or navigate to /swagger-ui/index.html of your stirling-pdf instance for your versions documentation (Or by following the API button in your settings of Stirling-PDF) Login authentication Prerequisites: User must have the folder ./configs volumed within docker so that it is retained during updates. Docker uses must download the security jar version by setting DOCKER_ENABLE_SECURITY to true in environment variables. Then either enable login via the settings.yml file or via setting SECURITY_ENABLE_LOGIN to true Now the initial user will be generated with username admin and password stirling. On login you will be forced to change the password to a new one. You can also use the environment variables SECURITY_INITIALLOGIN_USERNAME and SECURITY_INITIALLOGIN_PASSWORD to set your own straight away (Recommended to remove them after user creation). Once the above has been done, on restart, a new stirling-pdf-DB.mv.db will show if everything worked. When you login to Stirling PDF you will be redirected to /login page to login with those default credentials. After login everything should function as normal To access your account settings go to Account settings in the settings cog menu (top right in navbar) This Account settings menu is also where you find your API key. To add new users go to the bottom of Account settings and hit 'Admin Settings', here you can add new users. The different roles mentioned within this are for rate limiting. This is a Work in progress which will be expanding on more in future For API usage you must provide a header with 'X-API-Key' and the associated API key for that user. FAQ Q1: What are your planned features? Progress bar/Tracking Full custom logic pipelines to combine multiple operations together. Folder support with auto scanning to perform operations on Redact text (Via UI not just automated way) Add Forms Multi page layout (Stich PDF pages together) support x rows y columns and custom page sizing Fill forms mannual and automatic Q2: Why is my application downloading .htm files? This is a issue caused commonly by your NGINX configuration. The default file upload size for NGINX is 1MB, you need to add the following in your Nginx sites-available file. client_max_body_size SIZE; Where \"SIZE\" is 50M for example for 50MB files. Q3: Why is my download timing out NGINX has timeout values by default so if you are running Stirling-PDF behind NGINX you may need to set a timeout value such as adding the config proxy_read_timeout 3600;",
    "commentLink": "https://news.ycombinator.com/item?id=38765627",
    "commentBody": "Stirling-PDF: local web application to perform various operations on PDFsHacker NewspastloginStirling-PDF: local web application to perform various operations on PDFs (github.com/frooodle) 385 points by alexzeitler 13 hours ago| hidepastfavorite161 comments mrfumier 3 hours agoBut... why? WHY??Why would I run a docker container, a webserver, start a browser, navigate webpages... just to do some operations on a pdf locally?A few KiloBytes native program like PDFtk (https:&#x2F;&#x2F;www.pdflabs.com&#x2F;tools&#x2F;pdftk-the-pdf-toolkit&#x2F;) does the job perfectly.I don&#x27;t understand what is the point of bloating softwares like this. Not even speaking of the very bad consequences for the planet. reply kristiandupont 1 hour agoparentBecause it&#x27;s a simple (for me as the user) and reliable way to get a UI without having to send my personal files to some server somewhere. What&#x27;s the big deal? reply ornornor 3 hours agoparentprevA web app makes it cross platform. If you have a homelab, deploy it only once for every client.And PDFtk doesn’t do annotations afaik which is a huge pain point on Linux (at least for me) because there are no applications that I know of to easily do things that are trivial on OSX like adding text or hand drawn signatures to PDFs. Masterpdf can do it but with a watermark and some limitations.Maybe it doesn’t suit your particular use case but I wouldn’t say pdftk can replace this project. reply plugin-baby 5 minutes agorootparent> no applications that I know of to easily do things that are trivial on OSX like adding text or hand drawn signatures to PDFsTry xournal++ reply adrenvi 2 hours agorootparentprevFirefox now has some simple built-in PDF editing tools. Text and images can be added on top, but existing text can&#x27;t be modified. reply subtra3t 1 hour agorootparentprevI think edge would be perfect for you reply maltris 41 minutes agoparentprevTf are you talking about reply nadermx 9 hours agoprevIt&#x27;s funny to see this #1 on HN. I have a PDF converter site[0] that I did a show hn [1] years back, and have been currently pushing updates too as I work on a entire site redesign since the PDF niche is massive. I&#x27;m alleviated to see that some one actually made a package for PDF to OCR[2]. And that they are using it[3]. It will finally make what I was doing less hacky.[0] https:&#x2F;&#x2F;www.pdf.to [1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23238862 [2] https:&#x2F;&#x2F;github.com&#x2F;ocrmypdf&#x2F;OCRmyPDF [3] https:&#x2F;&#x2F;github.com&#x2F;Frooodle&#x2F;Stirling-PDF#technologies-used reply tbarbe 18 minutes agoprevI did a small only-front app for that, it&#x27;s open source if you want to check it (disclaimer: im not a front end dev, the ui is not good) https:&#x2F;&#x2F;timothebarbe.github.io&#x2F;pdfModer&#x2F; reply Ldorigo 3 hours agoprevI&#x27;m surprised no one mentioned LibreOffice Draw - it doesn&#x27;t always work perfectly (I guess it doesn&#x27;t support some parts of the spec), but when it does, it&#x27;s by far the most powerful pdf editor I found allowing to do things like move elements around, edit them (as in actually edit, not just annotate), etc. It&#x27;s cross platform and FOSS.For page-level edits (rotating, reordering etc) pdftk in the cli (+ChatGPT to find the right incantations) works very well. reply dpacmittal 2 hours agoparentYeah, libreoffice draw and inkscape are usually my go to tools for editing pdf. reply nirav72 1 hour agoprevAny recommendations for a desktop&#x2F;cli PDF optimization tool that will reduce the size of a pdf? I&#x27;ve tried few and the best one so far is the one that is included in the subscription version of Adobe Acrobat. But I only need it occasionally and is not worth paying $20&#x2F;month sub. reply aidos 1 hour agoparentGhostscript maybe? Depends on what you’re doing but it can downsample images etc. reply nirav72 1 hour agorootparentYes, its mainly to reduce image size for scanned documents. I&#x27;ll give Ghostscript a try. reply aidos 45 minutes agorootparentSomething like this is probably a good starting point: ghostscript -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=&#x2F;printer -dNOPAUSE -dQUIET -dBATCH -sOutputFile=output.pdf input.pdfFrom this gist https:&#x2F;&#x2F;gist.github.com&#x2F;guifromrio&#x2F;6390547# reply nirav72 22 minutes agorootparentVery helpful tip. Thank you! - Ran it through GS and I got 30% reduction in a 50mb pdf file. I think if I play around with some options - such as converting images to grayscale, I might be able to reduce it by another 10-20%. reply evrflx 1 hour agoparentprevDid you already give ghostscript a try? reply Alifatisk 10 hours agoprevIt&#x27;s scary how such a widely used format (PDF) is almost in full control by Adobe. I have yet to see a true competitor to Adobe Acrobat. The only one that has come really close is the one that comes built-in for macOS. It&#x27;s a hidden gem. reply simondotau 6 hours agoparentPDF has been a free-as-in-beer standard since 1993 and a free-as-in-speech ISO standard since 2008. The reality is that PDF is open, reliable, useful, feature rich, and widely accepted. It has no serious competitors.There&#x27;s a reason why, unlike raster image formats, there aren&#x27;t any serious competitors. The thing to realise about printed page file formats is that even if you set aside all of the silly \"multimedia\" and \"interactivity\" features, there&#x27;s still a gargantuan rabbit hole of non-trivial features that need to be implemented absolutely perfectly, from kerning to spot color. PDF does it all very well. There&#x27;s really no scope for a competitor to come along to make something that&#x27;s obviously better. reply fuzztester 5 hours agorootparent>PDF has been a free-as-in-beer standard since 1993 and a free-as-in-speech ISO standard since 2008.Yes. The first sentence of the Wikipedia article about PDF is:>Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.And the last sentence of the first paragraph of the same article is:>PDF was standardized as ISO 32000 in 2008.[5] The last edition as ISO 32000-2:2020 was published in December 2020. . reply bla3 9 hours agoparentprevPDF had an open spec and oodles of programs supporting it. I don&#x27;t understand where this comment is coming from. reply webel0 9 hours agorootparentAdobe acrobat (and maybe reader) is really the only app that fully supports the full PDF spec as understood by the authors of the spec. There are ridiculous parts of the spec that allow support for things like JS, etc. reply wolverine876 8 hours agorootparentI&#x27;ve seen many third party PDF viewers; I think all supported JavaScript. It&#x27;s commonplace, not &#x27;ridiculous&#x27; at all.> Adobe acrobat (and maybe reader) is really the only app that fully supports the full PDF specThe full spec is large and afaik has many obscure pieces, including 3-D, etc. Like many specs, they don&#x27;t match reality and nobody takes completeness too seriously. For almost all users, supporting the entire PDF spec doesn&#x27;t matter (does it matter for any user - does any person or organization use the entire spec over their lifetimes?).Also, do we know that Adobe supports the entire spec? reply bdd8f1df777b 6 hours agorootparentprevThat is true, but I have never encountered a PDF that is not produced by me and cannot be faithfully represented in third party PDF readers. And I give up the idea of producing those kinds of PDFs because I know the people I send to will complain about me rather than their PDF readers. So, Adobe Acrobat doesn&#x27;t have any monopoly power here, since almost no one cares about those things only they can do. reply Moru 1 hour agorootparentWe often get PDF&#x27;s that does not work in our pipeline and it&#x27;s always blamed on the pipeline, not on the creating software. The user usually converts the PDF to an image with adobe reader and screenshot, load up Libreoffice, paste and export it as PDF archive. reply bdd8f1df777b 1 hour agorootparentSo the PDF that does not work in your pipeline is created by LibreOffice rather than Adobe Acrobat? That doesn&#x27;t seem to add any strength to the argument that \"Adobe Acrobat has unusual powers because only it can handle the full spec of PDF\". reply Moru 19 minutes agorootparentNo, you missread. The PDF that works is created by anything that does not use the full spec of new PDF versions. We have chosen Libreoffice because we already use it for other things. If we recreate the PDF in Libreoffice as PDF archive version it works just fine. The problem is usually a pamphlet created by some ad agency using the absolutely latest version of some layout program, neither adobe nor libreoffice. The PDF usually works just fine in Adobe but not in our pipeline that uses all sorts of linux programs to process into a JPG in the format and orientation our system needs. Noone has had the time or energy to fix it since most stuff works so for now it will be downsampled by a screenshot and just showed into the system. The added benefit is the PDF shrinks from 150 MB to 300 kB in the process.Adobe Acrobat is the only thing that can handle all cases yes. All other programs uses (different) special cases each and most of them fail in some edge cases. It can be funny letters showing up because of fonts not working properly or images disapearing or all sorts of things. I have given up to fix them all. I still have a library of PDF&#x27;s that we used to run through to try to get as many as possible to work. reply KeplerBoy 9 hours agorootparentprevWhat&#x27;s wrong with using a sane subset of the spec aka PDF&#x2F;A? reply cmrx64 9 hours agorootparentprevI don’t think it’s ridiculous to want a scriptable document, especially for complicated forms. Likewise for the other much-dragged features for 3d scenes.https:&#x2F;&#x2F;pdfa.org&#x2F;resource&#x2F;pdf-in-manufacturing&#x2F; is a great usecase. reply fuzztester 5 hours agorootparentThe PDF spec even supports attachments in PDF files. reply wolverine876 8 hours agorootparentprevAgreed. Also, possibly the most commonly used reader is pdf.js, the FOSS component used by at least some major web browsers. reply hyperthesis 7 hours agoparentprevAdobe is expert at software standards. They aren&#x27;t compulsive about control, yet don&#x27;t give the farm away. The know when to be open and how much. That is how they dominate. reply philsnow 10 hours agoparentprevDoes that one have a name? I’m a MacOS transplant and have never gotten terribly familiar with the territory. Thanks! reply cmdrriker 10 hours agorootparentPreview.app which owes its heritage to NextStep. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Preview reply philsnow 4 hours agorootparent... ah, thanks, I misread. I thought GP was talking about a document format in the same space as PDF that was native to MacOS. reply tonyedgecombe 10 hours agorootparentprevPreview is the app on macOS that lets you view and even edit PDF files. reply jwong_ 10 hours agorootparentprevpreview.app reply rmbyrro 8 hours agoparentprevFoxit Phantom is pretty good reply whatisyour 8 hours agoparentprevWhat about Okular? reply pmarreck 8 hours agoparentprevIt’s incredible to me that not only has Preview.app been the best non-Adobe way to use PDF’s for decades now and only on macOS (perhaps because NextStep, its roots, used PostScript natively?) but that Linux actually also seems to have better tooling in this space than Windows (where you’re pretty much stuck with Adobe Reader if you want a free solution) reply wpm 7 hours agorootparentIsn&#x27;t SumatraPDF a decent program for Windows?In regards to Preview, I still find it insane that it doesn&#x27;t have an iOS&#x2F;iPadOS equivalent. Bits of the functionality are scattered all over the place, usually in ways that don&#x27;t feel as good as they do on the Mac. Sometimes I just want to open a PDF and leave it open, and not have to do it from Files which assumes I want to do something else with it than just looking. reply sphars 6 hours agorootparentI personally use SumatraPDF on Windows, but it&#x27;s basically just a fantastic PDF viewer. It does little else in regards to editing&#x2F;modifying PDFs. Even the PDF viewer in Edge does more.But for a lightweight, bloat-free experience, SumatraPDF is the way to go. reply wolverine876 8 hours agorootparentprev> Preview.app been the best non-Adobe way to use PDF’s for decades nowWhere is all this stuff coming from? Why would you say Preview is the best? Foxit? Nitro? Their are endless PDF applications much more powerful and capable, some designed for professionals. reply fauigerzigerk 1 hour agorootparent\"Best\" isn&#x27;t necessarily the same as \"has the most features\".I think many people find that Preview.app does everything they ever wanted to do with PDFs. It really is surprisingly capable. It&#x27;s also fast and far less convoluted than most PDF tools I have seen.And of course it comes free with every Mac, which often makes it \"best\" in terms of value for money.It doesn&#x27;t help that many PDF editors (including the two you mentioned) are full of the most ridiculous pricing shenanigans. reply ornornor 3 hours agorootparentprevFor annotating and adding a hand drawn signature to PDFs, preview really is the best: lightweight, straightforward, free, comes with the OS. I don’t know any comparable app for Linux (or windows although I rarely use it) reply nip 2 hours agorootparenthttps:&#x2F;&#x2F;simplePDF.eu will be the closest « Preview-like » experience on Linux (and any OS really).It’s local only (the document you load and data you fill in never leave the browser) and freeDisclosure: I’m the developer behind it reply asdfologist 9 hours agoparentprevI find Chrome&#x27;s built-in PDF viewer much snappier than Adobe Acrobat. reply noAnswer 9 hours agorootparentSadly I had to install Adobe Reader on my father PC again after he had documents* with formulas. Chrome would calculate the numbers wrong. Everything was off by 10.*To get reimburses from a union or something. reply manmal 28 minutes agorootparentI recently had issues with macOS‘ Preview.app and formulas. It’s a nice feature, but probably not widely supported. reply aragonite 6 hours agorootparentprevIf you occasionally need Adobe Reader&#x2F;Acrobat exclusive features but don&#x27;t want to install, you can use the free online version of Acrobat. It&#x27;s pretty decent though it doesn&#x27;t have all the features:https:&#x2F;&#x2F;acrobat.adobe.com&#x2F;us&#x2F;en&#x2F; reply asdfologist 9 hours agorootparentprevWhoa, I had no idea PDFs can have formulas. reply SturgeonsLaw 7 hours agorootparentYou can embed Javascript in PDFs reply fuzztester 5 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38768892 replynf3 1 hour agoprevAs long as I can fill in forms and add a signature I&#x27;m sold. I loved being able to do this on MacOS but now that I&#x27;m on Linux I still haven&#x27;t found any app that can do this. reply rozman50 13 hours agoprevhttps:&#x2F;&#x2F;tools.pdf24.org&#x2F;en&#x2F;creatorThis tools is not open source, but it’s free. Files should remain on local pc. Developers claim that they make money only by advertisement on their website. reply Alifatisk 10 hours agoparentWow, it covers almost anything, including redacting text. reply RyanShook 13 hours agoprevI have a PDF problem that I thought was simple but has proven difficult to solve and there is no paid solution I’ve found…I want to forward an email to an inbox, have the email body converted into a PDF, and then email that attachment to someone all automatically. I’ve tried Make, Zapier, pdf.co, pdftool, and a few other tools but have had no success. Has anyone solved this problem reliably? reply victorbojica 12 hours agoparentIf you are able to code or can ask someone, then you should be able to do it with some email api service (Nylas, AWS SES, etc) or headless client that gets the body of the email and convert it to pdf using wkhtmltopdf and then send it as attachment using the same service as before.Using low&#x2F;no code tools might be very hard&#x2F;unlikely reply RyanShook 12 hours agorootparentThanks, yes I think this is the right direction. Surprised it doesn’t exist as SAAS, I guess demand isn’t there. reply geraldwhen 11 hours agorootparentIf you want the pdf to look anything like the email, you will need to render it in a browser and capture a pdf. It’s not particularly hard if you know what you’re doing. reply vinibrito 5 hours agorootparentAny libs to help with that? Thanks. reply toomuchtodo 12 hours agoparentprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38545255https:&#x2F;&#x2F;www.tapdone.com&#x2F;perhaps? Or something similar? reply RyanShook 12 hours agorootparentThanks for sharing! reply hkhanna 9 hours agoparentprevI needed this for expensing receipts that come via email. I created an API for it where you POST the email to an endpoint and get back a PDF.Email me and I’ll give you access for free. reply cookie_monsta 10 hours agoparentprevIf you have access to O365 (or whatever it is called this week) this would be easy to do using powerautomate reply fgonzag 12 hours agoparentprevIt seems quite doable but you&#x27;d need scripting skills to set it all up. Read the incoming queue, pass it to wkhtmltopdf then pipe the result to the mail command. For windows I believe I once used a java smtp server (apache james) that allowed you to set custom code as an incoming email handler. After that the conversion and email sending is trivial. reply brailsafe 12 hours agoparentprevProbably depends on the purpose of the pdf and why it needs to be an attachment, but I&#x27;d just skip all the steps and print the email since that&#x27;s more or less what pdf is for. Print it and re-attach or just print at the destination. reply RyanShook 12 hours agorootparentThis is what I currently do. I was just hoping to automate the process. reply JumpCrisscross 10 hours agoparentprevI think Mail.app in macOS can do that with Automator. At the very least, the PDF emails coming from an email address and forward as attachment bits. reply mlfreeman 9 hours agorootparentAnecdotal bug warning:Mail.app can \"Export as PDF\" from the File menu, but I noticed on 13.6 that it exports blank pages if the email is plain text only.I had to choose to print the emails and then save as PDF from the print dialog. reply reachableceo 8 hours agoparentprevIf you need to send an email anyway , why not print to pdf and email the pdf? reply rqtwteye 12 hours agoparentprevI did something like this 10 years ago as an internal tool for a company. BAck then I did it with Outlook VBA. reply karl_gluck 12 hours agoparentprevGoogle Apps Script can do all of this. Take the email body and put it into a Google doc, then export the doc as a pdf to drive and attach it from there to send. reply davchana 7 hours agoparentprevI use Google apps script for it.A filter labels a specific email.A timed trigger runs a script.Script fetches all emails with that filter.Script runs in loop. Convers each message into a blob, blob gets converted to pdf. Pdf gets saved in google drive. Email gets label removed.My code was based on this https:&#x2F;&#x2F;www.labnol.org&#x2F;code&#x2F;19117-save-gmail-as-pdf reply 101008 12 hours agoprevI still couldn&#x27;t find a tool for a difficult problem to solve. I have some magazines in PDF, with layouts in two columns, etc. I want them to be transformed into Markdown. I know, it should identify automatically the two columns, different layouts, etc.I am not desiring something perfect - I can fix if ther are some errors, but so far nothing has come with a good result. reply solardev 10 hours agoparentI use Briss for this: https:&#x2F;&#x2F;github.com&#x2F;mbaeuerle&#x2F;Briss-2.0It overlays all the pages on top of each other, you the human draws rectangles around the stacked columns in the easy GUI, and then it processes them into pages. reply jftuga 12 hours agoparentprevHave you tried this (for at least solving part of the problem)?https:&#x2F;&#x2F;github.com&#x2F;pdfcpu&#x2F;pdfcpu reply layer8 12 hours agoparentprevThis can be arbitrarily difficult to do, depending on the PDF. This is generally called PDF reflowing. Another approach is to use column-aware OCR software. reply pklee 9 hours agoparentprevHave you considered marker. Does a very good job of turning PDF into markdown. - https:&#x2F;&#x2F;github.com&#x2F;VikParuchuri&#x2F;marker reply qingcharles 12 hours agoparentprevThis is a hard problem. Cut the PDF down so it&#x27;s only the pages of the article you want and then try feeding it through GPT Pro or Claude? reply rmbyrro 8 hours agoparentprevI bet GPT vision will do that like cutting a piece of cake. It&#x27;ll even do the OCR for you and organize the text nicely. reply stavros 10 hours agoparentprevDepending on how much you&#x27;re willing to pay, the OpenAI GPT-Vision API can definitely do this extremely well. reply 101008 9 hours agorootparentI am willing to pay for this, I only have around ~80 files, with 30 pages each (average). Is there a quick way to test this without wasting too much on the code part? reply stavros 9 hours agorootparentYes, ChatGPT will do it if you upload photos of the page. reply 101008 8 hours agorootparentI just tried it with the API and it worked better than expected. Now I need to find to convert PDF to JPG with an API, and find the best prompt to ask GPT to only convert to markdown articles and not pages with columns, ads, etc. Thanks! reply stavros 8 hours agorootparentNo problem! There are many Linux programs (some in this thread) to convert a pdf to images, and the prompt will hopefully not be too hard.I started making app to read our board game cards out loud (with voice) for our horror board game nights (https:&#x2F;&#x2F;boardguru.net) and GPT-4 could read cards that I couldn&#x27;t make out! replyjbverschoor 10 hours agoparentprevThe built-in apple preview application does exactly what you want..It just looses bold etc. reply alex_suzuki 3 hours agoprevSmallpdf [1] probably deserves a mention here. Not OSS and not self-hosted, but I‘ve used it occasionally and it has always worked really well. When I was running an agency, we inherited their first office – very cool folks.[1] https:&#x2F;&#x2F;smallpdf.com&#x2F; reply buryat 2 hours agoparentdamn, that&#x27;s a huge teamhttps:&#x2F;&#x2F;smallpdf.com&#x2F;about reply gnyman 2 hours agorootparentI&#x27;m not surprised... I mean just the the specification for PDF 1.7 is what ~1300 pages ?And then there is 2.0, and all the extensions [1]And multiply that with the number of implementations.If the goal is to make something that \"always\" works, you probably need a big team to keep up with the moving field of various bugs and reimplementations[1] https:&#x2F;&#x2F;www.loc.gov&#x2F;preservation&#x2F;digital&#x2F;formats&#x2F;fdd&#x2F;fdd0000... reply lordofgibbons 12 hours agoprevHow easy or difficult would it be to turn this into an electron app so that non-technical users can use it easily too? reply Froodle 12 hours agoparentDev here, totally could, we dismissed it at first as electron is quite bulky containing a whole chromium instance inside the exe. instead we kept it small as possible for the exe version Truth is its not to hard to port to electron We have plans for a full UI version in V2. We are releasing V1 (SPDF is currently in beta) sometime this month. But have begun work on a V2 port to different language and framework. reply layer8 12 hours agoparentprevBetter use existing applications like PDFsam [0] or PDF-XChange [1].[0] https:&#x2F;&#x2F;pdfsam.org&#x2F;pdfsam-basic&#x2F;[1] https:&#x2F;&#x2F;pdf-xchange.eu&#x2F;pdf-xchange-editor&#x2F; reply ornornor 3 hours agorootparentWhy “better use some to big else”? reply judge2020 10 hours agoparentprevIt would be nice if it were WASM-based. Then someone could host that version of the app and it&#x27;d still be local processing. reply marwis 2 hours agoprevLooks like the pdf-lib.js used by the project can do most of the advertised features right in the browser and there is even a wasm build of tesseract out there.Have you considered making serverless&#x2F;browser-only version? reply Froodle 1 hour agoparentYes our v2 version we are working on is this! We plan to completely migrate functionality to be all client with a server side one for API requests as well reply ObscureScience 11 hours agoprevWhat I have mainly have been looking for in the free software ecosystem is a good tool to work with PDF tagging&#x2F;structure&#x2F;element attributes.At work I really have only been able to do the work I need on random PDFs with Adobe Acrobat. It seems strange that this is the case as PDF is now an open standard. reply Ldorigo 3 hours agoparentLibreOffice Draw can do that (not sure about tagging). reply zikohh 13 hours agoprevI like using https:&#x2F;&#x2F;www.pdftool.org&#x2F;en reply kleiba 12 hours agoparentWhat about pdftk? reply eyegor 9 hours agorootparentpdftk has an issue where it corrupts pdfs occasionally in modern windows server versions. Had a weird bug in a random helper service at work that we narrowed down to pdftk mangling documents sometimes. Never looked much into it since it was only a couple of hours to replace it with another tool, and haven&#x27;t had issues since. I think all we used it for was merging and adding watermark text. reply anjanb 5 hours agorootparent\"replace it with another tool\" which tool was that ? reply lukew3 4 hours agoprevDoes anybody know of a similar foss suite of pdf tools that runs as a static site only using local javascript? I would prefer that to something like this. reply c0mbonat0r 57 minutes agoprevreminds me of smallpdf.com but open source reply rodlette 13 hours agoprevNice. I&#x27;ve been looking for something like this to self-host, to avoid my partner uploading sensitive documents to random PDF manipulation websites.Any better alternatives I should be considering? reply Etheryte 13 hours agoparentIf you happen to be on macOS, the Preview app does an absurd number of things to PDFs, and it does it well. To be honest I&#x27;m always surprised it isn&#x27;t highlighted more by Apple, it&#x27;s a great tool that pretty much always just works. You can split files, join them, rotate, add signatures, drawings, annotations, redact sections, etc. The feature list is long, especially considering that by the name of the application you&#x27;d think it could just preview files, not edit them. reply sumedh 8 hours agorootparent> to be honest I&#x27;m always surprised it isn&#x27;t highlighted more by AppleProbably because its not so intuitive, I have to google how to use some of the advanced features of Preview. reply somethingsome 12 hours agoparentprevI often use PDF Sam (basic) and usually it works quite well and is offline.https:&#x2F;&#x2F;pdfsam.org&#x2F; reply jftuga 12 hours agoparentprevA really nice, stand-alone command line tool is pdfcpu.https:&#x2F;&#x2F;github.com&#x2F;pdfcpu&#x2F;pdfcpu reply rodlette 57 minutes agorootparentLooks great, but my partner needs something more convenient.It needs to be web based and work on desktop&#x2F;mobile. reply jbc1 10 hours agoparentprevDoes it need to be a self hosted web based tool or do you just need PDF software? If the latter I find PDF Expert to be powerful and nice to use. reply tony69 10 hours agoparentprevI use pdftool.org which I saw on HN a while back reply bayindirh 11 hours agoparentprevKDE’s Okular. Works on Linux, Windows and macOS.If you’re on already macOS, Preview already has you covered. reply cde-v 12 hours agoparentprevEdge is surprising decent for marking up PDFs. reply mderazon 8 hours agoprevI&#x27;m looking for a tool other than adobe pdf reader that lets me upload an image file of my signature to sign a pdf. Most of the tools I found let me draw a signature and I can&#x27;t draw my signature on a track pad or with the mouse reply ajot 7 hours agoparentI use GIMP for that, and if I need it to look like printed-signed-scanned some ImageMagick incantation [0] or https:&#x2F;&#x2F;lookscanned.io&#x2F;[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30024658 reply voltaireodactyl 7 hours agoparentprevPDF Expert is the best I’ve found that also does this, and while expensive, is a really robust and well done program. PDFpen also has this ability. reply whatisyour 8 hours agoparentprevXournal++ does what you are looking for. reply ryloric 4 hours agoprevCan this add paragraph numbers? I see page numbers in the README, but nothing on how I can number paragraphs. reply cryingpotato 7 hours agoprevThis is really neat! Is there a paid product backing this or planned for the future? I&#x27;m curious what motivates all the dev hours going into it. reply Froodle 1 hour agoparentNo paid backing, just running on donations at the moment. I am tempted to try add a paid feature for AI integration or something or some high end office features as I have a fair few offices that use this software now. But to be honest I would always want it free and it&#x27;s just been a hobby reply d4rkp4ttern 12 hours agoprevI’ll join some other commenters, to add my favorite difficult pdf problem that I haven’t found a ready to use (even paid) solution for: extract key value pairs from a filled form such as this medical claims form:https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;EJDi7L7There are two levels of difficulty: the starting file could be an image (pdf or png or jpg), which is the most difficult scenario. The slightly easier one is where it’s a text-based pdf so no OCR is needed.I threw this as an image file at google form parser but it did poorly, I.e missed quite a few fields. reply Froodle 11 hours agoparentDev here for the above stirling pdf app, Please raise features like this as a feature request github issue ticket and we can try address it in future! reply kpandit 10 hours agorootparentI would do exactly what you have done here if I were the dev of the said app. But with the luxury of being an outsider, a user has expressed an inconvenience and it seems to make sense, then if I were to be the dev of the app here, wouldn&#x27;t I go and create the ticket in whatever system with a link to this post instead of asking the user of the app to follow the red tape? I know there are places where this is not incentivised so this is a question for your org and not for you. reply Froodle 10 hours agorootparentI see what you&#x27;re saying and for simple features I agree However Without the OP creating the ticket there can be no feedback look on the feature. If i wanted it tested for their usecase, there input and confirmation on if its what they wanted and improvements for the workflow etc.. If I base the whole feature on this comment it could end up only doing half a job. Id rather have that communication loop open! reply d4rkp4ttern 10 hours agorootparentprevI tend to agree. As an open source dev myself, I avoid asking folks to create issues, as it puts a burden on the user. I’ve see some highly respected open source leads so this, and I’m not faulting them, as I think they’re coming from a good place; it may be a difference of opinion on what’s best practice. reply Sai_ 8 hours agorootparentprevNot OP. My take is that if the requester can’t be bothered to create a GH issue, it’s likely that this isn’t really a problem for them. An annoyance possibly but has not risen to “pain” levels. reply ylk 10 hours agoparentprevThis could be a paid option for parsing forms (not sure about ocr): https:&#x2F;&#x2F;demos.textcontrol.com&#x2F;chapter&#x2F;topic&#x2F;PDF&#x2F;PDFFormData https:&#x2F;&#x2F;www.textcontrol.com&#x2F;technologies&#x2F;pdf&#x2F; reply dave8088 9 hours agorootparentTheir scummy website doesn’t list their prices in any way I can see. Hard pass. reply Closi 11 hours agoparentprevHave you tried Azure AI Document Intelligence?In theory it&#x27;s exactly this... reply brianjking 11 hours agorootparentI second this, that or have you tried GPT-4 Vision or Donut? reply d4rkp4ttern 10 hours agorootparentStill waiting for GPT4V but doubt it will do this. Yes I’ve tried Donut and other options but this is a very gnarly problem.One option is to extract text blocks along with their coordinates (unstructured.io gives this, probably based on another pkg because it’s basically a container for many pigs). Then do the same with a blank template, and you then have an algorithmic problem of matching the filled values spatially with the key locations from the template. reply brianjking 10 hours agorootparentI&#x27;m fairly confident GPT-4V will do this just fine, tbh.You just need to extract each of the elements into a structured JSON or something, right?I&#x27;ll try with your example later today. reply d4rkp4ttern 9 hours agorootparentExactly, the form has filled values in named cells, so we need a JSON of cellName -> filledValue mappings.Let me know how GPT-4V does! reply qingcharles 10 hours agorootparentprevI second trying GPT-4 Vision, though they have dumbed it down a bit since launch. reply zeagle 7 hours agoprevWould be really interesting to use this with paperless-ngx to annotate or watermark documents. reply 11235813213455 11 hours agoprevDoes it support adding &#x2F; managing named form fields? reply Froodle 11 hours agoparentdev here, Not currently but its a planned feature reply ziofill 12 hours agoprevit says this started as a 100% chatGPT project! reply jwilk 12 hours agoparentWhat does it mean? reply monospaced 11 hours agorootparentFrom my understanding they mean the code was generated by instructing OpenAI’s ChatGPT (contrary to writing the code themselves). reply laurensr 13 hours agoprevWhat seems to be missing is an OSS tool to add&#x2F;remove form fields reply christkv 13 hours agoprevCan it add attachments to pdf files?. Until this year I did not even know that this was possible but a government agency asked me to add files as attachments to a pdf as their website only allowed uploading valid pdf files. reply alexzeitler 13 hours agoparentHave learned about it this year as well reply layer8 12 hours agoparentprevYou can use Acrobat Reader for that. reply pmarreck 8 hours agoprevNo one commented yet on how this entire app was built by ChatGPT? reply sagarpatil 6 hours agoparentYep. That&#x27;s the most interesting thing here. OP can you elaborate on how you got it to develop a full fledged application? reply Froodle 1 hour agorootparentSo the whole app is not made in chatgpt It started like that 11 months ago though yes I made the website and 7 pdf operations with chatgpt as a test to investigate chatgpts power and applications Everything after that has been manual though and basically all the code has been changed by now reply toasted-subs 13 hours agoprevSelf hosted sites are pretty awesome. Love seeing these here. reply nashashmi 7 hours agoprevBluebeam PDF has an amazing Stapler tool. I can have a job that combines various pages of various PDF files and does a few other operations on them. When time for print comes, I run the job and output a PDF. For a kind of work that has to frequently put together various pages of various PDFs repeatedly to send as draft for review, this is a tool that makes life easy. https:&#x2F;&#x2F;support.bluebeam.com&#x2F;articles&#x2F;revu-21-revu-configure...However, I have yet to find an equivalent tool from any other PDF application. And that includes this one. reply adamnemecek 13 hours agoprevI have not looked into this yet but can someone recommend an application for repairing pdfs? For example, I have PDFs where selecting text highlights a line above or below. reply layer8 12 hours agoparentThat doesn’t sound like the PDF is broken, just that it uses unusual font metrics or line displacements. Tools that could amend this are unlikely to exist.More generally, the PDF format is too flexible to decide what is “broken” or really is as intended, in many cases. It’s l a bit like asking for a tool that repairs “broken” source code where it’s really just the business logic that is broken. reply adamnemecek 9 hours agorootparentSome ocr no? reply me_jumper 12 hours agoparentprevTry converting it to PDF&#x2F;A reply adamnemecek 12 hours agorootparentThat&#x27;s not it. reply tobinfricke 11 hours agoprevProbability density functions, presumably. Oh, partial differential equations?For the document files, I love PDF Studio: https:&#x2F;&#x2F;www.qoppa.com&#x2F;pdfstudio&#x2F; reply karol 12 hours agoprevWhy can&#x27;t this be an electron app? reply Froodle 12 hours agoparentDev here, totally could, we dismissed it at first as electron is quite bulky containing a whole chromium instance inside the exe. instead we kept it small as possible for the exe version We have plans for a full UI version in V2. We are releasing V1 (SPDF is currently in beta) sometime this month. But have begun work on a V2 port to different language and framework. reply eyegor 8 hours agorootparentAs an alternative you could write some automation scripts to handle all the requirements for self hosted install. If you look at oogaboogas text-generation-webui [0] you can see what I mean. Although ease of install also leads to a larger user base, which can be a double edged sword for something as ubiquitous as a pdf app. It&#x27;s much easier to get people to submit issues than to help solve them.[0] eg, windows install script https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F;blob&#x2F;main... reply fagrobot 3 hours agoprev [–] As a local gay robot, I’d like to perform gay operations on PDFs replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Stirling-PDF is a locally hosted web-based tool for manipulating PDF files, offering features like splitting, merging, converting, and more.",
      "The tool ensures the security and privacy of files, without making outbound calls for tracking or record keeping.",
      "It utilizes technologies like Spring Boot, Thymeleaf, PDFBox, LibreOffice, and more, and can be accessed through a hosted instance or run locally using Docker or Podman."
    ],
    "commentSummary": [
      "Users are discussing various PDF editing tools, including their compatibility, limitations, and alternative options.",
      "The conversation encompasses automation processes like converting emails to PDFs and organizing PDF columns.",
      "Users mention specific software, features, pricing concerns, the use of AI technology, bugs encountered, and suggestions for alternative PDF tools."
    ],
    "points": 385,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1703534528
  },
  {
    "id": 38768678,
    "title": "Challenging Projects for Programmers: Text Editor, Game, Compiler, OS, Spreadsheet, Emulator",
    "originLink": "https://austinhenley.com/blog/challengingprojects.html",
    "originBody": "Austin Z. Henley I work on software. azh321@gmail.com @austinzhenley github/AZHenley HomePublicationsBlog Challenging projects every programmer should try 12/11/2019 Update 12/14/2019: This post spurred a lot of discussion on Hacker News and Reddit. I collected some of the suggested projects and put them in a list at the end of this post. Check out the sequel to this post: More challenging projects every programmer should try. Check out the second sequel too: Challenging algorithms and data structures every programmer should try. I talk to a lot of students and professional developers that often want to start a side project, but aren't sure what to build. Below is a handful of software projects that taught me a lot. In fact, they're great because you could build them multiple times and learn new things each time. So whenever I don't know what to build or I want to learn a new programming language or framework, I start with one of these: Text editor 2D game - Space Invaders Compiler - Tiny BASIC Mini operating system Spreadsheet (hard!) Video game console emulator (hard!) Text Editor We use text editors everyday, but do you know how it really works? Ignoring all of the fancy features that your favorite editor has, how would you implement a textbox that supports a movable text cursor and selecting, inserting, and deleting text? No, you can't use the builtin textbox component from your favorite GUI framework! The biggest challenge is figuring out how to store the text document in memory. My first thought was to use an array, but that has horrible performance if the user inserts text anywhere other than the end of the document. Luckily, there are some nice data structures to learn to solve this. Another hurdle was learning how a text cursor behaves in popular editors. For example, if I press the up arrow key with the cursor in the middle of the document, where will the cursor move? Same column? Not if that line is shorter. Keep pressing up. The cursor will snap back to the original column once a line is long enough. It turns out that the cursor has a memory for the column and tries to get back to it. It is these details that I never noticed until I tried to implement it. After implementing the basic editor, I challenge you to implement two more features: undo/redo and word wrapping. Implementing undo/redo in an efficient way was mind blowing to me! I first tried keeping an array of previous states, then tried the Memento pattern, before finally settling on the Command pattern. Word wrapping forces you to separate the visual aspects of a text line from the memory aspects. Things to learn: Data structures for storing the text: array, rope, gap buffer, piece table. Behavior and implementation of the text cursor. Design patterns for undo/redo: memento, command. Abstractions to separate the visual and memory aspects of the text. Further reading: Text Editor: Data Structures (web) Design and Implementation of a Win32 Text Editor (web) Data Structures and Algorithms in Java (Amazon) 2D game - Space Invaders Even the most simple games require some unique data structures and design patterns. The idea here is to implement a well-defined game from start to finish without getting bogged down on the other fun stuff (e.g., game design and art). Also, it is best if you use a barebones 2D graphics library (e.g., SDL, SFML, PyGame), not a big game engine that'll hide all of the interesting bits from you. First, you'll have to learn to draw to the screen. I had no idea how this worked. You are actually clearing the screen then drawing each portion of the screen in rapid succession, many times a second, to create the effect that objects are moving. Second, you'll learn all about the game loop. A game is effectively looping between drawing, getting user input, and processing the game logic. Third, you'll learn how to process user input. I never paid attention to the subtlties of initially pressing, holding, and releasing keys or mouse buttons, let alone handling things like a double click. And how often do you check for user input? If you are constantly checking then that means the rest of the game is frozen! Fourth, you'll learn how to create and manage all of your game objects and their state. For example, how do you generate a dynamic number of enemies? The factory pattern helps a lot. Fifth, you'll learn how to apply the game's logic. When do bullet positions get updated? When do more enemies come onscreen? How do you know when an enemy is destroyed? When is the game over? I had never used the modulo operator prior to making games but it is littered all over my games' code. Once you get the basic game working, add a title screen menu, a game over screen, make sure the game runs at the same speed even on different computers, and explore how to implement more interesting enemies with AI. Still not enough? Add shader effects, sound, and online multiplayer! Things to learn: Drawing to the screen. Handling user input. Game loop. Creating and managing a dynamic number of objects (e.g., factory pattern). State machines for enemy AI. Playing sound. Using shaders. Networking for online features. Further reading: Game Programming Patterns (Amazon, web) Data Structures for Game Programmers (Amazon) Programming Game AI by Example (Amazon) The 8 lessons I learned from releasing 8 video games (web) Compiler - Tiny BASIC The most-eye opening projects I have worked on are compilers. Even now, if I have a free Sunday afternoon to do some coding, chances are it is a compiler. It is a great feeling when you create something that enables others to create more things. By implementing one I had to learn so much more about the intricacies of compilers that I normally would never think about (e.g., when do expressions get implicitly type converted). I suggest writing the compiler from scratch for a very small BASIC-like language (see Tiny BASIC) and compile to any other language that you know well. For example, you could write a Tiny BASIC compiler in Python that outputs C# code. It does not have to output assembly or C! Avoiding those will let you focus on the compiler itself. The first hurdle is figuring out how to lex (or tokenize) the input code. Then you will parse the code, that is check the structure of the input and produce a tree representation of the code. The recursive descent parsing technique is beautiful! Next you will semantically check the input, ensuring the code makes sense and that the type rules are being followed. Finally, you can generate output! This project has a ton of existing resources to help you, and a simple compiler can be completed in a few days. Don't let the jargon scare you. Plus the possibilities are endless to what you can add! Once you have the basic compiler working, you can add a standard library (in PeayBASIC I added simple 2D graphics functionality), optimization passes, and improve the error messages. Finally, you should write some example programs in your own language to show off to the world! Things to learn: Lexical analysis Syntactic analysis Recursive descent parsing Abstract syntax tree Semantic analysis Optimization passes Code generation Further reading: My tutorial: Let's make a Teeny Tiny compiler (web) Crafting Interpreters (Amazon, web) Write an Interpreter in Go (Amazon) Let's Build a Compiler (web) PeayBASIC source code (GitHub) Mini Operating System Over the years I have found myself applying fundamental concepts from operating systems to a variety of domains, like games and even predictive models of human behavior. In a classroom setting the algorithms and data structures used by operating systems might seem abstract or useless, but they really are useful. Implementing an operating system also helped me understand far more about what is going on under the hood. There is a bit of a learning curve and some barriers to get started since it is dependent on hardware. However, by following a book or tutorial then you should be able to get a bootable OS working that can run your own programs. I highly recommend my colleague's free online book, Making a RISC-V Operating System using Rust. Things to learn: Cross compiling Bootloading BIOS interrupts x86 modes Memory management and paging Scheduling (e.g., round robin) File systems (e.g., FAT) Further reading: OSDev.org's wiki of resources (web) Making a RISC-V Operating System using Rust (web) Operating System Concepts (Amazon) Still not difficult enough for you? Try these two projects: Spreadsheet A spreadsheet application, like Excel, combines some of the challenges from a text editor with those of a compiler. You'll have to learn how to represent the cell contents in memory and implement an interpreter for the programming language used for equations. Further reading: Directed acyclic graph (web) Reactive programming paradigm (web) Spreadsheet Implementation Technology (Amazon) Video game console emulator Writing an emulator (or virtual machine) for a video game console combines the challenges of writing a compiler, an operating system, and a compiler all into one. It is quite rewarding to play a real game made by someone else with your emulator! Emulating a real video game console means writing a virtual machine that pretends to function just like the actual CPU and other hardware components. This allows you to run games designed for the video game console with your emulator. I recommend starting by emulating CHIP-8, which is a simple, fictitious console, before moving on to a real video game console. The NES, SNES, Gameboy, and Gameboy Advance are all quite feasible to emulate, with a far amount of documentation and open source emulators already, though they each have their own quirks to make things interesting (e.g., certain games may rely on undocumented bugs/features of the specific hardware). There is also the PICO-8, which has become a very profitable \"fantasy\" console. Further reading: Writing a Chip-8 emulator (web) JavaScript Chip-8 Emulator (Wayback Machine) How to Emulate a Game Boy in Rust (Wayback Machine) PyBoy source code (GitHub) Please let me know if you have any other project ideas! Here is a list of suggestions from Hacker News, Reddit, Twitter, and emails I received: Database from scratch Ray tracer MS Paint clone Vector graphics editor Image decoder Chatroom web app Digits of pi calculator Common terminal utilities (e.g., grep) FTP client and server There are Amazon affiliate links on this page.",
    "commentLink": "https://news.ycombinator.com/item?id=38768678",
    "commentBody": "Challenging projects every programmer should try (2019)Hacker NewspastloginChallenging projects every programmer should try (2019) (austinhenley.com) 334 points by azhenley 6 hours ago| hidepastfavorite175 comments p-e-w 5 hours agoWhile writing a text editor, a compiler, an operating system, or a raytracer might make you a better programmer, it won&#x27;t make you a better software engineer. In fact, it might make you worse at software engineering, because it embodies the disastrous \"Not Invented Here\" doctrine.Hackers like to obsess about Big-O, data structures, HoTT, and other high-theory stuff, yet the following skills, essential for software engineering, are almost never discussed and even more rarely practiced:- Deciding what to write yourself and what to take from a library- Identifying high-quality libraries and frameworks that meet your project needs- Deciding where optimization is worth the effort and where it is not- Writing code that will still be readable to you (and others) a few years from now- Thinking about the project as a large-scale, complex system with software and non-software dependenciesIn that spirit, I offer the following alternative challenge: Create a web search engine. Don&#x27;t bother with string matching algorithms etc., others have already done that for you. \"Just\" make a search engine (and crawler) that can actually work, even if it only supports a subset of the web and a single concurrent user at the beginning. reply bobsomers 2 hours agoparentI don&#x27;t understand why you think a search engine requires the use of \"real engineering skills\" like picking and choosing libraries and identifying which opportunities will yield fruitful optimization.Literally all of the listed projects, text editors, compilers, operating systems, and ray tracers, can exercise the exact same activities.I&#x27;m more inclined to think that your comment is really more revealing about what kind of knowledge is in your own personal wheelhouse. Having worked on a ray tracer that was subsequently used on many feature films, I can assure you that all of your bullet points apply to that project, too.It&#x27;s much more a matter of whether you want to do something small scale and fun, or whether you want to suck all the joy out of it by applying the same soul crushing constraints we already get paid to do in our day jobs. Bleh. reply p-e-w 2 hours agorootparent> Literally all of the listed projects, text editors, compilers, operating systems, and ray tracers, can exercise the exact same activities.In the linked article, these projects are all explicitly described as opportunities to learn about low-level stuff like how to efficiently store editable text. The difference with a web search engine is that nobody today can build such a thing completely from scratch, therefore it forces you to give up the toxic NIH mentality, which in my experience is usually driven by elitism and ego (on full display in this comment thread), not by some lofty desire to learn something new. reply 59nadir 1 hour agorootparent> The difference with a web search engine is that nobody today can build such a thing completely from scratchI&#x27;m sorry, but can you substantiate this claim? I&#x27;ve seen no indication that a search engine is not buildable from scratch at all. reply fho 1 hour agorootparentSigh ... Of to the silicone mines it is then ... again &#x2F;s reply isoprophlex 58 minutes agorootparentYou mean, the beach? reply sethammons 40 minutes agorootparentIt is a joke based on needing to define \"from scratch\". Similar to, \"how do you bake a cake from scratch? First you must create the universe.\" Op is gathering the raw ingredients to start fabricating his chips. reply enneff 21 minutes agorootparentYeah, that’s sand. :) replyindigo945 26 minutes agorootparentprevBack when online learn-to-code courses like Codecadamy and Udemy were a fad, I remember that one of them (and unfortunately I don&#x27;t remember which, and Google, ironically, turns up nothing) taught how to build a search engine in Python from scratch as a first project for complete beginners. I thought it had a reasonable level of complexity for this task.You can still find search-engine-from-scratch courses on Udemy, complete with all the necessary algorithms [1].[1]: https:&#x2F;&#x2F;www.udemy.com&#x2F;course&#x2F;build-a-search-engine-with-pyth... reply yu3zhou4 1 hour agorootparentprevI enjoy reading your discussion and just wanted to add that some people write a big scale software from scratch nowadays - for instance Marginalia for web search and Andreas Kling and team for operating system and web browser reply p-e-w 11 minutes agorootparentMarginalia, which I&#x27;m a big fan of, is not \"written from scratch\" (it would be stupid to do so). Check the project on GitHub, it has lots of third-party dependencies. reply cinntaile 31 minutes agorootparentprevI guess the first step in writing large scale software is to become Swedish! reply benj111 16 minutes agorootparentprev>elitism and egoYou know those car guys who will rebuild their engine, just because? Or those retro computer guys that will recap an ancient board rather than buying a modern pc?For you it is a job, for me it is a hobby. I have no interest in making something &#x27;professional&#x27; I want to take it apart to understand how it works. Want to understand how a text editor works? Write one.What component of that is ego?It seems to me you&#x27;re the elitist, you&#x27;re not far off saying mere users shouldn&#x27;t be allowed to modify their own software, shouldn&#x27;t be allowed to install software that hasn&#x27;t been okayed by the people who know what they&#x27;re doing. reply PH95VuimJjqBqy 2 hours agorootparentprev> I&#x27;m more inclined to think that your comment is really more revealing about what kind of knowledge is in your own personal wheelhouse.That&#x27;s my read as well. reply auggierose 2 hours agoparentprevThis sounds like sensible advice. But there are a few problems with making software purely from ready-made building blocks. Here are two of them:1) Much more often than not, the ready-made building blocks are crap. Your software will reflect that crappiness, and your life will consist not of writing software, but of maintaining and massaging crap.2) Even if your ready-made building blocks are high-quality, they limit what kind of software you can write. Ideally, you imagine what you want your software to do, and then you write software to do it. You create the building blocks in that process. If you are only using ready-made building blocks, there is a lot of great software you just cannot write. And I think we all see that, because there isn&#x27;t much great software around.These problems might not be a concern for you. If you write software that is pretty much just more of the same, 2) does not apply to you. And while 1) is still problematic, it will be just manageable because you use these building blocks mostly on their happy path.But I have bad news for you. This kind of software will soon be written not by you, but by an AI. reply p-e-w 1 hour agorootparent> If you are only using ready-made building blocks, there is a lot of great software you just cannot write. And I think we all see that, because there isn&#x27;t much great software around.I claim that the opposite is true: The reason there are so few software projects that are really great is because high-level skills, not low-level ones, are in short supply. Every CS graduate can implement Paxos. The number of people with the experience needed to take an implementation of Paxos, and many other components, and put them together into something that works really well is much, much smaller.> But I have bad news for you. This kind of software will soon be written not by you, but by an AI.AI is actually much better at writing low-level code than high-level code. If you tell it to implement a piece table or a Fibonacci heap, it will do so without problems, in any language. If you tell it to create a simple CRUD application using existing libraries, it will output something that doesn&#x27;t actually work. reply auggierose 1 hour agorootparentI guess it all depends on your definition of low-level. High-level can also be low-level, just with different building blocks, if the building blocks are based on well-specified abstractions.I am actually currently writing a novel text editor, and I can guarantee you, my requirements mean that an AI cannot help me with that directly, because the underlying mechanisms I need don&#x27;t exist yet. The AI is still helpful though when researching existing mechanisms, and to pinpoint why they don&#x27;t work for me.> AI is actually much better at writing low-level code than high-level code.> If you tell it to create a simple CRUD application using existing libraries, it will output something that doesn&#x27;t actually work.If your low-level code is just a copy or adaptation of something existing, then yes, AI is really good at that. Something novel though, AI cannot help you much here.On the other hand, simple CRUD applications will all be done by AI very soon. Probably not using existing libraries though, because these are crap.But there is certainly a role for humans currently in high-level design, I agree with you here. But this high-level design crucially relies on your ability for low-level design, with the ability to imagine and then implement (possibly with the help of AI) the building blocks you need, not just reuse the ones that are there. reply eternityforest 11 minutes agorootparentYou have to be pretty smart to even think of an idea that can&#x27;t be done with existing building blocks.It seems to show up more in hobby stuff, or in cutting edge projects.I&#x27;m always excited whenever I see any kind of algorithm work, because it&#x27;s such a novelty. Most everything I do is just a UI around a few libraries. reply kaba0 17 minutes agorootparentprev> But I have bad news for you. This kind of software will soon be written not by you, but by an AIPress X to doubt reply tehnub 3 hours agoparentprevThis is like telling a student learning an instrument never to practice scales or études because there are other skills necessary for playing in an orchestra. Those other skills are important, but you have to develop your chops at some point, and being a better a programmer will certainly help with basically all those skills you listed anyway. reply hilux 1 hour agorootparentNowadays (and increasingly, going forward) it&#x27;s possible to be a very productive programmer without knowing much low-level stuff. This may seem unfair to those who spent years wrestling assembly and then C pointers but that&#x27;s just today&#x27;s reality.It&#x27;s not possible to be a \"productive\" musician on a traditional instrument (i.e. excluding iPads) without knowing how to play scales, chords, etc. reply snovv_crash 59 minutes agorootparentThis is also the reason a computer with 4GB of RAM can&#x27;t run Gmail and Spotify at the same time. reply ttoinou 28 minutes agorootparentGoogle and Spotify are supposed to get among the best &#x2F; most productive developers though reply cpursley 36 minutes agorootparentprevTell that to most guitarists. Vast majority are self taught and can’t read music; a number are excellent players. reply eternityforest 20 minutes agorootparentThey can&#x27;t read music, but they can still make their hands move in repeatable patterns without thinking about each finger position, which I think is roughly the equivalent of implementing quicksort.As someone who has played guitar on and off for years as a hobby, I&#x27;m shocked by how much harder it is than programming.I can pick up almost any random codebase on GitHub, and as long as they use libraries and don&#x27;t touch low level stuff, I can probably start working with it in 10 minutes to a day at most.Then, I could leave that project for a year and be almost as productive as when I left. So much of the action is on the screen, not in the head, and there&#x27;s no muscle memory required.If any instrument was as easy as coding... I think a lot of coders might have music careers instead.... reply p-e-w 2 hours agorootparentprev> This is like telling a student learning an instrument never to practice scales or étudesNo, it&#x27;s like recognizing that an orchestra conductor doesn&#x27;t need to play every instrument (or even any instrument!) in order to make music.Or alternatively, that a violin player doesn&#x27;t need to understand the physics of acoustic dispersion in order to be the best in the world at playing the violin. reply tock 2 hours agorootparentYes a software engineer understanding data structures and runtime complexity is akin to a violin player understanding the physics of acoustic dispersion. reply p-e-w 2 hours agorootparentIs it not? I can&#x27;t tell if you&#x27;re being sarcastic or not. reply Arch-TK 1 hour agorootparentI would say, given how absurd the statement is, sarcastic. reply MikeTheGreat 2 hours agorootparentprev> an orchestra conductor doesn&#x27;t need to play [...] any instrument! in order to make musicOk, this is clearly a side-topic AND at the risk of being pedantic: Is this actually true?Like, I can see how theoretically one could learn to sight-read music well enough to be able to direct an orchestra of individual musicians, then do enough ear-training to identify enough notes to keep tabs on everyone (especially if you&#x27;re conducting a high school or (god help you :) ) middle school orchestra), etc, etc.But does anyone actually do that? Has anyone ever done that?\"I&#x27;m going to learn how to conduct an orchestra without learning any instruments\" kinda feels like \"I&#x27;m going to become a software engineer using an LLM instead of learning any foundations)\"(To be clear - the LLM path might be viable in the future, possibly the near future, but at least today it&#x27;s not quite there. My apologies in advance if my analogy doesn&#x27;t work in the future :) ) reply ofcourseyoudo 1 hour agorootparentNo, it&#x27;s not true, there are no prominent conductors that cannot play an instrument (or sing at a high level).A conductor should have a deep understanding of music, theory, and rehearsal pedagogy. At least in current western schools of music I don&#x27;t see how you would explore these topics outside of the study of an instrument. Maybe there is some esoteric path to this; I just can&#x27;t imagine how you go to Berklee and begin to explore the nuances of a composition without ever engaging with it as an instrumentalist.On top of that, the conductor isn&#x27;t just engaged at performances, they&#x27;re also responsible for leading rehearsals. If they&#x27;ve never deliberate practiced the learning of music from an instrumentalist perspective I think they would be very hard-pressed to structure strategies for getting the larger group to a high level. reply darreninthenet 1 hour agorootparentprevI guess it depends what you mean by \"play an instrument\" - almost all proficient conductors have proficiency in at least one orchestral instrument.There is at least one (so I&#x27;m speculating he&#x27;s not the only one, but it is likely to be rare) proficient conductor (Leopold Stokowski) who had no real proficiency with any instrument but he did have some very rudimentary piano training... and then pretty much taught himself conducting. Whether that rudimentary piano ability counts as \"play an instrument\" reply lodovic 1 hour agorootparentprevI&#x27;d rather put the violin player with understanding of acoustic dispersion in the same bracket as a software engineer who understands the effects of magnetic interference on a memory controller. reply hurril 1 hour agorootparentprevThis is correct, a conductor does not need this. But you are not the conductor in this analogy, you are a player of one or more instruments. reply steve_taylor 3 hours agoparentprevNotice it said programmer, not software engineer.Speaking for myself, software engineering is something I do because I have bills to pay. Programming is something I started doing because it’s fun. The projects in this article are the types of projects I would do for fun if I had the time. reply serial_dev 14 minutes agorootparent> Software engineering is something I do because I have bills to pay. Programming is something I started doing because it’s fun.Sudden clarity.I feel like printing it and putting it next to my workstation, so that I remember this both when doing something fun and when having to work so that my bills get paid. reply DeathArrow 3 hours agorootparentprev>Speaking for myself, software engineering is something I do because I have bills to pay. Programming is something I started doing because it’s fun.Same for me. While I strive to do stuff fast, in a way that is easy to maintain, modify and extend for work, see the big picture, take the right time of shortcuts, understand business and customers, there is not were the fun is.I enjoy the time when I am alone with the PC, far from user stories and scrums.I love to program, to convince the PC to do the trick I tell it to do. What I enjoy also is CS, algorithms, data structures, abstract thinking. reply ixaxaar 1 hour agorootparentprevAlso, I&#x27;d add that doing HoTT or other such \"high theory\" stuff actually enhances my understanding of the fundamentals and gives me the machinery to handle complexities systematically that building a mere web search engine would not. I already have a job for building such commodity stuff everyday. reply tugberkk 1 hour agorootparentprevI like watching Tsoding in my spare time and I love what he calls \"recreational programming\". That is what we need imho, more recreational programming. reply bmitc 3 hours agoparentprev> In that spirit, I offer the following alternative challenge: Create a web search engine.Yea, no thanks.If I&#x27;m going to work on something in my spare time, I am going to work on something that I am interested in and find fun. I generally loathe the dirty work often involved in software engineering and debugging all of these dependencies all the time. It&#x27;s exhausting. Doing things from scratch puts me in charge.And I mean, creating a search engine is the ultimate \"not invented here\" project. I&#x27;d just pay for and use Google, Bing, or whatever else API to do things for me. So it doesn&#x27;t even make sense in the context of your objections. reply p-e-w 2 hours agorootparent> And I mean, creating a search engine is the ultimate \"not invented here\" project. I&#x27;d just pay for and use Google, Bing, or whatever else API to do things for me. So it doesn&#x27;t even make sense in the context of your objections.Except that none of the established search engines actually does full-text search (anymore). There is no way to prevent those engines from breaking apart and rewriting your query as they see fit. No matter how many quotation marks you put around it, and even if you enable \"Verbatim\" mode or whatever.So if you just implement the option to do that (which is actually the default if you leverage a standard FTS library), you already have something that AFAIK you can&#x27;t get anywhere else. Then you can work on kicking the blogspam out of your index, and before long you will have a search engine of real value for yourself (and possibly others).Or, you can build a crappy clone of a text editor from the 70s. reply exe34 2 hours agorootparentThis sounds like an excellent project! I look forward to following your work on GitHub. Everybody needs a crappy search engine from the 90s! reply mkii 1 hour agorootparentprev> and before long you will have a search engine of real value for yourself (and possibly others)How much do you think hosting would cost? reply bufio 4 hours agoparentprevGentlemen, you can&#x27;t hack in here; this is Hacker News. reply arcanemachiner 3 hours agorootparentI&#x27;m shocked, SHOCKED, to find that hacking is going on in here! reply melagonster 5 minutes agoparentprevIs not this the main point of the editor war? programmers built tool for enhancing programming abilities, but they argued with which tool is best one... reply short_throw 4 hours agoparentprevIf you want learn how things scale across a team and last years, read or contribute to open source code.It takes years for a single person to get a project to the point where it&#x27;s a good learning ground for scaling and maintenance.Gluing a few libraries together is real software engineering but unless you&#x27;re really invested in the outcome it&#x27;s not that engaging and it&#x27;s not that educational. reply p-e-w 4 hours agorootparent> Gluing a few libraries together is real software engineering but unless you&#x27;re really invested in the outcome it&#x27;s not that engaging and it&#x27;s not that educational.That&#x27;s only true if complex systems don&#x27;t interest you.Personally, I have always found the experience of \"putting the pieces together\" and orchestrating highly diverse systems into a coherent whole to be much more educational than learning about algorithmic details. I also generally find making things work well more interesting than making things work. reply exe34 2 hours agorootparentSo if I&#x27;m understanding your argument correctly, if you enjoy it, it&#x27;s what everybody else should do. The other points are just post-hoc justification. reply tonyg 4 hours agorootparentprev> That&#x27;s only true if complex systems don&#x27;t interest you.Gluing a few libraries together will certainly produce a complex system. reply DeathArrow 3 hours agoparentprev>While writing a text editor, a compiler, an operating system, or a raytracer might make you a better programmer, it won&#x27;t make you a better software engineer.To me learning the engineering part is easiest. And also not terribly valuable if you don&#x27;t know CS fundamentals. reply sarafiq 4 hours agoparentprevThere is a need for both \"solving complex problems alone\" and \"learning how to work as a team developing a complex project within a timeline\". The Software Engineering part is best learnt in industry under a mentor. reply DeathArrow 3 hours agorootparentThe tooth extraction skill is fundamental if you are a dentist. You learn it in school. Knowing how to market and sell that skill is valuable but you can learn it while working.CS I learned in school, engineering I learned while working. reply cryogenicfire 1 hour agoparentprevI don&#x27;t understand why you believe low-level \"intrusive\" programming and general software engineering are mutually exclusive. There is a big, open field for high quality, low-level software to be written well bearing good practices and practical decisions.1. To be faif, these kinds of \"hacking\" projects aren&#x27;t technically meant for learning software engineering in the context of a job, but they are really interesting and a treasure trove of new knowledge for anyone willing to put in the effort. I don&#x27;t think it&#x27;s a bad thing. A person can learn to be a good software developer and simultaneously have deep knowledge of the systems they are working with.2. The goal of this project is not to research and implement some novel algorithm to replace existing works. The goal is to learn how things work. You are still going to use libraries, procedures and algorithms designed by other people and compile them into a cohesive system, it is merely the depth and complexity of the problem that makes it an interesting learning challenge. It&#x27;s not about some absurd NIH philosophy, it&#x27;s about curiosity.3. Software development is not as straightforward as you make it seem. It&#x27;s not just about best practices, management and finding an optimal way to combine existing libraries into your project. Sometimes you run into unforeseen issues, strange niches that your libraries may not account for. Sometimes you need to dive into the specifics of these libraries, understand at a lower level why they do not function for your use case. You might need to \"hack\" these libraries. Fork and customise them to truly fit in your project and produce the desired results. And the only thing that will help you then is deep knowledge and the ability to work with low level software. reply tester756 36 minutes agorootparent>I don&#x27;t understand why you believe low-level \"intrusive\" programming and general software engineering are mutually exclusive.Hmm, while I don&#x27;t fully agree with his comment,then your comment reminded me how I hate to discuss programming languages and programming ecosystems with C people.It feels like C&#x2F;low lvl people often refer to some \"standard\" that they treat as a bible of programming languages even when nobody mentions C and they treat GCC&#x2F;CLANG as a perfect reference for compilers.So, while high level devs dont understand low lvl stuff, then I believe low lvl programmers aren&#x27;t creative at very abstract level, very abstract system modeling cuz they&#x27;re too used to modeling everything with integers in C.And they&#x27;re too used to being hurt by C ecosystem that they believe it is \"normal\".High level people (web developers) spend a lot of time arguing about their buzzwords like microservices, ddd, oop vs fp, etc. reply cryogenicfire 14 minutes agorootparentHonestly, that is fair. My perspective on this is as a high-level developer, looking into how the things I am using daily actually work. I haven&#x27;t actually interacted with any proper low-level developer, kind of hard to come across them where I am tbh, so I don&#x27;t have any clue about how snobbish they can be, but I have seen a fair share of high level devs do it too, as you mentioned. I kind of get it? It&#x27;s like a way to get validation on the technology you are stuck with for the rest of your working lives, I&#x27;m guilty of pushing Flutter onto people despite having had a painful experience with it (state management is a nightmare).But hey ultimately I just think people should satisfy their curiosities. My work is often always in Python, JS or Java, but at some point I got tired of just doing regular software development stuff and lately I&#x27;ve happened to gain interest in low level development. (Like any definitely sane person I chose to start with rust and decided my first ever rust project should be an emulator, so maybe I&#x27;m just dead inside and I don&#x27;t know it yet) reply anta40 4 hours agoparentprevI think those who deal with OS kernel, compiler etc on daily basis also understand those points. They use various tools to make code review, time management etc easier.Not all hackers are overly obsessed with the most efficient Big O and various low level (sorry pun intended) details. reply DeathArrow 3 hours agorootparent>Not all hackers are overly obsessed with the most efficient Big O and various low level (sorry pun intended) details.A NAND gate is low level. Big O is just theory that anyone should know if he&#x27;s worth something as a programmer. reply Arcanum-XIII 2 hours agorootparentMost of the time, big O is not relevant if you&#x27;re not writing new algorithm. For the usual CRUD app? Not so much. Heck even for more involved work, you will not touch them because your solution will be called or will call some external tools.The good news is that, while still valuable, you won&#x27;t have to lose time creating a new broken wheel. The bad news is that this part of CompSci is now mostly fundamental research. reply atq2119 2 hours agorootparentAnd then you get needlessly inefficient CRUD apps that take minutes or even hours to generate a simple report because they&#x27;re doing accidentally quadratic or even cubic work somewhere. reply sfn42 1 hour agorootparentprevThis is just wrong. Understanding the difference between O(1), O(n) etc is essential for literally everyone who writes code. Every single programmer is better with this understanding than without it. You should know the complexity of the code you write - and most of the time that doesn&#x27;t even require actively thinking about it. If you know the basics of complexity analysis it&#x27;s just intuitive. reply johnnyanmac 4 hours agoparentprevI figured that was the point here. It&#x27;s nice to follow tutorials for a new language or framework or whatnot, but to really stress and test what you absorbed, you want some non-trivial project with minimal dependencies. the game section exemplies this the best:>The idea here is to implement a well-defined game from start to finish without getting bogged down on the other fun stuff (e.g., game design and art). Also, it is best if you use a barebones 2D graphics library (e.g., SDL, SFML, PyGame), not a big game engine that&#x27;ll hide all of the interesting bits from you.This kind of game won&#x27;t go on sale nor even be a portfolio piece for a non-junior engineer, but it&#x27;s a good enough idea for someone like me who say, wanted to really wanted to solidify their Rust skills and show what my and the language&#x27;s weaknesses are.After I can get that done, I may feel confident enough to move on to work on a toy renderer based on what I figured out in the game. And then later contributing to a proper engine that already has a lot of groundwork figured out. I&#x27;d just be getting in the way if I jumped straight into trying to throw anything but the simplest PRs into Bevy. reply toast0 5 hours agoparentprevI&#x27;m working on a hobby OS. It&#x27;s mostly just a fun project, but there&#x27;s certainly a lot of deciding what to write and what to use, and identifying quality libraries when you want to use something. You can start from nothing and build your own board and bring it up with no software you didn&#x27;t write or you can use a commercially available board, bios or uefi boot, use an existing boot loader, use an existing libc, etc etc, and explore the specific thing you&#x27;re interested in, while still earning a lot of systems knowledge.Deciding when to optimize isn&#x27;t too hard when nobody is ever going to use it (only optimize run time if something really takes too long, otherwise don&#x27;t do anything tremendously stupid, but optimize for less development time because this is taking forever)Readable code would be nice, because sometimes it takes a long time to get back to it, but I&#x27;ve also designed in a real reason to come back and retouch everything (x86 -> amd64; aarch64 as a stretch) and maybe I&#x27;ll make things reasonable then... Although it&#x27;s not my strongest skill.Even most simple OSes become complex. Maybe the dependency chain isn&#x27;t too long though.Seems to tick all your boxes, IMHO. reply bee_rider 4 hours agoparentprevI don’t really see how one could have any hope of performing engineering with any sort of rigor while throwing away big-O.Then again, big-O is useless in many cases because real computers have too many arbitrary performance thresholds.I suspect software engineering is impossible, or at least, nobody has made the model required to do it. reply ozim 1 hour agorootparentSo you say software engineering is not real engineering I will drop this link here:https:&#x2F;&#x2F;youtu.be&#x2F;RhdlBHHimeM?feature=shared reply sfn42 1 hour agorootparentprevGoing from O(n) to O(1) on an operation where n is 10 could be a performance downgrade. That doesn&#x27;t mean it&#x27;s useless, it just means there&#x27;s more to it than the big O.Asymptotic complexity is about how things scale up. You should care about it when you&#x27;re working with things that scale. Doesn&#x27;t mean it&#x27;s useless if your data is static, just means you need to understand when to go for the high scaling solution and when not to. reply hurril 1 hour agoparentprevYou&#x27;re making a strawman here, based on a very much false dichotomy. The things you list here are all very important.But something you learn from writing a larger piece of software yourself is that you get to appreciate complexity and \"bulk\" (for lack of a better term) that you yourself created. You get to ask yourself questions like:Is all this code needed? (Why is it 400 lines to do X?!) Why did this get so involved&#x2F; complicated?! How do I progress (eat the elefant)? Can I (teach myself to) make small iterative units of progress every day, for instance?These kinds of katas are very very useful for a 5-7 year beginner (which I use as a label of respect - the longer we can remain beginners, the longer we learn with an open attitude!) reply BlackjackCF 2 hours agoparentprevI agree that these are all valuable things for a software engineer to learn, but in my experience, it’s valuable to at least take a crack at the projects listed in the post. I wasn’t under any illusion that I was going to build anything amazing, and gave me deeper appreciation of why you don’t try and build everything in-house. reply Turing_Machine 5 hours agoparentprevWhat if we don&#x27;t want to be \"software engineers\"?I&#x27;m still not totally convinced that \"software engineer\" is even a thing, frankly. reply p-e-w 5 hours agorootparentWho do you think puts systems like a web search engine together?It&#x27;s certainly not people who are lost in details like string matching or how ACID is implemented in distributed databases.Of course you need all these things in order for the search engine to work – but if you write them yourself, even if you think about them excessively, you will never finish.Software engineering is knowing that you don&#x27;t need to know everything, you only need to know where to find everything. \"Programming\" is an important part of it, but far from the only one. reply enneff 3 hours agorootparentI find your comment quite ironic considering the engineers that built Google search did it by developing novel software systems, to great success. The Google codebase is basically the definition of NIH syndrome. reply steve_taylor 3 hours agorootparentprev> Who do you think puts systems like a web search engine together?A really good programmer who is free from the tyranny of software “engineering”. reply carom 1 hour agorootparentI believe this more and more as I go through my career. There is usually one person carrying progress hard. If you can get three or four of those people and another one to coordinate them you can do truly amazing things. Usually though you just need one unencumbered by bureaucracy. reply sfn42 1 hour agorootparentNot sure what you guys think software engineering means, but it&#x27;s definitely not the same as what I think it means. reply bruce511 5 hours agorootparentprevThe good news is that the field of computer programming is huge - so there is room for all sorts of preferences, skills, and abilities.And sure, use of the word \"engineer\" will cause angst among some - because it used to have a precise meaning which has been diluted (and in the case of software, ignored.)Indeed the list of projects runs the gamut of where a programmer might go in life. They might do user UI, or games, or work on an OS or compiler. More likely they&#x27;ll work at some random company doing databases and reports. Or they&#x27;ll be Web focused doing lots of JavaScript. Or they&#x27;ll be deeply involved in the field of Advertising (Advertising Engineer anyone?)Of course wherever you end up, you can still have some fun. And if you&#x27;re just starting out then it can help you understand your desires, and limitations.So don&#x27;t worry too much about the \"engineer\" word. It&#x27;s pretty irrelevant. Even the title of the thread is \"programmer\" not \"engineer\". reply inimino 2 hours agorootparentNot ignored! It&#x27;s precisely because software engineering discards the very parts of programming that are closest to real engineering that this term came to describe it. \"Don&#x27;t bother learning the fundamentals, but focus on bureaucratic ritual instead\" is a message that requires excellent marketing. reply hnfong 5 hours agorootparentprevMaybe the *term\" \"software engineer\" is not an established thing.But these points raised by GP... are basically self-evident.> - Deciding what to write yourself and what to take from a library> - Identifying high-quality libraries and frameworks that meet your project needs> - Deciding where optimization is worth the effort and where it is not> - Writing code that will still be readable to you (and others) a few years from now> - Thinking about the project as a large-scale, complex system with software and non-software dependencies... But since they don&#x27;t have immediate effect (along the tune of \"look I made this shiny thing myself in a weekend!\"), it&#x27;s hard to brag about it and perhaps even hard to establish causality that your skills in the areas above contributed to the software&#x2F;business&#x27; success. But you can always brag about how you implemented a Fibonacci heap or something and made your heap operations 0.2ms slower. reply yoyohello13 4 hours agorootparentI do that shit every day at my job. When I’m just coding for fun at home I want to implement crazy data structures, otherwise what’s the point? reply MountainMan1312 3 hours agorootparentprevI honestly don&#x27;t see a difference between programmer and software engineer. The one I see a difference with is \"coder\" reply da4id 4 hours agoparentprevDo you have any good resources for what you mentioned? reply yoyohello13 2 hours agorootparentHave good critical thinking skills and you’re pretty much there. reply p-e-w 2 hours agorootparentprevI wish. As you can plainly see in this thread, most \"real programmers\" consider such things beneath them, and the scarcity of relevant resources is a natural consequence. reply Sparkyte 4 hours agoparentprevI agree with this, only working on a project with certain expectations of delivery can make you a better software engineer. reply samstave 5 hours agoparentprev>> Writing code that will still be readable to you (and others) a few years from now-This will be a wonderful feature for copilots, to allow for the human to provide a verbal narrative of the logic&#x2F;process or even the environment and of others in the room commenting on why a such-and-such is being done, and the copilot elegantly documenting the narrative.Wait until we have \"Thick Code\" (where an app comes with an AI generated Mini-Documentary-Series on the creation of the piece (as an optional function of your enterprise Copilot Agent (With the [Security Assistant] [Compliance Assistant] [Legal Assistant] [Media Assistant] and whatever Alignment Agents are required and inform the narrative of the project.EDIT: @Tao3300 - I do that all the time. You just need to be a better MeatPT and infer \"like, my, opinion, man\" reply Tao3300 4 hours agorootparentI suffered a fatal error because I expected a few end parentheses there. reply whateveracct 5 hours agoparentprevnext [7 more] [flagged] p-e-w 5 hours agorootparentI strongly disagree. Software engineering is simply the next higher abstraction level above programming. Just like programming is the level of abstraction above writing machine code, and writing machine code is the level above hardware manipulation.Almost all \"programming\" problems have been solved. Today&#x27;s software is laughably inefficient not because we need better implementations of data structures, but because putting all those existing pieces together properly is a neglected discipline.The best place to see this is in Machine Learning. The vast majority of ML&#x2F;AI software that is published (which often implements revolutionary techniques!) is of incredibly poor quality from a software engineering standpoint. As a result, practical AI applications are orders of magnitude slower than they could be. reply nsguy 5 hours agorootparentNot to split hairs but writing machine code is programming. I&#x27;m not sure what you&#x27;re thinking about as \"hardware manipulation\". Programming is just one (and a very important one) part of what it takes to be a \"software engineer\" (or software developer, or whatever you want to call having skills to deliver, or be part of a team that delivers, major software projects). reply ericjmorey 5 hours agorootparentprev\"The vast majority of ML&#x2F;AI software that is published (which often implements revolutionary techniques!) is of incredibly poor quality from a software engineering standpoint. As a result, practical AI applications are orders of magnitude slower than they could be.\"That&#x27;s quite the claim. Why should anyone take your word for it? reply p-e-w 4 hours agorootparentThere are literally performance breakthroughs being made every few weeks (most recently, PowerInfer, which can speed up LLM inference by 10x or more) where the main improvement amounts to the application of caching&#x2F;preloading techniques.If the \"engineering\" part of ML had kept up with the \"science\" part, I have no doubt that performance for typical use cases would be 100x-1000x higher than we are seeing today. reply slumberdisrupt 5 hours agorootparentprevI genuinely love your sentiment. We have way too much faux asceticism and way too little self-mockery in this godforsaken industry that pays us all way too much money. Programming is wizardry. But being a professional one (a software engineer) is a ridiculous occupation we&#x27;re coerced into. We all know this, otherwise Silicon Valley wouldn&#x27;t have been a universally cathartic show.But GP is completely correct that all of the fun, magical projects in the OP article are antithetical to the profession. reply whateveracct 3 hours agorootparent> But GP is completely correct that all of the fun, magical projects in the OP article are antithetical to the profession.I guess I was emphasizing GP&#x27;s point. The profession is the problem. Not the subject matter. I love computers. reply dang 3 hours agoprevDiscussed at the time:Challenging projects every programmer should try - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21790779 - Dec 2019 (297 comments)Also related:More challenging projects every programmer should try - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25489879 - Dec 2020 (223 comments) reply anta40 4 hours agoprev+1 for mini operating system.Us, application developers, rely on many OS features: memory management, filesystem, etc. I&#x27;m sure eventually we&#x27;ll ask \"how such things are done behind the scene?\"That&#x27;s why I tinker with xv6 (https:&#x2F;&#x2F;github.com&#x2F;mit-pdos&#x2F;xv6-public) during sparetime. Learning various process scheduling algorithms from textbook is a thing. Implementing it is another thing. I learn a lot. And it&#x27;s definitely fun, even though there&#x27;s almost zero chance the knowledge gained is relevant for my job (I&#x27;m a mobile app dev). reply z3phyr 5 hours agoprevI would really love to try my hands on something much more physical, like a robot; or a drone with autopilot; maybe accurate simulation of flight dynamics of a spaceplane with programmable GNC parameters?I have a copy of \"Fundamentals of Astrodynamics\" by Bate, Mueller et al and I would love to do something with it this holiday season.I say simulation because all the rest of the stuff seems to cost a lot. I am really interested in the GNC aspect of robots, and would love some good pointers on the topic! reply krallja 5 hours agoparenthttps:&#x2F;&#x2F;ksp-kos.github.io&#x2F;KOS&#x2F; Kerbal Space Program might not simulate aerodynamics quite to the realism level you prefer, but a lot of people seem to enjoy writing GNC software for it. reply sowbug 5 hours agoparentprevI bet a self-balancing two-wheeled robot would be a fun (and relatively safe) project. I mean a Segway-like thing that can just stand in one place without falling over or yeeting itself off the table.You&#x27;d need a microcontroller, an IMU, a stepper motor controller, a motor, some LEGO wheels, and maybe a block of wood.I haven&#x27;t tried this, so my guesses are probably way off. reply daemonologist 4 hours agoparentprevI feel the same way - almost all my personal projects have a hardware component. After spending all day on software I very much appreciate working towards a physical object. reply bmitc 3 hours agoparentprev> I have a copy of \"Fundamentals of Astrodynamics\" by Bate, Mueller et al and I would love to do something with it this holiday season.What do you plan on doing with it? I&#x27;d love to hear more about what the book is about and a project you might do. reply defrost 3 hours agorootparenthttps:&#x2F;&#x2F;books.google.com.au&#x2F;books?id=UEC9DwAAQBAJis the direct link to the Google Books overview with sample pages, table of contents, etc. reply Flux159 5 hours agoprevFor a more UI &#x2F; Web based slant, I would recommend these (beyond a Spreadsheet - which is incredibly helpful for understanding data flow systems):* Simple video game using Unity or Unreal (understanding perf limitations in a game where 30-60 fps is critical helps make performant interfaces elsewhere - even on Web)* A simple Javascript framework similar to React (again, will help understand data flow & handling events)* An http library wrapper around XMLHTTPRequest (fetch exists now, but understanding how to send & read HTTP requests from scratch will help in debugging any problems down the line like CORS issues, OPTIONS requests, etc.). reply kylegalbraith 2 hours agoprevTotal long shot. But does anyone have any good side projects that would center around simulating fluid dynamics? I’ve always been interested in aerodynamics and I’ve wanted to see if there is a way to learn more about it with my programming skills. reply TheAlchemist 37 minutes agoparentNot sure if this fits, but I&#x27;ve thought about doing an app to approximate cyclists drag coefficients from video and help improve aero positioning.I have no idea if it&#x27;s realistic - from what I&#x27;ve read, it looks like not really, but hell, I would love to give it a shot. reply remram 38 minutes agoparentprevSome sort of game might be a good idea, for example about building or managing a dam, a reservoir, or canal. Maybe a simple colony sim about otters. reply brosco 1 hour agoparentprevIf you&#x27;re interested to learn more about aerodynamics I would highly suggest learning a bit of classical aerodynamics. It will not be software oriented, since most of the theory deals with approximating very complicated behavior with simple analytical models.It could be interesting to do a comparison with finite volume methods to see when&#x2F;how those approximations break down. reply TheAlchemist 41 minutes agorootparentTotally newbie question - &#x27;approximating very complicated behavior&#x27; - this seems like a perfect problem for ML to me. Is this something that&#x27;s used or explored ? reply knutzui 1 hour agoparentprevSebastian Lague recently did a video on simulating fluids, which may be interesting. As always, he takes a \"from scratch\" approach to it.https:&#x2F;&#x2F;youtu.be&#x2F;rSKMYc1CQHE?si=pXdsHlQSCpw8nY8mThe GitHub repository also contains links to some of the research papers used to implement the simulation.https:&#x2F;&#x2F;github.com&#x2F;SebLague&#x2F;Fluid-Sim reply vedosity 23 minutes agorootparentI recently went this route. I didn’t want to set up or use Unity so I wrote my own 2D fluid simulator based on some of the same papers using Metal compute shaders (though I’d love to try again using webgpu). Sebastian’s video is great and the implementation is good. But this was a great (and fun) opportunity to look for ways to improve on it.For starters, the way he’s doing the spatial lookup has poor cache performance, each neighbor lookup is another scattered read. Instead of rearranging an array of indices when doing the sort, just rearrange the particle values themselves. That way you&#x27;re doing sequential reads for each grid cell you look for neighbors in, instead of a series of scattered reads. The performance improvement I got was about 2x, which was pretty impressive for such a simple change.The sorting algorithm used isn’t the fastest, counting sort had much better performance for me and was simpler for me to conceptualize. It involves doing a prefix sum though, which is easy to do sequentially on the CPU but more of a challenge if you want to try keeping it on the GPU. \"Fast Fixed-Radius Nearest Neighbors: Interactive Million-Particle Fluids\", by Hoetzlein et al [0].Or, if you want to keep using bitonic sort, you can take advantage of threadgroup memory to act as a sort of workspace during bitonic merge steps that are working on small enough chunks of memory. The threadgroup memory is located on the GPU die, so it has better read&#x2F;write performance.I ended up converting his pure SPH implementation to use PBF (\"Position Based Fluids\", Macklin et al, [1]), which is still SPH-based but maintains constant density using a density constraint solver instead of a pressure force. It seems to squeeze more stability out of each “iteration” (for SPH that’s breaking up a single frame into multiple substeps, but with PBF you can also run more iterations of the constraint solver). It’s also a whole lot less “bouncy”. One note: I had to multiply the position updates by a stiffness factor (about 0.1 in my case) to get stability, the paper doesn’t talk about this so maybe I’m doing something wrong.The PBF paper talks about doing vorticity confinement. It’s implemented exactly as stated in the paper but I struggled for a bit to realize I could still do this in 2D. You just have to recognize that while the first cross product produces the signed magnitude of a vector pointing out of the screen, the second cross product will produce a 2D vector in the same plane as the screen. So there’s no funny business in 2D like I had originally thought. Though, you can skip vorticity confinement, the changes aren&#x27;t very significant.There’s a better (maybe a bit more expensive) method of doing surface tension&#x2F;avoiding particle clustering. It behaves a lot more like fluids in real life do and avoids the “tendril-y” behavior he mentions in the video. \"Versatile surface tension and adhesion for SPH fluids\" by Akinci et al [2].One of the comments on Sebastian&#x27;s video mentions that doing density kernel corrections using Shepard interpolation should improve the fluid surface. I searched and found this method in a bunch of papers, including \"Consistent Shepard Interpolation for SPH-Based Fluid Animation\" by Reinhardt et al, [3] (I never implemented the full solution that paper proposes, though). There&#x27;s kernel corrections, and then there&#x27;s kernel gradient corrections, which I never got working. With the kernel corrections alone, the surface of the fluid seems to \"bunch up\" less when it moves, and it was pretty simple to implement. Otherwise, the surface looks a bit like a slinky or crinkling paper with particles being pushed out from the surface boundary.I found [0] and [1] on my own but I found [2] through a thesis, \"Real-time Interactive Simulation of Diverse Particle-Based Fluids\" by Niall Tessier-Lavigne [4]. I also use the 2nd order integration step formula from that paper. It has some other excellent ideas that are worth trying.Many years ago I used a paper (that is in fact one referenced by Sebastian’s video) and some C sample code I found to write an SPH simulator in OpenCL. I had been wanting to write one again but this time get a real understanding of the underlying mathematics now that I have some more tools under my belt. I owe it to Sebastian that I finally started on my implementation and I understand SPH a lot more now.[0]: https:&#x2F;&#x2F;on-demand.gputechconf.com&#x2F;gtc&#x2F;2014&#x2F;presentations&#x2F;S41...[1]: https:&#x2F;&#x2F;mmacklin.com&#x2F;pbf_sig_preprint.pdf[2]: https:&#x2F;&#x2F;citeseerx.ist.psu.edu&#x2F;document?repid=rep1&type=pdf&d...[3]: https:&#x2F;&#x2F;www.hdm-stuttgart.de&#x2F;hochschule&#x2F;forschung&#x2F;forschungs...[4]: https:&#x2F;&#x2F;project-archive.inf.ed.ac.uk&#x2F;ug4&#x2F;20181074&#x2F;ug4_proj.p... reply jaggederest 5 hours agoprevI think a little toy raytracer is another great thing to try out. Just something that outputs bitmap graphics of spheres and does diffuse and specular reflection, couple light sources. Should be a relatively self-limited project if you don&#x27;t go too crazy with it. reply ketzo 5 hours agoparentI went to a university with a great computer science & video games major, and while I didn’t finish out all the credits, I took a couple of the videogame classes; holy shit, you will never learn more about how to abuse geometry and data structures than trying to render graphics. reply mkii 1 hour agorootparentNot just geometry on the math side but numerical computation and linear algebra as well. Was enough to make my head spin. reply azhenley 5 hours agoparentprevThat is in the sequel! “More challenging projects every programmer should try”https:&#x2F;&#x2F;austinhenley.com&#x2F;blog&#x2F;morechallengingprojects.html reply nine_k 4 hours agorootparentHey, putting a ray tracer and a web browser in the same category of \"more challenging projects\" seems a bit weird. A ray tracer is a weekend project. A web browser is a multiple man-years project, unless you use a third-party HTML+CSS engine and a third-party JS engine. reply johnnyanmac 3 hours agorootparentdepends on the ray tracer. You can make \"a\" ray tracer in a weekend. You can spend months making a mid-scoped tracer if you decide to pick up PBRT (which is online for completely free now!): https:&#x2F;&#x2F;pbr-book.org&#x2F;4ed&#x2F;contentsIf you want to upgrade your \"weekend\" ray tracer to a 2-4 week project, I&#x27;d suggest:1. have it take input a scene&#x2F;model file (FBX is the industry standard but also a pain in the butt because Autodesk. I&#x27;d suggest looking at gltf or blender scenes). This may or may not mean supporting triangles&#x2F;quads if you only focused on spheres and planes.2. texture support. Which sounds easy and then you enter the wonderful world of sampling. you can dive as shallow or as deep as you want there.3. acceleration structures to improve runtime.for a small start. reply sbuk 2 hours agorootparentTry using USD instead[0]. It&#x27;s an open scene description from Pixar that is well documentented and seeing adoption across the board - including apps like Blender.[0]https:&#x2F;&#x2F;openusd.org&#x2F;release&#x2F;index.html reply stevage 3 hours agorootparentprevTheir definition of web browser is basically the UI and renderer for a text based browser. reply azhenley 4 hours agorootparentprevA fully featured, commercial ray tracer takes many years, much like a fully featured, commercial web browser. reply nine_k 55 minutes agorootparentMy point is that a barebones ray tracer (spheres, planes, metal vs plastic) is much, much simpler than a barebones web browser (a minimal HTML parser + a minimal CSS parser and cascading + a minimal JS implementation + a miimal layout engine + a minimal renderer).A text-only browser without scripting support, like lynx, could be a more reasonable project, but still larger than a basic ray tracer, or even a ray tracer + a basic material system. reply tukajo 5 hours agoparentprevMy friend did one of these in a weekend!https:&#x2F;&#x2F;raytracing-iow.shuttleapp.rs``` curl --request POST --header &#x27;Content-Type: application&#x2F;json&#x27; --data &#x27;{\"height\":10,\"width\":10}&#x27; https:&#x2F;&#x2F;raytracing-iow.shuttleapp.rs ``` reply robocat 5 hours agoparentprevOr go more esoteric: \"Raycasting engine in Factorio 1.1\": https:&#x2F;&#x2F;youtube.com&#x2F;watch?v=0bAuP0gO5pc reply lattalayta 5 hours agoparentprevRay Tracing in One Weekend is a popular tutorial series for those interested in trying this out https:&#x2F;&#x2F;raytracing.github.io&#x2F; reply kazinator 5 hours agoprevIf you think you need a \"factory pattern\" to write Space Invaders, there is something wrong.I&#x27;m close to absolutely certain no such design concept was involved in the original. reply Tomis02 3 hours agoparentIt&#x27;s the result of 30 years of OOP and design patterns. When your brain gets infected with them you start looking for ways to spread the infection. reply mvdtnz 2 hours agoparentprevAt no point does the author say or even imply that you need the factory pattern to implement Space Invaders. Are we reading a different article? reply jmnicolas 2 hours agorootparentIn the bullet points \"things to learn\":- Creating and managing a dynamic number of objects (e.g., factory pattern). reply mvdtnz 1 hour agorootparentYup where does he say or imply that it&#x27;s necessary to implement the game? reply whazor 4 hours agoprevA text editor can use an array as data structure. You only need it to be fast during the typing, where you are only changing one line. But for entering new lines, the extra latency needed for rebuilding the array after pressing enter is not noticeable for several million lines.The more challenging part of a text editor is making sure you only render what the user sees. reply p-e-w 4 hours agoparentAnd the most challenging part is making a text editor that actually works well from a usability perspective.Which has almost nothing to do with data structures and optimization. I&#x27;ve used dozens of text editors. I have never once thought \"man, that thing is slow\". But I have thought \"man, that thing is a bug-ridden, unintuitive piece of garbage\" many, many times. reply Flam 3 hours agorootparentYou must not have used Eclipse back in the day reply PH95VuimJjqBqy 2 hours agorootparentoh man, this one hurts.the original Eclipse was so godawful slow, this was back in the days where you would install Textpad after installing Java because it would pick up your classpath during installation and configure it for you. Java 1.4 I think. reply steve_taylor 3 hours agorootparentprevor Atom reply MBCook 6 hours agoprevI’m surprised an emulator (especially Game Boy) is considered harder than a little operating system.I guess that would make sense if you’re not familiar with ASM but an OS will force you to learn that too. reply bombcar 5 hours agoparentYou can make a surprisingly usable OS with (relative) ease - because you can control all the features you choose to support (or not).An emulator already has a \"spec\" you have to operate to. reply MBCook 5 hours agorootparentI guess you could do something ultra-simple (no loadable programs or me port allocation for example) but that doesn’t feel like an OS to me.You can sort of do that with an emulator too. For example on the GB you could do just the CPU&#x2F;memory at first, skipping some rare&#x2F;tough&#x2F;quirky ones. Graphics aren’t that bad, you can avoid emulating some bugs&#x2F;ultra-tight timing. Controls are quite easy.Honestly none of it is that tough as long as you’ve skip sound. Sound is the worst part, and what’s next on my plan for my Swift based emulator.Of course if you wanted to keep going you could add on color Game Boy support, Game Boy advanced support, cheat codes, save states, stuff like that.It’s turned in to a pretty great little project. reply grishka 5 hours agoparentprevA GameBoy emulator has a lot of edge cases to cover. Yes, it&#x27;s straightforward to get most games running in a playable state, but there are several games (Prehistorik Man) and demos that rely on precise timing of the PPU relative to the CPU and those are notoriously hard to get right.Here&#x27;s the emulator I made not so long ago: https:&#x2F;&#x2F;github.com&#x2F;grishka&#x2F;miscellaneous&#x2F;tree&#x2F;master&#x2F;GBEmula... reply qingcharles 2 hours agoparentprevHaving checked off most of the list, I would agree the Game Boy emulator is far easier than the OS.I guess with the emulator it depends how much you want to do. You&#x27;d be foolish to write a console emulator and not import someone else&#x27;s CPU code. When I wrote a Game Gear emulator 26 years ago I used off-the-shelf CPU code and just mapped all the in&#x2F;out and did the graphics bits. Took me and a friend a single evening to get it happily playing games.And OS is harder. Well, it was last time I wrote one, again about 26 or 27 years ago. Getting something to boot at all was tricky. I used this book as my main source of inspiration:https:&#x2F;&#x2F;www.amazon.com&#x2F;Developing-32-Bit-Operating-System-Cd... reply 59nadir 1 hour agorootparent> You&#x27;d be foolish to write a console emulator and not import someone else&#x27;s CPU code.Why? It&#x27;s part of the learning and it&#x27;s not particularly complex. reply DeathArrow 3 hours agoprev>So whenever I don&#x27;t know what to build or I want to learn a new programming language or frameworkWhile the mentioned have some merits if you learn how to program, doing them once might be enough. Not sure how implementing a text editor the nth time will help you learn language X.If I am learning a new language, I try to implement what interests me at that time, from small to big. It might be a small game, it might be an AI algorithm, it might be an authentication system, it might be an ORM. Doing thing that I like or need helps.So unless you fancy text editors, I wouldn&#x27;t churn one after another. reply MichaelNolan 5 hours agoprevI would add in a security or network related project.Overflow attack, (sql) injection attack, and maybe something like using wireshark to see what a http request actually looks like.I took two capture the flag classes which changed how I look at some of my day to day dev work. reply cvhashim04 3 hours agoparentInteresting, I will look into this for learning, thanks for the inspiration reply umvi 5 hours agoprevFor a fun challenge, implement space invaders in Verilog (i.e. purely in hardware) reply omgtehlion 36 minutes agoparentCouple of years ago I implemented a snake game in 74-series logic ICs, and 8x8 led indicator, it was fun ) reply MBCook 5 hours agoparentprevHow would you suggest going about the display? Driving an LCD or generating an NTSC&#x2F;PAL signal?Or maybe a giant array of LEDs?Is there a good tool to simulate Verilog so you can test without hardware? reply programjames 5 hours agorootparentYou can hook it up to a monitor and stream the graphics over HDMI. And yes, there are ways to simulate Verilog reply CatchSwitch 3 hours agoparentprevFun fact: The original Pong had no CPU and had all the logic built into the hardware reply petabyt 2 hours agoprevWhen I was 17 I gave myself the challenge of making a profitable and useful app. The discipline and real market skills I learned made the 6 month development processes worth it, even though the app ended up being scrapped. reply 0raymond0 42 minutes agoprevThank you for this idea, I was inspired by it years ago and wrote a delay queue using Golang. But it is dependent on the Redis, recently I want to remove the Redis and write a Key-value store by myself. Welcome to contribute your code to it: https:&#x2F;&#x2F;github.com&#x2F;raymondmars&#x2F;go-delayqueue reply slmjkdbtl 20 minutes agoprevsoftware rendererprograming language reply Sparkyte 4 hours agoprevWriting a tool that can do large template conversions are particularly fun. Like handling Jinja into markdown. You can use this for future projects to build out documents without relying on too much effort if the documentation for things you work on follows a formula. reply beretguy 1 hour agoprevYeah, I don’t have time for any of this. reply BeefySwain 5 hours agoprevIf you would like to contribute to a Python Text Editor &#x2F; IDE, I would suggest https:&#x2F;&#x2F;github.com&#x2F;Akuli&#x2F;porcupineIt has a great (but very small) community and the maintainer is phenomenal as well. reply paganel 1 hour agoprevWhat’s with many programmers’ obsession with writing their own text editors? In part a rhetorical question, but it still boggles me. Not that many people that are obsessed with manufacturing their own hammers and nails, for example, hence why I’m asking. reply cryogenicfire 4 minutes agoparentWell you would normally use hammers and nails for woodworking but you wouldn&#x27;t be able to use woodworking to make hammers and nails... But I guess with a text editor it&#x27;s a weird recursive thing where the programming tool is itself a programming project. I think people just do it for fun and because they can. You&#x27;ll probably never make something you can productionize but maybe you will learn some cool things along the way. reply Waterluvian 4 hours agoprevDoing some 2D game dev without an engine was the most humbling experience that showed me just how ridiculously fast computers have become. You do things that you swear are far too slow to work, and yet it works even on a Game Boy because it’ll do a million operations in a second and a million is apparently a big number.“Wait… so I’m looking up and drawing every sprite every time? There’s no clever diffing happening to know which ones to change? There’s no second buffer to reference the previous frame and steal work from?!” And then you find the much more complex games that do start using these tricks and it’s ridiculous. reply johnnyanmac 3 hours agoparentwell, there ARE some very interesting tricks back in the old days on both the application and hardware side to help out with these exact problems (for one thing, this is exactly how a SpriteAtlas as a data structure is utilized. Why waste time uploading a dozen sprites that usually render in a predictable way when you can upload one big image and sample parts of the image?).But in terms of today, yes. You can certainly brute force render 99% of anything from 15+ years ago on modest commercial hardware (i.e. not even gaming PCs) by drawing and re-drawing a scene. reply kristianpaul 5 hours agoprevThere should be also, implement a Net Cat clone reply adamnemecek 5 hours agoprevI will also add a CAS, computer algebra system to the list. reply ThrowawayR2 2 hours agoparentI&#x27;ve never seen an explanation of Gröbner bases that&#x27;s accessible enough to the average non-mathematician developer to make that practical. Any pointers? reply dmitrygr 5 hours agoprevThose are all good easy projects to do. Good intermediate-level follow-ons would be a JIT binary translator from any architecture to any other and expanding that simple OS to support SMP scheduling. reply sqs 6 hours agoprevAwesome list.A few more I’d add:- search engine- web crawler reply deadbabe 2 hours agoprevTry coding a massive multiplayer game if you really want to send shivers down a spine. From scratch of course. reply gregjor 6 hours agoprevGreat, have fun experimenting and learning. Just please don&#x27;t release your hobby projects as innovations or npm modules. reply codeTired 6 hours agoprev [–] I wish every dev would try projects and things completely unrelated to computers.I enjoy being outside.These headlines “projects every dev should try” really annoy me. I try to put in enough effort at work, and that’s tough. But I have been messing with computers for over 20 years now. reply johnnyanmac 3 hours agoparentWe&#x27;re on Hacker News. Do you go to a fitness community and say \"I wish every gym bro would put down a dumbell and pick up a book?\"But if you&#x27;re curious, I hike, am learning Japanese, and want to eventually clean up and pick back up my saxophone once I can get the money to get it fixed. Tech is a big but not the only part of my life. reply photonbeam 5 hours agoparentprevI think it’s important that those who want a 9-5-only are able to get it, and those who want to make it their calling in life are also able to have that reply Underphil 2 hours agoparentprevI don&#x27;t really understand how this comment relates to anyone but you.Nerding on a computer and doing outdoor things are not mutually exclusive. They may be for you, but that&#x27;s... well... you. reply ohdannyboy 3 hours agoparentprevA strange sentiment for someone who&#x27;s wasting time heckling articles on HN.Of course nobody said don&#x27;t go outside or pursue non tech interests. reply oakejp12 6 hours agoparentprevI just do both. reply abhinavstarts 5 hours agoparentprevCan you please elaborate what do you mean by \" completely unrelated to computers\" ? reply soniczentropy 5 hours agorootparentWoodworking, blacksmithing, gardening, etcThings that don&#x27;t take computers to create reply brcmthrowaway 5 hours agorootparent*makig music reply exe34 2 hours agoparentprevYou could always pull a Wolfram [1].[1] https:&#x2F;&#x2F;content.wolfram.com&#x2F;sites&#x2F;43&#x2F;2019&#x2F;02&#x2F;07-popcorn-rig1... reply csdvrx 6 hours agoparentprev> I enjoy being outside.I don&#x27;t. It&#x27;s cold outside! reply codeTired 6 hours agorootparentCaribbean is nice this time of year. reply brcmthrowaway 5 hours agoparentprev [–] Agreed. This site selects for people who have made computers their entire life. Consider this an unsolicited reminder to touch grass. reply johnnyanmac 3 hours agorootparent [–] >This site selects for people who have made computers their entire lifeisn&#x27;t it the other way around? The site allows anyone to post on nearly any topic, but the longest standing audience veers tech. there still is quite a few topics on medicine, transportation, economics, and politics as well. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Austin Z. Henley suggests a variety of challenging software projects for programmers to try, such as building a text editor, a 2D game like Space Invaders, a Tiny BASIC compiler, a mini operating system, a spreadsheet, and a video game console emulator.",
      "Through these projects, programmers can gain valuable knowledge and skills in key concepts.",
      "Henley provides further reading recommendations for each project and includes a list of additional project ideas from readers."
    ],
    "commentSummary": [
      "The article and comment threads cover a range of challenging programming projects and the importance of different skills in software engineering.",
      "The limitations of AI in certain coding tasks and the value of low-level programming knowledge are discussed.",
      "There are debates on software engineering vs programming and suggestions for learning projects in various fields, such as game development, machine learning, and fluid dynamics. Additionally, the discussion touches on finding a balance between a career in tech and pursuing other non-computer-related interests."
    ],
    "points": 334,
    "commentCount": 175,
    "retryCount": 0,
    "time": 1703561124
  },
  {
    "id": 38765176,
    "title": "Top Software Blog Posts of 2023: Scaling systems, optimizing architectures, programming languages, and more!",
    "originLink": "https://news.ycombinator.com/item?id=38765176",
    "originBody": "Hey folks, I&#x27;m on the lookout for standout software engineering blog posts this year! Interested in anything from system scaling to crafty architectures, optimization, programming languages, and cool features. Whether it&#x27;s from open-source projects, companies, or individuals, what are your absolute favorite blogs for tech insights in 2023?P.S. Wishing you all a Merry Christmas and Happy Holidays!",
    "commentLink": "https://news.ycombinator.com/item?id=38765176",
    "commentBody": "Share your favorite software blog posts of 2023Hacker NewspastloginShare your favorite software blog posts of 2023 270 points by devta 14 hours ago| hidepastfavorite57 comments Hey folks, I&#x27;m on the lookout for standout software engineering blog posts this year! Interested in anything from system scaling to crafty architectures, optimization, programming languages, and cool features. Whether it&#x27;s from open-source projects, companies, or individuals, what are your absolute favorite blogs for tech insights in 2023?P.S. Wishing you all a Merry Christmas and Happy Holidays! ya3r 7 hours agoBicycle by Bartosz Ciechanowski: https:&#x2F;&#x2F;ciechanow.ski&#x2F;bicycle&#x2F; - HN post: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35343495Bartosz has many great blog posts, maybe most famously the one on mechanical watches published in 2022: https:&#x2F;&#x2F;ciechanow.ski&#x2F;mechanical-watch&#x2F;HN posts for Bartosz&#x27;s blog: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;from?site=ciechanow.ski reply samstave 1 hour agoparentThat Bicycle post is Pulitzer worthy - every middle school student should be taught that post in science.As a cyclist for decades - I still learned a lot - how to put to words that which I had innate muscle memory knowledge of, but no language for.The demonstrations are fantastic.Hands down should get some sort of IRL award of meaning.I forgot I had seen the watch as well... Man this guy is amazing!Thanks for resurrecting these for me. reply healsdata 10 hours agoprevWorking With Discovery Trees: https:&#x2F;&#x2F;www.industriallogic.com&#x2F;blog&#x2F;discovery-trees&#x2F;Happened to see Paige Watson present about FaST Agile at the PhillyXP meetup group and then tried some of the concepts with my team at work to great success. We were looking for a good way to turn high-level product asks into actionable work and Discovery Trees fit the bill for us. reply rand846633 5 hours agoprevNew amazing web security research by James Kettle:Smashing the state machine: the true potential of web race conditionshttps:&#x2F;&#x2F;portswigger.net&#x2F;research&#x2F;smashing-the-state-machineThe talk (on YouTube) is also absolutely brilliantly done.James finds new vulnerabilities classes where others don’t even see potential for problems. Absolutely amazing! reply bosky101 11 hours agoprevThis post on embeddings by simonwhttps:&#x2F;&#x2F;simonwillison.net&#x2F;2023&#x2F;Oct&#x2F;23&#x2F;embeddings&#x2F; reply bosky101 5 hours agoparentThis one as well by a former intern from a decade ago who now writes on python and ml internals:How Many Lines of C it Takes to Execute a + b in Python?https:&#x2F;&#x2F;codeconfessions.substack.com&#x2F;p&#x2F;a-war-story-involving... reply HomeDeLaPot 4 hours agorootparentOw. There&#x27;s a paywall halfway through. Don&#x27;t do what I did and get interested in the story if you aren&#x27;t up to subscribing. reply rag-hav 4 hours agorootparentMaybe the reason for CoW being triggered is reference counting. Does anyone know? reply sgeisenh 3 hours agorootparentUsually from GC. Anthony Sottile has a nice explanatory video: https:&#x2F;&#x2F;youtu.be&#x2F;sdmcCQ7Em04?si=9PObAJixALFiZ9vd replysteppi 9 hours agoprevThe &#x27;eu&#x27; in eucatastrophe – Why SciPy builds for Python 3.12 on Windows are a minor miraclehttps:&#x2F;&#x2F;labs.quansight.org&#x2F;blog&#x2F;building-scipy-with-flang reply citelao 6 hours agoparentWow! Thanks for sharing. Sometimes I get disheartened about programming, then posts like this remind me how complicated the world actually is. And how much perseverance and elbow grease we put in to make the world simpler. reply kqr 2 hours agoprevI wrote a lot of articles on fundamentals (verifiable time estimation, leverage points with systems theory, using the Kelly criterion to shape project portfolio, system observability, evolution, etc.) with the intention of ending up on lists like these. None of them gained much traction, which means I need to get better at condensing the key points.In the end, I think my most popular article of the year ended up being a relatively short note on how Bill Tindall approached software development for the moon landings: https:&#x2F;&#x2F;two-wrongs.com&#x2F;tindall-on-software-delays.html reply WolfOliver 13 hours agoprevThe Big TDD Misunderstanding https:&#x2F;&#x2F;linkedrecords.com&#x2F;the-big-tdd-misunderstanding-8e22c... reply GuB-42 10 hours agoparentMy opinion on methodologies is that if it is too often misunderstood, then it is wrong.The entire point of giving a methodology a name and writing about it is to get everyone on the same page. So if people have different ideas on what TDD is, then people should stop talking about TDD until everyone agree what is and what is not TDD.And only after everyone agrees, one should talk about the pros and cons and assess the success of the methodology depending on the situation. \"you are doing it wrong\" is not helpful.Back to the article. I think not mentioning TDD at all would make it a better article. reply bhaney 9 hours agorootparentTalking about it is how we figure out what to agree on. reply throwup238 7 hours agorootparentprevThe entire point of giving a methodology a name is making money off it as a tech influencer slash management consultant. Those people don&#x27;t care one iota about whether everyone agrees or not. reply tunesmith 9 hours agoparentprevThe biggest missing element, in my mind, of the pro-\"classicist\" and anti-\"mockist\" view is that the practice of writing unit tests with mocking leads to refactoring your code until it works with that approach, which in turn leads to better-designed code. I don&#x27;t like the emphasis of \"yeah but refactoring code leads to needing to rewrite mocked tests\", because if you&#x27;ve designed your code well, then the need to adjust an api boundary should be less frequent than the need to adjust the internal implementation details. Focusing on integration tests means you can get away with poorly designed code full of corner cases that your integration tests can&#x27;t catch. Besides, \"we can keep the fast feedback loop with parallel tests\" really increases the demands on complicated tooling that breaks often. reply DanHulton 7 hours agorootparentYou can only get away with poorly designed code if that&#x27;s not caught in the code review. I&#x27;d argue that while that might be a nice side benefit of some testing practices, forcing you to rewrite your code isn&#x27;t relevant to the test - in fact the opposite! Your tests should work irrespective of your code&#x27;s internals!(Also, you can easily run integration tests in parallel with a little planning and attention to detail. For example, if your IDs don&#x27;t rely on a sequence (like UUIDs), you can generally run them in parallel regardless of database connections.) reply tunesmith 6 hours agorootparent> forcing you to rewrite your code isn&#x27;t relevant to the test - in fact the opposite! Your tests should work irrespective of your code&#x27;s internals!Are you avoiding rewriting your code so you can write integration tests, or are you writing integration tests so you can avoid rewriting your code?Those that have been around the block of refactoring code so you can write good unit tests, tend to realize that the better-designed code isn&#x27;t a side benefit. It&#x27;s the entire point. The test is the side benefit.Integration tests should be avoided if the same coverage can be reached with a refactor and some unit tests. For instance, it&#x27;s very common for components to rely on complicated combinations of state. For instance, imagine a nightmare component that has nine boolean state parameters. To integration-test every combination, that&#x27;s 512 cases. But in cases like those, you might discover through refactoring that some of those state combinations can compressed. For instance, you might be able to refactor into three sub-components, each of which take three boolean parameters and return one boolean result, and where the parent component only depends on those three booleans, which can be mocked. So then in that case, you&#x27;ve reduced the amount of tests you need to write to 32 total... that&#x27;s 1&#x2F;16th the effort.I mean, I know that in common practice, neither are done, and people just leave the component largely untested, and then get bug reports that they close as \"Can&#x27;t reproduce\". reply jimmaswell 8 hours agoparentprev> Now, you change a little thing in your code base, and the only thing the testing suite tells you is that you will be busy the rest of the day rewriting false positive test cases.Never happened to me, and we use a lot of junit tests at work.I don&#x27;t see the value in \"Do not isolate code\". Isolating a single method or such is often necessary, especially a unit test of a Utils class. But I only tend to do this if the \"user story\" centric test cases don&#x27;t end up covering everything. reply xwowsersx 6 hours agoparentprevThis is pretty good and much of it resonates with my recent thinking on testing (I seem to revisit this topic every few years and rethink testing in general). I appreciate that it&#x27;s pragmatic and not dogmatic. There&#x27;s a lot of \"tradition\" in testing that has kind of built up over the years and not a lot of questioning the assumptions. Thanks for sharing. reply zachmjr 2 hours agoprevI haven&#x27;t found my favorite this year, but instead I was heavily into newsletters. Currently I&#x27;m subscribed to:https:&#x2F;&#x2F;www.pragmaticengineer.com&#x2F; - industry insights.https:&#x2F;&#x2F;www.workspaces.xyz&#x2F; - people sharing their home office setup incl. photos.https:&#x2F;&#x2F;bigtechdigest.substack.com&#x2F; - all recent tech articles from companies engineering blogs.https:&#x2F;&#x2F;leaddev.com&#x2F; - leadership stuff.https:&#x2F;&#x2F;hackernewsletter.com&#x2F; - weekly hackernews summary nicely split into categories.https:&#x2F;&#x2F;www.ben-evans.com&#x2F; - product and business around tech with nice deep dives. reply dsotirovski 1 hour agoprevPaul Graham&#x27;s Essays keep me amused during this winter season - https:&#x2F;&#x2F;www.paulgraham.com&#x2F;articles.html They go way back, and I do expect(and look forward to) new content.Came across them via multiple sources, but what got me hooked was a reference from Robert Morris&#x27; work.Kinda funny to reference this here :D. reply ngshiheng 3 hours agoprevhttps:&#x2F;&#x2F;samwho.dev&#x2F;blog&#x2F;The visualizations help with the understanding while keeping it engaging too reply samstave 1 hour agoparentForgot about this guy!These writeups and animations are great.There is so much one can learn in this thread alone. reply latch 7 hours agoprevAnother shameless plug. I&#x27;m pretty proud of my Learning Zig series (1). It&#x27;s been translated into Chinese, Russian and Korean.Some may know my other writings (e.g. Little Go&#x2F;Redis&#x2F;MongoDB Book). I don&#x27;t feel like I captured Zig quite as well, but it&#x27;s hopefully a useful resources especially if you&#x27;re coming from a garbage collected language.(1) https:&#x2F;&#x2F;www.openmymind.net&#x2F;learning_zig&#x2F; reply pradeepchhetri 6 hours agoparentI have read your blogs and The Little Go Book. I must say that they are great. Thank you for writing those and keep writing. reply Etheryte 11 hours agoprevThis post is a hilarious example of how little most users on HN pay attention to the actual content at hand. The title is explicit about asking for specific posts, yet almost all the comments as of right now just link to a whole blog. reply Sajarin 11 hours agoparentYour comment (and hypocritically, this comment as well) is also a hilarious example of how some people on HN also disregard the actual content of the parent post and instead point out&#x2F;share their negative meta-observations of the HN community at large. reply Kye 11 hours agoparentprev>> \"what are your absolute favorite blogs\"A reasonable person could infer from the title and this line that OP is fine with both. reply paulgb 6 hours agoprevJake Lazaroff’s CRDT intro: https:&#x2F;&#x2F;jakelazaroff.com&#x2F;words&#x2F;an-interactive-intro-to-crdts... reply planetjones 2 hours agoprevI was happy to get back into blogging in 2023 and write ‘A trip to the internet in 1996 with The Rough Guide 2.0’ -> https:&#x2F;&#x2F;www.planetjones.net&#x2F;blog&#x2F;10-06-2023&#x2F;a-trip-to-the-in... reply karbon0x 10 hours agoprevAnything from Brandur is usually great - https:&#x2F;&#x2F;brandur.org&#x2F;Also, https:&#x2F;&#x2F;www.applied-cartography.com&#x2F; from Justin Duke reply sjfjsjdjwvwvc 11 hours agoprevhttps:&#x2F;&#x2F;danluu.com&#x2F; is my all time favourite. Unfortunately hasn’t posted in 2023, but I reread old posts often. reply kyawzazaw 11 hours agoparentdo you have a specific post? I think entire blog would be too big to check out, just to be in line with this post reply sjfjsjdjwvwvc 9 hours agorootparentThese are some of my favourites:- https:&#x2F;&#x2F;danluu.com&#x2F;culture&#x2F;- https:&#x2F;&#x2F;danluu.com&#x2F;p95-skill&#x2F;- https:&#x2F;&#x2F;danluu.com&#x2F;wat&#x2F;- https:&#x2F;&#x2F;danluu.com&#x2F;look-stupid&#x2F; reply fbdab103 6 hours agorootparentI do not know how real-world accurate it is, but I enjoy the p95 post. For a huge number of skills in my life, I got to an acceptable level of performance, and then more or less never developed it. reply teaearlgraycold 5 hours agorootparentprevI really like the \"culture matters\" and \"look stupid\" posts. I&#x27;ve been allowing myself to look stupid since I was a kid in school. Dan is humble (frequently saying things such as \"If an idiot like me can [do X]\"), but I think this strategy requires a certain degree of intellectual security. For me the logic isn&#x27;t just \"this question may sound stupid but the knowledge gained outweighs that\". It&#x27;s also \"this question may sound stupid but anyone who thinks I&#x27;m dumb is wrong\". reply marcoc 11 hours agorootparentprevMine is: https:&#x2F;&#x2F;danluu.com&#x2F;p95-skill&#x2F; reply akeck 7 hours agoprevWe&#x27;re Knot Friendshttps:&#x2F;&#x2F;jeremykun.com&#x2F;2023&#x2F;04&#x2F;01&#x2F;were-knot-friends&#x2F; reply sam_bristow 4 hours agoprevIt&#x27;s more hardware than software, but \"Infra-Red, In Situ (IRIS) Inspection of Silicon\" by Bunnie Huang was interesting.https:&#x2F;&#x2F;www.bunniestudios.com&#x2F;blog&#x2F;?p=6712 reply pjot 9 hours agoprevI enjoyed this post on pull&#x2F;push based query engines - its examples were wonderfully simple.https:&#x2F;&#x2F;justinjaffray.com&#x2F;query-engines-push-vs.-pull&#x2F; reply ashton314 7 hours agoprevShameless plug, as many others on this thread seem to have done. :) I wrote about the spectrum of macro systems available in different languages and why I think greater adoption for macros in development has been slow here: https:&#x2F;&#x2F;lambdaland.org&#x2F;posts&#x2F;2023-10-17_fearless_macros&#x2F;I learned a lot while writing it! reply quickthrower2 10 hours agoprevNot a blog post, but it could be one, this video about Github Actions: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9qljpi5jiMQ reply sliq 10 hours agoprevTechnically not a blog, but the FIRESHIP youtube channel changed my life: https:&#x2F;&#x2F;www.youtube.com&#x2F;@FireshipA wild mix of super short videos about current software engineering topics, extremely well made, always on the edge of slapstick comedy, trashy memes, inside jokes, but still extremely densely packed with actual information. Plus, the nearly daily video series \"the code report\" is godlike: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GyllRd2E6fg&list=PL0vfts4Vzf... reply samstave 55 minutes agoparentHECK YES!!!!This! is up my alley. thanks.-Ill come back with more when i grok ;-) this whole channel reply neverrroot 11 hours agoprevThis post (The Techno-Optimist Manifesto), but in particular this section (that contains such gems as “Our enemy is anti-merit, anti-ambition, anti-striving, anti-achievement, anti-greatness”): https:&#x2F;&#x2F;a16z.com&#x2F;the-techno-optimist-manifesto&#x2F;#section--13 reply Exoristos 6 hours agoparent\"In lieu of endnotes, read the works of these people.\" Goes on to list 53 authors in alphabetical order. reply DoughnutHole 8 hours agoparentprevProbably the most pompous drivel I’ve read all year.This isn’t a software blog post. It’s a juvenile political screed with some tech buzzwords. reply CPLX 9 hours agoparentprevOMFG I didn’t realize that guy could get even more insufferable. reply maroonblazer 8 hours agoprevLike some of the renegades in the comments, I&#x27;m tempted to share an entire blog. Instead I&#x27;ll share some highlights from my favorite blog of 2023. It&#x27;s not tech-focused per se, but rather politics&#x2F;policy by a former \"Last Week Tonight w&#x2F; John Oliver\" writer and EPA speechwriter, Jeff Mauer. The blog is called \"I Might Be Wrong\". It&#x27;s a perfect mix of smart and funny.Here are some highlights from this past year:\"YIKES: Bing&#x27;s Chatbot Made a Pass at Me After Only 90 Minutes of Relentless Prodding\" https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;yikes-bings-chatbot-mad...Six Products That Will Gently Defeat Your Baby. https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;six-products-that-will-...AI Spells Doom for Incompetent Hacks. https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;ai-spells-doom-for-inco...The \"Rules\" About Which Actors Can Play Who Never Made Sense. https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;the-rules-about-which-a...Holy Moly Do We Ever Over-Value College https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;holy-moly-do-we-ever-ov...Before You End Fencing Scholarships, Consider the Impact That Would Have on Major League Fencing https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;before-you-end-fencing-...Why Is Homelessness a Municipal Issue? https:&#x2F;&#x2F;imightbewrong.substack.com&#x2F;p&#x2F;why-is-homelessness-a-m...EDIT: Just noticed the \"software\" qualifier in the OP. I almost deleted this comment, but it includes a few software-adjacent articles, on AI, so I&#x27;ll leave it up. reply tetris11 13 hours agoprevI&#x27;ve greatly enjoyed reading this Mainlining blog series from ichernev, about porting an Android phone to PostmarketOS:https:&#x2F;&#x2F;mainlining.dev&#x2F;It teaches you how to probe the system, scrape out the proprietary microcode, and use it to build against a newer kernel (albeit with much tweaking) reply zmgsabst 9 hours agoprevI’m a fan of Terry Tao’s blog, which while not strictly software, is both good for advice and discusses one of my passions — formal verification.https:&#x2F;&#x2F;terrytao.wordpress.com&#x2F;2023&#x2F;12&#x2F;05&#x2F;a-slightly-longer-...https:&#x2F;&#x2F;terrytao.wordpress.com&#x2F;career-advice&#x2F;ask-yourself-du...Both previously appeared on HN. reply tirex 6 hours agoprevFor me, it was a post from Levels.fyi, inspiring story about simple and effective tech solutions.\"How Levels.fyi scaled to millions of users with Google Sheets as a backend\"https:&#x2F;&#x2F;www.levels.fyi&#x2F;blog&#x2F;scaling-to-millions-with-google-... reply rareitem 13 hours agoprevbytebytego, really good content reply linusg789 12 hours agoprevhttps:&#x2F;&#x2F;justine.lol&#x2F; reply Brajeshwar 8 hours agoprev [–] This is going to be a shameless plug of my own writing, not even technical but I needed to put it down in writing, so I did.I found Timers to be a perfect tool to free up my brain and reminding me when I need to do something else. Making tea but I need to walk around, or do something else; timer on and I can get back to the right brew that I wanted. Browsing HackerNews but I need to get out after a specific time; timer on and I can get out.Start a Zoom meeting but the attendant(s) are missing; timer on for 5 minute increment, then decide to ignore&#x2F;cancel the meeting in either 5-min or 10-min.https:&#x2F;&#x2F;brajeshwar.com&#x2F;2023&#x2F;timer&#x2F; replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The person is seeking software engineering blog posts covering topics like system scaling, architectures, optimization, programming languages, and cool features.",
      "They are open to recommendations from open-source projects, companies, or individuals.",
      "They also extend holiday greetings."
    ],
    "commentSummary": [
      "The forum post discusses users' favorite software engineering blog posts from 2023, covering topics such as system scaling, architectures, optimization, programming languages, and cool features.",
      "The discussion includes debates on programming and software development methodologies, specifically integration tests versus unit tests.",
      "Users recommend their preferred blog posts and resources, providing valuable insights for software engineers seeking relevant and up-to-date information."
    ],
    "points": 270,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1703531369
  },
  {
    "id": 38767936,
    "title": "Retired engineer wins First Amendment case against state board",
    "originLink": "https://www.wect.com/2023/12/20/federal-court-decides-favor-retired-engineer-told-by-state-not-talk-about-math-public/",
    "originBody": "Skip to content Senior Connect Home Pros Contests Cape Fear Strong Hurricane Center Advertise with WECT Election Results Watch Live News Weather Investigate Traffic Health Cape Fear Weekend Submit Your Pictures Home About Us Meet the News Team Live Online See It, Snap It, Send It Previous Newscasts WECT Anywhere Contests WECT Jobs WECT Internship Program News Investigate Crime Back to School Here We Grow National Politics Election Results Lottery Crimes of the Cape Fear 1-on-1 with Jon Evans School Sex Scandal Black History Month Weather First Alert Skycams Sky Tracker First Alert Action Days FAQs Weather Pics First Alert Hurricane Center Shootin’ the Breeze Traffic Gas Prices Health Coronavirus Opioid Epidemic Senior Connect Sports Olympics Friday Night Football Get Fit With 6 Stats & Predictions How to Watch Cape Fear Eats Cape Fear Foodie Cape Fear Cooking Community Holiday Smiles & Weller’s Wheels Event Calendar Community Classroom Collector's Calendar Cape Fear Weekend Pet of the Week Forever Family Highway 6 Sounds of Summer Clear The Shelters Community Spotlight Birthdays & Anniversaries Home Pros Cape Fear Strong Schedule Carolina in the Morning First at Four Conserve Cape Fear Side Hustle Telemundo Wilmington Previous Newscasts PowerNation Circle - County Music & Lifestyle Gray DC Bureau InvestigateTV Press Releases Coastal Flood Advisory is in effect Dismiss Weather Alerts Alerts Bar Federal court decides in favor of retired engineer told by state to not talk about math in public Nutt used his experience as an engineer to give his opinions about the designs of public works on the internet. By WECT Staff Published: Dec. 20, 2023 at 11:22 PM UTC|Updated: Dec. 21, 2023 at 7:44 PM UTC WILMINGTON, N.C. (WECT) - Chief Judge Richard Myers ruled on Wednesday that the state violated the First Amendment when it told retired engineer Wayne Nutt to stop expressing his opinions about engineering without a state license, per an Institute for Justice announcement. Nutt used his experience as an engineer to give his opinions about the designs of public works on the Internet. The NC Board of Examiners and Surveyors claimed that this was punishable by a misdemeanor unless he obtained a professional engineer’s license from the state. “This is a win for more than just me,” said Wayne. “There are a lot of people in the same situation—people who have expertise that they’ve been blocked from talking about. This decision is an affirmation that the First Amendment protects all of our rights to share what we know.” You can read the full opinion online here and find WECT’s previous coverage below: Retired Wilmington engineer files federal lawsuit against state board, claims First Amendment violations Calculations or a crime? Judge will determine if talking about engineering amounts to practicing engineering Copyright 2023 WECT. All rights reserved. Most Read Family displaced following Christmas morning house fire Sheriff’s office investigating antisemitic incident in Brunswick County Local church provides thousands of free meals for Christmas Eve Wilmington police looking for missing man Latest News Three people injured in Wilmington motorcycle crash Coast Guard ends search for man who fell overboard off Charleston coast ‘It’s easy being green’: Tips from the North Carolina Aquarium at Fort Fisher for a sustainable lifestyle Wilmington police looking for missing man Zoo Atlanta welcomes southern white rhinoceros calf on Christmas Eve Home News Weather Sports Event Calendar See It, Snap It, Send It About Us Meet the Team WECT 322 Shipyard Blvd. Wilmington, NC 28412 (910) 791-8070 Public Inspection File PUBLICFILE@WECT.COM (910) 791-8070 Terms of Service Privacy Policy EEO Report Advertising Digital Advertising Closed Captioning/Audio Description At Gray, our journalists report, write, edit and produce the news content that informs the communities we serve. Click here to learn more about our approach to artificial intelligence. A Gray Media Group, Inc. Station - © 2002-2023 Gray Television, Inc. advertisement advertisement advertisement",
    "commentLink": "https://news.ycombinator.com/item?id=38767936",
    "commentBody": "Fed court rules for retired engineer told by state to not talk about mathHacker NewspastloginFed court rules for retired engineer told by state to not talk about math (wect.com) 258 points by IronWolve 8 hours ago| hidepastfavorite77 comments whats_a_quasar 8 hours agoThe headline isn&#x27;t accurate. The suit was about whether the retired engineer could offer testimony as an expert witness in a lawsuit without a professional engineering license. Notably, the dude had worked as a chemical engineer for decades but never got a PE license because it wasn&#x27;t required in his industry. So he was a legitimate expert. The North Carolina Board of Examiners for Engineers and Surveyors tried to block him from giving testimony because he had a license. The court ruled that his expert testimony was first-amendment protected speech and that the state couldn&#x27;t block it on the basis of not having a PE license.The suit is about licensing requirements for expert testimony in a lawsuit. Not about talking about math in public.The opinion is here: https:&#x2F;&#x2F;ij.org&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;12&#x2F;Nutt-v.-Ritter-opi... reply perihelions 8 hours agoparentThey didn&#x27;t try to \"block\" the testimony, per se; they tried to intimidate him by sending him threatening letters, warning he&#x27;d be criminally prosecuted and thrown in jail. Those threats were unconstitutional; he sought, and obtained, a federal injunction saying as much.There was no motion (AFAIK) to block his testimony through legal means. reply awinter-py 7 hours agorootparentdefense stopped a deposition where he was presenting (top of p4) + &#x27;contacted&#x27; the NC board of examinershe ignored them, defense submitted formal complaint, board ended up seeking declaratory judgment that both his research and his testimony separately violate the Engineering and Land Surveying Actfrom the opinion https:&#x2F;&#x2F;ij.org&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;12&#x2F;Nutt-v.-Ritter-opi...> The Board seeks a counter-declaration that Nutt&#x27;s engineering work for the plaintiffs in the Autry litigation, including his engineering calculations, analysis, and resulting expert report, constituted the unauthorized practice of engineering. The Board also seeks the same declaration regarding \"testifying at the discovery depositions in support of the work contained in the expert report prepared by Wayne Nutt.\" reply whats_a_quasar 6 hours agorootparentprevFair enough, they didn&#x27;t block his testimony in the suit.In general though I think the legal system worked pretty well here. I don&#x27;t think the board&#x27;s initial position was crazy. The dispute was escalated to federal court, and the court made a pretty reasonable judgment. Probably could have happened faster though.Edit: trimmed my comment so that it&#x27;s less cranky. Merry Christmas! reply awinter-py 5 hours agorootparentfwiw the NC rules of evidence clearly states &#x27;knowledge, skill, experience, training, or education&#x27; as qualifications for expert testimonyhttps:&#x2F;&#x2F;ncpro.sog.unc.edu&#x2F;manual&#x2F;706-2nothing about specific licensingalso NC is a daubert state, which I think means you can attack the testimony&#x27;s methodology via motion in limine, but doesn&#x27;t add anything about the expert&#x27;s qualificationhttps:&#x2F;&#x2F;www.law.cornell.edu&#x2F;wex&#x2F;daubert_standardthat said the engineering + survey act seems fairly clear that evaluating the safety of a public work constitutes &#x27;practice&#x27;. if dude has 20+ yoe he could just take the exam under the 13(a3) long-established practice sectionhttps:&#x2F;&#x2F;www.ncleg.net&#x2F;enactedlegislation&#x2F;statutes&#x2F;html&#x2F;bycha... reply mock-possum 5 hours agorootparentprevAnd here I thought witness intimidation wasn’t allowed - doesn’t that kind of mean they conceded their argument? reply AndrewKemendo 7 hours agoparentprevThe whole expert testimony thing is a farce anyway.I am far and away an expert in artificial intelligence, and had one of these “expert witnesses” interview me about my expertise. They hardly knew the basics of software engineering in a modern way let alone modern machine learning pipelines. This is a person who had some patent exposure and generally does small business type of “IT.”The key differentiator in this case is because they couldn’t make it as a actual engineer they decided to parlay their skills into convincing even less technical people that they knew what they were talking about. reply adastra22 5 hours agorootparentI was asked to be an expert witness for a divorce case where bitcoin was involved. This is a pseudonymous HN account not linked to my real world identity, but I&#x27;d been a developer of bitcoin core for 8 years at the time, and had cofounded a very well known bitcoin company. I&#x27;ve presented at multiple bitcoin conferences, and the lightning network was made possible due to changes to bitcoin I personally spearheaded. In fact the set of people this could describe is so small, I&#x27;ve probably blown my cover to someone reading this from that scene.The expert witness called by the opposing side was someone I had never heard of, who had a certificate from \"Blockchain University,\" and near as I can tell never worked as a software engineer anywhere, much less on bitcoin.Guess which one of us nearly got disqualified for lack of credentials.Expert witness testimony is such a joke. reply gnicholas 5 hours agorootparentI’ve thought about making a line of collegiate apparel with ornate lettering: SDU. When asked what “SDU” stands for, the wearer would reply, “Signaling Device University”. reply tomcam 4 hours agorootparentI hear they’re Blockchain University’s biggest rivals reply adastra22 3 hours agorootparentNah man, Crypto Tech is the best! reply bredren 5 hours agorootparentprevWere you at the first Bitcoin conference in 2013? We had a booth there.I’m curious about the context of Bitcoin in this divorce proceeding. What was at dispute? reply adastra22 4 hours agorootparentYes I was in San Jose in 2013, if that’s the one you’re talking about (technically there was one conference earlier in Thailand, but nobody remembers that one). I was on a panel at the SJ conference.The case I was consulted for was pretty bog standard “guy claims he lost his bitcoin in a hard drive reformat X years ago; wife claims BS and wants half of peak market value as of the highest historical price.”Without getting into identifying details, I was able to use blockchain data to independently verify the guy’s claims. Traced transactions, found watermarking features tying them to specific wallet versions. Can’t actually prove that the keys were destroyed of course, but I did show the coins were being spent like crazy from one wallet on one machine, then all activity stopped right around when he claims he reformatted the computer, and the coins sit there on those same wallet outputs to this day, even with multiple market peaks in the intervening years, and many years between then and when he became aware of his wife’s intent to divorce.That’s the way things go in court cases. Us software developers like to think that the law is a highly rational, proof based system. But in reality it basically comes down to “which story seems more believable” in the end, and being able to point to technical proof is the exception. reply CrazyStat 6 hours agorootparentprev> The key differentiator in this case is because they couldn’t make it as an actual engineer they decided to parlay their skills into convincing even less technical people that they knew what they were talking about.The guy had an entire career as an engineer, he’s now in his 70s and retired.Be kind. Don&#x27;t be snarky. Converse curiously; don&#x27;t cross-examine. Edit out swipes.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html(I originally had something snarky here but in the spirit of being better I edited it out) reply dmoy 6 hours agorootparentIt ranges the whole gamut. You&#x27;ll find expert witnesses who are complete hacks, and expert witnesses who are like literal top10 in whatever field.In computing even. E.g. that time Rivest and Diffie both went on the stand to bat for newegg reply ahazred8ta 5 hours agorootparent\"public key encryption. Are you familiar with that?\" \"Yes, I am.\" \"And how is it that you&#x27;re familiar with public key encryption?\" \"I invented it.\" reply dmoy 4 hours agorootparentLol was that how the direct went for real? reply tel 7 hours agorootparentprevAgreed, though being an expert witness is its own skill. You need to be able to coordinate and&#x2F;or write reports which will hold up under scrutiny in court and also be willing and able to stand for depositions and testimony. This also means that your credentials need to stand up to questioning so your credentials need to be transparent and hopefully unimpeachable.Unfortunately, it’s work that’s pretty distinct from engineering expertise despite in theory being supplemental atop engineering experience itself. reply awinter-py 7 hours agorootparentprevexpert witness could barely even invert a binary tree reply asylteltine 7 hours agorootparentprevIt’s true. An expert witness is someone who can hold up in court not someone who is an expert in their field sadly. reply mynameisnoone 7 hours agorootparentprevAn \"expert witness\" is merely an ostensible title meaning someone is available to be paid for their testimony. One irreducible problem is \"Who decides who an &#x27;expert&#x27; is?\"A former customer of mine was a civil engineer, and also a California-credentialed Professional Engineer (PE), who did code consulting and gave expert testimony about the ASME boiler and pressure vessel code. His code interpretations earned about $100k in 2023 dollars ($50k in 1996) for 45 minutes of effort in 1996. I&#x27;d take a guess that an appearance was ~$10-80k depending on the amount of preparation, time, and travel. Needless to say, he had&#x2F;has a 8-figure house in Saratoga, CA. Finding a niche that is essential to industry and monetizing it well is a fairly repeatable plan for success if one identifies and chooses the right profession.(PE in California means someone has attained accredited education, worked in a learning capacity at an appropriate type of firm for 4 years, and taken the very difficult PE exam. California licenses generic PEs and fields related and adjacent to construction and civil engineering. It&#x27;s a shame there aren&#x27;t specific software or hardware critical assurance PE subcategories.) reply bumby 7 hours agorootparentIt’s a little odd that a civil engineer is being an expert witness for pressure vessels, which are typically the Dobson of mechanical engineers. Though, to be fair, most states leave it up to the individual license holder to determine what domains they’ve are competent in.The other aspect that’s interesting to me is that, like “engineer”, the term “expert witness” may be too generic to have much meaning. From the related Oregon case linked elsewhere:>“Courts have long recognized that the term ‘engineer’ has a generic meaning separate from ‘professional engineer” reply mynameisnoone 7 hours agorootparentIn this case, it&#x27;s not for the time period because the specialty of ASME boilers and pressure vessels had legacy CivEs in addition to MEs. These guys had decades of experience on massive industrial, petrochem, and nuclear engineering projects. reply bumby 6 hours agorootparentThat makes sense. As an aside about your comment:>It&#x27;s a shame there aren&#x27;t specific softwareNCEES tried to have a software PE but it withered on the vine and was only offered for a few years. I suspect the incentives in industry don’t support it and the only way itv would get traction is if it were forced by regulation. reply ThrowawayR2 5 hours agorootparentI probably sound like a broken record on this but the software PE was effectively impossible to get firstly because the Fundamentals of Engineering exam that is the first step to becoming a PE wasn&#x27;t discipline specific at that time IIRC and contained topics like thermodynamics that very few CS students would have had exposure to. Even for those candidates who got past the Fundamentals of Engineering exam, four years of professional experience under an already certified PE was the next step but there weren&#x27;t any existing software PEs to do the supervision. Only after passing those two hurdles could the candidate take the software PE exam and become a PE. So basically NCEES made no honest effort to make attaining a software PE realistically possible. reply toasted-subs 6 hours agorootparentprevWell there&#x27;s a reason why. There&#x27;s an EE licensing example, but it&#x27;s just a review of basic circuit design.Not all that useful in practice. reply lolinder 5 hours agoparentprevThanks for this!A bit of additional context: the dispute stemmed from the fact that Nutt was asked to give testimony about stormwater management systems, not chemical engineering. Unlike chemical engineering, this subject is within the purview of the Board, so they believed that their ban on unlicensed expert witness testimony should apply.From what I can see, the court here ruled that the ban itself is unconstitutional, so not only do they need to leave Nutt alone, but they&#x27;re not allowed to enforce the ban on expert engineering reports at all going forward. reply phkahler 6 hours agoparentprev>> The suit is about licensing requirements for expert testimony in a lawsuit. Not about talking about math in public.It pretty much says the state licensing requirements do not apply to expert testimony or preparation of reports supporting such testimony, which in this case they specifically say \"doing some math\" in the decision. reply toasted-subs 7 hours agoparentprevPE licenses are only common place in structural and civil engineering. The reason for the license stemed from bridges.Seems like lawyers unsure of how decide if someone knows what they are doing or not. reply vkou 8 hours agoparentprev> The headline isn&#x27;t accurate.The understatement of the century. It would be like calling someone trying to practice law without a license to be &#x27;A restriction by the state from talking about words.&#x27;The reason this was upheld by the court was because he was giving public testimony, as opposed to rendering a professional opinion for a client (Which would have been absolutely been under the purview of the relevant licensing board). reply resoluteteeth 7 hours agorootparent> The understatement of the century. It would be like calling someone trying to practice law without a license to be &#x27;A restriction by the state from talking about words.&#x27;> The reason this was upheld by the court was because he was giving public testimony, as opposed to rendering a professional opinion for a client (Which would have been absolutely been under the purview of the relevant licensing board).If he was was giving testimony that was protected by the first amendment and not attempting to work as an engineer, saying \"It would be like calling someone trying to practice law without a license to be &#x27;A restriction by the state from talking about words.&#x27;\" seems even more misleading than the headline since he wasn&#x27;t actually attempting to do something analogous to unauthorized practice of law reply anon-3988 7 hours agorootparentprev> The understatement of the century. It would be like calling someone trying to practice law without a license to be &#x27;A restriction by the state from talking about words.&#x27;I don&#x27;t quite understand why this is a problem? If a parrot is able to perfectly defend someone in the court of law then does it really matter if it never had a license to do so? reply vkou 7 hours agorootparent> I don&#x27;t quite understand why this is a problem?There&#x27;s a problem, for the same reason that you can&#x27;t do surgery on people without being a doctor.We&#x27;ve tried letting parrots practice, and it has turned out poorly for everyone involved. reply toasted-subs 6 hours agorootparentYeah but I wouldn&#x27;t trust half the people who build software projects.Seems like the money gets sent to people who know how to talk, not on their abilities. reply vkou 5 hours agorootparent> Yeah but I wouldn&#x27;t trust half the people who build software projects.Unlike engineering, or medicine, the overwhelming majority of software projects are not life-critical.I wouldn&#x27;t build a bridge the way I build software. I don&#x27;t work that way because I can&#x27;t be trusted, I work that way because the stakes of failure are low. reply razeh 6 hours agorootparentprevEvery profession is a conspiracy against the laity. reply 6stringmerc 7 hours agoparentprevnext [3 more] [flagged] tomrod 6 hours agorootparentI read your comment a few times but don&#x27;t understand what you are saying. I think I&#x27;m missing some context. reply cas2325 6 hours agorootparentReads like an LLM reply perihelions 8 hours agoprevSecurity from these kinds of abuses isn&#x27;t strong enough. This guy&#x27;s defense was free, courtesy of a public interest group [0]; but litigation is an unaffordable non-option for most people. You&#x27;re fighting government agencies: people with infinitely more resources than you, and who fear no personal consequences if their judgement is wrong. (Or if they&#x27;re just being vindictive).[0] https:&#x2F;&#x2F;ij.org&#x2F;press-release&#x2F;federal-judge-hands-free-speech... (\"IJ is a public interest law firm. We represent clients free of charge in cutting-edge litigation defending vital constitutional rights.\") reply joe_the_user 8 hours agoprevSo this isn&#x27;t Charles L Marohn, the founder of Strongtowns.org but he got a similar treatment.https:&#x2F;&#x2F;www.strongtowns.org&#x2F;supportreform reply IronWolve 8 hours agoprevWILMINGTON, N.C. (WECT) - Chief Judge Richard Myers ruled on Wednesday that the state violated the First Amendment when it told retired engineer Wayne Nutt to stop expressing his opinions about engineering without a state license reply jerpint 8 hours agoparentnext [2 more] [flagged] aeonik 8 hours agorootparentIf he doesn&#x27;t play his cards right, he may be Nutt Sacked:https:&#x2F;&#x2F;www.theguardian.com&#x2F;politics&#x2F;2009&#x2F;oct&#x2F;30&#x2F;drugs-advis... reply ajb 8 hours agoprevWhat a stupid regulationLicensing regimes have a valid purpose: protecting those who have to rely on qualified engineers, when they calculate and advise that something is safe and fit for purpose.Restricting those who raise concerns that something is not safe or fit for purpose is the opposite. reply toasted-subs 6 hours agoparentPlaying devil&#x27;s advocate, but telling a jury information as if you are an expert when you are not is something to be careful of.Not saying you need credentials but it&#x27;s difficult for outside disciplines to know if somebody knows what they are talking about. reply sbuttgereit 5 hours agorootparentYes, and having credentials is no guarantee that you know what you&#x27;re talking about. The licensure boards themselves will sometimes warn you that a licensee&#x27;s credential is in no way a guarantee of any sort of quality and you need to apply your own judgement in assessing the person&#x27;s qualifications. This makes sense... At the end of the day all the licensure boards can really tell you is if they licensee passed a test and if they&#x27;ve had a history of complaints. reply epgui 8 hours agoprevWhat does this have to do with talking about math? Title is rather misleading. reply vkou 7 hours agoparentIt doesn&#x27;t.Professional engineering is as much &#x27;talking about math&#x27; as performing legal services is &#x27;talking about words&#x27;.Both need a license if you&#x27;re doing it for a living. Neither needs a license if you&#x27;re just shooting the shit, and don&#x27;t try to put the profession&#x27;s weight behind you.In this case, though, this was closer to political, rather than professional speech, and ended up protected. reply equivocates 7 hours agorootparentLawyer here. Tbh, legal services is a lot of talking about words. reply bumby 7 hours agorootparent…in conjunction with a ethics oath and a duty to public, no?So “talking about words” is a subset of a larger requirement. reply ksherlock 8 hours agoprevAlso, Paul Tappel vs Washington state.https:&#x2F;&#x2F;www.cairncross.com&#x2F;blog&#x2F;ch-news&#x2F;engineer-wins-ground... reply heads 4 hours agoprevThe thing I worry about with expert witness testimony is that if you assume a spherical cow then you can make all sorts of logical deduction work in your favour.Something feels fundamentally uneasy about an expert bringing of supposedly rigorous scientific facts to only one side of a court argument. Cases that come to a court are based on much fuzzier, human condition concepts like “did they mean to do it?”, “was it in the heat of the moment?”, and “did they know what they were doing was wrong?”. Even more so when it comes to the sentence which is handed down.I think it’s also the same sort of queasiness I feel when I see a paper that states that an exoplanet has butterflies due to the presence of a certain kind of Nitrogen molecule in its atmosphere. The science of the molecule detection is bang on but the inferred conclusion is not. reply GabeIsko 8 hours agoprevI remember this, so ridiculous. Can&#x27;t believe it took thos long for the trail to go through. reply monero-xmr 8 hours agoprevInstitute for Justice is an excellent non profit and all donations are fully tax deductible, if you are looking for some year end donations. They take up fights for the common man that when properly fought to conclusion affect far more people. A great organization reply pfdietz 7 hours agoprevAs is often the case, it&#x27;s well worth your time to read the judgment. They go through the various ins and outs and explain the legalities. reply nraynaud 7 hours agoparentagreed, I read the thing (without following any reference), and Common Law court orders are generally quite ok to read out of context, the procedure itself is explained in the text. reply rcbdev 8 hours agoprevIn my home country of Austria it&#x27;s easy to distinguish a federally licensed engineer without forbidding the use of that word for people who are not licensed.A licensed engineer may put the title \"Ing.\" in front of his name (e.g. \"Mr. John Doe\" becomes \"Mr. Ing. John Doe\") in communication, everyone else can still call themselves an engineer without issue but are not allowed to use that specific issued title in front of their name.A similar solution could have been found here, where people who are licensed can use a suffix like \"CE\" with their name. reply ekianjo 7 hours agoparentFederal licensing does not mean that the dudes in question know what they are talking about. Titles and papers are, at the end, only titles and papers. If you live long enough you meet enough clowns with PhDs. reply razeh 6 hours agoparentprevSomething similar is brought up in the decision —- the licensing board could have had the licensed engineer&#x27;s stamp their reports as a way of marking them as produced by licensed engineers. That the board just tried to shut Nutt up instead is one of the reasons they lost. reply matt3210 7 hours agoprevLicense? What’s that? — CS engineer reply seanw444 7 hours agoparentAs it should be. Be gone licenses. Return reputation and references. reply nraynaud 7 hours agorootparentOr even targeted certifications, I would not be opposed that the people writing code for nuclear power plants would have to pass a certain training + test before doing so. It doesn&#x27;t remove anything from other people.I&#x27;d take as an example the welding industry, there are bajillions of domains, with various requirements depending on what&#x27;s at stake. There are some interesting forces at play, some domains do 100% weld testing, so they can recruit non-certified welders, because they would see the problems, generally they have a 3 strikes system, others would not take the risk and want to see certification, and some underwater welders have to pass a welding test immediately upon entering the water (then the crew pulls the coupon out, cut it and gives the ok), before really diving and doing their task, every day. reply bumby 6 hours agorootparentThe vast majority of engineering is done under industrial exemptions so licenses don’t apply anyway. The main concept is mitigating risk, and there are multiple ways to skin that cat. reply bumby 6 hours agorootparentprevThat’s easily games as well, though. Bernie Madoff was able to screw over a lot of people based largely on his reputation. While bad, at least that was “just” money and not something safety critical. reply akg_67 7 hours agoparentprevTry using Engineer in your job title in Canada. The PEO (PoS org) will come after you for using Engineer word without being PE aka PEO mafia member. reply thewanderer1983 8 hours agoprevnext [3 more] [flagged] vkou 8 hours agoparentYou do realize that this case predates COVID by almost half a decade..? reply thewanderer1983 7 hours agorootparentNo I had just read the link provided and assumed it was 2023 given the article date. Upon reading the full brief I&#x27;m now aware of my mistake. Thanks for pointing it out. reply renewiltord 8 hours agoprev [–] Because of cases like this and https:&#x2F;&#x2F;ij.org&#x2F;press-release&#x2F;oregon-engineer-wins-traffic-li... I have the opinion that Professional Engineer is a title on par with Microsoft Certified Support Technician. It sounds like a dumbass certification. reply sircastor 8 hours agoparentI think whats happening in these cases is someone in office gets annoyed that someone else is being critical of them, or their work, or making them look bad. So they lean on the levers they have to make these problems go away. I live in the city where this traffic light mess happened and to me it&#x27;s an embarrassment that someone tried to use the law to strong arm this guy into shutting up.The certifications are (ostensibly) there to make sure the people who are doing the work are qualified to do it - a protection against scammers and fraudsters doing shoddy engineering work and endangering people. If instead the powers that be uses it as a tool to silence people, it becomes simply a corrupt access point to power. reply bardworx 8 hours agoparentprevExcept an Engineer is liable for their work. However, these cases go too far because it’s one thing to speak about something and another thing to do.https:&#x2F;&#x2F;www.nspe.org&#x2F;resources&#x2F;professional-liability&#x2F;liabil.... reply acdha 7 hours agoparentprevThat is very much an incorrect opinion. I know two people who went to very good schools and completed their PE certifications in different states, both of whom described it as quite challenging. It makes sense in those cases because you’re talking about someone getting a professional certification involving positions where they are designing things which, if they fail, are likely to result in a number of deaths. reply phkahler 8 hours agoparentprevIt&#x27;s not a dumbass certification. When briefly looked into it last millennium, you&#x27;d best be a recent engineering student whose up on some calculus and physics and I don&#x27;t recall what. But it also seemed geared toward civil engineering, and in many places large construction projects do have to be signed off by a P.E. But if we had to throw away everything designed by regular ME, EE, and SWEs without a PE involved, we&#x27;d be in the technological dark ages. reply axoltl 8 hours agoparentprevThis has everything to do with the way the US constitution was designed and nothing with certifications. reply renewiltord 7 hours agorootparentYeah, thank god for the US constitution. It&#x27;ll keep these half-wit certifications from damaging us. reply astrea 6 hours agoparentprevThis is an absolutely wild opinion from someone who I can only assume has no knowledge of what goes into PE certification reply tekla 7 hours agoparentprev [–] A PE means that shit you do actually matters. 99.9999999% of Software Devs could take a lesson from it. reply renewiltord 7 hours agorootparent [–] I am glad that software engineers don&#x27;t have a certification. Man, could you imagine the struggle? You report a bug and it&#x27;s closed as \"Not reported by a PE\". You build a better product, but you can&#x27;t sell it because you&#x27;re not a PE. You find a horrible security flaw in software but they prevent you from telling the news because you&#x27;re not a PE.God bless freedom and the First Amendment. And God bless software for being a field so concordant with America&#x27;s principles. reply bumby 6 hours agorootparent [–] The SWE may not have a certification but their products sometimes do. If you disagree, try writing avionics software without having it going through a certification process. They aren’t perfect, but to the OPs point, they serve an important function in terms of risk mitigation. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A retired engineer in North Carolina, Wayne Nutt, has won a First Amendment case against the state's Board of Examiners and Surveyors.",
      "Nutt was told by the board to stop sharing his engineering opinions online without a state license.",
      "The court ruled in Nutt's favor, stating that the state violated his First Amendment rights, setting an important precedent for others in similar situations."
    ],
    "commentSummary": [
      "The discussion revolves around the court ruling on the eligibility of retired engineers to provide expert testimony without a professional engineering license.",
      "Debates arise regarding the qualifications and credibility of expert witnesses, as well as rivalries in the blockchain and cryptocurrency industry.",
      "Licensing requirements, the role of expert witnesses in court cases, the value of certifications in professions like engineering, and the significance of math in engineering are also discussed."
    ],
    "points": 258,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1703552511
  },
  {
    "id": 38762214,
    "title": "Improving SSH Password Authentication with a Password Manager and Zsh Wrapper",
    "originLink": "https://vincent.bernat.ch/en/blog/2023-sshpass-without-sshpass",
    "originBody": "Non-interactive SSH password authentication Vincent Bernat November 5, 2023 Also available in français Filed under programming > shell SSH offers several forms of authentication, such as passwords and public keys. The latter are considered more secure. However, password authentication remains prevalent, particularly with network equipments.1 A classic solution to avoid typing a password for each connection is sshpass, or its more correct variant passh. Here is a wrapper for Zsh, getting the password from pass, a simple password manager:2 pssh() { passh -p$helper$helper/dev/null' EXIT INT TERM HUP stty -echo print \"\\rpassword: \" read password printf \"\" } > /dev/tty /dev/null)}\"}:#(host|hostname|user) *}}) local remote=${details[host]:-details[hostname]} local login=${details[user]}@${remote} # Get password name local passname case \"$login\" in admin@*.example.net) passname=company1/ssh/admin ;; bernat@*.example.net) passname=company1/ssh/bernat ;; backup@*.example.net) passname=company1/ssh/backup ;; esac # No password name? Just use regular SSH [[ -z $passname ]] && { command ssh \"$@\" return $? } # Invoke SSH with the helper for SSH_ASKPASS # […] } It is also possible to make scp invoke our custom ssh function: scp() { set -o localoptions -o localtraps local helper=$(mktemp) trap \"command rm -f $helper\" EXIT INT > $helper <<EOF #!$SHELL source ${(%):-%x} ssh \"\\$@\" EOF command scp -S $helper \"$@\" } For the complete code, have a look at my zshrc. As an alternative, you can put the ssh() function body into its own script file and replace command ssh with /usr/bin/ssh to avoid an unwanted recursive call. In this case, the scp() function is not needed anymore. Update (2023-12) This post was heavily discussed on Hacker News. First, some vendors make it difficult to associate an SSH key with a user. Then, many vendors do not support certificate-based authentication, making it difficult to scale. Finally, interactions between public-key authentication and finer-grained authorization methods like TACACS+ and Radius are still uncharted territory. ↩︎ The clear-text password never appears on the command line, in the environment, or on the disk, making it difficult for a third party without elevated privileges to capture it. On Linux, Zsh provides the password through a file descriptor. ↩︎ To decipher the fourth line, you may get help from print -l and the zshexpn(1) manual page. details is an associative array defined from an array alternating keys and values. ↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=38762214",
    "commentBody": "Non-interactive SSH password authenticationHacker NewspastloginNon-interactive SSH password authentication (bernat.ch) 239 points by jandeboevrie 21 hours ago| hidepastfavorite98 comments adontz 18 hours agoI believe privileged access management is the proper way to manage access to a password protected systems.It is basically a terminal server, proxy, bastion or anything similar. You log in there with federated identity (for example AD) and it logs you in into target system with some shared or temporary user. Usually it also records session and does other security&#x2F;compliance related things.Examples are Delinea (former Thycotic), CyberArk, To some extent Apache Guacamole can be used as PAM. reply oneplane 13 hours agoparentPAM does not preclude having everything secure instead of some sort of &#x27;hardened&#x27; bastion and &#x27;soft&#x27; destination.Everything should be &#x27;hardened&#x27;. This also means everything has to do proper authentication and authorisation, and skipping that step by letting some proxy do that just creates a bottleneck in security, reliability, availability, and performance.It also doesn&#x27;t really matter how it&#x27;s done, a Kerberos Ticket, x509 client certificate, JWT or multiple credentials (i.e. username with a password and MFA token) are all plenty valid. Granted, a ticket, certificate or token allows shipping claims or attributes allows for directory-less access control, but that doesn&#x27;t mean that having to do directory lookups is not feasible anymore.Most of the other things like f5, pa, Citrix, powerbroker and bomgar are just really shoddy software that you setup to attempt to not have to bear responsibility or know what you&#x27;re doing (or it&#x27;s clipboard&#x2F;checklist-based security...), but that just bypasses fulfilling the actual need of a good IAM and PAM implementation. None of those products do it better than what is natively supported, and they are consistently more problematic (be it performance, cost or actual security). reply 616c 18 hours agoparentprevThey become a very high value target though and I have learned \"security software\" devs are as fallible as all devs, sometimes more.Thycotic had some vulnerability with a symmetric recovery key a few years ago. But comprehensive product like this or roll your own this is frequent so I&#x27;d rather do keys and certs like others suppose reply Too 1 hour agoparentprevIs there any tool out there that can provide this using short lived ssh certificates? reply oarmstrong 1 hour agorootparentHashicorp&#x27;s Vault works quite nicely. Teleport is another tool I believe handles this but haven&#x27;t used it personally. reply steve1977 18 hours agoparentprevWhy not use something like Kerberos (for example) and have the proper identity also on the system where you log in to via SSH? reply adontz 17 hours agorootparentKerberos isa) relatively complex to set up properly if its not a Windows in ADb) an SSO, not federated ID. Which means reasking MFA is not possible. reply mmh0000 17 hours agorootparentCheck out FreeIPA (or Red Hat IdM if you like paying for things.). It’s Kerberos and a few other utilities in a very easy to setup package. It also support OTP MFAhttps:&#x2F;&#x2F;www.freeipa.org&#x2F;https:&#x2F;&#x2F;www.freeipa.org&#x2F;page&#x2F;V4&#x2F;OTP reply gnufx 14 hours agorootparentMIT Kerberos supports preauth with OTP, or PKINIT (X.509 certifies); I don&#x27;t know what Heimdal currently has. FreeIPA has been doing good work past that, on integrating FIDO, for instance, and can issue tickets on the basis of external identity providers. It certainly does more -- like a souped-up AD. reply josephcsible 17 hours agorootparentprev> reasking MFA is not possibleIsn&#x27;t reasking MFA on purpose just a way to make people hate MFA? Shouldn&#x27;t everything support a \"Trust this device\" option and then never ask again from it? reply adontz 17 hours agorootparentI&#x27;d rather reask credentials before elevating effective access level. Just like sudo reasks password. I don&#x27;t mean reasking MFA to access corporate intranet website with a blog no one reads, I mean reasking for administrative access. reply gnufx 14 hours agorootparentIf you want a session with extra permissions you use an appropriate Kerberos principal, e.g. admin&#x2F;... reply adontz 3 hours agorootparentI know. This practice of having two user accounts sucks. reply gnufx 14 hours agorootparentprevI don&#x27;t see how setting up MIT or Heimdal Kerberos is complex compared with AD (which is more than Kerberos); they seem easy enough to me. SSO seems to me what you want, and Kerberos is the reasonable implementation. reply yetanotherloss 14 hours agoparentprevI&#x27;ve been moving away from this model towards user-asssociated VPNs or (inverse) captive portals.Used Powerbroker and cyberark for a long time and while they&#x27;re good at stated purpose the integration with more flexible and modern auth systems has had a lot of friction.The particular regulatory area I work in is also just a non-starter for federated AAA from outside the regulated systems which colors my opinion though.Combined with command restrictions in openssh and sudo etc you end up with several wholly disjoint attack surfaces, decent logging, and granular user restrictions. reply unixhero 12 hours agorootparent>I&#x27;ve been moving away from this model towards user-asssociated VPNs or (inverse) captive portals.Would you care to share how you achieve this&#x2F;what does the implementation of these two look like? reply yetanotherloss 12 hours agorootparentThe terminology varies by vendors but essentially there are authentication portals that users will log into and receive auth tickets. These are forwarded to network gateways, usually encrypted in a vpn tunnel, that allow traffic based on user RBAC, sometimes region or time, etc.Captive portals are web auth pages for use cases the more structured method doesn&#x27;t work for. They were envisioned as making you sign in hotel wifi and such but work in the other direction as well by forcing a web user login before allowing traffic from a host for some period of time. reply bityard 18 hours agoparentprevThese are a good idea for large enterprise organizations. We are using a product called Securden which offers PAM features.(But I much prefer keys&#x2F;certs over passwords where possible.) reply pphysch 15 hours agoparentprevIf using OpenSSH, you can roll your own solution by setting AuthorizedKeysCommand to curl a secure internal auth server. reply johann8384 16 hours agoparentprevThere are multiple proper ways depending on your needs and the context. I&#x27;ve used systems like this and I completely agree with you for many cases. reply cmrx64 18 hours agoparentprevI fully agree. Essentially, the PAM wraps a pure knowledge-based “keys as capabilities” model into a much richer “real capabilities” model. reply alsetmusic 19 hours agoprevWait, why aren&#x27;t we using SSH keys? I just did a search on the page for &#x27;key&#x27; and didn&#x27;t see an explanation for why that&#x27;s not the best option. reply infotogivenm 19 hours agoparentIt’s covered under footnote #1:> First, some vendors make it difficult to associate an SSH key with a user. Then, many vendors do not support certificate-based authentication, making it difficult to scale. Finally, interactions between public-key authentication and finer-grained authorization methods like TACACS+ and Radius are still uncharted territoryKeys (with&#x2F;without certs) are the best route, but not always possible for every situation. reply squeaky-clean 18 hours agorootparentHonest question, unless it&#x27;s mandated by your employer, or you don&#x27;t personally care, why would you ever choose to use a service that doesn&#x27;t offer that? reply daneel_w 18 hours agorootparentYou may be in a position where you must employ and interact with networked equipment that does not support pubkey authentication. reply tialaramex 15 hours agorootparentPublic key authentication is actually a Must Implement for SSHv2. Since SSHv1 is long obsolete, any gear that doesn&#x27;t have pubkey doesn&#x27;t actually have a de jure SSH implementation.\"All implementations MUST support this method\" reply wtallis 15 hours agorootparentThat doesn&#x27;t mean it&#x27;s always easy to install and manage keys. For example, the author of the passh tool recommended by this post somehow managed to come away with the impression that OpenWRT&#x27;s ssh server only supports password authentication. reply varenc 13 hours agorootparentAnother example: Ubiquiti gateway consoles like the UDM-Pro. You can install an SSH key but these are erased on reboot. So after every reboot I have a script that uses the SSH user password to re-install an SSH key but this can’t be relied upon and I haven’t found a way to make an SSH key persist. reply a_subsystem 5 hours agorootparentHere you go:https:&#x2F;&#x2F;github.com&#x2F;fire1ce&#x2F;UDM-Persistent-SSH-Keys reply justsomehnguy 14 hours agorootparentprevDell PowerConnect 5500 series has a very picular SSH implementation, which could be described as &#x27;allow all SSH proxy for telnet&#x27; reply tsimionescu 15 hours agorootparentprevThat doesn&#x27;t mean that a device that doesn&#x27;t offer pub key storage is not accessible over SSH. reply jiveturkey 5 hours agorootparentprevAnd if you don&#x27;t, anyway? Do you not get to use the SSH(TM) logo on your product? You&#x27;re reading MUST a bit too literally. reply wkat4242 18 hours agorootparentprevYeah this is why fido2 doesn&#x27;t work either. Most embedded ssh implementations don&#x27;t support it. reply vbernat 18 hours agorootparentprevThere are not many network vendors. Check the link in the first footnote for an example how Cisco, the leader in the field, makes it difficult to deploy SSH keys. This is getting better. For example, Juniper (another network vendor) now supports SSH certificates. reply RedShift1 18 hours agorootparentI have no idea what&#x27;s going on in the footnote, but deploying SSH keys on Cisco equipment is like 3 commands (conf t, user x, ssh something something) to deploy public keys, not hard at all. reply bnny 18 hours agorootparentIt&#x27;s been a few years, but this requires manually deploying keys and adding&#x2F;removing users on all your devices. Most use TACACS+ and&#x2F;or Radius to centrally manage users, which don&#x27;t support keys in that way (or at least didn&#x27;t the last time I worked with them.) reply vbernat 17 hours agorootparentThere is an implementation with an extension: https:&#x2F;&#x2F;github.com&#x2F;MarcJHuber&#x2F;event-driven-servers&#x2F;wiki&#x2F;TACA.... But I don&#x27;t know if there are any supported clients.Another possibility would be to use CA certificates for authentication and only TACACS+ for authorization and accounting. Juniper now supports CA certificates. Cisco may in 10 years. reply vbernat 18 hours agorootparentprevNot on IOS XR: https:&#x2F;&#x2F;vincent.bernat.ch&#x2F;en&#x2F;blog&#x2F;2020-syncing-ssh-keys-iosx.... The commands you mention are for NXOS. reply infotogivenm 15 hours agorootparentprevOne good example is bringing up equipment that comes out-the-box with a default password. This is common on BMCs for example, and you have to initially provision things somehow. reply nine_k 18 hours agorootparentprevIt may be a box configured and serviced by a vendor, and your org may be short on IT staff. reply brewedDoritos 18 hours agoprevRecently I tried to use an sftp script created with expect that ran fine on the command line, but the same script failed to run under cron. I made sure that all environment variables were properly set, but sftp didn&#x27;t ask me for a password. I think it might have been an issue with the absence of a ttysshpass didn&#x27;t work, ended up rewriting the whole thing in Paramiko ... only to find out it doesn&#x27;t respect the http_proxy environment variable.That was not a good day reply rubicks 17 hours agoparentWorking with less-than-stellar tools --- ahem ROS --- has taught me how to placate commands that assume interactivity and&#x2F;or a tty. To wrap up the offending command with a \"fake\" `tty`, I do script -qfec \"mycommand\" &#x2F;dev&#x2F;nullIf the thing insists on interactive input, then I break out the big guns: https:&#x2F;&#x2F;manpages.debian.org&#x2F;bookworm&#x2F;expect&#x2F;expect.1.en.html reply brewedDoritos 16 hours agorootparentI&#x27;ve actually tried script and expect, but they didn&#x27;t work.I had enabled the debug option on expect and I couldn&#x27;t see the password prompt when the program ran under cron (i was redirecting the script output to a log file). It did appear when running on the prompt though.I couldn&#x27;t figure how the sftp program was determining that it was running under cron. I suspect that it was inspecting if stdin was connected to a terminal or not, but I gave up around 4 am. reply oasisaimlessly 2 hours agorootparentIt was probably checking for a &#x27;controlling terminal&#x27; by e.g. opening &#x2F;dev&#x2F;tty. reply MobiusHorizons 16 hours agorootparentprevStrace is your friend in such circumstances. reply noAnswer 14 hours agorootparentprevThe other month I had to wrap a commercial server program with &#x27;screen&#x27;. &#x27;script&#x27; wasn&#x27;t enough.If you would run it in the background \".&#x2F;program &\" and then exited ssh it would also exit. It wouldn&#x27;t run with cron until: export TERM=vt100 script -c \"screen &#x2F;foo&#x2F;bar&#x2F;program\" &#x2F;dev&#x2F;nullAll the program did on the console was print to stdout. How are you even program shit like this!? reply brewedDoritos 13 hours agorootparent> If you would run it in the background \".&#x2F;program &\" and then exited ssh it would also exit.Just wondering... have you tried running it with nohup and in the background? reply noAnswer 12 hours agorootparentNo, I haven&#x27;t tried that. replyxorcist 9 hours agoparentprevAvoid sftp and use rsync instead (much better support for more types of metadata, more robust error handling).Avoid passwords and use keys instead (easier to distribute, easier to generate, lets you lock them down to a single command).The above avoids much unnecessary thinking.If you really have to, there&#x27;s always sshpass. And ssh -t to allocate a tty even if you are running without one. But this is seldom really necessary, first try harder do it the easy way. reply brewedDoritos 9 hours agorootparent> Avoid sftp and use rsync insteadI should have explored rsync better. I asked chatgpt some use cases and it made seem to be a bad fit because I needed to also delete some files on the destination machine. My prompt fu was probably a bit bad at the time.> Avoid passwords and use keys instead .The vendor only provides password authentication in this case> If you really have to, there&#x27;s always sshpass.I´ve tried it, but sftp, when running under a cron script, detects that it is not running in interactive mode and does not issue the password prompt. The problem might have been caused by the TERM environment variable not being set as another reader suggested.> And ssh -t to allocate a tty even if you are running without one. But this is seldom really necessaryI&#x27;ve used -o RequestTTY=force, but it also didn&#x27;t work. Granted, it was close to 4 am and I might have missed a key aspect.> first try harder do it the easy way.Paramiko endep up being easier once I understood how to use the proxy command to interact with the company&#x27;s http proxy. reply qweqwe14 9 hours agoprevIn Dropbear SSH client, you can provide the password with DROPBEAR_PASSWORD environment variable reply dtgriscom 20 hours agoprevSeems overly complicated; sshpass works fine for me. (And the passh examples of why sshpass is broken seem contrived to me.) reply rubicks 17 hours agoparentSame. As soon as I read the title: \"Surely `sshpass` still works in this instance? Yup.\"Even if avoiding good practices with PKI was defensible (and it definitely is not), further avoiding `sshpass` in favor of this more contorted trickery is (imho) probably the wrong choice. reply flyingcircus3 19 hours agoparentprevOverly contrived examples are the hallmark of software zealots. I knew to stop reading after \"its more correct variant\". reply IshKebab 17 hours agorootparentIgnoring failures because they&#x27;re moderately unlikely is the hallmark of a bad developer.It&#x27;s an extremely common attitude unfortunately - you can see it all over the place, especially in the Unix&#x2F;Linux world e.g.* People thinking sysvinit (janky Bash scripts) are fine.* 50% of Linux software doesn&#x27;t work if you have spaces in your path. GNU Make explicitly doesn&#x27;t support that.* Over use of text based APIs, e.g. &#x2F;proc and &#x2F;sys. reply qweqwe14 2 hours agorootparent1) How are shell scripts janky? Could you elaborate on that? Obviously if someone doesn&#x27;t know shell very well they will write suboptimal scripts. Personally I use runit init, which uses shell scripts for services and it works well.2) No idea where you got that from, I never had a problem with this (as a full-time Linux user)3) Mixed opinions on this one. There&#x27;s a ton of various info in &#x2F;proc that could theoretically be exposed via different syscalls, or maybe a single syscall? But having a text-based API in this case isn&#x27;t a big issue really. reply IshKebab 36 minutes agorootparent1. Sounds like you have written very few shell scripts if you don&#x27;t know the issues and think you can just \"don&#x27;t make mistakes\" (a classic fallacy). You can Google it and there are a ton of articles. Here&#x27;s the first one I found which is decent but doesn&#x27;t even mention some big issues like quoting: https:&#x2F;&#x2F;pythonspeed.com&#x2F;articles&#x2F;shell-scripts&#x2F;2. Try putting a space in your home directory and let me know how that goes...3. Most programs don&#x27;t resort to reading &#x2F;proc or &#x2F;sys because it is such a pain! I bet there&#x27;s a ton of undiscovered vulnerabilities in programs that do. reply generalizations 14 hours agorootparentprevOn the other hand, text-based line-oriented APIs are a force multiplier that lets one solo dev&#x2F;sysadmin be capable of administering (troubleshooting and building out and keeping alive) far more infrastructure than can be reasonably expected. And it&#x27;s not sysvinit you should critique, but runit (fast and bulletproof - two things the other modern alternative doesn&#x27;t really do).> Ignoring failures because they&#x27;re moderately unlikely is the hallmark of a bad developer.Totally agree. reply IshKebab 12 hours agorootparentI dunno I think something like JSON would still allow solo dev&#x2F;sysadmins to get a lot done without the risk and effort of having to hand-roll separate parsers for every API. Then you could also offer something like Fuchsia&#x27;s FIDL for programs to interface with - it allows generating the interface code fully typed in whatever language you want. No need to hand-roll a parser at all!> runitFirst I&#x27;ve heard of that. Looks interesting, but it doesn&#x27;t seem like it has nearly enough features to run a modern desktop system? It just starts daemons and keeps them running as far as I can see. replygeneralizations 17 hours agoprevWhat bit me recently was trying to set up non interactive password protected ssh keys. (The use case is wrapping the ssh functionality inside another program.) Turns out, if you want to script the use of an ssh key that requires a decryption password, you can’t do it without ssh-agent (which isn’t really the best solution for a multi user program). reply jamespwilliams 15 hours agoparentSomething like https:&#x2F;&#x2F;matrixzj.github.io&#x2F;documentations&#x2F;idm_decrypt_ssh_pr... (then ssh -i decrypted_key) should work and avoid ssh-agent reply generalizations 14 hours agorootparentThanks for the link. It&#x27;s ironic that in the name of security, that solution is probably one of the best available. SSH is so protected against footguns that legitimate use cases are forced to use demonstrably worse security practices, just because some people might shoot themselves in the foot. I&#x27;m stuck with either that option, expect, or a total misuse of ssh-agent. reply jamespwilliams 12 hours agorootparentDepending on your use case it might be better to just store the key unencrypted. There’s not really much point encrypting it if you’re storing the passphrase on disk alongside the key anyway. reply gnufx 11 hours agorootparentRight (what&#x27;s the threat model)? The possibilities of restricted passphrase-less keys are under-appreciated for non-interactive use, or even interactive use. I&#x27;d rather mint an ephemeral key for an endpoint I control than type credentials or, worse, forward the agent, if I have to call out of an untrusted system (like an HPC login node). reply generalizations 10 hours agorootparentI mean, the use case is I want my GUI wrapper to interactively prompt the user for the decryption password. It’s not getting saved to disk; I just want ssh capabilities (including password protected ssh keys) inside an interactive desktop app. reply gnufx 11 hours agorootparentprevIf you want to remove a passphrase, just use ssh -p. reply dthakur 19 hours agoprevI disable password login all my hosts but good to know people do this. reply midasuni 19 hours agoparentCan’t do that in some cases. Tacacs for example doesn’t allow for private keys reply nixgeek 19 hours agorootparentI’ve worked at more than one place where you SSH into a Linux host (often just for that datacenter) using certificate-based authentication, only to be printed a JIT (just in time) password for TACACS-based usage in that datacenter, and which is only valid for a few minutes.Workarounds are many for network devices it seems! reply vinay_ys 19 hours agorootparentprevDon&#x27;t use that then. Tell that vendor their security posture is bad. reply blueflow 19 hours agorootparentIts Cisco. They already know that. reply dark-star 19 hours agoprevThe author claims that sshpass is \"broken by design\" and goes on to show some examples of why, without ever explaining anything.Can anyone enlighten me why sshpass is broken, or explain the examples on that page? reply vbernat 18 hours agoparentAuthor here. I don&#x27;t claim sshpass is \"broken by design\". I claim it is brittle as it relies on the detection of a password prompt. passh author has several examples here: https:&#x2F;&#x2F;github.com&#x2F;clarkwang&#x2F;passh&#x2F;blob&#x2F;master&#x2F;sshpass-broke.... reply rovr138 17 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;clarkwang&#x2F;passh&#x2F;On the sidebar, in the about, it says,> sshpass is broken by designThis is another repo. But probably where they got it. reply bityard 18 hours agoparentprevYou may wish to edit your comment to clarify that the author of https:&#x2F;&#x2F;github.com&#x2F;clarkwang&#x2F;passh claims sshpass is broken by design, not the author of the linked article. reply MikePlacid 18 hours agoparentprevYou are probably asking about the passh page. Examples there show that sshpass creates a new permanent tty entry with each use, while passh does not.More importantly though is that sshpass keeps your password permanently on your computer, thus increasing security risks considerably. reply erinnh 19 hours agoparentprevI’ve always been told that ssh is not supposed to work non-interactively. Which is the whole reason for sshpass, to work non-interactively. Ie. Broken by design. reply nine_k 18 hours agorootparentWhat, how about scp and sshfs?I can argue that SSH password auth only makes sense.as in interactive affair; for non-interactive auth cases, there are public keys, certificates, smart cards, etc. reply yanko 19 hours agoprevUsed &#x27;expect&#x27; like 20 years ago... reply nulbyte 19 hours agoparentI was waiting for the article to mention why the author chose not to employ that option. Though the author mentions in passing that one solution is brittle because it requires parsing output, I don&#x27;t see why that&#x27;s a problem. It&#x27;s exactly what &#x27;expects was designed to do. reply Joel_Mckay 14 hours agorootparentexpect&#x2F;tcl offers many options, but does have some quirks with remote shells.What it does do well:1. can validate a key signature issue2. firewall port-knocking (extra http ports interleaved with instant ban ports)3. ssh over https setup4. IDS tripwire Morse-code knocking5. reverse-proxy configuration for trusted zone ingressThis approach helps solve several issues:i. distributed firewall probes or nuisance trafficii. brute force attempts or nuisance trafficiii. obscures security posture identification (what got an IP blacklisted might have occurred several minutes ago)Indeed, I alsoI ran about 30k machines with sshpass and it worked just fine. Easy to script. I don’t understand at all why we need something else here.Do you keep all your passwords in one directory or in something more complicated? reply latchkey 17 hours agorootparentnext [–]User: user Pass: 1Lol reply gossamer 15 hours agorootparentI kinda like the way ansible does it. There is a concept of a vault. You put all the passwords in that file and they are all encrypted. You use one password when running the command or playbook and all of the keys are decrypted as needed.I don&#x27;t know if that is efficient for 30K machines though. reply latchkey 13 hours agorootparentIt isnt. I ended up building a small golang binary that ran as root and I could hit it with http calls to execute whatever I wanted. Built a message queue that would work through all the machines for eventual consistency. Worked great. replyInetgate 7 hours agoprevIt&#x27;s interesting. So, I wonder the difference between this method and expect command? reply unixhero 13 hours agoprevGreat thread. Many insightful perspectives on AAA here reply linsomniac 20 hours agoprevI like the trick of setting the sticky bit to indicate that it&#x27;s taking a second kick at the can. reply mrstone78 13 hours agoprevI am looking into how to automate the totp authentication with SSH. Would an approach similar to this work? reply throwaway892238 13 hours agoprevWrapping SSH requires handling a lot of different exceptions. If you want to avoid bugs and errors, find someone else&#x27;s library for handling SSH that deals with things like host key prompts, changed fingerprints, filesystem permissions, connection errors and reconnects. If you&#x27;re running commands, some may need things like proper PTY handling. reply gg2424 18 hours agoprev [2 more] [flagged] Lvl999Noob 18 hours agoparent [–] Is this a chatgpt written summary? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explores non-interactive SSH password authentication and offers a Zsh wrapper for retrieving passwords from a password manager.",
      "It presents a method to make scp utilize the custom ssh function.",
      "The post highlights the benefits of using public keys instead of passwords and discusses the challenges associated with certificate-based authentication and more granular authorization methods."
    ],
    "commentSummary": [
      "The discussion explores different aspects of SSH password authentication, privileged access management systems, and authentication methods, such as Kerberos and its limitations.",
      "It also covers the implementation of FreeIPA for simplified setup, challenges with SSH key authentication and their solutions, and the use of SFTP, rsync, and sshpass for file transfer.",
      "Other topics include issues with shell scripts and APIs, decrypting SSH keys, concerns about storing passwords permanently, and managing passwords in large-scale environments."
    ],
    "points": 239,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1703508923
  },
  {
    "id": 38766178,
    "title": "Software update renders vehicle undrivable, owner advised to contact support",
    "originLink": "https://twitter.com/danluu/status/1739387245034139692",
    "originBody": "\"Unfortunately, a recent software update was not successful. Your vehicle cannot be driven. Please call customer support:\" pic.twitter.com/WE059pkfdK— Dan Luu (@danluu) December 25, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38766178",
    "commentBody": "A recent software update was not successful. Your vehicle cannot be drivenHacker NewspastloginA recent software update was not successful. Your vehicle cannot be driven (twitter.com/danluu) 235 points by lopkeny12ko 12 hours ago| hidepastfavorite148 comments linusg789 12 hours agohttps:&#x2F;&#x2F;nitter.net&#x2F;danluu&#x2F;status&#x2F;1739387245034139692 onetimeuse92304 11 hours agoprevSome 20 years ago I was asked to prepare OS distribution with OTA upgrade capability for some PoS system.I think I prepared two system partitions and a custom MBR which would alternate the system partition on every start (uses one bit of non-volatile memory to alternate selection of partitions on each boot).When the system starts, it does self-test. If it fails the self-test it just restarts. If it succeeds -- it writes the result on its partition and then looks at the other partition. If the other partition did not succeed the test, it reports the fact back to HQ and overwrites it with the current system.The upgrade procedure is extremely simple -- the current system writes to the other partition, then restarts. If the upgrade is interrupted at any point in time, the other system will know it was interrupted and will just restart immediately. In any case, after two restarts we are back to the system that initiated the upgrade and if it checks the other system did not start and self-tested successfully, it can redo the upgrade as many time as we want and you still have a working system.Could it be done better? Probably it could. It took me one day to think up and implement.I would think Ford could do it better (Edited: yes, not a Tesla) reply rollcat 10 hours agoparentA&#x2F;B boot is old, good, and proven, but what do you do when you have dozens of separate microcontrollers, each governing a semi-independent subsystem, all running their own software that needs its own updates? It would make sense from safety&#x2F;reliability PoV when a crash&#x2F;bug in a slightly less critical system (like adjusting mirrors) does not affect a slightly more critical system (like indicators). What do you do when updating only one of the components fails? Do you rollback everything? Do you continue with the rest?Just to be clear, I&#x27;m firmly in the \"less smart = more reliable\" camp, but even a SoC resembles a distributed system nowadays, and this architecture has its merits. The GPU on my M1 Mac crashed, rebooted itself, and all I saw was 1-2s of glitched graphics - no application noticed. Of course ideally GPUs wouldn&#x27;t crash, but the same could be said of cars. reply onetimeuse92304 10 hours agorootparentI don&#x27;t think \"more smart = less reliable\" is inevitable.The goal should be designing it in a way that failure of the more smart features does not spill to critical functionality. Or that you can use it in a degraded state sort of like fly by wire planes do.I have no car design experience, but here is my 5-minute idea:For starters, you build a basic car. It drives, it has basic indicators, it has ABS, etc. It has some APIs that can be connected to but there is limited ability to break the basic car through those APIs.Then you build your smart car around it by adding to the basic car. You add on more computers, electronics, etc. But any time you rip off the smart car functionality, you still have the basic car working.If there is a need to update software, this should really only be needed for the smart car part. But even if it fails completely, the basic car underneath should be functional and you should be able to use the car albeit without infotainment and navigation and other \"stuff\". You should be able to do whatever you need to do, call your mechanic and limp there to get them to sort the problem out for you. reply aendruk 5 hours agorootparentThis sounds like the concept of progressive enhancement. reply AlotOfReading 9 hours agorootparentprevThat&#x27;s not how vehicles are designed for many reasons. For one, there&#x27;s no option where critical components aren&#x27;t designed with updateability in mind. It&#x27;s simply a fact of life that code has bugs, and the only way to fix those bugs is updates. It&#x27;s valid to feel that that those updates should applied at a dealership where the system can be tested afterwards, but that has a lot of implications of its own. reply onetimeuse92304 9 hours agorootparentYou simply do not understand the point of extracting \"basic car\" from \"smart car\".The point isn&#x27;t that the software will have no bugs.The point is that the basic car will have much less software and much more basic software and that it is much easier to test and ensure this software is in working condition.Also, it is absolutely not true that the basic software has to be updateable. With care, basic functionality can absolutely be completely finished.Imagine you have been in the market with ABS controller for a decade or more. It has really simple functionality, it should be possible to just bake it and never touch it again. Or maybe a controller that takes care of basic battery protection. Or motor ESC. When the components are simple enough and well defined enough, it should be possible to \"finish\" the software to a state where it never again needs to be updated. Or updated only in exceptional circumstances. reply AlotOfReading 9 hours agorootparentI have a very deep appreciation for simpler automotive components. Please don&#x27;t take anything I&#x27;m saying as discounting those very real benefits.What I&#x27;m saying is that no practical amount of testing and verification can eliminate the need for updates. Let me give some practical examples I&#x27;ve seen: a bug in the silicon vendor BSP that prevented programs from accessing half of the physical memory. In another case the vendor provided optimistic battery curves that caused safety issues in certain conditions, so changes were needed after units were already in the field. In another case, a factory was taking the stuff we were giving them and using it to build weird Frankenstein images from various binary blobs, so nothing that had been produced for those weeks corresponded to anything that had been tested. reply shiroiuma 7 hours agorootparentCars have been built for decades without needing any updates at all. Microcontrollers were first put in cars in the 1970s, for fuel injection control, and later for ABS and SRS. No one ever got a software update for their ABS controller in the 1990s. They&#x27;ve been happily running non-updateable code for many decades now, and all of a sudden you think it&#x27;s normal to update embedded software? No, it really isn&#x27;t. If there was a real problem, there was a manufacturer recall and they replaced parts. reply ryandrake 7 hours agorootparentYes, this fatalistic \"all software inevitably has bugs\" attitude is corrosive and self-reinforcing. How about we replace it with \"the more complex the software, the faster it&#x27;s built, the more likely it will have bugs\". At least then, there&#x27;s a solution. Simplify. Slow down. Test. Remove software. Don&#x27;t use software when it&#x27;s not required.The current free-for-all where we must put complex software into everything is killing us. reply AlotOfReading 6 hours agorootparentprevThose systems had bugs like anything else, they were just never addressed if the customer didn&#x27;t bring their vehicle back to a dealership. Have you dealt with code from the 70s-90s before? The codebases I&#x27;ve worked with from that time period were rife with bugs and quality issues we wouldn&#x27;t consider remotely acceptable today. reply torstenvl 3 hours agorootparentI am struggling to understand what it is you&#x27;re trying to communicate. The original point is that it&#x27;s quite clear that motor vehicles can physically operate without software, and so therefore smart automotive systems should use graceful degradation in order to avoid situations such as in the OP.Are you disagreeing that a motor vehicle can operate without software? Or are you disagreeing that a vehicle should continue to operate when smart features are unavailable? replyintern4tional 9 hours agorootparentprevSo this is mostly a solved problem at other OEMs, and I do not know how Ford does it.I know that other OEMs do variant testing, have complex SILS (software in the loop) test systems so that all potential failure scenarios are tested in software prior to update. The downside is that updates are slow to release then, with some other OEMs only putting out an update once or twice a year, but they avoid this scenario.Software wise, the industry is moving towards defined standardized interfaces for sensors that are versioned. Example: https:&#x2F;&#x2F;blackberry.qnx.com&#x2F;en&#x2F;ultimate-guides&#x2F;software-defin...Back to the topic though, all major domain ECUs will have an A&#x2F;B partition. Usually one of these is the OTA master, and has the capability to update the other microcontrollers via UDS. For safety critical microcontrollers that do not have a A&#x2F;B partition, about half will not support OTA (this is just a thing for small MCUs), and the other half are flashable completely. So something like this is rare and should only happen on a secure boot failure or some other catastrophic scenario, which ideally your SILS system will have tested (SILS won&#x27;t test all scenarios but will definitely test all failure cases).Larger OEMs may even have HILS (hardware in the loop systems) where these things are also tested on physical hardware prior to launch, but with software defined vehicles this is slowly going away. reply blep-arsh 7 hours agorootparentprevRegarding M1 Macs: Apple bundles all the firmware with the OS and initializes every auxiliary core by uploading the corresponding firmware into its RAM on system boot (as far as I understand it). Not sure if that&#x27;s something that can be done with a car (e.g. what if a controller loses power physically and reboots from a clean slate?), but that&#x27;s one way of keeping firmware in sync with the OS release. reply Kirby64 11 hours agoparentprevThis is a Ford Mach-E, not a Tesla. reply znpy 11 hours agoparentprevMy router does that. It’s the wrt3200 and has two partitions and if it fails at booting three times in a row it will boot the old partition. I know because i have bricked and unbricked it this morning whole updating openwrt ^_^” reply jnwatson 11 hours agoparentprevThat is very much standard. reply onetimeuse92304 11 hours agorootparentI wouldn&#x27;t know what the standard is. This seems like something my kid could figure out. It is a shame that multi-billion dollar company that makes consumer products costing hundreds of thousands of dollars can&#x27;t. reply matt-attack 9 hours agorootparentprevYep TiVos did something similar reply otterley 12 hours agoprevIt’s a bit troubling that automakers (and, well, anyone who is building things that have mechanisms for software updates) aren’t making software updates failsafe. If you have multiple copies of the image on storage, and you take care not to touch the currently-running image, then a failed software update to the alternate image shouldn’t have any impact. Think of it like blue-green deployments on the cloud; and it’s what TiVo was doing with software updates to their DVRs all the way back in the late 1990s. reply variadix 12 hours agoparentMy router has dual firmware partitions, the fact a car doesn’t is inexcusable reply g_p 10 hours agorootparentAbsolutely. One fact I recall from many years ago (so I don&#x27;t know how true it is now) is that auto makers were shipping 7 year old silicon (and thus board support packages for their software). The guys working on chips and CPUs were writing software and it wouldn&#x27;t hit the road for 7 years.This was why infotainment systems lagged the state of the art for so long - they were apparently shipping components that would have belonged in a smartphone from more than half a decade before.In this case, I believe we had a few phones get A&#x2F;B updates by Android 7, which was late 2016. Giving it a year or so to filter to more CPU chipsets, that would mean (if the old rule held true), we would expect to see A&#x2F;B hitting new cars in the next year or two. This assumes auto makers are using enough of the Android BSP to get the bootloader with A&#x2F;B (which isn&#x27;t a given), and then that they use it!Anyone with any experience of auto software know if the teams doing software are experienced and understand the platform side of things, or if it&#x27;s a traditional front-end heavy \"crunch release\" type affair? I&#x27;ve seen some pretty poor quality infotainment systems in the past, so my assumption is inexperienced devs with limited platforms knowledge, focused on \"get it working to ship it\", but would be interesting to hear from anyone with experience of how this really goes down. reply KennyBlanken 11 hours agorootparentprevIt should be mandated, but corporations dominate legislation and regulations.\"You&#x27;ll drive up costs for the hard-working American consumer\"\"We&#x27;d have to cut salaries or fire factory workers\"\"We wouldn&#x27;t be able to compete against that car company from Nothereistan!\"etc. reply justsomehnguy 9 hours agorootparentprevIt was a great advantage, both in marketing and the real usage, when the motherboards started to support the Dual BIOS (GIGABYTE term, AFAIR). 2003 I think? reply cedws 12 hours agoparentprevThis is more commonly known as A&#x2F;B partitioning and as you say, is standard practice in embedded devices. It is indeed disturbing if automakers have not adopted this, nor a rollback mechanism. reply iknowstuff 12 hours agoparentprevTesla is. Failed updates are non-destructive, they also have an RTOS gateway isolating entertainment software from the software needed to drive the vehicle.https:&#x2F;&#x2F;www.pentestpartners.com&#x2F;security-blog&#x2F;reverse-engine...And this is their decade old architecture. If you watch some cybertruck videos you’ll see it is much more elegant now. reply KennyBlanken 11 hours agorootparentThis isn&#x27;t a tesla-specific thing or even something they innovated. The earliest cars with data networks had this.It&#x27;s also not something Tesla does better; numerous security researchers have bypassed that gateway.Since you bring up Tesla: used to be that Tesla control units would fail after a certain number of drive time hours because they did so much logging to the flash chips they&#x27;d wear them out.In a vehicle which is highly connected and basically should never lose power most of its life, they were writing logs to flash memory. Anyone who has done embedded work can tell you how stupid an idea that is. reply xw3089 11 hours agorootparentYes, that happened to my car. But one could still drive their car after the failure and there was a free recall.https:&#x2F;&#x2F;www.tesla.com&#x2F;support&#x2F;8gb-emmc-recall-frequently-ask... reply rpmisms 12 hours agorootparentprevTesla is very very good at software engineering. They still need to find the balance in their software and process engineering, though. reply ahahahahah 1 hour agorootparentYeah, they have some truly breathtaking software controlling the automatic wipers. It&#x27;s like a true ai, probably competitive with a 6 month or so old child. The automatic high beams are up there with the pinnacle of software engineering as well. reply stefan_ 11 hours agorootparentprevYou are talking about the company that wrote logs to the fully read-write filesystem of their infotainment system and killed the EMMC from raw flash cycles within as few as 2 years. Recalled 10 years later. reply rpmisms 11 hours agorootparentYes, this happened to me, although it took 10 years. Free replacement, and the car still worked fine. reply FirmwareBurner 11 hours agorootparentIt&#x27;s still a major embedded engineering oversight on their part. We had fallback developed for such cases in $5 embedded devices.Calling out Tesla as a model for excellent software is insulting to SW that&#x27;s actually quality.What Tesla SW has and others lack, is a great \"wow\" factor, which consumers who don&#x27;t get to see how the sausage is made, mistakenly associate with &#x27;quality&#x27; because it behaves like their iPad, but don&#x27;t know all the skeletons in that closet. reply rpmisms 10 hours agorootparentYeah, it&#x27;s also a mistake they made 10 years ago.Tesla is very good at automotive software engineering. reply FirmwareBurner 9 hours agorootparent>Yeah, it&#x27;s also a mistake they made 10 years ago.You&#x27;re making it sound like that mistake was an \"I spilled my coffee on you boo-boo\" and not a terrible engineering decision that should not have passed anyone with actual experience in the embedded industry, let alone a team. If this is the kind of engineering oversights that ends up in Tesla SW, only God knows what else they have lurking in there that hasn&#x27;t yet reared its ugly head.>Tesla is very good at automotive software engineering.Citation needed. Repeating something doesn&#x27;t make it true. replyamelius 11 hours agoparentprevWe should have a law for this. In most countries, new vehicles need to be tested by govt agencies before they are allowed to hit the road. The same should hold after software updates.Ideally, the update should be done by independent agencies, so they can make sure the software is tested and they can properly inform the user (something which we already know companies don&#x27;t always do).The way it is now, it is all too easy for a company to decide to push a quick fix for a problem that really needs a more careful approach (but which might cost the company money). reply andsoitis 11 hours agorootparentYou want an agency to validate every single software updates to vehicles? reply norir 10 hours agorootparentI actually think this isn&#x27;t a bad idea. I really don&#x27;t want an automaker treating consumer updates like a developer repeatedly pushing nearly empty commits to github to get ci green. reply Klonoar 10 hours agorootparentprevAt the very least, if it touches anything that impacts the driving… maybe?It’s a 3 ton (+) machine with people paying attention less each passing day. It should be taken very seriously. reply andsoitis 7 hours agorootparentA scalable way, and which I believe is in place, is having rules and then periodic audits validates that the controls and processes provide a high degree of assurance of compliance with the rules and regulations.This seems far better than having an agency ad hoc review every single specific software update to vehicles - would people at the agency review the code? Do they write automation? Do they do manual verification? reply amelius 11 hours agorootparentprevAt the very least, I want the agency to keep a hold on the update for $N days.That way, I am more convinced that the software engineers of the car manufacturer won&#x27;t push any quick fixes that might cause bigger problems later.In the case of urgent problems, the correct response is to ground the fleet. This will cost the manufacturer money, but I&#x27;m a software engineer for long enough to know that a quick fix won&#x27;t be a safer solution. reply throwaway2037 3 hours agorootparent> At the very least, I want the agency to keep a hold on the update for $N days.What is the difference between this and \"No Deploy Fridays\"? reply superkuh 11 hours agoparentprevAnyone on the &#x27;net back in the 1990s will remember the image macro, email forwards, and usenet posts about \"If cars were made by software companies\". It looks like they&#x27;re finally coming true. reply soganess 10 hours agorootparentExcept the price part. We have an inverse Miley Cyrus situation on our hands. reply j45 12 hours agoparentprevIt&#x27;s really interesting that updates can&#x27;t revert, or enable some limp mode, or disable the offending functionality. reply stefan_ 12 hours agoparentprevI&#x27;m sure the infotainment system does, but that is not all that is being updated; you have many more processors in ECU, assistance systems and so on that are also sometimes getting fed new firmware over various wonky buses as part of an upgrade. In some instances there might even be multiple levels involved in the firmware distribution. reply yjftsjthsd-h 11 hours agorootparentSo? Everything that can update firmware should do the same thing. reply stefan_ 11 hours agorootparentAnd then what? A&#x2F;B update isn&#x27;t magic dust, if some sub component ends up with an incompatible firmware because it had to boot to the alternate partition, you might still have an incompatible overall system.(Not like the subsubsupplier of that module even specced the extra flash memory for A&#x2F;B update, hah) reply mistercheph 9 hours agorootparentRetain the known good firmware for each controller on master disk A, if the update fails, reflash all components. reply gpderetta 10 hours agorootparentprevThe real question is why would they be doing OTA upgrades of such critical systems. reply sillysaurusx 11 hours agoprevI see a lot of people asking \"How could this possibly happen?\" It turns out that there&#x27;s a common failure mode that makes it past almost every unit test suite: a lack of disk space.Running out of disk space pops up time and again. I&#x27;ve often wondered why software fails so often in this situation. But it&#x27;s because the basic components of the system start to break -- things like \"Call with temporary file\" stop working, because creating a tempfile fails. And usually you&#x27;re writing that code precisely in a spot where it assumes it can&#x27;t fail.This just happened on my PS5. I thought I&#x27;d play a bit of Armored Core 6 over Christmas, so I sat down and was greeted by \"Can&#x27;t start game.\" There was a pending update which couldn&#x27;t be installed. So I skipped update; same error. But now the update was skipped, so it wouldn&#x27;t even try to reinstall it. I ended up having to reinstall the whole game. Never seen a PS5 game completely brick itself like that.Disk space woes are also one of the primary reasons websites go down. Ever forget about a server for two years and suddenly see your service break? It&#x27;s almost always because the process ran out of file handles (resource leak) or because it ran out of disk space (hello imagemagick tempfiles).Of course, the bug here could be completely different, but disk space errors are so common that it&#x27;s as good a guess as any. Computers don&#x27;t do well when you&#x27;re out of disk space. MacOS freezes and bluescreens instead of going to sleep, because it can&#x27;t save the hibernation file to disk. PS5 media recording stops working, because the hour-long recording backlog no longer has room to write the video to disk. This software update obviously passed their unit tests, but failed in this particular case; disk space is one of the few variables that they probably didn&#x27;t test for.I wish it were easier to write unit tests for all possible out-of-space situations. There are just so many. Even if it technically doesn&#x27;t break, it often craps up the experience so much that the user ends up wondering why the software is so bad. reply qingcharles 11 hours agoparentI had a rock solid app that I wrote die on me yesterday because it tried to access a folder and Windows returned \"Drive is corrupt,\" which of course I hadn&#x27;t handled because that will never happen.Out of drive space is the worst, though. Like you say, most things don&#x27;t handle it, they just plough headlong into an install and then die, leaving the whole drive in a horrible unknown mess of files where you might or might not be able to retry the operation, and you might or might not have used up the last few bytes on the drive and now for some reason when you try to reboot it can&#x27;t even boot the system up because it can&#x27;t write some temp file it needs. reply Szpadel 10 hours agoparentprevBtrfs have (had?) interesting failure mode for this scenario, because this is Copy On Write file system it need to allocate new block to modify metadata, when you are out of space, you cannot do that anymore. You might end up in scenario where your filesystem is full but you cannot delete anything because this required allocating new metadata block and your drive is full reply somerandomqaguy 10 hours agoparentprevCould also be out of memory errors which are also tricky. Linux&#x27;s OoM killer just picks something at random and terminates it. If you&#x27;re lucky is something your app doesn&#x27;t need but if you&#x27;re unlucky and you&#x27;re not paying close attention to syslogs, you&#x27;re in for a fun time trying to figure out why your app just stopped for no logged reason. reply mikewarot 11 hours agoprevBack in the 1980s I was in the room with a customer who I had written an inspection system for, using a hand-held computer. After downloading the data from the handheld, it would upload a new inspection route.While demoing the transfer, He asked \"What happens if I disconnect this right now?\".... I didn&#x27;t know, and said so.I week later it was bulletproof... you could unplug it any time you wanted, and never lose data.That was the days of MS-DOS.So, here we are, 30+ years later, and computers are nowhere near as constrained as they were back then.I don&#x27;t understand how Ford could even allow a screen like that to exist. It&#x27;s a big red flag saying \"Never buy a Ford again, they&#x27;re unreliable\" reply 7thaccount 11 hours agoparentAs someone who has been considering an EV, I&#x27;m noping out pretty hard right now and thinking about buying an old and reliable Honda Accord. A few more of these posts and I&#x27;ll be driving a Volkswagen bug with a garage full of spare parts ;) reply olyjohn 5 hours agorootparentIt&#x27;s not an EV thing. All this same tech is moving into ICE cars too. I know someone with a Genesis GV80 that just randomly threw itself into limp mode and wouldnt go over 20mph. Genesis support gave him the magic button combination to reboot the onboard computers and the car was totally fine. This car has all the same tech as any EV. It gets updates. Has all the sensors, screens, safety tech, advanced cruise (he says it drives itself)... Hell even my mom&#x27;s Subaru Outback has all this same tech, an onboard modem, updates, etc. reply neon_electro 7 hours agorootparentprevThere are EVs without this problem. reply solarkraft 5 hours agorootparentWhich? reply tap-snap-or-nap 12 hours agoprevEvery passing news cycle, I am getting more and more reasons to repair and stick with my current vehicle. Perhaps I would be better off paying a mechanic to teach me how to do the basic maintenance and repairs. reply afn 12 hours agoparentCan’t recommend highly enough: https:&#x2F;&#x2F;www.howacarworks.com&#x2F; reply j45 12 hours agoparentprevProblems can be found just as easily with the wrong year and make of any ICE vehicle. In those vehicles, software updates are generally only done by a mechanic, sometimes loaded from a cd or DVD loaded into the car&#x27;s stereo. reply eastof 11 hours agorootparentExcept it&#x27;s not going to ever leave your car inoperable... reply j45 7 hours agorootparentProbably, although I don’t think I’ve ever looked nor would the media have a reason to.EVs get attention as disruptors reply cs702 11 hours agoprevVery lame.My immediate question upon seeing the headline was: Which EV brand are we talking about? Evidently it&#x27;s not Tesla, because if it had been, the headline would have mentioned it, no doubt. It&#x27;s a Ford, in case you&#x27;re wondering. Shame on Ford!Ford and all other automakers are learning the old-fashioned way that making truly great user-facing software is... harder, slower, and costlier than they expected. reply ProjectArcturis 10 hours agoparentFord makes bad cars in general, so why would we expect them to make decent UI, let alone truly great? reply pharrington 12 hours agoprevDoes anyone have an original source for this? The picture is reposted from a different social media influencer&#x27;s tweet https:&#x2F;&#x2F;twitter.com&#x2F;githii&#x2F;status&#x2F;1738289618921951296, but with less compression artifacts and without that influencer&#x27;s story. reply sp332 12 hours agoparentIt&#x27;s not the same photo, but here&#x27;s one with the same error from from July. https:&#x2F;&#x2F;www.f150lightningforum.com&#x2F;forum&#x2F;threads&#x2F;priority-up... (about halfway down) reply throwaway2037 3 hours agoprevDoes the owner get compensation for this bug? For example, if you need a rent a car for the day, will Ford reimburse the cost? If no, can you sue in small claims court? reply DrawTR 12 hours agoprevsaying \"for the tow truck operator\" is horrifying language to put in a &#x27;your car is bricked&#x27; spot reply fmajid 11 hours agoprevFor decades software engineers have moaned “why can’t software engineering be a real engineering discipline like civil engineering”. The travails of the legacy car makers, compared to Tesla or Rivian, show conclusively mechanical engineering is easier. reply Retr0id 11 hours agoparentOr maybe there&#x27;s just a stronger regulatory environment around mechanical engineering. If you sell cars whose fronts fall off, you&#x27;re going to get in trouble. If your software updates fail, your users are mostly limited to complaining at you on twitter. reply rightbyte 11 hours agoparentprevMechanical engineer is in no way easier. However, it is easier for a better mechanical engineer to spot issues in your design just by eying it, whereas software is for all practical purposes a black box unless you spend 100s of hours reading the code. reply est31 11 hours agoparentprevYou take a software engineer&#x27;s point of view. The people who build cars, especially at established car companies are mechanical engineers however. And they design consumer technology, they don&#x27;t design military vehicles or ambulances, so their main goal is not reliability, never has been.Cars have constantly gotten harder to repair, more brittle, and if a repair is needed, you often have to, instead of being able to swap out a $5 component, replace larger components that the $5 component is part of. This is by design as replacement parts is a high margin revenue source for the car manufacturers.Why should the software side of things be any different? reply lispisok 6 hours agoparentprevI&#x27;ve done both. Software engineering is way easier. In traditional engineering you dont have \"move fast and break things\" and if you get sloppy with edge cases at best it could cost $$$ at worst people die.Cars have had computers controlling them for decades and didnt have these problems. What&#x27;s happening now is auto makers are adopting the silicon valley way of doing things which worked ok for webapps but is horrible for hard goods. reply analog31 11 hours agoparentprev>>> why can’t software engineering be a real engineering discipline like civil engineeringProgramming pays better than civil engineering or mechanical engineering.The software team pays better than the hardware team, and programming in support of hardware pays like hardware. When asked why, the answer is: \"Software is more valuable because it&#x27;s closer to revenue.\" And: \"Software has no cost after it has been written once.\" No manger or engineer can explain what this phrase means, but it&#x27;s taken as conventional wisdom. reply FullyFunctional 3 hours agoprevThe same thing happened to our Tesla Model X a few years back. Tesla even wanted us to pay $200 flat fee to fix the problem they created and that we couldn’t opt out off. I may have used impolite language until they waived that. And that’s not even addressing the massive time sink it was. reply rpmisms 12 hours agoprevMy Tesla had an update fail, and it didn&#x27;t break anything, I just got a new update package the next day.I also replaced my own headlight and had to run a software update to initialize the new part. I called a service center and had a software update in less than an hour. Try that at Audi. reply alphabettsy 11 hours agoparentAn Audi doesn’t need a software update to replace a light from my experience.Also, my experience with Audi and BMW are that community tools exists to let you flash modules and change settings all on your own. Try that on a Tesla.Tesla is way ahead on software imo, but I don’t want my car to be like modern smartphones where they’re dependent on the manufacturer to maintain and keep working. reply smsm42 10 hours agoparentprevI replaced two of my lights in my car and I had to re-adjust the carpet piece that covers it. That&#x27;s all I had to do, no software updates, no service centers, nothing.Are we going in the future to have to call a service center for a software update when we replace a floor mat or a windshield wiper? reply neither_color 11 hours agoparentprevBack when it was in news cycles that Tesla&#x27;s stock couldn&#x27;t possibly be worth more than legacy automakers&#x27; because it was only a matter of time until they came for Tesla&#x27;s lunch, I couldn&#x27;t imagine they&#x27;d fumble it this badly. reply inferiorhuman 10 hours agorootparentLord knows Tesla&#x27;s never had any problems with updates before…https:&#x2F;&#x2F;teslamotorsclub.com&#x2F;tmc&#x2F;threads&#x2F;my-car-is-bricked-by...https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;TeslaLounge&#x2F;comments&#x2F;112oqln&#x2F;new_te...https:&#x2F;&#x2F;teslamotorsclub.com&#x2F;tmc&#x2F;threads&#x2F;failed-software-upda...https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;TeslaLounge&#x2F;comments&#x2F;qt0ekf&#x2F;2021_mo... reply iknowstuff 12 hours agoparentprevTesla knows what it’s doing. Not these guys. reply gumballindie 11 hours agorootparentThey know so well that there was a report yesterday showing how tesla’s a low quality vehicle. Behind the dacia. reply rpmisms 12 hours agorootparentprevThat&#x27;s the point I&#x27;m making. Fail-safe and good testing. reply j45 12 hours agoparentprevThis is the way.Also the scrutiny Tesla has received at the start of it&#x27;s operations might be quite a bit more than the other makers.I&#x27;m hearing Kia&#x2F;Hyundai&#x27;s needing a replacement battery are having to wait months if not up to a year, while new ones sell away.Buying a used EV will become like buying a used ICE car - there are ways to do it well, and ignoring either is at your peril... and no guarantee a brand new one will be reliable, nor the warranty performant when needed. reply rabbits_2002 11 hours agoprevDo car companies outsource their software to fiverr or something? Every single car I rent lately is a buggy piece of shit. reply fragmede 10 hours agoparentUgh. I rented a Ford Explorer recently, and somehow they managed to screw up Applr Carplay. I&#x27;m in a place I don&#x27;t know very well, navigating using Apple Maps via Carplay, and my GPS location goes for a wander. Just wanders off so that the navigation gets way confused trying to route me to my designation, because the current location is miles and miles off from where we are. So I unplug my phone and suddenly my GPS location is back to the correct location. HowTF did that even happen? reply emeril 9 hours agorootparentcarplay just seems like crap on all cars I&#x27;ve used (including the new subaru I own)I don&#x27;t even try it anymore and just bring a vanilla charger and pipe audio to the car via bluetooth (which generally works without issue on every car I&#x27;ve tried) and the phone for actual navigation reply fragmede 8 hours agorootparentlol even that was broken on the rental Ford Explorer - audio from Siri and music worked, so I know the Bluetooth connection was fine, but the GPS navigation audio didn&#x27;t speak. reply prakashn27 6 hours agoprevSoftware and hardware are prone to bugs , but that should not hinder its ability to perform the core operation (driving) of the product unless something major (brake failure) is detected. reply Szpadel 10 hours agoprevLet me try to play devil&#x27;s advocate.This screen is actually result of alternative boot in dual boot image, but it&#x27;s not A&#x2F;B system but system&#x2F;recovery.This is valid solution when there is not enough space to fit second full os in available storage. Recovery allows for repeating update of major system.Another potential issue is that car is composed of multiple connected systems and one \"main\" computer, it will try to upgrade everything else to the one expected version that was tested with this release. Something failed in secondary module that does not support a&#x2F;b systems (3rd party?)Another possibility, update is composed of update and verification of secondary modules and verification is not passing, because update is passing there is not really good way to recover now, because maybe flash is now damaged.edit: usually all components in car communicate using canbus (including software updates) this usually works in this way: You first switch device into flashing mode by sending speciall command, it will then jump to special mini application that will write new bytes to flash and finally you finalize to reboot. In case something in flashing went wrong and device is crash looping or stuck in infinite loop or in any other way is not able to finish boot, you cannot retry anymore because there is no way to put it again into flash mode as its not able to receive canbus messages anymore. If that is critical component the safest thing to do is prevent car from driving reply lifestyleguru 12 hours agoprevHow could they waste the opportunity of undivided driver attention not to display any ads?! Show them nearest Starbucks where they can relax, or Lidl where they can buy some Coke. C&#x27;mon automotive, hammer in the final nail to your coffin. reply from-nibly 10 hours agoprevWell I think 90s Honda&#x27;s are gonna start going up in value. reply wyclif 4 hours agoparentAs a huge fan of &#x27;90&#x27;s Hondas, I agree. reply yieldcrv 12 hours agoprevI can hear the dejected software engineer that wrote or plugged in that error message after layers of bureaucracy reply lifestyleguru 12 hours agoparentNot at all. Dejection and uncooperativeness render one a bad team player. The recruitment pipelines aggressively screen against these. Software engineers rarely care or have authority to be ethical gatekeepers. reply yieldcrv 11 hours agorootparentI’m pretty good at hiding it tbh reply pengaru 2 hours agoprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sturgeons_law reply chillingeffect 10 hours agoprevFwiw there are dozens or perhaps 100s of microcontrollers on cars, usually sharing a small number of comms networks. Not all have the luxury of flash space for dual-boot. It&#x27;s possible an error on one can affect a large number of others. It should be better, but it&#x27;s more complex than a single firmware image. reply tibbydudeza 11 hours agoprevBricking a device like a car is not on , even my router and PC has a recovery option if a firmware update goes south.Don&#x27;t they know about A and B images ???.They cheaped out to ensure their flash memory is adequate for restoring from a bad update. reply mensetmanusman 10 hours agoprevSoftware ate the world. reply anothernewdude 12 hours agoprevWhat brand of car? So I know what to avoid? reply _trampeltier 12 hours agoparentIn the centre over the phone number is \"Ford Customer Relationship Center\". So I guess it&#x27;s a Ford. reply jofla_net 12 hours agoparentprevFound On Road Deactivated reply exmicrosoldier 12 hours agoparentprevIt is a Ford. Either an f150 lightning or a mustang mach e. reply jpollock 11 hours agorootparenthttps:&#x2F;&#x2F;cars.usnews.com&#x2F;cars-trucks&#x2F;ford&#x2F;mustang-mach-e&#x2F;phot...Looks like the Mach-E reply Rebelgecko 12 hours agoparentprevLooks like the Ford Mach E screen reply shreyansh_k 12 hours agoparentprevFord reply rsstack 12 hours agoparentprevScreenshot says Ford. reply bastard_op 12 hours agoparentprevI&#x27;m sure it&#x27;s the Chevy Blazer, or at least same problem as. https:&#x2F;&#x2F;www.thedrive.com&#x2F;news&#x2F;the-chevy-blazer-ev-launch-has... reply djhope99 12 hours agoprevFORD- fix or return daily ? reply bilsbie 12 hours agoprevI wish someone would make a truly dumb car. Sure you can have microcontrollers for emissions, safety, etc but beyond that give me a 1970s user interface and make the car as independent of technology as possible. reply markx2 12 hours agoparentMy eldest daughter knows her way around cars, and she refuses to buy any car that has any sort of computer in it.She knows how to change this, repair that, fit whatever and is very happy doing that. But she also knows that as a female if she goes into any garage for a &#x27;diagnostic&#x27; she will be overcharged. In fact even for something normal with a &#x27;non-computer&#x27; car she will be overcharged.Cars without computers are like gold. reply trentgreene 12 hours agorootparentAs a fellow “analog” automotive enthusiast, I’m curious how she defines computer in this situation?Given that ECUs &#x2F; microprocessors have been standard on cars since the late 60s &#x2F; early 70s.For me it’s the network connections and updates that scare me. The software on my ‘99 Benz hasn’t changed in 24 years, and I don’t need it too. reply trentgreene 12 hours agorootparentI’ll add a small point to this. The computers my old cars do have, I’m quite thankful for. Being able to purchase a ~100-200 buck code reader and easily plug it in and figure out what my warning lights are trying to tell me has been a great educational tool and saved me a ton in maintenance. reply mistercheph 9 hours agorootparentAdvanced software can be used for good. It&#x27;s sad that the same advanced systems that can perform extremely accurate self-diagnostics that empower even the most amateur mechanic to do their own work on extremely complex ICE setups for years and years will also be the component most likely to render the vehicle a 6000-lb brick made of animal skin and rare earth metals reply userbinator 11 hours agorootparentprevI suspect she may be referring to the stereotypical carbureted V8 + manual &#x2F; hydraulic auto combination that&#x27;s still highly popular amongst US enthusiasts, which certainly has no ECU at all.Microprocessors didn&#x27;t exist until the early 70s. Late 70s &#x2F; early 80s is when they started becoming common in cars. reply trentgreene 11 hours agorootparentHeh, thanks for the info, I have a bit of a gap of knowledge about that era of vehicles outside of a type II fun experience with an older Ranchero.I see VW advertising a car with an ECU in 1968, but likely just transistors. reply heywhatupboys 12 hours agorootparentprevany car builtin the last 100 years have electrical components. Any car built in the last 50 have \"computers\". reply inportb 10 hours agorootparentEven the camshaft-crankshaft system could be considered an analog computer that renders (in realtime) the positions of the valves based on the phase of the pistons. Any car with an internal combustion engine has \"computers.\" reply thot_experiment 12 hours agoparentprev100% this, an electric car could be so reliable and simple to work on and repair if we wanted it to be. reply pyaamb 12 hours agoparentprevAbsolutely this. Been hoping that this will become a cool trend someday. Perhaps when teen-age Gen-Alpha or Gen-Beta kids seek to differentiate themselves from their Algorithm-controlled over-sharing IG&#x2F;Tiktok parents. reply Avshalom 11 hours agoparentprevI know motorcycles are basically just an occasionally-useful game of russian roulette but every fucking automotive news cycle has me thinking about how they&#x27;re basically the only way to buy just a motor and some wheels anymore. reply sam_lowry_ 11 hours agorootparentYou&#x27;d better check twice. Some had dial-out networking for years, like BMW. reply Avshalom 11 hours agorootparentoh, well, shit, there goes the g310gs I had being eyeing for noodling around the state. reply shwouchk 12 hours agoparentprevNissan Versa. It’s also one of the cheapest cars available.Enjoy reply poulpy123 11 hours agoparentprevMy 2012 Dacia Sandero is as dumb as you can be nowadays I think. reply whstl 8 hours agorootparentGreat news! [1][1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=A7-7Ps8EWnk reply josephcsible 12 hours agoparentprevhttps:&#x2F;&#x2F;bollingermotors.com&#x2F;b1-b2&#x2F; reply KennyBlanken 11 hours agoparentprevIt would not be economically feasible to build. CANBUS has revolutionized cars; now cars look more like a human body, with power and data being distributed to major points and then branching out. Before, everything ran from the fusebox. That meant a LOT of wiring, among other things. Copper is expensive and heavy. Car makers had a lot of incentive to save weight and cost so the wiring was as thin as they could get away with, so stuff never worked quite right.It would be dangerous, because various driver warning systems and such would not be possible. System that are having a significant impact on per-mile safety for vehicle occupants (road safety for vulnerable road users has plunged.)It would not be economically viable to operate, because engines are efficient as they are thanks to things like variable valve timing, direct injection, and so on. Some ECUs can sense how good the combustion was on a particular firing cycle via resistance across the spark plug after the ignition event. None of that would be possible with a \"dumb\" car.It would also not be economically feasible to repair, because the diagnostic time would be crazy. Trying to diagnose \"dumb\" cars from the 80&#x27;s and 90&#x27;s was a nightmare. You could spend hours just trying to figure out what was wrong in a maze of wiring, relays, resistive packs, analog sensors, vacuum lines, etc. Dealerships are staffed by low-level techs, people on their way to something else or starting their own shop. Car companies couldn&#x27;t possibly train them on all the intricacies of analog \"dumb\" car technology anymore.Now? I plug in a OBD2 wireless module, tap \"scan\" on my phone, drink a cup of tea while it systematically talks to every module in the car, and I not only get fault codes, they&#x27;ve likely got time and mileage stamps, an indication of whether they were intermittent or continuous.I can trigger a test on a component.I can see what the ECU or body control module THINKS is going on versus what&#x27;s actually going on.I can tell the body control module to adapt to a new analog sensor.all without needing to so much as pop the hood, remove a single screw, or upholstery clip.It&#x27;s a fucking dream.The shittiness in \"smart\" cars is because legislation in the US hasn&#x27;t kept pace with technology, and that is because legislation and regulation in the US is dominated by corporate interests. reply clumsysmurf 12 hours agoparentprevThat&#x27;s why I have kept my &#x27;97 dodge dakota all this time... Like you said, dumb, but also using standard components like headlamp bulbs for repair-ability. reply thot_experiment 12 hours agoprev [–] I know there&#x27;s no market for people like me, but I would never buy an internet connected car. It just seems so fucking insane to me that people are willing to accept relying on something that can be bricked remotely. Same goes for any sort of involuntary OTA updates to anything, and software as a service in general. The thing that matters to me is that my tools still work tomorrow when I need them to, and if they break it&#x27;d better be my fucking fault. We live in fucking clown world. Thank god you can still perma disable windows update, having a cell phone that breaks itself every few months is bad enough. reply blueridge 12 hours agoparentYou&#x27;ll enjoy this, should start right where he talks about his experience buying a car:https:&#x2F;&#x2F;youtu.be&#x2F;hlrv7DIHllE?t=1203 reply JCharante 12 hours agoparentprevI&#x27;m fine with having both. A dumb ICE car for emergencies and an electric car with bells and whistles for daily use reply ajross 12 hours agoparentprev [–] You&#x27;ll change your mind the first time you turn on the heat from across the parking lot while sipping coffee in the ski lodge, or need to check the charge status while eating lunch, or point stuff out on the satellite imagery on the live map.I know it&#x27;s easy to imagine that the product you think is \"a car\" is finished, but product categories evolve. People want their devices to do different things today than they did 20 years ago, and next year will be more changes. Connectivity isn&#x27;t going away, the market has spoken. reply whstl 12 hours agorootparentAll this is possible without integrating the software into the vehicle itself, making it brickable.Reliability and repairability going down is not \"evolution\" in any sense.And the market hasn&#x27;t really said anything when those things have been pushed into consumers without much choice. Saying \"the market has spoken\" in this case is like saying the market has spoken when someone claims that slapping a fruit logo is enough to sell computers. Turns out the choice of which car to buy is non-binary, it&#x27;s not \"internet connected\" vs \"non internet connected\". reply hgomersall 12 hours agorootparentI feel it&#x27;s not completely impossible to design a system that is properly partitioned, such that an update failure to the seat heating software doesn&#x27;t brick the car. Updates to core systems should be rare in the extreme. reply benj111 12 hours agorootparentI would say part of the problem is that they want the option of updating seat heating software, rather than actually properly testing the up and down buttons and the thermostat. reply iknowstuff 12 hours agorootparentprevTesla does it well with their real time gateway mechanism isolating entertainment software from crucial vehicle driving software. reply ajross 12 hours agorootparentprev> All this is possible without integrating the software into the vehicle itself, making it brickable.Sure. And Ford messed up. But the request upthread wasn&#x27;t for a vehicle with robust software update semantics, it was for a vehicle without connectivity. That&#x27;s not going to sell well. reply g-b-r 12 hours agorootparentprevSure, it&#x27;s the market that has spoken..https:&#x2F;&#x2F;foundation.mozilla.org&#x2F;en&#x2F;blog&#x2F;privacy-nightmare-on-... reply thot_experiment 11 hours agorootparentprevMy car does this and more, so perhaps I chose my words unwisely. (I live in a van I have pretty much full remote control of save actual driving, I&#x27;m out right now and I just turned on my espresso machine so it&#x27;s preheated when I get home). I don&#x27;t mind connectivity, I mind having to trust other idiots, I&#x27;m happy to trust this idiot. I want to be able to approve every change. It&#x27;s MY car.I want to have the final say about what happens with the things I own. I want to be able to rely on them. reply benj111 12 hours agorootparentprev [–] >the market has spoken.In the sense that a market is made up of buyers and sellers, and the sellers have decided to offer no other option yes.I think the issue is more of the design and ownership of these things. No one wants an update bricking their car. I doubt a lot of people here would object to a discrete subsystem where you could poll charge status, turn on heating etc. reply beau_g 11 hours agorootparent [–] You can buy many vehicles today dating all the way back to the turn of the last century. Here&#x27;s some listings for steam cars if you insist on no electronics whatsoever https:&#x2F;&#x2F;www.steamcarnetwork.com&#x2F;for-saleWhatever your line is in the sand for tech integration, you have many great options from before that point. reply whstl 8 hours agorootparentThis answer is like Microsoft saying the 1990s that \"abacus exist, so we&#x27;re not really a monopoly\".People want modern cars, modern TVs and modern computers. They don&#x27;t want a steam engine. But modern doesn&#x27;t mean \"crap that the manufacturer can brick remotely\". reply benj111 10 hours agorootparentprev [–] Except you&#x27;re proposing a false dichotomy of no tech, and complete tech integration.Would you also propose a calculator as a valid alternative to a locked down tablet&#x2F;phone&#x2F;pc that you can&#x27;t install your own software on? reply beau_g 10 hours agorootparent [–] I don&#x27;t understand where you are trying to go with this - steam cars have the same primary feature as any other vehicle - longitudinal and lateral control to traverse asphalt bands across the country. They can be retrofitted with any modern convenience feature as that stuff does not need to be integrated into the propulsion system. The same can be said of any other vehicle made between then and now. Of course, nobody has retrofit an early 1900s vehicle with 12 impact sensors and multistage airbags, and no modern manufacturer has offered a steam powerplant, because nobody actually wants this. Products are sold on features, not principles. In the US, you can (and people do) build just about anything and drive it legally on the road, so if not a single person has created (whatever it is several people in this thread think should exist), it would be preposterous to think a manufacturer would do it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A vehicle's software update has failed, causing the vehicle to be unusable.",
      "The owner is urged to reach out to customer support for assistance.",
      "The post does not provide any further details regarding the specific issue or how it can be resolved."
    ],
    "commentSummary": [
      "The discussion highlighted the importance of software updates and integration in vehicles, particularly for enhancing smart car functionalities.",
      "Challenges in updating multiple components and the need for failsafe mechanisms were identified as key concerns.",
      "Tesla's software engineering, the need for stricter regulations, concerns about software reliability, and the demand for internet connectivity in vehicles were also discussed."
    ],
    "points": 235,
    "commentCount": 148,
    "retryCount": 0,
    "time": 1703538836
  },
  {
    "id": 38762065,
    "title": "Inflight WiFi glitch caused by crowded network with 55 connected devices",
    "originLink": "https://twitter.com/erratarob/status/1739132876732674539?s=46&t=FFxXRm_qmWG4nJwsccRUbA",
    "originBody": "Inflight wifi didn&#39;t work so of course I had to debug it. It appears the problem is lack of DHCP lease. The WiFi was using 8 hour leases, which was time enough for many planeloads of passengers to embark/disembark.A quick ARP scan at the time showed there were 55 devices on the… pic.twitter.com/f1HRsZ4sy4— Robᵉʳᵗ Graham 𝕏 (@ErrataRob) December 25, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38762065",
    "commentBody": "I told the flight attendant \"the WiFi isn&#x27;t working\"Hacker NewspastloginI told the flight attendant \"the WiFi isn&#x27;t working\" (twitter.com/erratarob) 221 points by jonathanzufi 21 hours ago| hidepastfavorite155 comments linsomniac 20 hours agoThis reminds me of a conference, attendees were having sporadic problems with accessing the Internet and eventually I was able to capture a trace of the problem: when the main lease network filled up, it started allocating IPs from another block, but with the same gateway. I got a lease for something like 10.1.1.69&#x2F;24 with a gateway address of 192.168.1.1.I went to the support person and she offered to reset the WiFi, but I explained that she needed to escalate it because it was a configuration problem, resetting it was only a temporary solution.(edit: PyCon 2006 IIRC, DFW) reply jdthedisciple 19 hours agoparentAnd? Did she escalate it and was it solved?Don&#x27;t keep us hanging! reply midasuni 19 hours agorootparentAlmost certainly no. Unlike the assertion made, she didn’t need to escalate it. reply nulbyte 19 hours agorootparentWhy didn&#x27;t she need to escalate it?I can imagine the hospitality industry would not want the WiFi sporadically going down for their guests; that&#x27;s not a very hospitable experience. reply gumby 16 hours agorootparentWiFi is not considered that important to a hotel or conference center, especially when most people have access to the phone network.There’s a reason why many conferences deploy their own wifi infrastructure reply undersuit 16 hours agorootparentWhat about in 2006? reply gumby 14 hours agorootparentEven more so. reply undersuit 2 hours agorootparentSorry, I meant to try and nicely nudge you into the correct conclusion and you have doubled down. 2006 was before the iPhone.You used the wifi, you didn&#x27;t tether to your Nokia 6650. reply ricardobayes 18 hours agorootparentprevCompanies should work out a way to incentivise low-level workers to escalate and chase up \"difficult to tackle\" issues. Ignoring problems rarely work long-term and it&#x27;s companies best interest to know and solve issues. reply lupusreal 18 hours agorootparentprevShe didn&#x27;t need to escalate it because for her personally there was no downside to simply ignoring the matter. reply okeuro49 17 hours agorootparentAnd indeed, would have probably thought that people at a conference would be better being human beings and talking to each other, rather than staring into a laptop screen. reply Dalewyn 9 hours agorootparentprevPath of least resistance.She offered a solution, customer refused it. She had no obligation to act further (assuming no such requirements set by company policy). reply RecycledEle 15 hours agoparentprevI did tech support for a database conference at the Adams Mark around 2000.That was the biggest fluster cluck I&#x27;ve ever seen.The hotel sabotaged the DSL line that provides Internet access until thousands of dollars in previously undisclosed fees were paid. reply linusg789 19 hours agoprevhttps:&#x2F;&#x2F;nitter.net&#x2F;erratarob&#x2F;status&#x2F;1739132876732674539?s=46... reply crtasm 19 hours agoparenthttps:&#x2F;&#x2F;nitter.net&#x2F;erratarob&#x2F;status&#x2F;1739132876732674539 reply thyrox 20 hours agoprevHow does one learn about this stuff? I learned about basic networking in college (the TCP layers) etc but people doing such stuff sounds like Greek to me.If I want to learn more about what the author is doing, is there a resource like a udemy course or YouTube channel you guys can recommend? reply sandworm101 19 hours agoparentBack before cellular data coverage as ubiquitous and cheap, getting on an using shoddy wifi was an essential skill for anyone with a laptop. The ability to lock onto a stable wifi router, piggyback on another network, or syphon some bandwidth from a network you shouldn&#x27;t ... those with such abilities managed to book tickets or hotel rooms within seconds of a flight being cancelled. Or, if you were really evil, you kicked everyone in the terminal off the router, hogging all the bandwidth for yourself. At school I had a script to randomize my laptops MAC ever few minutes then reconnect to the school&#x27;s network. Mine was the only laptop that never got throttled by the wifi police for using too much data in a given session.I used to have a little wifi antenna on my car. Some called it \"wardriving\" but I called it being able to check my email while traveling. reply jampekka 20 hours agoparentprevBack in the day you needed to know this stuff to get things working. It was not that uncommon for routers not to have DHCP so you had to input the IPs by hand. I think this may have been even the default and DHCP had to be explicitly enabled (e.g. in Linux installing and configuring dhclient).Also it wasn&#x27;t that uncommon to expose a computer to internet through the router, so you had to make sure that computer didn&#x27;t change its IP.I think having to set these up yourself is the best way of learning them. reply sunnybeetroot 20 hours agorootparentI remember ye ol’ port forwarding to get Xbox live to work reply mingus88 20 hours agoparentprevThe vagueries of DHCP can be learned best with a home lab, IMOBack in the day, setting up random hardware or VMs on an isolated subnet taught you everything you needed to know about low level network protocols like DHCP, STP, BOOTP, ARP, RARP, and how to sniff it all with wire shark when you weren’t getting a leaseContainers have largely hidden this plumbing from us at a test&#x2F;dev layer reply vander_elst 20 hours agoparentprevI&#x27;d suggest a book. I was pretty happy with \"Computer Networking: A Top-down Approach\" by Jim Kurose. I find it more appealing that it starts with the upper layers (http), because I was more familiar with them. reply i_k_k 18 hours agorootparentFrom the authors’ website:“You can&#x27;t buy a hard copy of the 8th edition, but instead can rent (and then choose&#x2F;pay to keep the hardcopy if you want a hard copy book). You can rent a copy or subscribe to Pearson+ from our publisher, or rent a hard copy or purchase a Kindle version from Amazon, or rent a hard copy from VitalSource.”That’s just… odd!http:&#x2F;&#x2F;gaia.cs.umass.edu&#x2F;kurose_ross&#x2F;index.php reply jampekka 18 hours agorootparentOr just http:&#x2F;&#x2F;library.lol&#x2F;main&#x2F;8B547BCDF967B08655D6360F6FE9D809 reply salawat 11 hours agorootparentprevIt&#x27;s probably intended to elide transfer of rights of first sale by tracking it as a rental with no intent to term in which to return.It&#x27;s bullshit. reply mypalmike 19 hours agorootparentprevNice to see the name Jim Kurose here. Many years ago, I learned networking and C programming in his computer networks course at UMass. Such a great teacher and a real breakthrough class for me in understanding not just networks, but low level systems programming, computer architecture, and other things tangentially related to networks, I&#x27;m not surprised to hear his book is good. reply andrecarini 19 hours agoparentprevGet yourself a router that supports OpenWRT, install that on it and figure out what every configuration option does. Bonus points: setup WPA Enterprise on it and a DNS resolver. reply godzillabrennus 18 hours agorootparentRunning an old PC or at least a VM that does OpnSense is even more versatile. reply OnlyMortal 12 hours agorootparentprevI prefer dd-wrt as I can’t be bothered with the complexity of open-wrt. I’m way too lazy.Admittedly, it run on much fewer platforms - meaning Raspberry Pi for me. reply bzzzt 20 hours agoparentprevDon&#x27;t know about video courses, but Internet standards like DHCP are open and available on IETF.org. There are explanations on Wikipedia too. Also, if you&#x27;re into Linux the HOWTO section on tldp.org can also be a big help for more practical stuff. reply ytch 20 hours agoparentprevMost computer networks 101 class teach how their state machine is designed only.If you want to know \"how to use them in real world\", some universities has courses with \"System Administration\" would be more suitable. or learning the certificate program (CCNP, CCIE, JNCIP and others) materials with their lab. reply colanderman 19 hours agoparentprevIf you&#x27;re ok working through a textbook, I found https:&#x2F;&#x2F;intronetworks.cs.luc.edu&#x2F;current1&#x2F;html&#x2F; to be a thorough course on all things networking. reply throwawaaarrgh 18 hours agoparentprevBack in the day you would just follow The Linux Documentation Project&#x27;s HOWTOs and set up each kind of software on a little computer on your home network and play around with things. Today there&#x27;s nothing like that unfortunately. HOWTOs were abandoned for individual blog posts written for one specific use case at a time, and I know of no index of such blog posts. reply wpm 18 hours agoparentprevI learned a lot at my student job in the university IT department troubleshooting why I could boot from my Xserves NetBoot server in one room but not another.The rest I learned in the last year by switching to pfSense&#x2F;Opnsense for my router&#x2F;firewall. reply nunez 17 hours agoparentprevI would take courses oriented towards getting your CCNA (Cisco Certified Network Administrator). It covers the basics while also teaching you a bit about navigating through a Cisco switch. reply baobun 18 hours agoparentprevStart homelabbing. Set up your own network. reply jacquesm 18 hours agoparentprevRead the RFCs. reply woodruffw 19 hours agoprevThis is adjacent to the classic free WiFi hack on airplanes, which is to boot another client off of their DHCP lease by spoofing their MAC.It’s unfortunate that, below HTTPS and a light smattering of WiFi encryption, there’s essentially no authenticity controls on LAN management protocols. reply spr-alex 19 hours agoparentI work on SPR, http:&#x2F;&#x2F;github.com&#x2F;spr-networks&#x2F;super, we make it easy to use distinct WiFi 3&#x2F; WPA2 passwords to authenticate devices on the network for policy based access reply amazingman 17 hours agorootparent>we make it easy to use distinct WiFi 3&#x2F; WPA2 passwordsIf only we could get the industry to move to this model, we could dramatically reduce the amount of congestion due to APs broadcasting multiple SSIDs. reply nixgeek 19 hours agorootparentprevGreat project, a lot of APs themselves support VLAN segregation using RADIUS, has SPR ever considered the scenario where it might be ideal if it were just the router and it controls APs (and even switches) that way? reply spr-alex 18 hours agorootparentSPR supports receiving VLAN tagged packets over a wired LAN interface today.Soon we are planning to support an OpenWRT package that will allow people to link up into SPR from lots of APs, provided the AP card supports AP&#x2F;VLAN mode which is critical for the segmentation.We have no plan to work more closely with managing RADIUS right now, enterprise wifi authentication is difficult to deploy securely without client-side certificates for authentication. So that makes it less appealing due to our goal of supporting any kind of wifi capable device.Lastly, SPR does have an upsell feature where we support leaf node APs running SPR that have backhaul into a primary instance. reply nixgeek 18 hours agorootparentYeah I already do some combination of MPSK and MAC-based Security on Aruba AP-555 and AP-655 at home with a couple hundred IOT devices, OPNsense and FreeRADIUS. I segment by (vendor, device model) instead of &#x2F;30 per individual device but that’s more setup convenience than anything (it’d be possible to uniquely dot1q every device, too).I think SPR looks neat, it’s a more well-packaged version of essentially what I already do (albeit in a kludgey way), hence the curiosity about ambition. reply godzillabrennus 19 hours agorootparentprevClient isolation at the access point level does this. reply spr-alex 18 hours agorootparentYes, this is part of the story of how SPR achieves this.So the hostapd configuration for SPR has the following components: - ap_isolate=1 - per_sta_vif=1 - unique passphrases for devices - firewall rulesap_isolate stops the AP from doing L2 forwarding between clients using the pairwise keys. the per_sta_vif=1 will also ensure that each client has a unique GTK so they can&#x27;t use group key encryption to communicate without the AP.Next, unique passphrases are used. Without this, it&#x27;s possible for a malicious device to decrypt WPA2 traffic passively or spin up a Rogue AP to capture traffic from peers.And lastly -- firewall rules with default deny connect devices by policy.That ap_isolate alone is not enough is kind of interesting, as it&#x27;s possible to instead push packets to the router that will then forward to the client destination. Most off the shelf routers have forwarding on without a default deny policy, enabling this. The subtlety here is the attacker uses the router as the L2 destination instead of the other wireless client. At the very least attackers can send UDP packets to bypass the intended isolation. This bypass is especially powerful when changing mediums between Wireless and Wired as the Wired victim receiving packets will be responding back to the router, and on many consumer routers a full TCP connection will be possible then. reply amluto 18 hours agorootparentprevDoes this usefully support multiple APs with the same ESSID? reply spr-alex 18 hours agorootparentYes, although it is part of our upsell and not in the core FOSS project. We need to update our documentation to be more clear as we have been getting this question more often. reply amluto 16 hours agorootparentI poked around the site, and it was entirely unclear to me that one could buy this feature or how it works.Can it make it painless to manage multiple APs and to get fast roaming, etc working? UniFi pulls this off nicely — there’s nothing particularly fancy under the hood AFAICT, but it all just works. A more intelligent solution where clients got assigned to appropriate VLANs would IMO be extra nice.(The enterprise vendors seem to have decent ACL and maybe even anti-spoofing measures for their wired networks, and they have some security features for wireless, but I haven’t seen anyone with a nice solution that makes wired and wireless security cooperate. I haven’t looked that hard.) reply placatedmayhem 19 hours agoparentprevEvery time I have to interact with a \"captive portal\", I&#x27;m annoyed at the hack implemented through DNS hijacking, rather than implementing and extending 802.1X and&#x2F;or another layer-2 authentication scheme. The idea seems to have been tossed aside entirely. Instead, every device has to have a web browser. There&#x27;s not even a way to do surrogate registration for devices that don&#x27;t have browsers, with Apple TV and Nintendo Switch at launch (added later) being prime examples. IoT and headless gear is also a pain. On trips, I end up bringing my own travel router and using my laptop to auth it by proxy, but it&#x27;s another thing to remember to bring. reply sandworm101 18 hours agorootparentI have a work laptop (government) that hates captive portals. It has a security system that won&#x27;t let it connect using the local DNS. So it doesn&#x27;t get captured. Those of us with such laptops all have tricks for getting to a hotel&#x27;s wifi login page using IP addresses. But we have to do it fast, before the security software fully wakes up and blocks the hack.We used to just login on our phones, then tether the work laptop to the phone over USB. The security people caught up to that a couple years ago and disabled USB tethering. So now I alter my laptop&#x27;s MAC to be the same as that from the work laptop. That tricks about 90% of hotel wifi into allowing the work laptop to connect without need of a splash page. But for the other 10%...(Not a joke, I do this) I sometimes login to the hotel wifi on my personal phone, tether that phone to my personal laptop, then setup that laptop as a router. The work computer can then connect to the wifi from the personal laptop, which tethers into the phone, which is on the hotel wifi. All of this just avoid another ridiculous wifi login page. reply throw0101b 18 hours agorootparent> I have a work laptop (government) that hates captive portals. It has a security system that won&#x27;t let it connect using the local DNS.Does the OS not pay attention to DHCP option 114: This document describes a DHCP option (and a Router Advertisement (RA) extension) to inform clients that they are behind some sort of captive-portal device and that they will need to authenticate to get Internet access. It is not a full solution to address all of the issues that clients may have with captive portals; it is designed to be used in larger solutions. The method of authenticating to and interacting with the captive portal is out of scope for this document.* https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc8910* https:&#x2F;&#x2F;developer.apple.com&#x2F;news&#x2F;?id=q78sq5rv reply sandworm101 18 hours agorootparentIt is more layered than that. The work machine initiates a VPN automatically at login. Once that VPN is up, all traffic goes through the VPN, including DNS. It will actively ignore&#x2F;block anything that isn&#x27;t coming from the VPN. So we do tricks to get to the hotel splash page before the VPN software wakes up. These are corporately-managed windows machines. The boot&#x2F;login process isn&#x27;t exactly quick. reply jemmyw 14 hours agorootparentWhy do you try to solve the problem at all? Wouldn&#x27;t it be better to say \"sorry I can&#x27;t do any work from this location because of our IT policy\" and let your organisation sort it out if they need you to work from a hotel? reply nunez 17 hours agorootparentprevThis was the reason why I bought a travel router&#x2F;wifi repeater. You connect your corp laptop to the travel router then use your phone to log into the hotspot. Hotels are now using Meraki Air Marshal to block them on 2.4Ghz networks though reply breakingcups 12 hours agorootparentI&#x27;ve been reading up on it. Seems like it sends spoofed de-Auth packets to AP&#x27;s it deems \"rogue\". That sounds highly illegal. reply yodon 17 hours agorootparentprevI wasn&#x27;t familiar with Air Marshall. I understand it complicates your work-around, but I&#x27;d probably pay extra to stay in a hotel that cared enough about security to deploy it reply nunez 15 hours agorootparentNo, i think it&#x27;s a great feature. Definitely increases security. I don&#x27;t believe it works on 5GHz networks though. reply mdorazio 18 hours agorootparentprevDoes the laptop also prevent wireless tethering to your phone? Turning your phone into a hotspot is pretty trivial, at least on iOS. I often have to do it due to similarly arcane security configuration settings on my work laptop. reply sandworm101 18 hours agorootparentYes, but unless you have a phone with two wifi connections then you will have to use your cellphone&#x27;s data plan rather than the hotel wifi. When traveling, doing a teleconference or having your work laptop perform a windows update over your cellphone data connection isn&#x27;t cheap. We used to just tether to our work phones, but they locked that down after seeing the international roaming bills. reply mendelmaleh 16 hours agorootparentConnecting to wifi and enableing the hotspot at the same time works on my phone (pixel 5), it probably just uses different bands. It&#x27;s pretty useful to avoid typing passwords twice. reply pests 11 hours agorootparentprevAndroid on certain phones can hotspot a WiFi connection both over wireless and USB. reply fragmede 18 hours agorootparentprevI don&#x27;t know if it&#x27;s more or less ridiculous, but I bring a small travel router running OpenWrt to do said bridging so I don&#x27;t need to have my laptop running so I can use my Chromecast on the hotel TV. reply throw0101b 18 hours agorootparentprev> Every time I have to interact with a \"captive portal\", I&#x27;m annoyed at the hack implemented through DNS hijacking, rather than implementing and extending 802.1X and&#x2F;or another layer-2 authentication scheme. The idea seems to have been tossed aside entirely.It has not: it&#x27;s simply easier (less infrastructure) to not implement 802.1X.Basically every corporate &#x2F; enterprise-y password where you use your AD&#x2F;LDAP credentials to log into Wifi has gone through the effort. Not everyone wants (or needs) to do that. (Source: recently implement 802.1X as IT when we moved to a new work office.) reply chimeracoder 19 hours agorootparentprev> Nintendo Switch at launch (added later)The Nintendo Switch actually had a browser either at launch or close to it, then removed it in an update, and didn&#x27;t add it back until about 3 years later.It&#x27;s really hilarious that a device that touted its portability from the beginning was literally incompatible with most public Wi-Fi for years. reply spr-alex 18 hours agorootparentprevneverssl.com reply hrunt 16 hours agoprev> Obviously, one solution to the problem is that DHCP leases on planes should be drastically shorter, like at 1 hour intervals. Secondly, the number of leases should be drastically increased.Why isn&#x27;t the solution as simple as, \"Reset the Internet at every flight turnover\"? Once the plane lands and (almost) everyone deplanes, hit the button as another step in crew handover. reply D13Fd 16 hours agoparentBetween “crew has to remember to hit the button” and “everything just works,” I have a strong preference for the second one. reply gpjt 10 hours agoparentprevThat would help, but I can imagine that on larger planes, especially if people connect their phone, then later their laptop, and so on, you could hit the limit of a 192.168.x subnet even during a flight. reply workfromspace 17 hours agoprev15+ years ago, I had the same problem at a Starbucks. I asked the cashiers to reboot the modem, but they didn&#x27;t understand why. Then I showed my new Microsoft certification card which has MCSE and few others and told them that \"trust me, I know what I&#x27;m doing\".They called their manager, who was also suprised but decided to go along with it and restarted the modem, solving the problem. I remember all the employees were looking at me for the rest of my visit (which was few hours because at that time I was working from Starbucks).Glad I wasn&#x27;t the only one :) reply belter 16 hours agoparentThat happened to me also. The manager told me all employees had a MCSE and CCIE and they were not currently hiring, thank you... reply mewpmewp2 16 hours agoparentprevI would like a \"Blessed by the Elders of the Internet\" certificate for such occasions. reply mynameisnoone 10 hours agoparentprevThat&#x27;s adjacent to \"Do you know who I am?\" The problem with certifications are that they aren&#x27;t a very good signal of quality employees because A+ and MCSx were on every resume along with SQL and Java. The best technical people I&#x27;ve know&#x2F;n have few to no certifications to please HR, but maybe a Master&#x27;s or PhD in CS or CCIE. Mostly, certifications have fallen by the wayside since 2008 apart from low-productivity businesses that aren&#x27;t technology-focused. reply ano-ther 21 hours agoprevI love that “internet reset” button reply laurencei 21 hours agoparentWe laugh as IT experts.But think about it from the end user perspective. Literally the most simple instruction; near fault proof. On an airplane that is thousands of feet from remote IT support (plus \"costs\").The instruction to staff; problem with \"the Internet\"? - press the \"Interest Reset\" button.Far better than \"router restart\", \"renew DHCP leases\" or \"reboot IT\"Explicit, non ambiguous and without technobabble.Brilliant. reply martinflack 15 hours agorootparentWhat&#x27;s interesting is that the button need not actually reset the Internet right away. It&#x27;s actually a user signal that \"customers are complaining the Internet does not work\". The button could initiate a whole series of diagnostics and target a fix. reply alpaca128 53 minutes agorootparentThat sounds mainly like yet another thing that could malfunction. reply laserbeam 20 hours agorootparentprevHonestly, that should be the mindset of IT experts in general. Any reset&#x2F;reset should fix everything and bring the system to a known functional state before doing any work.Obviously you don&#x27;t want to have to restart to fix issues, but having that as a fallback (especially for issues you didn&#x27;t predict during development) is great UX. reply alexwasserman 19 hours agorootparentIsn’t this the fundamental point of the push for impotency in configuration management tools?You just need the state set to “good”, regardless of which bits need to change and current state. Hit the button and it makes it “good”. reply chimeracoder 19 hours agorootparent> Isn’t this the fundamental point of the push for impotency in configuration management tools?FYI, The word you&#x27;re looking for is idempotence (EYE-dem-poh-tense). reply smelendez 18 hours agorootparentThank you. I thought this was some reference to giving people config options that don’t actually do anything. reply alexwasserman 16 hours agorootparentNo, just phone autocorrect, and too late to edit it.Typing too fast and not paying attention.Although I do like your interpretation. Maybe I’ll call poorly implemented or useless functions impotent from now on. reply alexwasserman 18 hours agorootparentprevYes, autocorrect. reply macintux 19 hours agorootparentprevHence Erlang. When in doubt, restart the part of your application with bad data. reply fifteen1506 20 hours agorootparentprevI refuse.I stand my ground on using quotes.\"Reset\" \"Internet\". reply YurgenJurgensen 18 hours agorootparentprevIf that&#x27;s your attitude, you may as well rename the button \"Appease Machine Spirit\" and attach a few purity seals to it. reply lupusreal 18 hours agorootparentThat&#x27;s a bad name for the button because now the staff have to remembered what it&#x27;s for. reply nunez 17 hours agorootparentprevagreed. It’s a great solution for a flight crew that is most likely unable&#x2F;unwilling to troubleshoot stale DHCP leases or bouncing ifaces. The only disadvantage is that if the Internet reset button doesn’t work for whatever reason, the FAs will mark the entire system INOP for your entire six hour cross country flight that you planned to work on... reply op00to 20 hours agorootparentprevImmutable OS FTW! reply angrygoat 20 hours agoparentprevI&#x27;m a priest who was a software engineer for twenty years. This morning during the service in a small semi-rural church, the bluetooth speaker broke. I paused the service briefly, joked that I knew what to do, and turned it off and on. The IT Crowd got that part of the industry right! reply sunnybeetroot 20 hours agorootparentWow why the career change? reply angrygoat 17 hours agorootparentit&#x27;s a complicated answer: faith is at the heart of it, of course. In Christianity there&#x27;s the idea of vocation, which applies to all, not just the clergy. A simple way to think about it is to consider the things you&#x27;re good at, the things you can do that will serve others, and what you enjoy: imagine that as a Venn diagram, and try to discern what lies in the middle for you.My software skills still play a part in what I do. But seven or eight years ago now I felt drawn to explore a vocation in ordained ministry – after study, a formation programme, completing a Masters degree in Divinity, and a lot of thought and prayer, here I am. It&#x27;s the happiest I&#x27;ve ever been. Which isn&#x27;t to say that it hasn&#x27;t been difficult: being a cleric is not easy work.Intentional discernment about vocation really has made my life a lot happier, and it&#x27;s something I talk about a little because it&#x27;s of value to other people as well.(I&#x27;m in the Anglican [in the states, Episcopalian] tradition, but the process of ministerial formation is very broadly similar between the various mainline protestant denominations and Roman Catholicism.) reply atonse 19 hours agorootparentprevPaying penance for using Angular 2.0 (had to insert some random technology to make my silly joke work)Software engineer turned priest, perfect story for HN on Christmas Day, do tell! reply FunnyLookinHat 19 hours agorootparentprevYes, don&#x27;t leave us hanging (on Christmas, no less!). reply op00to 21 hours agoparentprevI don’t remember seeing a button on the internet when watching a documentary about an IT team that gave their manager the box that controls the internet. Only had a red led. This must be a new version of the internet. reply sammy2255 21 hours agorootparentAre you sure you’re not thinking of The IT Crowd? https:&#x2F;&#x2F;youtu.be&#x2F;iDbyYGrswtg reply op00to 20 hours agorootparentThat’s it! That’s the documentary! Weird choice for a documentary to have the laugh track though. reply em-bee 17 hours agorootparentit&#x27;s because truth is funnier than fiction reply tym0 21 hours agorootparentprevAfter it was dropped they had to do a v2 reply Brajeshwar 21 hours agorootparentprevI believe the “Button for the Internet” is the Browser - Internet Explorer. reply op00to 20 hours agorootparentI don’t have a browser on my computer. Can you help me install it? reply RedShift1 20 hours agorootparentSure, just Google for Firefox and install that. reply jltsiren 19 hours agoparentprevThis must be something language&#x2F;culture dependent. To a native Finnish speaker, labeling the button that resets the internet connection as \"internet reset\" makes perfect sense. Just like the power button only switches the power on&#x2F;off for that particular device but not for the rest of the world. reply SkipperCat 19 hours agorootparentThe entire commercial aviation industry operates using the english language. All pilots communicate with all airports via english. I&#x27;m sure FAs are most proficient in english too. Its the lingua franca of the biz. reply jltsiren 19 hours agorootparentI meant that I would label the button that resets the internet connection \"internet reset\", and there would be nothing weird or amusing about that. Because my native language is Finnish, English words often have subtly different meanings to me than to a native English speaker, even when we agree on the literal meaning of the word. reply apantel 17 hours agorootparentprevI think we’re ready for ‘Lingua Anglica’. reply Ekaros 19 hours agorootparentprevActually reset is kinda weird term.Internet is not working Solution: Set it again to working condition, thus reset Internet.Sometimes it is pointless to go to technical details. I was on flight with issues with infotainment systems, they fixed it by restarting them. Or reset. reply cassianoleal 19 hours agorootparentprevThis is a very confusing message.The \"internet reset\" message makes sense in all languages that I know. Same with the power button.What do you think they mean in other languages? reply fmajid 19 hours agoparentprevhttps:&#x2F;&#x2F;www.southparkstudios.com&#x2F;video-clips&#x2F;hq0tek&#x2F;south-pa... reply amelius 18 hours agoparentprevDon&#x27;t press it too often, or you&#x27;ll hear cursing from the cockpit. reply linsomniac 20 hours agoparentprevShould be labeled \"Turn Internet off and on again\". reply rasse 20 hours agoparentprevFrom an end user perspective the better label would be \"Fix internet\" reply poopsmithe 20 hours agorootparentNo. That would mean the button needs to stay pressed indefinitely. reply op00to 20 hours agorootparentprevTechnically the button breaks the internet then fixes it. reply mewpmewp2 16 hours agorootparentprevMaybe it should be \"press when in trouble\". reply mnutt 19 hours agoprevBack when my company was a tiny startup the old nyc building door had an intercom buzzer and physical keys. To make it easier to get in I wired a raspberry pi w&#x2F;relay into the intercom and built a web UI. The pi setup wasn’t solidly reliable for weeks at a time, but fortunately it was plugged into an outlet with a light switch so everyone knew to turn it off and back on again. But since it was by the door, no matter the labeling from time to time we’d come in to find it turned permanently off. reply cheese_van 20 hours agoprevDeep in the granite mountain where the internet Kill Switch is located, there is also the US national Internet Reset switch.What exactly, in this fictional universe, is the restoration flow if it is pressed? reply flutas 19 hours agoparentYou have to unplug the giant router and plug it back in like South Park did.https:&#x2F;&#x2F;giphy.com&#x2F;gifs&#x2F;southparkgifs-l0Hlwi7KzoajIJTI4 reply mynameisnoone 10 hours agorootparentThe problem is it&#x27;s incapable of running DD-WRT. reply ganzuul 15 hours agoparentprevInstructs Intel ME to boot into TempleOS with a Gopher client and IRC. reply raadore 20 hours agoparentprevnext [3 more] [flagged] ThrowawayR2 15 hours agorootparentI&#x27;ll point out again that the moderators have said that posts with machine generated content are not welcome on HN: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33950747 reply urbandw311er 17 hours agorootparentprevI find it really tedious when people just post direct paragraphs written by ChatGPT. I mean, we could all just go and ask chatGPT to write that right? It doesn’t add anything to the conversation.Sorry if that sounds harsh but I can’t think of a better way to post it and honesty felt like the best approach. reply jancsika 9 hours agoprev> Apparently in the front near the entrance&#x2F;exit, there&#x27;s a button simply labeled \"INTERNET RESET\" that she presses whenever a customer complains.I worry that this is actually part of a RESTful interface. In that case it probably garbage collected erratarob et al, replacing them with a fresh version of our universe&#x27;s page that had working internet for that plane.Until someone proves me wrong we probably shouldn&#x27;t press that button again... reply nunez 17 hours agoprevDHCP is broken all of the time in these inflight WiFi systems. After they reset, you need to wait forever for the portal to turn up after which point there&#x27;s a storm of clients trying to create or re-establish an Internet session which usually saturates the super small link unless it&#x27;s satellite-based (and sometimes even then) reply bilsbie 20 hours agoprevI upvoted this in the futile hope that the right person sees it. reply umvi 20 hours agoparentWould need to know which vendor. I used to work for a company that provided satellite Internet solutions for airplanes but might not be what OP used reply flutas 19 hours agorootparentIn my mind, probably either Panasonic Avionics or Gogo.If this debugging is true... I&#x27;d guess Panasonic from experience working there.Things like an office scavenger hunt usually took priority over actual work. reply joezydeco 18 hours agorootparentGogo was bought out by Intelsat, so that reduces the amount of possible sources. reply ratg13 16 hours agoparentprevThe problem is that the person reporting this needs to identity the provider or nothing will get done.The plane usually tells you if the WiFi is provided by viasat, anuvu, or any of the other big players.These companies program this stuff before it goes into the aircraft and the airline IT has no access to this stuff.Without the missing info, it’s almost impossible to trace this. reply calamari4065 16 hours agoprevReminds me of when our router failed at work. Every machine got booted off the network, except mine. Digging in, my machine somehow got assigned an IP that looked like our public facing IP, not a local address.We replaced the router, but the problem turned out to actually be that a construction worker had accidentally cut our fiber line.Absolutely no clue how my laptop got to the internet. It must have failed over to some other WiFi network or something reply duxup 19 hours agoprevIt’s fun how a sorta absurd term like “reset the internet” now has an obvious meaning, usually resetting whatever access point type device is nearest the person resetting it. reply baldgeek 9 hours agoprevI used to work at one of the larger IFE providers and we always being asked to make the system as dumb as possible because flight crews hating supporting them. Not surprising to see this exists. reply Tijdreiziger 9 hours agoprevThe author has more courage than me, opening “hacking tools” (Wireguard and Terminal) on an airplane.(Yes, I know they’re not actually hacking tools, but try explaining that to a random flight attendant.) reply lionkor 9 hours agoparent\"These are not hacking tools, I work in IT and these are harmless diagnostics for my laptop\" seems pretty simple reply Comfy-Tinwork 10 hours agoprevAlways good to see something from Rob.Question would be how high in the management chain did that have to go before a \"internet reset\" button was added to a plane. reply ape4 19 hours agoprevWhy don&#x27;t laptops randomize their MACs? reply zamadatix 19 hours agoparentDevices tend to support randomization by default these days but it comes in multiple types: scanning, persistent, per ssid, or full random. Full random is not typically used, particularly if a captive portal is detected, because it breaks connectivity. reply ruune 19 hours agoparentprevProbably because no desktop OS I know of randomizes MAC addresses by default. How many people are gonna enable that manually? At least android (and I think iOS) default to random addresses reply woodruffw 18 hours agorootparentI believe recent versions of macOS also perform MAC randomization by default. reply m3047 14 hours agoparentprevBecause they&#x27;re connected to the network. Seriously.It&#x27;s like \"why do recursing DNS servers spam queries if they don&#x27;t get an answer within 10 milliseconds?\" To give you an idea how shortsighted this is, a production grade DNS server doing this also supports response rate limiting (warfighting capability which treats the spamming as spam), and the recursing DNS server is supposed to be caching and should be trying to optimize \"whole of page\" to achieve so-called \"happy eyeballs\".To give you a somewhat more technical explanation, a MAC address can be permanently tethered to an IP address (so that each time it connects it always gets that address on that particular network). When that is not done (when there is no association for a particular MAC), an address is assigned from a (finite) pool. In some deployments the finitude of the pool provides a \"fusible link\" for defense in depth against some forms of resource exhaustion.The MAC address is visible regardless of whether or not a device is connected to a network: it is an address (it has broadcast and multicast too). When devices are not connected to a network and want to go around mumbling \"notary sojack\" (with a major 0) to every man + dog + keyhole to see who&#x2F;what responds there&#x27;s no downside for them doing it; at least, I haven&#x27;t seen any hostapd option for running a tarpit like we do for some level 3&#x2F;4 services (the first attempt is rejected; sometimes the entire TCP handshake is completed and at the app level the server says \"not now, try later\").Once they&#x27;re connected to a network there&#x27;s a network stack with DHCP, ARP and server state. The set of MAC addresses is orders of magnitude larger than the set of IP addresses in a DHCP pool. It doesn&#x27;t \"hand out an address\" as the first order of business; it records your MAC address and gives you an address from the pool. Addresses return to the pool when the lease expires or when they&#x27;re observed not to be in use. (There is a DHCPRELEASE op but crappy software so defense in depth doesn&#x27;t rely on clients cleaning up after themselves.)Once you&#x27;ve got an IP address associated with a MAC address associated with your network interface it looks like a LAN segment on the internet. If somebody on the segment wants to send a packet to that IP address they use ARP to ask what hardware machine code (MAC) do I address a packet to this IP address to? (IP addresses are a layer of indirection)Beyond that the LAN segment is connected to other segments with a router. The router knows things about topology that you&#x27;re not supposed to know, and more importantly that random peers elsewhere on the internet aren&#x27;t supposed to know. If you were on a LAN segment connected with a hub, you&#x27;d have some idea what other internet addresses were active on that segment. You can make an educated guess about what addresses are allowed (by the router) on that segment based on the broadcast mask; you could perhaps ping addresses within the broadcast range to see which ones are &#x2F; aren&#x27;t in use and hijack one of them.What happens to packets which are part of a session which are in-flight when an IP address changes? Quite frankly, many applications very wrongly presume that an address (or DNS name, but that&#x27;s out of scope) is some form of identity. TCP has no way to change one of the addresses mid-session. So you&#x27;re not going to be changing the IP address with garden variety cloud services.Now we&#x27;ve got the problem defined: what happens if the MAC address associated with an address changes? First off, packets coming from the router destined for the old MAC address based on the cached IP -> MAC association are going to start dropping. Or be intercepted: what&#x27;s to stop some joker from grabbing such an address and claiming the \"legitimate\" holder is the impostor?(I wouldn&#x27;t be so sure that you can&#x27;t see wifi traffic which isn&#x27;t addressed to your MAC if you&#x27;ve successfully authenticated to a wifi network. It&#x27;s more like a hub, at least if you&#x27;re connected to the same AP.) reply meinheld111 16 hours agoparentprevCaptive portals reply tyingq 18 hours agoprevInteresting. The \"minimum F&#x2F;A&#x27;s required: 5\" sticker suggests it&#x27;s a pretty big plane that holds around 250 passengers. So it probably happens less often on smaller planes. reply mynameisnoone 10 hours agoparentProbably a narrowbody though. I&#x27;ve been on overseas flights on widebodies where there were ~20 F&#x2F;A&#x27;s. reply belter 17 hours agoprevSounds appropriate... - https:&#x2F;&#x2F;youtu.be&#x2F;kBLkX2VaQs4?t=92 reply dkjaudyeqooe 20 hours agoprevThere&#x27;s another one in the cockpit, marked \"Avionics Reset\". reply asystole 19 hours agoparentYou joke, but there absolutely are procedures in some airplane QRMs that involve cycling breakers. reply gugagore 18 hours agoprevI had a Internet connectivity problem on a JetBlue flight recently that I couldn&#x27;t figure out. I could see the captive portal, with a URL like \"planSelectionPage\". I would check the agreement and hit \"Let&#x27;s go\", and some JavaScript would trigger and look like a new page was loading, but would just stay on the same page. It happened on both Firefox and Chrome. My phone connected without a problem.I wasn&#x27;t sure how to debug it. reply mynameisnoone 10 hours agoprevAll the WiFi vendor had to do was use a properly-sized subnet like 10.N.0.0&#x2F;16, but no, they couldn&#x27;t provide something better than a shitty retail home router with an aviation-grade reset button panacea. reply sys_64738 18 hours agoprev [–] Hacking WiFi on a plane is a sure fire way to get yourself added to the no-fly list. reply perlgeek 18 hours agoparentNote that what the author did could have been done in a purely passive way, just by capturing packages and seeing the DHCP responses others got. I don&#x27;t think that qualifies as \"hacking\". reply sys_64738 17 hours agorootparentTell that to the judge then. reply mynameisnoone 10 hours agorootparentThe ignorant masses demonize what they don&#x27;t understand. If you don&#x27;t appreciate the subtleties of passive investigation vs. offensive intrusion, then why are you even here? reply sys_64738 8 hours agorootparentA layman only sees a terrorist hacker interfering with the operation of an airplane. The no-fly list at best or Gitmo at worst. reply bdavbdav 11 hours agoparentprevWhat was hacked? reply sys_64738 8 hours agorootparentRunning hacker tools against aircraft operations will get you easily indicted. This can be seen as probing an aircraft defenses for weaknesses. reply bdavbdav 10 minutes agorootparentDefine a hacker tool - is the whole computer a hacker tool because it could be used by a hacker? How do we define tools that can be used both legitimately and illegitimately. The tools used were common network diagnostics tools. reply UrineSqueegee 18 hours agoparentprev [–] good thing he didn&#x27;t do any then lol replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The individual encountered problems with the inflight wifi, which were attributed to a lack of DHCP lease.",
      "At the time of the issue, there were 55 devices connected to the wifi network."
    ],
    "commentSummary": [
      "The discussion encompasses a range of networking topics, such as WiFi connectivity issues, book suggestions, home network setup, and bypassing captive portals.",
      "Specific networking technologies and methods like VLAN segregation and access point management are also discussed.",
      "Other topics include frustrations with captive portals, travel router usage, security concerns, the concept of \"internet reset,\" IT certifications, and the legal implications of using hacking tools on airplanes."
    ],
    "points": 221,
    "commentCount": 155,
    "retryCount": 0,
    "time": 1703507270
  },
  {
    "id": 38763566,
    "title": "Contest Factory Uses Broad Software Patents to Sue Online Contest Organizers, Challenged by EFF",
    "originLink": "https://www.eff.org/deeplinks/2023/12/stupid-patent-month-selfie-contests",
    "originBody": "Patents are supposed to be an incentive to invent. Too often, they end up being a way to try to claim “ownership” of what should be basic building blocks of human activity, culture, and knowledge. This is especially true of software patents, an area EFF has been speaking out about for more than 20 years now. This month’s Stupid Patent, No. 8,655,715, continues the tradition of trying to use software language to capture a monopoly on a basic human cultural activity–in this case, contests. A company called Opus One, which does business under the name “Contest Factory,” claims this patent and a related one cover a huge array of online contests. So far, they’ve filed five lawsuits against other companies that help build online contests, and even threatened a small photo company that organizes mostly non-commercial contests online. The patents held by Contest Factory are a good illustration of why EFF has been concerned about out-of-control software patents. It’s not just that wrongly issued patents extort a vast tax on the U.S. economy (although they do—one study estimated $29 billion in annual direct costs). The worst software patents also harm peoples’ rights to express themselves and participate in online culture. Just as we’re free in the physical world to sign documents, sort photos, store and label information, clock in to work, find people to date, or teach foreign languages, without paying extortionate fees to others, we must also be free to do so online. Patenting Contests Claim 1 of the ‘715 patent has steps that claim: Receiving, storing, and accessing data on a computer; Sorting it and generating “contest data”; Tabulating votes and picking a winner. The patent also uses other terms for common activities of general purpose computers, such as “transmitting” and “displaying” data. In other words, the patent describes everyday use of computers, plus the idea of users participating in a contest. This is a classic abstract idea, and it never should have been eligible for a patent. In a 2017 article in CIO Review, the company acknowledges how incredibly broad its claims are. Contest Factory claims it patented “voting in online contests long before TV contest shows with public voting components made their appearance,” and that it holds patents “associated with online contests and integrating online voting with virtually any type of contest.” Lawsuit Over Radio Station Contest In its most recent lawsuit, Contest Factory says that a Minneapolis radio station’s “Mother’s Day Giveaway” for a mother/daughter spa day infringed its patent. The radio station asked people to post mother-daughter selfies online and share their entry to collect votes. Contest Factory sued Pancake Labs (complaint), the company that helped the radio station put the contest online. Contest Factory also claimed a PBS contest in which viewers created short films and voted on them was an example of infringement. For the “Mother’s Day Giveaway” contest, the patent infringement accusation reads in part that, “the executable instructions … cause the generation of a contest and the transmission of the first and second content data to at least one user to view and rate the content.” Contest Factory has sued over quite a few internet contests, dating back more than a decade. Its 2016 lawsuits, based on the ‘715 patent and two earlier related patents, were filed against three small online marketing firms: Vancouver-based Strutta, Florida-based Elettro, and California-based Votigo, for contests that go back to 2011. We don’t know how many more companies or online communities have been threatened in all. Sharing user-generated content like photos—cooperatively or competitively—is the kind of sharing that the digital world is ideal for. When patent owners demand a toll for these activities, it doesn’t matter whether they’re patent “trolls” or operating companies seeking to extract settlements from competitors. They threaten our freedoms in unacceptable ways. The government shouldn’t be issuing patents like these, and it certainly shouldn’t be making them harder to challenge. Opus One d/b/a Contest Factory v. Pancake Labs complaint Opus One d/b/a Contest Factory v. Telescope complaint Opus One d/b/a Contest Factory v. Elletro complaint Opus One d/b/a Contest Factory v. Votigo complaint Opus One d/b/a Contest Factory v. Strutta complaint",
    "commentLink": "https://news.ycombinator.com/item?id=38763566",
    "commentBody": "Stupid Patent of the Month: Selfie ContestsHacker NewspastloginStupid Patent of the Month: Selfie Contests (eff.org) 171 points by glitcher 18 hours ago| hidepastfavorite43 comments AlbertCory 17 hours agoJust wait another year and a half, and then you&#x27;re free:2025-08-10 Adjusted expirationNo one&#x27;s bothered to invest the $500,000 or so for an IPR to destroy this patent, which should be easy. Just adding the words \"on a computer\" to a common activity does not make it patentable. reply mort96 15 hours agoparent> Just adding the words \"on a computer\" to a common activity does not make it patentable.Someone should tell the patent office reply AlbertCory 15 hours agorootparentThey did. But that didn&#x27;t automatically invalidate all the old patents. reply nikanj 14 hours agoparentprevJust wait for the next wave of patents where they add ”using AI” reply ikekkdcjkfke 15 hours agoparentprevThe legitimicy of whoever approved this patent needs to be questioned reply btrettel 14 hours agorootparentFormer patent examiner here.Getting angry at the examiner when the patent stinks is similar to getting angry at programmers when the application stinks. Often, it wasn&#x27;t the programmer&#x27;s fault. Management didn&#x27;t give them enough time, for example, so the programmer did the best they could given the time constraints.And that&#x27;s exactly what happens at the USPTO. Many examiners understand that patent quality is a problem, but USPTO management simply doesn&#x27;t give examiners enough time to do a quality job. Mistakes will happen.[I posted this elsewhere: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38765299] reply jdksmdbtbdnmsm 8 hours agorootparent>Management didn&#x27;t give them enough timeNo no no, humans never do a good job of anything unless they earn a profit, which is why we need capitalism, which is why we need patents. reply nfriedly 14 hours agorootparentprevI think it&#x27;s mostly congress&#x27;s fault. They told the patent office to basically approve anything that didn&#x27;t have prior art in the form of an existing patent for the exact same thing. reply btrettel 14 hours agorootparentThat&#x27;s not how the USPTO operates. I know because I&#x27;m a former USPTO examiner. Prior art is not restricted to existing patents. I&#x27;ve used YouTube videos, webpages, academic papers, other patents&#x2F;applications, and probably more.Also, it doesn&#x27;t need to be exactly the same thing. Obviousness&#x2F;103 rejections are probably the most common. (The legal definition of obviousness doesn&#x27;t correspond exactly to the colloquial definition, by the way.)The main problem is my view is the very limited time examiners get. If it&#x27;s not found fast, it&#x27;s probably not going to be found. reply smcin 12 hours agorootparent> Prior art is not restricted to existing patents... legal definition of obviousness...Cough, cough:WO2006068865A3: \"Method and apparatus for making a sandwich\" (2004&#x2F;5) https:&#x2F;&#x2F;patents.google.com&#x2F;patent&#x2F;WO2006068865A3&#x2F;Abstract: The present invention relates to a sandwich assembly tool and methods of making a sandwich, which may be a hot or cold sandwich, quickly by pre-assembly of various sandwich components and simultaneous preparation of different parts of the same sandwich. The sandwich assembly tool is composed of a member preferably having one or two cavities for containing a quantity of garnish. The cavities are used for the assembly of the sandwich. The tool may have a raised ridge adjacent one or both cavities for placement against the hinge of a bread component. Methods of making a sandwich] are disclosed. The methods may include one or more of the use of preasseribled sandwich fillings, assembly of garnishes in advance of a customer&#x27;s order or while ether portions of the sandwich are being heated using the sandwich assembly tool, the simultaneous heating of a bread component and the sandwich filling, placing the bread component over the tool containing garnish, and inverting the tool and bread combination to deposit the sandwich garnish onto the bread component.And meet the rest of the McCrew: https:&#x2F;&#x2F;iptica.com&#x2F;patent-food-recipe&#x2F;mcDonalds-patents&#x2F;... and then in 2022, McDonald&#x27;s applied for 10 metaverse-related patents to allow it to deliver food online and in person, offer entertainment services... reply btrettel 11 hours agorootparentThe WIPO document you linked to is not a patent. The WIPO&#x27;s opinion (available on Espacenet and elsewhere) is that the claims are not novel or non-obvious. There is an associated US patent application, but the USPTO rejected the application. Looks to me like the international and US patent systems worked fine here.I see people on HN confusing patent applications and granted patents too frequently. People can write basically whatever they want to in applications, and do.I don&#x27;t have time to look at the others, but you should check if patents were actually granted, and if they were, look at the \"Notice of Allowance\" in Patent Center to see the examiner&#x27;s reasoning. In my experience, you&#x27;ll usually find a small detail in the claims that the prior art lacked. reply smcin 10 hours agorootparentYou don&#x27;t think it was an attempted abuse of the (US and worldwide) patent system that McDonald&#x27;s tried to patent something that was obvious, non-novel and already being made for half a century? Seems pretty shameless.Not everyone who attempts to file a patent is an inventor. Some are nuisances, some are outright trolls.We could cite patents that were actually granted that should have failed obviousness. reply AlbertCory 10 hours agorootparentYou&#x27;re arguing a different point. G*P said \"only patent prior art is considered.\"That is clearly wrong. If you want to broaden the argument, you might want to start a new thread. reply AlbertCory 10 hours agorootparentprevThanks, and \"searching the patent prosecution history\" is a skill that you can&#x27;t explain in a few seconds. Even if I went to the trouble of finding a PTO rejection based on non-patent prior art, most people wouldn&#x27;t bother reading it. Or would argue about it.It IS true that non-patent art is incompletely searched by examiners the world over, but it&#x27;s not the case that it isn&#x27;t searched at all. reply AlbertCory 12 hours agorootparentprevWhat do you think you&#x27;re proving here? reply AlbertCory 14 hours agorootparentprevAs brettel tells you:that&#x27;s not how it works. we can find plenty of rejections based on non-patent prior art. reply pclmulqdq 15 hours agoparentprevHonestly, the EFF should be IPR-ing all of these instead of complaining about the patent system in general.It sounds like the lawsuits over this patent are probably for minimal amounts of money. reply monsieurbanana 15 hours agorootparentI completely disagree, complaining about the patent system is a good thing to do, that doesn&#x27;t preclude doing something else too. I also don&#x27;t see why the amount of money extorted matter. reply AlbertCory 14 hours agorootparentComplaining makes you feel good. Meantime the trolls are cashing the checks.Abolishing software patents would be a very heavy lift, but not impossible. reply iamjfu 13 hours agorootparentprevIn this case, complaining made me aware of the issue. I&#x27;ve known about patent trolling but not this particular kind. So complaining is a form of raising awareness which could be a good first step if system reform is needed. reply Flux159 16 hours agoprevSo how would someone go through the process of invalidating patents like this? I assume that there&#x27;s no easy or cheap way otherwise the eff would have already done it.Another post mentions spending $500k for an IPR to invalidate - would that be the only way, limiting it to only well funded startups or larger established companies? reply analog31 16 hours agoparentI&#x27;m not a lawyer, but I have several patents and get involved as an internal technical expert in investigating IP issues with my employer. None of this is actual advice:There are multiple levels of engagement. The simplest is simply to ignore the patent and take the risk.You can get an independent lawyer to write a finding that the patent is invalid for reasons X, Y, and Z. What this does is to insulate you from treble damages.There is a formal process for requesting invalidation, but it requires starting with the confidence that the patent is invalid (or a lot of money to waste, or both), and those things are usually enough to justify either of the two above options.Situations where it makes sense to request formal invalidation seem to be rare.You can wait until you get sued, and counter with an invalidation action.I don&#x27;t think you can DIY any of this. Especially, the rules for what is \"obvious\" and what actually counts as prior art, are complicated and it&#x27;s easy to be wrong. reply AlbertCory 16 hours agorootparentBeing known for filing IPRs makes you a \"hard target.\" The trolls will avoid targeting you until they&#x27;ve built up a war chest by settling with all the soft targets. reply abduhl 15 hours agorootparentprev>> What this does is to insulate you from treble damages.This is a dangerous suggestion. Using advice of counsel as a defense to willful infringement is not always successful, and this would be especially true if counsel’s advice is that the patent should be invalidated (rather than your technology not infringing). reply analog31 15 hours agorootparentYes, thanks for that comment. As a relative layperson, I would describe all of this as dangerous territory. reply barapa 13 hours agorootparentprevThanks for the advice! reply AlbertCory 16 hours agoparentprevthat&#x27;s the standard defense we used at Google. It&#x27;s like a trial but without a courtroom. Briefs and answering briefs. Not for amateurs. reply jacobgorm 14 hours agoprevFriends of mine ran a site called Hotpeople.dk from around 2002 that seems like it would be prior art, see https:&#x2F;&#x2F;ekstrabladet.dk&#x2F;nyheder&#x2F;samfund&#x2F;article4805511.ece . reply qingcharles 14 hours agoparentThe headline translates amusingly in Google \"Undressed young people show themselves online\".I was going to say that the original Hot or Not predates your friends&#x27; site, but Wikipedia has prior art for that too:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hot_or_Not#Predecessors_and_sp... reply siliconc0w 14 hours agoprevShown HN: I made a tool to help visualize patent claims - here is the patent in question https:&#x2F;&#x2F;recurveip.com&#x2F;claims&#x2F;8655715(tool is still WIP, if you&#x27;re interested I would love to get your thoughts) reply Kwpolska 14 hours agoparentThe diagram is hard to read and doesn’t add anything over the text of the claim. reply siliconc0w 14 hours agorootparentAgreed it could use improvement, I&#x27;m working on fine-tuning the model to create better diagrams (this is using the latest 3.5 turbo model which typically requires a couple iterations before it gets to a valid diagram). reply rpigab 14 hours agoprevThe Fine Bros youtube channel tried to patent reaction videos. reply m3kw9 15 hours agoprevWhat about the idiots that allowed this patent? reply btrettel 14 hours agoparentFormer patent examiner here.Getting angry at the examiner when the patent stinks is similar to getting angry at programmers when the application stinks. Often, it wasn&#x27;t the programmer&#x27;s fault. Management didn&#x27;t give them enough time, for example, so the programmer did the best they could given the time constraints.And that&#x27;s exactly what happens at the USPTO. Many examiners understand that patent quality is a problem, but USPTO management simply doesn&#x27;t give examiners enough time to do a quality job. Mistakes will happen. reply chrismorgan 2 hours agorootparentBut also often when the application stinks, it’s because the programmer was incompetent. reply ametrau 3 hours agorootparentprevI think by idiots they mean the org collectively reply yieldcrv 16 hours agoprevokay since these arent going to to away, lets try something else:one stop gap solution would be making it more streamlined and standardized to make a licensethese are antagonistic tolls because the conditions are onerousyou do something ambitious and lucrative, patent owner comes out of the woodwork and says “cease doing that”, “pay me this toll” or “cease doing that and pay me this toll” or “pay me this toll and continue doing that”and you’re like “no, thats ridiculous, have fun in court” and then they go have fun in court and you freak outits a state sanctioned monopoly, the state should standardize how the licensing is done. a model uniform patent license, almost like an insurance model that businesses pay into maybe even from existing fees, where patent holders file claims to that insurance pool reply zw123456 17 hours agoprevDear eff.org, I am informing you that you are in violation of intellectual property laws by having a contest for \"The Stupidest Patent of the Month\" you are infringing on the property rights covered by patent No. 8,655,715 which covers all such contests. reply GuB-42 14 hours agoprev [–] The EFF and similar organizations often voice their opposition against the patent system.But why couldn&#x27;t the EFF use the flaws of the patent system to their advantage.They could file all kinds of patents for things they oppose. DRM schemes, surveillance and tracking tech, dark patterns, etc... And then patent troll companies that use these techniques.Win&#x2F;win. If they lose their lawsuit, it creates a precedent against patent trolls. If they win, that&#x27;s one less of the things they are against. reply dbspin 14 hours agoparentThink it through - there are a literally infinite number of such potentially patentable non-innovations. And such lawsuits are expensive and time consuming. Meanwhile the bar to entry for patent trolls is extremely low. That would be and endless futile game of whackamole. reply GuB-42 10 hours agorootparentThe idea here is mostly for the EFF to be the patent troll.But unlike most patent trolls who prey on companies producing useful things, the EFF would attack companies making things that shouldn&#x27;t be done (according to the EFF).For example, let&#x27;s have the EFF patent ad banners with a close button that is too small to click. If the patent is granted (unlikely but let&#x27;s imagine it is), the EFF can then threaten sites with such an ad banner with a patent lawsuit. Hopefully discouraging websites from using such tactic. reply oh_sigh 14 hours agoparentprev [–] Patent trolls definitionally don&#x27;t produce anything, so aren&#x27;t going to run afoul of other patents. Squatting on shitty patents might be a good idea to prevent them from ever getting into a troll&#x27;s portfolio, but it might be a good idea just to put the money towards invalidating patents that the biggest trolls use to extort money out of companies. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Contest Factory has filed multiple lawsuits against companies organizing online contests, asserting that their patents cover a broad range of online contests.",
      "The Electronic Frontier Foundation (EFF) argues that these software patents harm people's right to express themselves and participate in online culture.",
      "The EFF believes that such patents should not have been granted and advocates for a more accessible process to challenge these patents."
    ],
    "commentSummary": [
      "The Electronic Frontier Foundation (EFF) has raised concerns about a patent called \"Selfie Contests\" and argues that simply adding the words \"on a computer\" to an everyday activity should not be patentable.",
      "The discussion focuses on issues such as prior art, obviousness, patent trolling, and the process of invalidating patents.",
      "Various suggestions are made, including the use of lawyers or a formal process for requesting invalidation, but the complexity and cost involved are acknowledged. Examples of prior art and questionable patent approvals are also mentioned."
    ],
    "points": 171,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1703519513
  },
  {
    "id": 38764353,
    "title": "TKey: The USB Stick Computer for Secure Applications",
    "originLink": "https://dev.tillitis.se/intro/",
    "originBody": "Introduction # The Tillitis TKey is a small computer in a USB stick form factor that can run small device applications that are loaded onto it. The purpose of the TKey is to be a secure environment for applications that provide some kind of security function. Some examples of such security functions are: Time-based one-time password (TOTP) token generators Signing oracles Secure random numbers Encryption There is no way of storing a device application (or any other data) on the TKey. A device app has to be loaded onto the TKey every time you plug it in. TKey specifications # 32-bit RISC-V CPU running at 18 MHz Execution monitor Hardware-assisted address randomization and RAM scrambling 128 kiB RAM for TKey device applications 2 kiB firmware RAM 6 kiB ROM True random number generator USB CDC (Communications Device Class) over a Type-C connector Timer Two levels of hardware privilege modes: firmware mode and application mode CPU-controlled LED No persistent storage Note well: In the end-user version (not TKey Unlocked) the FPGA configuration is locked down. This means you cannot change the FPGA bitstream or read out the bitstream (or the Unique Device Secret, UDS) from the configuration memory, even if you break the case and insert it into a programmer board. Measured boot & secrets # A unique feature of the TKey is that it measures the loaded device application before starting it. A hash digest measurement (using BLAKE2s) combined with a Unique Device Secret (UDS) makes up a base secret we call a Compound Device Identifier (CDI) which can then used by the TKey device app. If the TKey device app is altered in any way the CDI is also changed. If the keys derived from the CDI are the same as the last time the given device app was loaded onto the same TKey the device app’s integrity is guaranteed. The UDS is unique per TKey. The same device app loaded onto another TKey results in a different CDI. The key derivation can also include a User Supplied Secret (USS). Then the keys are based on both something the user has – the specific TKey – and something the user knows – the USS. This is the algorithm for the CDI: cdi = blake2s(UDS, blake2s(device_app), USS) All of the TKey software, firmware, FPGA Verilog source code, schematics, and PCB design files are released under open source/hardware licenses, like all trustworthy security software and hardware should be. This, in itself, makes the TKey different, as other security tokens use at least some closed source hardware for security-critical operations. Getting Started # Get started using your TKey. Tools & Libraries, setup and introduction for application developers. Tkey Unlocked, instructions for the provisioning process",
    "commentLink": "https://news.ycombinator.com/item?id=38764353",
    "commentBody": "TKey is a RISC-V computer in a USB-C case, that can run security applicationsHacker NewspastloginTKey is a RISC-V computer in a USB-C case, that can run security applications (tillitis.se) 168 points by jandeboevrie 16 hours ago| hidepastfavorite68 comments anishathalye 9 hours agoThis is really neat!We&#x27;ve been working on some research to formally verify the hardware&#x2F;software of such devices [1, 2]. Neat how there are so many shared ideas: we also use a PicoRV32, run on an iCE40 FPGA, use UART for communication to&#x2F;from the PicoRV32 to keep the security-critical part of the hardware simple, and use a separate MCU to convert between USB and UART.Interesting decision to make the device stateless. Given that the application keys are generated by combining the UDS, USS, and the hash of the application [3], it seems this rules out software updates? Was this an intentional tradeoff, to have a sort of \"forward security\"?In an earlier project I worked on [4], we had run into a similar issue (no space for this in the write-up though); there, we ended up using the following approach: applications are _signed_ by the developer (who can use any keypair they generate), the signature is checked at application load time, and the application-specific key is derived using the hash of the developer&#x27;s public key instead of the hash of the application. This does have the downside that if the developer is compromised, an adversary can use this to sign a malicious application that can leak the key.[1]: https:&#x2F;&#x2F;github.com&#x2F;anishathalye&#x2F;knox-hsm [2]: https:&#x2F;&#x2F;pdos.csail.mit.edu&#x2F;papers&#x2F;knox:osdi22.pdf [3]: https:&#x2F;&#x2F;tillitis.se&#x2F;blog&#x2F;2023&#x2F;03&#x2F;31&#x2F;on-tkey-key-generation&#x2F; [4]: https:&#x2F;&#x2F;pdos.csail.mit.edu&#x2F;papers&#x2F;notary:sosp19.pdf reply kfreds 1 hour agoparentThank you. Interesting paper!As you&#x27;ve already noted the TKey&#x27;s KDF is Hash(UDS, Hash(TKey device app), USS), which means every device+application combination gets its own unique key material. As you conclude this means an update to the loaded application changes the key material, which changes any public key the application might derive. This is a hassle and not very user friendly.However, nothing prevents the loaded application (A1) to load another application (A2) in turn. This is a key feature, as it allows A1 to define a verified boot policy of your choice. The immutable firmware would do the KDF using A1&#x27;s machine code. A1 running accepts a public key, a digital signature and A2 as arguments. A1 measures the public key as context, verifies the digital signature, and then hands off its own contextualized key material to A2. In this example A1 is doing verified boot using some policy, and A2 is the application the end user uses for authentication: FIDO2, TOTP, GPG, etc.Regarding key compromise of the developer&#x27;s key you might want to look into transparency logs. Another project I&#x27;m a codesigner or is Sigsum - a transparency log with distributes trust assumptions. We recently toggled it v1, and it should be small enough to fit into a TKey application. We haven&#x27;t done it yet though. Too many other things to do. :) reply pierrelf 1 hour agoprevStoked to see Tkey back on the front page! Bought one when it launched and it&#x27;s been great fun tinkering with my own apps using their Go library, and the community seems pretty active.Also hardware wise the new injection molded case is a huge step up!I&#x27;m really hoping for fully fledged FIDO2 support soon, perhaps on android aswell? reply kfreds 15 minutes agoparentThank you for your support! I&#x27;m pleased to hear you&#x27;ve been tinkering with it. We&#x27;re working on FIDO2 and will get there one way or another. The current TKey uses CDC ACM as USB device class, which presents some compatibility challenges. I suspect we&#x27;ll have to change that to USB HID FIDO2, possibly with additional endpoints to simultaneously support loading of applications from the host. We&#x27;ll get there. :) reply rwmj 14 hours agoprevWhich FPGA are they using?Edit: There&#x27;s a lot to like here, but a lot that is confusing. An FPGA based version of PicoPV32 could be really secure. Your attack vector would be the FPGA vendor doing something at the hardware level (hard to pull off), or the toolchain being compromised.But what FPGA it is matters, also what toolchain they are using to programme the FPGA (yosys is not mentioned ...). The whole \"locked down\" FPGA bitstream sounds very fishy as well.PicoRV32 does fit into Lattice FPGAs and they are fully reverse-engineered and supported by yosys. reply kfreds 13 hours agoparentFPGA: Lattice ice40up5kToolchain: Yosys.For the convenience of most end users we configure and lock the FPGA. This allows them to start using it right away. The core cryptographic technology relies on a Unique per Device Secret (UDS). If we didn&#x27;t lock the FPGA&#x27;s configuration memory from reads a physical attacker would be able to read it out in seconds.Users that want to provision their own hardware design &#x2F; FPGA configuration &#x2F; bitstream can simply buy the TKey Unlocked and the TKey Programmer. They can then configure the on-die OTP NVCM and lock the FPGA themselves. Configuration and locking of the ice40up5k was not possible to do with open tooling until we made it happen, as part of the project to create the TKey.Since you seem knowledgeable it might interest you that:* The OTCP NVCM uses antifuse technology, so it&#x27;s most likely not possible to read out the UDS with an electron microscope. The physical attacker will have to circumvent the locking mechanism and read out the NVCM through probing.* One of the pins can be used to toggle SPI slave configuration mode even after NVCM has been configured and locked. This allows a physical attacker to configure their own bitstream. Unfortunately EBR and SPRAM also keep their state across warm reboots. As mitigations we (1) store the UDS in LCs until it is used by the KD, (2) use our TRNG to randomize when the UDS readout happens, (3) accelerate the hashing (Blake2s G function) in LCs, (4) randomize address and data layout using a non-cryptographic PRP, and some other things I don&#x27;t remember at the moment. Depending on the user&#x27;s security concerns we recommend the use of a user-supplied secret in addition to the UDS. In that case the TKey by itself doesn&#x27;t contain all the key material, making a physical attack insufficient. The KDF can be read in the manual.Edit: Clarified _physical_ attacker. Added details about the chip. reply 70rd 12 hours agoparentprevSupply chain attacks can be mitigated with \"golden chip analysis\", you destructively analyse a known good chip after measuring various power and timing benchmarks across adversarial configurations, and repeat those measurements across all future chips and check they are within margin of error. reply wslh 13 hours agoparentprevGenuine question: how many transistors and&#x2F;or logic gates do we need to perform ECDSA and feel more secure than using FPGA or other security elements? I see that security elements used by Ledger crypto wallets is the [1] and an ASIC one would be better to reduce the attack vector? But do they could have memory inside or just cache? I don&#x27;t know too much about electronics.[1] https:&#x2F;&#x2F;octopart.com&#x2F;stm32wb55ccu6-stmicroelectronics-100293... reply kfreds 13 hours agorootparentThe answer is, as always, it depends. I&#x27;ll do my best to characterize the problem:If we only care about minimizing logic gates we could use SERV, the world&#x27;s smallest RV32 core, and run a bare metal ECDSA implementation on it. Let&#x27;s use it without the M extension, so RV32I. I&#x27;m not sure what SERV&#x27;s max clock frequency is, but assuming we configured it on the ice40 and it runs at 40 MHz I&#x27;m guessing a single ECDSA signature would take hours to comput.Due to the math involved in ECC it is quite challenging to make a \"hardware-only\" ECC signer. The ones I&#x27;ve seen are effectively ECC accelerators with some kind of state machine or microcode to run the algorithm.In the case of TKey we use picoRV32 configured as RV32ICZmmul (multiply without divide). We use the FPGA&#x27;s DSPs to accelerate multiplication. On the TKey an Ed25519 signature takes less than a second, which we believe is acceptable for many use cases, and I&#x27;m willing to bet there is no Ed25519 signer that is more open source hardware and software than the TKey.As GP points out using an FPGA is in fact an excellent way to mitigate various supply chain attacks. It&#x27;s like hardware ASLR, to paraphrase bunnie in his CCC talk. reply wslh 12 hours agorootparentThank you! BTW I assume you will support U2F, Crypto, etc in the future? or do you expect third parties to develop on it?From a quick glance at the product it seems I should buy the unlocked to have full control of the device and in the future could be a device with a display and some more sensors and&#x2F;or buttons to know what I am signing in?I am currently in South America so waiting to travel to one of your shipping locations to buy several TKeys. reply kfreds 12 hours agorootparentI believe we already have a U2F prototype for Linux. In general we are quite selective about which applications we take on development and maintenance responsibilities for.Given that this is the most open source hardware USB authenticator we hope the communities that value this level of openness, design assurance and design verifiability will adopt the TKey and build whatever applications they need for it. Having said that we see lots of opportunities for us to make it easier for developers to build what they need. replykfreds 13 hours agoprevI created the TKey together with my colleagues. AMA. :) reply sowbug 6 hours agoparentWould appreciate it if you tested for compatibility on a Chromebook running Linux via Crostini. The Crostini distro is fairly ordinary Debian, but Crostini has an unusual system mediating USB-device access, so it&#x27;s hard to predict whether any given device or device feature will work.(And even if a feature works today, it might break tomorrow. It&#x27;s too bad the Chrome OS team doesn&#x27;t appear to dogfood with Yubikeys, for example; GnuPG smart cards will work for a few CrOS releases and then inexplicably break for months&#x2F;years. VSCode runs amazingly well on a Chromebook, but if I can&#x27;t reliably sign a git commit, it doesn&#x27;t matter.) reply kfreds 1 hour agorootparentThe TKey enumerates as a CDC ACM (serial port) to the host, so I&#x27;m afraid it doesn&#x27;t work on the Chromebook from what I can remember. My colleagues would know better. In any case it&#x27;s something we aim to support one way or another, even it if means a new hardware.I suspect using Yubikey&#x27;s FIDO2 functionality rather than its GnuPG smart card functionality would be reliable. I think Crostini&#x27;s motivation comes down to security, which they enforce by only passing through certain USB device classes. A device enumerating as USB HID FIDO2 should work reliably, given that Google uses those kinds of USB authenticators internally. reply ecesena 9 hours agoparentprevVery cool project, will certainly dig deeper!If you need code for u2f&#x2F;fido2 I hope you can find something useful from our solokeys (v1 for C, v2 for rust). https:&#x2F;&#x2F;github.com&#x2F;solokeysP.S: the usbc plug looks a bit brittle (been there). not sure about your plans to scale production but you prob want to address that sooner rather than later :) reply kfreds 1 hour agorootparentThank you! I absolutely what you&#x27;ve done with the Limited Edition Solo 2. The epoxy + nail polish and exposed PCB is a great artistic expression of the openness of the device. I appreciate the tip about the USB-C plug. As I recall we&#x27;ve improved the structural integrity through the case and glue. reply adastra22 10 hours agoparentprevWhat assurance do I have (I&#x27;m speaking cryptographically) that the per-device secret isn&#x27;t known to you? reply kfreds 10 hours agorootparentNone. You&#x27;ll simply have to trust that we have configured your TKey with a UDS of good entropy, and that we haven&#x27;t saved it - intentionally or unintentionally.However, the device&#x27;s flexibility allows you considerable control. For instance you could have its KDF mix in a user-supplied secret in addition to the UDS.Of course you&#x27;d still be trusting that the device actually performs the KDF we claim it does. That&#x27;s why we also sell the TKey Unlocked. reply adastra22 10 hours agorootparentSeems like that secondary derivation is something that can be attested to, if it is done homomorphically. reply xw3089 10 hours agoparentprevGenuinely curious, what’s the argument for locking down the FPGA? reply kfreds 10 hours agorootparentTo protect the UDS that we provision for you. See my other responses in this thread for more details. Also see the TKey Unlocked. reply daneel_w 8 hours agoparentprevFor security-only end-user applications, what are the benefits from spending €80 on your device instead of €60 on a Yubikey 5? reply kfreds 1 hour agorootparentIt depends on what you value. If you want a computer that can produce Ed25519 signatures with a minimum of software and hardware complexity and a maximum of inspectability then you probably can&#x27;t do better than a TKey.Yubikey on the other hand have a lot more features than TKey, for now. reply thewanderer1983 4 hours agoparentprevCan you consider OpenBSD support? reply kfreds 1 hour agorootparentYes. :) reply fsflover 12 hours agoparentprevHow is it better than Precursor? https:&#x2F;&#x2F;www.crowdsupply.com&#x2F;sutajio-kosagi&#x2F;precursor reply kfreds 12 hours agorootparentWhether TKey or Precursor is better depends on your needs. Here are some differences between them:* TKey uses open tooling for everything. Precursor uses Vivado.* Precursor has a screen and a keyboard, allowing the user to interact directly with the trusted device in a completely different way than the TKey.* The Precursor is bigger than the TKey.* The Precursor costs much more than the TKey.Finally I&#x27;d just like to mentiont that bunnie and xobs work on Precursor as well as their other projects have been a great inspiration to the TKey project. reply fsflover 12 hours agorootparentThank you! reply INTPenis 12 hours agorootparentprevI&#x27;m not affiliated with either but I just looked at the precursor page because I&#x27;m a huge nerd and love crowdfunded projects.They seem to be in slightly different leagues. Tkey is small and meant to be easily carried with you to authenticate with ssh, gpg and more. While precursor is a full development board that can probably do everything tkey can, and more. reply 70rd 11 hours agorootparentprevDifferent product at a different price point with different objectives. Security keys are suitable for mass deployment across an entire workforce, precursor aims to be a launchboard for general purpose secure and trustable computation. Even at mass production prices, precursor would likely still cost more than 100$. reply rdl 14 hours agoprevIf they could add some hardware tamper-evidence&#x2F;tamper-response (design-to-meet FIPS 140-3 level 3 or EAL whatever, although no need to actually get certified), this could be super useful as a cheap application-specific HSM (which can run app logic inside, rather than the lobotomized&#x2F;zombie signing oracle PKCS \"HSM\" use which is common.)Obviously can prototype without this functionality, and can build out the toolchain&#x2F;etc. I&#x27;m a lot more excited about Tropic Square than most alternatives, but this is shipping now. reply kfreds 11 hours agoparentRegarding FIPS 140-2 level 2 tamper evidence and level 3 tamper response I&#x27;m interested to hear what you (and others here on HN) value and why.Level 2 can be accomplished with nail polish and glitter, or plastic potting. Yubikey&#x27;s potting is a good example of level 2 tamper evidence.For level 3 tamper response, e.g. of a rack-mounted server case, it is enough to put micro-switches under the lid. For that type of product level 2 tamper evidence could be accomplished by covering the server case&#x27;s screws with copper cans stamped with serial numbers.When I first learned what is actually required for FIPS 140-2 level 2 and 3 I thought it was security theater. Then I realized that in practice such a server case will be (1) in a locked server cabinet, in a server room with access control, within a building with access control. Add a two-person requirement for entering the room and unlocking the cabinet, and the attacker will have to be quite sophisticated and capable to not be discovered way before any tamper evidence or tamper response comes into play.In other words, if you don&#x27;t care about FIPS for regulatory reasons, or insurance reasons, or company policy reasons, then how much does level 3 tamper response really matter?Regarding CC EAL, I&#x27;ll simply say that I don&#x27;t believe there is any other hardware security product that is more open source hardware and software than the TKey. Thanks to it being FPGA-based it is somewhat protected from various attacks on the supply chain. If you&#x27;re looking to do an Ed25519 signature I don&#x27;t believe there is a single device more simple or easily verifiable than the TKey and it&#x27;s Ed25519 signer application. I&#x27;d love to be proven wrong. reply rdl 8 hours agorootparentI was at ACM Copenhagen although more downstairs at ASHES (which my company sponsored) and DeFi. Ryan Hurst who was there is probably the best person to ask about the specific certification use cases.But overall -- I work for an insurer. Having to document how something was done a year+ after it was done to convince auditors&#x2F;insurers&#x2F;large clients is a LOT easier if you can point to a specific piece of hardware vs. a bespoke process. The downside of not having tamper-evidence or tamper-response (ideally) at the hw level is you need to build a lot of other controls around it, and that is expensive, impractical, and difficult to document in a lot of environments. e.g. in a datacenter it&#x27;s unlikely you can enforce \"two man from security&#x2F;senior executive team in the cage\"; it&#x27;s probably going to be (at best) two ops staff, often contractors, and two-man rule isn&#x27;t actually that widely used outside CAs themselves. The use cases I&#x27;d like for this are application logic, not traditional CAs (who do need FIPS). Add to this lifecycle management of the hardware from production to pickup&#x2F;delivery to provisioning, pre-deployment storage, deployment, operation, routine audit, replacement, audit, and decommissioning, and it&#x27;s way easier to put protection into the module. Most of the time I&#x27;ve just seen hardware protection inherited from single-chip vs. module-level protection created, but if there&#x27;s no certified IC available, module protection it is.Actual FIPS certification would be nice (or a better standard), but challenging in deployment because almost every vendor FIPS certifies with a specific application load and as soon as you run custom applications (which is badly supported in the HSM world), you lose certification anyway. \"FIPS rated hardware running a non-FIPS load, audited in appendix A\" is insurable, but ideally there would be something better. 99+% of HSM deployments are just used as dumb key signers which are trivially exploitable when you pop the host, though, so I&#x27;d certainly take the non-FIPS option.(Today, the state of the art is pretty much SGX or another TEE on the host running custom application logic to evaluate and instruct signing which talks to the FIPS HSM to do key control and actual signing, e.g. what Anchorage does.) reply mongol 4 hours agoprevI don&#x27;t understand the usecase. If the application is loaded from the host, why is this better than the host running the application directly? reply AgentME 2 hours agoparentThe program running on the device is able to access a special Compound Device Identifier secret, which is only available by running that specific program on that specific device. Any different program you run on the device gets its own unique CDI secret, so it&#x27;s not possible to load a secret-dumper program onto the device and grab the CDI available to a different program.You could use the device to implement a TPM&#x2F;HSM with application-specific logic, even like a cryptocurrency wallet. A program on the device could be made to generate its own private keypair using the CDI, announce the public key to the connected device, and offer to sign messages using its keypair under some specific conditions enforced within the program. reply treyd 15 hours agoprevI&#x27;m kinda skeptical of security devices like this that don&#x27;t have their own screens that let you know what you&#x27;re authenticating. Obviously there&#x27;s some applications where it&#x27;s fine but if the PC it&#x27;s plugged into is compromised it could be MITMing the auth. reply kfreds 10 hours agoparentIt&#x27;s a trade-off.We&#x27;ve thought about adding a screen to a future product, but it begs the question of how much information you want displayed in order to make your authentication decision.And even if a screen gives you more information, are you authenticating an action where the cryptography terminates in the device? If you are authenticating an SSH session for instance, the screen helps you ensure you are authenticating a login to the right server. Once you have authenticated though, nothing prevents the attacker in your local machine from using the established SSH connection. reply lxgr 3 minutes agorootparentVery good point. \"What you see is what you sign\" is a powerful property, but it does often need some support on the side of the signature verifier to make it possible.Reading through an entire email (maybe MIME multipart encoded) on a small OLED screen isn&#x27;t fun; on the other hand, something like \"confirm transfer of €x to IBAN y from your account z\" would be great – but needs support of your bank.That support is incredibly hard to get. Android has supported \"protected confirmation\" [1] for many years now (on Pixel devices), but I have yet to see support for it by any real-world service I&#x27;m using, and I&#x27;m not holding my breath, since I can&#x27;t even use FIDO with any of my banks...[1] https:&#x2F;&#x2F;developer.android.com&#x2F;privacy-and-security&#x2F;security-... reply fmajid 13 hours agoparentprevHave a look at Bunnie Huang’s Precursor project, but it’s much more expensive. reply gorkish 14 hours agoparentprevYes agree the end user needs feedback at the authenticator. This device has an RGB LED and a touch sensor, so there are still some possibilities. reply rdl 14 hours agorootparentI&#x27;d put a key inside my app which then talks out of band to multiple devices (including maybe a trusted one?) -- e.g. \"run app on the device, request input using the directly-connected PC, message tunneled out to my phone for confirmation\")A screen and 2-3 buttons would be nice, though; also a tamper-evident&#x2F;tamper-responding package. But my main desired use case for this is a lightweight app-specific HSM so I&#x27;d just need to validate integrity of device before connecting it to host. USB Armory II is the main alternative. reply wepple 14 hours agoprevCan anyone comment on the design decision to not store device firmware? Is this common?I would’ve assumed it would generally be safer to have permanent but updatable firmware, to reduce the attack surface of malicious firmware loadings reply kfreds 12 hours agoparentSure. Specifically regarding not storing firmware: The TKey does have roughly 6 KB of immutable firmware which is responsible for loading device applications sent by the host. This firmware receives and then hashes the application together with the Unique per Device Secret. The resulting hash is handed to the loaded application as key material, which is now unique per device+application combination. This model doesn&#x27;t prevent storing applications on the device, but to enable the user to have flexibility to load other apps we would need to change things a bit.Regarding security: This is a question of measured vs verified boot. Until the TKey, users of USB authenticators had to choose between security and flexibility. Yubikey is not updatable at all, but several USB authenticators have updatable firmware using signed firmware updates. Some of them are open source software, and of those a few are open source hardware in the sense that they provide BOM, schematics and PCB design. We do all of the above, and in addition we provide the HDL &#x2F; \"chip design\" &#x2F; FPGA configuration. In any case, having a USB authenticator which is updatable using a signed update begs the question of who is allowed to sign updates, which then leads to central control and a long tail of interesting use cases not being signed. TKey aims to combine security, openness and flexibility. We accomplish this thanks to unconditional measured boot as a KDF, as opposed to verified boot.There is more information on our website. reply wepple 14 hours agoparentprevI guess as a follow-up, you possibly can’t actually “update” firmware for this, without it creating entirely new keys that would have to be registered with every application reply kfreds 11 hours agorootparentYou&#x27;re mostly correct. The immutable firmware derives unique key material for each device+application combination. However, nothing prevents the loaded application from loading another application. This allows the developer to construct their own update logic. For instance, the first application could simply exist to verify a digital signature over some hash, then load an application, hash it, compare it to the trusted hash, and then execute it. The first application could hand over its own key material. reply josephcsible 14 hours agoprev> Note well: In the end-user version (not TKey Unlocked) the FPGA configuration is locked down. This means you cannot change the FPGA bitstream or read out the bitstream (or the Unique Device Secret, UDS) from the configuration memory, even if you break the case and insert it into a programmer board.That seems like it&#x27;s only useful for \"security\" against the owner, rather than for any legitimate form of security. reply FiloSottile 13 hours agoparentThat&#x27;s the whole point of a TKey as a security device: the secret available to an application depends on both the device it&#x27;s running on and the application, and can&#x27;t be extracted, so you can do things like \"sign a blob only if it follows these rules\" and enforce it in hardware. If the device wasn&#x27;t locked, you could just... change the rules.How is that not a legitimate form of security? reply josephcsible 12 hours agorootparentIf it&#x27;s my device, then I should be able to change the rules. reply teruakohatu 11 hours agorootparentIf you can change the rules then someone else can also change the rules.And any ability to change the rules will greatly increase the surface area of attack. reply kfreds 11 hours agorootparentprevYou&#x27;re more than welcome to change the rules. Please read my other comments in this thread, and you&#x27;ll hopefully find answers to your concerns. The TKey Unlocked gives you all the control you&#x27;re asking for. reply ooterness 11 hours agoparentprevBuy the unlocked version, program it and lock it down yourself. reply AVincentInSpace 14 hours agoparentprevHow so? reply josephcsible 14 hours agorootparentConsider a DRM system that does challenge&#x2F;response against said secret so that only one computer at a time can use something. As the owner of this device, if I want to clone it, I should be able to. reply charcircuit 12 hours agorootparentBut then the device could be used by 2 computers at once defeating the security. Another use case would be as a second factor of authentication. Making it impossible to clone is essential for a \"something you own\" factor. reply its-summertime 13 hours agorootparentprevYou can buy an unlocked version and clone it, no? reply 5- 11 hours agoprevhardware wise, looks to be a usbc version of fomu.https:&#x2F;&#x2F;www.crowdsupply.com&#x2F;sutajio-kosagi&#x2F;fomu reply kfreds 11 hours agoparentOne major difference between TKey and Fomu is that Fomu uses the ice40 for USB hardware logic as well as USB device firmware. TKey uses a dedicated USB chip (CH552, which comes with open source firmware).Fomu could likely not fit USB logic as well as the security-related cores we have. That, and the fact that we don&#x27;t want the attack surface of the USB firmware running in the same core that handles the KDF.They are very different products for very different use cases. reply daneel_w 8 hours agorootparentSo that would be the Chinese WinChipHead CH552. You have surely vetted the firmware, but what about the hardware?I understand that for some people this is an agitating stance and question to ask, but it&#x27;s after all a security-focused USB device meant to be plugged into users&#x27; computers. reply 5- 11 hours agorootparentprevthanks, that&#x27;s an important distinction.i like the conceptual purity of fomu, but it does take quite a bit of work to get to the point of talking to it over usb. reply kfreds 10 hours agorootparentSame here. It was a source of inspiration when we started working on the TKey.Could you expand on what you mean by \"take quite a bit of work\". I thought Fomu came preconfigured? reply 5- 10 hours agorootparentyes, sorry, i was referring to writing gateware from scratch. you have to implement a usb device before you get past a blinky. reply kfreds 10 hours agorootparentRight. Speaking of which, do you have any recommendations for good USB cores? reply7e 13 hours agoprev\"There is no way of storing a device application (or any other data) on the TKey. A device app has to be loaded onto the TKey every time you plug it in.\" reply goodpoint 15 hours agoprev [–] Way too expensive. reply rdl 14 hours agoparentQty 1, $80 seems tolerable for a dev device. They should explicitly list 10 for $500 and 100 for $3000 or something though.This is competing with $5-30K HSMs as well as $30-400 \"hardware wallets\" or second factor keys, as well as (free) embedded secure enclaves. reply rwmj 14 hours agoparentprevI would guess because of the FPGA. The advantage is it&#x27;s (somewhat, arguably) more secure than a RISC-V ASIC from some random vendor. reply charcircuit 12 hours agorootparentDo not forget that they also need to recoup the $$$$$ spent getting it certified. For niche electronics this can be a big percentage of the price. Making something into an actual commercial product, especially globally, results in extra markup. reply SpaceNoodled 15 hours agoparentprev [–] And they couldn&#x27;t even put application ROM on there. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Tillitis TKey is a USB stick computer specifically made for running secure applications that offer various security features like encryption and token generation.",
      "It comes with a 32-bit RISC-V CPU, hardware-assisted address randomization and RAM scrambling, and no persistent storage.",
      "The device ensures the integrity of the loaded application by measuring it using a Unique Device Secret (UDS) and a Compound Device Identifier (CDI), and all of its software and hardware designs are open source."
    ],
    "commentSummary": [
      "The discussion centers around the TKey, a RISC-V computer in a USB-C case that can run security applications.",
      "The TKey is stateless and uses a key derivation function to generate unique key material for each device+application combination.",
      "It supports loading other applications, verified boot policies, and addresses key compromise through transparency logs.",
      "Note: The discussion also includes:",
      "Mention of authentication methods like FIDO2, TOTP, and GPG.",
      "Challenges of compatibility and hardware security.",
      "The project Sigsum for distributing trust assumptions.",
      "The use of FPGA technology to mitigate supply chain attacks.",
      "Comparison of TKey to other devices like YubiKey and Precursor.",
      "Importance of tamper evidence and tamper response in hardware security.",
      "Challenges of FIPS certification.",
      "Risks and practicality of using security devices without screens.",
      "Desire for lightweight app-specific HSMs.",
      "Cost of certification for niche electronics.",
      "Additional markup involved in commercialization."
    ],
    "points": 168,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1703525177
  },
  {
    "id": 38764452,
    "title": "Achieving Reproducibility in Git Backups by Forcing Single-Threaded Execution",
    "originLink": "https://baecher.dev/stdout/reproducible-git-bundles/",
    "originBody": "Home Reproducible git bundles December 2023 As part of a backup script for my entire system I wanted to back up all my git repositories. Some of them don't have a remote anywhere, so I cannot rely on implicit backups in The Cloud. The naive solution of simply backing up the entire file-system tree is clearly not desirable since that would clutter the backup with useless build artifacts. One solution is to create a fresh clone (with --mirror), but that will typically consist of many small files which isn't ideal for backups, either. Conveniently git can create a single-file archive of a repository via git bundle create which appears to be the perfect fit for backups. After a few test runs of my backup I noticed that a small but fixed subset of repositories are getting backed up despite having no changes made. That is odd because I would think that repeated bundling of the same repository state should create the exact same bundle. However: $ git bundle create -q /tmp/a --all $ git bundle create -q /tmp/b --all $ md5sum /tmp/a /tmp/b 44891a87b08b75c1b518889fcba73204 /tmp/a a37a81710313cdbb5f065ddb2c797630 /tmp/b Huh? Turns out that for some repositories bundling is nondeterministic. After browsing some vaguely-related Stackoverflow answers and several AI hallucinations later I decided to dig into the bundles to see what the differences are. Bundling reorganizes all git objects into a single pack, which is an internal git data structure to aggregate many objects into one file and apply some optimizations like delta coding along the way. Both bundles contained a single pack in my case but each pack had a fairly different structure, as revealed by git verify-pack -v! At this point, having looked at many outputs from git bundle create, I had a suspicion: Enumerating objects: 733, done. Counting objects: 100% (733/733), done. Delta compression using up to 8 threads Compressing objects: 100% (598/598), done. Writing objects: 100% (733/733), 97.15 KiB6.48 MiB/s, done. Total 733 (delta 419), reused 0 (delta 0), pack-reused 0 What caught my eye was Delta compression using up to 8 threads—parallelism is a classic source of inherent (as opposed to accidental) nondeterminism. Testing this hypothesis should be quite simple. Having browsed my fair share of git manpages in the past I knew that many commands have a --threads option, but git bundle does not. Luckily any git subcommand can be run with ad-hoc configuration options, and the relevant option here turns out to be pack.threads. $ for i in $(seq 1 100); do \\ > git -c 'pack.threads=1' bundle create -q /tmp/bundle-$i --all; \\ > done $ md5sum /tmp/bundle-*cut -f 1 -d ' 'uniq -c 100 4898971d4d3b8ddd59022d28c467ffca Success! Forcing git to be single threaded makes the output deterministic. In case you are wondering, using just one thread instead of eight does not have any discernible performance impact on my personal repositories, so I'm very happy to trade performance for reproducibility. Return to top",
    "commentLink": "https://news.ycombinator.com/item?id=38764452",
    "commentBody": "Hacker NewsHacker NewsSorry, we're not able to serve your requests this quickly.reload",
    "originSummary": [
      "The author encountered issues with non-deterministic behavior when backing up git repositories.",
      "They identified the bundling process as the cause and resolved it by enforcing single-threaded operation in git.",
      "The trade-off in performance resulted in deterministic output, enabling reproducibility in the backups."
    ],
    "commentSummary": [
      "The popular website Hacker News is currently encountering problems and is unable to handle requests in a timely manner.",
      "Users may experience delays or difficulties in accessing content on Hacker News.",
      "The technical issues impacting the website's performance are currently being addressed."
    ],
    "points": 156,
    "commentCount": 24,
    "retryCount": 0,
    "time": 1703526056
  },
  {
    "id": 38763165,
    "title": "German Courts Affirm User Freedom: Ad-blockers and Copyright Laws",
    "originLink": "https://fsfe.org/news/2023/news-20231220-01.en.html",
    "originBody": "News Unblocking User Freedom: the right to use adblockers on: 2023-12-20 Companies increasingly aim to control how users interact with their content online, threatening user freedom. As more companies crack down on browser extensions and other third-party software used by internet users to customise their experiences, two recent German court cases on adblockers could strengthen the legal case for user control over technology. CC-BY-NC-SA by Rahak Advertisements are a part of our lives, including our digital ones. They are in the websites we browse, the search results we receive, and the online news we read. Tired of receiving so many ads, some users try to avoid them by installing an adblocker. But is this a legal practice? Is using adblockers an act of restricting market autonomy, or do they help achieve user freedom? Imagine a scenario where website owners hold copyright over their websites, including whatever ads they place, and could effectively sue for copyright infringement if users were to remove or suppress ads when visiting these websites. This hypothetical situation would enable any website copyright holder to use the legal system to stop any ordinary user on the internet who tries to bypass these ads. This would lead to an internet where unsolicited information and advertisements are imposed on users. Fortunately, recent court decisions have at least prevented this hypothetical from becoming a reality in Germany. Is it legal to use adblockers? The lawsuit in question Using an adblocker is the main way in which many internet users bypass ads and pop-ups when accessing websites. Adblockers usually come in the form of browser extensions and plugins that filter out unwanted ads for an ad-free internet browsing experience. As the use of these adblockers increases, some companies have begun considering whether it is legal for users to be able to block their ads. This was the case in Germany when Axel Springer SE (Axel Springer), one of Germany’s largest publishing companies, engaged in lawsuits against Eyeo GmbH (Eyeo), the creator of Adblock Plus (a Free Software adblocking tool licensed under the GPLv3). These lawsuits have resulted in a legal battle for user freedom and an open internet. In the case of Adblock Plus, ads are blocked according to filter rules maintained in a so-called “black list”, which users use as a default setting. The extension offers ad providers the possibility of having their ads excluded from this black list (and included in a “white list”) by complying with “acceptable advertising standards”, disclosing their annual turnover, and paying a sum to Eyeo. Users will only see ads that have been included in the white list, but they also have the option of blocking ads from both white and black lists altogether. Axel Springer filed several suits in Germany against Eyeo on the grounds that the Adblock Plus extension interfered with their business, alleging that by blocking its advertisements, Eyeo had engaged in anti-competitive measures. According to Axel Springer, Eyeo’s business model constituted: Targeted obstruction and aggressive business practice; and A violation of freedom of the press. The right not to be advertised to After ruling that the option to use adblockers is a decision that internet users should be able to make, the courts in Germany ruled that user rights not only include the freedom to express an opinion and to receive information, but also the rights to refrain from expressing an opinion and to refuse to receive imposed information. In doing so, the rulings considered a user’s interest in being spared from obtrusive advertising. Accordingly, internet users are simply exercising their right to not have certain forms of advertising displayed when visiting internet websites when they choose to make use of an adblocker. Adblock Plus’s business model, according to the courts, was therefore a marketable service offer which was not primarily aimed at impairing the competitive development of Axel Springer. In the opinion of the courts, Adblock Plus also does not directly interfere with the business, as users retain autonomy to do as they wish with the settings of the add-on after installation. Users can block or wish to see only the ads in the whitelist. Adblock Plus is therefore merely a product whose use is decided solely by the internet user. The HTML argument: does the use of adblockers constitute a modification of a computer program? Axel Springer also submitted an argument to the German courts that their websites would be protected under German copyright law as a copyrighted computer program, and that their HTML code would similarly be covered under this ambit because of the control components it included. Because of how Adblock Plus interacts with its website, Axel Springer therefore claimed that copies and adaptations of the code in its website were violations of copyright made without permission. In both the initial court ruling and the decision on the subsequent appeal in favour of Eyeo, the court disagreed with Axel Springer and held that the use of Adblock Plus solely affects the program flow through external commands, without altering the program’s essence or generating a changed version. Thus, the use of the extension results in a mere browser configuration carried out by users according to their preferences. The courts noted that internet users do not require permission from website owners when they want to make the website look better for themselves. Modern websites are made up of many separate parts that can be technically distinguished from each other, including text, images, and videos, as well as software that is embedded in the HTML page. For the courts, it wasn’t enough that these software components were used in the website’s HTML page to mean that the website itself was a protectable computer program. We can therefore infer that adblockers do not infringe upon a program’s protections. Downsides of the case Nevertheless, some aspects in the judgments are still not ideal in promoting the average user’s rights. While user freedom means that users are able to use the tools that they wish to when browsing the World Wide Web, the court nevertheless preserved Axel Springer’s right to exclude users with an activated adblocker from accessing its content. This can be understood as an approval on the use of adblock detection tools by companies like Axel Springer. Unfortunately, the court also mentioned that Axel Springer can convert its content into a paid access model, justifying this measure as an element inherent for competition. We fear that this tacit approval can result in paywalls and adblock detection tools becoming the basic standard on the internet. More importantly, tools to detect the use of adblockers go against Art. 5(3) of the ePrivacy directive, which mandates that websites must seek consent before accessing or storing information about a user’s device. The EU commission has confirmed that, Art. 5(3) of the ePrivacy directive is not just limited to cookies but ‘all types of information’ stored or accessed in the user’s terminal device. This applies to the storage by websites of scripts in users’ terminal equipment to detect if users have installed or are using adblockers. A win for user freedom? With many service providers and websites on the internet following the trend of restricting users with adblockers from accessing their services, these court decisions in Germany help build precedents that uphold and recognize principles of user freedom. Indeed, these decisions support the principles of a Next Generation Internet, including ensuring that internet users can make individual choices and exercise their freedom of expression, in ways in which they can freely develop and use new extensions and browser features to enhance their online experience and user control. Despite the steps forward for user control found in these judgments, they do not go as far as we would hope to secure user freedom when using the internet, and are still subject to appeals and therefore may not be final. We will keep an eye on the legal proceedings in this case and keep you updated when new developments occur. In the meantime, the court cases can be read on the Bundesgerichtshof and Landesgerichts websites. If you are aware of any similar cases or other developments to support user freedom in any other member states in the EU, then please do share and reach out to us! Discuss this Tags Next Generation Internet Germany Press Press Room Latest News Free Software Basics Become a supporter About the FSFE Free Software Foundation Europe is a charity that empowers users to control technology. Software is deeply involved in all aspects of our lives. It is important that this technology empowers rather than restricts us. Free Software gives everybody the rights to use, study, share, and improve software. These rights help support other fundamental rights like freedom of speech, freedom of press, and privacy. Learn more",
    "commentLink": "https://news.ycombinator.com/item?id=38763165",
    "commentBody": "Unblocking User Freedom: the right to use adblockersHacker Newspastlogin [dupe] Unblocking User Freedom: the right to use adblockers (fsfe.org) 149 points by pabs3 18 hours ago| hidepastfavorite105 comments jraph 17 hours agoPosted 3 days ago, 282 comments: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38726389 reply MzHN 15 hours agoprevSomeone brought up piracy from the monetary perspective.Another perspective I like is piracy and streaming services.I, and most in my bubble, stopped pirating when streaming services provided, well, good service.We&#x27;ve bit by bit moved back to piracy when the service has degraded.My journey with ad blocking is similar.Even though my browser was loaded with extensions, I used to not run an ad blocker.No other reason really than laziness. The ads didn&#x27;t bother me much. It was one of those \"I&#x27;ve been meaning to do it but never got to it\".What finally got me to install an ad blocker were news of malware being served even on popular websites through ads.Ads weren&#x27;t simple anymore if they ever were. They were part of one of the most complex and lucrative domains of tech business. And that was leaking into websites. It felt too dirty, so I got an ad blocker.Nowadays the ad-tech industry boasts about moving to first-party ad tracking, a cat-and-mouse game where I don&#x27;t hold high hopes for ad blockers. So I went a step further and turned off JavaScript by default in uBlock Origin.Or take YouTube ads. I was still watching them on my TV not long ago, but when it got to the point where a 20 minute video has 5 ad breaks I couldn&#x27;t take it anymore.If ads sticked to being image only, no dark patterns, no targeting persons but instead content and not exceedingly disruptive, I would have probably never bothered with ad blocking. reply MikePlacid 14 hours agoparentI remember clicking on some Google ads - when they were unobtrusive and textual - just to get these new nice guys some additional revenue (often ads were “on-topic” even).But these jumping, blinking, content obtrusing things? And I am on a tablet 90% of the time… reply _Algernon_ 13 hours agoprevThe right to general purpose computing should be on a level with the right to free speech in every country that claims to value free speech[1]. Same protections as speech.Because nowadays computing is essentially speech. There certainly is a better argument for computing to be speech than monetary political donations (ie. bribes) being it.And this does of course not mean that every form of computation is permitted, just as not every form of speech is allowed (ie. threats or libel). It also doesn&#x27;t mean that anyone has to platform your speech. But using technological tools to take away other&#x27;s right to computing on their purchased device would be considered a free speech violation. This would include DRM, Web Integrity, denial of service and other attacks on computing devices you don&#x27;t yourself own.[1] I&#x27;m referring to the free speech value with its roots in the enlightement, not on the narrower definition of the free speech as defined in the first amendment (which only limits governments from hindering free speech). reply austinjp 15 hours agoprevITT: Tails wag dogs.Ads are, in the vast majority, toxic shit. Endemic income inequality and unicorn worship has produced VC-backed hustle culture where \"creators\" spew \"content\" over platforms, and slap ads on top to generate income.If a business can&#x27;t generate sufficient income by selling a product, it&#x27;s not a viable business. It&#x27;s certainly not one I want to interact with.Tail wags dog: Without advertising, all this content would be paywalled or simply wouldn&#x27;t exist.Dog wags tail: Sell your product, maybe give away samples. Sink or swim. reply sedev 16 hours agoprevThere is no right to advertise, is how I see it, any more than there is a right to use asbestos, lead, and mercury any way you please. There is societal permission to use those substances in strictly controlled ways, requiring that serious work be invested in preventing and limiting the toxic effects upon the public of using those substances, because those toxic effects are real and taking the benefits of using those substances while shuffling off the toxic effects onto someone else, is evil. We should regulate advertising in the same way: it is evil to shuffle off its toxic effects onto the public at large while the advertiser and ad-inventory-seller keep all of the benefits. Ad-blocking is as virtuous as carrying around kits and sensors to check how much lead and mercury is in my immediate environment — certainly I will benefit from doing it, but I shouldn&#x27;t have to, because pumping out ad-toxins into the social environment constantly and pervasively, is evil. reply andrepd 15 hours agoparent> those toxic effects are real and taking the benefits of using those substances while shuffling off the toxic effects onto someone else, is evil*is capitalism, ftfy :)More seriously though, there is always a dicothomy between the \"healthier\" features of capitalism (competition, private initiative, etc) and the rest: rent-seeking, pocketing the profits and dumping externalities on others, enclosing the commons, etc. reply iteria 16 hours agoparentprevIs there a right to free content? Because ads are obnoxious and I do block them, but I also pay for stuff were I can. If ads didn&#x27;t exist there effectively there would be a pallwall on the internet. As there should be, people need money to live. If people feel so strongly about ads they should either not consume the content or pay for the ad-free version. I use YouTube premium and I&#x27;ve never seen an ad. I get the ad-free version of everything. My child even uses Amazon kids, so she can enjous apps to her hearts content without ads. But I pay for that.Ad blocking is theft. It&#x27;s theft that I will commit, but it is theft. When you block an ad you reduce the content creator&#x27;s salary. We then have to ask: what happens if the creator gets no money? They stop giving the content away \"for free\".This is the piracy fight all over again. Again, I&#x27;m on the high seas, so I&#x27;m not innocent. I still think that we need remember that content isn&#x27;t free. We pay for it with attention or money. If enough people don&#x27;t do that then the content won&#x27;t be there. That&#x27;s how capitalism works. reply Sevii 16 hours agorootparentAd blocking is not theft. If it were, leaving the room with the television on while ads were playing would also be theft. Youtube is freely sending people content. No one is forcing Youtube to send them cat videos. No one is acquiring Youtube videos illegally via torrents.Ad blocking is only possible on Youtube because Youtube insists on doing big data auction based advertising. If they wanted to, Youtube could embed ads in the video stream making it impossible to block them.Youtube does not have a right to display whatever content they want on my devices. If they freely send me data, I have the right to display that data however I can on my device.If Youtube wanted they could end the utility of adblock today. They could only send data to people who paid. They could embed ads into the video stream. It is their choice to make adblocking possible on Youtube. reply insanitybit 16 hours agorootparentnext [12 more] [flagged] Kamq 15 hours agorootparent> They don&#x27;t? Why not?Because it&#x27;s my device. If youtube wants to not send me the video, that&#x27;s perfectly within their rights. But once they&#x27;ve sent the video, their rights end unless they have a contractual agreement with me personally. reply _jal 15 hours agorootparentprev> Who says it isn&#x27;t?Me. And, I believe, the vast majority of other humans who have given it any thought.> They don&#x27;t? Why not?If you feel that way, you must also believe I have the right to display whatever I want on your devices. Which you naturally agree I do, right? I hope you like very early morning disco...> it seems obvious that they can say \"in exchange for sending you this video you must watch the ads\".People can say whatever they like. Like, I can say \"for reading these words, the person behind the insanitybit account owes me $20.\"Tell me, just how obligated do you feel to pay that? reply insanitybit 15 hours agorootparentIf I don&#x27;t want to view this post I can close the window. I&#x27;m on HN, a site with an existing ToS. If HN decided to put ads on display and say \"if you want to read you have to abide by a ToS that ensures you don&#x27;t block our ads\" obviously that would be legal. reply _Algernon_ 13 hours agorootparent“But the [ToS] were on display…”“On display? I eventually had to go down to the cellar to find them.”“That’s the display department.”“With a flashlight.”“Ah, well, the lights had probably gone.”“So had the stairs.”“But look, you found the [ToS], didn’t you?”“Yes,” said Arthur, “yes I did. It was on display in the bottom of a locked filing cabinet stuck in a disused lavatory with a sign on the door saying ‘Beware of the Leopard.”- Hitchhikers Guide to the Galaxy (slightly modified by me). reply insanitybit 12 hours agorootparentDid you have a point? reply _Algernon_ 11 hours agorootparentEquivocating sending a GET request with signing&#x2F;agreeing to a 100 page contract of legalese is about as ridiculous a proposition as the quote I posted depicts, if not more. reply insanitybit 4 hours agorootparentSo if Youtube required a sign-in you&#x27;d say that they have a right to enforce ads not being blocked? reply oivey 15 hours agorootparentprevProbably not legally enforceable, and probably HN’s only recourse would be to block you from viewing. reply LesZedCB 15 hours agorootparentprevholy fucking shit. no. you&#x27;ve been gaslit into this absolutely insane reality friend.bodily autonomy is basical human right number one, including the right the close your fucking eyes. there&#x27;s no fucking \"contract law\" with https requests. if you&#x27;re playing devil&#x27;s advocate, well the devil forgetting basic human rights is bad rhetoric reply insanitybit 15 hours agorootparentBodily autonomy? Uh, what? You... you have the right to close your eyes.> there&#x27;s no fucking \"contract law\" with https requestsBut there is when you sign up for a service.This has nothing to do with human rights... reply LesZedCB 15 hours agorootparent> Well, it seems obvious that they can say \"in exchange for sending you this video you must watch the ads\".\"you must watch\" is bodily autonomy. currently what they can enforce technologically is \"you must wait\" for these 30 seconds of ads, which I can close my eyes for, or similarly with technology block the domain name they are served from> > If it were, leaving the room with the television on while ads were playing would also be theft.> Who says it isn&#x27;t?\"you must stay\" is bodily autonomy. I&#x27;m not sure how this is hard to understand replyndriscoll 15 hours agorootparentprevAd blocking is no more theft than is blocking crypto miners or a virus turning your computer into a botnet member. This particular form of malware is common, but it&#x27;s still malware attempting to hijack my computer to do things I did not authorize.Would you support websites using your GPU to mine crypto coins? It&#x27;s a more direct form of payment that doesn&#x27;t create editorial conflicts or involve spying. Even if you&#x27;re on battery, energy is just the price being charged. Or would you see it as them using your computer without your consent and taking advantage of the horrible security model of the web?Ad- and spyware should be recognized as what they are: malware. Distributing malware and using someone else&#x27;s computer for unauthorized purposes is a crime. Doing it to 10 or more computers is a felony. It also gets used to destroy markets by dumping free products onto them. The whole model should be illegal. reply pdonis 13 hours agorootparentprev> Is there a right to free content?No, but there&#x27;s also not a right to force others to consume content. Websites are within their rights to send ads to my browser, and&#x2F;or to make users pay to get ad-free content, and I am within my rights to block ads if I don&#x27;t want to see them, or just not visit their site at all (the latter is mostly what I do). This isn&#x27;t a contest of theft on one side vs. honest toil on the other. It&#x27;s a straightforward conflict of interest--websites want to show me ads that I don&#x27;t want to see--which leads to a straightforward arms race of ads vs. ad blocking.> When you block an ad you reduce the content creator&#x27;s salary.No, I don&#x27;t; I&#x27;m not paying the content creator a salary by viewing an ad. I am simply not participating in the content creator&#x27;s chosen business model. The content creator has no right to force me to do so. He does have the right to detect that I&#x27;m using an ad blocker and simply refuse to show me his content at all in that case. And then I&#x27;ll just go surf somewhere else.If the content creator wants me to pay him for his content, he should set up a Patreon or a Substack or something like that. There are perfectly good vehicles available for people to get paid for the content they write without having to clutter it up with ads. If a content creator chooses not to do that, that&#x27;s his choice, and choices have consequences.> This is the piracy fight all over again.No, it isn&#x27;t. Using an ad blocker is not piracy; I&#x27;m not going and fetching content behind the back of the copyright holder. I&#x27;m just refusing to view content I don&#x27;t want.> If enough people don&#x27;t do that then the content won&#x27;t be there.Which for me at least would be no great loss. Given the content that I usually see with ads, I would be perfectly fine with not having it at all. Which is why, as I said above, I mostly just don&#x27;t go to websites that insist on showing me ads; their content isn&#x27;t worth enough of either my money or my attention to make me even care about entering the ads. vs. ad blocking arms race with them. reply BLKNSLVR 14 hours agorootparentprev> If ads didn&#x27;t exist there effectively there would be a paywall on the internet.This is a false premise. The internet of old, from which the current version evolved, had no advertising and yet still contained useful information. In fact, the ratio of useful information to garbage was much higher, so it could be said that with advertising was brought a flood of trash, and so a more informative, useful internet is one without advertising.That&#x27;s how capitalism works, it brings the con men and scammers and bottom feeders looking to make a quick dollar from the naive and unsuspecting, and if such behaviour can stay under the radar of regulation long enough then it becomes normalised, and otherwise good citizens defend it as &#x27;the only way&#x27;. reply catlifeonmars 15 hours agorootparentprevOne could make the argument (I do) that the way advertising is done today is a cancer on society. Never mind whether it’s legally sanctioned to do so.> That’s how capitalism worksIndeed, capitalism has a weakness when it comes to enabling and encouraging predatory behavior. Thankfully, we don’t live in a (completely) capitalist society. Instead, we can make laws to protect consumers against the negative effects and don’t need to strictly adhere to an “ideal” vision of capitalism. reply InCityDreams 14 hours agorootparentprev>As there should be, people need money to live.Not at my expense they don&#x27;t. reply jMyles 15 hours agoprevI can&#x27;t believe this has become so over-complicated. It&#x27;s very straightforward:You can respond however you want to my HTTP request. I can then render that response how I see fit.&#x2F;thread reply freitzkriesler2 16 hours agoprevIt needs to be said. I don&#x27;t careI started blocking ads back in the 2000s when viruses would be delivered over bad flash videos.Nowadays, I still block ads because I&#x27;m paying for limited bandwidth on my mobile devices. I&#x27;m not paying for unlimited bandwidth when 5gb with ad blocking gets me what I want. I can&#x27;t use this excuse on my PC but...I honestly don&#x27;t care if it harms the content creators and more importantly, the video delivery networks like Google.Does that mean there might be less content made? Sure and I&#x27;m Ok with that as a consequence. reply paulddraper 16 hours agoparent> I can&#x27;t use this excuse on my PCPerhaps you should just state your real reason, rather than excuses. reply whstl 15 hours agorootparentI can state some of mine:I don&#x27;t want loud audio blasting on my headphones before watching a Youtube or news site video. I don&#x27;t want to watch scam advertisements on Youtube or Instagram. I don&#x27;t want to be tracked without my consent by third-party ad companies. I don&#x27;t want to even support companies that track users without consent. I would actually prefer that websites using non-privacy-respecting ad-ware would die. I don&#x27;t want my computer to be slowed down by random websites. I don&#x27;t want to be forced to spend hundreds&#x2F;thousands on computer upgrades. I don&#x27;t want ad code from ad companies running on my device. I don&#x27;t want the risk of malware that might come via ads in some websites. I don&#x27;t want my attention going to jumpy animations on GIF banners (the original reason I started blocking in the early 2000s). And finally: I don&#x27;t want to spend the bandwidth, regardless of the fact it&#x27;s gonna cost me money or not.I am, however:Happy to watch a Youtube NordVPN or Ridge Wallet sponsorship segment on Youtube that doesn&#x27;t track me and allow me to skip if I want. Same for TV ads (unless they&#x27;re obnoxious and loud). Also Happy to unblock websites that don&#x27;t have obnoxious third-party ads. reply AllegedAlec 15 hours agorootparentprevI wish for companies that require my attention be taken up by their ugly pixels to all bankrupt and for their C-staff and marketing departments to be unemployed and in the gutter. reply freitzkriesler2 14 hours agorootparentprevI don&#x27;t want to pay with my money or my eyeballs. Simple as. reply varispeed 16 hours agoprevThe problem is that the content offered most of the time is not good enough to pay for it.For instance the so called news. Most newspapers publish ready made stories with their own editorial take at best. Articles are typically processed by LLM so the wording is slightly different than the stock story.The press has abandoned investigative journalism because it is too risky. Corrupt governments and police can&#x27;t protect journalists. So they mostly serve three-letter agency approved information and not much beyond that.and they want people to pay for this nonsense.If Google wants people to stop using adblockers, they should be forced to share ad revenue with every single contributor. If they show in their results your aunt recipes, the aunt should get a share of the revenue from ads displayed on that results page. reply andrepd 15 hours agoparentWell, re: journalism yes there is now 1000x more shit-tier content spamming farms than there were before. But the prestigious and serious news organisations still do perform serious high-quality reporting and investigative journalism. From Der Spiegel to The Guardian and many others. Even in my small country with a dire newspaper market there are still 2 or 3 serious newspapers performing high quality journalism. reply MikePlacid 14 hours agorootparent> But the prestigious and serious news organisations still do perform serious high-quality reporting and investigative journalism.You’ve omitted one word: honest. reply varispeed 10 hours agorootparentprevThey only \"investigate\" approved stories. What you say is an illusion they create quite well.In the UK, there is probably only one that goes slightly deeper - Private Eye and they still have not touched many topics related to corruption and other scandals where Guardian either low-key supports (the perpetrators) or don&#x27;t talk about it at all. reply kstenerud 17 hours agoprev> Despite the steps forward for user control found in these judgments, they do not go as far as we would hope to secure user freedom when using the internetThis is a strange take. They contend that the courts not forbidding website owners from refusing access to adblock users is a bad thing somehow, as if the courts should have forced businesses to serve them... The German courts took the only logical conclusion: You can block ads all you want, and website owners can block you all they want. reply Quarrel 17 hours agoparent> the only logical conclusion: You can block ads all you want, and website owners can block you all they want.I very much agree with this bit.The real worry is the next step, as per your TOS you force me to render your website content only in an \"approved\" signed browser. This is a step several players are pushing towards (Netflix and others are already there, but for distinct reasons- at least they degrade your experience if you aren&#x27;t using an approved stack).This we need to fight against. reply ToucanLoucan 17 hours agorootparentI mean, what if there are actual technical limitations of whatever browser you&#x27;d like to use that prevent, for example, the on-the-fly playback of 4K video?Or, even more broadly, what if the device you&#x27;re watching on has insufficient compute to accomplish the task? Do you, as proverbial Netflix&#x27;s chief engineer or whatever, degrade the quality of the experience so things run smoothly, or do you press on and let the user choose a worse experience, and leave nasty feedback on public listings&#x2F;forums&#x2F;what have you?I don&#x27;t mean to argue for the Netflix&#x27;s in this situation, I&#x27;m just genuinely curious what HN thinks of this: in a situation where whatever tech a user is bringing to the table is insufficient to run your product, be it hardware or software, what do you do?I&#x27;ve been in a situation myself where the tech stack of our user base was directly contributing to the stream of angry emails our support was getting and was forbidden by management to gate content only to those who we knew could run it, yet simultaneously was held responsible for the negative impressions of our product as a result of it. I left that job soon after because it was an obvious lose&#x2F;lose scenario. reply yesco 15 hours agorootparentNetflix does not offer 1080p+ content to people watching on a Linux desktop. There is no technical reason for this, Linux browsers are capable of playing 1080p+ content of course. So why do you think Netflix does this?Rather than deal with hypotheticals let&#x27;s focus on reality, a lot of people have put a lot of effort into ensuring that web browsers can run the same content on every platform. This is already a solved problem, even if imperfect.The only genuine reason a device might not be able to play a browser supported 4k video is because it&#x27;s too resource expensive (rare) and this is simply an immutable property of computers that isn&#x27;t going to change unless you are expecting all users to use the exact same hardware forever. reply jofla_net 15 hours agorootparentYou&#x27;re absolutely right, and its pathetic. There is no reason for anything to just \"not work\" on linux. As far as technical limitations go, computers have hit a zenith over 10 years ago. Yes sometimes things change, i remember when youtube&#x27;s codec was altered and suddenly perfectly good hardware was unable to stream videos any longer. This was however still a technical change, as it allowed for more efficient packing of content. I digress.What we&#x27;re seeing now, is purely political, or at the very least business-strategic, and linux is being purposefully omitted as an un-attested platform since it precisely gives users too much control&#x2F;takes away revenue from someone&#x27;s bottom line. The same thing could be said for console games which never hit pc at all either. And the last example which i think really brings it home is that ms teams not only doesnt work on firefox, linux is also off the table. Not because of any technical limitations in the least, as an off the shelf dell laptop + ubuntu + ff will give you a working video conferencing solution with google meet. Out. Of. The. Box. So it certainly isn&#x27;t technically limited. It is rather chosen to be this way to force users into windows + edge or their native app solution. reply andrepd 15 hours agorootparentprev>Netflix does not offer 1080p+ content to people watching on a Linux desktopThis is the reason I refuse to use streaming platforms even though I have enough money to pay for them. It&#x27;s not a question of money. It&#x27;s a question of: paying money to install spyware on my computer for the privilege of streaming low-quality video on a list of pre-approved devices? That is simply not gonna happen. reply ToucanLoucan 15 hours agorootparentprev> Rather than deal with hypotheticals let&#x27;s focus on realityImagine coming into a discussion telling of a thing you experienced and then the reply is: I don&#x27;t want to discuss hypotheticals, which is great because a) this isn&#x27;t a hypothetical, it&#x27;s the reason I quit my last job and b) you replied to my comment, which is the only way you could possibly even have the chance to discuss this.I am explaining (admittedly with low detail because Internet) an actual situation I experienced, and it&#x27;s not like there aren&#x27;t all manner of entertainment product available on the market which requires a floor of technical power to consume in a way the average consumer would deem acceptable, be that hardware requirements like VR or other bespoke controlling apparatus, or looser ones like the minimum requirements on videogames, or more is-or-isn&#x27;t ones like the ability for streamer boxes, phones or tablets to playback video of a given resolution and at a given frame rate. reply yesco 13 hours agorootparent> I mean, what if there are actual technical limitations of whatever browser you&#x27;d like to use that prevent, for example, the on-the-fly playback of 4K video?This is the core of what you were asking, perhaps my answer was too roundabout for you. What I&#x27;m trying to tell you is that:- This question is a hypothetical because it&#x27;s not true, you can encode videos to play on every platform so long as it&#x27;s browser supported, this is not 2013- There is not a technical floor in video playback of even 4k videos unless you are playing on something like a first gen raspberry pi, and even then, bandwidth constraints necessitate multi-quality video support regardless- VR and other \"manners of entertainment\" are moving goal posts and irrelevant to this discussion- Streaming content to multiple platforms is a solved problem, if you failed to accomplish this then it sounds to me that you probably couldn&#x27;t do your job- Using platform based attestation to resolve this technical incompetentcy is an unreasonable solution to the problem and deserving of complaints replycousin_it 17 hours agoparentprevIt&#x27;s not the only logical decision, because it leads to a technological arms race which is costly to all parties. The outcome is binary: see ads or not. The only logical decision is to figure out from first principles what the outcome should be, and make it binding for all parties to avoid the arms race. reply MikePlacid 17 hours agoparentprevTechnical curiosity: how site owners are able to detect blockers and why blockers are not able to bypass detection?As for ads I prefer Brave Browser model, where I pay websites directly, bypassing advertisers. reply judge2020 17 hours agorootparentDespite you preferring paying websites directly (besides the fact that Brave is&#x2F;was some crypto BS and took money even for recipients that didn&#x27;t opt-in that didn&#x27;t opt in[0]), most people mad at YouTube for blocking ads are people who won&#x27;t pony up the money to pay for YouTube Premium. I get the sentiment, but it&#x27;s still piracy if you don&#x27;t pay for a service in the ways they provide.0: https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;brave_browser&#x2F;comments&#x2F;a8d34y&#x2F;youtu... they try to defend the opt-out model, lol reply anonymousab 8 hours agorootparentThey still load you up with many more adtech trackers on YouTube premium than you get when using adblock.But yeah, if you use youtube a lot, at least premium does exist as a more morally righteous choice if you don&#x27;t really care about the tracking side of things and are mostly just annoyed at ads themselves. Which I&#x27;d imagine is most people. reply MikePlacid 13 hours agorootparentprev> but it&#x27;s still piracy if you don&#x27;t pay for a service in the ways they provide.Nope, it’s called “negotiation”. Here’s the money I want to pay for your service. You don’t want it? Fine, I’ll leave it here in case you change your mind.(Youtube can die in my book, I’ll just shrug.) reply judge2020 10 hours agorootparentNegotiation despite them not accepting that negotiation. In contracts, if you try to \"negotiate\" and the counterparty rejects your offer, you can&#x27;t just drop a bag full of cash at their door then expect to reap the benefits of an unsigned unexecuted contract to which they didn&#x27;t agree to.All I&#x27;m saying is that it is \"piracy\" by definition, even if it&#x27;s morally acceptable and basically 0 risk to partake in (AFAIK the only criminal offenders of Piracy have been booked for distribution, at least in the US). reply shepherdjerred 15 hours agorootparentprevI was paying for YouTube Premium, but then I realized I still saw all of the sponsorship segments within videos. reply BLKNSLVR 14 hours agorootparentprevEeesh, the whole world pirated YouTube for all those years before Premium became a thing. reply baq 16 hours agorootparentprevWhy am I being served content if I block ads? reply Sephr 17 hours agorootparentprevThe Brave model does not allow you to directly pay websites.You directly pay Brave, who then distributes funds to some participating websites. Additionally, they take a 30% cut of the value of their \"basic attention token\" shitcoin for themselves. reply insanitybit 15 hours agorootparent> You directly pay Brave, who then distributes funds to some participating websites.This isn&#x27;t worse than the way ads work anyway, so that seems fine.> Additionally, they take a 30% cut of the valueI also don&#x27;t see the problem here. They develop the browser, the infra, etc. What is the problem?What is it that you people want? reply healsdata 16 hours agorootparentprev> Technical curiosity: how site owners are able to detect blockersLet&#x27;s take a simple rule from EasyList:> &#x2F;snowplow.jsThis blocks the loading of any URL ending in snowplow.js. To see if a visitor to my website is using an ad blocker with EasyList, I can set a global variable `window.usingAdBlocker = true;` in my main content and then later change it in a scriptcalled snowplow.js that I include (`window.usingAdBlocker = false;`). So with a fresh Chrome install, the page loads and then the script sets the variable to false. However, with an ad blocker, the script never loads and the variable remains true.> why blockers are not able to bypass detection?Adblockers have developed rules to block this detection mechanism. It is a cat and mouse game. For example, there&#x27;s a library called &#x27;jQuery Adblock&#x27;. So the AakList (Anti-Adblock Killer) has a rule to block scripts called `&#x2F;jquery.adblock.js`It is a cat and mouse game. reply bl4kers 17 hours agorootparentprevThey run JS to see if content is present and visible after page load. Also I guarantee 99% of websites don&#x27;t want or care about your cryptocurrency reply beeboobaa 16 hours agoparentprevThis works until they shove remote attestation down our throats and it becomes practically impossible because you no longer own your machine reply insanitybit 16 hours agorootparentIt still works at that point - websites can send you ads and you can choose not to view those websites. No one is forcing you to go to Youtube or whatever. reply beeboobaa 15 hours agorootparent> No one is forcing you to go to Youtube or whateverOh boy. They sure are. Many countries their governments post their videos on youtube. Many employers put their training videos on youtube. And so on. reply insanitybit 14 hours agorootparentThat doesn&#x27;t sound like a Youtube problem, it sounds like a your-government problem. reply beeboobaa 8 hours agorootparentJust responding to what you said.> No one is forcing you to go to Youtube or whatever reply Kamq 13 hours agorootparentprevNobody is forcing youtube to respond to my https request either.If they wanted, they could lock it down and force you to log in and agree to a bunch of rules in order to use the service, but they don&#x27;t. reply ls612 15 hours agorootparentprevThe quick death of WEI makes me hope that RA might end up like the Secure Boot fracas a decade ago; it’ll end up in the enterprise because companies want it in their internal IT but won’t end up being used in the consumer world. reply beeboobaa 15 hours agorootparentEvery modern apple device has it, most androids do as well, chromebooks do as well, and microsoft is already requiring a TPM for windows 11. reply ls612 12 hours agorootparentNo Apple device can attest to what extensions are running or what apps are installed (at least not without some kind of MDM) and Apple specifically won’t support that to prevent user tracking and fingerprinting. reply beeboobaa 8 hours agorootparentNo, they&#x27;ll just forbid any extensions&#x2F;apps they don&#x27;t like from their store and that&#x27;s that. reply ls612 7 hours agorootparentApple openly supports ad blockers in the App Store so idk where you’re getting that from. reply beeboobaa 5 hours agorootparentI&#x27;m talking about what can be done with remote attestation. It forces you to be beholden to what the device manufacturer allows you to run. For now they allow you to run ad blockers. replykmbfjr 15 hours agorootparentprevGoogle et al are fooling themselves if they think this is the end of the game. reply em-bee 16 hours agoparentprevthe problem is that they also say it is legitimate to charge for adfree access. while that is technically correct is has negative impact on society because it means only rich people (i exaggerate intentionally to make a point) can live ad free.poor people have to suffer ads or be excluded, which is fine if the content is something not of interest to the general public, but it is not fine at all if it is eg facebook or youtube.add to that that poorer segments of the population tend to be less well educated and thus more susceptible to manipulation.if you force ads on people you must do so to everyone equally and block adblockers equally. any exchange of money creates a situation where only those that can afford it can protect themselvesif you charge for access you may not offer the same access for the price of watching ads. it should be either one or the other reply gumby 16 hours agoparentprevI’m a determined ad blocker and I agree with you. The only exception should be a government web site (I also block analytics). reply baz00 17 hours agoparentprevYeah nothing wrong with that. This is how it goes for me though:1. Company stuffs ads down my throat.2. I use adblocker3. Company blocks me4. I ignore company.The whole problem starts at (1) which is \"create a business supported only by advertising revenue\". That says your actual product is worth fuck all. reply herodotus 17 hours agorootparent> That says your actual product is worth fuck all.Look I use ad blockers and a pi-hole. And I don&#x27;t bother reading paywalled sites that I don&#x27;t pay for. But your comment is a little harsh. It is a sad reality of the internet that there are so few options for generating revenue. I wish there was a micro-payment model where part of my monthly ISP payment was divvied up and paid to websites based on volume of content read by me. That way niche websites (like, for example, hobby sites or local sites) could get some income without having to resort to ads or fundraising. In my view the real ripoff are the exorbitant monthly fees I pay to my ISP. reply seanp2k2 16 hours agorootparentThe fact that even in Silicon Valley, the Comcast monopoly is very strong for both single-family and multi-tenant housing tells you everything you need to know about the viability of anyone actually solving this problem. They’re simply making far too much profit from bad service and terrible business practices, and they’ve paid for all the regulators they need to ensure they’ll never have to change or have any meaningful competition. That they and others in the ISP and mobile ISP cartel have been handed hundreds of billions of taxpayer dollars to build out FTTH and rural areas that they instead pocketed is just the cherry on top of the turd banana split that is consumer protection in the USA. Check out “The Book of Broken Promises: $400 Billion Broadband Scandal” for more on this. reply tcfhgj 16 hours agorootparentprev> I wish there was a micro-payment model where part of my monthly ISP payment was divvied up and paid to websites based on volume of content read by me.something like that already exists: https:&#x2F;&#x2F;www.contentpass.net&#x2F;en reply baz00 16 hours agorootparentprevIt&#x27;s brutal but true. Either have a revenue model or expect no income. That is the reality. The fuzzy grey bit in the middle is where all the garbage is.Your idea sounds a fantastic way to make a system incredibly complicated with no actual gain other than a billing dystopia. reply squarefoot 16 hours agorootparentprev> The whole problem starts at (1) which is \"create a business supported only by advertising revenue\". That says your actual product is worth fuck all.It&#x27;s a bit more complex than that as the market is long oversaturated with products and services, that is, there are not enough buyers compared to the number of products and services, but that awful thing called consumerism calls for more and more production anyway to keep the machine going and prices down, therefore companies need to fight hard for potential customers attention, and one way to achieve that goal is to put their names on every possible free spot where one&#x27;s eyes might look. There&#x27;s nothing wrong in being dependent on advertising, but at the level necessary today it simply doesn&#x27;t scale anymore, and on the web a lot more than half of the (sometimes metered) traffic is already made of advertising, and is growing steadily. We already know where this thing is leading: more and more advertising, coupled with less and less attention which in turn will generate the need for even more advertising.It doesn&#x27;t scale and it doesn&#x27;t work anymore like it should. I would rather start looking right now for alternatives, for example one where (local) governments convert a tax collected from all registered companies to a system of unobtrusive advertising which by rotating equally, still being weighted according to the amount of investment in research, production, personnel, etc. would guarantee fair exposure to all businesses. That would be however deeply against current idea of uncontrolled capitalism, though, therefore we likely will have to wait for the day the world will be ready for a more mature, harmless way of doing business. reply seanp2k2 17 hours agorootparentprev100% this. If companies use Admiral to block Adblock and don’t have the tiny “heck off” link at the bottom of the modal, I just hit back and don’t read their article. Sometimes Reader works on iOS in those situations, sometimes not.Between crap like Admiral, GDPR nag screens that help no one, incessant useless live chat boxes, large banners on mobile that are pinned to the tops and bottoms of views (doubly so if they’re simply cosmetic), “spin the wheel for a discount” modals, and SMS spam signup schemes, many websites are quite annoying to use and very user-hostile on the modern internet. reply giantrobot 14 hours agorootparent> If companies use Admiral to block Adblock and don’t have the tiny “heck off” link at the bottom of the modal, I just hit back and don’t read their article.The most asinine part of that is the fucking site has already delivered the content. They incurred whatever costs their multi-megabyte bloated JavaScript monstrosity requires and only then blocks it with a stupid blocking banner.They&#x27;d incur the same (or less) costs if they just sent a static HTML page with the content. Doing this they could still make advertising money with a simple text add saying \"this content brought to you by Slurm\" inline with the content. Just log analysis will get them a ton of visitor information some overwrought AdTech product promises will revolutionize their synergies.A $5 VPS with its included terabyte of data transfer can serve so many fucking web pages in a month. Loading that down with autoplaying videos, megabytes of uncompressed PNGs, and a dozen copies of Doom worth of JavaScript is just a ludicrous pointless cost. A sprinkle of CSS can make those basic pages look amazing. reply blooalien 13 hours agoparentprev> \"You can block ads all you want, and website owners can block you all they want.\"This is absolutely the correct conclusion to come to, given that the Internet is really \"just\" a network of networks (still an amazing thing, don&#x27;t get me wrong), and when one connects a device to a network, they should have absolute control over the data that device allows to flow to and from the \"outside world\", for the safety of the user, the device, and for the health of the larger \"outside\" network. This holds even more true when connecting a network to another network. For your own security, you (should) run a firewall at the very least. Even better is when all devices on the network all have their firewall enabled, but sadly, not all devices were designed with network security in mind, so that&#x27;s not always possible.TL;DR: All the above is just to say an adblocker is just another form of the end user exercising control over the data that flows into and out of their devices &#x2F; network, as they&#x27;ve always been able to, until advertising companies (which initially all scoffed at the entire idea of advertising on the \"passing fad\" Internet) decided that they had a right to our eyeballs and our devices&#x27; network data flows at any time and in any way they please. reply sys_64738 17 hours agoprevThis is pretty much like the piracy argument where the assumption is there is 100% buy-in from people if they don&#x27;t pirate. There isn&#x27;t. Likewise, here. If you insist on forcing ads then I won&#x27;t participate. There are no monetary damages as people refuse to look at or listen to ads. reply davidy123 16 hours agoprev [–] This is going to be a controversial position, but nobody is really arguing the other side, the benefits of ads. And if they were more accepted and integrated (a \"perfect\" federated model), maybe they could be acceptable rather than abrasive and irrelevant. Who is talking, with a measured perspective, about the shift to participatory, user produced content (yes, I know, a lot of it isn&#x27;t good, but some is and it is available to many more people without barriers), and the benefits that brings? I just see hand waving about alternatives, some \"good old days\" ideas about media, and a lot of people accessing essentially free ad-sponsored content with generally minor inconvenience in a murky going-nowhere conflict.I think as much as anyone Google brings alternatives; I pay for Youtube Premium and never have any ads on Youtube&#x2F;Youtube Music (places where it would be particularly unwelcome), I get paid for Google Surveys, and I think with some work their federated model could be perfectly reasonable.If you disagree, please say why, rather than simply downvoting. reply whatshisface 16 hours agoparentHere&#x27;s my proposal to replace ads:1. The server does not send the content to you, unless you pay. Websites are responsible for deciding what to give out for free - only public \"abstracts\" of NYT articles get search indexing.2. Some browsers keep an account for you, others show you ads and let the advertising companies pay your way through the internet.3. Anyone who wants to run a server for free or host P2P content may still do it.All of the advanced tracking technology would be unnecessary if some people browsed through their adsense consumer account and other people ran a tab with their \"content intermediary\" to pay websites to serve (anonymous) address x.y.z.w. reply yjftsjthsd-h 16 hours agorootparent> All of the advanced tracking technology would be unnecessary if some people browsed through their adsense consumer accountWell yeah, if you do all the tracking officially and up front there&#x27;s no need to tack it on, but that&#x27;s not a win.> and other people ran a tab with their \"content intermediary\" to pay websites to serve (anonymous) address x.y.z.w.Thereby ensuring that the intermediary does the tracking.None of this gives the user privacy. reply whatshisface 16 hours agorootparentThe content intermediary could offer anonymity as a service and a selling point, like a VPN.Putting the tracking up front is a win because you&#x27;d be able to escape it. reply dns_snek 15 hours agoparentprevI disagree.1. Advertising is a net negative on the human psyche, it steals attention that could be spent on productive work or entertainment. Proliferation of ad blockers affirms this.2. Advertising is a zero sum game which benefits corporations with the largest advertising budget and hurts small businesses3. Ads have expected return on investment or they wouldn&#x27;t be run => In aggregate we&#x27;re actually paying for that content with hard cash, so it&#x27;s not \"free content with ads\", but \"content with obscure, deferred payment\"4. Ads incentivize high volume, low quality, clickbait content. This makes it difficult to find high quality information because the only metric being optimized is the number of eyeballs that land on your website.By eliminating ads as a funding model, we could eliminate this source of stress (1), even the playing field for small businesses (2), make it clear to users that they&#x27;re, in fact, paying for the content (3). There&#x27;s no free lunch, just a blue pill illusion of one.What we need for web that actually serves its users are not ads, but easy, ubiquitous, private micropayments without middlemen who charge a hefty fee. I&#x27;ll pay 20 cents to read this article, no I won&#x27;t subscribe for $20 a month. reply baq 16 hours agoparentprevAds want my attention. It is a limited resource and I don’t want to spend it on ads.Google in particular are some of the richest companies in the world due to people who can’t or won’t figure out ad blockers. Why they care about mine now I can’t exactly understand. reply IsoldesKnight 16 hours agorootparentThe answer is probably related to why a paid premium tier negates the value of an ad-supported free tier. A person who can&#x27;t (or won&#x27;t) afford the paid tier is probably not going to pay an advertised product, and thus the consumers of the free tier are less interesting (e.g. valuable) to advertisers.For value to exist in the free tier, it must reach the entire audience. Think about how radio or newspaper advertising worked. If one segment figures out how to avoid the advertisements, it reduces the value of the remaining audience more than proportionally. reply em-bee 16 hours agoparentprevpaying for ads to be removed disadvantages weaker more susceptible segments of the population.see my comment here:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38764246 reply gosub100 14 hours agorootparentwhat makes them \"weaker\" ? reply em-bee 11 hours agorootparenti explain that in my other comment. reply gosub100 11 hours agorootparentI think it&#x27;s a prejudicial point of view, no? pre-judging someone based on their race and socioeconomic status. reply em-bee 9 hours agorootparenti said nothing about race.the correlation between wealth and education is supported by plenty of evidence. but that isn&#x27;t even the strongest argument. the mere fact that people who can&#x27;t afford to pay for an ad free experience are forced to endure ads already is a problem in itself, even if their level of education is the same as that of those who can afford it.it is just that the likelihood of being less educated rises with lower income, and that only exacerbates the negative effect of ads, but even without that the effect is bad enough because ads motivate people to spend money on things they don&#x27;t need which has a worse negative effect if you are poor. reply Vaslo 8 hours agorootparentSo I need to have ads forced on me because some kid didn’t pay attention in school. Sounds great. reply em-bee 7 hours agorootparenti think you took a wrong turn somewhere in interpreting what i said. :-) for the record, if it were up to me, i&#x27;d like to see forced commercial advertising banned completely.i get your point, you think it&#x27;s fair to pay for ads to go away. i think it isn&#x27;t. but that doesn&#x27;t mean you should have ads forced on you. on the contrary, as it is said in the article, we do have a right to not have ads forced on us, and that right needs to become legally enforceable, but in such a way that we all can benefit from it, and not just those who can afford it. replykmbfjr 16 hours agoparentprevMy proposal is that my browser downloads all the content, it just does not display the advertisement.This levels the playing field among traditional broadcast, the content creators get paid and it is just a little less ethical than just getting up to use the bathroom during a commercial break.If Google and ad agencies want to press the issue, this is really the next step. reply LesZedCB 16 hours agoparentpreveverybody deserves a room of ones own. [1]ads are just a parasite pretending to provide it, manufacturing demand for overproduced commodities that are mostly harmful for humanity and our environment.so long as the public library remains upheld as a public institution, with free access to information for all, ads remains merely a parasite slowly eating away at our perception of the public good. and it&#x27;s no surprise in our rent-seeking, enshittifying economy that the library is crumbling.1. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;A_Room_of_One%27s_Own reply EA-3167 16 hours agoparentprevFor me it&#x27;s much simpler than this... I don&#x27;t trust the ads to run on my device. They&#x27;re often disruptive at best, and sometimes little more than malware at worst. I don&#x27;t trust ad-tech companies to be ethical and responsible, and I don&#x27;t trust most site operators to do their due diligence before an ad harms someone.I also remember what TV was like when it was primarily supported by ads... it wasn&#x27;t \"the good old days,\" it sucked. It was an era of the blandest, LCD-chasing content that was constantly at the whims of hundreds of advertisers. There&#x27;s a reason that HBO was such a revelation back in the day, you paid them money and they showed you interesting things.And frankly what I&#x27;ve learned from the Patreon model of funding is that still works, and most people consuming the content don&#x27;t need to pay for it; the percentage who can and do are enough. Take the fall of The Escapist recently, where all of the talent was fired&#x2F;left and then formed Second Wind. Like most successful, but not top-20 YT&#x27;ers they make their money from merch, Patreon (currently about 13.5k people sending them north of $60k per month) and sponsorships.So to me the answer is that ads are a terrible way to make money, and we already have working, better alternative funding models that don&#x27;t require paywalls (for most content) or embedded ads. reply yjftsjthsd-h 16 hours agorootparent> and sometimes little more than malware at worst.No, not \"little more\"; the worst is ads literally using browser vulnerabilities and serving malware. reply EvanAnderson 16 hours agorootparentEven if there&#x27;s no malware, full screen scary looking pop ups trying to scare non-technical users into calling a \"support\" number are very common in my experience. reply paulryanrogers 15 hours agorootparentThose are fraud, which is already illegal. Regulators should be doing some random sampling and find ad platforms that distribute it. And if there is evidence they systematically allow it for profit reasons then they are coconspirators who should be prosecuted as such. reply dns_snek 15 hours agorootparentprevI recently opened YouTube in incognito mode without an ad blocker, the very first video on the home page was a crypto scam video, followed by a Mr. Beast scam when I tried it again a few hours later. Those videos were still up the next day.Advertisers can cry crocodile tears all they want, they&#x27;re directly facilitating crime that hurts real people. reply giantrobot 15 hours agorootparentprevWithout ads how am I supposed to hook up with the hot singles in my area that want to talk to me? reply gosub100 14 hours agoparentprev1) I do think fondly of the \"good ole days\" where advertising hadn&#x27;t destroyed most of the internet, but I concede the cats out of the bag; we&#x27;re never going to see that again.2) I think the only benefit of ads is that it staves off the alternative: widespread shilling. inb4 people with binary outlooks tell me that shilling already exits. I&#x27;m well aware. But if you plug the advertising hole (somehow), the same garbage is going to come out through another opening.3) I pay for YT premium as well (which increased in cost substantially this last year). I love their music service, and I love that I dont get YT ads. However, I think this service should also skip over content-creator-placed ads (since they get more $ per view from subscribers like us). Furthermore, I&#x27;m starting to see \"subscriber only\" videos - essentially pay-per-view - which I view as an erosion of the contract. Just like there was erosion in the number of ads in TV over the decades, I think we can expect further erosion where \"premium\" means you just get \"one or two (quite often two !)\" ads before a video starts, and the \"free\" version will just be a cesspool or rate limited to N-number ad-infested videos per hour. reply gigel82 15 hours agoparentprev [–] Display a price-tag on content. You can watch 2 ad breaks, or you can pay $0.05 to watch the video (or whatever it is Google is making off of them). Make it super easy to pay (for example with a prepaid wallet you can refill). replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Recent court cases in Germany have upheld the right of internet users to use ad-blockers as a means of avoiding intrusive advertising.",
      "The court rulings state that using ad-blockers does not violate copyright laws, giving users legal protection.",
      "However, the court also ruled that companies can choose to exclude users with ad-blockers from accessing their content or implement a paid access model."
    ],
    "commentSummary": [
      "The article discusses various topics related to user freedom and adblockers, including the impact of advertising on free speech and the legality and ethics of ad-blocking.",
      "It explores issues of malware, unauthorized computer use, and alternative monetization methods for content creators.",
      "Different viewpoints and suggestions are presented, such as paying for ad-free versions or exploring alternative revenue models for websites."
    ],
    "points": 149,
    "commentCount": 105,
    "retryCount": 0,
    "time": 1703516766
  },
  {
    "id": 38765196,
    "title": "Build Your Own Night Clock Projector: Easy DIY Guide (2018)",
    "originLink": "https://microengineer.eu/2018/05/01/diy-night-clock-projector/",
    "originBody": "DIY Night Clock Projector Veröffentlicht am Mai 1, 2018Juli 31, 2021 von Thomas Pototschnig A Clock Projector can project the time to a ceiling in the night. There are lots of commercial alarm clocks with integrated clock projector on the market but I thought, it would be fun to build one myself. Moreover it was a good project for becoming accustomed to the process of 3d-designing cases which can be 3d printed and to learn about designing tolerances. The principle is easy – basically it works like a video beamer (or any other projecting clock^^). LCD and Calculations I choosed a small negative (background black) 64×32 LCD which has the dimensions of just 15mm x 12mm (active area 11.18mm x 5.58mm). The goal was to build a complete projector with not more than 50mm x 50mm x 50mm (which I didn’t managed … But close to^^). A small LCD has the advantage that everything becomes smaller and cheaper – this influences heavily costs for optics because a smaller LCD needs smaller optics to project an low distorted image. Moreover a smaller LCD needs smaller focal length for a decent sized imaged on the ceiling. A good distance would be 2m from LCD to ceiling. The formula for image width depending from the focal length is defined as: with: – S2 distance from lens to LCD and – S1 distance from lens to ceiling – W2 is the width of the LCD – W1 is the width of the projected image The formulas show that the smaller the focal length the larger the projected image will be. I decided to go for 25mm because there are cheap lenses which can be obtained for about $12 in china. For our values that would magnify the image by about x80 – 11.1mm LCD width would become 88.1cm image width on the ceiling in a distance of 2m. Light and Condensor Lens It was not really clear how strong a LED has to be in order to get a reasonable well readable picture in the night on the ceiling. To be sure – actually I wasn’t really – I decided to use a high power LED with 1W and use a cheap chinese condensor lense to parallelize the light before it passes the LCD (this has do be done anyway but a condensor lens makes it possible to use more light because condensors are shaped in a way that allowes to get the lens as near to the LED as possible – so catching more light). The two pictures show the condensor-lense which is directly mounted to the PCB the resulting light spot on the ceiling. It is a really gread lens which is made for my LED – so it fits perfectly and parallelizes the light nicely. Electronics Construction Two PCBs were designed – one holding the LCD and the actual projecting board. The latter is equipped with 1W LED driver, STM32F103 Cortex ARM, a rotary encoder (for changing settings like brightness, standby-timer, time, …), USB, IR (both not used yet). Mechanics Construction Originally, I aimed for 50mm x 50mm x 50mm but I only managed to get to 60mm x 60mm x 60mm 😥 😉 Here an overview about all I designed: From left to right: Case with DIY projection lens (I skip this part – it worked but not really well), Sony E-Mount, C-Mount. In the middle the rest. LCD-Holder A custom LCD-holder was designed to perfectly mount the LCD on the right place on the PCB. Case – C-Mount Variant There are incredibly cheap chinase C-Mount lenses with a focal length of 25mm. They are sooo cheap that image quality is really really bad when using for fotography. But surprisingly it works (almost) perfect for the Mini DIY Projector 😀 The pillow-effect (optical distortion where the edges are not straight but bent outwards) is almost neglectable – resulting a much better image than I expected (after reading reviews to this lense) Case – Sony E-Mount Variant Just for fun – and because I have a 3d printer which works reliably without much attention – I did a variant for Sony E-Mount. Here the projector with Walimex Pro 10mm 2.8 lens. I have to admit – it isn’t that bright in reality but it’s still very readable although it is so large. The image has more than 2m in width! And distortions almost non-existent 🙂 Downloads Followig GitHub-Repository contains: – Schematic – Layout – Bill of material – STM32 Cortex ARM Source – 3D-STL-Files – Images Link to GitHub Repository STL-Files on Thingiverse Ähnliche Beiträge",
    "commentLink": "https://news.ycombinator.com/item?id=38765196",
    "commentBody": "DIY Night Clock Projector (2018)Hacker NewspastloginDIY Night Clock Projector (2018) (microengineer.eu) 147 points by GeoAtreides 14 hours ago| hidepastfavorite40 comments speps 12 hours agoI bought a MicroVision Laser Projector from eBay a while ago. It doesn&#x27;t need the usual focus adjustment and can project from 15cm to 2.5m. Originally only meant to be used with an iPod, I managed to get the VGA cable as well which will be useful.Docs: https:&#x2F;&#x2F;www.projectorcentral.com&#x2F;Microvision-SHOWWX_Laser_Pi... Tech details: https:&#x2F;&#x2F;www.techinsights.com&#x2F;blog&#x2F;look-inside-microvisions-p... reply sllabres 8 hours agoparentDoes someone know why all these small laser mems projectors are discontinued? Anyview, Sony, ... Is it a reliability issue?I found them quite interesting for similar applications especially as there is no need to focus and an image on a curved abject is possible. reply kedikedi 1 hour agorootparentI have two of the microvision ones and I can tell you the reason: they have to scan to draw and that makes everything look very wobbly. It isn’t something you can clearly see but it is stil somehow visible (through peripheral vision I suppose). It makes looking at still images and text very tiring.Theoretically you can make it scan faster and that’ll fix it, but there’s probably more to it than just faster scanning. reply spdustin 11 hours agoparentprevWhere’d you find the VGA cable? I’ve held on to my MV for years in hopes I could find time to resurrect it. I only had a dock connector, like you. I thought about just using composite and an external video DAC, but I know the thing can take a VGA signal as well. reply speps 10 hours agorootparentIt was just on eBay around the same time, didn&#x27;t know it was hard to find, just needed it as the dock option was already obsolete by that point. Although I think I&#x27;ve now got a compatible iPod Nano found purely by chance. reply vardump 11 hours agoparentprevCan it run continuously for years? reply daemonologist 5 hours agoprevI&#x27;ve often wondered why mono LCD projectors aren&#x27;t more common - it seems like they&#x27;d be easier to make by a nontrivial amount and allow higher brightness&#x2F;efficiency. I guess it&#x27;s a matter of market scale as usual, or maybe I just don&#x27;t know the right search keywords. (You do see mono LCDs nowadays in SLA 3d printers though.) reply Havoc 12 hours agoprevImage is impressively sharp reply netsharc 8 hours agoparentI think the sharp image is from the projector mounted to a professional camera lens, not the cheap AliExpress one... reply addandsubtract 7 hours agorootparentOnly the last pic seems to be from the pro lens. The others before are almost as sharp with just the small lens. reply kentiko 12 hours agoprevI love this. I would really like to have a clock like this with the outside temperature and maybe a counter for unread messages. reply FirmwareBurner 12 hours agoparentA counter for unread messages on the bedroom clock? I can&#x27;t think of anything more anxiety inducing for my sleep than that. Bedtime is the one time and place I want to fully disconnect from anything &#x27;on-line&#x27;.I even charge my phone in the other room just to eliminate the thought of reaching over from the bead to the nightstand to do &#x27;smartphone things&#x27; with it. reply kentiko 11 hours agorootparentIt could be set with an allowed list of friends and family only. The idea for me would be to know if it&#x27;s worth looking at my phone if someone I care about tried to reach me, or if I can keep my eyes closed a bit longer instead. I absolutely do not want an email or Slack messages counter, of course. But in any case, maybe you are right, and it&#x27;s a bad idea entirely... reply shiroiuma 5 hours agorootparentNo, I agree: I&#x27;d want some kind of app&#x2F;webui where I could select which people I really care about, and the counter will show me if those people, and only those people, have sent me messages. So basically, my most immediate family and my girlfriend and that&#x27;s it. If any of them send me a message, I&#x27;m willing to check it out. reply zikduruqe 10 hours agoparentprevThey make them. I used to have one years ago, minus the message notifications. reply ourmandave 12 hours agoprevCan you adjust the size to like 3&#x27; numbers?I&#x27;m so near sighted the store bought ones that project on the ceiling are like trying to read the bottom row of an eye chart. reply GeoAtreides 12 hours agoparentThe article gives a formula for image width; the author also tried it with a Walimex Pro 10mm 2.8 lens, which gave a 2 meter width image. reply stavros 10 hours agoprevI&#x27;ve always wanted one of these. Unfortunately, I sleep on my side or stomach, so I&#x27;d never be able to see it. reply seabass-labrax 9 hours agoparentYou could mount it on the ceiling at the foot of your bed, then rotate it to shine at your bed&#x27;s headboard! reply stavros 9 hours agorootparentBut then I have the same issue, as I never look at my headboard! I made a bedside table alarm clock instead, it&#x27;s pretty good. reply roge7331 12 hours agoprevI love the project in terms of creating something but actually using such a clock just gives me anxiety just thinking about it. Endless cycle of waking up, checking the time, calculating the rest hours until I need to get back and falling back to sleep. reply laweijfmvo 7 hours agoparentOne of several things I’ve done over the years to optimize my sleep is never look at the time if i wake up. just go back to sleep. reply shiroiuma 5 hours agoparentprevMaybe it can be connected to a voice-interface system so you have to actually tell it \"show me the time\". reply JKCalhoun 10 hours agoprevMaybe attach an old iPad to you ceiling? reply netsharc 8 hours agoparentOne would need many iPads for a 90cm wide image (about a yard for the non-SI), but hey, it seems like it&#x27;d be easy enough to gather obsolete iPads to pull that off... reply barbs 11 hours agoprevCool project. Does anyone know if they make those LCD screens in a higher definition? I&#x27;ve tried googling but I tend to find consumer electronics instead of electronic components. reply orenlindsey 11 hours agoprevIt would be too bright for me. And it would probably be quite anxiety-inducing. reply Rebelgecko 11 hours agoparentFWIW you could probably just recompile with a lower brightnessEdit: nvm, just reread and saw the rotary encoder. So no need to recompile! reply KennyBlanken 14 hours agoprev [12 more] This seems incredibly counter to good sleep hygine. There&#x27;s extensive evidence that even relatively low levels of light harm sleep quality; blue light from white LEDs is particularly disruptive to circadian rhythm, and if you&#x27;re having trouble falling to sleep, this seems like an excellent way to just ramp up your anxiety?One of the best things I did for sleep anxiety was to NOT have a bedroom clock at all, my phone goes face-down, I disabled my watch&#x27;s auto-backlight functions, and I&#x27;ve tried very, very hard to not try and figure out the time once I&#x27;m \"going to bed.\" Thankfully my e-reader also doesn&#x27;t have a clock displayed unless you tap something, so if I wake up, I can read (with an orange book reading light) until I&#x27;m sleepy.The only lights I have that are on once I&#x27;m in bed are red LED night-lights (finding them was surprisingly tough.)Literally never has determining what time it is helped me get back to sleep. reply jstanley 13 hours agoparentWhat about when you wake up and it&#x27;s still dark and you don&#x27;t know whether it&#x27;s worth trying to go back to sleep? reply ginko 25 minutes agorootparentI was thinking of building a touch-operated clock for that. Some sort of dongle with a single button that would vibrate the hour and quarter-hours like a church bell.You could keep it under your blanket so you wouldn&#x27;t need to move all that much to check the time. reply nkrisc 13 hours agorootparentprevThat’s what alarms are for. You go back to sleep and your alarm will wake you up.In my opinion it’s always worth trying to go back sleep if you’ve got an alarm.Speaking for myself, there’s nothing worse for falling back asleep than looking at the time. When I wake at night and it’s dark, it might be 11pm, 2am, or 5am. I don’t want to know what time it is. I go back to sleep and unless it happens to actually be within minutes of my alarm, I’ll fall back asleep and never know what time it was. reply Turing_Machine 13 hours agorootparentprevExactly so. \"Do I have time to get another hour or two of sleep, or is it time to get up and make coffee?\" reply theglenn88_ 13 hours agorootparentYou and parent comment don’t have kids xD reply mft_ 13 hours agoparentprevI recall reading about a bedside clock which offers a dim and subtle colour-shift at certain times; for example, it might glow red until 4am, amber from 4-6am, and green from 6am onwards.The idea was to offer you you the ability to roughly determine the time to aid decision-making (as another commenter wrote, &#x27;is it worth trying to go back to sleep?&#x27;) without the alertness and&#x2F;or anxiety that interacting with a gadget that tells the exact time. reply nirav72 13 hours agoparentprevCan be easily solved by adding some kind of motion sensor. Wave hand and the clock projects the time on the ceiling. Have a 10-15 second time out period to turn off the projection. reply 2024throwaway 13 hours agoparentprev> There&#x27;s extensive evidence that even relatively low levels of light harm sleep quality; blue light from white LEDs is particularly disruptive to circadian rhythmMaybe not.https:&#x2F;&#x2F;www.unibas.ch&#x2F;en&#x2F;News-Events&#x2F;News&#x2F;Uni-Research&#x2F;Light... reply itishappy 12 hours agoparentprevYeah, when I complained about sleep issues, projector clocks were one of the first thing my doctor mentioned. Right up there with screen time and food before bed. I was told no light, no clocks, phone on the other side of the room.Anecdotally, removing my brains ability to worry about how soon I need to wake up has been one of the most impactful sleep hacks I&#x27;ve found. reply 1023bytes 13 hours agoparentprevRed filter could probably help reply elsewhen 9 hours agoparentprev [–] What about including a red light filter? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The DIY Night Clock Projector is a project that involves building a clock projector that can project the time onto a ceiling at night.",
      "The project utilizes a small negative LCD screen and calculates the image size based on the focal length.",
      "It includes two PCBs designed for the electronics construction and offers various case options. Additionally, downloadable files for schematics, layout, bill of materials, and 3D STL files are provided."
    ],
    "commentSummary": [
      "The article explores a DIY night clock projector project using a MicroVision Laser Projector.",
      "The author shares their personal experience with the projector and addresses the availability of VGA cables for it.",
      "Comments from users touch upon the discontinuation of small laser MEMS projectors, concerns regarding image quality, and suggestions for alternative options to address potential sleep quality issues."
    ],
    "points": 147,
    "commentCount": 40,
    "retryCount": 0,
    "time": 1703531529
  },
  {
    "id": 38763933,
    "title": "The Rise of Affordable Computing: From Mainframes to Microcomputers",
    "originLink": "https://www.theregister.com/2023/12/25/the_war_of_the_workstations/",
    "originBody": "OSes 33 War of the workstations: How the lowest bidders shaped today's tech landscape 33 The MIT and New Jersey schools of software design, and how big lies turned into holy truths Liam Proven Mon 25 Dec 2023 // 15:57 UTC Feature Digging into stories of 1980s OSes, a forgotten war for the future of computing emerges. It was won by the lowest bidders, and then the poor users and programmers forgot it ever happened. Retrocomputing is a substantial, and still growing, interest for many techies and hobbyists, and has been for a decade or two now. There's only so much you can write about a game that's decades old, but operating systems and the different paths they've taken still have rich veins to be explored. Anyone who played with 1980s computers remembers the Amiga versus the Atari ST and other battles. But digging down past the stratum of cheap home computers and gaming reveals bigger, more profound differences. The winners of the battles got to write the histories, as they always do, and that means that what is now received wisdom, shared and understood by almost everyone, contains and conceals propaganda and dogma. Things that were once just marketing BS are now holy writ, and when you discover how the other side saw it, dogma is uncovered as just big fat lies. The biggest lie The first of the big lies is the biggest, but it's also one of the simplest, one that you've probably never questioned. It's this: Computers today are better than they have ever been before. Not just that they have thousands of times more storage and more speed, but that everything, the whole stack – hardware, operating systems, networking, programming languages and libraries and apps – are better than ever. The myth is that early computers were simple, and they were replaced by better ones that could do more. Gradually, they evolved, getting more sophisticated and more capable, until now, we have multi-processor multi-gigabyte supercomputers in our pockets. Which gives me an excuse to use my favorite German quote, generally attributed to physicist Wolfgang Pauli: \"Das ist nicht nur nicht richtig; es ist nicht einmal falsch!\" (That is not only not right, it is not even wrong!) Though probably apocryphal, someone asked John Glenn, America's first person in space, what it felt like just before launch. Supposedly, he replied: \"I felt about as good as anybody would, sitting in a capsule above a rocket that were both built by the lowest bidder.\" Well, that is where we are today. The story about evolution is totally wrong. What really happened is that, time after time, each generation of computers developed until it was very capable and sophisticated, and then it was totally replaced by a new generation of relatively simple, stupid ones. Then those were improved, usually completely ignoring all the lessons learned in the previous generation, until the new generation gets replaced in turn by something smaller, cheaper, and far more stupid. Evolution The first computers, of course, were huge room-sized things that cost millions. They evolved into mainframes: very big, very expensive, but a whole company could share one, running batch jobs submitted on punched cards and stuff like that. After a couple of decades, mainframes were replaced by minicomputers, shrunk to the size of filing cabinets, but cheap enough for a mere department to afford. They were also fast enough that multiple users could use them at the same time, using interactive terminals. All the mainframes' intelligent peripherals, networked to their CPUs, and their sophisticated, hypervisor-based, operating systems, with rich role-based security just thrown away. Then, it gets more complicated. The conventional story, for those who have looked back to the 1970s, is that microcomputers came along, based on cheap single-chip microprocessors, and swept away minicomputers. Then they gradually evolved until they caught up. But that's not really true. First, and less visibly because they were so expensive, department-scale minicomputers shrank down to desk-sized, and then desk-side, and later desk-top, workstations. Instead of being shared by a department, these were single-user machines. Very powerful, very expensive, but just about affordable for one person – as long as they were someone important enough. Unfortunately, though, in the course of being shrunk down to single-user boxes, most of their ancestors' departmental-scale sophistication was thrown away. Rich file systems, with built-in version tracking, because hard disks cost as much as cars: gone. Clustering, enabling a handful of machines costing hundreds of thousands to work as a seamless whole? Not needed, gone. Rich built-in groupware, enabling teams to cooperate and work on shared documents? Forgotten. Plain-text email was enough. Meanwhile, down at the budget end and at the same time as these tens-of-thousands-of-dollar single-user workstations, dumb terminals evolved into microcomputers. Every computer in the world today is, at heart, a \"micro.\" At first, they were feeble. They could hardly do anything. So, this time around, we lost tons of stuff. Hard disks? Too expensive. Dropped. Multitasking? Not enough memory. Removed. Choice of programming languages? Retained in the 1970s CP/M machines, then when they got cheaper still in the early '80s, dropped: kids don't need that. Shove BASIC in a ROM, that will do. The machines mostly got used for playing games anyway. Early micros could handle floppy disk drives and had a DOS, but over the longer run, even those got eliminated: too expensive. Instead, you got an audio cassette recorder. How we got here Those early-1980s micros, the weakest, feeblest, most pathetic computers since the first 1940s mainframes, the early eight-bit micros, those are the ancestors of the computers you use today. In fact, of all the early 1980s computers, the one with the most boring, unoriginal design, the one with no graphics and no sound – that, with a couple of exceptions, is the ancestor of what you use today. The IBM PC, which got expanded and enhanced over and over again to catch up and eventually, over about 15 years, exceed the abilities of its cheaper but cleverer rivals. It is a sort of law of nature that when you try to replace features that you eliminated, the result is never as good as if you designed it in at the beginning. We run the much-upgraded descendants of the simplest, stupidest, and most boring computer that anyone could get to market. They were the easiest to build and to get working. Easy means cheap, and cheap sells more and makes more profit. So they are the ones that won. There's a proverb about choosing a product: \"You can have good, fast, and cheap. Choose any two!\" We got \"fast\" and \"cheap.\" We lost \"good\", replaced by \"reliable,\" which is definitely a virtue, but one that comes with an extremely high price. What we lost Like many a middle-aged geek, there was a time when I collected 1980s hardware, because what was inaccessible when it was new – because I couldn't afford it – was being given away for free. However, it got bulky and I gave most of it away, focusing on battery-powered portable kit instead, partly because it's interesting in its own way, and partly because it doesn't take up much room. You don't need to keep big screens and keyboards around. That led me to an interesting machine: the other line of Apple computers, the ones that Steve Jobs had no hand in at all. The machine that inspired Jobs, which led to the Lisa and then the Mac, was of course the Xerox Alto, a $30,000 deskside workstation. In Jobs' own words, he saw three amazing technologies that day, but he was so dazzled by one of them that he missed the other two. He was so impressed by the GUI that he missed the object-oriented graphical programming language, Smalltalk, and the Alto's built-in ubiquitous networking, Ethernet. The Lisa had none of that. The Mac had less. Apple spent much of the next 20 years trying to put them back. In that time, Steve Jobs hired John Sculley from PepsiCo to run Apple, and in return, Sculley fired Jobs. What Apple came up with during Sculley's reign was the Newton. I have two Newtons, an Original MessagePad and a 2100. I love them. They're a vision of a different future. But I never used them much: I used Psions, which had a far simpler and less ambitious design, meaning that they were cheaper but did the job. This should be an industry proverb. The Newton that shipped was a pale shadow of the Newton that Apple originally planned. There are traces of that machine out there, though, and that's what led to me uncovering the great computing war. The Newton was – indeed, still is – a radical machine. It's designed to live in your pocket, store and track your information and habits. It had an address book, a diary, a note-taking app, astonishing handwriting recognition, and a primitive AI assistant. You could write \"lunch with Alice\" on the screen, and it would work out what you wrote, analyze it, work out from your diary when you normally had lunch, from your call history where you took lunch most often and which Alice you contacted most often, book a time slot in your diary and send her a message to ask her if she'd like to come. It was something like Siri, but 20 years earlier, and in that time, Apple seems to have forgotten all this: It had to buy Siri in. NewtonOS also had no file system. I don't mean it wasn't visible to the user; I mean there wasn't one. It had some non-volatile memory on board, expandable via memory cards – huge PCMCIA ones the size of half-centimetre-thick credit cards – and it kept stuff in a sort of OS-integrated object database, segregated by function. The stores were called \"soups\" and the OS kept track of what was stored where. No file names, no directories, nothing like that at all. Apps, and some of the OS itself, were written in a language called NewtonScript, which is very distantly related to both AppleScript on modern macOS and JavaScript. But that was not the original plan. That was for a far more radical OS, in a more radical language, one that could be developed in an astounding graphical environment. The language was called Dylan, which is short for Dynamic Language. It still exists as a FOSS compiler. Apple seems to have forgotten about it too, because it reinvented that wheel, worse, with Swift. Have a look. Dylan is amazing, and its SK8 IDE even more so (a few screenshots and downloads are left). Dylan is very readable, very high-level, and before the commercial realities of time and money prevailed, Apple planned to write an OS, and the apps for that OS, in Dylan. Now that is radical: Using the same, very high-level, language for both the OS and the apps. It was feasible because Dylan is built as a layer on top of one of the oldest programming languages that's still in active use, Lisp. Both Smalltalk and Lisp are very much still around. For both, there are commercial and FOSS versions. Both can run on the .NET CLR and on the JVM. There's even a Smalltalk that runs in your browser on the JavaScript engine. The primary text editor of the Lisp environment is still widely used today, mostly by old-timers. But these are only traces. They are faint memorials left after the war. Because once, these things were not just slightly weird languages that ran on commodity OSes. They were OSes in their own right I started digging into that, and that's when the ground crumbled away, and I found that, like some very impressive CGI special effects, I wasn't excavating a graveyard but a whole, hidden, ruined city. Once, Lisp ran on the bare metal, on purpose-built computers that ran operating systems written in Lisp, ones with GUIs that could connect to the internet. And if you find the people who used Lisp machines ... wow. They loved them, with a passion that makes Amiga owners look like, well, amateurs, hobbyists. This level of advocacy makes Vi versus Emacs look like a playground squabble. Some of the references are easy to find. There's a wonderful book called The Unix-Haters Handbook [PDF] which I highly recommend. It's easy to read and genuinely funny. It's a digest of a long-running internet community from the time when universities were getting rid of Lisp machines and replacing them with cheaper, faster Unix workstations – Sun boxes and things like that. Lisp machine users were not impressed. For them, Unix was a huge step backwards. The code was all compiled, whereas Lisp OSes ran a sort of giant shared dynamic environment (it's hard to explain something when the words for it have been lost). On a Unix machine, if you didn't like the way a program did something, you had to go find the source code, edit it, save it in a new file, compile that file, restart the program to try it ... and if it worked, find your existing binary, and replace it with the new one. Then you would probably find that you'd made a mistake and it didn't work, and try again. This is why, apart from the hardcore Gentoo users, we all outsource this stuff to OS vendors and Linux distributors. On the Lisp machines, your code wasn't trapped inside frozen blocks. You could just edit the live running code and the changes would take effect immediately. You could inspect or even change the values of variables, as the code ran. Developer and blogger Steve Yegge called it \"living software.\" Lisp machines booted slowly, but that didn't matter much because you rarely cold booted them. At the end of the day, the OS wrote the values of all its objects and variables to disk – called \"saving a world\" – and then just stopped. When you turned it back on, it reread these values into memory, and resumed exactly where it was. Most of this, incidentally, also applies to Smalltalk machines. That's why these two are sometimes called languages of the gods. This is what Steve Jobs missed. He was distracted by the shiny. He brought the world the GUI, but he got his team to reimplement it on top of fairly conventional OSes, originally in a mixture of assembly and Pascal. He left behind the amazing rich development environment, where it was objects all the way down. And we never got it back We got networking back, sure, but not this. Now Lisp and Smalltalk are just niche languages – but once, both of them were whole other universes. Full-stack systems, all live, all dynamic, all editable on the fly. The closest thing we have today is probably JavaScript apps running in web browsers, and they are crippled little things by comparison. The difference, though, is where the biggest losses in the war came. Smalltalk machines ran on relatively normal processors. Smalltalk is all about objects, and you can't really handle objects at hardware level. (Well, you can – a very expensive Hi-Fi manufacturer called Linn tried with a machine called the Rekursiv, but it flopped badly. So did Intel's attempt to do a chip that implemented high-level stuff in hardware – not the Itanium, no, long before that, the iAPX 432.) But Lisp machines ran on dedicated chips, and this is where stuff gets real. As in, the stuff that hits the fan. There were several big vendors of Lisp machines. As we covered recently, Xerox sold them, and its Lisp OS is now FOSS. But the bigger one, and the most influential, was Symbolics. At risk of sounding like a hipster, \"you've probably never heard of it.\" Forgotten as it is now, as an indication of how significant the company was, it owned the first ever dot-com domain on the internet. It launched in 1980 with a commercial version of the MIT CADR Lisp machine, and made dedicated Lisp hardware until 1993. Revival of Medley/Interlisp: Elegant weapon for a more civilized age sharpened up again Version 100 of the MIT Lisp Machine software recovered The quest to make Linux bulletproof Linux luminaries discuss efforts to bring Rust to the kernel The company's dead, but the OS, OpenGenera, is still out there and you can run it on an emulator on Linux. It's the end result of several decades of totally separate evolution from the whole Mac/Windows/Unix world, so it's kind of arcane, but it's out there. There are a lot of accounts of the power and the productivity possible in Lisp and on Lisp machines. One of the more persuasive is from a man called Kalman Reti, the last working Symbolics engineer. So loved are these machines that people are still working on their 30-year-old hardware, and Reti maintains them. He's made some YouTube videos demonstrating OpenGenera on Linux. He talks about [video] the process of implementing the single-chip Lisp machine processors. We took about ten to 12 man-years to do the Ivory chip, and the only comparable chip that was contemporaneous to that was the MicroVAX chip over at DEC. I knew some people that worked on that and their estimates were that it was 70 to 80 man-years to do the microVAX. That in a nutshell was the reason that the Lisp machine was great. Now that is significant. When different people tell you that they can achieve such a huge differential in productivity – one tenth of the people taking one tenth of the time to do the same job – you have to pay attention. 'Better is the enemy of good' I am not here to tell you that Lisp machines were some ultimate super workstation. An environment that is mostly semi-interpreted code, running in a single shared memory space, is not very stable ... and when it crashes, if you don't have a snapshot to go back to, you have pain in store. The point here is not that this long-gone technology was better in every way. It wasn't. But it did have advantages, and it's instructive to look at some of these that were shared by both Lisp and Smalltalk machines. They were written in one language, or mostly in one, all the way down. As original Smalltalk implementer Dan Ingalls put it: \"An operating system is a collection of things that don't fit inside a language; there shouldn't be one.\" They had a pervasive model of data, all the way down the stack. In Smalltalk, everything is objects. In Lisp, everything is lists. What the Unix model offers by comparison is weak stuff: Everything is a file. More big lies The Unix model of computation was designed in response to Multics, the original all-singing, all-dancing 1960s OS. Unix was intended, in contrast, to be the ultimate in minimalism (although it very much is not anymore). This shows up another of the big lies that everyone just takes as read, but this one has layers like a cabbage: For speed, you need a language that's close to the metal. That means it must be very simple. This has costs, but they're worth it: the programmer must manually manage their memory, meaning that they must be very, very careful. But that's hard, so to keep life easier, you layer simpler languages on top. Early on, AWK and SED and so on; later, Perl and Python; then later still, runtimes such as the JVM and WASM, and languages on top of that, such as Clojure or Scala. As the stack matures, it grows ever more layers. The higher layers are ever further from the metal. Many of these languages are much easier but slower. In the old days, you needed to rewrite code in a lower-level language for speed, such as C++. So what if it's huge? You don't need all of it! So what if it's hard to read? It was hard to write! Then, in time, computers keep getting faster, so you can retain the inefficient implementation and keep going. The result is a folk belief that there is a necessary, implicit contrast between \"readable\" and \"fast.\" This is one of the big assumptions behind both the Unix and Windows schools of OS design, that different languages are best for different jobs, and so you need a mixture of them. That means that the layers are sealed off from one another, because of different models of variable storage, of memory management, etc. That's one big lie. Firstly, because the layers are not sealed off: higher-level languages are usually implemented in lower-level ones, and vulnerabilities in those permeate the stack. For instance, a common way of trying to make stuff safer is to wrap it in a runtime or VM, but that doesn't solve the problem, it creates new ones. Problem: The language eliminates whole types of error, but they persist in the VM. Problem: Now, your code is dependent on the performance of the VM. Problem: Try to fix either of these, you risk breaking the code. Problem: Because the VM isn't part of the OS, you end up with multiple VMs, all sharing these issues. Secondly, there is the existence proof that multiple projects and products, successful in their time, show that if you pick the right language, you can built your entire stack all in one. Lisp code is structured as lists, which is the data structure that Lisp is designed to manipulate. That is the reason for its legendary plethora of parentheses. It also makes it very easy to write macros that manipulate program code, meaning programs can modify themselves. This sort of thing is why Neal Stephenson referred to it thus: It is written in Lisp, which is the only computer language that is beautiful. It is highly readable, and vastly powerful. Alan Kay, the designer of Smalltalk, said of Lisp: When I finally understood that the half page of code on the bottom of page 13 of the Lisp 1.5 manual was Lisp in itself. These were Maxwell's Equations of Software! This is the whole world of programming in a few lines that I can put my hand over. These are powerful qualities – but possibly only to a certain type of mind. Dylan, however, shows that it need not be like that. If you lose the list-based notation, yes, there is a price in efficiency and power, but the result is readable by mere mortals. Dylan was not the only attempt to do this. There are quite a few – PLOT, CGOL, sweet expressions, the cancelled Lisp 2 project, and more. The plan was that the Newton would be a Dylan-based Lisp machine in your pocket. The Newton was Sculley's baby. Jobs didn't invent it, so he didn't like it, derided it as a \"scribble thing,\" and on his return to Apple he killed it along with Hypercard. In 1993, the Newton was Apple's first Arm-powered computer, a CPU architecture it returned to 17 years later. It was planned to be the a pocket Lisp workstation, and it launched the same year that Symbolics quit making Lisp processors and moved to the DEC Alpha [PDF] instead. In the end, the big fight was between dedicated hardware, with custom processors running custom operating systems, versus a shared, lowest-common-denominator technology: UNIX, running at first on off-the-shelf chips such as the Sun-1's Motorola 68000 and later on RISC chips such as Sun's SPARC and the MIPS R2000, launched the same year as Acorn's RISC OS 2 on its ARM chips. A cross-platform OS, its development sponsored by Bell Labs and refined at the University of California, compiled from source written in a cut-down form of BCPL. As is usually the way, the cheaper, simpler solution won. Commodity chips were replaced with faster RISC chips, broadly speaking designed to run compiled C code efficiently. Then, decades later, the PC caught up: 32-bit x86 processors became comparable in performance to the RISC chips, and we ended up with a few varieties of Unix on x86, plus Windows NT. Unix, of course, was originally developed on the DEC PDP-7, moved to the PDP-11, and later its 32-bit successor the VAX. Windows NT, meanwhile, was designed by the chief architect of the VAX's native OS, VMS. That's why it's so visibly influenced by it. Instead of DEC's BLISS language, NT is implemented in Unix's native language, C. From the perspective of a Smalltalk or Lisp machine, they are siblings, almost twins, with deep roots in DEC. They are representatives of a school of design called the \"New Jersey approach\" by Lisp luminary Richard Gabriel in his essay \"Lisp: Good News, Bad News, How to Win Big\" [PDF]. He compares it to what he calls the \"MIT approach,\" and his summary of the New Jersey way is called \"Worse is Better.\" It's well worth reading at least the summary, but the key points are this. The MIT/Stanford style of design ... captured by the phrase the right thing ... it is important to get all of the following characteristics right: Simplicity – the design must be simple, both in implementation and interface. It is more important for the interface to be simple than the implementation. Correctness – the design must be correct in all observable aspects. Incorrectness is simply not allowed. Consistency – the design must not be inconsistent. A design is allowed to be slightly less simple and less complete to avoid inconsistency. Consistency is as important as correctness. Completeness – the design must cover as many important situations as is practical. All reasonably expected cases must be covered. Simplicity is not allowed to overly reduce completeness. He continues: The worse-is-better philosophy is only slightly different: Simplicity – the design must be simple, both in implementation and interface. It is more important for the implementation to be simple than the interface. Simplicity is the most important consideration in a design. Correctness – the design must be correct in all observable aspects. It is slightly better to be simple than correct. Consistency – the design must not be overly inconsistent. Consistency can be sacrificed for simplicity in some cases, but it is better to drop those parts of the design that deal with less common circumstances than to introduce either implementational complexity or inconsistency. Completeness – the design must cover as many important situations as is practical. All reasonably expected cases should be covered. Completeness can be sacrificed in favor of any other quality. In fact, completeness must be sacrificed whenever implementation simplicity is jeopardized. Consistency can be sacrificed to achieve completeness if simplicity is retained; especially worthless is consistency of interface. Early Unix and C are examples of the use of this school of design, and I will call the use of this design strategy the New Jersey approach. I have intentionally caricatured the worse-is-better philosophy to convince you that it is obviously a bad philosophy and that the New Jersey approach is a bad approach. The conclusion, though, is the stinger: However, I believe that worse-is-better, even in its strawman form, has better survival characteristics than the-right-thing, and that the New Jersey approach when used for software is a better approach than the MIT approach. Time has certainly proved Dr Gabriel correct. Systems of the New Jersey school so dominate the modern computing industry that the other way of writing software is banished to a tiny niche. Smalltalk evolved into Self, which begat JavaScript, which in the hands of a skilled Smalltalker can do amazing things – but only its visual design transformed the computer industry. The Lisp text editor is now just one of the more arcane options on Linux boxes. Lisp itself is a fringe programming language, beloved by some industry heroes but ignored by most – even those who need the very best tools. As one famous Lisp programmer put it: Writing in C is like building a mosaic out of lentils using a tweezer and glue. If you want to become a billionaire from software, you don't want rockstar geniuses; you need fungible cogs, interchangeable and inexpensive. Software built with tweezers and glue is not robust, no matter how many layers you add. It's terribly fragile, and needs armies of workers constantly fixing its millions of cracks and holes. There was once a better way, but it lost out to cold hard cash, and now, only a few historians even remember it existed. ® Bootnote For a look at a Lisp machine in action, as well as BTRON and IBM i, this talk from the Chaos Computer Congress entitled \"What have we lost?\" is worth a watch. Whitepaper: Top 5 Tips For Navigating Your SASE Journey Share More about MIT Software More like these × More about MIT Software Narrower topics AdBlock Plus App Application Delivery Controller Audacity Confluence Database FOSDEM FOSS Grab Graphics Interchange Format IDE Jenkins Legacy Technology LibreOffice Map Microsoft 365 Microsoft Office Microsoft Teams Mobile Device Management OpenOffice Programming Language QR code Retro computing Search Engine Software bug Software License text editor User interface Visual Studio Visual Studio Code WebAssembly Web Browser Wordpress Broader topics Education More about Share 33 COMMENTS More about MIT Software More like these × More about MIT Software Narrower topics AdBlock Plus App Application Delivery Controller Audacity Confluence Database FOSDEM FOSS Grab Graphics Interchange Format IDE Jenkins Legacy Technology LibreOffice Map Microsoft 365 Microsoft Office Microsoft Teams Mobile Device Management OpenOffice Programming Language QR code Retro computing Search Engine Software bug Software License text editor User interface Visual Studio Visual Studio Code WebAssembly Web Browser Wordpress Broader topics Education TIP US OFF Send us news",
    "commentLink": "https://news.ycombinator.com/item?id=38763933",
    "commentBody": "War of the workstations: How the lowest bidders shaped today&#x27;s tech landscapeHacker NewspastloginWar of the workstations: How the lowest bidders shaped today&#x27;s tech landscape (theregister.com) 145 points by lproven 17 hours ago| hidepastfavorite78 comments di4na 11 hours agoOne thing i think forgotten here, which actually is in the Worse is Better talk. But people tend to miss it.These ST and Lisps systems failed at another aspect. Reuse. The biggest change of the past 2 decades in software engineering compared to previous generations is the amount of reuse. It is tremendous.It is hard to talk of cause and effects here, but mostly this is due to the Internet. At this point, the vast majority of code running on any proprietary system is... Open source infrastructural packages.This condition a lot of the current ecosystem. You can only reuse code on systems in which said code runs well. As such, the Linux \"stability\" combined with x86 won, same as C and friends because of the tooling that made the code \"portable\".Yes i know. It is far from magically portable, but it is far more than full machine living image SmallTalk or Lisp like.As such, these \"living code\" are fundamentally evolutionary deadend. They are amazing but they cannot easily move to different machines and sharing parts of them is hard to separate from the rest of the living organism.On top of this, a lot of the elements to make this kind of machine works does necessitate deep in depth expertise. As the piece shows, the Newton is a pale copy of the goal because they did not have that knowledge in house nor the time (or money) to create it.Same thing all over the stack. A good efficient logger need deep expertise. Same for a good localization library. Same for a good set of graphic servers. Same for audio servers. Same for a http parser or a network library. A good regexp engine is knowledge knows by less than 10 people in the world probably.Once you realise that, you realise that at scale reuse is the only realistic way forward for software so ubiquitous as it is today. And that is how we got the current FOSS ecosystem, not because the code is better but because it would need too many licences to be manageable without breaking the bank in numbers of lawyers.Same thing for the Worse is Better. It works because it provides extension points and can adapt. Something the Lisp and SmallTalk machines fundamentally failed to provide. And that is something Richard Gabriel focuses on far more than the whole New Jersey schtick in his talk. reply lispm 1 hour agoparent> They are amazing but they cannot easily move to different machines and sharing parts of them is hard to separate from the rest of the living organism.The code of a Symbolics Lisp Machine is written in so-called \"systems\". A \"system\" is a collection of files in a directory. Moving the code to another machine is either a) a copy of the directories to another directory or b) dumping an archive to copy to somewhere else or c) most of the time not necessary, since the Lisp Machine edits files on NFS file servers , which makes it possible to share the Lisp code directly with other Lisp systems in the network.The Symbolics keeps track of versions of files and systems, something other Lisp systems typically don&#x27;t do themselves.> As such, the Linux \"stability\" combined with x86 won, same as C and friends because of the tooling that made the code \"portable\".There is little stability. The main theme is ever evolving fragmentation. Linux &#x2F; BSDs is fragmented in zillions distributions, variants, versions, competing library variants, software archive systems, ... and open source UNIX is fragmented into various BSDs, Linux variants, ... Look at some portable code, it uses a huge configuration checker, which looks for all the variations of code and libraries. Zillions of checks... reply smackeyacky 3 hours agoparentprevLisp and Smalltalk failed because it was near impossible to share the code. Living images are really hard to merge.Smallltalk did eventually get a fantastic solution for code sharing between living images (Envy&#x2F;Developer) but by that stage it was too late.All that philosophical guff about “worse is better” had nothing to do with the practical ease of sharing files rather than a tangled mess of code that Lisp and Smalltalk encouraged. Sharing files is definitely not “worse” by any definition. reply msh 11 hours agoprevI think the author confused lowest bidder with producing something people could afford. For all their weaknesses micro&#x27;s could be purchased by normal people. You could not produce a lisp machine or alto equalent in the 80&#x27; that it was possible to afford for regular people. reply ta988 10 hours agoparentAnd Lisp machines were extremely complicated to use. Every time I see one at Vintage computer conventions I am reminded that. reply dreamcompiler 7 hours agorootparentThey were complicated to use but they were also self-teaching. I learned how to use a Lisp machine by sitting in front of one and trying things. By the end of a week I was fluent. And this was before the Internet; there was no Google. The machine itself contained all the docs and tutorials you needed to learn it. This was a remarkable achievement.Once you learned it you felt like a god because of the abilities the machine gave you. Some degree of learning curve was more than acceptable for that kind of power. reply whartung 6 hours agorootparentI did not have this experience.We had a pair of them, TI Explorers, in our office. I spent several hours over different days \"fiddling\" with them, and made no progress.The single person that could use them, was not a generalist at all. He simply knew whatever was necessary to dabble wit the expert system bit he was working on.Whatever intuitive relationships were to flower from access, did not manifest with this person. Simply, he wasn&#x27;t seeking them. He was focused on his little task. If the training docs said \"type xxx and hit F5\" he would do so without spending an iota of attention about either what he was typing, why he was typing it, or whatever the F5 button did.I made no progress on that machine. Perhaps if I had an hour of knowledgable introduction or guidance as a jumping off point, it would have been different and it would have opened a world to explore.But at the time, for me, it was inscrutable and I went back spending my time on the Suns that we had instead. reply dreamcompiler 4 hours agorootparentCan&#x27;t speak to your experience with TI machines because I never used them. I learned on Symbolics and LMI machines. reply gonzo 3 hours agorootparentprevTI Explorer LX machines ran Unix with LISP on top. Very different. reply nl 3 hours agorootparentprevUnix had (has!) excellent manual page (man ls for those who don&#x27;t know). I had a similar experience learning SunOS in the early 90s like this. reply lispm 1 hour agorootparentYou can see the Symbolics documentation interface in action: https:&#x2F;&#x2F;vimeo.com&#x2F;83886950It comes with built-in hypertext documentation, which was available online and printed. reply DonHopkins 7 hours agorootparentprevAnd once you let the Lisp Machine teach you everything about itself, you had superhuman abilities!One of my favorite Lisp Machine stories (I&#x27;ve fixed dead links to point to archive dot org, and archived the file from stanford&#x27;s ftp to my https server):https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30812434Reposting this from the 2014 HN discussion of \"Ergonomics of the Symbolics Lisp Machine\":https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7878679http:&#x2F;&#x2F;lispm.de&#x2F;symbolics-lisp-machine-ergonomicshttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7879364eudox on June 11, 2014Related: A huge collections of images showing Symbolics UI and the software written for it: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201216064308&#x2F;http:&#x2F;&#x2F;lispm.de&#x2F;s... ...agumonkey on June 11, 2014Nice, but I wouldn&#x27;t confuse static images with the underlying semantic graph of live objects that&#x27;s not visible in pictures.DonHopkins on June 14, 2014Precisely! When Lisp Machine programmer look at a screen dump, they see a lot more going on behind the scenes than meets the eye.I&#x27;ll attempt to explain the deep implications of what the article said about \"Everything on the screen is an object, mouse-sensitive and reusable\":There&#x27;s a legendary story about Gyro hacking away on a Lisp Machine, when he accidentally trashed the function cell of an important primitive like AREF (or something like that -- I can&#x27;t remember the details -- do you, Scott? Or does Devon just make this stuff up? ;), and that totally crashed the operating system.It dumped him into a \"cold load stream\" where he could poke around at the memory image, so he clamored around the display list, a graph of live objects (currently in suspended animation) behind the windows on the screen, and found an instance where the original value of the function pointer had been printed out in hex (which of course was a numeric object that let you click up a menu to change its presentation, etc).He grabbed the value of the function pointer out of that numeric object, poked it back into the function cell where it belonged, pressed the \"Please proceed, Governor\" button, and was immediately back up and running where he left off before the crash, like nothing had ever happened!Here&#x27;s another example of someone pulling themselves back up by their bootstraps without actually cold rebooting, thanks to the real time help of the networked Lisp Machine user community:ftp:&#x2F;&#x2F;ftp.ai.sri.com&#x2F;pub&#x2F;mailing-lists&#x2F;slug&#x2F;900531&#x2F;msg00339.html => https:&#x2F;&#x2F;donhopkins.com&#x2F;home&#x2F;SlugMailingList&#x2F;msg00339.html (I archived the whole directory so you can follow the \"Followups\" links to read the whole discussion.)Also eudox posted this link:Related: A huge collections of images showing Symbolics UI and the software written for it:http:&#x2F;&#x2F;lispm.de&#x2F;symbolics-ui-examples&#x2F;symbolics-ui-examples.... reply mycall 7 hours agorootparentprevMaybe something like LISP will be what AI naturally converges to on its own journey towards superhuman intelligence. reply lispm 10 hours agorootparentprevSlightly more complex than the UI of something like GNU Emacs, but with a better user interface. Keep in mind that not that many machines ever existed, I would think around 10000 -> thus the UI was less polished, but more capable.It&#x27;s definitely more difficult, because it does not look&feel like common other user interfaces (say, the Desktop Metaphor used by Apple and others), plus it lacks a few decades improvements. reply Phiwise_ 15 hours agoprevGlad to see you&#x27;re still fighting the good fight on this one, lproven. If anyone finds this interesting, Liam has three great fosdem lectures out introducing this topic from the perspective of business software dev, hardware tech, and open source. I found the first after reading The Unix-Haters Handbook, and as much as I like its style Proven&#x27;s videos are broader and up-to-date, so much better for learning:The Circuit Less Traveled: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=16309195Generation Gaps; a heretical history of computing: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22265615Starting Over; a FOSS propisal for a new type of OS for a new type of computer: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26066762I also coincidentally found what might be the only good video about the Apple Newton on the internet today (although with the state of google search it&#x27;s impossible to know outside of youtube). It makes a great supplement to the discussion of breaking the mold of OS conventions: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5kxRi34PqWoThe channel also has full interviews used in the dicumentary. I haven&#x27;t seen the newest one, but it&#x27;s two hours with a Mac and Newton architect so it&#x27;s probably great: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KsaGx0loR3M reply lproven 14 hours agoparentOh, thank you! :-) That was a very pleasant Newtonmas surprise to read! :-DYes, the core of this article was adapted -- with my editors&#x27; full knowledge and agreement, of course -- from one of my FOSDEM talks. I plan to return with some more of the talk -- and some new stuff! -- in later pieces.Sadly, the FOSDEM organisers did not accept my proposal for a talk this year. Ah well. reply DonHopkins 7 hours agorootparentI started reading the article, and it was making so much sense that I scrolled back up to the top to see if you wrote it, and you did! So I came here to say I really love your work because you really get the big picture and do your research, but somebody beat me to it, dammit! After recently watching that depressing trending four hour youtube video about psychopathic plagiarizing charlatans, it&#x27;s really refreshing and uplifting to read something original that&#x27;s so well researched with great citations. I hope you don&#x27;t get plagiarized too, but if you do, consider it the highest form of flattery. reply PeterStuer 2 hours agoprevI was around when our lab replaced Symbolics Lisp Machines with Sun workstations.Maybe this was a European (or non-US) thing, but non of the Lisp vendors had a built out worldwide distribution and service network, so buying and actually getting machines delivered was not a trivial undertaking.Once Sun did add the support for performant garbage collection that Lisp needed, the choice was clear. Local sales and service clenched the deal, and versatility and broader support were cherries on top. Then the whole lisp machine business collapsed so they weren&#x27;t even a remote option anymore.A relatively short term later Suns where replaced by Apple Mackintoshs running Mac Common Lisp. MCL was a very decent Lisp environment, machinrs were cheap and by now used for much more than just programming.The next wave would have been PCs, which had far better support. Apple never seemed to understand that your work depended on your computer, and that driving to an Apple store to drop of your machine so you could hopefully pick it up again in 2 to 3 weeks was not a serious option. Meanwhile Dell and the likes offered cheap Next Business Day on-site service.But PC&#x27;s for Lisp would be held back for a long time by Allegro cornering the PC Lisp market with a product that at the time felt inferior to MCL, while having very aggressive (phone) sales techniques and extremely high prices. reply tyingq 16 hours agoprevThere&#x27;s a lot that rings true here, but the article keeps noting that the IBM PC won partially because it was cheap. That&#x27;s only true versus the examples the authors cite. In the business space, it was pretty expensive when compared to, for example, business oriented Z80&#x2F;CPM platforms. And it was very expensive compared to the variety of home 8-bit choices. There were a lot of different markets&#x2F;niches at the time, and things changed quickly, so it&#x27;s hard to distill the history into soundbites about what happened and why. reply lproven 14 hours agoparentNot quite.Firstly, re predecessors:DOS was a lot more capable than CP&#x2F;M-80 and any 8-bit systems. It displaced them for much the same reasons x86-64 displaced x86-32: it became affordable to have lots of RAM. In the early 1980s, 8080&#x2F;Z80 couldn&#x27;t handle >64kB without clunky paging. Some 25Y later, x86-32 couldn&#x27;t handle >4GB without clunky paging, in much the same way.Secondly, re the PC&#x27;s cheapness. I&#x27;d argue the PC was cheap for a business machine, but it&#x27;s not simply that the PC hardware was cheap, but the bigger point that the bundle of the cheap machine and the cheap OS is what won out.The PC launched with 3 OSes: PC DOS, the UCSD p-System (a self-hosted Pascal IDE based on a JVM-like environment), and DR&#x27;s CP&#x2F;M-86.MS-DOS was about ¼ of the price of the other offerings.DR had an amazing comeback planned: it added the multitasking of MP&#x2F;M to CP&#x2F;M-86, creating Concurrent CP&#x2F;M, then bolted on MS-DOS emulation, to create a multitasking OS that could run and multitask MS-DOS apps on a 286: Concurrent DOS (CDOS for short).It also had a multitasking version of the GEM GUI called X&#x2F;GEM.This is something even the later OS&#x2F;2 1.x couldn&#x27;t do, and of course OS&#x2F;2 1.0 didn&#x27;t have a GUI at all.But CDOS&#x2F;286 depended on a feature of the development versions of the 80286 which Intel removed from the final shipping version. So, when IBM launched the first 286 PC, CDOS didn&#x27;t work.Intel put the hardware feature back but it was too late: the OS had been killed at birth -- it didn&#x27;t work on shipping 286 kit. Only native apps multitask.DR had a fallback plan: it promoted CDOS as a realtime OS and made a living for years afterwards, but the big product to outdo DOS, which originated as a clone of DR&#x27;s CP&#x2F;M anyway, was thwarted.So it&#x27;s not just \"the PC was cheap\", no. It&#x27;s bigger than that.It&#x27;s:* On the business desktop, the PC was cheap, _and_ the dominant PC OS was cheap, and the PC was built from open COTS parts and ran a COTS OS so was cheap to clone.* In academia and research, UNIX on mostly-COTS hardware killed off elaborate proprietary OSes on proprietary hardware. While PCs used x86, ST-506 and then ESDI and then IDE disks, ISA slot cards, etc., workstations used fancy 32-bit CPUs on fancy buses like NuBUS, VMEbus, and so on, with SCSI storage... and later moved to RISC chips with fancy buses and SCSI.This killed off proprietary non-open non-standard OSes such as VMS, Apollo DomainOS, and other exotica.Meanwhile, in business, DOS killed DR and the p-System and all the eight-bits.Later, Windows killed all the 16-bit GUI machines, except the Mac, which only survived by self-destroying and becoming a Unix machine. reply akira2501 12 hours agorootparent> ISA slot cardsThis was actually bigger than I think people remember. IBM gave away all the information on their bus standard immediately. They clearly understood they had to create a robust third party add on market for the PC and this would be key to driving the platform. They were not wrong. reply FirmwareBurner 12 hours agorootparentThey were not wrong in terms of what had to be done to make the OC platform the dominant one, except they didn&#x27;t get to profit from the PC business for too long. The openness \"mistake\" is what Apple fought to avoid. reply toyg 11 hours agorootparentAnd Apple almost died because of that opposition to openness. They only returned to profitability once they promised to be as open as everyone else: having intel processors and a standard Unix userland.(They then got filthy rich by effectively pivoting to portable computing, a world where openness and standardization were never essential.) reply lmm 10 hours agorootparent> And Apple almost died because of that opposition to openness. They only returned to profitability once they promised to be as open as everyone else: having intel processors and a standard Unix userland.Not really. The brief time when they allowed what we would now call \"hackintoshes\" was when they came closest to dying. They adopted intel processors for cost reasons, but went out of their way to keep their system \"different\". (And IIRC that was after they&#x27;d recovered to healthy profitability on the back of the iMacs and iPod) reply qwytw 9 hours agorootparentprev> They only returned to profitability once they promised to be as open as everyone else: having intelThey were profitable in the early 2000s with PowerPC and they probably would&#x27;ve stayed on it had it remained competitive with Intel. reply shrubble 9 hours agorootparentprevThey gave it away because of the consent decree they were operating under. Until the consent decree, IBM preferred to rent&#x2F;lease their computers to you, not sell them. reply Narishma 9 hours agorootparentprev> But CDOS&#x2F;286 depended on a feature of the development versions of the 80286 which Intel removed from the final shipping version. So, when IBM launched the first 286 PC, CDOS didn&#x27;t work.What feature was that? reply radicalbyte 12 hours agorootparentprevI&#x27;d argue that the Mac only survived because of the anti-trust case against Microsoft which meant that MS needed (on paper) competition so bailed them out., reply giantrobot 11 hours agorootparentprev> In the early 1980s, 8080&#x2F;Z80 couldn&#x27;t handle >64kB without clunky paging. Some 25Y later, x86-32 couldn&#x27;t handle >4GB without clunky paging, in much the same way.This isn&#x27;t analogous. At the time x86-64 was introduced virtually no one had memory limitation issues. PAE allowed the systems to have more than 4GB of RAM even if individual processes on 32-bit OSes were limited to 4GB. Even today you&#x27;d be hard pressed to find normal user workloads running into 4GB RAM limitations.That&#x27;s not to say larger memory spaces aren&#x27;t useful and aren&#x27;t used. It&#x27;s just not the same as some very basic task hitting limitations of only 64K of RAM. reply anigbrowl 6 hours agoprevReally outstanding article. The opening paragraphs did not hint at the depth to come; I&#x27;m happy I put in the time to read the whole thing. There were little bits I disagreed with or thought overly simplified, but on the whole a banger.This bit jumped outa t me:The language was called Dylan, which is short for Dynamic Language. It still exists as a FOSS compiler. Apple seems to have forgotten about it too, because it reinvented that wheel, worse, with Swift.Have a look. Dylan is amazing, and its SK8 IDE even more so (a few screenshots and downloads are left). Dylan is very readable, very high-level, and before the commercial realities of time and money prevailed, Apple planned to write an OS, and the apps for that OS, in Dylan.On investigating the screenshots, Dylan turned out to be remarkably reminiscent of Visual Basic - arguably another good design that has rather unfairly fallen by the wayside. reply DonHopkins 6 hours agoparentI was lucky enough to get the chance to play around with sk8 when I worked at Kaleida. It was absolutely amazing, totally reflective and introspective and browsable and editable and even graphically beautiful! I just wrote about it a month ago (plate of shrimp!!!):https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38406111DonHopkins 31 days agoparentcontextfavoriteon: The Revival of Medley&#x2F;InterlispWhen I worked at Kaleida (a joint venture of IBM and Apple), I had the wonderful opportunity to play around with Sk8, which was amazing! It was kind of like Dylan and ScriptX, in that it was an object oriented dialect of Lisp&#x2F;Scheme with a traditional infix expression syntax. But it also had wonderful graphics and multimedia support, and cool weird shaped windows, and you could point at and explore and edit anything on the screen, a lot like HyperCard.Q: What do you get when you cross Apple and IBM?A: IBM!https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SK8_(programming_language)>SK8 (pronounced \"skate\") was a multimedia authoring environment developed in Apple&#x27;s Advanced Technology Group from 1988 until 1997. It was described as \"HyperCard on steroids\",[1] combining a version of HyperCard&#x27;s HyperTalk programming language with a modern object-oriented application platform. The project&#x27;s goal was to allow creative designers to create complex, stand-alone applications. The main components of SK8 included the object system, the programming language, the graphics and components libraries, and the Project Builder, an integrated development environment.[...]The SK8 Multimedia Authoring Environment:https:&#x2F;&#x2F;sk8.dreamhosters.com&#x2F;sk8site&#x2F;sk8.htmlWhat is SK8?SK8 (pronounced \"skate\") is a multimedia authoring environment developed in Apple&#x27;s Research Laboratories. Since 1990, SK8 has been a testbed for advanced research into authoring tools and their use, as well as a tool to prototype new ideas and products. The goal of SK8 has been to enable productivity gains for software developers by reducing implementation time, facilitating rapid prototyping, supporting cross platform development and providing output to multiple runtime environments including Java. SK8 can be used to create rich media tools and titles simply and quickly. It features a fully dynamic prototype-based object system, an English-like scripting language, a general containment- and renderer-based graphic system, and a full-featured development interface. SK8 was developed using Digitool&#x27;s Macintosh Common Lisp.[...]Sk8 Users Guide:https:&#x2F;&#x2F;macintoshgarden.org&#x2F;sites&#x2F;macintoshgarden.org&#x2F;files&#x2F;...Lots more information discussion of Sk8 at this link -- I&#x27;ll just include the first comment, but click for more:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21846706mikelevins on Dec 20, 2019parentcontextfavoriteon: Interface Builder&#x27;s Alternative Lisp Timeline (201...Dylan (originally called Ralph) was basically Scheme plus a subset of CLOS. It also had some features meant to make it easier to generate small, fast artifacts--for example, it had a module system, and separately-compiled libraries, and a concept of \"sealing\" by which you could promise the compiler that certain things in the library would not change at runtime, so that certain kinds of optimizations could safely be performed.Lisp and Smalltalk were indeed used by a bunch of people at Apple at that time, mostly in the Advanced Technology Group. In fact, the reason Dylan existed was that ATG was looking for a Lisp-like or Smalltalk-like language they could use for prototyping. There was a perception that anything produced by ATG would probably have to be rewritten from scratch in C, and that created a barrier to adoption. ATG wanted to be able to produce artifacts that the rest of the company would be comfortable shipping in products, without giving up the advantages of Lisp and Smalltalk. Dylan was designed to those requirements.It was designed by Apple Cambridge, which was populated by programmers from Coral Software. Coral had created Coral Common Lisp, which later became Macintosh Common Lisp, and, still later, evolved into Clozure Common Lisp. Coral Lisp was very small for a Common Lisp implementation and fast. It had great support for the Mac Toolbox, all of which undoubtedly influenced Apple&#x27;s decision to buy Coral.Newton used the new language to write the initial OS for its novel mobile computer platform, but John Scully told them to knock it off and rewrite it in C++. There&#x27;s all sorts of gossipy stuff about that sequence of events, but I don&#x27;t know enough facts to tell those stories. The switch to C++ wasn&#x27;t because Dylan software couldn&#x27;t run in 640K, though; it ran fine. I had it running on Newton hardware every day for a couple of years.Alan Kay was around Apple then, and seemed to be interested in pretty much everything.Larry Tesler was in charge of the Newton group when I joined. After Scully told Larry to make the Newton team rewrite their OS in C++, Larry asked me and a couple of other Lisp hackers to \"see what we could do\" with Dylan on the Newton. We wrote an OS. It worked pretty well, but Apple was always going to ship the C++ OS that Scully ordered.Larry joined our team as a programmer for the first six weeks. I found him great to work with. He had a six-week sabbatical coming when Scully ordered the rewrite, so Larry took his sabbatical with us, writing code for our experimental Lisp OS.Apple built a bunch of other interesting stuff in Lisp, including SK8. SK8 was a radical application builder that has been described as \"HyperCard on Steroids\". It was much more flexible and powerful than either HyperCard or Interface Builder, but Apple never figured out what to do with it. Heck, Apple couldn&#x27;t figure out what to do with HyperCard, either. reply shrubble 11 hours agoprevThings to add: Wirth&#x27;s Oberon hardware and software a small but successful bit of software that was ported to many other architectures and the language remains influential. Also Apollo&#x27;s DomainOS which had network transparency in the early 1990s reply eschaton 9 hours agoparentDomain&#x2F;OS was the final name of the system, it was originally called Aegis and had network transparency in the early 1980s. reply DonHopkins 6 hours agoparentprevITS (which Richard Gabriel discussed in his \"Worse is Better\" paper in relation to the \"PC-loser-ing\" problem in particular, and the \"better\" MIT school of design in general) had a network transparent file system in the 70&#x27;s!https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Incompatible_Timesharing_Syste...https:&#x2F;&#x2F;www.techopedia.com&#x2F;definition&#x2F;26097&#x2F;incompatible-tim...Techopedia Explains Incompatible Timesharing System[...]The ITS OS was developed in late 1960s and continued to be used up to 1990 at MIT, and until 1995 at the Stacken Computer Club in Sweden.Some of the important technical features of ITS are as follows:The operating system contained the first device-independent graphics terminal output. The screen content was controlled using generic commands created by a program. The content was usually translated into a sequence of device-dependent characters defined by the terminal the programmer was using.Virtual devices were supported in software run in user processes called jobs.It provided inter-machine file system access and was the first OS to include this feature.It provided a sophisticated process management in which the processes were organized in a tree. Any process could be transparently frozen or restarted at any point in time.A highly advanced software interrupt facility was provided, which could operate asynchronously.It supported real-time and time-sharing operations, which worked simultaneously.[...]https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;cs240&#x2F;old&#x2F;sp2014&#x2F;readings&#x2F;wor....[...]Two famous people, one from MIT and another from Berkeley (but working on Unix) once met to discuss operating system issues. The person from MIT was knowledgeable about ITS (the MIT AI Lab operating system) and had been reading the Unix sources. He was interested in how Unix solved the PC loser-ing problem. The PC loser-ing problem occurs when a user program invokes a system routine to perform a lengthy operation that might have significant state, such as IO buffers. If an interrupt occurs during the operation, the state of the user program must be saved. Because the invocation of the system routine is usually a single instruction, the PC of the user program does not adequately capture the state of the process. The system routine must either back out or press forward. The right thing is to back out and restore the user program PC to the instruction that invoked the system routine so that resumption of the user program after the interrupt, for example, re-enters the system routine. It is called ``PC loser-ing&#x27;&#x27; because the PC is being coerced into ``loser mode,&#x27;&#x27; where ``loser&#x27;&#x27; is the affectionate name for ``user&#x27;&#x27; at MIT.[...] reply 6stringmerc 11 hours agoprevThis is one angle of the history and I do think it is a useful and accurate representation for what it describes.My critique: This lacks context regarding the still ongoing conflict between terminals and functional workstations. Time and again there is a back and forth in the computing realm. Case in point - I was selling SaaS deployments of what had been traditionally an On-Premises large cost platform.Who gets control is, to me, fundamentally a more significant angle on the history and future of computing. Again, will AI be on your phone or via network sends to a Host? Cost is a factor but I believe quite downstream from how these decisions are truly reached at the time. reply api 10 hours agoparentLocal and personal vs remote and centralized tends to follow the same pattern as hardware and OSes that this article describes. The wheel turns when the precious iteration gets complex and expensive.Cloud offered an escape hatch from the nightmare of Microsoft centric enterprise IT and expensive complicated on premise business applications, not to mention the awful bureaucracy of IT departments themselves.Now I get the sense that cloud has become complicated, expensive, and encrusted with hordes of consultants and vendors layered on top of vendors. A back to local anti-cloud movement has been brewing for a while but hasn’t quite boiled over.You’ll probably soon start seeing more and more articles about how much money a company saved by leaving cloud.… and the wheel will turn once again. reply agumonkey 8 hours agorootparent> Local and personal vs remote and centralized tends to follow the same pattern as hardware and OSes that this article describes. The wheel turns when the precious iteration gets complex and expensive.I&#x27;ve been looking for a name on such pattern, compression&#x2F;diffusion based on cost, scale, market. It&#x27;s so prevalent. reply e-dant 14 hours agoprevI wonder if there’s room for a theory of convergent evolution, in software and languages, towards something that is generally appreciated.Maybe there will always be camps arguing for one thing or another, but together and over the longest term, do they all pull in one general direction?I’m not so sure I agree with most of the article. The perspective is valuable. reply lmm 10 hours agoparent> I wonder if there’s room for a theory of convergent evolution, in software and languages, towards something that is generally appreciated.There definitely seem to be a few attractors. Almost every serious language from the last 20 or so years is now essentially OCaml with some minor tweaks. (e.g. Java has pretty much spent 25 years gradually turning into OCaml; so has Python, despite a very different starting point). Meanwhile languages that get extensive macro capabilities early on tend to turn into Lisp. reply mastax 10 hours agorootparentIn many ways Rust was an attempt to turn OCaml into C (deliberately stopping partway). reply lproven 14 hours agoparentprev> towards something that is generally appreciated.I think it&#x27;s simpler than that.It&#x27;s convergence to the lowest common denominator. The simplest implementation of the simplest thing that does the job, in the simplest easiest language that is capable of it.But because \"simple\" can be taken to extremes of very clever but abstruse tools that only near-genius level minds can use effectively, and those folks do not work well together, what ends up cheap at first is the simple easy thing that is simple and easy to get working.Lisp might be arguably simpler in a theoretical sense but for a lot of ordinary folks it&#x27;s just too weird and too hard.APL is \"simple\" inasmuch as a hundred lines of nested loops can be written as one line of a dozen hieroglyphics that does the same task in one operation... but there are only a few hundred people on the planet that can read it.C is a simple tool for simple computers but you can pick it up and learn how to use it with just a book and some time.It&#x27;s fiddly and hard to do anything clever which means programmer must do grug brain stuff.https:&#x2F;&#x2F;grugbrain.dev&#x2F;And that means others can follow it, and work with it, and that means teams scale. Not very well but a bit. So companies can hire rooms full of grugs and make it work.Result, fairly simple dumb tool beats clever fancy more capable tool.Result, people who like the dumb tool have strength of numbers and they mock the speccy nerdy weirdos who like the weird tool.Which is fine until you end up with a million programs built from a million lines of C each and a million techies trying to get them to work together.Then you end up with an industry that makes billions of dollars a month, selling billions of lines of code that nobody understands, and hundreds of thousands of people trying to prop it up and keep it working.By that point it becomes clear that you should have employed a dozen geniuses to do it in a few thousand lines of the weird nerdy tool. You&#x27;d have ended up with something smaller and simpler and easier to maintain, and even the paycheques of the dozen geniuses would be less than the paycheques of a thousand grug brain developers.But it&#x27;s too late. The geniuses retired or went off to grow bonsai or something. All that&#x27;s left is people who only know the grug brained methods.It is easy to believe it&#x27;s some kind of elegant evolution of the best possible solution... but it&#x27;s not really. It&#x27;s lots and lots of the cheapest worst solution until everything else dies out.That is what I am trying to get at here.But I am always learning and I try hard to be open minded. If you have specific point by point rebuttals, I&#x27;d love to read them! reply AnimalMuppet 7 hours agorootparent> By that point it becomes clear that you should have employed a dozen geniuses to do it in a few thousand lines of the weird nerdy tool. You&#x27;d have ended up with something smaller...Probably.> ... and simpler...Maybe not. Some geniuses produce simple; some produce insane complexity.> ... and easier to maintainAlmost certainly not, unless you have another genius. reply dist-epoch 12 hours agoparentprevMost likely, just like all phones now are big black rectangles.There are also orders of magnitude more programmers now, so the style of programming changed. Think classical music (few listeners) versus popular music (lots of listeners). reply DonHopkins 3 hours agorootparentAnd all phones in sci-fi movies are big transparent rectangles! What&#x27;s up with that???Maybe it&#x27;s meant to be scathing social commentary on the ultimate destination of today&#x27;s mobile phone trends in terrible user interface design and terrible privacy. But probably not.https:&#x2F;&#x2F;www.quora.com&#x2F;Why-do-so-many-SF-shows-depict-future-...https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;Showerthoughts&#x2F;comments&#x2F;g5w1ph&#x2F;the_... reply civilized 9 hours agoprevIt&#x27;s an interesting perspective but ultimately unsatisfying because it doesn&#x27;t touch on basic questions it seems like anyone would think to ask.For example: from a hardware perspective, today&#x27;s \"microcomputer\" hardware is vastly more powerful than the mainframes of old, is it not? The time when it was much less powerful was long ago. If the old philosophy is so vastly superior, what&#x27;s stopping folks from recreating it in today&#x27;s computing ecosystem? reply jdksmdbtbdnmsm 9 hours agoparentThe article is comparing systems from the same or close time periods. To merely compare modern systems with systems from 30+ years ago ignores what happened in those 30 years, which is why your comment says so little. reply civilized 8 hours agorootparentIt&#x27;s also trying to suggest that that history explains the dominant computing paradigms today. I think that historically-driven thinking only goes so far when today&#x27;s hardware is vastly more powerful than anything we used to have. Any paradigm that serves users better could be used on today&#x27;s very capable hardware, and presumably it would be extremely attractive. So why does this article sound like moving to the old paradigm that it prefers is a lost cause? We&#x27;re not at the end of history quite yet. reply mtrower 6 hours agorootparentWell, in my opinion, inertia is a dominant factor. There is an enormous amount of inertia present in the current systems and thought patterns. Redesigning the world from scratch while applying different principles is hard, especially when you need to catch up with 30 years of evolution and situational developments.The point of the article, I believe, is that the current set of principles underlying modern systems are not necessarily sacred and immutable. It does not follow that applying differing principles to today’s ecosystems, where current principles have metastasized, would be easy or even necessarily achievable. reply geocar 9 hours agoparentprevI kindof think that’s what private cloud is: mainframe-style workflows and architectures on (many) microcomputers. reply ashton314 12 hours agoprevThe description of Lisp machines sounds a lot like running Emacs in a way. Is Emacs… just a Lisp machine emulator?!(There is a lot I dislike about Emacs Lisp; there is a lot of power in it though. :) reply mtrower 6 hours agoparentIn some sense, you might consider it to be a crude one. If you configure your computer to boot directly into full screen emacs, never leave it, and do your damndest to interact only with in-process elisp, you might get some feel for what such a machine could be like.It will also be a frustrating experience, since emacs was never really intended to be used in such a way. There’s going to be a lot of friction and limitations. Still, it’s a fun exercise for the right sort of person :) reply DonHopkins 3 hours agorootparentYou&#x27;ve just described the user interface to every cloud server I use.0) ssh to server1) run screen -RD2) run user emacs in one screen, run user shells in emacs3) run root emacs in another screen, run root shells in emacs4) run top in another screen5) run nvitop in another screen on gpu servers6) try to remember not to leave tail -f foo.log running in any shells or server explodes after six months reply pandaman 11 hours agoparentprevEmacs predates Lisp machines, but a version of Emacs was written in Lisp and used there (EINE[1]). The point of a Lisp machine was that it ran Lisp natively or, at least, closer to native than, say, a 8086 DOS box.1. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EINE_and_ZWEI reply lispm 10 hours agorootparentEINE was the second Emacs (the first was TECO EMACS, an Emacs written in TECO macros) and EINE was the first one to be (completely) written in Lisp, on a GUI-based system. reply marcosdumay 12 hours agoparentprevIt&#x27;s a Lisp interpreter that happens to come with a text editor. I guess you can replace the text editing default skin, but I never tried it. reply lispm 10 hours agoprevIf one wants to read a description of the hard- and software of a Lisp Machine from the 1980s, here are two good and lengthy overviews of second and third generation systems. The first generation were the research prototypes developed at MIT: CONS and CADR. The Symbolics 3600 is an improvement (and a commercial offering) and the TI Explorer then already moved to higher integration incl. a special Microprocessor. Both operating systems were based on the original MIT Lisp OS. The TI Explorer from 1988 already supported Common Lisp, which Symbolics at that time also did. The Symbolics 3600 from 1983 ran ZetaLisp (aka Lisp Machine Lisp), a very object-oriented Lisp, using the Flavors object-system.Symbolics 3600 in 1983The Symbolics 3600 was the first improved machine after Symbolics was founded, released in 1983. The first machine, the LM-2, was a re-packaged version of the MIT CADR. The 3600 was an improved design with 36bit architecture (plus 8 bit ECC). Typically a machine new would have cost around $100k in 1983. When the machine boots up, it says \"Yes, master\" on a LED display. It was very extensible with memory, color graphics, disks, tapes, network, printer, ... It had a console with special keyboard, mouse, high-res b&w screen and digital audio. A dedicated Motorola 68000 was the Front End Processor.The Symbolics 3600 Technical Summary from 1983http:&#x2F;&#x2F;www.bitsavers.org&#x2F;pdf&#x2F;symbolics&#x2F;3600_series&#x2F;3600_Tech...A brochure for the machine: http:&#x2F;&#x2F;www.bitsavers.org&#x2F;pdf&#x2F;symbolics&#x2F;brochures&#x2F;3600_Jul83....TI Explorer in 1988The second overview is from TI and is from 1988, not long before they were quitting the market. There machine range was called TI Explorer, after licensing some technology from LMI (Lisp Machine, Inc.), another Lisp Machine company. TI had in 1988 already developed a Lisp Megachip, a 553k transistor 32bit CPU for running Lisp. The Chip design was done inhouse using a dozen Lisp Machines (including several from Symbolics). It was at the time one of the first CPUs of that complexity. The CPU had been financed by DARPA and one of the applications thought was adding a Compact Lisp Machine into a fighter plane, running an AI-based co-pilot, based on a large research project (Pilot&#x27;s Associate). The TI Explorer itself used the NuBUS as extension bus. Their console was attached via a fiber-optic cable.The TI Explorer Technical Summary from 1988:http:&#x2F;&#x2F;www.bitsavers.org&#x2F;pdf&#x2F;ti&#x2F;explorer&#x2F;2243189-0001D_ExplT... reply DonHopkins 6 hours agoparent> The CPU had been financed by DARPA and one of the applications thought was adding a Compact Lisp Machine into a fighter plane, running an AI-based co-pilot, based on a large research project (Pilot&#x27;s Associate).So is that why everybody called it the \"TI Exploder\"? I always assumed it was because they occasionally exploded, not because they made other things explode!https:&#x2F;&#x2F;cl-pdx.com&#x2F;comp.lang.lisp&#x2F;1988&#x2F;apr&#x2F;553.html#:~:text=...http:&#x2F;&#x2F;computer-programming-forum.com&#x2F;50-lisp&#x2F;e1910d32684c7e...https:&#x2F;&#x2F;gopherproxy.meulie.net&#x2F;sdf.org&#x2F;0&#x2F;users&#x2F;kickmule&#x2F;unix...(Oh wow cool, by googling for \"TI Exploder\" I found those old unix-haters archives, with some of my old sarcastic Unix Weenie &#x2F; X-Windows &#x2F; Perl combo-rants from &#x27;91, that I&#x27;d completely forgotten about! Including DSHR&#x27;s epic \"Sun Deskset == Roy Lichtenstein Painting on your Bedroom Wall\" rant that somebody with the initials DH leaked. https:&#x2F;&#x2F;blog.dshr.org&#x2F; ) ... I&#x27;ll transclude the highlights since it perfectly illustrates what Liam was getting at in the article and his comments here: Date: Thu, 8 Aug 91 18:20:00 PDT From: DH Subject: Simple Unix Weenie Question Date: Thu, 8 Aug 91 20:50:26 EDT From: J > =+= Gee, I can&#x27;t seem to convince a shell script or a > program to change my working directory. This makes some > sense, given how Unix handles programs (as separate > processes). But when I put \"cd\" in a shell script, it > works for the duration of the shell script, and then > reverts back to where I was before. So, what&#x27;s wrong with that? running a shell script forks off another shell, and when it terminates, you are returned to where your parent shell left you. If you want to end up in another directory, use an alias. The elegant approach is for the subshell to open &#x2F;dev&#x2F;mem and change the directory of its parent process directly. Another popular approach is for both shells to open connections to the X server, select for property notify events on screen 0, and negotiate an incremental selection transfer in a manner acceptable to both the parent process, child process, and the X Consortium Office of Management and Budget, falling back on the system wide default directory (which you must be running automounter to access) in case the server returns a BadAlloc error. From: DH Date: Thu, 8 Aug 91 19:07:55 PDT Subject: Simple Unix Weenie Question Oh yeah, in case you were wondering how to open an X connection from the shell, you have to be running \"xperlsh\". But since it runs your .xperlshrc file through the C preprocessor first, you have to make sure you have an ANSII cpp in your path supporting ## style macro concatination, but other than that it&#x27;s pretty much like you would expect. (But of course you have to set your path up right first, so you need to set the \"SkipAheadOnErrorsAndTryAgainSomeOtherTime\" option to xperlsh in your .xperlshinit file, which is sourced by your session manager (so naturally you have to restart the window system before it takes effect.).) Date: Mon, 14 Oct 91 18:01:14 PDT Subject: I Love Working At Sun ... -- Customers are really stupid: if you dump on them they quit buying your product ;-&#x2F; - Author&#x27;s name withheld (not me). From: DH Date: Mon, 21 Oct 91 14:18:19 PDT Subject: dr on Deskset Date: Wed, 31 Oct 90 09:39:51 PST From: OD To: tt Subject: fyi Hmmm... ----- Begin Included Message ----- >From kh From: kh To: ws Subject: dr on Deskset From: DR Date: 18 Oct 90 17:02:39 GMT Newsgroups: sun.open-windows Subject: Re: Deskset environment [NS replied to me directly. Her reply illustrates the reasons why I sent out yesterday&#x27;s mail so perfectly that I&#x27;m taking the liberty of copying my reply to openwindows-interest] > When we give standard Deskset presentations, a couple of > things tend to \"dazzle\" the audience ... > > 1. Use the MT Calendar template to generate an > appointment. Mail it to yourself, then > drop it onto CM which will schedule it. The > template is totally hokey (we&#x27;re working on > it) but it works and is wizzy. > > 2. Build a small application with GUIDE and make it > on the spot. Show it up and running on XView > in minutes. You can talk to BW about that > Thank you, but you have completely missed the point. I don&#x27;t want to show people how whizzy the standard default desktop environment is. That&#x27;s your job. I want to give a talk about a quite different subject. I merely want to *use* the desktop environment to achieve my own ends. And as soon as I try to actually *use* it for something instead of merely showing off the glitz, it falls to pieces in my hands. Unfortunately, this is becoming all too common in Sun products these days, because we no longer *use* the things we build for anything but whizzy demos. Have you ever actually tried to *use* the desktop for anything? Like, say, printing a PostScript file? The answer has to be no - because dropping a PostScript file on the print tool doesn&#x27;t work. Or binding a shell command to a pattern? Again no, because doing so depends on undocumented features of &#x2F;etc&#x2F;filetype. Even trying to create a new icon from the standard set causes the icon editor to dump core. I&#x27;m not joking when I say that I&#x27;ve been filing a bug report every couple of hours of trying to use the desktop. Its this kind of fragility that shows me that I&#x27;m treading on fresh snow. No-one else has walked this way. And that is a truly sad commentary on the state of Sun - no-one has been this way because no-one believes that there&#x27;s anything worth doing over this way. The reason Unix was such an advance over previous operating systems was that you could customize your environment in arbitrary ways. With just a few shell scripts, for example. Its just like the cold war - in our anxiety to compete with the enemy we&#x27;ve ended up losing the things that made our way of life worth defending in the first place. Like the freedom to disagree with the authorities. > I believe you&#x27;re correct in saying that most people live > with the default environment, but I think it&#x27;s only partly > because they don&#x27;t know how to customize it. We&#x27;ve done > some user testing and, surprisingly, people either prefer > the default environment or just don&#x27;t want to take the > time to make it special. This is particularly true of > people like admins, marketing, etc. Testing whether people actually do customize their environment is beside the point. Of course they don&#x27;t. In order to do it, I have to write C code using bizarre features of Xview, exercise all my shell wizardry, and dredge up undocumented features of the system from the source. And you&#x27;re suprised when admins can&#x27;t do this? I don&#x27;t expect admins to do it. But I do expect ISVs and Sun&#x27;s SEs to be able to do it, and right now they can&#x27;t. PS - I notice that someone filed a bug today pointing out that even your example of dropping a mail message on CM doesn&#x27;t work if CM is closed. That&#x27;s a symptom of the kind of arrogance that all the deskset tools seem to show - they&#x27;re so whizzy and important that they deserve acres of screen real estate. Why can&#x27;t they just shut up and do their job efficiently and inconspicuously? Why do they have to shove their bells and whistles in my face all the time? They&#x27;re like 50&#x27;s American cars - huge and covered with fins. What I want is more like a BMW, small, efficient, elegant and understated. Your focus on the whizzy demos may look great at trade shows, but who wants to have their tools screaming at them for attention all the time? It&#x27;s like having a Roy Lichtenstein painting on your bedroom wall. ----- End Included Message ----- From: DH Date: Tue, 22 Oct 91 12:43:59 PDT Subject: Forwarding Messages Please don&#x27;t forward that message about the deskset around. It is only for the enjoyment of people who truly hate Unix. Since the incredible bogosity of Unix is one of the best kept \"open secrets\" of the industry, I assumed that this was a relativly private mailing list. From: DC Date: Tue, 22 Oct 91 12:53:32 -0700 Subject: Getting People Fired Well, it also made you some friends here. Yes; apparently quite a number of them. Perhaps in fact it was a net gain! From: DH Date: Tue, 19 Nov 91 08:27:49 EST Subject: Once Again, Weenix Unies Reinvent History Yesterday Rob Pike from Bell Labs gave a talk on the latest and greatest successor to unix, called Plan 9. Basically he described ITS&#x27;s mechanism for using file channels to control resources as if it were the greatest new idea since the wheel. There may have been more; I took off after he credited Unix with the invention of the hierarchial file system!The other archive contains the whole 1990 thread about ESR rewriting the JARGON file!https:&#x2F;&#x2F;gopherproxy.meulie.net&#x2F;sdf.org&#x2F;0&#x2F;users&#x2F;kickmule&#x2F;unix... Date: Fri, 14 Dec 1990 13:54 EST From: DH Subject: Re: MC:HUMOR;JARGON > The JARGON file is being updated. The guy doing so has changed the nasty references to Unix to refer to MS-DOS because \"all the ITS partisans have now become Unix partisans, since the Unix philosophy is the same as the ITS philosophy.\" as he says. Date: Fri, 14 Dec 1990 16:57-0500 From: KP Subject: Re: MC:HUMOR;JARGON > Isn&#x27;t there some pending federal law against colorizing things that were originally black and white? Perhaps we should each call our congresspeople and lobby for its immediate passage of that so we can go after this vandal in court... Date: Mon, 17 Dec 90 15:04:18 EST From: MT Subject: Re: MC:HUMOR;JARGON > This guy is also a flaming political loony, so make sure to mention that you&#x27;re an agent of the international communist conspiracy if you write to him (unless you&#x27;re trying to be persuasive, in which case you should claim to be a sworn enemy of the ICC). Date: 27 Dec 90 07:17:26 GMT From: ESR Newsgroups: alt.folklore.computers For the record, I have been a GNU contributor and supporter since 1982. From: DH Date: 28 Dec 90 22:08:22 GMT Um, for the record, there wasn&#x27;t any GNU project in 1982. Date: Tue, 1 Jan 91 17:25:11 EST From: RS Subject: This Is What Worries Me Eric the Flute&#x27;s credibility has just taken another nose-dive... you would expect someone who claims to be a purveyor of net history and lore to at least get the dates right when he&#x27;s lying... From: ESR Date: Tue, 1 Jan 91 19:44:17 EST Subject: Re: This Is What Worries Me In recent spewage, dh calls me a liar for writing that I&#x27;ve been a GNU contributor and supporter since 1982. My history with GNU spans its entire lifetime to date (most recently, RMS accepted an SCCS control mode into the libraries for v19 EMACS). It&#x27;s possible that the project had an official start time that postdates 1982, but I was involved before that, when the project was just a gleam in RMS&#x27;s eye (by 1982 I&#x27;d already known him for four years). He&#x27;s welcome to ask RMS when I volunteered the code that became GNU sed. That was before the project had even definitely settled on the GNU name. RMS may even recall that I was one of the first people -- possibly *the* first -- to urge that an EMACS implementation be the flagship product of his embryonic project. I can only assume that gumby&#x27;s remarks are a function of ignorance and his expressed distate for the Jargon File revision I am currently undertaking. I leave it for others to judge whether any juxtaposition of the above facts with GNU&#x27;s official history justifies a vindictive flame. -- >>eric>> From: AB Date: Tue, 1 Jan 91 21:09:08 EST Subject: But DH didn&#x27;t know Mr. Raymond was on unix-haters! For the moment I have removed Mr. Raymond from unix-haters. If anyone wants to put him back, they should first give him a crystal clear explanation of the boundaries of discussion, and they should also warn the rest of us in advance so that we can avoid repeating dh&#x27;s faux pas. Personally, I think it&#x27;s kind of inhibiting to have \"prominent Unix personalities\" on unix-haters. It&#x27;s hard to work up a really good flame about clueless, twinkie-crazed, brain damaged unix weenies when you have to worry that you might offend someone. This is not a list for the faint of heart. Accuracy is -not- required on unix-haters. Unix-haters requires only hatred. (Of course accuracy does have its role. Nothing improves a really good anti-Unix rant more than the knowledge that the eye-popping misfeature in question really does work -exactly- as described.) reply selimnairb 16 hours agoprevSo computers should’ve stayed expensive and inaccessible to most people. Yeah, that’s how markets grow. reply lproven 14 hours agoparentThat is not only not right, that is not even wrong.It&#x27;s not even a misinterpretation of what I was saying. It&#x27;s like taking the first letter of each line, spell checking it until it reads as English somehow, and disagreeing with the result!I am saying we shouldn&#x27;t have done it the cheap way. We should have done it the best way when it was visible what was the better but more expensive way.Because that is what we must do know, but it&#x27;s going to be much harder and much more expensive now because we need to replace 30+ years of accumulated useless cruft, while staying interoperable with it throughout. reply kens 16 hours agoprevThis is a very interesting article on computer history. There&#x27;s a lot that I disagree with, though... reply lproven 14 hours agoparentLike I said above -- please do read my earlier comments -- I&#x27;d love to hear what, and why. reply BaculumMeumEst 11 hours agoprev> Software built with tweezers and glue is not robust, no matter how many layers you add. It&#x27;s terribly fragile, and needs armies of workers constantly fixing its millions of cracks and holes.Dude, come on. I really don&#x27;t think anyone who actually worked on a medium to large Lisp codebase would write something like this. reply Phiwise_ 9 hours agoparentThe author of the linked blogpost, Mark Tarver, has spent over a decade developing his own pair of Lisp dialect and symbolic AI system, called \"Shen\" and \"The Logic Lab\". reply agumonkey 8 hours agorootparentI have no say in the matter but I think it&#x27;s a matter of crowd and sociology rather than tools. I&#x27;ve seen people go into shock at the first mention of smalltalk. \"Message not understood\" they said.These languages are powerful weapons, for some it will allow creating suns, for other it will be a self damaging nuclear meltdown. reply jauntywundrkind 14 hours agoprev> The story about evolution is totally wrong. What really happened is that, time after time, each generation of computers developed until it was very capable and sophisticated, and then it was totally replaced by a new generation of relatively simple, stupid ones. Then those were improved, usually completely ignoring all the lessons learned in the previous generation, until the new generation gets replaced in turn by something smaller, cheaper, and far more stupid.Beautifully said. But for the last couple decades not even that is true. It&#x27;s just been more and more of the same OSes, doing basically the same things. What it means to develop a native app is pretty fundamentally unchanged since Windows 3.11 or ISX days.Software has changed, but only neo-mainframes. All the groupware and multi-tenant and scale-out software systems the author decries as lost? Rebuilt as online systems, powered by communicative capitalism and vast data-keeps (\"the cloud\").> We run the much-upgraded descendants of the simplest, stupidest, and most boring computer that anyone could get to market. They were the easiest to build and to get working.Unsaid here is I think where we really got on the fixed path, is what begat honogenization. Everyone else seemed to have been competing to build better hardware+software+peripheral systems against everyone else (with some close alliances here and there).1989 changed everything. The EISA bus was the reformation of a thousand different competing computing industries into a vaster cohesive competitive ecosystem, via the Gang of Nine. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Extended_Industry_Standard_Arc... . This commodified what used to be closed systems. Everyone either adapted to the homogenized common systems, or, one by one, the DECs and Suns and every other computer maker folded or got sold off.The business model, to me, defines what happened. Giving up on being proprietary, giving up on controlling \"your\" ecosystem was the hinge point. Computing was boutique and special systems, competing on unique and distinct features and capabilities. With the rise of interchangable computing parts it transitioned to a more collaborative & much more competitive system. Distinction carried the risk of being too far afield, of your stuff not being compatible with the others. You had to play in the big tent. Versus all the other upstarts playing against you. Meanwhile the legacy featureful unique & distinct business-model players never could get enough market share to survive, could certainly never compete downmarket, and slowly has positions eroded up and up market until those last upmarket places collapsed too.The love of lisp here has many of the same pitfalls. Sure it&#x27;s an elegant modifiable system, one that can be shaped like a bonsai tree into distinct and beautiful forms. And I hope we see the rise, I hope very much, that we make software soft again, that big overarching ideas of cohesive computing where OS and apps and user&#x27;s will blend together in dynamic fashion rise again. But the peril is disjointedness. The peril is a lack of cohesion, where different users have vastly different bespoke systems and commonality is lost.I&#x27;m tempted to stop here while I&#x27;ve said little that feels controversial. Putting in anything people dont want to hear risks the greater message, which is that the new ways could arise via many many means. But, I do think: the brightest most malleable most user controlled system we have is the web. Userscripts are very powerful, and they grant us power over disjointed chaotic industrial systems, which have no desire to let the user shape anything. I believe that, with a little effort, with tools already available like web components, we can build very sympathetic forms of computing. HTML like LISP can make visible and make manifest all the components pieces of computing, can be an S-expr like system, as we see with modern front-end-derived router technology for example. The whole web might not be terraformed in our lifetimee, we might not dislodge the contemporary industrial web practices to make all the web excellent, but I think many stable wonderful media forms that spread and interoperate can take root here, I think they already resemble the alive system of the gods the author so nicely speaks to. I too speak, for malleable systems everywhere (not mine but https:&#x2F;&#x2F;malleable.systems ), and for the web as one conduit to bring us closer to the gods. reply intrasight 5 hours agoparentFirst, you comment was a nice addition to the lproven article and was thought-provoking.>> The story about evolution is totally wrong.Actually, this is exactly the story of evolution. Mammals are the simple, stupid things that showed up when the MUCH smarter and capable dinosaurs ruled the world. But there is a HUGE amount of homology in the biological tree of life. That is true in computer evolution too. But more in core hardware and less in platforms and in software - which is what lproven was mostly writing about. Core hardware evolves more like basic metabolic and signaling pathways and channels - very slowly and with stability. Hardware platforms evolved in pretty dramatic step functions. Some of those steps did effectively obsolete everything that came before - like the EISA bus. But computer software is very much like human software - it can be largely rewritten in a evolutionary blink of the eye.> But for the last couple decades not even that is true.It&#x27;s not true in computers for the same reason it&#x27;s not true with humans in ecological evolution. We&#x27;ve won. There will likely be no next evolutionary step biologically. That&#x27;s a change from the history of the last several hundred million years and one of which we don&#x27;t yet full understand the ramifications. In computer tech, it&#x27;s why we now have the Magnificent Seven, and why it differs from the Nifty Fifty. The Nifty Fifty didn&#x27;t have an evolutionary moat.I was very actively in the computer industry from 85 to 2000 and witnessed first-hand the very Darwinian evolution at work in computer tech. My first job (88-90) was at Westinghouse building a bespoke nuclear plant operating system running on minicomputers and Sun workstations. Then a new species arrived running on EISA bus and Windows OS and they kicked our ass even though we&#x27;d been doing that type of work for two decades.I also saw it at my second job (91-95 - studied neuroscience in between) at Dataviews - the dominant computer workstation software vendor at the time. We ran on all the major and most of the minor Unix workstations. We&#x27;d port the software to your workstation for about $100K and had many takers - which meant that it ran on basically everything. But it didn&#x27;t run on Windows. And so we hit a cost&#x2F;produtivity wall and had other companies kick our ass that were Windows-native just as had happened at Westinghouse.The web arrived and HTML&#x2F;Javascript kicked the ass of everything else. I was an X&#x2F;Motif expert and trainer in the early 90s. Great tech. Dead end because it&#x27;s license couldn&#x27;t compete against free.Is machine learning different? Certainly, there have been some step functions (\"Attention is all you need\") but mostly it&#x27;s been a slow evolution of Moore&#x27;s Law and better backpropogation stacks. I did my early independent research in AI at CMU in &#x27;88 and mostly ran my backpropogation models in Excel. Biologically, this isn&#x27;t so different from a slug brain vs a human brain. Same basic hardware but 100,000x more capable. If I&#x27;d told my 20 year old self that in 40 years we&#x27;d have backprop models with a trillion parameters that could run on PCs, I&#x27;d have said \"yeah right - in some very distant future\". But it was&#x2F;is a pretty distant future. reply II2II 8 hours agoprevThere is so much to unpack here, but I am going to focus upon one thing: interpretation.The recounting history aspect of the article coincides with my understanding of the history of computing. The point of victors writing the history is certainly valid. While this is not the case literally, their success has offered a sense of legitimacy to their versions of history. Our acceptance is also shaped by our own experiences, which will favour the victors simply because they gained our acceptance back in the day.Yet I also think that the \"lowest bidders\" interpretation is deeply flawed for two reasons. One reason is that the success of the successors was built upon making computing more affordable to a broader base of customers. That is to say that there is a lower end to the cost of a vacuum tube based computer, which is higher than the cost of a transistorized computer, which is higher than one based upon integrated circuits, which is higher than one based upon microprocessors. The goal at each stage isn&#x27;t necessarily to be the lowest bidder, but it is to sell computers at a lower price point than the prior generation.The second issue is that customers rarely needed the best technology at the time. Such an ideal would force many adopters into bankruptcy. The real point is to adopt technology in a way that either to improve efficiency, improve accuracy, or enable them to do more. That does not necessarily imply they need the best technology. It does imply they need technology which balances a cost-benefit analysis. Good is often the enemy of the best because it does not strike that balance. In a sense, that suggests that the best is not actually the best (i.e. it fails on some criteria).Of course the real point of the article is that some technologies were delayed and some have never been adopted at a large scale. The delays were necessary, not just because they required more sophisticated software but because they required time to implement. To understand that you only need look at our mobile devices. We are over a decade into the introduction of the smartphone, yet the software has yet to reach the sophistication of software seen on traditional desktop computers. While some of this is due to shifting priorities and the challenges of adapting traditional interfaces to fit within new interfaces, part of it is also due to the effort required to port software that may have 20 years of development behind them to a new platform. The second crack at a problem may be easier, but it is not easy.As with the author, I have much disappointment in the paths not taken. Or, to be more accurate, the paths so rarely taken that the industry can, by in large, be considered to be striving towards homogeneity. While I have no real love for LISP[1], SmallTalk helped me to understand object oriented programming much more deeply. While I have never truly pursued them, other oddities helped me realize that there is a plurality of paths the technology could have followed (Oberon comes to mind).As for retrocomputing, I truly appreciate those who choose to document the history of computers. It has guided my understanding that what we have today is not a foregone conclusion, and that our pet technology may have taken a very different path (and, perhaps, a better path) if the various detours were followed through to their conclusion. That said, I also believe that the path we have followed is viewed with too much cynicism in the eyes of some. It would have been better to have more diversity in our toolkit, than to prefer one approach over another.[1] Okay, I&#x27;m weird. I love the syntax of LISP, brackets and all, while I can appreciate the benefits of functional programming. I simply haven&#x27;t crossed the threshold to view it as a useful language, even in an abstract way. reply amadeuspagel 12 hours agoprevIs this \"Worse is Better\", but in the snarky and obnoxious style of The Register? reply LeoPanthera 11 hours agoparentThe answer to this is in the article. reply facialwipe 14 hours agoprevAfter reading 30% of the article, it became clear to me that the author has probably never created a GitHub account. reply lproven 12 hours agoparentYou didn&#x27;t look very hard.https:&#x2F;&#x2F;github.com&#x2F;lproven reply mtrower 6 hours agoparentprevI’d be interested to hear how you reached that conclusion, and what that conclusion is meant to imply. reply facialwipe 1 hour agorootparentThis ridiculous paragraph:“Now Lisp and Smalltalk are just niche languages – but once, both of them were whole other universes. Full-stack systems, all live, all dynamic, all editable on the fly.The closest thing we have today is probably JavaScript apps running in web browsers, and they are crippled little things by comparison.” reply snakeyjake 16 hours agoprev [–] LISP fetishism must be resisted every time it appears.Programmers who learn LISP and think they have become enlightened are no different than drunks who ramble on about how it is impossible to know if the colors they see are the same as the colors you see. reply lproven 14 hours agoparentI&#x27;m not a Lisp fetishist and I personally find it nearly as unreadable as Perl and APL.The article is in fact expressing my admiration of Dylan, if you look more closely, and Smalltalk and other things of that ilk.Lisp was a tremendously important step... In 1959. They should have continued with the planned Lisp-2, but they didn&#x27;t, and sadly, McCarthy is dead now.In its absence, Dylan is about the best candidate for a Lisp-2 we have. reply agumonkey 8 hours agorootparentAs a somehow lisp head, and even though I mellowed with time, especially about syntax, I still don&#x27;t think there&#x27;s anything wrong with sexps. It might be a neurological trait, some people just can&#x27;t live with a syntactic layer.. their brain might rejoy with it, think clearer and faster. I, for one, is the opposite, it removes one dimension in the problem space, and structural edition is so cute. I also have a tiny personal bet that in 30 years, if people are still writing code.. someone will make sexps mainstream.. just like closures are now, just like tree processing &#x2F; ast &#x2F; transpiling is mainstream now.. it just take time to cook the mainstream. reply Phiwise_ 15 hours agoparentprev [–] It&#x27;s a strange sort of Lisp fetishism that wants to bring back Smalltalk instead of Lisp. reply lproven 14 hours agorootparent [–] Exactly! :-) replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This article challenges the idea of progress in computing and highlights the development of simpler and cheaper models of computers throughout history.",
      "It explores the evolution of computers from mainframes to microcomputers in the 1980s and the trade-offs made for simplicity and affordability.",
      "It discusses the development, capabilities, and decline of the Newton, Lisp, and Smalltalk machines, as well as various operating systems. It also raises questions about the use of multiple programming languages and the advantages of dedicated hardware.",
      "The article mentions different design approaches in software development and the decline of Lisp in favor of inexpensive and interchangeable software.",
      "It concludes by listing various software, technologies, and topics mentioned, such as Microsoft Office, Visual Studio, open source software, programming languages, and education."
    ],
    "commentSummary": [
      "The text is a compilation of comments, discussions, and opinions on a range of computing technology and programming language topics.",
      "It covers the use of low-cost technology, open-source software, code sharing challenges, PC dominance, programming language history, and computing paradigms.",
      "Specific technologies and projects mentioned include Lisp Machines, Sk8, Dylan, and the GNU project."
    ],
    "points": 145,
    "commentCount": 78,
    "retryCount": 0,
    "time": 1703522316
  }
]
