[
  {
    "id": 38061187,
    "title": "YouTube's Anti-Adblock and uBlock Origin",
    "originLink": "https://andadinosaur.com/youtube-s-anti-adblock-and-ublock-origin",
    "originBody": "Zhenyi Tan And a Dinosaur Youtube’s Anti-adblock and uBlock Origin 29 October 2023 Recently, YouTube has been ramping up its anti-adblock effort, and I’ve been watching this closely due to personal interest. This blog post is where I write down what I know. Some Background Here’s how adblockers (used to) block YouTube ads. Before playing a video, YouTube would check its API, and the server would send back something like this: { \"video\": \"something.mp4\", \"ads\": [ad1, ad2, ad3], \"etc\": { ... } } And the adblockers would override JSON.parse and Response.json to make it return this instead: { \"video\": \"something.mp4\", \"ads\": [], \"etc\": { ... } } This trick worked for a few years. But earlier this year, YouTube started making fake requests to see if the responses were changed. If the responses were changed, it meant the user was using an adblocker. Most adblockers stopped working, but a few like uBlock Origin and AdGuard updated their filters to avoid these fake requests. Then YouTube would update their fake requests so the adblockers would fall for them. It’s been a game of cat and mouse between YouTube and the adblockers ever since. The Tech Support Hell YouTube isn’t rolling out the anti-adblock to everyone. It seems to depend on things like your account, browser, and IP address. And if you’re not logged in or you’re in a private window, you’re safe. As a result, there are a bunch of people saying, “I use XYZ and I haven’t seen an anti-adblock popup yet,” unknowingly spreading misinformation. But here’s the thing: YouTube isn’t just targeting adblockers. Use Privacy Badger? You’ll get flagged. Use Malwarebytes? You’ll get flagged. Set your Edge browser’s tracking protection to “strict”? Yep, you’ll get flagged. So a lot of people think their extensions are safe to use, but actually they’re not. And contrary to what you might think, using multiple adblockers can actually make things worse. That’s because all your adblockers need to be up-to-date to dodge YouTube’s detection. As you can imagine, this is creating a tech support nightmare if you’re part of an adblocker team. The Redditors On Reddit, the uBO team put up a detailed post on how to handle YouTube’s anti-adblock. But many people don’t actually follow it. You’d see people saying, “I did what the post said but I’m still having issues.” But when they’re asked to share their system info for troubleshooting, it turns out they didn’t really follow the post. Then there are non-tech-savvy users looking at the post and saying, “This is too complex. I give up.” Then there are tech-savvy users who say, “Your filter has CODE in it. That’s risky. Can you explain what it does? I don’t want to run anything I don’t understand.” And of course, there’s always the classic “IVE TRIED EVERYTHING AND NOTHING WORKS HELP!!!!” All this noise makes it hard to find any useful info. The Stupid Filters Some people have been sharing custom filters that use CSS to hide the popups. But that’s like sticking your head in the sand. Sooner or later, they’ll get totally blocked and won’t know why. Recently, someone shared a filter on Twitter that literally had code to set adBlocksFound to 0. It’s as if they think YouTube’s anti-adblock works like this: if (adBlocksFound > 0) { blockUser(); //!!!!! } That tweet got super popular. And it probably led a lot of people to add those filters to their adblockers. This has really piled on the work for the troubleshooting team. Did the person who shared it not realize it was harmful? Or did they just care about getting likes? The Script ID Every time YouTube tweaks their script, part of the URL changes. This part is what uBO calls the ID, and they have a webpage that keeps track of the latest one. But here’s where things get messy. Some people think this ID is what they need to block. Some even suggest ways to automate the process (like, “Why don’t you just block that with REGULAR EXPRESSION?”) Another issue is that sometimes YouTube pushes out an update that has nothing to do with adblock. But it still changes the ID. Then you get people saying, “The ID changed, why hasn’t this post updated yet???” The Moderator Who Quit Reddit All this resulted in a ton of pressure on the uBO team members who were trying to help out in the thread. One by one, I saw them say they’d had enough of the comments and weren’t going to reply in these threads anymore. And then one of the moderators actually deleted their Reddit account. “The ID in the post wasn’t updated because my mother was hospitalized,” they said. It’s sad to see them leave because of some drive-by comments — new users who sign up for Reddit, leave their comments, and then delete their accounts without facing any consequences. Sure, there are people who appreciate what the uBO team is doing. But the hurtful comments leave a bigger mark than the good ones. The War of Attrition Since May, uBO has been in a cat-and-mouse game with YouTube. And they’ve shown incredible resilience, especially when you consider that there are only two people on the uBO team dealing with YouTube. The uBO team members are all volunteers. They’ve gone above and beyond to meet every little request from their users. But there’s a limit to how much they can take. At some point, the constant demands become too much, and they will leave uBO for good. It’s one thing to play cat and mouse with YouTube. It’s quite another to deal with a wave of angry users. Maybe that’s how YouTube will win this war of attrition. My Apps • Tip Jar • Archive • About • RSS Feed © 2023 Zhenyi Tan",
    "commentLink": "https://news.ycombinator.com/item?id=38061187",
    "commentBody": "YouTube&#x27;s Anti-Adblock and uBlock OriginHacker NewspastloginYouTube&#x27;s Anti-Adblock and uBlock Origin (andadinosaur.com) 683 points by mrzool 22 hours ago| hidepastfavorite671 comments eqvinox 13 hours agoThis is of course bringing up the discussion on the \"morality\" of Adblocking. I&#x27;d like to point out something that I don&#x27;t think is getting enough attention.There was a point in the past where video platforms were competing, and by no means was it clear that YouTube would end up dominating this area to the point of being close to a monopoly.When YouTube won that race, they won it with a given set of parameters, including the kind and amount of ads they show. Society at large has, at that point in the past, basically decided that YouTube&#x27;s offering is the best, and given this market domineering position.YouTube is increasingly moving away from the parameters of this implicit agreement, in minor ways at first, more now. Had they \"competed\" in the video platform race with current policies, maybe everyone&#x27;d be using Vimeo now.And here&#x27;s the crux. YouTube can only do this because their old policies allowed them to establish this domineering position, and by doing so are breaking the implicit \"deal\" that actually allowed them to get into this position.To me, there&#x27;s currently no alternative to going onto YouTube. And no, I won&#x27;t pay for YouTube Premium — because that wasn&#x27;t part of the deal either. The platform won the race as a free platform. So, until Google can figure out how to serve a reasonable amount of safe ads — adblocker it is. reply boredpeter 12 hours agoparentThis reminds me of the concept of predatory pricing which is when a business lowers their prices to below cost in order to drive out all its competitors and create a monopoly. https:&#x2F;&#x2F;www.ftc.gov&#x2F;advice-guidance&#x2F;competition-guidance&#x2F;gui...I do wonder if it could be argued (maybe even in the current monopoly case against google) whether youtube engaged in predatory or below-cost pricing in order to drive out all of its competitors, establish a monopoly, and now use that monopoly in order to \"raise prices\" i.e. increase the amount of ads on its service in order to maximize its profit margins.Although this does seem to be the business plan of basically every startup out there. Get VC funding, run at a loss and burn through money but gain a monopoly market share, and once you&#x27;ve done that you can raise your prices and have a profit margin that far exceeds what should be normal. reply wodenokoto 11 hours agorootparentThey did. They ran at a huge deficit for a very long time while expanding.But this seems to be the play book for all VC funded web apps. Facebook and MySpace did the same. In fact, you can argue that moving towards profitability too soon and too fast is what killed MySpace. But that argument only works if you are willing to see the growth phase as something other than predatory pricing.I think your comment is a sobering input to the whole startup discussion. reply greatNespresso 8 hours agorootparentAgreed. Bruce Schneier allocated a chapter in his last book, .A hacker&#x27;s mind&#x27;:\"Venture capital itself is not a hack. The hack is when unprofitable companies use VC funding to ignore the dynamics of the market economy. We don’t want some central planner to decide which businesses should remain operational and which should close down. But this is exactly what happens when venture capital firms become involved. The injection of VC money means that companies don’t need to compete with each other in the traditional manner, or worry about the normal laws of supply and demand. They can do what would normally be crazy things—give away their products, pay extravagant salaries, sustain enormous financial losses, provide a service that actually harms people—because of that external funding source. It’s basically central planning by elite investors, something that would be called communism if the government did it.\" reply literalAardvark 7 hours agorootparentHah, I&#x27;d given some thought to malinvestment in capitalism but never quite connected it to malinvestment under central planning.It feels about right... it&#x27;s almost the same thing. Except there are multiple competing \"central authorities\" with money, so the ones who fuck up do get burned a lot harder than they would if they were part of the very big government. reply jampekka 7 hours agorootparentprevThat&#x27;s more or less the opposite of communism. reply snapplebobapple 2 hours agorootparentIt&#x27;s not really. Communism is just the super monopoly on everything by one firm (plus a bunch of kooky religious like beliefs). This subset of VC funding uses is basically abusing external funding to gain market dominance so that one can abuse your customers with product changes that make the product more profitable for you. It&#x27;s very equivalent to how an oligopolist&#x2F;monopolist enters new markets using money from the rest of the business to undercut everyone in the new market and push them out. It&#x27;s bad for society, just like communism.This doesn&#x27;t mean there&#x27;s no place for VC funding, there&#x27;s lots of legitimate uses for it (i.e. handling mismatched cost&#x2F;revenue flows from expansion where there are a lot of upfront costs and cash flows come over the following years). Just that it&#x27;s usually more profitable to be a monopolist&#x2F;oligopolist and so that has been where the money has been flowing, at great detriment to society. reply keep_reading 3 hours agorootparentprevHe&#x27;s literally complaining about one of the worst \"features\" of fiat money but attacks Bitcoin in his other publications. Amazing. reply HeavyStorm 3 hours agorootparentprev_Dumping_, how it was called when I was young, is the main strategy of most startups out there: operate at a loss until they establish themselves (usually as the sole provider of certain services or goods) then start to climb the prices.It _should_ be illegal, but since it&#x27;s the current status quo, it won&#x27;t change anytime soon. reply kikokikokiko 3 hours agorootparentI think that the amount of free services we got in the last decade is the strongest argument IN FAVOR of dumping. They got there through subsidized services, now they want to fleece everyone, let&#x27;s see how it goes. My guess is that competitors will arise and gain market share. It&#x27;s happening to Uber down here in Brazil. The prices are getting too high, Brazilians are migrating to other apps, especially InDrive, a russian based app. Capitalism is great. reply selcuka 12 hours agorootparentprev> Get VC funding, run at a loss and burn through money but gain a monopoly market share, and once you&#x27;ve done that you can raise your pricesSlightly off topic, but the business plan of most startups seems to be \"get VC funding, and exit\". What you wrote may be the business plan of VCs.I don&#x27;t understand the valuation of many startups these days (even in the hypothetical case where they capture 100% of their potential market one day). reply gmerc 7 hours agorootparentVCs don’t invest because your business has a bright future as a valuable, sustainable operation . Not anymore.The crypto dynamics have shifted the expectations so far to cheap, quick moment they most VCs, especially the a16z kind are more about “Can I juice this business and it’s metrics enough to sell it to someone to hold the bag”.Ironically I think the large numbers involved are basically part of that PR game - they act as proof that the business is worth it and attract attention and bagholder interest.The crypto economy worked like that too - the NFT wash trading, the signal metrics used to sell the idea that there is value where there is none.Probably something something wework too. reply uncletammy 5 hours agorootparent> The crypto dynamics have shifted the expectations so far to cheap, quick moment they most VCs, especially the a16z kind are more about “Can I juice this business and it’s metrics enough to sell it to someone to hold the bag”.This strategy existed long before \"crypto\" reply pasttense01 11 hours agorootparentprevYoutube got to its current position not by lowering prices but instead by Google making sure that Youtube videos are returned at the top of Google search results. Competing video websites don&#x27;t have this advantage. reply Gud 11 hours agorootparentYouTube had already beat its competitors before it was sold to Google. reply JimDabell 10 hours agorootparentIncluding Google Video. Google did try the tactic of using their search engine to promote their own video platform, but it was against YouTube and Google only bought them because it didn’t work. reply chii 9 hours agorootparentit didnt work because people don&#x27;t search for videos via google usually. They get the video directly from youtube, or was linked by friends virally.Plus the early days of google (before youtube acquisition), i dont think their video search was as good as the text search anyway (but i might be misremembering of course...). reply lobocinza 37 minutes agorootparentTheir video search still sucks. replyJumpCrisscross 11 hours agorootparentprev> Get VC funding, run at a loss and burn through money but gain a monopoly market share, and once you&#x27;ve done that you can raise your pricesGoogle, YouTube&#x27;s owner, isn&#x27;t a VC. YouTube was its best when it was burning VCs&#x27; cash. reply zarzavat 12 hours agoparentprevMy perspective: Google is not an agent directed by morality when they interact with me, therefore I don’t allocate any morality when interacting with them. It’s a power relationship not a moral relationship.I do feel bad for the creators, but I would rather donate to their Patreons than buy YT premium. reply eqvinox 12 hours agorootparent> I do feel bad for the creators, but I would rather donate to their Patreons than buy YT premium.I ended up subscribing to both Nebula and Dropout.tv, especially after noticing that a good portion of my favourite YT channels are in fact on Nebula. Sadly, this is primarly larger ones, and I do feel bad about smaller creators being kinda stuck on YT… especially when it&#x27;s the odd one-time well-made video that really doesn&#x27;t warrant e.g. Patreon.But yeah, the real moral quandry is with the creators. They&#x27;re more or less under the same monopoly pressure; in most cases you just can&#x27;t ignore the YT audience :( reply axelthegerman 11 hours agorootparentTotally agree this is the real problem.Where do creators go if not YouTube!? Ideally they could self host videos which could be expensive AND not bring any revenue, neither do they are they discoverable - this is where the internet is broken these days.And maybe this is where micro transactions would have a proper use case, i.e. if you had a browser extension where you add $5 and then you can dish out 1ct or 10ct for some content... reply Freak_NL 8 hours agorootparentI&#x27;m still in favour of a fixed subscription one pays for a service like YouTube in the range of €5&#x2F;month, with 95% of the proceeds going to creators. If you do nothing, the money will be doled out equally based on some set of fair (and frequently scrutinized) parameters. If the subscriber wants to, they can allocate a portion of this fee to specific creators, and also remove it from creators the you do not want to support (this might help with clickbait and empty fluff created to work well with specific searches).It won&#x27;t happen of course.I recently had ads show up before videos on YouTube (audio only, so uBlock Origin was blocking part of it), and the only thing I felt was disgust and a mental note never to buy insurance from InShared (a Dutch insurance company) simply for repeating the same stupid jingle for each video. reply j16sdiz 11 hours agorootparentprevNebula was created by a few creator, trying to solve this problem.I have no idea how well it worked out - I am still contented with the ad-filled YouTube reply HeeroML 9 hours agorootparentNo it actually wasn’t. Nebula isn’t sustainable. It’s co financed by curiositystream. reply collaborative 8 hours agorootparentDo you know if Rumble is sustainable? Just curious reply notthemessiah 7 hours agorootparentNo way in hell, it&#x27;s currently just a vanity project financed by untrustworthy billionaires (the main financier is literally a snitch for the FBI https:&#x2F;&#x2F;www.businessinsider.com&#x2F;peter-thiel-fbi-informant-ch...). reply valdiorn 2 hours agorootparenthaha, you think the fact that Peter Thiel talks to the FBI is the worst thing about Peter Thiel? :) replykzrdude 5 hours agorootparentprevI signed up for nebula too, but it&#x27;s clear that nebula is not a competitive platform. Nebula does the basics, it has channels and it shows videos, that part is great.Youtube is great because of the wide availability of videos, recommendations and (maybe not great because of this) the comments.I know the comments are not that well liked, but it means the videos are not in a vacuum. They are in a social context. And comments are pretty good, maybe because negative ones are heavily suppressed, that&#x27;s at least what it looks like.Nebula feels empty because of those missing parts. It doesn&#x27;t draw you in to new channels. I don&#x27;t like half the recommendations youtube gives, but some of them I do. reply jampekka 6 hours agorootparentprevThis is the right response that&#x27;s all too often missing from these threads.If you want \"free-market\" you should deal with its basic premise that consumer pays as little as they can and seller tries to milk the consumer as much as they can. That&#x27;s quite literally how it&#x27;s supposed to work.I&#x27;m very much in favor of bringing some morality to the economic system, but it shouldn&#x27;t be one sided. reply xxs 8 hours agorootparentprevThe issue is that the content (format&#x2F;pacing&#x2F;etc.) is made to show ads which pretty much makes &#x27;premium&#x27; a weird thing. reply sensanaty 3 hours agoparentprevMorally, I consider ads to be outright evil, especially the modern day cancer we call advertisement where they track every singular molecule of your existence. As soon as these scumbags stop hiring psychologists and other similar professionals to make the most addicting and psychologically impactful advertisements possible, then maybe I&#x27;ll consider them less than pure evil.I still have uBlock turned off on a few sites, though that list is becoming vanishingly smaller. 4Chan, funnily enough, has the best ads, where it&#x27;s just old school banner ads on the top of the page and the very bottom of the page. No click hijacking, no embedded ads made to mimic organic content, no fucking audio and flashing lights ads. The only type of targeting those ads have is that the general audience that goes on 4Chan is into anime and Japan, both of which I don&#x27;t care about. If the internet still had these kind of ads, I think adblockers would be much less of a \"problem\", but since 99% of them are invasive garbage, whoever is pushing them and whoever argues it&#x27;s \"immoral\" to block them can go fuck themselves. reply brnt 9 hours agoparentprevWhat is the morality of thinking anyone is allowed to fully control my machine? I guess I&#x27;m showing my age, but browsers were _user_ agents, once. reply matheusmoreira 8 hours agorootparentYeah. The audacity of these corporations. It&#x27;s offensive that they even think they can dictate what our computers do or don&#x27;t do. reply temporallobe 53 minutes agoparentprevWhat still gets me is that even with YT Premium, there are still ads if the content creators decide to embed them as part of the content. Yes, they are skippable, but there are still ads…that I paying, to NOT see. This is also a moral issue. What does the exact definition of “no ads” actually mean to YT and is their definition misleading or purposefully vague?Unless they qualify their definition with something like “you may still see in-video sponsored content”, ad-free should 100% ad-free, and it is irritating that that (perhaps) through some nuanced definition of “ads” that they allow this. IMO this needs to be investigated by the FCC.If you look at the advertising literature for Premium, it simply says “Enjoy ad-free videos…” with no asterisk or fine print that has any exclusions. Perhaps there is something deeply buried in one of the “terms and conditions” documents that allows for this, but I haven’t taken the time to look. My point is, YT and the content creators benefit from these ads on a supposed no-ad plan. Imagine if other streaming services like Netflix started doing this. reply rchaud 43 minutes agorootparentLike a TV show with ads, but where the TV actors put in their own ads right into the shows dialogue, in addition to the network&#x27;s commercial breaks.This happens because Youtube doesn&#x27;t pay content makers a flat rate, unless they&#x27;re a whale. reply temporallobe 22 minutes agorootparentYeah there are various ways to sneak advertising into content, but that why this is so insidious. Is product placement an “ad”? Is a quick mention of a sponsor an “ad”? Is a “passive” ad such as background graphic or wearing a sponsor’s t-shirt an “ad?”. Where do we draw that line? I think we’ve simply been conditioned to accept that ads are a normal and acceptable part of life, even if you pay not to have them. Remember when cable TV first became available to the public? It was supposed to be, and was at first, ad-free because you paid for it unlike broadcast TV. Now, cable TV is more ads than content in many cases, and those who have it pay dearly because in most markets, the cable companies have an effective monopoly. We have become the dystopian future we predicted and abhorred, but don’t even know it. reply lobocinza 37 minutes agorootparentprevUse yt-dlp, no ads or sponsor segments. reply philistine 11 hours agoparentprev> And no, I won&#x27;t pay for YouTube Premium — because that wasn&#x27;t part of the deal either.There&#x27;s also the ridiculous fact it is literally impossible to pay to remove the ads without also getting the horrible Youtube Music service. reply crote 3 hours agorootparentHeck, it won&#x27;t even remove all ads. A significant number of creators have sponsor segments, and YT Premium won&#x27;t get rid of that. Why would I pay the Premium tax to get rid of some of the ads? reply lxgr 11 hours agorootparentprevWhat makes me really sad is that Google doesn&#x27;t just not offer a \"Music-less Youtube Premium\" (due to a lack of attention or whatever) – no: They used to offer that product in some markets and have actively discontinued it. reply HeeroML 9 hours agorootparentJust that it does. You only get ads in music videos then. reply figmert 8 hours agorootparentprevWhy does this matter? Can&#x27;t you just not use it? reply willdr 8 hours agorootparentBecause they&#x27;re sold together, so if you wanted forgo YouTube Music, you&#x27;d assume it&#x27;d be cheaper. reply figmert 6 hours agorootparentI&#x27;d be very surprised if it would be considering YouTube already has music where they already pays the copyright holder for. My guess is YouTube music is focused UI on an already offered service and separating it out will likely not make it cheaper, or if it does, it won&#x27;t be a big difference. reply dageshi 7 hours agorootparentprevI wonder if there are licensing shenanigans with music that mean they have to be bundled together otherwise you might not be able to watch pure music videos on youtube. reply literalAardvark 7 hours agorootparentprevI really enjoy YTM and see YT Premium as a wonderful perk. reply seydor 8 hours agoparentprevAnd the platforms that were free and distributed, i.e. torrents became illegal. Youtube started with a ton of illegal stuff (and still contains tons of illegal stuff, but mostly in languages&#x2F;regions that \"don&#x27;t matter\").Internet speeds are maturing, and maybe it is time to try again a self-hosted or distributed model. The hard part is to put ads in it, because ad-supported is traditionally the best medium for videos. However most video creators are already having sponsorship deals reply adhesive_wombat 8 hours agorootparent> still contains tons of illegal stuffI came across whole episodes of British TV on there this very week that were uploaded 12 years ago. I know they have a strict \"no humans involved, ever\" system going, but the programme name was in the title and the video was one of those ones inset into a fake background and the audio was original. I find it amazing that no one (or rather nothing) with a ban button has noticed that for so long.If they actually cared even a microgram and they couldn&#x27;t even get an intern to do a days&#x27; work searching for TV show titles, there&#x27;d be enough failed Reddit moderators out there who they could recruit who would gleefully do the job for free. Not that I would want them to - it&#x27;s bad enough when only bring reactive to often-spurious complaints - but it&#x27;s such a completely perfect lack of interest that it must be very deliberate. reply dageshi 7 hours agorootparentIs it illegal though? Who owns it?General principle of the internet seems to be people can host what they like till someone who has legal ownership of it tells them to take it down at that point they&#x27;re expected to take it down and keep it off their service unless added by the owner.That&#x27;s what google is sticking to because frankly any other method would be a nightmare.The old tv episodes might have muddy&#x2F;unclear ownership and so things continue to coast along until someone exercises their right of ownership. reply seydor 7 hours agorootparentyes it s entirely illegal hosting it , as it is copyrighted content, it even says so in the credits. there are tons of tv series from around the world being hosted, and it&#x27;s not fair use even under the relaxed US laws. The fact that someone has not issued a takedown request doesn&#x27;t make it legal either. reply adhesive_wombat 6 hours agorootparentprevThe TV show was first aired in 2009, and they&#x27;re still on streaming services so it&#x27;s hardly an orphan work. Not that I&#x27;m agitating for more or stricter enforcement, far from it, but it seems strangely lackadaisical compared to the \"walk past a shop playing music and cop a copyright strike\" that also happens on the very same platform.Then again I guess YouTube makes money from ads on these videos being up, so that does explain the sphinx-like impassivity. reply Aerbil313 6 hours agorootparentprevWait a minute…What about a distributed model, but with a distributed ad network which pays people and&#x2F;or the project?Would it be enough to cover internet service provider costs of average folks? reply givemeethekeys 12 hours agoparentprevClassic bait and switch. Google&#x27;s own search page is a good example of how ads have overrun the search results. reply Rastonbury 3 hours agorootparentAd blocker detected please disable to use Search reply jterrys 10 hours agoparentprevEven prior to this change, as far back as a decade ago when Youtube (according to Google) was burning money, they still knew there was some perversely wealthy incentive to keep the platform around. Google has shut down far more useful products for far less. That leads me to believe that the value in Youtube goes far beyond ads. Right now it&#x27;s merely trying to optimize and squeeze as much blood from stone as possible, up until they can measure the tipping point of maximum pain before users spend time on other platforms. reply xxs 8 hours agoparentprev>This is of course bringing up the discussion on the \"morality\" of AdblockingNo, it does not. There is no discussion to be had. reply amadvance 9 hours agoparentprevI&#x27;m also a heavy user of ad blockers, but there is something to be said in defense of YouTube.Creators have the final decision on the ads shown. I have a YouTube channel, and I always disable monetization on all my videos, so no ads are ever shown on my channel.If you see an ad, it&#x27;s because the creator decided to include one. YouTube is simply the platform that enables this choice. reply Prickle 7 hours agorootparentThey are actually removing the ability to control ads in the near future. To my understanding, the only ads creators will have full control over are midroll ads.They will be improving ads on the platform by removing the creator&#x27;s control over them.> optimizing creator revenue and taking the guesswork out of which ad formats to use by removing individual ad controls for pre-roll, post-roll, skippable, and non-skippable ads on newly uploaded videos.https:&#x2F;&#x2F;support.google.com&#x2F;youtube&#x2F;thread&#x2F;233723152&#x2F;simplify... reply amadvance 3 hours agorootparentFrom what is written, they plan to reduce the control of where ads are placed, but still allow enabling or disabling them.Anyway, at present it&#x27;s possible to disable them if you have reached the monetization requirements on the channel, like 1000 subscribers and some amount of hours viewed. reply radley 9 hours agorootparentprevThat&#x27;s not correct. A few years ago YouTube changed their TOS, so they&#x27;re now allowed to show ads on any content, regardless of settings. reply amadvance 3 hours agorootparentYou&#x27;re mixing up two different things. It&#x27;s true that YouTube now places ads to small channels that have not reached the monetization requirements.But after the channel satisfy such requirements, like 1000 subscribers, the creator gets control of the monetization and they can choose.For any major channel you watch, it&#x27;s the creator decision that you see ads or not. reply samplatt 7 hours agorootparentprevMy YT account has a total of five personally-recorded videos (from the era where smartphone cameras still sucked) with no music in the background and no monetisation on any of them.One of the videos was hit with an automated DMCA takedown, one was hit with a \"mature content\" takedown, and the remaining 3 have ads on them now. reply windowsrookie 8 hours agorootparentprevThat&#x27;s not necessarily true. If you are not in the Youtube partner program, Youtube can still monetize your videos and keep the ad money for themselves. reply bongobingo1 9 hours agorootparentprevIs it an on-off switch, or a slider for how many and when? reply iforgotpassword 8 hours agorootparentYour can individually toggle pre- mid- and Post-Roll ads. Your can even set suggested spots within the video for the mid-roll ads, but that doesn&#x27;t really control how many will actually be played.This applies to videos with no copyrighted content. If you use any excerpts or music that someone else claims, anything might happen to your video regarding ads. reply jedrek 6 hours agoparentprevDo realize that viewers are not YouTube&#x27;s only \"customer\". They spend a lot of time and energy courting video creators as well, and their monetization program is one of the few that allows even mid-sized creators to record videos for a living. reply crote 3 hours agorootparentYouTube&#x27;s partner program pays relatively little, though. Pretty much all mid-sized creators I follow also have sponsors and&#x2F;or a Patreon - that&#x27;s their main source of income. reply mrtksn 10 hours agoparentprevIsn&#x27;t that the whole premise of the SV tech?Give a dollar(unprofitable and unsustainable service) for a pennies by burning the money of the investors to capture a market then switch to high profit margin business practices and milk out the captured market thereafter.Sure, it can be framed as spend money when developing a product then make profit of it when released but the winners are determined by keeping alive the developed product longer than everyone else ane when everyone else is gone, then monetise.People who spent billions of dollars to run YouTube at loss for years were not philanthropists, they rightfully expect to make that money back and make much more on top of it. reply mkesper 7 hours agorootparentEverything you said is right except for the \"rightfully\". reply mrtksn 7 hours agorootparentWhy? reply ndriscoll 4 hours agorootparentBecause providing a product&#x2F;service below cost to drive competitors out of the market followed by using your new monopoly to raise prices is exactly the definition of illegal predatory pricing. reply rakkhi 6 hours agoparentprevA few Argentinian peso via VPN for Youtube premium seems fine. reply darklycan51 12 hours agoparentprevThe real reason why anyone could never compete with Youtube was (lack of) monetization reply eqvinox 12 hours agorootparentThat&#x27;s actually an interesting question in itself. Google also has a domineering (though not monopoly) position in ads. If someone were to try to compete with an ad-funded service… how much of a problem would that be?Also: part of the problem is the quality of the ads. Could you actually get \"better quality\" ads for a competitor video platform? Do such ads even exist in sufficient number at this point? (I vaguely remember a significant portion of larger companies reducing their internet ad budgets because they simply weren&#x27;t seeing good returns…) reply raincole 10 hours agorootparentprevThere is a very interesting example, but unknown to western readers. It&#x27;s called Bilibili.It&#x27;s the largest video platform in China[0]. However, it keeps losing money since forever, including in last year, and is expected to keep losing more in 2023.[0]: Youtube is blocked in China and you need a VPN to access it there. reply nvm0n2 7 hours agoparentprev> To me, there&#x27;s currently no alternative to going onto YouTubeVimeo, Rumble, DailyMotion, Facebook Video and self-hosting all still exist you know. There are plenty of alternatives. reply keep_reading 3 hours agorootparentVimeo changed their model and are focused on paid business users now reply HeeroML 9 hours agoparentprevJust that energy and such got more costly. Why should YouTube pay extra cause you feel you had an agreement with them on how much ads there are? reply wiseowise 7 hours agorootparent> Why should YouTube pay extra cause you feel you had an agreement with them on how much ads there are?Because I say so with my AdBlock. This is the reason why small guy should have power. reply crop_rotation 21 hours agoprevApart from the Youtube stuff, the post also highlights something else, entitlement towards free services like uBlock origin.> It’s one thing to play cat and mouse with YouTube. It’s quite another to deal with a wave of angry users.> And then one of the moderators actually deleted their Reddit account. “The ID in the post wasn’t updated because my mother was hospitalized,” they said. It’s sad to see them leave because of some drive-by comments — new users who sign up for Reddit, leave their comments,I have seen this becoming more and more common on open source projects and totally free services, where people act as if they are entitled to something as if it is their god given right. The people doing public services like uBlock origin can only take so much from the mob. reply dessant 20 hours agoparentIt also feels awful to be called a beggar and a panhandler just because you&#x27;re trying to find a balance and build a sustainable project by having a donation popup (that can be disabled) in your software.This disgusting review was sitting at the top of the review page for Search by Image on the Chrome Web Store: https:&#x2F;&#x2F;i.imgur.com&#x2F;P1QU176.pngThis person has edited their review a couple of times in the past year which pushed it to the top, and also emailed me with a similar demeaning message. I&#x27;ve reported it to Google staff, and they thought that the review did not break their content policy, so they did not remove it.So yeah, it hurts when you&#x27;re offering so much of your free time for so little benefits, or none at all, and a couple of entitled jerks still manage to poison the well for everyone.With each abusive message the thought of no longer offering up your time and the results of your work for free grows stronger and stronger. It&#x27;s no surprise that people either quit, sell their open source projects, or stop offering it for free. reply kerkeslager 10 hours agorootparent> This disgusting review was sitting at the top of the review page for Search by Image on the Chrome Web Store: https:&#x2F;&#x2F;i.imgur.com&#x2F;P1QU176.png> This person has edited their review a couple of times in the past year which pushed it to the top, and also emailed me with a similar demeaning message. I&#x27;ve reported it to Google staff, and they thought that the review did not break their content policy, so they did not remove it.So? What&#x27;s the point you&#x27;re making? Users aren&#x27;t allowed to have preferences about software they get for free? User experience doesn&#x27;t matter for free software? Who did you release this software for if not for users?It&#x27;s a 4 star review, ffs. Do you think every review that isn&#x27;t glowing is disgusting? Why on earth would you expect Google staff to remove a review which merely expresses a preference?It really feels like a significant portion of Hacker News just doesn&#x27;t really grok the whole \"doing nice things for other people\" thing. If you only did this for money or glowing praise for how generous you are, you&#x27;d have been better off choosing one of those and pursuing it singlemindedly instead of trying for both money and being perceived as generous, and then being surprised when people notice you aren&#x27;t doing either perfectly. And sure, you&#x27;re not obligated to just do it out of the kindness of your heart, and you have every right to choose how nice you want to be. But if you aren&#x27;t doing it for purely prosocial reasons, then maybe don&#x27;t expect people to fawn over how purely prosocial you are. reply dessant 8 hours agorootparentYou&#x27;ve lost the plot if you think that it is normal or acceptable to call the maintainers of an app or extension beggars and panhandlers if there is a donation prompt shown once a year when you open the app. Most people would in fact find it appalling and demeaning to treat people with such little respect. I think you should also take a second look at your own performance in this thread, and maybe ask a friend for an opinion about your comments, because that behavior is not normal either. reply least 20 hours agorootparentprev> It also feels awful to be called a beggar and a panhandler just because you&#x27;re trying to find a balance and build a sustainable project by having a donation popup (that can be disabled) in your software.Interrupting someone&#x27;s browsing experience to ask for donations is both providing a poor user experience and is in poor taste. I think it&#x27;s fine to solicit donations in the browserAction popup, the settings page or even the initial installation window, but doing so elsewhere would deservedly be criticized. reply dessant 20 hours agorootparentA donation popup is shown once a year, and only when you use the extension, it does not randomly interrupt your browsing experience. Te popup can even be disabled from the extension&#x27;s options. It is similar to a donation prompt being shown when an app is opened, once a year.That&#x27;s what this person was complaining about, that they&#x27;ve seen a donation prompt once when they&#x27;ve initiated an image search with the extension.There is no winning with some of these people, they want your time and the results of your work, they want it for free, and they want it to be neatly packaged and presented exactly the way that is most convenient for them. If you deviate even a little bit from their unreasonable expectations, you&#x27;ll be promptly attacked.Once your projects grow past a certain size, threats of physical violence also become a regular occurrence, here&#x27;s a milder email I have received last year: https:&#x2F;&#x2F;i.imgur.com&#x2F;LKJQq1p.pngThis kind of harassment is happening every 1-2 weeks on different channels, we keep these private messages because everything has to be documented in case law enforcement needs to be involved. reply ryandrake 16 hours agorootparentNot defending the trolls, but this kind of abuse is part and parcel of merely being online and putting anything out there. I&#x27;ve received hate mail and even one death threat from just commenting on HN. Lots of unhinged (but ultimately cowardly) people out there who feel empowered by distance and anonymity. I don&#x27;t know a single female internet user who hasn&#x27;t been on the receiving end of absolutely vile anger and hate at least once. Thick skin is a must. reply dessant 16 hours agorootparentOf course, though the frequency of repeated abuse makes all the difference. reply kerkeslager 10 hours agorootparentprev> There is no winning with some of these people, they want your time and the results of your work, they want it for free, and they want it to be neatly packaged and presented exactly the way that is most convenient for them. If you deviate even a little bit from their unreasonable expectations, you&#x27;ll be promptly attacked.You&#x27;re making a pretty big leap from \"users prefer these things\" to \"users expect these things\".Are you going to pretend you don&#x27;t want things to be free, neatly packaged, and convenient? Who wouldn&#x27;t want this?And the idea that a four star review which starts with \"A good extension.\" is an \"attack\" is absurd. Given it appears you expect your users not to express any preferences that aren&#x27;t exactly what you&#x27;ve implemented, perhaps it&#x27;s you who has unreasonable expectations? reply account42 3 hours agorootparentprev> Once your projects grow past a certain size, threats of physical violence also become a regular occurrence, here&#x27;s a milder email I have received last year: https:&#x2F;&#x2F;i.imgur.com&#x2F;LKJQq1p.pngThat&#x27;s not a threat of physical violence at all. reply caconym_ 15 hours agorootparentprev> doing so elsewhere would deservedly be criticized.I suggest that these people express their criticism by not using the software in question. I doubt the typical purveyor of free-as-in-* software who&#x27;s stuck between a rock and a hard place re: monetization particularly cares what somebody who doesn&#x27;t understand the personal specifics of their dilemma thinks about their chosen solution to it. reply least 14 hours agorootparent> I suggest that these people express their criticism by not using the software in question.Do you also suggest that when an application is ad-ridden or potentially malware-ridden to also just not use the app? Naturally that&#x27;s an option, but the review is to warn other users of their experience.I don&#x27;t think death threats or calling people slurs is appropriate, but the review being complained about it is pretty mundane. reply caconym_ 13 hours agorootparent> Do you also suggest that when an application is ad-ridden or potentially malware-ridden to also just not use the app? Naturally that&#x27;s an option, but the review is to warn other users of their experience.Is a restaurant owner pissed off about a one star review by somebody who didn&#x27;t like the decor in the bathroom implicitly suggesting that people who receive food poisoning at a restaurant have no right to communicate that experience to other potential customers? Is a homeowner who puts out ant traps in her kitchen tacitly endorsing genocide?I think there is such a vast gulf between displaying a mildly annoying message asking for donations and tricking someone into installing malware on their computer that anybody with a moderately intact sense of proportionality should have no trouble seeing it. So, no, I don&#x27;t suggest that. reply least 9 hours agorootparentI think there&#x27;s even greater utility in telling people about minor things that might annoy them, because those minor things aren&#x27;t going to get a developer&#x27;s application pulled from the app store, but have a meaningful impact on the user&#x27;s experience.That is, in fact, exactly what reviews are for. reply caconym_ 38 minutes agorootparent> I think there&#x27;s even greater utility in [...]You really think it&#x27;s more important for me to air my grievances about a free software&#x27;s occasional donation nag messages than to tell other potential users it&#x27;s a front for malware? That&#x27;s honestly really strange, and I categorically disagree. reply xorcist 6 hours agorootparentprevI totally agree with this sentiment. Could I also bill the creator for my time invested in learning the software and adjusting my workflows for it, all the hours invested before the hidden anti-features showed the true intention of the software? Otherwise this whole argument could legitimize spyware. I could not reasonably decide to stop using the software before I was informed of the anti-features, regardless of how their invasiveness. reply dessant 3 hours agorootparentIt&#x27;s definitely a strange proposition, but you could try it yourself.Install Signal on your phone and start using it, in a couple of months you will be shown a donation popup a single time when you open the app. At this point uninstall the app and contact Signal&#x27;s development team to send them an invoice for your invested time that has now been ruined when that donation prompt has interrupted your messaging experience.Also call them beggars and panhandlers, after all that&#x27;s perfectly reasonable, and even respectable. reply glenneroo 2 hours agorootparentFor the record, I get that donate popup on Signal every couple weeks, and it&#x27;s all the more annoying because I donated for several years until they recently removed SMS support. reply kerkeslager 10 hours agorootparentprev> I suggest that these people express their criticism by not using the software in question.As with most \"love it or leave it\" arguments, this is a transparent attempt to silence critics without actually bothering to engage with criticism, even if it&#x27;s constructive.Anything you put in front of a significant number of people will be criticized, and rightly so, because it&#x27;s not perfect. Admitting things aren&#x27;t perfect is the first step to making things better.This argument is particularly disigenuous in the context of a discussion about YouTube, because YouTube is effectively a monopoly in a number of ways--it&#x27;s effectively an argument that once a product reaches monopoly status, it can do whatever it wants and nobody can criticize.Adults learn to accept, integrate, and throttle their intake of criticism. If you haven&#x27;t, you have some growing up to do. reply chii 9 hours agorootparent> Admitting things aren&#x27;t perfect is the first step to making things better.the implied assumption being made here with this train of thought is that it is the author&#x27;s imperative duty to make things better.It is not. The author has zero obligation to make it better for anyone; they do it at their leisure and at their convenience. reply pigbearpig 3 hours agorootparentprevThat review is completely respectable and something I would leave if an extension added popups asking for money to my browsing experience. reply PH95VuimJjqBqy 18 hours agorootparentprevimagine having the ability to dislike something without characterizing it as disgusting.One could almost call it a super power. reply dessant 17 hours agorootparentI think empathy is a much more relevant superpower, and the lack of it can be disgusting. reply kerkeslager 10 hours agorootparentWhere&#x27;s your empathy for your users? Do you really not see the point of view of that review? reply shiroiuma 14 hours agorootparentprevUnfortunately, after all my observations of humans over the course of decades, I feel like real empathy is actually pretty rare in humans. It might be common in fictitious characters, but not in real people. reply PH95VuimJjqBqy 14 hours agorootparentempathy to random humans is rare, empathy to those in your immediate vicinity is not. I suspect the biggest asshole at your work probably has empathy for their family.The fundamental issue at play here is trying to manipulate language by using the word disgusting to evoke a stronger reaction than is warranted.At some point you&#x27;re going to need a stronger word than disgusting because you&#x27;ve watered it down so much. Where do you go? reply RugnirViking 14 hours agorootparentprevStrange that we should come to opposite conclusions; I feel like pretty much everyone I&#x27;ve ever known has real empathy. reply lofaszvanitt 15 hours agorootparentprevCreate a wall of shame and let people laugh about the idiots. So simple. reply shiroiuma 14 hours agorootparentIt sounds good, but a lot of people just aren&#x27;t mentally equipped for that: some people are fighters, some just aren&#x27;t. So instead of confronting the assholes and putting up the \"wall of shame\" like you suggest, they&#x27;ll just give up and go find another hobby that doesn&#x27;t result in receiving such vile messages. reply lofaszvanitt 14 hours agorootparentYeah. People need to go in the line of fire a lot more. Once you are hardened, you just waltz through these bullshits like a 70 ton tank. reply armada651 14 hours agorootparentThe people we&#x27;re talking about are providing a service for free, with no direct benefit to them. Why would they go into the line of fire for something like that?It is our collective duty to make sure individuals providing a service to society are treated with respect. If we can&#x27;t do that then we simply don&#x27;t deserve their time and effort. reply lofaszvanitt 14 hours agorootparentWhy would someone who fears crossing photocell doors try it again and again... For years? To overcome the phobia, that&#x27;s why.Nah, people need to be brought out of the protecting bubble.You give money to them, so they have a tangible evidence that their work means something. Not just stars and patting in the back. Time to stop the open source beggar movement. reply armada651 14 hours agorootparentRegularly having to deal with abusive comments takes a mental toll on you no matter how much of a tough guy you are. Why do you think we&#x27;re entitled to them not only sacrificing their time, but also their mental heath? Donations on most open-source projects don&#x27;t even come close to covering the costs of either.Again, we are not entitled to their services and assholes can and will ruin nice things for all of us. reply lofaszvanitt 13 hours agorootparentNot really. Tbh I like to gut these people. Most of those who belittle-berate others are weak people, they compensate for something. Once I give them some treatment, 99% percent backs off, because they don&#x27;t like the barrage of insults&#x2F;whatever.I never said we are entitled for anything. I don&#x27;t like that oss developers get paid nothing and have to - seemingly - beg for sponsorhip&#x2F;money. But the open source model was ugly from the get go. You build something up, decide to abandon it, and people fork it, expropriate it, and the original dev is forgotten. They get nothing. The actual guy, who maintains it might get something in the future, but who created the foundation - since he left the project - gets nothing. Ridiculous.The open source movement&#x2F;idea is flawed and needs to be changed, that&#x27;s all. replyJohnTHaller 16 hours agoparentprevIt&#x27;s unfortunately been this way for a long, long time. Though it does seem to have gotten more frequent in recent years. I&#x27;ve been running PortableApps.com for nearly 2 decades and, in that time, I&#x27;ve been sworn at, harassed, doxxed, received death and rape threats, etc. My personal favorite was a user who accused me of donating a kidney to my father because I thought I was better than everyone else and to try to garner donations. Despite the fact that I donated it years before PortableApps.com existed. Just this week I had someone mad a meet for not updating an app due to the fact that I am recovering from a concussion. reply mixmastamyk 16 hours agorootparentThe common advice to delete toxic people from your life applies to those online as well. I don&#x27;t think of this as a FLOSS-centric problem. Instead of taking it personally I try to think of a suffering person lashing out at the world attempting to spread misery. Then I hit the delete&#x2F;block button and move on. reply matheusmoreira 20 hours agoparentprevI hope the people developing uBlock Origin and all the filter lists are alright. They&#x27;re my heroes. No one deserves this treatment, least of all them.I like to take a moment to publicly thank them whenever the opportunity to do so arises. Thank you so much! reply blooalien 13 hours agorootparentEvery single time I meet one of the developers of an open source project that has benefited me in some way, I always make it a point to tell them \"Thank you\" and let them know how (and how much) their generosity benefited me, and how much I really appreciate it. I also make efforts to help out in any ways I&#x27;m able. Sometimes that&#x27;s cash (when I&#x27;ve got some available to spare), and sometimes it&#x27;s just helping out in support channels, or bugreports &#x2F; pull requests, etc. reply chii 8 hours agorootparentThank you for making the world a better place! reply blooalien 7 hours agorootparentNot I, thank you. The folks who create and release open source software (which I myself have not done in many years now). I&#x27;m just reacting appropriately to their generosity which is actively contributing to the world being just that little bit better because of their actions &#x2F; decision. :~) reply matheusmoreira 1 hour agorootparentYes! Their generosity is an inspiration to me. Open source technology is empowering and world changing. I really admire these people. replydeadmutex 21 hours agoparentprev> I have seen this becoming more and more common on open source projects and totally free services, where people act as if they are entitled to something as if it is their god given right.Do you count YouTube as a \"free service\" (with ads) in this case?I wonder if there is an overlap with people that expect free stuff and people that use uBO on YouTube. YT does offer most users YT premium, which gives users an ad free experience.Disclosure: I worked at YT in the past, but still pay for premium because I don&#x27;t want the ads. reply esrauch 20 hours agorootparentI pay for YT premium and Ads are still my #1 complaint about YT.Partly this is by design, where it seems to decide that a creator having a \"merch\" ad integration doesn&#x27;t count as an ad. Which might be understandable (but still not what I want) if merch meant creator&#x27;s face on a mug, but it also includes products where a home fix it channel will have an overlay of products from Home Depot which is literally just an ad with no caveats (an overlay that obscures the video on Chromecast, it&#x27;s part of YT UI not embedded in the video).Though I guess I&#x27;m also unclear how often I see that because Premium is buggy and how often it&#x27;s intentional. Ever since they made YT on Chromecast an \"app\" it&#x27;s been a disaster of account state bugs where it also keeps trying to enforce safe mode (which blocks half of everything, including practically any music video) because it says it&#x27;s not logged in even though I&#x27;m trying to cast from a phone that is logged in. reply chii 8 hours agorootparent> a creator having a \"merch\" ad integration doesn&#x27;t count as an ad.this is why you also install sponsorblock (https:&#x2F;&#x2F;sponsor.ajay.app&#x2F;). Only whitelist the channels you want to \"support\", if you really want to make sure to eyeball the sponsorship (which doesn&#x27;t really help unless it happens to be a product you actually are interested in buying). reply perryizgr8 13 hours agorootparentprevThis is the reason I won&#x27;t pay for youtube red. It doesn&#x27;t do what it says. It says \"ad-free\" but only filters some of the ads. It&#x27;s literally false advertising. It&#x27;s doubly frustrating because youtube can easily fix it if they want. They would just like the extra money. reply wdb 19 hours agorootparentprevYT Premium costs more than Netflix or Disney+. Quite pricey to get ad free Youtube videos and not as much content than normal streaming sites. reply codeTired 12 hours agorootparentYou are still served ads in videos. It sucks paying for premium and your content creators use 3 minutes of 15 minute video to promote “nordVpn”. reply chii 8 hours agorootparenthttps:&#x2F;&#x2F;sponsor.ajay.app&#x2F; - sponsorblock is a must. reply skyyler 9 hours agorootparentprevThat’s kind of your fault. None of the channels I subscribe to do sponsored content. reply userinanother 14 hours agorootparentprevEspecially considering that YouTube gets the content for almost free reply Jensson 13 hours agorootparent> YouTube gets the content for almost freeGoogle pays out about 50% of ad revenue to content creators, that isn&#x27;t \"almost free\" that is many billions of dollars. reply kerkeslager 9 hours agorootparentIf a channel hasn&#x27;t make any ad&#x2F;premium revenue yet, Google still has the content for the cost of supporting the upload--i.e. they got it almost for free.The fact is, Google takes on no risk and does none of the work of creating content, and takes a 45% cut for distribution, and is free to continue changing their terms to make things worse for content creators. reply userinanother 13 hours agorootparentprevYeah but what percentage of subscription costs go to paying creators? reply Jensson 13 hours agorootparentThis site says 55% since youtube take 45%:> In the end, YouTube takes a 45% cut of a creator’s Premium earnings, just as it does for ad-generated revenue.https:&#x2F;&#x2F;vidiq.com&#x2F;blog&#x2F;post&#x2F;youtube-premium-creator-revenue&#x2F; replynavigate8310 19 hours agorootparentprevImagine paying to an ad company that profiles, tracks and snoops. reply matheusmoreira 20 hours agorootparentprevYou still have ads despite paying YouTube not to show you ads. They&#x27;re hardcoded into the videos themselves now. You&#x27;re also tracked and profiled by Google which is an indignity unto itself. reply ozarker 21 hours agorootparentprevI think he’s referring to the Adblock as the free service here. reply ysavir 21 hours agorootparentI think deadmutex is pointing at a bit of irony and hypocrisy at how we&#x27;re saying it&#x27;s bad for people to feel entitled to free adblock support (and ask for more) but champion people feeling entitled to free videos by blocking the ads or refusing to pay for no ads. reply matheusmoreira 19 hours agorootparentNot hypocritical at all.There is no \"entitlement\" to videos. They are free. YouTube sends them to us for free. They do so hoping we&#x27;re gonna look at the ads. We&#x27;re under exactly zero obligation to actually do that though. It is not at all our responsibility to make their business model work.Abusing open source developers is the true entitlement. reply caconym_ 15 hours agorootparentAnother true entitlement is adblock users complaining that YouTube is greedy, etcetera, now that they&#x27;re actually kicking said users off their site. You (in the general sense) are certainly not responsible for making YouTube&#x27;s business work, but by a similar token they are certainly not under any obligation to continue serving data to users who don&#x27;t generate any revenue. reply matheusmoreira 14 hours agorootparent> by a similar token they are certainly not under any obligation to continue serving data to users who don&#x27;t generate any revenueSure. Let&#x27;s see them return HTTP 402 Payment Required instead of a free video stream then. I&#x27;m actually okay with that.Somehow I doubt they&#x27;ll ever do that. They want that mass market appeal, don&#x27;t they? I know it. You know it. Everyone knows it. Just like the \"free\" apps who do anything in the world to get themselves installed so they can start monetizing. reply caconym_ 13 hours agorootparentI&#x27;m not really sure what you&#x27;re getting at here. By all accounts, YouTube is implementing countermeasures that block adblock users from watching videos on their site. What is functionally different between that and returning a 402, especially since you can in fact pay for ad-free YouTube? reply matheusmoreira 13 hours agorootparentNope. Still free, they just managed to circumvent my browser extension. They&#x27;re not even supposed to know I have it installed.They need to either start charging everyone for access or stop complaining. I pay for access to a lot of things but I&#x27;m not paying money to avoid ads. I sure as hell am not gonna pay money to watch videos with hard coded ads. reply thirdsun 4 hours agorootparent> They need to either start charging everyone for access or stop complaining. I pay for access to a lot of things but I&#x27;m not paying money to avoid ads.Then don&#x27;t. It&#x27;s fine. However please don&#x27;t complain about not being able to get access to the content on Youtube without paying or watching ads.> I sure as hell am not gonna pay money to watch videos with hard coded ads.That&#x27;s up to the content creators, not Youtube. Very few of my subscribed channels use hard-coded apps and if they do they need to make up for it with worthwhile content. reply matheusmoreira 1 hour agorootparent> please don&#x27;t complainI don&#x27;t complain. If I see an ad I just close the tab. uBlock Origin and yt-dlp is the only reason I watch stuff on YouTube at all.> That&#x27;s up to the content creators, not Youtube.Their business relationships are not my concern. I&#x27;m not paying to watch ads. Maybe YouTube should implement their own Sponsor Block system for the benefit of their paying customers. reply caconym_ 12 hours agorootparentprev> Nope.What part of my comment, specifically, is this responding to?> They need to either start charging everyone for access or stop complaining.Why? reply matheusmoreira 12 hours agorootparent> What part of my comment, specifically, is this responding to?The notion that detecting our adblocker and actually charging for content are equivalent.> Why?Because if they send us ads we&#x27;ll delete them and there is pretty much nothing they can do about it. reply caconym_ 12 hours agorootparent> The notion that detecting our adblocker and actually charging for content are equivalent.Well then maybe you meant to respond to somebody else, because that&#x27;s not something I said at any point.> Because if they send us ads we&#x27;ll delete them and there is pretty much nothing they can do about it.This entire HN thread and the linked article are about how they are literally doing something about it, and it&#x27;s working. reply matheusmoreira 9 hours agorootparent> it&#x27;s workingThe cat and mouse game is not instantaneous. Give it a little time. replyhombre_fatal 14 hours agorootparentprevConvenient lack of mention of the content creators in these threads where people just complain about Youtube corporation. reply matheusmoreira 13 hours agorootparentContent creators have other revenue streams these days. The ones I enjoy have quite the following on Patreon and other such platforms. Unlike ads, those are perfectly ethical ways to make money and I wish them all the success in the world. They don&#x27;t even require copyright to work since they don&#x27;t depend on artificial scarcity. reply fennecbutt 15 hours agorootparentprevPsssh, you and I both know the model only works because people _do_ sometimes look at ads.If people don&#x27;t, then YouTube will stop delivering videos for free. Your argument is pretty disingenuous. reply shiroiuma 14 hours agorootparentSo you think people watching over-the-air television are morally obligated to watch the ads and not mute them, leave the room, use a DVR to skip them, etc.? reply matheusmoreira 14 hours agorootparentprevSo what? Let them stop. Let their \"model\" stop working. reply pb7 8 hours agorootparentprevAd blockers are free. They’re made available to be downloaded for free. It is not at all our responsibility to make their business model work. Open source developers are entitled. reply matheusmoreira 1 hour agorootparentWhat business model? reply Vt71fcAqt7 19 hours agorootparentprevExpecting that the videos will be free with no qualifiers (such as an ad playing) is also entitlement. Not that you have said that explicitly but that seems to be a common assumption among many adblock users. reply 8note 18 hours agorootparentYouTube is free to make windows and Mac apps, and turn off their web views.They&#x27;re relying on me doing work to run a browser that renders their ads, rather than providing a binary. They&#x27;re not sending me a page of ads, they&#x27;re sending me a couple files that I can choose how to show and what to put through a JavaScript interpreter reply caconym_ 15 hours agorootparentThey&#x27;re also free to build more serious adblock countermeasures into their website, which is exactly what they&#x27;re doing now, and people are complaining about it.As GP said, maybe this is not your position, but it&#x27;s a common enough one that their comment is not out of line (given that you are the one who replied to them). reply Vt71fcAqt7 17 hours agorootparentprev>YouTube is free to make windows and Mac apps, and turn off their web views.I have revanced which edits their binary to remove ads. I don&#x27;t see what your point has to do with mine though. My point is this: adblock users are grazing from youtube&#x27;s field. We are eating the grass that youtube has planted and watered. To expect that such a field exists and then to expect that it can be eaten from at will is entitlement. To say \"but they put up no fence\" (or, more accurately, a weak fence) is not a refutation of this point. In fact it is exactlty what defines it as being a tragedy of the commons. reply matheusmoreira 18 hours agorootparentprevYouTube switching entirely to a Netflix-like paid model or going bankrupt are entirely acceptable outcomes. reply ndriscoll 20 hours agorootparentprevOne is free high quality security software, and the author doesn&#x27;t even accept donations. The other is \"free\" videos that come with malware. reply pb7 8 hours agorootparentOne is the best, most reliable video serving platform on the planet and the other is a scriptkiddie’s project that evidently doesn’t even work and he’s so salty about it that he had to make a post. reply ndriscoll 3 hours agorootparentThe OP is a post by a random person discussing reddit drama. As far as I can tell, the author of uBO isn&#x27;t involved in any of it.uBO does work fine, and is easily one of the most valuable pieces of end user software there is. Raymond Hill is very generous and has made a very positive impact on the world. reply crop_rotation 21 hours agorootparentprevCorrect. reply AshamedCaptain 21 hours agoparentprevBut I don&#x27;t understand why this would be annoying at all to the developers. I have absolutely zero conundrum with just ignoring a request if I&#x27;m not in the mood to do it.Most of them I even delete outright, but I still have requests that were sent to me in 00s that I&#x27;m keeping just in case one day \"I&#x27;m in the mood\".And yes, people request (demand!) crazy things, and have done so for decades. There are even \"If you don&#x27;t do it, then $threat\" guys. And my area of software is generally industrial&#x2F;professional.... reply taftster 21 hours agorootparentI mean, you still read them though, right? And you somewhat sort out the ones based on how much of a buffoon the user is? Maybe someone with excellent writing skills and having demonstrated reading all the documentation and FAQs is still asking for help in a respectful and intelligent way, and so maybe you engage.All of that is mental tax. And it gets tiring, even if you&#x27;re mostly ignoring the request. It&#x27;s still tiring even when you&#x27;re in the mood for it.Just saying, it&#x27;s a hard thing and I definitely sympathize for the way which open source &#x2F; open project &#x2F; volunteer collaborators get treated. reply AshamedCaptain 20 hours agorootparent> Maybe someone with excellent writing skills and having demonstrated reading all the documentation and FAQs is still asking for help in a respectful and intelligent way, and so maybe you engage.You mean it gets tiring to find the entertaining messages instead of the random trash? Because it doesn&#x27;t matter how much effort the sender has put, or how intelligent his request&#x2F;question&#x2F;contribution&#x2F;comment is. If I&#x27;m not in the mood, I will ignore it. I&#x27;m doing it for the fun, not to provide free support, so I will only read stuff that is fun to me. Obviously being an intelligent question is likely to add points, but it&#x27;s not always the case.It&#x27;s not like this is race to see who is the least Torvalds-like of the bunch. It&#x27;s 100% OK to just ignore everything. The people who complain \"I had to moderate comments while my mother was in the hospital!\" look like they have an addiction, or a runaway hobby.I even have an online board for this sort of requests and generally I just read the subject lines. Fortunately for them, once your software is popular enough, a lot of people seem to like to reply to other people&#x27;s questions, for some reason. reply taftster 20 hours agorootparentMaybe you can ignore it? And that&#x27;s great, if so.But I know I can&#x27;t. I&#x27;m perfectly fine ignoring the buffoons. But I feel much anxiety over ignoring an insightful request or comment that would benefit both myself and the user if I were to engage.If I&#x27;m passionate about a project (in whatever form of contribution), I definitely want to help people who are genuinely looking for help. The problem is the signal to noise is way out of line, heavy skewed the wrong direction.For me it&#x27;s a mental tax to wade through and find the good requests sorting them out from the bad ones. And it causes anxiety to miss the good ones. reply blooalien 13 hours agorootparent> \"For me it&#x27;s a mental tax to wade through and find the good requests sorting them out from the bad ones.\"This might be one of those very valid use-cases for an \"A.I.\" &#x2F; LLM to classify \"hostile\" messages into some sort of \"junk bin\" and maybe flag ones it&#x27;s not entirely certain about for human review. Could fairly dramatically cut down on the garbage hopefully, leaving only the stuff worth reading. reply Ferret7446 18 hours agorootparentprevSome people just aren&#x27;t suited for certain jobs. There&#x27;s nothing wrong with the person, and there&#x27;s nothing wrong with the job (in this case, the job \"just is\"). reply PH95VuimJjqBqy 17 hours agorootparentprev> I mean, you still read them though, right?no?am I the only one with the super power of leaving a discussion and never going back? reply bri3k 20 hours agorootparentprevBut why are you working on a project? If it isn&#x27;t for the money then you are doing it to &#x27;give back to the community&#x27;. But if they are turning hostile to you then why continue? reply amenhotep 17 hours agorootparentWho is \"they\"? In the UBO threads I&#x27;ve seen there are about a hundred supportive comments for every entitled dickhead - if that&#x27;s enough to make you characterise the community as \"turning hostile\" then you are unlikely to ever be satisfied. Bad and inconsiderate people exist. The sensible thing to do is just ignore them. reply blooalien 13 hours agorootparent> \"The sensible thing to do is just ignore them.\"I tend to go one step further than \"ignore mode\" (when I&#x27;m not bein&#x27; so utterly stupid as to get sucked in and actually respond) and actively block them any and every way that I can so that I never see that person&#x27;s crap again. reply satvikpendem 20 hours agorootparentprevBecause you want to see that sort of project exist and if no one else is doing it, why not yourself? That&#x27;s why I work on (certain) projects anyway, not for any community support or for money. reply blooalien 13 hours agorootparent> \"Because you want to see that sort of project exist and if no one else is doing it, why not yourself?\"That right there was my understanding of how most open source projects come into existence. Building a thing because it&#x27;s a thing you want, and it don&#x27;t yet exist in the form you&#x27;re seeking, so ... \"I&#x27;ll just make it myself!\" Then you throw it out into the world, because \"Hey, why not?\" reply frebdo 21 hours agoparentprevThese services have had years to set up privacy-preserving micropayment systems. Instead they want your PI and a monthly fee, all the while using network effects to create defacto monopolies.Why are these big tech monopolists so entitled? reply crop_rotation 21 hours agorootparentI am talking about free and open source products like ublock origin and not YouTube itself. Entitilement towards youtube can be debated, entitlement toward uBlock origin is just bad behaviour. reply frebdo 21 hours agorootparentSuch is my reading comprehension on Saturday lol reply bluish29 21 hours agorootparentI hateto bring it to you but we are on sunday :) reply uoaei 21 hours agorootparentprevToday is Sunday reply LordShredda 21 hours agorootparentprevIf we&#x27;re going through the hassle of micropayments and other unnecessary beggar stuff, when why rely on some big company to take a cut of the money? Just setup a bank account and host your videos on a simple web hoster. If you&#x27;re not willing to learn how to use wordpress then don&#x27;t complain about youtube putting ads. reply plasticeagle 20 hours agoparentprevIronically, \"entitlement towards free services like uBlock origin\" is exactly the kind of sentiment that leads to the use of ad-blockers in the first place.So it can scarcely be surprising that the sorts of people blocking youtube abs because they want the content for free, are the same sorts of people that feel entitled to uBlock Origin&#x27;s services for free.If you want youtube&#x27;s content without ads, then pay for it. If you despise ads, but refuse to pay, then don&#x27;t watch youtube. reply goalieca 20 hours agorootparent> Ironically, \"entitlement towards free services like uBlock origin\" is exactly the kind of sentiment that leads to the use of ad-blockers in the first placeEntitlement towards tracking me across the internet and delivering malware is why I use an adblocker. reply sofixa 19 hours agorootparentPrecisely why I use an adblocker but still pay for services thay provide that option (like YouTube Premium, Nebula, various Patreons). reply jonathanstrange 7 hours agorootparentprevWhy can&#x27;t I just use an ad blocker? My machine, my choice of what and how I display things on it. You haven&#x27;t presented any argument why people shouldn&#x27;t use ad blockers. I suppose the pejorative term \"entitled\" is supposed to replace the actual argument? reply fennecbutt 15 hours agoparentprevDoesn&#x27;t the same apply to YouTube then? People who want to block ads are entitled imo. Those people outright refuse to pay or to simply not use the service if they don&#x27;t like ads. And it enrages so many people when this is pointed out.Google made a mistake in offering free drive, gmail, Google docs, etc etc. Imagine telling someone in the 90s all the shit we get for free with a couple ads&#x2F;our data being sold.People have free will, they should use it, and stop using these services if they don&#x27;t like ads or want their data sold.Pay for email instead of your Gmail. Everyone refuses to do this, they&#x27;d rather shake hands with a devil and then cry when their soul is taken. reply wintermutestwin 3 hours agorootparentWhy does youtube have a paid option to avoid ads but not to avoid the violation of our privacy?Everyone talks about how no one cares about their privacy and just want free stuff. When the world was signing up for gmail or watching youtube, where was the big click to acceopt that explained the (obscenely unfair) trade users were making?Entitled? Google is the one that feels entitled to our data. reply kerkeslager 9 hours agorootparentprev> People have free will, they should use it, and stop using these services if they don&#x27;t like ads or want their data sold.People have free will, and they should use it the way you want them to?No thanks, I don&#x27;t agree to the rules set forth by the ad-supported companies. I think I&#x27;ll use my free will to install an adblocker.I don&#x27;t use Gmail any more, but that&#x27;s because there are viable alternatives for people with my technical abilities. Not everyone is a software dev. The tradeoffs for most people switching off Gmail aren&#x27;t acceptable.When the choices are \"conform to what this company wants\" or \"don&#x27;t have working email\", that&#x27;s not freedom of choice. Freedom requires real viable alternatives. Only in late-stage-capitalist hellholes like Hacker News is this sort of choice considered freedom.I literally read someone on HN recently saying that if people didn&#x27;t want to pay tens of thousands yearly for insulin they were welcome to not, i.e. the choices are pay a pharma company or die. That&#x27;s a much more extreme example, but it&#x27;s pretty typical of HN these days. reply jonathanstrange 7 hours agorootparentprevThe way I see it, Youtube feels entitled to get some of my ad viewing time. If they&#x27;d pay me 14.95 USD per month, I&#x27;d probably watch their ads. But they never made me that offer, they believe I should spend my time to increase their business revenue for free. Not only that, they&#x27;ve convinced tens of thousands of unemployed people to make content for them! reply FuckButtons 13 hours agorootparentprevYou say that as though there’s a viable alternative, which is precisely googles business model. reply josteink 9 hours agorootparentprev> Those people outright refuse to pay or to simply not use the service if they don&#x27;t like ads. And it enrages so many people when this is pointed out.YouTube used to offer “Premium Lite” which was reasonably priced and only offered ad-free YouTube.But now Google has shut down that subscription and only offer is one more than twice the price which includes lots of things people don’t want. I can see why some people refuse to pay for that. reply Gigachad 19 hours agoparentprevOf course Ublock users think they are entitled to free stuff when the whole point of the tool is getting free access to sites without paying for ad free. reply gchamonlive 21 hours agoparentprevWe could apply LLMs to act as an interface with the angry crowd, rephrasing angry comments into constructive criticism and summarizing needs. In turn LLMs could be applied to synthesise development progress and answer the angry crowd. Everyone would be happy. reply djbusby 21 hours agorootparentOr, use an LLM to detect angry comments and delete them before any humans have to deal with the BS reply PH95VuimJjqBqy 17 hours agorootparentor use LLM&#x27;s to ruby my feet before bed since apparently LLM&#x27;s can, and should, be applied to everything.I can&#x27;t wait for the day an LLM can wipe my ass for me. reply gchamonlive 20 hours agorootparentprevYou don&#x27;t need llm for that I think. But sure, if you want people to just leave you. It is a pain but a part of scaling is dealing with a crowd.And I would prefer LLMs to hallucinate a nice constructive criticism than to delete comments by mistake. reply djbusby 19 hours agorootparentI&#x27;m pretty familiar with scale and open source. Entitled jerks can fuck off. They take away from your passion and those helpful & respectful users. I draw a hard line there - not letting haters get in the way of love. reply Tao3300 20 hours agorootparentprevNo. Because then angry people are rewarded for being angry, and that&#x27;s not happy. reply gchamonlive 20 hours agorootparentThey are not angry because they are rewarded for being angry. And an answer is far for being a reward. A negative answer is still an answer. reply high_5 11 hours agoparentprev> I have seen this becoming more and more common on open source projects and totally free services, where people act as if they are entitled to something as if it is their god given right. The people doing public services like uBlock origin can only take so much from the mob.Only donators should be allowed to review the service and complain then. reply thomastjeffery 21 hours agoparentprev> especially when you consider that there are only two people on the uBO teamWhy in the world are there only two? That&#x27;s your problem right there.How many competent devs are right here in the comment section? Why is it so difficult to get their help? reply drivebycomment 20 hours agorootparentuBO readme https:&#x2F;&#x2F;github.com&#x2F;gorhill&#x2F;uBlock&#x2F;blob&#x2F;master&#x2F;README.md makes it clear this is not for profit;> Free. Open-source. For users by users. No donations sought.> If you ever want to contribute something, think about the people working hard to maintain the filter lists you are using, which are available to use by all for free. reply zimpenfish 18 hours agorootparentprev> Why in the world are there only two?You may have missed \"there are only two people on the uBO team dealing with YouTube\" rather than \"on the whole team\". reply thomastjeffery 16 hours agorootparentIndeed I did. reply daeros 14 hours agoprevWhile it has ultimately come up in this discussion my honest input is most of the comments I see here evaded the elephant in the room of all of it which is that Google doesn&#x27;t do a good enough job of vetting the people who advertise with it, its search engines have repeatedly allowed malware to slip through the cracks leading to people being exploited and nothing stops those same malware developers from serving up ads on YouTube with the self same malware and engaging in malvertisement.\"Entitled\" came up a lot, but I would have to disagree. Au contraire, YouTube is the one that feels \"Entitled\" to show me advertisements, even when that feature potentially exposes me to the risk of Malware. reply garciansmith 13 hours agoparentWhile I agree to an extent, to me the larger issue is that Youtube has become the default video hosting platform with no real competition.I adblock everything but I am sympathetic to the idea that video hosting costs money. But I watch, on average, less than 1 hour of Youtube videos a month, so paying for Youtube makes no sense. Plus I have issues with privacy (part of the reason I&#x27;ve never created a Youtube account). The videos I do watch on Youtube are short ones for a specific need: e.g., a company showing me how to install their product in an easy way (I&#x27;d prefer a write up, but sometimes those are so bad you need to rely on a video), or a simple how-to on changing the battery in X model of car. So when I do need to go to Youtube for something, often its because the video is nowhere else. People don&#x27;t even think of hosting it elsewhere. I don&#x27;t watch any long form stuff there, don&#x27;t listen to music there, etc., so paying for premium makes no sense.I wish there was a free and open video platform that had a funding model like Wikipedia, where people could upload things that they had no intention of \"monetizing\". reply ohhnoodont 13 hours agorootparentEspecially when youtube&#x27;s early success was built on piracy. That continued for a long time even after Google&#x27;s acquisition. Arguably still is a major contributor regardless of Content ID. reply garciansmith 13 hours agorootparentYes, true. Gain traction through piracy to get to an immense size, let everyone use the service for free to grow even larger, introduce ads but only easily blockable ones, then slowly tighten the vise. reply cglong 9 hours agorootparentFrom my understanding, this is the exact model Crunchyroll used too to gain a virtual monopoly on anime streaming. reply daveevad 12 hours agorootparentprevBetween Youtube and PirateBay, who do you think has distributed more unauthorized copyrighted works? reply rchaud 35 minutes agorootparentPirate Bay websites disappear all the time due to network uptime or just evading copyright cops. Youtube just sits there however, churning out its trove of pirated content and have the gall to throw ads on it. reply shiroiuma 7 hours agorootparentprevI&#x27;d say Youtube has distributed unauthorized copyrighted works to FAR more people. Most people have never heard of PirateBay or have any idea what a torrent is. reply belltaco 13 hours agorootparentprev> But I watch, on average, less than 1 hour of Youtube videos a month, so paying for Youtube makes no senseWhat&#x27;s your issue with having to watch ads if you watch less than 1 hour of video content a month?> I wish there was a free and open video platform that had a funding model like Wikipedia, where people could upload things that they had no intention of \"monetizing\"There&#x27;s a lot of content on YouTube that people upload that they have no intention of monetizing.> I wish there was a free and open video platform that had a funding model like WikipediaWhy don&#x27;t you or someone else try starting one? reply garciansmith 12 hours agorootparent> What&#x27;s your issue with having to watch ads if you watch less than 1 hour of video content a month?Moral issues, security issues, etc. These have been discussed in pretty much every thread about adblocking ever, really. I get that you might disagree with them, of course, but no need to rehash the here. I don&#x27;t even like company logos displayed on my clothing, so you can guess which side of the \"how much do you hate ads?\" spectrum I&#x27;m on.> There&#x27;s a lot of content on YouTube that people upload that they have no intention of monetizing.So on those you never see ads? Hilariously I don&#x27;t actually know how Youtube works since the only time I&#x27;ve seen ads is when someone who doesn&#x27;t use an adblocker shows me something (i.e., extremely rarely). Firefox + uBlock Origin (and Adblock Plus before that) has been enough to guard me for as long as I can remember.> Why don&#x27;t you or someone else try starting one?Well, I can&#x27;t speak for anyone else but I&#x27;m a middle-aged historian, so starting a video hosting platform is far beyond my expertise. Though in general asking someone \"why don&#x27;t you just go build it yourself\" in response to a complaint about a service, software, or hardware item is a bit trite. reply belltaco 12 hours agorootparent> Moral issues, security issues, etc.How is blocking ads not a moral issue? Video creators also get hurt by ad blockers, not just YT, which does have costs associated with serving you video.> So on those you never see ads?I think they started showing ads on them, just fewer. They do cost storage and bandwidth, so what&#x27;s wrong with that?> Well, I can&#x27;t speak for anyone else but I&#x27;m a middle-aged historian, so starting a video hosting platform is far beyond my expertise. Though in general asking someone \"why don&#x27;t you just go build it yourself\" in response to a complaint about a service, software, or hardware item is a bit tritePopular web sites are typically co-founded by non-tech folks. Anyway, what I meant that if you looked into starting one, you&#x27;d understand the immense scale of storage and bandwidth costs. reply jonathanstrange 7 hours agorootparentThere is a moral issue, you&#x27;re right. Blocking ads is clearly morally permissible. Blocking ads is equivalent to not locking at billboards and skipping ad pages in a magazine (or tearing the pages out). There is no moral issue with any of that. You&#x27;ve bought a PC, you run whatever software you like on it. You have a right to chose how your machine displays content you download from the net. In turn, the maker of a web page can chose to offer whatever they want. If they need more money, then they can transmit the content only if you pay. That&#x27;s perfectly feasible and reasonable. What they cannot and should be able to decide is how your machine displays their content and what kind of other software you use on your machine.I believe that - if at all - only tightly controlled government authorities should be allowed to force display messages on end user machines, and if so, only in severe emergencies and for the protection of civilian lives.People in this debate sometimes argue based on costs and money lost from ad revenue. These are business discussions that have no place in the moral evaluation at all. Not every business model works. So what, find another business model, is the answer. reply erremerre 5 hours agorootparentBlocking ads is not morally permissible. Charging ads by the display is. Any ad should charge the user by ad displayed or attempted to display, not by click or any other way. Just as TV advertisement. If the user goes to make a sandwich, skip it or remove the sound the ad should still be charged to owner of the ad. reply jonathanstrange 5 hours agorootparentDo you have any arguments for this opinion or is it an expression of a personal moral sentiment?My argument why ad blocking is morally permissible is that it&#x27;s a matter of the end users personal freedom if and how they display content from remote servers. They should be allowed to use a hex editor, plaintext, braille, TTS, a browser with or without ad ons, etc., and must be allowed to modify the content for their display purposes as they wish as long as they don&#x27;t redistribute it. That&#x27;s even a central idea of the HTML specification. There are also plenty of analogies to similar freedoms, for example if I buy a magazine (or get it for free) I can tear out ad pages and use them to fire my stove.Redistribution is another matter and concerns copyright, but I just can&#x27;t see any reason why the maker of a web page ought to have a right (or even feel entitled) to control my machine and how the data they voluntarily send to my machine is displayed on it. It&#x27;s not as if anyone forces them to send the data in the first place. reply kahnclusions 8 hours agorootparentprev> Video creators also get hurt by ad blockersI don’t have any kind of business relationship or agreement with content creators. This is their problem and YouTube’s problem.I only deal with YouTube, which sends video streams to my computer for free, and I’m exercising my right to decide what I want to play on my own computer that I own.More and more content creators are getting their income through sponsorships and referrals, anyways, as they feel the squeeze of YouTube’s exploitative and predatory behaviour. reply daeros 10 hours agorootparentprevYes but, how are the content creators my problem, especially when Google isn&#x27;t vetting their ads well enough to keep scam and malvertising people off their and networks. I could raise you to counter that the morally right thing to do is block those ads, at least until Google starts vetting its advertisers well enough to keep scammers out. How do content creators feel, profiting from the scamvertising going on on google&#x27;s platforms? reply guappa 8 hours agorootparentContent creators do a lot of scamming from their part as well.They advertise nordvpn claiming that without using it, all of your traffic is unencrypted for example. reply vehementi 12 hours agorootparentprevAs they said, you aren&#x27;t breaking new ground by asking these questions. Maybe bring yourself up to the state of the art of this debate etc. and contribute to that discussion wherever it is reply kahnclusions 9 hours agorootparentprev> What&#x27;s your issue with having to watch ads if you watch less than 1 hour of video content a month?Why should I be forced to watch something I don’t want to watch? Google sends my computer a stream of “[ad][ad][content]”. It’s my own damn choice which parts of that to watch. reply screamingninja 12 hours agorootparentprev> Why don&#x27;t you or someone else try starting one?https:&#x2F;&#x2F;joinpeertube.org&#x2F;There are several instances, but that is not the solution to what the parent comment is pointing out. Videos are being published on YouTube because of network effect; it has become the defacto platform. reply tjpnz 13 hours agoparentprevI ditched Chrome after a Google ad hijacked the browser and attempted download malware onto my device. If you value your own security you absolutely should be using a browser with support for ad blocking extensions. At the same time Google must be held criminally liable for the massive amounts of fraud their ad business facilitates. reply gruez 13 hours agorootparent[deleted] reply tjpnz 13 hours agorootparentChrome for Android doesn&#x27;t support ad blockers. The ad was served through Double Click on a non-Google property. reply radicalriddler 13 hours agoparentprevYup, this is exactly why I installed ublock origin on my grandparents computers. Malware and scams are too prevalent across the web, and unfortunately, google SERP and Youtube aren&#x27;t immune. reply BLKNSLVR 14 hours agoparentprevAbsolutely the case for me too.Google ad for a scam site made to look like a legitimate Australian Bank: https:&#x2F;&#x2F;www.abc.net.au&#x2F;news&#x2F;2022-06-21&#x2F;scammers-using-text-m...Youtube&#x27;s home page seems to always have, at the top, some kind of get-rich-quick video advertisement when I (rarely these days) visit it. Far from trying to improve on this, it feels as if Google&#x2F;YT are actively trying to normalise scam advertising. I just cannot support that, at all, ever.If Google has no mechanism to prevent their platform from being used by scammers, I feel it&#x27;s my responsibility that their platform doesn&#x27;t reach my screen, lest I, or my family members fall for a scam - which can be psychologically damaging beyond the potential financial damage.I&#x27;ve mentioned before that this isn&#x27;t a problem Google are inspired to solve, since their current advertising scheme successfully scales to the size of the Web. However, appropriately policing advertising to ensure scams don&#x27;t get through would seriously affect the ability to scale. And it&#x27;s the scaling that makes the billions.Regulate Internet advertising the same way television advertising is regulated.Colour me unsympathetic at my most forgiving. reply PH95VuimJjqBqy 14 hours agoparentprevEven if the advertising were perfect in every way I&#x27;d run ad-block.you don&#x27;t get free access to my time, there will never be a point where I&#x27;m willing to spend time watching an advertisement or sifting through advertisements looking for real content.I haven&#x27;t watched television regularly since the mid-90&#x27;s specifically due to the commercials, I&#x27;ll be damned if I&#x27;m going to do it online.And I don&#x27;t give a shit if you think I&#x27;m entitled or not, it&#x27;s my time not yours. reply CSMastermind 14 hours agoparentprev> YouTube is the one that feels \"Entitled\" to show me advertisementsThey show you advertisements in exchange for the free content they provide.You can just as easily not visit the website if you don&#x27;t feel like the service they provide is worth the risk of being shown the ads they serve. reply leventonportera 13 hours agorootparentThis is false logic. Youtube is free to not show anyone anything - once they send me data and it leaves their system, they have no claim to it.When I shout on a public street \"sing me the Francoise Hardy version of I&#x27;ll Be Seeing You,\" no one has to reply. If they do reply, but they decide to sing a 2 minute ad for a pyramid scheme first, I am free to cover my ears till the song comes on.Google&#x27;s servers have a public internet IP. I can \"shout\" a request to them. The data they send back to me, is mine to do with as I please. I am free on My computer, from the memory buffer on a RAM stick I own, to ignore some of the bytes, in My RAM change some of the bytes, or save some of the bytes to a file on my HDD. They are free to ignore any request I shout at them, but they have zero say in what I do on equipment they do not own. reply gretch 13 hours agorootparent> Youtube is free to not show anyone anything - once they send me data and it leaves their system, they have no claim to it.Okay well they&#x27;re about to not show you the videos. You support their latest announcement right? It is completely in line with the the philosophy you just put forward. reply leventonportera 13 hours agorootparentIf you read the entire comment before replying to the comment, you would have your answer before you asked the question.\"They are free to ignore any request I shout at them\"I don&#x27;t have any opinion on, nor care about their latest announcement to do with their hardware as they please. Their announcements are theirs and of no concern of mine. It&#x27;s just a random website the has content duplicates available at a hundred more places. Bing video search has fifty times more results than youtube for example for any item I search.Given that, of course, they&#x27;re always going to show me their videos, because about a day after whatever change they make, software (that runs on my computer against my data) will catch up. They&#x27;ve made changes like this many times over many years. For about a week awhile ago the ads were not blocked and I stopped clicking youtube videos and just typed the title into bing and in 5 seconds played the same video from another source. Worked 100% of the time.Sorry if that&#x27;s not the gotcha you were going for. reply shiroiuma 6 hours agorootparent>because about a day after whatever change they make, software (that runs on my computer against my data) will catch up.Exactly: it just takes one bored or determined hacker to investigate their changes and update the ad-blocking software, and suddenly everyone is able to see the videos and block the ads again. The ad-blockers don&#x27;t seem to have trouble keeping people around to do this work. reply matheusmoreira 9 hours agorootparentprevNot really. They&#x27;re still showing people videos for free. Only difference is they&#x27;re detecting the ad blocker and discriminating. That&#x27;s a bug, they&#x27;re not supposed to know about the blocker. reply raincole 10 hours agorootparentprev> they are free to ignore any request I shout at themExactly. That&#x27;s why they&#x27;re blocking ad-blocker users now. You&#x27;re describing the exact thing they are doing and going to do more. Guess you&#x27;re actually supporting Youtuber&#x27;s policy. reply matheusmoreira 9 hours agorootparentWe&#x27;ll just block their blocker instead. reply shepherdjerred 13 hours agorootparentprevAt a certain scale, you can no longer say \"it&#x27;s just business\".YouTube is where people go to post and upload videos. YouTube has a dominant place in the market and in people&#x27;s minds.Does it cost money to run? Yes. Does Google deserve to have those costs covered? Yes. Should Google be entitled to abuse their dominant position? Certainly not.I do feel bad for who high-quality creators are not able to make ends meet, but I have zero sympathy for a business the size of Google. reply lelanthran 10 hours agorootparent> At a certain scale, you can no longer say \"it&#x27;s just business\".Of course you can. Me blocking ads is just business. It&#x27;s nothing personal.Them blocking my blocking is also just business. Me blocking their blocking is likewise just business.Either they&#x27;ll give up or I&#x27;ll give up. Whichever happens, that content will make less money.IOW, the money that content is making right now is exactly what the market will bear.If too many people stop watching because they can&#x27;t block the ads then content producers have to decide to migrate, to stay and make exactly what their product is worth, or to simply stop producing.It&#x27;s purely business for all parties involved, including the product i.e. viewers. reply PaulDavisThe1st 11 hours agorootparentprev> Does it cost money to run? Yes. Does Google deserve to have those costs covered? YesThose are not the terms of the implicit (and somewhat explicit) deal Google&#x2F;YT originally offered.Any and every net pundit and idiot pointed out at the start that any video hosting system that became as successful as YT said it wanted to be (and has become) would cost a fortune to provide.YT could have said from the start \"once this scales beyondwe&#x27;ll need to chargebecause the only alternative to that are ads\". But they never said that, they just gave us ads even if we didn&#x27;t want them. reply matheusmoreira 9 hours agorootparentprevI can just as easily block their ads unconditionally. If they want something in exchange, they better require payment. reply daeros 13 hours agorootparentprevColor me too unsympathetic, Frankly I&#x27;ve been stream ripping them with yt-dlp for quite a while now. I&#x27;m motivated to do more of that now.It&#x27;s one thing if Google were demanding I watch their ads to get the free video in exchange, but it is not an honest broker, because it doesn&#x27;t vet the people it allows to advertise with it thoroughly enough to prevent scams and everything else from slipping through.And frankly i&#x27;m taking a moral stand as well by blocking their ads, I refuse to allow Google to profit off of scammers in my or my families name.ackphtttt with those typos. btw. fixed. reply 389 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "YouTube has been intensifying its attempts to counteract adblockers, initiating a tug-of-war between itself and adblocker developers, including targeting other privacy extensions and tracking protection settings.",
      "Reddit users face difficulties in seeking useful information, with some resorting to sharing detrimental filters that may result in their adblockers being completely blocked.",
      "The pressure on the adblocker developers has caused team member attrition and account deletion, hinting at a potential future where the adblockers might acquiesce."
    ],
    "commentSummary": [
      "Topics on Hacker News focus on YouTube's implementation of anti-adblock measures and the ensuing debates on the ethical considerations of ad-blocking.",
      "Some users express dissatisfaction with YouTube's ad-free subscription service, the challenges faced by free software developers, and discuss the varying attitudes towards open-source software and free online services.",
      "Concerns are raised about privacy violations, the influence of ad-blocking on YouTube, issues related to open-source project maintenance, effects on content creators, and the efficacy of ad vetting."
    ],
    "points": 683,
    "commentCount": 671,
    "retryCount": 0,
    "time": 1698603659
  },
  {
    "id": 38069710,
    "title": "I accidentally saved my company half a million dollars",
    "originLink": "https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/",
    "originBody": "Ludicity I Accidentally Saved Half A Million Dollars Published on October 29, 2023 I saved my company half a million dollars in about five minutes. This is more money than I've made for my employers over the course of my entire career because this industry is a sham. I clicked about five buttons. Let's talk about why happened and why it's a disgrace that it was even possible. I. Background Let's start with some background, because it is fucking wild that an inefficiency that took me five minutes to solve in a GUI configuration panel was allowed to persist. We cancelled someone's contract the week before I did this. Someone lost their job because no one could get their act together long enough to click the button I told them to click. A few years ago, this company decided that it wanted to create an analytics platform, following the decision to become more \"data driven\". They hired some incredibly talented people to make this happen, and then like five times as many idiots. At the time this was happening, I had just graduated and joined the organization as a data scientist. We, of course, did not do any data science, because the organization did not require any data science to be done - what they actually needed to do was fire most of the staff in every team, leaving behind the two people who actually had good domain knowledge, then allow them to collaborate with good engineering teams to build sensible processes and systems. Instead, they hired a bunch of Big Firm Consultants. You can see where this is going already. Nonetheless, at the time I was young and took the organization at its word. Executives would tell us constantly how excited they were for us to roll out new A.I initiatives (then tell us there was no time, so could we please get that report to them in a spreadsheet), and I'd ask for some sort of compute to perform some machine learning, or even set up data pipelines. It never worked. Instead, we were told that we just had to wait for the Advanced Analytics Platform (AAP) to be deployed. You see, it's December, and it's launching in January. Then in January I was told to be patient, it was coming in March. In June, I was told it had been put on hold due to Covid - this was a very convenient excuse because they had absolutely fucked the whole project up already, but it bought some valuable time. By the next December, I had left the organization and the AAP was still nowhere to be seen. We skip ahead three years. The AAP is finally ready to launch. It turns out none of the features I needed were ever planned, so I guess they were just lying to me before I left. Four engineers leave the company in the same week, and I speak with the directors because I know they need a real engineer in and they can't find them. I'm a substantially less experienced engineer than many of the readers here, but suffice it to say that I can read documentation without panicking, which is considered S-tier in this country. My conditions - a big pile of money and they had to put me on the AAP team because they're the only team that gets actual toys to play with. II. It Fucking Sucks It's an insane dumpster fire spiderweb of technical debt and it's only like one week old. Here are some fun details. I get a friend of mine hired (big fan of nepotism), and he finds, on day one, a file in the project's repository that deletes prod using our CI/CD pipelines if it is ever moved into the wrong folder. It comes complete with the key and password required for an admin account. It was produced by the former lead engineer, who has moved on to a new role before his sins catch up with him. The entire thing is stitched together by spreadsheets that are parsed by Python, dropped into S3, parsed by Lambdas into more S3, the S3 files are picked up by MongoDB, then MongoDB records are passed by another Lambda into S3, the S3 files are pulled into Snowflake via Snowpipe, the new Snowflake data is pivoted by a Javascript stored procedure into a relational format... and that's how you edit someone's database access. That whole process is to upload like a 2KB CSV to a database that has people's database roles in it. This is considered more auditable. Everything is transformed into a CSV because the security team demanded something that could undergo easy scanning for malicious content, then they never deployed the scanning tool, so we have all the downsides of the CSVs and none of the upsides. Every Lambda function, the backbone of all the ETL pipelines, starts with counter = 1 because one of the early iterations used to use a counter and people have just been copying that line over and over. Senior data engineers have been copying that line over and over. The test suites in the CI/CD pipelines have been failing for months, because someone during debugging chose to use the Linux tee command to log any errors to both stdout and a file at the same time, but tee successfully executing was overwriting the error code from the failing tests. To get access to the password for any API we need to hit, you search for something like service-password in an AWS service, which returns the value... service-password (as in, literally all the values are the same as the keys), then you use that to look up the actual password in a completely different service. No one knows why we do this. The script that generates configuration files for our pipelines starts with 600 lines of comments, because senior engineers have been commenting the lines out in case they're needed later. The lines are just setting the same variables to different values, and they're all on GitHub anyway. This is at an organization that some percentage of readers will recognize on sheer brand strength if they're in my country. I'm not even getting started, but we have to stop for now because I am going to catch fire. These details are important because now you understand the kind of operational incompetence that allows you to waste so much money on processing <1TB of data per day that it dwarfs your team's salary. III. The Budget The next thing to realize is that this platform never really had a chance of making any money for the organization. They do a little accounting trick (read: lying) which I'll talk about in another post that makes it seem like they've had huge wins, but really this is just many times more expensive than our previous operational model. The deal is that we pretend the whole team is doing something or other, and we stay within budget because the organization can't afford to spend infinite money on this social fiction. However, the budget for our database costs was being drastically overrun. I'm not sure what the original estimate was, but I think it was intended to cost something like 200K for a year of operations, but we were now close to a million dollars. Some quick facts: We use Snowflake as our database, which charges you based on the size of the computer you use to run your queries. You only pay for computers while they're on. We probably run a few thousand queries per week, mostly developers experimenting with little tweaks for PowerBI reports that no one reads, and on average they take about 2 seconds to run. The computers are set to idle for 10 minutes after every query. I noticed this about a month into joining the team, and suggested we uh... don't have the computers run for like two orders of magnitude longer than they need to for every query. I literally can't remember what was said, there was some Agile bullshit about doing a discovery piece, then it just never happened. IV. Just Doing The Fucking Thing Anyway, months later, they finally give me a card that says \"Discovery: Optimise Costs\". Now I have to optimize costs so that I have something to say at the next standup, and fortunately I know just the thing! I'll test my hypothesis that this is all a sick joke, and I'm going to push the button that I secretly think should obviously have been pushed. We've got a new guy on another team who seems excellent, so I ask management if I can give him admin credentials since we need competent people. They say no. I flick him some lower-level database credentials that I technically wasn't told not to do since they aren't admin credentials, and he sanity-checks that it would save money. At 4PM on the last day of the week, I ping a chat full of good engineers and no managers to make sure I'm not about to nuke everything, then just do it. V. Chaos Reigns I return to work the following Monday. I suspected that this would save a bunch of money, and guess what, our projected bill dropped from a million to half a million dollars, and everyone is losing their fucking minds. My team has spun this as a huge cost saving, when really we just applied a fire extinguisher to the pile of money that we had set alight. Other teams are attacking my team, insisting that it can't be a coincidence that the one new guy joined exactly as we did this, and how was it possible we didn't know how to generate that kind of saving without his help? They are saying this because it makes them seem higher status and their teams only produce money in the land where you lie all day, but it is a fair question. While my managers are very happy, they quietly suggest it may be unwise to roll out the changes to all the computers (I only did a few to be safe) because it would oversaturate the department to hear about us all day. And invite unwelcome questions. The subtext is that if we do this all slowly enough, it might seem like it took a lot of effort instead of just clicking buttons that I said had to be clicked almost a year ago. I am asked to write some PowerPoints, which include phrases like \"a careful statistical analysis of user usage patterns indicated an opportunity to more effectively allocate resources\", implying that nothing was wrong, we just needed to collect more data before deciding not to let the expensive machines idle all day. Every day, I dread someone asking me to explain what the change was, because I will have to fucking yeet some managers I like under a bus, but they can't resist talking about the change non-stop because it is the closest some of them will ever get to impacting the bottom line. And many of them are actually decent managers, it's just that this whole department, like many departments, is some sort of weird political PsyOp to get executives promoted. It's cosplaying as a real business and the board thinks the costume is convincing. VI. The Aftermaths and Takeaways By identifying a handful of good engineers and going totally rogue, we outperformed the entire department pretty effortlessly. The competent people are there, just made totally impotent by the organization, and I'm still convinced that this place is probably better than the median organization. I ask management for a 30K raise after saving 500K and my message is still unread. I suspect I will eventually receive either nothing or 5K. I have even more meetings now because everyone wants to talk about how we saved the money. I had to make a PowerPoint. Kill me. I would have been better off not doing anything. Let that be a lesson to you. Do you hear me? I applied myself for five minutes against my own better judgement, had the greatest success of my career, and have immediately been punished for it. Learn from my mistakes, I beg of you. Subscribe via RSS / via Email. Powered by mataroa.blog.",
    "commentLink": "https://news.ycombinator.com/item?id=38069710",
    "commentBody": "I accidentally saved my company half a million dollarsHacker NewspastloginI accidentally saved my company half a million dollars (mataroa.blog) 320 points by softskunk 2 hours ago| hidepastfavorite149 comments neilv 1 hour ago> The entire thing is stitched together by spreadsheets that are parsed by Python, dropped into S3, parsed by Lambdas into more S3, the S3 files are picked up by MongoDB, then MongoDB records are passed by another Lambda into S3, the S3 files are pulled into Snowflake via Snowpipe, the new Snowflake data is pivoted by a Javascript stored procedure into a relational format... and that&#x27;s how you edit someone&#x27;s database access. That whole process is to upload like a 2KB CSV to a database that has people&#x27;s database roles in it.Sometimes it&#x27;s hard to distinguish resume-driven development from iterative-StackOverflow-driven development. reply baz00 29 minutes agoparentEverything I look at these days looks like this. And most of the time it doesn&#x27;t even solve the initial problem statement but everyone is too naive to even realise that.The worst thing I&#x27;ve seen is a stack that parses out a file and loads it into a DB. So someone sends us a file via an expensive SFTP+S3 thing in AWS. That is then picked up by some scheduled task using a proprietary in house scheduler process running inside kubernetes. This proceeds to download the file to the local pod. Then it makes tens of thousands of API calls to match up data which cranks the CPU up on a huge database server. This breaks all the other jobs running. Then it writes another file out to S3, consuming 17GB of RAM in the process. Another process picks that up and then batches it and inserts it into the DB with no transactional stuff around it.The original process this replaced was a copy into a temporary table and then a bit of transaction-wrapped SQL that took about 20 seconds to import + run. They improved that to 7 hours and reduced the success rate from 100% to about 80% reply foobiekr 3 minutes agorootparentI know of an engineer who built a work queue by having a chain from an app to kafka to a processor to Kafka to a database writer.Literally instead of a table.This stuff is everywhere. Microservices made it worse and half legitimized it. reply latexr 2 minutes agoparentprevThat reads like the KRAZAM Microservices sketch.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=y8OnoxKotPQ reply foobiekr 4 minutes agoparentprevI see stuff like this every day. It is a natural consequence of people who only “develop” by gluing things together. God help them if they’d actually have to write some core function themselves. reply oooyay 21 minutes agoparentprevYou can actually make a very comfortable career of Senior and Staff by learning to identify this kind of work&#x2F;system and proposing ways to simplify it. These kinds of systems, as the author pointed out, are incredibly expensive and inefficient, but look readable on an architecture diagram. reply lainga 18 minutes agorootparent> You can actually make a very comfortable career of Senior and Staff by learning to identify this kind of work&#x2F;system and proposing ways to simplify it.Where? reply tomrod 6 minutes agorootparentIT departments, typically, though occasionally there are whole companies that work in \"technology\" where this type of work can be found.I said the above as a jest, but seriously, simplification of complex stacks has been a good consulting gig. reply topaz0 38 minutes agoparentprevOf course the answers on stack overflow are partly a result of resume-driven answerers. reply syntaxing 46 minutes agoparentprevI’m genuinely curious what a unit test for something would look like. reply yonixw 44 minutes agorootparent&#x2F;&#x2F; TODO reply FartyMcFarter 34 minutes agorootparentprevThat would be an integration test, not a unit test. reply jacquesm 43 minutes agorootparentprevChecksum on the resulting csv with a parallel implementation of the whole pipeline ;) reply syntaxing 38 minutes agorootparentI don’t work with large databases so pardon my ignorance. Is there typically a “unit test” bucket you run it on or do you just put in test entries on a production bucket? reply jacquesm 33 minutes agorootparentNormally you&#x27;d fire up a separate environment, mock the process and see if it produces the expected results. By the time you put &#x27;test entries in a production bucket&#x27; there are so many lines crossed that it likely won&#x27;t end well even if the tests do pass. reply hightrix 35 minutes agorootparentprevWe tend to only test what is being tested. So, most DB calls are mocked in our unit tests. For stored procs or other tests that need to be run on a DB, we use a test DB that is setup to mirror production.I&#x27;d bet there are a 100 different answers to your question though. This is the way we handle it. reply tommek4077 38 minutes agorootparentprevThat is probably quite straight forward and of course they have 100% coverage. reply jack_riminton 1 hour agoprev\"this whole department, like many departments, is some sort of weird political PsyOp to get executives promoted. It&#x27;s cosplaying as a real business and the board thinks the costume is convincing.\"Came for the engineering, stayed for the blisteringly on-point observations of corporate life reply andrewstuart2 56 minutes agoparentAt my previous $JOB I started calling this Promotion-Driven Development because it&#x27;s everywhere. Take the easy problems that look good and you can finish quickly, get promoted, hand off the facade to team that has to actually solve the real problem, and repeat. reply shalmanese 39 minutes agorootparentThe purpose of a system is what it does. All development is promotion driven development, different people can either choose to be clear eyed about this or not and, subsequently, good at it or not.Your job is the venn diagram intersection of an organized system of rewards and punishments from both inside and outside of the firm intersected with your own goals and aspirations over time. Anything not in this intersection is not a job, it&#x27;s something else we like to delude ourselves into thinking is a job to preserve our egos.More specifically, your worry about how distorted incentives lead to poor quality software is not your job unless it is your job to worry about said incentives. People keep hoping to go work for one of the magically sane company where all the incentives are correct and everyone is doing the quote-unquote \"right\" thing at all times. Such a company does not exist because the very concept is incoherent, every system of possible incentives will come with a different set of tradeoffs and the art of operating a firm is to pick from amongst a bunch of shitty options for the least shitty one.People who do not accept this will be perpetually unhappy and bitter about how others obtain undeserved success because they simply did the unsporting thing of playing the game they were asked to play. You can either be one of those people or you can receive the radical acceptance of what a job is. reply OkayPhysicist 16 minutes agorootparentNot all jobs are promotion driven, at all. My current dev job is for a small family biotech business, and the only path upwards from where I currently am would involve church bells and a flower girl. reply shalmanese 5 minutes agorootparentBut there are still things you need to avoid that would get you fired if your performance dropped and there are still things you can do that would improve or decrease your job prospects on the open market if the company ever goes under or is forced to let you go. I&#x27;m using \"promotion\" in a more abstract sense than literal promotions. reply em-bee 20 minutes agorootparentprevPeople who do not accept this will be perpetually unhappyor they go start their own business to get away from this nonsense.when i deal with clients i actually have to deliver something because i am not getting any promotions. reply shalmanese 8 minutes agorootparentClient work is its own unique hell of misaligned incentives. You&#x27;ve just replaced one boss with a dozen bosses, all of which have the power to \"promote\" or fire you.I&#x27;m not saying that any one individual can&#x27;t find a job that is the unique perfect blend of incentives for them, indeed, the entire point of this framework is that alignment between your goals and the incentives of your job is the most powerful lever an employee can pull. But that incentive structure will necessarily make others working there deeply unhappy as its unique choice of tradeoffs is just shitty in a way invisible to you. reply Spivak 23 minutes agorootparentprevI like to think I&#x27;m pretty good at this game, swung two promotions and raises by working every request from outside the team out of band to the detriment of my main flow of work -- \"everyone loves you and your work is constantly noticed by $upper_management.\" Wow that&#x27;s crazy, it&#x27;s just nice to be appreciated I guess wink wink. reply syntaxing 45 minutes agorootparentprevI think the crappy part is that it works most of the time. reply dmitrygr 45 minutes agorootparentprevThis is very much how Google is on the inside. And that’s not surprising. People respond to the incentives presented. If you spend years fixing hard problems that actually affect users, and don’t get promoted, you’ll almost certainly become jaded, and start doing things that are pointless but do get you promoted. Because that’s how you make more money. And that’s the actual reason to be working. reply andrewstuart2 29 minutes agorootparentAnd yeah, it shows via ye olde Google graveyard. Honestly I do think it&#x27;s just a hard problem not to have, because the world tends to work on visibility combined with innovation. You can&#x27;t solve hard problems and make money if nobody uses your solution because they don&#x27;t know it exists. But I struggle with the balance because yeah, I&#x27;m a bit jaded. reply npsomaratna 28 minutes agoparentprevAlmost sounds like a piece from the BOFH reply vwoolf 1 hour agoprevThis reminds me of some of Dan Luu&#x27;s stories, https:&#x2F;&#x2F;danluu.com&#x2F;nothing-works&#x2F;Likewise with chip software tooling; despite it being standard to outsource tooling to large EDA vendors, we got a lot of mileage out using our own custom tools, generally created or maintained by one person, e.g., while I was there, most simulator cycles were run on a custom simulator that was maintained by one person, which saved millions a year in simulator costs (standard pricing for a simulator at the time was a few thousand dollars per license per year and we had a farm of about a thousand simulation machines). You might think that, if a single person can create or maintain a tool that&#x27;s worth millions of dollars a year to the company, our competitors would do the same thing, just like you might think that if you can ship faster and at a lower cost by hiring a person who knows how to crack a wafer open, our competitors would do that, but they mostly didn&#x27;t. reply tehlike 1 hour agoprevThe whole post is gold.- managers asked how it was possible we saved that much without help from them- asked to prepare slides- asked many times on how it happened- had to roll it out slowly to make it look like they did it over time incrementally vs one small toggle- asked for a raise due to impact and did not happen.Sir, for your sake, apply to a FAANG or something, you&#x27;ll be at least taken care of better.Also please implement Twitter card metadata in your blog so it looks better on twitter :) reply Justsignedup 44 minutes agoparentLol, if I wasn&#x27;t given a raise, I&#x27;d agree to everything, and at the start of my presentation say\"hi everyone, I wanted to walk you how we got to a half-a-million dollar savings, basically I spent a day looking at how terrible the original infrastructure was deployed and removed a code test feature that was causing the problems. This was just complete oversight from every aspect of the development, management, testing, and everything. Overall this code is as bad as it can possibly get, and we just launched it. And basically I was told not to say any of this because it makes everyone look bad, so I was to roll this out gradually to make it seem like managers were doing some sort of work.\"Then drop the mic and walk off stage.Honestly the amount of give-a-fucks I would have lost would have been a lot. And this is coming from someone who&#x27;s done this for almost 2 decades and cares about his job because bills to pay, kids to feed. reply whartung 34 minutes agorootparentBack in the day I worked at a company that if you came up with some long term cost saving measure, they gave you a bonus of 10% net savings for the first year. reply dugmartin 11 minutes agorootparentA co-worker in the early 90s (he was a tech writer) told me of a cost savings device he invented in the 80s at Texas Instruments to fix a process where occasionally a mirror on a very expensive piece of military camera gear got scratched (I think it was during field disassembly). It was basically some forceps with more metal welded on to make them longer and that allowed you access via a different route than where the mirror was installed. TI gave cost savings awards as a percentage of money saved and he did very, very well with that little invention. reply quest88 32 minutes agorootparentprevWhile this feels good to imagine, the social fallout would be disastrous. reply mcv 8 minutes agorootparentWould it? I mean, the people you&#x27;re throwing under the bus would hate you, but the top of the company should love because a) you saved them a ton of money, and b) you identified a pile of incompetence in their company.And who&#x27;s going to fire you for this?The people telling you to roll this out slowly are doing so mostly to protect themselves from having their incompetence exposed and to appear useful. Protecting them will help them steal your credit and will get them promoted. reply yjftsjthsd-h 25 minutes agorootparentprevIt really depends on your priorities and operating environment, but there are many people who would be leaving anyways if they save the company that much money and were given exactly zero reward, and at that point plenty of people would be happy to burn bridges on the way out. Like I said, it really depends on the environment and your priories. reply quest88 1 minute agorootparentThe thing about burning bridges is you don&#x27;t know when you&#x27;ll need them.Let&#x27;s say 5 or 10 years later you&#x27;re applying to a job where one of these upper-level people now work. How do you want them to remember you? The know-it-all who wasn&#x27;t a team player and kind of an asshole? Or the engineer who gets things done and has demonstrably shown to land impact and value, an engineer the exec would consider lucky to have?Some of you will say you wouldn&#x27;t want to work for one of these executives again. But people change, incentives change, the environment changes.And maybe you don&#x27;t work for them. Maybe you&#x27;re applying to a different company where someone knows these previous upper-level management folks and they ask about you. How do you want that recommendation to come across? \"That engineer was an asshole.\", \"That engineer was amazing, I wish we could have kept them. We made a big mistake by not trying to keep them.\". tehlike 19 minutes agorootparentprevTech is a small circle. Unless it&#x27;s something obviously wrong, you may want to be at least milder :) reply herpdyderp 1 hour agoparentprevMaybe my friends are all just bad devs but I don&#x27;t hear of people getting treated well at FAANG anymore. (Though I haven&#x27;t heard anything about Netlifx recently.) reply tehlike 1 hour agorootparentMaybe they are busy working - after while layoffs everyone is working a bit more to say the truth reply y-c-o-m-b 6 minutes agorootparentI&#x27;m at a FAANG, still getting treated like shit. The problems outlined in the article are 1000x worse in a FAANG and you&#x27;ll have the same 99% of the people that have drank the proverbial kool-aid telling you everything is great and it&#x27;s supposed to function like this. At least you get paid more for it though. reply tehlike 0 minutes agorootparentTrue, and not true. It&#x27;s nuanced. It depends a lot on the org.I have moved from admob (google ads) to robotics to facebook, and worked with different orgs, and have seen differences. mparnisari 2 minutes agoparentprev> Sir, for your sake, apply to a FAANG or somethingNoooooooooo reply munk-a 52 minutes agoparentprevSkip FAANG and go straight to a company that&#x27;ll value you! reply nfRfqX5n 54 minutes agoparentprevAt least at fang you can write a mostly plaintext document instead of PowerPoint. Downside is you would probably have to do it before making the changes, have it reviewed by the entire team and get “alignment” reply tehlike 52 minutes agorootparentYes and no, changes based on the orgBut you would get handsomely paid. reply pavlov 1 hour agoparentprev> “please implement Twitter card metadata in your blog so it looks better on twitter”Didn’t Xitter recently remove the display of all external site metadata except the image? reply tehlike 1 hour agorootparentYeah people use image interestingly these days thoughSee, for example: https:&#x2F;&#x2F;twitter.com&#x2F;simonw&#x2F;status&#x2F;1717768637799706922 reply CrimsonChapulin 1 hour agoparentprevIm surprised no one asked to automate an email to management of the status for the rollout of changes.“We’ll need the percentage complete as well and a summary of the savings expected. It needs to be sent out every Friday at noon.” reply CobaltFire 1 hour agoprevI feel this entire post.My career record (US Navy) for cost savings was something over $50MM. Every time I did something I had to do PowerPoints, present to Flag Officers, etc. Hell, once I almost got hugely punished because I didn&#x27;t let my boss take the credit (he had no desire to because he had zero idea what it was I even did).Note that some of that was as a Lean Six-Sigma Black Belt doing Enterprise projects (I hate every single bit of terminology in that entire godforsaken sentence), where it was literally my JOB to save the DOD as much money as possible with the least disruption possible. Those were the absolute worst years of my career. That period of my career was my reward for just going rogue and fixing things that saved millions.I&#x27;ll echo the last part of that post: Beware of doing good things at work; the reward is rarely compensation and is usually more work for the same pay. reply tehlike 54 minutes agoparentSometimes I think of joining government org (3 letter agency) to find areas to improve $ efficiency on, or make decent direct contribution to US as a thank you for accepting me as an immigrant.I&#x27;m an engineer in a FAANG, who worked directly in money flow, and have had experience in diverse areas where it could come handy.Then I start thinking finding the right person to work with & right area to start at is probably 95% of the job, then give up. reply wslack 14 minutes agorootparentAs someone who does this sort of work (but posting personally, not officially), you&#x27;re 100% right. There are groups of already-networked folks you can join like USDS or 18F that are already connected to the problems. The post reminds me of some of the stuff you might see in gov, though I&#x27;ve never seen someone save money and be punished like this. reply busterarm 54 minutes agoparentprev> Six-Sigma Black BeltI&#x27;m so triggered by this phrase. The worst (to work for and performing) company I was at hired SSBBs like crazy and none of them really did anything or made a damn bit of difference, but if you took the courses you were fast-tracked for success as far as promotions went. reply CobaltFire 49 minutes agorootparentI was not at all popular among my \"peers\" in that world. I had too much common sense, and didn&#x27;t make changes just to make changes. I was extremely effective, but since I didn&#x27;t play by the rules I was ostracized internally.That said, it did give me the opportunity to get the hell out of that community and back into IT&#x2F;CyberSec.In all honesty, there are absolutely good concepts and tools in that world. The issue is that the people who gravitate to that world have no ability to provide any value themselves so don&#x27;t actually understand how to USE those tools properly.Everything is a nail when all you have is an ENTIRE TOOLBOX. reply syntaxing 41 minutes agorootparentprevIt’s interesting because I found Mech design engineers with green belts to usually be really sharp. I only met like one black belt design engineer and he pivoted careers a decade ago. But most black belts I met in QA were managers. Most of the technicians that did the work weren’t certified but lived and breathed the products for decades. reply CobaltFire 38 minutes agorootparentMy experience was that the tools are absolutely useful. Green Belts are those who learned the tools, but stayed at their day job. Black Belts are when you pivot into doing it full time.Much like people who underperform in technical fields often pivot to Management, you see the same in the pivot to Process Improvement. That creates the issue of the lowest performers at the actual job being the ones most inclined to pivot into that position.There are always good ones (I&#x27;m biased, but think I was). The issue is that they are a relative rarity due to those (and I&#x27;m sure other) factors. reply syntaxing 34 minutes agorootparentThe pivot part rings so true, especially “Engineering Services”, aka process and infrastructure control. They often lead the engineering change committee too. I shudder just recalling those meetings. reply busterarm 39 minutes agorootparentprevIn that industry it makes sense. We were a services platform -- basically a massive, distributed call center. reply unicornmama 52 minutes agoparentprev> I&#x27;ll echo the last part of that post: Beware of doing good things at work; the reward is rarely compensation and is usually more work for the same pay.Let’s rephrase this in a less nihilistic way: Understand your organization’s values and culture. And beware of doing good (or bad) things in a way that goes against your organization’s values and culture. reply CobaltFire 47 minutes agorootparentSpeaking as someone who spent over 20 years in the DOD:There isn&#x27;t a way to make things better in the DOD that doesn&#x27;t go against the culture. Period. My literal JOB was to make things better and it was the worst time of my career. That was with Flag Officer backing and independent authority. I got a chest full of shiny candy and a pathological distaste for it all after a few years of that. reply esafak 38 minutes agorootparentBigger organizations tend to be more pathological; they attract and shelter sociopaths. So try to find a smaller one that is compatible with your values. reply CobaltFire 35 minutes agorootparentInstead of finding a new org I retired and am doing my own thing.Figuring out what said own thing is is proving a bigger challenge than anticipated, but I&#x27;m enjoying it. replymcv 1 hour agoprevYou didn&#x27;t accidentally save half a million, you deliberately and intentionally saved them half a million, but now you regret it. That&#x27;s not the same thing.Large organisations are so woefully inefficient that I&#x27;m surprised they&#x27;re able to compete at all, but they have a ton of money and economy of scale and all that, and along the way there&#x27;s more than enough money to waste millions on stupid nonsense and inefficiency and nobody really cares. reply Vinnl 6 minutes agoparentIt would be helpful if you&#x27;d point out what term is appropriate. Given the reference to \"my country\", odds are that they&#x27;re not a native speaker. (I can&#x27;t tell from the English though, but I&#x27;m not a native speaker myself.) reply photonbucket 11 minutes agoparentprevIn my mind, there is where inflation really comes from. For every wage paid that wasn&#x27;t useful, the resulting product becomes more expensive &#x2F; less profitable. If we were able to optimize out all the waste we&#x27;d probably have deflation while computers and business processes keep getting more efficient reply j0hnyl 2 hours agoprevOnce upon a time I uncovered a bug that recovered $4MM&#x2F;year in revenue. It was swept under the rug to protect the team and executives that let the blunder continue for as long as it did. I didn&#x27;t get a raise, but I made some allies and got to coast for a while. reply busterarm 1 hour agoparentVery early in my career I discovered some mission-critical network devices at the hedge fund I worked at that would have caused a network loop if either of the two machines were ever rebooted. The two servers were related to some feed data and I had noticed that they were cabled together oddly based on how their function was described to me.The estimated cost of downtime for these systems was something like $7 million per minute. I had raised the issue to a couple of the staff responsible for the machines and to the networking team but was completely dismissed because \"there is no way we would have hooked them up that way\" and because I was the FNG.I then raised the issue again at the weekly group meeting because it seemed important -- somebody was dispatched to check visually and came back to confirm what I said. It was a big deal -- the networking team had about 2 weeks of emergency work to do to resolve the issue cleanly.EVERYONE was angry at me. Even though I had just averted a catastrophe for the company, I made everyone look bad by doing it and particularly because of my status&#x2F;position on the team. It was an important lesson learned. reply mablopoule 46 minutes agorootparentOn his book \"The Secrets of Consulting\", Gerald Weinberg advise against improving more than 10% of performance, and if so, of hoping to have any credit.Just like the article, his reasoning is that if you improve performance too much, it makes management&#x2F;the team look bad for not doing it before, while a smaller improvement in performance make management looks good. reply phkahler 47 minutes agorootparentprev>> EVERYONE was angry at me. Even though I had just averted a catastrophe for the company, I made everyone look bad by doing it and particularly because of my status&#x2F;position on the team.People can be excessive in both taking credit and placing blame. An appropriate and helpful way to frame this is \"the system was configured incorrectly but nobody noticed because the problem never actually happened. It&#x27;s a good thing the new guy had time to go through things and spotted the problem before it ever happened.\" No need to crucify the team or exaggerate the value of the new guy. reply tehlike 53 minutes agorootparentprevKeep doing the right thing. reply busterarm 53 minutes agorootparentIt&#x27;s 20 years later and I&#x27;ve made my career off of pointing out fundamental mistakes made by very smart people. ;) (just with more skill and tact)90% of what I do is ask dumb questions as if I&#x27;m completely clueless. reply tehlike 30 minutes agorootparentI know the feeling. I&#x27;m similar in that regard. Debugging complex things by asking dumb questions is extremely fruitful.Also asking dumb questions to newer engs teaches them to think different aspects of a problem themselves.One of the things I&#x27;m hoping I could keep alive in my child reply chasd00 1 hour agoparentprevI did something similar early in my career but it very much went noticed. The system I wrote to correct the bug was basically a MITM attack against pharmacy rx transmissions, it re-priced prescriptions just before they went to the insurance carrier&#x27;s system because the pharmacies would never apply price updates (i worked at a small independent pharmacy chain, they didn&#x27;t have a central dispensing system). In my infinite genius I named the system after my current crush. Corporate liked it so much they made an annual award named after my system... so therefore after my crush but i was too embarrassed to tell them the real origin of the name. That was 25 years ago but, to this day, every year a trophy gets made with the first name of my old crush printed on it and handed out. heh if she ever knew she&#x27;d be mortified. reply digging 1 hour agoprevThis is such a good article. My skin was crawling.What really scared me is that I couldn&#x27;t identify any of the issues raised in my own organization, even though we often run into similar, smaller-magnitude problems caused by a blindness to obvious mistakes. It makes me fear I, too, am blind to massive bleeding wounds. Here&#x27;s hoping the actually don&#x27;t exist. reply nickdothutton 7 minutes agoprevThe unsaid part is that this kind of situation is everywhere. It only really hits home when (IMO) when you’ve had a couple of decades in the industry. We have totally squandered the abundance of resources in many sites&#x2F;situations&#x2F;use-cases. Whether it be IOPS or threads or memory or network bandwidth and latency. Yes premature optimisation is the root of all evil, but the other side of that coin is pretty ugly looking too. Not even because of monetary waste in many cases, but because of unnecessary complexity and fragility. For what? A slightly higher level of abstraction? A bit more interoperability? A marginal gain in some other metric? reply cameron_b 18 minutes agoprevI love this for purely self-appeasing reasons. this machine kills imposter syndromeor at least it helps. Having a background in solid CS theory from High School, and having a degree in Art, I find it very hard to apply for engineering roles, and my mixed bag of experience often lands me in Support Engineer &#x2F; application admin &#x2F; integration roles, fuming tremendously when the people with SwEng &#x2F; Developer titles fumble on with implementing some JavaScript change for a feature I need in Service Now for my application&#x27;s customers.It is incredibly reassuring that it is not simply my organization that is hamstrung by the pretense of complexity, when really someone just made it complicated to make it seem important. reply thefourthchime 9 minutes agoprevI saved my company $1 million a year a couple of months ago by noticing that there was an S3 bucket that kept growing and costing 80k a month.I poked around and realized that there was a system that we weren&#x27;t using anymore that was copying files to the bucket I reached out to the stakeholders and they turned it off and we deleted the files.The higher-ups didn&#x27;t seem to really care, My boss&#x27;s boss told me to reach out to another team that should&#x27;ve caught this and that was about it. reply dpifke 43 minutes agoprevThe author&#x27;s gallery of poignant HN commentary on their writing is chef&#x27;s kiss: https:&#x2F;&#x2F;ludic.mataroa.blog&#x2F;compliments&#x2F; reply cybernoodles 1 hour agoprevI saved Amazon $10MM as an intern back in 2012. If only I could have seen 1% of that. reply WediBlino 20 minutes agoparentMy company paid a consultant £25K to increase efficiency. He recovered about 5 minutes a job.I wrote a tool that saved about two hours a case, in total this saved about £500k. I got a free case off beer. reply microtoodle 52 minutes agoparentprevI once saved a company $20k in infra costs and saw nothing of it.In fact the team was pretty upset that they&#x27;d budgeted that money for infra already and it&#x27;d have been better spent instead of waiting till next year to re-budget it. reply busterarm 35 minutes agorootparentI once talked AWS into a 5-digit refund for something that was our team&#x27;s mistake.It wasn&#x27;t necessary though because we had a committed spend target to reach and we just had to figure out how to legitimately spend the money somewhere else. :( reply shepherdjerred 1 hour agoparentprevI also saved Amazon a ton of money and saw nothing from it! reply gottorf 1 hour agorootparentOn the other hand, employees aren&#x27;t liable for the company&#x27;s losses and debts, so it works out in the end. reply foxyv 1 hour agorootparent> employees aren&#x27;t liable for the company&#x27;s losses and debtsNever been laid off during a recession or had your pay frozen and bonuses cancelled during a hard time? Employees risk a lot more than most stock holders by working for a company. On average, stock holders are way more diversified. reply martin8412 1 hour agorootparentPay frozen? Absolutely not. The company would be undergoing bankruptcy by the end of day if not all employees agreed to it. reply vdqtp3 31 minutes agorootparentPay frozen != no payPay frozen == no pay raises reply geodel 1 hour agorootparentprev> Employees risk a lot more than most stock holders by working for a company.hmm, they can perhaps reduce the risk by not working for a company. They can just be stock holders or launch their own company, that way whatever may happen they will never get fired. reply birdyrooster 1 hour agorootparent> They can just be stock holders or launch their own company reply throwaway98797 1 hour agorootparentprevlosing your job is not the same as losing capital reply mao_tse_tung 1 hour agorootparentCorrect, is way worse. Proletarians don&#x27;t have any capital to lose. Capitalists do. So if they lose their capital, they can just be like the rest of us. If we (proletarians) lose our job, we risk poverty and death. reply anonymouskimmer 16 minutes agorootparent> So if they lose their capital, they can just be like the rest of us.Nah, if they had enough capital to live off of before then, they are far more likely than us to fail upward into a management job. reply dvt 1 hour agorootparentprev> On the other hand, employees aren&#x27;t liable for the company&#x27;s losses and debts, so it works out in the end.How can anyone seriously type this? If you fuck up bigly enough, you will 100%—without fault—get sacked. Again, not even talking about long tails (bad economic conditions, layoffs, etc.).This is under totally normal situations: if you lose the company money, you will be fired. As a bonus, you also lose unvested options or equity. These kinds of posts are exactly why engineers have garbage bonuses compared to finance even though they probably generate an order of magnitude more value. reply chii 1 hour agorootparent> If you fuck up bigly enough, you will 100%—without fault—get sackedwhich is to be expected - making a big mistake might not be something that can be forgiven and overlooked (depending on the magnitude of the mistake).But you will not lose capital as an employee, since you did not put in capital to lose. Your time would still have been paid, up to the day you are fired.Therefore, you obviously have no incentive to take on a risk that can result in a mistake (but which the reward you take no part in). You just do your assigned job, and whether it saves the company money or not, as long as you can cover your ass, you&#x27;re golden.Unless the company incentivize you to save money - for example, via a bonus through hitting a target or achieving some goal that was set. reply anonymouskimmer 11 minutes agorootparent> But you will not lose capital as an employeeIt depends on how much you mess up. Mess up large enough as an employee and you can end up sued by your former employer. Losing a lawsuit is losing capital.Depending on the state you can also have your pay docked (if that&#x27;s not a capital loss, at least for transportation costs, then I don&#x27;t know what is): https:&#x2F;&#x2F;www.avvo.com&#x2F;legal-library&#x2F;employment-law&#x2F;paycheck-d... reply dvt 41 minutes agorootparentprev> But you will not lose capital as an employee, since you did not put in capital to lose.The conversation is a lot more complicated because there&#x27;s an opportunity cost, you lose time (your time is finite, company time is infinite), you lose reputation, and so on. Besides, your argument is a bit weak as it&#x27;s not like hedge fund managers put up the cash themselves, either.My point is only that value-generators should be rewarded as such, and it&#x27;s a bit weird that engineers are totally cool with not getting a piece of the pie. reply robertlagrant 57 minutes agorootparentprevYou&#x27;ve completely missed the point. Businesses can lose money for all sorts of reasons. Owners have to eat the losses while keeping on paying salaries. reply anonymouskimmer 9 minutes agorootparentNo they don&#x27;t, they can instead fold the company and sell it off in parts. reply TuringNYC 1 hour agorootparentprevIn trading&#x2F;PM roles in finance, before clawbacks became more popular, employees would regularly get the upside and avoid the downside. reply searchableguy 1 hour agorootparentAre clawbacks common at trading companies? reply tshaddox 51 minutes agorootparentprevWho is liable for the company&#x27;s losses and debts, I wonder? reply tiffanyh 1 hour agorootparentprevSounds like you should move into sales if you want a % paid on value you help a company. reply ipaddr 1 hour agorootparentWe&#x27;re all in sales reply rvnx 54 minutes agorootparentprevIn some way, I made Amazon get a lot of profit by choosing to purchase on their platform, and saw nothing from it, though I directly contributed to their profit and could deserve a %. reply justin_oaks 59 minutes agoprevAnd this is the difference between competence and incompetence in tech. We can argue about whether 10x developers exist, but one thing I hope we can agree on is this: Certain problems can&#x27;t be solved no matter how many incompetent people we throw at the problem. reply Groxx 1 hour agoprev>I am asked to write some PowerPoints, which include phrases like \"a careful statistical analysis of user usage patterns indicated an opportunity to more effectively allocate resources\", implying that nothing was wrong, we just needed to collect more data before deciding not to let the expensive machines idle all day.Yep.If you don&#x27;t make them realize it was a Hard Problem™ that was only solved by their smart hiring, funding, and task-deciding, you might shatter their whole world view. reply datadrivenangel 1 hour agoprevWhy are corporations so allergic to competence? reply yetihehe 1 hour agoparentCompetent people in corporation could show how uncompetent the rest of corporation is, so they are found and eliminated before they can do too much damage to management. reply SillyUsername 1 hour agorootparentThat last line isn&#x27;t a joke.I&#x27;ve been on the receiving end of middle management because I&#x27;ve been able to fix things in the business that have always been broken but never got fixed until I worked on them.Management will claim it&#x27;s their work, will give you just lip service, will not use your name higher up the hierarchy and will actively down play their own mistakes whilst blaming the rest of the department or developers (e.g. like building a project with wrong requirements they actually provided, then missing the deadlines because stakeholders demand changes).Where that has happened I quit and then they just go back to the status quo. reply prmoustache 39 minutes agorootparentprevThey are not eliminated, they are assimilated.A company is like a chain, as strong as its weakest link. There is not much gain to have some links much stronger than the others.The famous \"I&#x27;ve learnt my lesson\" which means you really reached the same low level of incompetence as everyone but secretly thinking you are more competent than all the others.The funny thing is that among all those incompetent peoples &#x2F; idiots mentionned there are probably smart people who just learnt their lesson years&#x2F;months and adjusted to the weakest links in the chain. reply yetihehe 30 minutes agorootparentThey are \"dealt with\". One way or another, competent people are stopped from being a problem for management, either by being eliminated (fired), or tempered down (not assimilated, more like \"converted\") so they are no longer competent, but that&#x27;s a small difference for me. reply NovemberWhiskey 24 minutes agoparentprevCorporations are not allergic to competence; they&#x27;re allergic to bomb-throwing. Except in times of tremendous strife or revolution, incremental change is the best that can reasonably achieved in large organizations. The definition of competence in a large organization includes understanding the concept of Chesterton&#x27;s Fence, and knowing what the Overton window is. reply barryrandall 43 minutes agoparentprevI think it&#x27;s just the result of assembling a large number of humans. Beyond some size, relationships get replaced with internal politics and aggregated individual shortcomings become organizational pathology. reply rekoil 1 hour agoparentprevPossibly hot take; everyone wants to be a manager because managers make more, but you can&#x27;t have a bunch of managers unless you hire a bunch of people, and hiring a bunch of people that are all competent is hard. reply r00fus 56 minutes agoparentprevIs it possible that the corporate veil is essentially a cloak of invisibility for scam artists? reply SillyUsername 1 hour agoprevI did something similar.Success and super efficiency was rewarded with additional work, including hinting I should help other departments (apparently a joke).I received no extra remuneration despite asking, yet my company continues to hire new staff weekly.I&#x27;ve learnt my lesson, just like this author. reply bitwize 1 minute agoprevGreat! That&#x27;s worth (let&#x27;s see... carry the three...) a 1% raise! reply znagengast 21 minutes agoprevI have to play devils advocate here because for every one of these cases, there is probably a dozen of similar stories where the ambitious new guy actually did nuke the system with a risky friday release and then logged off for the weekend xD reply jjkaczor 43 minutes agoprevHuh, I wonder which of the \"big-4\" advised them on their practices?Am willing to bet it was &#x27;KTMJ&#x27;... (Batman reference, but... strangely similar to one of the \"big-4\") reply trealira 1 hour agoprev> I&#x27;m not sure what the original estimate was, but I think it was intended to cost something like 200K for a year of operations, but we were now close to a million dollars.> ...> I return to work the following Monday. I suspected that this would save a bunch of money, and guess what, our projected bill dropped from a million to half a million dollars, and everyone is losing their fucking minds.Wow, so they&#x27;re still over budget by 300k dollars. This is a funny story, but the company sounds incompetent. reply NoMoreNicksLeft 1 hour agoparent> This is a funny story, but the company sounds incompetent.I&#x27;ve seen \"typical\" spelled this way several times on Hacker News. Is it a British thing or something like that? reply pavel_lishin 1 hour agoprevThis person is a good writer, I&#x27;m looking forward to seeing what else they&#x27;ve written. reply bcjordan 1 hour agoparentIt is really what you want out of a hacker-stuck-in-corporate story.There was a tale maybe 10+ years ago about someone who automated their job with a script or Excel sheet or macro and didn&#x27;t tell anyone about it. Having a hard time tracking it down again, anyone remember what that was? reply pavel_lishin 1 hour agorootparentGoogle reveals two things, followed by a bunch of shitty blogspam:- Last year, there was a post on Reddit, with an HN discussion as well: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29994776- In 2017, there was a question about whether someone should tell their employer that they&#x27;ve automated their job: https:&#x2F;&#x2F;workplace.stackexchange.com&#x2F;questions&#x2F;93696&#x2F;is-it-un... reply orzig 1 hour agorootparentprevI’ve found LLMs to be good for those sorts of vague “remember that thing like this?” searches. Bing (with GPT) or even Bard with potentially better search integration are both worth a try. reply pedro_hab 50 minutes agoprevI had a friend in a similar situation, he explained the issue and how he would fix it.I was baffled and urged him to be careful and assume he was wrong that it had to be wrong.Anyways, he is still fixing it, getting some people to validate it.I would think he will save at least hundreds of thousands a year.But seriously, why a company that spends millions of dollars in an area would not hire an expert to try to save some money in it is beyond me. reply freeopinion 19 minutes agoparentWhy would a manager of a multi-million dollar department reduce the department to a single-million dollar department? That would reduce the prestige of their own job. I&#x27;ve seen managers who were overstaffed by double work hard to double their staff again. And the only staff that actually accomplished anything were punished and culled.It doesn&#x27;t make sense until you realize that they operate in an environment where there is no competition that can disrupt their business model. If their costs go up, their rates go up. There is never an incentive for costs to go down. reply marcos100 44 minutes agoparentprevBecause \"we don&#x27;t have the budget\". reply esafak 26 minutes agorootparentThat \"we\" may be too low on the org chart, and the qualified manager may not be aware of the problem. reply runamuck 1 hour agoprevThank you for writing a hilarious and painfully true slice of office life. reply pgraf 1 hour agoprevIn my opinion this red tape is why startups are more successful than large organisations… At least in the beginning reply dudeinjapan 1 hour agoprevMy goal is to make my company the opposite of this one. reply world2vec 1 hour agoprevLike staring at a mirror, this post made me cringe with how relatable it was. Guess I have a whole blog to read now. reply asow92 42 minutes agoprev> I saved my company half a million dollars in about five minutes. This is more money than I&#x27;ve made for my employers over the course of my entire career because this industry is a sham. I clicked about five buttons.I&#x27;m sorry, but this needs a privilege&#x2F;gratitude check. You are guaranteed your salary, and you&#x27;re welcome to take on the same level of risk your company is by starting your own. If you think it&#x27;s so easy go ahead. reply isoprophlex 30 minutes agoprev> I ask management for a 30K raise after saving 500K and my message is still unread. I suspect I will eventually receive either nothing or 5K.Only one thing left to do. Leave &#x27;sleep(600)&#x27; calls all over the place and resign. reply cainxinth 1 hour agoprevTLDR: They changed the idle time settings for running queries in their Snowflake database. Originally, they were set to idle for 10 minutes after every query, but most queries only took about 2 seconds to run. reply ChrisMarshallNY 1 hour agoprevToo bad Scott Adams self-immolated.This is Dilbertland, at its finest. reply 23B1 14 minutes agoprevI accidentally cost my company half a million dollars, but it&#x27;s not really my fault HR misplaced a comma. reply alex7734 1 hour agoprevIn a sane world this would have to be satire, but unfortunately I believe every single word of this reply tgv 1 hour agoparentA writer cannot make up so much shit. You need a board of managers for that. Effing hell. reply j45 37 minutes agoprevGreat post on why LLMs will have Management Consultants looking for their future. Average skill is highly profitable. One skilled senior and 20 juniors at an affordable rate is always most profitable.Developers - Always do this as bonus paid by contingency of saved money and a signed off scope if it works out, especially if you’re d looking into it on your own time.Specifically if you like you can get signatures from everyone on the hierarchy on how much money or time this will save, cost or make them.Do it enough times and the right kind of CEp&#x2F;President will tell you to stop bringing the business case to them for approval and just do them if they make sense and you have your backup.You will enter a side door, bypassing most politics and c-levels (and maybe triggering some new), reserved for people who say let me see what’s possible instead of coming back with reasons why it can’t be done.From there, paint a picture of what if you built a team of only doers, minus talkers across the organization.:)Tech should never report into Finance, the group that can’t even tame spreadsheets.Yes, business owners pay. reply knodi 49 minutes agoprevyou mean someone costed your company half a million dollars for x amount of time. reply orliesaurus 52 minutes agoprevi loved the style of writing! what do you call it? Realism? Sarcasm? IdkIt had me stuck reading until the very end - usually that never happens!! reply rybosworld 1 hour agoprevTLDR: Bureaucracy is everywhere. reply davedx 1 hour agoprev [–] Incredible.Meanwhile big tech thinks the way to reduce costs is to wholesale fire 1&#x2F;2 their company. reply pavel_lishin 1 hour agoparentFor what it&#x27;s worth, OP also recommended that approach. reply mcv 59 minutes agorootparentYeah, but corporations rarely fire only the incompetent people. Quite often it&#x27;s the best paid engineers who get fired first because that saves the most money. And when there&#x27;s a voluntary get-out program, it&#x27;s the unappreciated competent people who are the most eager to leave. reply goalieca 1 hour agoparentprev [–] The two are not exclusive. Companies can run hundreds of programs many of which are not productive and actually hurt and frustrate engineering teams. Just in the same way government can hurt the environment by throwing up a lot of red tape on green initiatives, companies can hurt quality and productivity by spending thousands of hours on things like employee annual reviews. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article captures the author's experience of saving their company $500,000 by optimizing an analytics platform and tackling operational inefficiencies.",
      "It underscores the obstacles encountered, including technical debt, an inadequate budgeting process, and departmental resistance, despite achieving significant cost savings.",
      "The author voices discontent over a lack of recognition or reward despite their substantial financial contribution to the company."
    ],
    "commentSummary": [
      "The article discusses the issues with convoluted and inefficient company processes particularly seen when driven by resume-centric or iterative-StackOverflow development methods, suggesting simplification could lead to success.",
      "The comments section concentrates on problems in client-based settings, disillusionment with work environments at FAANG (Facebook, Amazon, Apple, Netflix, Google) companies, and underappreciation of profit-generating employees.",
      "It concludes advocating for a work culture promoting action and efficiency while critiquing the concept of technology being subservient to finance departments."
    ],
    "points": 320,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1698675307
  },
  {
    "id": 38063536,
    "title": "π in Other Universes",
    "originLink": "https://azeemba.com/posts/pi-in-other-universes.html",
    "originBody": "Azeem Bande-Aliazeemba.com Home Posts Projects Artwork π in Other Universes How the value of π depends on the definition of distance. October 29, 2023 · 10 min Everyone loves 𝜋 π. It’s usually the first irrational number someone encounters. 𝜋 π is conceptually simple enough that it can be explained with basic geometry. 1 2 3 4 5 6 7 8 −1 0.5 1 1.5 2 2.5 3 3.5 −0.5 n = 10.00 2π r = 1 C (estimate) = 6.180 π (estimate) = 3.090 A circle with diameter 1 has a circumference of 𝜋 π. The circumference can be measured by slicing the circle and unwrapping it. The more slices that are added by moving the slider, the more accurate the measurement becomes. (Adapted from here) 𝜋 π is the ratio between the circumference and the diameter. Usually, written as: 𝐶 = 2 𝜋 𝑟 C=2πr where 𝐶 C is the circumference, 𝑟 r is the radius (half of the diameter) and 𝜋 π is famously 3.14159.. 3.14159... But why does 𝜋 π have to have that value? Could it have some other value? The answer is yes! But to figure that out, we first have to talk about circles which are closely tied to the definition of 𝜋 π. Circle Since the definition of 𝜋 π depends on two properties of a circle (circumference, radius), it’s good to figure out what a circle even is. Mathematically, a circle is the collection of all points that are an equal distance from the center. So if the radius of a circle is 1, then the circle is the collection of all the points that are 1 unit distance away from the center. In practical terms, a circle tells you all the points that have an equal “cost”. For example: If you start running from the center, then the circle represents all the farthest points you can reach in a given amount of time. Here the distance is measured in units of time. If you start driving from the center, then the circle represents all the farthest points you can reach in a given amount of fuel. Here the distance is measured in units of fuel. But not all constant-cost functions will create the same shape. For example, suppose you are sailing on a windy day. Traveling in the direction of the wind will be easy but traveling orthogonal to the wind will require more effort and traveling against the wind will require significant effort. So for fixed effort, the farthest points you can travel will create an ellipse shifted against the direction of the wind. If there is strong wind to the right, you can sail much farther to the right than to the left with the same effort. The red ellipse shows the points you can reach with equal effort. The black circle represents the farthest you can travel with equal effort when traveling on a day without any wind or current. [graph] But does this cost-function (effort needed to sail) define a proper distance? Can we use it to measure radius and measure circumference? Seems kinda arbitrary to say yes or no. If time and fuel can all be “distances” in some situations then why couldn’t effort be a distance in this situation? Fortunately, we don’t have to make an arbitrary decision here since we can rely on a preexisting concept that defines what kinds of cost functions are valid distances. Metrics Mathematics can be seen as a logic game. You start with a set of assumptions and you come up with all the logical conclusions you can from that. Then, if someone else finds a situation that fits those assumptions, they can benefit from the pre-discovered logical conclusions. This means that if some conclusions require fewer assumptions, then those conclusions are more generally applicable. As a result, mathematics goes through continuous cycles where mathematicians go back and trim down the assumptions needed for any mathematical system. For example, a lot of geometry from the times of the Greeks used only the single definition of distance: the Euclidean distance ( 𝑑 = 𝑥 2 + 𝑦 2 d= x 2 +y 2 ). We even named it after the Greek mathematician. Even Newton relied solely on Euclidean distance when he invented Calculus. Then, in the early 20th century, mathematicians realized that any function can be used as a distance function, as long as it followed some basic requirements. As long as the distance function followed those requirements, a lot of the established math would still work. So you could still do geometry and calculus and topology with just minor tweaks. Functions that fit these requirements are called metrics. A function is a metric if it follows the following rules: The distance between a point and itself is always 0. If you don’t go anywhere, the distance traveled is 0. The distance between any two different points is always positive The distance from 𝑎 a to 𝑏 b is the same as the distance from 𝑏 b to 𝑎 a Going directly from 𝑎 a to 𝑐 c is at least as fast as going from 𝑎 a to 𝑏 b and then from 𝑏 b to 𝑐 c Now, with these requirements, does “effort to sail” define a metric? The answer is no. We can probably debate 1 and 2 but 3 is very clearly not true. If 𝑏 b is downwind of 𝑎 a, then the effort in one direction is smaller than the effort in the opposite direction. Okay, so what functions are a metric? There are two classic examples: Manhattan distance and maximum distance. Manhattan Distance When you are driving in a city grid, you can’t drive diagonally. You have to drive in one grid direction and then the other. When you drive like this, the distance between two points is just 𝑑 = 𝑥 + 𝑦 d=x+y. This is popularly called the Manhattan distance or the taxicab distance. One application of this metric is measuring accuracy. Suppose you are asked to predict the total population change of two cities. If you guess within 1,000 people, then you win a prize. You can visualize this by charting the population change of one city on the x-axis and the population change of the other city on the y-axis. Then a “circle” around your guess with a radius of 1,000 tells you the range where you can still win the prize. A circle using the Manhattan distance. The circle captures all the points that add up to 1,000. These are all the points that have a total inaccuracy of 1,000. [graph] The circle looks like a rotated square! The circle has radius of 1,000 but what is its circumference? If we use the Manhattan distance to measure the circumference then each line has a distance of 2,000 ( 𝑥 + 𝑦 = 1000 + 1000 x+y=1000+1000) and since there are 4 lines, the circumference is 8,000. This means: 𝐶 = 2 𝜋 𝑟 C=2πr 8 , 000 = 2 𝜋 ( 1 , 000 ) 8,000=2π(1,000) 4 = 𝜋 4=π In the universe where you measure distance using the Manhattan distance, the value of 𝜋 π is 4! Maximal Distance Another distance function that is a valid metric is the maximal distance: 𝑑 = 𝑚 𝑎 𝑥 ( 𝑥 , 𝑦 ) d=max(x,y). So instead of combining x and y, we use the larger of the two as the distance. A lot of times when you are doing multiple things at the same time, it only matters how long the longest item takes. For example, suppose you need to prepare two ingredients for a dish, and you can prepare the ingredients in parallel. The amount of time you need to finish your dish is as long as the slowest ingredient. Suppose for a cooking competition, you are required to finish cooking in exactly 60 minutes plus/minus 5 minutes. Then how much time can each ingredient take? If we use the x-axis to represent the time ingredient 1 takes and the y-axis to represent the time ingredient 2 takes, then we can draw a 5 minutes-wide circle that tells us how long each ingredient can take. As long as both ingredients are finished between 55 and 65 minutes, we can win the cooking competition. The red ‘circle’ demarcates the area where we can still win. [graph] This circle looks like a regular square! The circle has radius 5 but what is its circumference? Each line has a distance of 10 and there are 4 lines so the circumference is 40. 𝐶 = 2 𝜋 𝑟 C=2πr 40 = 2 𝜋 5 40=2π5 4 = 𝜋 4=π And again, in the universe where distance is measured using the maximal distance, the value of 𝜋 π is 4! p-norm Till now we have covered three distances: Euclidean, Manhattan, and Maximal. What other examples can we look at? Well, we have the p-norm metric which is a collection of infinite metrics defined as: 𝑑 = ( 𝑥 𝑝 + 𝑦 𝑝 ) 1 / 𝑝 d=(x p +y p ) 1/p where 𝑝 p can be any number greater than or equal to 1. The cool thing about p-norms are that they are a generalization of the metrics we covered before. Euclidean, Manhattan, and maximal distances are specific examples of p-norms. When 𝑝 p is 1, we have the Manhattan distance. When 𝑝 p is 2, we have the Euclidean distance. When 𝑝 p is ∞ ∞, we have the maximal distance. So Manhattan distance and maximal distance are the extremes of the p-norms. Here are what circles look like in different p-norms: 0.2 0.4 0.6 0.8 1 1.2 1.4 −0.2 −0.4 −0.6 −0.8 −1 −1.2 −1.4 0.2 0.4 0.6 0.8 1 1.2 1.4 −0.2 −0.4 −0.6 −0.8 −1 −1.2 −1.4 p = 2.00 P-norms define a different metric for different values of 𝑝 p. Here we graph the “circles” of the respective p-norm metrics. Just as we did before, the circumference and the value of 𝜋 π can be calculated for the different p-norms. In previous examples, we were able to calculate the circumference just by looking at it, since they were straight lines but that strategy doesn’t work in general. So, for the rest of the shapes we need to caculate the circumferences computationally. We can write a program to tell a computer to walk around the circle and track the distance traveled. Fortunately, someone else has already done this work so we can refer to their results1. p𝜋 π 1 4 1.1 3.757… 2 3.141… 2.25 3.155… 3 3.259… 11 3.757… ∞ ∞ 4 In addition to calculating these values, the paper linked above also proves that 3.14159 is the smallest value of 𝜋 π possible for all the p-norms. Our regular 𝜋 π is the smallest possible 𝜋 π in the family of p-norms! All Metrics While there are infinitely many p-norm metrics, there are infinitely more metrics that are not p-norms. What are the values of 𝜋 π in all the other metrics? This article by Sahoo proves that 𝜋 π is between 3 and 4 for all metrics. We have seen the metrics that give us 𝜋 = 4 π=4. What’s the metric that gives us 𝜋 = 3 π=3? The answer is a little gnarly2 𝑑 = 1 2 3 ∑ 𝑛 = 1 6 ∣ 𝑥 sin ⁡ ( 𝜋 𝑛 3 ) + 𝑦 cos ⁡ ( 𝜋 𝑛 3 ) ∣ d= 2 3 1 n=1 ∑ 6 ∣ ∣ xsin( 3 πn )+ycos( 3 πn ) ∣ ∣ But drawing out the circle for this metric gives us a hexagon. Circle with the ‘hexagon’ metric. Note that changes in the y-direction are weighed more (because of the cosine term) so no point on the ‘circle’ ever reaches to y=1. [graph] By using the distance equation defined above, we can calculate the length of each line of the hexagon3. This gives us a length of 1 for each line of the hexagon which means that the circumference is 6. 6 = 𝐶 = 2 𝜋 𝑟 = 2 𝜋 ( 1 ) 6=C=2πr=2π(1) 3 = 𝜋 3=π So next March, instead of just celebrating 𝜋 π-day on March 14th (3/14), feel free to celebrate 𝜋 π-month all through March. You just have to do the work of finding the appropriate metric for each day of the month. I learned of the original article from this StackExchange post that summarizes the article. ↩︎ The StackExchange post gives the metric that has n-sided polygon as its circle. The article linked above hints that the “shape” that minimizes the value of 𝜋 π is a hexagon. So we set 𝑚 = 6 m=6 into the formula. Also, note that the 𝜋 π in this formula is the regular 𝜋 π since it’s derived using Euclidean trigonometry. ↩︎ If you miss textbook math problems where a crazy equation resolves into a neat simple answer, then you should calculate the distance with 𝑥 = 1 2 x= 2 1 and 𝑦 = 3 2 y= 2 3 . ↩︎ Math",
    "commentLink": "https://news.ycombinator.com/item?id=38063536",
    "commentBody": "π in Other UniversesHacker Newspastloginπ in Other Universes (azeemba.com) 302 points by azeemba 18 hours ago| hidepastfavorite91 comments IanCal 16 hours ago> Mathematics can be seen as a logic game. You start with a set of assumptions and you come up with all the logical conclusions you can from that. Then, if someone else finds a situation that fits those assumptions, they can benefit from the pre-discovered logical conclusions. This means that if some conclusions require fewer assumptions, then those conclusions are more generally applicableThis is a really, really nice expression of something my mind&#x27;s been hovering around for a while. reply jerf 3 hours agoparentMathematics is humanity&#x27;s longest running, largest-scoped, most complicated game.It also happens to be useful, and you can dive into a lot of philosophy about that which is all very interesting. The utility itself is a large thing on its own. But I think of that utility as something separate from the game itself. The game is just a game. You can do whatever you want with it. If you want to convert your cookbook to hexadecimal just for fun, you can. The fact that it is (broadly speaking) useless, that it will produce no new knowledge, and if anything negative utility in general, doesn&#x27;t mean you can&#x27;t do it.That&#x27;s the game.You can also try to play the game to prove the Twin Prime conjecture. That&#x27;s a much harder level.This game is scalable to all ages and skill levels, has the best level variety, and can be done with anything from just your personal noggin, to a pencil & paper, to the largest computing cluster in the world. Technically all other games you play are a subset of this game; that may not always be a useful way to think of it, but it is technically true. And while there are a few rules, generally, nobody can tell you how to play it. You want to color pretty pictures? The game has lots of ways of doing that. You want to smash atoms together? The game can help with that. You want to simply count to the highest number you possibly can? Go for it. It&#x27;s a very popular play with the younger players, but anyone can do it. reply tetha 9 hours agoparentprevThis is also a part of why I am somewhat fascinated by the idea and the state of Lean4 and mathlib in Lean4. People put more and more formally verified proofs into mathlib, which in turn makes formally proving further theorems in mathlib easier.If you start with nothing (like in the numbers game), simple proofs are a lot of ... just effort, because you have specify a lot of rewrites and overall work. In mathlib, however, systems like simp (the simplification system) or linarith (\"There is a solution by linear arithmetic\") seem to do a lot of heavy, repetitive lifting by now.It&#x27;s a really interesting snowball effect. Sadly, everything I understand is most likely already in there, so I doubt I could contribute meaningfully, haha. reply IanCal 8 hours agorootparentThat&#x27;s very interesting, I&#x27;m no mathematician but I should have a play around with it.> Sadly, everything I understand is most likely already in there, so I doubt I could contribute meaningfully, haha.I wouldn&#x27;t be so sure - and even if so then remember there&#x27;s enormous benefit to improving tooling around a system. If you want to be involved somehow, better devx, tutorials, output, packaging, error messages all make a big difference to end users.Edit -As another thought, is there benefit in going through papers and translating that work into lean4? I&#x27;m not really familiar enough with it but if so that may1. Find issues in current work, like Tao did in his own work2. Add to a reusable body of work reply lmpdev 6 hours agorootparentprevFormer computational mathematics majorYou absolutely can contribute meaningfullyThe maths world is incomprehensibly broad and deep, even if you just take the Erdos approach and go for interesting but shallow problems reply lachlan_gray 12 hours agoparentprevIt blows my mind to think of mathematics&#x2F;logic almost like a huge cellular automaton. “axioms” don’t necessarily correspond to “truth”, to me they’re arbitrary constraints that can give rise to complexity. And sometimes the resulting systems can be useful reply gumby 11 hours agorootparentThe whole of the puzzles of cosmology actually all might be obvious if we had a few different fundamental theorems. But because we hit on some that almost work, and then build upon them a hole edifice of mathematics that is internally consistent and almost fits the universe we keep beating on it, not realizing that backing up a little and then driving forward again at a slightly different angle might yield a simpler, and even more consistent and explanatory system. reply chongli 11 hours agorootparentMost mathematics has no application to science whatsoever. It&#x27;s a huge parts bin which scientists delve into when they build their models. And then much of the work is in trying to shoehorn the mathematics into being tractable.Mathematics is also not provably internally consistent. This was famously shown by Gödel [1].[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gödel%27s_incompleteness_theor... reply tsimionescu 8 hours agorootparentMost mathematics originates from trying to solve physical or engineering problems. Typically physicists have been on the forefront of mathematical research - this has only really changed significantly in the last few decades.Also, mathematics as practiced is internally consistent. It is incomplete, though. That is how it stays afloat of Godel&#x27;s result. Basically Godel&#x27;s results showed that no matter how much we strive, there will always be propositions which might be true, but which we will not be able to prove are true. Unless of course we start using methods that sometimes prove false propositions, which we have not done. reply gumby 4 hours agorootparent> Most mathematics originates from trying to solve physical or engineering problems.Has this been true since the early 20th century? I have no feel for what constitutes \"most\" in the vast corpus of pure mathematics, so am not challenging your claim but rather am curious. reply tsimionescu 4 hours agorootparentYou&#x27;re right, that might actually be wrong.However, the claim I was actually thinking of, which is right I think, is that the maths used in the physical revolutions of the turn of the century (SR, QM, GR, and probably QFT, QED, and QCD as well) was invented by physicists or by mathematicians working with physicists for the express purpose of developing this theories, not the other way around.Also, the basis of mathematics and the first few thousand years were indeed motivated by these kinds of concerns. reply defrost 3 hours agorootparentI wouldn&#x27;t agree - consider the hyperbolic transforms used to describe space time \"bending\" wrt relativity:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;History_of_Lorentz_transformat... In mathematics, transformations equivalent to what was later known as Lorentz transformations in various dimensions were discussed in the 19th century in relation to the theory of quadratic forms, hyperbolic geometry, Möbius geometry, and sphere geometry, which is connected to the fact that the group of motions in hyperbolic space, the Möbius group or projective special linear group, and the Laguerre group are isomorphic to the Lorentz group.Mathematicians were following up on \"what happens when you discard one of Eucilids Axioms\" and discovering there was an entire world of consistent hyperbolic geometry and more.Some time later: In physics, Lorentz transformations became known at the beginning of the 20th century, when it was discovered that they exhibit the symmetry of Maxwell&#x27;s equations. Subsequently, they became fundamental to all of physics, because they formed the basis of special relativity in which they exhibit the symmetry of Minkowski spacetime, making the speed of light invariant between different inertial frames.If you read mathematics histories it&#x27;s a common complaint that it&#x27;s nigh on impossible to discover something new and esoteric that doesn&#x27;t soon end up with a military application; the ongoing search for interesting but useless mathematics is akin to the search for the fountain of youth.It is the case (IIRC) that quaterions arose directly from Hamilton&#x27;s search for a better way to describe mechanical motions in three dimension spaces - ie created to be useful from the outset. reply gumby 3 hours agorootparentprevYes, I agree to some extent with the restricted claim, which only (slowly) started to break down in the 17th century in the west.A lot of Indian mathematics was rather abstract going back to Vedic times, but since they didn&#x27;t develop the concept of proof, it sadly had little impact on other mathematics practice (except as inspiration to Persian and Arab scholars) other than the the famous cases of zero and positional notation. The mathematical documents I&#x27;ve seen from that practice have been in the form of essays.I know little of Chinese or Mesoamerican mathematics and wonder where they were on this axis. It seems pretty likely that maths started in support of astronomy&#x2F;planting predictions in the cultures I know of so likely also for East Asia and the Americas, but whither thence did it go? replymoring 11 hours agorootparentprevThis has happened, and is happening all the time. Many groundbraking theories in physics can be framed this way. The problem is that \"slightly different angle\" is a huge space, so scientists throw a lot of theories at it and see what sticks. reply nylonstrung 12 hours agorootparentprevI love this idea.You might enjoy Stephen Wolfram&#x27;s writing- it&#x27;s exactly what you&#x27;re talking about reply thriftwy 9 hours agorootparentprevAxioms are not wrong if you can derive some math from them.They may not correspond to anything in our world, and then we usually discover something that does. reply tsimionescu 8 hours agorootparentThe point wasn&#x27;t that they&#x27;re wrong, but instead that they are arbitrary. You could create a mathematical system with entirely different axioms than what we explore typically, and it would only be different in how usefully it maps onto real world concepts. reply random_ 7 hours agoparentprevA good example of that is how the Axiom of choice impacts the measure&#x2F;probability theory.It imply the existence of some sets that cannot be Lebesgue measured (which is an generalization of width, volume, etc for arbitrary sets, also generalization of probability for arbitrary sets)... but it&#x27;s not possible to present a single example of those non measurable sets, only prove that they exist.And it&#x27;s possible to construct an alternative theory with the axiom of determinacy, then any subset of R is measurable.* https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Axiom_of_choice * https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Axiom_of_determinacy * https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lebesgue_measure reply greydius 15 hours agoparentprevThe same principle applies to programming. Functions that know less about their arguments are more generally applicable. reply msds 11 hours agoprevOne thing this doesn&#x27;t touch on is that there are multiple meaningful definitions of pi-like constants for the p-norm unit circle that don&#x27;t necessarily agree with each other in p != 2. Defining pi as the area of the unit circle gives an entirely different set of values that satisfying some wonderful properties - in particular, that definition of pi turns out to be the periodicity constant for a (arguably) natural set of trigonometric functions for the p-circle. Furthermore, pi(p) = 2 Beta(1&#x2F;p,1&#x2F;p)&#x2F;p...However, this (circumference&#x2F;arc-length based) definition of pi does have a fascinating property for conjugate p,q: pi(p) = pi(q)\"Squigonometry: The Study of Imperfect Circles\" is a very fun reference for this sort of stuff. reply waveBidder 8 hours agoparentI wonder whether not being a Hilbert space has any awkward implications for geometry. I guess we have to chuck out the Polarization identity, which probably has implications for parallelograms, though I&#x27;m not sure quite what. anyway, thanks for the rec! reply msds 1 hour agorootparentWell, there isn&#x27;t a meaningful inner product, so how can you speak of parallelograms? The geometries are definitely weird! Once you leave p=2 and break the rotational symmetry around the origin, the only isometries in your geometry are signed permutation matrices - so geometry \"over here\" looks different from \"over there\". Angles aren&#x27;t really meaningful, I guess.The other interesting thing is that duality kicks in (or maybe becomes non-trivial, since it&#x27;s always there) and derivatives naturally start to live in a different space. If you take the particularly natural definitions of general cos_p and sin_p I alluded to, you get a nice parameterization of the unit p-circle as (cos_p(t), sin_p(t)) - but if you differentiate this wrt t, the resulting tangent vectors don&#x27;t lie on the p-circle. Instead, they form a parameterization for the q-circle! reply tzs 15 hours agoprevNote that even if another universe has a different π when it comes to geometry they are still going to also have an important constant that has the same value as our π.E.g., the zeros of the function defined by the series x - x^3&#x2F;3! + x^5&#x2F;5! - x^7&#x2F;7! + ... are nπ where n is an integer and π is our π. Another place our pi will come up is in the exponential function. It&#x27;s periodic with period 2πi. reply svat 12 hours agoparentRight. Also (just a few more concrete examples):• the sum of the series 4(1 - 1&#x2F;3 + 1&#x2F;5 - 1&#x2F;7 + …) will still be our π: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Leibniz_formula_for_%CF%80• the sum of the series (1 + 1&#x2F;4 + 1&#x2F;9 + 1&#x2F;16 + 1&#x2F;25 + …) will still be π²&#x2F;6: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Basel_problem• (therefore) the probability that two numbers chosen uniformly at random from [1…N] are relatively prime will still approach 6&#x2F;π² as N grows large• the product 2(4&#x2F;3)(16&#x2F;15)(36&#x2F;35)(64&#x2F;63)(100&#x2F;99)… will still be our π: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Wallis_product• the value of (n!&#x2F;(√n (n&#x2F;e)^n))²&#x2F;2 as n grows large will still (very slowly) approach π: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stirling%27s_approximation (e.g. https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i2d=true&i=N%5C%2891%29Di... )and so on, for most of the non-geometry results listed: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;w&#x2F;index.php?title=List_of_formulae_... reply NeoTar 7 hours agorootparentIn a change from the normal refrain of &#x27;there&#x27;s an XKCD about that&#x27; - in this case there is an Saturday Morning Breakfast Cereal (SMBC) about it: https:&#x2F;&#x2F;www.smbc-comics.com&#x2F;comic&#x2F;pi-2?ref=refindFor those unwilling to click-through, it essentially posits an alternate history where infinite series were explored by mathematicians before geometry, so rather than being surprised that the &#x27;circle constant&#x27; is found in many infinite series, we would instead be surprised that the &#x27;infinite series constant&#x27; is found in the geometry of a circle. reply thechao 45 minutes agorootparentPi is the scaling factor of the diameter of a circle to its circumference; there&#x27;s an infinite set of such scaling factors: one for each ellipse (the circle is a special case). I wonder which&#x2F;what sort of infinite series arise from&#x2F;for the generalized elliptic scaling factors? reply nlitened 12 hours agoparentprev> Another place our pi will come up is in the exponential function. It&#x27;s periodic with period 2πi.Isn&#x27;t it the opposite? As I understand, we (European civilization humans) historically _define_ our complex exponential function to have a period of 2πi to match the period of our previously defined sin and cos functions.We could have defined it to have another period — for example, if we define \"360° angle\" to be equal to 1 instead of 2*Pi, and define sin0=0, sin0.25=1, sin0.5=0, sin0.75=-1, sin1=0, we&#x27;d also define periodicity of e^ix to be 1.UPD: Same idea as for why we use base-ten numbers. The only reason is that we have ten fingers on two hands, and historically we&#x27;ve been using base-ten numbers for the past few hundred years. But there&#x27;s no reason to expect that \"aliens\" would be having ten digits also. reply jlokier 9 hours agorootparent> As I understand, we (European civilization humans) historically _define_ our complex exponential function to have a period of 2πi to match the period of our previously defined sin and cos functions. We could have defined it to have another period — for example, if we define \"360° angle\" to be equal to 1 instead of 2Pi, and define sin0=0, sin0.25=1, sin0.5=0, sin0.75=-1, sin1=0, we&#x27;d also define periodicity of e^ix to be 1.*No, it doesn&#x27;t work in degrees.The definition of e isn&#x27;t that arbitrary.2π is the unique period which satisfies the definition of e using derivatives and the extension of real number algebraic laws to complex numbers. This shows up as a real world physical measurement, which I describe below.The (natural) exponential function eˣ is defined as the unique function which equals its own derivative and satisfies e⁰ = 1 (like other exponentials). The value of e comes from this.Combine that with the definition i² = -1 and using basic rules of algebra which are observed on real numbers with exponentials and derivatives (such as (xª)ᵇ = xªᵇ) and you find the function eˣ must be periodic with period 2πi.This comes from sin(x) and cos(x) and their derivatives. The derivative of sin(x) is cos(x), and of cos(x) it is -sin(x), but only if sin(x) and cos(x) are defined in the usual math way with period 2π.Those sin&#x2F;cos derivatives and that little negative sign are enough to make them components of the unique solution to the derivative definition of eˣ applied to a complex argument, and thereby fix its period in the complex plane and prove Euler&#x27;s famous identity (without needing the Taylor expansion).That in turn has.a more physical basis. Asin(x+B) with constants A, B are the family of functions whose second derivative equal themselves negated.Physically, it means an object whose acceleration is proportional to its displacement from a fixed position and in the opposite direction will oscillate with a period of exactly 2π seconds, if the acceleration is -1m&#x2F;s² per 1m displacement.This setup is called a harmonic oscillator.In this way, 2π arises (and is measurable!) from physical properties of time, force and inertia, of things moving in straight lines.No circles required. reply nlitened 7 hours agorootparentI agree with you that e is not arbitrary. I say that the period of 2π for e^ix is arbitrary, because we&#x27;ve arbitrarily defined periods of sin and cos as 2π.If we defined a function sin to take not an angle in radians, but in degrees (with a period of 360.0), and used that definition of sin in our math, then our complex e^ix would have a period of exactly 360, and the entire complex math would still work — for example, Euler&#x27;s formula below would still hold: e^ix = cos x + i sin xAnd people in comments would rave about how magic number 360 is, and its magic properties were discovered by Romans two thousand years ago. reply codeflo 6 hours agorootparentYou seem to think that the 2pi is injected into the definition of e^ix somewhere, but actually it&#x27;s the other way round, 2pi comes out as a theorem. I&#x27;ll give the rough outline.exp(x) for complex x is simply defined to be the infinite sum from k = 0 to infinity of x^k&#x2F;k!. That is, exp(x) = 1 + x + x^2&#x2F;2 + x^3&#x2F;6 + x^4&#x2F;24 + x^5&#x2F;120 ...(BTW, the motivation for this definition is that exp&#x27;(x) = exp(x), which shouldn&#x27;t be too hard to see because it&#x27;s already a Tailor series.)Purely from this you can prove that exp(ix) with real x is periodic with period 6.28...It just so happens that this number is also the circumference of the unit circle. reply quickthrower2 6 hours agorootparentI had never spotted that before, each term of the series is the integral of the previous. That is pleasing!The Pi thing feels now less of a coincidence than the fact that exp is a power. That probably falls out of expanding the polynomials but it so ingrained as taken for granted that it is wonderous when you think about it. reply nlitened 5 hours agorootparentprevHey, you&#x27;re right! So Pi is special :) reply quickthrower2 6 hours agorootparentprevI guess radians are “magic” in that sin and cos can be defined by infinite series that look nice (and feel canonical). You have to manipulate those series to get 360 or even just revolutions. reply nlitened 5 hours agorootparentAs codeflo showed in a sibling comment, actually I am wrong, and Pi&#x27;s special magic also becomes from Taylor&#x27;s series expansion. So turns out that Pi is the real magic number rather than just our arbitrary choice! reply moring 11 hours agorootparentprevWhere in the definition of the complex exponential function is π used? IIRC its: the exponential function is defined to be its own derivative (note 1), i is the square root of -1, and exp(ix) is observed to have a period of 2π. There isn&#x27;t any arbitrary choices in there that could be said to be defined in such a way that π results.note 1: exp(x) can alternatively be defined by the exponential series, but that series does contain arbitrary numbers that could be said to be selected in such a way that π results. reply nlitened 7 hours agorootparentAs I understand, \"complex exponential\" function f(x) = e^ix must satisfy only two equalities: f(0) = 1 f&#x27;(x) = i f(x)So any function that satisfies these equalities can work as a \"complex exponential\" function which we denote as e^ix.So we can define a function with period of 1, and use it everywhere — then \"2π\" vanishes from most equations, and the complex math still works and all equalities hold.* reply messe 7 hours agorootparentThe only function that satisfies those two equalities is e^ix which has period 2π. reply nlitened 5 hours agorootparentHey, you&#x27;re actually right! My bad reply jojobas 4 hours agorootparentprevConsider simultaneous functional equations:f(x) = dg(x)&#x2F;dxg(x) = df(x)&#x2F;dxIts only linearly independent solutions are sin(x+c) and cos(x+c) with, x being in radians, periodic by 2pi. reply nlitened 3 hours agorootparentYep, you’re right, my bad. reply zoomablemind 3 hours agorootparentprevFact that pi is irrational may point at something fundamental missing in our knowledge system.It appears that we cannot precisely measure circle length&#x2F;area in units of radius and vice versa. Basically, the unity as such does not exist in our knowledge, nor can we truly comprehend infinity.Perhaps, unity and infinity are just our abstractions for something else. reply gus_massa 3 hours agoparentprevI think it&#x27;s better to say that π is the same number everywhere 3.14... , but in other universe you don&#x27;t use π in the formula of the length of a circle.* Manhattan (L_1): C = 8 R...* Euclidean (L_2): C = 2π R...* Maximal Distance (L_infinity): C = 8 R reply passion__desire 13 hours agoparentprevwould their π re-emerge if unit distance i.e distance between 2 and 3, 5 and 6 is defined by their metric. sort of like change in base in number systems. reply codeflo 12 hours agoprev* pi = 3.14159… appears in analysis and by extension statistics, independent of geometry. So aliens in these other universes would know this value, they’d just have a different constant for circles. Since they wouldn’t use Greek letters anyway, we’d have to translate, and it would be a bit silly to equate their 3.757… with “pi” instead of their 3.14159…* Personal aside: Of course, whether 3.14… (pi), 6.28… (2pi) or even 0.785… (pi&#x2F;4) should be the fundamental constant is debatable, and aliens might have different ideas about that.* The article introduces the concept of metrics to explain that there could be different circle constants in other universes. But arbitrary metrics don’t necessarily have linear scaling or translation invariance. You need stronger assumptions than a metric to meaningfully define a circle constant at all, like a normed vector space. AFAICT, all of the given examples are in fact normed vector spaces, not just metric spaces. reply dylukes 12 hours agoparentI don&#x27;t find the first point surprising. (Our) pi is the one tied to the only metric where the unit circle is perfectly continuous, differentiable, etc.The 2-norm is very special for many reasons I won&#x27;t enumerate... and it seems apropos that its corresponding constant (pi)... for relating a distance from a point (wlog 0,0) to the result of integrating a constant around the path those points occupy&#x2F;form&#x2F;consist in... would itself tend to be found more than others.Perhaps this is simply because without that continuity and differentiability everywhere of the corresponding path generated by the metric&#x27;s unit circle, many other pieces would fall like dominoes.There is something uniquely central about a concise relation between a point, a distance, and a path. reply PennRobotics 8 hours agoparentprevhttps:&#x2F;&#x2F;tauday.com&#x2F;tau-manifesto#table-quadratic_forms(Not to sound all Buzzfeed-y, but Table 3 makes a lot of sense) reply BlueTemplar 6 hours agoparentprevYes, and they actually keep using 2pi over and over in their examples. reply lfnoise 14 hours agoprevThis person is not a sailor. Sailing orthogonal to the wind, a \"beam reach\", is the fastest point of sail due to the lift of the sail. reply Zanni 14 hours agoparentI knew someone would make this comment. I love HN for this kind of pedantry when it&#x27;s specific, accurate and doesn&#x27;t dismiss the entire article for one inaccurate analogy. reply jws 14 hours agorootparentAlso, \"broad reach\" would like a word with lfnoise. (It&#x27;s complicated.)https:&#x2F;&#x2F;physics.stackexchange.com&#x2F;questions&#x2F;186515&#x2F;why-is-a-... reply bmm6o 12 hours agorootparentThe polar diagram shown there is what should replace the ellipse in TFA. It&#x27;s far more complicated than a simple geometric shape since it has to account for such practicalities as sail inventory. reply mnw21cam 3 hours agoparentprevA beam reach isn&#x27;t necessarily the fastest point of sail. It depends on the boat, the efficiency (lift&#x2F;drag ratio) of the sail, and the efficiency of the centreboard&#x2F;keel (again, lift&#x2F;drag ratio), but a reach of some kind is likely to be the fastest - it just won&#x27;t be exactly perpendicular to the true wind direction. It&#x27;ll also vary with the wind speed, wave height, weight distribution, etc. reply sepen77 10 hours agoparentprevI didn&#x27;t know anything about sailing, but your one comment made me search up point of sail and now you&#x27;ve opened my eyes to something that was a mystery to me for all my life -- how sailboats can \"course made good\" against the wind. Thank you.. this stuff is amazing, and sailing is an incredible science! reply jacquesm 14 hours agoparentprevWhat&#x27;s interesting is that if you manage to exceed the hull speed doing that you&#x27;ll end up surfing on your own bow wave! reply joelthelion 7 hours agoparentprevWhat does the \"circle\" look like with correct assumptions? reply gumby 11 hours agoprevWhen I was a kid I liked to muse about relationships like these. Since I was a kid I imagined that there might have been a god that created the universe, and imagined that they were a bored kid like me perhaps making it as a school assignment.So what if the god had turned the pi or e knobs to a rational number (presumably in a god’s universe knobs can be turned to precise irrational values). Would it have made our lives easier or harder (probably easier…?). Or what about the apparent size of earth&#x2F;moon&#x2F;sun when viewed from earth? It’s a great clue, but perhaps we would have known more about astronomy if that coincidence had not existed? (We would have missed out on that fabulous Connie Willis story though).Maybe all those weird cosmological QM oddities and (literally obscure) imbalances needing mysterious dark matter are just due to bugs in a kid’s rushed assignment and actually don’t make sense?But the irrationals…they led to the most musing. reply TheOtherHobbes 15 hours agoprevAll of these assume your background metric is Euclidean.If your background 2D metric is a projection of a warped 3D space, you can make π as big as you want by tugging on the centre of the circle. reply azeemba 15 hours agoparentThere is no concept of the \"background metric\" here. Both the radius and the circumference are measured in the defined metric itself.Any metric that \"pulls on the origin\" compared to Euclidean distance will have to do the mapping in a continuous way. This will basically result in both the radius and circumference being expanded in that metric.Matter of fact, I linked an article that proves that for _all_ metrics, the value of π is always between 3 and 4 (inclusive). Unfortunately the article might have gotten the hug of death so here is an alternative link: https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;353330827_Extremal_... reply charlieyu1 14 hours agorootparentHow is circumference defined?And I can think of a counterexample on a sphere, just using Euclidean distance on the surface. Consider a circle with centre at North Pole and radius being the distance from the North Pole to a point on the equator. For this circle it is easy to find out that pi=2 reply Filligree 12 hours agorootparentHmm. And if you keep increasing the radius, pi will shrink all the way to 0. reply Miiko 11 hours agoparentprevIt&#x27;s not the background metric but the space geometry is assumed Euclidean - in non-Euclidean geometry the ratio of of the circumference of any circle to the diameter of that is not a constant, it depends on such diameter (so you simply cannot define &#x27;pi&#x27; in that case) reply cjfd 7 hours agorootparentWell.... One still obtains pi for the ratio of circumference vs diameter in the limit that the diameter goes to zero. reply jimmySixDOF 12 hours agoparentprevrelatively completely off topic but everything I understand about pi has come from 3D gif models I never saw in school they should be a core part of the learning curve much further to the start of it than 3B1B reply seanw444 3 hours agorootparentThose GIFs really do make it super simple. I learned it the same. The unit circle made absolutely no sense to me, and appeared as yet another dogmatic arbitrary \"rule\" shoved down my throat in school. Had they made an attempt to make it intuitive by showing one single GIF, it&#x27;d have all come together for me much quicker.Math is far more elegant than public school allows it to appear.https:&#x2F;&#x2F;raypatrick.xyz&#x2F;blog&#x2F;2023&#x2F;10&#x2F;27&#x2F;were-you-mathematical... reply lloeki 6 hours agoprevThere&#x27;s this fun space made of p-adic numbers upon which you can define a simple distance, and then circles have mind bending properties like the diameter (max edge to edge distance) and radius (distance from edge to center) being equal to each other.Quirky stuff happens to disc area and perimeter as well, and open discs are also closed. The equivalent of Pi there is nuts.Sadly I can&#x27;t recall the details (it was a 2000-ish exercise on my maths course).https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;P-adic_number#Topological_prop... reply defrost 16 hours agoprevIF I&#x27;ve correctly assesed the zeitgeist of HN postingsTHEN it follows Terence Tao&#x27;s Introduction to Measure Theory must be a bullet.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38064211But seriously, who&#x27;s going to read|skim a free 260+ tract on measure theory?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Measure_(mathematics) reply thomasahle 15 hours agoparentYou don&#x27;t just read&#x2F;skim Tao&#x27;s lecture notes. I used them to teach myself measure theory to skip some prerequisites at university, and they were _hard_. Every other page is a list of exercises. I doubt you would learn much if you didn&#x27;t take time to solve them. But they are hard exercises. reply ajkjk 14 hours agoparentprev> who&#x27;s going to read|skim a free 260+ tract on measure theory?Why is that so hard to believe? People read 260 page books all the time.I&#x27;m not going to read this one, but only because it&#x27;s not my area of interest. I&#x27;m busy reading 100+ page books on other subjects. reply defrost 14 hours agorootparentTake that as a tongue in cheek comment - I&#x27;ve read such things with close attention, I was studying measure theory back in the 1980s when I first met the author of this work here in Australia.There is a subset of people on HN that do read and enjoy mathematical texts, they appear outnumbered by a larger group that seem to post and comment on anything Terence Tao without seeming to be that deep in the actual math, which is fine, but it has struck me as a HN trend of late. reply wcoenen 7 hours agoprevI noticed that all the \"circles\" for alternative metrics are aligned with the coordinate system. For example, the one for the Manhattan distance has its corners on the coordinate axes.What if we added an additional condition that a distance metric should not change when the orientation of the coordinate system is changed? Could we still have different values for the pi constant then? reply BlueTemplar 6 hours agoparentIs that true for the hexagon, or just very close ? reply nologic01 8 hours agoprevMaybe worth pointing out that there are countless other weird Universes where \"Pi\" retains its standard value.This is the domain of differential geometry where the relation of circumference and radius holds only in the limit of infinitesimally small.By all accounts our own Universe is of such a deformed-in-the-large but Euclidean-in-the-small variety. At least for as far we understand geometry in the quantum realm. reply kibwen 3 hours agoprevExcellent article, both informative and accessible, and the interactive visualizations are lovely. reply WiSaGaN 9 hours agoprevThis largely depends on how one defines pi. I believe that the concept of R^n (Euclidean space) exists even in entirely different physical spaces. This is because Euclidean space represents a universally recognized idea of simple space in terms of curvature. For instance, in any world, the concept of &#x27;0&#x27; represents simplicity. In this context, pi will always remain constant. reply cyclotron3k 14 hours agoprevThe boat analogy seems particularly poor.a) Comparing a sailboat on a windy day to a sail boat on an [implied] non-windy day? Surely the boat with no wind wouldn&#x27;t even have a circle.b) I&#x27;m no boatologist, but if the wind is X knots, then the boat can travel downwind at a rate of X knots, but contrary to what the article states, the boat would be able to travel cross-winds at some multiple of X. So you would get something resembling an oval, but in the opposite orientation as depicted.Also, it&#x27;s worth pointing out that it&#x27;s perfectly possible for a boat to travel \"into\" the wind via \"tacking and jibing\" reply tedunangst 15 hours agoprevNot sure about your universe, but here on earth, pi is 2. The length of the equator is 4 times the distance from the pole. (Approx.) reply cvoss 15 hours agoparentWhy stop there? Take the circle with its center at one pole, its radius running an entire meridian, and its perimeter making an infinitesimally tight loop around the other pole. That exhibits a pi that&#x27;s zero. reply quickthrower2 15 hours agorootparentYou can have any Pi_Earth you like where 0 < Pi_Earth < Pi_Euclidian reply simonblack 15 hours agoparentprevSorry, but you&#x27;re wrong.Pi is 3. (more accurately, 3.2). https:&#x2F;&#x2F;cs.uwaterloo.ca&#x2F;~alopez-o&#x2F;math-faq&#x2F;mathtext&#x2F;node18.h... reply quickthrower2 15 hours agoparentprevA flat earth would have pi at about 3.14159 though. reply tragomaskhalos 9 hours agorootparentBased on the attitude of its advocates, a flat earth would lack science and mathematics entirely, so pi would be undefined? reply quickthrower2 15 hours agoprevA p-norm of 3 make quit a funky \"retro\" rounded corner style for avatars. It also shows what the \"opposite\" of rounded corners might look like. In CSS you can only go to a circle. reply pr337h4m 15 hours agoprevThis is the sort of thing that makes me want to learn VR development. reply i_am_a_peasant 7 hours agoprevDidn&#x27;t 3blue1brown have a video on exactly this? reply skykooler 13 hours agoprevThe hexagonal metric at the end uses pi in its definition - is this our value of pi, or the value of 3 that that metric provides? reply passion__desire 13 hours agoparentMy belief, which could be wrong, if we change π and distance metric i.e. definition of unit distance between 1 and 2, 4 and 5, 10 and 11 to be their unit distance, all the equations involving numbers and pi would come out to be same. e.g. basel problem etc. reply daxfohl 14 hours agoprevThe area of the circle in Manhattan distance comes out to 2 million, but pi * r^2 is 4 million. What am I doing wrong? reply daxfohl 14 hours agoparentOh, I was measuring the sides in Euclidean length. In Manhattan length they&#x27;re 2000 each, so area is 4 million. reply dclowd9901 15 hours agoprev [–] I must be missing something. In the example of using a sailboat with constant wind and distance, wouldn’t sailing against the wind (let’s call it any constant oppositional force), cause us to get a circle, just shifted from the origin? Not an ellipsis? reply mannykannot 4 hours agoparentThere are a number of complications. Two of them are that firstly, when when the wind direction is within about 45 degrees against the direction you want to go, you have to tack, and secondly, a reasonably efficient sailboat is fastest when it is on a reach, with the wind coming from the side.https:&#x2F;&#x2F;physics.stackexchange.com&#x2F;questions&#x2F;186515&#x2F;why-is-a-... reply SamBam 15 hours agoparentprev [–] I think you&#x27;re right. Just apply a transform equal to the speed and direction of the wind. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the determination of the value of pi, a fundamental mathematical constant, and how it's influenced by the definition of distance.",
      "It introduces concepts like Euclidean and Manhattan distances, metrics that influence the calculation of pi.",
      "It mentions that the lowest possible value of pi is 3.14159 across all metrics, but countless other metrics see pi ranging between 3 and 4. This suggests the value of pi is not absolute but depends on factors like the chosen metric."
    ],
    "commentSummary": [
      "The discussion revolves around numerous aspects of mathematics, featuring its interpretation as a logic game and its applicability and scalability.",
      "The conversation sheds light on the origins of mathematics and its intertwined relationship with science, as well as the navigation of novel and esoteric mathematical concepts.",
      "The dialogue also reflects on the discretionary nature of mathematical axioms, the implications of pi, the idea of diverse circle constants, and the consideration of reading a comprehensive treatise on measure theory."
    ],
    "points": 302,
    "commentCount": 91,
    "retryCount": 0,
    "time": 1698618924
  },
  {
    "id": 38062297,
    "title": "Apple's Blue Ocean",
    "originLink": "https://hypercritical.co/2023/10/29/apples-blue-ocean",
    "originBody": "APPS ABOUT ARCHIVE CONTACT RSS Hypercritical Apple’s Blue Ocean October 29, 2023 at 4:11 PM by John Siracusa I first read about the “blue ocean” strategy in a story (probably in Edge magazine) about the Nintendo Wii. While its competitors were fighting for supremacy in the game-console market by producing ever-more-powerful hardware capable of high-definition visuals, Nintendo chose not to join this fight. The pursuit of graphics power was a “red ocean” that was already teeming with sharks, fighting over the available fish and filling the water with blood. Nintendo’s “blue ocean” strategy was to stake out a position where none of its competitors were present. The idea of creating a standard-definition game console in the generation when all the other consoles were moving to HD seemed ridiculous, but that’s exactly what Nintendo did. In place of impressive graphics, the Wii differentiated itself with its motion controls and a low price. It was a hit. Lately, I’ve been thinking about the blue ocean strategy in the context of Apple. Like Nintendo, Apple has made some bold moves with its products, many of which were ridiculed at the time: a smartphone without a physical keyboard, a candy-colored desktop computer with no floppy drive and no legacy ports, a $695 (in 2023 dollars) portable music player, a digital music store in the age of ubiquitous music piracy. Unlike Nintendo, Apple has seen its competitors move quickly to imitate its innovations, turning these oceans red and leaving Apple to compete on the basis of execution…until it finds its next blue ocean. But what is that? It’s tempting to point to the Vision Pro. AR/VR headsets are not new, but then, neither were smartphones or portable music players. The Vision Pro hasn’t shipped yet, so the jury’s still out. Let’s keep an eye on it. I have something else in mind. It’s actually related to one of Apple’s earlier \"blue ocean\" changes: the elimination of removable batteries. In the beginning, Apple’s laptops all used removable battery packs. Some even let the user pull out the floppy-drive module and replace it with a second battery. Starting in 2009, Apple began to phase out removable batteries across its laptop line in favor of batteries that were sealed inside the case and were not user-accessible. The iPod and the iPhone arguably started this trend by never including removable batteries to begin with. (The iPhone defied so many other norms that the sealed battery was less remarked upon than it might have been, but it was still noted.) The upsides, which Apple touted, were many: lighter weight, smaller size, better reliability, longer battery life. We are still reaping these benefits today, and we Apple fans rarely question them. Today, predictably, non-removable batteries are a red ocean in many product categories. They are the norm, not an innovation. When thinking about Apple’s next blue ocean, it’s tempting to ignore past innovations. Technological progress seems like an arrow pointing in only one direction, never turning back. But I just can’t shake the idea that a return to removable, user-accessible batteries has now become a blue-ocean opportunity just waiting for Apple to seize it. Follow me, here. Yes, sealed batteries still offer all the same advantages they always have. And, yes, a return to removable batteries would bring back all their problems: increased size and weight, increased risk of liquid and dust ingress, decreased aesthetic elegance. But some things have changed in the past couple of decades. Battery technology has improved, and Apple has moved its entire product line to its own silicon chips that lead the industry in power efficiency. There’s more headroom than there has ever been to accommodate a tiny bit more size and weight in Apple’s portable products. That’s still a step backwards, right? But there are several countervailing forces, one of which is rapidly increasing in importance. The first is the fact that, as noted earlier, removable batteries are now a blue ocean. Apple would be alone among its biggest competitors if it made a wholesale change (back) to removable batteries in any of its product lines. Second, people still crave the advantages of removable batteries that were left behind: increasing battery life by swapping batteries instead of using a cumbersome external battery pack, inexpensively and conveniently extending the life of a product by replacing a worn-out battery with a new one—without paying for someone else to perform delicate surgery on the device. Finally, related to that last point, worn-out batteries are an extremely common reason that old tech products are traded in, recycled, or replaced. Removable batteries are an easy way to extend the useful life of a product. This leads to less e-waste, which is perfectly aligned with Apple’s environmental goals as 2030 approaches. Of course, longer product lifetimes means fewer product sales per unit time, which seems to run counter to Apple’s financial goals. But this is a problem that can be solved using one of Apple’s favorite financial tools: higher product margins. If Apple can actually make products that have a longer useful life, it can charge more money for the extra value they provide. It’s easy to think of product ideas that run counter to accepted wisdom; it’s harder to think of the right one. Sometimes a blue ocean is free from sharks simply because there are no fish there. But I think this idea has merit. I am not making a prediction, but I am making a suggestion. I know some of you remain unconvinced. How can a removable battery be easy to swap and yet also be sealed against the elements? Won’t removable batteries ruin the appearance of Apple’s existing products by adding unsightly cut lines? Won’t they become unacceptably large and heavy? How can structural integrity be maintained with a giant hole cut out of the product frame? What about the risk of fire due to faulty battery connections or battery packs coming in contact with something metal in someone’s pocket? The list of problems goes on and on. Innovation is never easy, but since when has Apple shied away from a challenge? As the industry leader in consumer-electronics design and manufacturing, Apple is best positioned to overcome the obstacles and reap the benefits of removable batteries. There’s no question it will be difficult, but if done well, it will undoubtedly be a hit. And as the company that led the transition away from removable batteries, it’s only fitting1 for Apple to be the one to bring them back. ← PREVIOUS",
    "commentLink": "https://news.ycombinator.com/item?id=38062297",
    "commentBody": "Apple&#x27;s Blue OceanHacker NewspastloginApple&#x27;s Blue Ocean (hypercritical.co) 244 points by hutattedonmyarm 20 hours ago| hidepastfavorite216 comments ttfkam 15 hours agoTwo things I&#x27;ve been waiting on for years:• MST (DisplayPort daisy chaining) in MacOS. The hardware has supported it for over a decade. The OS is the weak link here. It&#x27;s the difference between spending $75-$300 for a dock in addition to the cables and just connecting the monitors together along with a single cable to the first monitor.• Non-soldered storage. Seriously. Storage is the most likely component to fail. SSDs only have so many write cycles.• BIOS on a separate chip. To make matters worse, with the introduction of the T2 chip, the BIOS is stored on the SSD as well. This means if the SSD fails, you don&#x27;t just lose your data; you have an expensive brick. You can&#x27;t even boot to external drive anymore if one of the two SSD chips fails.• Safer SSD chips. If a cheap capacitor fails on newer Macs, 13V gets shorted straight to the SSD. The SSD commonly doesn&#x27;t survive this. And since the BIOS is on the SSD now… Literal ten cent part blows up your multi-thousand dollar laptop with zero warning.https:&#x2F;&#x2F;youtu.be&#x2F;RYG4VMqatEY reply bilalq 9 hours agoparentThe lack of MST support caught me by surprise. Six years ago, I intentionally bought an expensive monitor with USB-C and daisy-chaining support as the second screen so that the monitor itself would be able to function as my dock. Lo and behold, it worked fine on Windows but not on MacOS. Had to buy a dock separately and now have one more thing cluttering my desk.I spent so long troubleshooting and trying to figure out why it didn&#x27;t work before I stumbled on this article[1].[1]: https:&#x2F;&#x2F;sebvance.medium.com&#x2F;everything-you-need-to-know-abou... reply rekoil 6 hours agorootparentIt&#x27;s such a frustrating missing feature. reply Dig1t 6 minutes agoparentprev>Non-soldered storage. Seriously. Storage is the most likely component to fail. SSDs only have so many write cycles.One thing to note is the quality of Apple’s storage is above and beyond anything else you can buy. They have teams at every level of the storage stack and have an amazing focus on quality. From individual chips all the way up to the filesystem, all of the software is customized to extend the lifespan of the device. They do wear-leveling so the larger the drive you buy with your device the longer the device will last, but honestly the drives they come with will last much longer than 99.9 of people will ever actually use a Mac. reply 1letterunixname 12 hours agoparentprevApple devices aren&#x27;t engineered to last; they&#x27;re engineered to be manufactured, sell new, and sometimes sell expensive repairs by them.Also, NVIDIA cards in eGPUs and Thunderbolt (arm64) aren&#x27;t supported.The best solution is either don&#x27;t use Apple, or have a machine under warranty and very good backups.Complaints aside, the Anker 777 dock does 5K-8K DP over USB-C, 1 GbE, 100w charging, 4 USB-A and more and works with m1 and m2 MBPs. Add a quality magnetic USB-C connector, and it&#x27;s \"MagSafe\" docking to a monitor, power, and accessories with one cable. I&#x27;m in the camp of 1 giant 49\" monitor, with occasional AirPlay to a nearby Apple TV 4K on an 85\" TV. reply audunw 5 hours agorootparentI have had many Apple devices since the 2nd gen iPod, and they have all lasted a very long time compared to my other devices. All my laptops back to my 15” PowerBook is still working. They have fixed a faulty GPU on a 4 year old laptop for free, even though I had opened the laptop and changed thermal paste. (Known manufacturing issue with that GPU, but still impressive)They have made mistakes. Like the battery in my current 2015 MBP is too hard to replace. And I avoided upgrading for a long time due to the known issues with the keyboards. But it seems like they generally correct when making mistakes like that.I do agree that SSDs shouldn’t be soldered on though. Hopefully it’s one of the mistakes they’ll eventually fix. I kind of understand the motivation.. you can make it impossible to effectively steal a device, or access its contents. The device becomes very simple and robust in some ways. But they could come up with a good compromise.Like, sure, keep the concept of not having an SSD controller on the drive, and firmware on the SSD. But sell replacement SSDs with the firmware and a recover OS preloaded. One that lets you provision the new drive with the SOC through your iCloud account. Depending on the on-chip storage and whether it’s fuse&#x2F;EPROM-based or flash, the number of possible drive replacements might be limited. But that’s an OK compromise. reply nl 11 hours agorootparentprev> Apple devices aren&#x27;t engineered to lastThis doesn&#x27;t match either my experience, the experience of others I know or the good resale value Apple devices continue to have. reply ironick09 12 hours agorootparentprevAll of my apple devices have lasted multiple (4+) years. The only time an apple device hasn’t is because I broke it. reply PakG1 11 hours agorootparentI suppose the interesting question is whether this is true of the newest devices or not. My wife&#x27;s MacBook Pro lasted 11 years. It finally died this year. Can I expect the MacBook Pro that&#x27;s replacing it to last 11 years too? Only time will tell. Hope so. reply graphe 9 hours agorootparentprevSome of us remember our 2008 MacBook pros GPUs dying and apple refusing to fix it. Their electronics have, however never let me down. reply AdamN 7 hours agorootparentprevThat&#x27;s just wrong - Apple devices are much more hearty than the competition (Lenovo as a possible exception). reply stouset 12 hours agorootparentprevCan you explain why Apple devices in general maintain a higher percentage of their resale value for longer than their competitors’ counterparts? reply ffgjgf1 3 hours agorootparentOne (but certainly not the only) reason is that Apple rarely discounts their products and even if they do it’s not by that much.It’s not that hard to find a high-end&#x2F;$2000+ PC laptop for 40% or so off 1-2 years after its release, not so much a macbook. Apple is still selling refurbished M1 airs for $849.00 from 2020 ($999 was the price on introduction) reply luckydata 10 hours agorootparentprevonly laptop I know carved from a single piece of aluminum. not the only reason but for sure that one is a good one. No other laptop feels as solid and I don&#x27;t understand why nobody else does it. reply vladvasiliu 8 hours agorootparentI haven&#x27;t had any of the recent MBPs, but my 2020 HP EliteBook&#x27;s main body looks similar to my 2013 retina mbp, which already had the \"unibody\" construction. If also feels quite solid when I hold it by one corner while open. The lid does feel somewhat flimsier, though, especially the hinge. reply thfuran 9 hours agorootparentprevMilling a case from a block must be far more expensive that folding a few sheets, right? reply mojo74 6 hours agorootparentprevI&#x27;ve got a 14 year old imac that says otherwise reply andromeduck 13 hours agoparentprevMost people don&#x27;t write terabytes per day and the ones who do can just double their storage. reply javchz 13 hours agorootparentBut they do, specially in low RAM systems, as the SSD becomes like a backup ram to juggle extra information. reply graphe 11 hours agorootparentI remember modding osx Yosemite to run the swap in the ram when I had an SSD since I was so worried about it, not sure if it still does this but with the infrequently of negative problems and the fact that one of my friends used a 2gb MacBook air 2009 until 2017 made me realize it probably doesn&#x27;t matter. reply pier25 3 hours agorootparentprevThat&#x27;s user error reply andromeduck 12 hours agorootparentprevIf you&#x27;re swapping a dwpd. reply webmobdev 12 hours agorootparentprevMore so when the RAM remains limited on Macs as it too is integrated with the CPU and hence is non-upgradable. This is even worse than soldered SSD, as we can still make an attempt to replace the SSD chips with new ones with careful soldering, but nothing can be done about the RAM. These deliberately irreparable new Macs are just shitty products. reply Savely 9 hours agorootparentYou know you can buy other products, right? There’re plenty of computer manufacturers that use discrete modules. reply ffgjgf1 3 hours agorootparentTo be fair not that many if you want alternative to the Air and size&#x2F;weight is a priority. Also.. I’m not sure what are you trying to say? That there is something wrong about criticizing Apple’s design choices? replygraphe 12 hours agoparentprevWith a large 4K screen, I&#x27;m not seeing any benefit for MST, and studies have shown it decreases productivity after 2 screens. The other problems are simply fixed with using iCloud and treating your laptop as a disposable, which many laptops have been designed as. If you use the MacBook add intended and invest in apple care it&#x27;s unbeatable. reply faeriechangling 8 hours agorootparent“Studies show” cannot possibly account for all workflows. The most extreme monitor users I saw were security personnel who used them to… monitor things. Their office looked very cyberpunk being utterly littered with corporate desktops and cheap TVs and LCD monitors. reply ed_mercer 12 hours agorootparentprevAny source for said studies? As an engineer I often find my current 2 external monitors limiting and wish I had four. reply zoky 11 hours agorootparentIt never ends. I have 4 monitors and sometimes wish I had 5 or 6. If I could physically fit more monitors on my desk, I would. reply graphe 11 hours agorootparentprevNYT in 2014, (personal experience too). https:&#x2F;&#x2F;www.nytimes.com&#x2F;2014&#x2F;03&#x2F;20&#x2F;technology&#x2F;personaltech&#x2F;s... this advocates for one monitor https:&#x2F;&#x2F;hackernoon.com&#x2F;why-i-stopped-using-multiple-monitors... the tl;dr is that mutiple screens mean more distractions, and some tasks are better with 2 monitors but the studies don&#x27;t indicate it&#x27;s universal. reply nl 11 hours agorootparentThese aren&#x27;t studies, just anecdotes, and the actual study quoted in the NYT shows the opposite:> One study commissioned by NEC and conducted by researchers at the University of Utah showed that people using a dual-display machine to do a text-editing task were 44 percent more productive than those who used a single monitor.I think it&#x27;s fair to say that any research from 2014 isn&#x27;t the most relevant now. Both screen size and (importantly) software has changed to better support both multiple screen usage as well as large screens.The argument for single screens in the NYT is mostly that it reduces distractions:> But for most people, the time spent juggling two windows or scrolling across large documents isn’t the biggest bottleneck in getting work done. Instead, there’s a more basic, pernicious reason you feel constantly behind — you’re getting distracted.This seems to indicate they were comparing a maximized window on a single screen vs non-maximized windows on multiple screens, and probably in the days before modern notifications on desktop OSs.Based on this it is fair to say more research is needed, but it is inaccurate to claim that studies support the idea that one monitor is better. reply graphe 11 hours agorootparentRealistically where would you position these monitors? Ergonomically there aren&#x27;t many great solutions for any extended use especially once you go up to mutiple large monitors. Tilt your head in those directions and see how long you maintain them comfortably. If you think modern notifications are less distracting I&#x27;ll respectfully disagree. reply klohto 10 hours agorootparentRespectfully disagree all you want but don’t come here claiming studies that don’t exist. reply nl 9 hours agorootparentprev> Realistically where would you position these monitors?I have a 34\" main monitor positioned directly in front of me, a 24\" in vertical orientation I use mostly for multiple terminals and my MPB screen below the 34\".I don&#x27;t think this is an unusual setup.> Tilt your head in those directionsThis applies to large single monitors too. I think (hope?!) most people have a setup where their main work is right in front of them.> If you think modern notifications are less distracting I&#x27;ll respectfully disagree.No I&#x27;m saying they are more distracting, so reduce the relevance of old articles claiming a single monitor reduced those. reply graphe 9 hours agorootparentAre they all in front of you? They sound like they are. Do you find that the positions are comfortable? I cannot see a single article that claims mutiple monitors are ergonomic beyond 2, and most only try to suggest one. https:&#x2F;&#x2F;ergo.human.cornell.edu&#x2F;ergoguide.html this article might not like the positions you use, but they&#x27;re just suggestions that I read and found useful. reply mdekkers 11 hours agorootparentprevCome on, those are not “studies” - they are just the opinions of some random people, and they carry no more or less weight than, for example, my opinion, which is “you can pry my 4 x 27” screens out of my cold, dead, hands.”The NYTimes article is actually explicit about that:> Unlike monitor makers with their multidisplay studies, I have no research proving you’ll find as much benefit from a single monitor as I did.In other words “there are actual studies proving multimonitor setups enhance productivity, but Big Screen(tm) paid for them so they must be wrong” which has no basis in science at all.Also:> “Two monitors are a double-edged sword,” said Gloria Mark, a professor who studies workplace distractions at the University of California, Irvine. Ms. Mark hasn’t specifically researched how second monitors might affect focus, and when she recently had a chance to work at a two-monitor machine, she felt that it did make some of her tasks easier. “But most people have their email up on the second screen, and of course, when anything comes in, it’s a great source of distraction,” she said.So the only actual scientist in all of this actually said “hey, this is making me more productive, unless I fill the screens with distractions”The tl;dr is that people need to set up their workspace to enhance their flow and focus, and reduce distraction to be productive. The amount of screens is about as relevant to that as the weather outside. (“Hey, the sun is shining and the birds are singing, it is a beautiful day outside, let’s go out!”). As per your own conclusion (“the studies don’t indicate it’s universal” - setting aside the fact that there _are_ no studies) It is not universal.Trying to whitewash Apple’s lack of DP Daisychaining support as “You don’t need this anyway, Apple simply cares about your productivity!” Is silly. reply graphe 11 hours agorootparentMy point was that Apple probably don&#x27;t care to cater to these use cases, and see them as niche. I know 0 people who use more than two monitors on any OS. reply onion2k 9 hours agorootparentEvery person in my company has a laptop screen and two monitors on their desk, including devs, product, managers, infra, admin... Literally everyone. The only people who don&#x27;t use them are senior leadership because they&#x27;re rarely at their desks. reply mdekkers 10 hours agorootparentprev> I know 0 people who use more than two monitors on any OS.Three in this thread alone, and shifting the goalposts from “studies show it is bad” to “I don’t know anyone with multiple monitors” or “It is tiring to move your head around all the time” indicate you are not debating this in good faith, so I am done with this chat.Have a great day! replys17tnet 9 hours agorootparentprevThe productivity after the second screen decrease because the software sucks at support those configurations.With specialized software ( multi track AV) and&#x2F;or ad hoc setup ( e.g. deeply tuned Linux) the more the screens you throw at it, the better. reply graphe 9 hours agorootparentVirtually perhaps, physically there&#x27;s a limit. https:&#x2F;&#x2F;www.viewsonic.com&#x2F;library&#x2F;business&#x2F;monitor-ergonomic... ViewSonic doesn&#x27;t account for more than one monitor for an ergonomic workstation, and I&#x27;ve never seen it done well myself. reply brailsafe 10 hours agorootparentpreviCloud is simply not a replacement for onboard storage reply AdamN 7 hours agoparentprev* Just use TB monitors and daisy chaining works fine* Nothing to add.* Hardware enclave is a requirement for most corporate&#x2F;government computers so you&#x27;re just comparing two different classes of computer. All the enterprise Windows machines also do this.* Same as above reply bogantech 6 hours agorootparent> * Just use TB monitors and daisy chaining works fineNot everybody has a zillion dollars to spend on expensive thunderbolt displays and they shouldn&#x27;t have to when the Displayport standard (and other operating systems) support daisy chaining. reply Terretta 20 minutes agorootparent> when the Displayport standard (and other operating systems) support daisy chainingIt doesn&#x27;t support it, exactly, it supports a compressed image in each of the multiple streams transported, which can introduce quality problems when doing the production work people use higher end Macs for.\"the combined data rate requirements of all the displays cannot exceed the limits of a single DP port\" -- https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;DisplayPort#Multi-Stream_Trans...Arguably, compared to TB ports transmitting a full quality image to each screen, this could be \"unexpected behavior\". reply lxgr 11 hours agoparentprev> Storage is the most likely component to fail.Got any sources for that? I find that hard to believe.> MST (DisplayPort daisy chaining) in MacOS. The hardware has supported it for over a decade. The OS is the weak link here.This is indeed annoying, but with USB4&#x2F;Thunderbolt support becoming more common in monitors, I believe this is going to be less of an issue going forward. reply tverbeure 9 hours agorootparentThe only reason I was able to use my 2012 MacBook Pro 15 as my daily driver for 11 years, is because I was able to replace 2 failed non-soldered SSDs. reply pier25 3 hours agorootparentThose were old SSDs with I presume much lower capacity than modern drives reply vishnugupta 9 hours agorootparentprevData point of one. Last 20 years storage has not failed on me across close to a dozen laptops I’ve owned across various brands.So even I get puzzled whenever I see “storage is the most likely component to fail”. Maybe I just got lucky? reply Moldoteck 9 hours agorootparentI think it&#x27;s more about ssd&#x27;s with limited cycles+ the fact that with smaller RAM, swap can nuke those ssd&#x27;s pretty fast if you go beyond ram capacity reply smcl 8 hours agorootparentprevIf you&#x27;re replacing your laptop every 1.5 years then you&#x27;re probably not likely to encounter any part failing. reply vishnugupta 3 hours agorootparentThat’s a fair point, if I recall correctly I had three laptops for about 5 years each. And about 7 over 5 years period as I switched jobs and laptops frequently. reply thombat 8 hours agorootparentprevAnd if a man mates with nine women he&#x27;ll be holding one baby this time next month? With both electronic devices and gestating females concurrency is common. reply smcl 8 hours agorootparentNo, you don&#x27;t understand. SSDs begin to encounter problems over time after some number of read&#x2F;write cycles. This is entirely expected and when one sector has issues it gets remapped to one of some spares that are built into the drive. Once those are exhausted it&#x27;s a matter of time before you have an unusable SSD and, if it&#x27;s soldered to the motherboard, an unusable laptop.A sister comment to mine referred to this too: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38066645 reply thombat 6 hours agorootparentBut where did they say they only used each device for 1.5 years? That seemed like your assumption based on the quoted dozen laptops across twenty years; I certainly have a number of devices concurrently, with the oldest now being 14 years (still working though only on a power supply as the battery is badly degraded). That said I also strongly prefer a replaceable drive, but more because I don&#x27;t want to buy the capacity at today&#x27;s price that I&#x27;ll only truly need in a few years time, if ever. reply smcl 6 hours agorootparentIt’s a pretty fair assumption, I think. It’d be a really unusual if they kept buying laptops and somehow continued using all or some of them at the same rate. replyraverbashing 8 hours agorootparentprevSSDs and batteries are the only components (as far as I remember) that have a \"guaranteed\" cycle lifetime. Or in another words, a \"very likely after this point\" failure threshold. reply lxgr 4 hours agorootparentI completely agree on batteries (and I believe this is in fact why most devices are being replaced was what I was getting at!), but where is that point practically for SSDs?With typical usage, it should hopefully be out many more years than the laptop gets security updates. reply raverbashing 3 hours agorootparent> With typical usage, it should hopefully be out many more years than the laptop gets security updates.Well, that&#x27;s a good question, isn&#x27;t it? Especially when you&#x27;re selling memory-limited hardware and shoving the swap in your SSD(And using it past the availability of security updates should be the user&#x27;s prerogative, not Apple - you can run Linux on the ARM laptops) replyChuckMcM 19 hours agoprevThe short version is: \"Wouldn&#x27;t it be disruptive if Apple went back to replaceable batteries?\" but the author stopped short of where that leads.One of the things that doable \"now\" that wasn&#x27;t doable \"then\" is wireless charging. I love that I can put my phone on a pad next to the bed at night and it charges, pick it up and there is no trailing wire to unplug, put it down and there is no wire to find and plug in. This is a big improvement in my user experience.Another of the things that have moved us forward is that power efficiency has gone up dramatically, as a result a smaller battery can give the same \"run time\" as a large battery of old without the bulk associated with the larger energy storage capacity.Why not combine them?Why not no battery in the device? Seal it against the elements. Then put in a pocket where a battery that is a wireless \"charger\" can drop into a slot on the device and provide the power. Current demands on a modern device are low enough that you just go wireless all the time for main power. Now your device takes a sealed \"toaster pastry\" sized unit that looks innocuous, but slide it into the slot and poof the device powers up, put it on a recharging mat and it starts charging up itself.Now you have no exposed terminals to \"short out\", no worries about the battery in your device becoming a \"pillow of doom\"[1]. And you can carry a couple of extras if you&#x27;re going to be away from power for a while.You get all the benefits of replaceable batteries and none of the downsides with the possible exception of a \"slot\" in your device that looks funny when there isn&#x27;t a battery in it.I totally should have patented this :-)[1] Just Google it :-) reply esperent 11 hours agoparentWireless charging wastes a lot of energy. I&#x27;m not sure of the exact figures but I recall around 50%. Not a huge deal, on a personal level, for a plugged in charger (although if everyone in the world starts doing this it&#x27;ll be more of a problem).However wireless charging from a battery pack is not ideal because the battery will have to be bigger. I already feel my phone is too big to be comfortable in my pocket, and I know it&#x27;s even more of an issue for smaller people&#x2F;women&#x27;s clothing with tiny pockets.It&#x27;s an interesting idea though. reply buildbot 18 hours agoparentprev> One of the things that doable \"now\" that wasn&#x27;t doable \"then\" is wireless charging. I love that I can put my phone on a pad next to the bed at night and it charges, pick it up and there is no trailing wire to unplug, put it down and there is no wire to find and plug in. This is a big improvement in my user experience.The palm pre and several early android phones had both removable batteries and wireless charging. The back panel just had pogo pins for the coil to transfer power. reply FractalParadigm 17 hours agorootparentIn many cases the coils were integrated into the casing of the battery, and the back panel of the phone was thin enough to transfer sufficient power through. reply silisili 19 hours agoparentprevThat&#x27;s pretty close to how power tools work, minus the wireless charging of course. My first concern would be warmth, my phone always warms up when wireless charging. Doing something CPU intensive would probably get the device blazing.My second concern would be size - is the total package going to get a lot bigger here? If we forgo the pocket and just use magnets at each corner maybe it gets slimmer, but can it be about as slim as they are today?If we could overcome those two hurdles, I&#x27;d be a huge fan of the idea. reply ChuckMcM 19 hours agorootparentThere is a tradeoff here which might mislead. That is that when you&#x27;re wirelessly recharging a battery \"good\" is defined by \"charges in a short time\" which means a lot of current and thus a lot of heat. When operating a device \"good\" is defined by \"runs a long time\" which means minimal current and thus little heat.So before we could dismiss the idea, we would really need to run the experiment of \"running\" via wireless power to see how the current requirements in that state would be reflected in device heating (or not). I agree with you though that if the answer was \"always smoking hot\" then it is a non starter.As for size, the \"wireless\" part is really really thin (a loop antenna). Battery size is a function of how much electrolyte it can carry and LiOn batteries are about 0.5g&#x2F;cc and 250Wh&#x2F;kg (or .25Wh&#x2F;g) iPhones are around 12Wh so about 48g of battery which is 96cc of Lithium. Call it 100cc and you&#x27;re looking as a \"7.8 x 15 x 1\" cm \"battery card\" (order of magnitude approximation based on that math and rough measurements of my iPhone 13SE which is a smallish phone)I like the idea of magnets but I don&#x27;t like the idea of the battery being \"jostled off\" my phone in my pocket and so effectively turned off when I think it should be on. So I think that would take some design work to get right. reply punkybr3wster 10 hours agorootparentModerate super capacitor for interstitial periods? reply judge2020 19 hours agorootparentprevMagSafe&#x27;s auto-alignment really helped the efficiency of Wireless Charging, supposedly 75% efficient with MagSafe (based on the cable pulling 20w and phone supposedly accepting 15w) versus 50% for regular Qi charging. reply Reason077 16 hours agoparentprev> \"Why not no battery in the device?\"How about a nuclear battery, aka radioisotope thermoelectric generator (RTG)? This would be sealed in (carefully!) and would last the lifetime of the device, with no need for charging, ever. Would need special steps&#x2F;handling to ensure safe disposal at end of product life, however. reply ChuckMcM 13 hours agorootparentThis is challenging because you probably don&#x27;t want a phone that is hot all the time. There is however a very interesting technology which uses beta radiation and what are essentially \"solar cells\" to generate electricity directly[1]. Basically you could paint some Cesium 137 on to a solar cell and it would generate power 24x7![1] Beta Voltaics a new kind of nuclear battery -- https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Betavoltaic_device reply Dylan16807 9 hours agorootparentCurrently single digit efficiency so it&#x27;s still going to be unacceptably hot. reply Dylan16807 15 hours agorootparentprevYou can&#x27;t really have more than 4-5 watts of heat in a phone, so even with the friendliest heat source don&#x27;t expect more than a quarter watt of electricity. reply M3L0NM4N 15 hours agorootparentprevWhat about a fusion reactor, generating its own hydrogen molecules to power nuclear fusion through electrolysis from the water vapor in the air.There isn&#x27;t really a theoretical limit to how small a fusion reactor can be, although clearly this would not achievable for a long time. reply eru 12 hours agorootparentIf you want to go totally crazy, you can use a black hole as a power source. The laws of physics don&#x27;t give you a minimum size for them either. However for black holes the smaller they are, the more power they emit in terms of hawking radiation. reply thfuran 9 hours agorootparentThe power scales to such an extent that a black hole light enough to be in a phone is just an explosion. reply eru 8 hours agorootparentYes. I tried to find the calculations, but couldn&#x27;t find them. Google Bard to the rescue (and cutting out the actual calculations she gave):> Therefore, a black hole needs to be at least 9.49 × 10^{22} kilograms in mass to emit 100 watts of Hawking radiation. This is about the mass of the Moon.No clue whether those numbers check out.EDIT: poking bard a bit more gives this correction:> However, for a black hole to emit 100W in gamma rays, it would need to be very small, with a mass of only about 10^22 kilograms. This is much smaller than the Moon, which has a mass of about 10^25 kilograms.But poking more and more makes me less and less confident, because bard seems to believe that bigger black holes emit more than smaller black holes. reply Dylan16807 9 hours agorootparentprevFusion is silly but at least possible. Unless you have an idea for keeping the black hole inside the phone? reply eru 8 hours agorootparentYes, I do: use a bunch of carefully controlled magnets to spin your block hole in a circle inside the phones.Black holes can hold charge, and thus electromagnetism works on them.(Not really useful for a phone, of course. But manipulating black holes like that is not any harder than manipulating an equally massive lump of ordinary matter.) reply SV_BubbleTime 12 hours agorootparentprevI’m pretty sure there was a Rick and Morty close to this. reply ungamedplayer 14 hours agorootparentprevTotally planned obsolescence. reply Savely 9 hours agorootparentprevImagine Samsung battery incident on another level! reply albertgoeswoof 19 hours agoparentprevWireless power is too inefficient for this to make sense. You’d be throwing 30% of the battery capacity to the wind reply bradgessler 18 hours agorootparentYou could have low profile metal contacts between the battery case and the phone to achieve full efficiency. reply silisili 14 hours agorootparentEvery phone with moto mods were built this way. The battery mod was probably the most popular.They didn&#x27;t sell well, apparently. reply amelius 17 hours agorootparentprevHow do you keep them clean? reply ungamedplayer 14 hours agorootparent$45 apple cleaning cloth. reply pjerem 19 hours agoparentprevYou really don’t have to go wireless to protect your device&#x2F;battery against the elements. In fact, most smartphones today are totally waterproof while still being charged by a good old cable.It’s also pretty easy to design a connector with exposed pins that are totally inoffensive until something real is exposed. In fact, modern USB charging already works like this : a charger will not send anything over 5v x 150mA before having negotiated with the device to know what it needs. reply Thorrez 19 hours agoparentprevYou&#x27;d still need some in-device battery to keep the phone from fully powering off every time you change the outside battery. I think people want their phones to not have to fully power off all the time. reply lbotos 18 hours agorootparent30min of standby capacity for an internal lil battery, external poptarts galore? I don&#x27;t hate it.It&#x27;s kind of an interesting play because apple could make a super thin phone that has 30 min battery life and then a few different size pop tarts with different capacities. You want 3 days, get the mondo brick. reply bradknowles 13 hours agorootparentHow is that materially different from what Apple already has? reply Haemm0r 11 hours agorootparentApple can charge the same prize for the phone and upsell you on the battery :-) reply bradknowles 9 hours agorootparentAgain, how is that different from the current situation? reply windowsrookie 11 hours agorootparentprevInterestingly Apple&#x27;s old PowerBooks had this. They had a very small internal lithium rechargeable battery. So you could close the lid(making the PowerBook go to sleep). Then you could swap the main battery without having to shut down the laptop. It could power itself off the internal battery (in sleep mode) for a few minutes. reply threetonesun 13 hours agoparentprevWasn’t a similar but worse version of this common in laptops 15ish years ago? You often had the option of running two batteries instead of 1 and a CD drive because they had interchangeable slots. reply hasoleju 8 hours agoparentprevI googled pillow of doom but I still have no idea what you meant by it. I only find information about real doom themed pillows.Did you mean a damaged, blown up battery pack? At least that&#x27;s what I expected to find. reply joshstrange 7 hours agorootparentYou are correct. “Pillow of doom” is sometimes used to refer to bulging&#x2F;swollen batteries. There is subreddit named “SpicyPillows” that’s centered around the same concept. I assume it’s due to the pillow shape a swollen battery takes. reply rzzzt 19 hours agoparentprevAKA spicy pillows, there is a subreddit with the same name dedicated to those puffed up bastards. reply todd3834 19 hours agoprevI really enjoyed the first half talking about how Apple and Nintendo followed a blue ocean strategy. Then the second half ranting about removable batteries felt totally out of place. I’m not sure I buy the blue ocean strategy of that, although well written. reply jldugger 8 hours agoparent> I really enjoyed the first half talking about how Apple and Nintendo followed a blue ocean strategy.Let me fix that for you.Blue ocean is roughly the idea of inventing new markets. While it might apply to Nintendo, that&#x27;s really a stretch and I view it as product differentiation in a highly entrenched market where Sony and Microsoft are clear sharks in the water.If you look at Apple&#x27;s product and marketing history, blue ocean has not applied in two decades. The iPod was hardly the first MP3 player -- Diamond Rio was already in that space. There were several smartphones in the market before apple shipped iPhone, people were speculating on when for years before it was announced. Smartwatches supported android 2 years before Apple Watch Series 0 shipped. HomePod shipped 5 years after the first Amazon echo. What Apple does is wait for other people to prove out the market, and then produce an expensive high end version. This is an effective strategy that captures a lot of high margin & affluent demand, but it&#x27;s very clearly a red ocean strategy.A blue ocean strategy doesn&#x27;t have to shout \"Think Different,\" your product uniqueness is obvious and usually confusing. A red ocean strategy means focusing on margins, inventory, and balancing product differentiation versus convention. It means keeping your product secret until the big announce and suing competitors who copy you. At one point Tim Cook was calling himself the Atilla the Hun of operations, and was quoted in articles as saying \"inventory is the root of all evil.\" reply dangus 18 hours agoparentprevI agree. It made no sense after the excellent first half.Apple has designed the Mac to become obsolete in approximately 10 years. That’s when you lose official OS support. And yes, you can get your battery serviced but nobody’s going to buy a $200 battery for a laptop worth $500. Adding it back wouldn’t be a blue ocean, it would just be Apple ceding profits to nobody.Apple’s blue ocean is stacking ecosystem benefits. If you have an iPhone it makes more sense to own a Mac or an Apple Watch. If you own a Mac or Apple Watch it makes more sense to own AirPods. If you own AirPods it makes more sense to own an Apple TV. reply jen20 13 hours agorootparentI don&#x27;t disagree with anything you&#x27;ve written, but (somewhat) regularly buy new batteries for my Lenovo X220, at about the same price to value ratio. reply Animats 20 hours agoprevThe future is batteries with more charge cycles, not replaceable batteries. The solid state battery people are claiming 10,000 charge&#x2F;discharge cycles. If they can achieve that, it&#x27;s 27 years of battery life. The case will wear out first. reply lopis 5 hours agoparentActually, if the EU gets its way, a future with mandatory removable batteries might be the only possible future. And I&#x27;m so looking forward for it. Next up should be mandatory recycling of batteries by the manufacturers. reply rollcat 3 hours agorootparentI think, if given an exclusive choice between the two, I would take (much) more reliable batteries over user-replaceable batteries.10k cycles (~27y) sounds absurdly good - I think 80% of original capacity by 10y would be more than adequate. Basically you never need to replace the battery throughout the useful life time of a device. reply KennyBlanken 19 hours agoparentprevLithium ion batteries that can handle a thousand to several thousand charge cycles and only see 80% reduction in capacity have been available for ten years.My 2013 Macbook Pro has just such a battery, rated for 80% capacity after 1000 cycles, and it lasted over 6 years before the battery&#x27;s internal resistance rose enough that heavy load would cause a brownout and the machine to force sleep.Yet they are not in widespread use; most devices have prioritized capacity&#x2F;weight&#x2F;size over longevity, Apple included. My current M1 has lost 10% of its capacity after just 120 cycles and less than a year of ownership, even using a utility that allows you to set a limited maximum charge level to preserve the battery. And the battery is less accessible, less replaceable.Battery companies and device manufacturers don&#x27;t care. There&#x27;s no incentive for anyone involved and consumers have gotten used to replacing devices every few years.Solid state batteries with 10k charge&#x2F;discharge cycles are never going to happen for the same reason incandescent bulbs are purposefully manufactured by every single lightbulb manufacturer to fail when they figured out a hundred years ago how to make them last forever.We need something like a e-waste import duty, tax, fee, or &#x27;recycling deposit&#x27; on devices with non-replaceable lithium ion batteries. reply PaulKeeble 18 hours agorootparentIts a bit of a myth for ever lasting bulbs, its more complicated than that. The life time was a trade off of colour and brightness. If you made them very red shifted and quite dim then there are bulbs that are very old still around, but they don&#x27;t produce much light and never did. The harder you drive the filament the better the light properties but the quicker it died. The industry choose a point for trade offs as a standard. You can watch about the history of it on Technology connections. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zb7Bs98KmnYSaying that the Dubai Philips LED bulbs really do last a lot longer since they have twice the filaments and run the filaments a lot less hard as a result (as well as being more efficient). It is possible nowadays to make an LED that wont fail anytime soon although LEDs are already much better than incandescents in that regard but there are ones that will likely survive your lifetime available at a higher price but only in Dubai. Most LED bulbs are designed to fail sooner, but they are also cheaper.Those 10k recharge batteries are absolutely coming and we will have them in a few years time, li-ion as it stands today will simply be obsolete. reply SoftTalker 16 hours agorootparentI&#x27;d be happy with an LED bulb that lasted a year. I haven&#x27;t yet found one that can do that reliably.Remember that 60W incandescent bulbs costing $0.25 used to be available that met that goal. We&#x27;ve taken huge steps backwards on interior household lighting. reply postexitus 5 hours agorootparentYou likely have an issue with your wiring. LED bulbs last much longer on average on a a good circuit - but they are less tolerant of spikes and drops in voltages, thus circuit, switch, wiring quality comes into play.Would be much easier instead of embedding an AC&#x2F;DC converter inside each bulb that we now get standard 12V DC for lighting throughout homes - That would centralize the voltage sensitivity and allow larger circuits &#x2F; capacitors to regulate this. reply ruggeri 13 hours agorootparentprevJust joining in with others who report that I haven&#x27;t had any problems with LED bulb failures. I&#x27;ve used exclusively LED bulbs for at least 5 years now (maybe about 15 bulbs across my home), and none has ever failed on me.They do sometimes flicker when they&#x27;re in a traditional dimmer set at an intermediate level, even though the ones I&#x27;ve bought claim to work with a dimmer. That&#x27;s frustrating.But I haven&#x27;t had any outright failures.If it helps: I bought mostly SANSI bulbs off Amazon. reply wingworks 6 hours agorootparentDimming is complicated. Some switches do it differently to others. Your dimmable bulbs probably have fineprint somewhere saying which it supports. reply Reason077 16 hours agorootparentprev> \"I&#x27;d be happy with an LED bulb that lasted a year. I haven&#x27;t yet found one that can do that reliably.\"I do remember in the early days of LED bulbs, many were quite unreliable, especially dimmable ones. It was probably more the electronics in them failing more than the LEDs themselves?But now days LED bulbs seem much more reliable and I very rarely have to replace them. In fact the only bulbs I can recall replacing in the past 18 months living in my current house were some old CFL bulbs that hadn&#x27;t actually completely failed, but had gradually become a bit too dim.Certainly, now days, I need to replace bulbs far, far less often than in the old incandescent days where it was a regular chore in any house.(Also, now days I avoid using old-style dimmer switches, and even removed some in one house I lived in. Better to get a smart bulb with it&#x27;s own built-in dimming if you want it.) reply SoftTalker 16 hours agorootparentWhat brand of LED bulb do you buy?I&#x27;m consistently replacing one or two bulbs a month around the house. I don&#x27;t know if it&#x27;s the electronics or the LEDs; I don&#x27;t really care either. reply artimaeis 15 hours agorootparentJumping in to recommend Cree if they&#x27;re still around. Used to be able to get them at Home Depot here in the US.I started going Cree when I was renting 10 years ago, I&#x27;ve yet to have a single failure of the bulbs that I&#x27;ve drug with me to the place I live now. Have at least 25 bulbs currently in the house that are Cree LEDs. Their reliability actually has me frustrated at the current trend of lighting fixtures with integrated LEDs that I have 0 trust in. reply andrewjf 14 hours agorootparentI’m replacing all the ecosmart bulbs with crees. The normal 60w&#x2F;100w equivalents have been fine so far, but I have some 7500 lumen Cree ED37s that are trash, replaced 3 already out of ~7. Not sure what the deal is. Maybe my power at my house is bad or something. We blow through LEDs like crazy. They just start flickering. reply xnyan 15 hours agorootparentprevIkea and generic home depot LEDs have lasted 13 years of daily use with zero failures. Also, I&#x27;ve never seen that high a rate of LED failure. You may want to have your house checked out by an electrician for peace of mind. reply SoftTalker 13 hours agorootparentNo trouble with any other electronics in the house. Just the bulbs. reply AdamN 7 hours agorootparentProbably an old dimmer or something in the light circuit or you&#x27;re getting some weird off-brand LEDs - my LEDs last for years. replyusefulcat 12 hours agorootparentprevMost of the LED bulbs I&#x27;ve gotten have lasted quite a while (multiple years). I just recently replaced a front porch light that was about 10 years old. Granted it was controlled by a motion&#x2F;light sensor so it wasn&#x27;t on all night, but OTOH it was outside in the heat and the cold for 10 years.IME the worst are the ones that get really hot. I&#x27;ve had multiple (rather expensive) LED spotlights like that in my kitchen which never lasted more than a year or so. reply foobiekr 13 hours agorootparentprevFelt, GE, Philips. I have ~20 bulbs, including several on dimmers, in the house and have never had to replace a failed LED bulb in ten years.Are you sure your power isn&#x27;t bad in some way? reply csomar 10 hours agorootparentI am guessing you are about to find out once you replace these old light bulbs? reply mathieuh 13 hours agorootparentprevThat’s crazy to me, I couldn’t tell you the last time I had to change an LED bulb, certainly it’s at least five years. And I work from home in a part of the world where it’s very dark for half the year so they get a lot of use.They’re Philips Hue bulbs, a mix between LWB010 and LTW001, but even the cheap supermarket bulbs have lasted so long I also couldn’t tell you when I last changed them. Some of them have been in the house longer than I have. reply Reason077 16 hours agorootparentprev> \"Yet they are not in widespread use; most devices have prioritized capacity&#x2F;weight&#x2F;size over longevity, Apple included. My current M1 has lost 10% of its capacity after just 120 cycles\"A simple way to significantly extend battery longevity is to limit charge to 80% (only charging to 100% occasionally when you know you might need it, like a long day travelling).Unfortunately Apple doesn&#x27;t yet provide this option on most of it&#x27;s devices, other than the iPhone 15 line. But you can use third-party apps to do it on Macs. reply JodieBenitez 9 hours agorootparent> doesn&#x27;t yet provide this option on most of it&#x27;s devicesit has this though: https:&#x2F;&#x2F;www.macinstruct.com&#x2F;images&#x2F;2022&#x2F;optimized-charging.p... reply Reason077 7 hours agorootparentYeah, that doesn&#x27;t work very well in my experience. Not aggressive enough about stopping at 80% unless your routine is very regular. I want it to always stop charging at 80% unless I say otherwise. replyusefulcat 12 hours agorootparentprev> even using a utility that allows you to set a limited maximum charge level to preserve the batteryPlease tell me what that utility is--I&#x27;ve long wanted something like that but have yet to find anything like it.FWIW, I&#x27;ve been doing something similar with my phone, but manually. I found an unusually low current charger that charges the phone at a rate of ~5% per hour, and I almost always keep the battery level between 25% and 75%. So far the phone is 4 years old and iOS claims that the maximum capacity of the battery is still 92%. reply eviks 12 hours agorootparentAldente is one such app reply abhinavk 13 hours agorootparentprev> Solid state batteries with 10k charge&#x2F;discharge cycles are never going to happen for the same reason incandescent bulbs are purposefully manufactured by every single lightbulb manufacturer to fail when they figured out a hundred years ago how to make them last forever.Technology Connections has an interesting video on this. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zb7Bs98KmnY reply eru 12 hours agorootparentprev> There&#x27;s no incentive for anyone involved and consumers have gotten used to replacing devices every few years.If anything, I would have thought that devices are good enough know that people don&#x27;t exchange them quite so often? Especially laptops.I can still reasonably comfortably use my 2016 laptop today. In 1993 using computer from 1986 would have been a much bigger downgrade. reply h0l0cube 18 hours agorootparentprev> Solid state batteries with 10k charge&#x2F;discharge cycles are never going to happen for the same reasons, which are identical to the same reason incandescent bulbs are purposefully manufactured by every single lightbulb manufacturer to fail when they figured out a hundred years ago how to make them last forever.My first phone was NiCad Nokia. Later Nokia monochrome display phones used Li-ion well before smartphones. I use an iPhone now, but if a user-upgradeable Android phone came out with a solid-state battery, I would switch. reply huytersd 15 hours agorootparentprevThere is a huge difference between 1000 and 10,000 charge cycles. 30 years is longer than a human generation. reply svnt 15 hours agoprevPeople not realizing this ship has sailed. Apple switched to supporting right to repair because1) They are no longer dependent on the loss of battery capacity to drive new device purchases — meaning this issue is effectively over. Batteries now last all day for longer than most new device users will keep a device.2) Margins on services sold to hand-me-down family devices are a growing high-margin and young-user market and much of the market isn’t open to buying a device here — they will only use the service if they get a device for “free.”3) The net outcome is an increase in service revenue and decrease in recycling costs for Apple.All these trends will only accelerate from here. reply hellotheretoday 7 hours agoparentThese are good points and interesting, I’ve never seen such analysis, but imo their support of right to repair is because they’ve steered the discussion into a direction they are comfortable with.The apple self service program is apples ideal of right to repair. A shitty program where you can buy board assemblies and larger parts for fairly high prices with no changes to their software approach whatsoever. A battery change through this program is ~$120 up front (if you rent the tools, which you probably should) with a $30 refund when you return your dead battery. A battery change via the apple store is $99. You can only buy parts if you give them the device serial number up front (so fuck independent shops) and you need to call apple at the end to pair the part on their end.A pointless program with tons of waste still created. A short on your laptop motherboard? Better buy a new motherboard. An issue with the camera on your MacBook? Better buy a new lcd assembly.They will suddenly become very against right to repair the moment it starts to actually fight for things like schematics and board diagram access, component availability and not just parts assemblies, parts pairing that’s done in a consumer friendly way, etc.imagine legislation that says apple has to change parts pairing so that if a consumer unlocks their phone the parts have to be able to be sold as well? Or that they can no longer enter a contract with Texas Instruments to buy 100% of their stock of a usb c controller ic for a MacBook Pro so repair shops can’t buy it on digikey or mouser? Etc. they will fight that hard and then just find a way to circumvent it (like making their own usb c controller ic) reply rezonant 19 hours agoprevThe Blue Ocean strategy is choosing a specific market segment underserved by your direct competitors and refusing to compete on the product attributes that your competitors are emphasizing, not just \"trying something new\". reply echelon 19 hours agoparentThis article is a hodgepodge of Apple praise [1], incorrectly applied business analysis, and a misguided hope that Apple will be considerate enough to build user-serviceable parts. It makes no sense.[1] yes, the trillion dollar company is better than everyone else reply makeitdouble 19 hours agoprev> [fewer product sales per unit time] is a problem that can be solved using one of Apple’s favorite financial tools: higher product margins.It&#x27;s weird people forget the main message Apple has been touting for years now: services revenue.Even without removeable batteries, with right to repair device longevity will increase, and they&#x27;ve seen the writing on the wall for a long time.Apple will continue increasing services revenue. They&#x27;ll fight the bitter end for the 15&#x2F;30% tax on everything, iCloud tiers, Apple Music, TV, etc.If they find a blue ocean, it will be in services. Their entry into emergency satellite calls and other \"wouldn&#x27;t you feel bad being dead because you didn&#x27;t pay us ?\" push could be that. reply Cupprum 18 hours agoparentI do not understand why you are being downvoted. reply acdha 16 hours agoprevThe second part seemed pretty weak to me, too, but I think there&#x27;s a potentially bigger shift which could be steel-manned out of the battery idea. e-waste is getting a lot of attention, as are right to repair laws, and general realization that we can&#x27;t keep generating waste on a 20th century scale.Apple might have an interesting angle for embracing that because unlike their competitors they profit from the whole stack, have a robust service portfolio, and retail presence near a large portion of their customers. Turning device longevity into a competitive point really puts pressure on anyone who can&#x27;t easily switch from Qualcomm&#x27;s blink-and-you-miss-it support period or negotiate some kind of revenue sharing agreement between themselves, Microsoft&#x2F;Google, and services like Spotify or Netflix, and unlike most other attempts to make it harder to compete with them this would actually be seen as a general good by almost everyone other than their direct competitors. reply ekianjo 6 hours agoprevApple never had a blue ocean strategy. Almost none of their products sold because they were innovative. They sold well because they had a better execution and integration. reply kristianpaul 4 hours agoprevApple software ecosystem is pretty unique and ubiquitous in its way, this allow then to introduce features like- Advance encryption in iCloud&#x2F;iPhone its something not present in other products and services currently.- FindMy network to find lost keys and iphone- Private relay for more private browsing- AirDrop for fast file transfer reply Grustaf 18 hours agoprevOf all the things I&#x27;ve ever wanted to be different on my macbook, removable batteries have never been one of them. Now when battery life exceeds a (long) working day, why on earth would anyone want this? The very few times you will be away from a wall socket for more than 12 hours, you can just bring a power bank. reply makeitdouble 18 hours agoparentAt some point Apple refuses to replace the batteries of your macbook as they stop supporting the model. At that point you could be down to a few hours of battery life, with no third party repair shop willing to work on your laptop at a reasonable price. That&#x27;s where you&#x27;d be with a 2017 macbook Air for instance.Replaceable batteries gives an out to that situation, as one battery maker somewhere in the world could be enough to keep the remaining laptops alive, with no need for invasive serviceing.Of course that brings Apple close to nothing in revenue, but would boost good will from users and let them tout sustainability?Also won&#x27;t resonate if you&#x27;re cycling through devices every 2 years anyway. reply windowsrookie 9 hours agorootparentThe 2017 MacBook air has a ton of aftermarket batteries available for less than $60. It&#x27;s really not that difficult to replace it yourself. The ifixit guide says it takes 15 minutes.https:&#x2F;&#x2F;www.ifixit.com&#x2F;products&#x2F;macbook-air-13-late-2010-201...\"with no third party repair shop willing to work on your laptop at a reasonable price.\"I am not aware of any third party repair shop who would refuse to work on a 2017 MacBook Air. Unless it is a repair shop that refuses to work on Apple products in general. reply jlokier 8 hours agorootparentprevAre you sure about that 2017 Macbook Air?I have a 2013 Macbook Pro and I&#x27;m getting the battery replaced next week by Apple.My laptop is over 10 years old and they&#x27;re still doing it at their standard battery replacement price. reply makeitdouble 6 hours agorootparentMy mistake, I mixed up a Macbook pro and an Air. The Air was from 2014, the pro is 2017.Could it be regional differences ? I rechecked on the online support page - both Jp and Fr -, and repair support falls off right at 2015 (which is nothing to sneeze at for a maker, but I&#x27;d still wish for more) reply diffeomorphism 10 hours agoparentprevYou are confusing removable=repairable and hotswap. The latter indeed is \"who cares\", the former is important. reply warrenm 20 hours agoprevMake battery packs (call them \"removable batteries, if you like\") 100% completely and totally separate from the device itself - think of it like a UPS for a desktop...no (or practically \"no\") battery on&#x2F;in the device, and instead you run the device with a Qi-compatible battery packIOW - the device becomes 30-50% lighter (on its own), and the buyer determines how heavy his&#x2F;her experience will be based on which Qi-pack [s]he has chosen to run their phoneWant a 10,000mAh battery? No problem!Want only a 2,000mAh battery? Again: no problem!This even solves a problem Apple has let other vendors &#x27;solve&#x27; with regard to cases - want an OtterBox? CrayolaCase? SiliconSoftie? Go get your case from any of a thousand manufacturesApple could provide a pair (or trio, etc) of Qi-packs for their devices, and let other manufacturers go banana pants coming up with other optionsThis modularizes the iPhone in a smart way (not like that goofy Motorola method (which was reminiscent of IBM in the 80s open-standardizing the buses for their Personal Computer) whereby the only thing you \"have\" to get from Motorola was the core moduleApple&#x27;s \"core module\" with such a program would still be iPhone ... and that is still the biggest differentiator Apple has vs the 80 scadzillion Android makers out there: iPhone is only Apple. Android is whomever wants to make one. reply threeseed 19 hours agoparentI can&#x27;t tell if this is sarcasm or not.Because Apple has had this for years a while now with the MagSafe battery pack.I actually think it should become a standard that all companies adopt. It&#x27;s far easier and quicker to use than removable batteries and doesn&#x27;t remove valuable space inside the phone. reply ProfessorLayton 13 hours agorootparentIt’s also incredibly wasteful. 30-40% of a battery bank’s capacity is lost to inefficiency, and even worse with a case on. It would be great if phones commonly offered pogo pins on the back in addition to wireless charging. reply foobiekr 19 hours agoparentprevI used to feel like you - the non-removable battery thing was annoying, the non-modular flash was a deal breaker, etc.None of them turned out to matter, at all. What does matter is a solid feel and solid construction and the flash and batteries lasting the lifetime of the product. I&#x27;d rather have that than replaceable. reply highwaylights 19 hours agorootparentBut the batteries dont last the lifetime of the product.Most iPhones are still very useful devices by the time their batteries have deteriorated below 70% original capacity. reply BreveDev 18 hours agorootparentiPhone batteries can be replaced for $89 from Apple and last for years. This is not the problem you think it is reply warrenm 3 hours agorootparentprevI usually keep my phones for about 4 yearsThe devices start glitching and&#x2F;or won&#x27;t run newer apps as well as they should long before the battery goes on them reply highwaylights 1 hour agorootparentAre the apps you&#x27;re using substantially better than they were 4 years ago? Are they doing substantially more for you that you wanted from them?If the hardware is failing then I guess fair enough (it shouldn&#x27;t be, that&#x27;s a design defect), but inflated hardware demands to compensate for increasingly sloppy code isn&#x27;t a reasonable justification to demand dropping another $500+ on a device that works fine.I recently gifted a used iPhone X to a relative. It&#x27;s still an exceptional device on which the hardware works as well as it ever did, minus the reduced battery life. I would have been happy to keep using it if I could replace the battery simply and it was still getting O&#x2F;S updates.(As it is, the device still receives security updates, which I can&#x27;t really grump at Apple for after almost six years - but only because they&#x27;re better than the rest of the industry. It&#x27;s still a poor situation). reply warrenm 39 minutes agorootparent>(As it is, the device still receives security updates, which I can&#x27;t really grump at Apple for after almost six years - but only because they&#x27;re better than the rest of the industry. It&#x27;s still a poor situation).I am continually astonished at folks who expect OS and&#x2F;or security updates past a few years (this is not a slight against you, just an observation on my part)A lot of folk like to gripe about \"planned obsolescence\" or similar because eventually their device is no longer supportedYet the fact that manufacturers support equipment as long as they do is ... kind of astonishingThe higher the volume of production, the shorter you would expect a manufacturer to support it (a 747 is worlds different from a pickup truck which is worlds different from a phone or laptop)The cost-benefit analysis of continuing to support&#x2F;update a given device has to be taken into account ... and - for most phones (since that is what we are talking about in this thread) for most people, that means that between 3 and 4 years after release, it makes [nearly] no economic sense to keep supporting themThat Apple does for so long speaks volumes about their commitment to their customers (even though, of course, they would like you to get a new phone every year, I am sure) reply warrenm 1 hour agorootparentprev> Are the apps you&#x27;re using substantially better than they were 4 years ago? Are they doing substantially more for you that you wanted from them?Yes - in general, the apps I am running are doing more and are better than they were when I first got a given model phone :)I went from the 4S to the 6S Plus to the 11 and am waiting on my backordered 15 Pro currentlyI still have the 6S Plus in a drawer in my utility room - it \"works\" for lite tasks like web browsing, but will not run most of the productivity apps I need&#x2F;want for work or the educational apps my kids need&#x2F;want for school. So, for me, it is a \"useless\" device (so the kids get to play with it - and nobody cares what happens because it is 8 years old)My 11 still \"works\", too - but it is getting very long in the tooth replyankushnarula 19 hours agoparentprevAgree with the most of youir premise - but a magnetically aligned and secured pogo-pin interface on the bottom back edge of every MacBook might be superior to inductive charging, which wastes electricity and generates too much heat. Such battery packs could also include a second pair of pass-thru pins for stacking and connecting to a direct wall power adapter. reply warrenm 36 minutes agorootparentwas not really thinking about MacBook, more iPhone (and, possibly iPad) ... but that is an intriguing idea, too: supply a basic battery that would last for X long, and have a pass-through (hermetically-sealed, if you wanted to move into the IPS zone for dust&#x2F;liquid resistance) MagSafe (or similar) connector for additional battery packs on the bottomI could totally see getting a second laptop-footprint-shaped pod for my MBA that would click on and give me another 20-40h of run time between charges! reply crooked-v 19 hours agoparentprevThis is basically what they&#x27;re doing with the Vision Pro, though out of engineering necessity rather than preference: the headset by itself only has about 5 minutes of battery life, to give you just enough margin to swap out the external battery pack you keep in a pocket. reply lxgr 11 hours agorootparentHopefully that internal battery is purely optional, i.e. implemented like in most laptops and not like in most phones, where it&#x27;s impossible to use a device with a dead battery even when externally powered. Otherwise it&#x27;d be the worst of both worlds. reply LeafItAlone 19 hours agoparentprev> instead you run the device with a Qi-compatible battery packAnd lose 20% percent efficiency? A bigger battery for the same usage time and my device is constantly warmer? Sign me up! &#x2F;s reply warrenm 35 minutes agorootparentI used Qi as an example - a couple folks have suggested some kind of pogo-pin arrangement (maybe a derivation of the MagSafe connector?) reply reactordev 6 hours agoprevI call BS on this. Apple’s strategy is not battery tech. It’s personal computing devices. Always has been. Always will. Wearables, services, AI-capable hardware, is where Apple wins. Wearables beyond the watch and the vision pro. Meta and Ray-Ban teamed up for some Google Glass-like shades. Apple will come out with Shade (TM) if they choose to go into that market.The point is, Apple has had a strategy for a while now. It’s not going to win against Android in the phone wars. It’s going to win in the AR&#x2F;XR space if they can manage to get a decent wearable out and provide cores within cores within cores for AI NN’s. reply greedo 2 hours agoparentI would say that Apple has already won against Android. Android may have more units world-wide, but Apple owners spend more, are more desirable customers etc. reply mynegation 19 hours agoprevSealed off user-interchangeable batteries are a solved problem. GoPro does it. reply Waterluvian 19 hours agoparentIndeed. Which is the solution camcorders and consumer cameras used for decades. reply Kon-Peki 15 hours agoprevI thought that EU regulations were going to force smartphones to have removable batteries within the next few years. That’s hardly swimming out into the blue ocean.But regardless, easily removable batteries are going to create more e-waste, not less. Replacing a battery is perfectly doable right now, but there is a hurdle you have to jump over - you aren’t going to do it until you really need it. Once those batteries are easy to replace, people are going to be replacing them much more frequently, they’re going to be buying spares, etc. And people are going to be throwing old batteries in the trash without even thinking about it. reply makeitdouble 14 hours agoparentBatteries are still expensive. An iPad battery for instance is easily in the 100~200 bucks, same for laptops. The iPhone might come lower (50?) but even with a simple system, opening the device will till probably enough of a friction to not make it worth it to most people.To make a comparison to cameras, I don&#x27;t know how many people care to buy spare batteries outside of pros and people actually going through 2 or 3 batteries on their trips. Everyone else is probably using the one coming with their camera until it dies and then replaces it. reply pests 14 hours agoparentprevI think its \"replaceable\" not \"removeable\" batteries, using \"readily available tools\".So don&#x27;t think removeable batteries of the past held together by a sliding cover - more like grab an eyeglass screwdriver and a few minutes later its out.I think the distiction is slight but there is a difference between an object meant to attach&#x2F;de-attach (like old laptop batteries) and the m2 hard drive in my laptop. Both are technically replaceable, only one was designed to be removeable. reply omneity 19 hours agoprevThis article wasn&#x27;t particularly insightful or thought-provoking. Maybe I missed something. reply al_be_back 7 hours agoprevI much doubt that giants such as Microsoft, Apple etc, rely on strategies such as \"Blue&#x2F;Red Ocean\", it&#x27;s too fancy&#x2F;romantic to be practical at their level. They tend to focus on established markets, which is very messy and competitive. reply Mrirazak1 12 hours agoprevI think Apple’s blue ocean strategy is unique in the sense that it’s not when you feel they should release something but more so when they feel it’s the right time to release something and doing so in an Apple fashion way by being late. Because they make it refined to their standards.In terms of blue oceans it’s where they see a lack of innovation because you can have many blue oceans within in anything you do if you see the problems that exist in a way that your competitors don’t and then you apply great engineering with great marketing (although sometimes it’s just marketing) to reach the numbers you need. reply dwighttk 5 hours agoprevI can’t really picture how removable batteries would work, but I do admit it’d be nice to be able to replace them… at least for like $25-50 max. reply lapcat 19 hours agoprevMy favorite MacBook Pro ever was my 17-inch 2006 model.Replaceable battery and matte display! I hate that these features were eliminated. reply Cupprum 18 hours agoparentI prefer these glossy displays, i think its actually quite sad that the external display market does not offer many nice monitors with glossy screen. reply bonestamp2 16 hours agoprevThe real Blue Ocean strategy that Apple should apply would be to use AI to help analyze our behaviors and then actually change our behaviors to help us be happier and healthier, not just use it to sell us more stuff (as some competitors are doing). reply FireBeyond 19 hours agoprev> the Wii differentiated itself with its motion controls and a low price. It was a hit.> Lately, I’ve been thinking about the blue ocean strategy in the context of Apple. Like Nintendo ...Well, Apple is certainly not differentiating on &#x27;low price&#x27;. And I don&#x27;t know that high margin is \"innovative blue ocean\". reply s3p 15 hours agoprevThis article frustrates me.>Starting in 2009, Apple began to phase out removable batteries across its laptop line in favor of batteries that were sealed inside the case and were not user-accessible. >The upsides, which Apple touted, were many: lighter weight, smaller size, better reliability, longer battery life.What are you talking about? The link provided to Apple&#x27;s press release for that laptop did not include anything about why a non-removable battery was advantageous. They provided other reasons the new battery was great, but they did not say the elimination of user-serviceability allowed for any of those benefits.>The iPhone defied so many other norms that the sealed battery was less remarked upon than it might have been, but it was still noted.Noted by who? Remarked upon by who? It sounds like this author is generalizing his own opinions to the entire population. I&#x27;m sure this comment sounds nitpicky but I just don&#x27;t like this kind of fast and loose writing. reply throwawaaarrgh 13 hours agoprevTheir next big move will probably be some AI product that ties together their other offerings into their exclusive platform. The ideal would be that you buy all their products and they automatically learn how you live your life, ancitipate your needs and provide for them seamlessly. Other companies try to do this now but it&#x27;s not seamless at all. If Apple can use some tricks to identify a user, link all their stuff together, begin predicting needs and popping up solutions for them, all tied into a privacy-first data warehouse (nobody can use your data except you on your Apple devices), that could capture much bigger segments of the worldwide tech product landscape.At least, that&#x27;s my assumption based on their massive spend on infrastructure related to AI. I&#x27;ve been waiting for their cloud hosting project to jump out of stealth mode, if it&#x27;s still in progress, but maybe it was never intended for anyone other than Apple&#x27;s use. If that&#x27;s the case then it makes more sense that they&#x27;d sort of pull a Google and invest more heavily in the backend server side for one product that could really be a killer, which would most likely be something AI. An answer to Google&#x27;s search product that isn&#x27;t search. reply Despegar 20 hours agoprevIf there&#x27;s going to be removable batteries for any product it will be for new product categories like the Vision Pro. Apple is definitely not going to take established products like the iPhone and change it up just to be different (which isn&#x27;t a sustainable competitive advantage because anyone can do it). Even with the Vision Pro it&#x27;s a compromise that Apple is likely tolerating, rather than what the &#x27;final form&#x27; of the product will be in 10 or 15 years. reply Sparkyte 12 hours agoprevMore like comparing wallgardens with few open tech standards.I was going to rant. But it is pointless. These companies find ways to hold customers because of their tailored experiences and it has less to do with technology and more with targeting. reply emadabdulrahim 17 hours agoprevThe first half of the article was great. But regarding going back to replaceable batteries, I couldn&#x27;t disagree more. If you know anything about Apple&#x27;s design philosophy, you&#x27;d know the last thing Apple wants is for users to even consider opening up their device to replace&#x2F;swap a battery. reply ugizashinje 8 hours agoprevNon US resident here, I just switched from macbook 13 to system76 lemur. Half the price and double performance, could not be happier. Market is ready for segmentation and users today are more tech savvy then before. reply Toutouxc 4 hours agoparentWhat kind of performance? The best Geekbench scores for a System76 Lemur Pro with an i7 are still significantly lower than those of a M1 MacBook Air, which is the slowest Apple Silicon laptop. The Lemur also costs $1,300+ with the i7 (i.e. not cheaper than the Air) and has a 1080p screen.Not saying it&#x27;s a bad machine or anything, but the \"half the price compared to a MacBook\" meme is now more irrelevant than ever. reply niek_pas 7 hours agoparentprev> \"users today are more tech savvy then before\"What are you basing this on? How do you operationalize \"more tech savvy\"? reply marban 12 hours agoprevTech success is less about envisioning the future but more about forgetting the past. reply fnordpiglet 18 hours agoprevI’d rather have hot swappable batteries where you have a ten minute battery in the device and the main battery can be swapped out on the fly. reply tpmx 19 hours agoprevWaterproof batteries, transferring power to the device via induction? Then the bay where they are installed wouldn&#x27;t need to be glued shut. reply arcticbull 19 hours agoparentI mean, they don&#x27;t need to be glued shut now lol. reply IshKebab 19 hours agoprevNot going to happen. Battery life is good enough for 99% of people that they aren&#x27;t going to want to swap batteries. Only nerds really did that in the first place.Battery technology has improved so much that removable batteries are less desirable. reply Synaesthesia 19 hours agoprevIt could be easily done. Sadly Apple doesn’t seem to view that in its interest, despite its repeated claims to care about the environment.They could make slick, elegant devices which are still repairable and have replaceable batteries.I remember the original iMac G5 had a great design which let you simply remove the backplate with 3 screws and access everything. Of course in the next iteration they changed the design entirely so that opening it up became a huge ordeal. reply pipeline_peak 14 hours agoprevReally bad article, the author doesn’t seem to have any idea what blue ocean strategy is about. It’s not about making “bold moves” in an unchanging market. It’s about cutting down cost through focusing on what really matters to an under looked consumer audience. That audience being one the competition isn’t even focusing on. Also low cost wasn’t just Nintendo’s choice, that was a major factor in the definition of Blue Ocean. Apple cuts down cost in some areas to compensate for quality and user experience, keeping the cost. They do this because they make luxury items.Yellow Tail Wine and Nintendo’s Wii were text book examples. They both found an untapped audience, novice consumers who don’t know nor care for over the top quality. In Nintendo’s case, hard core gamers valued graphics and performance as quality. To Yellow Tail it was Wine enthusiasts and their interest in vineyards, vintages, and hints of whatever.Apple products are novice, but they aren’t cheap. The Chromebook is a better example of Blue Ocean. It does only what an entry level consumer wants in a laptop. It browsers the web, writes documents. Google said “hey, pretty much everyone who owns a MacBook but isn’t an artist or techie could use this”. Like MacBooks it doesnt require expertise, it offers a similar user quality experience, but unlike them it’s affordable because it doesn’t have unnecessary hardware specs and Swiss watch leveled build quality.I don’t blame the author for not reading the whole ass book. But for god sakes, at least read the wiki page about it, don’t use a gaming magazine as your source. Because he clearly took the Wii example in the magazine and ran with it. He thought he could map it onto Apple products because what, they get rid of stuff and are innovative like the Wii was?I’m glad I’m not the only one who found the battery ramble irrelevant. reply mensetmanusman 14 hours agoprevPlease make twist on cylinder battery replacements for the AirPods… reply bravoetch 19 hours agoprevPlease make them cheaper and sustainable instead of adding removable batteries. reply hn_throwaway_99 20 hours agoprevI&#x27;m all for Apple reversing their long-standing decision to make device batteries non-user-replaceable - an original decision which I personally loath, and one where the EU will most likely force Apple&#x27;s hand anyway by requiring batteries to be user-replaceable.But excuse me while I throw up in my mouth a little with this \"Blue Ocean\" nonsense. Apple makes an original, user-hostile decision for the sole purpose of increasing planned obsolescence and to make them more money, and then when the winds shift they might go back the other way - but, again, they&#x27;ll likely be forced to anyway. No need for poetic blog posts.I suppose we&#x27;re owed another \"Blue Ocean\" missive about how Apple led the way with Lightning connectors and then found another Blue Ocean with ... USB-C. Puhleeez. reply threeseed 19 hours agoparent> Apple makes an original, user-hostile decisionYou make it sound like the decision comes with no benefits.All of the hardware to support removable battery means less space for the battery.And especially in the early days the iPhone was struggling to reach a normal working day. reply blkhawk 7 hours agorootparentIn the apple devices i have seen the insides off there is plenty of room to add screwed brackets that hold the battery in - the battery does not fill all available space because even pouch cells are basically rectangles. That means in every curve there is plenty of space for a screw post or hook.But I agree that \"Apple makes an original, user-hostile decision\" is a bit too simplistic. I have long since come to the conclusion that Apple simply always chooses the cheapest option for them in cases where user-serviceability is concerned or to maybe put it another way they ignore user-serviceability semi-actively. Routing screw posts costs time and wear on tools. screwing in extra screws costs time thus just mainly gluing the battery in place is the cheapest option.Soldering on flash and RAM saves on costs and makes the PCB design easier. At the same time it \"locks\" the longevity of the device neatly. This leads to not-overlong replacement cycles simply for practicability reasons - for instance modern chrome eats all the RAM. reply EPWN3D 19 hours agorootparentprevR2R enthusiasts are incapable of seeing any decision from a perspective that isn&#x27;t their own personal fetish for tinkering. So any and all advantages of sealing the battery into the chassis are just waved away and not acknowledged at all.Lighter devices? That&#x27;s irrelevant, no one cares about device weight.Cheaper to manufacture? That&#x27;s just a ploy to gasp make more money! How dare they?!Waterproofing? Well I don&#x27;t go SCUBA diving with my phone, so clearly no one else does. And if they do, just put it in a ziplock bag!And so on. reply hn_throwaway_99 17 hours agorootparentOn the contrary, I find in amazing to see the lengths that Apple apologists will go to point out these spurious reasons why Apple included non-removable batteries.The only point that you really list that is defensible is waterproofing. Lighter devices? Cheaper to manufacture? The idea that making a removable battery would make a phone noticeably heavier or impact the cost more than a cent or two is laughable.Even with the waterproofing, I&#x27;m dumbfounded on how one hand people can laud Apple for their truly amazing engineering capabilities (I may question its utility but the Vision Pro is really an incredible piece of engineering), yet somehow a waterproof removable battery (which some other phones have) is beyond their grasp. reply threeseed 13 hours agorootparentRemovable batteries requires valuable space for the mechanism to hold the battery, transfer the power from the battery, eject the battery etc. It doesn&#x27;t come for free.At least based on what I&#x27;ve seen on camera mechanisms you&#x27;re taking about 10-20% reduction in the battery cell. reply blkhawk 7 hours agorootparentSince the EU law is about making batteries \"removable with normal tools\" one could argue that encapsulating the battery like a camcorder battery with a plastic hull isn&#x27;t needed. A normal pouch with contacts will do.Assuming \"All day battery life\" (24h) a 1% reduction in battery life is about equal to 15minutes but frankly I can&#x27;t see the replaceable battery reduce the capacity at all if you are doing halfway good engineering - there is plenty of void space in an iPhone even now. By that I mean space over&#x2F;under PCBs where the battery cannot go because it is still just a rectangular polygon even in say the iphone 15. I think it has 2 rectangular smaller cells with a casing around them to make an L shape.So why doesn&#x27;t apple forgo the \"casing\" and take that sweet 10 to 20% extra capacity? :) reply smoldesu 18 hours agorootparentprevThere are reasonable levels of supply chain integration, and then there is user-hostility. With Apple we&#x27;ve seen both sides of the coin, so you&#x27;ll have to excuse the people who accuse them out the gate.It stands to reason that a company as large as Apple is capable of making decisions that impact large amounts of people. It&#x27;s not just Right to Repair enthusiasts that care about that impact, it&#x27;s extended to regulatory bodies that are tired of meaningless standards competition and arbitrary market separation. Apple can excuse these base truths with whatever feature or novelty they choose, but it doesn&#x27;t overwrite the insidious functionality of their choices.You&#x27;re basically describing the situation in reverse, from the perspective of foreign markets and regulatory watchdogs:\"Another special, licensed connector for data and power? Why do consumers need that!\"\"An App Store? Why give Apple complete control over a feature as basic as installing software?\"\"Only one browser engine? How are new technologies intended to compete on a platform that doesn&#x27;t acknowledge newcomers?\"So on and so forth. reply TapamN 18 hours agorootparentprevThese \"advantages\" to sealing the battery are incredibly weak&#x2F;false.The weight difference from sealing the battery is negligible. If it saved several hundred of grams, it would one thing, but a replaceable battery adds at most tens of grams.Even if the sticker price of device is cheaper, I would still have to pay more to replace the entire device once the battery is worn. This is the primary reason for most companies sealing the battery, to force buying an entire phone. Having a replaceable battery would save me money.Sealing the battery was not responsible for waterproof phones. There were already waterproof phones with replaceable batteries. reply LaSombra 19 hours agoparentprevI have huge respect for John Siracusa. His articles at Ars Technica, pragmatic opinions on the world of computing always spoke to me, but this article sounds like something written by John Gruber.Apple indeed innovated in multiple ways and markets, but un-removable batteries wasn’t one. reply ace2358 19 hours agorootparentI also have massive respect for Siracusa and I find I have a few similar opinions that made it really enjoyable listening to him and reading his articles.But over the years, as John has gotten older (and as the other members of ATP) I find that my values are starting to diverge. It feels much more of a news show than a tech show and I find I’m not gaining much insight from their discussions or opinions. Even their tech insights are starting to feel out of touch with the rest of the world. reply matwood 18 hours agorootparentMarco was always disconnected because he&#x27;s well off and could do whatever he wanted (good for him). When Casey and John had jobs, they were able to keep Marco grounded and the trio really worked. Now that Casey and John both only really do the podcast now, they all are a bit disconnected. I&#x27;m happy for all them to make money doing what they love, but the show definitely changed once they all became essentially full time podcasters. reply LaSombra 7 hours agorootparentI didn&#x27;t know John pivoted to full time podcasting. This actually explains, IMHO, the shift towards a more forgiving view of Apple&#x27;s product directions. reply ace2358 6 hours agorootparentIndeed, if I remember correctly, he quit about 12 months ago or so. It made me wonder what the earning of a high profile podcast can be! Also how much that can fall away when the advertising business drops (as they constantly like to remind me, multiple times on every show…).It makes me confused that while they’re working on the show(s) full time, the quality is dropping? It’s less interesting somehow? reply greedo 2 hours agorootparentI did the math a couple of years ago, and it came out to roughly $100k per podcaster. This has obviously dropped off significantly the last year with ad sales in general tanking. replyranqet 19 hours agoparentprevSiracusa&#x27;s simpering, consoomer defensiveness for Apple has become intolerable. He seems unable to deal with the fact that his precious company&#x27;s business practices are incompatible with his political&#x2F;enviromental beliefs. Instead concocting this &#x27;blue ocean&#x27; dream that Apple will switch back to user serviceable batteries, creating a new market where there competitors don&#x27;t dare tread.What?There are still plenty of Android devices that have user serviceable batteries, but they don&#x27;t sell as well because what the majority of users want is to minimize size and weight at any cost. The minority of geeks out there who think something like this is important doesn&#x27;t move the needle. Apple (particularly under Tim Cook) only cares about maximizing profits. Their environmental schtick is merely dressing in front of the ruthless profit making machine at work.Obviously Siracusa can&#x27;t deal with the dissonance that his precious Apple doesn&#x27;t care about the environment as much as he does. Thus typing up silly articles like this... reply makeitdouble 19 hours agorootparent> they don&#x27;t sell as well because what the majority of users want is [...]I think in the current market we have no idea of what the majority of users want because there&#x27;s no combination of all the available options.The majority of users might value iOS more than any specific hardware feature. Second to that, they might value price and career rebates.That makes fringe android phones failures irrelevant and would leave us with only random guesses on what people would want outside of what Apple and Sumsung is offering right now. reply linguae 18 hours agorootparentExactly. Just because a company sells something doesn&#x27;t mean the majority of users want it that way. I would love for Apple to sell a laptop akin to the 2006 MacBook and MacBook Pro but with modern components, complete with removable batteries as well as user-upgradeable RAM and storage. It doesn&#x27;t need to replace the existing Apple laptop lineup; it could supplement it (let&#x27;s call it the MacBook Pro Max or the MacBook Extreme or something to that effect). Of course, Apple doesn&#x27;t sell this product, and so I have to choose between two compromises: dealing with non-replaceable components so I could use macOS, or dealing with Windows or Linux so I could use something like a Framework laptop. In other words, I must choose between macOS or user-serviceable laptops, and unless Apple experiences noticeable declines in sales, this won&#x27;t change; in fact, even PC laptops have largely moved toward the Apple model; even many ThinkPads have soldered RAM these days. reply chaostheory 13 hours agoprevThe article is about Apple, but it describes the https:&#x2F;&#x2F;frame.work&#x2F; blue ocean of mobilizing the laptop where nearly everything is replaceable and upgradeable reply mruniverse 13 hours agoprevI thought Apple&#x27;s Blue Ocean stuff were:* Macintosh* iPhone* Apple Store reply Condition1952 19 hours agoprevremovable batteries was to allowed the laptop to run without a battery pack for as long as needed reply 1letterunixname 12 hours agoprev [–] Nintendo died by hiding in the corner, being afraid to compete, not making anything cool, and instead making something nobody wanted in a category too small to sustain itself. reply lxgr 11 hours agoparentNintendo died? Who&#x27;s making these nice, popular hybrid portable&#x2F;docked consoles then that I see all around my friends&#x27; living rooms and on public transit? reply pipeline_peak 3 hours agoparentprev [–] Um, it was the most successful console that generation. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author introduces the \"blue ocean\" strategy, illustrated through Nintendo's triumph with the Wii console. A blue ocean strategy refers to creating new market space that makes competition irrelevant.",
      "The author suggests Apple’s next big opportunity or \"blue ocean\" could be reintroducing removable, user-accessible batteries in its gadgets, owing to technological advancements and evolving consumer needs.",
      "The proposed idea presents potential benefits like enhanced battery life and decreased electronic waste, making Apple, a consumer-electronics design leader, capable of surmounting any foreseeable challenges tied to this initiative."
    ],
    "commentSummary": [
      "The conversation highlights limitations and drawbacks of Apple devices, including non-upgradable RAM and soldered storage, and the lack of features like MST support and removable batteries.",
      "Users are discussing the reliability and lifespan of LED bulbs and batteries, the pros and cons of wireless charging, and the potential of Apple developing a super thin phone with reduced battery life.",
      "The discussion also revolves around Apple's design choices, the concept of user-replaceable batteries, and the influence of sustainability concerns on the device industry."
    ],
    "points": 244,
    "commentCount": 216,
    "retryCount": 0,
    "time": 1698610641
  },
  {
    "id": 38064856,
    "title": "Web FM synthesizer made with HTML5",
    "originLink": "https://www.taktech.org/takm/WebFMSynth/",
    "originBody": "1 2 3 4 1.00 0.30 1 BELL Click to share this sound #webfmsynth ã«é–¢ã™ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆ Web FM synthesizer made with HTML5 WAAPISim: Web Audio API Simulator and WebMidiLink by g200kg. WebAudioSynth by aike serves as a good reference of Web Audio API. Please see also: DXi FM synthesizer for iPhone/iPad 2010-2014 Takashi Mizuhiki & creative studio CUE",
    "commentLink": "https://news.ycombinator.com/item?id=38064856",
    "commentBody": "Web FM synthesizer made with HTML5Hacker NewspastloginWeb FM synthesizer made with HTML5 (taktech.org) 225 points by __anon-2023__ 15 hours ago| hidepastfavorite43 comments zX41ZdbW 13 hours agoIt has click artifacts in my browser (Firefox).PS. I&#x27;ve recently implemented an FM &#x2F; additive &#x2F; modular synthesizer entirely in SQL: https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;NoiSQL reply rollcat 3 hours agoparentI have a question regarding this formatting style: 44100 AS sample_frequency , number AS tick , tick &#x2F; sample_frequency AS timeI see this used a lot in Haskell, nix, and sometimes other languages (first time here with SQL). I personally find it very odd to read. It feels like starting a sentence with a dot, instead of ending it with one, which feels quite jarring. What is the primary motivation for employing this style, especially in languages (like SQL) where this doesn&#x27;t seem to be the norm? And especially for the languages (Haskell, nix) where this is the standard (?) coding style, wouldn&#x27;t it be preferable to use a different token as the separator, one that doesn&#x27;t look as odd at the beginning of a line? reply otikik 2 hours agorootparentLess diff noise when adding&#x2F;removing lines in a commit.If you put the comma at the end, and then you need to add a line, you either:* Insert the new item \"in the middle\" of the list. This is often possible, but not always.* Add the new item to the end of the list, in which case the the line that was at the end before will now need to be modified to add a line.Lines that begin with the coma can be more easily moved around&#x2F;resorted. With the comma at the end, if you put the \"last\" item in the middle, you also need to add a comma at its end (and remove the comma from the new item that is now the final one).Personally, I like languages where you can simply leave a comma at the end of a list or enumeration without this being deemed a syntax error (for example, in Lua the table {1,2,3,} is equivalent to {1,2,3} ) reply hiAndrewQuinn 2 hours agorootparentprevAesthetically: Keeps the names lined up nice.Practically: Overkill to avoid \"no final commas in JSON\" moments. reply cbrpnk 5 hours agoparentprevHaven&#x27;t logged into my hn account in ages. But I did to say this: Awesome. reply denton-scratch 5 hours agoparentprevConfirm click artifacts in Firefox. reply terlisimo 11 hours agoparentprevWow. That&#x27;s pretty insane. In a positive way :) reply g105b 8 hours agoparentprevAbsolutely insane concept! Bravo! reply anonu 38 minutes agoprevI found the wikipedia article [1] on the subject to be helpful to understand a little bit whats going on here.I wonder if there&#x27;s more performant wasm implementations that can interface with the WebAudio API [2]? Quick search brings up things like [3][1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frequency_modulation_synthesis[2] https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;API&#x2F;Web_Audio_A...[3] https:&#x2F;&#x2F;github.com&#x2F;a-cordier&#x2F;wasm-audio reply cronix 20 minutes agoprevOn an old macbook pro 2013...no clicking in Firefox...This is really cool. The only thing I found kind of odd was you click the down arrow to increase the program number instead of up. reply fenomas 12 hours agoprevVery neat! Though I got prominent clicks and artifacts in both chrome and firefox.If anyone&#x27;s interested, some years ago I made a wrapper library for things like this, to wallpaper over the famously hairy WebAudio synthesis API. Basically you pass in a static object describing the audio graph and parameters you want, and the lib creates the WebAudio nodes and then cleans them up after the sound releases (hopefully without clicks, unless you specifically want them).https:&#x2F;&#x2F;github.com&#x2F;fenomas&#x2F;wasgen reply fiala__ 5 hours agoparentNice one! At BBC R&D we built a similar declarative library for React https:&#x2F;&#x2F;github.com&#x2F;bbc&#x2F;r-audio reply chaosprint 6 hours agoparentprevclicks are challenging for web audio. your project looks great. I have a similar work here. Hopefully it can achieve performant audio synthesis in browsers:https:&#x2F;&#x2F;glicol.js.org&#x2F; reply assimpleaspossi 9 hours agoprevAs in most cases, \"HTML5\" has little to do with this and it&#x27;s all javascript. reply fenomas 8 hours agoparentTFA is old enough that the \"HTML5\" here means \"as opposed to Flash\". reply sumtechguy 4 hours agorootparentthe only downside to flash going away was zombo.com no longer works correctly. reply FpUser 4 hours agorootparentYou scared me for a sec. Life is dull without that site. I did check right away and it does work. Phew ;) reply marban 3 hours agorootparentprevThen it&#x27;d be DHTML reply fenomas 3 hours agorootparentNewp. DHTML as a term is way older, and referred to earlier things. reply ioseph 6 hours agoparentprevBrowser audio support came about with HTML5, the js APIs used for this sort of thing were to support thereply Cthulhu_ 6 hours agoparentprevIt&#x27;s an okay catch-all term for \"browser technology from after 2010\" I suppose, like how DHTML was a catch-all for HTML + JS and AJAX for fetching things from JS. reply keepamovin 10 hours agoprevThis is REALLY cool! I love WebAudio. Things that can be achieved with it, plus new speech recognition tech, plus other AI stuff, I think are going to be truly incredible!Audio processing and synthesis is one of those things where you can do high quality in real time on mobile devices, and achieve delicious fast feedback loops. Creating new interactive modes of creativity! It&#x27;s less possible with video because of the complexity and added cost. Right now anyway.So exciting! I know the synth may look simple, but it&#x27;s my feeling that it&#x27;s really well made.Regarding commenters mentioning click artefacts...that&#x27;s troubling! I personally did not encounter it here, but I find, quite strangely I think, that: click artefacts are almost a \"Random\" bug. They show up sometimes, but not other times, even if everything else is seemingly the same.That&#x27;s been my experience. Maybe it&#x27;s an \"artefact\" (pun intended) of dealing so closely with hardware. I don&#x27;t know! Any experts want to weigh in on a way to avoid click crunches in WebAudio?? :)edits in italic:I found the GitHub repo: https:&#x2F;&#x2F;github.com&#x2F;mizuhiki&#x2F;webfmsynth from 11 years ago!!!! :) ;px xx ;pMore fascinatingly it seems the original genesis of this project and its innovations came from the guy&#x27;s academic work: https:&#x2F;&#x2F;github.com&#x2F;mizuhiki&#x2F;webfmsynth&#x2F;blob&#x2F;2cd2655fb5f8e1f7... reply chaosprint 7 hours agoparenthttps:&#x2F;&#x2F;github.com&#x2F;chaosprint&#x2F;glicolyou can check my project; audio synthesis in browsers without gc reply keepamovin 6 hours agorootparentCool, thank you! :)Post a Show HN reply YoshiRulz 1 hour agoprevAs opposed to AM: https:&#x2F;&#x2F;fulldecent.github.io&#x2F;system-bus-radio&#x2F; reply bqmjjx0kac 2 hours agoprevIn case anyone else convinced themselves that iOS doesn&#x27;t support the Web Audio API, try turning off silent mode with the physical switch on the side of your phone. reply yawnxyz 13 hours agoprevThis is really amazing, but a part of me is really sad this reminds me of the Actionscript 3 Audio API, which I used to build something similar, more than a decade ago while in undergrad.Looking into it, it&#x27;s kind of crazy it&#x27;s an ECMAScript standard, and that its spiritual successor is TypeScript. reply treve 12 hours agoparentI wrote a bit about this a few years ago in case people want to know more about this: https:&#x2F;&#x2F;evertpot.com&#x2F;ecmascript-4-the-missing-version&#x2F;Language aside. Flash offered so much. I wonder if we&#x27;re mostly caught up now, but it&#x27;s taken years! reply PaulDavisThe1st 12 hours agorootparentSpecifically in connection with synthesis, consider reading up on the history of the Music N language family.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;MUSIC-NThis goes back to 1957, and as the article notes, is the parent of many of the most used synthesis languages right down to the present day (which is both good and bad). reply JSavageOne 13 hours agoprevIs there no way to play the notes on the keyboard (without clicking)? reply ruined 11 hours agoparentit seems to support webmidi, so you could plug in a midi keyboard, or use an application that generates midi. reply gka 8 hours agoparentprevI was wondering the same, the ASD.. keys should ideally be the piano keys, like in most software synths reply otikik 8 hours agoprevThe more code-oriented folk might like Glicol https:&#x2F;&#x2F;glicol.org&#x2F; reply rippeltippel 7 hours agoparentAnd Sonic Pi, perhaps: https:&#x2F;&#x2F;sonic-pi.net&#x2F; reply stall84 2 hours agoprevI was planning to get work done this morning... reply Rodeoclash 12 hours agoprevGreat work, still feels impossible to program though! ;) reply FpUser 4 hours agoprevInteresting thing. It does have clicking sound artifacts though. Is it the programming or some GC &#x2F; other periodic thing in a browser kicking in? reply dimatura 11 hours agoprevawesome! I actually have this synth on ios as well. Can&#x27;t have enough FM. reply xeckr 13 hours agoprevAmazing work. reply ChrisArchitect 11 hours agoprev(2016)? reply roymj88 12 hours agoprevWow, this is amazing work!! reply ecmascript 8 hours agoprevThere is also https:&#x2F;&#x2F;plypp.net&#x2F; reply 38 13 hours agoprev [–] Thanks for killing my browser replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text discusses a web FM synthesizer constructed using HTML5, showcasing advancements and possibilities in web-based music technology.",
      "It also references other related tools and resources, highlighting the breadth of support and availability in the field.",
      "The text touches upon the DXi FM synthesizer created for iPhone/iPad between 2010-2014 by Takashi Mizuhiki and creative studio CUE, revealing a historical precedent in mobile music technology."
    ],
    "commentSummary": [
      "A web-based FM synthesizer, created using HTML5, has been introduced and shared on Hacker News, receiving predominantly positive feedback.",
      "Some users have experienced click artifacts in their browsers while using the synthesizer, indicating potential compatibility issues.",
      "There's ongoing discussion about Haskell and SQL programming languages' formatting style, and many users are sharing projects and resources linked to browser-based audio synthesis, demonstrating community participation."
    ],
    "points": 223,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1698630809
  },
  {
    "id": 38062923,
    "title": "DIY IP-KVM Based on Raspberry Pi",
    "originLink": "https://github.com/pikvm/pikvm",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up pikvm / pikvm Public Sponsor Notifications Fork 392 Star 6.7k Code Issues 75 Pull requests 1 Actions Security Insights pikvm/pikvm master 2 branches 0 tags Go to file Code Latest commit mdevaev update 45cdd72 Git stats 1,629 commits Files Type Name Latest commit message Commit time .github passwords doc docs update img v4 .gitignore docs.pikvm.org LICENSE license README.md new sponsor mkdocs.yml jiggler README.md Open and inexpensive DIY IP-KVM based on Raspberry Pi A very simple and fully functional Raspberry Pi-based KVM (Keyboard-Video-Mouse) over IP that you can make with your own hands. This device helps to manage servers or workstations remotely, regardless of the health of the operating system or whether one is installed. You can fix any problem, configure the BIOS, and even reinstall the OS using the virtual CD-ROM or Flash Drive. The website: pikvm.org. Also check out the documentation and join to the Discord Community Chat for news, questions and support! >>> New PiKVM V4 - Buy it right now! >> DIY Device Getting Started >> PiKVM V3 Getting Started 200ms, not very reliable), H.264 is not supported, Read more info about the limitations Only for Raspberry Pi 4: parts for Y-splitter cable (one variant at your choice): ❓ Why is this cable necessary? ❗Variant #1❗: (No mod solution - Amazon) Y cable with power blocker ends. ❗Variant #2❗: DIY for soldering or twist. ❗Variant #3❗: Ready-made using USB-micro splitter. ❗Variant #4❗: Ready-made using USB-C splitter. Only for Raspberry Pi Zero2W: 2x USB A-to-micro cables (male-male, for power and keyboard & mouse emulator). A power splitter OR a modded cable is required for this 2x usb configuration. 1x USB A-to-Micro is ONLY needed for direct connection to the target. 1x Raspberry Pi Zero Camera Cable (if using HDMI to CSI-2 Bridge, but not compatible with Auvidea B101, check pinout). For ATX control (optional): 4x MOSFET relays OMRON G3VM-61A1. 4x 390 Ohm resistors (see #46 for alternatives). 2x 4.7k Ohm resistors. A breadboard and wires. Kit parts suitable for assembly are also on sale in Poland Hardware for V0 Raspberry Pi 2 or 3. MicroSD card (8 GB is enough). USB-A 3A charger (female socket) or power supply. For keyboard & mouse emulator (HID): Arduino Pro Micro (based on an ATMega32u4). Logic level shifter. 1x NPN transistor (almost any NPN transistor: 2n2222 or similar). 1x 390 Ohm resistor. A breadboard and wires. 2x USB A-to-micro cables (male-male, for power and HID). HDMI capture device: see V2 description. ATX control (optional): see V2 description. Addition If you want to capture VGA from your server instead of HDMI, buy the VGA-to-HDMI converter. Some VGA HDMI adapters have issues with not supporting all resolutions and refresh rates. PiKVM can be powered using PoE, but it is not recommend to use the official PoE HAT: the old generation is not compatible with the HDMI bridge. Use any other PoE hat without an I2C fan controller. Don't use random relay modules or random optocouplers! Some relays or optocouplers may not be sensitive enough for the Raspberry Pi, some others may be low-level controlled. Either use relays that are activated by a high logic level, or follow the design provided and buy an OMRON. See details here. How to set up the device can be seen from here PiKVM V3 We have developed our own HAT and pre-assembled device based on the Raspberry Pi 4. The Pre-Assembled device The DIY kit >>> Buy PiKVM V3 right now! >> PiKVM V3 User Guide <<< HDMI video capture for extra low latency with MJPEG or H.264/WebRTC (1080p 50Hz max). HDMI audio capture. USB keyboard & mouse, bootable Virtual CD-ROM & Flash Drive; Ability to simulate \"removal and insertion\" for USB. Onboard ATX controller to manage the server's power. PWM fan controller. A real-time clock for accurate logging. CISCO-style and USB serial console port (to manage PiKVM OS or to connect the server). No need for soldering or breadboarding. It's a ready-made, reliable thing which you can use yourself or provide to your clients. Watch the video: PiKVM V3 Review by Novaspirit Tech Another review by Level1Techs Review by The Geek Freaks (DE) History: PiKVM V3 HAT on Kickstarter (huge success!) Setting up the hardware Connecting the video capture For the HDMI-CSI bridge ❗Click to show the instructions❗ For the HDMI-USB dongle ❗Click to show the instructions❗ Setting up the V2 ❗Click to show the instructions❗ Setting up the V0 ❗Click to show the instructions❗ The final steps Flash the operating system. Carefully read the \"First steps\" guide - how to find a device on the network, how to log in there, change passwords, and so on. Follow the steps described there and come back here. V0 only: flash the Arduino HID. Learn about the basics of working with PiKVM and CHANGE THE PASSWORDS Note for the HDMI-USB dongle: ❗Click to show❗ If you are a happy PiKVM V3 user then we have a special guide for you. Explore the features of PiKVM using the documentation's table of contents. Configure access to PiKVM from the Internet using port forwarding or Tailscale VPN. If you encounter a problem, take a look at the FAQ, but if nothing helped, contact our Discord chat - experienced users and the PiKVM team will definitely help you. OPTIONAL Addon: If adding an OLED to your V2, please see this. Happy using of PiKVM :) Donate This project is developed by Open Source enthusiasts. If you find PiKVM useful or it has saved you a long trip to check on an unresponsive server, you can support us by donating a few dollars on Patreon or Paypal or buying our devices. With this money, we will be able to buy new hardware (Raspberry Pi boards and other components) to test and maintain various configurations of PiKVM, and generally devote significantly more time to the project. At the bottom of this page are the names of all the people who have helped this project develop with their donations. Our gratitude knows no bounds! If you wish to use PiKVM in production, we accept orders to modify it for your needs or implement custom features you require. Contact us via live chat or email the lead developer at: mdevaev@gmail.com Special thanks These kind people donated money to the PiKVM project and supported work on it. We are very grateful for their help, and commemorating their names is the least we can do in return. View all people! About Open and inexpensive DIY IP-KVM based on Raspberry Pi pikvm.org Topics raspberry-pi hardware raspberrypi kvm ipmi vnc hdmi mass-storage-device vga atx ip-kvm ipkvm video-capture-device pi-kvm pikvm Resources Readme License GPL-3.0 license Activity Stars 6.7k stars Watchers 144 watching Forks 392 forks Report repository Sponsor this project patreon.com/pikvm https://paypal.me/pikvm Contributors 79 + 68 contributors Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=38062923",
    "commentBody": "DIY IP-KVM Based on Raspberry PiHacker NewspastloginDIY IP-KVM Based on Raspberry Pi (github.com/pikvm) 208 points by Croftengea 19 hours ago| hidepastfavorite72 comments INTPenis 8 hours agoOn the re-sellers page the Swedish&#x2F;Norwegian re-seller Direktronik [1] are selling the unit for 6300 SEK (534 Euro).1. https:&#x2F;&#x2F;www.direktronik.se&#x2F;direktronik&#x2F;natverk&#x2F;kvm-switchare... reply rekoil 4 hours agoparentSaw that too. Insane, predatory almost. The Swiss or Netherlands based shops seemed to be the most reasonable way if you wanted to buy the HAT. reply pizza 17 hours agoprevWould love a bluetooth muxer via rpi.Have a few devices that keep conflicting with one another and acquiring the connection to my bluetooth headset. I have to go through the hassle of navigating to the offending device&#x27;s bluetooth settings, disconnect it, go to my desired device&#x27;s settings (which, although it reports it is connected, doesn&#x27;t actually produce any sound), disconnect it, then reconnect it. Each time.I&#x27;d rather have them all stay connected (maybe one cheap dongle per endpoint) to my rpi and then route to the intended destination with just a press of a physical toggle&#x2F;key&#x2F;slider etc, or via phone app.Additionally would like to be able to simultaneously mix multiple audio sources to the one headset.. oh, and all of this with no latency overhead, please :) reply magixx 24 minutes agoparentI think the reverse of this kind of exists in the from of Bluetooth to 3.5mm receivers. The one I have and most I&#x27;ve seen support two connections so I can have both PC and laptop output sound on some speakers. You could probably chain a multi input receiver to a single output transmitter via 3.5mm to your Bluetooth headphones and just toggle connections on the receiver to select the device you want your headphones to use.The bad news is the latency which is about 200ms regularly and 40ms with APT Low Latency or 80ms with APT Adaptive. If you go BT > BT RX > BT TX > BT this might be doubled. Both devices will also need to support the same codes and only newer devices support APT Adaptive. reply adamzegelin 11 hours agoparentprevProbably do-able using Pipewire&#x2F;Pulseaudio.I just tried, and I&#x27;m able to pair both my Macbook Pro and iPhone to my Linux desktop PC. The PC has Kensington Bluetooth USB dongle. Both the MBP and iPhone can simultaneously play audio over Bluetooth and I can route the incoming audio to a pair of wired headphones. The volume of each stream is independently adjustable via `pavucontrol`.I also tried pairing a bluetooth headset, but the audio was choppy. Maybe too much bandwidth for 3 devices streaming audio at once? Maybe another dongle would work?Note that at one point I was experimenting with receiving BT audio on my PC. I can&#x27;t remember the exact set of configuration changes needed to make this work (if any -- it might&#x27;ve worked out of the box). But the stack is BlueZ + Pipewire on Archlinux.Pipewire (and Pulse) have a lot of modules and config knobs. Might be possible to get auto-switch working too. They also expose a D-Bus interface, so control from some sort of e.g. Python webapp from your phone is likely. reply Nextgrid 6 hours agorootparentDefinitely possible, and I&#x27;ve done a similar proof of concept using PipeWire with \"Wireplumber\" as the GUI to map the required inputs&#x2F;outputs to a wired headset.The problem was that I had no clue where to even begin to make this setup persistent so I could eventually put it all on a GUI-less RPi, so I gave up. reply consp 9 hours agorootparentprev> I also tried pairing a bluetooth headset, but the audio was choppy.Try reconnecting it. I have the same problem with my headset sometimes and reconnecting fixes it. My best guess is the implementation of the two Bluetooth modules don&#x27;t play nice with each other. I have no troubles connecting to a different pc. reply fensgrim 1 hour agoparentprevI had plans to do such project for exactly same reasons since, like, 2011..Wanted to have pulseaudio&#x2F;alsa dmix handling multiple streams&#x2F;mixing them out with a help of dedicated hardware BT&#x2F;DAC-ADC-BT path, with a goal to have smart handling of voice calls over music on the go, fake 5.1 in the room, and a voice enhancer &#x2F; fast rewind for call streams..Then, Volumio took enough of the raspberry-based hifi market (despite having no bluetooth support, lol) that I&#x27;ve declared these plans no-go as investing in this solely for fun wasn&#x27;t that enticing, compared to just getting a spare set of equipment to separate work&#x2F;home audio. reply deegles 12 hours agoparentprevYou could do it with a 4 channel mixer and USB audio devices hooked up to one Bluetooth transmitter... I don&#x27;t know about latency though and good luck with the cable management!Rolls MX51S Mini Mix 2 Four-Channel Mixer https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;48XLqLiUSB to RCA https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;iam01XjBluetooth 5.0 Transmitter 3-in-1 https:&#x2F;&#x2F;a.co&#x2F;d&#x2F;47TuAMn reply midasuni 7 hours agoparentprevSo a normal analog 3.5mm input into a cheap mixer?20 years on and bluetooth still can’t get the ease and reliability of a 50 cent audio cable. reply redserk 6 hours agorootparentDepends on your devices. My Airpods switch between my iPhone, Macbook, and iPad without issue. reply progbits 17 hours agoprevI like this project but the hardware seems quite overpriced at $300+. Similar for tinypilotkvm.com.In the past I&#x27;ve considered making and selling a cheaper version. Aside from lack of time (or motivation), one thing which discouraged me is that I would feel bad \"undercutting\" someone selling open hardware. reply mtlynch 16 hours agoparentTinyPilot founder here.I understand the feedback about the price. When I created the original TinyPilot,[0] I wanted a low-priced alternative to the $600 KVM over IP options I was seeing, and now I sell my devices for $400-500&#x2F;unit.The thing that&#x27;s tough about selling hardware is that it seems easy to produce a few units cheaply, but creating a sustainable business for it, the costs add up. You have to fulfill orders, provide support when there are delivery issues, provide support when the customer has trouble understanding how to connect to a device on their local network. And there&#x27;s certification, stockpiling components so you don&#x27;t run out of stock, managing inventory from many different vendors.TinyPilot became profitable in 2023, but for the first 2.5 years, we were operating at a loss. [1]Also, small correction: no KVM over IP vendor is really selling open hardware. The part that&#x27;s open is the software. I haven&#x27;t seen any vendors publish their hardware schematics. It&#x27;s expensive to create PCBs, and it&#x27;s not like open-source software where you can hope to get useful external contributions.[0] https:&#x2F;&#x2F;tinypilotkvm.com&#x2F;blog&#x2F;build-a-kvm-over-ip-under-100[1] https:&#x2F;&#x2F;mtlynch.io&#x2F;retrospectives&#x2F;2023&#x2F;10&#x2F;#tinypilothttpstin... reply SCUSKU 14 hours agorootparentI have been following the TinyPilot project on & off for a while, and I just wanted to say I appreciate your openness as well as your excellent attitude toward feedback. I think many of us (myself included) have been spoiled with various forms of free&#x2F;open software and have come to expect things to be cheap or free.But of course github stars and positive reviews won&#x27;t pay our bills. So it totally makes sense to charge what you are charging for your product. You deserve it, and you&#x27;re clearly putting in hard and honest work. If and when I need a KVM I will 100% be reaching for a TinyPilot. reply fensgrim 1 hour agorootparentprev> provide support when the customer has trouble understanding how to connect to a device on their local network.Is it possible to order current revision of TinyPilot for someone in a remote location and connect to it on arrival through some managed service - without going through all the hoops of helping end user with setting up some form of reverse shell (e.g. either meshcentral or openvpn&#x2F;wireguard for webinterface)? reply mtlynch 1 hour agorootparentNo, unfortunately that&#x27;s not something we offer.Customers could do that on their end, but they&#x27;d have to buy the device from us, configure it for remote access,[0] and then forward the device to the final destination.[0] https:&#x2F;&#x2F;tinypilotkvm.com&#x2F;faq&#x2F;cloud-access reply progbits 5 hours agorootparentprevHey, thanks for commenting. I&#x27;m a big fan of your transparency and don&#x27;t get me wrong, I like the product and the price is certainly better than the \"enterprise\" gear.But I personally don&#x27;t care about support, the enclosure can be 3d printed or some cheap plastic box, if sold as DIY kit it would save assembly costs and avoid need for certification and so on. I think there is a small market for homelabers like myself who would pay maybe $100-150 for a simpler product.And congrats on being profitable. reply mtlynch 1 hour agorootparent>But I personally don&#x27;t care about support, the enclosure can be 3d printed or some cheap plastic box, if sold as DIY kit it would save assembly costs and avoid need for certification and so on. I think there is a small market for homelabers like myself who would pay maybe $100-150 for a simpler product.We used to sell both the pre-made units and a $190 DIY kit. Surprisingly, when I tried removing the DIY kits, sales jumped by 50%. And it wasn&#x27;t just higher revenue because people were buying the more expensive product - order volume increased too.[0]My theory is that when we asked customers if they wanted to pay more for a pre-made version, some of them stopped to think about which version they wanted and then just never returned. So, when we simplified to just one product, it eliminated friction in the buying process.With the Pi 4 shortage the past few years, using our limited Pi 4 supply for DIY kits instead of our pre-made product would be a terrible move. We&#x27;re expecting the shortage to be over in the next few months, but even if there was a way for me to sell an extra 50 units per month at a $50 profit, selling a second product line and managing it end-to-end is so complicated that it wouldn&#x27;t be worth the extra $2.5k&#x2F;month. And that $2.5k&#x2F;month is before chargebacks, hiring people to assemble and fulfill the kits, etc.We do still work to serve DIY customers and make sure our software stays compatible with users who just use off-the-shelf parts. And we still sell a power splitter,[1] as it&#x27;s the one thing you can&#x27;t really buy off the shelf from other vendors. We&#x27;re able to do that because they cost about $10&#x2F;unit to make, so we can make a year&#x27;s worth in a week and just ship them to our warehouse. But doing that with a whole kit would be way more costly.[0] https:&#x2F;&#x2F;mtlynch.io&#x2F;retrospectives&#x2F;2021&#x2F;12&#x2F;#reducing-to-a-sin...[1] https:&#x2F;&#x2F;tinypilotkvm.com&#x2F;product&#x2F;tinypilot-power-connector reply zeagle 4 hours agorootparentprevI&#x27;m very impressed with your write up and transparency. I hope the manufacturing issues are sorted out! I don&#x27;t manufacture anything but I&#x27;ve read a 3x rule of sale price to raw input cost. reply wferrell 15 hours agorootparentprevFan of your work, your blog and your openness. Thank you. reply mtlynch 15 hours agorootparentThanks! I appreciate you saying that. reply Aurornis 16 hours agoparentprevYou’d be surprised at how expensive it can be to manufacture, program, test, package, warehouse, sell, ship, and support small hardware projects like this.It may seem overpriced when compared to collecting all of the pieces and putting them together for yourself, but the person trying to do this as a business has to make a big investment in up front purchasing as well as labor to get them all together and shipped out. It quickly reaches a point where doing it for an “undercutting” level price doesn’t justify the risk and effort. reply JonChesterfield 5 hours agorootparentIt helps to remember that your own time has a cost associated with it. Standing one up from pieces is probably a couple of days of indecision over component selection and loss to misc software refusing to behave itself.An arm soc is probably $100. So break even is maybe $200 per day getting the thing working. Thus should buy the thing, unless you particularly enjoy the construction process more than whatever else you could spend the weekend doing.The posted profit over time figures suggests the above back of envelope is rather optimistic, so there&#x27;s a non-zero risk that after the weekend the thing wouldn&#x27;t work.(and thus I&#x27;ve learned that the UK distributor is in Germany with possible brexit&#x2F;VAT hazards, but hopefully it&#x27;ll turn up at some point) reply geerlingguy 15 hours agoparentprevNote there are also alternative Pi-KVM hardware boards (in a variety of formats) from BliKVM.They don&#x27;t seem to directly support the upstream project, and I believe they may have even forked some of the software from PiKVM and TinyPilot both and may or may not have provided proper attribution&#x2F;recognition... so take that as you may. reply m463 15 hours agoparentprevbasic functionality with generic hardware looks doable and one-clickable for a pi4:usb splitter $9 - https:&#x2F;&#x2F;www.amazon.com&#x2F;dp&#x2F;B08C5FWQNDusb power blocker $7 - https:&#x2F;&#x2F;www.amazon.com&#x2F;dp&#x2F;B094FYL9QThdmi-csi2 adapter $32 - https:&#x2F;&#x2F;www.amazon.com&#x2F;dp&#x2F;B09GY9M9BXatx power control looks less off-the-shelf reply Y_Y 2 hours agorootparentYou can save even more by making the splitter&#x2F;power blocker yourself. It&#x27;s simple enough that you can even do it by twisting instead of proper soldering, as long as you have a couple of cables you can sacrifice. On top of that you can get a cheaper hdmi-usb converter instead of using MIPI. They don&#x27;t recommend it because the latency is bad and it&#x27;s awkward, but it&#x27;s still serviceable, especially if you only use the KVM for quick tasks. Doing it this way you could make the thing for only about ten euro cost on top of the pi. reply numpad0 9 hours agoparentprevI wonder if the cost can be cut by replacing computer part with ESP32 at the cost of losing .iso mount and video input quality, and at the same time take out SD card anxiety. The only problem is difficulty of getting framebuffer cheaply, I think. reply themoonisachees 7 hours agorootparentA kvm without iso mount may as well not be a kvm at al reply vbezhenar 5 hours agorootparentprevRaspberry Pi cost is few bucks. You won&#x27;t save significant money here, but will lose very significant computing power and software ecosystem. reply numpad0 4 hours agorootparentBut it&#x27;s also bloat on a rescue device. KVM has to and only has to work when a remote computer is unable to come back online, no need for computing power or app marketplace to fix that. reply jermaustin1 17 hours agoparentprev>I would feel bad \"undercutting\" someone selling open hardwareAs a potential customer, I feel bad you feel that way. reply theodric 17 hours agorootparentRoll your own. I&#x27;ve got one running PiKVM software on a Pi Zero 2W with an AliExpress HDMI-CSI board connected, and the whole thing bundled together with kapton tape and hanging off the USB port on a headless system. I had to mask off one pin on one of the two microUSB cables. I think I&#x27;m into it for about €50 including the Pi0. The instructions are&#x2F;were on their website. reply MaKey 2 hours agorootparentDo you have a link? reply maxlin 15 hours agoprevI once wanted to build one like this, but for console devkits. That situation was and went, but I did end up wanting to have the same for all windows machines at work and home (Unity dev, so workstations, test runners even servers are desktop windows machines).My solution was:-BIOS: auto-power on when power is connected-Smart power plugs on important computers-AnyDesk for software on all machines, with unattended password set (connectable even at login screen, less annoying for licenses than Teamviewer)-(Optional) my own WoL sending &#x2F; restarting &#x2F; RAT program for all the machines too-(Optional) Parsec also installed, to allow remote desktop good enough latency&#x2F;control wise for actually gaming remotely (which I often did!)This way, I will never be stuck in a situation that I can&#x27;t access a machine that I&#x27;m away from, unless it&#x27;s one of those without a smartplug and has somehow hard crashed. Costs less than 20€ per machine. I&#x27;ve NEVER needed to access the bios or similar remotely.I&#x27;ve recently played around with a lot of SBC&#x27;s and have a spare capture card and cheaper sbc&#x27;s that could work as OTG keyboards. Might end up building a crappy version of one of these for fun reply rfoo 8 hours agoparentI have one and indeed my only use of it is to type in BitLocker password when I&#x27;m not at home. I really hope one day I can just ssh in and unlock the disk like what I do with LUKS. reply PaulWaldman 13 hours agoparentprevI went with a similar setup and the only thing I&#x27;d add to your list is using multiple NICs and having one dedicated for remote management. reply gmurphy 15 hours agoprevIf price is a barrier, a less open, fiddlier, but much cheaper ($79) solution I&#x27;ve used recently is the Aurga viewer[0]. You have to use their awful apps to access the device, but if you can get past that, it does work - I was able to access and control the BIOS of a NUC I had in a closet. It can join a wifi network or host its own, which is useful in the field.[0] https:&#x2F;&#x2F;www.aurga.com&#x2F; reply squarefoot 9 hours agoprevThe suggested CSI2 adapter works up to 25fps at 1080p, while this one which also declares compatibility with the Rpi goes up to 60fps at the same resolution.https:&#x2F;&#x2F;www.aliexpress.com&#x2F;item&#x2F;1005002861310912.html reply thewanderer1983 18 hours agoprevHere is another one about to go live on crowdsupply. https:&#x2F;&#x2F;www.crowdsupply.com&#x2F;hackergadgets&#x2F;pi-cast reply dr_kiszonka 11 hours agoprevI am curious if there are any decent and very affordable regular KVMs (to use locally, not over IP).The cheapest one I found for a three monitor DP setup was ~$500 (Star Tech). reply mbrameld 11 hours agoparentBest value I&#x27;ve found is a just a cheap USB switcher for the keyboard and mouse and use the monitor input switch for video. Might not work for all use cases, but if you just have 2 computers you want to switch between it works pretty well. reply universa1 9 hours agorootparentAdding to this: search for haimgel&#x2F;Display-Switch[1] on GitHub, which can switch monitor inputs using DDC commands on USB connect&#x2F;disconnect events. Poor man&#x27;s KVM :-)[1] https:&#x2F;&#x2F;github.com&#x2F;haimgel&#x2F;display-switch reply newsclues 5 hours agoparentprevhttps:&#x2F;&#x2F;www.store.level1techs.com&#x2F;products&#x2F;p&#x2F;14-kvm-switch-t...Not the cheapest, but very good. reply breitling 5 hours agoprevNot sure how common knowledge this is, but there&#x27;s a growing community of people using this for work from home gigs. reply comprambler 17 hours agoprevUsed Raritans are pretty cheap on ebay. The dongles are even cheaper. reply hattmall 16 hours agoparentCan you explain what all would be needed to make a similar setup? I see the dongles for ~30 but does it need to be in a location with another piece of hardware or what? reply mcpherrinm 16 hours agorootparentYou buy a KVM device like the raritan kxiii. That’s a rack-mount unit that’ll support a bunch of connected devices.For each connected device you need a dongle, which is what will plug into the display and usb ports of the server. reply comprambler 14 minutes agorootparentCorrect, the dongles connect via ethernet cables (not ip protocol) to the raritan unit. Then you access the raritan via IP to access the dongle outputs. reply mike_d 12 hours agorootparentprevThere is a great video from Level 1 Techs where he explains why he started making KVMs and why it is an extremely hard problem. (Edit: I can&#x27;t seem to find the video now, it might have been on another channel, but I&#x27;ll keep looking)The TLDR is that manufactures don&#x27;t follow specs as closely as you&#x27;d think, and as a KVM you have to handle the bugs of thousands of different manufactures for both upstream and downstream devices. reply ajot 17 hours agoprevI&#x27;ve recently seen this project in Wolfgang&#x27;s Channel [0]. The team behind it seem to be pretty nice about the open source nature of it and the DIY ways of getting a similar hardware doing the same thing as their own product. Kudos to them![0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=BpKcqLcApTQ reply johnklos 14 hours agoprevI&#x27;m glad projects like this exist, but I&#x27;m too lazy and more than happy to have a Pi provide a serial console and a hardware reset via GPIO over IPv6 for colocated hardware. It&#x27;s much simpler ;) reply nilespotter 14 hours agoparentI thought about building one of these, but then I just switched both of my servers to boards with IPMI reply jofla_net 17 hours agoprevi got the V3 a bit ago, was definately worth it for an out-of-box running solution. though the fan settings needed fiddling so as to not make too much noise. KVMD_FAN_ARGS=\"--speed-idle=50 --speed-low=60 --temp-low=50\"anywhoo for those who never and are curious the lag is almost entirely on the return channel, processing the hdmi signal and getting it back to client side. it is definatley useable for programming but certainly not for any interactive graphics or gaming. i&#x27;m wondering if since its a processing bottneck if overclocking the pi would speed it up a bit... it seems to idle at around %20 usage as per the little display. reply hackcasual 16 hours agoparentV4 is a massive improvement in lag. The CM4 doubles the camera interface bandwidth, which was the bottle neck. reply mouth 15 hours agorootparentHow much has video lag improved? reply hugs 18 hours agoprevI&#x27;m currently working on a variation of this, specifically for accessing&#x2F;controlling smartphones. My hunch is that even though a hardware-based KVM approach was meant for remote manual control, it could also be extremely useful for automation (and specifically test automation). But the big question is if anyone would agree with me about that. Hope to find out soon enough... reply RockRobotRock 18 hours agoprevIt works great! I got a cheaper case and modules from aliexpress, though. reply nirav72 12 hours agoparentWhich module&#x2F;case did you get? I saw a bunch of them sold as BliKVM. Is that it? reply RockRobotRock 8 hours agorootparentGeekworm&#x27;s KVM kits are what I got. reply girishso 15 hours agoprevLittle confused, can this be used for Remote Desktop sharing, like VNC? reply numpad0 15 hours agoparentIP-KVMs are more useful for fixing remote access without physically interacting servers. In cases where a server is stuck in BIOS, BSoD, wrong IP configured, just waiting for a RETURN key input, etc. and not responding to RDP&#x2F;VNC&#x2F;SSH, an operator can log into KVM to unstuck it. reply hugs 15 hours agoparentprevIt can... but this goes one level lower to the hardware layer... so that you can do things like reboot the computer and view&#x2F;edit BIOS settings (since you&#x27;re viewing the same raw HDMI signal that would otherwise show up on a real monitor display). You wouldn&#x27;t be able view the BIOS with Remote Desktop or VNC because those are not available until after the operating system has launched. reply xupybd 18 hours agoprevAll the use cases I have for one of these would need VGA sadly. reply hugs 18 hours agoparentThe project lists several DIY options for building (more like buying and plugging in) the hardware yourself. You might be able to find an off-the-shelf VGA-to-HDMI adapter&#x2F;converter that would then be downstream compatible with the rest of the stack. There is discussion about VGA support in the project&#x27;s GitHub Issues and Discord. reply RockRobotRock 18 hours agoparentprev AMT is designed into a service processor located on the motherboard, and uses TLS-secured communication and strong encryption to provide additional security.[6] AMT is built into PCs with Intel vPro technology and is based on the Intel Management Engine (ME).[6] AMT has moved towards increasing support for DMTF Desktop and mobile Architecture for System Hardware (DASH) standards and AMT Release 5.1 and later releases are an implementation of DASH version 1.0&#x2F;1.1 standards for out-of-band management.[7] AMT provides similar functionality to IPMI, although AMT is designed for client computing systems as compared with the typically server-based IPMI.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;linux&#x2F;comments&#x2F;s41a17&#x2F;in_2017_amd_p... :> To understand what PSP and ME can do you need to understand CPU security rings. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Protection_ring . These are different levels of privilege software has on the system.> Originally the Linux kernel occupies ring 0, which is the level with highest privilege. Then user space would run in some other ring.> However with things like PSP and ME they have created rings lower then ring 0. Things like Ring -1 and -2. Intel Minix ME runs in -3 ring.vPro supports VNC over TLS.coreboot and Libreboot don&#x27;t support PQ SSH, TLS, VNC, or DASH; https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Libreboot, https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;CorebootDASH: Desktop and Mobile Architecture for System Hardware https:&#x2F;&#x2F;www.dmtf.org&#x2F;standards&#x2F;dash :> DASH provides support for the redirection of KVM (Keyboard, Video and Mouse) and text consoles, as well as USB and media, and supports the management of software updates, BIOS (Basic Input Output System), batteries, NIC (Network Interface Card), MAC and IP addresses, as well as DNS and DHCP configuration. reply renewiltord 17 hours agoprev [–] We have a couple of these. They&#x27;re actually quite nice.I wish the Asrock Rack boards would have a similar letsencrypt integration. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "PiKVM is an open-source, cost-effective DIY IP-KVM system that utilizes Raspberry Pi for remotely managing servers or workstations. It assists in troubleshooting, BIOS configuration, and OS reinstallation.",
      "The project provides various versions of the device, with guidance and assistance made accessible through their website and Discord community.",
      "PiKVM has specific requisites for certain Raspberry Pi models and extra components needed for particular configurations. The initiative accepts donations and provides customization for commercial usage."
    ],
    "commentSummary": [
      "The central topic is the development of an affordable, simplified version of a remote access device known as Pi-KVM.",
      "User experiences, solution suggestions, and alternatives are discussed in the thread, along with responses from a founder of a similar project on hardware selling challenges.",
      "The discussion also features DIY options for constructing or purchasing hardware and outlines functionalities offered by DASH for out-of-band management."
    ],
    "points": 208,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1698614351
  },
  {
    "id": 38060912,
    "title": "Carl Sagan's Rules for Bullshit-Busting and Critical Thinking",
    "originLink": "https://www.themarginalian.org/2014/01/03/baloney-detection-kit-carl-sagan/",
    "originBody": "Each month, I spend hundreds of hours and thousands of dollars keeping The Marginalian going. For seventeen years, it has remained free and ad-free and alive thanks to patronage from readers. I have no staff, no interns, not even an assistant — a thoroughly one-woman labor of love that is also my life and my livelihood. If this labor has made your own life more livable in the past year (or the past decade), please consider aiding its sustenance with a one-time or loyal donation. Your support makes all the difference. MONTHLY DONATION ♥ $3 / month ♥ $5 / month ♥ $7 / month ♥ $10 / month ♥ $25 / month START NOW ONE-TIME DONATION You can also become a spontaneous supporter with a one-time donation in any amount: GIVE NOW BITCOIN DONATION Partial to Bitcoin? You can beam some bit-love my way: 197usDS6AsL9wDKxtGM6xaWjmR5ejgqem7 Need to cancel a recurring donation? Go here. archives browse by subject culture books art psychology philosophy science history design illustration children's books all subjects SURPRISE ME ABOUT CONTACT SUPPORT SUBSCRIBE Newsletter RSS CONNECT Facebook Twitter Instagram Tumblr sunday newsletter The Marginalian has a free Sunday digest of the week's most mind-broadening and heart-lifting reflections spanning art, science, poetry, philosophy, and other tendrils of our search for truth, beauty, meaning, and creative vitality. Here's an example. Like? Claim yours: midweek newsletter Also: Because The Marginalian is well into its second decade and because I write primarily about ideas of timeless nourishment, each Wednesday I dive into the archive and resurface from among the thousands of essays one worth resavoring. Subscribe to this free midweek pick-me-up for heart, mind, and spirit below — it is separate from the standard Sunday digest of new pieces: also The Universe in Verse Figuring The Snail with the Right Heart: A True Story A Velocity of Being art sounds bites bookshelf favorite reads 16 Life-Learnings from 16 Years of The Marginalian Hannah Arendt on Love and How to Live with the Fundamental Fear of Loss Trial, Triumph, and the Art of the Possible: The Remarkable Story Behind Beethoven’s “Ode to Joy” Resolutions for a Life Worth Living: Attainable Aspirations Inspired by Great Humans of the Past Emily Dickinson’s Electric Love Letters to Susan Gilbert The Courage to Be Yourself: E.E. Cummings on Art, Life, and Being Unafraid to Feel Singularity: Marie Howe’s Ode to Stephen Hawking, Our Cosmic Belonging, and the Meaning of Home, in a Stunning Animated Short Film How Kepler Invented Science Fiction and Defended His Mother in a Witchcraft Trial While Revolutionizing Our Understanding of the Universe Rebecca Solnit’s Lovely Letter to Children About How Books Solace, Empower, and Transform Us Fixed vs. Growth: The Two Basic Mindsets That Shape Our Lives In Praise of the Telescopic Perspective: A Reflection on Living Through Turbulent Times A Stoic’s Key to Peace of Mind: Seneca on the Antidote to Anxiety The Writing of “Silent Spring”: Rachel Carson and the Culture-Shifting Courage to Speak Inconvenient Truth to Power A Rap on Race: Margaret Mead and James Baldwin’s Rare Conversation on Forgiveness and the Difference Between Guilt and Responsibility The Science of Stress and How Our Emotions Affect Our Susceptibility to Burnout and Disease Mary Oliver on What Attention Really Means and Her Moving Elegy for Her Soul Mate Rebecca Solnit on Hope in Dark Times, Resisting the Defeatism of Easy Despair, and What Victory Really Means for Movements of Social Change SEE MORE related reads Carl Sagan’s Cosmos, Remastered The Two Pillars of the Sensible and Sensitive Mind: Carl Sagan on Mastering the Vital Balance of Skepticism and Openness Carl Sagan on Moving Beyond Us vs. Them, Bridging Conviction with Compassion, and Meeting Ignorance with Kindness labors of love Famous Writers' Sleep Habits vs. Literary Productivity, Visualized 7 Life-Learnings from 7 Years of Brain Pickings, Illustrated Anaïs Nin on Love, Hand-Lettered by Debbie Millman Anaïs Nin on Real Love, Illustrated by Debbie Millman Susan Sontag on Love: Illustrated Diary Excerpts Susan Sontag on Art: Illustrated Diary Excerpts Albert Camus on Happiness and Love, Illustrated by Wendy MacNaughton The Holstee Manifesto The Silent Music of the Mind: Remembering Oliver Sacks The Baloney Detection Kit: Carl Sagan’s Rules for Bullshit-Busting and Critical Thinking BY MARIA POPOVA Carl Sagan (November 9, 1934–December 20, 1996) was many things — a cosmic sage, voracious reader, hopeless romantic, and brilliant philosopher. But above all, he endures as our era’s greatest patron saint of reason and critical thinking, a master of the vital balance between skepticism and openness. In The Demon-Haunted World: Science as a Candle in the Dark (public library) — the same indispensable volume that gave us Sagan’s timeless meditation on science and spirituality, published mere months before his death in 1996 — Sagan shares his secret to upholding the rites of reason, even in the face of society’s most shameless untruths and outrageous propaganda. In a chapter titled “The Fine Art of Baloney Detection,” Sagan reflects on the many types of deception to which we’re susceptible — from psychics to religious zealotry to paid product endorsements by scientists, which he held in especially low regard, noting that they “betray contempt for the intelligence of their customers” and “introduce an insidious corruption of popular attitudes about scientific objectivity.” (Cue in PBS’s Joe Hanson on how to read science news.) But rather than preaching from the ivory tower of self-righteousness, Sagan approaches the subject from the most vulnerable of places — having just lost both of his parents, he reflects on the all too human allure of promises of supernatural reunions in the afterlife, reminding us that falling for such fictions doesn’t make us stupid or bad people, but simply means that we need to equip ourselves with the right tools against them. Through their training, scientists are equipped with what Sagan calls a “baloney detection kit” — a set of cognitive tools and techniques that fortify the mind against penetration by falsehoods: The kit is brought out as a matter of course whenever new ideas are offered for consideration. If the new idea survives examination by the tools in our kit, we grant it warm, although tentative, acceptance. If you’re so inclined, if you don’t want to buy baloney even when it’s reassuring to do so, there are precautions that can be taken; there’s a tried-and-true, consumer-tested method. But the kit, Sagan argues, isn’t merely a tool of science — rather, it contains invaluable tools of healthy skepticism that apply just as elegantly, and just as necessarily, to everyday life. By adopting the kit, we can all shield ourselves against clueless guile and deliberate manipulation. Sagan shares nine of these tools: Wherever possible there must be independent confirmation of the “facts.” Encourage substantive debate on the evidence by knowledgeable proponents of all points of view. Arguments from authority carry little weight — “authorities” have made mistakes in the past. They will do so again in the future. Perhaps a better way to say it is that in science there are no authorities; at most, there are experts. Spin more than one hypothesis. If there’s something to be explained, think of all the different ways in which it could be explained. Then think of tests by which you might systematically disprove each of the alternatives. What survives, the hypothesis that resists disproof in this Darwinian selection among “multiple working hypotheses,” has a much better chance of being the right answer than if you had simply run with the first idea that caught your fancy. Try not to get overly attached to a hypothesis just because it’s yours. It’s only a way station in the pursuit of knowledge. Ask yourself why you like the idea. Compare it fairly with the alternatives. See if you can find reasons for rejecting it. If you don’t, others will. Quantify. If whatever it is you’re explaining has some measure, some numerical quantity attached to it, you’ll be much better able to discriminate among competing hypotheses. What is vague and qualitative is open to many explanations. Of course there are truths to be sought in the many qualitative issues we are obliged to confront, but finding them is more challenging. If there’s a chain of argument, every link in the chain must work (including the premise) — not just most of them. Occam’s Razor. This convenient rule-of-thumb urges us when faced with two hypotheses that explain the data equally well to choose the simpler. Always ask whether the hypothesis can be, at least in principle, falsified. Propositions that are untestable, unfalsifiable are not worth much. Consider the grand idea that our Universe and everything in it is just an elementary particle — an electron, say — in a much bigger Cosmos. But if we can never acquire information from outside our Universe, is not the idea incapable of disproof? You must be able to check assertions out. Inveterate skeptics must be given the chance to follow your reasoning, to duplicate your experiments and see if they get the same result. Just as important as learning these helpful tools, however, is unlearning and avoiding the most common pitfalls of common sense. Reminding us of where society is most vulnerable to those, Sagan writes: In addition to teaching us what to do when evaluating a claim to knowledge, any good baloney detection kit must also teach us what not to do. It helps us recognize the most common and perilous fallacies of logic and rhetoric. Many good examples can be found in religion and politics, because their practitioners are so often obliged to justify two contradictory propositions. He admonishes against the twenty most common and perilous ones — many rooted in our chronic discomfort with ambiguity — with examples of each in action: ad hominem — Latin for “to the man,” attacking the arguer and not the argument (e.g., The Reverend Dr. Smith is a known Biblical fundamentalist, so her objections to evolution need not be taken seriously) argument from authority (e.g., President Richard Nixon should be re-elected because he has a secret plan to end the war in Southeast Asia — but because it was secret, there was no way for the electorate to evaluate it on its merits; the argument amounted to trusting him because he was President: a mistake, as it turned out) argument from adverse consequences (e.g., A God meting out punishment and reward must exist, because if He didn’t, society would be much more lawless and dangerous — perhaps even ungovernable. Or: The defendant in a widely publicized murder trial must be found guilty; otherwise, it will be an encouragement for other men to murder their wives) appeal to ignorance — the claim that whatever has not been proved false must be true, and vice versa (e.g., There is no compelling evidence that UFOs are not visiting the Earth; therefore UFOs exist — and there is intelligent life elsewhere in the Universe. Or: There may be seventy kazillion other worlds, but not one is known to have the moral advancement of the Earth, so we’re still central to the Universe.) This impatience with ambiguity can be criticized in the phrase: absence of evidence is not evidence of absence. special pleading, often to rescue a proposition in deep rhetorical trouble (e.g., How can a merciful God condemn future generations to torment because, against orders, one woman induced one man to eat an apple? Special plead: you don’t understand the subtle Doctrine of Free Will. Or: How can there be an equally godlike Father, Son, and Holy Ghost in the same Person? Special plead: You don’t understand the Divine Mystery of the Trinity. Or: How could God permit the followers of Judaism, Christianity, and Islam — each in their own way enjoined to heroic measures of loving kindness and compassion — to have perpetrated so much cruelty for so long? Special plead: You don’t understand Free Will again. And anyway, God moves in mysterious ways.) begging the question, also called assuming the answer (e.g., We must institute the death penalty to discourage violent crime. But does the violent crime rate in fact fall when the death penalty is imposed? Or: The stock market fell yesterday because of a technical adjustment and profit-taking by investors — but is there any independent evidence for the causal role of “adjustment” and profit-taking; have we learned anything at all from this purported explanation?) observational selection, also called the enumeration of favorable circumstances, or as the philosopher Francis Bacon described it, counting the hits and forgetting the misses (e.g., A state boasts of the Presidents it has produced, but is silent on its serial killers) statistics of small numbers — a close relative of observational selection (e.g., “They say 1 out of every 5 people is Chinese. How is this possible? I know hundreds of people, and none of them is Chinese. Yours truly.” Or: “I’ve thrown three sevens in a row. Tonight I can’t lose.”) misunderstanding of the nature of statistics (e.g., President Dwight Eisenhower expressing astonishment and alarm on discovering that fully half of all Americans have below average intelligence); inconsistency (e.g., Prudently plan for the worst of which a potential military adversary is capable, but thriftily ignore scientific projections on environmental dangers because they’re not “proved.” Or: Attribute the declining life expectancy in the former Soviet Union to the failures of communism many years ago, but never attribute the high infant mortality rate in the United States (now highest of the major industrial nations) to the failures of capitalism. Or: Consider it reasonable for the Universe to continue to exist forever into the future, but judge absurd the possibility that it has infinite duration into the past); non sequitur — Latin for “It doesn’t follow” (e.g., Our nation will prevail because God is great. But nearly every nation pretends this to be true; the German formulation was “Gott mit uns”). Often those falling into the non sequitur fallacy have simply failed to recognize alternative possibilities; post hoc, ergo propter hoc — Latin for “It happened after, so it was caused by” (e.g., Jaime Cardinal Sin, Archbishop of Manila: “I know of … a 26-year-old who looks 60 because she takes [contraceptive] pills.” Or: Before women got the vote, there were no nuclear weapons) meaningless question (e.g., What happens when an irresistible force meets an immovable object? But if there is such a thing as an irresistible force there can be no immovable objects, and vice versa) excluded middle, or false dichotomy — considering only the two extremes in a continuum of intermediate possibilities (e.g., “Sure, take his side; my husband’s perfect; I’m always wrong.” Or: “Either you love your country or you hate it.” Or: “If you’re not part of the solution, you’re part of the problem”) short-term vs. long-term — a subset of the excluded middle, but so important I’ve pulled it out for special attention (e.g., We can’t afford programs to feed malnourished children and educate pre-school kids. We need to urgently deal with crime on the streets. Or: Why explore space or pursue fundamental science when we have so huge a budget deficit?); slippery slope, related to excluded middle (e.g., If we allow abortion in the first weeks of pregnancy, it will be impossible to prevent the killing of a full-term infant. Or, conversely: If the state prohibits abortion even in the ninth month, it will soon be telling us what to do with our bodies around the time of conception); confusion of correlation and causation (e.g., A survey shows that more college graduates are homosexual than those with lesser education; therefore education makes people gay. Or: Andean earthquakes are correlated with closest approaches of the planet Uranus; therefore — despite the absence of any such correlation for the nearer, more massive planet Jupiter — the latter causes the former) straw man — caricaturing a position to make it easier to attack (e.g., Scientists suppose that living things simply fell together by chance — a formulation that willfully ignores the central Darwinian insight, that Nature ratchets up by saving what works and discarding what doesn’t. Or — this is also a short-term/long-term fallacy — environmentalists care more for snail darters and spotted owls than they do for people) suppressed evidence, or half-truths (e.g., An amazingly accurate and widely quoted “prophecy” of the assassination attempt on President Reagan is shown on television; but — an important detail — was it recorded before or after the event? Or: These government abuses demand revolution, even if you can’t make an omelette without breaking some eggs. Yes, but is this likely to be a revolution in which far more people are killed than under the previous regime? What does the experience of other revolutions suggest? Are all revolutions against oppressive regimes desirable and in the interests of the people?) weasel words (e.g., The separation of powers of the U.S. Constitution specifies that the United States may not conduct a war without a declaration by Congress. On the other hand, Presidents are given control of foreign policy and the conduct of wars, which are potentially powerful tools for getting themselves re-elected. Presidents of either political party may therefore be tempted to arrange wars while waving the flag and calling the wars something else — “police actions,” “armed incursions,” “protective reaction strikes,” “pacification,” “safeguarding American interests,” and a wide variety of “operations,” such as “Operation Just Cause.” Euphemisms for war are one of a broad class of reinventions of language for political purposes. Talleyrand said, “An important art of politicians is to find new names for institutions which under old names have become odious to the public”) Sagan ends the chapter with a necessary disclaimer: Like all tools, the baloney detection kit can be misused, applied out of context, or even employed as a rote alternative to thinking. But applied judiciously, it can make all the difference in the world — not least in evaluating our own arguments before we present them to others. The Demon-Haunted World is a timelessly fantastic read in its entirety, timelier than ever in a great many ways amidst our present media landscape of propaganda, pseudoscience, and various commercial motives. Complement it with Sagan on science and “God”. donating = loving Each month, I spend hundreds of hours and thousands of dollars keeping The Marginalian going. For seventeen years, it has remained free and ad-free and alive thanks to patronage from readers. I have no staff, no interns, not even an assistant — a thoroughly one-woman labor of love that is also my life and my livelihood. If this labor has made your own life more livable in the past year (or the past decade), please consider aiding its sustenance with a one-time or loyal donation. Your support makes all the difference. MONTHLY DONATION ♥ $3 / month ♥ $5 / month ♥ $7 / month ♥ $10 / month ♥ $25 / month START NOW ONE-TIME DONATION You can also become a spontaneous supporter with a one-time donation in any amount: GIVE NOW BITCOIN DONATION Partial to Bitcoin? You can beam some bit-love my way: 197usDS6AsL9wDKxtGM6xaWjmR5ejgqem7 CANCEL MONTHLY SUPPORT Need to cancel an existing donation? (It's okay — life changes course. I treasure your kindness and appreciate your support for as long as it lasted.) You can do so on this page. sunday newsletter The Marginalian has a free Sunday digest of the week's most mind-broadening and heart-lifting reflections spanning art, science, poetry, philosophy, and other tendrils of our search for truth, beauty, meaning, and creative vitality. Here's an example. Like? Claim yours: midweek newsletter Also: Because The Marginalian is well into its second decade and because I write primarily about ideas of timeless nourishment, each Wednesday I dive into the archive and resurface from among the thousands of essays one worth resavoring. Subscribe to this free midweek pick-me-up for heart, mind, and spirit below — it is separate from the standard Sunday digest of new pieces: PRINT ARTICLE EMAIL ARTICLE PocketFacebookTwitterLinkedInRedditPinterest27 FILED UNDER BOOKSCARL SAGANCULTUREPSYCHOLOGYSCIENCE The Marginalian participates in the Bookshop.org and Amazon.com affiliate programs, designed to provide a means for sites to earn commissions by linking to books. In more human terms, this means that whenever you buy a book from a link here, I receive a small percentage of its price, which goes straight back into my own colossal biblioexpenses. Privacy policy. (TLDR: You're safe — there are no nefarious \"third parties\" lurking on my watch or shedding crumbs of the \"cookies\" the rest of the internet uses.) Sumo",
    "commentLink": "https://news.ycombinator.com/item?id=38060912",
    "commentBody": "Carl Sagan&#x27;s Rules for Bullshit-Busting and Critical ThinkingHacker NewspastloginCarl Sagan&#x27;s Rules for Bullshit-Busting and Critical Thinking (themarginalian.org) 203 points by haxiomic 23 hours ago| hidepastfavorite185 comments Animats 21 hours ago\"Always ask whether the hypothesis can be, at least in principle, falsified. Propositions that are untestable, unfalsifiable are not worth much.\"This. That&#x27;s a good way to put it. I&#x27;ve mentioned Fred Hoyle&#x27;s line on that, \"Science is prediction, not explanation\" (which is from one of Hoyle&#x27;s novels), but Sagan&#x27;s line is better.Key point: unfalsifiable theories do not lead to useful technology. Engineering requires predictability. reply rossant 19 hours agoparentThis is a problem with shaken baby syndrome, which asserts that infants presenting a certain pattern of medical findings (mostly subdural and retinal hemorrhage) MUST have been violently shaken if no other alternative medical or accidental explanation is found. It is a diagnosis by default, which raises a number of legal issues. [1, 2]This medical diagnosis is \"certain\" even with no witness, no admission of violence, no antecedents of violence, no sign of trauma on the baby&#x27;s body. There is absolutely no way to falsify the idea that this gesture occurred (and no way to prove one&#x27;s innocence — it&#x27;s a presumption of guilt). Yet, this theory is qualified as \"scientific\" by its proponents, but it does not lead to any predictions, only explanations.That shaking must have occurred on a given child at a particular moment, while the only person present with the child denies any violence, is an untestable and unfalsifiable proposition that is totally anti-scientific.[1] https:&#x2F;&#x2F;www.cambridgeblog.org&#x2F;2023&#x2F;05&#x2F;a-journey-into-the-sha...[2] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37650402 reply jfengel 20 hours agoparentprevFalsifiability is critical for engineering, but not all science is for engineering. The further you get from engineering, the fuzzier the line between science and non science.We try to apply the tools of science to things like astrophysics and paleontology, but they&#x27;re practically never going to have engineering consequences. That&#x27;s fine. It&#x27;s great that we want to know stuff just because we like knowing -- even if \"knowing\" sometimes gets hard to define.Falsifiability is a great tool for being able to say some things don&#x27;t work. But it&#x27;s important not to let it limit curiosity. reply foolswisdom 19 hours agorootparentIf you can&#x27;t explain how the statement could be falsified, at least in principle (although it may be not practical to do so), then you are admitting that reality will always be the exact same regardless of whether your hypothesis is true. And in that case, it&#x27;s really not useful or meaningful for any sort of reasoning at all.A concept which will in no way ever make a difference, is meaningless. reply kybernetikos 19 hours agorootparentMWI of quantum physics is most likely unfalsifiable. But if I believe that there are other versions of me that will definitely win the lottery if I am the sort of person to enter it in particular circumstances then that may well change my behaviour.I would argue that occams razor is unfalsifiable but is still a great principle. reply TeMPOraL 17 hours agorootparent> I would argue that occams razor is unfalsifiable but is still a great principle.Occam&#x27;s razor is provable, in the sense it&#x27;s a heuristic based on probability. Out of the two alternative hypotheses explaining the same observations to the same degree, the simpler one is more likely to be true. reply bazoom42 5 hours agorootparentThat is not what occam razor means. It doesn’t say anything about probabilities. It says that if two models give the same predictions, you should chose the simpler. If the models make the same predictions, neither can be said to be more true than the other. But if there is a difference in falsifiable predictions, this can be used to determine which model is best - but then occams razor does not apply. The most correct model wins, whether or not it is the simplest. reply TeMPOraL 4 hours agorootparent> It doesn’t say anything about probabilities. It says that if two models give the same predictions, you should chose the simpler.Which is where it becomes probabilistic. The answer to what it means for one model to be \"simpler\" than another is part of information theory, and that is essentially the flip side of probability theory. Information is (unsurprisingly) counted in bits, and one way of defining \"a bit\" is as amount of information that cuts your uncertainty by half.> If the models make the same predictions, neither can be said to be more true than the other. But if there is a difference in falsifiable predictions, this can be used to determine which model is best - but then occams razor does not apply. The most correct model wins, whether or not it is the simplest.The point of applying the razor is that, if there&#x27;s no evidence to support one model over other, your best bet is to chose the simpler one now, because when new evidence comes to light that will favor one over other, it&#x27;s more likely to favor the simpler one. reply bazoom42 4 hours agorootparent> The point of applying the razor is that, if there&#x27;s no evidence to support one model over other, your best bet is to chose the simpler one now, because when new evidence comes to light that will favor one over other, it&#x27;s more likely to favor the simpler one.I highly doubt that. The history of science has plenty of examples where more complex hypotheses turn out to be more correct. E.g Einsteins relativity is more complex than Newtonian mechanics, but nevertheless better matches observations. The current model of the universe is far more complex than the Ptolmaic model, the periodic system is more conplex than the four elements etc.Occams razor applies if two models make the same predictions and therefore neither can be more correct than the other. reply TeMPOraL 3 hours agorootparent> The history of science has plenty of examples where more complex hypotheses turn out to be more correct. E.g Einsteins relativity is more complex than Newtonian mechanics, but nevertheless better matches observations.Yes, but that&#x27;s after people made observations that couldn&#x27;t be explained by Newtonian mechanics. If you were living at the time the latter were formulated, and someone came to you with relativistic equations, showing that their result all line up perfectly with Newtonian ones, but otherwise offering no example of divergence, nor any explanation why the person chose these particular equations - you&#x27;d be right to call them a kook and ignore them. After all, there would be no way to distinguish between Newtonian formulation, Einstein&#x27;s formulation, and an infinite amount of other formulations that also give the exact same results.Ockham&#x27;s razor makes sense only if some two models in question, which today make the same predictions, can also make divergent predictions that you expect to be testable in the future. The Razor tells you to stick with the simpler one, because it&#x27;s most likely to remain the best model. The more complex model has more moving parts, requiring more bits of information to identify among many possible variations of same or greater complexity - bits you don&#x27;t have, because if you had them, you could use them to disprove the simpler model.In other words: the Razor worked for Newtonian mechanics despite Einstein, because a Newton&#x27;s contemporary couldn&#x27;t just randomly come up with the exact formulation of relativity we use today, given evidence available then. So whatever theory they would propose, it would overwhelmingly likely be wrong - as in, made bad predictions where Newtonian mechanics still made good ones.> Occams razor applies if two models make the same predictions and therefore neither can be more correct than the other.So to reiterate: Ockham&#x27;s razor is future-facing; it applies to theories that can generate divergent predictions, but which you can&#x27;t test just yet. If you expect the two models to always give the same predictions, now and in the future, then... they&#x27;re literally the same thing, just expressed in different ways. There is no meaningful difference there, and you may just pick whichever one you like more, or whichever is easier to work with. reply BellsOnSunday 17 hours agorootparentprevMore likely but not certain. People who rely on this rhetorically tend to ignore it isn&#x27;t a slam dunk. reply ukj 10 hours agorootparentprevHickam&#x27;s dictum is also provable.In the domains where simplicity prevails Occam&#x27;s razor is more probable.In domains where complexity prevails Hickam&#x27;s dictum is more probable. reply karencarits 19 hours agorootparentprevBut it can be hard to know whether a concept will make a difference in the future. String theory may for example provide some testable hypotheses at some point. Theory building is important and original thoughts may have unpredicted consequences some way down the road reply ukj 10 hours agorootparentprevIn asking a statement to be falsified (in principle) you are assuming it to be true (in principle).Is is true? What makes it true?>A concept which will in no way ever make a difference, is meaningless.So what would falsify this statement? How would you convince yourself that you are wrong? reply croes 20 hours agorootparentprevWithout falsifiability it&#x27;s belief not science.How can a hypothesis become a theory if it can&#x27;t fail? reply esafak 21 hours agoparentprevFalsifiability is not his idea; it was promoted by Karl Popper. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Falsifiability reply vivekd 20 hours agorootparentThis is correct, Falsifiability was origionally concieved of by Karl Popper. I would also add, that while Popper had the best of intentions and good ideas in creating falsifiability theory, it is not generally accepted today by people who study philosophy of science. The consensus, which I agree with, is that it doesn&#x27;t refelct how science atually works and it eleminatates many things that we do consider science. I mean many people may disagree with string theory, but it&#x27;s hard for me to accept that it&#x27;s science at all. Evolution also didn&#x27;t pass Mr. Popper&#x27;s tests, but he eventually recanted, not by changing his views on how evolution fits with his theories but just because his friends convinced him that it was \"really important.\"Popper made contributions to science in that he was one of the main thought leaders that began the field of philosophy of science. That said, I don&#x27;t think falsifiability by itself is a very good criterion for science or truth.I don&#x27;t think the wikipedia article on this is very good. The encyclopedia of philosophy has a much better overview of his theory and where it stands currentlyhttps:&#x2F;&#x2F;iep.utm.edu&#x2F;pop-sci&#x2F;#H3 reply JohnFen 19 hours agorootparent> I mean many people may disagree with string theory, but it&#x27;s hard for me to accept that it&#x27;s science at all.Science is a method, not a thing. I think most scientists, including those looking into string theory, would agree that the hypothesis is not science. It&#x27;s a hypothesis. Maybe not even that, depending on whether or not you think it&#x27;s falsifiable. But either way, it&#x27;s an intriguing idea that scientists are looking at. That&#x27;s a legitimate part of the process as well. reply pengstrom 18 hours agorootparentprevI always cringe when I hear evolution brought up as some invented method or mere developmental happenstance. It&#x27;s a cold, unavoidable consequence of variation, selection and inheritance, in the absolutely most general way possible.The universe evolves, life just found a way to make it quicker. Then we invented sexual dimorphism to make several selections within a single generation. Our human intelligence allows us to evolve ideas at an even faster rate.The effects of evolution are in the realms of science, but evolution itself is the superstructure science, and anything else, has \"evolved\" in. It&#x27;s time. reply Mawr 12 hours agorootparentI think the strongest argument for evolution is it&#x27;s the simplest approach that could possibly work.Or, using backward reasoning, what would be the simplest possible way to achieve life as complex as a human? Evolution. reply afro88 18 hours agorootparentprevAm I misunderstanding something about falsifiability? In principle, evolution can be falsified by observing no incremental development of species over time.Falsifiability just means there&#x27;s some possible way for it not to be true? reply vivekd 16 hours agorootparentHe thought it was untestable because it was based on a series unique one time unrepeatable events in the distant past.Parts of the theory like Mendelian genetics are testable but on the whole... Evolution happens so slowly that we can&#x27;t observe it or test it in a lab.To me it seems like with Popper inquiry into how species came to be can never fit into science. It&#x27;s a much narrower view than what we commonly understand as science today. reply rixed 12 hours agorootparentOf course evolution is falsifiable, as are falsifiable the big bang theory and the iron kernel theory.To falsify a theory does not require to reproduce it in a lab. It means that the theory predicts something that you can actually observe, or not observe and thus disprove it.For instance, we can falsify the theory like this: let&#x27;s grow bacteria and subject them to some poisonous chemical. The theory predicts that, after many generations, if the colony survive then it should become resistant to that poison.Here is an example of a theory that is not falsifiable: after they die, people&#x27;s souls go to a place that is impossible to observe when you are alive.Falsifiability is about \"impossible to observe\", not about repeatability. reply readthenotes1 20 hours agorootparentprev\" by people who study philosophy of science. The consensus, which I agree with, is that it doesn&#x27;t refelct how science atually works and \"Science &#x27;works&#x27; today by p-hacking and data falsification.I&#x27;m not sure that we should consider current practices an argument against a quality threshold. reply fastaguy88 19 hours agorootparentPerhaps you meant to day \"science doesn&#x27;t work by p-hacking and data falsification\". The great thing about science is that it involves a process of building models and hypotheses, and then running experiments to produce results that support the models and hypotheses. To the extent that p-hacking and data falsification produce results that are not correct, longer term they will have a difficult time distorting our understanding of the underlying phenomena. Short-term, certainly they can be distracting, but we care about reproducibility because scientists are constantly trying to reproduce (possibly by building on older) results. Results that cannot be reproduced do not contribute to science. reply jimwhite42 20 hours agorootparentprevAren&#x27;t you mixing two distinct things here? reply glenstein 19 hours agorootparentI think you&#x27;re right to identify two distinct things in the air, but it&#x27;s the other guy doing the mixing. What science is and the extent to which that is approximated in practice are indeed two things. Neither is inherently more real or true than the other, or necessarily more right, depending on the context.But I take this particular context to be about Sagan&#x27;s comments on distinguishing truth from \"baloney\" via science by expressing principles that best express the scientific ideal. I don&#x27;t take that to be \"corrected\" by appealing to science as practiced, which is where the mixing up of the two comes in. reply jimwhite42 19 hours agorootparentI think there&#x27;s a subtlety which isn&#x27;t implicit in what you say. There is the ideal of science - which I think there&#x27;s a case to be made that it&#x27;s not something that can be fixed, but constantly evolves - and the practice.But I think there&#x27;s also a separate distinction between good faith and successful enough attempts to do science, and people just gaming the system. The fact that there&#x27;s plenty of the latter must be acknowledged (in fact, I think the people who discovered this current set of issues and made a big deal of it are from the same group of academics as the ones abusing this loophole, and also, it&#x27;s likely to be a perennial problem), but the former also exists and is not the same as the abstract ideal you bring up.I&#x27;m not sure I would characterize Sagan&#x27;s system here as specifically best expressing the scientific ideal. I think it&#x27;s a great list to think carefully about to help with clear thinking, but I&#x27;m not sure applying the label of &#x27;science&#x27; to all these points is the right way to think about them, although I&#x27;m not sure it isn&#x27;t either. replyjimwhite42 20 hours agorootparentprevI&#x27;ve been wondering if falsifiability is misunderstood, based on what a few people have commented about it. The alternative version is only that if claims are made that a system has made specific predictions that proved to be true, then it should be falsifiable on that basis. This was Popper&#x27;s criticism of Marxists claiming Marxism was scientific - they would constantly claim that Marxism can predict what already happened, but it&#x27;s bogus to claim this in retrospect, they repeatedly claimed this for occurrances only after they had occurred. Is this the same as demanding every theory be falsifiable?Sean Carroll talks pretty positively about string theory. I think he paints the picture that although the popular view is it&#x27;s not falsifiable (or not yet), therefore it&#x27;s somewhere between very suspicious and junk, but actual theoretical physicists are much more positive about it. reply vivekd 20 hours agorootparentPopper did have the idea of combating communism&#x27;s claim of being a science or scientific materialism. And that&#x27;s a pretty noble goal in my mind. His heart was in the right place.I don&#x27;t think Popper was going for that soft falsifiability - but if you modify his theory to do that, say it has to make some predictions, and only require that it should be falsifiable on the basis of it&#x27;s predictions, you let in a lot of stuff in that obvious isn&#x27;t science.To take the obvious example of using exactly what Popper was trying to oppose. the current Chinese communist party&#x27;s claim that capitalism will eventually transition into socialism once a certain level of development is achieved, it is a prediction, it will be falsifiable later. Clearly it is still not science.But even if we give Popper the falsifiability angle and imagine there is some workable version of falsifiability, I still don&#x27;t thik his theory works, it&#x27;s just not a good reflection of day to day science and scientists. reply jimwhite42 20 hours agorootparent> To take the obvious example of using exactly what Popper was trying to oppose. the current Chinese communist party&#x27;s claim that capitalism will eventually transition into socialism once a certain level of development is achieved, it is a prediction, it will be falsifiable later. Clearly it is still not science.I think this is the point on this issue, right? It can&#x27;t count as falsifiable later, or still not science, unless they describe what they mean by \"socialism\" specifically enough in advance - which I think is a pretty nebulous constraint? Not sure about it. Definitely, there&#x27;s a lot of (reasonable IMO) theoretical controversy about what &#x27;welfare capitalism&#x27; has to do with proper socialist ideas, even though it&#x27;s usually given the label &#x27;socialist&#x27;.I&#x27;ve also been wondering things like what working scientists do, and what this thing is that we call science generally - non research related stuff like teaching, or using science to do better engineering, and what the connection is between the two.Is there still a place for any variation of falsifiability?Bonus cheeky request: do you have any recommendations on modern philosophy of science? reply vivekd 19 hours agorootparentFyerabend is the top dog right now I wouldn&#x27;t recommend investing too much in him, he basically thinks there is no demarcation and Voodoo and Einstein are equally valid.I accept Quine who I admit isn&#x27;t much better, he thinks it&#x27;s all about creating a coherent world view. I think he&#x27;s onto something but he&#x27;s missing truth which I think is a problem - we want to think science gives us truths about the world, or at least we want a way to get to truth.There&#x27;s another view that says science starts with a set of untested assumptions which I haven&#x27;t gotten around to reading much about reply jimwhite42 4 hours agorootparentI like some of what I think I understand about Feyerabend&#x27;s ideas, but I didn&#x27;t get on with his actual books. I expected something ethnographic-y or observation based, but only found incredibly abstract stuff.I listened to a few interviews with Liam Kofi Bright, and his ideas about what truth is are pretty interesting. The perspective of &#x27;giving us truths&#x27; or &#x27;getting to the truth&#x27;, is unsatisfying to me.I think there has to be a core of some kind of &#x27;predict what will happen when we do something, then see how close we got, tweak it in response to these observations, then repeat&#x27;. replyclankyclanker 21 hours agoparentprevOr, more pithily, always ask \"how can you disprove it?\" - If you can&#x27;t, it isn&#x27;t science and can&#x27;t be treated as such. reply ukj 20 hours agorootparentHow can we disprove the hypothesis “If we can’t disprove it - it isn’t science.”?The scientific metaphysic relies on so many declarative&#x2F;prescriptive statements which are themselves exempt from the criteria for science and are thus self-defeating on their own terms.It is so peculiar when scientists are so dogmatic about science.Are the formal sciences (logic&#x2F;mathematics&#x2F;computer science) not science? The testability&#x2F;falsifiability criterion certainly excludes them from being sciences. reply mcv 20 hours agorootparent> How can we disprove the hypothesis “If we can’t disprove it - it isn’t science.”?That statement isn&#x27;t science. It&#x27;s a definition. It&#x27;s philosophy of science. It&#x27;s the briefest summary of Karl Popper&#x27;s definition of the scientific method. According to him, science can never be proven, only disproven. reply ukj 19 hours agorootparentIt is in the nature of definitions to include some things and exclude others.If the definition of “science” excluded computer science as a science; would you say the definition is correct? reply mcv 19 hours agorootparentIn this context, most of computer science is more a form of applied mathematics.Of course there are different ways to look at science, like making a distinction between analytical (or empirical) science, and synthetic science; the science that makes stuff, rather than analysing it. Not sure if that&#x27;s really a good distinction; the latter is really technology, isn&#x27;t it? reply JohnFen 19 hours agorootparentprevThere is such a thing as computer science, but the majority of what gets called that is really engineering, not science. People often get those two things confused because they have a fair bit of overlap in the Venn diagram, but they are two different things. reply ukj 10 hours agorootparentI am talking about (theoretical) computer science, not (practical) software engineering.This should&#x27;ve been clear in the context of my question:\"Are the formal sciences (logic&#x2F;mathematics&#x2F;computer science) not science?\" reply mcv 6 hours agorootparentMath is itself indeed not science. It is the language of science. It follows different rules than empirical sciences. But note that word \"empirical\" there; Popper was really only talking about empirical science, and according to him, that was the only real science. You could argue that there are non-empirical sciences.Another problem with Popper is probably that outside of physics and chemistry, there are a lot of less exact sciences where predictions and refutations of a theory are never that clear cut. Like his issues with the theory of evolution.Ultimately, I guess science is also simply \"getting to stuff that works by trial and error\". reply ukj 19 minutes agorootparentOk… I reject your reality and substitute my own.In this reality I don’t have to do the mental gymnastics where the formal *sciences* aren’t sciences.In this reality there is at least one unfalsifiable (not even in principle) true claim: the halting problemThis renders falsifiability as a modal criterion. Useful in some scientific contexts - useless in others. reply anonymous_sorry 7 hours agorootparentprev> \"Are the formal sciences (logic&#x2F;mathematics&#x2F;computer science) not science?\"Not by this definition. The distinction between mathematical theorems and scientific theories is a useful one. reply ukj 7 hours agorootparent>Not by this definition.Which is precisely the problem with all definitions I am drawing attention to - they are exclusionary in nature.Sometimes creating distinctions is useful. Sometimes erasing distinctions is even more useful.How much physics could you do without Noether&#x27;s theorem? reply anonymous_sorry 7 hours agorootparentHow much engineering could we do without Mathematics? How much commerce?I don&#x27;t see it as exclusionary. You won&#x27;t find many scientists in doubt about the fact that everything they do is built upon Logic and Mathematics, in addition to observation.But don&#x27;t we need a word to group fields that try to systematically describe, understand, and make predictions about the physical world? (Rather than seeking to explore and characterise idealised logical constructs?). What would you suggest? reply ukj 7 hours agorootparentYou may not see it as exclusionary but many people do. Just look at the comments!It&#x27;s precisely the grouping I am talking about.If you group science in such a way so that logic&#x2F;mathematics&#x2F;computer science falls outside the group then isn&#x27;t that an erroneous grouping?Isn&#x27;t that a silly definition?True and False are idealized logical constructs. It&#x27;s the idea; and the idealization of the notion that there is a difference between Truth and Falsehood. Or if you want to get biblical - there is a difference between Right and Wrong.If True ≡ False then... fuck it. reply anonymous_sorry 6 hours agorootparentWe need a grouping to make it clear that some fields produce theories and others produce theorems.We need theory-producers to be more humble and provisional in their statements. We need theory-producers to forever remain open for their theories to be falsified or refined (whilst not being paralysed by doubt about theories that have stood the test of time). In other words, we need a slightly different culture.But we also need a way to rebut someone who says \"OK, but can you prove we&#x27;re not living in a perfect simulation of reality with a fabricated history that was created yesterday?\". In science, the rebuttal is \"No, I can&#x27;t prove that, science depends falsification rather than proof. Can you suggest a way I could falsify it? If not, then I&#x27;m going to get on with my work because it doesn&#x27;t make a difference to my field either way\" reply ukj 5 hours agorootparentWe who? Don&#x27;t \"we\" also need a grouping to make it even clearer that some fields can&#x27;t produce any falsifiable theories if other fields don&#x27;t produce at least some unfalsifiable theorems? A terra firma of sorts.It&#x27;s like a dependency graph. Or something.Your insistence on \"making a difference\" seems to echo the sentiment of many pragmatists: It is astonishing to see how many philosophical disputes collapse into insignificance the moment you subject them to this simple test of tracing a concrete consequence. There can be no difference anywhere that doesn’t make a difference elsewhere – no difference in abstract truth that doesn’t express itself in a difference in concrete fact and in conduct consequent upon that fact, imposed on somebody, somehow, somewhere, and somewhen. The whole function of philosophy ought to be to find out what definite difference it will make to you and me, at definite instants of our life, if this world-formula or that world-formula be the true one. --William JamesDoes falsifiability make any difference? If something is only falsifiable in principle (e.g in theory), but not in practice then is it really falsifiable? On pragmatism - it&#x27;s not a difference that makes any practical difference. And yet you insist on differentiating. Why?Is \"All humans are mortal.\" falsifiable or unfalsifiable? It sure is falsifiable in theory, but unfalsifiable in practice. Any living human is potentially immortal until they actually die.Any running process is potentially non-halting, until it actually halts.If falsifiability doesn&#x27;t make a difference in practice (and it doesn&#x27;t!) then I guess we can all get on with whatever scientific discipline we are busy practicing.So, I&#x27;m going to carry on my life knowing at least one unfalsifiable scientific truth: the theorem known as The Halting Problem.It&#x27;s not even wrong, because it&#x27;s right.Anybody who insists the Halting Problem is falsifiable (even in principle) is welcome to solve it in principle. reply anonymous_sorry 4 hours agorootparent> Don&#x27;t \"we\" also need a grouping to make it even clearer that some fields can&#x27;t produce any falsifiable theories if other fields don&#x27;t produce any unfalsifiable theorems?Sure. And I suspect a subset of pure mathematicians would want terminology to make clear that they produce theorems out of intellectual curiosity rather than because they have any regard for whether those theorems can be applied by other fields. Fortunately we can categorize things in multiple ways. I&#x27;m open to suggestions on the semantics, but something more widely understood and less clunky than my own theorem&#x2F;theory-producers would be good! Perhaps \"Natural Sciences\" or \"Empirical Sciences\" might be more specific terms for fields that produce theories, if you like.I differentiate simply because seems possible to do so. And as I said, because it&#x27;s worth considering whether different processes and cultures are useful. I&#x27;m intrigued as to why you object so strongly.I am afraid my intellect isn&#x27;t quite up to the application of scientific principles to the philosophy of science itself this morning. I&#x27;ll have to think harder about whether that&#x27;s even a valid thing to do.I don&#x27;t think you&#x27;ve shown that falsifiability makes no difference in practice. The fact that it&#x27;s possible to come up with some borderline or problematic examples (which themselves aren&#x27;t terribly practical) doesn&#x27;t mean it&#x27;s not a useful criterion for a scientific theory. Falsifiability is a valuable filter for ideas that the natural sciences are not able to speak to. String theory has been criticized as unfalsifiable. I think a good string theorist would accept that it&#x27;s a serious accusation that requires an answer.To be honest I&#x27;m quite happy to say \"All humans are mortal\" is not a well-stated scientific theory. \"Human lifespan is limited to 180 years\" is better, as it may one day be falsified. reply ukj 4 hours agorootparentIt&#x27;s pointless to speak of usefulness without specifying a utility function.It is just as possible to differentiate as it is to integrate.If it is determined a priori that unfalsifiable propositions are not useful, then knowing the result of the Halting Problem is not useful. Isn&#x27;t that silly?I strongly object to categorizations which discriminate against valid science (knowledge? truth? understanding? reasoning? Useful facts?). Is all.The human process of trying to udnerstand reality is continuous, not discrete, so it&#x27;s silly to reason about it in terms of discrete categories. It necessarily leads to confusion; and the sort of gatekeeping and self-justification Carl Sagan is guilty of.Science benefits much more from being defined too broadly; than being defined too narrowly.I&#x27;d rather be too permissive then ignore the junk; than be too restrictive and never even encounter good ideas which were erroneously discarded as junk. reply anonymous_sorry 2 hours agorootparentI don&#x27;t think I said unfalsifiable propositions are not useful! A proven theorem is sacred!Of course, until the laws of thermodynamics are revised we can provisionally say that all programs actually running in nature will indeed stop at some point, no matter what is proven about idealized Turing machines.And before I&#x27;m misunderstood. There are many ways the laws of thermodynamics can be tested. This prediction, unfortunately, cannot be tested. But it is a predicted consequence of the simplest known theory that explains of all sorts of observations about thermodynamics. Which is the limit of what the natural sciences aim to do here. Provisional truth based on observation vs. proven truth based on stated axioms.I am explicitly not claiming that one truth is to be valued more than the other. I honestly don&#x27;t think that. Merely noting, again, that the distinction is there to be made. I may be \"discriminating between\", but I&#x27;m certainly not \"discriminating against\".It may or may not be a continuum. Curious researchers on both sides can certainly be informed and inspired by each others work, and can use the same techniques and tools. But even if only as an academic exercise can&#x27;t we describe these two modes of discovery. And isn&#x27;t it worth being clear about their respective limits? replyJohnFen 2 hours agorootparentprev> If you group science in such a way so that logic&#x2F;mathematics&#x2F;computer science falls outside the group then isn&#x27;t that an erroneous grouping?Why would it be erroneous? reply ukj 1 minute agorootparentFor much the same reasons as grouping cars and engines separately is erroneous.The whole requires all of its parts. seanhunter 19 hours agorootparentprevWhen did maths become unfalsifiable? Someone should have told these guys https:&#x2F;&#x2F;www.ams.org&#x2F;journals&#x2F;bull&#x2F;1966-72-06&#x2F;S0002-9904-1966... reply ukj 17 hours agorootparentSomeone should tell you that there is a difference between a conjecture and a theorem.Theorems are unfalsifiable. reply seanhunter 9 hours agorootparentFirstly there&#x27;s no need whatsoever to be rude even if I&#x27;m wrong. It doesn&#x27;t help the discussion and isn&#x27;t nice. You also don&#x27;t know anything whatsoever about what I do and don&#x27;t know about maths or the definitions of words.Secondly prospective theorems are absolutely falsifiable. Since a theorem is a statement that has been proven to be true yes they are unfalsifiable by definition - they have already passed that test. That doesn&#x27;t really generalise to any sort of meaningful statement about the falsifiability of maths. Saying theorems are unfalsifiable is equivalent to saying \"True statements can&#x27;t be proven false\". Well, yes.[1]ie If I say Sean Hunter&#x27;s theorem is that if you take a triangle with arbitrary sides a b c and angle opposite a of theta thata^2 = b^2 + c^2 -42 b c cos thetathat statement is absolutely falsifiable (and false), which you can establish with basic geometry and trig[2]. When you demonstrate it not to be true it is not a theorem, so I was wrong to call it that. That is a demonstration of how maths is falsifiable.[1] Even so it&#x27;s often possible to make progress via proof by contradiction - showing that if this theorem were not true something else which we know to be true would be false. But in most of my maths books proving all of the theorems is the norm, so they are for sure falsifiable while you are trying to establish whether or not they are theorems.[2] Drop an altitude from one of the angles at b and c and then use pythagoras and a bunch of cancelling. You will prove that a^2 = b^2 + c^2 -2bc cos theta of course. My statement is only true if a is the hypotenuse of a right triangle meaning cos theta is zero and my incorrect coefficient doesn&#x27;t matter. reply ukj 9 hours agorootparentI merely attempting to reciprocate&#x2F;mirror your tone. You are the one (self)identifying it as \"rude\".I have some idea about what you do and don&#x27;t know about definition and definability (in general) given the words you&#x27;ve said so far and the way you&#x27;ve used them.Prospective theorems are not theorems until a proof is presented. At which point they become retrospective theorems.All that \"falsification\" and counter-examples prove is that the so-called \"proof\" of a \"theorem\" wasn&#x27;t. If you have indeed provided a counter-example that&#x27;s a proof of negation which raises questions: what was wrong with the original \"proof\" of the theorem? Since proofs are programs - there must have been a bug in the proof. Better type-check that proof&#x2F;program...The presence of a counter-example to Sean Hunter&#x27;s \"theorem\" simply demonstrates that it&#x27;s not a theorem. It&#x27;s a misnomer. Theorems are exactly those Mathematical stataments for which no proof of negation exists.You seem to be presupposing some particular kind of mathematics. I am talking about all possible Mathematics in general; of which the particular Mathematics you are currently using is just one particular instance. A historical and cultural coincidence.There&#x27;s a Mathematical paradigm in which proof-by-contradiction is a valid proof method e.g mathematics founded upon classical logic.And there&#x27;s a Mathematical paradigm in which proof-by-contradiction is not a valid proof method e.g mathematics founded upon intuitionistic logic. This is basically what we call Computer Science. It has fewer axioms than Classical Mathematics (e.g the axiom of choice is severely restricted) and so it&#x27;s a much stronger proof-system. You could even say Intuitionistic Mathematics (which is basically CS) is \"more foundational\" (it is much closer to the foundations?) than Mathematics.The fact that you are admitting proof-by-contradiction in your methodology tells me about your choice of foundations, but so what? There&#x27;s a foundation which axiomatically pre-supposes choice; and a foundation which doesn&#x27;t.And in the foundations where choice is not axiomatic \"proof\" by contradiction is not a valid proof.The reasoning goes something like this:1. Choice implies excluded middle. 2. Excluded middle implies all proposition are either true or false. 3. Excluded middle implies that proof by contradiction is valid.Rejecting 1 results in the rejection of 2 and 3 also.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Diaconescu%27s_theorem reply seanhunter 8 hours agorootparent> Prospective theorems are not theorems until a proof is presented. At which point they become retrospective theorems....> The presence of a counter-example to Sean Hunter&#x27;s \"theorem\" simply demonstrates that it&#x27;s not a theorem. It&#x27;s a misnomer.That is what I said. I showed a mathematical statement and I showed how you could falsify it. Since you said \"mathematics is not falsifiable\" I have shown your statement is not true. Do you see why?You were the one who decided that the distinction between conjectures and theorems is important. I have now shown two examples of mathematics that was falsified.Unless you&#x27;re trying to say neither me nor Euler was a mathematician in which case we can agree about me but not about Euler. reply ukj 7 hours agorootparentYour failure to understand what I am saying is abysmal.>That is what I said. I showed a mathematical statement and I showed how you could falsify it. >Since you said \"mathematics is not falsifiable\" I have shown your statement is not true.You have taken it upon yourself to interpret \"Mathematics is not falsifiable\" as broadly as needed in order to confirm your own biases; and then proceeded to attack a strawman instead of a steelman. That&#x27;s the lack of charity...>You were the one who decided that the distinction between conjectures and theorems is important.And you were the one who decided that it isn&#x27;t; so you falsely equated them.What you have demonstrated is the falsification of the statement \"X is a theorem\"; not the falsification of \"mathematics is not falsifiable.\" - a hasty generalization fallacy.Which doesn&#x27;t demonstrate anything of import or relevance whatsoever. Obviously a non-theorem is not a theorem. This is no more interesting than demonstrating that non-Mathematics is not Mathematics.This in no way diminishes or falsifies my own claim that theorems are unfalsifiable! And neither is Mathematics.Because if you do falsify it - then it was never a theorem. By definition. Theorems are true, not false. A false theorem is a contradiction in terms. A misconception. An error in reasoning.Maybe Euler wasn&#x27;t a Mathematician either. Who knows? Those sort of questions are undecidable. replydemondemidi 19 hours agorootparentprev> How can we disprove the hypothesis “If we can’t disprove it - it isn’t science.”?You just answered the question yourself: that&#x27;s a question for metaphysics and not science. Pick a lane! :) reply ukj 19 hours agorootparentOne way to view metaphysics is as the science of science.So if the science of science is not science - is that not a contradiction? reply demondemidi 18 hours agorootparentThat&#x27;s not what metaphysics is about.Metaphysics is the study of \"being qua being\".\"[Aristotle] claims that each science studies a unified genus, but denies that there is a single genus for all beings\". You&#x27;re applying tautology without really understanding the construction of your own question.https:&#x2F;&#x2F;academic.oup.com&#x2F;edited-volume&#x2F;28232&#x2F;chapter-abstrac...ELI5: asking about science isn&#x27;t science. Like reading about painting isn&#x27;t painting. Or more poetically, \"Ce n&#x27;est pas une pipe\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Treachery_of_Images reply ukj 17 hours agorootparentThe study of being qua being; or science qua science; or mathematics qua mathematics; or X qua X for any X.Metaphysics.Or as it is commonly referred to in computer science: function self-application. One example of which being the Y combinator (as in the name of this very forum).I am applying a tautology in exactly the mathematical sense of a tautology; and I understand my construction just fine.Had you been more charitable you would’ve addressed my argument; not your strawman of my argument. reply demondemidi 16 hours agorootparentI&#x27;m charitable by trying to teach you with examples.> Or as it is commonly referred to in computer science: function self-applicationNo, that&#x27;s recursion, not metaphysics.Is computer science the same as programming, no. Computer science is the study of programming, not programming. You learn this in your first year of CS.If you&#x27;re smart enough to _really_ understand what a Y combinator is, this should be a piece of cake. reply ukj 12 hours agorootparentI am struggling to spot the charity in all your condescension.metaphysics &#x2F;ˌmɛtəˈfɪzɪks&#x2F; noun the branch of philosophy that deals with the first principles of things, including abstract concepts such as being, knowing, identity, time, and space.First principles? Like logical&#x2F;mathematical axioms? Sprinkle abstraction. Identity? f(x) = x ?Time? Space? Spacetime? Minkowsky space?On a fuzzy-match that sounds ludicrously similar to the sort of stuff the formal sciences concern themselves with. Almost as if the distinction between science and philosophy is non-existence given the demarcation problem. reply Kranar 19 hours agorootparentprevNo because metaphysics is not the science of science. reply ukj 17 hours agorootparentWhat makes this assertion; or the assertion “If it isn’t disprovable - it isn’t science” true? reply demondemidi 16 hours agorootparentWhat makes this assertion? The literal definition of the term.Are you the kid who thinks he&#x27;s edgy by saying in philosophy class: \"It depends on the meaning of the word &#x27;X&#x27;\" every time someone tries to explain X to you? replyvivekd 20 hours agorootparentprevand you hit one of the main objections to the theory of falsifiability as the criterion of science. There are also other more serious ones, like the obvious fact that actual science does&#x27;t seem to actually work this way. The idea is more to explain observations in a coherent way rather than to be falsifiable for example. One example is the big bang theory being proposed by a Catholic astronomer who didn&#x27;t like the then prevaling idea that the universe did not have a beginning or end because it went against his religious beliefs. Or Kepler looking for planets at locations in accord with musical harmonies because he though it was consistent with the existence of a God reply JackFr 19 hours agorootparent> One example is the big bang theory being proposed by a Catholic astronomer who didn&#x27;t like the then prevaling idea that the universe did not have a beginning or end because it went against his religious beliefs.That’s simply not true.Fr. LeMaitre developed the theory to explain observed red shifts of galaxies (deriving Hubble’s Law prior to Hubble.) He felt his theory (and science in general) had no connection or contradiction to his faith. reply borlanco 18 hours agorootparent> One example is the big bang theory being proposed by a Catholic astronomer who didn&#x27;t like the then prevaling idea that the universe did not have a beginning or end because it went against his religious beliefs.This actually came from the skeptics [0]. They were unwilling to believe a Catholic priest proposing a scientific theory too similar to his religious beliefs, about God creating the whole universe in an instant.When the cosmic background radiation was discovered in 1964, the Big Bang was accepted by (mostly) everyone.[0] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Big_Bang#Development reply JohnFen 19 hours agorootparentprevThe reason that falsifiability is a core requirement of science is because if there is no way a proposition can possibly be falsified, then there is no way to objectively assess whether or not it is true.This is not to say that the proposition is false. It&#x27;s possible that things can be unfalsifiable and true nonetheless, but those things would still exist outside the range of the scientific method (at least until&#x2F;unless our understanding of reality expands enough to devise a test). That&#x27;s an intentional trade-off, in order to gain greater confidence in the truth of the things we can test. reply ukj 20 hours agorootparentprevPersonally, I am weary of the notion of “actual science” since science is not a well-defined term. The demarcation problem isn’t solved; and philosophers like Fayerabend in his book “Against method” suggest that science is more of an anarchic enterprise than any particular set of methods.Take any criterion and apply it too strictly and there is some scientific discovery&#x2F;progress in history which violates the rules and wouldn’t pass for “science” given any definition…Take any given methodological approach - and you will always find counter examples in scientific history.Almost like genius isn’t algorithmic. reply vivekd 20 hours agorootparentsure, but I mean, it&#x27;s pretty hard to call flat earthers or proponents of voodo unscientific if we have to admit that we haven&#x27;t solved the demarcation problem. Also more importantly for Popper, he wanted to oppose communists&#x27; ideas of \"scientific materialism.\"There does seem to be this thing that good scientists are doing. Popper did seem to touch on some good aspects of it, like the willingness to be proven wrong.I think maybe that&#x27;s the part Popper got right, maybe Science is about an unbiased search for knoweldge with no other agenda other than a genuine curiousity. And maybe that&#x27;s why demarcation is so hard, it&#x27;s hard to tell a person&#x27;s motives.I donno, just throwing stuff out there. . . Still I mean at least we have a test that communists obviously fail which should make Popper happy. reply pengstrom 19 hours agorootparentI mean, the non-schizo proponents for flat earth does approach it with scepticism. It&#x27;s just that the their required level of proof are unreasonable. Any experiment, no matter how genuinely designed, is exempt from flaws. Science works because the detractors doesn&#x27;t have the energy to waste decades in the academic apparatus, unlike true curiosity. reply toofy 14 hours agorootparentprev> … he wanted to oppose communists&#x27; ideas of \"scientific materialism.\"> … that’s the part Popper got right, maybe science is about an unbiased search…> …at least we have a test that communists obviously fail…i could be misunderstanding what you’re implying and if so apologies, but Popper wasn’t some anti-communist nutbag, in fact, if he “wanted to oppose” communism, that would have been fundamentally counter to his ideal of keeping things “unbiased”Popper was very open how much he admired Marx, he even tended to agree with Marx’ analysis of capitalism. where he disagreed was that 1) we were destined to be slaves to be servants if we 2) don’t have violent revolution.. He was quite clear that the state should absolutely be heavy handed to protect the lower classes from the wealthy’s constant tendencies to abuse the poor. Again, he agreed with much of Marx’s writing but where Marx thought it would require violent revolution, Popper believed we could use other methods such as “social engineering” to counter the rich. He was also concerned that so many people agreed about violent revolution being the only way out. He wrote about this admiration for Marx quite a bit:> …a grandiose philosophic system, comparable or even superior to the holistic systems of Plato and Hegel. Marx was the last of the great holistic system builders.and> [Marx] made an honest attempt to apply rational methods to the most urgent problems of social life… His sincerity in his search for truth and his intellectual honesty distinguish him…Popper was concerned that under unrestrained capitalism:> ..the economically strong is free to bully one who is economically weak, and to rob him of his freedom,… Those who possess a surplus of food can force those who are starving into a ‘freely’ accepted servitude.”Philosophy Now sums it up well, “Throughout his scrutiny of Marx, Popper treads a thin line between admiration and apprehension.” [0]again, apologies if i misinterpreted what you were implying, just wanted to clarify that Popper wasn’t some kind of nutbag mccarthy style rabid anti-communist or whatever. he just thought we could “social engineer” our way away from psychotic nationalism and unchecked capitalism rather than requiring full blown revolution.[0] https:&#x2F;&#x2F;philosophynow.org&#x2F;issues&#x2F;131&#x2F;Popper_on_Marx_on_Histo... reply vivekd 14 hours agorootparentHe wrote an autobiography - he was a young man who was a communist because he believed in scientific materialism. He later recanted after some of his friends were shot and killed by the police.Popper said he noticed that scientific materialism proposed by communists or Freud&#x27;s theories was very different from the lecture he heard by Einstein - Einstein looked more like science.Communism whatever anyone thinks about it is obviously not science. They claimed to be science at first and proposed scientific materialism as the future.Today even communists seem to have recanted this idea instead preferring to criticize capitalism and present themselves as the only alternative. We all know today it&#x27;s not science.I don&#x27;t want to debate politics only to say Communism was never science, it&#x27;s politics - Popper noticed that quickly and it was one of the imputus for his ideas based in his own autobiographyHe also dedicated his book the poverty of historicism to the countless men and women who lost their lives to fascism and Communism and their false belief in historical destinyOpen society and it&#x27;s enemies also contains a long critique of Marx and the idea that history follows certain laws that must play out a certain way. reply ukj 10 hours agorootparentThe problem with all ideas is always their reification. Computers may be deterministic, but humans aren&#x27;t. The same software&#x2F;idea produces wildly different understandings; and behaviour in differnt humans.What always seem like great ideas in theory, innevitably has to cope with the (mis)understanding; (mis)interpretation; and (mis)application of said idea by the mass population. replybsder 19 hours agorootparentprev> How can we disprove the hypothesis “If we can’t disprove it - it isn’t science.”?You can&#x27;t. That&#x27;s an axiom. Welcome to Philosophy of Science.Science, at bottom, has some axioms.1) Cause and effectThe same causes always create the same effects is an axiom. We assume that the God or the Devil don&#x27;t change all the rules every other Thursday. If there is a being who arbitrarily shifts the rules, science loses a lot of its predictive power. Science will adjust to that, but it makes science much less useful.2) ContinuityThe rules \"today\" are the same as the rules \"yesterday\" are the same as the rules \"tomorrow\". The rules \"here\" are the same as the rules \"there\".This is a little spicier as we do try to test that the rules haven&#x27;t changed. We try to test whether or not the fundamental constants have shifted with time, for example. We try to see if things are behaving the same in our galaxy are the same as in otehr galaxies.In fact, practically everything which defines \"science\" is about the ability to predict and quantify.A) Side: \"math\" is NOT \"science\". Math, while certainly falsifiable, is neither quantitative nor predictive.This, in fact, has provoked quite a bit of discussion: See: The Unreasonable Effectiveness of Mathematics in the Natural Scienceshttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Unreasonable_Effectiveness... reply ukj 6 hours agorootparentIs it the \"philosophy of science\"? What is now called \"science\" was once called \"natural philosophy\"?Maybe it&#x27;s the science of science? Maybe it&#x27;s the philosophy of philosophy? Maybe it&#x27;s the science of philosophy? Maybe it&#x27;s the philosophy of science?Maybe it&#x27;s all the same under naturalism?Studying science (itself a natural process) using our computational understanding of what a \"process\" is and does sure fits the Oxford definition of \"science\". reply stjohnswarts 5 hours agorootparentprevBecause they have worked over time, empirically as opposed to a lot woo woo stuff proposed by religion, spirituality, metaphysics, mentally ill, etc. which can never be disproved but which really don&#x27;t have any value in those areas where we apply science like technology and attempting to understand natural processes reply pengstrom 18 hours agoparentprev\"Only a sith deals in absolutes\"Science clearly works because humans have a genuine curiosity to find truth. While every person is flawed and prone to error, the curiosity points in the same direction, rising above the noise.We&#x27;ve only recently had to even discuss this after the deployment of large scale truth poisoning making the errors non-uniform. reply BellsOnSunday 16 hours agorootparentRecently like in the last hundred years? reply passion__desire 21 hours agoparentprevAdd to that David Deutsch&#x27;s point that \"Good explanations MUST be hard to vary\" reply pengstrom 19 hours agorootparentDeutsch also heavily argues for explanations as first-class existence on the level of matter. For him, predictions are simply a practical concern. I still fondly remember his dialogue between Socrates and Apollo in dream, where he convincingly makes the point that even there he can find true knowledge about the world. reply walleeee 2 hours agorootparentI also like his point (in conversation with Sean Carroll) that we have rigorous proof that the notion of explanation can&#x27;t be formalized, yet explanation is at the core of the scientific endeavor anyway. reply crabmusket 19 hours agorootparentprevI also loved that chapter.Deutsch really argues for Popper&#x27;s \"conjecture and refutation\" model of science (or as he renamed it, \"conjecture and criticism\") and one of the great points he makes is that both those processes can be done entirely in the mind. Physical evidence may be necessary for some kinds of criticism, but sometimes reason alone can produce useful criticism. reply pengstrom 18 hours agorootparentThat&#x27;s true, I might have been a little aggressive on the claiming reply crabmusket 19 hours agorootparentprev\"Hard to vary\" is, I think, some sort of isomorphism of \"easy to refute\". I found it difficult when reading Deutsch to pin down exactly what made something hard to vary. reply passion__desire 17 hours agorootparentLet&#x27;s say we have 16 distinct phenomena. All of them are currently explained by a rooted tree T of explanations of depth 4. Say, we come across 8 new phenomena. Suddenly you can&#x27;t rejig or shake your tree T anyhow. You have to preserve the original structure of T or at least relationships while constructing a new tree R such that it not only explains old 16 phenomena but also the new 8 as well. We might construct a new tree R such that tree T is a subtree of it. This new tree covers more ground and has more depth. In this sense, new explanations are constrained by whatever that came before and they are tasked with explaining more on top of that. There are very few ways to do it. In physics, they call the more general law to be valid at all time scales, energy scales and length scales, velocity scales and so on. reply canjobear 19 hours agoparentprevWhat about, for example, the Drake equation? Not falsifiable, but a useful tool for thinking. reply crabmusket 19 hours agorootparentNot all useful tools for thinking must be considered science. I think it&#x27;s quite fair to say the Drake equation isn&#x27;t \"science\".However, I think Popper&#x27;s \"conjecture and refutation\" is a more interesting model for thinking about the increase of knowledge than falsifiability is.Through that lens, you might say the Drake equation was a conjecture intended to stimulate refutations, which might lead to further productive theories.Popper&#x27;s essays on Parmenides are really interesting on this. Popper frames Parmenides&#x27; philosophy as essentially a conjecture that \"change is an illusion\", and the history of western science since then as various \"research programmes\" in response to that. I&#x27;m summarising terribly, but I think he illustrates well the value of conjectures that aren&#x27;t necessarily \"scientific\" in stimulating thought. reply JohnFen 19 hours agorootparentprevThe Drake equation is falsifiable. All you have to do is plug the values (which are all things that could technically be measured) into the equation, then count the number of civilizations in the Milky Way, and see if that&#x27;s equal to what the equation predicted. it is possible that it&#x27;s not, so the equation is falsifiable.That it&#x27;s impractical for us to actually do the experiment just means that we cannot perform the experiment and so it doesn&#x27;t help us in practical terms. But it is a thing that could be done, strictly speaking.That said, it&#x27;s also a thought experiment, not a scientific postulate, and isn&#x27;t meant to be \"scientific\". reply thicknavyrain 19 hours agorootparentprevCertainly useful for thinking, but its lack of falsifiability, predictive power or validation is indeed why there&#x27;s so much controversy around it and why it remains a hypothesised model rather than widely accepted scientific fact. The best you can do is test the assumptions of the model itself, or its constituent terms. reply cwillu 19 hours agorootparentprevNot everything _has_ to be science. reply wredue 21 hours agoparentprevI like Sagan, but he didn’t make these rules for a post truth world, unfortunately. There were certainly well funded lies in his day, but right now we are seeing massive investment, easily rivalling a large tech corporation or a Disney media empire, in to creating “news” orgs who’s specific goal is to lie, muddy waters, sow discord, and otherwise mislead the public, and who are seen as independent bodies of verification.It’s much more difficult now to find real facts, which is actually insane given that real facts should be available with the click of a button these days. reply omgwtfbyobbq 21 hours agorootparentI think the increase in spending on spreading&#x2F;amplifying certain kinds of information is because there&#x27;s a greater depth and breath of information available now that people can and are using to derive their own opinion.Influencing people was less expensive when media&#x2F;news&#x2F;information&#x2F;etc was relatively limited. reply wredue 20 hours agorootparentYeah, but what Sagan is trying to give is a framework for forming opinions based on reality. While it’s a good start, it’s missing imperative steps like “if Fox News is your independent verification, it’s probably a lie”.As stated, we are in a post-truth world, and a framework from Sagan era for forming opinions with a factual justification is much more difficult. reply demondemidi 19 hours agorootparentprevHello:\"Flood the channels with shit.\" - Steve BannonGoodbye:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;FCC_fairness_doctrine reply gadders 21 hours agoparentprevDoesn&#x27;t that apply to climate science&#x2F; climate change though? reply Aunche 20 hours agorootparentWhat are you implying? Scientists can&#x27;t make stars either, but they can make models describing stars and make new observations about these stars that test the validity of these models. Plenty of climate models have been disproven by this exact way. What has been remarkably consistent is that man-made greenhouse gases are causing climate change. For example, models predict that man-made global warming would cause the stratosphere to cool, which is exactly what they measured. By contrast, increased solar activity would have also heated up the stratosphere. reply daanlo 20 hours agorootparentprevWhy? Climate science works with quantative models and makes concrete predictions. So if the predictions don‘t come true the model is false. E.g. this random blog I found googling compares IPCC predictions with actual outcomes: https:&#x2F;&#x2F;johncarlosbaez.wordpress.com&#x2F;2012&#x2F;03&#x2F;27&#x2F;the-1990-ipc... [the link is just supposed to show how climate science is falsifiable. I have no idea whether the numbers in this specific source are trustworthy] reply gadders 6 hours agorootparentThe thing is - there are so many predictions made and a lot that don&#x27;t come through, it&#x27;s hard to find which are the \"real\" ones.I also read somewhere that there are several different scenarios available for the IPCC climate models and a lot of the more \"scary\" predictions are based on the least likely model.Finally - we saw the limitations of modelling in COVID in the UK, with adverse consequences. reply godelski 18 hours agorootparentprevMore comparisons here[0]. As is important, it&#x27;s noticed that models even from the 80&#x27;s made fairly accurate predictions. That&#x27;s the real kicker: models accurately predict observable outcomes 20-40 years later (and have only improved since then).I&#x27;m not sure why there&#x27;s so much contention about climate science given that we&#x27;ve been observing this trend for nearly 50 years now. Scientist makes prediction about something 50 years later and 50 years later the prediction is shown to be accurate. It feels weird to not trust a source with such a good and observable track record...[0] https:&#x2F;&#x2F;www.carbonbrief.org&#x2F;analysis-how-well-have-climate-m... reply aeternum 20 hours agoparentprevIs climate change falsifiable? reply HPMOR 20 hours agorootparentYes because you could simulate a small-scale atmosphere, and notice how changing the composition of the \"atmosphere\" affects average temperature or other features. John Von Neumann actually predicted climate change from first principles and described it as potentially more debilitating than nuclear weapons.--Great essay.https:&#x2F;&#x2F;geosci.uchicago.edu&#x2F;~kite&#x2F;doc&#x2F;von_Neumann_1955.pdf reply aeternum 20 hours agorootparentWell that&#x27;s more evidence for it, not an attempt to falsify.If we want to falsify, we should ask questions like: Was there a time in the past when the atmosphere contained even more CO2 than it did now? What was the temp and did life survive?What evidence or experiment would convince you the theory is false? Or is that impossible? reply glenstein 19 hours agorootparent>If we want to falsify, we should ask questions like: Was there a time in the past when the atmosphere contained even more CO2 than it did now? What was the temp and did life survive?Do you believe that question isn&#x27;t already asked and answered? Just going off the top of my head, I understand historical considerations to be a routine observation as part of your typical course or even presentation on the history of climate change. If you believe this counts, then your answer to your own question about the falsifiability of climate change is yes.I also don&#x27;t think that&#x27;s the only kind of example - I think the routine things talked about on a day to day basis, including year by year and decade by decade temperature predictions would qualify, and these data are quite frequently discussed and quite visible.I also also don&#x27;t think the distinction between \"evidence in favor\" and \"attempts to falsify\" makes a whole lot of sense. These are two different sides of the same coin, and evidence in favor of something is the same as surviving a test of falsifiability. reply mr_mitm 19 hours agorootparentprevClimate change is not a fundamental theory. It is derived from thermodynamics, the Navier Stokes equation, quantum mechanics and probably quite a few assumptions on what is negligible. Falsify any of those and you falsify climate change. reply roughly 20 hours agorootparentprevDepends on how valid you consider statistics and climate modelling. We&#x27;re seeing increasing numbers of events that are incredibly statistically unlikely in a climate unaffected by anthropogenic climate change, so - can we say with absolute certainty that X was caused by climate change? That&#x27;s hard. But we say that X was incredibly, unbelievably unlikely without climate change, and that&#x27;s usually been a sufficient standard for accepting a hypothesis. reply ianai 20 hours agorootparentprevYes. The base test for how increased co2 impacts the environment stems from an experiment in the 1800s.https:&#x2F;&#x2F;www.climate.gov&#x2F;news-features&#x2F;features&#x2F;happy-200th-b...And much science passed that. reply anon84873628 20 hours agorootparentprevCertainly. E.g., set up a model greenhouse system and show that increasing CO2 doesn&#x27;t increase the temperature.Or demonstrate that convective phenomena aren&#x27;t affected by changing temperature.\"Climate change\" comprises a causal chain of well studied and testable hypothesis. Including disproving alternate hypothesis like \"solar radiation is increasing\". reply aeternum 20 hours agorootparenthttps:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;320123470_The_Relat...The problem is climate change has become a motte and bailey (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Motte-and-bailey_fallacy). If we do come up with evidence that rising temps aren&#x27;t all that correlated to CO2, then we just change the target to &#x27;yeah but it causes ocean acidification&#x27; or &#x27;natural disasters are increasing&#x27; or &#x27;yeah but it kills coral reefs&#x27;.At this point, I&#x27;m not sure there is any possible experiment or evidence that would actually change most people&#x27;s mind on climate change. It has become a cause to support rather than a theory. reply duckmysick 5 hours agorootparentIf I understand this paper correctly, it compares the temperature and CO2 levels on geologic time scales:> Atmospheric CO2 concentration is correlated weakly but negatively with linearly-detrended T proxies over the last 425 million years.> To estimate the integrity of temperature-proxy data, δ^18O values were averaged into bins of 2.5 million years (My)It makes sense. Over long time scales, other factors are more important.Does the same apply to shorter time scales, like thousands, hundreds, or tens of years?> At this point, I&#x27;m not sure there is any possible experiment or evidence that would actually change most people&#x27;s mind on climate change.One possible way would be to continue releasing the CO2 at the current or larger rates. If then temperatures and the climate reverse to the state from 200 or 300 years ago then it means it&#x27;s part of a natural cycle and humans had nothing to do with it. reply roflyear 1 hour agorootparentprev> At this point, I&#x27;m not sure there is any possible experiment or evidence that would actually change most people&#x27;s mind on climate change. It has become a cause to support rather than a theory.Aren&#x27;t you (your way of thinking about this) part of the problem here, or even the whole problem?You&#x27;ve reduced climate change to politics - certainly there are many people (myself included) who don&#x27;t agree that it is political.There are people that say \"we need to think about the climate\" purely because they are liberal, but they can be ignored, and their views don&#x27;t change the reality. reply godelski 18 hours agorootparentprevYes. Make predictions. Wait. Observe. Measure difference between predicted outcome and actual outcome.We&#x27;ve had scientists making predictions since the 80&#x27;s, so we have some long term observations. I&#x27;ll save you the read, historical models are fairly accurate and have become more accurate over time.I&#x27;m not sure why anyone considers this a debate. It&#x27;s not a debate. It&#x27;s willingness to look at data or not.https:&#x2F;&#x2F;www.carbonbrief.org&#x2F;analysis-how-well-have-climate-m...https:&#x2F;&#x2F;agupubs.onlinelibrary.wiley.com&#x2F;doi&#x2F;full&#x2F;10.1029&#x2F;201... reply mikem170 20 hours agorootparentprevPredictions have been made, and we can check if they were correct, but maybe not at the moment.Some past short-term predictions, like predictions for 2020 made in 1990, may or may not be correct. We can look those up. Many other predictions are for what will happen in the coming decades, and we won&#x27;t be able to assess with certainty whether they were correct until those future dates. reply croes 20 hours agorootparentprevPretty easily.Do nothing and wait. But it could have severe consequences. reply dzwa 19 hours agoparentprevPopper reply umvi 21 hours agoprevThis article has good advice for logical thinking, but just one nit pick:> having just lost both of his parents, he reflects on the all too human allure of promises of supernatural reunions in the afterlife, reminding us that falling for such fictions doesn’t make us stupid or bad people, but simply means that we need to equip ourselves with the right tools against them.I feel like grouping all religion in with psychics and con artists is a bit extreme. Sure, it&#x27;s impossible by contradiction for all tenets of all religions to be simultaneously true.But... there were, are, and will yet be many intelligent people of different religions that, for various empirically-unprovable reasons, feel there is a God - even if they know at an intellectual level that their current church or belief system isn&#x27;t entirely consistent or correct.It&#x27;s important to respect their religious liberty even if you disagree. Many people (including on this very forum) have had spiritual experiences that seem to confirm the existence of a God at a visceral level. It&#x27;s hard to explain unless you&#x27;ve had a spiritual experience, but they can include moments of emotional connection to deceased loved ones, \"gut feelings\" that helped you do something important or avoid something bad, or unexpected and unusual ideas or thoughts (in my case, sometimes even programming related) that aid in overcoming life&#x27;s obstacles, just to name a few. reply sergiosgc 21 hours agoparent> But... there were, are, and will yet be many intelligent people of different religions that, for various empirically-unprovable reasons, feel there is a God - even if they know at an intellectual level that their current church or belief system isn&#x27;t entirely consistent or correct.No one should be denied the freedom to follow these feelings, within the boundaries of not infringing on other people&#x27;s rights and liberties.Having said that, please accept mass delusions do happen, smart and intelligent people do get caught in them, and so this is no proof of a god. You need material proof, and there is none. reply user_7832 20 hours agorootparentI agree with most of your comment. However, when you say> You need material proof, and there is none.I would like to add the the old adage holds true - absence of evidence is not evidence of absence. (Also, this is more for the god as an almighty person in the sky type of case. For a person who considers the natural elements as god, it is simply different) reply lmm 19 hours agorootparent> I would like to add the the old adage holds true - absence of evidence is not evidence of absence.Oh but it is - it&#x27;s not proof of absence but it is evidence. Any piece of evidence must have two sides - if observing A would increase your confidence that B, then observing not A must reduce your confidence that B. reply umvi 19 hours agorootparentThat&#x27;s like monkeys being observed by scientists behind one way mirrors saying they have evidence that there is no one watching them because they&#x27;ve never seen any scientists. But that would be a mistaken assumption because the scientists intentionally made themselves difficult to observe for the purposes of their research (monkeys behave differently if they know they are being watched).I think most religious people would agree that God intentionally makes it impossible to verify his existence at a social level via empirical means... but that he does provide evidence of his existence at the individual level by speaking directly to you via spiritual experiences. reply lmm 18 hours agorootparent> I think most religious people would agree that God intentionally makes it impossible to verify his existence at a social level via empirical meansFunny how that went from an obscure, almost certainly heretical idea to mainstream in such a short time. reply pengstrom 19 hours agorootparentprevTechnically only true for formal systems where you can axiomatically define A = not A, which is principally arbitrary. reply coupdejarnac 19 hours agorootparentprevAnd to that I say, extraordinary claims require extraordinary evidence. Christianity has had 2000 years to produce extraordinary evidence. What&#x27;s the hold up? reply Mawr 12 hours agorootparentprevThe reverse of that adage holds even truer - absence of evidence is not evidence of existence. reply sokoloff 21 hours agoparentprev> respect their religious liberty even if you disagreeBelieve and do whatever you want with respect to religion, so long as it doesn&#x27;t extend to telling me what I can or cannot do because of your beliefs.You and others have my full support for religious liberty up until that line (overwhelmingly in the form of \"yeah, whatever; I literally could not care less what you believe or do\"). reply denton-scratch 21 hours agoparentprev> It&#x27;s important to respect their religious liberty even if you disagree.I respect other people&#x27;s right to have strongly-held beliefs about roughly anything, even if they&#x27;re wrong. I&#x27;d rather they were wrong, than that they \"believed\" something that is beyond belief and disbelief.In the case of \"beliefs\" that are unverifiable in principle, well I don&#x27;t count those as beliefs; and equally, I don&#x27;t think it&#x27;s possible to disagree with such \"beliefs\". I&#x27;m with Wittgenstein on that; these are things that you can state (or deny) completely grammatically, but whose assertion (or denial) is meaningless.I also like the idea that if a thing can&#x27;t, in principle, make a detectable difference to the world, then it doesn&#x27;t make sense to speak of it as real or unreal. reply TeMPOraL 20 hours agorootparentExactly this. If a belief can&#x27;t generate a testable prediction, even one not necessarily testable by us right now, but testable in principle, then that belief is meaningless. There&#x27;s no basis to claim its true or false, it has no impact on reality whatsoever. It&#x27;s a waste of effort to even think about it. reply mizzao 20 hours agorootparentThis is the textbook definition of the religion of Scientism: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Scientism reply denton-scratch 6 hours agorootparentThanks for the wikipedia link.It says that Dennett and the \"New Atheists\" assert \"that God does not exist\". That perfectly exemplifies my point: you can&#x27;t use non-verifiability to prove that God doesn&#x27;t exist. What it proves is that neither an unverifiable claim nor it&#x27;s contradiction is meaningful.From the wiki article, it looks to me like my position isn&#x27;t Scientism at all. The article presents Scientism as a kind of fallacy: attempting to apply some version of scientific method to everything. What I&#x27;m on about is more like ternary logic: a thing can be True, or it can be False, or it can be neither. It&#x27;s closer to Not Even Wrong.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Not_even_wrong reply TeMPOraL 17 hours agorootparentprevSure, whatever. Call it religion if you like, but try and define something existing or being true in a way that doesn&#x27;t involve making testable predictions. reply switchbak 12 hours agorootparentprevThis is why discussions of free will and living in a simulation seem pointless to me. I’ve never heard of a way to test them.Provide me a test and I’ll happily reconsider! reply TeMPOraL 5 hours agorootparentThe simulation hypothesis is in principle testable in that, if we were in a simulation, we may be able to find bugs in it, possibly even escape the sandbox. Right now, we don&#x27;t have any \"angle of attack\", and nothing we could suspect of being a bug (which includes e.g. being able to perceive artifacts of some optimization in the simulation) - so there&#x27;s no point in working oneself up about this, or assuming it&#x27;s true. However, because this is testable in theory and there&#x27;s a possibility it&#x27;ll become testable in practice, it doesn&#x27;t qualify as fundamentally \"meaningless\" in my book. reply Mawr 12 hours agoparentprevPeople are products of their environment.What are the chances a child born to christian parents will be a christian vs a buddhist?Why as the access to knowledge has been increasing more and more people are becoming non-believers?Why have religious beliefs in the sun, lighting, fire, etc. vanished as we developed full understanding of the phenomena?What makes you think you will be able to justify sticking to your \"gut feelings, therefore god\" position as we develop a greater understanding of the brain? reply renox 20 hours agoparentprev> It&#x27;s important to respect their religious liberty even if you disagreeRespect in what sense? My stepsister is religious so I \"respect\" her by not talking about this subject.But if she ever talk with me about religion I would say that I&#x27;m an atheist who believe that all religions are a kind of self deception to make believers feel better.. reply asynchronous 20 hours agorootparentBy not writing off everyone who is religious as categorically wrong or incorrect in every other category? reply verve_rat 19 hours agorootparentWhich no one in this thread has done? The article even has advice on this matter quoted at the root of this thread: \"reminding us that falling for such fictions doesn’t make us stupid or bad people\". reply umvi 19 hours agorootparentConfidently labeling religious beliefs as \"fictions\" seemed a bit disrespectful to me. reply bazoom42 18 hours agorootparentLabelling it fiction is more respectful than labelling it baloney. But if the belief is non-falsifiable or outrigth falsified, then it is baloney.People should be allowed to belive whatever they want, but that does not mean other should have to belive it. reply pengstrom 19 hours agorootparentprevThat&#x27;s sad. I&#x27;d assume your love for you sister would make you find common ground in doubt and humility, virtues of both science and religion. Every single human tells themselves lies to feel better, we just call them Justice or Democracy. We&#x27;re just self-conscious meatbags thrust into existence against our will, after all. reply gwbas1c 19 hours agoparentprevGod is not falsifiable.If anything, \"god\" exposes aspects of human psychology that we understand poorly and often don&#x27;t have the maturity to discuss rationally.But I will say this: Anyone who says things like \"God wants you to do XXX\" is trying to manipulate you. reply aerjot4 20 hours agoparentprev>It&#x27;s important to respect their religious liberty even if you disagree.I respect people&#x27;s religious liberty for the same reason I respect any other kind of freedom of belief.I do not know what it means to respect a religion. Either a prophet actually witnessed what they claim to have witnessed, or they are lying, or they are delusional. Perhaps Jesus and Moses and Siddhartha Gautama get a pass because we don&#x27;t know exactly what they said or did, but how can a non-believer explain Joseph Smith or Mohammad as anything except insane or malicious? What does respect for a religion look like when I believe that its most sacred figures are the most contemptible of con men?I am respectful in that I don&#x27;t go around insulting people. I am respectful in that I understand life is hard and people find comfort wherever they can. But respect for the victims of a scam does not imply respect for the scam itself. I can understand the fear of poverty, and I can understand the temptation of wealth, but the people who write me saying I will inherit $15 million still belong in prison. reply ryandrake 18 hours agorootparentTo me, \"respect\" means only a base level of tolerance that we should give to people believing in things. Respecting someone else&#x27;s religious belief doesn&#x27;t mean validating or endorsing it. And it doesn&#x27;t prevent one from criticizing it. Just because someone&#x27;s belief is religious doesn&#x27;t give them a free \"get out of criticism\" pass.We should treat religious belief just like we treat belief in other supernatural things or in other types of extraterrestrial life. reply rixed 11 hours agoparentprevI wish parents would respect religious disbelief of their kids as much as scientists respect religious beliefs. reply demondemidi 19 hours agoparentprevYou seem to have restated Sagan&#x27;s position with more words. What about your comment differs from his assertion? I&#x27;m not seeing it? reply thenerdhead 19 hours agoparentprevYou’d have to read the book to get more context on his sadness of losing his parents and his reflections on being susceptible during that time. A famous quote is:“Science is not only compatible with spirituality; it is a profound source of spirituality.”― Carl Sagan, The Demon-Haunted World: Science as a Candle in the Dark reply wredue 21 hours agoparentprevThe article did not advocate for disrespecting liberty.It actually very hilariously directly talked about exactly your post:“Gut feelings” and “people experiencing things” are not independently verifiable facts. In fact, every time religious experiences are tested, they are not repeatable or verifiable. reply ukj 21 hours agorootparentRepeatability and verifiability aren’t the be-all&#x2F;end-all criteria for knowledge&#x2F;truth.Thus is over-selling science as the only avenue to truth&#x2F;knowledge.Where does it leave formal&#x2F;mathematical&#x2F;theoretical knowledge?Where does this leave historical and political facts?Moral truths?Science is at best instrumentalism. reply verve_rat 19 hours agoparentprevRespecting your religious liberty does not mean suppressing my opinions about religion.Your religious freedom is not more important than my rights of speech or freedom from religion. reply tcbawo 21 hours agoprevCarl Sagan was very wise. I find his insights thought provoking and salient. However, the cynic in me is sad that the default of human nature is to be gullible, tribal, delegate fact checking to authority figures, and prone to confirmation bias. I would love to become better at rational thought and discernment. But, I feel that I (and frankly, 95% of the people on this site) are already better than the vast majority of people out there in this regard. In other words, these messages are preaching to the choir. I’m not sure what media or messenger could bring these (or similar) lessons to the masses, or whether they could have an enduring impact. The optimist in me hopes that this will be possible some day. reply ironmagma 20 hours agoparentI think the answer is in better education. There is never a logic class in elementary school or middle school. Why? reply JohnFen 19 hours agorootparentThere was when I was in middle school. I&#x27;m always unpleasantly surprised when I hear what is no longer taught. reply rdedev 19 hours agorootparentprevI think a good place to start would be to teach it during highschool. Especially since a lot of bad science gets spread around social media. College may be a bit too late since that&#x27;s when you really need to start applying those critical thinking skills reply anotherevan 19 hours agoprevThe thing that bugs me a bit about Occam&#x27;s razor [paraphrased] - All other things being equal, the simplest explanation is usually the right one - is I&#x27;ve seen too many people smugly quote the second half, leaving off the, \"All other things being equal\" bit.That&#x27;s not Occam&#x27;s fault. Razors are meant to be sharp, and people cut themselves with far blunter implements. reply johnsanders 20 hours agoprevI&#x27;m not sure if it&#x27;s made my life better or worse, but this book above all others has had the most profound impact on how I have lived it. reply ckrapu 21 hours agoprevThese are excellent but I think #8 (statistics of small numbers) is one that, with some nuance, you can get more personal mileage out of if you&#x27;re willing to tolerate being wrong some of the time.For example, I&#x27;ve noticed that of the managers I&#x27;ve had, the good ones and bad ones are cleanly separated by one trait or property. This is a sample size of maybe 7 or smaller.Depending on your priors, my P(HypothesisData) is maybe 0.6-0.7 which is terrible from a research and scientific point of view.I&#x27;ll take that level of certainty for day-to-day decision making anytime, though. Make enough of these weakly-backed hypotheses and you can avoid a lot of trouble. reply nerdponx 17 hours agoparentIsn&#x27;t this essentially the basis of decision theory and statistical hypothesis testing? The hard part is to determine an acceptable probability of being wrong in any given situation. reply ckrapu 16 hours agorootparentYes, and my only commentary here is that the threshold for academic decision science is a lot higher than the one I have for managing my day-to-day life. reply plugin-baby 20 hours agoparentprev> I&#x27;ve noticed that of the managers I&#x27;ve had, the good ones and bad ones are cleanly separated by one trait or property.What was the trait? reply norir 19 hours agoprevGood thoughts overall. I will assume Sagan has deeper thoughts on religion than what he writes here, but I found those parts superficial and overly simplistic. The problem I have with his perspective is that we know from Godel&#x27;s incompleteness theorem that no formal system can explain its own consistency in the language of the system. As a human, this means that there are things in life we have to accept as true but are fundamentally unexplainable. Religion does not explain the unexplainable but it provides a language and framework in which certain experiences of being alive can be felt and communicated. Both science and religion (to the extent to which these are even different concepts) have positive and negative sides. I personally think the dark side of science is just as dark as that of traditional religion but I don&#x27;t deny the light or dark contained in both. reply chrisweekly 21 hours agoprevMaria Popova is an extraordinary essayist; I highly recommend exploring themarginalian.org site. The breadth of topics, and the keen intelligence coupled with such warmth and humanity... it&#x27;s a treasure trove. reply mihaic 17 hours agoprevWhile Sagan&#x27;s advice is great, it&#x27;s still putting burden on the individual to handle bullshit.The more I&#x27;ve thought about bullshit as a phenomenon, the more I think the only real solutions are social ones, where non-bullshitters need to coordinate to make bullshitting a bad scenario. Things like shaming, publicly crying bullshit, coordinated dismissing bad actors.If handled individually, it&#x27;ll always be asymetrically easier to bullshit than to defend against bullshit. reply chmod600 20 hours agoprev\"Arguments from authority carry little weight — “authorities” have made mistakes in the past. They will do so again in the future. Perhaps a better way to say it is that in science there are no authorities; at most, there are experts.\"That&#x27;s the most controversial, because a lot of people want to be authorities and don&#x27;t want to be questioned.For instance, the origins of Covid... or really lots of things about the pandemic were pushed by authorities with little justification other than authority. It turns out many of those things were subsequently reversed or reasonably doubted. reply anon84873628 20 hours agoparentI agree that that particular point is one of the biggest problems when it comes to translating scientific understanding to public policy.Can there be \"settled science\"? What is considered an acceptable level of skepticism?Governing society is largely based on rough estimates of ROI and optimizing for certain value systems based on minimal firm data at best. Often under time pressure.The problem is that it&#x27;s easy to generate bullshit skepticism to lock up the process (to benefit the status quo) whereas it takes lots of effort to scientifically disprove and debunk the bullshit. We generally use appeal to authority as a shortcut to overcome this effort asymmetry.The thing we need to be clear about is when&#x2F;how that is a valid tool for public policy, but not science itself. reply SoftTalker 19 hours agorootparentThe bullshit skepicism should usually be identifiable by applying the same set of rules to evaluate its claims. Take the claim that Ivermectin was effective in treating COVID. Some doctors did support this, but that&#x27;s Argument by Authority, and probably also Statistics of Small Numbers if not several others. reply JohnFen 19 hours agoparentprev> lots of things about the pandemic were pushed by authorities with little justification other than authority.Whatever people&#x27;s feelings about how this was handled, please don&#x27;t include the scientists in the issue. The authorities mandating things were the political folks, not the scientists. reply dgudkov 14 hours agoprevI&#x27;ve long been thinking that society is badly missing technology-enabled social tools for finding consensus because, unfortunately, the current social networks and their monetization principles drive exactly the opposite - i.e. polarization.Carl Sagan&#x27;s Rules seem like a candidate for a framework for such a tool, or at least, a starting point. reply robomc 21 hours agoprev> misunderstanding of the nature of statistics (e.g., President Dwight Eisenhower expressing astonishment and alarm on discovering that fully half of all Americans have below average intelligence);this one would be surprising though reply asynchronous 20 hours agoparentAlso a bad statistical statement, because the way it is phrased implies that the average is being taken from the whole world, rather than just America. reply ls612 21 hours agoparentprevIntelligence doesn’t have much skewness in its distribution so the mean is approximately the median. reply nerdponx 16 hours agorootparentRight, but that&#x27;s less and assumption about basic statistical literacy than it is about a particular distribution that happens to describe the data. Many things in society and nature are not symmetric around their means. reply Yizahi 19 hours agoprevA thing of note - to wield such a kit, one must be a an expert in the baloney detection, even if a just a little. Example:It is year 2020 and there are these new and suspicious vaccines for the new illness and you want to understand what&#x27;s going on. Smart people say that multiple hypothesis need to be evaluated, authorities are unreliable, unquantified promises bad and so on. So an unprepared person might simply drown in the sea of baloney hypotheses, like invermectin treatments, electrophoresis treatments, etc.If a person lacks critical thinking facilities which actually work, and aren&#x27;t simply contrarian kindergarten style, then adhering to authorities would be the optimal path. reply apienx 19 hours agoprevThinking is hard. Learning to change your opinions&#x2F;beliefs is even harder. It takes deliberate and consistent practice to get better at these things (join your local Skeptics&#x2F;Humanists group if interested).To quote Bertrand Russell: “Many people would rather die than think; in fact, most do.” ;-) reply agumonkey 19 hours agoparentIt&#x27;s a subtle topic, but I think we&#x27;re often conflating extrapolating from our current mental model with thinking.Often when I get into a dead end, I realize, all I had to do was to walk my knowledge slower, and try to poke holes at it, flip it backward, toy with it, do games with the problem at point .. it&#x27;s more of a poetry seeking game than hard thinking. That&#x27;s why (IMO) most eureka&#x2F;new solution feels like a loosening, the hard part was going too hard in the wrong direction.After failing a few too many times you get the habit of not rushing the bad mode of thinking and rather play with ideas.my 2 cents reply passion__desire 17 hours agoparentprevWe need to collect as many Thinking Tools (Daniel Dennett book) as early as possible. reply joering2 19 hours agoprevSlight OT, but his suing of Apple was such a douchery move, I will never be able to understand how such brilliant and humble human being would want to entangle himself in such radicicolous petty and frankly baseless lawsuit. reply chiefalchemist 20 hours agoprevSee also Jim Lehrer&#x27;s rules for journalism. That is, when you see these rules broken someone is very likely wanting to bullshit you and&#x2F;or as a \"journalist\" has failed to use critical thinking.https:&#x2F;&#x2F;www.openculture.com&#x2F;2020&#x2F;01&#x2F;jim-lehrers-16-rules-for... reply ukj 4 hours agoprevIn the spirit of bullshit-busting and critical thought here&#x27;s a thought experiment...Alan Turing: The claims made in the Halting Problem is genrally true, and is therefore unfalsifiable even in principle.Carl Sagan: Propositions that are untestable, unfalsifiable are not worth much.All computer scientists in synchronized act of distributed consensus: Bullshit. reply zubairq 21 hours agoprevInteresting read reply kazinator 20 hours agoprevThe point 9 about falsifiability needs a lot more nuance. The problem is that we cannot get away from unfalsifiable hypotheses. No matter how far we probe into some phenomenon, there is always the question \"why?\" beyond which we don&#x27;t know.When we are left with a \"why\", our only choices are (1) take an agnostic stance and decline to make hypotheses, (2) make unfalsifiable hypotheses. If we choose (2) there are unfalsifiable hypotheses that are superior and those that are inferior. The superior ones are ones which postulate less. The best unfalsifiable hypothesis is the one which postulates no hidden variables. The answer to \"why\" (why things are the way they are, and not in some other arrangement) is that (a) other arrangements for a universe are valid and exist, but we are biased because we are intelligent beings which live in a particular arrangement and only that one is observable to us (the \"anthropic principle\"); and (b) in fact, why not: all the other possible universes exist, just not \"here\". (If they don&#x27;t, then we need to come up with a hypothetical reason why they don&#x27;t, which is more complicated than assuming there is no reason: by Occam&#x27;s Razor, we just trim that out.)What we don&#x27;t want to be doing is spouting some unfalsifiable hypothesis as if it were unvarnished truth; but nevertheless, we can pick the best one and defend it against the others, when they come up.I should add that there is nothing wrong with postulating theoretical entities and processes; doing so has served us well, and in many cases, additional discoveries lended reality to the postulated entities. E.g. atoms were originally a philosophical construct based on the idea that subdividing matter into smaller pieces has to bottom out at some indivisible particle; and that&#x27;s where we got the atom word. Subatomic particles were postulated initially too. These are not exactly the same as hidden variables because their existence is falsifiable. We have evidence that there exists an electron, for instance, even though originally it was just postulated. reply Thrir94994i 20 hours agoprev [3 more] [flagged] passion__desire 17 hours agoparentKnow the rules and then break them. If you are criticising a physicist, you should be competent enough to know their jargon and conclusively point out gaps in their knowledge. E.g. as Sabine is doing with lost in math.Just stating scientist could be wrong isn&#x27;t helpful. reply billfor 19 hours agoparentprev [–] Not sure why you&#x27;re getting downvoted. Sagan himself said to be skeptical of those in authority. \"Who is running the science and technology in a democracy if the people don&#x27;t know anything about it?\" https:&#x2F;&#x2F;www.youtube.com&#x2F;shorts&#x2F;bZ0x3cQ0PnU replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author of The Marginalian, a free and ad-free website, is seeking reader support to maintain the website.",
      "The author discusses Carl Sagan's book which underlines the significance of critical thinking and offers methods for distinguishing truth from falsehood.",
      "To navigate a world brimming with propaganda and pseudoscience, the author underscores the need for critical evaluation of claims, avoidance of logical fallacies, and usage of tools like the \"baloney detection kit.\""
    ],
    "commentSummary": [
      "The article touches on numerous subjects such as Carl Sagan's principles for critical thinking, the significance of falsifiability in science, and the obstacles of differentiating science in a post-truth era.",
      "It brings up discussions on climate change models, the existence of God and religious beliefs, decision theory, statistical hypothesis testing, and the necessity of critical thinking in journalism.",
      "Ultimately, the article underscores the importance of rational thinking, considerate discussion, and information rooted in solid evidence in society."
    ],
    "points": 203,
    "commentCount": 184,
    "retryCount": 0,
    "time": 1698601640
  },
  {
    "id": 38068801,
    "title": "Raspberry Pi 5 has no hardware video encoding and only HEVC decoding",
    "originLink": "https://www.raspberrypi.com/news/introducing-raspberry-pi-5/#comment-1594055",
    "originBody": "For home For industry Hardware Software Documentation News Forums Foundation News All news Search the archive RSS feed Introducing: Raspberry Pi 5! 28th Sep 2023 Eben Upton 657 comments Today, we’re delighted to announce the launch of Raspberry Pi 5, coming at the end of October. Priced at $60 for the 4GB variant, and $80 for its 8GB sibling (plus your local taxes), virtually every aspect of the platform has been upgraded, delivering a no-compromises user experience. Raspberry Pi 5 comes with new features, it’s over twice as fast as its predecessor, and it’s the first Raspberry Pi computer to feature silicon designed in‑house here in Cambridge, UK. Key features include: 2.4GHz quad-core 64-bit Arm Cortex-A76 CPU VideoCore VII GPU, supporting OpenGL ES 3.1, Vulkan 1.2 Dual 4Kp60 HDMI® display output 4Kp60 HEVC decoder Dual-band 802.11ac Wi-Fi® Bluetooth 5.0 / Bluetooth Low Energy (BLE) High-speed microSD card interface with SDR104 mode support 2 × USB 3.0 ports, supporting simultaneous 5Gbps operation 2 × USB 2.0 ports Gigabit Ethernet, with PoE+ support (requires separate PoE+ HAT, coming soon) 2 × 4-lane MIPI camera/display transceivers PCIe 2.0 x1 interface for fast peripherals Raspberry Pi standard 40-pin GPIO header Real-time clock Power button In a break from recent tradition, we are announcing Raspberry Pi 5 before the product arrives on shelves. Units are available to pre-order today from many of our Approved Reseller partners, and we expect the first units to ship by the end of October. Watch Eben do some talking about Raspberry Pi 5 We’re incredibly grateful to the community of makers and hackers who make Raspberry Pi what it is; you’ve been extraordinarily patient throughout the supply chain issues that have made our work so challenging over the last couple of years. We’d like to thank you: we’re going to ringfence all of the Raspberry Pi 5s we sell until at least the end of the year for single-unit sales to individuals, so you get the first bite of the cherry. We’re also giving every print subscriber to The MagPi and HackSpace magazines a single-use code, giving them priority access to Raspberry Pi 5 hardware. Click those links to learn more about our Priority Boarding programme — and if you subscribe today, you can get your hands on a Priority Boarding pass too. Between now and the end of October, we’ll be running a series of regular articles and videos, focusing on different aspects of the platform. Keep checking in here. A little history Way back in June 2019, we launched Raspberry Pi 4, the first true PC-class Raspberry Pi computer. With a quad-core Arm Cortex-A72 processor clocked at 1.5GHz, it was roughly forty times faster than the original Raspberry Pi model from 2012. In many ways the timing was perfect: in March the following year, schools closed, and millions of schoolchildren around the world were sent to study from home. Tens of thousands of them were able to rely on a Raspberry Pi 4 as their primary PC. Watch Raspberry Pi 5 show you all of its bits without talking In the four years since then, Raspberry Pi 4, and its derivatives Raspberry Pi 400 and Compute Module 4, have become firm favourites of enthusiasts, educators, and professional design engineers worldwide. Modern Raspberry Pi 4 computers run 20% faster than the launch variant, with a core clock speed of 1.8GHz. And, despite the well publicised challenges that have affected the electronics supply chain over the last two years, we’ve made and sold over 14 million units of Raspberry Pi 4 in that time. But time doesn’t stand still, and neither does our community’s appetite for performance. And since 2016 — the era of Raspberry Pi 3 — we’ve been quietly working on a much more radical overhaul of the Raspberry Pi platform. Today, that effort bears fruit, with the launch of Raspberry Pi 5: compared to Raspberry Pi 4, we have between two and three times the CPU and GPU performance; roughly twice the memory and I/O bandwidth; and for the first time we have Raspberry Pi silicon on a flagship Raspberry Pi device. New platform, new chipset Three new chips, each designed specifically for the Raspberry Pi 5 program, come together to deliver a step change in performance. BCM2712 BCM2712 is a new 16-nanometer application processor (AP) from Broadcom, derived from the 28-nanometer BCM2711 AP which powers Raspberry Pi 4, with numerous architectural enhancements. At its heart is a quad-core 64-bit Arm Cortex-A76 processor, clocked at 2.4GHz, with 512KB per-core L2 caches, and a 2MB shared L3 cache. Cortex-A76 is three microarchitectural generations beyond Cortex-A72, and offers both more instructions per clock (IPC) and lower energy per instruction. The combination of a newer core, a higher clock speed, and a smaller process geometry yields a much faster Raspberry Pi, and one that consumes much less power for a given workload. Our newer, faster CPU is complemented by a newer, faster GPU: Broadcom’s VideoCore VII, developed here in Cambridge, with fully open source Mesa drivers from our friends at Igalia. An updated VideoCore hardware video scaler (HVS) is capable of driving two simultaneous 4Kp60 HDMI displays, up from single 4Kp60 or dual 4Kp30 on Raspberry Pi 4. A 4Kp60 HEVC decoder and a new Image Sensor Pipeline (ISP), both developed at Raspberry Pi, round out the multimedia subsystem. To keep the system supplied with memory bandwidth, we have a 32-bit LPDDR4X SDRAM subsystem, running at 4267MT/s, up from an effective 2000MT/s on Raspberry Pi 4. RP1 Previous Raspberry Pi generations were built on a monolithic AP architecture: while some peripheral functions were provided by an external device (the Via Labs VL805 USB controller and hub on Raspberry Pi 4, and the Microchip LAN951x and LAN7515 USB hub and Ethernet controller chips on earlier products), substantially all of the I/O functions were integrated into the AP itself. Fairly early in the history of Raspberry Pi, we realised that as we migrated the AP to progressively newer process nodes, this approach would eventually become both technically and economically unsustainable. Raspberry Pi 5, in contrast, is built on a disaggregated chiplet architecture. Here, only the major fast digital functions, the SD card interface (for board layout reasons), and the very fastest interfaces (SDRAM, HDMI, and PCI Express) are provided by the AP. All other I/O functions are offloaded to a separate I/O controller, implemented on an older, cheaper process node, and connected to the AP via PCI Express. RP1 is our I/O controller for Raspberry Pi 5, designed by the same team at Raspberry Pi that delivered the RP2040 microcontroller, and implemented, like RP2040, on TSMC’s mature 40LP process. It provides two USB 3.0 and two USB 2.0 interfaces; a Gigabit Ethernet controller; two four-lane MIPI transceivers for camera and display; analogue video output; 3.3V general-purpose I/O (GPIO); and the usual collection of GPIO-multiplexed low-speed interfaces (UART, SPI, I2C, I2S, and PWM). A four-lane PCI Express 2.0 interface provides a 16Gb/s link back to BCM2712. Under development since 2016, RP1 is by a good margin the longest-running, most complex, and (at $15 million) most expensive program we’ve ever undertaken here at Raspberry Pi. It has undergone substantial evolution over the years, as our projected requirements have changed: the C0 step used on Raspberry Pi 5 is the third major revision of the silicon. And while its interfaces differ in fine detail from those of BCM2711, they have been designed to be very similar from a functional perspective, ensuring a high degree of compatibility with earlier Raspberry Pi devices. DA9091 BCM2712 and RP1 are supported by the third new component of the chipset, the Renesas DA9091 “Gilmour” power-management IC (PMIC). This integrates eight separate switch-mode power supplies to generate the various voltages required by the board, including a quad-phase core supply, capable of providing 20 amps of current to power the Cortex-A76 cores and other digital logic in BCM2712. Like BCM2712, DA9091 is the product of a multi-year co-development effort. Working closely with the Renesas team in Edinburgh allowed us to produce a PMIC which is precisely tuned for our needs. And we were able to squeeze in two frequently requested features: a real-time clock (RTC), which can be powered by an external supercapacitor or a rechargeable lithium-manganese cell; and a PC-style power button, supporting hard and soft power-off and power-on events. Two other elements of the chipset have been retained from Raspberry Pi 4. The Infineon CYW43455 combo chip provides dual-band 802.11ac Wi-Fi and Bluetooth 5.0 with Bluetooth Low-Energy (BLE); while the chip itself is unchanged, it is provided with a dedicated switched power supply rail for lower power consumption, and is connected to BCM2712 by an upgraded SDIO interface which supports DDR50 mode for higher potential throughput. As before, Ethernet connectivity is provided by a Broadcom BCM54213 Gigabit Ethernet PHY; this now sits at a jaunty 45-degree angle, a first for Raspberry Pi, and a source of enduring disappointment for orthogonal-layout enthusiast and CTO (Software) Gordon Hollingworth. Form-factor evolution On the outside, Raspberry Pi 5 closely resembles its predecessors. But, while retaining the overall credit-card-sized footprint, we’ve taken the opportunity to update some elements of the design, to align with the capabilities of the new chipset. We’ve removed the four-pole composite video and analogue audio jack from the board. Composite video, now generated by RP1, is still available from a pair of 0.1”-spaced pads on the bottom edge of the board. We now sport a pair of FPC connectors, in the space formerly occupied by the four-pole jack and camera connector. These are four-lane MIPI interfaces, using the same higher-density pinout found on various generations of Compute Module I/O board; and they are bi-directional (transceiver) interfaces, meaning that each one can connect either to a CSI-2 camera or to a DSI display. The space on the left of the board formerly occupied by the display connector now contains a smaller FPC connector which provides a single lane of PCI Express 2.0 connectivity for high-speed peripherals. The Gigabit Ethernet jack has returned to its classic position in the bottom right corner of the board, after a brief sojourn in the top right on Raspberry Pi 4. And it’s brought with it the four-pin PoE connector, simplifying the board layout at the cost of a compatibility break with our existing PoE and PoE+ HATs. Finally, we’ve grown a pair of mounting holes for a heatsink, as well as JST connectors for the RTC battery (two pins), Arm debug and UART (three pins), and fan with PWM control and tacho feedback (four pins). Designed in Cambridge, manufactured in Wales Like all flagship Raspberry Pi products, Raspberry Pi 5 is built at the Sony UK Technology Centre in Pencoed, South Wales. We have been working with Sony since the launch of the first Raspberry Pi computer in 2012, and we’re firm believers in the benefits of manufacturing our products within a few hours’ drive of our engineering design centre in Cambridge: a decade of frequent interaction with the Sony team has helped us understand how to design products that can be built reliably, cheaply, and at massive scale. Raspberry Pi 5 marks the introduction of a number of manufacturing innovations. One of these is intrusive reflow for connectors, which improves the mechanical quality of the product, increases throughput, and eliminates the costly and energy-intensive selective- or wave-solder process from the production flow. Others include fully routed panel singulation for cleaner board edges, and a new approach to production test inspired by our experiences testing our RP2040 microcontroller at scale. Accessories, accessories, accessories Every new flagship Raspberry Pi product is accompanied by new accessories, and Raspberry Pi 5 is no exception. Layout changes, new interfaces, and much higher peak performance (and a smaller increase in peak power consumption) have led us to redesign some existing accessories, and to develop some entirely new ones. Case The updated case for Raspberry Pi 5, priced at $10, builds on the aesthetic of its Raspberry Pi 4 predecessor, but adds a host of new usability and thermal-management features. An integrated 2.79 (max) CFM fan, with fluid dynamic bearings selected for low noise and an extended operating lifetime, connects to the four-pin JST connector on Raspberry Pi 5 to provide temperature‑controlled cooling. Air is drawn in through a 360‑degree slot under the lid, blown over a heatsink attached to the BCM2712 AP, and exhausted through connector apertures and vents in the base. We’ve lengthened the case, and tweaked the retention features, to make it possible to insert the Raspberry Pi 5 board without removing the SD card. And by removing the top of the case, it is now possible to stack multiple cases, as well as to mount HATs on top of the fan, using spacers and GPIO header extensions. Like all our plastic products, the new case is manufactured by our friends at T-Zero, in the West Midlands, UK. Active Cooler Raspberry Pi 5 has been designed to handle typical client workloads, uncased, with no active cooling. Users who wish to use the board uncased under continuous heavy load, without throttling, have the option of adding a $5 Active Cooler. This attaches to the board via two new mounting holes, and connects to the same four-pin JST connector as the case fan. A radial blower, again selected for low noise and extended operating lifetime, pushes air through an extruded and milled aluminium heatsink. Both the case and the Active Cooler are able to keep Raspberry Pi 5 well below the thermal throttle point for typical ambient temperatures and worst-case loads. The cooling performance of the Active Cooler is somewhat superior, making it particularly suitable for overclockers. 27W USB-C Power Supply Raspberry Pi 5 consumes significantly less power, and runs significantly cooler, than Raspberry Pi 4 when running an identical workload. However, the much higher performance ceiling means that for the most intensive workloads, and in particular for pathological “power virus” workloads, peak power consumption increases to around 12W, versus 8W for Raspberry Pi 4. When using a standard 5V, 3A (15W) USB-C power adapter with Raspberry Pi 5, by default we must limit downstream USB current to 600mA to ensure that we have sufficient margin to support these workloads. This is lower than the 1.2A limit on Raspberry Pi 4, though generally still sufficient to drive mice, keyboards, and other low‑power peripherals. For users who wish to drive high-power peripherals like hard drives and SSDs while retaining margin for peak workloads, we are offering a $12 USB-C power adapter which supports a 5V, 5A (25W) operating mode. If the Raspberry Pi 5 firmware detects this supply, it increases the USB current limit to 1.6A, providing 5W of extra power for downstream USB devices and 5W of extra on-board power budget: a boon for those of you who want to experiment with overclocking your Raspberry Pi 5. It should be noted that users have the option to override the current limit, specifying the higher value even when using a 3A adapter. In our testing, we have found that in this mode Raspberry Pi 5 functions perfectly well with typical configurations of higher-power USB devices, and all but the most pathological workloads. Camera and display cables The new, higher-density pinout of the MIPI connectors means that an adapter is required to connect our own cameras and displays, and third-party products, to Raspberry Pi 5. To support existing camera and display owners, we are offering FPC camera and display cables, which convert from the higher-density format (now referred to as “mini”) to the older lower-density format (now referred to as “standard”). These cables are available in 200mm, 300mm, and 500mm lengths, priced at $1, $2, and $3 respectively. Camera Module 3, the High-Quality Camera, the Global Shutter Camera, and the Touchscreen Display will all ship with both a standard-to-standard and a 200mm mini-to-standard cable. PoE+ HAT From early 2024, we will be offering a new PoE+ HAT. This supports the new location for the four-pin PoE header, and has an L-shaped form factor which allows it to sit inside the Raspberry Pi 5 case without interfering mechanically or disrupting airflow. Prototype PoE+ HAT. We don’t know yet what the production version will look like, but we do know that it won’t look like this. The new PoE+ HAT integrates a planar transformer into the PCB layout, and utilises an optimised flyback converter architecture to sustain high efficiency across the whole zero to 25W range of output powers. M.2 HATs One of the most exciting additions to the Raspberry Pi 5 feature set is the single-lane PCI Express 2.0 interface. Intended to support fast peripherals, it is exposed on a 16-pin, 0.5mm pitch FPC connector on the left-hand side of the board. From early 2024, we will be offering a pair of mechanical adapter boards which convert between this connector and a subset of the M.2 standard, allowing users to attach NVMe SSDs and other M.2-format accessories. The first, which conforms to the standard HAT form factor, is intended for mounting larger devices. The second, which shares the L-shaped form factor of the new PoE+ HAT, supports mounting 2230- and 2242-format devices inside the Raspberry Pi 5 case. Prototype M.2 HAT. Final hardware will not look like this. Raspberry Pi Beginner’s Guide, 5th Edition Sporting a brand-new look and feel, and priced at RRP £19.99 ($24.99), this new edition of our bestselling Raspberry Pi Beginner’s Guide is the definitive manual for Raspberry Pi computers and accessories. It has been comprehensively updated to cover Raspberry Pi 5, and the upcoming release of Raspberry Pi OS based on Debian Bookworm. RTC battery Last, but very much not least, we have sourced a Panasonic lithium manganese rechargeable coin cell, with a pre-fitted two-pin JST plug and an adhesive mounting pad. This is priced at $5, and is suitable for powering the Raspberry Pi 5 real-time clock (RTC) when the main power supply is disconnected. A newer, better Raspberry Pi OS In parallel with the final stages of the Raspberry Pi 5 programme, our software team has been busy developing a new version of Raspberry Pi OS, the official first-party operating system for Raspberry Pi devices. This is based on the most recent release of Debian (and its derivative Raspbian), codenamed “Bookworm”, and incorporates numerous enhancements, notably the transition from X11 to the Wayfire Wayland compositor on Raspberry Pi 4 and 5. Raspberry Pi OS will launch in mid-October, and will be the sole supported first-party operating system for Raspberry Pi 5. Keep checking back here: we’ll be telling you some more about the new OS, and you’ll be able to download it shortly before Raspberry Pi 5 arrives on the shelves in late October. Credits Bringing Raspberry Pi 5 to life has been a seven-year, $25 million endeavour, involving tens of organisations and hundreds of individuals. A non-exhaustive list of those who have contributed to Raspberry Pi 5, and its constituent silicon programs, can be found below — just click to expand it. A credits list for Raspberry Pi 5 Share this post Post to Twitter Post to Facebook Post to Linkedin Post to Pinterest Raspberry Pi 5 LATEST POSTS It's #MagPiMonday - show us what you're making DIY Raspberry Pi 5-powered computer| HackSpace #72 ScreenDress is embellished with spooky Pi-powered eyesThe MagPi #135 Teacher's Pi cluster controls digital learning classroom NEXT POST How can I get a Raspberry Pi 5 before everyone else? PREVIOUS POST Build a bipedal companion robot Share this post Post to Twitter Post to Facebook Post to Linkedin Post to Pinterest 657 comments Jump to the comment form Max 28th September 2023, 7:00 am Congratulations on the new Pi 5 – this is an awesome step for Raspberry Pi and the world of computing in general! Reply to Max Raspberry Pi Staff Liz Upton 28th September 2023, 11:37 am Thanks Max! (Trust you to get the first comment in!) Reply to Liz Upton Jim 28th September 2023, 7:11 pm Can the M.2 interface be used to boot of an SSD instead of the SD card? Reply to Jim Danny Pontbriand 30th September 2023, 6:08 am Of course why not. Your choice of in the worst case you can use sdcard to route booting to ssd. Reply to Danny Pontbriand Daniël van den Akker 28th September 2023, 7:01 am Congratulations on another marvelous product! I am really curious what everybody will make with the PCIe extension! Keep up the good work!! Kind regards, Daniël Reply to Daniël van den Akker philden 28th September 2023, 7:03 pm Hi! it Would be very nice to be able to boot from an mvne SSD… Reply to philden Dewey D Freeman 1st October 2023, 3:59 am aleady can b done Reply to Dewey D Freeman Ron Williams 21st October 2023, 12:00 am Dear philden, Pi and Chips. In answer to your query concerning the Pi 5 and M.2 chips. I have been booting, and running my Pi 4 on an M.2 SATA chip for quite sometime now. I also have another M.2 set aside, ready for when my Pi 5 arrives. Stay safe and my kind regards, Ron Williams. Reply to Ron Williams Alan McCullagh 28th September 2023, 7:10 am Félicitations et bravo to all the team from over here in France. Wonderful news and product – another huge step up/leap forward! Welcome to the family number 5. Reply to Alan McCullagh Raspberry Pi Staff Liz Upton 28th September 2023, 11:37 am Bisous! xx Reply to Liz Upton JulianG 28th September 2023, 7:13 am I was expecting RPI5 news since starting 2023 , and now they delivered a lot of what we were expecting, it will be amazing. Congratulations to the whole community from Argentina. Reply to JulianG Joe 3rd October 2023, 9:32 pm YES, a real time clock. I hope we will be able to buy them. Unlike the RP4. Reply to Joe Rogier Kerstens 28th September 2023, 7:16 am Congrats on this marvelous new product! Reply to Rogier Kerstens dave c 28th September 2023, 7:19 am looking forward to another generation of low power hardware hacking and projects! Reply to dave c KunYi 28th September 2023, 7:19 am Sound Great! want know more detail about RP1 I/O controller Reply to KunYi Raspberry Pi Staff Liz Upton 28th September 2023, 7:39 am We’re going to be publishing a lot of content about all the new features – keep watching this space! Reply to Liz Upton Leepspvideo 28th September 2023, 7:21 am Great work by all involved. The performance is great. Reply to Leepspvideo Karagir 28th September 2023, 7:31 am Congralution!! Another right step forward in the journey of RPi. Dying to know more about audio capabilities. Will it be only through the I2S port? Will HDMI port support ARC/ eARC? Thanks and congralutions again!! Reply to Karagir Mike 28th September 2023, 7:43 am How about a Pi Zero update? It’s badly needed. Reply to Mike Raspberry Pi Staff Alasdair Allan 28th September 2023, 7:46 am We did that? The Raspberry Pi Zero 2 W launched back in 2021. Reply to Alasdair Allan Raspberry Pi Staff PhilE 28th September 2023, 8:43 am Thanks, Mike! I won the sweepstake on how many comments it would take for somebody to whinge about something completely off-topic. Read the room – today is not the day. Reply to PhilE Pat 28th September 2023, 4:26 pm The problem is, you don’t listen to your customers. You’re are manufacturing PIs for the commercial market listening to their demands. You claim and $80 device which will more than likely be sold out for years to come and if you can get one, the price will be north of $200. Hard pass for me and I’m sure others. Reply to Pat Raspberry Pi Staff Liz Upton 28th September 2023, 4:50 pm Can we hold off on the predictions about how awful everything is going to be until people have actually bought one? Reply to Liz Upton Tap 28th September 2023, 5:20 pm The point Pat is making is that it’s nearly impossible for *people* to buy one. They all get sold to corporations. D Smith 29th September 2023, 8:22 am It will be interesting to see just how close to reality your £200 prediction comes. Would be lovely if it really turned out to be £80 and if supply didn’t create a real black market. I see a real hunger for the Pi 5 and designing it is only the first step, but to market in demand volumes at £80 !! now that is a ‘Muskarian’ challenge that has bedeviled the Pi team since the very first little gem that graced my desk. But whatever happens – well done to the Pi Team – we love you… Reply to D Smith Raspberry Pi Staff Liz Upton 29th September 2023, 9:52 am $35? Reply to Taylor Ben 28th September 2023, 9:43 am Only because they haven’t yet launched the 1GB and 2GB models :-) Reply to Ben Gordon77 28th September 2023, 8:20 am Great news. Well done, looks an impressive upgrade. Reply to Gordon77 Eric_S 28th September 2023, 8:22 am An amazing achievment! I have a question: – What is the specification of the new GPU? (raw FLOPS and real world performance vs the old one) Reply to Eric_S Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:04 am PI 4 was 4.4 GFLOPS Pi 5 over 10 Reply to Gordon Hollingworth Eric_S 28th September 2023, 11:11 am *Tips hat* Thanks! Reply to Eric_S QwertyChouskie 28th September 2023, 6:03 pm Would love to see some SuperTuxKart benchmarks on the shiny new GPU hardware at various graphics levels ;) Reply to QwertyChouskie Asher Klein 12th October 2023, 8:25 pm absolutely amazing. Can’t wait to see what some folk are gonna make with pi5 Reply to Asher Klein Eric Olson 28th September 2023, 4:55 pm The Pi 4 achieves from 10 to 13 GFlops on the high-performance linpack benchmark HPL, which is used industry wide to measure such things. Judging from other Cortex-A76 based systems, I’d expect 25 to 35 GFlops on the HPL for the new Pi 5. Reply to Eric Olson Anders 28th September 2023, 8:23 am Great choices to make the full wish list available by options hats whilst improving the core features. Price maintained l, excellent work. Reply to Anders Roger Hardiman 28th September 2023, 8:25 am Any changes on Video Encoding, eg adding H265 (HEVC) or AV1 encoding? Reply to Roger Hardiman Raspberry Pi Staff Rob Zwetsloot 28th September 2023, 9:14 am It’s hardware H265 decoding and VC1 on the chip Reply to Rob Zwetsloot Jamie Whitehorn 28th September 2023, 9:17 am 🎉 Reply to Jamie Whitehorn Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:05 am Actually only 4kp60 H265 (HEVC) decode is available But it only uses 50% of the processors to do 1080p60 on YouTube Reply to Gordon Hollingworth drich 28th September 2023, 10:23 am No realtime video encoding so ? Reply to drich Jamie 28th September 2023, 10:48 am H264 hardware decoding has been removed? Reply to Jamie Raspberry Pi Staff Liz Upton 28th September 2023, 11:01 am Gordon’s been talking about this elsewhere in the comments – scroll through for more! Reply to Liz Upton Jamie 28th September 2023, 11:07 am I only see discussions on encoding Yannick 28th September 2023, 3:51 pm VC1 is different than AV1 though right? what about AV1 decoding? Reply to Yannick Raspberry Pi Staff Liz Upton 28th September 2023, 3:53 pm We can decode AV1. It won’t do 4k, but it should do 1080p. Reply to Liz Upton Sanjin Ganić 28th September 2023, 8:25 am Why again using non-standard video outputs? I’d rather have one standard HDMI output than those 2, requiring you to have adapter with me wherever I move Pi … Reply to Sanjin Ganić aBUGSworstnightmare 28th September 2023, 8:49 am https://www.raspberrypi.com/products/micro-hdmi-to-standard-hdmi-a-cable/ microHDMI ‘IS’ standard btw … Reply to aBUGSworstnightmare Sanjin Ganić 28th September 2023, 9:28 am Yes, it is, we find it on all TV’s, monitors, cameras, displays … If something is industry standard, it doesn’t mean it is a consumer standard ;) Reply to Sanjin Ganić Raspberry Pi Staff PhilE 28th September 2023, 8:55 am If you look at the board you’ll see that it fits two micro-HDMIs, the HDMI logo and the new UART socket (my favourite feature) into the space occupied by one full-size HDMI socket. The Pi 5 is even more of a real computer than Pi 4 was, and running the desktop across two monitors is something worth trying. Reply to PhilE Sanjin Ganić 28th September 2023, 9:39 am Sorry, but it seems like you didn’t get the point. Let me rephrase – Why would I need to always carry mHDMI adapter with my Pi? One full HDMI + mHDMI would be a perfect solution. I am aware of space constraints, but I expected RPI team will find a way and make Pi5 more “consumer friendly”. On Pi4, I mitigated that “mistake” by buying Argon One case, which allows me to use it as a small portable computer compatible with all displays without without worry about any adapter cables. Reply to Sanjin Ganić Raspberry Pi Staff PhilE 28th September 2023, 11:12 am What you call an adaptor cable I call a cable. The only disadvantage of having full-sized HDMI on end and micro-HDMI on the other is that you have to get it the right way round, but most people seem to manage. And it’s smaller, which may be a disadvantage if you have a thing for chunky connectors. Reply to PhilE Ben Pietras 28th September 2023, 12:22 pm So, the Pi4 already moved away from full hdmi ports… but you were expecting the Pi5 to move back? Micro hdmi is tiny and does a great job. Kind of the point of a Raspberry Pi.. Reply to Ben Pietras Sanjin Ganić 28th September 2023, 1:34 pm Sure! If product is intended for consumer market (and Pi4/Pi5 are targeting exactly that – small computers), why not make it then fully compatible with globally available consumer devices (TV’s, displays)? Craig Taylor 28th September 2023, 6:15 pm Micro HDMI connectors are not as robust. I lose connection and have to jiggle them sometimes. It gets annoying. Hanif 28th September 2023, 12:48 pm I’m sure there will be a new case at some point to give you the full size HDMI that you crave. Reply to Hanif Sanjin Ganić 28th September 2023, 1:28 pm Of course it will be, there are always people who know to listen voice of customers and earn on that :) I don’t know what is situation in Western Europe and USA, but in this part of world, if you forget mHDMI->HDMI adapter cable (I am travelling a lot because I am expat), you’re screwed. Because it’s that not easy to find it in stores here – nobody is using that. Mike Morrow 28th September 2023, 11:29 pm There are cables with mini and micro HDMI on them so no adapter needed. Easy l, yes. Slight expense? Yes. I don’t find it a bother. W. H. Heydt 29th September 2023, 1:05 am When I travel, I carry a 15.6″ portable monitor. Looks kind of like a giant tablet. It uses USB-C for power and *mini*-HDMI for video input. So with it, I carry a zip lock bag that contains: monitor PSU, USB-A to USB-C (power) cable, HDMI to mini-HDMI cable, and micro-HDMI to mini-HDMI cable. That way, it’s all contained and I’m ready for anything. Reply to W. H. Heydt David 29th September 2023, 12:34 am UART socket? Eee bah gum! I’ve not seen one o’ those since me old times wi ‘t Z80. Proper tricky it were ‘n all, what with stop bits an’ parity and getting ‘t cable to work wi’ RTS ‘n that. But you try telling ‘t youth of today… Reply to David D Smith 29th September 2023, 9:51 am Now yor gettin technical Lad with yore bits and stuff – in my day it was two tin cans and a length of wet bailer twine – you younguns dont know how easy youv got it… Reply to D Smith aBUGSworstnightmare 28th September 2023, 8:47 am Because of the new RP1 I/O chip will there be any impact on existing drivers (CSI/DSI/I2S/etc.)? Will Pi5 start with Bookworm or Bullseye? Reply to aBUGSworstnightmare Raspberry Pi Staff Liz Upton 28th September 2023, 8:50 am We’ll be launching with Bookworm – you’ll be able to download the OS very soon. Keep an eye out here: we’ve got lots of goodies coming! Reply to Liz Upton HPCguy 30th September 2023, 7:06 am WIll the 32bit armhf variant of Bookwork be supported in PI OS? Reply to HPCguy Michael Kelly 30th September 2023, 2:53 pm Is the I2S still limited to PCM up to 192Khz? Reply to Michael Kelly Raspberry Pi Staff PhilE 28th September 2023, 9:13 am There is no impact on existing drivers because each of those interfaces you mentioned gets a completely new driver which, thanks to Linux’s driver models, slot right in. Reply to PhilE aBUGSworstnightmare 28th September 2023, 10:27 am … but requires a change of existing overlays (i.e. as PWM/GPIOs are no longer part of the SoC because they’ve move to RP1), right? Reply to aBUGSworstnightmare 6by9 28th September 2023, 11:13 am As long as you’re using aliases rather than explicit paths to nodes, then almost all of those just transfer. There is a slight change around CSI and DSI as each connector now has a dedicated I2C bus, but GPIO, I2S and PWM, should all be the same. Reply to 6by9 Raspberry Pi Staff PhilE 28th September 2023, 11:14 am Backwards compatibility has been maintained as much as possible – many overlays will work unmodified. Reply to PhilE Tovli 10th October 2023, 7:31 pm My robot used wiringpi to bit-bang clock stretching I2C in bullseye, and not available in bookworm. Does RP1 implement true clock stretching I2C? Reply to Tovli Kainomad 28th September 2023, 8:48 am Great specs, great price, great conception, as always but i would rather see another usb-c with display-port alternate mode than 2 mini-hdmi (also would have been great for data) . Also are 2 cameras ports necessary ? Why not use a hat for this and embed a m.2 directly on board or direct PoE compatibility? Or even a SIM card reader ? Reply to Kainomad Raspberry Pi Staff PhilE 28th September 2023, 9:01 am For the small board area required, adding the option of 2 cameras, 2 DSI displays, or 1 camera and 1 display is going to be very popular. Adding an M.2 socket would increase the height of the board significantly – you’d have to fit it on the bottom to avoid blocking the fan/ambient air circulation. Reply to PhilE Kainomad 28th September 2023, 9:16 am I guess I’m not part of the popular kids’ team ;) Thank you for your answer. Great job and great ideas! I really like the PWM, UART/Arm debug and JST additions. Can’t wait to get this baby. Reply to Kainomad Gunnar Larsson 28th September 2023, 8:52 am Will the raspberry 400 come with a new version as well? Reply to Gunnar Larsson Raspberry Pi Staff Liz Upton 28th September 2023, 8:55 am Oo, that’s a good idea. Must mention it to Eben. Reply to Liz Upton Alastair Stevens 28th September 2023, 9:07 am I run a busy code club at my son’s school in Gloucester, using 15x RPi 400s, which everyone loves. We struggle with the school’s cranky old non-HDMI monitors, but that’s another story. I can envisage a future RPi 500 taking it to the next level! The club resumes today, so I look forward to telling them all about RPi5 first… Reply to Alastair Stevens Jamie Whitehorn 28th September 2023, 9:21 am +1 on an updated version of the 400, please 🙏🏻 The 400 is my favourite version probably because I cut my teeth on the BBC Micro Reply to Jamie Whitehorn Richard Molyneux 29th September 2023, 11:26 am +1 from me too, for a Pi 500, and please don’t forget to include media legends (play/pause, fast forward/rewind, etc.) printed on the keys this time; as found on the competition ;-) Reply to Richard Molyneux Andrew Kirby 29th September 2023, 4:43 pm +1 for an update to the PI 400 – but with the M.2 slot inside for storage Reply to Andrew Kirby Momo 1st October 2023, 7:34 am Please update P400, too. And add an updated soft shutdown / power off option better than FN + F10 for all children and headless clients, please… Reply to Momo Raspberry Pi Staff Liz Upton 1st October 2023, 4:42 pm I’ll line up a nice shiny pony for you too. ;) (Please, please do what my toddlers do not do, and be satisfied with the nice thing we’ve done rather than asking for a pony.) Reply to Liz Upton Matt Cruikshank 24th October 2023, 7:30 pm If you give me a way to Pre-Order, and actually pre-pay, I will instantly buy a “Raspberry Pi 500” kit. Jeff Geerling 28th September 2023, 8:55 am Thank you for this comprehensive peek behind the board’s features and development… so many little details about the RP1 and the new architecture—I only hope we can see even more bandwidth and more refinements to RP1 in it’s next iteration. Glad it’s finally seeing the light of day in a real product! Reply to Jeff Geerling Alex Ivanovs 28th September 2023, 8:55 am Great work, team! Reply to Alex Ivanovs Richard Eric 28th September 2023, 8:57 am Nice upgrade. Good to see the same footprint. The form factor of the RPi is just about perfect. I had hoped that the RP2040 was going to be added like how the iMX7 has an M4 co-processor. For embedded stuff it’s a big win. But I guess would make the silicon too big or pricy. Maybe next time. ;) Reply to Richard Eric Raspberry Pi Staff PhilE 28th September 2023, 9:06 am RP1 and RP2040 are not quite sister chips, but definitely cousins, and RP1 does have some PIO capabilities – something we are hoping to expose to Linux and application code over the coming months. Reply to PhilE BrianW 28th September 2023, 9:44 am Could you expand on what the PIO capabilities are please? For me, PIO has been the defining feature of the RP2040, and I was coming to the comments to say I was disappointed see no mention of it in the RP1. I had been hoping that PIO could be integrated into the RPi GPIO, and the RP1, designed by the same team as the RP2040, seemed like a missed opportunity to include this excellent feature, until I saw your comment. Reply to BrianW James Adams 28th September 2023, 10:51 am RP1 has an internal subsystem that predates RP2040 and is primarily designed for system management purposes. It does have PIO but is not quite the same as RP2040 PIO, we are looking at whether we can put togheter a nice way to expose it without falling over ‘my RP2040 PIO stuff doesn’t “just work” on RP1’ type issues. Reply to James Adams Luke Wren 28th September 2023, 11:42 am There is one PIO instance (4 state machines). It’s identical to the PIO blocks on RP2040, except the FIFO depth is doubled. It has single-cycle bus access from the dual Cortex-M3 management processors on RP1, and the PIO FIFOs can also be accessed from the host processor (2712) over PCIe, but the PIO configuration registers are only accessible to the RP1 processors. One of RP1’s Cortex-M3s is currently going spare, so it should be possible to write your own Cortex-M firmware and load it into the 16 kB per-Cortex-M3 private SRAM. There won’t be any software support for this at launch though. Reply to Luke Wren BrianW 28th September 2023, 12:36 pm Thank you, and James too triss64738 on the forums 28th September 2023, 6:14 pm That sounds rather nice. Is there any chance the RP1 (or a similar chip) will be released as a standalone? It could be useful for high-bandwidth applications (I myself had almost used the RP2040 for interfacing with a >100Msps ADC, or emulating an LCD screen), but the USB1.1 bandwidth limitations of the RP2040 meant I had to resort to chips >10x as expensive. DrDnar 28th September 2023, 10:41 pm That’s great and very exciting information! My first thought when I saw the Pi5 news was, “That thing had better have a PIO block!” I’m glad to see it’s there even if the software support isn’t quite ready yet. As an embedded software person myself, I don’t think it’s reasonable to expect that RP2040 stuff could “just work” on the RP1. The fact that the RP1 is a chip with very a different purpose not directly connected to the host CPUs makes writing drivers for it a lot different. For example, on the RP2040 you can have very tightly bounded latency between the CPUs and a PIO block, which is impossible to get with the main A76 cores, never mind over a chip-to-chip bus. I think it’s reasonable (perhaps necessary) to tell people that PIO programs for the RP1 will need to be adapted to work with the Linux kernel. I’m also curious to see accessible main system RAM is from the RP1 and how DMAs between the chips work, as I suspect that’s really going to be what makes or breaks custom high-bandwidth interfaces. I’m guessing you might end up coordinating two levels of DMA: one from the SoC/DDR4 to RP1, and one from the internal RP1 RAM to the PIO block. I really look forward to reading the documentation on the RP1 when it becomes available! Chad Page 30th September 2023, 10:09 pm Does the RP1 support ‘raw’ output to the composite ADC? I’ve been looking for a good raw composite output for my low-level laserdisc decoder for quite a while now… Raspberry Pi Staff Liz Upton 1st October 2023, 5:01 pm We’re going to be doing an in-depth video about RP1 here some time over the next few weeks: watch this space. Leah 29th September 2023, 12:50 am Oooh, I can’t wait to play with it! The whole PIO concept is a massive gamechanger. It completely changed how I think about peripherals, and I really dread having to work with MCUs without a PIO in the future. I wouldn’t be too surprised if someone came up with a chip which had a dozen PIO cores and just dropped all the legacy IP. When you can get the same result by loading a bitstream into a PIO, why bother hardwiring any protocol? Reply to Leah Cbj 28th September 2023, 9:55 am The write up.mentions the RP1 is designed using principles from the RP2040 so you never know there may be an Easter Egg there… But yes being able to have some basic microcontroller style watchdog processes running that can kick in the main board when needed, that could be very useful Reply to Cbj zal 28th September 2023, 9:02 am Very disappointed in 1x PCI Express and an m2 HAT that makes it impossible to fit a proper heatsink and fan. That severely handicaps it in comparison to RK3588 based options such as the Orange Pi 5 Plus. Too bad, I was looking forward to Raspberry Pi matching the competition. Reply to zal Raspberry Pi Staff PhilE 28th September 2023, 9:09 am I have a Pi 5 with a prototype M.2 HAT and cooling fan running happily on my desk. I looked up the price of the “competition” and nearly choked on my coffee. Reply to PhilE zal 28th September 2023, 1:05 pm How much did you pay for your Pi 5 and m2 HAT, Phil? Choke all you want. Not all Pi customers are in the UK – for customers outside your borders the price difference might not be that big, especially not if you factor in the additional cost of an m2 hat. Reply to zal David 29th September 2023, 12:48 am I just checked the price of the Orange 8GB on Amazon.com. $128 excluding shipping and taxes. Unless you like binary numbers, Raspberry Pi 5 is cheaper by a wide margin, even with $5 for active cooling. And I’m sure we’ll see a $64 bundle for the binarists soon… Reply to David Raspberry Pi Staff Liz Upton 28th September 2023, 9:13 am The active cooler is $5, as you’ll see from the post you’re replying to. I’ve just eaten a breakfast croissant that cost more than that; and I can confirm that the cooler is very proper indeed. Reply to Liz Upton James Adams 28th September 2023, 9:42 am The croissants were very proper too…! Reply to James Adams Ben 28th September 2023, 9:45 am Don’t ever change, Liz :-) Reply to Ben Raspberry Pi Staff Alasdair Allan 28th September 2023, 10:24 am Can confirm that ham and cheese breakfast croissants were excellent value for money! Reply to Alasdair Allan Alastair Stevens 28th September 2023, 9:03 am Very exciting – thanks for the fascinating article with lots of interesting design details. This really will be another new era for Raspberry Pi, with a machine seemingly powerful enough to serve as an everyday computer (the RPi4 was almost, but not quite, there). I’m already brimming with ideas for RPi5 projects, although sadly the one thing that remains truly out of stock is spare time! Reply to Alastair Stevens Dreamcat4 28th September 2023, 9:09 am geez i really hope you guys will be taking it upon yourselved to ensure a spart parts supply replacement of these custom Renesas DA9091 ics. with the 8x smps and 20 amps. otherwise it’s going to be like the rpi4 / cm4 all over again. which was an r2r nightmare. btw speaking of cm4 will there be an equivalient cm5 planned / coming? because that would also be pretty desirable actually. Reply to Dreamcat4 acquer 28th September 2023, 9:15 am If it is always sold out or with extra premiums elsewhere it has no sense to plain users. RPi was a thing. Reply to acquer Raspberry Pi Staff Liz Upton 28th September 2023, 9:18 am I’m sorry, what? Reply to Liz Upton Camefrom Sirius 28th September 2023, 10:01 am Hi Liz, I’ve used AI to help us decode his message. This is the translation: “If a product is always sold out or only available at a higher price than usual, it does not make sense for regular customers to purchase it. The Raspberry Pi was an example of this.” Reply to Camefrom Sirius Raspberry Pi Staff Liz Upton 28th September 2023, 10:06 am Jolly good that he’ll be able to buy one, then. (Seriously: go and pre-order.) Reply to Liz Upton maussirk 7th October 2023, 5:42 pm Will there be also Raspberry Pi Compute Module 5 versions available? – not for industry reason but for my Home Assistant Yellow and there are also other board which use Compute Modules. I really would like to pre-order … where is the link? Dirk 28th September 2023, 9:15 am Are there plans to release it also as Compute Module 5? Reply to Dirk MW 28th September 2023, 9:15 am WoW despite all the crap in the world, RPL have managed to release a massively updated RPi at a great price, be interesting to see how well RPi OS Bookworm performs. Also finally we have a PD Power, and as usual the price is extremely competitive for a Power Supply. Reply to MW Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:13 am Bookworm is something we’ve been working on for a while (and I’d like to thank the beta testers who have been feeding back to us, I might have a present for some of you!!!) Reply to Gordon Hollingworth James Adams 28th September 2023, 10:56 am Worth mentioning the PD supply doesn’t just support the 5V/5A mode but also does standard 27W PD modes 9V/12V/15V so can be used as a high quality, low cost ‘generic’ USB-PD supply. Internally has Rubycon and Panasonic caps and uses latest-generation GaN switching tech. Reply to James Adams Raspberry Pi Staff Liz Upton 28th September 2023, 11:00 am I’ve been using mine to power my MacBook Pro, which is very pleasing (it’s charging as I type this): it’s nice to be able to eat my own dogfood, and a MacBook Pro power supply costs £79 in the UK, which is a lot more than the $12 we’re charging for ours. Reply to Liz Upton James Adams 28th September 2023, 12:51 pm I probably should have put more emphasis on the fact you are getting a *REALLY AWESOME* power supply for $12! Reply to James Adams David 29th September 2023, 1:01 am I don’t know exactly which Apple power supply you’re referring to, but mine is 140W and costs about $85 (excl.). That’s nearly six times the power at a bit more than six times the price (as you’d expect from Apple). Reply to David David 29th September 2023, 1:18 am I don’t know exactly which power supply you mean, but my 140W MacBook power supply costs 7 times more than the Pi for a bit less than six times the power. Still a very impressive achievement for a $12 power supply. Can you say how efficient it is? Reply to David Taylor 28th September 2023, 6:45 pm I wish the Pi itsself had those PD capabilities. I don’t think I’ve seen a power supply that can do over 3A on any voltage under 20V, so having 9V input to the Pi would open the amount of power supplies from 1 to ∞ (ok, not quite) Reply to Taylor Andrew Waite 28th September 2023, 9:16 am Looks awesome. The micro rather than full size HDMI connectors is disappointing though. Reply to Andrew Waite Chris 28th September 2023, 11:02 pm I will buy the Argon One case that is a brilliant heat sink and puts all ports at the back whilst conveying the HDMI ports to full size ones. Issue solved. Reply to Chris Alex Ellis 28th September 2023, 9:17 am Congrats to the team, this is a wonderful upgrade for I/O and overall performance. I shared my testing via Twitter, feel free to check out the benchmarks and pictures. https://x.com/alexellisuk/status/1707296079849365650?s=20 Reply to Alex Ellis Ian Hollis 28th September 2023, 9:17 am Congratulations on hitting a SIX once again. You folks are feeding my SBC (RPi specifically) obsession. Keep it up. I hope there’ll be sufficient produced to feed the obvious demand which you’ll generate. Perhaps RPi 4s will reduce in price to reasonable. :-) Reply to Ian Hollis Sergio Costas 28th September 2023, 9:25 am Looks awesome! But about the MIPI connectors… will they be limited to the current screens, or we would be able to connect others? I ask because I have a 1920×480 screen with a dual-MIPI interface (the cable has, literally, two independent MIPI signals), and I was wondering if I would be able to power it directly from the MIPI connectors instead of having to use the current HDMI adapter, which is a nuisance. Reply to Sergio Costas James Hughes 28th September 2023, 9:54 am The latest graphics stack (KMS) has allowed the use of third-party DSI displays for a while, as long as you have the right driver. Reply to James Hughes Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:16 am Annoyingly, MIPI is a lot more complex than nice things like HDMI. Even people with experience making displays have trouble getting all the commands and signals exactly correct. Plus in general, you need a £17k scope to debug it!!! Reply to Gordon Hollingworth aBUGsworstnightmare 28th September 2023, 10:49 am Sure it is dual channel MIPI and not dual-lane (as what would be sufficient for 1920x480pixels)? Also asked the question if RPI offers possibility for Dual-Channel MIPI-DSI; thinking of high-res DSI displays and FPD-Link III Bridge Serializer with Video Splitting (3k/2k) here Reply to aBUGsworstnightmare 6by9 28th September 2023, 11:20 am No, there is no support for dual interface displays. They are two discrete DSI interfaces, and show up under Linux as two distinct DRM devices. This is why I commented on the forums about Wayfire handling multiple DRM cards nicely – we’re relying on it here as DSI1/DSI2/DPI/VEC are 4 DRM devices, plus a 5th for vc4. Yes, I have had 5 displays running simultaneously (I didn’t hook up composite). Substituting DPI for an SPI display also works incredibly well. Reply to 6by9 aBUGSworstnightmare 28th September 2023, 1:19 pm Thanks for letting us know! I’m sure prepared to test Pi5 with 5 screens once I can buy one/get it at hands. Sorry, but I don’t understand the meaning of ‘Substituting DPI for an SPI display also works incredibly well’! Reply to aBUGSworstnightmare 6by9 28th September 2023, 2:12 pm Both 2 x HDMI, 2 x DSI, and 1 x DPI, and 2 x HDMI, 2 x DSI, and 1 x SPI have been tested and work. Seeing as you can use multiple chip selects and SPI buses, you could create a tiled desktop with multiple SPI displays. Don’t expect a fantastic refresh rate though (I wouldn’t try watching video on it). manuti 28th September 2023, 9:26 am Congratulations to the whole team!!! Reply to manuti Simon Monk 28th September 2023, 9:26 am A fantastic and well thought out update to the Pi. This is now an extremely good desktop replacement machine. Reply to Simon Monk Geoff 28th September 2023, 9:28 am What I would like is active cooling + PoE + M.2 support. Reply to Geoff Raspberry Pi Staff Liz Upton 28th September 2023, 9:42 am You can do that. As you can see if you read the post you’re replying to, you can stack the active cooler with hats – which will include PoE and M.2. Reply to Liz Upton supdude 28th September 2023, 10:06 am All the post says is that you can mount HATs on top of the case fan He is talking about the active cooler, which is not specified in the post if a HAT can be mounted on top or not without the use os gpio spacers Reply to supdude James Adams 28th September 2023, 11:00 am With an appropriate GPIO spacer and 15mm standoffs you can stack HATs above the Active Cooler – works very nicely. Reply to James Adams Raspberry Pi Staff Ashley Whittaker 28th September 2023, 9:43 am You mean like the Active Cooler mentioned in the post? Reply to Ashley Whittaker Mehmet Aksoy 28th September 2023, 9:35 am Congratulations to all! Reply to Mehmet Aksoy Jamie Whitehorn 28th September 2023, 9:37 am Congratulations on the new version 🎉 Really pleased to see the inclusion of the new PCI Express connector. Can’t wait to see what the partner community does with this. Reply to Jamie Whitehorn Jarom Hatch 28th September 2023, 9:37 am Does the USB-C port have USB3 host support now rather than USB2? Reply to Jarom Hatch Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:28 am No, the USB-C is the same dwc-otg peripheral as before, it’s the most reliable one we have (we’ve now been using it for 12 years)… Reply to Gordon Hollingworth Michal Tarovsky 28th September 2023, 9:38 am Is it a Secure Platform? Will I be able to run Android TV with HW keys for Widevine L1? Reply to Michal Tarovsky Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:29 am No, it does not have a full TrustZone security implementation. As such it’s not really possible to gain a full Widevine certification. Reply to Gordon Hollingworth Sean Gilligan 11th October 2023, 5:49 pm When you say “full TrustZone support” is not present, what is missing? (I’m hoping you just mean the locked bootloader is missing.) Is there (or will there be) documentation about what TrustZone (hardware) support is provided? Is it the same as on the 3/4 or has memory protection been added? Reply to Sean Gilligan drich 28th September 2023, 9:39 am Did just read somewhere that there is no hardware video encoding, is it true ? That sounds strange as it would means poor performances for real-time applications Reply to drich Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 10:36 am Ok, this is a big one… The problem is that video encoding is not a standard. You can put as much or as little effort into encoding as you like, on Pi 1, 2, 3, & 4 the encoding quality (for the bitrate) was relatively poor. The nice thing about using the processors to do this is you get to choose exactly what balance between quality and bitrate you want. Obviously, the bad thing is the power consumption, but actually it only takes around 1 processor to encode 1080p60 with our default settings (which is still better quality than the PI 4 hardware encoder). We think it might be possible with the right settings to be able to hit 4K encode at around 24fps, but we’ve not been optimising in that direction yet. In future we’ll have to do something, but for Pi 5 we feel the hardware encode is a mm^2 too far. Reply to Gordon Hollingworth drich 28th September 2023, 11:02 am Thank you for the detailed reply. Surprised that it can be done with onlyallowing for high resolution DSI displays? Reply to aBUGsworstnightmare 6by9 28th September 2023, 11:28 am Answered above, but no they are two discrete DSI interfaces. With each running at up to 1.5Gbit/s/lane it can go somewhat beyond the 1080p60 limit of the older SoCs though. Reply to 6by9 Brian Beuken 28th September 2023, 10:14 am Wow this is exciting, my order is in, can’t wait. Though I am a bit worried about the loss of X11 to Wayland, Ive never quite got my head around that, but I guess this will force some new learning. Reply to Brian Beuken Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 11:05 am In the long run, this is going to make everything better across all Pi devices. I am hoping to one day be able to send video images through the operating system directly to the hardware to put onto the screen, no longer converting them From YUV wallpaper mode to RGB tiled to be composed with the 3D into a buffer which might even then need to be converted back to a linear (untiled) mode and then pushed out the display… My target is 1080p30 in a window on Pi 1 :) Reply to Gordon Hollingworth Ben Pietras 28th September 2023, 12:33 pm Wayland has been working great for a while now. I use sway for my daily driver and (aside from using x2go) it works well with everything. Reply to Ben Pietras Shivam 28th September 2023, 10:20 am This is great news. Can’t wait to get my hands dirty. Reply to Shivam Dale 28th September 2023, 10:24 am Having followed these things from the beginning and probably owning 1 if not 2 of most models, I think its amazing how far these little devices have come! I think there are 2 questions here though: 1) Will there be a RPi500 to replace the 400? 2) from a point of pricing, these are amazing little devices, but they do seem to be stepping away from the affordable devices of a few years ago, even the Zero2 is now 3 times more expensive than the original Zero, will this created accessibility problems or are there plans to fit in an ‘inbetween’ model? Something which gives you most of the ports so all USB/ethernet, maybe only 1 hdmi, less base ram and a few other things less like no pci connector or RTC stuff, to essentially strip out component cost, which still make it a better fully fledged version than a Zero, but more affordable than a flagship? Reply to Dale Raspberry Pi Staff Liz Upton 28th September 2023, 10:42 am This is a $5 increase over the equivalent Pi 4 models – we think that’s actually pretty good for a >2x increase in performance and a number of new features, and if you’re particularly price-sensitive, all the predecessor models are still available. Reply to Liz Upton Dale 28th September 2023, 12:36 pm I probably have enough already :) I guess I was thinking of the fact that in the earlier days when the Zero came out, there was essentially a £5, £20 and £30 model, where the range topper was £30 and that stuff generally held its price well until Raspberry Pi 4, where the ram just seemed to inflate the cost a fair bit. I loved how fully fledged yet cheaply disposable the Rpi Zero was when it was £5. I have seen you can still get some models some times, do you actually still produce all the earlier models as components become available? I guess everyone always wants more for less dosh these days. I’ve just been quite happy with the Zero, but having lots of extra power gives possibility for so many things! Reply to Dale Raspberry Pi Staff Liz Upton 28th September 2023, 12:41 pm We do, yes. rpilocator.com is your friend! Reply to Liz Upton Sumanta Das 28th September 2023, 10:26 am Will there be 16GB model coming? Reply to Sumanta Das nafanz 28th September 2023, 10:34 am Wow! This is the best news today. Reply to nafanz Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 11:27 am And hopefully tomorrow? Reply to Gordon Hollingworth nafanz 29th September 2023, 6:39 am Yes. I also want to believe that in the near future you will announce a version with 16 GB of RAM and an updated RPi 500. Then it will be a bomb. Reply to nafanz Bouarfa MAHI 28th September 2023, 10:39 am Hello, is there a datasheet available for the Raspberry Pi 5? I need information on the exact positions of the Ethernet port and power button for customizing a 3D-printed case Thanks Reply to Bouarfa MAHI Raspberry Pi Staff Liz Upton 28th September 2023, 10:43 am Not yet, but it’ll be available when the hardware itself is available. Reply to Liz Upton Raspberry Pi Staff PhilE 28th September 2023, 11:27 am But the mechanical drawings are available now: https://datasheets.raspberrypi.com/rpi5/raspberry-pi-5-mechanical-drawing.pdf Reply to PhilE Stewart Watkiss 28th September 2023, 10:43 am Congratulations. Sounds great! I’ve placed a pre-order already and I’m looking forward to having a go once it arrives through the door. Reply to Stewart Watkiss Tally 28th September 2023, 10:52 am A great update, looking forward to getting it but one question. Is the Pi 5 a “proper” Arm PC ? By that I mean does it have UEFI support out of the box that adheres to the Arm system ready standard so we can use any general ARM64 compatible operating system [similar to x86 UEFI] or is it still limited to uboot and its tailored OS images. Thank you. Reply to Tally Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 11:29 am The bootloader doesn’t support UEFI, it’s a bit too much to fit into the EEPROM along with everything else. I don’t know if there’s a minimal UEFI implementation, but it does seem like UEFI is quite large. Reply to Gordon Hollingworth M. Mediouni 28th September 2023, 12:14 pm U-Boot nowadays has a UEFI implementation available. Can you tell the size of the EEPROM? Is it 128KB like previous RPi generations? Reply to M. Mediouni James Adams 28th September 2023, 12:40 pm 16GBit (2MByte) Reply to James Adams M. Mediouni 28th September 2023, 12:51 pm I understand that to be 16Mbit instead of Gbit :) Depending on how much is taken by the firmware, that’s way more than enough space to fit in a U-Boot UEFI-compatible implementation with some ACPI tables (preferably if that PCIe controller is ECAM compliant). I wonder if Raspberry Pi would be interested by such a project. Tally 28th September 2023, 4:10 pm Thank you for the reply. I understand the limits and price points to get it to ship. Maybe one day we could see a deluxe Pi 5, with the hardware mounted on a mini-ITX motherboard with all the I/O PCI-e etc and a UEFI bootloader. Reply to Tally Lukáš Říha 29th September 2023, 7:51 pm There actually is a project trying to provide UEFI for Rpi4, https://github.com/pftf/RPi4 . Is larger than current EEPROM size as stated below, but I imagine it could be optimized for size. Reply to Lukáš Říha Vojtěch Hron 28th September 2023, 10:53 am this is very good i will buy Reply to Vojtěch Hron Raspberry Pi Staff PhilE 29th September 2023, 8:56 am Thanks, Vojtěch, this was my favourite comment of the day! Reply to PhilE Ignas Kiela 28th September 2023, 10:57 am Does RP1 emulate SMI(Secondary Memory Interface) that HATs like CaribouLite use for high-speed data transfer? Reply to Ignas Kiela Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 11:31 am That should be possible in the future with a suitable PIO driver. There is a PIO implementation and we’re hoping to develop a nice Linux driver and some userland tools for it. But we’re not there yet! Reply to Gordon Hollingworth Ignas Kiela 28th September 2023, 1:43 pm PIO!? You got me very interested :) Reply to Ignas Kiela Joe Fongo 28th September 2023, 11:09 am Does the power button support instant on/off like a cell phone? Or will the pi still need 30s to boot each time? Reply to Joe Fongo Raspberry Pi Staff PhilE 28th September 2023, 11:35 am The power button currently triggers a full boot or shutdown – booting to the desktop is under 30 seconds. In future it may support a low power suspend mode which will boot much more rapidly, but until it actually works I can’t promise it. Reply to PhilE thagrol 28th September 2023, 12:42 pm The only thing instantly powered on/off by your phone’s power button is the screen. Everything else is still running otherwise you’d not be abel to recieve calls. Reply to thagrol Giovanni Rito Russo 28th September 2023, 11:09 am I know realvnc doesn’t support “Wayland” as I read that debian Bookworm will be released with Wayfire Wayland composer, what system will Pios use? always realvnc with wayland support or other software? Reply to Giovanni Rito Russo Raspberry Pi Staff Liz Upton 28th September 2023, 11:11 am Right now we’re recommending WayVNC on the server end, and TigerVNC on the client end. There will be plenty of documentation available around VNC – watch this space! Reply to Liz Upton Giovanni Rito Russo 28th September 2023, 11:14 am So in raspi-config we will no longer find the active realvnc entry? Do we have to manually install compatible software? in debian 12? Reply to Giovanni Rito Russo Raspberry Pi Staff Gordon Hollingworth 28th September 2023, 11:39 am We do have contact with the WayVNC developer but this won’t give the ability to remotely access your Pi as RealVNC does. We’re hoping it will start working, now they have a full example of how to port to Wayland, but it will take time. Reply to Gordon Hollingworth meltwater 28th September 2023, 11:16 am Wow the little RPi has grown. Some awesome features and huge potential for learning, really can’t wait to see what crazy uses we can make of this one. Might have to get back to writing again! Reply to meltwater Kumar Abhishek 28th September 2023, 11:24 am Awesome, congratulations! This is great and I am looking forward to buy one when it’s available. I am curious if BCM2712 retains the SMI (secondary memory interface) that was present on the earlier silicon. Reply to Kumar Abhishek Raspberry Pi Staff PhilE 28th September 2023, 11:37 am Not directly, but see Gordon’s answer above: https://www.raspberrypi.com/news/introducing-raspberry-pi-5/?trashed=1&ids=1594104#comment-1594103 Reply to PhilE Kumar Abhishek 28th September 2023, 1:38 pm I read Luke’s comment about the PIO architecture on the RP1 and it seems really interesting! On the Pico, only 30 pins are connected externally to the PIO even though it seems to have 32 pins for itself as per the block documentation in the Pico datasheet. So are all 32 pins contiguously available on a PIO block brought out on the 40-pin header? Just curious – because by default only 28 GPIOs are available on the 40-pin header and I assume you will maintain backward compatibility on the header. Reply to Kumar Abhishek Raspberry Pi Staff PhilE 28th September 2023, 4:57 pm by default only 28 GPIOs are available on the 40-pin header and I assume you will maintain backward compatibility on the header. This. Reply to PhilE Radek Suski 28th September 2023, 11:25 am Cool. Exactly on my birthday Reply to Radek Suski Raspberry Pi Staff Liz Upton 28th September 2023, 11:31 am Happy birthday! Reply to Liz Upton David Mohring 28th September 2023, 11:27 am Will SKUs of the Raspberry Pi 5 with more memory than 4GB & 8GB be available in the future? If so what ETA? Reply to David Mohring Raspberry Pi Staff PhilE 28th September 2023, 11:38 am But that would be an announcement of something we haven’t announced, which sounds like some kind of paradox. Reply to PhilE David Mohring 28th September 2023, 12:05 pm So it is not a no then. Your being so enigmatic that it seems to hint it even be an option for the Pi 5 version of the Raspberry Pi 400. Reply to David Mohring Raspberry Pi Staff PhilE 28th September 2023, 12:14 pm No, I just find it strange that people don’t seem to understand how announcements work. Reply to PhilE Ashish 28th September 2023, 11:29 am This looks awesome! Congratulations to Raspberry Pi team. Reply to Ashish Chris Stagg 28th September 2023, 11:46 am Congrats on the new flagship! And kudos on not having the mad dash release. One question, if the RP1 chip is not available for general release, would there be a pico-esk board with it that uses USB-C/thunderbolt/pcie for connecting to it? Reply to Chris Stagg Raspberry Pi Staff Liz Upton 28th September 2023, 11:54 am Hi Chris! It did feel like pre-announcing would give the most people the most opportunity to get their hands on one on day one! As usual, I’m afraid we can’t comment on future releases (apart from the one in the headline), so I’m going to gliiiiide past your question. :) Reply to Liz Upton Chris Stagg 30th September 2023, 10:02 am After a couple of days, and a bit more comment reading (in multiple forums), I sense hope for RP1’s solo act. Reply to Chris Stagg Lee Gibson 28th September 2023, 11:51 am Fantastic job guys, great news on the RTC, this was a real bug bear for remotely deployed system that was required to to rebooted every xx days or hours in know down time periods. So many other improvements too! I use the Pi4 for industrial product development (poettnially at large volumes) and a solution which is incredibly cost sensitive. I use HD video as a key function and my solution does not require much RAM (runs okay on 512MB), but it does need network and masses of connectivity via USB. I could use the Zero 2 from a cost perspective (it will work on that), but lack of network and USB ports makes it non viable. Pi 5 at 4Gb and 8gb prices are great but are too expensive. So bottom line, will we see 1GB and 2GB versions around the Pi 4 equivalent price? And yes I could use the Pi4 for now but eventually Pi will replace and we will be ascending the cost curve by default without Pi5 1GB and 2GB. I appreciate you are stuck between a rock and a hard place trying to be all things to all people, I just hope the hunt for ‘PC use’ status does not overshadow the well connected, low cost credentials that only a Pi with smaller memory offers and always has, in fact it is what it was born for! Reply to Lee Gibson Maik 28th September 2023, 11:56 am Nobody seems to want to answer the question if there will be a CM5 and when :) Is it not allowed to give any information about this yet? Reply to Maik Raspberry Pi Staff Liz Upton 28th September 2023, 11:57 am We do not comment on future product releases. Apart from the one we’re talking about today. :) Reply to Liz Upton Lee Gibson 28th September 2023, 12:41 pm Hi Liz, does this ‘no comment’ response also apply to my question (the one above this) relating to 1GB and 2GB Pi5’s above as I have not seen any feedback on that? Reply to Lee Gibson Gray 28th September 2023, 11:58 am This is a really amazing upgrade and I’m really looking forward to trying it out. Side note, when the inevitable CM5 drops a year or so from now, please, please make the new carrier board mount directly to ATX chassis like a VIA APC or similar. The only ATX carriers that came out for the CM4 were £200 cluster boards. I just need the standard one but slightly wider with different hole placement. Literally 5 servers and a desktop in this house running 12 year old CPU’s, waiting for a compelling ARM8 ATX board to replace them with! Reply to Gray Doğukan Sahil 28th September 2023, 12:22 pm I want to buy a product, but I hope you are aware that the stocks you sell to Turkey are generally problematic.. Reply to Doğukan Sahil Raspberry Pi Staff Liz Upton 28th September 2023, 12:27 pm The stock our Turkish Authorised Resellers sell is exactly the same as the stock that we sell in every other country in the world. Who are you buying from? Reply to Liz Upton James 28th September 2023, 12:24 pm Congrats and thanks for the detailed post. With the pleasantries out of the way, as a Model A enjoyer, I am compelled to ask: Can we get a Model A this time, pretty please? It’s such a neat form factor. Reply to James Javier Goldman 28th September 2023, 12:34 pm First of all, congrats! The pi 5 looks awsome. Wouldve loved it announced a little later(or earlier), i just got my first pi (4b) and wouldve waited if i had known D= Still, i find it kinda sad there’s no AV1 decode/encode support Reply to Javier Goldman Erwin 28th September 2023, 12:36 pm Is Raspberry Pi 5 compatible with the current Raspberry Pi Operating System for Raspberry Pi 4? Reply to Erwin Raspberry Pi Staff Alasdair Allan 28th September 2023, 12:42 pm As mentioned in the post we’re currently working on a new release of Raspberry Pi OS based on the most recent release of Debian, codenamed “Bookworm.” This new version of Raspberry Pi OS will launch in mid-October, and you’ll be able to download it shortly before Raspberry Pi 5 arrives on the shelves in late-October. Reply to Alasdair Allan Lee Gibson 28th September 2023, 1:11 pm Hi Alastair, I think the question was, will Pi 5 still run Bullseye? And further to that, for my purposes will Pi 5 it still run Buster? Reply to Lee Gibson Raspberry Pi Staff Liz Upton 28th September 2023, 1:15 pm No, you’ll need to be running Bookworm. Promise you’ll like it though. Reply to Liz Upton Lee Gibson 28th September 2023, 1:27 pm Ouch, that’s a killer for long term killer commercial/industrial applications like mine that rely Buster and cannot run on Bullseye or Bookworm (reliant on OMX Player as VLC does do what is needed and probably never will) once the Pi4 and Pi3 are no longer available :( Raspberry Pi Staff Liz Upton 28th September 2023, 1:27 pm You’ve got plenty of time; we’re not going to be discontinuing Pi 4 until at least the 2030s. James Hughes 28th September 2023, 1:30 pm Lee, can you clarify why VLC or some combination of FFMPEG et al doesn’t do what you need? OMXplayer can never run on Pi5, so getting alternatives up and running is important to us. You can email applications@raspberrypi.com Javier Goldman 28th September 2023, 1:37 pm will current installations be updated? or do we need to do a clean install? Reply to Javier Goldman Raspberry Pi Staff PhilE 28th September 2023, 1:44 pm Moving from Bullseye to Bookworm will require a clean install even more than the Buster to Bullseye transition. I think it will be less effort to move your customisations across than to upgrade an image in-place, and much less error-prone. Reply to PhilE Javier Goldman 28th September 2023, 3:10 pm is there any recommended way to backup my customizations? kinda still new to this Mark 28th September 2023, 12:47 pm Great to see the new raspberry pi 5. PCI express is also very good. I will add an external SSD. I will be using this device for home assistant. Will there also be a compute module 5? Or is that difficult due to a higher power consumption? Please do something about the distribution, so we don’t have to pay extra because the RPI 5 won’t be freely available in the market. But nice to see this new chip. Great work. Best regards, Mark Reply to Mark Raspberry Pi Staff Liz Upton 28th September 2023, 12:49 pm Go to your local Authorised Reseller: they’ll all have stock at launch, and most, if not all of them, are taking pre-orders. And they’ll all be selling at the recommended price (but be aware of your local taxes please). Reply to Liz Upton boltronics 28th September 2023, 1:31 pm I wish there was a model with 16Gb of RAM. Not that it matters. Everywhere in Australia seems to be completely sold out just a few hours after release. I wonder how long it will take to restock? Reply to boltronics Raspberry Pi Staff Liz Upton 28th September 2023, 1:36 pm It is not released yet: this is an announcement post that you are replying to! Please go back and read more to find out when and where you’ll be able to buy one. Reply to Liz Upton boltronics 28th September 2023, 2:08 pm Thanks. The article says “Units are available to pre-order today from many of our Approved Reseller partners”, and the stores I checked either said “sold out” or “out of stock” (which I took to mean that pre-orders have sold out). OFC I’ll be happy if that’s not actually the case (and yes I’m now on the waiting lists but it’s not possible to put money down like a true pre-order at piaustralia.com.au or core-electronics.com.au). Thomas Dieckmann 28th September 2023, 12:52 pm I’m still missing a WLAN connector (U.FL)… When using metal cases, the signal might be supressed. So please produce a Rev.2 with this connector, very soon! Reply to Thomas Dieckmann Raspberry Pi Staff Liz Upton 28th September 2023, 12:55 pm No. Reply to Liz Upton Sam 28th September 2023, 12:59 pm Can the RP1 be used as a standalone processor? I.e. in the future, is it possible that an rp2040 equivalent of the RP1 might be released? I only ask because a rp2040 style microcontroller with a camera interface would be amazing 👌 Reply to Sam Marcin 28th September 2023, 1:06 pm If connector PCIe 2.0 can be used to connect fast NVME disk? If so, how to design and count performance for such setup? Could we boot from NVMe then? Adapter needed or not? Reply to Marcin aBUGSworstnightmare 28th September 2023, 1:22 pm That’s what the M.2 HAT will be used for. NVMe boot will be possible for sure. Reply to aBUGSworstnightmare Raspberry Pi Staff PhilE 28th September 2023, 1:49 pm Yes, the M.2 HAT Eben mentioned will allow booting from an NVME SSD – the prototype works really well. Reply to PhilE Satadru Pramanik 28th September 2023, 1:19 pm Hooray for a new iteration! I assume the RTC battery fits neatly within the new case? Reply to Satadru Pramanik James Adams 28th September 2023, 1:42 pm Yes it does! Reply to James Adams Mike632T. 28th September 2023, 1:29 pm Just in time for Christmas !!! Now I know what I want in my stocking this year. Reply to Mike632T. Raspberry Pi Staff Ashley Whittaker 28th September 2023, 1:53 pm It’s the most wonderful time of the year. Reply to Ashley Whittaker Rob Beard 28th September 2023, 1:30 pm Sounds like an awesome upgrade to the Pi 4, looks like it’s worth the wait. :-) Reply to Rob Beard tek 28th September 2023, 1:44 pm Will PI5 be at Maker Faire in Rome next month? Reply to tek Raspberry Pi Staff Ashley Whittaker 28th September 2023, 1:52 pm YES! Here is a list of all the events you can get hands-on with Raspberry Pi 5: https://events.raspberrypi.com/experience-raspberry-pi-5 Reply to Ashley Whittaker W. H. Heydt 28th September 2023, 4:19 pm Thanks for the list. I see that the Maker Faire that is practically in my back yard–and for which I already have a ticket–will have Pi5s. Reply to W. H. Heydt Steffen 28th September 2023, 1:49 pm Interesting. I’m curious why you didn’t address a huge weak point, being the SD card, by introducing emmc storage? Reply to Steffen James Hughes 28th September 2023, 1:54 pm For the vast majority of people, SD cards are not a weak point, but a useful feature. On the Pi5 the SD card speed has doubled. You will be able to use M.2 SSDs on HAT in the future, you can already USB or network boot if you want. Reply to James Hughes Steffen 28th September 2023, 10:44 pm It’s fine to keep the SD card slot. But it is well known in the home assistant community, that if you run the os on an SD card, the card will inevitably crash. So to not improve on this is pretty crazy to me. Reply to Steffen W. H. Heydt 29th September 2023, 1:27 am Beside the fact that no storage medium lasts forever, given what has been said, your solution is: Pi5+case+M.2 HAT+*internal* NVMe SSD. I did a quick look earlier and you can get 256GB PCIe3*4 NVMe SSDs for less that $30. Set up that way and the whole unit is self-contained. Reply to W. H. Heydt Robert White 29th September 2023, 5:26 pm Never had an SD crash in many years of use always on. The SD crashes if are cheap or os isn’t properly configured. SD is a a standard with many different quality cards and technologies, some have also trim feature that makes them basically as wear resistant as a SSD hard disk. Reply to Robert White CooliPi 2nd October 2023, 1:16 am I’ve settled on SAMSUNG PRO Endurance cards, because other cards fail at reading (and eventually wear out) because of TLC or QLC architecture after some time. PRO Endurance is MLC. Supports TRIM (lsblk -D shows it can trim) and fstrim -v / can trim it (once a week is sufficient). SanDisk has an equivalent line of SD cards (also MLC). I don’t know which of them is better. Raspberry Pi Staff PhilE 28th September 2023, 1:57 pm I find the removable storage to be a strength, not a weakness, since it allows easy switching between projects and encourages experimentation. The M.2 HAT will provide a higher performance, higher reliability alternative for those who feel the need. Reply to PhilE Sly 29th September 2023, 2:19 pm Exactly! Removable storage is a must. Not only it is more comfortable and allow to easily switch from a card to another to use a different OS image, configuration etc. But also increase the life of the board not forcing you to trash it because of NAND wearing. With more clue of the facts, many people would rather ask for a faster sd card standard (since it doesn’t even support UHS-II that now with SDUC and SD Express is 3 generations old) rather than emmc that would be a step back. Reply to Sly Sly 29th September 2023, 2:10 pm The emmc is not better than sdcard. This is an old myth built on the fact there are a lot of cheap poor quality sd card and a lot of cheap and old SD card reader on the market, not a problem of SD card standard itself. There are sd card with support to trim as SSD and very fast speed, not even mentioning SD Express readers and SDUC sdcard standards. Makes no sense to switch to emmc would be much better using just a newer SD card reader, that can take advantage of faster microsd. Reply to Sly Kelli 28th September 2023, 1:51 pm Ah, it’s too bad there isn’t any analog(ue) audio output on the board anymore. No more simple-build PiPod. Used to be that all that was needed was a small amplifier to boost the audio up from line level to more ‘oomph’ to drive higher-impedance headphones. Now there’ll have to be a DAC as well… and I don’t even know what it’ll connect to for the digital audio. Reply to Kelli Raspberry Pi Staff PhilE 28th September 2023, 5:02 pm A cheap USB DAC would be the obvious choice, unless you absolutely need all 4 ports for something else (and no hub), or you can’t make it all fit. Reply to PhilE ardencaple 2nd October 2023, 5:06 pm It really depends on what you want – there are lots of audio HATs available. A couple of things to remember – the original analogue output wasn’t very HiFi – so if you want quality audio you need something else anyway. Also, if you are just using it as an audio output device, then you don’t need all the processing power of a pi 4/5. The Pi Zero 2W is ideal for this, especially when paired with the rpi codec zero hat, although that takes the combined price up to about the same as a Pi 4/5. Availability of the Z2W is taking a bit longer than promised to ramp up, but should be here soon. Reply to ardencaple Tim 28th September 2023, 1:52 pm Please share cryptsetup benchmark output. Reply to Tim Liam Fraser 29th September 2023, 9:37 am For Pi4 # AlgorithmKeyEncryptionDecryption aes-cbc 128b 49.1 MiB/s 75.1 MiB/s serpent-cbc 128b twofish-cbc 128b aes-cbc 256b 42.5 MiB/s 57.3 MiB/s serpent-cbc 256b twofish-cbc 256b aes-xts 256b 82.5 MiB/s 73.0 MiB/s serpent-xts 256b twofish-xts 256b aes-xts 512b 64.5 MiB/s 56.1 MiB/s serpent-xts 512b twofish-xts 512b For Pi 5: # AlgorithmKeyEncryptionDecryption aes-cbc 128b 1073.5 MiB/s 1895.5 MiB/s serpent-cbc 128b twofish-cbc 128b 122.4 MiB/s 126.7 MiB/s aes-cbc 256b 869.4 MiB/s 1581.4 MiB/s serpent-cbc 256b twofish-cbc 256b 123.6 MiB/s 127.3 MiB/s aes-xts 256b 1539.2 MiB/s 1530.9 MiB/s serpent-xts 256b twofish-xts 256b 126.2 MiB/s 128.9 MiB/s aes-xts 512b 1347.9 MiB/s 1334.3 MiB/s serpent-xts 512b twofish-xts 512b 128.1 MiB/s 128.9 MiB/s Reply to Liam Fraser Raspberry Pi Staff PhilE 28th September 2023, 1:53 pm Dual 4Kp60 HDMI, dual camera/display connectors, high performance USB3 and PCIe connectors are all very well, but I expected more love for the dedicated UART/JTAG connector – perhaps I’m just odd. Reply to PhilE stan423321 28th September 2023, 2:23 pm Debugging support is useless until the day you need it [% Is it compatible with Pico probes? Does it have hardware “intrusion” support, or is it handled by software? Reply to stan423321 Logan H-D 28th September 2023, 2:24 pm So long as it remains compatible with the Pi probe, it’ll be a handy addition for any time I manage to completely break many things. Reply to Logan H-D James Adams 28th September 2023, 2:51 pm Yes it was designed to work with with the Raspberry Pi Debug Probe. Reply to James Adams pawel 29th September 2023, 9:36 am Is it going to replace JTAG from 40 pin connector and has it gdb support? Can you elaborate more what kind of JTAG is it (swd?) Reply to pawel Giovanni Rito Russo 28th September 2023, 1:59 pm Will the official 7 inch Raspberry display work with Pi5? Reply to Giovanni Rito Russo Raspberry Pi Staff Alasdair Allan 28th September 2023, 2:38 pm Yes, the 7-inch Touch Display will work with the Raspberry Pi, but you’ll need a new Flat Flexible Cable (FFC) as the MIPI DSI/CSI connectors on the 5 are now at a higher density. Reply to Alasdair Allan Laszlo Dobrovolszki 28th September 2023, 1:59 pm Congrats on the new raspberry pi to the whole team. I was waiting for rpi5 for quite a while. And yes, my biggest dream came true with the on board on/off switch! Already pre-ordered two units… :D (pssst) Reply to Laszlo Dobrovolszki stan423321 28th September 2023, 2:05 pm Hey folks, minor question on the power supply changes. If I connect a 5V 6A barrel adapter I use for other stuff through a barrel/USB-C kludge to a RPi5, how will the experience differ from new official adapter? Is there some USB negotiation involved over amperes, or is that only for volts? Reply to stan423321 James Adams 28th September 2023, 2:50 pm You can add a line to config.txt to tell the Pi to ignore the power autodetection and just assume the supply can give 5V/5A. Reply to James Adams gz 28th September 2023, 2:06 pm Did I read that correctly? There is no SATA connector, and the maximum load on USB is actually lower than Pi4. This means a couple of things. The first is that you still won’t be able to connect a standard 2.5″ SSD drive without an active USB hub in between. The second – the lack of a real SATA connector is the performance bottleneck for Pi4. Therefore an old laptop with the SATA and slower CPU will be much faster and responsive that this new Pi, no matter how much faster the CPU will be. Reply to gz James Hughes 28th September 2023, 2:26 pm USB load will be fine if you use our power supply, and we will release an M.2 HAT so you can have a nice fast SSD attached, although I have found the doubling of speed of the SD card interface to make for a very good desktop performance. Reply to James Hughes fanoush 28th September 2023, 4:48 pm SATA is old, NVME/PCI-E is better for the future. Even the 1x line gives NVME speed similar to SATA, definitely not bottleneck. Well, I secretly hoped at least for two pci-e lines as every nvme ssd has at least two or have at least 3.0 version but one can’t have everything, still PI5 os great :-) I hope at least CM5 will have more pci-e lines exposed. Reply to fanoush fanoush 30th September 2023, 9:46 pm Oh, found out the pci-e line is actually 3.0 unofficially and works just fine in 3.0 mode for nvme so I am happy. ~900MB/s disk i/o is plenty. Reply to fanoush Joseph Pierce 28th September 2023, 2:11 pm That sounds nice but I can get a full blown prodesk for cheaper and it’s faster bigger HHD and more ram Reply to Joseph Pierce James Hughes 28th September 2023, 2:24 pm Interested, please supply a link to this. Reply to James Hughes Norman Jackson 29th September 2023, 6:24 am James, I suspect your money won’t work in la-la-land. Reply to Norman Jackson Jason Jackson 28th September 2023, 11:30 pm Don’t hog them all! Spill the beans, where can I find some? Although, they won’t be nearly as power efficient as RPi. Reply to Jason Jackson Logan H-D 28th September 2023, 2:22 pm I see a lot of commentators say that the Pi5 supports USB PD. The actual blog post doesn’t mention this, is this confirmable by a Pi Foundation member? Also, how does this new power supply system work with gadget mode? Does the Pi5 even have gadget mode like the Pi4 did? Reply to Logan H-D Raspberry Pi Staff Alasdair Allan 28th September 2023, 2:27 pm The Raspberry Pi 5 requires a good quality USB-C power supply capable of delivering 3A at +5V (15W) in order to boot. However, using such a supply will restrict the current draw to peripherals. If you are using a power supply that cannot provide 5A at +5V on first boot you will be warned by the operating system that the current draw to peripherals will be restricted to 600mA. The Power Management Integrated Circuit (PMIC) of the Raspberry Pi 5 implements the USB-PD standard which allows higher voltages and currents to be negotiated via software. For users who wish to drive high-power peripherals like hard drives and SSDs, while retaining margin for peak workloads, a USB-PD enabled power supply capable of supplying a 5A at +5V (25W) should be used. If the Raspberry Pi 5 firmware detects such a supply, it increases the USB current limit for peripherals to 1.6A, providing 5W of extra power for downstream USB devices, and 5W of extra onboard power budget. Reply to Alasdair Allan Logan H-D 28th September 2023, 2:51 pm The phrasing in this seems a bit odd, would like some clarification. If I have a USB-PD power supply that can supply 12V at 3 amps, am I correct in interpreting that the Pi will *not* increase the downstream wattage? I can understand recommending 5V 5A specifically, that way there wouldn’t be a need to buck the power, but are other voltages just not going to be supported for proper supplying for other devices at full power? Reply to Logan H-D Raspberry Pi Staff Alasdair Allan 28th September 2023, 3:01 pm Our upcoming 27W USB-PD capable supply can deliver: 5.0A at 5.1V, 3.0A at 9.0V, 2.25A at 12.0V, 1.8A at15.0V. It comes with a 1.2m 17AWG captive cable. However, you are correct. If you have a power supply that can do 3A at 12V, there will be no increase in downstream Wattage. The Raspberry Pi 5 requires a 5V supply. It will negotiate for 5V at 5A. Reply to Alasdair Allan Raspberry Pi Staff Liz Upton 28th September 2023, 3:04 pm Mine’s busy charging my M2 MacBook Pro at the moment. Seems to be handling it quite nicely. Leah 29th September 2023, 12:41 am Wow, that’s a huge disappointment. I really did not expect that. I would’ve expected it to be USB PD compliant so that you can just use any regular old power brick. Being forced to use the official Raspberry Pi wall wart is a huge dealbreaker, in my opinion. I guess I’ll just have to wait for the rev2 which fixes this – just like the USB-C issues with the Pi 4. James Hughes 28th September 2023, 2:29 pm Yes, the Pi5 will negotiate for a 5v5A supply, and use that if present (the Official PS will do this as well as other voltages). In the absence of the negotiation,. 5v3A will be used, which is actually good enough for most use cases. Reply to James Hughes Raspberry Pi Staff Liz Upton 28th September 2023, 2:30 pm Yes, the Pi 5 has gadget mode, just like Pi 4. Reply to Liz Upton thagrol 28th September 2023, 2:25 pm I’d like to have seen more power for USB devices rather than less but otherwise it sounds like a great leap forward. Reply to thagrol James Adams 28th September 2023, 2:27 pm You do get more downstream USB current, 1.6A minimum (if you have a 5V/5A supply). Reply to James Adams Nicko 28th September 2023, 2:27 pm Does the fact that the drivers for the VideoCore VII GPU will be open sourced mean that Broadcom will be publishing full details of how to make the most of the GPU? It would be great to be able to write drivers for off-loading of compute-intensive machine learning inference using the GPU, especially now we have two camera interfaces! Reply to Nicko Mike Redrobe 28th September 2023, 2:39 pm Can the RTC wake/restart the pi after a period of time off/sleeping ? Reply to Mike Redrobe James Adams 28th September 2023, 2:47 pm Yes Reply to James Adams Alex 28th September 2023, 2:43 pm Does the new Pi support the standard OpenGL api (non ES)? Anyway, the faster I/O chip, the SOC and the PCIe lanes exposed are very great additions to the ecosystem. I expected a hexacore or an octacore tho Reply to Alex Jim 28th September 2023, 2:43 pm Squeee!!!!! The addition of the M.2 HAT is killing me! I wasn’t going to get a new RPi right away, but I want this so bad! Fantastic job to everyone involved! Reply to Jim Brent McGee 28th September 2023, 2:45 pm Can I play Skyrim on this? Reply to Brent McGee Jack Chaney 28th September 2023, 2:46 pm Is there any plan for a Pi-500? Reply to Jack Chaney MW 28th September 2023, 3:14 pm Jeez all this rubbish about CM5 / 500, some people are just not satisfied. Now an on topic question, will 32bit support be dropped from Raspberry Pi Bookworm OS for the RPi5 ? because it is about time that 64bit is the norm.. Reply to MW Raspberry Pi Staff PhilE 28th September 2023, 5:10 pm If you’re asking whether the 32-bit Bookworm images will also support Pi 5 then the answer is no. If you’re asking something else then you’ll have to clarify the question. Reply to PhilE MW 28th September 2023, 6:34 pm Thank you, yes you have deduced correctly, great.. Reply to MW Joe Thompson 28th September 2023, 3:21 pm Many congrats on this mighty achievement….Physical computing and Linux are super important for our students! Reply to Joe Thompson Brad Davis. 28th September 2023, 3:24 pm Quite jovial, but I will still use my Pi 4 for the moment as I have no need for a new one anytime soon. Reply to Brad Davis. Jeff Berntsen 28th September 2023, 3:32 pm A couple of questions about the new power management system: First, is there a connector or solder pads for an external power button? I could see that being useful for third-party cases. Second, will it support wake-on-lan via Ethernet? Reply to Jeff Berntsen Raspberry Pi Staff PhilE 28th September 2023, 5:15 pm Yes – there are two through-holes next to the power connector and RTC battery connector. For wake-on-LAN I think the answer is probably no – the hardware doesn’t make it easy, and we probably won’t get around to fudging it using RP1 software. Reply to PhilE solar3000 28th September 2023, 3:36 pm excellent of course, we’ll have to fight our way thru the horde of geeks to get one. what will I do with the 300 pis I already have…. Reply to solar3000 Meow 28th September 2023, 3:36 pm Are you considering swapping hdmi for displayport? Reply to Meow Masafumi Ohta 28th September 2023, 3:49 pm Congrats, happy launch to the team! Can’t wait the launch in Japan passing Giteki certification! And hope to see Eben and Liz in Japan soon. Reply to Masafumi Ohta Raspberry Pi Staff Liz Upton 28th September 2023, 3:50 pm You too, Masa! Giteki marks coming to a very small computer near you real soon now. Reply to Liz Upton Abu Abdulla 28th September 2023, 4:09 pm Any details on the ISP part, is there any updates on the codec e.g. h265, speed … etc Reply to Abu Abdulla James Hughes 28th September 2023, 4:44 pm ISP is about 3-4 times faster than previous models. No HW encoders – H264 is done in software, and gives 1080p60 at much higher quality than the previous HW encoder. No HEVC HW encoder. Reply to James Hughes Abu Abdulla 28th September 2023, 5:16 pm thank you for the response, no hw encoder means a bigger latency ? I was hoping to be honest for a better encoders and latency improvement Reply to Abu Abdulla Jon 28th September 2023, 4:11 pm Where’s The SD Card Slot? Reply to Jon Raspberry Pi Staff Liz Upton 28th September 2023, 4:12 pm Underneath! Reply to Liz Upton Andrew Waite 28th September 2023, 4:15 pm A new Raspberry Pi 5 🎉 Great to see the Pi now as a fan header, on/off switch and a case fan. Disappointing to see the microHDMI ports though. Maybe the RPi500 will have full size HDMI ports? Reply to Andrew Waite horace 28th September 2023, 4:22 pm wow! awesome! exactly what i wished for. :) i am looking forward to see what kind of pci-e hats will come out (except for the already announced ones). Reply to horace horace 28th September 2023, 4:47 pm oh, and the possibility to connect two cameras is extremely useful for me too. :) Reply to horace Roy Chau 28th September 2023, 4:27 pm Good to hear Raspi 5 is coming!! Thanks Team. By the way, will SATA HAT also be available? Thanks Reply to Roy Chau Raspberry Pi Staff PhilE 28th September 2023, 5:26 pm It’s unlikely that we would make one, but nothing to stop a third party taking advantage of the demand. Reply to PhilE Lorenzo 28th September 2023, 4:29 pm I’m very happy to see the RPI5… and I’ve already preordered mine. However, I’m also a bit disappointed: This is what I was expecting and I didn’t get: – USB-C instead of the horrible microHDMI (or rather a single full size HDMI) – At least one USB-C 3.0 port – At least one Qwiic/STEMMA QT connector – Color-coded 40-pin header – An RP2040 MCU included in the SoC What I’m curious to see in action: – The cryptography extensions of the A76 MPU – The PIO capabilities of the RP1 I/O controller Reply to Lorenzo Taylor 28th September 2023, 6:33 pm Genuine question, but why would the Pi need another Pi(co) on board? It already has 40 pins of GPIO like the Pico (yes, for any pedants I am aware 2040 =/= Pico) Reply to Taylor Joshka 29th September 2023, 12:43 am PIO basically adds extra protocols that aren’t already there. E.g. the Pi has 6 UARTs (bidirectional), but 28 pins – PIO means potentially an extra 14 pins of UART (whichever direction) without having to dedicate a CPU to bit bang those extra pins (i.e. your app just writes to a memory address). Same thing applies for I2C / SPI / whatever protocol you want more of. PIO is a game changer! Reply to Joshka Lorenzo 30th September 2023, 9:57 am Having a real MCU on the same SoC would incredibly expand the capabilities of the Raspberry Pi. You would then have the full power of the A76 MPU for the high level OS and the raw power of the MCU for real-time tasks. This is a setup increasingly seen on industry-level SoC and having it on a RPi would have been incredible. Reply to Lorenzo Eduard 28th September 2023, 6:33 pm I totally agree. There are a usb-c controllers with VESA amb power outage Reply to Eduard Gray 29th September 2023, 8:01 am – USB-C instead of the horrible microHDMI (or rather a single full size HDMI) Dual monitor support > specific choice of connector! – At least one USB-C 3.0 port Again,. this is an issue of form factor. I don’t think it’s really that big a deal, USB-A to C cables cost no more than a good quality USB-C to C cable. – At least one Qwiic/STEMMA QT connector This seems like the kind of thing a HAT is suited for. *Checks* And yes, Sparkfun already make that! – Color-coded 40-pin header Oooh, this one I can’t disagree with you on, that is a neat idea. Probably expensive though. – An RP2040 MCU included in the SoC / The PIO capabilities of the RP1 I/O controller Isn’t this kind of the RP1’s PIO stuff you mention you’re excited about? If not, hat! – The cryptography extensions of the A76 MPU This! So much this! I’m super excited to try it on the Pi 5, and another reason I’m really hoping that CM5 will finally give us an ATX-friendly ARM64 board I can stick in all my PC and Server boxes. Fast LUKS encryption will make desktop use viable for me, as well as significantly improve TLS performance when hosting services on Pi. Super excited for the Pi 5 to drop so I can get playing around with this stuff, even if it’s not in the ideal form factor for me. :) Reply to Gray Lorenzo 30th September 2023, 9:50 am > Dual monitor support > specific choice of connector! I totally disagree. Everything is better that the horrible, horrible micro-HDMI. That was by far the most common complaint of RPi4 and it’s incredible that they persisted with this really bad choice… >Again,. this is an issue of form factor. I don’t think it’s >really that big a deal, USB-A to C cables cost no more >than a good quality USB-C to C cable. It’s definitely not an issue of form factor, but of capabilities. A fully compliant USB-C port can be role switched and become a USB gadget. >– At least one Qwiic/STEMMA QT connector >This seems like the kind of thing a HAT is suited for. Having a connector on board costs next to nothing and spares the huge inconvenience of a HAT (and would fit in a standard case). The Arduino R4 WiFi has finally got one such connector on board. – An RP2040 MCU included in the SoC RP1 has just some limited PIO capabilities. And it would have been nice to have a full and programmable MCU integrated in the SoC. Reply to Lorenzo PicoBuster 1st October 2023, 9:35 am https://www.raspberrypi.com/news/introducing-raspberry-pi-5/#",
    "commentLink": "https://news.ycombinator.com/item?id=38068801",
    "commentBody": "Raspberry Pi 5 has no hardware video encoding and only HEVC decodingHacker NewspastloginRaspberry Pi 5 has no hardware video encoding and only HEVC decoding (raspberrypi.com) 195 points by InsomniacL 4 hours ago| hidepastfavorite107 comments firebat45 1 hour agoI really wish they would stop making newer, faster, more expensive Pi&#x27;s and just focus on making the existing Pi&#x27;s cheaper and more available. Out of the dozen or so RPi&#x27;s I have, not a single one is even connected to a monitor. I don&#x27;t need dual 4k HDMI ports. I&#x27;d love a widely available and in-stock $20 Pi. It&#x27;s like they&#x27;ve forgotten what the RPi is all about. reply 015a 25 minutes agoparentTheir mass production of the Pi keyboard should clue you into at least one direction that they believe \"the Pi is all about\"; education, and increasing access to modern computing hardware. Enhancing the performance envelope and connecting to a monitor do, to me, seem like worthy steps toward that end.Everyone uses general purpose computers differently. I feel your statement \"they&#x27;ve forgotten what the RPi is all about\" isn&#x27;t just ignorant; its hurtful. Maybe their direction isn&#x27;t parallel with what you want out of the products they make, but you should at least have the empathy to recognize that you aren&#x27;t the main character in this play. reply Teever 4 minutes agorootparentWhile I admit that I am a bit envious of the large 4k monitors that my coworkers use, I have managed to make it through life without buying anything larger than a 1440p monitor.What exactly is the educational advantage (for the demographic that the raspberry pi is supposed to be educating) of the inclusion of 2x 4k ports and does that advantage override the opportunity cost of including the ports?In other words &#x27;1080p ought to be enough for anybody learning how computers work from an SBC. reply weberer 1 hour agoparentprevHere you go. Its $10 at Microcenterhttps:&#x2F;&#x2F;www.microcenter.com&#x2F;product&#x2F;486575&#x2F;Zero_W reply lannisterstark 1 hour agorootparentNot everyone lives near a microcenter though. The pi zero W&#x2F;2W comes out to like , $15+ ship + taxes and is more like $24. reply bmurphy1976 47 minutes agorootparentI&#x27;ve been trying to get two Zero W 2s for almost two years now without getting ripped off by somebody on the second hand market. They are still nearly impossible to find for the advertised price. :( reply nmjohn 26 minutes agorootparentWhile that certainly has been true for the majority of the last two years - rpi&#x27;s in pretty much all skus have been back in stock for a few months now - to the point that even digikey has many of the skus in bulk stockSee: https:&#x2F;&#x2F;rpilocator.com&#x2F;As for Zero W 2s: In stock right now: https:&#x2F;&#x2F;chicagodist.com&#x2F;products&#x2F;raspberry-pi-zero-2 reply bmurphy1976 21 minutes agorootparentOh, thanks! I&#x27;ve been watching that religiously and while you are correct the other Pi&#x27;s have been available for a couple months now, the 2Ws have been absent. I haven&#x27;t checked in a couple weeks now, I&#x27;m happy to see they are finally in stock!Edit: it&#x27;s a bit premature. Only Chicago Distributors have them in stock at the moment and they are limiting the orders to 1, which is frustrating because I only need 2. reply georgeecollins 17 minutes agorootparentprevHaving grown up in a world where 8 bit computers with 4-16k ram (and no storage) cost the equivalent of $1000, inflation adjusted, this seems like an almost insane complaint. Hardware is so cheap now compared to software which is still very expensive to produce. A person could spend less than a $100 on a computer and make that money back very quickly doing various digital tasks on fiverr. reply cornstalks 45 minutes agorootparentprev> 11+ at $999.99 eachWow... reply nkozyra 35 minutes agorootparentTo discourage the hoarding that happened (although less-so with the Zero) in the last two years.At least they&#x27;re willing to take your money, a lot of shops had hard caps. reply opan 13 minutes agoparentprevTotally fair desire, though some people definitely do want these to be desktop or HTPC replacements.I&#x27;m usually more impressed with RockChip stuff anyway, though, so if the Raspberry Pi folks wanted to focus their efforts on affordable dev boards, I think there&#x27;d still be plenty of options for those who do want to play back 4k video on a monitor. They&#x27;ve done an excellent job with the Pi Pico, keeping it in stock and dirt cheap. I&#x27;ve gotten a dozen or more of those at like $4 each. So they&#x27;re still catering to the \"maker\" types with those.I&#x27;m excited to get a better version of something like the Pinebook Pro someday, based on a newer SoC with more RAM and a bit more GPU power for video playback and some simpler games like Minetest and Xonotic. reply bmurphy1976 49 minutes agoparentprevI wish they took performance more seriously. I migrated a bunch of my stuff off of a Pi 4 to an Intel N100 NUC because the Pi 4 just didn&#x27;t cut it. I have a bunch of other use cases as well that have struggled with the Pi 4s and competing RK3588 based systems look compelling.Point is, your use case doesn&#x27;t match my use case. I hope they continue to make things more performant AND cost effective. reply wkat4242 48 minutes agorootparentAn intel N100 NUC is just a really good low power server platform and it will always be better for that than a pi.The pi was never meant to be a server. reply tambourine_man 19 minutes agorootparentI never understand why people compare the Pi with NUCs. The latter is an order of magnitude more expansive (new, it’s hard to consider used stuff for serious work), has no GPIO built in, consumes way more power…It’s in a whole other category. reply bmurphy1976 40 minutes agorootparentprevOf course, but if you are trying to do something which requires GPIO or want to build on top of Rapsberry Pi&#x27;s other functionality (i.e. the cameras) your options are more limited. reply bilalq 19 minutes agoparentprevDifferent people have different needs though. I have a smart mirror that runs a 4K display driven by a Pi 4. I&#x27;m sure there a lot of other kiosk-like use-cases for Pis. reply snvzz 21 minutes agoparentprevFortunately, there is choice in RISC-V. reply starik36 1 hour agoparentprevThat&#x27;s what the RPi Zero 2 is all about. They are $15 and work great. reply CodeWriter23 1 hour agorootparentCan’t speak for GP but I want a $20 device with a wired Ethernet port. I’m using pis where they need to reliably communicate in real time. reply Blackthorn 49 minutes agorootparentThis is accidentally a fantastic example of the issues with the original commenter&#x27;s train of thought. Not everyone needs every single feature, but every single feature is needed individually by someone. reply paulmd 41 minutes agorootparentyeah, with how many \"maker\" things have emerged around RPi, it&#x27;s a bit of a dickpunch to be removing features that a nontrivial portion of the user base are building projects&#x2F;products around.Hopefully we have gotten past the \"RPi is for education, not makers!\" thing, there is really zero traction on big computer labs full of raspberry pis. even insofar as it&#x27;s used in education it&#x27;s still used for maker tasks, people building robots with computer vision or whatever, and some of those use-cases need the encoder too.RPi has always been a somewhat incoherent product that survived because it was a below-average solution to any problem, the jack-of-all-trades for $45 (plus another $100 of accessories). If it doesn&#x27;t have video encode, why would I want this for plex instead of a NUC clone? why would I buy this instead of a big AVR32&#x2F;STM32 microcontroller for building a robot? Why would I want this instead of a Bus Pirate for GPIO? Why would I want to use this as a mini-desktop if I can&#x27;t even do a Teams call on it? Etc etc. It&#x27;s barely an adequate product even with all the legacy feature set there, if you start pulling pieces off then competing products become even more compelling for many use-cases.Reality is they will probably be fine because of the name recognition and brand but it&#x27;s not good management either.I&#x27;d love to see real numbers but just like with the RX 6500XT I just can&#x27;t imagine the encoder is that big. We are talking about pennies more per die, and likely this will cost them more in total sales than the pennies represent in the total product cost - you are saving 0.1% of the MSRP and losing 5-10% of potential addressable market. Literally would just be better for them to eat the cost, almost certainly.And you are correct that while nobody uses all the features, everybody uses some of them.I frankly do not understand the decision to depart from mainstream SOC configurations here - which obviously would have an encoder. reply Blackthorn 12 minutes agorootparent> RPi has always been a somewhat incoherent product that survived because it was a below-average solution to any problem, the jack-of-all-trades for $45 (plus another $100 of accessories).In addition to what you wrote: it also has a really good software story. Everybody&#x27;s got a build for raspberry pi. Something like an odroid or banana pi or whatever has a much more \"gotta handle all the builds yourself\" path. The power of being the standard, I suppose. reply carlos_rpn 1 hour agorootparentprevCheck the Banana Pis if you haven&#x27;t already. Most of them have it. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Banana_Pi reply wkat4242 46 minutes agorootparentprevYou can add it over USB (even with hub) for a few $$. Which is exactly how it&#x27;s wired on the pi anyway until the 4. reply londons_explore 1 hour agorootparentprevI have found that a good chunk of random opensource projects won&#x27;t run on the zero 2. The ARM core is ARM7 and doesn&#x27;t support modern instructions, so plenty of software just immediately dies with &#x27;Illefal Instruction&#x27;.Also, it&#x27;s 32 bit, and a lot of software is starting to depend on the massive address spaces offered by 64 bit.And there is no high ram model. Some stuff just gobbles so much ram that 512M isn&#x27;t practical. reply ripley12 1 hour agorootparentThe Zero 2 W has a 64-bit Cortex-A53 (ARM8). reply Aerbil313 8 minutes agorootparentprevMy Pi Zero 2W is running 64 bit Raspbian and reports aarch64 (Armv8). reply repiret 56 minutes agorootparentprevArmv7. Arm7 is a much older core. reply RetroTechie 1 hour agoprevGordon Hollingworth:\"In future we’ll have to do something, but for Pi 5 we feel the hardware encode is a mm^2 too far.\"Sounds reasonable, given a fast cpu & less-than optimal hw-accelerated encoding options. As for that \"something\", maybe:1) Drop hw-accelerated encoding and decoding entirely, and use the freed up silicon for much beefier cpus (like ones including -bigger- vector units, more cores etc. Cortex X?). That would be useful for any cpu heavy applications.2) Include hw encoder for a common (1), relatively &#x27;heavy&#x27; codec. And hw decoder for same + maybe others.3) Only include decoder(s?), like they seem to have done for RPi5.4) Include some kind of flexible compute fabric that can be configured to do the heavy lifting for popular video codecs.Combined with:5) Move to newer silicon node to obtain higher efficiency or transistor budget.Whatever route a future RPi would go, imho hw-accelerated decoding is much more useful than encoding. reply ksec 30 minutes agoparentHW-Decoding uses less mm2 than encoding, provides biggest power saving and benefits to user, all while being cheaper on patents. reply aag01 1 hour agoprev\"In future we’ll have to do something, but for Pi 5 we feel the hardware encode is a mm^2 too far.\"is corporate speech for \"broadcom decided not to let us use their video IP cores for low cost&#x2F;no cost any longer\" reply jandrese 1 hour agoparentIt is a bit frustrating how married the Raspberry Pi foundation is to a company that couldn&#x27;t care less if they live or die. Broadcom has always been at best indifferent and at worst hostile to the open source community. reply cogman10 1 hour agorootparentThere&#x27;s not really an alternative.Broadcom is one of the few options out there for ARM SoC. Rpi could dump a bunch of money into making their own SoC, but that would really ballon the costs. reply aag01 1 hour agorootparentThey should partner with qualcomm, not broadcom.Too bad it&#x27;s because of the former broadcom employees within the foundation. reply foobiekr 35 minutes agorootparentQualcomm is the single worst company to work with. They try to negotiate % of revenue deals instead of cost-per-unit deals and they make Broadcom look like Stallman-level open source fanatics. reply NewJazz 57 minutes agorootparentprevThey should produce boards from multiple vendors&#x27; SoCs. reply foobiekr 33 minutes agorootparentThis doesn’t work in practice since your costs scale with vendor count and theirs don’t.In reality being a single big customer for a be for is far more influential than being a small one with other options. reply cogman10 39 minutes agorootparentprevYou generally get bulk discounts. The more vendors you have, the more expensive each is. reply burnte 46 minutes agorootparentprevIt&#x27;s highly likely they have a sweetheart deal with Broadcom in exchange for loyalty. reply pavon 27 minutes agoparentprevYes, for context the Pi 1-4 all had H264 hardware encoder&#x2F;decoder support, which could comfortable encode at least 720p @ 30Hz in realtime. The die space argument makes sense for why they don&#x27;t have AV1&#x2F;HEVC encoding, but it does not explain why H264 was dropped. The fact that the CPU is now powerful enough to encode H264 at better quality and frame rates than the old hardware encoder is a better argument, but still a step backwards for folks who need lower power consumption or need the CPU for other things, and doesn&#x27;t explain why the hardware support needed to be dropped. It really does sound like something else (like licensing) drove the decision, and this is a post-facto attempt to sell&#x2F;justify that decision. reply lxgr 3 hours agoprevThat’s somewhat understandable, but still a bit disappointing. Not all playback devices support HEVC, and additionally HEVC will likely remain patent-encumbered much longer than e.g. H.264.I really wish there was at least one other and open hardware-accelerated format. It’s probably a bit too early for AV1, but VP9 would work with modern iOS and Android devices, for example.I also wonder how much licensing costs were a concern here, although past RPis had software-unlockable codecs for that exact reason. reply danogentili 2 hours agoparentThe rk3588 and rk3588s (i.e. orange pi 5) both support hardware H264&#x2F;HEVC encoding @ 8k30fps, as well as hardware HEVC&#x2F;VP9 decoding @ 8k60fps, H264 decoding @ 8k30fps, AV1 decoding @ 4k60fps. reply smachiz 2 hours agorootparentAren&#x27;t they like 4x the price too? reply folmar 1 hour agorootparentThe boards are the same price, i. OrangePI 5 8GB costs same as Raspberry 5 8GB. At least in EU. reply francisduvivier 1 hour agorootparentYes, and there are more advantages to the Orange Pi 5 SBCs:- They have full size HDMI - They have an m.2 connector - They still have an audio jack - They have more powerful performance cores - They have low performance cores - They have a 6 TOPS NPUOn the other hand, that cheap base model has no built-in wifi, but so you can add it in the m.2 slot.For me, the Raspberry Pi 5 is quite disappointing. But hey, the good thing is that maybe this will push more of the community to the RK3588(S) based boards. reply hajile 1 hour agorootparentprevOrange Pi also has a bunch of extra features too including some standout ones like* don&#x27;t need to spend extra $$ for M.1 SSD support* full-size HDMI so no need for $10 dongle* 6 TOPS NPU* better Mali G610 MP4 GPU* 8k60 output* USB 3.1 port (10gb&#x2F;s instead of just 5gb&#x2F;s)* 4x A55 cores* Audio jack reply imtringued 48 minutes agorootparentNobody needs that GPU. Alyssa Rosenzweig stopped working on the driver and got poached by Valve.Also, real time encoding with VP8 (yes, that is the standard for WebRTC) barely works. It has barely enough CPU power to produce a working demo, but too little to actually do anything with it. reply Bud 10 minutes agorootparentprevMini-HDMI doesn&#x27;t require a dongle. Just get the right cable. They&#x27;re just as cheap as a normal HDMI cable. reply xyzzy123 1 hour agorootparentprevopi5 16gb is about 130 usd, rpi5 is about 80 usd I think? You get twice the cores and RAM so I think they&#x27;re comparable value. But it&#x27;s sort of academic for me because rpi5 8GB is not in stock in Australia. reply cogman10 1 hour agoparentprevSurprisingly, AV1 is easier to implement a decoder for than VP9 (by design). Some of the VP9 transforms were axed with AV1 purely to make the stream easier to decode.Why AV1 hardware decoding has taken so long seems to be an issue with hardware manufactures not wanting to support it. HEVC and VVC seem to have more hardware support. reply gjsman-1000 3 hours agoparentprevThey say elsewhere that the quality and usability of them did not meet what they considered reasonable for the mm^2 of die space required. reply lxgr 3 hours agorootparentAh, yes, I do agree on the quality – it certainly can&#x27;t compete in any way with high-quality software or dedicated encoders.But arguably it doesn&#x27;t have to; many real-time applications (e.g. surveillance cameras) have local bandwidth to spare and&#x2F;or don&#x27;t care too highly about quality, and compatibility with older viewing devices without re-encoding is a priority. reply franga2000 3 hours agorootparentIf compatibility is a priority and bandwidth isn&#x27;t an issue, MJPEG is still the way to go and is by far the most common encoding I see in security cameras. reply _flux 3 hours agorootparentOn the other hand you could get cool stuff from the video encoding hardware, such as access to motion vectors on the cheap: https:&#x2F;&#x2F;github.com&#x2F;osmaa&#x2F;pinymotionI wonder though if the OpenGL ES3.1 compute could be used for this purpose on it. reply franga2000 9 minutes agorootparentOh wow, this is such a great hack! reply garaetjjte 1 hour agorootparentprevI think nobody used MJPEG in last 15 years. reply its-summertime 3 hours agorootparentprevIf bandwidth ain&#x27;t much of an issue, can just dump frames to a separate device for encoding, aside, Can&#x27;t imagine someone using a pi 5 just for camera usage (aside from projects needing cameras) reply InsomniacL 3 hours agorootparentI was hoping to use RPI5 as an NVR with image detection for Home Automation.The Frigate add-on with Home Assistant can publish events based on image detection for automations and supports RPI3 &#x2F; RPI4 hardware acceleration.https:&#x2F;&#x2F;docs.frigate.video&#x2F;configuration&#x2F;hardware_accelerati... reply graphe 1 hour agorootparenthttps:&#x2F;&#x2F;pipci.jeffgeerling.com honestly I&#x27;d get a home server and run HA through docker, it&#x27;s gotten me into home servers. reply folmar 1 hour agorootparentprevESP32CAM might be good enough. reply lxgr 3 hours agorootparentprevMaybe not only for cameras, but also for cameras. And when doing other things simultaneously, a video encoder not hogging all processing power becomes even more important. reply fundatus 2 hours agorootparentprevLast time I tried to encode a video from H.264 to HEVC (hw-accelerated) on Linux it was such a pain to get to work that I eventually gave up and simply accepted the performance hit. I&#x27;m sorry, but I&#x27;m not gonna recompile ffmpeg so that it works on my machine. Considering that most RPi-users probably use a Linux-based OS this is IMHO a sensible decision. reply Levitating 2 hours agorootparentWell it&#x27;s not that uncommon to use a version of ffmpeg with more features enabled for a specific purpose. For instance my jellyfin server uses jellyfin-ffmpeg[0] to do hardware acceleration, even on my Pi.[0]: https:&#x2F;&#x2F;github.com&#x2F;jellyfin&#x2F;jellyfin-ffmpeg reply lxgr 1 hour agorootparentprevThe default ffmpeg I got from Raspberry Pi OS supports hardware acceleration out of the box these days, as far as I remember. reply Y_Y 2 hours agorootparentprevFor hardware acceleration it&#x27;s probably easier to use gstreamer, depending on what device you are using to decode. But then you have a whole new problem. reply mytailorisrich 3 hours agorootparentprevIf it is a vanilla Broadcom Soc then die space is not really their consideration or decision. But maybe it is customised for RPi?Can&#x27;t find the datasheet for the BCM2712 right now. reply gjsman-1000 3 hours agorootparentWell, to quote Gordon Hollingworth on the original post:\"In future we’ll have to do something, but for Pi 5 we feel the hardware encode is a mm^2 too far.\"Also, Raspberry Pi Foundation and Broadcom have been really working together on successors since the... BCM2787 in the Raspberry Pi 3, if I remember correctly? Broadcom still reserves the right to sell to anyone, but the Pi is still the primary customer for those specific chips now. reply synergy20 2 hours agoprevJetson Orin Nano, the new devkit from Nvidia, surprisingly does not have a hardware video encoder either, you&#x27;ll need use CPU to encode video instead, which is extremely odd considering video-encoding is a common use case on lots of video applications. reply Y_Y 2 hours agoparentWow, I was shocked to see that. They don&#x27;t even bother using CUDA cores to encode (less of an issue if you have unified memory like in Jetsons). Anyway it seems you can get four 1080p streams at 30fps encoded to h264 in CPU if you set it up right: https:&#x2F;&#x2F;www.ridgerun.com&#x2F;post&#x2F;jetson-orin-nano-how-to-achiev... reply synergy20 1 hour agorootparentyes but typically cpu is bad for video encoding, at least the power consumption will be much worse than hw encoder. reply Shorel 1 hour agoparentprevSo no more Nvidia NVENC?What will OBS do then?https:&#x2F;&#x2F;www.nvidia.com&#x2F;en-us&#x2F;geforce&#x2F;guides&#x2F;broadcasting-gui... reply paulmd 14 minutes agorootparentOnly removed from the tegras, not the gaming cards.But yeah if you were doing OBS streaming on your jetson, then the newer hardware won&#x27;t have NVENC. Normally I&#x27;d say \"but nobody is doing that\" but someone (was) indeed doing exactly that, lol.https:&#x2F;&#x2F;blog.fosketts.net&#x2F;2020&#x2F;09&#x2F;10&#x2F;introducing-rabbit-i-bo...As mentioned it&#x27;s probably a ton more relevant to embedded and robotics&#x2F;computer-vision use-cases, which NVIDIA is really trying to push for (automotive etc). So it&#x27;s still a surprising change and will be a pain for some people. reply lannisterstark 59 minutes agoprevRemember you can get an HP Prodesk G3 400 or some such for $60 refurbed with far more hardware capabilities if you don&#x27;t need the portable form factor, gpio, or power consumption.It&#x27;s actually a better deal for home servers. reply Thaxll 2 hours agoprevIt&#x27;s kind of crazy to not have h264 decoded by hardware in 2023, even if it&#x27;s low on CPU usage nowdays, it&#x27;s still by far the most used codec. reply judge2020 1 hour agoparenth264 is the most available but probably not the most used. Every streaming service today either seeds AV1, VP9, or HEVC content first since it saves bandwidth[0] and every client from the past 5 years supports one of these newer formats (phones, GPUs, smart TVs, streaming boxes, etc).0: https:&#x2F;&#x2F;www.etcentric.org&#x2F;netflix-switching-from-vp9-codec-t... reply supertrope 24 minutes agoparentprevIt&#x27;s to save the license fee. A76 cores are fast enough to brute force H.264. reply bhouston 2 hours agoprevIs the direct competition, like the Orange Pi 5 based on the Rockchip RK3588S, differ at all in this regards?I think that lack of choice in HW accelerated video encoding&#x2F;decoding may just be standard on low-end devices in part to reduce costs. reply danogentili 2 hours agoparentThe rk3588 and rk3588s both support hardware H264&#x2F;HEVC encoding @ 8k30fps, as well as hardware HEVC&#x2F;VP9 decoding @ 8k60fps, H264 decoding @ 8k30fps, AV1 decoding @ 4k60fps. reply MikusR 2 hours agoparentprevThe other even cheaper boards even had AES acceleration for years reply eurekin 3 hours agoprevAre there any external hardware encoders&#x2F;decoders? reply ehutch79 3 hours agoparentFrom what I can tell, they mostly live in video cards at this point.There used to be an elgator capture card with some encoding, i _think_&#x2F; reply ohthatsnotright 2 hours agoparentprevEl Gato has one, it&#x27;s really nice: https:&#x2F;&#x2F;www.elgato.com&#x2F;us&#x2F;en&#x2F;p&#x2F;game-capture-4k60-pro reply mbilker 2 hours agorootparentThat is a capture card and not an encoder card. It does not feature any accelerated encoding and relies on the host system to provide the video encoding, usually via a dedicated or integrated GPU. reply LoganDark 2 hours agorootparentprevIt also costs like five times the price of the Pi itself. reply harlanji 2 hours agoparentprevI got a metal box with HDMI and an ethernet ports which encodes the HDMI video + audio and serves&#x2F;publishes H.264 RTMP&#x2F;TS segments. My intended use case was actually working with Pi&#x27;s on live streams, installing fresh systems and the like where encoding might not be available anyway.I couldn&#x27;t find the one online but it looks like there are a few out there. Side note&#x2F;tangent, the Pi3 was powerful enough to transcode 720p down to lower resolutions in real time. reply ComputerGuru 46 minutes agoprevWow, I&#x27;m surprised this took this long to come out! The raspicam&#x2F;raspivid ecosystem is huge and without hardware h264 encoding it is absolutely dead in the water. This makes the rPi5 a neutered bit of hardware and the rPi4 (and even the rPi3) better options for quite a number of applications! reply CodeWriter23 1 hour agoprevCan someone explain the hubbub here? My read of the specs seems to match the specs of the Pi 4, HEVC decoding but no encoding. reply InsomniacL 40 minutes agoparentRPI3 &#x2F; RPI4 have hardware accelerated encoding&#x2F;decoding for H.264, this has not been included for RPI5. reply trebligdivad 2 hours agoprevI wonder how much the GPU and AI blocks can be used to acclerate encoding; I&#x27;d assume quite a bit. reply barbegal 2 hours agoparentHardly at all, video decoding isn&#x27;t parallelisable. It&#x27;s often lumped in with the GPU but it is significantly different. reply ajb 19 minutes agorootparentThe question is about encoding. It is significantly parallelizable because you are doing a search for the best encoding you can find. Also at a micro level there are things like motion search for which vector ops are useful. So I would say that it&#x27;s likely they will look into that. reply swayvil 1 hour agoprevWill it do as a desktop system? What do you think? reply lannisterstark 57 minutes agoparentWhy not just get an HP Prodesk or dell optiplex or hp elite desk or whatever Lenovo? 6th&#x2F;7th gen Intel CPU models are all cheaper than this. reply giantrobot 4 hours agoprevThe title doesn&#x27;t seem to match the content. The comments are talking about hardware accelerated encode but I didn&#x27;t see anything about accelerated decode being dropped. reply MikusR 3 hours agoparenthttps:&#x2F;&#x2F;forums.raspberrypi.com&#x2F;viewtopic.php?p=2138929#p2138...\"JPEG and H264 encode and decode is now in software\" reply InsomniacL 3 hours agoparentprevThe information is spread over multiple comments, I could only link to one comment and thought just linking to the main article would be confusing as the article itself doesn&#x27;t mention it. reply michaelt 3 hours agoparentprev> \"Actually only 4kp60 H265 (HEVC) decode is available> But it only uses 50% of the processors to do 1080p60 on YouTube\"https:&#x2F;&#x2F;www.raspberrypi.com&#x2F;news&#x2F;introducing-raspberry-pi-5&#x2F;... reply devl547 3 hours agoparentprevOfficial specs only state 4Kp60 HEVC decoderSo no encoders and no h.264 decoder. reply orra 3 hours agorootparentInteresting. Thankfully, LibreElec think the Raspberry Pi 5 is strictly better, despite shifting to software decoding:> BCM2712 supports HEVC 4K60 hardware decoding. It no longer supports H264 in hardware. This might sound odd but it removes the RPi4’s 1080p restriction on H264 decoding and the 4K H264 test media we have has played. The big increase in performance from the Quad-Core A76 chip means RPi5 can software decode AV1, H264, VC1, VP9, and more at 1080p with easehttps:&#x2F;&#x2F;libreelec.tv&#x2F;2023&#x2F;09&#x2F;28&#x2F;rpi5-support&#x2F; reply gjsman-1000 3 hours agoprevI initially posted that the title did not match the content. The title is true but here’s another link to read:https:&#x2F;&#x2F;www.raspberrypi.com&#x2F;news&#x2F;introducing-raspberry-pi-5&#x2F;... reply theragra 3 hours agoprevWhat about software encode, is it real time? reply traverseda 3 hours agoparentIt&#x27;s really not a long post, if you wanted to read it. reply tecleandor 3 hours agoparentprevThey say it can encode 1080p60 (for the context, I guess it&#x27;s real time) using just one processor (again, I&#x27;m guessing he means \"one core\"), and with a better quality than the RPi4 hardware encoder. They think it could be possible to encode 4K at 24fps with some work, but they&#x27;re not right now going for that optimizations. reply londons_explore 3 hours agoprev [–] Or... Does the SoC have support for such things, but there is no software API yet, either because nobody has had time to write it, or someone chose not to pay for the licenses? reply InsomniacL 3 hours agoparentFrom the linked comment, it appears it&#x27;s not on the chip.> \"In future we’ll have to do something, but for Pi 5 we feel the hardware encode is a mm^2 too far.\"My interpretation of this is they felt the benefit did not outweigh the cons of the die space. reply olabyne 3 hours agoparentprev [–] they are talking about \"ditching a few mm², so I guess it is a lack of hardware replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Raspberry Pi Foundation is preparing to launch the Raspberry Pi 5, which includes an in-house design and improved features such as a 2.4GHz quad-core 64-bit Arm Cortex-A76 CPU, VideoCore VII GPU, and dual 4Kp60 HDMI display output.",
      "There are pre-orders available for this new model, with a price of $60 for the 4GB variant and $80 for the 8GB version.",
      "The announcement has prompted mixed reactions from users; some are excited regarding the new features and potential projects, while others raise concerns about the product's availability and cost differences. The Raspberry Pi team is addressing these issues through active communication."
    ],
    "commentSummary": [
      "The Raspberry Pi 5 is criticized for its absence of hardware video encoding, causing it to be less attractive when compared to alternatives like Banana Pi and Orange Pi 5.",
      "User dissatisfaction stems from the Raspberry Pi Foundation's focus on developing new models instead of enhancing affordability and availability of the existing ones, and its reliance on Broadcom with a call to consider Qualcomm instead.",
      "The lack of modern instructions and 64-bit support on the Pi Zero 2 W adds to the drawbacks, affecting the Raspberry Pi 5's market appeal."
    ],
    "points": 190,
    "commentCount": 102,
    "retryCount": 0,
    "time": 1698670028
  },
  {
    "id": 38064287,
    "title": "How deep is the brain? The shallow brain hypothesis",
    "originLink": "https://www.nature.com/articles/s41583-023-00756-z",
    "originBody": "Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Subscribe Sign up for alerts RSS feed nature nature reviews neuroscience perspectives article Perspective Published: 27 October 2023 How deep is the brain? The shallow brain hypothesis Mototaka Suzuki, Cyriel M. A. Pennartz & Jaan Aru Nature Reviews Neuroscience (2023)Cite this article 2683 Accesses 193 Altmetric Metrics details Abstract Deep learning and predictive coding architectures commonly assume that inference in neural networks is hierarchical. However, largely neglected in deep learning and predictive coding architectures is the neurobiological evidence that all hierarchical cortical areas, higher or lower, project to and receive signals directly from subcortical areas. Given these neuroanatomical facts, today’s dominance of cortico-centric, hierarchical architectures in deep learning and predictive coding networks is highly questionable; such architectures are likely to be missing essential computational principles the brain uses. In this Perspective, we present the shallow brain hypothesis: hierarchical cortical processing is integrated with a massively parallel process to which subcortical areas substantially contribute. This shallow architecture exploits the computational capacity of cortical microcircuits and thalamo-cortical loops that are not included in typical hierarchical deep learning and predictive coding networks. We argue that the shallow brain architecture provides several critical benefits over deep hierarchical structures and a more complete depiction of how mammalian brains achieve fast and flexible computational capabilities. This is a preview of subscription content, access via your institution Access options Access through your institution Access Nature and 54 other Nature Portfolio journals Get Nature+, our best-value online-access subscription $29.99 / 30 days cancel any time Learn more Subscribe to this journal Receive 12 print issues and online access $189.00 per year only $15.75 per issue Learn more Rent or buy this article Prices vary by article type from$1.95 to$39.95 Learn more Prices may be subject to local taxes which are calculated during checkout Additional access options: Log in Learn about institutional subscriptions Read our FAQs Contact customer support References Hegde, J. & Felleman, D. J. Reappraising the functional implications of the primate visual anatomical hierarchy. Neuroscientist 13, 416–421 (2007). Article PubMed Google Scholar LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015). Article CAS PubMed Google Scholar Stokel-Walker, C. & Van Noorden, R. What ChatGPT and generative AI mean for science. Nature 614, 214–216 (2023). Article CAS PubMed Google Scholar He, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 770–778 (2016). Russakovsky, O. et al. ImageNet large scale visual recognition challenge. Int. J. Comput. Vis. 115, 211–252 (2015). Article Google Scholar Xu, K. et al. Show, attend and tell: neural image caption generation with visual attention. In 32nd Int. Conf. on Machine Learning (eds F. Bach. & D. Blei) 2048–2057 (2015). Fukushima, K. Neocognitron—a self-organizing neural network model for a mechanism of pattern-recognition unaffected by shift in position. Biol. Cybern. 36, 193–202 (1980). Article CAS PubMed Google Scholar Hubel, D. H. & Wiesel, T. N. Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex. J. Physiol. 160, 106–154 (1962). Article CAS PubMed PubMed Central Google Scholar Chang, L. & Tsao, D. Y. The code for facial identity in the primate brain. Cell 169, 1013–1028.e14 (2017). Article CAS PubMed PubMed Central Google Scholar Yamins, D. L. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proc. Natl Acad. Sci. USA 111, 8619–8624 (2014). Article CAS PubMed PubMed Central Google Scholar Guclu, U. & van Gerven, M. A. Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. J. Neurosci. 35, 10005–10014 (2015). Article PubMed PubMed Central Google Scholar Cichy, R. M., Khosla, A., Pantazis, D., Torralba, A. & Oliva, A. Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence. Sci. Rep. 6, 27755 (2016). Article CAS PubMed PubMed Central Google Scholar Schrimpf, M. et al. The neural architecture of language: integrative modeling converges on predictive processing. Proc. Natl Acad. Sci. USA 118, e2015646118 (2021). Article Google Scholar Kriegeskorte, N. Deep neural networks: a new framework for modeling biological vision and brain information processing. Annu. Rev. Vis. Sci. 1, 417–446 (2015). Article PubMed Google Scholar Yamins, D. L. & DiCarlo, J. J. Using goal-driven deep learning models to understand sensory cortex. Nat. Neurosci. 19, 356–365 (2016). Article CAS PubMed Google Scholar Friston, K. A theory of cortical responses. Philos. Trans. R. Soc. Lond. B Biol. Sci. 360, 815–836 (2005). Article PubMed PubMed Central Google Scholar Rao, R. P. & Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999). Article CAS PubMed Google Scholar Lee, T. S. & Mumford, D. Hierarchical Bayesian inference in the visual cortex. J. Opt. Soc. Am. A Opt. Image Sci. Vis. 20, 1434–1448 (2003). Article PubMed Google Scholar Srinivasan, M. V., Laughlin, S. B. & Dubs, A. Predictive coding: a fresh view of inhibition in the retina. Proc. R. Soc. Lond. B Biol. Sci. 216, 427–459 (1982). Article CAS PubMed Google Scholar Dayan, P., Hinton, G. E., Neal, R. M. & Zemel, R. S. The Helmholtz machine. Neural Comput. 7, 889–904 (1995). Article CAS PubMed Google Scholar Dora, S., Bohte, S. M. & Pennartz, C. M. A. Deep gated Hebbian predictive coding accounts for emergence of complex neural response properties along the visual cortical hierarchy. Front. Comput. Neurosci. 15, 666131 (2021). Article PubMed PubMed Central Google Scholar McDermott, J. H., Wrobleski, D. & Oxenham, A. J. Recovering sound sources from embedded repetition. Proc. Natl Acad. Sci. USA 108, 1188–1193 (2011). Article CAS PubMed PubMed Central Google Scholar Mill, R. W., Bohm, T. M., Bendixen, A., Winkler, I. & Denham, S. L. Modelling the emergence and dynamics of perceptual organisation in auditory streaming. PLoS Comput. Biol. 9, e1002925 (2013). Article CAS PubMed PubMed Central Google Scholar Kanai, R., Komura, Y., Shipp, S. & Friston, K. Cerebral hierarchies: predictive processing, precision and the pulvinar. Philos. Trans. R. Soc. Lond. B Biol. Sci. 370, 20140169 (2015). Article PubMed PubMed Central Google Scholar Schwartenbeck, P., FitzGerald, T. H., Mathys, C., Dolan, R. & Friston, K. The dopaminergic midbrain encodes the expected certainty about desired outcomes. Cereb. Cortex 25, 3434–3445 (2015). Article PubMed Google Scholar Rikhye, R. V., Wimmer, R. D. & Halassa, M. M. Toward an integrative theory of thalamic function. Annu. Rev. Neurosci. 41, 163–183 (2018). Article CAS PubMed Google Scholar Felleman, D. J. & Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. Cereb. Cortex 1, 1–47 (1991). Article CAS PubMed Google Scholar Minsky, M. & Papert, S. Perceptrons; An Introduction to Computational Geometry (MIT Press, 1969). Gross, C. G., Rocha-Miranda, C. E. & Bender, D. B. Visual properties of neurons in inferotemporal cortex of the macaque. J. Neurophysiol. 35, 96–111 (1972). Article CAS PubMed Google Scholar Tsao, D. Y., Schweers, N., Moeller, S. & Freiwald, W. A. Patches of face-selective cortex in the macaque frontal lobe. Nat. Neurosci. 11, 877–879 (2008). Article CAS PubMed PubMed Central Google Scholar Hegde, J. & Van Essen, D. C. A comparative study of shape representation in macaque visual areas V2 and V4. Cereb. Cortex 17, 1100–1116 (2007). Article PubMed Google Scholar Rockland, K. S. & Pandya, D. N. Laminar origins and terminations of cortical connections of the occipital lobe in the rhesus monkey. Brain Res. 179, 3–20 (1979). Article CAS PubMed Google Scholar Markov, N. T. et al. Cortical high-density counterstream architectures. Science 342, 1238406 (2013). Article PubMed PubMed Central Google Scholar Markov, N. T. & Kennedy, H. The importance of being hierarchical. Curr. Opin. Neurobiol. 23, 187–194 (2013). Article CAS PubMed Google Scholar D’Souza, R. D. et al. Hierarchical and nonhierarchical features of the mouse visual cortical network. Nat. Commun. 13, 503 (2022). Article PubMed PubMed Central Google Scholar Siegle, J. H. et al. Survey of spiking in the mouse visual system reveals functional hierarchy. Nature 592, 86–92 (2021). Article CAS PubMed PubMed Central Google Scholar Nakamura, H., Gattass, R., Desimone, R. & Ungerleider, L. G. The modular organization of projections from areas V1 and V2 to areas V4 and TEO in macaques. J. Neurosci. 13, 3681–3691 (1993). Article CAS PubMed PubMed Central Google Scholar Burkhalter, A., D’Souza, R. D., Ji, W. & Meier, A. M. Integration of feedforward and feedback information streams in the modular architecture of mouse visual cortex. Annu. Rev. Neurosci. 46, 259–280 (2023). Article PubMed Google Scholar Coogan, T. A. & Burkhalter, A. Hierarchical organization of areas in rat visual cortex. J. Neurosci. 13, 3749–3772 (1993). Article CAS PubMed PubMed Central Google Scholar Friston, K. The free-energy principle: a unified brain theory? Nat. Rev. Neurosci. 11, 127–138 (2010). Article CAS PubMed Google Scholar Bastos, A. M. et al. Canonical microcircuits for predictive coding. Neuron 76, 695–711 (2012). Article CAS PubMed PubMed Central Google Scholar Pennartz, C. M. A., Dora, S., Muckli, L. & Lorteije, J. A. M. Towards a unified view on pathways and functions of neural recurrent processing. Trends Neurosci. 42, 589–603 (2019). Article CAS PubMed Google Scholar Findling, C. et al. Brain-wide representations of prior information in mouse decision-making. Preprint at bioRxiv https://doi.org/10.1101/2023.07.04.547684 (2023). Keller, G. B. & Mrsic-Flogel, T. D. Predictive processing: a canonical cortical computation. Neuron 100, 424–435 (2018). Article CAS PubMed PubMed Central Google Scholar Keller, G. B., Bonhoeffer, T. & Hubener, M. Sensorimotor mismatch signals in primary visual cortex of the behaving mouse. Neuron 74, 809–815 (2012). Article CAS PubMed Google Scholar Jordan, R. & Keller, G. B. Opposing influence of top-down and bottom-up input on excitatory layer 2/3 neurons in mouse primary visual cortex. Neuron 108, 1194–1206.e5 (2020). Article CAS PubMed PubMed Central Google Scholar Padamsey, Z. & Rochefort, N. L. Defying expectations: how neurons compute prediction errors in visual cortex. Neuron 108, 1016–1019 (2020). Article CAS PubMed Google Scholar Muzzu, T. & Saleem, A. B. Feature selectivity can explain mismatch signals in mouse visual cortex. Cell Rep. 37, 109772 (2021). Article CAS PubMed PubMed Central Google Scholar Walsh, K. S., McGovern, D. P., Clark, A. & O’Connell, R. G. Evaluating the neurophysiological evidence for predictive processing as a model of perception. Ann. N. Y. Acad. Sci. 1464, 242–268 (2020). Article PubMed PubMed Central Google Scholar Schwiedrzik, C. M. & Freiwald, W. A. High-level prediction signals in a low-level area of the macaque face-processing hierarchy. Neuron 96, 89–97.e4 (2017). Article CAS PubMed PubMed Central Google Scholar Issa, E. B., Cadieu, C. F. & DiCarlo, J. J. Neural dynamics at successive stages of the ventral visual stream are consistent with hierarchical error signals. eLife 7, e42870 (2018). Article PubMed PubMed Central Google Scholar Chao, Z. C., Takaura, K., Wang, L., Fujii, N. & Dehaene, S. Large-scale cortical networks for hierarchical prediction and prediction error in the primate brain. Neuron 100, 1252–1266.e3 (2018). Article CAS PubMed Google Scholar Spratling, M. W. A review of predictive coding algorithms. Brain Cogn. 112, 92–97 (2017). Article CAS PubMed Google Scholar Spratling, M. W. Fitting predictive coding to the neurophysiological data. Brain Res. 1720, 146313 (2019). Article CAS PubMed Google Scholar Bianchini, M. & Scarselli, F. On the complexity of neural network classifiers: a comparison between shallow and deep architectures. IEEE Trans. Neural Netw. Learn. Syst. 25, 1553–1565 (2014). Article PubMed Google Scholar Cohen, N., Sharir, O. & Shashua, A. On the expressive power of deep learning: a tensor analysis. In 29th Annual Conference on Learning Theory (eds. Feldman, V., Rakhlin, A. & Shamir, O.) 698–728 (2016). Hinton, G. E. Training products of experts by minimizing contrastive divergence. Neural Comput. 14, 1771–1800 (2002). Article PubMed Google Scholar Dabelow, L. & Ueda, M. Three learning stages and accuracy-efficiency tradeoff of restricted Boltzmann machines. Nat. Commun. 13, 5474 (2022). Article CAS PubMed PubMed Central Google Scholar Liao, R., Kornblith, S., Ren, M., Fleet, D. J. & Hinton, G. Gaussian–Bernoulli RBMs without tears. Preprint at arXiv https://doi.org/10.48550/ARXIV.2210.10318 (2022). Hilgetag, C. C. & Goulas, A. ‘Hierarchy’ in the organization of brain networks. Philos. Trans. R. Soc. Lond. B Biol. Sci. 375, 20190319 (2020). Article PubMed PubMed Central Google Scholar Sherman, S. M. & Guillery, R. W. Functional organization of thalamocortical relays. J. Neurophysiol. 76, 1367–1395 (1996). Article CAS PubMed Google Scholar Jones, E. G. The thalamic matrix and thalamocortical synchrony. Trends Neurosci. 24, 595–601 (2001). Article CAS PubMed Google Scholar Sherman, S. M. & Guillery, R. W. Exploring the Thalamus and Its Role in Cortical Function 2nd edn (MIT Press, 2009). Halassa, M. Thalamus 1st edn (Cambridge Univ. Press, 2023). Kemp, J. M. & Powell, T. P. The cortico-striate projection in the monkey. Brain 93, 525–546 (1970). Article CAS PubMed Google Scholar Oka, H. Organization of the cortico-caudate projections. A horseradish peroxidase study in the cat. Exp. Brain Res. 40, 203–208 (1980). Article CAS PubMed Google Scholar Ito, S. & Feldheim, D. A. The mouse superior colliculus: an emerging model for studying circuit formation and function. Front. Neural Circuits 12, 10 (2018). Article PubMed PubMed Central Google Scholar Basso, M. A. & May, P. J. Circuits for action and cognition: a view from the superior colliculus. Annu. Rev. Vis. Sci. 3, 197–226 (2017). Article PubMed PubMed Central Google Scholar May, P. J. The mammalian superior colliculus: laminar structure and connections. Prog. Brain Res. 151, 321–378 (2006). Article PubMed Google Scholar McBride, E. G. et al. Influence of claustrum on cortex varies by area, layer, and cell type. Neuron 111, 275–290.e5 (2022). Article PubMed Google Scholar Narikiyo, K. et al. The claustrum coordinates cortical slow-wave activity. Nat. Neurosci. 23, 741–753 (2020). Article CAS PubMed Google Scholar Jackson, J., Karnani, M. M., Zemelman, B. V., Burdakov, D. & Lee, A. K. Inhibitory control of prefrontal cortex by the claustrum. Neuron 99, 1029–1039.e4 (2018). Article CAS PubMed PubMed Central Google Scholar Legg, C. R., Mercier, B. & Glickstein, M. Corticopontine projection in the rat: the distribution of labelled cortical cells after large injections of horseradish peroxidase in the pontine nuclei. J. Comp. Neurol. 286, 427–441 (1989). Article CAS PubMed Google Scholar Habas, C. & Cabanis, E. A. Cortical projections to the human red nucleus: a diffusion tensor tractography study with a 1.5-T MRI machine. Neuroradiology 48, 755–762 (2006). Article PubMed Google Scholar Tervo, D. G. et al. A designer AAV variant permits efficient retrograde access to projection neurons. Neuron 92, 372–382 (2016). Article CAS PubMed PubMed Central Google Scholar Murakami, T., Matsui, T., Uemura, M. & Ohki, K. Modular strategy for development of the hierarchical visual network in mice. Nature 608, 578–585 (2022). Article CAS PubMed Google Scholar Tang, L. & Higley, M. J. Layer 5 circuits in V1 differentially control visuomotor behavior. Neuron 105, 346–354.e5 (2020). Article CAS PubMed Google Scholar Takahashi, N. et al. Active dendritic currents gate descending cortical outputs in perception. Nat. Neurosci. 23, 1277–1285 (2020). Article CAS PubMed Google Scholar Fuster, J. M. The Prefrontal Cortex: Anatomy, Physiology, and Neuropsychology of the Frontal Lobe (Raven, 1980). Miller, E. K. & Cohen, J. D. An integrative theory of prefrontal cortex function. Annu. Rev. Neurosci. 24, 167–202 (2001). Article CAS PubMed Google Scholar Oswald, M. J., Tantirigama, M. L., Sonntag, I., Hughes, S. M. & Empson, R. M. Diversity of layer 5 projection neurons in the mouse motor cortex. Front. Cell Neurosci. 7, 174 (2013). Article PubMed PubMed Central Google Scholar Akintunde, A. & Buxton, D. F. Origins and collateralization of corticospinal, corticopontine, corticorubral and corticostriatal tracts: a multiple retrograde fluorescent tracing study. Brain Res. 586, 208–218 (1992). Article CAS PubMed Google Scholar Harris, K. D. & Shepherd, G. M. The neocortical circuit: themes and variations. Nat. Neurosci. 18, 170–181 (2015). Article CAS PubMed PubMed Central Google Scholar Musall, S. et al. Pyramidal cell types drive functionally distinct cortical activity patterns during decision-making. Nat. Neurosci. 26, 495–505 (2023). CAS PubMed PubMed Central Google Scholar Mohan, H. et al. Cortical glutamatergic projection neuron types contribute to distinct functional subnetworks. Nat. Neurosci. 26, 481–494 (2023). CAS PubMed PubMed Central Google Scholar Kuramoto, E. et al. Ventral medial nucleus neurons send thalamocortical afferents more widely and more preferentially to layer 1 than neurons of the ventral anterior–ventral lateral nuclear complex in the rat. Cereb. Cortex 25, 221–235 (2015). Article PubMed Google Scholar Cruikshank, S. J. et al. Thalamic control of layer 1 circuits in prefrontal cortex. J. Neurosci. 32, 17813–17823 (2012). Article CAS PubMed PubMed Central Google Scholar Schroeder, A. et al. Inhibitory top-down projections from zona incerta mediate neocortical memory. Neuron 111, 727–738.e8 (2023). Article CAS PubMed Google Scholar Ahmadlou, M. et al. A cell type-specific cortico-subcortical brain circuit for investigatory and novelty-seeking behavior. Science 372, eabe9681 (2021). Article CAS PubMed Google Scholar Brenner, J. M., Beltramo, R., Gerfen, C. R., Ruediger, S. & Scanziani, M. A genetically defined tecto-thalamic pathway drives a system of superior-colliculus-dependent visual cortices. Neuron 111, 2247–2257.e7 (2023). Article CAS PubMed Google Scholar Guo, Z. V. et al. Maintenance of persistent activity in a frontal thalamocortical loop. Nature 545, 181–186 (2017). Article CAS PubMed PubMed Central Google Scholar Hsiao, K. et al. A thalamic orphan receptor drives variability in short-term memory. Cell 183, 522–536.e19 (2020). Article CAS PubMed PubMed Central Google Scholar Redinbaugh, M. J. et al. Thalamus modulates consciousness via layer-specific control of cortex. Neuron 106, 66–75.e12 (2020). Article CAS PubMed PubMed Central Google Scholar Aru, J., Suzuki, M. & Larkum, M. E. Cellular mechanisms of conscious processing. Trends Cogn. Sci. 24, 814–825 (2020). Article PubMed Google Scholar Aru, J., Suzuki, M., Rutiku, R., Larkum, M. E. & Bachmann, T. Coupling the state and contents of consciousness. Front. Syst. Neurosci. 13, 43 (2019). Article PubMed PubMed Central Google Scholar Suzuki, M. & Larkum, M. E. General anesthesia decouples cortical pyramidal neurons. Cell 180, 666–676.e13 (2020). Article CAS PubMed Google Scholar Schiff, N. D. et al. Behavioural improvements with thalamic stimulation after severe traumatic brain injury. Nature 448, 600–603 (2007). Article CAS PubMed Google Scholar Bastos, A. M. et al. Neural effects of propofol-induced unconsciousness and its reversal using thalamic stimulation. eLife 10, e60824 (2021). Article CAS PubMed PubMed Central Google Scholar Crick, F. C. & Koch, C. What is the function of the claustrum. Philos. Trans. R. Soc. Lond. B Biol. Sci. 360, 1271–1279 (2005). Article PubMed PubMed Central Google Scholar Chevee, M., Finkel, E. A., Kim, S. J., O’Connor, D. H. & Brown, S. P. Neural activity in the mouse claustrum in a cross-modal sensory selection task. Neuron 110, 486–501.e7 (2022). Article CAS PubMed Google Scholar Huang, W., Qin, J., Zhang, C., Qin, H. & Xie, P. Footshock-induced activation of the claustrum–entorhinal cortical pathway in freely moving mice. Physiol. Res. 71, 695–701 (2022). Article CAS PubMed PubMed Central Google Scholar Smythies, J. On the function of object cells in the claustrum—key components in information processing in the visual system? Front. Cell Neurosci. 9, 443 (2015). Article PubMed PubMed Central Google Scholar Tsumoto, T. & Suda, K. Effects of stimulation of the dorsocaudal claustrum on activities of striate cortex neurons in the cat. Brain Res. 240, 345–349 (1982). Article CAS PubMed Google Scholar Remedios, R., Logothetis, N. K. & Kayser, C. A role of the claustrum in auditory scene analysis by reflecting sensory change. Front. Syst. Neurosci. 8, 44 (2014). Article PubMed PubMed Central Google Scholar Qadir, H. et al. The mouse claustrum synaptically connects cortical network motifs. Cell Rep. 41, 111860 (2022). Article CAS PubMed PubMed Central Google Scholar Taylor, N. L. et al. Structural connections between the noradrenergic and cholinergic system shape the dynamics of functional brain networks. Neuroimage 260, 119455 (2022). Article CAS PubMed Google Scholar Deutch, A. Y. & Roth, R. H. in Fundamental Neuroscience (eds M. J. Zigmond et al.) 193–234 (Academic, 1999). Chevalier, G. & Deniau, J. M. Disinhibition as a basic process in the expression of striatal functions. Trends Neurosci. 13, 277–280 (1990). Article CAS PubMed Google Scholar Voorn, P., Vanderschuren, L. J., Groenewegen, H. J., Robbins, T. W. & Pennartz, C. M. Putting a spin on the dorsal–ventral divide of the striatum. Trends Neurosci. 27, 468–474 (2004). Article CAS PubMed Google Scholar Budinger, E., Heil, P., Hess, A. & Scheich, H. Multisensory processing via early cortical stages: connections of the primary auditory cortical field with other sensory systems. Neuroscience 143, 1065–1083 (2006). Article CAS PubMed Google Scholar Benavidez, N. L. et al. Organization of the inputs and outputs of the mouse superior colliculus. Nat. Commun. 12, 4004 (2021). Article CAS PubMed PubMed Central Google Scholar Beltramo, R. & Scanziani, M. A collicular visual cortex: neocortical space for an ancient midbrain visual structure. Science 363, 64–69 (2019). Article CAS PubMed Google Scholar Constantinople, C. M. & Bruno, R. M. Effects and mechanisms of wakefulness on local cortical networks. Neuron 69, 1061–1068 (2011). Article CAS PubMed PubMed Central Google Scholar Aru, J., Siclari, F., Phillips, W. A. & Storm, J. F. Apical drive—a cellular mechanism of dreaming? Neurosci. Biobehav. Rev. 119, 440–455 (2020). Article PubMed Google Scholar Wainstein, G., Muller, E. J., Taylor, N., Munn, B. & Shine, J. M. The role of the locus coeruleus in shaping adaptive cortical melodies. Trends Cogn. Sci. 26, 527–538 (2022). Article PubMed Google Scholar Polack, P. O., Friedman, J. & Golshani, P. Cellular mechanisms of brain state-dependent gain modulation in visual cortex. Nat. Neurosci. 16, 1331–1339 (2013). Article CAS PubMed PubMed Central Google Scholar Harris, K. D. & Thiele, A. Cortical state and attention. Nat. Rev. Neurosci. 12, 509–523 (2011). Article CAS PubMed PubMed Central Google Scholar Parikh, V., Kozak, R., Martinez, V. & Sarter, M. Prefrontal acetylcholine release controls cue detection on multiple timescales. Neuron 56, 141–154 (2007). Article CAS PubMed PubMed Central Google Scholar Puig, M. V. & Gulledge, A. T. Serotonin and prefrontal cortex function: neurons, networks, and circuits. Mol. Neurobiol. 44, 449–464 (2011). Article CAS PubMed PubMed Central Google Scholar Buhot, M. C., Martin, S. & Segu, L. Role of serotonin in memory impairment. Ann. Med. 32, 210–221 (2000). Article CAS PubMed Google Scholar Petroni, F., Panzeri, S., Hilgetag, C. C., Kotter, R. & Young, M. P. Simultaneity of responses in a hierarchical visual network. Neuroreport 12, 2753–2759 (2001). Article CAS PubMed Google Scholar Zeki, S. The rough seas of cortical cartography. Trends Neurosci. 41, 242–244 (2018). Article CAS PubMed Google Scholar Silvanto, J. Why is “blindsight” blind? A new perspective on primary visual cortex, recurrent activity and visual awareness. Conscious. Cogn. 32, 15–32 (2015). Article PubMed Google Scholar Schmolesky, M. T. et al. Signal timing across the macaque visual system. J. Neurophysiol. 79, 3272–3278 (1998). Article CAS PubMed Google Scholar Bullier, J. & Nowak, L. G. Parallel versus serial processing: new vistas on the distributed organization of the visual system. Curr. Opin. Neurobiol. 5, 497–503 (1995). Article CAS PubMed Google Scholar Douglas, R. J. & Martin, K. A. Mapping the matrix: the ways of neocortex. Neuron 56, 226–238 (2007). Article CAS PubMed Google Scholar Rockland, K. S. & Ichinohe, N. Some thoughts on cortical minicolumns. Exp. Brain Res. 158, 265–277 (2004). Article PubMed Google Scholar Molnár, Z. & Rockland, K. S. in Neural Circuit and Cognitive Development Ch. 5 (eds J. Rubenstein, P. Rakic, B. Chen & K. Y. Kwan) 103–126 (Academic, 2020). Trojanowski, J. Q. & Jacobson, S. Medial pulvinar afferents to frontal eye fields in rhesus monkey demonstrated by horseradish peroxidase. Brain Res. 80, 395–411 (1974). Article CAS PubMed Google Scholar Baizer, J. S., Desimone, R. & Ungerleider, L. G. Comparison of subcortical connections of inferior temporal and posterior parietal cortex in monkeys. Vis. Neurosci. 10, 59–72 (1993). Article CAS PubMed Google Scholar Stanton, G. B., Goldberg, M. E. & Bruce, C. J. Frontal eye field efferents in the macaque monkey: I. Subcortical pathways and topography of striatal and thalamic terminal fields. J. Comp. Neurol. 271, 473–492 (1988). Article CAS PubMed Google Scholar Lynch, J. C., Hoover, J. E. & Strick, P. L. Input to the primate frontal eye field from the substantia nigra, superior colliculus, and dentate nucleus demonstrated by transneuronal transport. Exp. Brain Res. 100, 181–186 (1994). Article CAS PubMed Google Scholar Berman, R. A. & Wurtz, R. H. Exploring the pulvinar path to visual cortex. Prog. Brain Res. 171, 467–473 (2008). Article PubMed PubMed Central Google Scholar Huerta, M. F., Krubitzer, L. A. & Kaas, J. H. Frontal eye field as defined by intracortical microstimulation in squirrel monkeys, owl monkeys, and macaque monkeys: I. Subcortical connections. J. Comp. Neurol. 253, 415–439 (1986). Article CAS PubMed Google Scholar Leichnetz, G. R., Smith, D. J. & Spencer, R. F. Cortical projections to the paramedian tegmental and basilar pons in the monkey. J. Comp. Neurol. 228, 388–408 (1984). Article CAS PubMed Google Scholar Andersen, R. A., Asanuma, C., Essick, G. & Siegel, R. M. Corticocortical connections of anatomically and physiologically defined subdivisions within the inferior parietal lobule. J. Comp. Neurol. 296, 65–113 (1990). Article CAS PubMed Google Scholar Lynch, J. C., Graybiel, A. M. & Lobeck, L. J. The differential projection of two cytoarchitectonic subregions of the inferior parietal lobule of macaque upon the deep layers of the superior colliculus. J. Comp. Neurol. 235, 241–254 (1985). Article CAS PubMed Google Scholar Schall, J. D., Morel, A., King, D. J. & Bullier, J. Topography of visual cortex connections with frontal eye field in macaque: convergence and segregation of processing streams. J. Neurosci. 15, 4464–4487 (1995). Article CAS PubMed PubMed Central Google Scholar Vernet, M., Quentin, R., Chanes, L., Mitsumasu, A. & Valero-Cabre, A. Frontal eye field, where art thou? Anatomy, function, and non-invasive manipulation of frontal regions involved in eye movements and associated cognitive operations. Front. Integr. Neurosci. 8, 66 (2014). PubMed PubMed Central Google Scholar Liu, Y., Yttri, E. A. & Snyder, L. H. Intention and attention: different functional roles for LIPd and LIPv. Nat. Neurosci. 13, 495–500 (2010). Article CAS PubMed PubMed Central Google Scholar Coe, B. C. & Munoz, D. P. Mechanisms of saccade suppression revealed in the anti-saccade task. Philos. Trans. R. Soc. Lond. B Biol. Sci. 372, 20160192 (2017). Article PubMed PubMed Central Google Scholar Milardi, D. et al. Red nucleus connectivity as revealed by constrained spherical deconvolution tractography. Neurosci. Lett. 626, 68–73 (2016). Article CAS PubMed Google Scholar Na, J., Kakei, S. & Shinoda, Y. Cerebellar input to corticothalamic neurons in layers V and VI in the motor cortex. Neurosci. Res. 28, 77–91 (1997). Article CAS PubMed Google Scholar Martinez-Gonzalez, C., Bolam, J. P. & Mena-Segovia, J. Topographical organization of the pedunculopontine nucleus. Front. Neuroanat. 5, 22 (2011). Article PubMed PubMed Central Google Scholar Sherman, S. M. & Guillery, R. W. Distinct functions for direct and transthalamic corticocortical connections. J. Neurophysiol. 106, 1068–1077 (2011). Article PubMed Google Scholar de Kock, C. P., Bruno, R. M., Spors, H. & Sakmann, B. Layer- and cell-type-specific suprathreshold stimulus representation in rat primary somatosensory cortex. J. Physiol. 581, 139–154 (2007). Article PubMed PubMed Central Google Scholar Masamizu, Y. et al. Two distinct layer-specific dynamics of cortical ensembles during learning of a motor task. Nat. Neurosci. 17, 987–994 (2014). Article CAS PubMed Google Scholar Guo, K., Yamawaki, N., Svoboda, K. & Shepherd, G. M. G. Anterolateral motor cortex connects with a medial subdivision of ventromedial thalamus through cell type-specific circuits, forming an excitatory thalamo-cortico-thalamic loop via layer 1 apical tuft dendrites of layer 5b pyramidal tract type neurons. J. Neurosci. 38, 8787–8797 (2018). Article CAS PubMed PubMed Central Google Scholar Bharioke, A. et al. General anesthesia globally synchronizes activity selectively in layer 5 cortical pyramidal neurons. Neuron 110, 2024–2040.e10 (2022). Article CAS PubMed PubMed Central Google Scholar Larkum, M. A cellular mechanism for cortical associations: an organizing principle for the cerebral cortex. Trends Neurosci. 36, 141–151 (2013). Article CAS PubMed Google Scholar Brea, J., Gaal, A. T., Urbanczik, R. & Senn, W. Prospective coding by spiking neurons. PLoS Comput. Biol. 12, e1005003 (2016). Article PubMed PubMed Central Google Scholar Roelfsema, P. R. & Holtmaat, A. Control of synaptic plasticity in deep cortical networks. Nat. Rev. Neurosci. 19, 166–180 (2018). Article CAS PubMed Google Scholar Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. & Hinton, G. Backpropagation and the brain. Nat. Rev. Neurosci. 21, 335–346 (2020). Article CAS PubMed Google Scholar Whittington, J. C. R. & Bogacz, R. Theories of error back-propagation in the brain. Trends Cogn. Sci. 23, 235–250 (2019). Article PubMed PubMed Central Google Scholar Xiong, Q., Znamenskiy, P. & Zador, A. M. Selective corticostriatal plasticity during acquisition of an auditory discrimination task. Nature 521, 348–351 (2015). Article CAS PubMed PubMed Central Google Scholar Cox, J. & Witten, I. B. Striatal circuits for reward learning and decision-making. Nat. Rev. Neurosci. 20, 482–494 (2019). Article CAS PubMed PubMed Central Google Scholar Park, J. M. et al. Deep and superficial layers of the primary somatosensory cortex are critical for whisker-based texture discrimination in mice. Preprint at bioRxiv https://doi.org/10.1101/2020.08.12.245381 (2022). Hong, Y. K., Lacefield, C. O., Rodgers, C. C. & Bruno, R. M. Sensation, movement and learning in the absence of barrel cortex. Nature 561, 542–546 (2018). Article CAS PubMed PubMed Central Google Scholar Von Neumann, J. The Computer and the Brain (Yale Univ. Press, 1958). Mo, C. & Sherman, S. M. A sensorimotor pathway via higher-order thalamus. J. Neurosci. 39, 692–704 (2019). Article CAS PubMed PubMed Central Google Scholar Lake, B. M., Ullman, T. D., Tenenbaum, J. B. & Gershman, S. J. Building machines that learn and think like people. Behav. Brain Sci. 40, e253 (2017). Article PubMed Google Scholar Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. Philos. Trans. R. Soc. Lond. B Biol. Sci. 375, 20190307 (2020). Article PubMed Google Scholar Ruediger, S. & Scanziani, M. Learning speed and detection sensitivity controlled by distinct cortico-fugal neurons in visual cortex. eLife 9, e59247 (2020). Article CAS PubMed PubMed Central Google Scholar Brooks, R. A. A robust layered control-system for a mobile robot. IEEE T Robotic Autom. 2, 14–23 (1986). Article Google Scholar Brooks, R. A. New approaches to robotics. Science 253, 1227–1232 (1991). Article CAS PubMed Google Scholar Haider, P., Ellenberger, B., Kriener, L., Jordan, J., Senn, W. & Petrovici, M. A. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. Adv. Neural Inf. Process. Syst. 34, 17839–17851 (2021). Google Scholar Narayanan, R. T. et al. Beyond columnar organization: cell type- and target layer-specific principles of horizontal axon projection patterns in rat vibrissal cortex. Cereb. Cortex 25, 4450–4468 (2015). Article PubMed PubMed Central Google Scholar Chen, G., Scherr, F. & Maass, W. A data-based large-scale model for primary visual cortex enables brain-like robust and versatile visual processing. Sci. Adv. 8, eabq7592 (2022). Article PubMed PubMed Central Google Scholar Guest, J. M., Bast, A., Narayanan, R. T. & Oberlaender, M. Thalamus gates active dendritic computations in cortex during sensory processing. Preprint at bioRxiv https://doi.org/10.1101/2021.10.21.465325 (2021). Constantinople, C. M. & Bruno, R. M. Deep cortical layers are activated directly by thalamus. Science 340, 1591–1594 (2013). Article CAS PubMed PubMed Central Google Scholar Pluta, S. et al. A direct translaminar inhibitory circuit tunes cortical output. Nat. Neurosci. 18, 1631–1640 (2015). Article CAS PubMed PubMed Central Google Scholar Stuart, G., Spruston, N. & Häusser, M. Dendrites 3rd edn (Oxford Univ. Press, 2016). Major, G., Larkum, M. E. & Schiller, J. Active properties of neocortical pyramidal neuron dendrites. Annu. Rev. Neurosci. 36, 1–24 (2013). Article CAS PubMed Google Scholar Mikulasch, F. A., Rudelt, L., Wibral, M. & Priesemann, V. Where is the error? Hierarchical predictive coding through dendritic error computation. Trends Neurosci. 46, 45–59 (2022). Article PubMed Google Scholar Richards, B. A. & Lillicrap, T. P. Dendritic solutions to the credit assignment problem. Curr. Opin. Neurobiol. 54, 28–36 (2019). Article CAS PubMed Google Scholar Guerguiev, J., Lillicrap, T. P. & Richards, B. A. Towards deep learning with segregated dendrites. eLife 6, e22901 (2017). Article PubMed PubMed Central Google Scholar Hawkins, J. & Ahmad, S. Why neurons have thousands of synapses, a theory of sequence memory in neocortex. Front. Neural Circuits 10, 23 (2016). Article PubMed PubMed Central Google Scholar Schiess, M., Urbanczik, R. & Senn, W. Somato-dendritic synaptic plasticity and error-backpropagation in active dendrites. PLoS Comput. Biol. 12, e1004638 (2016). Article PubMed PubMed Central Google Scholar Poirazi, P. & Papoutsi, A. Illuminating dendritic function with computational models. Nat. Rev. Neurosci. 21, 303–321 (2020). Article CAS PubMed Google Scholar Beniaguev, D., Segev, I. & London, M. Single cortical neurons as deep artificial neural networks. Neuron 109, 2727–2739.e3 (2021). Article CAS PubMed Google Scholar Cossell, L. et al. Functional organization of excitatory synaptic strength in primary visual cortex. Nature 518, 399–403 (2015). Article CAS PubMed PubMed Central Google Scholar Seeman, S. C. et al. Sparse recurrent excitatory connectivity in the microcircuit of the adult mouse and human cortex. eLife 7, e37349 (2018). Article PubMed PubMed Central Google Scholar Garner, A. R. & Keller, G. B. A cortical circuit for audio-visual predictions. Nat. Neurosci. 25, 98–105 (2022). Article CAS PubMed Google Scholar Ghazanfar, A. A. & Schroeder, C. E. Is neocortex essentially multisensory? Trends Cogn. Sci. 10, 278–285 (2006). Article PubMed Google Scholar Fetsch, C. R., DeAngelis, G. C. & Angelaki, D. E. Bridging the gap between theories of sensory cue integration and the physiology of multisensory neurons. Nat. Rev. Neurosci. 14, 429–442 (2013). Article CAS PubMed Google Scholar Graybiel, A. M. The basal ganglia. Curr. Biol. 10, R509–R511 (2000). Article CAS PubMed Google Scholar Alexander, G. E., DeLong, M. R. & Strick, P. L. Parallel organization of functionally segregated circuits linking basal ganglia and cortex. Annu. Rev. Neurosci. 9, 357–381 (1986). Article CAS PubMed Google Scholar Parent, A. et al. Organization of the basal ganglia: the importance of axonal collateralization. Trends Neurosci. 23, S20–S27 (2000). Article CAS PubMed Google Scholar Takakusaki, K., Saitoh, K., Harada, H. & Kashiwayanagi, M. Role of basal ganglia–brainstem pathways in the control of motor behaviors. Neurosci. Res. 50, 137–151 (2004). Article CAS PubMed Google Scholar Graybiel, A. M., Aosaki, T., Flaherty, A. W. & Kimura, M. The basal ganglia and adaptive motor control. Science 265, 1826–1831 (1994). Article CAS PubMed Google Scholar Roseberry, T. K. et al. Cell-type-specific control of brainstem locomotor circuits by basal ganglia. Cell 164, 526–537 (2016). Article CAS PubMed PubMed Central Google Scholar Parent, M., Levesque, M. & Parent, A. Two types of projection neurons in the internal pallidum of primates: single-axon tracing and three-dimensional reconstruction. J. Comp. Neurol. 439, 162–175 (2001). Article CAS PubMed Google Scholar Parent, M. & Parent, A. The pallidofugal motor fiber system in primates. Parkinsonism Relat. Disord. 10, 203–211 (2004). Article PubMed Google Scholar Pennartz, C. M., Groenewegen, H. J. & Lopes da Silva, F. H. The nucleus accumbens as a complex of functionally distinct neuronal ensembles: an integration of behavioural, electrophysiological and anatomical data. Prog. Neurobiol. 42, 719–761 (1994). Article CAS PubMed Google Scholar Di Chiara, G., Porceddu, M. L., Morelli, M., Mulas, M. L. & Gessa, G. L. Evidence for a GABAergic projection from the substantia nigra to the ventromedial thalamus and to the superior colliculus of the rat. Brain Res. 176, 273–284 (1979). Article PubMed Google Scholar Williams, L. E. & Holtmaat, A. Higher-order thalamocortical inputs gate synaptic long-term potentiation via disinhibition. Neuron 101, 91–102.e4 (2019). Article CAS PubMed Google Scholar Gambino, F. et al. Sensory-evoked LTP driven by dendritic plateau potentials in vivo. Nature 515, 116–119 (2014). Article CAS PubMed Google Scholar Anastasiades, P. G., Collins, D. P. & Carter, A. G. Mediodorsal and ventromedial thalamus engage distinct L1 circuits in the prefrontal cortex. Neuron 109, 314–330.e4 (2021). Article CAS PubMed Google Scholar Schmitt, L. I. et al. Thalamic amplification of cortical connectivity sustains attentional control. Nature 545, 219–223 (2017). Article CAS PubMed PubMed Central Google Scholar Inagaki, H. K. et al. A midbrain–thalamus–cortex circuit reorganizes cortical dynamics to initiate movement. Cell 185, 1065–1081.e23 (2022). Article CAS PubMed PubMed Central Google Scholar Wang, M. B. & Halassa, M. M. Thalamocortical contribution to flexible learning in neural systems. Netw. Neurosci. 6, 980–997 (2022). Article PubMed PubMed Central Google Scholar La Terra, D. et al. The role of higher-order thalamus during learning and correct performance in goal-directed behavior. eLife 11, e77177 (2022). Article PubMed PubMed Central Google Scholar Ruis, L., Andreas, J., Baroni, M., Bouchacourt, D. & Lake, B. M. A benchmark for systematic generalization in grounded language understanding. In Proc. 34th Int. Conf. Neural Information Processing Systems (eds. Larochelle, H. et al.) 19861–19872 (Curran, 2020). Lake, B. M. & Baroni, M. Generalization without systematicity: on the compositional skills of sequence-to-sequence recurrent networks. In Int. Conf. Machine Learning (eds. Dy, J. & Krause, A.) 2879–2888 (2018). Pfeiffer, J., Ruder, S., Vulić, I. & Ponti, E. M. Modular deep learning. Preprint at arXiv https://doi.org/10.48550/arXiv.2302.11529 (2023). Goyal, A. et al. Recurrent independent mechanisms. Preprint at arXiv https://doi.org/10.48550/arXiv.1909.10893 (2020). Albright, T. D., Jessell, T. M., Kandel, E. R. & Posner, M. I. Neural science: a century of progress and the mysteries that remain. Neuron 25, S1–S55 (2000). Article PubMed Google Scholar Wallis, J. D., Anderson, K. C. & Miller, E. K. Single neurons in prefrontal cortex encode abstract rules. Nature 411, 953–956 (2001). Article CAS PubMed Google Scholar Verschure, P. F., Pennartz, C. M. & Pezzulo, G. The why, what, where, when and how of goal-directed choice: neuronal and computational principles. Philos. Trans. R. Soc. Lond. B Biol. Sci. 369, 20130483 (2014). Article PubMed PubMed Central Google Scholar Dias, R., Robbins, T. W. & Roberts, A. C. Dissociation in prefrontal cortex of affective and attentional shifts. Nature 380, 69–72 (1996). Article CAS PubMed Google Scholar Wilson, R. C., Takahashi, Y. K., Schoenbaum, G. & Niv, Y. Orbitofrontal cortex as a cognitive map of task space. Neuron 81, 267–279 (2014). Article CAS PubMed PubMed Central Google Scholar Fan, J., McCandliss, B. D., Fossella, J., Flombaum, J. I. & Posner, M. I. The activation of attentional networks. Neuroimage 26, 471–479 (2005). Article PubMed Google Scholar Womelsdorf, T. & Everling, S. Long-range attention networks: circuit motifs underlying endogenously controlled stimulus selection. Trends Neurosci. 38, 682–700 (2015). Article CAS PubMed Google Scholar Cohen, M. R. & Maunsell, J. H. Attention improves performance primarily by reducing interneuronal correlations. Nat. Neurosci. 12, 1594–1600 (2009). Article CAS PubMed PubMed Central Google Scholar Reynolds, J. H. & Desimone, R. Interacting roles of attention and visual salience in V4. Neuron 37, 853–863 (2003). Article CAS PubMed Google Scholar Poort, J. et al. The role of attention in figure-ground segregation in areas V1 and V4 of the visual cortex. Neuron 75, 143–156 (2012). Article CAS PubMed Google Scholar Reep, R. L. & Corwin, J. V. Posterior parietal cortex as part of a neural network for directed attention in rats. Neurobiol. Learn. Mem. 91, 104–113 (2009). Article PubMed Google Scholar Saalmann, Y. B., Pinsk, M. A., Wang, L., Li, X. & Kastner, S. The pulvinar regulates information transmission between cortical areas based on attention demands. Science 337, 753–756 (2012). Article CAS PubMed PubMed Central Google Scholar Rikhye, R. V., Gilra, A. & Halassa, M. M. Thalamic regulation of switching between cortical representations enables cognitive flexibility. Nat. Neurosci. 21, 1753–1763 (2018). Article CAS PubMed PubMed Central Google Scholar Van der Werf, Y. D., Witter, M. P. & Groenewegen, H. J. The intralaminar and midline nuclei of the thalamus. Anatomical and functional evidence for participation in processes of arousal and awareness. Brain Res. Brain Res. Rev. 39, 107–140 (2002). Article PubMed Google Scholar Groenewegen, H. J. & Berendse, H. W. The specificity of the ‘nonspecific’ midline and intralaminar thalamic nuclei. Trends Neurosci. 17, 52–57 (1994). Article CAS PubMed Google Scholar Breton-Provencher, V., Drummond, G. T., Feng, J., Li, Y. & Sur, M. Spatiotemporal dynamics of noradrenaline during learned behaviour. Nature 606, 732–738 (2022). Article CAS PubMed PubMed Central Google Scholar Ren, J. et al. Anatomically defined and functionally distinct dorsal raphe serotonin sub-systems. Cell 175, 472–487.e20 (2018). Article CAS PubMed PubMed Central Google Scholar Lohani, S. et al. Spatiotemporally heterogeneous coordination of cholinergic and neocortical activity. Nat. Neurosci. 25, 1706–1713 (2022). Article CAS PubMed Google Scholar Morris, L. S. et al. Fronto-striatal organization: defining functional and microstructural substrates of behavioural flexibility. Cortex 74, 118–133 (2016). Article PubMed PubMed Central Google Scholar Apicella, P., Legallet, E., Nieoullon, A. & Trouche, E. Neglect of contralateral visual stimuli in monkeys with unilateral striatal dopamine depletion. Behav. Brain Res. 46, 187–195 (1991). Article CAS PubMed Google Scholar Download references Acknowledgements M.S. discloses support for the research of this work from the Brain Science Foundation and the Sumitomo Foundation (2200084). C.M.A.P. discloses support for the research of this work from the European Union’s Horizon 2020 Framework Program for Research and Innovation (Human Brain Project SGA3, 945539). J.A. discloses support for the research of this work from the European Social Fund through the ‘ICT programme’ measure and the Estonian Research Council grant (PSG728). Author information Authors and Affiliations Department of Cognitive and Systems Neuroscience, Swammerdam Institute for Life Sciences, University of Amsterdam, Amsterdam, The Netherlands Mototaka Suzuki & Cyriel M. A. Pennartz Institute of Computer Science, University of Tartu, Tartu, Estonia Jaan Aru Contributions The authors contributed equally to all aspects of the article. Corresponding authors Correspondence to Mototaka Suzuki or Jaan Aru. Ethics declarations Competing interests The authors declare no competing interests. Peer review Peer review information Nature Reviews Neuroscience thanks Andreas Burkhalter and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Additional information Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Glossary Bayesian inference A method of statistical analysis that is grounded in Bayes’ theorem, which describes how the probability of a hypothesis (posterior probability) is updated as new data (evidence) become available, given prior knowledge about the hypothesis (prior probability). Cortico-cortical loops Neural circuits that connect different regions of the cerebral cortex to one another, allowing communication and integration of information across various cortical areas. These loops can be either short range, connecting adjacent or nearby cortical regions, or long range, linking distant regions of the cortex. Deep hierarchy A hierarchical structure consisting of many layers (roughly analogous to cortical areas) through which information from the external world is processed step by step. Deep learning architectures Structured configurations of hierarchical, interconnected layers of artificial neurons, or nodes, in a neural network. Common types of deep learning architecture include feedforward convolutional neural networks and recurrent neural networks. Hierarchical inference The process of drawing conclusions from data wherein parameters are organized into different levels or layers. In hierarchical Bayesian inference, Bayesian statistics are employed within a layered framework, integrating prior knowledge at multiple levels to refine posterior distributions. Higher-order thalamic nuclei Thalamic nuclei can be categorized anatomically into first-order and higher-order nuclei. First-order nuclei receive driving afferents from ascending pathways, whereas the higher-order nuclei receive driving afferents from cortical layer 5 pyramidal (L5p) neurons. Notable examples of higher-order thalamic nuclei include the pulvinar and the medial dorsal nucleus. Non-hierarchical lateral connections Connections made between two cortical areas that are not distinguished hierarchically (for instance, primary auditory and visual cortex). This connectivity pattern is illustrated in Fig. 1b. Recurrent connections Connections in which the output of a neuron at a given layer is fed back as an input to either the same layer or a previous layer. This creates a loop in the network, allowing information, for instance, to persist and be reused across sequential steps. Recurrent neural network A class of neural networks in which connections between nodes form directed cycles, enabling the retention of information from previous inputs. This sequential memory feature makes recurrent neural networks suitable for tasks involving time-series or sequential data. Reinforcement learning A machine learning method in which an agent makes decisions and receives reinforcing feedback to train the network to improve its output (for example, reward for desired behaviours, punishment for behaviour resulting in undesirable output). Shallow architectures Architectures that do not consist of a deep hierarchy. Shallow architectures instead have a minimum number of layers. Shallow processing Computations carried out by a shallow architecture, namely in a few steps instead of tens or hundreds of layers of processing. Thalamo-cortical loops Bidirectional pathways between the thalamus and the cerebral cortex. Thalamo-cortical loops play a vital role in the regulation of consciousness, attention and sensory processing, and have been implicated in several neurological and psychiatric disorders. Trans-thalamic connections Connections made between two brain regions via the thalamus. Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and Permissions About this article Cite this article Suzuki, M., Pennartz, C.M.A. & Aru, J. How deep is the brain? The shallow brain hypothesis. Nat. Rev. Neurosci. (2023). https://doi.org/10.1038/s41583-023-00756-z Download citation Accepted 25 September 2023 Published 27 October 2023 DOI https://doi.org/10.1038/s41583-023-00756-z Subjects Computational neuroscience Neural circuits Neurophysiology Sensorimotor processing Access through your institution Buy or subscribe Sections Figures References Abstract References Acknowledgements Author information Ethics declarations Peer review Additional information Glossary Rights and permissions About this article Advertisement Nature Reviews Neuroscience (Nat. Rev. Neurosci.) ISSN 1471-0048 (online) ISSN 1471-003X (print) nature.com sitemap About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Nano Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Live Expert Trainer-led workshops Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Career development Nature Careers Nature Conferences Nature events Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights © 2023 Springer Nature Limited",
    "commentLink": "https://news.ycombinator.com/item?id=38064287",
    "commentBody": "How deep is the brain? The shallow brain hypothesisHacker NewspastloginHow deep is the brain? The shallow brain hypothesis (nature.com) 182 points by vapemaster 16 hours ago| hidepastfavorite158 comments audunw 5 hours agoI seem to remember research stating that an individual neuron has very complex behaviour that requires several ML “neurons” &#x2F; nodes to simulate. So if you do a comparison, perhaps the brain is deeper than you’d think by just looking at the graph of neurons and their synapses.Could we construct a neutral net from nodes with more complex behaviour? Probably, but in computing we’ve generally found that it’s best to build up a system from simple building blocks. So what if it takes many ML nodes to simulate a neuron? That’s probably an efficient way to do it. Especially in the early phase where we’re not quite sure which architecture is the best. It’s easier to experiment with various neural net architectures when the building blocks are simple. reply rmorey 2 hours agoparent> I seem to remember research stating that an individual neuron has very complex behaviour that requires several ML “neurons” &#x2F; nodes to simulate.This is probably what you&#x27;re remembering: https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S089662732... reply magicalhippo 2 hours agoparentprev> Could we construct a neutral net from nodes with more complex behaviour?Well there&#x27;s spiking neural networks (SNN)[1], which are modeled more closely to how neurons actually work.Main obstacle is still, as far as I know, that there&#x27;s no way to train a SSN as efficiently as a \"regular\" neural network, which lends itself very nicely to gradient descent and similar[2].[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Spiking_neural_network[2]: https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC9313413&#x2F; reply rsrsrs86 1 hour agoparentprevThe brain backprops?????? reply chriskanan 5 hours agoprevThe brain has a lot of skip connections and is massively recurrent. In a sense, the brain can be thought of as having infinite depth due to recurrent thalamno-cortical loops. They do mention thalamno-cortical loops in the paper, so I think a more concrete definition of what is meant by \"depth\" would be helpful. reply lausbub 3 hours agoparentThe \"infinite depth\" seems to be a matter of definition. It&#x27;s practically infinite if you include feedback loops via learning. If you exclude learning, then it&#x27;s far from \"infinite\". Activations linger for up to 15-30 seconds, so at oscillations of around 30 Hz that would result in about 450-900 loops (times an unknown small multiplier for the actual number of layers). But the brain presumably only backprops&#x2F;optimizes a few layers at a time and not much \"through\" time. reply lawrenceyan 1 hour agoprevWe have skip connections and recurrent neural networks at home. reply rsrsrs86 1 hour agoprevBeyond the mere topological metaphor of neural networks there is almost nothing in common between brains and widigital computation. This is a widespread fallacy of category. reply epgui 1 hour agoparentI completely disagree, and I think this is an example of human-exceptionalism bias. reply sheeshkebab 15 hours agoprevIt’s indeed odd that current dnn’s require massive amount of energy to retrain and lack any kind of practical continuous adaptation and learning. reply quickthrower2 15 hours agoparentWith computer-based intelligence we have the overhead of computing every bit though (probably) inefficient silicon and direct electric currents. The brain leverages the properties of chemicals, though millions of years of evolution. reply jakobson14 15 hours agorootparentThe brain isn&#x27;t a faster computer.An infinitely-fast computer wouldn&#x27;t meaningfully change the \"expensive training vs fast, static inference\" workflow that neural networks have always been developed around (except in the most brute force-y \"retrain on the entire world, every single nanosecond\" sense). reply quickthrower2 14 hours agorootparentI think we agree? I am talking to the efficiency of the brain. Not processing speed. Efficiency of the brain to do things advantageous to the selfish genes I guess.The brain is supremely efficient at what the brain has evolved to do. It is almost tautological! Because if it wasn&#x27;t, it wouldn&#x27;t have evolved to that.Silicon comes from an alien land, and is emulating. Even with the best algorithms there has to be a limit on how efficient a computer-based intelligence can be without changing how the chips work.You could spin it around and say, well computers are better at many things than humans, and there is no way you could get a biological brain to be as good for the same amount of power (e.g. a raspberry pi can do calculations our brain couldn&#x27;t possibly do). reply DiggyJohnson 14 hours agorootparentReally well said, I think this is an excellent way to frame the dichotomy (comparison?).Much of these threads make the binary mistake: can these systems be compared, or are they fundamentally different? A bit of both, almost certainly. reply cortesoft 12 hours agorootparentprev> The brain is supremely efficient at what the brain has evolved to do. It is almost tautological! Because if it wasn&#x27;t, it wouldn&#x27;t have evolved to that.Not really, evolution doesn&#x27;t guarantee the brain will be supremely efficient. It just guarantees that it will be efficient ENOUGH. reply edgyquant 2 hours agorootparentAgain, it is efficient at what it does. reply PaulDavisThe1st 12 hours agorootparentprev> The brain is supremely efficient at what the brain has evolved to do. It is almost tautological! Because if it wasn&#x27;t, it wouldn&#x27;t have evolved to that.This echoes an extremely naive view of evolution.There are many phenotypes in the living world which have evolved but for which there is no reason to believe that the phenotype is either (a) supremely efficient and&#x2F;or (b) under selection pressure (the two are obviously related).Evolution has no tautology. Brains do not evolve to be supremely efficient, just like humans do not evolve to be supremely efficient.What exists today is that which has survived, for whatever reason. It&#x27;s not even possible to say something as apparently simplistic as \"the only purpose evolution respects is leaving behind more copies\" because that ignores (a) group selection (b) changing ecosystems that favor plasticity in the long run. reply cycomanic 10 hours agorootparent> There are many phenotypes in the living world which have evolved but for which there is no reason to believe that the phenotype is either (a) supremely efficient and&#x2F;or (b) under selection pressure (the two are obviously related).> Evolution has no tautology. Brains do not evolve to be supremely efficient, just like humans do not evolve to be supremely efficient.> What exists today is that which has survived, for whatever reason. It&#x27;s not even possible to say something as apparently simplistic as \"the only purpose evolution respects is leaving behind more copies\" because that ignores (a) group selection (b) changing ecosystems that favor plasticity in the long run.A primary example of this are our legs, they would be much more efficient if the knees pointed backwards. They are not the most efficient design, but simply good enough. reply m-i-l 1 hour agorootparent> \"our legs, they would be much more efficient if the knees pointed backwards. They are not the most efficient design, but simply good enough.\"I don&#x27;t think you can say one leg type is better than another without reference to the intended use of the leg - plantigrade legs have better \"stability and weight-bearing ability\"[0], whereas digitigrade legs (like those of cats and most birds, which BTW appear to have a reverse knee but don&#x27;t because it is the ankle working like a second backwards knee) \"move more quickly and quietly\"[1].Tying this back to the original point, the same is true for brains and computers - they are each better in very specialist cases within specific constraints.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Plantigrade[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Digitigrade reply cma 8 hours agorootparentprevYou&#x27;re talking about something orthogonal, how efficient it is. He&#x27;s talking about something different:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Catastrophic_interferenceWhich practically requires full retraining at every step to integrate new knowledge. I think we have some partial solutions like learning to select between finetunings, but not if the task needs to crosscut between them.The human brain doesn&#x27;t seem to suffer with catastrophic interference to nearly the same degree, independent of its computational efficiency, though there are possibly related things like developmental stages that if they are delayed may never be able to take place. reply uoaei 12 hours agorootparentprevIt&#x27;s an apples-to-oranges comparison. They&#x27;re both fruit that grow on trees, but that&#x27;s where the similarities end.The primary difference, and likely the reason that brains are unreasonably effective, is the specifics of the architecture and internal representations (in the rigorous, information-theoretic sense) of its computational systems. It&#x27;s not quite analog but it uses analog means. It&#x27;s not quite digital but it does process via abstractions.You can still reasonably call the brain a \"computer\" if you decide it can shed the laden history of that word and its close association with binary operations using transistors. You can do so because it uses internal structures to process inputs and emit outputs. But like I said above, it requires a generalized interpretation of the word to start to understand where and how the two fields of study may be unified. reply phkahler 3 hours agoparentprev>> It’s indeed odd that current dnn’s require massive amount of energy to retrain and lack any kind of practical continuous adaptation and learning.To me that just means nobody has figured out how to do that effectively. The majority will simply make use of what&#x27;s been done and proven, so we got a plateau at object recognition, and again at generative AI (with applications in several domains). One problem with continuous adaptation and learning is providing an \"entity\" and \"environment\" for it to \"live\" in which doing the adaptive learning. There are some researchers doing that either with robots, or simulations. That&#x27;s much harder to set up than a lot of cloud compute resources. I do agree with you that these aspects are missing and things will be much more interesting when they get addressed. reply jakobson14 15 hours agoparentprevYes, it&#x27;s odd that sled dogs make terrible housepets. &#x2F;sNeural networks fundamentally aren&#x27;t designed to be otherwise. The workflow that has guided their entire development for over a decade is based around expensive training and static inference. reply sheeshkebab 15 hours agorootparentWhy then all the talk about AGI when fundamentals don’t even allow for it to emerge. reply jakobson14 15 hours agorootparentBecause drumming up talk about AGI is a really great way to get funding for your startup. The tech industry sustains itself on hype. reply ben_w 6 hours agorootparentNot only but also. reply ben_w 6 hours agorootparentprevBecause \"AGI\" is very poorly defined, and ChatGPT is very \"general\" (compared to everything before it) and matches some (but not all) definitions of \"intelligent\". reply anon291 3 hours agorootparentprevBecause transformers et al have gotten us the closest we&#x27;ve ever been to any system that can even claim to be AGI. reply FeepingCreature 14 hours agorootparentprevFirst make it work; then make it efficient. reply jakobson14 14 hours agorootparentYour scientists were so preoccupied with whether or not they should that they didn&#x27;t stop to think if they could. reply drdeca 14 hours agorootparent... seems potentially better than the other way around? Well, I suppose it depends. reply4death4 15 hours agoparentprevWhen you say “massive amount of energy” are you comparing the energy requirements to a single human or to the billions of years of solar and geothermal energy that went into producing the human species? reply edmundsauto 14 hours agorootparentI don’t think this is an apt comparison, but I do think the amount of energy it takes to grow a human into brain maturity in adulthood is an interesting one. Brains + bodies over a 20 year development cycle is still probably much less than training even a low quality Llm. reply 4death4 14 hours agorootparentLet’s say a human needs an average of 2000 calories a day. A calorie is roughly equivalent to 1 Watt hour, so over 20 years, it takes about 15 MWh to sustain a human.Let’s say a single A100 has a peak power draw of 250W, and you need 100 to train an LLM. So each hour of training consumes 25,000 Wh of energy. 15 MWh &#x2F; 25,000 W = 600 hours, or 25 days, which is probably pretty close to the true training time.So the numbers are actually pretty close. But a human brain doesn’t start out as a set of random weights like an LLM. The human brain has predefined structure that’s the result of an extremely long evolutionary process. reply Affric 14 hours agorootparentprevBy that token the amount of energy for neural networks will be bound to some extent by the development of the biosphere and the creators of neural networks. reply fastball 12 hours agorootparentNot really? The point is that most artificial neural networks are started from basically zero (random noisy weights), where as a human neural network is jump-started with an overall neural structure that has been shaped by millions of years of evolution. Sure, it&#x27;s not fair to compare the overall energy required to get there, but the point is just that a biological neural network starts with a huge headstart that is frequently forgotten when talking about efficiency. reply golol 11 hours agoparentprevIn-comtext learning exists though. reply beaugunderson 12 hours agoprevhttps:&#x2F;&#x2F;anonymfile.com&#x2F;dR8a&#x2F;s41583-023-00756-z.pdf reply lawlessone 1 hour agoprevSo does this mean DNN are in some ways deeper than human brains? reply hliyan 11 hours agoprev\"brain seems shallow and neural networks are deep, ergo neural networks are doing it wrong\"Please don&#x27;t claim things the author didn&#x27;t. What I read was \"ergo (artificial) neural networks may be missing a trick\" reply hliyan 11 hours agoparentIgnore. Reposted this under correct parent comment reply jakobson14 15 hours ago[flagged]| prevnext [96 more] If I had a nickel for every time some neurologist tried to compare brains to neural networks. It&#x27;s a surefire way to tell someone is either desperate for grant money or has been smoking crack. (previously: comparing brains and \"electronic computers\")Their entire article hinges on the complaint \"brain seems shallow and neural networks are deep, ergo neural networks are doing it wrong.\"Neurologists seem to have a really hard time comprehending that researchers working on neural networks aren&#x27;t as clueless about computers as neurology is about the brain. They also vastly overestimate how much engineers working on neural networks even care about how biological brains work.Virtually every attempt at making neural networks mimic biological neurons has been a miserable failure. Neural networks, despite their name, don&#x27;t work anything like biological neurons and their development is guided by a combination ofA) practical experimentation and refinement, andB) real, actual understanding about how they work.The concept of resnets didn&#x27;t come from biology. It came from observations about the flow of gradients between nodes in the computational graph. The concept of CNNs didn&#x27;t come from biology, it came from old knowledge of convolutional filters. The current form and function of neural networks is grounded in repeated practical experimentation, not an attempt to mimic the slabs of meat that we place on pedestals. Neural networks are deep because it turns out hierarchical feature detectors work really well, and it doesn&#x27;t really matter if the brain doesn&#x27;t do things that way.And then you have the nitwits searching the brain for transformer networks. Might as well look for mercury delay line memory while you&#x27;re at it. Quantum entanglement too. reply robbrown451 15 hours agoparentI can&#x27;t agree with the dismissiveness of this comment, and frankly I find its tone out of line and not with the spirit of Hacker News.There are insights that can come from studying the brain, that do indeed apply. Some researchers may not glean anything from such studies, and some may. I have no doubt that as neural networks get more an more powerful, we will continue to find more ways they are similar to the brain, and apply things we&#x27;ve learned about the brain to them.I certainly prefer to see people making comparisons of neural networks to the brain, that the old \"it&#x27;s just a glorified autocomplete\" and the like.Relax. reply ramraj07 12 hours agorootparentNo one disagrees we might be able to discern insights if we understand how our brain is wired. The problem is the current state of neuroscience is so flawed in its approach it’s not looking like they’re of any use. They don’t even understand how a 900 neuron worms system works but are more than happy to tap half a billion dollars from unsuspecting politicians saying they’ll map the human connectome. Go read the brain initiative proposal [1] to see how out of touch with reality the scientists in this field are. I agree with OP that sharp criticism of the entire field is fully warranted.1. https:&#x2F;&#x2F;braininitiative.nih.gov&#x2F;sites&#x2F;default&#x2F;files&#x2F;document... reply andbberger 12 hours agorootparentwhat are you talking about is this konrad kording&#x27;s shitposting alt??? this reeks of naivetyI certainly have many critiques of methods used in neuroscience rn (as a working neuroscientist) but to reduce those to the conclusion that the entire project of neuroscience is hopeless is absurd. We understand certain things quite well actually, and it&#x27;s not at all obvious what \"understanding\" at a larger scale would look like. It is very possible that the brain is irreducibly complex, and that the model you would need to construct to describe it would itself be so complex as to be useless in providing insight. Considering that the brain is by far the most complex object in the universe I think we&#x27;re doing pretty well.Furthermore, there are quite a lot of disagreements about the utility of connectomics. Outside of the extremists (Sebastian Seung and his ilk) no one thinks that connectomics is going to be the key that brings earth shattering insight. It&#x27;s just another tool. There is a complete connectome for part of the drosophila brain already (privately funded btw), which is in daily use in many fly labs. It tells you what other neurons are connected to. Incredibly useful. Not earth shattering.also you might want to measure the neuroscience funding you deem wasteful up against the tens of billions NASA is spending to send humans (and not robots) back to the moon for \"the spirit of adventure\". cold war&#x27;s over. robots will do just fine for the moon. reply ramraj07 11 hours agorootparentCan you please elaborate what great strides the field of neuroscience has made in the past 30 years?From where I stand I can’t see anyone giving a clear explanation of anything our brain does or does not do in a disease. The only novel treatment that has come out seems to have been stick a rod into the brain and zap it and it just magically cures a lot of diseases we still don’t understand even a bit.This is not even starting to discuss what little we have learned about how brains algorithms work. I’m still waiting to understand why pyramidal neurons were somehow groundbreaking. We found some neuron that fires when you walk to a place, why wouldn’t we find one?And what are you saying about the fly connectome again? Do we have exact names for every neuron in the fly brain and its verified connectome for every neuron?Last I checked the worm connectome has been available in intricate detail for decades and the scientists still haven’t had any proper decoding of the algorithms in that system. In fact I know every lab trying to figure that out now, I wrote proposals in the topic myself. Everyone else has apparently decided it’s not sexy enough to work with worms so they have just leaped to more complex systems with no basic understanding. I’m not the only one saying this. Sydney Brenner said as much in an editorial. But the field was too busy doing I don’t know what to listen.Sydney, B. & Sejnowski, T. J. Understanding the human brain. Science 334, 567 (2011).I remember sauntering to the occasional neuroscience talk during my ut southwestern PhD and occasionally hearing some professor brag about how the majority of one of their PhD’s jobs was to segmenting a single neuron in the thousand EM images or something. Surely that’s a sign this field needs revision? reply andbberger 10 hours agorootparent> And what are you saying about the fly connectome again? Do we have exact names for every neuron in the fly brain and its verified connectome for every neuron?onus isn&#x27;t on me to justify the existence of an entire field to you. the claim that neuroscience has not made great strides in the last 30 years is an extraordinary one, and that&#x27;s all on you. but it especially doesn&#x27;t help your case that if you had googled \"fly connectome \" you would have seen that the first result is a complete connectome of a larvae and the third result is the tour de force from Janelia that produced an adult connectome. With names and verified connections. there is even a wikipedia article for the drosophila connectome!> I remember sauntering to the occasional neuroscience talk during my ut southwestern PhD and occasionally hearing some professor brag about how the majority of one of their PhD’s jobs was to segmenting a single neuron in the thousand EM images or something. Surely that’s a sign this field needs revision?and if you had gone on to actually read the hemibrain connectome paper you would have gained some appreciation for the gargantuan achievement that it was. it took hundreds of person years to generate ground truth segmenting neurons by hand, to develop the ML techniques required to automatically segment the rest (extremely difficult problem) and to then validate the automatic segmentations. not to mention the insane effort it was to acquire a half petabyte EM image of a single fly at sub-synaptic resolution in the first place.I gotta hand it to you though, the position of naivety you&#x27;ve delivered your middlebrow dismissal from is truly impressive in magnitude. reply anonymousDan 7 hours agorootparentprevIt&#x27;s typical of the arrogant, borderline anti-scientific attitude of a non-negligible fraction of the HN hive mind, i.e. if it came out of academia it must be a waste of time. reply civilitty 11 hours agorootparentprevAgreed. Reading the GP’s comment it feels like it’s from bizzaro world. It’s the computer scientists who have been claiming that neural networks resemble the human brain - they even fucking named them neural networks for christ’s sake! That could be excused as naive hubris in the 1980s, it’s utter delusion now.A surface review of neuroplasticity literature alone should free anyone of the illusion that “neural networks” have even a passing resemblance to biological neurons, something covered in neuroscience 101 and is widely internalized by its practitioners. The BS grant writing and PR scientists have to participate in is hardly reflect of state of the art science itself.The irony is that machine learning methods are a perfect fit for neuroscience and biology in general which generates reams of data that is largely so multidimensional that manual analysis is intractable. What we’re seeing now is the crest of the academic hype cycle which - if the history of bioinformatics is anything to go by - means that ML will take years if not decades for the field to understand and filly utilize. reply bjourne 3 hours agorootparentActually it was neuroscientists that developed the models nowadays used for machine learning. The McCulloch-Pitts neuron model introduced in 1943 which lead to Frank Rosenblatt&#x27;s perceptron introduced in 1958. Machine learning algorithms mostly still use those models but computational neuroscience has progressed towards much more complicated neuronal models. reply SubiculumCode 12 hours agorootparentprevAs another working neuroscientist, thank you. And cheers. reply __loam 13 hours agorootparentprevNo I think these comments are quite necessary. People need to stop making these comparisons because they have absolutely no grounding in how brains actually work. There are bad ideas that should be dismissed. reply fastball 12 hours agorootparentNeural networks are absolutely based on a very simplified model of how brains work. Specific NN architectures are in turn based on specific parts of the brain (e.g. Convolution Neural Networks are based on the visual cortices of cats&#x2F;frogs). reply andbberger 12 hours agorootparentnah, they&#x27;re arbitrary function approximators that caught a lucky break. CNNs rose to prominence because natural scene statistics are translation invariant and convolutions can be efficiently computed on GPUs. and now that we have whole warehouses of GPUs, the current mood in DL is to stop building the symmetries of your dataset into the model (which is insane btw) and use brute force.the tenuous connection DL once had to neuroscience (perceptrons) is a distant memory reply fastball 12 hours agorootparentA fabricated re-telling of the past, given that we didn&#x27;t start using GPUs for this type of compute until the turn of the millenium. reply andbberger 12 hours agorootparentAlexNet was the turning point for DL. reply fastball 11 hours agorootparentWhy do you say that? Deep Learning was accelerating well before that (I would argue it has been accelerating for its entire existence).AlexNet was a state-of-the-art image recognition net for a (relatively) brief amount of time. It wasn&#x27;t the first CNN to use GPU acceleration, and it was quickly eclipsed in terms of ImageNet performance.Regardless, I think bringing up AlexNet kinda invalidates your initial point. Although yes, it turns out that the two were a great match, CNNs and modern GPUs were clearly developed independently of each other, as evidenced by the many, many iterations of both before they were combined. replyrobbrown451 13 hours agorootparentprevYou&#x27;re saying the study has no grounding in how brains work? I&#x27;d think a more reasonable conclusion would be that the neuroscientists involved have no grounding in how artificial neural networks work.It seems the whole point is to bring in additional details of how brains work, that the think may be relevant to artificial NNs. reply p1esk 12 hours agorootparentprevArtificial neural networks are the closest working model of a brain we have today.Lots of graph nodes, with weighted connections, performing distributed computation (mainly hierarchical pattern matching), learning from data by gradually updating weights, using selective attention (and&#x2F;or recurrence, and&#x2F;or convolutional filters).Which of the above is not happening in our brains? Which of the above is not biologically inspired?In fact this description equally applies to both a brain and GPT4. reply aeternum 12 hours agorootparentMany organisms have just a handful of neurons yet exhibit complex behavior that would be impossible given the weighted connections model. Not to mention single-celled organisms that exhibit ability to navigate.The model can be the closest working model but that doesn&#x27;t mean it is complete. It&#x27;s very likely that cells can store memories&#x2F;information independent from weights. reply p1esk 12 hours agorootparentWe can’t do that not because our mathematical neurons are too simple. We can’t do that because we don’t know the algorithms those biological neurons are running.Do you see the difference? reply ben_w 7 hours agorootparentprev> Many organisms have just a handful of neurons yet exhibit complex behavior that would be impossible given the weighted connections model.That&#x27;s rather a bold claim given that artificial neural networks are universal function approximators. reply agalunar 5 hours agorootparentImpossible given that number of neurons.It&#x27;s perhaps not terribly surprising that it becomes possible with unlimited width or depth (or an arbitrarily complex activation function).https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Universal_approximation_theore... reply simiones 3 hours agorootparentprevIt&#x27;s incredible to me how widely this is misunderstood.The universal function approximator theorem only applies for continuous functions. Non-continuous functions can only be approximated to the extent that they are of the same \"class\" as the activation function.Additionally, the theorem only proves that for any given continuous function, there exists a particular NN with particular weight that can approximate that function to a given precision. Training is not necessarily possible, and the same NN isn&#x27;t guaranteed to approximate any other function to some desired precision.It seems pretty obvious to me that most interesting behaviors in the real world can&#x27;t be modelled by a mathematical function at all (that is, for each input having a single output); if we further restrict to continuous functions, or step functions, or whatever restriction we get from our chosen activation function. reply ben_w 2 hours agorootparent> The universal function approximator theorem only applies for continuous functions. Non-continuous functions can only be approximated to the extent that they are of the same \"class\" as the activation function.Yes, and?> Training is not necessarily possibleThat would be surprising, do you have any examples?> and the same NN isn&#x27;t guaranteed to approximate any other function to some desired precision.Well duh. Me speaking English doesn&#x27;t mean I can tell 你好[0] from 泥壕[1] when spoken.> It seems pretty obvious to me that most interesting behaviours in the real world can&#x27;t be modelled by a mathematical function at all (that is, for each input having a single output)I think all of physics would disagree with you there, what with it being built up from functions where each input has a single output. Even Heisenberg uncertainty and quantised results from the Stern-Gerlach setup can be modelled that way in silico to high correspondence with reality, despite the result of testing the Bell inequality meaning there can&#x27;t be a hidden variable.[0] Nǐ hǎo, meaning \"hello\"[1] Ní háo, which google says is \"mud trench\", but I wouldn&#x27;t know reply simiones 2 hours agorootparent> Yes, and?It means that there is no guarantee that, given a non-continuous function function f(x), there exists an NN that approximates it over its entire domain withing some precision p.> That would be surprising, do you have any examples?Do you know of a universal algorithm that can take a continuous function and a target precision, and return an NN architecture (number of layers, number of neurons per layer) and a starting set of weights for an NN, and a training set, such that training the NN will reach the final state?All I&#x27;m claiming is that there is no known algorithm of this kind, and also that the existence of such an algorithm is not guaranteed by any known theorem.> Well duh. Me speaking English doesn&#x27;t mean I can tell 你好[0] from 泥壕[1] when spoken.My point was relevant because we are discussing whether an NN might be equivalent to the human brain, and using the Universal Approximation Theorem to try to decide this. So what I&#x27;m saying is that even if \"knowning English\" were a continuous function and \"knowing French\" were a continuous function, so by the theorem we know there are NNs that can approximate either one, there is no guarantee that there exists a single NN which can approximate both. There might or might not be one, but the theorem doesn&#x27;t promise one must exist.> I think all of physics would disagree with you there, what with it being built up from functions where each input has a single output.It is built up of them, but there doesn&#x27;t exist a single function that represents all of physics. You have different functions for different parts of physics. I&#x27;m not saying it&#x27;s not possible a single function could be defined, but I also don&#x27;t think it&#x27;s proven that all of physics could be represented by a single function. reply ben_w 1 hour agorootparent> It means that there is no guarantee that, given a non-continuous function function f(x), there exists an NN that approximates it over its entire domain withing some precision p.And why is this important?> Do you know of a universal algorithm that can take a continuous function and a target precision, and return an NN architecture (number of layers, number of neurons per layer) and a starting set of weights for an NN, and a training set, such that training the NN will reach the final state?> All I&#x27;m claiming is that there is no known algorithm of this kind, and also that the existence of such an algorithm is not guaranteed by any known theorem.I think so: the construction proof of the claim that they are universal function approximators seems to meet those requirements.Even better: it just goes direct to giving you the weights and biases.> My point was relevant because we are discussing whether an NN might be equivalent to the human brain, and using the Universal Approximation Theorem to try to decide this. So what I&#x27;m saying is that even if \"knowning English\" were a continuous function and \"knowing French\" were a continuous function, so by the theorem we know there are NNs that can approximate either one, there is no guarantee that there exists a single NN which can approximate both. There might or might not be one, but the theorem doesn&#x27;t promise one must exist.I still don&#x27;t understand your point. It still doesn&#x27;t seem to matter?If any organic brain can&#x27;t do $thing, surely it makes no difference either way whether or not that $thing can or can&#x27;t be done by whatever function is used by an ANN?> It is built up of them, but there doesn&#x27;t exist a single function that represents all of physics. You have different functions for different parts of physics. I&#x27;m not saying it&#x27;s not possible a single function could be defined, but I also don&#x27;t think it&#x27;s proven that all of physics could be represented by a single function.I could point you to this: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PHiyQID7SBsBut that would be unfair, given the QM&#x2F;GR incompatibility.That said, ultimately I think the onus is on you to demonstrate that it can&#x27;t be done when all the (known) parts not only already exist separately in such a form, but also, AFAICT, we don&#x27;t even have a way to describe any possible alternative that wouldn&#x27;t be made of functions. reply simiones 48 minutes agorootparent> And why is this important?Since we know non-continuous functions are used in describing various physical phenomena, it opens the gate to the possibility that there are physical phenomena that NNs might not be able to learn.And while piece-wise continuous functions may still be ok, fully discontinuous functions are much harder.> I think so: the construction proof of the claim that they are universal function approximators seems to meet those requirements.Oops, you&#x27;re right, I was too generous. If we know the function, we can easily create the NN, no learning step needed.The actual challenge I had in mind was to construct an NN for a function which we do not know, but can only sample, such as the \"understand English\" function. Since we don&#x27;t know the exact function, we can&#x27;t use the method from the proof to even construct the network architecture (since we don&#x27;t know ahead of time how many bumps there are are, we don&#x27;t know how many hidden neurons to add).And note that this is an extremely important limitation. After all, if the UAF was good enough, we wouldn&#x27;t need DL or different network architectures for different domains at all: a single hidden layer is all you need to approximate any continuous function, right?> If any organic brain can&#x27;t do $thing, surely it makes no difference either way whether or not that $thing can or can&#x27;t be done by whatever function is used by an ANN?Organic brains can obviously learn both English and French. Arguably GPT-4 can too, so maybe this is not the best example.But the general doubt remains: we know humans express knowledge in a way that doesn&#x27;t seem contingent upon that knowledge being a single continuous mathematical function. Since the universal function approximator theorem only proves that for each continuous function there exists an NN which approximates it, this theorem doesn&#x27;t prove that NNs are equivalent to human brains, even in principle.> That said, ultimately I think the onus is on you to demonstrate that it can&#x27;t be done when all the (known) parts not only already exist separately in such a form, but also, AFAICT, we don&#x27;t even have a way to describe any possible alternative that wouldn&#x27;t be made of functions.The way physical theories are normally defined is as a set of equations that model a particular process. QM has the Schrodinger equation or its more advanced forms. Classical mechanics has Newton&#x27;s laws of motion. GR has the Einstein equations. Fluid dynamics has the Navier-Stokes equations. Each of these is defined in terms of mathematical functions: but they are different functions. And yet many humans know all of them.As we established earlier, the UFA theorem proves that some NN can approximate one function. For 5 functions you can use 5 NNs. But you can&#x27;t necessarily always combine these into a single NN that can approximate all 5 functions at once. It&#x27;s trivial if they are simply 5 easily distinguishable inputs which you can combine into a single 5-input function, but not as easy if they are harder to distinguish, or if you don&#x27;t know that you should model them as different inputs ahead of time.By the way, there is also an example of a pretty well known mathematical object used in physics that is not actually a proper function - the so-called Dirac delta function. It&#x27;s not hard to approximate this with an NN at all, but it does show that physics is not strictly speaking limited to functions.Edit to add: I agree with you that the GP is wrong to claim that the behavior exhibited by some organisms is impossible to explain if we assumed that the brain was equivalent to an (artificial) neural network.I&#x27;m only trying to argue that the reverse is also not proven: that we don&#x27;t have any proof that an ANN must be equivalent to a human&#x2F;animal brain in computational power.Overall, my position is that we just don&#x27;t know to what extent brains and ANNs correspond to each other. replysimiones 3 hours agorootparentprev> Lots of graph nodesNeurons are not connected by a simple graph, there are plenty of neurons which affect all the neurons physically close to them. There are also many components in the body which demonstrably affect brain activity but are not neurons (hormone glands being among the most obvious).> with weighted connectionsProbably, though we don&#x27;t fully understand how synapses work> performing distributed computation (mainly hierarchical pattern matching)This is a description of purpose, not form, so it&#x27;s irrelevant.> learning from data by gradually updating weightsWe have exactly 0 idea how biological neural nets learn at the moment. What we do know for sure is that a single neuron when alone can adjust its behavior based on previous inputs, so the only thing that is really clear is that individual neurons learn as well, it&#x27;s not just the synapses with their weights which modifies behavior. Even more, non-neuron cells also learn, as is obvious from the complex behaviors of many single-cell organisms, but also some non-neuron cells in multicellular organisms. So potentially, learning in a human is not completely limited to the brain&#x27;s neural net, but it could include certain other parts of the body (again, glands come to mind).> using selective attention (and&#x2F;or recurrence, and&#x2F;or convolutional filters).This is completely unknown.So no, overall, there is almost no similarity between (artificial) neural nets and brains, at least none profound enough that they wouldn&#x27;t share with a GPU. reply krainboltgreene 14 hours agorootparentprevWhat does this comment add to the discussion? reply robbrown451 13 hours agorootparentI dunno. My comment complained about the parent comment not adding positively to the discussion. And gave at least a bit of support for that complaint.Would you have preferred I emulate your style, and complain while providing no support for my complaint?Ok. reply krainboltgreene 10 hours agorootparentBeing positive is not a requirement of commenting on HN, but you should comment with something that is substantive, so yes I do think you shouldn&#x27;t have commented at all. Tone policing is cringe. reply JKCalhoun 4 hours agorootparentI don&#x27;t like tone-policing in general. But when I opened this post the negative comment we&#x27;re talking about was the top comment. That&#x27;s makes me much more sympathetic to someone calling out the cynicism. reply robbrown451 7 hours agorootparentprevExactly what are you doing here then?But hey I guess I can do this too. How&#x27;s this? Using cringe as an adjective is cringe. replyjacobsimon 14 hours agoparentprevThis is a really weird take. There is such a long history of shared insights between biology and neural network research, and to say they’re unrelated or can’t take inspiration from one another is bizarre.> The concept of CNNs didn&#x27;t come from biologyI just opened a survey paper on CNNs and literally the first sentence of the paper reads:> “Convolutional Neural Network (CNN) is a well-known deep learning architecture inspired by the natural visual perception mechanism of the living creatures. In 1959, Hubel & Wiesel [1] found that cells in animal visual cortex are responsible for detecting light in receptive fields. Inspired by this discovery…”Source: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1512.07108.pdf%C3%A3%E2%82%AC%E2%80%9A reply jakobson14 14 hours agorootparentThat&#x27;s later backfill, a retroactive change to give a manufactured \"biological\" origin story. Whether they&#x27;re real or not, researchers love a good \"we took this from nature, isn&#x27;t nature wonderful!\" explanation.The C in CNN isn&#x27;t \"Convolution\" for no reason. It came from work with convolutional filters (yay Sobel kernels!) which at it&#x27;s height became filter banks and gabor filters and so on before neural networks pretty much killed off handcrafted feature development. Every explanation of how CNNs work still falls back to the original convolutional kernel intuition. reply rerdavies 11 hours agorootparent> The C in CNN isn&#x27;t \"Convolution\" for no reason.The first N in CNN is \"Neural\" for a reason. reply mjburgess 7 hours agorootparentCan you explain that reason?Decision trees are called &#x27;trees&#x27; for, more or less, the same reason.ie., the diagrammed shape of a decision tree looks a little like the branches of a real one.likewise, in the 50s where diagramming the earliest networks they were aiming to immitate a similar real-world structure.Better that they had called them &#x27;Variable Activation Networks&#x27; or some such, and none of this superstition would have started reply TeMPOraL 5 hours agorootparent> Better that they had called them &#x27;Variable Activation Networks&#x27; or some suchBut that&#x27;s the thing: they didn&#x27;t. Instead, they called them \"neural networks\". It wasn&#x27;t random.It feels like part of the field now wants to pretend it was never about how to make a machine think. \"No, we&#x27;re only doing abstract maths, only going on self-contained explorations of CS theory.\" Yeah, right. That feels like a reaction to the new wave of AI hype in business. Now that the rubes are talking about thinking machines again, better distance themselves from them, lest we be confused for those loonies.Thing is, the field was always driven in big part by trying to catch up with nature. It took inspiration from neuroscience, much like neuroscience borrowed some language from CS, both for legitimate reasons. A brain is a computer. It&#x27;s precisely where the CS and neuroscience have an overlap - they&#x27;re studying the same thing, just from opposite directions. It&#x27;s just silly to play the \"oh my field is better and your field doesn&#x27;t know shit\" game.> Decision trees are called &#x27;trees&#x27; for, more or less, the same reason.Decision trees are called after the data structure, which is a way to express a mathematical object, which is older than CS and got that name from... who knows, but my money is on \"genealogical tree\", which itself is called a \"tree\" because people back then liked to tie everything to trees (symbol of growth) and flowers and cute animals (symbols of making babies).The field inherited \"trees\" from the past. \"Networks\", too. But \"neural\" - that was a modern analogy the field itself is responsible for. reply jacobsimon 3 hours agorootparentYep! Trees, tree structures, tree diagrams have been regularly in use since the 1700s as a way of defining relationships. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tree_structureThere’s also a pretty large link between the formal representation of language using syntax trees, which was being formalized by linguists and by programming language developers around the same time: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Formal_language?wprov=sfti1 reply dartos 14 hours agorootparentprevYou can use that argument for anything you disagree with. Do you have a source or anything? reply jakobson14 14 hours agorootparentHave a read through the first paper describing a convolutional neural network, from 1998: http:&#x2F;&#x2F;yann.lecun.com&#x2F;exdb&#x2F;publis&#x2F;pdf&#x2F;lecun-01a.pdfThere&#x27;s absolutely no mention of biological inspiration whatsoever. At the same time, one can point to a long and rich history of convolutional filters being used in signal processing. And then there&#x27;s the name, Convolutional Neural Network. The entire concept of a CNN is framed as a series of learned filters. reply fastball 13 hours agorootparentThat is definitely not the first paper describing a CNN. That is not even the first paper by Le Cun describing CNNs (he was already on them as early as 1989[1]).Regardless, Le Cun is not the first to describe CNNs, merely one of the first to use them for OCR (specifically for hand-written text).The first neural network arch to use convolutions instead of matmuls was this[2], from the year of our lord 1988. This in turn is based on Fukushima&#x27;s \"neocognitron\"[3] (1980), which is based on the visual cortex of felines (from work done by Hubel and Wiesel in the 50s&#x2F;60s).I guess it is not super surprising you might be confused – Le Cun seems a bit more reticent than average to cite the work he&#x27;s building on top of, and when he does it is frequently in reference to his own prior work. So if that is where you&#x27;re getting your picture of artificial neural network history, your skewed perception makes sense.[1] https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;abstract&#x2F;document&#x2F;41400[2] https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper&#x2F;1987&#x2F;file&#x2F;98f1370821019...[3] https:&#x2F;&#x2F;www.cs.princeton.edu&#x2F;courses&#x2F;archive&#x2F;spr08&#x2F;cos598B&#x2F;R... reply tudorw 7 hours agorootparentThanks, I was looking for something to do with early work and saccades, didn&#x27;t find that, but found this;\"The most influential of these early discussions was probably the 1943 paper of Warren McCulloch and Walter Pitts in which activity in neuronal* networks was identified with the operations of the propositional calculus. Actual simulations of recognition automata based on networks were carried out by Frank Rosenblatt before 1958 but the theoretical limitations of his \"perceptrons\" were soon pointed out by Marvin Minsky and Seymour Papert\"excerpt from a 1998 paper, \"Real Brains and Artificial Intelligence\" (https:&#x2F;&#x2F;www.jstor.org&#x2F;stable&#x2F;20025142)\"Walter Harry Pitts, Jr. (23 April 1923 – 14 May 1969) was an American logician who worked in the field of computational neuroscience.[1]\"&#x27;https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Walter_Pitts&#x27; reply jacobsimon 13 hours agorootparentprevSurely you are trolling me now. There is a very clear biological inspiration mentioned in this paper: they literally define a CNN as having “receptive fields” and then they cite the same Hubel & Wiesel research mentioned before multiple times. LeCun mentions their research in papers even earlier in the 80s as well, during which they were awarded the Nobel prize for their research on the visual system. Of course there is also a lot of computational and mathematical research that was ongoing simultaneously, but to say that there is “no inspiration whatsoever” is pretty far from the truth. reply albertzeyer 7 hours agorootparentprevSome time around mid 1995 until basically now, it became out of fashion to explain your motivations of some new modeling as inspired from biology, as that was often handwaving with only little understanding of the actual neuroscience. So that is why people stopped writing that in papers. Just let the actual performance numbers speak for themselves. Either you get good performance, then it doesn&#x27;t really matter where this was inspired from, or it does not work well, then it also does not matter where this was inspired from. In machine learning, it mostly matters whether it works well or not. reply readthenotes1 13 hours agorootparentprevThat&#x27;s funny. I had a book on \"neural nets\" in the 1980s, and it mentioned the analog to brain neurons. replytwo_in_one 14 hours agoparentprevWhile I agree with this emotional post there is one nuance. Neural networks aren&#x27;t intelligent, brain is. And that&#x27;s where we want to be. Checking gradients and studying filters can get us only this far. So, using brain as inspiration looks like a good option. There are other, but nobody knows where next breakthrough will be. Like nobody knew five years back that transformers are so powerful. My guess next step to AGI will be a complex modular multi-modal system. With hierarchy, workers and controllers, complex signals.. Sound familiar? Brain is sort of it. This is need for embodied AI, obviously. But, interesting thing, it&#x27;s needed even for body-less AGI too. I.e. AGI is not a big calculator (!), it&#x27;s more like real-time system. One reason is that full search is impossible. So, in many cases requests will be like &#x27;give the best answer you can find in 4 seconds&#x27;. &#x27;and keep looking&#x27;. So far we have only real-time dumb robots and NN big calculators. And brains, of course. reply dilawar 14 hours agoparentprev> previously: comparing brains and \"electronic computers\")Before that: comparing brain with hydraulic machines. There has been tendency to compare brain with most complex machine known to us at that particular time.\"Descartes was impressed by the hydraulic figures in the royal gardens, and developed a hydraulic theory of the action of the brain. We have since had telephone theories, electrical field theories, and now theories based on computing machines… . We are more likely to find out how the brain works by studying the brain itself, and the phenomenon of behavior, than by indulging in far-fetched physical analogies.\" -- Karl Lashley 1951 reply bondarchuk 6 hours agorootparentElectronic computers, artificial neural networks, hydraulic machines, clockworks etc... are all computationally equivalent to the brain. Anyone making such comparisons is grasping at the fact that the brain can be understood computationally. To complain that there are no pressure-driven pistons, rotating gears or whatever in the brain is missing the point of the analogy, IMHO, which is: all these systems perform computation on top of a physical substrate, and what we actually (should) care about is the computation itself and not the mechanical workings of the substrate. reply mjburgess 7 hours agorootparentprevI cannot agree enough with Karl here. What is the brain? An organic system with deep roots in the organic body, with deep causal connections with its environment.There&#x27;s little sense in ignoring the whole basic mode of operation, physics, chemistry and biology of the brain in order to analogise it to another system without any of those properties.This, at best, provides a set of inspirations for engineers -- it does nothing for science. reply TeMPOraL 5 hours agorootparent> There&#x27;s little sense in ignoring the whole basic mode of operation, physics, chemistry and biology of the brain in order to analogise it to another system without any of those properties.Sure there is. People had a feel for it back in \"clockworks\" times, nowadays we have a much better grasp because of progress of physics and math, particularly CS - mode of operation is an implementation detail. Whatever the mode, once you understand the behavior enough to model it in computational terms, you can implement it in anything you like - gears and levers, pistons, water flowing between buckets, electrons in silicon, photons going through lenses, photons diffusing through metamaterials, sound waves diffusing through metamaterials - and yes, also via a person locked in a room full of books telling them what to draw in response to a drawing they receive, and also via a billion kids following a game to the letter, via corporate bureaucracy, via board game rules, etc.Substrate. Does. Not. Matter.The only thing limiting your choice here is practical one. Humanity is getting a good mileage out of electrons in silicon, so that&#x27;s the way to go for now. Gears would work too, they&#x27;re just too annoying to handle at scale.Of course, today we don&#x27;t have a full understanding of biological substrate - we can&#x27;t model it fully in terms of computation, because it&#x27;s a piece of spontaneously evolved nanotech and we barely begun being able to observe things at those scales. We have a lot of studying in front of us - but this is about learning how the gooey stuff ticks, what does it compute and how. But it&#x27;s not about some new dimension of computation. reply mjburgess 5 hours agorootparent> Substrate. Does. Not. Matter.It only doesnt matter for counting a system as implementing a pure algorithm, ie., one with no device access. This is an irrelevant theoretical curiosity.Electronic computers are useful because they&#x27;re electronic -- they can power devices, and modulate devices using that power. This cannot be done with wood, or most anything else.\"Substrate doesnt matter\" is, as a scientific doctrine pseudoscience, and as a philosophical one, theological.The causal properties of matter are essential to any really-existing system. Non-causal, purely formal properties of systems which can be modelled as functions from the naturals to the naturals (ie., those which are computable) are useless. reply TeMPOraL 4 hours agorootparent> Electronic computers are useful because they&#x27;re electronic -- they can power devices, and modulate devices using that power. This cannot be done with wood, or most anything else.On the contrary. That&#x27;s an implementation detail. You can \"power devices, and modulate devices\" by having a clockwork computer with transducers at the I&#x2F;O boundary, converting between electricity and mechanical energy at the edge. It would work exactly like a fully electronic computer, if built to implement the same abstract computations - and as long as you use it within its operational envelope[0], you wouldn&#x27;t be able to tell the difference (except for the ticking noise).> The causal properties of matter are essential to any really-existing system. Non-causal, purely formal properties of systems which can be modelled as functions from the naturals to the naturals (ie., those which are computable) are useless.Yes and no. Of course the causal properties of matter... matter. But the breakthrough in understanding, that came with development of computer science and information theory, is that you can take the \"non-casual, purely formal\" mathematical models of computation, and define some bounds on them (no infinite tapes), you can then use the real-world matter to construct a physical system following that mathematical model within the bounds, and any such system is equivalent to any other one, within those bounds. The choice of what to use for actual implementation is done on practical grounds - i.e. engineering constraints and economics.It&#x27;s how my comment reached your screen, despite being sent through some combination of electrons in wires, photons down a glass fibre, radio signals at various frequencies - hell, maybe even audio signals through the air, or printouts carried by pidgeons[1]. Computer networks are a living proof that substrate doesn&#x27;t matter - as long as you stick to the abstract models and bounds described in the specs for the first three layers of ISO&#x2F;OSI model, you can hook up absolutely anything whatsoever to the Internet and run TCP&#x2F;IP over it, and it will work.I bet there&#x27;s at least one node on the Internet somewhere whose substantial compute is done in a purely mechanical fashion. And even if not, it could be done if someone wanted - figuring out how to implement a minimal TCP&#x2F;IP stack using gears and switches is something a computer can do for you, because it&#x27;s literally just a case of cross-compilation.--[0] - As opposed to e.g. plugging 230V AC to its GPIO port; the failure modes will be different, but that has no bearing on either machine being equivalent within the operational bounds they were designed for.[1] - https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc1149 reply mjburgess 4 hours agorootparent> matter to construct a physical system following that mathematical model within the bounds, and any such system is equivalent to any other one, within those boundsNo. This wasnt discovered.Nearly every physical system is implementing nearly every pure algorithm, ie., every computable function.The particles of gas in the air in my room form a neural network, with the right choice of activation function.Turing-equivalence is a property of formal models with no spatio-temporal properteis. Physical systems are not equivalent because they both implement a pure algorithmPure algorithms are useless, and of interest only in very abstract csci. All actual algorithms, when specified, have massive non-computational holes in them called &#x27;i&#x2F;o&#x27;, device access etc.If your two systems of cogs wants to communiate over a network of cogs, the Send() &#x27;function&#x27; (which is not a function!) has to have a highly specific causal semantics which cannot be specified computationally.These systems only have &#x27;equivalent functions&#x27;, as seen from a human point-of-view, if their non-computational parts serve equivalent functions. This has nothing to do with any pure algorithm.You cannot implement a web browser on &#x27;gears&#x27; in any useful sense, in any sense in which the partices of their air arent already implementing the web browser. That a physical system can-be-so-described is irrelevant.Computers are useful not because theyre computers. Theyre useful because they are electrical devices whose physical state can be modulated with hyper-fine detail by macroscope devices (eg., keyboards). We have rigged a system of electrical signals to immitate a formal programming langauge -- but this is an illusion.Reduce the system down to just want can be specified formally, and it disappears. reply TeMPOraL 3 hours agorootparent> Nearly every physical system is implementing nearly every pure algorithm, ie., every computable function.Sure. And also about the air and neural network. This is all irrelevant, for the same reason that every possible program and every possible copyrighted work being contained in the base-10 expansion of the number PI is irrelevant. Or that a photo of every event that ever happened anywhere is contained in the space of all possible (say) 1024x1024 24-bit-per-pixel bitmaps. It&#x27;s all in there, but it&#x27;s irrelevant, because you have no way of determining which combinations of pixels are photos of real events. And any random sample you take is most certainly not it.> All actual algorithms, when specified, have massive non-computational holes in them called &#x27;i&#x2F;o&#x27;, device access etc.Only if you stick to a subset of maths you use for algorithms, and forget about everything else. The only actual hole there would be in your memory, or knowledge.Sure, I&#x2F;O doesn&#x27;t play nice with functional programming. It doesn&#x27;t stop functional programming from being useful with real computers in the real world. We have other mathematical frameworks to describe things that timeless, stateless computation formalisms can&#x27;t. You are allowed to use more than one at the same time!> You cannot implement a web browser on &#x27;gears&#x27; in any useful sense, in any sense in which the partices of their air arent already implementing the web browser.Of course I can. Here is the dumb approach for the sake of proof (one can do better with more effort):1. Find a reference for how to make a NAND gate with gears. Maybe other logic gates too, but it&#x27;s not strictly necessary.2. Find the simplest CPU architecture someone made a browser for, for which you can find or get connection-level schematics of the chip; repeat for memory and other relevant components, up to the I&#x2F;O boundary. Make sure to have some storage in there as well.3. Build electricity&#x2F;rotational motion transducers, wire them to COTS display, keyboard, mouse and Ethernet ports.4. Mechanically translate all the logic gates and connections from point 2. to their gear equivalents using table 1., and hook up to 3.5. Set the contents of the storage to be the same as a reference computer with a web browser on it.6. Run the machine.Of course, this would be a huge engineering challenge - making that many gears work together, in spite of gravity, inertia, tension and wear, and building it in under a lifetime and without bankrupting the world. Might be helpful to start by building tools to make tools to make tools, etc.But the point is, it&#x27;s a dumb mechanical process, trivially doable in principle. May be difficult with physical gears, but hey, it worked in Minecraft. People literally built CPUs inside a videogame this way.> We have rigged a system of electrical signals to immitate a formal programming langauge -- but this is an illusion.It&#x27;s the other way around: we&#x27;ve rigged a system of electrical signals to make physical a formal theoretical program. We can also rig a system of optical signals, or hydraulic signals, or pidgeon-delivered paper signals, to \"immitate a formal programming language\" and implement a formal theoretical program - and as long as those systems immitate&#x2F;implement the same formal mathematical model, they&#x27;re functionally equivalent and interchangeable. reply mjburgess 2 hours agorootparentI think you aren&#x27;t following the defintion of &#x27;computer&#x27; or &#x27;computable&#x27;, you seem to have a mixed physical notion of what a &#x27;computer&#x27; is.A computer, from a formal pov, is just an abstract mathematical object (like a shape) which has abstract properties (eg., like being a circle) that are computable, ie., are functions from integers to integers.The physical devices we call &#x27;computers&#x27;, in many ways, arent. They exist in space and time and hence have non-computable properties, like their (continuous) extension in space and time.See Turing&#x27;s own paper where he makes this point himself, ie., that physical machines arent computers in his sense because they&#x27;re continuous in time.Insofar as you appeal to any causal aspects of a physical system you arent talking about a computer in turing&#x27;s sense, and nothing like a turing equivalence would apply.We already know that all computable functions can be implemented by &#x27;arbitary substrates&#x27; -- this is just the same as saying that you can &#x27;make a circle out of any material&#x27;.In exactly the same sense as gears can be networked, sand dunes already are. You can just go around labelling particles of sand with 0s and 1s, and for a subset, there you have it: the computable aspects of the TCP&#x2F;IP protocol.But this is irrelevant. TCP&#x2F;IP isnt useful because of its computable aspects. It&#x27;s useful as a design sheet for humans to rig systems of electrical devices with highly specific causal properties.The system we call &#x27;the internet&#x27; is useful because it connects keyboards, screens, mice, microphones, webcams, SSDs, RAM, etc. together -- and because these devices are provide for human interaction.The sand dune is likewise already implementing arbitary computable functions, so is the sun, so is the air, and any arbitary part of the universe you care to choose.But the sand dune lacks all the properties the internet has: there&#x27;s no webcam, no keybaord, no screen, etc.What we actually use are physical properties. Talk of algorithms is just a design tool for people to build stuff replyben_w 6 hours agorootparentprevI mildly disagree (although your final conclusion is correct: it indeed does nothing for science).The deepest fundamental structures in the brain[0] are quantum fields, which are also the deepest fundamental structures in everything else.There is no known quantum field of \"soul\" or \"intelligence\".The right abstraction is higher, and could still be a whole lot of things; but as maths can be implemented in logic, which can be implemented in electronics or clockwork or hydraulics, it doesn&#x27;t matter what analogy is used — and my mild disagreement here is that such inspiration has been useful and gotten us this far.[0] that we know of reply mjburgess 6 hours agorootparentThe process of evolution acts on organic systems, it doesn&#x27;t act on quantum fields.I appreciate there&#x27;s some (imv strange) sense of &#x27;intelligence&#x27; where &#x27;finding the right puzzle piece&#x27; counts. I cannot fathom why we care about such a notion, and it seems to have almost nothing to do with what we do care about re &#x27;intelligence&#x27;.We care about that thing animals do, that thing which some do better than others. That thing which evolution brought about for (rapid) adaptive fitness to one&#x27;s environment.&#x27;Everything else is stamp collecting&#x27;We already have a perfectly good understanding of puzzles and their solutions -- animals are their inventorsIntelligence isnt in the solution to a puzzle it&#x27;s in its design, and especially, in what one does when one cannot solve it -- ie., how one adaptsThe csci view of &#x27;intelligence&#x27; is an act of self-aggrandising, it turns out to be: csci!This is none-sense. reply ben_w 6 hours agorootparentWe can simulate evolution in a computer, and this is used as a form of AI directly.That said, the way you&#x27;re using biological evolution in your comment sounds as much like a strange analogy as all of the others: we may have some genetically programmed responses to snakes (bad) and potential mates (good), but we can also say that a loss of hydraulic pressure in our brain is a stroke, and use electrical signals to both read from and write to the brain.What we evolved to think, while interesting from a social perspective, seems to me like the least interesting part of our brains from an AI perspective — it&#x27;s the bit that looks like a hard-coded computer program, not learning, on the scale of a human life and seen from within. reply mjburgess 6 hours agorootparenti&#x27;m referring to evolution as the process by which animals were builtif aliens had come down and given us laptops, rather we invented digital machines, then likewise i&#x27;d be talking about the relevant materials science, physics etc.reverse engineering a laptop to figure out how it works would require extremely little computer science, and &#x27;only at the end&#x27;the reason digital computers are interesting and useful is that they route electricity around devices which are designed to be responsive to one another. the patterns of activation, as managed by the CPU, are weakly describable by abstract algorithms like sortingstarting with a laptop, and no further information, we&#x27;d be 100(s)+ years of research away from needing to understand that CPUs were implementing a sorting algorithmand importantly, that it is doing so has almost nothing to do with the value of the device -- which lies in its ability to provide &#x27;dynamical power and modulation of operation&#x27; using electricitywe&#x27;re in the same situation with animals and people think that, what, understanding gradient descent or backprop is helpful? this is just some csci bs reply ben_w 5 hours agorootparentI&#x27;m not really following you, sorry; this is all too disjointed.> we&#x27;re in the same situation with animals and people think that, what, understanding gradient descent or backprop is helpful? this is just some csci bsAssuming I&#x27;ve actually got your point for this (and I&#x27;m not sure I have):The backpropagation algorithm itself might be \"just some csci bs\" (it sure has vibes of \"let us shortcut the maths rather than find out how our brains did it\"), but gradient descent is nice and general-purpose — much like how evolution is both good for biology and in simulation for everything else. reply mjburgess 5 hours agorootparentTo get my point, imagine a laptop was delivered by an alien in the year 1900.Now, try to take that seriously and think about the laptop as an actual object of experimental curiosity -- what exactly does science need to invent, discover, describe etc. to understand the operation of that laptop?99.999% of that new knowledge has to be in physics and chemistry, before the tiny 0.0001% of theoretical csci knowlegde is brought to bare.Consider how impossible it would be to apply any csci knowledge first: we do not even have the ability to measure the cpu state! So we could not even identify any part of the system with 0s, 1s, etc.Now: that&#x27;s a laptop!Imagine now you&#x27;re dealing with an animal.Hopefully its now clear how ridiculous it is to describe basically any aspect of our mode of operation by starting with trivial little csci algorithms. It would be insane even with an actual electronic computer, let alone an organic system.A system whereby clearly our organic properties are radically fundamental to our mode of operation reply TeMPOraL 4 hours agorootparentWrong.Consider two hypothetical versions of this. One, the exact scenario as you described - history unfolded like it did, until the 1900 alien incident. CS and information theory is in its infancy. You&#x27;re correct that most of the necessary work would first go to physics and chemistry and their various spin-off fields, because that&#x27;s what&#x27;s needed to build tools necessary to inspect the machine in full detail. The math would develop along the way, and eventually enough CS to make sense of the observations made before.Now for an alternate scenario: it&#x27;s the 1900 again, with the twist that CS is already well-developed theoretical field of mathematics (IDK, perhaps the same aliens dropped us a mechanical computer in year 1800). We&#x27;d still need to push physics and chemistry (and spin-offs) forward, but this time, we would know what we&#x27;re looking for. We&#x27;d know the thing does computation, we&#x27;d be able to model what kind of computation it does. The question would change from \"what does this thing do\" to \"how exactly does it compute the specific things we know it does\". I imagine this would speed up the process of getting a complete picture, because it&#x27;s easier to understand a specific solution to a problem once you know the answer, than it is to figure out the answer along with the solution.In terms of understanding the brain, we are in the second situation. We may still know little about how the gooey thing ticks, but we have a growing understanding of what comes out of all that ticking, and a very good understanding of the fundamental rules of ticking. reply mjburgess 3 hours agorootparentNearly every physical system implements every algorithm -- if you wanted to find what in a laptop was &#x27;sorting numbers&#x27; that would every part.The light emitted by the screen is being &#x27;sorted&#x27; as it is scanned out, the heat air by the fan is being &#x27;sorted&#x27; as it swirls around, etc.You cannot ask, \"what physical system implements this algorithm?\" as an investigative question, the answer is: nearly all of them.This is why computable functions, ie., pure algorithms, are explanatorily useless. They play only a (observer-relative) &#x27;design role&#x27; in creating real programs. reply ben_w 2 hours agorootparentYou&#x27;re normally a lot more coherent than you have been in this thread, so… are you feeling alright? Getting enough sleep?> The light emitted by the screen is being &#x27;sorted&#x27; as it is scanned out, the heat air by the fan is being &#x27;sorted&#x27; as it swirls around, etc.This reads like either you&#x27;re trolling, or that was written by an LLM, or English isn&#x27;t your native language, or don&#x27;t know what &#x27;sorting&#x27; is, or you don&#x27;t know what screens and fans do.It&#x27;s so fundamentally wrong I was actually tempted to get ChatGPT to respond to it, but that would be a bit mean and add little.You&#x27;re better than this. What&#x27;s wrong? reply mjburgess 2 hours agorootparentthere&#x27;s nothing garbled about this idea -- not sure about my messaging in this thread, maybe the explanations are a bit looser todayA computable function is a function from naturals to the naturals typically specified as an algorithm: a sequence of steps by which input numbers are transformed into output numbers.Eg., consider sorting: 101, 001, 111, etc.Now any physical system can have any component part associated with 0 or 1. There is no reason, a priori, to suppose that voltage flux on a CPU is a \"1\" or a \"0\" any more than to associate a photon emission.If one associates a photon emission at some location with a 0, and another with a 1, then displaying content on a screen is a form of sorting.Likewise a planet orbiting the sun is implementing a while(true) i = -1*i, if one associates -1&#x2F;1 with position of the planet orbiting the sun. This is the heart of &#x27;reversible computing&#x27;.The only reason we associate some microscopic part of a CPU with 0, 1, etc. is by design it is something we as observers bring to bare on our interpretation of the physical system. But there&#x27;s an infinite number of such attributions. We would only ever come to conclude that voltage flux across transitiors was relevant to the operation of a laptop via physics experiments --- no hope via computer science.This is very important for understanding why csci is presently useless and misinformative as far as the brain is concerned. There are an infinite number of 0&#x2F;1 attributions to make, and infinite number of algorithms being implemented etc. almost all of those are irrelevant.Just, as you detect the absurdity, of using sorting algorithms to understand how an LCD works. This is presently less absurd than people talking about neural networks and equivocating with brain structures reply TeMPOraL 1 hour agorootparent> This is very important for understanding why csci is presently useless and misinformative as far as the brain is concerned. There are an infinite number of 0&#x2F;1 attributions to make, and infinite number of algorithms being implemented etc. almost all of those are irrelevant.What makes brain a computer, and the air molecules in your room not a computer, is entropy. The behavior of air molecules is effectively random, the behavior of a brain very much not so.Also, the universe isn&#x27;t an uniform temperature soup where everything is equally random. There&#x27;s energy cost to complexity, and there&#x27;s a likelihood penalty to complexity. This gives us good confidence that the brain isn&#x27;t doing something absurdly incomprehensible: it was made by evolution, which is a dumb, brute-force, short-term process. It didn&#x27;t go out of its way to make things complex - it went with the first random thing that improved survival, which, being random, means generally the simplest thing that could work well enough.Whatever trickery made brains tick, it must be something that&#x27;s a) dumb enough for evolution to stumble on it, b) generic enough to scale up by steps small enough for evolution to find, all the way to human level, while c) conferring a survival advantage at every step of the way. Sure, the brain design isn&#x27;t optimal or made in ways we&#x27;d consider elegant, but it&#x27;s also not actively trying to be confusing. There&#x27;s literally a survival penalty to being confusing (by means of metabolic cost)!All to say, we&#x27;re not dealing with a high-entropy blob of pure randomness. We&#x27;re dealing with a messy and unusual system, but one that was strongly optimized to be as simple as one could get away with. This narrows down the problem space considerably, and CS is our helpful guide, at the very least by putting lower bounds on complexity of specific computations. reply mjburgess 29 minutes agorootparentAs soon as you add these physical constraints on what counts as a &#x27;computer&#x27; you&#x27;re no longer talking about computers as specified by turing, nor computer science -- which is better called Discrete Mathematics.You&#x27;re conflating the lay sense of the term meaning &#x27;that device that i use&#x27; with the technical sense. You cannot attribute properties of one to the other. This is the heart of this AI pseudoscience business.All circles are topologically equivalent to all squares. That does not mean a square table is &#x27;equivalent&#x27; to a circular table in any relevant sense.If you want to start listing physical constraints: the physical state can be causally set deterministically, the physical state evolves causally, the input and output states are measurable, and so on -- then you end up with a &#x27;physical computer&#x27;.Fine, in doing so you can exclude the air. But you cannot exclude systems incapable of transfering power to devices (ie., useless systems).So now you add that: a device which, through its operation, powers other devices. You keep doing that and you end up with &#x27;electrical computers&#x27; or a very close set of physical objects with physical propeties.By the time you&#x27;ve enumerated all these physical properties, none of your formal magical &#x27;substrates dont matter&#x27; things apply. Indeed, you&#x27;ve just shown how radically the properties of the substrate do apply -- so many properties end up being required.Now, as far as brains go -- the properties of &#x27;physical computers&#x27; do not apply to them: their input&#x2F;output states may be unmeasurable (eg., if QM is involved); they are not programmable (ie., there is no deterministic way to set their output state); they do not evolve in a causally deterministic way (sensitive to biochemical variation, randomness, etc.).Either you speak in terms of formalism, in which case you&#x27;re speaking in applicable non-explanaotry toys of discrete mathematicans&#x27;; or you start trying to explain actual physical computers and end up excluding the brain.All this is to avoid the overwhelmingly obvious point: the study of biological organisms is biology. spindle 13 hours agorootparentprevAnd also comparing brains to clockwork. reply crustacean111 15 hours agoparentprevCNNs actually are biologically inspired. The receptive field in a CNN mimics the way that cortical neurons only respond to stimuli in a restricted region of the visual field. Different cortical neurons have receptive fields that partially overlap to cover the whole visual field [1].[1] - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Convolutional_neural_network reply jakobson14 14 hours agorootparentYou&#x27;re going to have to dig deeper. The concept of a receptive field goes all the way back to convolutional filters.It&#x27;s not surprising that we found out later the brain also uses such a fundamental element of signal theory. reply SubiculumCode 13 hours agorootparentOh good. So you do admit that there are useful parallels between signal processing, statistical processing, and the brain. reply vkou 13 hours agorootparentprevSure, and airplanes are inspired by birds. That doesn&#x27;t mean that detailed studies of the Boeing 747 are going to unlock a lot of hitherto unknown mysteries of heron behaviour. reply jacobsimon 10 hours agorootparentI mean, I know you’re just providing an analogy, but people are still studying the physics of bird flight and we’re nowhere close to building machines yet that can maneuver the way birds can. https:&#x2F;&#x2F;www.quantamagazine.org&#x2F;geometric-analysis-reveals-ho... reply ben_w 6 hours agorootparentI could believe \"we have more to learn\", but not \"we&#x27;re nowhere close\":https:&#x2F;&#x2F;youtu.be&#x2F;w6VLzKACnS8?si=DZgOPuBRG4Vt98su reply jacobsimon 3 hours agorootparentTIL replywslh 14 hours agoparentprevOnly an observer of the topic but I think it is good to review Koch&#x27;s book about the real complexity of a single neuron [1].[1] https:&#x2F;&#x2F;www.amazon.com&#x2F;Biophysics-Computation-Information-Co... reply mrstone 15 hours agoparentprevA neurologist is a medical doctor. Neuroscientists are the PhDs who do the actual research. reply blovescoffee 12 hours agoparentprevDude. What holy and special work do you do? There&#x27;s nothing dumb or dull in searching for analogous structure between two effective machines, neither of which we understand. reply hliyan 11 hours agoparentprev\"brain seems shallow and neural networks are deep, ergo neural networks are doing it wrong\"Please don&#x27;t claim things the author didn&#x27;t. What I read was \"ergo (artificial) neural networks may be missing a trick\" reply NoToP 7 hours agoparentprevI disagree profoundly.There are things the brain does we have not yet been able to reproduce with a neural network, or to the extent we have seemingly with excessive resources of training and network size. Therefore there is some salient feature of neurology which has been overlooked. I don&#x27;t think it is necessary to mimic biology down to the exact function of real neurons, but there must in fact be something we are neglecting to mimic. reply ben_w 7 hours agorootparentPossibly, but it may also be that we&#x27;re training them wrong.\"Book smart, not street smart\" (to use a catchphrase) would apply perfectly to GPT models: brain the size of a rodent&#x27;s, with 50,000 year&#x27;s experience of reading Reddit, Wikipedia, and StackOverflow, but no \"real life\" experiences of its own. reply bjourne 13 hours agoparentprevFirst, I wonder how you got access to the article? It is behind a paywall and not yet uploaded to the sites I usually find paywalled articles on.Second, there is no need to compare brains to neural networks because brains are neural networks. Neurons form vertices and axons edges connecting the aforementioned. What you are perhaps thinking of are artificial neural networks - most of which are very dissimilar to brains. But even then you are wrong. Artificial Izhikevich and Hodgkin-Huxley neural networks attempts to closely mimic the behavior of real neurons.While deep, hierarchical artificial neural networks have been more successful than biologically plausible ones, that may be because the technology isn&#x27;t ready yet. After all, the perceptron was invented in the 1950&#x27;s but didn&#x27;t become prominent until the 2010&#x27;s (or so). Perhaps we need new memories that better map to (real) neural network topologies, or perhaps 3d chips that can pack transistors in the same way brains pack neurons. reply mjan22640 8 hours agorootparentA neuron is analogous to a 3d integrated circuit rather to a transistor. A molecule acts like a transistor https:&#x2F;&#x2F;medium.com&#x2F;the-physics-arxiv-blog&#x2F;the-origin-of-life...Changes in mechanical pressure, electric field, other molecules attachment, photon absorption, can control the conductivity.Organic semiconductors designed to fit like lego bricks to naturally build the desired structure are IMHO the way to go to produce 3d circuits, rather than layered silicone litography. reply ben_w 6 hours agorootparent> siliconeI&#x27;ve seen this particular mistake a lot recently. New and exciting auto-corrupt from the latest version of iOS?Given that our brains rewire themselves live, which ANNs can only do by being excessively connected and updating weights to&#x2F;from zero, silicone (I&#x27;m thinking mainly the oil form) may be a better inspiration than lego.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Silicone reply mjan22640 5 hours agorootparentYes, puzzle pieces would be more accurate than lego.The bonds that silicone forms do not AFAIK allow as rich variety of polymers as carbon. reply ben_w 5 hours agorootparentSilicone, with the e on the end, is one of the main polymers. replyradarsat1 9 hours agoparentprev> every time some neurologist tried to compare brains to neural networksValue of this comment aside, it kind of makes me chuckle how casually it (and other comments in this thread) just drops the word \"artificial\" from neural networks here, specifically when comparing with neurology. The irony is funny. Like, somehow we&#x27;ve forgotten why we call them that in the first place, exactly when talking about the thing that inspired the approach. reply b33j0r 15 hours agoparentprevAgreed, but I do also think that order emerged from chaos. It’s an easy claim when order is defined by itself!But in reality, we’re equipped exactly to exist, and we still wonder why in a backwards way, even with education (guilty!)AI is the task of playing God like toddlers at recess, and LLMs the tower of babel. I still wanna play, it’s fun reply andromaton 13 hours agoparentprevBooks and articles I was reading in the 80s (eg Minsky and Papert, Byte magazine) were referring to Rosenblatt and retinas. reply peyton 15 hours agoparentprevI dunno, failure seems okay. Wouldn’t expect a better paradigm to beat SOTA at first. It’s totally plausible that neurons use eg. transposons in a way we don’t yet have the instrument resolution to characterize, which would suggest that you don’t need 1000 layers, but a lookup table or something. reply svara 7 hours agoparentprevDoesn&#x27;t know what a neurologist is, knows they do shit work. reply nathias 9 hours agoparentprevMetaphores and analogies are important tools of thinking, even in science, some bear fruits some lead to errors, but we can&#x27;t know in advance. reply SubiculumCode 13 hours agoparentprevIf you read this article, I think most would understand that it is primarily aimed at other neuroscientists, and only using ML structures an an analogy only, and I think a somewhat useful one to boot. The real point of the article was to propose a general hierarchy for how information flows in the brain, to emphasize the importance of subcortical brain even in higher order cognition, and proposes how simultaneous processing of multiple levels of representation can inform action and thought.As a developmental neuroscientist, I found the article insightful and thought provoking. Further, it is quite consistent with major hypotheses in psychology, how the hippocampus works (a subcortical structure) and combines information into memories: See fuzzy trace theory [1], for example.Your dismissive tone is unappreciated, ill-informed, and crass.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Fuzzy-trace_theory reply visitor4711 13 hours agorootparentfully agree reply __loam 13 hours agoparentprevAs a biomedical engineer who went into software, thank you for this comment lol. So tired of rehashing this. reply phlogisticfugu 11 hours agoprevdeep learning models have already been permitting \"shallow signals\" for a while. see \"skip connections\"https:&#x2F;&#x2F;theaisummer.com&#x2F;skip-connections&#x2F; reply MagicMoonlight 11 hours agoprevIf it was shallow then it wouldn’t take 25 years for a human brain to fully train. The fact that some parts of it need that much data mean they must be way up the hierarchy. reply gwern 1 hour agoparentThat doesn&#x27;t follow. Shallow networks can be harder to train than a deep one, which is one of the old arguments for why you should train a deep NN despite its many disadvantages (like latency - often a matter of life and death for biological organisms!). The depth allows easier learning.This is why today, if you need a low-latency NN, which means a shallow one, often your best bet is to train a deep one first and then distill or prune it down into a shallow one. Because the deep one is so much easier, while training a shallow one from scratch without relying on depth may be an open research question and effectively impossible. reply GranularRecipe 8 hours agoparentprevThe reason for deep learning is that shallow networks are very hard (or impossible) to train. In that sense, long time of training is evidence for shallow networks. reply IshKebab 8 hours agorootparentNo it&#x27;s because shallow networks can&#x27;t express complex functions. If you think about it the shallowest network is pretty much a lookup table. They can theoretically model any function, but the number of parameters needed means in practice they can&#x27;t. Deep networks can learn much more complex functions for the same number of parameters. reply simiones 3 hours agorootparent> They can theoretically model any function, but the number of parameters needed means in practice they can&#x27;t.Even theoretically, no they can&#x27;t. They can theoretically model any continuos function.Plus, even for continuous functions, the theorem only proves that, for any function, there exists some NN that approximates it to arbitrary precision. It is not known whether there is some base NN + finite training set that could be used to arrive at that target NN using some algorithm in a finite number of steps. reply GranularRecipe 1 hour agorootparentThis is not only an issue for shallow networks. As far I know, both points apply to all feed-forward networks regardless of depth. reply simiones 45 minutes agorootparentYes, both apply regardless of depth (as long as it is finite, I imagine). reply nightski 3 hours agorootparentprevI&#x27;m not sure it is all that interesting of a distinction seeing as non-continuous functions can be approximated by continuous ones (basically the entire premise of a digital computer). reply simiones 3 hours agorootparentI don&#x27;t think this is right at all. Digital computers express non-continuous functions, and they sometimes use those to approximate continuous functions.For example, for a function f(x) defined on R with f(x) = -x if x = 0, how would you approximate it by a continuous function g(x) with precision lower than, say, 1 (i.e. |f(x) - g(x)|a Universal approximatorYes that&#x27;s exactly my point. A lookup table is a universal approximator. Good luck making AI with LUTs.It&#x27;s kind of like the halting problem or the no-free-lunch theorem. Interesting academic properties but they don&#x27;t really have any practical significance and often confuse people into thinking that things like formal verification and lossless compression are impossible. replybjornsing 7 hours agoprev> This shallow architecture exploits the computational capacity of cortical microcircuits and thalamo-cortical loops that are not included in typical hierarchical deep learning and predictive coding networks.As I understand it the thalamus is basically a giant switchboard though. I see no reason to believe that it never connects the output of one cortical area to the input of another, thus doubling the effective depth of the neural network. (I haven’t read this paper though, as it was behind a paywall.) reply Salgat 14 hours agoprevThe brain communicates with itself, so deep layers are equivalent to sections of the brain talking to each other. The only relevance white matter depth has is with regard to how it&#x27;s trained, and since it doesn&#x27;t use gradient descent, it&#x27;s irrelevant to neural networks in that regard. reply blovescoffee 12 hours agoparentIntercommunication does not equal layer depth. reply Salgat 2 hours agorootparentWhy not? All a deep neural network is doing is progressive data transformations into something more abstract and meaningful to later layers. reply Simon_ORourke 9 hours agoprevJudging by some of the levels of driving around these parts, the brain may be very shallow indeed. reply low_tech_punk 11 hours agoprev [–] Replay of Jeff Hawkins group’s A Thousand Brains theory? reply SubiculumCode 6 hours agoparent [–] \"his theory\" lol. Jeff Hawkins is a bit player replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The articles touch upon a wide array of brain function-related topics such as cortical network organization, neural processing in diverse brain regions, the significance of certain brain parts in cognition and perception, the adaptability of neural circuits, and the role of neurotransmitters in brain activity and behaviour.",
      "The conventional viewpoint of hierarchical processing in the brain is being questioned by the articles, underscoring the importance of subcortical regions and thalamo-cortical loops in neural processing.",
      "The utilization of statistical methods and computational models to comprehend brain function is also discussed in the articles."
    ],
    "commentSummary": [
      "The article and subsequent discussions focus on the relationship between artificial neural networks and the complexity of the human brain.",
      "There is an ongoing debate regarding the value of studying the human brain to enhance the development and understanding of neural network technology.",
      "The discussion also underscores the differences in architecture between brains and computers, the constraints of current neuroscience research, and the application of metaphors and analogies in neuroscience."
    ],
    "points": 182,
    "commentCount": 158,
    "retryCount": 0,
    "time": 1698625718
  },
  {
    "id": 38069197,
    "title": "Private equity is devouring the U.S. economy",
    "originLink": "https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/",
    "originBody": "SKIP TO CONTENT Site Navigation Popular Latest Newsletters Sign In Subscribe MORE FROM THE NEW RULES The Secretive Industry Devouring the U.S. Economy ROGÉ KARMA Biden Says Goodbye to Tweezer Economics BRIAN CALLACI The 1970s Economic Theory That Needs to Die ROGÉ KARMA The College Backlash Is Going Too Far DAVID DEMING IDEAS The Secretive Industry Devouring the U.S. Economy Private equity has made one-fifth of the market effectively invisible to investors, the media, and regulators. By Rogé Karma Illustration by The Atlantic. Sources: Shutterstock; Getty. OCTOBER 30, 2023, 7:30 AM ET SHARE SAVED STORIES SAVE Updated at 9:30 a.m. ET on October 30, 2023 The publicly traded company is disappearing. In 1996, about 8,000 firms were listed in the U.S. stock market. Since then, the national economy has grown by nearly $20 trillion. The population has increased by 70 million people. And yet, today, the number of American public companies stands at fewer than 4,000. How can that be? One answer is that the private-equity industry is devouring them. When a private-equity fund buys a publicly traded company, it takes the company private—hence the name. (If the company has not yet gone public, the acquisition keeps that from happening.) This gives the fund total control, which in theory allows it to find ways to boost profits so that it can sell the company for a big payday a few years later. In practice, going private can have more troubling consequences. The thing about public companies is that they’re, well, public. By law, they have to disclose information about their finances, operations, business risks, and legal liabilities. Taking a company private exempts it from those requirements. That may not have been such a big deal when private equity was a niche industry. Today, however, it’s anything but. In 2000, private-equity firms managed about 4 percent of total U.S. corporate equity. By 2021, that number was closer to 20 percent. In other words, private equity has been growing nearly five times faster than the U.S. economy as a whole. James Surowiecki: The method in the market’s madness Elisabeth de Fontenay, a law professor at Duke University who studies corporate finance, told me that if current trends continue, “we could end up with a completely opaque economy.” This should alarm you even if you’ve never bought a stock in your life. One-fifth of the market has been made effectively invisible to investors, the media, and regulators. Information as basic as who actually owns a company, how it makes its money, or whether it is profitable is “disappearing indefinitely into private equity darkness,” as the Harvard Law professor John Coates writes in his book The Problem of Twelve. This is not a recipe for corporate responsibility or economic stability. A private economy is one in which companies can more easily get away with wrongdoing and an economic crisis can take everyone by surprise. And to a startling degree, a private economy is what we already have. America learned the hard way what happens when corporations operate in the dark. Before the Great Depression, the whole U.S. economy functioned sort of like the crypto market in 2021. Companies could raise however much money they wanted from whomever they wanted. They could claim almost anything about their finances or business model. Investors often had no good way of knowing whether they were being defrauded, let alone whether to expect a good return. Then came the worst economic crisis in U.S. history. From October to December of 1929, the stock market lost 50 percent of its value, with more losses to come. Thousands of banks collapsed, wiping out the savings of millions of Americans. Unemployment spiked to 25 percent. The Great Depression generated a crisis of confidence for American capitalism. Public hearings revealed just how rampant corporate fraud had become before the crash. In response, Congress passed the Securities Act of 1933 and the Securities Exchange Act of 1934. These laws launched a regime of “full and fair disclosure” and created a new government agency, the Securities and Exchange Commission, to enforce it. Now if companies wanted to raise money from the public, they would have to disclose a wide array of information to the public. This would include basic details about the company’s operations and finances, plus a comprehensive list of major risks facing the company, plans for complying with current and future regulations, and documentation of outstanding legal liabilities. All of these disclosures would be reviewed for accuracy by the SEC. This regime created a new social contract for American capitalism: scale in exchange for transparency. Private companies were limited to 100 investors, putting a hard limit on how quickly they could grow. Any business that wanted to raise serious capital from the public had to submit itself to the new reporting laws. Over the next half century, this disclosure regime would underwrite the longest period of economic growth and prosperity in U.S. history. But it didn’t last. Beginning in the “Greed Is Good” 1980s, a wave of deregulatory reforms made it easier for private companies to raise capital. Most important was the National Securities Markets Improvement Act of 1996, which allowed private funds to raise an unlimited amount of money from an unlimited number of institutional investors. The law created a loophole that effectively broke the scale-for-transparency bargain. Tellingly, 1997 was the year the number of public companies in America peaked. From the November 2018 issue: The death of the IPO “Suddenly, private companies could raise all the money they want without even thinking about an IPO,” De Fontenay said. “That completely undermined the incentives companies had to go public.” Indeed, from 1980 to 2000, an average of 310 companies went public every year; from 2001 to 2022, only 118 did. The number briefly shot up during the coronavirus pandemic but has since fallen. (Over the same time period, the rate of mergers and acquisitions soared, which also helps explain the decline in public companies.) Meanwhile, private equity has matured into a multitrillion-dollar industry, devoted to making short-term profits from highly leveraged transactions, operating with almost no regulatory or public scrutiny. Not all private-equity deals end in calamity, of course, and not all public companies are paragons of civic virtue. But the secrecy in which private-equity firms operate emboldens them to act more recklessly—and makes it much harder to hold them accountable when they do. Private-equity investment in nursing homes, to take just one example, has grown from about $5 billion at the turn of the century to more than $100 billion today. The results have not been pretty. The industry seems to have recognized that it could improve profit margins by cutting back on staffing while relying more on psychoactive medication. Stories abound of patients being rushed to the hospital after being overprescribed opioids, of bedside call buttons so poorly attended that residents suffer in silence while waiting for help, of nurses being pressured to work while sick with COVID. A 2021 study concluded that private-equity ownership was associated with about 22,500 premature nursing-home deaths from 2005 to 2017—before the wave of death and misery wrought by the pandemic. Eventually, the public got wind of what was happening. The pandemic death count focused attention on the industry. Journalists and watchdog groups exposed the worst of the behaviors. Policy makers and regulators, at long last, began to take action. But by then, much of the damage had been done. “If we had some form of disclosure, we probably would have seen regulatory action a decade earlier,” Coates told me. “But instead, we’ve had 10-plus years of experimentation and abuse without anyone knowing.” Something similar could be said about any number of industries, including higher education, newspapers, retail, and grocery stores. Across the economy, private-equity firms are known for laying off workers, evading regulations, reducing the quality of services, and bankrupting companies while ensuring that their own partners are paid handsomely. The veil of secrecy makes all of this easier to execute and harder to stop. Private-equity funds dispute many of the criticisms of the industry. They argue that the horror stories are exaggerated and that a handful of problematic firms shouldn’t tarnish the rest of the industry, which is doing great work. Freed from onerous disclosure requirements, they claim, private companies can build more dynamic, flexible businesses that generate greater returns for shareholders. But the lack of public information makes verifying these claims difficult. Most careful academic studies find that although private-equity funds slightly outperformed the stock market on average prior to the early 2000s, they no longer do so. When you take into account their high fees, they appear to be a worse investment than a simple index fund. “These companies basically get to write their own stories,” says Alyssa Giachino, the research director at the Private Equity Stakeholder Project. “They produce their own reports. They come up with their own numbers. And there’s no one making sure they are telling the truth.” In the roaring ’20s, the lack of corporate disclosure allowed a massive financial crisis to build up without anyone noticing. A century later, the growth of a new shadow economy could pose similar risks. The hallmark of a private-equity deal is the so-called leveraged buyout. Funds take on massive amounts of debt to buy companies, with the goal of reselling in a few years at a profit. If all of that debt becomes hard to pay back—because of, say, an economic downturn or rising interest rates—a wave of defaults could ripple through the financial system. In fact, this has happened before: The original leveraged buyout mania of the 1980s helped spark the 1989 stock-market crash. Since then, private equity has grown into a $12 trillion industry and has begun raising much of its money from unregulated, nonbank lenders, many of which are owned by the same private-equity funds taking out loans in the first place. Meanwhile, interest rates have reached a 20-year high, posing a direct threat to private equity’s debt-heavy business model. In response, many private-equity funds have migrated toward even riskier forms of backroom financing. Many of these involve taking on even more debt on the assumption that market conditions will soon improve enough to restore profitability. If that doesn’t happen—and many of these big deals fail—the implications could be massive. Joe Nocera and Bethany McLean: What financial engineering does to hospitals The industry counters that private markets are a better place for risky deals precisely because they have fewer ties to the real economy. A traditional bank has a bunch of ordinary depositors, whereas if a private-equity firm goes bust, the losers are institutional investors: pension funds, university endowments, wealthy fund managers. Bad, but not catastrophic. The problem, once again, is that no one knows how true that story is. Banks have to disclose information to regulators about how much they’re lending, how much capital they’re holding, and how their loans are performing. Private lenders sidestep all of that, meaning that regulators can’t know what risks exist in the system or how tied they are to the real economy. “Everything could be just fine,” says Ana Arsov, a managing director at Moody’s Investors Service who leads research on private lending. “But the point is that we don’t have the information we need to assess risk. Who is making these loans? How big are they? What are the terms? We just don’t know. So the worry is that the leverage in the system might grow and grow and grow without anyone noticing. And we really don’t know what the effects could be if something goes wrong.” The government appears to be at least somewhat aware of this problem. In August, the SEC proposed a new rule requiring private-equity fund advisers to give more information to their investors. That’s better than nothing, but it hardly addresses the bad behavior or systemic risk. Nearly a century ago, Congress concluded that the nation’s economic system could not survive as long as its most powerful companies were left to operate in the shadows. It took the worst economic cataclysm in American history to learn that lesson. The question now is what it will take to learn it again. This article originally stated that Ana Arsov works for Moody's Analytics. In fact, she works for Moody's Investors Service. Enjoy unlimited access to The Atlantic. Subscribe Now",
    "commentLink": "https://news.ycombinator.com/item?id=38069197",
    "commentBody": "Private equity is devouring the U.S. economyHacker NewspastloginPrivate equity is devouring the U.S. economy (theatlantic.com) 181 points by fortran77 3 hours ago| hidepastfavorite233 comments chollida1 3 hours agoThis is, IMHO, a serious problem for the markets and regular investors.Microsoft went public for a valuation of around $300M and is trading over a $1T now. This means that regular investors had a chance at all this growth.Newer companies like AirBNB and Uber went public at what could be their max market cap valuation of billions so investors wont&#x27; get much of a chance to make money from these companies.In addition to this problem of private investors(VC&#x27;s) taking most of the profits, we now have such concentration of wealth that the big PE firms can buy alot of what used to be small businesses and roll them up.Vet clinics, medial practices, engineering firms, etc all use to to thrive on being 20 person shops are now routinely being bought up by PE firms and rolled into larger companies which means far fewer entrepreneurs or chances for up and coming employees to buy into the firm from the founders, which helps stall careers.Heck you see it now with these firms buying up single family housing in US cities now and then renting them back to people, transforming regular middle class people from home owners to renters, and transferring the home appreciate from the middle and lower class to the PE limited partners ensuring the rich get richer and the middle class disappears even faster. reply spiralpolitik 2 hours agoparentIt&#x27;s worse than that. The 401k generation will begin think about retiring in the next few years. Most will discover that their 401K, despite maximum contributions, will be insufficient to retire on.This will either keep older workers in the workforce longer, preventing younger workers for getting into positions, or it will result in discrimination against older workers who will find themselves unable to get jobs, let go, or laid off to make room for younger, cheaper workers.The expectation for your 401k is that it&#x27;s going to grow by 6-8% each year. If there isn&#x27;t any room for growth in the market then it&#x27;s going to be hard to deliver that going forward, compounding the problem for later generations who probably won&#x27;t be inheriting anything from their parents. reply ilamont 2 hours agorootparent> despite maximum contributionsThe people with insufficient 401k balances aren&#x27;t making the max. They&#x27;re doing the minimum, starting too late, or selecting the most conservative investments such as bond funds (NAVs have collapsed) or cash. Many plans don&#x27;t have good low cost index funds, so people are forced into actively managed funds some of which are complete garbage in terms of fees and returns.Workers living paycheck to paycheck (61% of the population, see https:&#x2F;&#x2F;www.cnbc.com&#x2F;2023&#x2F;07&#x2F;31&#x2F;61percent-of-americans-live-...) means that contributions aren&#x27;t realistic for millions of people.Further, a lot of people don&#x27;t understand how they work, and never contribute, even if they could. Even with matching contributions. Or, they don&#x27;t trust them after the 2008 collapse or a vague suspicion that the system is rigged against them. This is what I hear from my spouse; many of her colleagues won&#x27;t touch the solid 401k investments offered by their employer.Some employers have made changes that makes it easier to get started, but many never will, assuming (wrongly) that social security is their retirement solution.Your predictions about older workers working longer is correct. You can see it now, seniors working at grocery stores into their 70s and even older. reply jandrewrogers 1 hour agorootparent> Workers living paycheck to paycheck (61% of the populationAccording to US BLS and Federal Reserve studies, only about 15% of the population necessarily lives paycheck-to-paycheck. The median US household has a ~$12,000 surplus per year after all ordinary expenses. Note that \"ordinary expenses\" includes car payments on a BMW, the latest iPhone, and other by-no-means-necessary expenditures, and also includes all healthcare costs.If 61% of the US population is living paycheck-to-paycheck, it isn&#x27;t because they need to. Americans have very high income surpluses compared to the rest of the developed world. 15% of the population necessarily living paycheck-to-paycheck is still a lot of people, but it implies 85% are not. reply ilamont 1 hour agorootparent> If 61% of the US population is living paycheck-to-paycheck, it isn&#x27;t because they need to.Consumers can share blame for not living below their means, needless wealth signaling, and financial illiteracy.But predatory entities are part of the problem, too - car dealers obscuring true costs of borrowing (\"how much do you want to pay per month?\"), credit card issuers jacking up rates to 37%, and real estate \"investors\" jacking up rents after buying mom & pop mobile homes and senior rental units knowing that tenants have nowhere else to go. Here&#x27;s one example from Montana:“I can’t tell you how many calls I got from folks that were older, like older than 55 or 60, that had lived in their same house for decades, had the same owner for decades who never raised the rent,” Huey said. “Then all of a sudden they lost their housing.”Huey and other providers across the state have heard countless stories of homeowners turning their rental property into Air-BnBs or evicting their long-term tenants in order to house their own children in increasingly affluent communities.https:&#x2F;&#x2F;billingsgazette.com&#x2F;news&#x2F;state-regional&#x2F;montana-seni... reply clbrmbr 55 minutes agorootparentRe: predatory landlords: if they are not breaking the law, are they really blameworthy? Seems like the previous landlord was naïve, or at least operating on an outdated worldview where local reputation mattered. (Hard to show up at the local Chamber or Elks or church when you are getting old folks kicked out of their homes).How to solve… I’d like to find a model to apply in my HOA to slow or reverse the corporate takeover of my community… reply renonce 38 minutes agorootparentThey are blameworthy for not getting public and sharing profits with regular people, rigging regular people by inflation replybluefirebrand 2 hours agorootparentprev> preventing younger workers for getting into positionsThis won&#x27;t matter anyways, or at least it feels that way.I have no real hope that jobs that open up above me will go to me or someone else in my cohort. What I think instead is one of three things will happen:1) Those job responsibilities will be split among remaining people as much as possible, and effectively remain vacant with other people scrambling to take over part of it. They will receive a tiny pay bump at most.2) Those job responsibilities will be filled by someone but pay nowhere near what the person retiring was making.3) The job will be automated somehow.Maybe this is too cynical but I really do feel like companies are getting better at making sure employees make exactly the minimum they will tolerate faster than employees are becoming intolerant of how little they are paid. reply HumblyTossed 7 minutes agorootparent> 3) The job will be automated somehow.If we&#x27;re talking middle management, that&#x27;s basically just an automated spreadsheet. reply nradov 2 hours agorootparentprevThose are the things that happen in static or declining companies. If you see those things happening then it&#x27;s time to look for a new job in a growing company, unless you&#x27;re already close to retirement. reply HumblyTossed 5 minutes agorootparentThis is happening all over the place and is the reason for the huge productivity&#x2F;wage gap over the past X decades. reply bluefirebrand 2 hours agorootparentprevMost companies have ups and downs. Longterm stable companies tend to be static, short term success can turn into cratering failure in a hurry, and no company can grow forever.When you&#x27;re interviewing, every company will swear they are growing rapidly and making oodles of money. How do you tell if they really are?If I could identify growing companies so easily I wouldn&#x27;t work at all, just make bank on the stock markets, right? reply nradov 1 hour agorootparentIt&#x27;s easy to tell if companies are actually growing. For public companies just read their quarterly financials. For private companies look through LinkedIn to check the pace of hiring and promotions.Of course there are no guarantees. If your current employer stops growing then it&#x27;s time to look for other opportunities.I don&#x27;t understand your point about the stock markets. All other investors have access to the same growth data about public companies. The growth rates are already priced in. reply jimmydddd 1 hour agorootparentprev--Static or declining companies Including companies recently purchased by PE. reply flashback2199 2 hours agorootparentprev> Most will discover that their 401K, despite maximum contributions, will be insufficient to retire on.How will that happen when there has been so much growth in the S&P? reply toomuchtodo 2 hours agorootparenthttps:&#x2F;&#x2F;www.nerdwallet.com&#x2F;article&#x2F;investing&#x2F;the-average-401...https:&#x2F;&#x2F;www.gao.gov&#x2F;blog&#x2F;growing-disparities-retirement-acco...https:&#x2F;&#x2F;www.gao.gov&#x2F;financial-security-older-americans(401k plans were a way for capital to con Americans that ditching pensions was the way to go; pension contributions became shareholder profits, and most did not or could not contribute to 401ks in any meaningful fashion) reply nightski 2 hours agorootparentWho do you think the shareholders are? That&#x27;s right, it includes 401(k) and retirement plan owners. It&#x27;s a way to diversify your retirement beyond a single company. A pension plan in a company that can disappear and that can make investments on your behalf without any control is the big con.The fact that people contribute less to their 401(k) means they care less about saving for retirement, not that the plans themselves are a con. I personally don&#x27;t even have a 401(k) because I am self employed and there are other options. reply toomuchtodo 2 hours agorootparenthttps:&#x2F;&#x2F;www.cnbc.com&#x2F;2021&#x2F;10&#x2F;18&#x2F;the-wealthiest-10percent-of-... (\"The wealthiest 10% of Americans own a record 89% of all U.S. stocks\")https:&#x2F;&#x2F;www.usnews.com&#x2F;news&#x2F;national-news&#x2F;articles&#x2F;2021-03-1... (\"Median household owns $15k in equities\")(unless you&#x27;re wealthy, you are a token participant in the capital markets) reply robertlagrant 2 hours agorootparent> > (\"The wealthiest 10% of Americans own a record 89% of all U.S. stocks\")This is tautologous. \"Wealthy\" means mostly \"built, and still owns a decent chunk of, a company whose shares are highly valued\".Also, I could, like my parents, own nothing in the stock market, but have a paid off house and decent savings and a state pension, and be doing well. Proportion of capital markets ownership is too skewed a metric to reason about. reply jwestbury 2 hours agorootparent> This is tautologous.No, it&#x27;s not, and it&#x27;s a problem that you&#x27;re thinking this way. A tautology would be \"Americans in the top 10% of wealth are wealthier than the bottom 90%.\" A tautology is necessarily true according to logic.Logic does not dictate that the top 10% own 90% of the equities. And, in fact, there&#x27;s a strong argument that societies with extreme inequality in wealth distribution are structurally unsound societies (I don&#x27;t mean that they&#x27;re economically unsound, though I&#x27;d argue that, too). reply mambru 1 hour agorootparentprevThis is not a tautology but a (not-so-good) measurement of inequality. reply nightski 2 hours agorootparentprevI&#x27;m fine being a token participant as long as it means I&#x27;ve been seeing significant gains over the past decade, which I have. reply toomuchtodo 2 hours agorootparentI&#x27;m not faulting the selfish position, simply pointing out the game is rigged for everyone except outliers (like yourself or the ultra wealthy). These are just facts, not feelings, when you review the data about who has sufficient cashflow for inflows into investments during accumulation phases as well as their current and potential future investment exposure to these asset classes.Congrats on the luck (no snark, honestly). But let us not extrapolate luck and personal anecdotes to solutions for systems. \"In God We Trust, all others must bring data\", working backwards from first principles, etc. reply nightski 2 hours agorootparentThey aren&#x27;t facts. The number of millionaires in the U.S. has exploded. Many are benefiting from the markets. It&#x27;s not luck.The fact that many would rather spend than save does not change that these opportunities are for everyone. The best selling car in America is the F-150 which is quite expensive... reply gottorf 1 hour agorootparent> The best selling car in America is the F-150To be fair, F-150 and other pickup truck sales figures are buoyed by fleet purchases. The better figure to cite may be that the average new car transaction is now north of $48k; ten years ago, it was around $30k, and this rise has beaten general inflation. reply Retric 2 hours agorootparentprevMillionaire is a fairly trivial threshold these days. Social security is now paying some people 54k&#x2F;year inflation adjusted which would take well over 1 million to safely generate.A couple living on social security + 2 million in assets may be financially secure but they are still middle class. reply toomuchtodo 2 hours agorootparentprev> They aren&#x27;t facts. The number of millionaires in the U.S. has exploded. Many are benefiting from the markets. It&#x27;s not luck.Are you sure it&#x27;s not luck?https:&#x2F;&#x2F;blogs.scientificamerican.com&#x2F;beautiful-minds&#x2F;the-rol... (\"The Role of Luck in Life Success Is Far Greater Than We Realized\")https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2018&#x2F;03&#x2F;01&#x2F;144958&#x2F;if-youre-...Ref: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.07068 (\"Talent vs. Luck: The Role of Randomness in Success and Failure\")https:&#x2F;&#x2F;www.pbs.org&#x2F;newshour&#x2F;economy&#x2F;making-sense&#x2F;analysis-i... (\"Analysis: If you’re rich, you’re more lucky than smart. And there’s math to prove it\")https:&#x2F;&#x2F;www.marketwatch.com&#x2F;story&#x2F;when-you-realize-how-much-... (\"When you realize how much luck goes into investing, you might change your methods\") reply beepbooptheory 1 hour agorootparentprevDo you think all prima facie economic problems can be resolved down to problems generally of individual responsibility&#x2F;spending choices like this? Or just this one? Does the prosperity of some always assert the culpability of the rest with regards to their own poverty? Is the measure of person always relative like this?What does it mean to you to live in world with other people in general? Are we all fundamentally competitors like this? Winners and losers in a game of skill (and definitely not of chance)? Does the existence of losers reinforce the necessity or merit of the game, of the structure in question? Or are we trying to make everyone winners, trying to teach them to get it together enough to not buy all their flashy cars and such? reply nightski 5 minutes agorootparentNo I don&#x27;t, but I do think in an ideal world it would. Not everyone wants to build wealth nor should they be compelled to. A society that gives people the options to do what they want (in the sense of building wealth vs spending it) would be ideal in my opinion.fnordpiglet 48 minutes agorootparentprevPension plans hold equity and other assets from many companies. They are essentially like mutual funds with a defined annuity payout.Defined benefit plans should never have died out, they should have been part of a total mix. There is no reason you can’t have pensions along side social security along side 401k&#x2F;IRA plans. This gives retirees multiple avenues for payout each with their own risk profile. The 401k is a great idea as a retirement supplement for folks who are interested in saving more and managing investments. But many (most?) people are not sophisticated enough to (a) take advantage of tax deferred savings vs paying rent and buying food, (b) muck with investment options roll overs and all the like.We are about to see a mass humanitarian catastrophe over the next 20 years as the 401k dependent generations retire, social security buckles, and we learn why pensions existed to begin with all over again. reply margalabargala 2 hours agorootparentprevPensions tend to be much more generous.They are also riskier.People see the generosity of pension plans and (understandably) want that, without having the risk. reply clbrmbr 51 minutes agorootparentprevTotally agree about diversification. Reliance on a company pension fund is terrifying.That said, the old pension model forced workers to make large contributions. The 401k model does not. (Unless your company has some amazing match deal… I’ve only ever seen shitty deals like 25% of up to 4% of salary, whereas more like a 30% savings rate is what’s really needed.) reply gosub100 2 hours agorootparentprev> means they care less about saving for retirementThey shouldn&#x27;t be \"caring\" so much about the high cost of living I guess? reply nineplay 1 hour agorootparentprevPensions have a lot of problems. They become handcuffs that keep workers at the same place no matter how unhappy they are, and employers know how to take advantage of that. It&#x27;s easy to look back with rose-colored glasses but I know several people who dragged themselves though several years of misery to hang on to their pension funds.I wouldn&#x27;t trade my 401k. reply onlyrealcuzzo 2 hours agorootparentprevThe majority of domestically-owned S&P shares are owned by either pension funds or IRAs (401ks): https:&#x2F;&#x2F;theirrelevantinvestor.com&#x2F;2020&#x2F;10&#x2F;25&#x2F;who-owns-the-st...The foreign share is a roughly similar breakdown to the domestic share.How do you think Pension Funds get a return if not investing in equities in similar ratios to most people&#x27;s 401k allocation? reply flashback2199 2 hours agorootparentprevThanks for this pile of links...I don&#x27;t believe what you&#x27;re saying that 401k&#x27;s are somehow not going to be enough to retire.Unless you meant retire where housing prices are rising the fastest. reply toomuchtodo 2 hours agorootparentYou didn&#x27;t read the links then. Median 401k balance is no more than $71k across all age cohorts. Assuming a 4% perpetual withdrawal rate (Trinity study), that is ~$2840&#x2F;year in income.Per the GAO:> Even for those who do have access, traditional defined benefit pensions have become much less common as defined contribution plans, such as 401(k)s, have become the primary type of retirement plan. This shift has increased the risks and responsibilities for individuals in planning and managing their retirement. Yet research shows that many households are ill-equipped for this task and have little or no retirement savings. As of 2016, about half of households with a worker age 55 and older had no retirement savings, and 29% had no retirement savings or a defined benefit plan. Policymakers will need to consider how to best encourage expanded pension coverage, adequate and secure pension benefits, and more effective use of tax preferences to foster workers’ retirement security.40% of Social Security recipients have no other income.https:&#x2F;&#x2F;www.ssa.gov&#x2F;news&#x2F;press&#x2F;factsheets&#x2F;basicfact-alt.pdfhttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231028173718&#x2F;https:&#x2F;&#x2F;www.nirso... reply flashback2199 2 hours agorootparentI&#x27;m not following your reasoningRegardless of whether and how much private equity is affecting growth in prices of stocks for public companies, the S&P in which people&#x27;s 401ks are invested has grown a lot, and will probably continue toLow balances in 401k&#x27;s are therefore due to insufficient contributions and not insufficient growth in S&P prices reply jandrewrogers 1 hour agorootparentprevThe term \"retirement savings\" is too narrowly defined here, since it only includes things like 401k, savings accounts, and pensions.Many people have their retirement savings entirely in rental real estate (I know several like this). Many people have small retirement accounts but millions of dollars in ordinary taxable investment accounts due to the myriad restrictions that the government places on what you can put into retirement accounts. All of these are outside the definition of \"retirement savings\", despite being actual retirement savings, but none of them are rare. reply ebiester 1 hour agorootparentprevI always wonder about this 401k balance. How many people don&#x27;t roll over their 401(k)s? reply commandlinefan 2 hours agorootparentprev> no more than $71kDon&#x27;t worry, I&#x27;m sure they&#x27;ll get together and vote to distribute everybody&#x27;s 401(k) balances equally among all retirees so that they people who did save will also end up with nothing. reply the_gastropod 2 hours agorootparentprevThis thread started as a response to:> The 401k generation will begin think about retiring in the next few years. Most will discover that their 401K, despite maximum contributions, will be insufficient to retire on.The maximum individual contribution—not counting employer contributions—is $22,500. Or if you’re over 50, it’s $30,000. If You’re maxing out your 401k, you’ll pass $71k after working just a few years.To retire with just $71k after working a typical career of 40 years, you’d have to save less than ~$600&#x2F;year. In other words, saving $600&#x2F;year—~4% of a minimum wage salary—is enough to surpass this median $71k number after a 40 year career and a conservative 5% avg return.I suspect most of these people have other savings. reply toomuchtodo 2 hours agorootparent> I suspect most of these people have other savings.Please show me the data, because all available public sources indicate this is not the case, and in my travels, the data confirms my conversations with these cohorts (because I am very curious). If they have other savings not showing up in the data, what and where is it? We cannot simply assume it exists. Hope is not a strategy. reply c22 1 hour agorootparentIt&#x27;s stashed in their depreciating vehicles and equity in their houses. reply the_gastropod 1 hour agorootparentprevWell, for starters, we can look at the median net worth of Americans, which in 2019 was between $250k and $310k for the age groups we’re talking about here. Is that enough? Still probably not, but it’s a heck of a lot more than just $71k.https:&#x2F;&#x2F;www.federalreserve.gov&#x2F;econres&#x2F;scf&#x2F;dataviz&#x2F;scf&#x2F;chart... reply toomuchtodo 1 hour agorootparentIf your net worth includes your primary residence, and you can&#x27;t live off the equity, it is not retirement savings. It is dead capital, as you must live somewhere. Certainly, we can include it in your estate and net worth, but that&#x27;s more pertinent to whomever is next of kin, not the person who needs cashflow for groceries, fuel, utilities, healthcare expenses, and so on. What the metrics represent is important, otherwise we are blinded to ground truth.I must strongly emphasize that vehicle equity is not retirement savings if you must keep the car for mobility. Home equity is not retirement savings if you must have a place to live and there is nowhere to downsize to, unless we are expecting 55+ to sell their homes and live in a van down by the river, burning through their housing proceeds and hopefully dying before it is exhausted. reply the_gastropod 1 hour agorootparentI think it’s still perfectly relevant. Retirees who own their homes have lower expenses than those that must pay rent. If your net worth is 100% equity in your wholly owned home, social security will go a much longer way than someone with $71k in a 401k who must still pay rent.I don’t know what point you’re trying to make here. Is US retirement a mess? Yes. But I don’t think the magnitude of bleakness is quite as high as you’re describing.While hardship exists, and I think we’d probably agree that there needs to be a much better safety net in place for people, I think it’s also true that many capable people neglect to save enough for the future. And, to be honest, I think often it’s because of rhetoric like yours. People are hopeless, and just give up trying. Reality is not that grim. Saving even $1M in a 401k over 40 years has been attainable for most people by following the boring “save 10%” strategy. reply danaris 53 minutes agorootparentBut a higher net worth due to having equity in a home is not the same as having fully paid off your home. There&#x27;s just not enough information in such statistics to make such a determination one way or another.You&#x27;re welcome to assume that retirees have paid off their mortgages, but it&#x27;s a wholly unsupported assumption, given just the information in this thread. If you want anyone else to give it credence, cite some sources for it. reply the_gastropod 37 minutes agorootparenthttps:&#x2F;&#x2F;fivethirtyeight.com&#x2F;features&#x2F;how-many-homeowners-hav...Most Americans over 65 own their homes outright without mortgages.ryandrake 48 minutes agorootparentprevI know far too many people (albeit all younger than me) who readily admit to having zero savings--retirement or otherwise. These aren&#x27;t destitute minimum wage workers. They&#x27;re professionals with decent jobs, often whose employers have 401(k) programs. They just don&#x27;t participate in them. They deliberately don&#x27;t because they want to spend today and not lock up their money for an uncertain future. About half think they&#x27;re going to die before retirement, and the other half have an overly rosy expectation of a future safety-net to help them. They are betting (unwisely IMO) that the USA will give in and not let an entire generation die on the street. reply the_gastropod 34 minutes agorootparentI have close friends with this mentality, and it frustrates me to no end. 6-figure earners with severe learned helplessness. replyarielweisberg 1 hour agorootparentprevPension plans as they were are still kind of bad because they could be mismanaged in a variety of ways.Pensions are kind of always problematic because you take control away from people and give it to people with misaligned incentives.It&#x27;s the same if you give people control over their own retirement because they can not contribute or mismanage how the money is invested. Defined contribution pensions are maybe an improvement on this because at least you know there is money there and can have a regulatory framework that is simple and heavily restricts how the money can be used. I would really like to see broad market index funds only. Dumb money should stay dumb.Maybe if you pull the responsibility up to the federal government you minimize the risk of mismanagement, but it&#x27;s still pretty large.Seems like we are doomed to pick an option that is still risky and it&#x27;s every person for themselves. You need to super save and not rely on any framework provided by others. And this is where 401ks shine. Sure I am stuck relying on the stock market, but I think the distribution of outcomes there are more in my favor than if it were managed by someone else. Whatever is in my 401k (or IRA or whatever) is owned by me and is heavily diversified. reply ryandrake 58 minutes agorootparent> Pensions are kind of always problematic because you take control away from people and give it to people with misaligned incentives.Maybe I&#x27;m the weird one, but I don&#x27;t necessarily want control of my retirement fund. My primary requirement is that it exists when I need it. Somehow the financial industry convinced the public that being able to micromanage their retirement investment and pick their own stocks and mutual funds is somehow beneficial. I can probably count on one hand the number of people I know who find this kind of micromanagement interesting.I just want \"money goes in\" and \"enough money eventually comes out\" and I don&#x27;t think I&#x27;m alone in that. You can accomplish that with a well-run pension, a well-run government plan, and so on. Lots of options that don&#x27;t involve me having to decide between stock and bond funds. reply WkndTriathlete 40 minutes agorootparentHaving watched a close friend of my dad&#x27;s sell at the bottom in 2007-2008 after he had retired, I understand your sentiment.However, before the advent of discount brokerages and widespread 401(k) plans investing really was only for the extremely wealthy and inept fund management - resulting in extremely high expense ratios - was rampant. Now investment is more accessible and ETFs are offering near-zero (or actually zero (!) - see FNILX) expense ratios on the strength of the economy, which has been a net win for a larger segment of the population than the 0.1%. We&#x27;re up to 20% now!I would like to see a much larger percentage of the population to be able to get in on this opportunity. Doing away with wealth and income inequality will get us halfway there. Trust-managed investing addresses what you&#x27;re asking for, where a company manages your investments and retirements for you at some level of expense ratio. (These companies exist today for retirees.) reply loeg 2 hours agorootparentprevThe quoted excerpt is referring to only the subset who has maxed out their 401k contributions, whereas you&#x27;re describing the median, who mostly have not. These are different groups. People who maxed out their 401ks for their working years and had vaguely reasonable investment options (mostly diversified stock funds) will be fine. And social security income should not be ignored. reply red-iron-pine 1 hour agorootparentprev> and most did not or could not contribute to 401ks in any meaningful fashion)burying the lede here, killer.to be clear, the 2% mgmt fee in a lot of 401k plans is terrible and is absolutely scamming the average folks.but you can&#x27;t retire on something you didn&#x27;t contribute to, either because you didn&#x27;t or couldn&#x27;t. reply spiralpolitik 2 hours agorootparentprevTwo market crashes and badly managed 401k accounts won’t help. Most trust that their 401k is correctly managed. This is often not the case.The merry-go-round of debt ceiling and budget confrontations in congress doesn’t help. Any gains from this year are probably going to be wiped out by that continuing drama.Finally the increase in cost of living expenses and cost of long term medical care will quickly eat into your 401k once you stop contributing.The math looks ugly once you sit down and figure it out. reply nradov 2 hours agorootparentWhat do you mean by \"trust that their 401k is correctly managed\"? Those 401(k) plans are self managed. In most plans the investment selection defaults to a low-cost retirement date fund. There&#x27;s no one to trust. reply spiralpolitik 1 hour agorootparentIf you start at a company today the default setting would be for the 401k money to be invested in something like LifePath N or similar ETFs that are designed for retirement funds. Most people, lacking the knowledge to do otherwise will stick with that.So you are working on the assumption that LifePath or similar ETFs are going to be correctly managed for their cohort (shifting into safer investments as the retirement date approaches). reply njarboe 1 hour agorootparentSomehow the \"safety\" of bonds were not adjusted as yields reached and sometimes went below zero. A multi-year zero interest bond is not a very safe investment. I did have that default setting on a retirement account and got out of those LifePath type ETFs over a decade ago. reply BeetleB 1 hour agorootparentprev> How will that happen when there has been so much growth in the S&P?Almost no one gave the obvious answer: Most 401 K plans are not investing in the S&P. Many give you the option to, but it&#x27;s not the default, and probably over 90% of workers are unaware of the fund.And quite a few do not even give you the option to invest in it. reply gymbeaux 2 hours agorootparentprevPast performance does not guarantee future results. You can find periods in the US stock market’s history of years, even a decade or so, where the return on the DOW was essentially 0. Look at other countries and it gets worse; Japan’s NIKKEI returned 0 between 1995 and 2020. 25 years of… dividend reinvestment I guess? Still nothing compared to the US stock market during that period.The stock market is a circus- that’s common knowledge- yet we rely on it for retirement? Okay. That’ll work until it doesn’t. reply EVa5I7bHFq9mnYK 12 minutes agorootparentIf we are going to cherry pick, Nikkei-225 returned -6% between Dec 1989 and Feb 2023 (dividends reinvested and inflation adjusted). 33 years of negative returns. reply nradov 2 hours agorootparentprevThe Dow Jones Industrial Average is a garbage index with components selected arbitrarily. No one in finance takes it seriously.No one can guarantee stock market returns, but over decades it&#x27;s a lot safer than depending on pension contributions from a single company. And most 401(k) plans now offer target date mutual funds which automatically reduce stock exposure over time, thus reducing risk of capital loss as you approach retirement. reply danaris 1 hour agorootparentWe&#x27;re not talking about what people \"in finance\" know or care about. We&#x27;re talking about regular people&#x27;s retirement funds. reply throw0101c 2 hours agorootparentprev> How will that happen when there has been so much growth in the S&P?If you invested in an index fund, you will get very close to the S&P 500&#x2F;Russell 3000&#x2F;Whilshire 5000&#x2F;etc.If you invested in an actively managed fund, then the fund manager takes their cut, but also probably tries to be &#x27;too clever&#x27; and doesn&#x27;t get as good returns as a plain index, and so you&#x27;re not getting as high returns. reply DontchaKnowit 2 hours agorootparentprevMy 401k account offered by fidelity, using the highest risk investment strategy available to me, returned about 8 percent during a period where the S&P did about 30%. and they took a 1.5% commission. Absolute fucking scam. took all my money out and ended contributions. reply wenebego 2 hours agorootparentYou werent allowed to invest in the s&p 500 or any other low cost index fund? reply DontchaKnowit 57 minutes agorootparentIf I was, they did not make that clear at all. They had a set of about 14 different \"packages\" that were aggregations of different etfs and such that were available to invest in and that&#x27;s it. I couldn&#x27;t find any way to invest in a single stock or etf.They also told me I couldn&#x27;t cash out my money until I left the company I worked for which I am pretty sure is untrue. reply bushbaba 2 hours agorootparentprevYou can always do a S&P 500 fund in a 401k reply quickthrowman 1 hour agorootparentprevMy 401k plan has an S&P 500 fund run by Fidelity that costs 0.015% a year in fees, FXAIX. If I didn’t have access to a fund like this, I would demand to be given access to it. reply PKop 1 hour agorootparentprevThe cost of real goods, energy, medical care etc will inflate to account for this, plus extracting the gains will involve selling..to whom? At what price? reply EVa5I7bHFq9mnYK 31 minutes agorootparentprev>> The expectation for your 401k is that it&#x27;s going to grow by 6-8% each year.I have always been suspicious of the 6-8% figure, as it also includes an unknown number of insiders. They know when to buy and when to sell, so their returns are higher than 6-8%. Correspondingly, all non-insider returns are lower, such as 3-4%, but you will not be able to tell because statistically, it will still average out to 6-8%. reply renonce 46 minutes agorootparentprevJust wondering, how many U.S. citizens have considered retiring in another country, possibly a developing country? I live in an Asian country where the living costs are significantly lower than that of U.S., so as long as the US dollar remains strong you can expect 2~3X more purchasing power for the same dollars. Countries like Malasyia have favorable policies for foreign retired workers, such as easy retirement visa, world-class medical care, etc. Could be an ideal place for retirement in case 401k was insufficient for retirement in US. reply EVa5I7bHFq9mnYK 25 minutes agorootparentDon&#x27;t know why, but all those cheap countries are too hot for me. All the colder climate countries are well developed and expensive. Maybe the chain of derivation is cold -> hard to survive -> expensive -> developed. reply mint2 2 hours agorootparentprevAlso all the older workers who do have enough used it to buy multiple investment properties, helping make house prices absurd. reply tbihl 2 hours agorootparentprevThis is over-hyped. Professionals who want out will overwhelmingly figure out how to save more, regardless of whether their investment returns are 5% or 9%. Most people are working for much more than a paycheck (though I believe they often fail to realize that), and stop working for far more varied reasons than achieving financial independence or a fully vested retirement plan.Sure, this will move some people at the margins, but most people will stop working from physical or mental frailty, to move across the country to be with grandchildren, or to preserve their limited energy to do things that they find more compelling than work. To the extent that they need to, they&#x27;ll find lower-cost ways to live, probably including down-sizing, living with their adult children, renting rooms, or other informal arrangements within their communities. reply gymbeaux 2 hours agorootparentIt’s not over-hyped. If you play around with the numbers, the ~$22k per year (increases a little each year usually) you can put in a 401k is insufficient to retire on, even if you start at age 20 and max it each year till 55… unless the stock market goes up, up, up. One flaw is that you can only contribute that $22k to retirement if you have an employer and that employer offers a 401k plan to employees. Most do, but it also discourages entrepreneurship and gig work (which can be lucrative). Without a 401k, we are limited to contributing $6k&#x2F;year to an IRA, which only has a tax deduction if you make less than $85k or so per year.Meanwhile 15% or so of our paychecks go towards social security, which many believe won’t exist in 20 years, regardless of contributions you made.Finally, the cost of retiring heavily depends on two things- healthcare and housing. Many Americans remain employed until 65 when they are eligible for Medicare as their employer-provided health insurance is all they can afford. Prior to Obamacare, these individuals would simply be uninsured, but now it’s “insured but it’s ridiculously expensive” without their employer.As for housing… it’s common to sell a single family home for X and use X&#x2F;Y of that money to buy a smaller townhome or condo to live in until the day you die. This can work out well, adding tens or hundreds of thousands of dollars to the retirement account, but it relies on the person owning the home, having significant equity in the home if it’s not fully paid off, and being willing and able to sell the house and downsize.The system is broken and in this software engineer-heavy forum, I think it’s easy to forget that we make more money than most Americans. Heck, we make more money than most humans. reply BeetleB 1 hour agorootparent> It’s not over-hyped. If you play around with the numbers, the ~$22k per year (increases a little each year usually) you can put in a 401k is insufficient to retire on, even if you start at age 20 and max it each year till 55Over the last 35 years, that would have netted you about $3M in today&#x27;s dollars. You could argue that&#x27;s not enough to retire on at 55 (although I&#x27;m sure many can), but if you keep it up to 65 that&#x27;s $6M. Easily enough to retire on. reply thunky 0 minutes agorootparentRight, but that&#x27;s also assuming the person is 100% invested in the stock market all the way up to their retirement. That&#x27;s a lot of risk. symlinkk 35 minutes agorootparentprevNot to mention Social Security kicks in once you hit your 60s. reply Kon-Peki 38 minutes agorootparentprev> discourages entrepreneurship and gig work (which can be lucrative)Self-employed folks can make both employee and employer contributions to tax-advantaged retirement accounts, and the aggregate yearly amount far exceeds what a W-2 employee can contribute on their own. reply nradov 2 hours agorootparentprevNo one retires at age 55 unless they already have substantial wealth. The expectation is that you continue contributing until you retire at about age 67. reply bushbaba 2 hours agorootparentprevHonestly just see a lot more RV&#x2F;Van dwellers in retirement. housing and healthcare are the greatest costs. reply peteradio 2 hours agorootparentprevMaybe by then Canada will have some sort of MAID tourist visa. reply bluefirebrand 2 hours agorootparentMaybe it&#x27;s time for a tech startup to invent the Futurama suicide booth. We could have a test market lined up.Combine it with a Cyberpunk 2077 crematorium vending machine and it sounds like a great one stop shop. reply Pet_Ant 2 hours agoparentprev> Newer companies like AirBNB and Uber went public at what could be their max market cap valuation of billions so investors wont&#x27; get much of a chance to make money from these companies.An argument I heard is that companies prefer to stay private longer to avoid the burden&#x2F;oversight of SOX etc. The charitable interpretation is that they are too busy growing to be bothered, the less charitable is that they aren&#x27;t capable of growing if they have to be accountable and forthright. reply tbihl 2 hours agorootparentThe availability of VC will necessarily siphon off enterprises from other funding sources. reply 1980phipsi 2 hours agorootparentVC isn&#x27;t a panacea and doesn&#x27;t operate in a vacuum. If you raise the cost of going public and staying public, then that makes VC funding or going private more attractive. The VC funding may come with terms that are not expected by public company investors.But VC-backed companies is only one part of the private equity trend.The other part that is discussed is small owner-operated or partnership firms getting bought up by bigger ones. Here again, if the government increases regulations, then that tends to fall more strongly on small businesses than bigger businesses. reply tbihl 2 hours agorootparentI agree with everything you have said.I&#x27;ll just add that, with the path of finding VC well-known and well-worn, we should expect greater difficulty. Even if we somehow reversed the trend of all institutions and bureaucracies to become over time larger and more cumbersome, that is, we streamlined government processes, we should expect an additional hesitation of growing enterprises to return to IPO, because VC is now a comfortable path for a significant portion of the roadmap. reply cs702 1 hour agoparentprevI agree!But I also think the rise in interest rates could help reverse this trend, at least somewhat.Consider: Until recently, interest rates in the US and other developed economies had only declined, in fits and starts, since the early 1980&#x27;s.[a]Not coincidentally, the modern private equity sector was born in the 1980&#x27;s.[b]Until recently, private equity firms had benefited from interest rates that only decline and valuation multiples that only expand -- for four decades!A lot of deals that \"work\" when rates only decline will stop working if rates don&#x27;t. For example, there are a lot of private-equity-backed middle-market businesses, including plenty of roll-ups, that were financed before rates went up, with such high leverage that the companies are now at risk of insolvency if rates don&#x27;t decline soon.If rates stay at current levels or (gasp!) continue to increase, I&#x27;d expect to see a significant contraction in the number of private equity firms. Those private equity firms survive may have to become mainly lenders, i.e., banks in all but name, and sooner or later will end up being regulated as such.---[a] https:&#x2F;&#x2F;fred.stlouisfed.org&#x2F;graph&#x2F;?g=1aNbC[b] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Private_equity#Private_equity_... reply jeffreyrogers 1 hour agorootparentThose companies are only at risk of insolvency if their debt is variable rate or has a balloon payment due soon. I imagine most PE firms are smart enough to avoid those risks. Banks are also incentivized to negotiate with debtors in those situations since the asset is worth more as a going concern than it would be in bankruptcy and banks don&#x27;t want to operate a business (they have no expertise there).Most PE deals would work (with lower returns) without any debt. The debt allows them to diversify into more deals (since they put less equity into any given deal). reply cs702 55 minutes agorootparent> Those companies are only at risk of insolvency if their debt is variable rate or has a balloon payment due soon.Actually, most LBO-type deals are financed with a combination of bank and bond debt. A shocking number of bond deals will be maturing within 1-3 years, and have to be refinanced. The bank debt, senior to the bond issues, is typically variable-rate and (depending on deal size) split into tranches that must be repaid at different schedules over time. Many PE-backed borrowers in recent years decided not to enter into swap contracts to fix their debt rates. My understanding is that things could get ugly quickly if rates don&#x27;t come down soon.> Most PE deals would work (with lower returns) without any debt.Actually, if a deal returns less than the yield on corporate debt of similar risk, then the deal does not work. LP&#x27;s in the PE fund will correctly view it as a failure. The raison d&#x27;être of PE funds is to earn returns above those yields. Moreover, if a portfolio company is already loaded with debt, finding buyers that will pay the old multiples given the new rates will prove difficult, if not impossible -- similar to the situation many US homeowners that locked-in ~2% mortgage rates a few years ago face today: They cannot sell their home at the old valuation because prospective buyers are looking at mortgages that cost ~8%&#x2F;year. Higher interest rates make it hard to impossible to \"exit\" at valuations that generate decent returns. reply jeffreyrogers 37 minutes agorootparentI&#x27;ll believe it when it happens. Banks&#x2F;creditors don&#x27;t want to operate these assets (no expertise there) and since the businesses are fundamentally sound for the most part there is no reason to force them into bankruptcy. \"Extend and amend\" (sometimes \"extend and pretend\") is what they called it after 2008.If they had unlevered yields below the corporate debt yield they would have negative leverage and debt would reduce returns. reply Aunche 1 hour agoparentprev> Newer companies like AirBNB and Uber went public at what could be their max market cap valuation of billions so investors wont&#x27; get much of a chance to make money from these companies.Almost all of these companies were massively overvalued by the time they IPO&#x27;d. I for one am glad that regular people were not allowed to invest in Theranos or WeWork. Looser restrictions on investing would create even more dodgy company&#x27;s whose primary goal is to scam retail investors, like what we&#x27;ve seen NFTs.> Vet clinics, medial practices, engineering firms, etc all use to to thrive on being 20 person shops are now routinely being bought up by PE firmsIMO, this is a symptom and not a cause. Vet clinics and medical practices would be terrible investments if it were sufficiently easy to start new vet clinics and medical practices. Likewise, housing would be a terrible investment if it were sufficiently easy to build more housing. reply hnthrowaway0328 49 minutes agoparentprevIMO this also impacts \"large\" institutional investors such as pension funds. A lot of them are going to hold the bag.I don&#x27;t see a way to get out of it without a fundamental change. reply leishman 2 hours agoparentprevIt’s because of cheap money flowing into Wall Street. The negative impact of ZIRP has only started to be felt. reply Retric 1 hour agoparentprevDon’t forget about inflation when comparing these numbers. 300M in 1984 is 0.85 Billion today. Some companies IPO at huge valuations, but ShockWave Medical, Inc., had a 2019 IPO at roughly the same valuation as Microsoft and has seen 11x returns since then.Looking at the other 2019 IPO’s you see a lot of volatility but many home runs. https:&#x2F;&#x2F;stockanalysis.com&#x2F;ipos&#x2F;2019&#x2F; reply Gustomaximus 2 hours agoparentprevI&#x27;ve thought about this a bit. This concentration shift seems good for the economy in the short term but a massive loss for society as business increasingly becomes a chains or centralised. Especially in areas that are traditionally owner run like restaurants, pubs, vets, dentists, GP clinic, pharmacy, hardware etc. Capitalism is the best system but we too often forget a core tenant for govt to create a level playing field. We seem to have forgotten this and make it increasingly hard for small business which should be a significant driver of innovation and improvement.I think some possible solutions would be to;1) Significantly lower taxes for smaller businesses vs larger. Even better bring personal rate inline to company rates... but this would be a very difficult shift for governments.2) Tax benefits for companies listed and actively traded, so companies are encouraged to list and share wealth&#x2F;growth.3) A &#x27;not in the national interest&#x27; law for companies that continually pay little to no tax where you would expect them to. Have tax department give something like a 3 year warning they are on the &#x27;consideration list&#x27; and if things dont change the tax office can make them sell, or if they prefer close. And then they remain on said list for a couple decades or so to verify. This, while being risky for overuse, would be an effective tool on the worst tax dodgers and wielded in a limited capacity quite useful for those that have high end tax strategists that keep getting around the rules.4) Limit investment ownership in residential so people dont spend their life trying to buy a house. This will allow people to take some business risk and invest in their entrepreurship far more easily.5) Put a low market cap limit on core local business like those mentioned above like vets, dentists, GP clinic, pharmacy. Or maybe a progressively sliding scale annual asset tax past a value&#x2F;outlet of X. Something that limits how big these organisations can get.6) Stop large consumer distributors selling their own brand product. Not sure how to word this exactly but places like Amazon or large supermarkets, they should be a retailer of other business goods only. Stop them sticking their own rip-off product next to the other.Obviously a load more... reply jeffreyrogers 1 hour agorootparentI think it will be a cyclical thing. The PE firms actually do run those businesses much more efficiently, but they also become homogenized and that&#x27;s offputting, which opens the door for new entrants to differentiate themselves. reply Eumenes 2 hours agoparentprev> Vet clinics, medial practices, engineering firms, etc all use to to thrive on being 20 person shops are now routinely being bought up by PE firms and rolled into larger companies which means far fewer entrepreneurs or chances for up and coming employees to buy into the firm from the founders, which helps stall careers.In the past 2 weeks, my local small biz autobody shop and furnace&#x2F;HVAC company have been bought by large regional firms. The furnace company refuses to service your boiler w&#x2F;o buying from their preferred oil supplier, and the autobody shop has adjusted their rates to essentially insure they only work with insurance claims. reply gymbeaux 2 hours agorootparentIt’s very common for auto body shops to only work with insurance claims. I think your best bet is to take the car to a dealership-owned body shop, especially if it’s the dealership you bought the car from, or the same make. reply JumpCrisscross 2 hours agoparentprev> Newer companies like AirBNB and Uber went public at what could be their max market capUber is worth 50%+ its IPO valuations.(EDIT: No it isn’t. Sorry, jet lagged.) reply chollida1 1 hour agorootparent> Uber is worth 50%+ its IPO valuations.Is it?I just looked at the chart and saw it went public at $45 and it currently trading at $45.Did it split at some point or issue a 50% div? reply ta1243 1 hour agorootparenthttps:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;UBER says opened at $41.91 in May 2019 and is now $42.42Had it kept track with inflation it would be about $50 - up 15%Had it kept track with S&P it would be about $63 - up 50% reply slotrans 1 hour agorootparentprevNo it isn&#x27;t, as 30 seconds of research would show. reply ikekkdcjkfke 2 hours agoparentprevWhere is all this money coming from? reply globular-toast 1 hour agoparentprevAs John Kay put it, the stock market used to be a way for new businesses to raise capital, now it&#x27;s a way for already profitable companies to cash out. The example he gives of one of the first ones is Google. So it&#x27;s been going on for quite a long time now.The funny thing is now many of these companies aren&#x27;t even profitable. It&#x27;s all driven by speculation. reply jeffreyrogers 1 hour agorootparentIt&#x27;s still how many new businesses raise capital. That&#x27;s how the biotech industry works for example. (In biotech VC just gets you to the IPO stage and you don&#x27;t cash out at IPO since typically those companies don&#x27;t even have an approved product yet). reply Andrex 36 minutes agorootparent> It&#x27;s still how many new businesses raise capital.Should it be? Theranos stained biotech badly. reply jeffreyrogers 29 minutes agorootparentBusiness and markets run on trust. The less trust you have the more overhead you have to verify that every claim your counterparty makes is true. That&#x27;s expensive and means some worthwhile things become impossible to do profitably. It&#x27;s a tradeoff and I think in general the US finds a good spot between regulation and ease of doing business, and the rest of the world benefits from it too.There are failures of course, but most of the big ones recently have been in private markets not the public ones. reply scarface_74 2 hours agoparentprevThen the market should value those companies properly. reply Supermancho 2 hours agorootparentNot sure what you are saying here. Which companies? Why? reply michaelt 2 hours agorootparentFor private equity to take a publicly traded company private, they&#x27;ve got to pay more for it than the public market values it at.For example, in 2016 Softbank was able to buy ARM for US$32 billion, but that was only possible because the stock market priced it below US$32 billion. reply Joker_vD 3 hours agoparentprev> we now have such concentration of wealth thatthe big PE firms can buy alot of what used to be small businesses and roll them up.If only those small businesses could just refuse and continue operating on their own... alas. reply chollida1 2 hours agorootparentWell think this through.There are 10 vet practices in your city. 7-8 get rolled up into one uber practice by a PE firm.They now have far less overhead per patient. Billing, equipment and even vets can be amortized over far more patients.You, the hold out clinic, are now more expensive, or have a far smaller profit ratio, thus you are operating at a big disadvantage to the other clinics in your city.You can hold out but what is your edge in this case where your competitor is now bigger and can handle things like a vet quitting as they have a bunch that roam from practice to practice. Or they can handle buying a new machine for millions while the bank won&#x27;t lend to you due to your shrinking margins.Economies of scale are a thing and can be a very real competitive differentiator.You the hold out are now getting crushed by your competitors while you look around and see your fellow vets taking weekends off to take their new boat to the lake because they sold their practice and you&#x27;re working your 11th weekend in a row because your other vet quit to work for your competitor that can now pay more than you.I&#x27;ve had friends live this and its not fun. reply lapcat 2 hours agorootparentAnother issue is that doctors are coming out of school with more student loan debt than ever before, so when it comes time for the older doctors to retire, the younger doctors haven&#x27;t built up enough personal equity to take over the clinics.Nobody seems to care about the student loan debt of doctors, because doctors can make a good salary, but student loan debt still has negative consequences down the road such as this. reply tbihl 2 hours agorootparentprev>what is your edge in this case where your competitor is now bigger and can handle things like a vet quitting as they have a bunch that roam from practice to practice. Or they can handle buying a new machine for millions while the bank won&#x27;t lend to you due to your shrinking margins.To answer your rhetorical question:1. People would rather deal with neighbors than with PE or megacorps, and will do so to the extent that the difference in price is tolerable (and to the extent that they even know their neighbors.)2. Management layers and performance based incentives are huge costs that small enterprises should be mostly able to avoid.3. Owning a business can have a really compelling advantage at tax time in the ranges of professional incomes we&#x27;re discussing.4. Owner-operated businesses should be able to integrate with family life, allowing dads to spend time closer to their kids, which should be another advantage in favor of professionals going it on their own.5. Owner-operated businesses can also operate with much more efficient facilities (housing over top of business) when not forbidden by zoning or other regulations.On the other hand, people like steady salaries and set working hours. They like leaving work at work. And, especially as these professions increasingly see their schools dominated by women, many of these professionals really like stepping away from work or going part time for 5-10 years around their 30s. reply Workaccount2 2 hours agorootparentPeople in general do not give a fuck about anything besides price, and behind that, convenience.However, people spend a lot of time talking about how they care about more than just price. The actual manifestation is tiny though. reply ethanbond 1 hour agorootparentPeople care about multiple things on different time horizons. There’s nothing contradictory in saying, “I would prefer a world not owned entirely by one PE firm” and “I will generally seek the lowest acceptable prices.” reply tbihl 1 hour agorootparentprevFirst, you should be careful about thinking you know people in general, and even if you could know such an abstract and totalizing thing, you don&#x27;t need all the customers, just enough customers, or even plenty of customers.Also, the very fact of charity shows that people must care about something other than price. Paying higher prices to interact with your neighbors is just a much smaller step on the same road of doing things you think are beneficial but that won&#x27;t maintain your bank account at the highest possible value at that exact instant. Farmer&#x27;s markets are another example of the same.You&#x27;re either looking at the wrong people or making the wrong changes, if you don&#x27;t think anyone actually cares about anything other than price. reply BeetleB 1 hour agorootparentprev> People in general do not give a fuck about anything besides price, and behind that, convenience.They do when it comes to their pets. reply TeMPOraL 2 hours agorootparentprevRE 1: Customers have zero influence on this. If you have a pet, you&#x27;ll need a vet, and if the owner of the owner-operated clinic next to you gets an offer they can&#x27;t refuse... I can&#x27;t imagine you&#x27;ll find some other owner-operated clinic to visit out of spite, where the now-corporate one next to you is open, and perhaps even cheaper.RE 2-5: These are all rounding errors compared to economies of scale the PE-backed companies have. Also, those PE roll-ups target businesses whose owners are at the stage of life when they&#x27;re just happy to take a big payout and retire. Tax time advantages and spending some time with kids (which is arguably less than salaried employees of the corpo-clinic will have) can&#x27;t possibly beat being able to not work at all anymore, live comfortably, and have all the time you want for kids. reply tbihl 1 hour agorootparent>RE 1: Customers have zero influence on this. If you have a pet, you&#x27;ll need a vet, and if the owner of the owner-operated clinic next to you gets an offer they can&#x27;t refuse... I can&#x27;t imagine you&#x27;ll find some other owner-operated clinic to visit out of spite, where the now-corporate one next to you is open, and perhaps even cheaper.I have seldom gone to the nearest vet&#x2F;pediatrician&#x2F;hospital. Inevitably I try it, it&#x27;s bad, and then I spend time driving to some place further away that I actually like. And I drive an average of 4000 miles per year; with the median driver traveling some multiple of that each year, I can only assume that most people are way more willing than I to shop around. reply JumpCrisscross 2 hours agorootparentprev> I can&#x27;t imagine you&#x27;ll find some other owner-operated clinic to visit out of spiteNo, but I did organise a few patients to grant our vet a loan to open a new facility. (It wound up creating some Michael Scott Paper Company drama between the vet and her former colleagues, which was interesting.) reply TeMPOraL 1 hour agorootparentPeople like you are our last line of defense on the ground. Sadly, I don&#x27;t think there&#x27;s enough of such people to hold the line against PEs doing targeted divide-and-conquer on specific market segments, one by one. reply mortify 15 minutes agorootparentprevIt&#x27;s not enough that large corporations use economy of scale to undercut smaller businesses. That would generally be a good thing for consumers. Instead, we&#x27;re seeing larger companies use their influence to increase regulation: a cost they can absorb that smaller businesses cannot.We&#x27;ve seen this in medicine in the last 10 years. I know of no independent doctor&#x27;s offices in my area. They looked at the cost to comply with electronic medical records requirements and joined a local health network. reply bondarchuk 2 hours agorootparentprevThe edge is far better service and less scammy practices (pushing unneeded treatments&#x2F;medications etc..), at least from what I heard locally about Dutch vets.Incidentally in Belgium they just passed a law requiring each veterinary practice be owned by a veterinarian. Life could be simple... reply gosub100 1 hour agorootparentprevI haven&#x27;t thought about it this way, I hope youre right. Here&#x27;s what comes to my mind after PE buys vet clinic:- Analyze all the employees using a \"system\" to gauge \"productivity metrics\"- Pressure management to get rid of an employee or two to increase profits, making everyone else work harder.- Seek additional income streams from dubious \"insurance\" products that may or may not pay. Help market their products by spreading false information that insurance gives them \"peace of mind\".- Increase costs to see what the market will bear- Put all employees on a unified HR system that has a strict 1-size policy, little gotchas like \"no health insurance for the first 60 days\", limited PTO, etc. Ignore anyone who speaks badly because \"this is company policy \". Give the business director a bonus when he finds new and creative ways to \"maximize profits\" at the cost of denigrating staff and making them work harder under more constrained policies.- Lock all dr&#x27;s salaries and staff pay to the same scale because \"policy\". Work harder? Why try? I get paid the same amount either way. Employees game the system to work the minimum to avoid termination. Not because they love animals, those people quit in the first 60 days (which is why our health coverage doesn&#x27;t kick in before then).- remove as much of their agency as possible, helping a poor persons injured dog is no longer acceptable, pay-as-you-go and sliding-scale billing are so 1990&#x27;s, we have a business to run, the policy is \"put the animal down and move on to the next paying customer\". House calls are a liability and take valuable time away from the business, effective next year they are no longer allowed.- appeal to emotion to upsell wealthy customers to services that promise to prolong the animal&#x27;s life (but increase suffering and are medically unethical).- Fewer people go to the vet now because they can&#x27;t afford it, more animals suffer so that rich men can have more profit. reply chii 2 hours agorootparentprevTaking the emotion out of the analysis, all i am hearing is that the PE uses more capital, but produces a cheaper, more efficient service.If the original small business owner sold, the money they got paid isn&#x27;t gone - they could&#x27;ve used it to start another small business (or fund one as a VC themselves). I don&#x27;t see how PE is stifling anything, but to produce a more intensely competitive environment. reply abosley 1 minute agorootparentQuantity has a quality of its own. Dude named Piketty wrote almost 2k pages about wrt capital accumulation. The opposite of what you propose is what actually happens. For another example, please see Amazon. lapcat 2 hours agorootparentprev> produces a cheaper, more efficient service.More profitable perhaps, but not cheaper. In fact, usually more expensive, because the PE firms buy up all the clinics in a city, eliminating competition, and then they can set the rates to whatever they want. Needless to say, any \"savings\" are passed along to the investors, not to the consumers.> If the original small business owner sold, the money they got paid isn&#x27;t gone - they could&#x27;ve used it to start another small businessThey&#x27;re usually selling because of retirement, so they&#x27;re not going to start another business. The issue here is that the business is not passed along to another new small business owner, it&#x27;s passed along to a giant PE firm.> produce a more intensely competitive environment.In reality, to reproduce an environment with less competition and more consolidation, as mentioned above. reply ghufran_syed 1 hour agorootparentGreat, that \"less competition\" means higher prices... Which means someone setting up a new clinic can benefit from those higher prices - oh look, now you have competition again. reply harperlee 2 hours agorootparentprevSure, until they have no competition anymore, and raise the prices to whatever they want them to be, extracting 99% of value from what they offer with a huge moat that eliminates all competition. Then the consumer is left with no pricing negotiation and the experience is objectively worse for most of the society.The escape hatch for that is taxes to the powerful market entities, that revert value back to the less powerful market entities, but that&#x27;s not popular in the U.S. reply banannaise 2 hours agorootparentprevBecause customers tend to almost universally agree that they create a worse service in the process. Scaled systems perform poorly in areas where people require customized service rather than a one-size-fits-all experience, and veterinary care is absolutely not a one-size-fits-all type of service. reply TeMPOraL 2 hours agorootparentprev> i am hearing is that the PE uses more capital, but produces a cheaper, more efficient service.You have to understand what \"more efficient\" means. It really means \"it&#x27;s shit and only getting worse, but isn&#x27;t bad enough to abandon the service entirely\". It starts with a corresponding price drop, and you either get a race to the bottom, or the competition gives up early, at which point the quality continues to go down the drain, but the price stays the same, as the provider pockets the difference. reply yoyohello13 1 hour agorootparentprevCheaper and more efficient does not mean higher quality. reply random_ 2 hours agorootparentprevVet is probably a very good example of economies of scale. I remember a vet in my town in Brazil complaining how hard it is if he get ill (or take vacations i presume), that he will lose his customers and how much he regretted not becoming a state employee. reply 1980phipsi 2 hours agorootparentprevIf the government increases regulations, then it tends to place a bigger burden on small businesses than big businesses for the same reasons you highlighted about overhead. reply Joker_vD 2 hours agorootparentprevAh, so the overall economic efficiency improves and then everyone&#x27;s better off. Wait, what&#x27;s wrong with that? reply jprete 2 hours agorootparentThe actual problem is that the unmonetizable value gets tossed out by PE. E.g. customer service will take a massive dive because everyone working for the clinic or whatever else will be time-pressured out of good service.Generally the problem with treating everything via pure financial models is that some things are valuable but hard to measure financially and those are inevitably destroyed by PE and other entropy-maximizers. reply Libcat99 2 hours agorootparentprevMore efficient for the mega-vet, sure. Once you&#x27;ve consumed all the competition, there&#x27;s no need to compete on price anymore. Prices can go up quite a bit before it becomes economical for a new entrant to take a risk in the market. Except maybe another mega-vet.See what Walmart did to communities and small business. Efficiency is not all roses. reply ToucanLoucan 2 hours agorootparentprevYou&#x27;re shifting goalposts. Your first comment was about how small businesses could just refuse to sell, then a commenter described the (very real) consequences of that decision: a person has to work harder, for less money, to compete with entities that can outspend them by a few factors. Now you&#x27;re saying that&#x27;s more efficient overall which is a completely different point.And, that&#x27;s true, it is more efficient. But those veternarians, despite now having their weekends off, are paid barely market rate for their skills (if that) and more importantly, no longer running their business: A PE firm is. That means they have zero recourse if the PE firm starts doing PE firm shit: keeping bare minimum stock at their clinic of every last consumable, to avoid taxation; keeping bare minimum staff at all times to avoid paying workers; abusing staff and causing high turnover; basically every stupid ass \"why would they do that\" type decision you&#x27;ve heard of a large business making in the last 30 years, PE&#x27;s LOVE those decisions.And that&#x27;s not even going into the fact that the profits of that business are no longer going to the community in which it operates, they&#x27;re going to far away shareholders. reply gmd63 2 hours agorootparentprevThink of Comcast but for puppies&#x27; health reply gmd63 2 hours agorootparentprevYou joke but it&#x27;s not benign. The reason economic regulations exist is to ensure we maintain the economy as a crucible for rewarding the smartest and hardest workers in society.When private money can grow cancerously via pump and dump crypto schemes, overhyping IPO&#x27;s that peaked during the series A round, and strong arming small branches of independently owned practices (all to later enable milk mode and reap monopolistic profits), the general public and society is left with overlords who do not build, they eat. reply robertlagrant 1 hour agorootparent> When private money can grow cancerously via pump and dump crypto schemes, overhyping IPO&#x27;s that peaked during the series A round, and strong arming small branches of independently owned practices (all to later enable milk mode and reap monopolistic profits), the general public and society is left with overlords who do not build, they eat.None of those practices create \"overlords\". reply fnimick 2 hours agorootparentprevWhen have the smartest and hardest workers ever been the richest? reply Applejinx 2 hours agorootparentIt&#x27;s easy for me to believe it&#x27;s not always been (and doesn&#x27;t have to be) THIS bad.There&#x27;s functional value in a capitalist system. It just requires ongoing maintenance, to avoid situations like we&#x27;re currently in. It&#x27;s not self-repairing. Operated properly, it makes market conditions self-repairing, but this is at the expense of the potential market capturers. reply ToucanLoucan 2 hours agorootparentIt was better when corporate tax rates and income taxes for the incredibly wealthy were much, much higher. My favorite hobby is putting Thatcher and Reagan&#x27;s faces on economic graphs to show what year they were elected is almost universally either the same year or just about when the global economic system went bugfuck by basically every metric we measure.But, thanks to those two and the larger political milieu they so well represent, those entities are now rich beyond all reason and in a capitalist system that permits things like Citizen&#x27;s United, money more or less equals political power so the odds of getting any of this addressed are basically nil, along side other issues that would demand corporations make less money: like climate change, crumbling infrastructure, socialized healthcare for the US, better socialized healthcare elsewhere, the vanishing middle class, etc.Private Equity is going to get us all killed in a very real sense. reply techdmn 2 hours agorootparentprevThey could, but my opinion is that this is putting personal responsibility front and center on what is a systemic problem. If our economic systems encourage the consolidation of wealth, we should change the systems, rather than blaming individuals. reply twobitshifter 2 hours agorootparentprevUsually what happens is that 60 something year-old founders have retained control and not shared profits with their employees. Looking to sell, the employees can’t buy out the founder, and the founder finds PE with deep pockets. The fork in the road for keeping the company out of PE was passed long before the founder got to retirement age. reply TeMPOraL 2 hours agorootparentprevIf what&#x27;s good for an individual short-term was also always good for them long-term, the world would&#x27;ve been an utopia. reply justrealist 2 hours agorootparentprevIt&#x27;s partly that, but in medicine (dentistry, fertility, etc) a lot of clinics are being rolled into PE conglomerates because the bureaucratic overhead in medicine has skyrocketed in the past 20 years, and clinic chains have better support for doing all the paperwork and legal side of things. reply scarface_74 3 hours agorootparentprevExactly. No one forces these businesses to sell. It’s the owners easiest retirement plan instead of passing them down to their kids who may not want to or have the skill set to run the family business. reply ryandrake 30 minutes agorootparentWhy would a PE firm be buying (for example) a doctor&#x27;s office if the doctor-owner was retiring? The doctor is why the business exists in the first place. Without him, it&#x27;s no longer a doctor&#x27;s office, it&#x27;s a charming little suite with front desk people and a few nurses running around.We had a local machine shop (that I used to go to for welding) sadly go out of business because the owner was retiring. I asked him if he considered selling it instead so it could stay open and he said \"Who would buy it? I am this shop and I&#x27;m retiring. In 5 days it&#x27;s just going to be a pile of tools.\" reply TeMPOraL 2 hours agorootparentprevSure, no one is blaming any individual business for selling. Nor would you blame any particular drop of water for flowing downhill. Still, too much water will make a dam burst and most of the water will flood the land; too much business owners realizing their retirement plan by selling out to PEs, and everyone suffers - including those retirees. reply scarface_74 1 hour agorootparentAre you going to tell these mom and pop shops they can’t sell? reply TeMPOraL 1 hour agorootparentOf course not. The problem aren&#x27;t the mom and pop shops. The problem are the PE companies making those offers. These are the ones to go after. reply scarface_74 34 minutes agorootparentHow is that any different? You’re still trying to stop mom and pop shops from selling out to PE’s.Are you also going to stop startups from getting acquired to? Seeing that only 6 of the hundreds of companies that YC has invested in have ever gone public, acquisitions is the most likely exit replypeteradio 2 hours agorootparentprevIf only each individual bond could try a little bit harder to resist the acid. reply starcraft2wol 2 hours agorootparentthe point is the owners have a positive exit that they choose. And yes people are agents reply peteradio 2 hours agorootparentRight America is governed by individual incentives. reply starcraft2wol 2 hours agorootparentThere are more kinds of incentives than money. reply peteradio 2 hours agorootparentDoing what&#x27;s morally responsible in spite of everyone else is a losers game these days. replyplagiarist 2 hours agorootparentprevWhat a convenient way to completely ignore the macro effects, well done. reply smeeth 2 hours agoprevI&#x27;ve seen a lot of lamentation about PE eating the world, but very few people discuss *why* PE got so huge.PE is popular for one reason and one reason only: taxes. PE generally makes money on a trade called a leveraged buyout (LBO), where they take out a massive loan to buy a company. Because interest on debt is tax-deductible, going debt-heavy increases the take-home profits of the company (this is called a \"tax shield\"). Because the profits are higher, the value of the company is higher, and the PE firm makes money on their trade.What this means in practice is that if you run your company sustainably (low debt, lots of assets). You become a target for a PE firm to attempt a hostile takeover of the company, all while claiming (defensibly, actually) to be doing whats in the best interest of the shareholders. So good companies will try to ward off these attacks by taking on lots of debt and going asset light to minimize the value gain a PE firm might have.In short, both PE ownership and the brittle, debt-heavy nature of the American economy today can be traced to the tax advantaged nature of debt. For reasons I can&#x27;t quite understand, nobody seems to be advocating for revoking this tax deduction. I can only surmise this is because everyone hates taxes.Thank you for coming to my TED talk, your take home exam is a short essay on what you think the mortgage interest tax deduction (started in 1913) did to household debt. reply onlyrealcuzzo 2 hours agoparent> For reasons I can&#x27;t quite understand, nobody seems to be advocating for revoking this tax deduction.Why can you not understand why the US would prefer people to be invested in the future of the US?That&#x27;s essentially what putting your money into US debt means.You are in the interest of the US not exploding in the middle of the night.I do think that the typical 90% debt to 10% equity LBO ratio is toxic and should be regulated down. I can see this incentivizing the types that would put in 10M now to get 100M now - spending that on coke & hookers now, and then hoping the US collapses and they don&#x27;t have to pay anything back. reply pjmorris 2 hours agorootparent> Why can you not understand why the US would prefer people to be invested in the future of the US?I can understand investing in the future of the US. I add an interest in investing in the present of the US, e.g. wages that support the consumption needs of the populace, including but not limited to food, shelter, health care, and education. reply onlyrealcuzzo 2 hours agorootparentUS wages dwarf almost every non-tax haven in the world adjusted for taxes and the cost of living. reply jeffreyrogers 1 hour agoparentprevHostile takeovers are a very small fraction (single digit percentage) of PE buyouts and have been for a long time.And if taking on debt were so advantageous in and of itself you would think the executives of these companies that solicit PE buyout offers would just issue the debt themselves and enjoy their increasingly valuable options packages. reply pjc50 1 hour agoparentprevFor some reason I don&#x27;t understand, the debt ends up on the balance sheet of the purchased company, not the buyer. That&#x27;s why the debt repayments can be used as a sort of tax-free dividend. reply jeffreyrogers 1 hour agorootparentBecause is secured by the company and serviced by the cash flows from the company. Since the debt only exists if the transaction (acquisition of the target company) goes through it is really the company funding its purchase through the issuance of debt.Btw you can get an SBA loan to purchase a small business. It works exactly the same way, and there are people who raise equity capital plus get an SBA loan to buy and run small companies, in effect they&#x27;re running a very small PE deal and installing themselves as CEO. reply marcosdumay 2 hours agoparentprev> PE is popular for one reason and one reason only: taxes.Well, I&#x27;d say it&#x27;s zero interest rates.Any extra cost will reduce your profits. It doesn&#x27;t matter if it&#x27;s tax-deductible. The reason PE can get so big is because that extra cost is minimal.The PEs that insist on antagonizing their customers and depend on being large will be bankrupt soon enough now that being large is expensive. reply danielmarkbruce 2 hours agoparentprevThis is only one quarter right. Public companies can also take on a lot of debt.The bigger reasons are twofold: 1 - the biggest one is that pension funds etc get to avoid the constant vol in stock prices. They get to stick their head in the sand and imagine asset prices not moving around. 2 - the annoying parts of being a public company can be avoided (public eye, some sec regs, constant need to \"grow\" rather than generate cash). reply robertlagrant 3 hours agoprevThis article is...not good.> One answer is that the private-equity industry is devouring them.Another is that public companies buy them and they consolidate. Another is management buyouts. Another is it&#x27;s harder to run a business than it used to be, for better or worse, so they close.> One-fifth of the market has been made effectively invisible to investors, the media, and regulators.No. You still have financial regulations to follow. If you&#x27;re a medical device company, you&#x27;ll still have to follow those regulations. You have employment regulations. All sorts of regulations.You just don&#x27;t have to follow regulations for public companies (such as \"don&#x27;t talk about this thing with anyone outside a list until you&#x27;ve announced it publically, because that would be unfair to other investors), which are expensive and onerous, nor follow the whims of the market, which can be expensive and onerous.E.g. Dell went private and the quality got a lot better. reply edoceo 3 hours agoparentI see how that works for a case like Dell. I&#x27;ve also read about PE buying up smaller medical&#x2F;dental practices and squeezing the price. Happened to my old dentist in Ballard, WA -- and dang, they pushed me for x-rays on every visit (turns out there is good margin on x-rays). Dell is still run by the OG -- these PE folks are just trying to squeeze margin.And sure, they still have to follow some regulations -- but with much less oversight when you&#x27;re not public. \"expensive and onerous\" is not a sufficient reason to not require a business to do something. Paying employees is expensive and onerous, should that stop? reply massysett 2 hours agorootparentAt least in US society, the general idea is that there should be a reason to require a business to do something. Not that there needs to be a reason to not require a business to do something.Public companies are subject to some requirements for good reason. Those reasons may not apply to private companies.Companies pay employees because if they don’t, they won’t have employees and therefore will lack labor, a critical input. reply scarface_74 3 hours agorootparentprevWhy do you care if a private company has to follow financial reporting regulations? The reason that public companies have to is because the public buys shares in the company. reply edoceo 2 hours agorootparentFor a small company, a sole-prop dentist for example -- I don&#x27;t. There is not enough motivation or sophistication or dollars on the table.For PE backed conglomerates I care because they can and do hide shady things in there. There is more motivation to juke the stats; more sophistication and dollars on the table. Sadly, because these companies are not public, when their anti-consumer operations are discovered there is little news about it. That results in a situation, for example, where folk don&#x27;t think there is any reason to care about the issue. reply scarface_74 1 hour agorootparentAgain why do you care as a consumer? If they aren’t getting money from the public market and no taxpayer money, how does that affect you?Whether the company is public or private they still have to follow the relevant laws for their industry. reply edoceo 1 hour agorootparentI care because these PE backed firms can (and do) screw the consumer (me, my family, my friends, you) and there is no visibility.Do you understand it&#x27;s possible to follow the law and still use greed to screw the consumer? Are you being intentionally naive? reply scarface_74 1 hour agorootparentI’m asking you for a specific case where a PE firm could specifically screw you and you have no choice but to be a consumer in a way a public firm couldn’t? reply QuadmasterXLII 7 minutes agorootparentHe gave a specific case of PE attemting to scam him in a way that not only steals money from him, but would literally irradiate his facerobertlagrant 2 hours agorootparentprev> \"expensive and onerous\" is not a sufficient reason to not require a business to do something.I don&#x27;t know where you&#x27;re getting this from. The reason to not require it is that the regulations don&#x27;t apply.However, it&#x27;s also true that making it cumbersome to do business, while making the big four consulting firms endless amounts of cash, is a real problem for all other public companies. reply anthonypasq 2 hours agorootparentprevwhy not get mad at the dentist for selling out then? people are acting like there is only 1 side on all of these deals. reply TeMPOraL 2 hours agorootparentBecause those deals are targeted \"offers you can&#x27;t refuse\", by design.Consider: surely there is a price for which you would be willing to sell me your business, or your house, pretty much on the spot. The current value of your assets could be X. Maybe you&#x27;re reluctant to sell for anything under 120% X. Maybe you know your neighbors will hate you if you sell it, so you really won&#x27;t do it for less than 140% X. I come to you and offer you 160% X. At this price, I can be certain you&#x27;ll sell. It&#x27;s a deal of a lifetime. It would be stupid not to.The trick is, as a PE firm, I can make this profitable for me all the way to say 250% X. I can just keep repeating that deal with every other person like you in the neighborhood, certain they&#x27;ll all individually agree. And by the time the neighborhood realizes some critical service or area is now owned by a profit-obsessed faceless corporation, it&#x27;ll be mostly sold out already.The trick is to target a market segment when you&#x27;re able to make offers the other side can&#x27;t refuse. Then you can literally divide and conquer it. reply anthonypasq 1 hour agorootparentwell the person CAN very easily refuse if they care about not selling out to some faceless corporation and fucking their customers, but obviously most of these people dont care about that, so again, seems like you should be getting mad at them.i just dont understand exactly what is the problem here. do you think people shouldnt be able to sell their businesses for what they are worth? reply TeMPOraL 1 hour agorootparent> well the person CAN very easily refuse if they care about not selling out to some faceless corporation and fucking their customers, but obviously most of these people dont care about thatThose people aren&#x27;t spherical cows in an toy ethics thought experiment. They are real people, with complex lives and many things competing for their care (like e.g. families). They all care about not selling out or hurting their customers... to some degree. Some to larger than others.The simplified algorithm the PE companies are doing is:- Estimate the upper bound of how much most - say, 80% - of the owners of targeted businesses care about things;- Express that upper bound in dollars over the value of business, call that number X;- If you can still make a profit while overpaying by up to X for each bought business, start making offers; otherwise, find a different target.There&#x27;s little point blaming the business owners, because the transactions are initiated by the PE companies, and they specifically target businesses they know they can get anyway. They&#x27;re taking advantage of the idea that people should be free to sell their business for a fair price if they want to. reply edoceo 1 hour agorootparentprevI spoke to the dentist. He was retiring and the offer was very, very good. The PE firms can afford this because they know they will get to squeeze a bunch of consumers for the next 10 years. reply ryandrake 24 minutes agorootparentWait a minute, if the dentist was retiring, why would the PE firm buy his practice? There&#x27;ll be nobody to clean those customers&#x27; teeth. Are they just paying a fortune for the office, equipment, and customer list? reply anthonypasq 1 hour agorootparentprevso what are you bitching about&#x2F;suggesting should happen? People should not be allowed to sell their businesses for what they are worth? reply em500 2 hours agoparentprev> This article is...not good.I agree. The opening paragraph reeks of picking numbers to fit a narrative. It states that the number of US listed public firms declined from 8000 in 1996 to 4000 today (suggesting but not explicitly claiming that a significant part has been devoured by PE), but leaves out that the valuation of the public companies in that period increased from 5T to 40T. reply dathos 2 hours agorootparentI’m not arguing for their suggestion. But if their logic is that this happened because of PE and those PE owning also a big chunk of those public firms, doesn’t your argument proof they are devouring a large part of the economy? reply onlyrealcuzzo 3 hours agoparentprevMost of this goes away when you have positive real interest rates.It makes sense to take on massive amounts of debt to buy things when you get paid to be in debt.Companies that do leveraged buyouts are going to have a good time.When money isn&#x27;t free - companies that do leveraged buyouts aren&#x27;t going to have as good of a time. reply lukas099 2 hours agorootparentDo you mean higher real interest rates? They have been positive almost all of the last 10 years. https:&#x2F;&#x2F;fred.stlouisfed.org&#x2F;series&#x2F;REAINTRATREARAT10Y reply michaelt 2 hours agorootparentThat&#x27;s the interest rate for people willing to lock their money up for 10 years.Look at https:&#x2F;&#x2F;fred.stlouisfed.org&#x2F;series&#x2F;REAINTRATREARAT1YE instead, the 1 year real interest rate, and it&#x27;s barely been positive between 2009 and 2022. reply onlyrealcuzzo 2 hours agorootparentprevMy understanding is the 10-y is not relevant to venture debt or leveraged buyouts: https:&#x2F;&#x2F;www.svb.com&#x2F;startup-insights&#x2F;venture-debt&#x2F;how-does-v...And anyway - yes - a 1% real return really only existed in a long capacity since the 2000s, since QE became main stream. reply DragonStrength 2 hours agoparentprevDid you read the full article? The majority of it is defending why public financial oversight is good. Saying the article is \"not good\" while ignoring its central argument to make a tangential point is not convincing. reply Joker_vD 3 hours agoparentprevYep. \"Oh no, the investors don&#x27;t get reliable information about private-equity companies and so investment is way too risky\" — well, then investors probably would just stop invest in them? What&#x27;s the problem? reply dangus 2 hours agoparentprevYou could also say “all private equity is not created equal.”I think that the common belief that private equity swoops in and sucks the company dry like a vampire is only a half-truth. The “company flipper” style private equity companies are usually buying companies that are not doing all that well in the first place.Not unlike a venture capital firm investment in a startup, private equity firms probably don’t expect 100% of their investments to pan out. The idea is to buy a struggling company for pennies on the dollar, turn it around, make a big return on that investment. However, turning around a struggling business isn’t always going to happen, and when it fails the private equity firms are perceived as vultures.A good example of a company that has done well under private equity ownership has been Popeyes. They launched their extremely popular chicken sandwich under private equity ownership. The parent company has for the most part left the strong parts of the business alone (keeping the product up to a good enough standard) while appeasing franchises’ need for more profitable operations, leading to growth in its footprint. reply no_wizard 2 hours agoprevOne critical thing to think about here: Often (though not exclusively always) PE firms are backed by leveraging debt to rollup up companies. This creates a big cycle of:- Acquiring massive debt against the new rollup entity- Using that debt for short term expansion, maybe even subsidizing the business model in some cases- Payouts to executives at the PE firms. There are instances where larger PE firms actually borrow from themselves via another entity so the debt payback goes solely to the PE firm under favorable terms to the PE firm.- Then, squeezing as much of the market as possible to service this debt via localized monopolies and&#x2F;or cost cutting measures. Typically higher prices and worse service follows in short order- Finally, if they can&#x27;t continue to service the debt, the debt, since being held by the new entity and not the PE firm directly, the entity declares bankruptcy to restructure the debt (or in some cases, absolve it entirely)PE firms can then rinse and repeat on this, over and over again, with little oversight or repercussions.Sometimes I feel like I&#x27;m in the wrong business reply alexpetralia 2 hours agoparentAnd who is on the losing end in the bankruptcy? Who keeps underwriting these deals?It used to be syndicated bank loans (often repackaged into CLOs), but now it is jumbo private credit funds. The banks ended up losing (which is why they are retrenching from this space), but I don&#x27;t believe private credit is (yet).https:&#x2F;&#x2F;www.ft.com&#x2F;content&#x2F;8962a5cc-2c4c-4e18-801c-9ad4e342f...https:&#x2F;&#x2F;www.wsj.com&#x2F;finance&#x2F;fed-rate-hikes-lending-banks-hed... reply renewiltord 1 hour agoparentprevSo there&#x27;s a bunch of sucker lenders here who are giving money away. That&#x27;s fine, I suppose, so long as the sucker lenders aren&#x27;t governments and their banks. reply throw0101c 2 hours agoprevSee also \"The United States of Bed Bath & Beyond\" from last month (raiding a company for cash and creating debt, then declaring bankruptcy):* https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37652479\"Bed Bath and Beyond files for bankruptcy\", April 2023:* https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35700918 reply xrd 2 hours agoparentOr, Toys R Us. reply throw0101c 2 hours agorootparent&#x27;The Toys “R” Us Bankruptcy and Private Equity&#x27;:* https:&#x2F;&#x2F;www.theatlantic.com&#x2F;magazine&#x2F;archive&#x2F;2018&#x2F;07&#x2F;toys-r-...* https:&#x2F;&#x2F;archive.ph&#x2F;OH9QF reply hartator 2 hours agoprevI wonder how it affects a BogleHead strategy to retirement.If the Sp500 (VOO, or VTI, VT) is less and less representative of the U.S. market, there is a case to be made that it&#x27;s becoming disconnected more and more of the \"real\" economy. This is kind of undermining BogleHead strategy to just buy the full market as the full market is less and less accessible. reply flint 2 hours agoprevSarbanes-Oxley https:&#x2F;&#x2F;www.investopedia.com&#x2F;terms&#x2F;s&#x2F;sarbanesoxleyact.asp reply j7ake 2 hours agoprevAlso many retail investors are passive, relying on ETFs.This means private companies take all the profits, and when there is sign of trouble, can dump their stock to the stock market, get it bundled into an ETF, and a passive retail investor will buy some through their monthly contributes to a popular ETF. reply sam345 1 hour agoprevCompliance costs and exposure to political risk is the primary driver of going or staying private in the US. A company immediately becomes a target for governmental and NGO political pressures once it becomes public. Now it no longer can focus on designing, producing, and selling the best products and services at a good profit for its shareholders, it must devote a substantial percentage of its efforts on hiring lawyers, PR specialists, and lobbyists. More recently the SEC has morphed from an agency whose primary goal was transparency of investment risk, to a cudgel for enforcing preferred political goals. Nobody wants a target on their back if they can avoid it. A company only goes public when it has no choice when it runs out of investors or shareholders need liquidity. Pretty ironic IMO that same voices that identified public corporations as the enemy are now lamenting their demise. reply braza 1 hour agoprevOne forgotten aspect of this PE taking over established businesses is that are the employees.I saw some cases where the company gave stock options for employees and kept everyone hanging due to a promise of an IPO and when the whole thing scrubs, the founders sells to the PE and the first measure is to expire all the options from the employee pool [1].Honestly I think the whole thing about options with the rise of PE and this brutal aspect to get best financial resources is over for any person joining wanting to have a more outsized exit.[1] - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28561054 reply typedef_struct 10 minutes agoprevWorking as intended reply Damogran6 1 hour agoprevRetirement is 8-10 away. I was considering &#x27;do I own my home outright&#x27; or do I &#x27;buy a new home with a mortgage I never expect to fully pay off&#x27;This kind of BS makes me think owning the property would be safe, so I don&#x27;t wake up one morning with a mortgage I can&#x27;t pay. reply cushpush 1 hour",
    "originSummary": [
      "The rapidly expanding private-equity industry, now valued at $12 trillion, is sparking concerns about transparency, accountability, and potential systemic risks, due to an increase in taking publicly traded companies private.",
      "The practice of taking companies private by these firms exempts the companies from mandatory public disclosures, leading to less scrutiny and potential for abuse such as workforce layoffs, regulatory evasions, and company bankruptcies, while ensuring high payouts for the firms’ partners.",
      "While government regulations have been proposed to demand more information from private-equity funds, additional actions are needed to address the intrinsic issues plaguing the industry, to prevent potential financial crises triggered by unmanageable debt and defaults."
    ],
    "commentSummary": [
      "The rise of private equity firms in the US and their small business acquisitions are leading to wealth concentration, transforming homeowners into renters, aggravating income inequality, and affecting retirement plans.",
      "The dialogue illuminates the need to diversify retirement savings beyond 401(k) plans and critiques pension plans, addressing the challenges posed by retirement systems.",
      "The consolidation of industries, such as veterinary practices, by private equity firms presents challenges for independent businesses, with potential adverse outcomes including cost-cutting, misinformation, higher prices, and compromised wellbeing."
    ],
    "points": 175,
    "commentCount": 225,
    "retryCount": 0,
    "time": 1698672347
  },
  {
    "id": 38061096,
    "title": "How many billions of transistors in an iPhone processor?",
    "originLink": "https://lemire.me/blog/2023/10/18/how-many-billions-of-transistors-in-your-iphone-processor/",
    "originBody": "Skip to content Daniel Lemire's blog Daniel Lemire is a computer science professor at the Data Science Laboratory of the Université du Québec (TÉLUQ) in Montreal. His research is focused on software performance and data engineering. He is a techno-optimist and a free-speech advocate. My home page My papers My software Join over 12,500 email subscribers: You can follow this blog on telegram. You can find me on twitter as @lemire or on Mastodon. Search for: SUPPORT MY WORK! I do not accept any advertisement. However, you can you can sponsor my open-source work on GitHub. RECENT POSTS Appending to an std::string character-by-character: how does the capacity grow? For processing strings, streams in C++ can be slow How many billions of transistors in your iPhone processor? Randomness in programming (with Go code) Web server ‘hello world’ benchmark : Go vs Node.js vs Nim vs Bun RECENT COMMENTS Vimal on For processing strings, streams in C++ can be slow Arseny Kapoulkine on Appending to an std::string character-by-character: how does the capacity grow? Arseny Kapoulkine on Appending to an std::string character-by-character: how does the capacity grow? Cly on For processing strings, streams in C++ can be slow jerch on Appending to an std::string character-by-character: how does the capacity grow? PAGES A short history of technology About me Book recommendations Cognitive biases Interviews and talks My bets My favorite articles My favorite quotes My rules Newsletter Predictions Privacy Policy Recommended video games Terms of use Write good papers ARCHIVES Archives Select Month October 2023 (5) September 2023 (4) August 2023 (5) July 2023 (9) June 2023 (7) May 2023 (7) April 2023 (15) March 2023 (9) February 2023 (5) January 2023 (7) December 2022 (10) November 2022 (9) October 2022 (3) September 2022 (5) August 2022 (3) July 2022 (7) June 2022 (4) May 2022 (4) April 2022 (4) March 2022 (2) February 2022 (4) January 2022 (3) December 2021 (2) November 2021 (7) October 2021 (12) September 2021 (5) August 2021 (2) July 2021 (4) June 2021 (5) May 2021 (8) April 2021 (6) March 2021 (5) February 2021 (4) January 2021 (6) December 2020 (11) November 2020 (10) October 2020 (6) September 2020 (6) August 2020 (4) July 2020 (6) June 2020 (7) May 2020 (6) April 2020 (7) March 2020 (8) February 2020 (7) January 2020 (7) December 2019 (10) November 2019 (6) October 2019 (7) September 2019 (9) August 2019 (9) July 2019 (10) June 2019 (9) May 2019 (10) April 2019 (8) March 2019 (15) February 2019 (9) January 2019 (10) December 2018 (9) November 2018 (8) October 2018 (10) September 2018 (9) August 2018 (10) July 2018 (14) June 2018 (9) May 2018 (11) April 2018 (11) March 2018 (10) February 2018 (7) January 2018 (15) December 2017 (9) November 2017 (16) October 2017 (13) September 2017 (20) August 2017 (11) July 2017 (8) June 2017 (9) May 2017 (10) April 2017 (11) March 2017 (11) February 2017 (6) January 2017 (8) December 2016 (8) November 2016 (4) October 2016 (6) September 2016 (10) August 2016 (6) July 2016 (4) June 2016 (6) May 2016 (5) April 2016 (10) March 2016 (9) February 2016 (8) January 2016 (5) December 2015 (8) November 2015 (4) October 2015 (8) September 2015 (5) August 2015 (6) July 2015 (5) June 2015 (2) May 2015 (4) April 2015 (4) March 2015 (5) February 2015 (5) January 2015 (3) December 2014 (6) November 2014 (4) October 2014 (3) September 2014 (5) August 2014 (5) July 2014 (4) June 2014 (2) May 2014 (6) April 2014 (7) March 2014 (3) February 2014 (5) January 2014 (5) December 2013 (8) November 2013 (5) October 2013 (5) September 2013 (5) August 2013 (3) July 2013 (4) June 2013 (4) May 2013 (3) April 2013 (7) March 2013 (6) February 2013 (6) January 2013 (8) December 2012 (2) November 2012 (5) October 2012 (4) September 2012 (6) August 2012 (4) July 2012 (4) June 2012 (3) May 2012 (3) April 2012 (6) March 2012 (5) February 2012 (3) January 2012 (8) December 2011 (3) November 2011 (5) October 2011 (5) September 2011 (4) August 2011 (8) July 2011 (3) June 2011 (5) May 2011 (6) April 2011 (6) March 2011 (5) February 2011 (4) January 2011 (10) December 2010 (7) November 2010 (6) October 2010 (3) September 2010 (3) August 2010 (5) July 2010 (4) June 2010 (7) May 2010 (5) April 2010 (7) March 2010 (8) February 2010 (5) January 2010 (7) December 2009 (4) November 2009 (6) October 2009 (10) September 2009 (8) August 2009 (11) July 2009 (9) June 2009 (7) May 2009 (7) April 2009 (7) March 2009 (7) February 2009 (14) January 2009 (14) December 2008 (16) November 2008 (25) October 2008 (13) September 2008 (15) August 2008 (14) July 2008 (15) June 2008 (14) May 2008 (15) April 2008 (20) March 2008 (18) February 2008 (12) January 2008 (19) December 2007 (24) November 2007 (23) October 2007 (19) September 2007 (13) August 2007 (23) July 2007 (18) June 2007 (15) May 2007 (19) April 2007 (9) March 2007 (7) February 2007 (27) January 2007 (20) December 2006 (20) November 2006 (18) October 2006 (9) September 2006 (11) August 2006 (25) July 2006 (10) June 2006 (18) May 2006 (27) April 2006 (25) March 2006 (11) February 2006 (11) January 2006 (39) December 2005 (23) November 2005 (25) October 2005 (20) September 2005 (25) August 2005 (39) July 2005 (17) June 2005 (16) May 2005 (9) April 2005 (13) March 2005 (30) February 2005 (20) January 2005 (30) December 2004 (11) November 2004 (19) October 2004 (14) September 2004 (17) August 2004 (13) July 2004 (16) June 2004 (16) May 2004 (12) BORING STUFF Log in Entries feed Comments feed WordPress.org How many billions of transistors in your iPhone processor? In about 10 years, Apple has multiplied by 19 the number of transistors in its mobile processors. It corresponds roughly to a steady rate of improvement of 34% per year on the number of transistors, or a doubling every 2.5 years. In real dollars, an iPhone has roughly a constant price: the price tag of a new iPhone increases every year, but it does so while tracking the inflation. Thus you are getting ever more transistors in your iPhone for the same price. processor release year transistors Apple A7 2013 1 billions Apple A8 2014 2 billions Apple A9 2015 2 billions Apple A10 2016 3.2 billions Apple A11 2017 4.3 billions Apple A12 2018 6.9 billions Apple A13 2019 8.5 billions Apple A14 2020 11.8 billions Apple A15 2021 15 billions Apple A16 2022 16 billions Apple A17 2023 19 billions PUBLISHED BY Daniel Lemire A computer science professor at the University of Quebec (TELUQ). View all posts by Daniel Lemire 4 thoughts on “How many billions of transistors in your iPhone processor?” Juho Vepsäläinen says: October 19, 2023 at 8:02 am That’s an interesting observation. It would be a good addition to track process level change (nanometers) but I imagine it follows that well. Chip-size might be another nice one. REPLY Sam Mason says: October 19, 2023 at 9:46 pm Plotting the data seems to suggest that transistor count increase is slowing down: Note that the y-axis is logged to show multiplicative increases as a linear trend. I was going to say that 2018 was the end of exponential growth but looking at the gradient doesn’t show much happening then. Presume it’s being limited by the increasing difficultly of engineering these bigger devices. REPLY Sam Mason says: October 19, 2023 at 9:49 pm there was an image in my comment but it seems to have been stripped out, see https://i.stack.imgur.com/lnQMw.png for the plot. [feel free to delete this comment the original image get whitelisted) REPLY jerch says: October 24, 2023 at 11:03 am Moore’s law still at its works, although it may have paced down a bit. I wonder if we can reach sub-nanometer resolution with optical technologies, as it is already deep in x-ray range. Is that finally the end of silicon-based computing as we know it, which has been announced for long but engineers kept teaching us otherwise so far? Are there any serious contenders on the horizont to dethrown current serial computing technology? Maybe from nanotechs? Also it seems quantum computing will not hold up to the high hopes many marketeers have promised (thats at least what some physicists say), not to mention the algebraic issues around it… REPLY Leave a Reply Your email address will not be published. COMMENT * NAME * EMAIL * WEBSITE Save my name, email, and website in this browser for the next time I comment. RECEIVE EMAIL NOTIFICATIONS? no, do not subscribe yes, replies to my comment yes, all comments/replies instantly hourly digest daily digest weekly digest Or, you can subscribe without commenting. You may subscribe to this blog by email. Post navigation PREVIOUS Previous post: Randomness in programming (with Go code) NEXT Next post: For processing strings, streams in C++ can be slow Terms of use Proudly powered by WordPress",
    "commentLink": "https://news.ycombinator.com/item?id=38061096",
    "commentBody": "How many billions of transistors in an iPhone processor?Hacker NewspastloginHow many billions of transistors in an iPhone processor? (lemire.me) 172 points by greghn 22 hours ago| hidepastfavorite184 comments mlsu 20 hours agoI&#x27;ve often struggled to really \"grok\" how complex chips are. They all kinda look the same. I write software, so I know how complex that is, but like the device itself -- it&#x27;s this little black box. What&#x27;s the difference between one little black box and another? Most people don&#x27;t even get that far; they think the computer is the screen that lights up.I&#x27;ve been reading datasheets a lot at work. The datasheet for an STM32F4 is 149 pages long. The technical manual is over 800 pages long. That puts it into perspective a little bit better for me. I might spend days or weeks writing a driver for some little few pages of that datasheet. It&#x27;s a dense 800 pages. Those manuals indicate just a fraction of the complexity that lies inside of the device -- they describe features that I can use, not even how those features are implemented or made. And that&#x27;s for a tiny chip that costs a couple dollars.A billion is a tough number to understand, but I recommend reading a datasheet of a chip sometime. It will put into perspective how much complexity there is in just a few millions of transistors.I sometimes have to take a moment, because I remember descriptions of alien technology from sci-fi books. Complexity, opaqueness, power. Chips. reply Salgat 13 hours agoparentThe reality is that 70-90% of a CPU is SRAM (cache and registers), and only a small portion is actual logic and even that is replicated across multiple cores. Factor in the extremely redundant gpu on the SoC with its own cores and SRAM along with the I&#x2F;O controller and those billions of transistors boil down to a tiny amount of actual unique logic circuits. Still very impressive, but helps put things in perspective. reply duskwuff 13 hours agoparentprev> Those manuals indicate just a fraction of the complexity that lies inside of the device -- they describe features that I can use, not even how those features are implemented or made.And even then:1) There&#x27;s parts of the manual which are brief summaries, written with the assumption you&#x27;re already familiar with the larger standards they interface with. The SDIO and USBOTG sections of the reference manual come to mind in particular, not to mention all the external manuals it takes to describe the ARM Cortex-M architecture.2) That&#x27;s a fairly simple microcontroller. (Given the page count, it sounds like you&#x27;re working with STM32F401.) The STM32H7 series reference manual is 3500+ pages. reply grishka 5 hours agoparentprevIf you want to gain a deeper understanding of how computers work, write an emulator of something relatively simple — GameBoy for example. This is kinda disillusioning. With the bugs you&#x27;ll inevitably make, you&#x27;ll understand how very, very, very dumb computers actually are. A CPU just fetches an instruction from memory, executes it, and updates the program counter. It does this indefinitely, for as long as power is applied. No magic whatsoever.The GameBoy CPU is simple and easy to understand, sure, but modern ones are built upon the same basic principles, it&#x27;s just that they run at much higher clock speeds and add lots and lots of parts (caches, pipelining, speculative execution, register renaming, multiple ALUs, SIMD ...) to execute as many instructions per clock cycle as possible. Also virtual memory support — MMU, TLB, all that stuff.For the other side, if you want to build a CPU out of logic gates, there was a web-based game where you did exactly that. I don&#x27;t remember the URL, sorry. reply lynguist 4 hours agorootparent> you&#x27;ll understand how very, very, very dumb computers actually areThat’s not true for any post 1995 desktop CPU.They just adhere to that model and pretend that that’s all they’re doing but in reality there’s layers of supercomputers inside the CPU: micro-op cache, branch predictor, reorder buffer, rename buffer.They extract hidden parallelism out of the code, run it in blazing fast multiple instructions per clock cycle (!), and pretend that nothing out of the order happened.CPUs are extremely complex and extremely smart. They can have errors in their implementation where the unseen branches that it executed can be accessed by some processes, etc. But there’s nothing dumb about CPUs. They are made of a million man-hours of engineering. reply grishka 4 hours agorootparentThe designs are smart. The CPUs themselves are still dumb, which is precisely the reason why speculative execution bugs exist. It&#x27;s magic up until the point all the tricks spill out. In the end, it&#x27;s always just logic gates wired together to do certain things — whether it&#x27;s a Z80 or an M2 Max. All this layered complexity is simply the product of 50 years of iterative improvements. reply John23832 1 hour agorootparentI think this is just doubling down and simplifying CPUs to the point of uselessness.What&#x27;s the difference between a logic gate and when my index and thumb have a static charge jump between them? About a couple trillion dollars of research. reply Koshkin 1 hour agorootparentprev> In the end, it&#x27;s always just logic gates wired together to do certain thingsThat seems to me a highly reductive point of view. The whole is always more than the sum of its parts. reply vulcan01 3 hours agorootparentprev> there was a web-based game where you did exactly thatThis is the one I played some time ago: https:&#x2F;&#x2F;nandgame.com&#x2F; reply dmd 3 hours agorootparentprev\"just\" and \"executes\" are doing a hell of a lot of heavy lifting here reply grishka 3 hours agorootparentSome bits in the instruction activate some logic gates in the instruction decoder that, in turn, activate and deactivate other logic gates in the control logic, and eventually the appropriate functional unit inside the CPU is configured for the thing the instruction calls for and does it. Like the ALU adding two numbers together. If it&#x27;s an architecture that uses microcode, like everything x86, I suppose the instruction decoder instead (or additionally?) outputs a microcode ROM address. reply dmoy 14 hours agoparentprev> I recommend reading a datasheet of a chip sometime. It will put into perspective how much complexity there is in just a few millions of transistors.I do miss working directly with small, simple (relatively), cheap chips. I don&#x27;t miss dealing directly with the low level bus protocols though. I still have stress nightmares about diagnosing can bus and i2c bus problems with an oscilloscope. Like in the stress dream I&#x27;ll either forget some important details about the protocol and not understand what is going on at all, or I will remember everything in perfect detail but be unable to speak and explain what&#x27;s wrong to the other person who&#x27;s there working on the issue. reply 7373737373 20 hours agoparentprevThe Intel® 64 and IA-32 Architectures Software Developer’s Manual Combined Volumes: 1, 2A, 2B, 2C, 2D, 3A, 3B, 3C, 3D, and 4has over 5000 pages![0] https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;developer&#x2F;articles&#x2F;t... reply penguin_booze 9 hours agorootparentI&#x27;m out of date by a couple of years, but the last I knew, the ARM Architecture Reference Manual (amusingly, also called the ARM ARM) is around 8000 pages. Though, it carries similar corpus from the ARMv7 manual, now bottled as AArch32. reply raverbashing 8 hours agorootparentprevSome people might be wondering \"huh, why number them in this weird way?!\"It&#x27;s because they were originally 3 volumes. volume 2 is the ASM reference, 3 is the \"how to do things\" reference (System programming guide). Volume 1 is more of a general reference so maybe that&#x27;s why it didn&#x27;t grow so much. reply vbezhenar 8 hours agoparentprevAs far as I understand, chips are basically made of parts. CPU, of course, then one part for USB peripheral, another for USART, another for ADC and so on. Every peripheral is more or less a complete and isolated device. So if it&#x27;s possible to get hands on this peripheral datasheet (I think it&#x27;s called IP) written for chip designers, that would reveal complete complexity of the given part of the MCU.Also I don&#x27;t really have an idea, but I wouldn&#x27;t be surprised, if a very significant part of transistor budget has been spent on SRAM or something similar, which is not very fascinating. reply SmallDeadGuy 8 hours agoparentprev> A billion is a tough number to understandI love using the money analogy for this:\"If you earned $1 every single second, that&#x27;s $60 per minute, $3,600 per hour, $86,400 per day. More than most people make in a year!Assuming no tax or expenditure whatsoever, it would take only 11 days to become a millionaire at that salary.It would take over 31 _years_ to become a billionaire.And that&#x27;s only a mere $1 billion, some people are worth _hundreds_ of billions.\" reply tigershark 11 hours agoparentprevYou don’t really need to go in the millions to appreciate the complexity of a chip. The famous Motorola 68000 had actually 68000 transistors. reply joshxyz 6 hours agoparentprevi do web development, not versed on the iot stuff.i tried to read an Espressif ESP32 manual, blew my fucking mind on how complex it is relative to how cheap it is. reply crote 35 minutes agorootparentThe expensive part is usually the engineering itself. Once the chip has been designed, manufacturing is relatively cheap. You can even get reasonably-capable MCUs for as little as $0.10! reply pzber 6 hours agoparentprevBeautifully written! reply dehrmann 20 hours agoparentprevIt&#x27;s turtles all the way down. reply jowea 17 hours agoparentprevIt&#x27;s the power of abstraction. reply Dalewyn 12 hours agoparentprev>I sometimes have to take a moment, because I remember descriptions of alien technology from sci-fi books. Complexity, opaqueness, power. Chips.Sufficiently advanced technology is indistinguishable from magic. reply Cthulhu_ 8 hours agorootparentThe wizzards can channel the power of lightning through rocks to produce porn, what a time to be alive. reply corethree 14 hours agoparentprevI don&#x27;t think it&#x27;s nearly as complex as you think. The important measure isn&#x27;t transistors, but the amount of concepts formed by composing transistors together.There&#x27;s no way in hell people can make sense of 19 billion separate concepts. Likely what&#x27;s going on in the chip is just repeated patterns designed to make a very simple machine operate really really quickly.But of course I&#x27;m not denying the complexity. But the 19 billion implication here is a bit too much. It&#x27;s likely just as complex as say linux. reply eru 12 hours agorootparent> There&#x27;s no way in hell people can make sense of 19 billion separate concepts. Likely what&#x27;s going on in the chip is just repeated patterns designed to make a very simple machine operate really really quickly.You are right about human designed chips. If you use something like simulated evolution or backpropagation or some other techniques from machine learning or mathematical optimization, you can get machines with billions of parts but not necessarily any clear pattern nor repetition.The human brain might be an example of such a mechanism. reply corethree 12 hours agorootparentThe human brain IS an example of such a mechanism.We&#x27;ve done it artificially as well with machine learning and genetic algorithms.The amount of concepts in the neural network of an LLM is too large for us to fully understand.At best we can only hope to understand these things as a sort of curve fitting optimization problem. reply eru 8 hours agorootparentI was using some weasel words, because the human brain does have some structure that we can decipher. Specific injuries to the brain, even in different people, tend to cause the same specific problems. (With heavy emphasis on &#x27;tend to&#x27;, this is not deterministic, like removing the &#x27;e&#x27; key from your keyboard.) reply corethree 1 hour agorootparentWe can do the same with LLMs. We can tease out some macro structure behaviors by looking at intermediate output from the feed forward network.But you see how this is far from true understanding. It&#x27;s like removing the WiFi module from a PC and you lose WiFi, therefore you know the WiFi module does WiFi stuff but in the end this action contributes nothing towards cohesive understanding of the PC. replyyieldcrv 13 hours agoparentprevhm, I dont feel the same wayyou should do some coding closer to the chipsome bitshifting, some bit level manipulationyou dont have to be good at assembly, just do a hello world and make a mental visualization of the registers being hitlook up the OPCODES in your specific chipset , make some code to hit that specificallymake a process that does it as fast as possible and benchmark it, do it faster or slower on a different chipset, or a resource constrained environmentit makes it all really easy to follow and visualize reply kccqzy 13 hours agorootparentThat&#x27;s not even close to the chip. Dabbling around with the ISA doesn&#x27;t tell you much about the micro architectural features of the chip. I&#x27;m sure \"do some bit twiddling\" is absurd advice for someone who has written a driver. reply yieldcrv 6 hours agorootparentis all of it absurd advice? its about breaking abstract problems into smaller digestible problems to get a mental mapI dont think you need to write a driver for that map reply rwmj 6 hours agorootparentprevBetter advice would be to look at some of the open source RISC-V cores. They are nowhere near as complex as Apple&#x27;s Axx silicon (probably not even 0.1%) but they demonstrate at least some of what goes on at the lower levels. reply htk 22 hours agoprevI consider myself very lucky to be born in this age of civilization where technology increases at such incredible pace. Playing games on an atari in my childhood, then sega master system, nintendo, snes, pc games, the first 3d acceleration consumer cards, all the way to having a supercomputer in my pocket. What a time to be alive. reply scarface_74 21 hours agoparentI think it is more amazing that we went from the Wright brothers in 1903 to landing on the moon in 1969. reply samwillis 21 hours agorootparentAnd we haven&#x27;t been back in 50 years, despite all the incredible technology improvements.The Apollo guidance computers had \"several tens of thousands of transistors\"[0], we now have 19 billion in our pocket!0: https:&#x2F;&#x2F;www.aei.org&#x2F;technology-and-innovation&#x2F;apollo-11-mank.... reply eru 12 hours agorootparentPutting humans on the moon in the first place was mostly just grandstanding. Manned space exploration in general is mostly just entertainment. I&#x27;m glad humanity hasn&#x27;t continued wasting resources on that particular endeavor.Unmanned probes do good work for science. (Though even there I am not sure about the bang-for-the-buck compared to other alternatives.)Have a look at &#x27;20 Breakthroughs from 20 Years of Science aboard the International Space Station&#x27; https:&#x2F;&#x2F;www.nasa.gov&#x2F;missions&#x2F;station&#x2F;20-breakthroughs-from-...That&#x27;s the list of the 20 best things they could come up with. And it scarcely has anything that couldn&#x27;t have been done cheaper with unmanned craft. And it includes gems like counting spending money as a benefit, instead of a cost. reply causi 8 hours agorootparentPutting humans on the moon in the first place was mostly just grandstanding. Manned space exploration in general is mostly just entertainment.Indeed, and I believe refusing to acknowledge that fact is actively harming not just spaceflight but manned spaceflight. We&#x27;re spending tens of billions of dollars trying to set up for some bullshit useless moon base when we could be setting boots on Mars just to prove we can. If we&#x27;re gonna waste money let&#x27;s waste it pushing the boundaries. reply Shawnj2 7 hours agorootparentI think a moon base is actually more useful because there’s actual commercial use cases to a moon base like mining etc. and not only that but doing a mars mission is far easier and cheaper if you already have a moon base since you can make rocket fuel on the moon for cheaper in terms of delta-V if you can come up with a hydro lox chemistry design. reply eru 7 hours agorootparentThat might be true, but that doesn&#x27;t mean the moonbase needs to be manned.Especially since the signal lag from earth is so small, so you can even use remote human operators for many tasks instead of investing a lot in AI. reply causi 7 hours agorootparentprevWhat could you mine on the moon that would be worth transporting home? reply ben_w 4 hours agorootparentBack when people were suggesting mining it for helium-3, I remember reading a blog post that claimed the best way to get it out of the regolith would produce ridiculously high-purity metals as a side product.It then went on to point out that the particle density of helium-3 in regolith of was so low that, despite it being a fusion fuel, it made more sense to catapult the ingots to earth and (1) magnetically decelerate them for energy, and&#x2F;or (2) burn them.I suspect one of the best things you can build on the moon and not on Earth is an orbital ring[0]. Well, two rings, first you build one orbiting the moon, learn what the failure modes are and how to mitigate them, then you use that learning experience to export the parts for another to Earth… but I am just straight up assuming that the cost of a moon-based factory won&#x27;t blow away the cost savings from the difference in delta-v going down to LEO from the Moon (with or without a lunar orbital ring) vs. going up to LEO from the surface of the Earth.(Also: not mining, but I imagine it would be a great place for dangerous research, inspired by all the people suggesting COVID leaked out of a gain-of-function research laboratory).[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Orbital_ring reply tim333 3 hours agorootparentprevI gather there are asteroids with a lot of gold and platinum. Just crash one into the moon and then mine the debris. replyscarface_74 20 hours agorootparentprevI think “For All Mankind” is a great “What If” show about what things would be like if we had kept pushing forward.The thing about the series though was that NASA was self funded and didn’t have to justify spending billions in taxpayer money.Also, do we really have better propulsion technology to make space travel more efficient? reply simonh 12 hours agorootparent> Also, do we really have better propulsion technology to make space travel more efficient?It’s not really the propulsion technology that’s the key, it’s not throwing away a whole bunch of rocket engines every time, just to launch something once. So it’s really a design methodology as much as the technology.Having said that I think a key contributor to reusability is computation. As far as I’m aware all the experiments with propulsive landing in the 60s and 70s were manual. You could compute optimal thrust profiles given enough time and ideal conditions, but the conditions for an actual landing are never ideal. Particularly issues like atmospheric conditions such as air pressure by altitude, the effect of humidity, wind conditions and allows for the variability of turbulence around the vehicle. Modern automation of such must be vastly more efficient than manual control, but I don’t know when this became viable. reply jacquesm 20 hours agorootparentprevImagine if all of the worlds armament budgets were instead rerouted to science and space travel... reply devnullbrain 14 hours agorootparent20 years ago nobody spent any money on smartphones. Now, the money spent on them has created billions of processors with magnitudes more power than the spacecraft we&#x27;re being wistful about. Consumerism rerouted itself to forwarding science.And that&#x27;s just a device for watching cat videos. The carry-over between rockets and modern technology like hypersonic missiles is even greater - which is why we invented the space race to begin with. reply eru 12 hours agorootparentCarry over is still not as efficient as directly spending on what you want. reply ben_w 4 hours agorootparentIf you know what you want.“If I had asked people what they wanted, they would have said faster horses.”I sure never anticipated cosmetic surgeons twerking on Instagram in their scrubs to advertise themselves between the videos of a chick jumping into a confused Labrador&#x27;s mouth and that one of the kid on a bike being shocked by the existence of brown chalk when they see a Pokémon drawn on a sidewalk. reply scarface_74 20 hours agorootparentprevWhitey on the Moon &#x2F; LyricsA rat done bit my sister Nell. (with Whitey on the moon)Her face and arms began to swell. (and Whitey&#x27;s on the moon)I can&#x27;t pay no doctor bill. (but Whitey&#x27;s on the moon)Ten years from now I&#x27;ll be payin&#x27; still. (while Whitey&#x27;s on the moon)The man jus&#x27; upped my rent las&#x27; night. (&#x27;cause Whitey&#x27;s on the moon)No hot water, no toilets, no lights. (but Whitey&#x27;s on the moon)I wonder why he&#x27;s uppi&#x27; me? (&#x27;cause Whitey&#x27;s on the moon?)I was already payin&#x27; &#x27;im fifty a week. (with Whitey on the moon)Taxes takin&#x27; my whole damn check,Junkies makin&#x27; me a nervous wreck,The price of food is goin&#x27; up,An&#x27; as if all that shit wasn&#x27;t enoughA rat done bit my sister Nell. (with Whitey on the moon)Her face an&#x27; arm began to swell. (but Whitey&#x27;s on the moon)Was all that money I made las&#x27; year (for Whitey on the moon?)How come there ain&#x27;t no money here? (Hm! Whitey&#x27;s on the moon)Y&#x27;know I jus&#x27; &#x27;bout had my fill (of Whitey on the moon)I think I&#x27;ll sen&#x27; these doctor bills, Airmail special (to Whitey on the moon) reply illwrks 18 hours agorootparentGreat song. reply throwanem 20 hours agorootparentprevAnd still mostly wasted.Look after the people on Earth first. Once we show we can accomplish that, then and only then do we begin to earn the stars. reply ben_w 4 hours agorootparentThis feels like you&#x27;re unaware that, for all that remains to be done, less than half as many people are living in extreme poverty today as compared to 1990: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Extreme_poverty#&#x2F;media&#x2F;File:To... reply throwanem 2 hours agorootparentIn a counterfactual that begins with a trillion dollars to spend on something other than war - even in reality, for that matter - do you really not imagine we could choose to do better as a species than a dollar a day? reply ben_w 2 hours agorootparent1) A trillion dollars, spread over the 1.8 billion people in extreme poverty in 1990 and the 32 years since then, would have been 0.046 USD&#x2F;person&#x2F;day.2) There&#x27;s also this graph, if you want to see how the other income brackets are changing: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Extreme_poverty#&#x2F;media&#x2F;File:Th... reply least 20 hours agorootparentprevSorry, but no. There&#x27;s billions of people on earth; we can tackle many problems at once in parallel. reply jvanderbot 14 hours agorootparentYou don&#x27;t have to convince this person and won&#x27;t. This is what it looks like to parallelize: vehiment disagreement on priorities. reply throwanem 20 hours agorootparentprevYes, that&#x27;s worked out wonderfully for us of late, hasn&#x27;t it. reply least 20 hours agorootparentIt largely has, yes. The fact that things aren&#x27;t perfect isn&#x27;t justification for condemnation of the entire process. reply throwanem 20 hours agorootparentIt&#x27;s rare I find myself reaching for the adjective \"Panglossian\". reply robertlagrant 19 hours agorootparentSadly you aren&#x27;t Dr Strange, able to see the results of every possible decision to get the best outcome. That would be cool.But for now, we have to just observe how countries enact progress, and it does seem to be that the ones that delegate and diversify do the best at it. reply throwanem 19 hours agorootparentIt takes being a Marvel superhero to extrapolate from yesterday and today to tomorrow? reply robertlagrant 18 hours agorootparentNo, to know what past change would&#x27;ve made today much better. reply throwanem 17 hours agorootparentI do wish that people who feel the need to dispute what I&#x27;ve said in this thread would more reliably address themselves to things I have said, rather than to claims I&#x27;ve not even approached making. reply robertlagrant 9 hours agorootparentIf you rely on implication to make your point, you should mentally underwrite the risk of being frustrated at people who read what you wrote, rather than read your mind :-) reply throwanem 2 hours agorootparentHardly frustrated! Believe it or not, I do change my opinions and perspectives when I find that warranted, but my view of the world is not lazily arrived at, and to see a need to change it requires an argument I find even on reflection I can&#x27;t answer.HN is one of the most reliable sources of those that I know, and developing a thread in this way is one of the more reliable methods I know to improve my odds of eliciting one. Luckily for me, I have enough of a prickly, disputatious streak in my own nature to appreciate the process quite as much as the result. replydullcrisp 18 hours agorootparentprevDon’t lie. reply scarface_74 20 hours agorootparentprevHow would spending billions on the space race help? reply least 20 hours agorootparentNumerous technological advancements have been made as a result of the space race, but asking for justification on spending money on scientific inquiry is just going to come to whether or not you support science generally. reply eru 12 hours agorootparentWe could have spent money directly on the technologies we are interested in. That would have likely been more efficient. reply throwanem 20 hours agorootparentprevI&#x27;d like to see some justification for considering science and space exploration as one and the same. It&#x27;s hardly as if we&#x27;ve run out of things to learn from this planet, after all. reply jacquesm 19 hours agorootparentPersonally I&#x27;d like to see some justification for discovering America, there was plenty to be learned in Spain and Portugal at the time. reply scarface_74 16 hours agorootparentWell the people that were already here and died from both disease brought by the Europeans and murder might not see that as progress reply throwanem 19 hours agorootparentprevGiven how Europeans have behaved themselves on this continent, that really doesn&#x27;t qualify as a meaningful counterargument. If anything, it&#x27;s more to my point than yours. reply wiseowise 19 hours agorootparentHow have they behaved? reply throwanem 18 hours agorootparentWith which slaughter would you like me to start? reply least 19 hours agorootparentprevThey don&#x27;t have to be the same, but exploration is a necessary part of the scientific process, whether that be in the depths of the ocean, inside the earth, or in space.Curiosity has driven exploration, discovery, and subsequently science. It&#x27;s fine that you&#x27;re not as curious as some, but suggesting that we must only focus on things on Earth when we have literally billions of people on earth that all have individual interests and things they&#x27;re curious about is just about limiting progress, not about preserving Earth. reply throwanem 18 hours agorootparentThe Nuremberg Code also limits progress. Will you make the same complaint about it?If not, then we&#x27;ve established a mutually acceptable baseline for limits on human progress, and a subset of mutually acceptable reasons for imposing such limits. I suggest only that we need not stop there. reply least 17 hours agorootparentThese aren&#x27;t remotely comparable. How about just justify your rationale behind wanting to impose limits on space exploration on all of humanity? reply throwanem 17 hours agorootparentI did that in my first comment. How on Earth do you support the claim that one deliberately self-imposed limit on human progress can&#x27;t be compared with another? reply least 15 hours agorootparentYou defined the limitation as \"looking after the people on earth first,\" which has basically no meaning, so no, I would not say that you adequately defined those constraints in your first comment.> How on Earth do you support the claim that one deliberately self-imposed limit on human progress can&#x27;t be compared with another?You&#x27;re being obtuse. There&#x27;s a much more clearly defined intersection of human ethics when it comes to performing science on human beings than there is with some sort of vague proposition that space exploration is a waste of resources that is harming humanity indirectly by not allocating those resources towards taking care of other human beings. reply throwanem 14 hours agorootparent> which has basically no meaningI don&#x27;t think it has less meaning than the idea that the most sere and hostile environment for our species that we&#x27;ve yet been able to access - the deadliest imaginable desert, accessible only at vast effort and expense - has for our taking the boundless cornucopia of riches that space maximalists constantly promise, and with no more support than you complain I offer.Meanwhile you blithely argue that some significant fraction of a trillion dollars, available in this happy counterfactual from what had been the war department&#x27;s budget, should be devoted to this and nothing else, with no thought to the opportunity cost - and demand I justify myself in arguing we should better do otherwise!That opportunity cost would be measured in human lives, consigned to neglectful death in the service of your cause - but whether by neglect or murder, dead is dead. You&#x27;d be far from the first so to act; history is replete with examples, even ignoring the one we live among now. Such people are sometimes called to account. What would you say if you were? reply least 9 hours agorootparent> I don&#x27;t think it has less meaning than the idea that the most sere and hostile environment for our species that we&#x27;ve yet been able to access - the deadliest imaginable desert, accessible only at vast effort and expense - has for our taking the boundless cornucopia of riches that space maximalists constantly promise, and with no more support than you complain I offer.We&#x27;ve already benefited greatly from just the process of trying to get there. Even if there is no \"riches\" to be had in terms of extracting resources from alien planets, we still gain from our endeavors. This can be indirectly through technological advancements made in service to that mission (which we&#x27;ve seen plenty of already), or it can simply be in the pursuit of knowledge in the understanding of our universe.> Meanwhile you blithely argue that some significant fraction of a trillion dollars, available in this happy counterfactual from what had been the war department&#x27;s budget, should be devoted to this and nothing else, with no thought to the opportunity cost - and demand I justify myself in arguing we should better do otherwise!Why do you assume that there is not thought to the opportunity cost? It&#x27;s quite clear that we have different priorities on how humanity should allocate its resources but to say that it&#x27;s not a consideration is just crass. The amount of human productivity we dedicate towards space exploration is a remarkably small percent of what&#x27;s available, and a lot of that is driven by individual&#x27;s interest in it.The space program&#x27;s budget is minuscale compared to what we spend elsewhere, maybe around 5% of a trillion dollars. That&#x27;s a significant amount of money, but you seem to think that could be better spent on... what, exactly? Let&#x27;s say we reallocate that budget to social security. That&#x27;d be adding less than 4% to its budget, which is already over a trillion dollars. Or the combined spend of medicaid and medicare, in which case it would be less than 3%.> That opportunity cost would be measured in human lives, consigned to neglectful death in the service of your causeA lot of things have indirect consequences, positive and negative. Many things that have dramatically improved the livelihoods of humanity have come at a great cost.> but whether by neglect or murder, dead is dead. You&#x27;d be far from the first so to act; history is replete with examples, even ignoring the one we live among now. Such people are sometimes called to account. What would you say if you were?The advancements made by curious people has made the world less impoverished and less \"dead.\" Even if 100% of human productivity was allocated towards protecting human life, people will still die. That is life. At what point in your hypothetical world where you got to make these policies would it be acceptable for humanity to start exploring space again? When humans stop dying?Humanity&#x27;s driven by curious people willing to explore well beyond what seems rational to most people, not myopic luddites who would eschew entire avenues of exploration simply because they can&#x27;t understand the utility in it. reply throwanem 2 hours agorootparentThese justifications aren&#x27;t novel, and aren&#x27;t really much better than you claim mine to be. You gesture vaguely at technological progress, as every humans-in-space booster does. I have yet to hear anyone defend any of those advances as both useful enough to be worth wanting, and impossible to achieve on Earth. That&#x27;s an easier job in this case because we&#x27;re discussing a counterfactual, so you&#x27;re as free to invent something novel to defend as I am to imagine a trillion dollars going to an aid organization that actually manages to put the money where it does the most good, rather than serving as a combined graft slush fund and political football as most such organizations do now.> At what point in your hypothetical world where you got to make these policies would it be acceptable for humanity to start exploring space again?When there is no human on Earth who suffers in a way that money can prevent, I&#x27;ll no longer consider a dollar spent on putting a human into space a dollar culpably wasted.> Humanity&#x27;s driven by curious people willing to explore well beyond what seems rational to most people, not myopic luddites who would eschew entire avenues of exploration simply because they can&#x27;t understand the utility in it.I grew up suffused in the US space program. Huntsville was my favorite vacation. I read everything I could get my hands on - which, thanks to my grandfather, was a lot - I dreamed of astronaut school, at least until I learned it had visual acuity requirements. But even that little dampened the dream; I still spent most of my childhood studying with the intent of becoming an engineer and ultimately joining NASA. There are a lot of reasons that didn&#x27;t happen, but none of them had to do with the dream itself failing - and in some ways, it still hasn&#x27;t; do you think, if I still could believe there was anything for us either to find or to offer out there, I wouldn&#x27;t want my people to go to the stars?If, even in the face of all that, I still can be unconvinced by the case for putting humans as we are now into space, then that case needs to be better made. But dreamer though I was, the thing I came eventually to understand about a dream is that, however beautiful it may be, eventually you wake up and find reality still there.As far as \"human curiosity beyond rationality\" goes, I would have been much more sympathetic to that argument before it became inescapably obvious that in its pursuit we have quite literally set the world on fire.In the face of an error on that scale, I believe only a fool would fail to adjust his perspective, at least to encompass the possibility that, in the argot of my youth, we have gotten quite a bit too big for our breeches.That we should reach beyond our grasp is something even I consider creditable in the species. That we should reach into the gearbox of the world and have it tear off a couple fingers, and then want to go right on reaching without a thought at least to stanch the bleeding, at some point becomes self-destructive madness. An individual human displaying such behavior would be restrained for his own good. As a species, we would have to do that for ourselves, or reality will do it for us. It is doing exactly that now. We would be wise to take that into account in deciding our next actions. We won&#x27;t. But we could, and we should.Humans aren&#x27;t going anywhere any time soon, and I see nothing meaningful to choose between Mars today and Mars a hundred years from now, or two hundred, or a thousand. In that meantime, our efforts could make a meaningful difference as to how many billion humans are alive to celebrate that happy day.You really want to convince me that space boosterism might still, in spite of everything, have merit? Show me you can take the long view. reply throwanem 20 hours agorootparentprevExactly my question. reply wiseowise 19 hours agorootparentprevWe would be still in caves if everybody followed your logic. reply throwanem 18 hours agorootparentThe equation of all progress with any progress is yours, not mine. I haven&#x27;t made that argument; if you want to see it defended, I&#x27;m afraid you&#x27;ll have to do so yourself. replydehrmann 20 hours agorootparentprevSending people there is incredibly risky, and there just isn&#x27;t that much science to do. reply TheSpiceIsLife 18 hours agorootparentprevKinda just a bucket list item really.Go to the moon - checkBeen there, done that, to expensive and the cocktails where shit. reply jdjdjdhhd 14 hours agorootparentprevWhy go to the moon a second time? reply RugnirViking 14 hours agorootparentWhy build another computer? The first one was enormously expensive, way too heavy, and difficult to use reply matwood 18 hours agorootparentprevThese are always fun thought exercises. IIRC, Sapiens had an example if someone fell asleep in 1000 and woke up in 1500, they would still recognize the world. But if they fell asleep in 1500 and woke up in 2000, it would be unrecognizable.What it seems like we&#x27;re seeing is the compounding of science. Much like how compound interest works. I often wish I was born today just so I could see the progress in the next 50-100 years. reply paulddraper 20 hours agorootparentprevFrigging mind blowing.Single lifetime from flying a powered wooden glider to flying a rocket to the moon and back reply m463 16 hours agorootparentprevOr more democratically the Boeing 747 in 1969.sort of like - a few guys fly across a field to me and my entire high school class can buy tickets and fly across the pacific. reply n3150n 22 hours agoparentprevReminded me of this great literary article I read not too long ago, detailing some of the story behind the TMSC factory of semiconductors. Truly a marvelous read, if you are interested.https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;i-saw-the-face-of-god-in-a-tsmc-... reply corethree 14 hours agoparentprevI think we&#x27;re unlucky. I think the next generation or a couple generations down the line they will figure out biological immortality. If you&#x27;re immortal the sum total of things you will see in your lifetime will dwarf the experience you&#x27;re having now. reply kaba0 8 hours agorootparentAnd what will we do with immortality? Our organs will continue to deteriorate, especially the brain. Many older people are already quite gullible and easy to feed propaganda to, being a favored target to politicians, let alone someone 90+. reply ben_w 4 hours agorootparentIf you think that&#x27;s a necessary part of immortality, you&#x27;re looking at fiction inspired by the ancient Greek tale of Eos and Tithonus and not, for example, SENS: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Strategies_for_engineered_negl... reply corethree 1 hour agorootparentprevThat deterioration is what eventually causes death so immortality involves removing said deterioration.I&#x27;m short Immortality is achieved by stopping aging. reply huytersd 12 hours agorootparentprevI agree. I feel like we missed immortality by a few decades to a hundred years at the most. We might be some of the last generations that actually have to die. reply ben_w 4 hours agorootparentI don&#x27;t know which generation you&#x27;re in, but I do remember people saying in the late 00s, that the first person to live to 200 had likely already been born, we just didn&#x27;t know how old they were. reply Waterluvian 20 hours agoparentprevFor me it was the experience of being a teenager for both Half Life 1 and 2 and the brilliant and mad rush of GPU improvements in such a short amount of time. reply Daz1 13 hours agoparentprevCapitalism is amazing :) reply this15testing1 6 hours agorootparentif you can willfully ignore exploitation and externalities reply permo-w 19 hours agoparentprevchange and power do not necessarily make one happy reply Mistletoe 22 hours agoparentprevUnfortunately this hasn’t resulted in people being more happy. It’s quite the paradox. What are we doing all this for?https:&#x2F;&#x2F;news.gallup.com&#x2F;poll&#x2F;505745&#x2F;depression-rates-reach-n...I don’t post that to be negative, because I agree with what you are saying about a unique time to be alive and have done the same Atari to Xbox Series X glow-up and I marvel at the improvements there. But I do think happiness (and decreased mortality, increased lifespan) should be the ultimate end goal we are striving for for humanity and we seem to be failing, at least in the USA. The reasons are certainly multifaceted, but increased transistor density may be one of the reasons just like obesity, environmental toxins, etc. reply moh_maya 21 hours agorootparentAt some level, I think this is orthogonal to technological progress.One possible way of getting at this is to ask if people were more ‘happy’ when there wasn’t this level of tech available - and I’m not sure the answer is yes - I mean, there’s the mythos of ‘a simple life’ and ‘noble savages’, but from what I’ve read of life even a 100 years back - I would surmise folks were as unhappy &#x2F; miserable then too - but likely for different reasons.I think expecting just tech to make us happy is framing the wrong problem space. reply edgyquant 21 hours agorootparentMaybe happy isn’t the right word, but I think it’s pretty clear people were more content and felt a sense of purpose. Social media has made things worse, but it’s really the loss of community and religion that has led to the crisis of loneliness and depression among todays people. reply eropple 19 hours agorootparent> I think it’s pretty clear people were more content and felt a sense of purposeFrom what available data would you derive this and not immediately question selection bias? reply jwells89 14 hours agorootparentprevModern loneliness is a far more multifaceted issue than it’s often presented as.For instance I’m sure that a major factor is the need for people to move great distances away from family and the community they grew up in to be able to find education, living wages, and other forms of opportunity. That breaks existing connections and makes it harder to form new ones, but I never see that talked about. reply hibikir 11 hours agorootparentThose kinds of movements aren&#x27;t new though: Entire generations in many a country ended up emigrating across the sea, back when it was far slower and dangerous, to make their fortunes, as their home was too poor to handle more than one son. And today we have our home culture on our phones. I can watch TV from my home country, and my home team&#x27;s soccer matches live. I can video call whenever, for free.So maintain connection has never been easier, and migration is not any worse. I have no doubt there are far more things than social media making people more unhappy than historically, but having to move away from where we were born isn&#x27;t it. reply jwells89 2 hours agorootparentMoving itself is probably wouldn’t be so bad if it weren’t as frequent, for instance if maybe moving once after college would be it for most people. That’d still give people time to set down roots.Instead it’s often necessary to move repeatedly, for reasons varying from going to school to getting a job to finding housing with room for kids to just trying to keep rent from eating up the majority of one’s paycheck.In my case I’ve moved 9 times in the ~15 years since I turned 20 and it’s very likely I’ll be moving again in the future. It’s been very disruptive for maintaining connections, even with the power of modern communications at my disposal. I’ve more or less grown used to it and am kind of introverted anyway so I’m not depressed but I could see where others might not be so lucky. reply kaba0 8 hours agorootparentprevAs opposed to living with a spouse that abused them&#x2F;who they were not in love with, without a way to divorce. Or a huge percentage of people having to experience losing their children?It was simply not spoken about, people either poisoned their husband if it got that bad, or lived a sad life in silence. reply pests 19 hours agorootparentprev> but I think it’s pretty clear [...]Is it? Because that is not clear to me in the slightest. reply agumonkey 21 hours agorootparentprevbut existence influences choicesso technological progress in itself, regardless of its use, is a consideration reply Etheryte 22 hours agorootparentprevLeaving aside issues caused by social media etc, this always seems like an odd take to me. Why do you expect technology to make people happier? I mean, cars have gotten drastically better since their inception, but I don&#x27;t really expect my car to make me happy, much like I don&#x27;t expect the insulation of my house to make me happy, or the x-ray machine my doc uses to make my life a happy one. I think technological development is a completely separate axis to happiness, you can be technologically stagnant and happy or advancing and happy, you can be standing still and sad and moving forwards and sad. reply accrual 21 hours agorootparent> I don&#x27;t really expect my car to make me happy, much like I don&#x27;t expect the insulation of my house to make me happy, or the x-ray machine my doc uses to make my life a happy oneI think this is valid for most people. But as I&#x27;ve tried to integrate more gratitude into my life, I&#x27;ve noticed that it is possible to feel happiness from these things. I find it all too easy to disregard many of the things I have because they&#x27;ve always been there and available. But as soon as I don&#x27;t have some of my comforts (being outside in the cold, camping and batteries are dying, my car needs an unexpected repair, a pain in my arm that I can&#x27;t treat myself, etc.), it becomes easier to realize just now nice things really are. reply docfort 21 hours agorootparentprevBread is a great invention and a staple for many across the world. People have grown better at the process of developing grass into ever more productive wheat crops, transforming the inedible into something people find comfort in. But yes, there’s also an element of bread and circuses. Technology is not enough. It is not orthogonal to happiness, as you point out, but having the best bread doesn’t fundamentally make the course of humanity better. That begins and ends with what we individually and collectively choose: technology merely enhances our will. reply calvinmorrison 20 hours agorootparentSome technology does and some doesn&#x27;t.A washing machine is a fantastic piece of machinery you could even build on a small scale that saves hard laborA patent by Sony that forces the TV viewer to stand up and lift their hands and say \"McDonalds!\" to continue watching TV, is not reply willis936 22 hours agorootparentprevSecurity. Nature owes nothing to anything. Even the warmest bosom in the cosmos (Earth) is hostile, temperamental, and temporary. If the death of one individual is a tragedy then I don&#x27;t know the right word to describe the termination of life. reply justinator 22 hours agorootparentOr the false sense of security. reply willis936 21 hours agorootparentWhat is false about it?Are you arguing that we are less secure against nature while sitting in climate controlled buildings with food stores in them, and a global industrial complex raised to keep these trains running? reply justinator 20 hours agorootparentI have never lived in a world where there was not the existential threat of nuclear annihilation in every minute of every hour of every day of my life.But you&#x27;re right: I&#x27;m not going to get lost in my own city - or yours - because I have an iPhone in my pocket. I may never really learn my city and all its hidden little secrets you find only by wandering around, but I&#x27;ll be efficient getting to the bar in a \"climate controlled buildings\" where I&#x27;ll just stare at the iPhone some more and not really talk to anyone, as that&#x27;s what everyone is doing, too.\"It is a world suited for monomaniacs obsessed with the idea of progress - but a false progress, a progress which stinks. It is a world cluttered with useless objects which men and women, in order to be exploited and degraded, are taught to regard as useful ... Whatever does not lend itself to being bought or sold ... is debarred\" –Henry Miller, The Air-Conditioned Nightmare reply barsonme 18 hours agorootparentThis is incredibly myopic and ungrateful.Thanks to technology, we don’t have to try and have eight kids—losing half of them at a young age—just so that we don’t lose the farm and starve.Thanks to technology, millions of children are protected from diseases that years ago they would’ve died from.But sure, blame technology for your lack of self control causing you to stare at your phone at bars. reply justinator 16 hours agorootparentThanks to technology, I have no interest in ever having kids. reply wiseowise 19 hours agorootparentprev> but I&#x27;ll be efficient getting to the bar in a \"climate controlled buildings\" where I&#x27;ll just stare at the iPhone some more and not really talk to anyone, as that&#x27;s what everyone is doing, too.Sometimes I wonder if internet people are living in parallel universe. I see literally opposite, wherever I go, of what people like you describe. reply justinator 16 hours agorootparentWell you&#x27;re spending your Sunday staring at a screen on a venture capitalist&#x27;s message board, having contributed nine comments in the last 24 hours. Where are you right now, exactly? replyrobertlagrant 19 hours agorootparentprevHappiness is relative. Paris Hilton might feel distraught if her credit card is declined, if that&#x27;s the worst thing that&#x27;s ever happened to her.That&#x27;s why it&#x27;s important to understand context, both local and historical, to understand our place in the world and how we should feel about it. reply st-keller 22 hours agorootparentprevIs it really happyness we should strive for? I hear this over and over without anyone challenging this. Maybe a meaningful live is more fulfilling than a happy one? If i remember Nitzsche correctly: „No one strives for happiness - only the englishman does!“ reply jprete 21 hours agorootparentI don’t think tech comes out better on this scale than the happiness one. reply amelius 21 hours agorootparentprevPerhaps people are happy when they are using their tech, but in normal life they feel depressed. reply agumonkey 21 hours agorootparentprevI think there&#x27;s reverted or diminishing returns.. a 400MHz svga was generational, now a prosumer pocket supercalculator quickly goes meh, very odd to observe reply FredPret 20 hours agorootparentprevWhat does happiness have to do with material progress?There are happy monks and unhappy billionaires.Humanity must push forward on all fronts. reply bobsmooth 21 hours agorootparentprevIdk man, air conditioning makes me very happy. reply downWidOutaFite 21 hours agorootparentprevThe book Sapiens argues that tech has made us less happy ever since the invention of farming 10,000 years ago, the hunter gatherers were happier and healthier than the farm villagers. But since tech allows the population density to grow we get stuck in \"the luxury trap\", we can&#x27;t go backwards or a bunch of people will die. And the unhappier larger village is more powerful than the hunter gatherers so they have an evolutionary advantage.I think you could apply a similar theory to the modern capitalist world. reply gary_0 19 hours agorootparentOn the one hand, I love the idea of living a slower-paced, less competitive life. Most humans ending up crammed into urban rat-races is a horrible outcome. On the other hand, I like not dying in agony of easily treatable diseases. I like that the vast majority of people in developed countries have zero chance of dying of malnutrition.Having to choose between one or the other would suck. I wonder if we can have both? reply pests 19 hours agorootparentNothing is stopping you from living a slower-paced, less competitive life right now, today. While still getting all the benefits of society being advanced enough to not die in agony of easily treatable diseases. reply vachina 14 hours agorootparentI cannot sleep well at night knowing my neighbor just upgraded his Porsche. reply wiseowise 18 hours agorootparentprev> healthier than the farm villagers.I would like to see some data comparing modern, fit worker against average hunter gatherer. reply timmaxw 10 hours agoprevWhat are all those transistors doing?I&#x27;ve heard the cache is the biggest part. Per https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Apple_A17, the A17 has 72MB of cache. Cache is typically SRAM. Per https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Static_random-access_memory, a single bit of SRAM typically uses 6 transistors, but it could be anywhere from 4 to 10. So that&#x27;s between 2.3B and 5.7B transistors for the cache.That leaves about 1B transistors for each of the 12 cores (6 CPU + 6 GPU). The instruction set is a few hundred instructions. Surely it doesn&#x27;t take millions of transistors to implement each instruction. Other than the cache, which parts of the processor need millions of transistors? reply Shawnj2 7 hours agoparentApple has a bunch of device function hardware in the SOC like the SSD controller, the security chip, the GPU, the neural engine, etc. a decent amount of which probably uses hardware logic. reply sva_ 49 minutes agoprevSeems like these numbers are very close to that of the Snapdragon[0] which of course makes sense, given technological progress.0. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Transistor_count reply throwaway4good 21 hours agoprevIn terms of usefulness and end user experience, I find no difference between the iPhone X (A11, 4 billion transistors) and my current 14.Seems to me that all that extra processing power is still looking for a use case. reply oraetlabora 20 hours agoparentWell that says more about you than about the iPhone. One example: User experience regarding camera processing improved tremendously between X and 14. Only with the bigger processing power they could optimize images in a fraction of a second after taking them. The photonic engine as we have today, would not be deliver the same experience on an iPhone X. reply throwaway4good 20 hours agorootparentIt is still the same use case. I mentioned the iPhone X and not the earlier models because the X takes really good photos and videos. Sure the later models are better; but it is a bit like watching 4K instead of 1080p on the TV. I can tell the difference but 1080p is fine. reply Legend2440 20 hours agoparentprevMachine learning is that use case, it&#x27;ll eat up as much processing power as you can throw at it.LLMs on your phone are a few hardware generations out, but they are coming. reply throwaway4good 20 hours agorootparentML&#x2F;AI is not really a use case but rather a technology. The use cases may come a one point but right now, as far as I can see, they are missing. reply Shawnj2 7 hours agorootparentThe use case is Siri not being complete shit reply niek_pas 7 hours agorootparentAnd autocomplete! The new iOS 17 completion stuff is neat but nothing compared to what state-of-the-art LLMs can do today. reply jwells89 21 hours agoparentprevFor me there’s some benefit in little things like on-device OCR and image classification, which has been helpful for quickly surfacing particular photos in my library but yes the broad strokes have not changed much. reply throwaway4good 20 hours agorootparentI am wondering about this; I have noticed the OCR (that you can photo something and the copy the text as plain text). How compute sensitive is that? Is that not available on the X?It is a useful feature. In particular in Google translate (lens function) which I am pretty was also there on the X (perhaps requiring a trip to Google’s server). reply jwells89 20 hours agorootparentI’m not sure if it’s available on the X or not, but it would make a lot of sense if a certain level of hardware acceleration is required to do this OCR in the background with little to no negative impact on battery life. The X’s SoC can probably handle one-offs just fine, but it might not hold up as well to the OS churning through photos OCRing them in the background. replyuser_7832 20 hours agoparentprevI would say consider yourself lucky that you don’t use questionably-coded apps. I have an iPhone se 2020 (a generation newer) and some apps have a noticeable and annoying lag. A local transport app (9292) is a particularly notorious offender. reply hedgehog 20 hours agoparentprevFeature, not bug. There is a steady stream of features that build on the newer hardware, for example local dictation support starts with A12 devices. The big question is not whether a five year old phone supports the most current software (I would hope so), it&#x27;s whether today&#x27;s brand new phone will likewise support the updated software in five years, and what features can app developers rely on being present in five years. reply adrr 14 hours agoparentprevDeep Fusion is noticeable on photos if you view on a bigger screen or crop in. Cinematic mode is very well liked for making videos with background blur. reply paulddraper 20 hours agoparentprevPhoto&#x2F;video processing reply throwaway4good 20 hours agorootparentThe iPhone X had excellent camera and photo&#x2F;video processing. So much better than the earlier models; from the X up to today&#x27;s model it is much more marginal improvements. Really nothing I notice as a casual user. reply jeffbee 21 hours agoparentprevEven if you didn&#x27;t change anything about the software, the newer CPUs would still give you better energy efficiency and thereby longer battery life. reply throwaway4good 20 hours agorootparentI found the battery life to be the same. reply londons_explore 20 hours agorootparentprevBut the software devs will always more-than use up any extra efficiency, so it&#x27;ll still barely last a day, and will die early when it gets heavy use... reply jwells89 20 hours agorootparentThis varies a lot from app to app. It’s true that some are built in a way that puts no thought towards efficiency, but there are plenty that are built by devs who care.I like to keep around test devices that somewhat represent the average user’s device, and when it’s practical a low end device and test against those every so often just to make sure the app performs reasonably well.This has been in my experience more important for Android apps than for iOS apps, though, because the gulf in power between currently-sold devices in the Android world is vastly more large than in the iOS world. With few exceptions, I find that reasonably efficient apps tested and developed chiefly on newer iPhones work fine on older iPhones, but developing and testing an Android app only on flagships will make for a miserable experience for users of low end or older Android devices. reply jeffbee 20 hours agorootparentprevThe CPUs (and the software) are so efficient now that only the screen and the radios really consume energy. If you find yourself blaming high CPU usage for low battery life, it&#x27;s likely you are either incorrect, or the problem is just some bug in the application, nothing intended. reply londons_explore 20 hours agorootparentOkay - App devs find yet more reasons to ping their server every 5 mins and keep those radios active... reply starcraft2wol 20 hours agoparentprevThe features you use are not the features everyone else uses. reply patterns 6 hours agoprevRelated to this is I watched a fairly recent talk by David May who worked on the implemention of the transputer in the late 80s together with Tony Hoare:https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=lXUWmHgLiyUAt the end of the talk, he mentions the staggering complexity of the design and manufacturing of chips with billions of transistors. We have long reached a point where nobody fully understands how the chips work. IIRC, only two companies can do the manufacturing.That modern chips work at all almost seems like a miracle. Do we really need chips this complex? reply bottlepalm 12 hours agoprevIt’s pretty frustrating having a locked supercomputer in your pocket. I just want to play some emulated games, PC games from the 90s, host a desktop experience from my phone, etc.. reply tralarpa 9 hours agoparentCouldn&#x27;t you run Windows 95 or 98 on DOSBox on your phone just for fun? (never tried myself, maybe there is something better than DOSBox for that) reply bullen 10 hours agoprevYes, but how many are doing the majority of the work, die heatmaps needed. reply AnimalMuppet 4 hours agoprevIn 1985, I was in a lab at a mainframe manufacturer. It was a big room. I estimated that the room had one transistor for every man, woman, and child on the planet. (We didn&#x27;t think about trans-tolerant vocabulary in those days.)Now here that is on one chip. That change blows my mind. reply olliej 21 hours agoprevI vaguely recall (many years ago) some GPU (a Matrox one iirc) coming out and it being a huge deal because of how many transistors it had. I think it may have been an amazing 100 million. Times have changed :D reply jdjdjdhhd 21 hours agoparentComputers used to evolve much more quickly... Or at least the improvements made a much bigger difference reply dehrmann 19 hours agorootparentThe difference between 1990 and 2000 was astounding. 2000 and 2010 was ok. 2010 and 2020 was meh. Now, what computers did in the 90&#x27;s, cell networks did from 2005 to 2015. reply holoduke 19 hours agorootparentprevMoore is still alive. In 2030 we have an estimated one trillion transistors on a chip. We would need that for our ever increasing hunger for memory and processing power. 1TB model on your iphone 22 with 100 tokens per second. reply rzimmerman 12 hours agorootparentWell technically he died in March, but the law holds true. reply 1letterunixname 4 hours agoparentprevMHz->GHz wars. This caused Intel and AMD to chase hyperdeep pipelines with terrible stall characteristics and awful cycle efficiencies.You&#x27;re misremembering. Matrox cards were also terribly slow in DOS and anything adjacent to 3D. I own several models with SGRAM. Even GeForce 2 GTS: 25m transistors. G200: 10m. Voodoo2: 4m. reply jeffbee 21 hours agoparentprevSub-micron lithography was also an inflection point in the discourse, even if it was an irrelevant threshold to physicists.https:&#x2F;&#x2F;books.google.com&#x2F;ngrams&#x2F;graph?content=submicron+lith... reply test77777 21 hours agoprevIt’s funny, but you’d figure as sophisticated as the manufacturering standards are they could give an exact number. Or couldn’t they? reply kylec 20 hours agoparentI&#x27;m sure the chip designers at Apple know the exact number, but that doesn&#x27;t mean Apple&#x27;s going to share it reply gpm 18 hours agorootparentI wonder if they even do. I&#x27;m sure they could theoretically compute it... but is it something that is ever actually computed?It seems sort of like asking a programmer how many instructions there are in a binary we maintain. We could find out if we decided it mattered. reply sweetjuly 12 hours agorootparentIt&#x27;s a one liner in Virtuoso (hard IPs aside). I doubt anyone memorized the exact number but it&#x27;s definitely not some unknown or hard to figure out quantity. reply dmitrygr 18 hours agoparentprevIn theory, the answer is computable, but it probably doesn’t mean what you think it does.A gigantic chunk of those transistors are just SRAM memory cells for various caches. The number of transistors used to actually implement the logic of the SoC is significantly smaller. I would be surprised if it was more than 5%.The growth of this number between generations is also likely not very large. Most of the growth is also probably cache sizes. reply corethree 14 hours agoparentprevI don&#x27;t think it&#x27;s as exacting as you think. They build redundant functionality into the chips to meet QA specs. They expect parts of the chip to fail. The point is that it meets the overall specs. reply vinni2 19 hours agoprev [–] Doesn’t seem to follow Moore’s law. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article examines the trend of rising transistor count in Apple's iPhone processors over the years, emphasizing its growth rate and doubling time.",
      "It points out that despite the increasing complexity of the chips, the price of iPhones has relatively remained the same.",
      "The piece ends with a commentary on quantum computing, suggesting that it might not meet the lofty expectations set by marketers."
    ],
    "commentSummary": [
      "The discussion encompasses a wide range of topics including the intricacy of computer chips, the ongoing debate between prioritizing moon bases and Mars missions, and the crucial role of resource distribution in space exploration.",
      "It also explores the influence of technology on general happiness and compares the capabilities of various iPhone models.",
      "Additionally, the concept of immortality and the critical function of transistors in chip design are being highlighted."
    ],
    "points": 171,
    "commentCount": 184,
    "retryCount": 0,
    "time": 1698603013
  },
  {
    "id": 38063112,
    "title": "Alan Wake 2 is an unexpected visual marvel even on older GPUs",
    "originLink": "https://www.xfire.com/alan-wake-2-performing-well-low-end-pcs/",
    "originBody": "GAMING ENTERTAINMENT TABLETOP WORDLE ABOUT TRENDING STARFIELD MINECRAFT DIABLO 4 CALL OF DUTY WORDLE GTA 6 ABOUT XFIRE About Standards Press Kit Accessibility DMCA Privacy Terms Contact Trending: StarfieldMinecraftDiablo 4Call of DutyWordleGTA 6 October 27, 2023 October 27, 2023 Home > Gaming Alan Wake 2 Is An Unexpected Visual Marvel Even on Older GPUs According to a developer over at Remedy Entertainment, the studio wanted to \"underpromise\" and \"overdeliver\" with Alan Wake 2 on PC. By: Ray AmpoloquioPublished: October 27, 2023Updated: October 29, 2023 Alan Wake 2 proves that a game with steep requirements on the PC doesn't always have to face backlash for underdelivering. Snapshot Despite initial skepticism over hefty system requirements, Alan Wake 2 is proving to be a successful game across various PC configurations. However, the game remains a challenge to older GPUs and low-end hardware, with minor graphical bugs also present. Incoming post-launch updates are expected to further enhance performance. Alan Wake 2 has won over fans and critics despite the initial skepticism regarding its demanding system requirements, showcasing the kind of performance that defies expectations if not logic. When Remedy Entertainment announced the game's high system requirements, the internet couldn't help but let out a collective groan. The minimum specifications outlined were high, to say the least. It called for an Intel i5-7600K CPU and an RTX 2060 GPU with 16GB RAM for 1080p gameplay at 30 fps using the low graphics preset. Many had expressed their concerns about the requirements barring many from enjoying the title. However, this disappointment seems to have been based on a misunderstanding. Remedy's approach is to \"underpromise\" and \"overdeliver.\" Thomas Puha, Remedy's communications director, indicated via a tweet that the PC settings were on the safe side. This implies the studio wanted to ensure the game runs well on many systems, even those that barely meet the low-end specifications. While the company wanted to avoid overhyping and potentially disappointing players, it inadvertently generated some uncertainty about what to truly expect. This speculation was further fueled by a deleted tweet from a Remedy developer, which highlighted potential issues with certain older GPUs like the Nvidia GTX 10-series and AMD RX 5000-series. But contrary to these reservations, tests conducted by Digital Trends on various graphic cards showcased that the game offers commendable framerates, even on low-end GPUs. Additional evidence supporting the game's scalability is seen in how the RTX 3070 GPU performs in comparison to the PS5's settings. With the game set to the PlayStation 5's performance mode, the RTX 3070 outperformed it by close to 50% at 1440p FSR2 Balanced. Further affirming the adaptability of Alan Wake 2, the \"medium\" preset, which raised eyebrows, includes settings set to high and ultra. To many gamers' relief, the game looks splendid on systems that meet the minimum requirements. Past titles from the studio, such as Control and Quantum Break, already proved the studio's commitment to creating a visually appealing experience even at the lowest settings. This commitment to quality visuals remains evident in Alan Wake 2, a game made with next-gen titles like the PS5 and Xbox Series S/X in mind. It isn't farfetched to say that Alan Wake 2, even at its lowest settings, outshines the maximum setting of others. We've said it before and we'll say it again - Alan Wake 2 belongs in the GOTY conversation. This is a testament to Remedy's efforts to create a game that squeezes the most out of the available hardware and the wonders of the studio's in-house Northlight engine. However, it's essential to keep expectations in check. The game does push boundaries with its use of advanced features like mesh shaders, which makes a significant difference in performance. Comparatively newer cards like the RTX 2060 tend to outperform even powerful older GPUs like the GTX 1070 Ti and 1080 in Alan Wake 2 due to this. Not all experiences are made equal. The game remains demanding, and for PCs at the minimum requirement threshold, the visuals and performance can vary. Performance might not drastically improve by switching to DLSS Performance mode either. We get it Alan Wake, we're just as shocked as you after finding out how well Alan Wake 2 is running on relatively low-end PCs. The duality of experience in Alan Wake 2 is pronounced based on the user's hardware. The game operates stably across a wide spectrum of machines. However, it unquestionably taxes lower-end hardware, often relegating them to sub 60 fps performance. Conversely, for those equipped with top-tier gaming rigs, Alan Wake 2 stands as a visual marvel. Features like path tracing and DLSS 3.5 create an immersive and aesthetically striking gaming environment. While Alan Wake 2 stands out for its visual appeal, there does remain some minor hiccups, which include texture pop-in and some immersion-dampening bugs. It's hoped that Remedy will address these in subsequent updates. Those fortunate enough to possess high-end systems are in for a visual treat with Alan Wake 2. But, it doesn't hide its beauty behind a paywall - those with lower-end systems, provided it meets the bare system requirements, can still fully enjoy what Alan Wake 2 has to offer. PC gamers get the most out of Alan Wake 2 but consoles aren't too far behind due to the excellent optimization. The hopes are high that Alan Wake 2's optimization and performance will only continue to improve with the release of post-launch updates, including multiple expansions. RELATED TOPICS ALAN WAKE , ALAN WAKE 2 , CONTROL , EPIC GAMES STORE , NORTHLIGHT , PLAYSTATION 5 , QUANTUM BREAK , REMEDY ENTERTAINMENT , XBOX SERIES S , XBOX SERIES X 2 COMMENTS Your email address will not be published. Required fields are marked * Save my name, email, and website in this browser for the next time I comment. Cecitynik17 says: October 27, 2023 at 5:37 am Can confirm it is running just fine despite me not getting any upgrades for my PC. I didn't match the recommendations but it looks fine and there is no issues with crashing or bugging out for me. REPLY kevin says: October 27, 2023 at 1:09 pm what is your system running? i am still on the fence about buying it cause i have not updated my pc since like 2017 Posted by Ray Ampoloquio // Articles: 6190 Ray is a lifelong gamer with a nose for keeping up with the latest news in and out of the gaming industry. When he's not reading, writing, editing, and playing video games, he builds and repairs computers in his spare time. LOAD MORE ABOUT STANDARDS PRESS KIT ACCESSIBILITY DMCA PRIVACY TERMS CONTACT Contact Xfire: PO Box 67003, Mt Eden, Auckland 1349, NZ+1 (401) 526-2881info@xfire.com Copyright © 2023 Xfire.com. \"Xfire\" is a trademark of Enoki Limited.|||",
    "commentLink": "https://news.ycombinator.com/item?id=38063112",
    "commentBody": "Alan Wake 2 is an unexpected visual marvel even on older GPUsHacker NewspastloginAlan Wake 2 is an unexpected visual marvel even on older GPUs (xfire.com) 171 points by mdotk 19 hours ago| hidepastfavorite209 comments ernst_klim 6 hours ago> the minimum requirements for Alan Wake 2 are 1080p at 30FPS with low graphics, with an Intel i5-7600K CPU, RTX 2060 GPU, and 16GB RAMI think we have different definitions of \"older\" then. Does the game runs decently on something like rx580?Ok, the game runs 2 fps even in low res on rx580: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=bbM433WwY8U reply KronisLV 5 hours agoparentI actually rebuilt a computer with an RX580 instead of RX570 this year (as well as a Ryzen 7 1700), because everything else is way more expensive at local stores (vs 140 EUR for the 580), to the point where current gen hardware doesn&#x27;t feel worth it: I don&#x27;t catch myself wanting to play any of the modern games that look \"amazing\" (can&#x27;t tell characters apart from the scenery in some visually cluttered games), but rather ones that have consistent performance&#x2F;art style and don&#x27;t make the fans spin up much.That said, it&#x27;s kind of a shame that not many games let you actually pull back the graphical fidelity if you want to, despite the engines themselves often scaling back even to mobile devices. Maybe I&#x27;ll upgrade in 3-5 years when Wirth&#x27;s law will catch up way more. Then again, I can kind of understand companies wanting their games not to look \"badly\", no matter the graphics settings; it just means that indie games are for me, not AAA titles. reply lithos 19 minutes agorootparentPulling back graphical fidelity is a no go. Art team sizes can scale up so much faster than anything else, and AAA competes on how much it can spend&#x2F;scale up compared to other AAA games or other offerings (like independent&#x2F;small team games). reply doikor 4 hours agoparentprevThe game is basically unplayable if your GPU does not support Mesh Shaders which means AMD RX 6xxx &#x2F; NVidia RTX 2xxx series or newer (or 1650 which is in reality a Turing card so RTX 2xxx but very low end).The game will tell you that during startup. reply Retric 5 hours agoparentprevThe 6 year old rx580 has moved from older to just old at this point.As a midrange card from 3 years ago the RTX 2060 is getting long in the tooth, the 5 year old RTX 2070 is well above the minimum specs. Which seems perfectly reasonable for a new game. You don’t have to upgrade constantly, just put off some titles until you do. reply ernst_klim 5 hours agorootparent> Which seems perfectly reasonable for a new game.Right, I&#x27;m okay with that. But \"being a visual marvel even on PS5 era GPU\" sounds not at all the same as \"being a visual marvel even on older GPU\" to me. I do consider RTX20xx modern GPU, even if they are not the highest range for sure. reply Retric 4 hours agorootparentIt also runs and looks good on a GTX 1650 with low settings which was a 150$ card from 3 years ago. Which I think is more their point. reply Nullabillity 4 hours agorootparentprevMeaningful improvements stalled years ago, it&#x27;s not exactly the 90s anymore. Games from the mid-2010s still look perfectly fine. \"It&#x27;s old\" isn&#x27;t an excuse if there&#x27;s no real benefit to be had from upgrading. reply Retric 3 hours agorootparentComparing midrange settings on modern titles vs older titles at ultra high settings is hardly a fair comparison. You really should be comparing games of each generation on hardware of that generation or hardware that’s powerful enough to maximize frame rates and settings on both.2015’s Bloodborn looks quite dated when you use the kind of mid range settings most gamers would at the time. We can’t see what 2023 titles look like on 2026+ hardware, but I think people looking back will notice a bigger gap than it currently seems like. reply Nullabillity 2 hours agorootparentA big enough gap that you&#x27;d pay hundreds of dollars to cross it? reply Retric 2 hours agorootparentI’m in no hurry.Tossing a low end graphics card into a new PC unlocks significantly better back catalog every time with the added benefit of having the most patched version at discounted prices. replythoughtpalette 17 hours agoprevHave not heard the name xfire in a long long time. It was the initial (IIRC) defacto gaming messaging service back in the early 2000s. You could download skins (like Winamp) and it would track game time hours and show running game status.Looks like they pivoted into a obscure news site. Will always have fond memories. reply hipadev23 15 hours agoparentxfire, roger wilco, teamspeak, kali, ventrilo, mumble, icq. Relics of better times. reply rlex 13 hours agorootparentTeamspeak and mumble are still alive. Definitely not as popular as it used to be, but not dead for sure.Mumble is still big in eve online afaik, due to some funky auth processes with EVE account.Teamspeak forums are still pretty active too, and updates are still being released at a regular pace. I&#x27;m still keeping teamspeak as primary voice chat for my small gaming community and i hear from my users that TS3 voice quality is superior to discord. Plus if something happens with server, i can fix issues myself, since i host TS3 server on my hardware. Which is not the case with discord - if you have issues with discord server, your only choice is to wait. reply kukkamario 9 hours agorootparentI think Mumble&#x27;s popularity in EVE scene is due to its support for talking to multiple channels simultaneously and ability to do hierarchical voice channels. This is require for large scale battle coordination. Battle group commanders can talk to each other and then command their ships without risk that any \"lower level\" can talk on top of them and so on. reply nannal 6 hours agorootparentThis also allows for hilarity whispering to users in other channels who will respond to other users who couldn&#x27;t hear the initial message. reply Darfk 12 hours agorootparentprevI&#x27;ve been hosting a Teamspeak server for more than half my life, it&#x27;s acted as the communication hub for the majority of my time gaming.It&#x27;s fallen off in terms of features and UX. But I feel the warm and fuzzies knowing that my memes and conversation aren&#x27;t being fed into some neural network owned by microsoft.I also love that I can just change the voice codec to whatever I please without me or my users forking over a monthly fee. reply idkyall 4 hours agorootparentprevI believe teamspeak is also pretty popular in the milsim community due to its support for mods in games like Arma 3 reply causi 11 hours agorootparentprevMumble is popular because it&#x27;s free, lean on resources, low on latency, and has incredible audio quality. reply routerl 12 hours agorootparentprevGameSpy. The original video game match-maker. Also the original home of another relic, Penny Arcade. reply automatic6131 7 hours agorootparentprevA friend of mine self hosts a teamspeak server and REFUSES to use discord. Absolutely won&#x27;t have it. I play along, I respect the self hosting. And it works, we can chat and game. reply pawptart 16 hours agoparentprevAh I remember Xfire, pretty sure the biggest draw for me was the FPS counter it gave you.I doubt this is related to the current domain, though. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Xfire#Video_game_and_pop_cultu... reply matheusmoreira 13 hours agoparentprevI came here to post this. For a second I thought Xfire was alive once more.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;XfireI remember. reply Cthulhu_ 7 hours agorootparentI don&#x27;t think anyone from the original xfire is involved in this new xfire.com gaming news site, it looks like it&#x27;s now owned by a New Zealand company called Enoki Limited. reply andrewmcwatters 17 hours agoparentprevEntirely different Xfire, as far as I can tell. The two are unrelated. reply gardenhedge 16 hours agoparentprevI remembered that xfire too. So many applications back then had broad and seemingly global audiences but none seem to have stuck around. It seems like everything now is about getting funding and growth. Back then it just seemed like people making cool applications. reply JohnBerea 16 hours agoprevI&#x27;ve heard that Remedy has used[1] the D programming language in the past. Is it used on Alan Wake 2?1. https:&#x2F;&#x2F;ubm-twvideo01.s3.amazonaws.com&#x2F;o1&#x2F;vault&#x2F;gdceurope201... reply dom96 7 hours agoparentThe author of that left Remedy in 2017 so I wouldn’t be surprised if they replaced the D code by now. They have at Facebook while I was there. reply wilsonnb3 16 hours agoparentprevSeems likely, they are apparently still using the same engine they developed for Quantum Break (Northlight) reply spookie 16 hours agoparentprevMost certainly, yes. reply xnx 16 hours agoprevArt direction trumps graphic horsepower every time. Tears of the Kingdom is a great example of this. Alan Wake and Control are great combination of style and visual dazzle. reply automatic6131 7 hours agoparentBut Control is one of the most graphically intense games of the pre-Unreal 5 era. And it was the demo game for Nvidia&#x27;s latest graphics features - raytracing, DLSS.They didn&#x27;t neglect the style and art direction, but it absoutely required graphical horsepower. Maybe - though - you need top tier art direction to sell the sizzle of top shelf graphics. reply enneff 4 hours agorootparentIt didn’t require it. It just was one of the first major titles that supported full ray tracing. If you didn’t use that then it could run on much more modest systems and still looks great. reply gadders 4 hours agorootparentprevI managed to play Control and really enjoy it on an RX590 and an Intel i5 processor. reply corgihamlet 6 hours agorootparentprevI played Control on a PS4 Slim and it still looked phenomenal without all the raytracing stuff. reply tuyiown 5 hours agorootparentprevIt&#x27;s clearly not the best setup, but I&#x27;m currently playing Control on steam deck and I like very much what it manages to pull up from such light hardware. reply FractalHQ 15 hours agoparentprevVisually, I find TOTK is extremely underwhelming at 720p on the half-baked potato they call a switch. It’s like 15 years behind in every way. Nonetheless… to your point, the fact that it’s not worse is a miracle, and testament to the significance of well rounded art direction. reply lucasyvas 13 hours agorootparentSeeing it emulated shows you how amazing the art direction is - it scales extremely well and it&#x27;s indisputable how beautiful it looks.One the hugest misses of Nintendo to be honest. The art styles they develop are designed to scale down to their hardware, but they also scale way up and they never provide you an official way to take advantage, even on future hardware. The art team is being done a bit dirty in this respect. reply bzzzt 9 hours agorootparentSince there is no &#x27;future hardware&#x27; announced yet how can you state Nintendo will never provide you with an official way to take advantage of it? Seems Nintendo regularly re-releases games on new consoles, often with graphical improvements. FI, you can play Zelda Skyward Sword in HD on the Switch. reply asmor 9 hours agorootparentNever is a long time, but it&#x27;s not likely to be the next iteration (which was demoed in private at Gamescom). Mostly because the Switch graphics API is very hard coupled to the specific Tegra chips they use. reply bzzzt 6 hours agorootparentYou mean you don&#x27;t get an upgraded version for free when buying a new console. While I&#x27;d like that Nintendo is not big on &#x27;for free&#x27; ;) reply asmor 4 hours agorootparentNo, I mean that there wouldn&#x27;t be backwards compatibility, and Nintendo usually doesn&#x27;t re-release games immediately (with the notable exception of Mario Kart 8 and some simultaneous releases like Twilight Princess and Breath of the Wild). reply zirgs 4 hours agorootparentprevMost games are still stuck on their older consoles. Even well known games like Super Mario Galaxy 1&#x2F;2 and Xenoblade Chronicles X. They port only their most popular stuff. This is why piracy is necessary in the long term. Platform holders don&#x27;t care about game preservation. reply bzzzt 2 hours agorootparentSuper Mario Galaxy 1 was part of the &#x27;Mario 3D All stars&#x27; pack for Switch. It&#x27;s hard to take a case for illegal copying serious if you start with incorrect examples.I&#x27;m convinced that as long as people want those games they will be made available eventually, but probably not on the timeline you want. I think some kind of &#x27;continued availability&#x27; provision in copyright law would be more realistic than an appeal to resort to piracy. reply zirgs 2 hours agorootparent> Super Mario Galaxy 1 was part of the &#x27;Mario 3D All stars&#x27; pack for Switch.It was on sale for a limited time and got delisted apparently. Better than nothing, I guess - but if you missed it - then it might not even exist.My point still stands - pirated copies of those games are available 24&#x2F;7. As GabeN said - piracy is a service problem and Nintendo fails to provide a better service. reply bzzzt 2 hours agorootparentStill doesn&#x27;t give you any right. Lobby your politicians if you want better copyright laws. Being a pirate will only strengthen the case for those who believe strong copyright enforcement is necessary. replymaccard 6 hours agorootparentprev> it scales extremely well and it&#x27;s indisputable how beautiful it looks.I disagree - I had a google and found [0]. This is emulated, at 4k with raytracing. It&#x27;s a good decade behind what we&#x27;re seeing come out these days IMO. It&#x27;s dated, suffers from the hallmarks of not-quite-HDR (that lovely shiny surface that we all learned to love during the late 360&#x2F;PS3 days).[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rA7BAbMQU3c reply xnx 12 hours agorootparentprevTears of the Kingdom came so late in the lifecycle of the Switch and the next Zelda is so far off, that I wonder if Nintendo will do some type of light re-release on Switch 2 (or whatever it is called). I read that the did a closed-door demo of Tears of the Kingdom running on Switch 2 hardware. reply zirgs 4 hours agorootparentThey most likely will. The same happened with the previous zelda game. reply bzzzt 9 hours agorootparentprev> It’s like 15 years behind Did you expect 4090 performance on a system you can pick up for less than $300?Finished TOTK last week and had a lot of fun with it. I&#x27;m not blind and can clearly see jaggies, frame drops and resolution drops, but nowhere in the game did that really interfere with the core gameplay or make it impossible to enjoy it.While newer systems have more detail, most of the time it&#x27;s imperceptible since you don&#x27;t have time to look at the scenery anyway and when it matters (e.g. when rendering faces) it still doesn&#x27;t look realistic to me. Burning a kilowatt just to get a bit more detail or framerate for the same old gameplay just sounds insane to me. reply Aaargh20318 6 hours agorootparent> While newer systems have more detail, most of the time it&#x27;s imperceptible since you don&#x27;t have time to look at the scenery anyway and when it mattersBut higher resolutions never were about more details. At least not for TV&#x27;s (and thus consoles).At the end of the SD era (576p) I had a 28\" TV. At the end of the HD era (1080p) I had a 50\" TV. That&#x27;s a very similar pixel density. We&#x27;re now partway through the 4k era (2160p) and I currently have a 77\" TV. 8k TV are not here yet in any significant numbers; my last 4k TV will likely be around 100\". When we move to 8k it won&#x27;t be because we want a more detailed image, it&#x27;s because we want a wider field-of-view. We need more pixels so our screens can get larger. reply bzzzt 2 hours agorootparentI think pixel density is a strange metric for a screen you&#x27;re watching fully (instead of reading text from a part of the screen). If you want a bigger screen you can take the same content and upscale it (early digital cinema showed mainly 2K movies and that was about as sharp as film). These days lots of \"4K\" blu-ray discs just contain an upscaled 2K movie and most people don&#x27;t seem to bother.Also, I don&#x27;t think the market will ever get to 100\" TVs as a norm. You&#x27;re an outlier: most people have other priorities (don&#x27;t want TV to dominate the room, don&#x27;t have room, don&#x27;t want to pay for the extra energy required etc). reply tokamak-teapot 7 hours agorootparentprev“when rendering faces […] it still doesn’t look realistic to me”This gets to the heart of the matter for me. No matter how much hair sways like real hair, skin wrinkles like real skin, or eyes get a glassy look when emotion suggests they should, real humans can spot weirdness from miles away.That person you see walking towards you, barely visible in the dark and without your glasses on? The tiniest stiffness in the way they made that last step, the way their elbow shifted, have raised your awareness and you’re now considering them a threat, and will watch them carefully and keep your distance.Or the way they get up from the table they are sitting at clues you into the fact they have a pulled muscle in their lower back or upper right leg and you instinctively watch a little closer in case they fall and you can help somehow.The scowl and glare of a woman who is playfully admonishing her kids and encouraging them to play along.While we asymptotically approach ‘perfect’ rendering and simulation, we are still just alongside it, unable to climb out of the uncanny valley.A game can look beautiful with some creativity and care in its visuals, and it seems like nearly everyone who’s played Tears of the Kingdom or Breath of the Wild is enamoured with their beauty.I often play just to travel around and enjoy the beautiful landscapes. Even The Depths is enchantingly beautiful, reminding me of what you can see while scuba diving. I wonder if this was intentional.So yes, while I do appreciate a super high resolution game with rock solid megahertz framerates and physically correct lighting, these are additive in their enhancement, not multiplicative.Spending effort on these that could have been spread more evenly across art direction, gameplay, music and other aspects serves only NVidia, AMD and those who enjoy ‘high fidelity’ visuals or the game (in its own right) of chasing hardware that is capable of running these games.To me, there is a parallel with the &#x27;audiophile&#x27;, who lusts after higher and higher &#x27;fidelity&#x27; and perpetually upgrades their equipment but only ever listens to a playlist titled \"Songs to test headphones with\". Spine-tingling cymbal wash and awe-inducing bass sweeps are amazing.Others are here for the remaining 90% of the music, and are happy to listen on their phones, and don’t even notice when a live performance isn’t a clone of album tracks.I personally fall into both camps. I love to put on some headphones and listen to ‘audiophile’ music, but that’s a hour or two every few months. Most of the time I’m having a blast with medium fidelity, ultra fun music … and gameplay. reply bzzzt 6 hours agorootparent> I often play just to travel around and enjoy the beautiful landscapes. Even The Depths is enchantingly beautiful, reminding me of what you can see while scuba diving. I wonder if this was intentional.You just made me wish for a Wind Waker like game with a full underwater world ;) reply Cloudef 6 hours agorootparentprevAll that yet modern games cant render mirrors reply zirgs 4 hours agorootparentThey can, but it&#x27;s really expensive so most devs avoid it. Currently the performance hit is not worth it.Games could render realtime reflections using various tricks even 20 years ago.I remember that in Hitman Blood money enemies could spot you in a mirror and mirrors were functional in that game. It&#x27;s a game from 2006 and mirrors were placed only in small rooms. reply asutekku 5 hours agorootparentprevModern games have been rendering mirrors with ray tracing for couple of years already reply kyleyeats 8 hours agorootparentprevLots of people forget that Breath of the Wild was developed for the Wii U. The engine for TOTK is actually two generations old. reply andrepd 9 hours agorootparentprevExactly. It runs on a \"potato\" yet it still looks better than many AAA games and their generic bland art direction and janky animations. reply pb7 8 hours agorootparentIt’s also a AAA game, it’s just running on a potato and looks the part. It would be a better game if it was developed for hardware from this decade. reply nullify88 10 hours agoparentprevControls art direction is beautiful and it&#x27;s atmosphere really unsettling. It&#x27;s a unique game. I&#x27;m in love with mostly every game Remedy develops. reply MrDresden 6 hours agoprevAlan Wake sits very comfortably at the top of my personal chart as the best game experience I have ever had.I truly look forward to a year or so from now when the game finally makes it&#x27;s way to Steam, fully patched and ready to go for Linux play. Until then, I&#x27;m content with playing the vast catalogue of non-exclusive games available. reply henriquecm8 4 hours agoparentIt&#x27;s unlikely that it will ever come to steam, it was funded and published by Epic, it&#x27;s basically a second party game. I don&#x27;t see it coming to steam unless egs closes. Remedy made a deal with Epic to publish 3 games, some people say Alan Wake Remastered was the first, and Alan Wake 2 is the second. reply doikor 4 hours agorootparentIt’s not “some people say”. It’s their yearly&#x2F;quarterly reports saying that. (Also it’s two games)https:&#x2F;&#x2F;investors.remedygames.com&#x2F;app&#x2F;uploads&#x2F;2023&#x2F;03&#x2F;remedy...They also have 2 more games with 505, max payne remakes with Rockstar and one game with Tencent. reply geku3 5 hours agoparentprevThis game is published by Epic, it likely won&#x27;t come to Steam for a very long time. reply MrDresden 5 hours agorootparentI&#x27;ll gladly wait. Don&#x27;t see the rush. reply zirgs 4 hours agorootparentIt was funded by Epic - so it&#x27;s unlikely to be a timed exclusive. reply Nullabillity 4 hours agorootparentI guess they&#x27;d rather have people pirate it then. reply zirgs 2 hours agorootparentGame not being available on steam is a pretty weak excuse for piracy. Epic simply doesn&#x27;t want to give 30% to a competing store. reply altairTF 5 hours agorootparentprevInteresting, it may never go to steam reply TylerLives 4 hours agorootparentI&#x27;ll wait reply altairTF 11 minutes agorootparentYour determination is unmatchable reply ShamelessC 5 hours agorootparentprevUghhhh, I won’t shoot the messenger but that is so annoying to hear. reply petermcneeley 13 hours agoprev\"visual marvel\" and no gameplay images? No frame breakdowns? No even comparisons of high&#x2F;low settings at fps and rigs.Is this an Ad? reply fancy_pantser 10 hours agoparentI wanted to see some of it with the maximum settings and found this video channel where they just walk around (no talking or fighting) without abrupt movements. The game looks fine, but the ground litter looks very flat when lit by the flashlight. The light also seems to illuminate through water to hit e.g. the bottom of a stream, which they show in the video a bit, but there&#x27;s no reflection of the light off the water&#x27;s surface in realtime. I also noticed the tree geometry regularly changing complexity at about 3-4 meters away in an abrupt way. After playing 2077 with the new ray reconstruction enabled, this is a great-looking game but not pushing the envelope for realism.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=E_dXLgmdqeM reply markedathome 2 hours agorootparentStrangely, Digital Foundry don&#x27;t [yet] have a video out with the max settings that a PC can provide.They have a PS5 review[1], and a &#x27;this is how best to get console quality settings on a PC&#x27; comparison with a PS5 on performance settings.[2]1. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=JawxvOF__4Q 2. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=QrXoDon6fXs reply the-dude 5 hours agorootparentprevNot a gamer, so pardon my ignorance.Does it always rain in the game? How depressing. reply criddell 4 hours agorootparentWell, it is set in Washington... reply Elhana 10 hours agoparentprevand \"older GPUs\" are GeForce RTX 2060 &#x2F; Radeon RX 6600 ? reply pb7 8 hours agorootparentThe lowest end of the offerings from 2 generations ago? Yeah. reply blashyrk 16 hours agoprevYeah, right.I can run basically any game at 1080p with at least 60fps with my 1080ti, except this game.What they did with the mesh shaders is basically the equivalent of releasing a raytracing-only game.So now I have to wait until GPUs become affordable again, which might not happen for a couple of years still. Shame, as this was the game I was the most excited about this entire year.And no, spending money to get the same (or worse) GPU which supports mesh shaders wouldn&#x27;t be worth it. reply spookie 16 hours agoparentThat GPU came out almost 7 years ago, it&#x27;s only natural its lack of modern features starts being apparent. I still remember not being able to run new games once Shader Model 3 became standard, it&#x27;s sad but what can you do? reply zirgs 4 hours agorootparentThe problem is that there are no good upgrade paths for 1080ti. It&#x27;s roughly as powerful as 3060ti. But there&#x27;s no point to upgrade to a card with a similar performance and less VRAM. So the only upgrade path to feel a noticeable performance gain is to buy RTX 3090 or RTX 4090 and those are very expensive. reply SkeuomorphicBee 2 hours agorootparentprevOne small caveat: the \"came out\" date is irrelevant, the relevant date is the date an alternative appeared. In this case the real info is the replacement came out ~5 years ago (or ~4 depending on the definition).And the situation is worse for AMD users, only 3 years since a compatible board came out. reply pinum 15 hours agoparentprevYour GPU is 6 years, 7 months old. As an analogy, consider someone in 2007 objecting that their 2001 GeForce3 Ti500 can&#x27;t run Crysis&#x2F;Mass Effect&#x2F;etc. The PS4 generation really messed with the usual conventions and expectations of PC upgrade cycles.(I appreciate that GPU prices have creeped up and up over time, though.) reply Arainach 14 hours agorootparentFor most people, Moore&#x27;s law died around 2013 with Haswell or even Ivy Bridge. In 2007, 2001 was forever ago (In particular, 2001-07 involved the jump between the space heater Pentium 4 and proper 64-bit multicore chips such as the Athlon 64 X2 and Intel Core 2 Duo&#x2F;Quad as well as the growth of dedicated gaming video cards - even the GeForce3 was uncommon, while by 2007 everyone had a video card)In 2007, CPUs and GPUs were still getting twice as fast (perceptibly) each year. That hasn&#x27;t been true for a while. Other than lacking a TPM, my i7-3770k machine and GTX 970 runs as fast in desktop use as my i9-9900k+2070 Super, and that machine (which dates to....2019, I think?) still plays new game releases at 1440p just fine.Recall that most games are designed for the XBox Series X (released 2020) and PS5 (released 2020) and still target that caliber of GPU performance. reply ThatPlayer 7 hours agorootparentThe mesh shader issue isn&#x27;t a Moore&#x27;s law raw performance issue. It&#x27;s an issue with the hardware not supporting specific graphic pipelines. The software fallback is slower than dedicated hardware. Like how AES-NI on a CPU is many times faster at doing AES. That&#x27;s why the parent comment likens it to newer GPUs&#x27; hardware raytracing features.\"Caliber of GPU\" is not just performance, but also features. The Xbox Series supports mesh shader (and PS5 with their equivalent). Nvidia 10-series and AMD RDNA1 GPUs and older do not. This youtube video compared two GPUs released around the same time, one with less performance but mesh shader support and one with more performance but no mesh shader support: https:&#x2F;&#x2F;youtu.be&#x2F;UiduP4Y7RSw reply wincy 12 hours agorootparentprevI went on a quest last year to reduce latency on my desktop and code using an 8khz polling speed mouse, a pro gamer keyboard, and two 1440p 165hz monitors. I read a fascinating article here on Hacker News about it (in November 2022, I’d have to look up the article) Anyway, it feels great. If you’re wanting things to feel faster consider these upgrades! I highly recommend them. For the first few weeks it’d feel like I had started typing before I started typing which was a weird experience. I’d just become so used to a ton of latency. reply paulmd 10 hours agorootparentprev> Recall that most games are designed for the XBox Series X (released 2020) and PS5 (released 2020) and still target that caliber of GPU performance.This cycle is extremely unusual though, the length of the cross-gen period has been dramatically extended by both covid shortages and also disruptions to the game development pipeline from covid and the Russian war among other things.Once developers are no longer forced to validate for literal base-tier ps4 hardware from 2012 (8 jaguar netbook cores and an underclocked 7850, oh my), gtx 970 tier hardware is going to immediately drop off a cliff. And frankly even pascal is not going to age well. There were lots of improvements and features in pascal that got downplayed by reviewers from 2018-2022 and now they are really starting to come into play (and would have done so earlier had it not been for the pandemic).You can hardly say we’ve even seen next-gen games at this point, tbh. Even CP2077 is a cross-gen title - which in many ways functionally means “last-gen”. reply yieldcrv 5 hours agorootparentprevThe lesson here is that you need to bite the bullet and get top of the line at least onceBecause then you always have some capital within the hardware to upgrade again without breaking the bankBut if you upgrade mid life cycle or even worse: to a mid range card that’s already mid life cycle, then you’re always getting less life span and having to do full upgrades again reply solardev 1 hour agoparentprevHave you considered geforce now? A lot more affordable than a GPU. You get a 4080 for $20 a month, no commitment. reply UtopiaPunk 12 hours agoparentprevThere&#x27;s lots and lots of other great games to play, so don&#x27;t stress if you miss one. reply ShamelessC 5 hours agoparentprev> I can run basically any game at 1080p with at least 60fps with my 1080tiNo, you can’t. reply wincy 12 hours agoparentprevYou can buy an RTX 3080 for $400 or a 3090 for $650-700 right now. Those can both run the game fine. I got mine from some gamer kid in a beat up van at the gas station and it’s working great. reply lm28469 6 hours agorootparent> You can buy an RTX 3080 for $400 or a 3090 for $650-700 right nowNew or with 10 000+ hours of 100% load mining coins ? reply Forbo 3 hours agorootparentStable load is better for GPU longevity than cycling between hot and cold repeatedly. Also, lots of mining farms will undervolt their cards for more efficiency. Getting a used mining card is probably better than getting one from a gamer. reply lm28469 2 hours agorootparent> Stable load is better for GPU longevity than cycling between hot and cold repeatedly.Same for cars but I&#x27;ll buy a 30k km car over a 300k km car every day replywincy 16 hours agoprevI spent a little bit fiddling with the graphics settings for 2880x1600 last night, and settled on 30FPS at max settings and 1280x800 internal rendering, which looks pretty good. This is with a 3080 and a 7800X3D and 64GB of RAM, but wow the game looks really really nice. It’s 30FPS in the forest and 60FPS in town, which is interesting. All that foliage takes a lot, apparently.I had to take the settings way way down to get to 60FPS and I don’t know as I get older, I prefer things to look nice and smudged vs high frame rates and crummy.I’m just enjoying the heck out of walking around the forest and staring at necrotizing obese ray traced wieners. The details are astounding!Also, if you’re looking to upgrade your GPU, it’s a great time. I bought this one off some kid for $400 and 3090s are selling for $650. reply Banditoz 13 hours agoparentThe fact that running a game at almost 720p and hitting 30fps in demanding areas with high-end last-gen hardware is slightly concerning. Are developers not optimizing their games anymore? reply doikor 9 hours agorootparentIt is actually quite well optimised. It is one of the best looking video games ever made.Maxing everything means enabling path tracing which is a massive performance hit. Basically to do that you need a 4090 or a cheaper 40xx card and use frame generation.The “PS5&#x2F;Series X equivalent” settings are a mixture of low&#x2F;medium without any hardware ray tracing (I think it still does some software ray tracing similar to UE5 Lumen) using FSR2 with post processing effects done before the upscaling (low resolution). On PC if you use high post processing effects they happen after the upscaling and thus at much higher resolution (this is the “heaviest” option outside of the ray tracing stuff)Remedy hasn’t made a game that targets “native” resolution since Max Payne 2. Basically starting with the first Alan Wake game they have used lower internal resolutions and used the budget for other graphical effects. (On PC you still always had the option to use native resolution) reply wincy 12 hours agorootparentprevI think it’s just the reality of how many bells and whistles there are, especially with ray tracing. It looks really good, it doesn’t seem unoptimized (generally you’d expect weird hitches in stuff like that, I definitely noticed that in Baldur’s Gate 3 with lighting effects) there’s a sumptuousness and wetness and warmth in all the right places to the environments that really feel like you’re walking along a path at sunset in an old growth forest.The feature sets involving AI in the newest cards are really the key, I think, and why my last gen premium card is lagging behind. DLSS 2.0 on the 4080 and 4090 especially are just revolutionary in how they work. The last gen cards just can’t quite keep up. It’s like magic, making frames out of seemingly thin air.In my opinion this is a good problem to have! I’d rather have games pushing the state of the art than sticking to what the PS5 and Xbox whatever it’s called these days can do. reply ThatPlayer 11 hours agorootparentprevThe comment mentions they&#x27;re running at max settings. So even current-gen high-end hardware might not be the target. As long as the lower settings scale down fine to lower end hardware, who cares about max settings? That&#x27;s what the original article is about.Max settings also means enabled path tracing, which current-gen Nvidia&#x27;s 4000 series have better hardware acceleration for. So you can&#x27;t really compare performance to previous hardware which don&#x27;t have that hardware acceleration. No amount of optimization is going to fix that, and it should probably be turned off if you&#x27;re not on a 4000 series or newer card.In that same way, AMD&#x27;s path tracing hardware acceleration falls behind Nvidia&#x27;s. A current-gen high-end AMD RX 7900 XTX does worse than Nvidia&#x27;s last-gen not as high-end 3070 in Cyberpunk 2077&#x27;s path tracing update. https:&#x2F;&#x2F;youtu.be&#x2F;cSq2WoARtyM?t=503 reply supertrope 12 hours agorootparentprevVideo games are slapped together because deadlines must be hit. The most popular titles can cost >$100 million to produce so there is huge pressure to get it out the door. Customers expect cutting edge graphics which contributes to production budget bloat (so does marketing). A lot of PC games are console first and ported over. The new console generation (PS5) means more VRAM is available so games expand to fill it. Just like how Blu-ray was a large increase over DVD capacity. Later 50GB was a ceiling commonly bumped up against. Once 50GB was exceeded why not have a 100GB install size since you’ve blown past the Blu-ray limit anyway? reply zirgs 4 hours agorootparentThis is not true about AW2 though - it&#x27;s pretty clear that it&#x27;s a PC-first title. Consoles run the game at medium-low settings. Max settings are for future PCs. Even the 4090 can&#x27;t run it @ native 4k 60 fps with everything maxed out. reply Geee 13 hours agoparentprevI&#x27;ve been playing with a 3090. I play in 1440p 21:9 ultrawide. So far it seems that medium settings with DLSS 720p and raytracing on medium is the most solid one. On high settings it&#x27;s mostly fine, but in the forest it gets slower, and sometimes very slow (like 5-10 fps) when there&#x27;s additional effects like smoke or something. reply marcus_holmes 14 hours agoprevI&#x27;m a PC gamer. I couldn&#x27;t give a toss what frame rate I&#x27;m getting, or what the graphics benchmark is.I get the fascination of tinkering with the build, and optimising stuff, and so on. But eventually it&#x27;s got to come down to actually playing the game, right? This article is a classic case in point: not once, in the entire article, does it talk about the actual game. It only talks about graphics performance. Who buys games just to run them at 60fps at 4K? Surely at some point you&#x27;ve got to actually, y&#x27;know, play the game and enjoy that game? reply poink 13 hours agoparentThe overwhelming majority of game reviews address the content of the games, but there are reviewers that concentrate specifically on graphics performance because the difference between a low end and high end gaming PC can easily be $3k+, and half that is in the GPU nowadays. People use articles like this to decide what to buy to get the optimal experience in games they want to play, not which games they want to play in the first place.Alan Wake 2 merits specific consideration on this front because its system requirements seemed to suggest it wouldn&#x27;t even be playable on a lot of popular configurations. reply lucasyvas 13 hours agoparentprevI think you are right, but what you are ragging on is the meta of PC gaming. It&#x27;s like an old muscle car nut trying to optimize the top speed of their car, acceleration, etc. They enjoy driving it, but the tweaking is an additive experience. It may eventually become the experience altogether.If this isn&#x27;t you, consoles or mid-tier PCs are a great fit.I would say I straddle the two - if I buy great hardware, I expect to capitalize on it. But I don&#x27;t overclock shit or care exactly what speed my RAM is, nor do I need the fastest SSD or top tier everything. reply apecat 2 hours agorootparentDue to how my head is wired, I&#x27;ve discovered that I enjoy gaming a lot more after I switched to console two years ago: all settings are curated (for better and worse). I&#x27;m not even sure why I didn&#x27;t switch earlier.The only reasons I can think of are fear of the controller and slow load times due to mechanical HDD on last-gen systems.I don&#x27;t spend time away from gameplay trying to get optimal setting. I&#x27;m just the type of neurotic that I will do that stuff even though I absolutely don&#x27;t enjoy it.I can jump directly into gaming without anxiety over how my hardware is falling behind. With my PS5 being in my living room, gaming is also time away from my desk, which I, much like doing anything on a Windows PC, associate with my IT jobby job.A console is an appliance. It&#x27;s like a toaster or dishwasher, except it lets me play games without any work.With PS5, I also don&#x27;t have to worry about weird glitches with audio through HDMI in my living room setup, since that&#x27;s how I prefer to play. And PS5 now also renders Dolby Atmos, without any glitches.These are of course all me-problems, but I thought I&#x27;d mention it here, since gaming is too much fun to be confined to the tuning-happy garage mindset of PC. reply marcus_holmes 13 hours agorootparentprevyeah, it feels like a parallel hobby - it&#x27;s not actually gaming, because the game doesn&#x27;t matter, it&#x27;s optimising the hardware. The game is just the benchmarking tool for the graphics setup. reply simondotau 13 hours agoparentprevOffering a good faith alternative explanation, I would hope that the main reason many people obsess over benchmarks and performance metrics is because GPUs are damn expensive — buyers would want to know that the money they&#x27;re spending has tangible benefits. I&#x27;d like to think that once someone actually loads a game in order to play it, they&#x27;ll actually focus on the game.(As a parallel example, I love the idea of seeing films in 3D, 4K, HDR etc, but I rarely notice the difference within ten minutes of the film starting. There&#x27;s a reason why digital cinema got along fine at 2K for so long: extra detail really, really, really doesn&#x27;t matter.) reply n1b0m 13 hours agoparentprevI think you’d care if you were getting less than 30 fps and the game is virtually unplayable. reply n8cpdx 13 hours agorootparentSome say that less than 120fps is literally unplayable.I remember when CoD 4 being 60fps on Xbox 360 was a big deal.Virtually unplayable is in the eye of the beholder. reply dawnerd 11 hours agorootparentThose people are ridiculous. You can have high fps but inconsistent frame timing which makes games feel terrible. I think that was the bigger issue with cod. reply marcus_holmes 13 hours agorootparentprevI started PC gaming back in the 90&#x27;s.I don’t understand how a big game like this could have you just walking around doing nearly nothing for several hours straightAlan Wake 1 had a lengthy walking around&#x2F;watching cutscenes first part, so this sounds good to me: I like walking simulators (e.g Gone Home, Firewatch). Not every game has to be about blowing things up to smithereens or solving over-rehashed puzzles.The most recent example for me was Scorn: for me it was fantastic until I got to the area where you get a thinly veiled shotgun thing with mandatory combat + solve those rotating puzzles over and over whose essential logic has been seen a thousand times (in stark with the first big room environmental puzzle whose logic wasn&#x27;t that complex but was immersive), at which point I dropped the game as it was just killing the mood for me. reply ljm 4 hours agorootparentprevThe first game was more action oriented while this one is more like survival horror. I think it&#x27;s a refreshing change from pushing back the hordes as it&#x27;s much more of a tense and atmospheric slow-burn.Personally I&#x27;m hugely fond of it but I absolutely love the weirdness of Remedy&#x27;s extended universe, and for me it&#x27;s less about the gameplay but the story and atmosphere. So, my bias couldn&#x27;t be more apparent but I think there&#x27;s a lot more to it than what you&#x27;re dismissing it for. reply sillysaurusx 16 hours agorootparentprevThank you! Exactly what I was hoping to hear, unless it was actually good. Thanks for saving us from disappointment. reply jahsome 15 hours agorootparentThe first couple hours are intentionally slow. It&#x27;s not \"doing nothing\" it&#x27;s building suspense and laying out the foundation for the story.I don&#x27;t understand why people need to hear whether games are \"worth it\" based on someone else&#x27;s opinion. reply chungy 14 hours agorootparentIt helps to make a decision about whether it&#x27;s worth buying. Of course opinions can vary wildly, which is why looking up multiple reviews and&#x2F;or videos might be a wise idea.As an example, I&#x27;ve struggled to get people to fully play one of my favorite platformers of all time, VVVVVV. And then the much vaunted Ocarina of Time bores me to tears and I can&#x27;t push myself to get through it. reply Vetch 12 hours agorootparentIt makes sense to make a purchase decision based on others opinions yes, but what I don&#x27;t understand is why sillysaurusx seems to have already decided based on one response, and without knowing how (dis)similar Drybones&#x27;s taste in games.Alan Wake is a great game but I consider Alan Wake 2 to be much better, but I also enjoyed Control more than Alan Wake and enjoyed all aspects of Quantum Break. Where you fall on those games will probably most affect how much you enjoy Remedy&#x27;s latest.How much you enjoy unorthodox multimedia narrative story telling, psychological and cosmic horror meta-narrative weirdness, how much you accept being confused from design jankiness in certain spots as part of the experience, stuff like that will decide how much you enjoy this game. Personally, its only real flaw is mystery solving can be a little too handholdy and bruteforce-able. reply ShamelessC 14 hours agorootparentprev> As an example, I&#x27;ve struggled to get people to fully play one of my favorite platformers of all time, VVVVVV. And then the much vaunted Ocarina of Time bores me to tears and I can&#x27;t push myself to get through it.VVVVV appears to be a fairly low budget indie game with graphics that haven&#x27;t aged very well compared to modern indie games. I&#x27;m sure it was fun and it seems it was very well received when it came out.Ocarina of Time was a AAA game that came out during the first real mainstream transition toward 3D graphics. It effectively kickstarted the RPG and free-roam genres while still presenting a typically polished Zelda experience. It was fun when I played it (when it came out) but it has not aged very well compared to modern games. If you didn&#x27;t play it when it came out you&#x27;re probably not going to enjoy it - but at least you can respect its impact on gaming.Anyway the point is that games don&#x27;t age well and similar to music, people don&#x27;t tend to like other people&#x27;s favorite games unless they&#x27;re highly aligned in the first place.Reviews are pretty pointless as well but in general you can tell in the first 2 hours of a game if you&#x27;re going to like it or not, at which point you can choose to return it or not return it. reply chungy 12 hours agorootparentVVVVVV holds up perfectly. Good level design, good physics, good gimmick at the core of its game play. The graphics were designed to be evocative of the Commodore 64 era. It&#x27;s hard for that to really age when that was the intent in the first place.Ocarina of Time bored me in 1998. It still does. It hasn&#x27;t \"aged poorly\" in my view; it was never good in the first place. (Yes, it&#x27;s my opinion. :P) reply lloeki 8 hours agorootparent> Ocarina of Time bored me in 1998. It still doesOh my so I am not alone. I always felt like it was terrible, especially compared to the GB and SNES ones, and whatever games were out on PC&#x2F;PS&#x2F;DC around that time (not so much about the graphics but the game&#x27;s pacing, controls, and mechanics). I feel the same about Golden Eye.I feel like these games got a lot of success not because of what they are but because it exposed a chunk of players (Nintendo die-hards) to a type of game that wasn&#x27;t previously available to them on their favourite platform. reply Reticularas 14 hours agorootparentprevVVVVV was released during the initial wave of indie game popularity. It may not be the most influential of that group- but it&#x27;s more relevant than it probably seems from a present day standpoint reply ShamelessC 13 hours agorootparentOkay I’ll take your word for it. Like I said it appears to have been well received. Gameplay looks interesting. reply lloeki 8 hours agorootparentVVVVVV has extremely simple and polished gameplay, what makes it interesting is how the same gameplay mechanic is constantly challenged and reinvented through very clever level design. It looks like metroidvania as far as exploration is concerned but is the complete opposite in general progress, as in the only thing that locks you out from an area is pure player skill, reinvesting what you learned to go further: \"oh, you can do this\" instead of \"oh, I unlocked this and so can now access that\".It was an instant classic for me. replywredue 14 hours agorootparentprevRandom internet people is, hilariously all you can even trust now.Reviewers have been pretty questionable of late with a few obvious gaffes, but Starfield was the last straw for me. A wall on 10s for reviews, but the game is a clear 6, maybe 7 on a good day. reply izacus 8 hours agorootparent> Reviewers have been pretty questionable of late with a few obvious gaffes, but Starfield was the last straw for me. A wall on 10s for reviews, but the game is a clear 6, maybe 7 on a good day.Pretty much all reviewers I follow were giving Starfield reviews explicitly mentioning how boring it is how it feels obsolete for 2023.So which \"reviewers\" are you quoting and why aren&#x27;t you reading the ones that match your taste in games?And how the heck are random people in the internet more trustable to you, there&#x27;s thousands of people that lost their shit because Starfield didn&#x27;t get perfect 10&#x2F;10 scores. reply pbj1968 14 hours agorootparentprevStarfield looked incredibly boring from the trailers and preview videos. I had to shake my head and roll my eyes at the review scores. I’ll stick to Halo if I want to constantly jump and shoot aliens. reply cassianoleal 7 hours agorootparentI must be about 50h into Starfield and I&#x27;m on NG+1.I found it extremely boring at first. I hugely disliked the potato graphics, the clunky animations and the rubbery faces.Now I find I pick it up to kill time and have fun while doing so. The story is not incredibly deep but it&#x27;s interesting enough. The gameplay is not 2023 AAA quality but it&#x27;s decent enough. The endless interruptions with fast travel and loading (even for crossing doors and riding lifts! :-o ) are pretty low effort but they don&#x27;t bother enough.Pretty much all aspects of the game are good enough but never great. I&#x27;d probably give it a 6&#x2F;10 but with a caveat that it&#x27;s something I keep going back to.This is the first time I&#x27;m actually playing a Bethesda game by the way. I tried Skyrim a few times and always found it extremely boring and clunky. I tried Fallout 76 and it was the same. This is the 3rd of their games I&#x27;m trying to play and so far it&#x27;s been going ... quite ok! And I&#x27;m glad I&#x27;m playing it, it&#x27;s fun despite its (many) shortcomings! reply physicles 12 hours agorootparentprevI was confused about Starfield until I saw https:&#x2F;&#x2F;youtu.be&#x2F;lHiP5OPZ2sA?feature=shared , which explains what it actually is: Fallout, but in space. Also apparently it takes about 12 hours to get into it. reply lloeki 8 hours agorootparentThat&#x27;s my take on it, and what I found so increasingly boring about those gamesStarfield is Fallout, but in space, Skyrim is Oblivion, but in the north, Fallout is Oblivion, but in post-nuke retrofuture, and Oblivion is Morrowind, but in a thinly veiled roman empire setting.I mean, from gameplay to quests, it&#x27;s the exact same thing, reskinned. e.g porphyric hemophilia was cool in Morrowind, but the exact set up + quests is reproduced over and over again in subsequent games (incl. across franchises!). I&#x27;m halfway wondering (and would not be surprised) if Starfield had vampires as well.It&#x27;s nice if you enjoy the thing a lot (good for fans! I&#x27;m all for them enjoying it) but is otherwise so repetitive that what was fun back then is not anymore, and a fresh coat of paint increasingly failed at saving the later entries. replysatvikpendem 13 hours agorootparentprevIt is good, but you have to go into it with different expectations. Skill Up has the best review of it that I&#x27;ve seen [0], where the game is actually a 4th wall breaking meta commentary on the story driven and mystery game genre as a whole, with live action parts interspersed with the gameplay and cutscenes.[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jh1vq0SljoU reply izacus 8 hours agorootparentprev> Thank you! Exactly what I was hoping to hear, unless it was actually good.So you were just peddling around to confirm your preconcieved bias for it to be bad?(Pretty much all reviews have been universally VERY good in media.) reply ShamelessC 14 hours agorootparentprev> Thank you! Exactly what I was hoping to hear, unless it was actually good. Thanks for saving us from disappointment.Eh let&#x27;s be real - you decided you didn&#x27;t like that game the moment you saw any sort of press about it. reply ShamelessC 15 hours agorootparentprev> I don’t understand how a big game like this could have you just walking around doing nearly nothing for several hours straightIsn’t that exactly how Alan Wake 1 starts out? reply illegalsmile 35 minutes agorootparentI started AW1 the other day because it had been on my list after playing through Control. There&#x27;s definitely a lot of walking around and cut scenes but I wouldn&#x27;t say you do nothing. You do have to fight people, collect items and do some very simple puzzles. reply LelouBil 16 hours agoparentprevI liked Control, there&#x27;s a lot of story that you can discuss. It&#x27;s like if someone made a game about SCPs but with an actually overarching story. reply wincy 12 hours agoparentprevAs a counterpoint I’m two and a half hours in and like the pacing. I’ve been drinking in the scenery and just had some really creepy stuff happen. I really like the whole “descent into madness” trope in my games though, and this definitely is scratching that itch. reply kevinmchugh 16 hours agoparentprevYou should draw no conclusions about quality or how well a game will run at launch from a game by another studio. reply olah_1 16 hours agoprevI have a 2070super GPU and realized that for most modern games, the bottleneck is my CPU. Seems like most games have pushed a lot of complexity to that these days. reply p1necone 16 hours agoparentThe GPU in the PS5 is roughly equivalent to a 2070 super. You&#x27;ll probably find pretty much everything that also releases on console will run just fine until the next console generation becomes the new performance target. reply solardev 1 hour agoprevWish they wouldn&#x27;t have made this an Epic exclusive. reply liampulles 8 hours agoprevStarted playing Max Payne for the first time last night - great game so far.Remedy know what they are doing reply climb_stealth 7 hours agoparentYou mean the first Max Payne? Oh man you are going to be in for a great time! Part 1 and 2 are absolute classics. So many quoteable things are being said and the athmosphere and attention to detail are amazing. reply dom96 17 hours agoprevIt is beautiful even on my 2070. But strangely mirrors are completely broken. reply zirgs 4 hours agoparentYes, because they are using ssr for mirrors on lower settings. reply smilespray 16 hours agoparentprevHave you tried toggling Vampire Mode? reply personjerry 10 hours agoprevIn stark contrast to Cities Skylines 2 reply distances 3 hours agoparentInterestingly both come from Finland. I guess the dev teams didn&#x27;t share performance tips! reply iamsanteri 18 hours agoprevStarted playing it yesterday with ray tracing turned off. Still absolutely stunning! reply FirmwareBurner 18 hours agoparentAre people really that invested into raytracing hype being so necessary for visuals?From what I was unless you&#x27;re comparing RTX ON vs OFF side by side it&#x27;s not noticeable enough to make a difference. reply Veedrac 16 hours agorootparentAlan Wake 2 doesn&#x27;t really have the option to disable ray tracing, only to disable hardware ray tracing. Software ray tracing is pretty good for diffuse GI nowadays. reply rjh29 17 hours agorootparentprevIt depends how games use it. Spiderman 2 for example uses raytracing for reflections which are very important in New York (glass buildings, water, cars) and even uses it to draw rooms inside the skyscraper as you are climbing them. It&#x27;s important enough that raytracing cannot be turned off even on the lowest quality settings. reply wlesieutre 17 hours agorootparentNo raytracing needed for the window interiors, it’s shader wizardryhttps:&#x2F;&#x2F;www.alanzucconi.com&#x2F;2018&#x2F;09&#x2F;10&#x2F;shader-showcase-9&#x2F; reply dleeftink 17 hours agorootparentAccording to Fitzgerald, ray&#x2F;path tracing is used for interiors in the most recent release:[0]: https:&#x2F;&#x2F;youtu.be&#x2F;fuu_wseJnIE?t=3m26s reply ohhnoodont 17 hours agorootparentInsomniac is incredible. I have great appreciation for studios willing to maintain their own engine and consistently push technological boundaries. Same with Remedy. reply imbnwa 12 hours agorootparentWith the horsepower behind Alan Wake 2, Control 2 is gonna be nuts reply MBCook 17 hours agorootparentprevThat was for the first, which needed to run on a PS4.Spiderman 2 uses a very different system. reply esperent 17 hours agorootparentprevThis article is from 2018 and talking about the original Spider-Man PS4 game. And I think it&#x27;s still wrong - as far as I know they used cubemaps for the interiors in that game.So I think this article is mostly just an ad for a Unity addon. reply wlesieutre 17 hours agorootparentArticle gives examples of the cube mapping interiors https:&#x2F;&#x2F;forum.unity.com&#x2F;threads&#x2F;interior-mapping.424676&#x2F;#pos...You’re right about the new one though, they’ve apparently gone to raytracing for Spider-Man 2’s windows. I wonder if they’ll stick to raytracing always enabled if they do a PC port of this one. replydewey 7 hours agoprevAn article about how visually amazing the game is on older GPUs without showing more than 3 very dark screenshots that don&#x27;t really show much. Sometimes I&#x27;m really wondering how people pick their article images. reply keyle 18 hours agoprevIs there one of those breakdown of a frame article? I&#x27;d be curious to understand the sauce. reply esperent 17 hours agoparentI haven&#x27;t seen one of those for years, is there anyone still doing them? They are great. They&#x27;re a huge amount of work though so I wouldn&#x27;t expect one for a new game. reply keyle 16 hours agorootparentThey&#x27;re still around ...https:&#x2F;&#x2F;mamoniem.com&#x2F;behind-the-pretty-frames-elden-ring&#x2F;https:&#x2F;&#x2F;alain.xyz&#x2F;blog&#x2F;frame-analysis-overwatchhttps:&#x2F;&#x2F;simoncoenen.com&#x2F;blog&#x2F;programming&#x2F;graphics&#x2F;DoomEterna... reply esperent 4 hours agorootparentNice, thank you. reply Piko 15 hours agorootparentprevI found these lists:https:&#x2F;&#x2F;www.gamedevpensieve.com&#x2F;graphics&#x2F;3d&#x2F;3d_frame-breakdo...http:&#x2F;&#x2F;www.adriancourreges.com&#x2F;blog&#x2F;2020&#x2F;12&#x2F;29&#x2F;graphics-stud...http:&#x2F;&#x2F;simonschreibt.de&#x2F;game-art-tricks&#x2F;Not super current, but still a nice overview :) reply esperent 4 hours agorootparentThank you. reply zaptheimpaler 15 hours agoprevWhat kind of performance are you all getting?On my RTX 2070 Super, I played the first hour so far on render resolution of 1080p (with DSLR upscale to 4K), medium settings, no ray-tracing at roughly 30-40FPS. reply asylteltine 11 hours agoprevToo bad the tech was wasted on a horror game. Tons of people don’t want to play those. reply mistyvales 15 hours agoprevGuess it&#x27;s finally time to upgrade my R9 Fury from 2015.. reply tjpnz 15 hours agoprevSupposedly it even runs on the Steam Deck. reply imbnwa 15 hours agoprevYou can do 4K@30 for most the part on a 4090 with max settings, no super-sampling or frame generation, with max ray-tracing on. The early bit in the forest it&#x27;d dip down to 21-24FPS though, so I up dropped the render resolution to 1440p.Though if you flip on frame generation at 4K max settings, you can do 60+ FPS reply bugglebeetle 17 hours agoprevI really tried to enjoy the first game, but it was too derivative of its influences (Twin Peaks, In the Mouth of Madness, Stephen King novels) for me to get through. Control did a much better job with this, including it’s retelling of the Alan Wake narrative. I had hoped the sequel would be better, but from everything I’ve seen, they’ve doubled down on the pastiche. Hopefully the next Control game won’t fall victim to the same. reply PumpkinSpice 17 hours agoparentMost of pop culture is derivative, and the benchmarks we use reveal more about our age than about true originality.That said, the references to Control in this game definitely feel a bit hamfisted. You even encounter a familiar character from Control, and they seem to have a lot less depth than in the original game. reply bugglebeetle 17 hours agorootparentI mean, there’s a reason we have the notion of pastiche vs. influence. Some works are derivative or unoriginal in a way that damages their artistry. Twin Peaks was wildly influential, but not everything it inspired does the same kind of cut-and-paste stuff that Alan Wake does. Control is, in fact, a better example of this - it’s thoroughly Lynchian without regurgitating so much of the specifics. reply crooked-v 17 hours agoparentprevFor me the main issue with the first Alan Wake was the awful controls. I stopped playing when it became clear I was spending more time wrestling with the game than actually playing. reply bugglebeetle 16 hours agorootparentYes, the controls were quite clunky and unfortunately the remastered edition did little to fix them. reply yurishimo 17 hours agoparentprevIf your up for it, I recommend the review by YouTuber “SkillUp” on Allen Wake 2 makes some good cases for why someone might enjoy it. He also compares it to the studios other games. reply xaellison 3 hours agoparentprevI really like the visual artistic direction... but the Mind Place feels like a Jira simulator. reply 101008 17 hours agoparentprevFor me it was the other way around. I loved the Alan Wake 1 story. It was clear, easy to follow with enough mystery. Control was a mess, I didn&#x27;t understand what I was achieving or had to do. The fact that it was \"open world\" inside the offices of that agency made it even worse. I skipped it and I couldn&#x27;t continue, despite the fact that I would have loved to learn more about Alan Wake backstory. reply imbnwa 12 hours agorootparentControl (the base game) was anti-climatic but I wouldn&#x27;t call it a mess. The story isn&#x27;t really about the main character and that certainly affects the aforementioned ending, but everything that&#x27;s going on is explained in the media you encounter throught the Oldest House. reply imbnwa 15 hours agoprevYou can do 4K@30 for most the part on a 4090 with max settings, no super-sampling or frame generation, with max ray-tracing on. The early bit in the forest it&#x27;d dip down to 21-24FPS though, so I up dropped the render resolution to 1440p. reply Dudester230602 17 hours agoprevAll that power and still they fail to position the camera directly behind the back... Hopefully same mistake will not be repeated on Max Payne remakes. reply estebank 17 hours agoparentEven Max Payne 1 had the titular character slightly to the left. It&#x27;s on purpose. reply Waterluvian 17 hours agoparentprevI’m not sure I’ve played a game where putting it directly behind doesn’t feel terribly uncomfortable. The player character ends up in the way of what people are looking at and moving towards. reply jncfhnb 6 hours agorootparentCamera behind the player is preferable for platformer games where you are concerned about your movement.Over the shoulder (offset behind the player) was popularized by resident evil 4. It makes sense because you want to both focus on what’s in front of you with a clear canvas for aiming while also keeping the character in view as part of the game. reply Dalewyn 16 hours agorootparentprevI&#x27;ve gotten used to it, but I never liked it because the direction of movement is decoupled from the direction of the camera. Moving the mouse left and right also swivels the camera around a moving invisible point looking inwards, instead of stationary around the character looking outwards.Also, is the obstruction you speak of really an issue? Never had I thought \"God damn, move over!\" to the character I was controlling straight from above-behind in ye olde days. reply bugglebeetle 17 hours agoparentprevRemedy sold off Max Payne to focus on other of their IP. reply z3phyr 11 hours agorootparentThey are officially developing the Max Payne remakes reply lofaszvanitt 17 hours agoprev [–] The hopes are high that Alan Wake 2&#x27;s optimization and performance will only continue to improve with the release of post-launch updates, including multiple expansions.---The idiocy of people. A game must be in a shipping ready state when it launches. End of story. If you wait for a game and buy it on T=0 day you do that because you want to experience the whole thing at that very moment, and don&#x27;t want to wait for possible updates that would elevate it to a level where it would run much better on your hardware. reply IanCal 17 hours agoparentSeems entirely reasonable to both enjoy something now and hope it becomes even more enjoyable. reply lofaszvanitt 16 hours agorootparentAfter you watch a movie, you hope for something more? The cut scenes maybe that are always horrible? reply georgeecollins 16 hours agorootparentGames are a different medium then movies. When was the last time you spent twenty hours watching a movie? My library is full of games I have spent a hundred hours or more on. So yeah, I expect a game to be good the day I buy it. But I also like when teams update a game after launch. reply lofaszvanitt 14 hours agorootparentIt was an example and the same applies to games. I never replayed a game because of a patch, never waited for any kind of updates and never will. When a game released, that&#x27;s the state I&#x27;m interested in, that&#x27;s what I will base my reviews on, end of story. reply jncfhnb 6 hours agorootparentThat’s fine. Nobody cares about your reviews if they refer to a version of the game that no longer exists though. reply IanCal 15 hours agorootparentprevAside from the problem of jumping types, yes?Have you never watched a film and wanted them to make a prequel, sequel or anything else in the same imagined universe? Never read a book and wanted more in the series?As for fixes, if you watched a film and there was some awkward CGI in it would you think \"wow I really hope they never improve that\"? reply lofaszvanitt 14 hours agorootparentYou are talking about a new game from the same thing. That takes years to come together. You cannot just sit down and say, ok, here is a few more hours of thing for you. That takes time, a lot of time and effort from multitude of people. That&#x27;s why 99% of DLCs are trash.There is no such thing in movies like bad cgi at a given time. Noone with a sane mind would ruin 10s of millions of investment with bad cgi nowadays. CGI reflects the state of the art, or a level that is acceptable&#x2F;affordable and won&#x27;t cause the viewer to be knocked out of concentration.Maybe for people who work in the industry and have an eye what to look for, cgi might have issues, but viewers won&#x27;t recognize anything odd.Also... movies either work or don&#x27;t work. I even rewatch movies from the 30s. There are movies, like Fritz Lang&#x27;s M (1931), which were tens of years ahead of the industry regarding pacing and storytelling and still (re)watchable almost 100 years later. reply lm28469 6 hours agoparentprev [–] > A game must be in a shipping ready state when it launches. End of story.I agree but reality doesn&#x27;t care about our opinions, it is how it is replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article documents the successful performance of Alan Wake 2 on PC, highlighting its adaptability to different hardware configurations including low-end GPUs.",
      "Despite initial fears about high system requirements, the game has garnered positive reviews and is commended for its remarkable visual appeal and performance on both high and low-end systems.",
      "It also acknowledges minor bugs in the game and anticipates upcoming updates to rectify them."
    ],
    "commentSummary": [
      "The discourse encompasses a range of gaming aspects such as the operation of \"Alan Wake 2\" on varied GPUs and the significance of resolution in gaming.",
      "It illustrates the obstacles of operating up-to-date games on outdated hardware and the fixation on benchmarks.",
      "The brief provides reviews of \"Starfield\", comments on \"Alan Wake 2\"'s use of raytracing, and various viewpoints on game enhancements and updates."
    ],
    "points": 170,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1698615772
  },
  {
    "id": 38069915,
    "title": "The costs of microservices (2020)",
    "originLink": "https://robertovitillo.com/costs-of-microservices/",
    "originBody": "Home About My Book The costs of microservices November 22, 2020 An application typically starts its life as a monolith. Take a modern backend of a single-page Javascript application, for example - it starts out as a single stateless web service that exposes a RESTful HTTP API and uses a relational database as a backing store. The service is composed of a number of components, or libraries, that implement different business capabilities: As the number of feature teams contributing to the same codebase increases, its components become increasingly coupled over time. This leads the teams to step on each other’s toes more and more frequently, decreasing their productivity. The codebase becomes complex enough that nobody fully understands every part of it, and implementing new features or fixing bugs becomes time-consuming. Even if the backend is componentized into different libraries owned by different teams, a change to a library requires the service to be redeployed. And if a change introduces a bug - like a memory leak - the entire service can potentially be affected by it. Additionally, rolling back a faulty build affects the velocity of all teams, not just the one that introduced the bug. One way to mitigate the growing pains of a monolithic backend is to split it into a set of independently deployable services that communicate via APIs. The APIs decouple the services from each other by creating boundaries that are hard to violate, unlike the ones between components running in the same process: This architectural style is also referred to as the microservice architecture. The term micro can be misleading, though - there doesn’t have to be anything micro about the services. In fact, I would argue that if a service doesn’t do much, it just creates more operational toll than benefits. A more appropriate name for this architecture is service-oriented architecture, but unfortunately, that name comes with some old baggage as well. Perhaps in 10 years, we will call the same concept with yet another name, but for now we will have to stick to microservices. Breaking down the backend by business capabilities into a set of services with well-defined boundaries allows each service to be developed and operated by a single small team. The reduced team size increases the application’s development speed for a variety of reasons: Smaller teams are more effective as the communication overhead grows quadratically with the team’s size. As each team dictates its own release schedule and has complete control over its codebase, less cross-team communication is required, and therefore decisions can be taken in less time. The codebase of a service is smaller and easier to digest by its developers, reducing the time it takes to ramp up new hires. Also, a smaller codebase doesn’t slow down IDEs, which makes the developers more productive. The boundaries between services are much stronger than the boundaries between components in the same process. Because of that, when a developer needs to change a part of the backend, they only need to understand a small part of the whole. Each service can be scaled independently and adopt a different technology stack based on its own needs. The consumers of the APIs don’t care how the functionality is implemented after all. This makes it easy to experiment and evaluate new technologies without affecting other parts of the system. Each microservice can have its own independent data model and data store(s) that best fit its use-cases, allowing developers to change its schema without affecting other services. Costs The microservices architecture adds more moving parts to the overall system, and this doesn’t come for free. The cost of fully embracing microservices is only worth paying if it can be amortized across dozens of development teams. Development Experience Nothing forbids the use of different languages, libraries, and datastores for each microservice - but doing so transforms the application into an unmaintainable mess. For example, it makes it more challenging for a developer to move from one team to another if the software stack is completely different. And think of the sheer number of libraries - one for each language adopted - that need to be supported to provide common functionality that all services need, like logging. It’s only reasonable then that a certain degree of standardization is needed. One way to do that - while still allowing some degree of freedom - is to loosely encourage specific technologies by providing a great development experience for the teams that stick with the recommended portfolio of languages and technologies. Resource Provisioning To support a large number of independent services, it should be simple to spin up new servers, data stores, and other commodity resources - you don’t want every team to come up with their own way of doing it. And once these resources have been provisioned, they have to be configured. To be able to pull this off, you will need a fair amount of automation. Communication Remote calls are expensive and introduce new and fun ways your systems can crumble. You will need defense mechanisms to protect against failures, like timeouts, retries and circuit breakers. You will also have to leverage asynchrony and batching to mitigate the performance hit of communicating across the network. All of which increases the system’s complexity. A lot of what I describe in my book about distributed systems is about dealing with this complexity. That being said, even a monolith doesn’t live in isolation as it’s being accessed by remote clients, and it’s likely to use third-party APIs as well. So eventually, these issues need to be solved there as well, albeit on a smaller scale. Continuous Integration, Delivery, and Deployment Continuous integration ensures that code changes are merged into the main branch after an automated build and test processes have run. Once a code change has been merged, it should be automatically published and deployed to a production-like environment, where a battery of integration and end-to-end tests run to ensure that the microservice doesn’t break any service that depends on it. While testing individual microservices is not more challenging than testing a monolith, testing the integration of all the microservices is an order of magnitude harder. Very subtle and unexpected behavior can emerge when individual services interact with each other. Operations Unlike with a monolith, it’s much more expensive to staff each team responsible for a service with its own operations team. As a result, the team that develops a service is typically also on-call for it. This creates friction between development work and operational toll as the team needs to decide what to prioritize during each sprint. Debugging systems failures becomes more challenging as well - you can’t just load the whole application on your local machine and step through it with a debugger. The system has more ways to fail, as there are more moving parts. This is why good logging and monitoring becomes crucial at all levels. Eventual Consistency A side effect of splitting an application into separate services is that the data model no longer resides in a single data store. Atomically updating records stored in different data stores, and guaranteeing strong consistency, is slow, expensive, and hard to get right. Hence, this type of architecture usually requires embracing eventual consistency. Practical Considerations Splitting an application into services adds a lot of complexity to the overall system. Because of that, it’s generally best to start with a monolith and split it up only when there is a good reason to do so. Getting the boundaries right between the services is challenging - it’s much easier to move them around within a monolith until you find a sweet spot. Once the monolith is well matured and growing pains start to rise, then you can start to peel off one microservice at a time from it. You should only start with a microservice first approach if you already have experience with it, and you either have built out a platform for it or have accounted for the time it will take you to build one. Written by Roberto Vitillo Want to learn how to build scalable and fault-tolerant cloud applications? My book explains the core principles of distributed systems that will help you design, build, and maintain cloud applications that scale and don't fall over. Sign up for the book's newsletter to get the first two chapters delivered straight to your inbox. Subscribe I respect your privacy. Unsubscribe at any time. ← Resiliency patterns of distributed systems Scalability patterns of distributed systems →",
    "commentLink": "https://news.ycombinator.com/item?id=38069915",
    "commentBody": "The costs of microservices (2020)Hacker NewspastloginThe costs of microservices (2020) (robertovitillo.com) 171 points by kiyanwang 2 hours ago| hidepastfavorite148 comments lr4444lr 1 hour agoDon&#x27;t disagree with the article, but to play Devil&#x27;s Advocate, here are some examples of when IME the cost IS worth it:1) there are old 3rd party dependency incompatibilities that you can spin off and let live separately instead of doing a painful refactor, rebuilding in house, or kludgy gluing2) there are deploy limitations on mission critical high available systems that should not hold up other systems deployment that have different priorities&#x2F;sensitive business hours time windows3) system design decisions that cannot be abstracted away are at the mercy of some large clients of the company that are unable or unwilling to change their way of doing things - you can silo the pain.And to be clear, it&#x27;s not that these things are \"cost free\". It&#x27;s just a cost that is worth paying to protect the simpler monolith from becoming crap encrusted, disrupted with risky deploys, or constrained by business partners with worse tech stacks. reply jupp0r 3 minutes agoparentTo add another to your list:Being able to easily use different programming languages. Not every language is a good fit for every problem. Being able to write your machine learning deduction services in Python, your server side rendered UI in Rails and your IO and concurrency heavy services in Go might justify the additional overhead of having separate services for these three. reply eduction 1 hour agoparentprevWouldn&#x27;t this just be \"having one or two services\"? I don&#x27;t think that&#x27;s the same as \"microservices\".Correct me if I&#x27;m wrong, but isn&#x27;t \"microservices\" when you make internal components into services by default, instead of defaulting to making a library or class? reply lr4444lr 16 minutes agorootparentI don&#x27;t want to get too tied up in the terminology, but \"microservices-first\" does not seem to be the problem the post is describing:One way to mitigate the growing pains of a monolithic backend is to split it into a set of independently deployable services that communicate via APIs. The APIs decouple the services from each other by creating boundaries that are hard to violate, unlike the ones between components running in the same process reply rmbyrro 38 minutes agorootparentprevExactly my thoughts reply sroussey 32 minutes agorootparentMicroservices is a newer term than SOA. reply gedy 12 minutes agorootparentprevFor some reason, most of the people I&#x27;ve worked with recently are either fully into monoliths or lots of fine grained, interdependent microservices.They don&#x27;t seem to understand there&#x27;s a useful middleground of adding fewer, larger data services, etc. It&#x27;s like SOA isn&#x27;t a hot topic so people aren&#x27;t aware of it. reply andorov 1 minute agorootparentI&#x27;ve been using the term &#x27;macro-services&#x27; to describe this middle ground. reply Dudester230602 51 minutes agorootparentprevExactly, just use well-factored services of any size and smack anyone saying \"micro...\" with a wet towel for they are just parroting some barely-profitable silicon valley money sinks. reply eterevsky 1 hour agoparentprev1) Why is it better than wrapping it in an interface with a clear API without extracting it into a separate service? reply voxic11 1 hour agorootparentBecause of dependency issues like he mentioned. If I am using Library A which depends on version 1 of Library C and I need to start using Library B which depends on version 2 of Library C then I have a clear problem because most popular programming languages don&#x27;t support referencing multiple different versions of the same library. reply rmbyrro 35 minutes agorootparentCan&#x27;t we just isolate these two services in containers, using different library versions?They don&#x27;t need to be microservices in order to isolate dependencies, do they?In Python, for instance, you don&#x27;t even need containers. Just different virtual environments running on separate processes. reply jethro_tell 2 minutes agorootparentI suppose if you do that, they will communicate over the network likely via api and have the ability to scale independently.You just invented microservices, lol. mjr00 17 minutes agorootparentprevIf you have two separate processes running in two separate containers... those are two separate services. You need to solve the same problems that would come with running them on two different EC2 instances: what&#x27;s the method for communicating with the other container? What happens if the other container I&#x27;m calling is down? If the other container is down or slow to respond to my API calls, am I dealing with backpressure gracefully or will the system start to experiencing a cascade of failures? reply furstenheim 58 minutes agorootparentprevThis node got it just right. You only get this issue for big stateful libraries, like frameworks reply paulddraper 1 hour agorootparentprevThose dependencies might cross language boundaries, or interfere with your other dependencies running in the same process. reply bingemaker 1 hour agorootparentOn the contrary, when they fail silently, it is hard debug \"dependent\" services reply j45 18 minutes agoparentprevThere are many ways to architecture well that doesn’t mean prematurely introducing micro services.I’m a fan of microservices btw.Premature optimization and scaling is almost as bad of a form of technical debt as others when you have to optimize in a completely different manner and direction. reply paulddraper 1 hour agoparentprevAnd those would apply toIncreasing architectural complexity to enforce boundaries is never a solution to a lack of organizational discipline,And yet we do this all the time. Your CI&#x2F;CD blocking your PRs until tests pass? That&#x27;s a costly technical solution to solve an issue of organizational discipline. reply nevinera 1 hour agorootparentThat&#x27;s technical, and not architectural. I&#x27;m _all about_ technical solutions to lack of discipline, and in fact I think technical and process solutions are the only immediate way to create cultural solutions (which are the long-term ones). I&#x27;d even consider minor increases to architectural complexity for that purpose justifiable - it&#x27;s a real problem, and trading to solve it is reasonable.But architectural complexity has outsized long-term cost, and service-orientation in particular has a _lot_ of it. And in this particular case, it doesn&#x27;t actually solve the problem, since you _can&#x27;t_ successfully enforce those domain boundaries unless you already have them well-defined. reply insanitybit 1 hour agorootparentCan you explain the salient distinction between a \"technical\" versus \"architectural\" solution? Candidly, I&#x27;m not convinced that there is one.> But architectural complexity has outsized long-term costAs do technical solutions, of course. CI&#x2F;CD systems are very expensive, just from a monetary perspective, but also impose significant burdens to developers in terms of blocking PRs, especially if there are flaky or expensive tests.> And in this particular case, it doesn&#x27;t actually solve the problem, since you _can&#x27;t_ successfully enforce those domain boundaries unless you already have them well-defined.Ignoring microservices, just focusing on underlying SoA for a moment, the boundary is the process. That is an enforceable boundary. I think what you&#x27;re saying amounts to, in microservice parlance, that there is no way to prevent a single microservice from crossing multiple bounded contexts, that it ultimately relies on developers. This is true, but it&#x27;s also just as true for good monolithic designs around modules - there is no technical constraint for a module to not expand into domains, becoming cluttered and overly complex.Microservices do not make that problem harder, but SoA does give you a powerful technical tool for isolation. reply nevinera 50 minutes agorootparent> Can you explain the salient distinction between a \"technical\" versus \"architectural\" solution? Candidly, I&#x27;m not convinced that there is one.Not concisely in the general case, but in this case the difference is fairly straightforward - CI&#x2F;CD doesn&#x27;t affect the structure of your executing application at all, only the surrounding context. I don&#x27;t want to spend the hours it would take to characterize architecture as distinct from implementation, but the vast number of textbooks on the topic all generally agree that there is one, though they draw the lines in slightly different places.> I think what you&#x27;re saying amounts to,Very much no - my point is about the process of implementation. The services.. _do_ enforce boundaries, but the boundaries they enforce may not be good ones.In order to successfully extract services from a monolith, you have to go through a process that includes finding and creating those domain boundaries for the domain being extracted. If it&#x27;s your first time, you might be doing that implicitly and without realizing it&#x27;s what you&#x27;re doing, but under the hood it&#x27;s the bulk of the mental effort.The part where you actually _introduce a service_ can be anywhere from a tenth to half of the work (that fraction varies a lot by technical stack and depending on how coupled the domain in question is to the central behavioral tangle in the monolith), but by the time you&#x27;ve gotten the domain boundary created you&#x27;ve _already solved_ the original problem. Now you&#x27;re facing a trade of \"extract this well-factored domain out to a separate service application, to prevent its now-clear boundaries from being violated in the future\". And I contend that that&#x27;s a trade that should rarely be made. reply jcstauffer 54 minutes agorootparentprevI would hope that there is more process in place protecting against downtime than code review - for example automated tests across several levels, burn-in testing, etc.People are not reliable enough to leave them as the only protection against system failure... reply nevinera 47 minutes agorootparentDid you mean to reply to somebody else? I&#x27;m a huge believer in automated testing, and if I said something that can be interpreted otherwise I&#x27;d like to clarify it. reply marcosdumay 12 minutes agorootparentI guess the GP&#x27;s issue is because automated tests (and every other kind of validation) imposes architectural constraints on your system, and thus are an exception to your rule.I don&#x27;t think that rule can be applied as universally as you stated it. But then, I have never seen anybody breaking it in a bad way that did also break it in a good way, so the people that need to hear it will have no problem with the simplified version until they grow a bit.Anyway, that problem is very general of software development methods. Almost every one of them is contextual. And people start without the maturity to discern the context from the advice, so they tend to overgeneralize what they see. reply jaxr 1 hour agorootparentprevAgreed. isn&#x27;t that why strongly typed languages made a comeback? reply vrosas 1 hour agorootparentprevThe other problem is that these self-imposed roadblocks are so engrained in the modern SDLC that developers literally cannot imagine a world where they do not exist. I got _reamed_ by some \"senior\" engineers for merging a small PR without an approval recently. And we&#x27;re not some megacorp, we&#x27;re a 12 person engineering startup! We can make our own rules! We don&#x27;t even have any customers... reply jacquesm 1 hour agorootparentYour &#x27;senior&#x27; engineer is likely right: they are trying to get some kind of process going and you are actively sabotaging that. This could come back to haunt you later on when you by your lonesome decide to merge a &#x27;small PR&#x27; with massive downtime as a result of not having your code reviewed. Ok, you say, I&#x27;m perfect. And I believe you. But now you have another problem: the other junior devs on your team who see vrosas commit and merge stuff by themselves will see you as their shining example. And as a result they by their lonesomes decide to merge &#x27;small PR&#x27;s with massive downtime as a result.If you got _reamed_ you got off lucky: in plenty of places you&#x27;d be out on the street.It may well be that you had it right but from context as given I hope this shows you some alternative perspective that might give you pause the next time you decide to throw out the rulebook, even in emergencies - especially in emergencies - these rules are there to keep you, your team and the company safe. In regulated industries you can multiply all of that by a factor of five or so. reply insanitybit 1 hour agorootparent> Your &#x27;senior&#x27; engineer is likely right: they are trying to get some kind of process going and you are actively sabotaging thatWhy? Because it&#x27;s a \"good practice\"? They have 12 people and no customers, they can almost certainly adopt a very aggressive developer cycle that optimizes almost exclusively for happy-path velocity. You&#x27;d never do that at 50+ engineers with customers but for 12 engineers who have no customers? It&#x27;s fine, in fact it&#x27;s ideal.> with massive downtime as a result.They have no customers, downtime literally does not exist for them. You are following a dogmatic practice that is optimizing for a situation that literally does not exist within their company. reply nevinera 24 minutes agorootparentWith no customers, one of the purposes of code-review is removed, but it&#x27;s the lesser one anyway. The primary goal of code-review should _not_ be to \"catch mistakes\" in a well-functioning engineering team - that&#x27;s a thing that happens, but mostly your CI handles that. Code-review is about unifying approaches, cross-pollinating strategies and techniques, and helping each other to improve as engineers.Your attitude towards code-review on the other hand is one I&#x27;ve seen before several times, and I was glad when each of those people were fired. reply jacquesm 1 hour agorootparentprevYou establish a process before you need it, and code review, especially when starting up is a fantastic way to make sure that everybody is on the same page and that you don&#x27;t end up with a bunch of latent issues further down the line. The fact that they have no customers today doesn&#x27;t mean that they won&#x27;t have any in the future and mistakes made today can cause downtime further down the line.If you&#x27;re wondering why software is crap: it is because every new generation of coders insists on making all the same mistakes all over again. Learn from the past, understand that &#x27;good practice&#x27; has been established over many years of very expensive mistakes. 12 engineers is already a nice little recipe for pulling in 12 directions at once and even if they&#x27;re all perfect they can still learn from looking at each others code and it will ensure that there are no critical dependencies on single individuals (which can bite you hard if one of them decides to leave, not unheard of in a startup) and that if need be labor can be re-divided without too much hassle. reply insanitybit 58 minutes agorootparentI&#x27;m not advocating for having no processes, I&#x27;m advocating for a process that matches their situation. A company with no customers should not be worrying about causing a production outage, they should be worried about getting a demoable product out.Dogmatic adherence to a process that limits developer velocity and optimizes for correct code is very likely the wrong call when you have no customers. reply jacquesm 50 minutes agorootparentIf it is dogmatic, then yes: but you have no knowledge of that and besides there are always people who believe there is too much process and there are people that there is too little. If you want to challenge the process you do that by talking about it not by breaking the process on purpose. That&#x27;s an excellent way to get fired.I don&#x27;t know the context and I don&#x27;t know the particular business the OP is talking about. What I do know is that if you feel that your management is cargo culting development methodology (which really does happen) you can either engage them constructively or you can leave for a better company. Going in with a confrontational mindset isn&#x27;t going to be a good experience for anybody involved. Case in point: the OP is still upset enough that he feels it necessary to vent about this in an online forum.Note that this is the same person who in another comment wrote:\"On the flip side I’m trying to convince my CTO to fire half our engineering team - a group of jokers he hired during the run-up who are now wildly overpaid and massively under-delivering. With all the tech talent out there I’m convinced we’d replace them all within a week.\" reply vrosas 27 minutes agorootparentHeh, both can be true. Process doesn&#x27;t make good engineers any better. Bad code gets approved and merged every day. I&#x27;d rather have a team I could trust to merge and steward their code to production on their own instead of bureaucracy giving people a false sense of security.> Case in point: the OP is still upset enough that he feels it necessary to vent about this in an online forum.I apologize for the conversation starter. replymgkimsal 21 minutes agorootparentprevThen... the people responsible for this should have blocked PRs without a review. Or protected the target branch. Or... something. If it&#x27;s sacrosanct to do what OP did, but the &#x27;senior&#x27; folks didn&#x27;t put in actual guardrails to prevent it... OP is not entirely at fault. reply vrosas 1 hour agorootparentprevI&#x27;m challenging my team to actually think about that process, why it&#x27;s in place, how it&#x27;s helping (or actively hurting!) us. Comparing ourselves to companies that have regulatory requirements (spoiler: we don&#x27;t and likely won&#x27;t for a long, long time) just furthers my point that no one really thinks about these things. They just cargo cult how everyone else does it. reply jacquesm 1 hour agorootparentYou can challenge them without actually violating established process. I wasn&#x27;t comparing you to companies that have regulatory requirements, I was merely saying that all of the above will factor in much, much stronger still in a regulated industry.But not being in a regulated industry doesn&#x27;t mean there isn&#x27;t a very good reason to have a code review in your process, assuming it is used effectively and not for nitpicking.Not having a code review step is usually a bad idea, unless everybody on your team is of absolutely amazing quality and they never make silly mistakes. I&#x27;ve yet to come across a team like that, but maybe you are the exception to the rule. reply elzbardico 50 minutes agorootparentprevReally man. I have almost two decades developing software and yet, I feel a lot more comfortable having all my code reviewed. If anything I get annoyed by junior developers in my team when they just rub-stamp my PRs because supposedly I am this super senior guy that can&#x27;t err. Code Reviews are supposed to give you peace of mind, not being a hassle.During all this time, I&#x27;ve seen plenty of \"small changes\" having completely unexpected consequences, and sometimes all it would take to avoid would someone else seeing it from another perspective. reply vrosas 8 minutes agorootparentNot a man.I’m not convinced bad code would get merged more often if we didn’t require approvals. I am convinced we’d deliver code faster though, and that’s what I’m trying to optimize for. Your company and engineering problems are not the same as mine. reply insanitybit 1 hour agorootparentprevIndeed, dogmatic adherence to arbitrary patterns is a huge problem in our field. People have strong beliefs, \"X good\" or \"X bad\", with almost no idea of what X even is, what the alternatives are, why X was something people did or did not like, etc. reply jacquesm 1 hour agorootparentAnother problem is people making decisions with potentially far reaching consequences well above their paygrade without authorization. reply insanitybit 57 minutes agorootparentI don&#x27;t think that problem is nearly as significant. reply jacquesm 54 minutes agorootparentWhat you think is usually the limit of your experience, which effectively makes it anecdata. I&#x27;ve looked at enough companies and dealt with the aftermath of enough such instances that I beg to differ. It&#x27;s possible that due to the nature of my business my experience is skewed in the other direction which makes that anecdata as well. But it is probably more important than you think (and less important than I think). replyavelis 2 hours agoparentprevSounds like a SISP (solution in search of a problem). Or throwing a solution at a problem not understanding the root issue of it. reply jeffbee 2 hours agoparentprevI find it odd that there is this widespread meme—on HN, not in the industry—that microservices are never justified. I think everyone recognizes that it makes sense that domain name resolution is performed by an external service, and very few people are out there integrating a recursive DNS resolver and cache into their monolith. And yet, this long-standing division of responsibility never seems to count as an example. reply nevinera 1 hour agorootparentYou&#x27;re certainly misunderstanding me. Microservices are definitely justifiable in plenty of cases, and _services_ even more often. But they _need to be technically justified_ - that&#x27;s the point I&#x27;m making.The majority of SOA adoption in small-to-medium tech companies is driven by the wrong type of pain, by technical leaders that can see that if they had their domains already split out into services, their problems would not exist, but don&#x27;t understand that reaching that point involves _solving their problems first_. reply Scarblac 1 hour agorootparentprev_Services_ are obviously a good idea (nobody is arguing something like PostgreSQL or Redis or DNS or what have you should all run in the same process as the web server)._Microservices_ attract the criticism. It seems to assume something about the optimal size of services (\"micro\") that probably isn&#x27;t optimal for all kinds of service you can think of. reply arethuza 0 minutes agorootparentYou do see people arguing for running SQLite in-process rather than using a separate database server like PostgreSQL? mjr00 1 hour agorootparentprevIt&#x27;s funny because the term \"microservices\" picked up in popularity because previously, most \"service-oriented architecture\" (the old term) implementations in large companies had services that were worked on by dozens or hundreds of developers, at least in my experience. So going from that to services that were worked on by a single development team of ~10 people was indeed a \"microservice\" relatively speaking.Now, thanks to massive changes in how software is built (cloud, containers et al) it&#x27;s a lot more standard for a normal \"service\" with no prefix to be built by a small team of developers, no micro- prefix needed. reply Scarblac 1 hour agorootparentI can understand wanting to split things off so that one team handles one service, roughly.There was a recent thread here where someone mentioned he personally was responsible for about four of their microservices... reply nicoburns 1 hour agorootparentYeah, my last company had 10 microservices (the entirety of their codebase) managed by a single team when I started. Some of them had fewer than 5 API endpoints (and weren&#x27;t doing anything complex to justify that). reply xnorswap 1 hour agorootparentprevThat may be true, but the article describes a services architecture and labels it microservices, indeed goes onto to say:> The term micro can be misleading, though - there doesn’t have to be anything micro about the services reply Scarblac 1 hour agorootparentYes, but the \"widespread meme\" as I see it is about microservices, not services in general. reply butlerm 1 hour agorootparentThe smaller the service, the more likely that the overhead of having a separate service exceeds the benefit of doing so. It isn&#x27;t at all normal for a service to have its own database unless it provides a substantial piece of functionality, for example, and there are non-trivial costs to splitting databases unnecessarily. If you are not very careful, it is a good way to make certain things a dozen times slower and a dozen times more expensive to develop. reply jeffbee 1 hour agorootparentprevThis seems subjective. It&#x27;s like putting \"compatible with the character of the neighborhood\" in a city&#x27;s zoning codes. reply pjc50 1 hour agorootparentprevDNS resolution is genuninely reusable, though. Perhaps that&#x27;s the test: is this something that could concievably be used by others, as a product in itself, or is it tied very heavily to the business and the rest of the \"microservices\"?Remember this is how AWS was born, as a set of \"microservices\" which could start being sold to external customers, like \"storage\". reply jeffbee 57 minutes agorootparentWhat about a mailer that&#x27;s divided into the SMTP server and the local delivery agent? reply rqtwteye 1 hour agorootparentprev\"I find it odd that there is this widespread meme—on HN, not in the industry—that microservices are never justified\"I think the problem is the word \"micro\". At my company I see a lot of projects that are run by three devs that and have 13 microservices. They are easy to develop but the maintenance overhead is enormous. And they never get shared between projects so you have 5 services that do basically the same. reply mjr00 1 hour agorootparentprev> I find it odd that there is this widespread meme—on HN, not in the industry—that microservices are never justified.There&#x27;s a few things in play IMO.One is lack of definition -- what&#x27;s a \"microservice\" anyhow? Netflix popularized the idea of microservices literally being a few hundred lines of code maintained by a single developer, and some people believe that&#x27;s what a microservice is. Others are more lax and see microservices as being maintained by small (4-10 person) development teams.Another is that most people have not worked at a place where microservices were done well, because they were implemented by CTOs and \"software architects\" with no experience at companies with 10 developers. There are a lot of problems that come from doing microservices poorly, particularly around building distributed monoliths and operational overhead. It&#x27;s definitely preferable to have a poorly-built monolith than poorly-built microservice architectures.I&#x27;ve been at 4 companies that did microservices (in my definition, which is essentially one service per dev team). Three were a great development experience and dev&#x2F;deploy velocity was excellent. One was a total clusterfuck. reply insanitybit 1 hour agorootparentIt doesn&#x27;t lack a definition, there&#x27;s lots of people talking about this. In general you&#x27;ll find something like \"a small service that solves one problem within a single bounded context\".> It&#x27;s definitely preferable to have a poorly-built monolith than poorly-built microservice architectures.I don&#x27;t know about \"definitely\" at all. Having worked with some horrible monoliths, I really don&#x27;t think I agree. Microservices can be done poorly but at minimum there&#x27;s a fundamental isolation of components. If you don&#x27;t have any isolation of components it was never even close to microservices&#x2F;SoA, at which point, is it really a fair criticism? reply mjr00 1 hour agorootparent> It doesn&#x27;t lack a definition, there&#x27;s lots of people talking about this. In general you&#x27;ll find something like \"a small service that solves one problem within a single bounded context\".How small is small? Even within this comment section there are people talking about a single developer being the sole maintainer of multiple microservices. I&#x27;m a strong advocate of (micro?)service architecture but I would never recommend doing the \"all behavior is 100-line lambda functions\" approach.A horrible monolith vs horrible microservices is subjective, of course, but IMO having everything self-contained to one repository, one collection of app servers, etc. at least gives you some hope of salvation, often by building new functionality in separate services, ironically. Horrible microservices that violate data boundaries, i.e. multiple services sharing a database which is a sadly common mistake, is a much harder problem to solve. (both are bad, of course!) reply insanitybit 1 hour agorootparent\"Small\" is a relative term, and not an ideal one, but what it generally means is \"no larger than is needed\" - that is, if you have one concrete solution within a bounded context, \"small\" is the code necessary to implement that solution. It&#x27;s not a matter of LOC.> IMO having everything self-contained to one repositoryI highly recommend keeping all microservices in a single repository. It&#x27;s even more important in a microservice world to ensure that you can update dependencies across your organization atomically.> Horrible microservices that violate data boundaries, i.e. multiple services sharing a database which is a sadly common mistake, is a much harder problem to solve.But that&#x27;s not microservices. Maybe this is in and of itself an issue of microservice architecture, the fact that people think they&#x27;re implementing microservices when they&#x27;re actually just doing SoA, but microservice architecture would absolutely not include multiple services with a single database, that would not be microservices.So I think the criticism would be \"people find it hard to actually implement microservices\" and not \"microservice architecture leads to these problems\", because microservice architecture is going to steer you away from multiple services using one database. reply sally_glance 35 minutes agorootparentA little off topic but there are even more sinister patterns than the shared database which some architects are actively advocating for, like1. The \"data service\" layer, which (if done improperly) is basically just a worse SQL implemented on top of HTTP but still centralised. Though now you can claim it&#x27;s a shared service instead of a DB.2. The \"fat cache\" database - especially common in strongly event-based systems. Basically every service decides to store whatever it needs from events to have lower latency access for common data. Sounds great but in practice leads to (undocumented) duplicate data, which theoretically should be synchronised but since those service-local mirror DBs are usually introduced without central coordination it&#x27;s bound to desync at some point. replymanicennui 1 hour agorootparentprevI rarely see anyone claiming that microservices are never justified. I think the general attitude toward them is due to the amount of Resume Driven Development that happens in the real world. reply mdekkers 1 hour agorootparentprev> I find it odd that there is this widespread meme—on HN, not in the industry—that microservices are never justified.Many HN patrons are actually working where the rubber meets the road.DNS is a poor comparison. Pretty much everything, related to your application or not, needs DNS. On the other hand, the only thing WNGMAN[0]may or may not do, is help with finding the user’s DOB.https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=y8OnoxKotPQ reply jihadjihad 2 hours agoprevnext [–]Microservices grug wonder why big brain take hardest problem, factoring system correctly, and introduce network call too seem very confusing to grughttps:&#x2F;&#x2F;grugbrain.dev&#x2F;#grug-on-microservices reply sethammons 2 hours agoparentgrug not experience large teams stepping on each other&#x27;s domains and data models, locking in a given implementation and requiring large, organizational efforts to to get features out at the team level. Team velocity is empowered via microservices and controlling their own data stores.\"We want to modernize how we access our FOO_TABLE for SCALE_REASONS by moving it to DynamoDB out of MySQL - unfortunately, 32 of our 59 teams are directly accessing the FOO_TABLE or directly accessing private methods on our classes. Due to competing priorities, those teams cannot do the work to move to using our FOO_SERVICE and they can&#x27;t change their query method to use a sharded table. To scale our FOO_TABLE will now be a multi-quarter effort providing the ability for teams to slow roll their update. After a year or two, we should be able to retire the old method that is on fire right now. In the meanwhile, enjoy oncall.\"Compare this to a microservice: Team realizes their table wont scale, but their data is provided via API. They plan and execute the migration next sprint. Users of the API report that it is now much faster. reply jjtheblunt 2 hours agorootparent> Team velocity is empowered via microservices and controlling their own data stores.Bologna. Choosing clear abstractions is an enabler of focus, but that doesn’t necessarily imply those abstractions are a network call away. reply sethammons 1 hour agorootparentour team of 300 - we _can&#x27;t_ enforce the clear abstractions. New dev gets hired, team feels pressured to deliver despite leadership saying to prioritize quality, they are not aware of all the access controls, they push a PR, it gets merged.We have an org wide push to get more linting and more checks in place. The damage is done and now we have a multi-quarter effort to re-organize all our code.This _can_ be enforced via well designed modules. I&#x27;ve just not seen that succeed. Anywhere. Microservices are a pain for smaller teams and you have to have CI and observability and your pains shift and are different. But for stepping on eachother? I&#x27;ve found microservices to be a super power for velocity in these cases. Can microservices be a shitshow? Absolutely, esp. when they share data stores or have circular dependencies. They also allow teams to be uncoupled assuming they don&#x27;t break their API. reply ChrisMarshallNY 1 hour agorootparent> leadership saying to prioritize qualityWell, that&#x27;s different.My experience is that \"leadership\" often finds quality to be expensive and unnecessary overhead.That&#x27;s one reason that I stayed at a company that took Quality seriously. It introduced many issues that folks, hereabouts would find unbearable, but they consistently shipped some of the highest-Quality (and expensive) kit in the world.Quality is not cheap, and it is not easy. It is also not really the path to riches, so it is often actively discouraged by managers. reply Pet_Ant 53 minutes agorootparentprev> we _can&#x27;t_ enforce the clear abstractionsReally, you can&#x27;t? Then I struggle to see how&#x27;ll get anything else right. I&#x27;ve done it by using separate build scripts. That way only the interfaces and domain objects are exposed in the libraries. Now you lock down at the repository level access to each sub-project to the team working on it. There you go: modularity, boundaries, all without network hops. reply sethammons 33 minutes agorootparentsure - if you do that from the start. Most don&#x27;t. The codebase organically grows and then lines are blurred and then you have to come in and refactor. When this refactor affects several teams, it gets harder in combinatorial fashion.With an HTTP API boundary, you don&#x27;t get to reach into my code - it is literally impossible. reply nicoburns 1 hour agorootparentprev> They also allow teams to be uncoupled assuming they don&#x27;t break their API.Presumably you would still need tooling to enforce teams not breaking their API, and also to prevent people just modifying services to expose private internals that should not be part of the public API? reply jacquesm 1 hour agorootparentprevYou can&#x27;t really retrofit culture and behavior, you can only very gradually move towards a particular goal and usually that&#x27;s a multi-year effort, if it can be done at all. reply shadowgovt 1 hour agorootparentprevIf you want to change that model, there&#x27;s three things that need to happen:1) engineering needs a reason to embrace abstraction. Because the only thing that stops a new cowboy engineer is their peers explaining to them in what ways this isn&#x27;t the Wild Wesst. One can assume if rules would benefit the team, they&#x27;d be doing them already, so why don&#x27;t they? Maybe they perceive feature output velocity to be too high to risk changing method. Maybe decisionmaking power rests in the hands of one system architect who is holding the whole machine in their head so things that look complex to others seem simple to them (in that case, the team needs to spread around peer review signoff responsibilities on purpose, so one engineer can&#x27;t be the decisionmaker and the architecture itself must self-describe). Maybe (this is how I see it usually happen) they were a three-person startup and complexity crept up on them like a boiling frog. Whatever the reason, if you&#x27;re gonna convince them otherwise, someone&#x27;s gonna have to generate hard data on how changing the abstraction could make their jobs easier.2) If management has no idea what \"prioritize quality\" means (meaning no metrics by which to measure it and no real grasp of the art of software engineering), the engineers will interpret buzzwords as noise and route around them. Management needs to give actionable goals other than \"release feature X by Y date\" if they want to change engineering culture. That can take many forms (I&#x27;ve seen rewarded fixit weeks and externally-reported issue burndown charts as two good examples).3) Engineering leadership needs time and bandwidth to do training so they can see outside their prairie-dog hole over to how other teams solve problems. Otherwise, they get locked into the solutions they know, and the only way new approaches ever enter the team is by hires.And the key thing is: microservices may not be the tool for the job when all is said and done. This is an approach to give your engineering team ways to discover the right patterns, not to trick them into doing microservices. Your engineering team, at the end of the day, is still the best-equipped people to know the machinery of the product and how to shape it. reply simonw 2 hours agorootparentprev> Team realizes their table wont scale, but their data is provided via API. They plan and execute the migration next sprint.... followed by howls of anguish from the rest of the business when it turns out they were relying on reports generated from a data warehouse which incorporated a copy of that MySQL database and was being populated by an undocumented, not-in-version-control cron script running on a PC under a long-departed team member&#x27;s desk.(I&#x27;m not saying this is good, but it&#x27;s not an unlikely scenario.) reply mason55 1 hour agorootparent> ... followed by howls of anguish from the rest of the business when it turns out they were relying on reports generated from a data warehouse which incorporated a copy of that MySQL database and was being populated by an undocumented, not-in-version-control cron script running on a PC under a long-departed team member&#x27;s desk.Once you get to this point, there&#x27;s no path forward. Either you have to making some breaking changes or your product is calcified at that point.If this is a real concern then you should be asking what you can do to keep from getting into that state, and the answer is encapsulating services in defined interfaces&#x2F;boundaries that are small enough that the team understands everything going on in the critical database layer. reply mjr00 1 hour agorootparentprev> they were relying on reports generated from a data warehouse which incorporated a copy of that MySQL database and was being populated by an undocumented, not-in-version-control cron script running on a PC under a long-departed team member&#x27;s desk.This definitely happens but at some point someone with authority needs to show technical leadership and say \"you cannot do this no matter how desperately you need those reports.\" If you don&#x27;t have anyone in your org who can do that, you&#x27;re screwed regardless. reply simonw 1 hour agorootparentA lot of organizations are screwed. reply mjr00 39 minutes agorootparentI do agree with that. Microservices are not a good idea whatsoever for organizations with weak senior technical people. Which is probably 90%+ of businesses. reply pjc50 1 hour agorootparentprevThis was why the \"if you breach the service boundary you&#x27;re fired\" Amazon memo was issued. reply sethammons 1 hour agorootparentprevanother reason why you provide data only over API - don&#x27;t reach into my tables and lock me into an implementation. reply simonw 1 hour agorootparentAn approach I like better than \"only access my data via API\" is this:The team that maintains the service is also responsible for how that service is represented in the data warehouse.The data warehouse tables - effectively denormalized copies of the data that the service stores - are treated as another API contract - they are clearly documented and tested as such.If the team refactors, they also update the scripts that populate the data warehouse.If that results in specific columns etc becoming invalid they document that in their release notes, and ideally notify other affected teams. reply hermanradtke 49 minutes agorootparentThis same thing can be applied to contracts when firing events, etc. I point people to https:&#x2F;&#x2F;engineering.linkedin.com&#x2F;distributed-systems&#x2F;log-wha... and use the same approach to ownership. reply simonw 43 minutes agorootparentYeah, having a documented stream of published events in Kafka is a similar API contract the team can be responsible for - it might even double as the channel through which the data warehouse is populated. replycharcircuit 25 minutes agorootparentprevOther teams can access your data directly even if it&#x27;s in your own separate database. reply shadowgovt 1 hour agorootparentprevAs with so many software solutions, the success of microservices is predicated upon having sufficient prognostication about how the system will be used to recognize where the cut-points are.When I hear success stories like that, I have to ask \"Is there some inherent benefit to the abstraction or did you get lucky in picking your cleave-points?\" reply esafak 25 minutes agorootparentThat comes with experience. Live with a factored monolith for a while. If the factorization proves stable, proceed with carving it out into microservices. reply manicennui 38 minutes agoparentprevI just wanted to note that static typing isn&#x27;t required for autocomplete. JetBrains has IDEs for languages like Ruby and Python that can do it. If you open the REPL in a recent version of Ruby you get much of what you expect from an IDE with a statically typed language (with regards to autocomplete and syntax checking). reply manicennui 28 minutes agorootparentAlso, DRY is not about repeated code. This drives me crazy. Ruby developers love to make code worse by trying to \"DRY it up\". reply Capricorn2481 3 minutes agorootparentWhat are you replying to? The article is about how Dry shouldn&#x27;t be over applied.Dry is literally \"Don&#x27;t Repeat Yourself\" and is definitely pushed for cleaning up redundant code, so it&#x27;s not unreasonable for people to think that&#x27;s what about. It&#x27;s only recently that people have pointed out that there&#x27;s a difference between Duplicated code and Repeated code. reply insanitybit 1 hour agoparentprevNetwork calls are a powerful thing to introduce. It means that you have an impassable boundary, one that is actually physically enforced - your two services have to treat each other as if they are isolated.Isolation is not anything to scoff at, it&#x27;s one of the most powerful features you can encode into your software. Isolation can improve performance, it can create fault boundaries, it can provide security boundaries, etc.This is the same foundational concept behind the actor model - instead of two components being able to share and mutate one another&#x27;s memory, you have two isolated systems (actors, microservices) that can only communicate over a defined protocol. reply nicoburns 1 hour agorootparent> Network calls are a powerful thing to introduce. It means that you have an impassable boundary, one that is actually physically enforced - your two services have to treat each other as if they are isolated.That is not too true at all. I&#x27;ve seen \"microservice\" setups where one microservice depends on the state within another microservice. And even cases where service A calls into service B which calls back into service A, relying on the state from the initial call being present.Isolation is good, but microservices are neither necessary nor sufficient to enforce it. reply insanitybit 1 hour agorootparentWell, I&#x27;d say you&#x27;ve seen SoA setups that do that, maybe. But those don&#x27;t sound like microservices :) Perhaps that&#x27;s not a strong point though.Let me be a bit clearer on my point because I was wrong to say that you have to treat a service as being totally isolated, what I should have said that they are isolated, whether you treat them that way or not. There is a physical boundary between two computers. You can try to ignore that boundary, you can implement distributed transactions, etc, but the boundary is there - if you do the extra work to try to pretend it isn&#x27;t, that&#x27;s a lot of extra work to do the wrong thing.Concretely, you can write: rpc_call(&mut my_state)But under the hood what has to happen, physically, is that your state has to be copied to the other service, the service can return a new state (or an update), and the caller can then mutate the state locally. There is no way for you to actually transfer a mutable reference to your own memory to another computer (and a service should be treated as if it may be on another computer, even if it is colocated) without obscene shenanigans. You can try to abstract around that isolation to give the appearance of shared mutable state but it is just an abstraction, it is effectively impossible to implement that directly.But shared mutable state is trivial without the process boundary. It&#x27;s just... every function call. Any module can take a mutable pointer and modify it. And that&#x27;s great for lots of things, of course, you give up isolation sometimes when you need to. reply nicoburns 1 hour agorootparentHmm... I guess I very rarely use shared mutable state in web services anyway. The last job I worked at, all state was either in the database (effectively another service anyway) or stored on the client (e.g. auth tokens). So anything that was mutating a function parameter would already be subject to extra scrutiny during code review (Why is it doing that? What scope &#x2F; module boundary is the mutation limited to?). reply insanitybit 1 hour agorootparentShared mutable state also goes beyond a mutable reference. If you call a function and that function throws an exception you are tying the caller&#x2F;callee&#x27;s states together. In a SoA the callee machine can literally blow up and your caller state is preserved.If your web service is generally low-state and these problems are manageable for the complexity scale you&#x27;re solving for, microservices aren&#x27;t really something to even consider - I mean, you basically have a microservice already, it&#x27;s solving a single problem within a bounded context, give or take. It&#x27;s just... one service and one context. reply manicennui 53 minutes agorootparentprevIt is trivial to tightly couple two services. They don&#x27;t have to treat each other as isolated at all. The same people who create tightly coupled code within a single service are likely going to create tightly coupled services. reply insanitybit 50 minutes agorootparentI think I&#x27;ve covered this in another comment just below the one you&#x27;ve replied to. reply agumonkey 1 hour agoparentprevnew role: lead grug reply sazz 52 minutes agoprevSpeaking from a Release Management point of view going from a monolith to microservices is often done for the wrong reasons.The only valid reason for actual doing the change seems to be for scaling reasons due to performance bottlenecks. Everything else is just shifting complexity from software development to system maintenance.Of course, developers will be happy that they have that huge \"alignment with other teams\" burden off their shoulders. But the clarity when and how a feature is implemented, properly tested across microservices and then activated and hypercared on production will be much harder to reach if the communication between the development teams is not mature enough (which is often the actual reason from breaking up the monolith). reply altairTF 13 minutes agoparentThis is the sole reason we&#x27;re considering breaking this out into a separate component of our app. It&#x27;s become too large to maintain effectively. The rest of the app will remain unchanged reply aleksiy123 1 hour agoprevI recently had some discussions and did some research on this topic and I feel like there is a lot people don&#x27;t talk about in these articles.Here are some more considerations between micro services and monolothic tradeoffs. Its also important to consider these two things as a scale and not a binary decision.1. Isolation. Failure in on service doesn&#x27;t fail the whole system. Smaller services have better isolation.2. Capacity management. Its easier to estimate the resource usage of a smaller service because it has less responsibilities. This can result in efficiency gains. Extended to this is you can also give optimized resources to specific services. A prediction service can use GPU while web server can use CPU only. A monolothic may need to use compute with both which could result in less optimized resources.3. Dev Ops Overhead. In general monolothic services have less management overhead because you only need to manage&#x2F;deploy one or few services over many.4. Authorization&#x2F;Permissions. Smaller services can be given a smaller scope permissions.5. Locality. Monolothic can share memory and therefore have better data locality. Small services use networks and have higher overhead.6. Ownership. Smaller services can have more granular ownership. Its easier to transfer ownership.7. Iteration. Smaller services can move independently of one another and can release at seperate cadences. reply tazard 1 hour agoparent1. IsolationWith a well built monolith, a failure on a service won&#x27;t fail the whole system.For poorly built microservices, a failure on a service absolutely does being down the whole system.Not sure I am convinced that by adopting microservices, your code automatically gets better isolation reply aleksiy123 59 minutes agorootparentIts not automatic but it has the potential for more isolation by definition.If your service has memory leak, crash it only takes down the service. It is still up to your system to handle such a failure gracefully. If such a service is a critical dependency then your system fails. But if it is not then your service can still partially function.If your monolith has memory leak, or crash it takes down the whole monolith. reply manicennui 51 minutes agoparentprev1. Except that a single process usually involves multiple services and the failure of one service often makes entire sequences impossible. reply aleksiy123 26 minutes agorootparentBut not all sequences. It depends on your dependencies. Some services are critical for some processes. In the monoloth design its a critical dependency for all processes. reply jedberg 14 minutes agoprevLast time I did a survey of my peers, companies that were all in on microservices in the cloud spent about 25% of their engineering time on the support systems for microservices. That number is probably a bit lower now since there are some pretty good tools to handle a lot of the basics.And the author sums up the advice I&#x27;ve been giving for a long time perfectly:> Splitting an application into services adds a lot of complexity to the overall system. Because of that, it’s generally best to start with a monolith and split it up only when there is a good reason to do so.And usually that good reason is that you need to optimize a particular part of the system (which often manifests as using another language) or your organization has grown such that the overhead of microservices is cheaper than the management overhead.But some of the things in this article are not quite right.> Nothing forbids the use of different languages, libraries, and datastores for each microservice - but doing so transforms the application into an unmaintainable mess.You build a sidecar in a specific language, and any library you produce for others to consume is for that language&#x2F;sidecar. Then you can write your service in any language you want. Chances are it will be one of a few languages anyway that have a preferred onramp (as mentioned in the article), and if it&#x27;s not, then there is probably a good reason another language was chosen, assuming you have strong technical leadership.> Unlike with a monolith, it’s much more expensive to staff each team responsible for a service with its own operations team. As a result, the team that develops a service is typically also on-call for it. This creates friction between development work and operational toll as the team needs to decide what to prioritize during each sprint.A well run platform removes most of the ops responsibility from the team. The only thing they really have to worry about is if they have built their system in a way to handle failures well (chaos engineering to the rescue!) and if they have any runaway algorithms. Otherwise it&#x27;s a good thing that they take on that ops load, because it helps them prioritize fixing things that break a lot. reply dec0dedab0de 15 minutes agoprevModern micro services are ridiculous, with few exceptions. IIRC the original idea of micro-services was that each team in a large company should provide a documented API for the rest of the company to use instead of just a web page or a manual process. this is in contrast to their being only one development team that decides what gets worked on. Which allows individual employees to automate bigger processes that include steps outside of their own department. Somehow that changed to people spinning up containers for things that could be a function. reply js8 1 hour agoprevI think people get the modularity wrong. Modularity is important, but I came to conclusion there is another important architectural principle, which I call \"single vortex principle\".First, a vortex in a software system is any loop in a data flow. For example, if we send data somewhere, and then we get them back processed, or are in any way influenced by them, we have a vortex. A mutable variable is an example of a really small vortex.Now, the single vortex principle states that there ideally should be only one vortex in the software system, or, restated, every component should know which way its vortex is going.The rationale is when we have two vortices, and we want to compose the modules that form them into a single whole. If the vortices are correctly oriented, composition is easy. If they have opposite orientation, the composition is tricky and requires decision on how the new vortex is oriented. Therefore, it is best if all the vortices in all the modules have the same orientation, and thus form a single vortex.This principle is a generalization of ideas such as Flux pattern, CQRS, event sourcing, and immutability. reply salvadormon 19 minutes agoparentI find this vortex concept interesting. Do you have any books or online sources that I could use to study this? reply js8 16 minutes agorootparentNo, I made it all up. I wish I had time and interest to formalize it. reply wnolens 35 minutes agoprevIf a monolith is well-factored, what is the difference between it and co-located microservices?Probably just the interface - function calls become RPC. You accept some overhead for some benefits of treating components individually (patching!)What is the difference between distributed microservices v.s. co-located microservices?Deployment is more complex, but you get to intelligently assign processes to more optimal hardware. Number of failure modes increases, but you get to be more fault tolerant.There&#x27;s no blanket answer here. If you need the benefits, you pay the costs. I think a lot of these microservice v.s. monolith arguments come from poor application of one pattern or the other, or using inadequate tooling to make your life easier, or mostly - if your software system is 10 years old and you haven&#x27;t been refactoring and re-architecting as you go, it sucks to work on no matter the initial architecture. reply Symmetry 1 hour agoprevIn the robotics world it&#x27;s pretty common to have something that looks a lot like microservices as an organizing principle. ROS[1] would probably the robotics framework that everybody cuts their teeth on and in that you have a number of processes communicating over a pub&#x2F;sub network. Some of the reasons for organizing this way would be familiar to someone doing websites, but you also have factors like vendors for sensors you need providing libraries that will occasionally segfault, and needing to be able to recover from that.[1]https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Robot_Operating_System reply abound 1 hour agoprevI&#x27;m as much of a \"build a monolith until you can&#x27;t\" person as any, but one motivation for using microservices that I haven&#x27;t seen mentioned here is differing resource&#x2F;infra requirements + usage patterns.Throw the request&#x2F;response-oriented API with bursty traffic on something serverless, run the big async background tasks on beefy VMs (maybe with GPUs!) and scale those down when you&#x27;re done. Run the payments infra on something not internet-facing, etc.Deploying all those use cases as one binary&#x2F;service means you&#x27;ve dramatically over-provisioned&#x2F;underutilized some resources, and your attack service is larger than it should be. reply charcircuit 19 minutes agoparentA load balancer can make this work with a monolith. Requests for expensive services can be routed to a separate tier of servers for example. reply spott 1 hour agoprev\"Microservices\" has always been weird to me.People argue for them from two different, drastically different, points of view:* Microservices become necessary at some point because they allow you to independently scale different parts of the application depending on load.* Microservices become necessary at some point because they allow you to create hard team boundaries to enforce code boundaries.Personal opinion: micro services are always thrown out there as a solution to the second problem because it is easier to split a service out of a monolith than it is to put the genie of bad code boundaries back in the box.An application goes through a few stages of growth:1) When it starts, good boundaries are really hard to define because no-one knows what the application looks like. So whatever boundaries are defined are constantly violated because they were bad abstraction layers in the first place.2) After a while, when the institutional knowledge is available to figure out what the boundaries are, it would require significant rewrites&#x2F;refactoring to enforce them.3) Since a rewrite&#x2F;major refactor is necessary either way, everyone pushes to go to micro services because they are a good resume builder for leadership, and \"we might need the ability to scale\", or people think it will be easier (\"we can splinter off this service!\", ignoring the fact that they can splinter it off within the monolith without having to deal with networks and REST overhead).Unfortunately, this means that everyone has this idea that micro services are necessary for code boundaries because so many teams with good code boundaries are using micro services. reply soco 1 hour agoparentGranular performance and team boundaries are both valid points. But, I haven&#x27;t seen yet (around me) monolith applications so complex to have more teams working on them. I&#x27;ve seen instead applications developed by two persons where some higher-ups requested splitting them into microservices just because (no, scaling wasn&#x27;t needed). reply nightowl_games 1 hour agoprevI tried to use an eBPF sampling profiler to produce a flame graph&#x2F;marker chart of our c&#x2F;c++ desktop application. I struggled to get it going, seems like the existing tools are for kernel level profiling and more complicated stuff.Anyone recommend a simple technique to produce a quality profiler report for profiling a desktop application? Honestly the chrome&#x2F;firefox profiler is so great that I do wasm builds and use those. Ideally Id like a native profiler that can output .json that chrome&#x2F;ff can open in it&#x27;s profile analyzer. reply holoduke 44 minutes agoprevI think that chunking up your application layer into smaller parts is always a good idea. But when do you say its a microservice? When its completely isolated, with its own database etc. Are many small applications running as seperate binaries&#x2F;processes&#x2F;on different ports talking to one database endpoint also microservices? reply never_inline 30 minutes agoparent> Are many small applications running as seperate binaries&#x2F;processes&#x2F;on different ports talking to one database endpoint also microservices?One database endpoint as in ? You can use different schemas and have no relations between tables used by different services, or on the other extreme have services which write to same table.I have read in a book that the most important criteria is independent deployability. I forget the name of the book. reply esafak 20 minutes agorootparenthttps:&#x2F;&#x2F;samnewman.io&#x2F;books&#x2F;building_microservices_2nd_editio... ? reply harry_ord 2 hours agoprevMy current job hasn&#x27;t been a great experience with microservices. It&#x27;s a industry where I&#x27;ve worked with a monolith that did a lot more but having everything split between like 17 different services makes managing anything not so fun. The other big blocker is small team and only one of us met the original staff who designed this. reply paulddraper 1 hour agoprev> The term micro can be misleading, though - there doesn’t have to be anything micro about the services. In fact, I would argue that if a service doesn’t do much, it just creates more operational toll than benefits. A more appropriate name for this architecture is service-oriented architecture, but unfortunately, that name comes with some old baggage as well.What baggage is that?Because in my experience 90% of the argument revolves around the word \"micro.\"If \"micro\" is indeed irrelevant to \"microservices,\" let&#x27;s name things better, yes? reply ranting-moth 1 hour agoprevThe article mentions Development Experience, but doesn&#x27;t mention what I think is an overlooked huge cost.Bad Development Experience results in unhappy and&#x2F;or frustrated developer. Unhappy and&#x2F;or frustrated developer is usually performing considerably worse than his happier self would. reply avandekleut 46 minutes agoprevWe started with a microservices architecture in a greenfield project. In retrospect we really should have started with a monolith. Every 2-3 days we have to deal with breaking changes to API schemas. Since we’re still pre-production it doesn’t make sense to have a dozen major versions up side-by-side, so we’re just sucking up the pain for now. It’s definitely a headache though.We also are running on AWS API Gateway + lambda so the availability and scalability are the same regardless of monolith or not… reply sorokod 1 hour agopreveventual consistencyA bit of tangent but one must admire the optimistic attitude reflected by this name.\"Most of the time inconsistent\" says the same thing but is not great for marketing. reply exabrial 1 hour agoprev> Getting the boundaries right between the services is challenging - it’s much easier to move them around within a monolith until you find a sweet spot. Once the monolith is well matured and growing pains start to rise, then you can start to peel off one microservice at a time from it.I couldn&#x27;t agree more. \"Do not optimize your code\" applies here. reply avelis 2 hours agoprev> Once the monolith is well matured and growing pains start to rise, then you can start to peel off one microservice at a time from it.Curious what is considered a growing pain of the monolith vs tech debt that hasn&#x27;t been tackled. If the issue is the monolith can&#x27;t scale in performance then a services oriented architecture doesn&#x27;t necessarily give you that automatically unless you know where the bottleneck of your monolith is. reply timwaagh 2 hours agoprevI liked this well balanced approach. What I think is necessary is more capability to have hard modularisation within a monolith, so decoupling is not a reason to introduce microservices. Performance should be the main&#x2F;only reason to do it. It&#x27;s a shame few languages support this. reply esafak 17 minutes agoparentYou mean like namespacing? What language did you have in mind? reply astonex 1 hour agoprevThere&#x27;s a spectrum between each function is a separate service, to everything is in one binary. The engineering part is finding the happy medium. reply eterevsky 1 hour agoprevIn my experience, if a piece of code is stateful and is called from several different services, then it should be its own service. Otherwise it is usually better off as a library. reply agumonkey 1 hour agoprevHas anyone approached microservices with good old brookes modularization perspective ? when and how to split your app into modules &#x2F; services whatever. reply ThinkBeat 2 hours agoprevSide issue: What software is used to make those diagrams? reply FL410 2 hours agoparentLooks like Excalidraw reply aiunboxed 1 hour agoprevIf your company has a microservice architecture but doesn&#x27;t have proper knowledge on how should they communicate, how should they share code etc then it is the worst thing possible. reply jeffbee 2 hours agoprevThe article sees to take for granted that your development org is completely broken and out of control. They can&#x27;t decide what to work on during sprints, they furtively introduce third party libraries and unknown languages, they silently ship incompatible changes to prod, etc. I guess microservices are easier if your developers aren&#x27;t bozos. reply alt227 2 hours agoparentUnfortunately there are very often bozos in your team or complete teams of bozos working on the same project as you. Im sure Microservices are easier if you work in a development team of smart, competent, intelligent developers. However Im sure everything would be easier then! reply simonw 1 hour agoparentprevEvery developer is a bozo for their first few months in a new job, simply because it takes time to absorb all of the information needed to understand how the existing systems work. reply jeffbee 1 hour agorootparentAcculturating new developers is one of the main tasks of an organization. I don&#x27;t think it&#x27;s very difficult to communicate that some company uses language[s] X[, Y and Z] only. reply simonw 1 hour agorootparentThat depends on the culture of each specific organization. Are there top-down engineering decisions? Is there a push for more team autonomy?My experience is that many organizations have something of a pendulum swinging between those two positions, so the current state of that balance may change over time.Also: many new developers, when they hear \"microservices\", will jump straight to \"that means I can use any language I want, right?\"(Maybe that&#x27;s less true in 2023) reply fwungy 1 hour agoprevJust use Rust. Rust solves all of this. reply resters 1 hour agoprevThere should be a distinction between doing a migration of a \"monolithic\" system to \"microservices\" vs adding functionality to a monolithic system by implementing a \"microservice\" that will be consumed by the monolithic system.In some cases, microservices are helpful for separation of concerns and encapsulation.But teams often get the idea that their monolithic system should be rewritten using \"microservice\" patterns. It&#x27;s important to question whether the monolithic system is using the correct abstractions and whether spllitting it into different services is the only way to approach the deficiencies of the system.In most systems there are bits that can (and probably should) be quite decoupled from the rest of the system. Understanding this is a more fundamental aspect of system design and does not apply only to monolithic or microservice approaches. reply lcfcjs 2 hours agoprev [–] Interesting article.Although one point I&#x27;d like to contest is the first \"pro\" which is you can use a different language for each service. We tried this approach and it failed fantastically. You&#x27;re right about the cons, it becomes un-maintable.We had 3 microservices that we maintained on our team, one in Java, one in Ruby and one in Node. We very quickly realized we needed to stick to one, in order to share code, stop the context switching, logging issues, etc.The communication piece is something that solid monoliths should practice as well (as is it touched on in the article). Calling an 3rd party API without a timeout is not a great idea (to be it lightly), monolith or microservice.Thought-provoking nevertheless, thank you for sharing. reply codesnik 58 minutes agoparent [–] lemme guess, you all converged to Java? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explores the benefits of a microservices architecture, including improved pace of development, reduced communication bottlenecks, scalability, and the ability to experiment with different technologies.",
      "It highlights the drawbacks of such architecture, including increased complexity, the need for management of resource provisioning, articulating communication challenges, and the necessity for automation.",
      "It emphasizes on the crucial role of continuous integration, testing, and monitoring in such environments, while also underlining the operational and debugging challenges. The author suggests starting with a monolithic approach and shifting to microservices when required and with adequate experience and a well-established platform."
    ],
    "commentSummary": [
      "The conversation focuses on the trade-offs of using microservices in comparison to a monolithic architecture, with factors including technical tools like Continuous Integration/Continuous Deployment (CI/CD), potential database difficulties, and the need for proper planning.",
      "It is discussed that while microservices offer benefits like increased control for individual teams and quicker software development velocity, they may also present challenges that require substantial understanding of the existing system’s dependencies.",
      "The discussion emphasizes that the decision to adopt a microservices architecture should be made after thorough evaluation and under strong leadership to effectively manage the complexity involved."
    ],
    "points": 162,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1698676421
  },
  {
    "id": 38062269,
    "title": "Kubernetes releases ingress2gateway tool for upcoming GA of Gateway API",
    "originLink": "https://kubernetes.io/blog/2023/10/25/introducing-ingress2gateway/",
    "originBody": "Documentation Kubernetes Blog Training Partners Community Case Studies Versions English KubeCon + CloudNativeCon NA 2023 Chicago, Illinois + Virtual. 4 days of incredible opportunities to collaborate, learn + share with the entire community! November 6 - November 9, 2023. 2023 Introducing ingress2gateway; Simplifying Upgrades to Gateway API Plants, process and parties: the Kubernetes 1.28 release interview PersistentVolume Last Phase Transition Time in Kubernetes A Quick Recap of 2023 China Kubernetes Contributor Summit Bootstrap an Air Gapped Cluster With Kubeadm CRI-O is moving towards pkgs.k8s.io Spotlight on SIG Architecture: Conformance Announcing the 2023 Steering Committee Election Results Happy 7th Birthday kubeadm! kubeadm: Use etcd Learner to Join a Control Plane Node Safely Show More Posts... 2022 2021 2020 2019 2018 2017 2016 2015 Introducing ingress2gateway; Simplifying Upgrades to Gateway API Wednesday, October 25, 2023 Authors: Lior Lieberman (Google), Kobi Levi (independent) Today we are releasing ingress2gateway, a tool that can help you migrate from Ingress to Gateway API. Gateway API is just weeks away from graduating to GA, if you haven't upgraded yet, now's the time to think about it! Background In the ever-evolving world of Kubernetes, networking plays a pivotal role. As more applications are deployed in Kubernetes clusters, effective exposure of these services to clients becomes a critical concern. If you've been working with Kubernetes, you're likely familiar with the Ingress API, which has been the go-to solution for managing external access to services. The Ingress API provides a way to route external traffic to your applications within the cluster, making it an indispensable tool for many Kubernetes users. Ingress has its limitations however, and as applications become more complex and the demands on your Kubernetes clusters increase, these limitations can become bottlenecks. Some of the limitations are: Insufficient common denominator - by attempting to establish a common denominator for various HTTP proxies, Ingress can only accommodate basic HTTP routing, forcing more features of contemporary proxies like traffic splitting and header matching into provider-specific, non-transferable annotations. Inadequate permission model - Ingress spec configures both infrastructure and application configuration in one object. With Ingress, the cluster operator and application developer operate on the same Ingress object without being aware of each other’s roles. This creates an insufficient role-based access control and has high potential for setup errors. Lack of protocol diversity - Ingress primarily focuses on HTTP(S) routing and does not provide native support for other protocols, such as TCP, UDP and gRPC. This limitation makes it less suitable for handling non-HTTP workloads. Gateway API To overcome this, Gateway API is designed to provide a more flexible, extensible, and powerful way to manage traffic to your services. Gateway API is just weeks away from a GA (General Availability) release. It provides a standard Kubernetes API for ingress traffic control. It offers extended functionality, improved customization, and greater flexibility. By focusing on modular and expressive API resources, Gateway API makes it possible to describe a wider array of routing configurations and models. The transition from Ingress API to Gateway API in Kubernetes is driven by advantages and advanced functionalities that Gateway API offers, with its foundation built on four core principles: a role-oriented approach, portability, expressiveness and extensibility. A role-oriented approach Gateway API employs a role-oriented approach that aligns with the conventional roles within organizations involved in configuring Kubernetes service networking. This approach enables infrastructure engineers, cluster operators, and application developers to collectively address different aspects of Gateway API. For instance, infrastructure engineers play a pivotal role in deploying GatewayClasses, cluster-scoped resources that act as templates to explicitly define behavior for Gateways derived from them, laying the groundwork for robust service networking. Subsequently, cluster operators utilize these GatewayClasses to deploy gateways. A Gateway in Kubernetes' Gateway API defines how external traffic can be directed to Services within the cluster, essentially bridging non-Kubernetes sources to Kubernetes-aware destinations. It represents a request for a load balancer configuration aligned with a GatewayClass’ specification. The Gateway spec may not be exhaustive as some details can be supplied by the GatewayClass controller, ensuring portability. Additionally, a Gateway can be linked to multiple Route references to channel specific traffic subsets to designated services. Lastly, application developers configure route resources (such as HTTPRoutes), to manage configuration (e.g. timeouts, request matching/filter) and Service composition (e.g. path routing to backends) Route resources define protocol-specific rules for mapping requests from a Gateway to Kubernetes Services. HTTPRoute is for multiplexing HTTP or terminated HTTPS connections. It's intended for use in cases where you want to inspect the HTTP stream and use HTTP request data for either routing or modification, for example using HTTP Headers for routing, or modifying them in-flight. Portability With more than 20 API implementations, Gateway API is designed to be more portable across different implementations, clusters and environments. It helps reduce Ingress' reliance on non-portable, provider-specific annotations, making your configurations more consistent and easier to manage across multiple clusters. Gateway API commits to supporting the 5 latest Kubernetes minor versions. That means that Gateway API currently supports Kubernetes 1.24+. Expressiveness Gateway API provides standard, Kubernetes-backed support for a wide range of features, such as header-based matching, traffic splitting, weight-based routing, request mirroring and more. With Ingress, these features need custom provider-specific annotations. Extensibility Gateway API is designed with extensibility as a core feature. Rather than enforcing a one-size-fits-all model, it offers the flexibility to link custom resources at multiple layers within the API's framework. This layered approach to customization ensures that users can tailor configurations to their specific needs without overwhelming the main structure. By doing so, Gateway API facilitates more granular and context-sensitive adjustments, allowing for a fine-tuned balance between standardization and adaptability. This becomes particularly valuable in complex cloud-native environments where specific use cases require nuanced configurations. A critical difference is that Gateway API has a much broader base set of features and a standard pattern for extensions that can be more expressive than annotations were on Ingress. Upgrading to Gateway Migrating from Ingress to Gateway API may seem intimidating, but luckily Kubernetes just released a tool to simplify the process. ingress2gateway assists in the migration by converting your existing Ingress resources into Gateway API resources. Here is how you can get started with Gateway API and using ingress2gateway: Install a Gateway controller OR install the Gateway API CRDs manually . Install ingress2gateway. If you have a Go development environment locally, you can install ingress2gateway with: go install github.com/kubernetes-sigs/ingress2gateway@v0.1.0 This installs ingress2gateway to $(go env GOPATH)/bin/ingress2gateway. Alternatively, follow the installation guide here. Once the tool is installed, you can use it to convert the ingress resources in your cluster to Gateway API resources. ingress2gateway print This above command will: Load your current Kubernetes client config including the active context, namespace and authentication details. Search for ingresses and provider-specific resources in that namespace. Convert them to Gateway API resources (Currently only Gateways and HTTPRoutes). For other options you can run the tool with -h, or refer to https://github.com/kubernetes-sigs/ingress2gateway#options. Review the converted Gateway API resources, validate them, and then apply them to your cluster. Send test requests to your Gateway to check that it is working. You could get your gateway address using kubectl get gateway-n-o jsonpath='{.status.addresses}{\"\\n\"}'. Update your DNS to point to the new Gateway. Once you've confirmed that no more traffic is going through your Ingress configuration, you can safely delete it. Wrapping up Achieving reliable, scalable and extensible networking has always been a challenging objective. The Gateway API is designed to improve the current Kubernetes networking standards like ingress and reduce the need for implementation specific annotations and CRDs. It is a Kubernetes standard API, consistent across different platforms and implementations and most importantly it is future proof. Gateway API is the next generation of the Ingress API, but has a larger scope than that, expanding to tackle mesh and layer 4 routing as well. Gateway API and ingress2gateway are supported by a dedicated team under SIG Network that actively work on it and manage the ecosystem. It is also likely to receive more updates and community support. The Road Ahead ingress2gateway is just getting started. We're planning to onboard more providers, introduce support for more types of Gateway API routes, and make sure everything syncs up smoothly with the ongoing development of Gateway API. Excitingly, Gateway API is also making significant strides. While v1.0 is about to launching, there's still a lot of work ahead. This release incorporates many new experimental features, with additional functionalities currently in the early stages of planning and development. If you're interested in helping to contribute, we would love to have you! Please check out the community page which includes links to the Slack channel and community meetings. We look forward to seeing you!! Useful Links Get involved with the Ingress2Gateway project on GitHub Open a new issue - ingress2gateway, Gateway API. Join our discussions. Gateway API Getting Started Gateway API Implementations ←Previous Next→ RSS Feed Submit a Post @Kubernetesio on GitHub #kubernetes-users Stack Overflow Forum Kubernetes Documentation Blog Training Partners Community Case Studies © 2023 The Kubernetes AuthorsDocumentation Distributed under CC BY 4.0 Copyright © 2023 The Linux Foundation ®. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our Trademark Usage page ICP license: 京ICP备17074266号-3",
    "commentLink": "https://news.ycombinator.com/item?id=38062269",
    "commentBody": "Kubernetes releases ingress2gateway tool for upcoming GA of Gateway APIHacker NewspastloginKubernetes releases ingress2gateway tool for upcoming GA of Gateway API (kubernetes.io) 142 points by kodama-lens 20 hours ago| hidepastfavorite31 comments robertlagrant 18 hours agoI&#x27;ve not used Gateway, but I have felt the pain and confusion of Ingress. Hopefully this simplifies things for our Devops&#x2F;SRE heroes. reply mflendrich 15 hours agoparentMy team at Kong would agree - as maintainers of a very feature-rich implementation of Ingress we&#x27;ve felt the pain of pushing Ingress to the limits of its expressive power (hence our current strong focus on Gateway API).The Ingress API is fine as long as you&#x27;re in the \"basic proxying with simple path-based routing\" territory, but once you want to do something more serious (route by query string, configure weighted load balancing, work with TLS, deal with methods, etc - let alone other protocols than HTTP) you&#x27;re kinda stuck with vendor-specific extensions that mostly rely on annotations.Kong has an implementation of Gateway API for HTTP(S), TCP, UDP, TLS, gRPC that aims to offer a fairly smooth transition from Ingress to Gateway API by supporting both in our Kong Ingress Controller and working on conversion tooling (we&#x27;re the only provider other than nginx currently available in the ingress2gateway tool). We strongly believe that (at least Kong&#x27;s implementation of) Gateway API will be much easier to use than Ingress.You can try out Kong&#x27;s (certified conformant with Gateway API \"core\" profile) beta implementation by following [1] for HTTP. There&#x27;s a guide for gRPC as well, among others [2]. As Kong&#x27;s implementation of Gateway API [3] is nearing general availability, we&#x27;re very open to community feedback.[1] https:&#x2F;&#x2F;docs.konghq.com&#x2F;kubernetes-ingress-controller&#x2F;2.12.x...[2] https:&#x2F;&#x2F;docs.konghq.com&#x2F;kubernetes-ingress-controller&#x2F;2.12.x...[3] https:&#x2F;&#x2F;github.com&#x2F;Kong&#x2F;kubernetes-ingress-controller reply benatkin 12 hours agorootparent> route by query string, configure weighted load balancing, work with TLS, deal with methods, etc - let alone other protocols than HTTPExcept for weighted load balancing*, these are all things NGINX does, which Kong is built on via OpenResty, right? What makes Kong different? (Trying to be open to explore even though I was disappointed when Insomnia users got locked out of their data unless they signed up for an account when they updated what was marketed as an open source project)* Which I think NGINX Plus, a competitor, probably has, and they have an Ingress controller for Kubernetes that would likely get updated to use the Gateway API soon. reply mflendrich 10 hours agorootparent> What makes Kong different?I am specifically talking just about OSS functionality in the Kong Ingress Controller. It can assign weights to service backends.And, FWIW, Insomnia 8.3 defaults to local projects (again)https:&#x2F;&#x2F;konghq.com&#x2F;blog&#x2F;product-releases&#x2F;insomnia-8-3Gateway API is a broad community standard governed by SIG Network - fingers crossed for various other implementations (including mesh) working their way to GA implementation-wise - this will make the standard stronger and the community more vibrant. reply sofixa 7 hours agoparentprevHaving looked at some Gateway configs, I wouldn&#x27;t say simplify. It looks painfully verbose, but at least more things should be possible without resorting to hacky annotations for everything. reply pram 15 hours agoparentprevIngress seems to make easy things hard. I’ve spent hours dicking around with its config in some deployments, when I could have done the same thing in vanilla nginx in like 10 minutes.Especially with some vendor helm charts, it’s often a nightmare if you’re deviating from the base config. reply dharmab 12 hours agorootparentSince 2018-2019, many of the really big Kubernetes users ditched Ingress for custom controllers and CRDs that allowed for more flexible configuration. reply ggm 9 hours agoprevSince it makes no mention of ipv4 or ipv6 I&#x27;m going to hope it&#x27;s underlying ip protocol agnostic and works in the UDP&#x2F;TCP level only, which would encompass all TLS and QUIC behaviours too.Past experience with k8s suggests this hope is prone to being wishful thinking. reply jpgvm 9 hours agoparentThe Gateway spec itself supports both v4 and v6 addresses: https:&#x2F;&#x2F;gateway-api.sigs.k8s.io&#x2F;reference&#x2F;spec&#x2F;#gateway.netw...More importantly you will want to check your specific Gateway implementation for support. reply Already__Taken 6 hours agoparentprevcilium gateway for UDP is still WIP but that&#x27;s because of the cni implementation not the spec. they do not differentiate data streams so they can&#x27;t use 2 gateways on the same port for TCP and UDP. I think. reply hardwaresofton 8 hours agoprevWelp, I wonder when this will make sense to look at -- I&#x27;m pretty happy with `IngressRoute`[0] and related CRDs that are used with traefik.I guess when traefik goes all-in on gateway (they were one of the earliest with support for it), then it will make sense.[0]: https:&#x2F;&#x2F;doc.traefik.io&#x2F;traefik&#x2F;routing&#x2F;providers&#x2F;kubernetes-... reply Already__Taken 6 hours agoparentingressRoute crd exists because builtin ingress isn&#x27;t quite good enough. so it&#x27;ll probably live on a good while. reply hardwaresofton 6 hours agorootparentNote that I was talking about Gateway, which is the tool that the original article is about. I was referring to whether it would make any sense for me to move from IngressRoute to Gateway any time soon. reply pylua 15 hours agoprevTools like istio provide this sort of functionality currently, right? Does this adding anything to that?I wonder how developers will be able to develop extensions for it. reply gaganyaan 14 hours agoparentIstio kind of sucks TBH from the architecture astronauts getting high on their own supply. It reminds me of the worst excesses of OOP abstraction. The sort of code that you want to burn down to the ground after hitting your head against it for a few days.The Gateway API is a relatively straightforward implementation of \"north-south\" traffic and doesn&#x27;t try to handle \"east-west\" traffic, limiting its complexity. Its existence means I can use something more sane like Contour, but it&#x27;s built on common resources that Istio can understand nicely as well, if need be. So the overall advantage is that you can hop between implementations without having to relearn everything from scratch.My biggest frustration with the Gateway API is actually how extensions are developed: the spec just doesn&#x27;t (or didn&#x27;t last time I looked) touch timeouts other than just saying \"implementation defined\" because of the different ways that&#x27;s handled currently. To create extensions, just define your own custom resource that does whatever you want not currently covered by the spec. reply dilyevsky 11 hours agorootparentThere is experimental support for basic http timeouts now - https:&#x2F;&#x2F;gateway-api.sigs.k8s.io&#x2F;geps&#x2F;gep-1742&#x2F;#api reply pjmlp 9 hours agorootparentprevI can&#x27;t ever debug anything on Istio, it is like playing around with configurations hoping to finally sort it out, usually takes a couple of hours to sort every issue. reply kbumsik 15 hours agoparentprevIstio and other popular tools has implemented its own gateway APIs because of the limits of Ingress API.So the the new Gateway API seem to support more use cases so the user can use a more portable API.Istio and many other tools already supports this: https:&#x2F;&#x2F;gateway-api.sigs.k8s.io&#x2F;implementations&#x2F;#implementat... reply denkmoon 8 hours agoprevevery day, kubernetes strays further from god&#x27;s light reply sheepo39 15 hours agoprev [–] I hate when open source projects (especially common in the Kube-sphere I feel) adopt these super buzzwordy roles in their announcements. reply kbumsik 15 hours agoparent [–] What is super buzzwordy to you? reply benatkin 12 hours agorootparent [–] API Gateway is a bit of a buzzword. I think part of it&#x27;s because of Amazon API Gateway. People like to imagine they&#x27;re recreating big parts of AWS, and a lot of Amazon&#x27;s other products have names that are trademarked or are clunky to use. reply theossuary 12 hours agorootparentI mean, the title says Gateway API, because it&#x27;s literally about an API named Gateway. Idk how you avoid it. reply benatkin 12 hours agorootparentThe text repeats it a lot. Maybe more than it should. Also GatewayClasses. It’s nitpicky, but I’m trying to understand OP’s comment. reply jpgvm 11 hours agorootparentThe Kubernetes API is structured as \"resources\". (I&#x27;m oversimplifying but it&#x27;s OK for what we are going to explain here).In this case. Gateway is merely a new resource type introduced to replace the aging and inadequate Ingress resource. GatewayClass was introduced alongside it as a way for the infrastructure providers to define essentially a \"template\" for how Gateways can be created that are tied back to a specific implementation.This is similar to how StorageClass and PersistentVolume (two other resources) already work for defining block storage in Kubernetes.This isn&#x27;t buzzword soup and the original commenter just has no clue what they are talking about so there isn&#x27;t any point in defending their potential point because there isn&#x27;t one there. The text repeats these terms a lot because they are what are being discussed, as in -concrete- things. Not buzzwords.FWIW I hate buzzwords, marketing and pretty much everything else of that ilk. Talk is cheap, show me the code. In this case, this is the code. reply benatkin 10 hours agorootparentI understand what GatewayClass means and still think it could have been repeated less. I didn&#x27;t say it was buzzword soup. I think it&#x27;s good but I wouldn&#x27;t want this to become the prevailing style.This paragraph:> Subsequently, cluster operators utilize these GatewayClasses to deploy gateways. A Gateway in Kubernetes&#x27; Gateway API defines how external traffic can be directed to Services within the cluster, essentially bridging non-Kubernetes sources to Kubernetes-aware destinations. It represents a request for a load balancer configuration aligned with a GatewayClass’ specification. The Gateway spec may not be exhaustive as some details can be supplied by the GatewayClass controller, ensuring portability. Additionally, a Gateway can be linked to multiple Route references to channel specific traffic subsets to designated services. reply misnome 9 hours agorootparentUnfortunately, in terms of Kubernetes this is written pretty clearly about what it’s doing and how it interacts with other parts. reply jpgvm 9 hours agorootparentprevWell it&#x27;s the subject of the vast majority of the sentences. I fail to see how you can write this information in a way that doesn&#x27;t use it multiple times without going out of your way to imply the subject instead of just stating it clearly as is done here. replyzx8080 9 hours agorootparentprevIt&#x27;s OK, but almost impossible to search.At least when using Google search where double-quotas seem to be not always understood as the \"required term\" anymore. reply Foobar8568 9 hours agorootparentprev [–] Especially that API Gateway used to encompass several more services provided by middlewares than the rather limited AWS one. reply Foobar8568 5 hours agorootparent [–] Since I got downvoted, anyone could explain what is incorrect with my statement? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Kubernetes blog introduced \"ingress2gateway,\" a tool that aids the transition from Ingress to the more functional and flexible Gateway API for managing external service access in Kubernetes clusters.",
      "The blog dispersed the advantages of Gateway API over Ingress - its role-oriented strategy, portability, expressiveness, and expansibility.",
      "It also provided a tutorial on installing and utilizing ingress2gateway for migrating. The blog concluded by acknowledging the continuous development of Gateway API and the community backing it."
    ],
    "commentSummary": [
      "Kubernetes has unveiled the ingress2gateway tool as part of the preparations for the General Availability (GA) of the Gateway API, aimed at making the usage of the API easier for DevOps and SRE professionals.",
      "The tool, developed by Kong - a known provider of Ingress, supports both Ingress and Gateway API providing a seamless transition between the two.",
      "The move is due to limitations encountered with Ingress API in handling advanced features such as query string routing and weighted load balancing, believed to be addressed by the Gateway API."
    ],
    "points": 142,
    "commentCount": 31,
    "retryCount": 0,
    "time": 1698610474
  },
  {
    "id": 38062649,
    "title": "Migrating our backend from Vercel to Fly.io",
    "originLink": "https://www.openstatus.dev/blog/migration-backend-from-vercel-to-fly",
    "originBody": "OpenStatus Blog Changelog Docs Sign Up Back Why we migrated our backend from Vercel to Fly.io and the challenges we faced. TD Thibault Le Ouay Ducasse Oct 29, 2023•4 min read In this article, we are going to see the reasons that made us change our backend to Fly.io and the challenges we had during the migrations. We chose Hono as our API server with Bun as the runtime and picked Fly.io as our hosting service. 🤔 Why did we want to move our backend from Vercel? ⚡ A lightweight Server We required a lightweight server with a simple REST API for our monitoring endpoint. Deploying a simple Express server is possible, but it is not specifically designed for this purpose. It's possible to deploy an Express.js application as a single Serverless Function, but it comes with drawbacks and should only be used as a migration path. Instead, use Next.js or embrace multiple Serverless Functions as you incrementally migrate to the Vercel platform. Source Vercel Doc Also launching a clean and new Next.js server takes 2.5 seconds on my MacBook Pro M1 and takes 110mb of RAM, and it includes unnecessary extra features from Next.js. Our prod Next.js app takes about 5 seconds to launch on my computer (contentlayer). For comparaison launching our current server takes 0.19ms and only takes 91mb. Our current server stack is Hono + Bun. 💸 Pricing We initially aimed to provide multi-region monitoring for all users while maintaining a free tier. On Vercel, if you want a multi-region function, you need to opt for Edge Functions. Edge functions are cost-effective as you only pay for the actual CPU execution. This means that you won't be billed for idle times when fetching data. It's still affordable, but we are a bootstrap business and it difficult for us to predict our monthly expenses. If we experience an increase in new users, our costs will also increase accordingly. Here's the math for the cost of one monitor for a user: 6 (10 min monitors) * 24 * 30 * 3 (average execution unit per monitor) * 6 (number of regions) = 77,760 executions units per month 77,600 * (2/1,000,000) = 0.15c per monitor monthly We have over 1000 monitors, and the monthly cost to run them would be $150. While on fly we only have 6 servers with 2vcpu/512Mb It cost us $23.34 monthly ($3.89*6). 🤯 What challenges did we face during our migrations? Docker + monorepo = 🪨 We are deploying to fly.io. We have to setup our app as a Docker image. Our apps is in a monorepo. Our initial image was over 2 GB in size, which was excessively large for a basic server. Our image included everything, which was inefficient. After optimizing, our image now occupies only 700MB. Although it is still somewhat large, it is a significant improvement over our initial version. It was something we never had to manage with Vercel deployment. ⏳ Fly deployment timed Our Fly deployments have been experiencing frequent timeouts without any specific reason. The only solution we have discovered is to increase the timeout duration. flyctl deploy --wait-timeout=500 Based on our experience, Fly deployments are generally less reliable compared (more timed out) to Vercel deployments. Additionally, we have not discovered a quick method to rollback to the previous version. 🐛 The Bun bug When we migrated to Fly, we decided to use Bun as our runtime. However, in the first few hours after the migration, we observed an unexplained increase in request failures. After digging into the Bun GitHub we found a solution: We needed to set the keepalive parameter to false. This is necessary because closed connections are not automatically removed and remain in the CLOSE_WAIT state. Here's the GitHub issue: https://github.com/oven-sh/bun/issues/3327 I wish it had been documented elsewhere. Our conclusion We are pleased with our migration to Fly.io, although it was accompanied by a challenging weekend. And we still love Vercel, they offer a super product, it removes a lot of pain for the developers. However, if you require a hosting an application other than Next.js, it may not be the best option. We are still using it for our frontend. Create an account on OpenStatus to start monitoring our website and managing your incidents for free. Operational Community GitHub Discord X Resources Blog Changelog Docs OSS Friends Legal Terms Privacy",
    "commentLink": "https://news.ycombinator.com/item?id=38062649",
    "commentBody": "Migrating our backend from Vercel to Fly.ioHacker NewspastloginMigrating our backend from Vercel to Fly.io (openstatus.dev) 139 points by Hooopo 20 hours ago| hidepastfavorite146 comments steve_adams_86 18 hours agoUnreliable deployments are my experience as well. I also encountered unexpected and unannounced downtimes surprisingly often.I was excited about fly, but ended up sticking with digitalocean. I have only had one issue with deployment reliability there (when they changed their build tooling for Python applications on the apps platform), but they responded quickly with a fix and shortly after announced the change and potential issues to all customers. Fly is not like this, and as a hobbyist I don’t have the time or energy to deal with their platform’s issues. I’d rather pay for something I can depend on. DO has been amazing in that regard, and their tooling is excellent.I’ve used vercel in a professional context and wouldn’t use it for personal work. The markup is crazy and the tooling isn’t appealing enough to justify the cost. This is definitely a subjective matter as opposed to reliability and communication which are objectively necessary. Vercel just “rubs me the wrong way”, and I’m sure many people here love it. reply danpalmer 17 hours agoparentAt my last place we ran into a number of issues with using DO in production. It was fine for dev machines, testing, etc, but we had production downtime due to DO&#x27;s networking setup, and support were unable to understand the problem, let alone fix it.Quick summary: we backed up our other prod hosting to DO over SSH. One day our backups went offline, DO claimed this was because of a DDoS attack, but our backups were working fine and there were no noticeable effects. Only one port was open, SSH, and we had great security on it. Support re-enabled networking for the host, backups resumed, then the next day the same thing happened again. We told them not to do this, and they said they could not, and that we should \"put Cloudflare in front of it\", completely missing how that was not possible or useful for our case, and missing the fact that we were not having any problems other than DO disabling networking. reply solarkraft 17 hours agorootparentThat level of uselessness is impressive. They must&#x27;ve trained on Microsoft&#x27;s forum. reply corobo 5 hours agoparentprevI really want to love Fly (for some reason? Maybe I&#x27;ve succumbed to the darling effect? Idk, their tech is cool in any case)But yeah, failing deployments and the weirdness around persistent storage (if my VM starts up on another physical host my data just no longer exists) I can&#x27;t use them. I&#x27;d be doing the same amount of systems work as I would anywhere bespoke, with less ability to fix any issues that come upThis is fine for the app part, 12 factor and all that, but I don&#x27;t want a database relying on it.Really hope they fix these two issues somehow, I&#x27;ve had to learn kubernetes instead lmao (I was going to get round to it anyway in all fairness) reply Lucasoato 17 hours agoprevI really don’t understand how people can trust platforms like Vercel, Fly.io over robust could providers like Cloudflare, AWS or Azure.I mean, Vercel has its usefulness, it’s so well integrated with the NextJS stack, it totally makes sense for small amateurish projects since it saves you time and money… but once you want to push to production, have real customers and satisfy them reliably, these platforms can’t compete with the big ones. reply oefrha 16 hours agoparentThis is what happens when you do HN-frontpage-driven development. I mean, they use Bun (which I’m sure will be great in a couple years’ time) and quickly ran into an fd leak in it. Does that sound like a production grade runtime?However, I suppose it’s good for content marketing. You’re not going to make front page by choosing boring old technology (unless you’re migrating back to boring old technology after failed HN-frontpage-driven development). reply ushakov 16 hours agorootparentTheir stack speaks for itself:Next.js, TailwindCSS, shadcn&#x2F;ui, tinybird, turso, drizzle, clerk, ResendThat’s for an app which sends a ping to a URL every x minutes… reply hipadev23 14 hours agorootparent> That’s for an app which sends a ping to a URL every x minutes…My bigger question is: How the fuck do these companies keep getting created? There&#x27;s gotta be more uptime-monitor SaaS companies than todo MVC demos in existence. reply tmikaeld 11 hours agorootparentIt’s easy to get the free users, where of just a smaller % need to upgrade to keep you afloat. Then there’s the possibility to upsell other related services like analytics or logs.Betterstack did this very well. reply ushakov 7 hours agorootparent> a smaller % need to upgrade to keep you afloatUntil yet another free competitor comes along. Then you&#x27;re out of business reply ushakov 7 hours agorootparentprevBecause these people are bad businessmen. There is not a single reason yet another uptime monitoring business needs to exist. They have no chance at succeeding the likes of Datadog, New Relic.Conclusion: promising builders being bad at startups reply rozenmd 2 hours agorootparentWho says they have to reach Datadog&#x2F;New Relic scale to \"succeed\"? replydboreham 17 hours agoparentprev> I really don’t understand how people can trust platforms like VercelIt&#x27;s not an apples to apples choice. The people who use Vercel don&#x27;t know anything about how to deploy on AWS. That&#x27;s the whole point of Vercel. Whether or not they can be trusted is really orthogonal to the reason they were selected as a provider. But that said, they&#x27;re just a layer over AWS so why should they be significantly less trustworthy? I haven&#x27;t used Vercel in production, but I have used a similar \"layer over AWS\" service (Aptible). The problem where wasn&#x27;t to do with QoS or support, but rather that the narrowing of the functionality of the \"interface\" (which is pretty much the point) ends up causing frustration when you want to integrate with other stuff you&#x27;re doing in AWS. reply Swizec 16 hours agorootparent> The people who use Vercel don&#x27;t know anything about how to deploy on AWSEhhhh. I’ve been deploying to AWS professionally for years and I’d choose Vercel for a personal project any day of the week.Life’s too short to play devops&#x2F;sysadmin&#x2F;sre without someone paying you the big bucks. reply bingemaker 15 hours agorootparentThis. Anyone who has done enough ops knows that a platform (Vercel, Heroku, Netlify etc) which lets devs connect a git repo with a couple of clicks, and deploys automatically happen is a good devops experience.This is great for personal projects. This is great for budding projects in a professional setup as well. reply Swizec 15 hours agorootparentIf I never again have to write a httpd.conf or nginx.conf file from scratch it will be too soon. reply OJFord 15 hours agorootparentEither you mean &#x27;too late&#x27; or that&#x27;s a complicated way of making a dissenting point? reply Swizec 15 hours agorootparentIt’s an idiom that means I never want to do this again. Even if I waited an infinite amount of time, it would still be too soon to have to write httpd.conf or nginx.conf files again.https:&#x2F;&#x2F;hinative.com&#x2F;questions&#x2F;337452 reply OJFord 12 hours agorootparentI&#x27;m a native English speaker, I&#x27;m well aware of the (misused here) idiom.You could also have said &#x27;ever&#x27; instead of &#x27;never&#x27;, that would be a simpler and better fix on re-reading. reply OJFord 1 hour agorootparentHuh, what was I smoking? I don&#x27;t even smoke. That&#x27;s not right, don&#x27;t know what I was thinking, sorry! replyelforce002 15 hours agorootparentprevThis x100. I use gcp, DO, and Vultr, for almost everything (ml, be, vas, etc.) but for webapps, vercel wins 9&#x2F;10 times. reply elliotec 17 hours agoparentprevVercel is great for pre-prod ethereal environments for testing and CI. But they desperately want to sell you their enterprise stack which is completely inadequate, and will drag their feet for months if you just want to sign the damn “pro” version. reply crooked-v 17 hours agorootparentAlso, simple stuff like bandwidth is wildly overpriced with Vercel. My company switched away from all their magic image resizing stuff because as our traffic increased the bandwidth was 10x that of doing all media content through Prismic. reply judge2020 17 hours agorootparentVercel is hosted on AWS, and they&#x27;re definitely not in the business of subsidizing AWS per-GB costs. Although the >2x markup is egregious ($40&#x2F;100gb aka $0.40&#x2F;gb over 1tb, versus AWS&#x27; $0.15&#x2F;gb in its most expensive region, Sao Paulo, Brazil). reply teddyh 15 hours agoparentprevSome people avoid large providers, since large providers have approximately no incentive whatsoever to keep you, specifically, as a customer. I.e. large providers will happily raise their prices, alter the deal, throw you under the bus, disable your account, delete all you data and then refuse to talk to you. They can do this because, when they look at the big picture, you don’t matter to them. And since doing this saves them some money, they all do it. reply kunley 7 hours agorootparentRight. Plus, large providers usually don&#x27;t offer support for small-sized instances&#x2F;containers&#x2F;whatever, so even if you optimized your deployment to use less resources, you need to buy a bigger thing.But to the main point: using an extra layer which is on the top of said large provider, like here Vercel over AWS, is not a solution, as this middle man also can be marginalized by the big bully at some moment.This is why I prefer small providers, like Vultr. (Not affiliated with them in any way; just a happy customer). reply MuteXR 15 hours agorootparentprevAnd a small service can go under anytime, without any real warning.Most big providers end up being cheaper for you as well. Vercel is insanely expensive. reply teddyh 12 hours agorootparent> And a small service can go under anytime, without any real warning.Both large and small providers could make the ground from under your feet disappear, in different ways. But only the small provider has a real incentive to actually keep you, as just one customer. It’s only when a small provider goes out of business completely that you have any risk. And that’s unlikely to happen, unless they’re delusional or funded by squirrel-minded VCs – which are things you can determine beforehand. reply junon 17 hours agoparentprevI worked at ZEIT (before it became Vercel) and if they&#x27;ve retained even a 10th of their engineering culture then they&#x27;re solid, if not a bit \"niche\" in what and who they target.Anecdotal, sure, but it&#x27;d be hard to quantify it. reply reducesuffering 16 hours agorootparentIt’s funny how frontend has a stigma of less serious engineering when the caliber of programming being done at Vercel is far beyond the level of inadequacy I’ve seen being in big tech FAANG eng departments. reply KRAKRISMOTT 16 hours agorootparentModern day frontend is ridiculously complex. Back in the day, the only compilers that tried to do code splitting and optimization across network boundaries were ASP.NET WebForms and similar. They were dreadfully simplistic compared to the SSR+ react-streaming-over-the-wire that Vercel is doing. Don&#x27;t get me wrong, the React compiler written in Rust is leagues ahead of the slow tech in for example the angular world, but it is also magnitudes more complex.I see this as a side effect of developing economies in the world coming online. When you have to service millions in places with poor network and provide a competitive UX, you don&#x27;t have the luxury of going with \"simple\" solutions. reply arcanemachiner 16 hours agorootparentprevI think this comment is intended as a compliment to Vercel, but it&#x27;s hard to tell from the wording. reply reducesuffering 16 hours agorootparentApologies. Yes, big tech == overrated, Vercel tech == underrated reply OJFord 15 hours agorootparentIt&#x27;s &#x27;beyond the level of inadequacy&#x27; which is amusingly ambiguous! reply globalise83 10 hours agorootparentThey reliably exceed 99.99% inadequacy overachievement - there, made it less ambiguous for you. reply meiraleal 15 hours agorootparentprev&#x27;use server&#x27;sql(\"select * from db\");This is what Vercel is pushing into React code. The caliber of their work is low, very low. They are con masters with MBAs reply junon 14 hours agorootparentThey are objectively not that, lol. If you don&#x27;t like what they&#x27;re doing I understand but please don&#x27;t disrespect people you don&#x27;t know. reply meiraleal 14 hours agorootparentThat&#x27;s what you get for working in a famous company that took over an open source software.If the destruction of React by Vercel paid your bills and you feel disrespected by my total despise for this get rich fast schema (a la crypto rugpulls), that&#x27;s a problem for you to solve, not me.Edit: but in reality I&#x27;m happy and thankful to Vercel for imploding React, it helped me to finally check that there are so many better options nowadays. reply junon 13 hours agorootparentHow did Vercel \"destroy\" React? How are they a \"get rich quick\" \"rugpull\"?Respectfully, you have no idea what you&#x27;re talking about. reply aurareturn 11 hours agorootparentprevI started using Next.js in 2017. It made React a real production framework. Prior to Next.js, React was hard to setup and maintain and hard to make it go fast (on first load). Next.js solved the worst React problems.I don&#x27;t think it ruined React at all. I think it helped React gain in popularity - which you might interpret as \"destruction\". reply meiraleal 5 hours agorootparent> Prior to Next.js, React was hard to setup and maintainNo, it wasn&#x27;t. Now it is an engineering process.> I started using Next.js in 2017. It made React a real production frameworkIn 2017 I had React projects in production for years.> React was hard to setup and maintain and hard to make it go fast (on first load)And it only got worse and the overengineering to make it looks fast in the first load is not worth it as modern JS frameworks are faster than React out-of-the-box.> I don&#x27;t think it ruined React at all. I think it helped React gain in popularityThat&#x27;s not what stackoverflow&#x27;s Insights says[0]. Looks like a free fall for me.0. https:&#x2F;&#x2F;insights.stackoverflow.com&#x2F;trends?tags=reactjs reply junon 2 hours agorootparent> In 2017 I had React projects in production for years.I doubt that. React wasn&#x27;t stable until 2015, and wasn&#x27;t mainstream until 2016.> And it only got worse and the overengineering to make it looks fast in the first load is not worth it as modern JS frameworks are faster than React out-of-the-box.Again, Next.js != React; the former builds on the latter, it doesn&#x27;t replace it nor does it claim to be the same thing. I&#x27;m not sure why you keep conflating the two.> That&#x27;s not what stackoverflow&#x27;s Insights says[0]. Looks like a free fall for me.Perhaps you shouldn&#x27;t bury the lede here. I&#x27;m also not entirely sure what your argument is, or why you hold such strong emotions without making your opinions very clear.https:&#x2F;&#x2F;insights.stackoverflow.com&#x2F;trends?tags=reactjs%2Cnex... reply meiraleal 1 hour agorootparent> I doubt that. React wasn&#x27;t stable until 2015, and wasn&#x27;t mainstream until 2016.I started using React before its 1.0 version. Your reasoning is exactly what&#x27;s wrong with Vercel. Arrogant inexperienced people that think they know better, empowered by VC money. Together with some idealization of being the smartest people around makes you come with solutions like \"use server\" and throw tantrums when people say this is stupid for a frontend library.> Again, Next.js != React; the former builds on the latter, it doesn&#x27;t replace it nor does it claim to be the same thing. I&#x27;m not sure why you keep conflating the two.It is okay if you can&#x27;t understand what I&#x27;m saying, it is difficult to get a man to understand something, when his salary depends upon his not understanding it. I also don&#x27;t expect you to agree that the work you did contributed to an open source take-over for the sake of profit.Edit: I just did a research to see if Meta is adopting the amazing \"use server\" and no public information is available, only people discussing that they aren&#x27;t. That says a lot about the applicability of this feature and the direction React is being leaded to. reply aurareturn 1 hour agorootparentI was a tech lead and managed a massive project (multiple billions of page views per year) that did a complete rewrite with React in 2014-2015.React was complete shit back then - especially the first load speed. It was not ready for \"real\" production. We basically built an internal framework on top of React for things like server side rendering (which no one did with React back then), above the fold loading optimization, developer experience, devOps on top of React. We basically built Next.js internally.So no. It was not production ready for real performance-based websites. Next.js made it significantly better as soon as it came out. reply meiraleal 54 minutes agorootparentReact was a terrible idea for a static page in 2014-2015 and is still a terrible idea for a static SSR page + hydration in 2023. React back in 2014 was devised to be a performant way to create SPAs. Of course it wouldn&#x27;t be good to use it as if it was PHP. It is still a bad idea. replyreducesuffering 12 hours agorootparentprevDan Abramov, de facto lead for React, said that the React team was driving the vision behind the new features in React. Vercel just said, \"how can we help? You guys think server components are great, ok, we&#x27;ll make them first class as that&#x27;s where the React ecosystem is headed.\"Vercel is doing nothing but trying to improve DX for all the things people complain about React. reply refulgentis 15 hours agorootparentprevThat&#x27;s awesome work. You don&#x27;t like it for aesthetic reasons, pre-conceptions of aesthetic purity. That&#x27;s fine too and I think I agree. But it&#x27;s awesome work. reply meiraleal 15 hours agorootparentGo ahead. It is all yours, awesome work is simple work. Vercel wants React to do everything so they can sell everything. Not to me. That was a sad takeover of an open source project tho reply Rapzid 15 hours agorootparentI like to joke that because Vercel doesn&#x27;t make money when you run components in the client, and React is now made for Vercel, that React is now developed for backends.I&#x27;m a big fan of OSS projects being sponsored by companies that use them for a higher level business. Vs a ton of the C# ecosystem where they try to sell you the library&#x2F;framework.But hosting businesses ain&#x27;t it when it comes to frameworks.. It creates weird incentives. replymattnewton 16 hours agoparentprevPlenty of people end up building vercel-but-worse out of CI pipelines on aws or similar, doesn’t strike me as crazy to keep using it well past the prototype stage for projects that for its constraints. reply pjmlp 9 hours agoparentprevSeveral SaaS companies are pushing for Next.js as their main SDK, that is how real customers end up in Vercel. reply infecto 16 hours agoparentprevWhats the use case for edge computing like Fly.io. I have yet to figure it out the use case where a edge provider is necessary. That is, having a database on the edge. reply simonw 16 hours agorootparentHaving customers in places around the world. If you site is hosted in North Virginia, and you have customers in Australia, they are going to really suffer from the speed of light. reply infecto 5 hours agorootparentDefinitely. I guess where my ignorance comes in, from an engineering perspective is the way fly.io thinks about edge databases more difficult to architect than a more traditional route creating a subdomain for a region and just replicating your entire infrastructure in a newregion?I guess you can setup the same kind of structure inside of fly.io but I remember some of their writeups have been talking about deployment and pushing the DB to the edge and then having eventual consistency across?I think that is my hangup on use cases. reply ushakov 16 hours agorootparentprevThat’s very rare though. Unless you’re Shopify, location doesn’t really matter reply x0x0 15 hours agorootparentCommon enough to have a couple customers in the EU or apac who consistently complain that your site is glacial and it turns out to be pretty bad for them... reply maxbond 16 hours agorootparentprevYou could have your realtime competitive FPS game like Call of Duty host the data and compute necessary to run a match as close to the median location of all the players involved as possible to reduce latency. You could make the same case for something like Zoom or a collaborative editing tool. reply x0x0 15 hours agorootparentprevLots of us (well, me at least) use fly because it&#x27;s a bundled set of aws best practices that I could configure in aws if I wanted to, but I&#x27;d waste another week of my life. alb + various vpcs + autoscaling group + fargate + ecs + their super shitty vpn service to vpn to a console + rds + elasticache or... just type \"fly deploy\" and go from zero to live in 20 minutes.That said, fly&#x27;s deploys are flaky. I hope they get it fixed because the rest of the service is pretty good. reply infecto 5 hours agorootparentThe first part is good to hear. And the last part is the only reason I have not consistently used them. As an aside, I have started to use chatgpt heavily for aws questions and walkthroughs. Have been using ECS heavily and this has been super helpful for me to get through what I consider the hardbits, non-obvious permissions and configurations that aws that does tell you about but is buried in the documentation for a json like configuration object. reply intelVISA 15 hours agoparentprevThe only platform you can truly trust is the one you handcraft down to the NAND gates. reply preciousoo 12 hours agorootparentIf you’re not mining your lithium and cobalt with your own handmade pickaxe you’re doing it wrong reply paradox460 8 hours agorootparentIf you don&#x27;t have your own star spitting out bespoke elements, are you really doing it at all, or just using someone else&#x27;s work reply leerob 17 hours agoparentprevEdit: Nevermind, wrong thread. Vercel does honor DCMA, of course, though. reply jiayo 17 hours agorootparentYou work at Vercel. Are you saying Vercel does not honour DMCA takedown requests and that is a selling point of using Vercel? This seems like a strange thing to brag about. reply DaiPlusPlus 17 hours agorootparent> This seems like a strange thing to brag about.Not to me, it isn&#x27;t.There are plenty of areas-of-interest that attract both hobbyists and serious academics alike - which also tends to attract unwanted attention from callous legal departments who are keep to adopt a shoot-first-ask-questions-later policy - things like (lawful) research into DRM techniques, retro video-games (and not ROM hosting), infosec disclosures, and so on - so if you&#x27;re really into those areas and want a safe place for your lawful content but without worrying about your site&#x2F;content&#x2F;services being taken-down without good cause then it makes sense to side with a provider who is able to resist DMCA requests. reply rozenmd 17 hours agoprevMy uptime monitoring business made a similar migration (AWS Lambda to fly.io), and I ended up rolling it back a few months later.I wrote more about the move to fly.io here: https:&#x2F;&#x2F;onlineornot.com&#x2F;on-moving-million-uptime-checks-onto...and (part of) the move back to AWS here: https:&#x2F;&#x2F;onlineornot.com&#x2F;scaling-aws-lambda-postgres-to-thous...Edit: forgot that second link doesn&#x27;t actually explain that I moved off fly.io, will write a follow-up. reply rjh29 18 hours agoprev> Edge functions are cost-effective as you only pay for the actual CPU execution.> We have over 1000 monitors, and the monthly cost to run them would be $150.> While on fly we only have 6 servers with 2vcpu&#x2F;512Mb It cost us $23.34 monthly ($3.89*6).So edge functions are in no way cost-effective right? People using lambda functions are getting ripped off, they could just buy a couple of VPS. reply maccard 17 hours agoparent> People using lambda functions are getting ripped off, they could just buy a couple of VPS.A non-zero amount of our CICD pipelines are \"perform API call with secret pulled from SSM&#x2F;Secrets Manager\". They happen 1-2 times per day and take less than a 5 seconds to run on each invocation. We currently have a burstable EC2 instance running 24&#x2F;7 to handle these which costs us ~$5&#x2F;mo. My napkin math says that this would cost us ~$0.01&#x2F;month to run these as lambdas. More to the point though, we&#x27;re limited in concurrency on these. It&#x27;s pretty common that they all get triggered at the same time, it would be ideal if we could allow for an \"unlimited\" number of these to run. This sort of workload would be great to run for lambda functions, the engineering cost of implementing it just doesn&#x27;t ever make sense.If we paid someone $150&#x2F;hour to spend half a day on it, right now our break even point is probably 5 years... reply SOLAR_FIELDS 17 hours agorootparentAlso, if you implement it as lambdas, your solution is now less portable. Your EC2 instance can probably be ported to something else easier than some lambda solution. reply bastawhiz 16 hours agorootparentThis is objectively false. In fact, it&#x27;s the opposite of true. Lambda forces you to have a single entry point to your code that passes the details of a request to your application in a structured way. Wrap that in the http server of your choice in about fifty lines of code and you&#x27;re done.Or, you use something like Express inside Lambda with Serverless and adapting it to a long running server is literally just deleting the fifty lines of code that export your lambda handler. It couldn&#x27;t be more simple.Which is to say, you&#x27;ll almost always have more trouble going from something else to Lambda and not the other way. reply nicoburns 16 hours agorootparent> Wrap that in the http server of your choice in about fifty lines of code and you&#x27;re done. > Or, you use something like Express inside Lambda with Serverless and adapting it to a long running server is literally just deleting the fifty lines of code that export your lambda handler. It couldn&#x27;t be more simple....which is all extra setup that you need to do compared to if you weren&#x27;t using lambda, in which case you&#x27;d already be set up using something like express. To be fair, it doesn&#x27;t like it&#x27;d be too much work to do the conversion. But it would still be extra work compared to say moving something running on express and deployed in a container to another VPS and&#x2F;or container hosting provider which would likely require no application changes at all. reply bastawhiz 15 hours agorootparentThere are services that offer compatible APIs to Lambda, in which case there&#x27;s also no effort.You could be switching from an integrated http server to using WSGI, which is almost identical to the effort I described. Who cares about the twenty minutes of work? It&#x27;s \"less portable\" in such a trivial way. reply maxbond 16 hours agorootparentprev> This is objectively false. In fact, it&#x27;s the opposite of true.I apologize for the tangent but in your mind, is false sometimes but not always the opposite of true? Or is this just emphasis? (Genuinely asking, not being snarky.)ETA: Thanks for clarifying. reply bastawhiz 16 hours agorootparentSomething being wrong does not mean it is the exact opposite of what is the truth. reply maccard 8 hours agorootparentprevThat&#x27;s for abstractions to take care of. If my CI platform offers a lambda runner instead of an ec2 integration, I would use it in a heartbeat.Also, it&#x27;s a 5 line shell script that already depends on 2 AWS services (SSM and IAM) that makes an API call to a third AWS service (S3). It&#x27;s already locked to AWS reply intelVISA 15 hours agorootparentprevI&#x27;m guessing the original developer was only $50&#x2F;hr with a cheap, non-scaling setup like that. reply maccard 8 hours agorootparentI wrote it. It was a 50 line packerfile with a shell script that installs buildkite, docker, and the AWS cli, and hasn&#x27;t been touched in 2 years other than bumping version numbers. reply 616c 18 hours agoparentprevIf you&#x27;re bursty and only run 1000 invocations every few days or weeks and otherwise you run it 0 or 1 times per increment then you can end up spending a lot less than that estimated server cost with fly.io no? reply rjh29 17 hours agorootparentDefinitely there will be cases where it makes sense. But intuition would suggest if your servers are say 80% idle then serverless functions would be cheaper, but that isn&#x27;t actually the case. Cloud companies don&#x27;t incur much of a cost from a VPS either if it&#x27;s idle.My team noticed the same with AWS Aurora Serverless (a database), it was so expensive that it was easier to just run a normal instance of RDS. reply bastawhiz 17 hours agoparentprevIn what universe is the difference between $23&#x2F;mo and some amount less than that incomparable? That&#x27;s what? Two paid users worth of revenue? $23 per month is a rounding error. It&#x27;s one T-shirt. It&#x27;s the cost of a few minutes of your time. If you&#x27;re running a business and you&#x27;re worried about saving ones of dollars on hosting, you need to reconsider how you&#x27;re spending your time and how your business makes money. reply meiraleal 15 hours agorootparentunless you remove the need for said server then you save on reduced complexity&#x2F;maintenance which is money reply NicoJuicy 18 hours agoparentprevEdge functions are cost effective, the problem is that they are comparing from Vercel.Vercel is basically a dev friendly wrapper for tier 1 services: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35774730Eg. Vercel is 25x more expensive than eg. Cloudflare Workers. Raw guess would be that their 150$ bill would have become 6$.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37891412Eg. Image resizing> Vercel : 5$ &#x2F; 1000 requests> Cloudflare : 9$ &#x2F; 50.000 requestsEdit for comment below:That&#x27;s a blog post. I got my info from here:https:&#x2F;&#x2F;www.cloudflare.com&#x2F;plans&#x2F;See: image resizing> 50,000 monthly resizing requests included with Pro, Business. $9 per additional 50,000 resizing requests reply danpalmer 17 hours agorootparent$5 &#x2F; 1k requests... wow. That&#x27;s like, entirely unworkable for almost all use-cases surely?Even coming from a backend-heavy world where one request does a lot of work, that&#x27;s got to be an order of magnitude off the mark at least. If you go for a frontend-heavy setup where there are more smaller requests (in my experience, common, when using things like Lambda), this could be another order of magnitude off again! reply NicoJuicy 17 hours agorootparentSorry about that. The pricing was about Image Resizing requests ( updated my comment).On http requests itselve.Vercel is 2 $ per million requests. Cloudflare is 0,15$ per million requests.So Cloudflare in this case is > 13 x cheaper. reply shrubble 16 hours agorootparentprevAccording to this page at Cloudflare, their pricing is 50 cents per 1000, is that correct? Or is it a different product... https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;merging-images-and-image-resizin... reply NicoJuicy 10 hours agorootparent50,000 monthly resizing requests included with Pro, Business. $9 per additional 50,000 resizing requestshttps:&#x2F;&#x2F;www.cloudflare.com&#x2F;plans&#x2F; - section: image resizing reply junon 17 hours agorootparentprevWorkers are also free for the first 100k every month I believe. reply vlakreeh 16 hours agorootparentThe free tier gets 100k requests per day, not month. And then for $5 you get 10M or 1M free a month depending on your settings and then you get charged for additional usage. reply NicoJuicy 17 hours agorootparentprev10 million included per month.On the free plan, it&#x27;s 100 k. per day included - https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;workers-pricing-scale-to-zero&#x2F; reply junon 16 hours agorootparentOh, even better. Thanks :) reply calvinmorrison 18 hours agoparentprevBoth are free for business, reply robertlagrant 17 hours agoprevWhy is Fly apparently so unstable? I like many love the idea, but get a little scared by the many many anecdotes of issues.What are they doing that makes it unstable? Lots of new locations spinning up that shake bugs loose? Cost-reducing refactorings that reduce stability? reply urschrei 16 hours agoparent(Fly customer for the past 12 months: small web app (three machines across two regions plus replicated Postgres across two regions, on a paid plan)). Fly has been extremely stable for us, with the sole exception of deploys: once a month or so, deploys from CI start failing for a couple of hours. That doesn’t result in any downtime (I have never experienced any downtime due to a failing machine on Fly), just that new code doesn’t end up on prod until it’s fixed. If it’s urgent I email support (highly competent), or wait it out.I would describe myself as “extremely happy with the service, yet also annoyed by this aspect”. Fly allows me to manage my resources in a way that isn’t really possible elsewhere (from standard Python web apps in multi-hundred-mb containers to specialised Rust apps inI want to write some code and have it run and I don&#x27;t want or need to care about the details of how that happens as long as it works reliablyI&#x27;m sorry, this is an incredibly stupid take. You always \"need\" to care about the abstraction that your infrastructure is providing to you. Vercel also provides a abstraction in terms of serverless functions.>I want to write some code and have it run and I don&#x27;t want or need to care about the details of how that happens as long as it works reliably.Yeah, same. As long as it works, I have no problem. Now add background tasks or streaming responses or a cron job. Oh, guess what, you have to suddenly care about the options your provider is giving you, or go out and buy some stupid cron-as-service or ssh-as-service because you don&#x27;t have any control over your infrastructure. And now suddenly your infra is way more complicated than mine. I am still one that single dockerfile.>Being able to ssh into your server is giving you more tools to fix problems, sure, but mostly problems that you created for yourself by having a server in the first place.How is running a clean-up script anything to do with having a server? That is the most common use-case for ssh-ing into your server. In fact I am wracking my brains right now to come up with anytime I had a problem because of having a server and coming up short. Fly.io (or AWS, or GCP) has problems, for sure, but none of them are because I am running a server. reply lmm 16 hours agorootparent> You always \"need\" to care about the abstraction that your infrastructure is providing to you.Sure. But as long as it implements something reasonable, you don&#x27;t care about the details of how. \"Runs version x of this programming language\" is generally an easier abstraction to run business functionality on than \"it&#x27;s an x86-compatible computer\".> Now add background tasks or streaming responses or a cron job. Oh, guess what, you have to suddenly care about the options your provider is giving you, or go out and buy some stupid cron-as-service or ssh-as-service because you don&#x27;t have any control over your infrastructure.Cron is a terrible model for actually solving business problems with. Do you know what happens when a cron job fails to run&#x2F;errors out?Running your own unix system gives you a bunch of options that a higher-level abstraction doesn&#x27;t, sure. But those options are rarely worth the cost, IME. (And like I said, if you&#x27;re actually getting a unique value-add from running the whole server, then do it!)> And now suddenly your infra is way more complicated than mine. I am still one that single dockerfile.I guarante you that anything Docker-based is more complicated than what I&#x27;m doing. Docker is the worst kind of layer; it doesn&#x27;t provide a consistent abstraction of its own, you still have to know all the ins and outs of how the unix system it&#x27;s running on works, it just adds a whole bunch of extra concepts on top that you have to learn. And then sometimes breaks the usual rules of the platform it&#x27;s running on as well! (e.g. silently bypassing your iptables rules).> In fact I am wracking my brains right now to come up with anytime I had a problem because of having a server and coming up short.- Your program runtime crashing because of mismatched system library ABIs- A dependency you didn&#x27;t expect is suddenly available because it got installed by the base system- &#x2F;var filling up because of out of control logs or the like- Any other disk filling up for whatever reason- Log collectors going AWOL- Directory traversal order differing because two servers are using different filesystems- Upgrade changed the network management commands and now all your traffic is being blocked- Buggy RAID controllers- Thermal throttling kicking in when it shouldn&#x27;t because of a broken temperature sensor- Power outagesAll this stuff still needs to be fixed, but it&#x27;s great to have it be someone else&#x27;s problem and get on with your program. reply nicoburns 15 hours agorootparentThe big advantage of Docker based solutions is that they&#x27;re portable between providers. And you can ramp up the complexity as you need. Just need a language runtime? Then you can have a single-line Dockerfile. Need to support a native dependency? Then you might need to install it, but at least it will be possible to do that. reply lmm 15 hours agorootparentI can do all that with puppet without the extra complexity of containers. reply hntorpldisb 16 hours agorootparentprev> Cron is a terrible model for actually solving business problems with. Do you know what happens when a cron job fails to run&#x2F;errors out?Do lambdas not fail to run &#x2F; error out? I’m not following. reply lmm 15 hours agorootparent> Do lambdas not fail to run &#x2F; error out? I’m not following.You generally have some kind of monitoring&#x2F;alerting built in. With cron the usual behaviour is to email root@localhost using local sendmail, which generally achieves nothing except for filling up &#x2F;var. reply maxbond 16 hours agorootparentprevHere&#x27;s a thought experiment people may or may not find helpful. If you&#x27;re writing say a Flask app, what Flask is doing for you is routing a request to a function. That&#x27;s where the core kernel of value is; the rest of what&#x27;s going on is overhead you pay to wire your function up to what it needs, like a database connection pool and such.So if you were AWS and you saw everyone running an instance of Flask, you might think to yourself, I could run one really big instance of Flask that everyone could share, and the economies of scale would mean I could charge a cheaper price.And you as the software developer might think, well, I get paid to execute these functions, not to run Flask, so I might as well rent a spot in the big Flask. Then I won&#x27;t have to spend time updating and maintaining the framework, I can focus on writing my functions.This may or may not work out for a specific use case, eg maybe that database connection pooler that we threw out was load bearing and moving to serverless overwhelms our database or causes us to spin up more database servers and costs more money. YMMV. reply aurareturn 11 hours agoprevI&#x27;ve tried Fly.io probably 3 times. I&#x27;ve never gotten a simple Node.js project to deploy correctly. Meanwhile, I deployed the same projects to DigitalOcean and Render without a single change successfully every time. reply tehlike 13 hours agoprevNext up: Migrating to Hetzner. reply kavaruka 17 hours agoprevI would be curious to know the performance using node.js as runtime, given that at the moment there is no evidence that bun on a real application offers better performance reply konaraddi 13 hours agoprev> Additionally, we have not discovered a quick method to rollback to the previous versionI feel like this should be a high priority. Deployments should be quickly reversible so that a livesite caused by a bad deployment can be mitigated quickly. reply mvdtnz 16 hours agoprevFrom one toy to another. reply reducesuffering 15 hours agoparentAre Adobe, Splunk, Washington Post, Netflix, Zapier, Notion, and Uber toys? Because they&#x27;re running on Vercel infra. reply ies7 14 hours agorootparentIts not about vercel or fly.io. Its about openstatus devTheir migration timeline from their blog:1. August 2, 48 hours after public launch 400+ users2. August 20, migrate from planetscale to turso (sqlite)3. Oct 29, migrate from vercel to fly.io, migrate from nextjs to hono, also mentioned change to bunjs.This is seems like they tend to (sorry I&#x27;m judging here):1. move fast break things or2. don&#x27;t have a plan before launch day or3. only chasing the latest tech buzz. reply tibozaurus 8 hours agorootparentWe are trying, breaking and learning.And you were right we did not have plan before launch, we wanted to build something that bring us excitement. and we are planing more about the future, since the project took offFYI we still both have full time job reply ies7 4 hours agorootparentSorry for the harsh words.Obviously I can&#x27;t speak about excitement but if you&#x27;re worried about cost, you might want to research aws grant or things like that.In 2019 my company invest in a startup, while doing IT due diligence I found out they get $100K AWS grant to be used for 2 years. Fyi this company business is writing articles about baby and almost no revenue at that time. replyschneems 16 hours agoprevI’m curious if you looked at Heroku (I work there). You mention functions (which we don’t support), also servers (which we definitely support). I’m curious if that’s it or there was more to the decision. reply drwl 16 hours agoparentI’m a bit out of the loop but I thought heroku died or is languishing under Salesforce. That’s my current perception of everything and no longer see it recommended in HN threads. Hopefully this does not come off as an attack (it’s not). reply brundolf 15 hours agorootparentIt never stopped working, it just... stopped. More of an omen than a practical issue (so far) reply antod 12 hours agorootparentThat&#x27;s a good way of describing it. Another issue is they&#x27;ve locked a whole lot of useful (practically required these days) features behind requiring an enterprise account - the trouble is that \"enterprise\" isn&#x27;t just paying a whole lot more (if only). Enterprise involves getting involved in Salesforce style opaque fixed priced annual paid upfront contracts etc. It&#x27;s just not a cloud provider any more at that point - you know the whole elastic thing the cloud was supposed to do. reply animal_spirits 16 hours agorootparentprevI&#x27;m currently using Heroku for a small business app, and it is working wonderfully for me reply ebcase 13 hours agorootparentprevWe’ve run Domainr on Heroku for over a decade, and it’s been rock solid all along. reply preciousoo 12 hours agoparentprevI discovered fly because I made an heroku account, connected the wrong card (I’m a broke college student), and heroku told me I couldn’t change the card for the next 30 days. This was all within 5 mins of making my account. I couldn’t find a support avenues.I tried many clever workarounds but their alt-account defector is top notch (props to that team).Asked around in dev circles and they recommended me fly io.Idk who hurt heroku for them to put such measures in place but I’ve never encountered such strict policies before, and I’ll forever avoid places like that. reply factormeta 16 hours agoprevHmm if they hole point is save memory and smaller sizes, and since they are willing go with Bun (very experimental type of tech), then they should also just tried Deno. reply recroad 16 hours agoprevI have been using Vercel for production NextJS apps and have been very satisfied. reply tibozaurus 8 hours agoparentWe are too but for a simple REST API it might not be the best reply notnmeyer 17 hours agoprevthese issues aren’t particularly severe and strike me as the kind of thing you’d generally run into switching hosts. reply NicoJuicy 17 hours agoprevTLDR: They could have done it cheaper, quicker and without adding DevOps to their workload with just migrating to Cloudflare.- Vercel: 150$&#x2F;m.- Fly: 23$&#x2F;m ( + managing servers and devops)- Cloudflare: 11 $&#x2F;m.--- (original comment)They could have gone from Vercel to Cloudflare to reduce their costs.But that would have been almost no work to create a blog post about :phttps:&#x2F;&#x2F;developers.cloudflare.com&#x2F;pages&#x2F;framework-guides&#x2F;dep...Did some raw math.Cloudflare is 0,15$ per million requests and Vercel is 2$ per million requests.Their calculation for Vercel was: 77,600 * (2&#x2F;1,000,000) = 0.15c per monitor monthlySo that&#x27;s ~0,011c per monitor monthly on Cloudflare. That would be a bill of 11€ per month ( vs 150 € per month on Vercel ). Probably less, since Cloudflare doesn&#x27;t count idle CPU time, which is very relevant in this use-case ( outbound http calls) ... - https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;workers-pricing-scale-to-zero&#x2F;Which is cheaper than their VPS of 23.34$ &#x2F; month.And would have avoided managing servers + security to their workload... reply tibozaurus 8 hours agoparentFounder of OpenStatus here: We can&#x27;t use Cloudflare because there&#x27;s no way to execute in a specific region, if you know how to do it let me know reply NicoJuicy 6 hours agorootparentThat was an interesting rabbit hole, thanks :pFound this to be the best resource:https:&#x2F;&#x2F;community.cloudflare.com&#x2F;t&#x2F;how-to-force-region-in-cl...Guess it&#x27;s a bit more work than originally expected.An alternative would be to use proxy ip&#x27;s to hint regions, which would resolve to other locations. And then parse the Colo from the request. reply grrowl 16 hours agoparentprevCan you deploy 700MB Dockerfiles to Cloudflare, as they mention as a minimum requirement in the article? reply radicalriddler 15 hours agorootparentDidn&#x27;t they only need the 700MB dockerfile due to Fly.io requiring it? reply benwaffle 14 hours agorootparentFly.io supports up to 8GB docker images reply radicalriddler 14 hours agorootparentCool. By the sounds of it, they needed the docker image in the first place because they chose fly.io. This guy is saying that Cloudflare wouldn&#x27;t support it, but if they went the cloudflare route (which I&#x27;m not saying whether or not it&#x27;s actually possible), they wouldn&#x27;t have needed the docker image in the first place. reply NicoJuicy 10 hours agorootparentCorrect. Which was actually already in my tldr> TLDR: They could have done it cheaper, quicker and without adding DevOps to their workload with just migrating to Cloudflare.See: quicker= less changes required to migrate... reply NicoJuicy 16 hours agorootparentprevWhy would they need that on Cloudflare?Since they didn&#x27;t had to change much of their original functions to docker, if they would have switched to Cloudflare from Vercel directly.That would have been a lot quicker for them to do...Alternatively, Cloudflare supports hono which they moved too.https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;pages&#x2F;framework-guides&#x2F;dep... reply reducesuffering 12 hours agoparentprevIt is beyond me why anyone but the most pre-revenue bootstrapped projects would spend $150k+&#x2F;yr eng hours into saving $100 month on infra. Projects like this are trying to make $1m+&#x2F;yr in revenue. reply NicoJuicy 9 hours agorootparentThis was done in a weekend fyi ( mentioned in the blog post) reply pech0rin 17 hours agoprev [–] I find it interesting that people seem to be trading short term gains with long term reliability and maintenance costs. This glut of 0-friction deploy services lull people into a nice false sense of security.But in actuality you are wasting hours, days, weeks of time when they become unreliable, support is unresponsive, or something unexpected pops up.There is a huge advantage (outside of amateur, low importance projects) for putting in place - at the beginning - an infrastructure that is dead simple and reliable. AWS, GCP may have some upfront complexity but provide advantages in terms of reliability, knowledgeable support, and proven track records.I would never recommend these current platforms to be used for building a long term business on top of. I have been tempted by the siren song of one click deploys but in the long run so much extra time is wasted. reply yowlingcat 16 hours agoparent> I find it interesting that people seem to be trading short term gains with long term reliability and maintenance costs. This glut of 0-friction deploy services lull people into a nice false sense of security.I find it interesting as well. I agree that it&#x27;s a false sense of security, and there is no real long-term gain from avoiding the one time paydown of deploying to a big 3 cloud services provider. Still, I think the impulse reflects something a very real pain, and something I find my team continuing to face as we try to manage a the operationally minimalistic stack we can get away with on AWS -- poor DX.It does still boggle my mind that AWS still doesn&#x27;t have a Heroku-esque happy path DX that lets you get started easily and then add in complexity on an as needed basis rather than forcing it to get the most basic thing running. It seems like every minor customization requires in AWS parlance spinning up a Lambda to do something that should be a first class feature in the platform by default. Will I migrate off the platform? No. Would I use a simpler, opinionated interface that let me focus on my application and not arcanae, if AWS made it avaiable? Absolutely. reply Rapzid 15 hours agorootparentThe latest effort from AWS to address this seems to be copilot. reply kdazzle 11 hours agoparentprevAzure actually had a nice Heroku-like service that served me well for a couple years. I forget what it’s called, but it’s probably the one reason I’d ever consider choosing Azure if that was ever my call to make. reply heraldev 17 hours agoparentprev [–] This! Can&#x27;t agree more, I think we share the same idea, that&#x27;s what the tool we&#x27;re making is about: https:&#x2F;&#x2F;github.com&#x2F;mify-io&#x2F;mify&#x2F;. It generates backend service code in a scalable way from the beginning, so that you wouldn&#x27;t have to rewrite and move services to some other platform.It&#x27;s better to have good architecture from the beginning, but I understand why people choose these platforms - they are saving a lot of time in the initial development, that helps them iterate quickly. What will happen next is that people spending time and resources to perform costly migrations, and some do this more that once. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article recounts the migration of the backend of OpenStatus from Vercel to Fly.io, motivated by the need for a more lightweight server and concerns over Vercel's pricing.",
      "The transition faced challenges, such as optimizing a Docker image in a monorepo, dealing with deployment timeouts on Fly.io, and troubleshooting a bug with the Bun runtime.",
      "Despite these hurdles, the migration to Fly.io was successful, and the authors maintain their appreciation for Vercel's product."
    ],
    "commentSummary": [
      "The discussion revolves around users' experiences and opinions on migrating their backend from Vercel to Fly.io, highlighting issues with Vercel's unreliable deployments, functionality, and pricing.",
      "The impact of Vercel on React, cost-effectiveness of edge and lambda functions, and stability of the Fly.io platform are important subtopics within the discourse.",
      "The debate also includes mention of alternative platforms like DigitalOcean, Render, and Hetzner, and discusses the trade-off between short-term gains and long-term maintenance costs in deploying infrastructure."
    ],
    "points": 139,
    "commentCount": 146,
    "retryCount": 0,
    "time": 1698612626
  }
]
